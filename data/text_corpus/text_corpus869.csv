index,text
4345,this study quantifies the level of observational accuracy required from a spaceborne light detection and ranging lidar snow depth retrieval mission for enabling beneficial impacts for snow estimation the study is conducted over a region in western colorado using a suite of observing system simulation experiments osses the joint uk land environment simulator version 5 0 jules v5 0 is employed to simulate a suite of idealized lidar observations considering a range of lidar snow depth retrieval errors different hypothetical sensor swath widths and the impact of cloud cover on observability these simulated observations are then assimilated into the noah land surface model with multi parameterization options version 3 6 noah mp v3 6 model this data assimilation setup is used to systematically evaluate the potential utility of lidar observations for improving modeled snow water equivalent swe estimates and water budget variables such as runoff results from the osse runs show that in general assimilation of synthetic lidar observations provide beneficial impacts when the lidar snow depth retrieval error standard deviation σerror is below 60 cm based on comparisons between the realistic i e swath limited and cloud attenuated case and the idealized i e infinite swath width in the absence of cloud cover case this study concludes that observations with a conservative error standard deviation threshold of 40 cm i e upper limit of the snow depth retrieval error that adds value to the swe estimates via assimilation are needed for improving modeled snow estimates more than a 33 reduction in swe root mean square errors and more than a 15 increase in correlation coefficients are achieved when σerror 40 cm using a 170 km sensor swath width in the presence of cloud attenuation effects further the integrated hydrologic response as represented by total surface and subsurface runoff estimates during the snow ablation season are also enhanced when assimilating synthetic lidar snow depth retrievals with errors below this level keywords snow water equivalent lidar snow depth retrieval error swath width synthetic fraternal twin nasa land information system 1 introduction snow water equivalent swe is a key hydrological variable that impacts snowmelt runoff and river discharge in snow dominated basins and hence water availability for human and ecosystem needs however our knowledge of the spatial and temporal distribution of swe across the globe is limited especially in mountainous regions where snow is commonly found bales et al 2006 although in situ measurements provide accurate swe data interpolating or extrapolating these measurements in data sparse regions is problematic because of the significant spatial variability commonly witnessed in swe clark et al 2011b remote sensing platforms can provide spatially distributed observations though they are subject to measurement noise and errors associated with the retrieval algorithms one approach toward enhancing our understanding of swe and its spatiotemporal distribution is a data assimilation da framework that systematically merges the strengths of remote sensing observations and land surface model lsm simulations into a unified framework previous studies have shown that da is a promising means of improving swe and snow depth estimates by assimilating snow cover fraction scf e g rodell and houser 2004 su et al 2008 xue et al 2019 zaitchik and rodell 2009 microwave brightness temperature t b e g andreadis and lettenmaier 2012 durand et al 2009 kim et al 2019 kwon et al 2015 2016 2017 xue et al 2018 t b based swe snow depth retrievals e g dong et al 2007 kumar et al 2014 liu et al 2013 and terrestrial water storage tws data e g forman et al 2012 kumar et al 2016 zaitchik et al 2008 into lsms however several factors weaken the relationships between these variables i e scf t b or tws and swe and as a result often degrade da performance for example robust snow depletion relationships linking scf to swe have not yet been established nor can scf provide useful information on swe variations when the ground is fully covered with snow de lannoy et al 2012 zaitchik and rodell 2009 analogously t b observations are of limited value especially at 36 5 ghz once swe information saturates when reaching a threshold swe value ranging from 100 to 200 mm derksen 2008 de sève et al 1997 kwon et al 2019 mätzler 1994 and is further adversely affected by the presence of wet snow changes in snow grain size the presence of forest cover and proximity to open water bodies e g lakes and rivers finally improving swe estimates by using tws retrievals i e vertically integrated amount of freshwater found above and below the earth s surface including canopy water snow surface water storage soil moisture and groundwater is complicated as the correlation between swe and tws is non trivial and is significantly influenced by variations in other hydrological components that are not snow related in some regions bahrami et al 2020 the requirement of groundwater schemes in lsms kumar et al 2016 and coarse spatial horizontal and temporal resolutions of the data are additional drawbacks of assimilating the tws retrievals for swe estimation more recent work harnessing the nasa airborne snow observatory aso has yielded unprecedented snow depth data for mountain basins painter et al 2016 using an airborne scanning light detection and ranging lidar system lidar has the potential to provide high quality snow depth data during wet snow conditions when most microwave based estimation techniques tend to fail kim et al 2017 margulis et al 2019 furthermore because the majority of swe variations are largely driven by snow depth variations sturm et al 2010 it is expected that the utilization of lidar based snow depth observations within a da framework will not only significantly improve snow depth estimates but also swe estimates by association e g hedrick et al 2018 margulis et al 2019 however airborne lidar measurements are sparse in time and limited in spatial coverage hence global coverage using lidar requires a viable space based snow observing mission that currently does not exist spaceborne lidar can measure snow depth from space but compared to airborne lidar the accuracy of spaceborne lidar measurements will be affected by additional error sources such as scattering effects of cloud cover and aerosol particles moller et al 2017 russell et al 1982 coupled with pointing errors associated with the large distance between the lidar and the ground surface hunt et al 2009 therefore prior to implementing a space based lidar snow mission it is necessary to first quantify the accuracy requirements of spaceborne lidar in generating snow depth retrievals that in turn add sufficient utility to hydrological applications in addition to the feasible error characteristics of the lidar based snow depth retrievals the sensor resolution sensor swath width and repeat cycle are important factors that will dictate the scientific utility of the measurement products collected by spaceborne lidar and as a result must be explored when considering a space based lidar snow mission with the goal of quantifying the level of possible improvements in swe a hypothetical space based snow lidar system that measures snow depth is considered as part of an observing system simulation experiment osse namely the osse here conducts a synthetic fraternal twin experiment using the joint uk land environment simulator version 5 0 jules v5 0 best et al 2011 clark et al 2011a and noah lsm with multi parameterization options version 3 6 noah mp v3 6 niu et al 2011 yang et al 2011 within the nasa land information system lis kumar et al 2006 2008a peters lidard et al 2007 to explore the following research questions 1 what is the added value to modeled swe estimation associated with the assimilation of lidar based snow depth retrievals 2 what is the upper limit of error in a hypothetical spaceborne lidar snow depth retrieval that still adds value to the modeled swe estimates 3 how is the da performance influenced by the sensor swath width and the presence of cloud cover for lidar measurements and 4 does the assimilation of lidar retrievals of snow depth translate into enhanced skill at predicting total surface and subsurface runoff during the snow ablation season and if so to what level of retrieval error in short the goal of this exercise is to help answer the question that if a spaceborne lidar system for snow estimation were to be developed in the future what sensor error characteristics are required such that the lidar based retrievals add value to land surface model estimates 2 methods 2 1 land information system lis and land surface models the nasa lis is a comprehensive software framework for land surface modeling lis is an ideal framework for conducting da experiments e g de lannoy et al 2010 fang et al 2018 hall et al 2010 kumar et al 2008b 2009 as it encapsulates a variety of satellite and ground based observations advanced lsms lis lsm and sequential and non sequential da algorithms lis da in this study we employed jules v5 0 and noah mp v3 6 which are prognostic lsms embedded within lis to simulate snow state variables such as swe and snow depth fig 1 shows the structure of the experiment explained in detail in section 2 3 2 2 1 1 jules jules is a community lsm based on the met office surface exchange scheme moses cox et al 1999 model in jules the land surface is composed of grid cells such that land surface heterogeneity in a grid cell is represented by subgrid tiles which have different land surface types nine subgrid land surface types are considered in jules five plant functional types broadleaf trees needleleaf trees c3 temperate grass c4 tropical grass and shrubs and four non vegetation types urban inland water bare soil and land ice the surface energy balance is calculated for each land surface type in a given grid cell and then the grid cell mean flux is determined by weighting the values from each surface type elevation bands are also introduced for each surface type by adjusting the atmospheric forcing and surface energy balance in order to minimize spurious occurrences of sublimation and snowmelt a multilayer snowpack is used in jules and the snow layers are merged or subdivided based on the layer thickness jules simulates snowmelt refreezing of liquid water and a reduction in snow depth resulting from snow compaction liquid water is retained within the snow layers while excess water percolates to the lower layers the soil column is vertically divided into four layers with default thicknesses of 10 cm 25 cm 65 cm and 200 cm from top to bottom with a total soil depth of 3 m to capture soil temperature variations on sub daily to annual time scales best et al 2005 snow melt or precipitation at the soil surface infiltrates into the soil column or alternatively becomes surface runoff infiltration excess surface runoff is determined from the soil hydraulic conductivity which is estimated based on van genuchten 1980 with consideration of frozen soil effects cox et al 1999 2 1 2 noah mp noah mp is largely based on the original noah lsm however representations of land atmosphere interactions and hydrological processes were augmented such that multiple parameterization options were added to the model in noah mp a model grid cell is composed of a vegetation canopy layer a snowpack layer a soil layer and an unconfined aquifer layer subgrid land surface heterogeneity is represented using a semitile scheme niu et al 2011 incoming shortwave radiation is simulated based on a modified two stream approximation dickinson 1983 sellers 1985 with the assumption of evenly distributed vegetation canopies over the entire grid cell other energy components including longwave radiation latent heat flux sensible heat flux and ground heat flux are calculated separately for vegetated and non vegetated areas noah mp represents the snowpack using multiple layers up to three snow layers depending on the total snow depth analogously noah mp discretizes the soil column into four separate layers with soil thicknesses of 10 cm 30 cm 60 cm and 100 cm from top to bottom noah mp is capable of simulating snow destructive and melt metamorphisms snow layer compaction by overburden and snowmelt refreeze cycles surface runoff and groundwater discharge are computed using a simple topmodel based runoff model niu et al 2007 saturation excess surface runoff which is the main component of total surface runoff is estimated by summing the amount of rainfall snowmelt and dew encountering saturated areas the fraction of the saturated areas within a model grid cell is computed by considering inundated lowland areas where the water table depth is zero along with impermeable areas associated with frozen soil niu and yang 2006 2 2 data assimilation in this study the 1 dimensional ensemble kalman filter enkf method evensen 1994 reichle et al 2002 is employed to assimilate synthetic spaceborne lidar based snow depth retrievals into noah mp the enkf has been widely applied in many atmospheric and hydrologic studies because of its robustness efficient computation and ease of implementation keppenne 2000 enkf implementation consists of two steps 1 a forecast step and 2 an update step during the forecast step an ensemble of state vectors i e swe and snow depth is propagated by noah mp until observations i e synthetic snow depth retrievals become available each ensemble member is generated by perturbing the meteorological boundary conditions model initial conditions and model prognostic variables based on the assumption of a gaussian distribution the ensemble distribution implicitly represents the uncertainty of the model simulations during the update step each forecasted state variable a priori is updated to a new value a posteriori as follows 1 x i a x i b k y h x i b where xa is the updated model states a posteriori xb is the forecasted model states a priori subscript i denotes the ensemble member k is the kalman gain y is the observation and h is the observation operator that transforms the a priori state variables into observation space the kalman gain which weighs the model estimates and the predicted observations according to their error covariances is given by 2 k c o v x i b h x i b c o v h x i b h x i b r 1 where cov xi b hxi b is the error cross covariance of the model simulated states xi b with the predicted observations hxi b cov hxi b hxi b is the error covariance of the predicted observations and r is the covariance of the observation error see section 2 3 3 for details on the prescribed snow depth observation error standard deviations 2 3 experimental design 2 3 1 study area and model setup experiments were conducted over western colorado fig 2 fig 2 includes maps of elevation dominant land cover type and mean merra 2 modern era retrospective analysis for research and applications version 2 bosilovich et al 2015 precipitation and mean trmm tropical rainfall measuring mission trmm 3b42v7 huffman et al 2007 precipitation over the western colorado domain the digital elevation estimates fig 2a were derived from the shuttle radar topography mission srtm elevation data farr et al 2007 and the dominant land cover types fig 2b were obtained from the terra moderate resolution imaging spectroradiometer modis sensor based international geosphere biosphere programme igbp land classification map friedl et al 2002 both of which were used for land surface characterization in noah mp during the experiments the elevation of the study area ranges from 1 314 m to 4 215 m and is mostly composed of grasslands 39 6 forests 33 8 and shrublands 20 3 mid elevation regions 2500 m to 3500 m are dominated by forests while lower elevation regions 2500 m are dominated by grasslands and shrublands about 39 33 19 and 9 of higher elevation regions greater than 3500 m are covered with grasslands shrublands forests and barren or sparsely vegetated land cover types respectively large precipitation rates were observed in the central northern part of the study domain especially in the merra 2 precipitation product the study area was discretized into grid cells with a horizontal spatial resolution of 0 01 on an equidistant cylindrical projection grid jules and noah mp were initialized by spinning up a single replicate simulation from 1 may 2002 to 1 january 2005 after that for noah mp a 20 member ensemble run was further spun up from 1 january to 1 december 2005 using this ensemble to establish the initial conditions the ol and da cases were run from 1 december 2005 to 30 april 2006 this particular simulation period was selected in order to reduce computational expense without sacrificing simulation of the entire snow season that is there was no significant snowfall prior to december 1 nor was there significant melt driven surface runoff after may 1 in either the nature run or the ol hence the selection of this simulation period makes the set of experiments tractable while still enabling the simulation of both the snow accumulation and snow ablation seasons a model time step of 15 min was used and daily averaged model outputs were saved for subsequent analysis for all experiments the noah mp options of physical parameterization schemes were applied as listed in table 1 2 3 2 synthetic fraternal twin experiment the synthetic fraternal twin experiment was composed of a nature run a k a synthetic truth open loop ol and da scenarios fig 1 within the fraternal twin experiment model structure errors resulting from model physics and parameterizations were implicitly considered based on the differences between two different lsms jules as used for the nature run and noah mp as used for the ol and da cases during the nature run jules was forced by meteorological fields from merra 2 nominal estimates i e expected value of likely distributions of swe snow depth and total runoff were produced using a single replicate deterministic simulation these nominal states were considered as the truth and used during the validation of the ol and da results it is important to note that the synthetic truth need not be the actual truth but rather a reasonable representation of the true system variability the synthetic snow depth retrievals a k a synthetic observations were then created by adding random errors i e white gaussian noise with zero mean and prescribed standard deviation see section 2 3 3 for details to the synthetic snow depth truth in order to generate the synthetic observations it was assumed that the observation error was temporally and spatially horizontally uncorrelated subsampling of the synthetic snow depth retrievals in space and time was further conducted as to explicitly consider sensor swath width limitations and the effect of cloud attenuation see section 2 3 4 for details on land surface observability and hence observability i e data availability of the snow depth retrievals in the ol and da cases noah mp was similarly forced by merra 2 except that the precipitation was changed merra 2 precipitation was replaced by the trmm 3b42v7 satellite precipitation product huffman et al 2007 after applying a monthly bias correction factor which was derived by dividing the average temporally and spatially merra 2 precipitation by the average trmm precipitation for each month see kwon et al 2019 for details it is seen in fig 2c and 2d that as compared to the merra 2 precipitation estimates the bias corrected trmm precipitation used for the ol and da cases has a dry bias at high elevations while it has a wet bias at low elevations using the bias correction procedure the domain averaged climatological precipitation of trmm was matched to that of merra 2 however considerable differences in space and time still exist that serve as a reasonable proxy for the true errors potentially encountered by an operational assimilation system furthermore the nonlinear response of snow dynamics to precipitation and its errors results in significant differences in modeled swe estimates forman and reichle 2013 which is expected to be mitigated via the update equation highlighted in section 2 2 ensemble stochastic simulations for both the ol i e without assimilation and da i e with assimilation experiments were generated by perturbing the meteorological forcing boundary conditions i e precipitation shortwave radiation and longwave radiation table 2 and model prognostic variables i e swe and snow depth table 2 for the da experiments the prior ensemble of swe and snow depth were updated by assimilating the synthetic snow depth retrievals for these experiments in lis da the enkf scheme was employed note that only snow depth was directly updated during the assimilation whereas swe snow layer ice content and snow liquid water content were adjusted depending on the amount of snow depth applied during the update by assuming a constant snow density diagnostic variable calculated as the ratio of swe and snow depth and a constant snow temperature before and after the update 2 3 3 synthetic lidar snow depth retrieval error lidar measures the distance to a target by computing the elapsed time between emitted and received pulses snow depth is retrieved by differencing the snow free and snow covered surface elevations acquired by lidar at two different dates deems et al 2006 lidar snow depth retrieval error sources include topography vegetation laser scan angle and pulse rate interactions of laser light with the snow surface procedures creating the gridded dataset i e digital elevation model dem and horizontal resolution of the resulting snow depth retrieval deems and painter 2006 deems et al 2013 reported vertical errors of airborne lidar snow depth data range from 2 to 30 cm e g deems and painter 2006 harpold et al 2014 painter et al 2016 however in the context of spaceborne lidar relative to airborne lidar the errors will presumably be larger due to an increase in pointing errors in the suite of synthetic da experiments conducted here the error standard deviations of spaceborne lidar snow depth retrievals were treated as a range of feasible values including 0 02 0 10 0 15 0 20 0 30 0 40 0 50 0 60 0 70 0 80 and 0 90 m the smaller errors i e 0 02 to 0 30 m were based on the reported airborne lidar snow depth errors and the larger errors i e 0 40 to 0 90 m were used to consider additional possible error sources in the context of spaceborne lidar measurements such as cloud cover aerosol particles and a large distance to the ground surface hunt et al 2009 moller et al 2017 russell et al 1982 lidar based snow depth retrievals could have a high spatial resolution on the order of tens of meters depending on the particular lidar design however given the spaceborne context of this study and consideration of the increase in pointing errors it was assumed that spaceborne lidar snow depth products used in this study have a horizontal resolution of 0 01 spatially and temporally uncorrelated random errors drawn from a gaussian distribution with zero mean and the prescribed error standard deviation were added to the synthetic snow depth truth simulated by jules to generate the synthetic spaceborne lidar snow depth retrievals the same observation error standard deviation was used in the enkf scheme during the assimilation as expressed in equation 2 the observation error standard deviation was applied uniformly to all grid cells within the study area although the spatial distribution of snow depth retrieval uncertainty was represented by randomly drawn errors the effect of landscape characteristics such as forest land cover and rugged terrain on the observation error was not explicitly considered in the current study however the range of observation error standard deviations explored here implicitly contain these errors for values at the higher end 2 3 4 subsampling of the synthetic lidar snow depth retrievals a two step subsampling procedure was used to generate realistic albeit synthetic in design snow depth retrievals 1 subsampling with a realistic satellite viewing area and 2 subsampling with a realistic cloud mask in the first step observations within the satellite viewing area defined by the given orbital configuration and specified swath width were extracted from the synthetic truth after being corrupted with the specified observation error the viewable region of the hypothetical lidar satellite was generated using the trade space analysis tool for constellations tat c le moigne et al 2017 orbital simulator with specified sensor swath widths of 20 70 120 and 170 km in a sun synchronous polar orbit satellite altitude of 500 km and inclination angle of 92 similar to icesat 2 ice cloud and land elevation satellite 2 the existing sampling geometry of icesat 2 markus et al 2017 which includes three pairs of beams with a pair width of 90 m i e one grid width and with each pair being separated by approximately three km was also explored in the osse please note that the osse in this paper considers future spaceborne snow lidar missions beyond the capability of the currently operating missions and thus the experimental scenarios include larger swath width cases in a hypothetical environment in the second step a cloud mask using an optical depth threshold of 0 4 ackerman et al 2008 obtained from the moderate resolution imaging spectroradiometer modis terra daily surface reflectance data l2g global 1 km in mod09ga vermote and wolfe 2015 was further applied to the subsamples produced in the first step in order to account for cloud attenuation effects resulting repeat cycles of the hypothetical lidar satellite within the study domain are summarized in table 3 which were obtained from tat c it should be noted here that the overpass frequency decreases considerably as the swath width decreases and the presence of cloud cover significantly reduces the viewability of the land surface by the lidar especially for relatively narrow swath widths i e icesat2 20 km and 70 km these two factors i e swath width limitations and cloud attenuation effects greatly influence the performance of synthetic snow depth observability and thus the performance of the da framework in order to explore the effects of sensor swath width limitation and cloud attenuation i e cloud mask enforced in conjunction with the lidar snow depth retrieval errors a total of 121 da experiments were carried out as summarized in table 4 3 results and discussion this section presents results from experiments employing realistic viewing scenarios section 3 1 that consider the marginal and synergistic effects of sensor swath width limitations cloud attenuation effects and observation snow depth retrieval errors and those from experiments employing idealized viewing scenarios i e infinite swath width in the absence of cloud cover section 3 2 the idealized scenario serves as an upper bound on lidar observability and helps to assess the marginal losses to lidar utility associated with swath width limitations and cloud attenuation effects 3 1 realistic observation scenarios 3 1 1 domain averaged statistics the performance of the da framework in estimating swe under the realistic observation scenario see table 4 for experimental conditions is presented in fig 3 root mean square errors rmses fig 3a and correlation coefficients r fig 3b were calculated by comparing the estimated swe from the ol and da runs against the synthetic swe truth for each model grid cell and then spatially averaged across the study area as shown in fig 3a the domain averaged swe rmse increased as the observation error standard deviation herein σerror for simplicity of the synthetic lidar snow depth retrievals increased when the σerror 0 80 m da reduced the domain averaged swe rmse relative to the ol swe rmse 61 2 mm given a larger sensor swath width and cloud free conditions i e greater number of available observations da greatly reduced the swe rmse however as the observation error standard deviation was further increased beyond 0 80 m the snow depth retrievals added no value to noah mp swe estimates using the data assimilation framework rather a slight but non negligible degradation was observed e g 2 8 increase in the domain averaged swe rmse in the da case of the 170 km swath width as the swath width increased under the large error assumption da degradation continued to increase this feature is due to more random noise being incorporated into the a posteriori estimates across larger regions of space as the swath width increases although the swe rmse was reduced by da when σerror 0 80 m there was a convergence of the da performance between cloud free and cloud attenuated cases at σerror 0 70 m after which the cloud attenuated cases that were assimilating fewer observations across space exhibited a smaller rmse than that for the cloud free cases assimilation of the synthetic lidar snow depth retrievals also improved the domain averaged r between the da based swe estimates and true swe when σerror 0 80 m especially as more observations were made available when using a larger sensor swath width in the absence of clouds fig 3b marginal improvements in the domain averaged r were also seen even for σerror 0 90 m it is worth noting that the snow depth retrievals using the sampling geometry of the currently operating mission i e icesat 2 also added value to the swe estimates via assimilation although the improvement was relatively small i e 6 9 reduction in the swe rmse and 4 1 increase in r when σerror 0 02 m fig 3a and b respectively compared to the larger swath width cases with large retrieval errors the smaller number of available snow depth retrievals given the relatively narrow icesat 2 sampling geometry led to less random noise being incorporated into the a posteriori estimates and therefore the degradation in the da performance as the retrieval error increased was minimal as previously mentioned only snow depth was directly updated by assimilating the synthetic snow depth retrievals an updated swe is then computed based on the model s snow density at each timestep the lsm updates snow density as a ratio of the updated swe and updated snow depth fig 4 shows that snow density was also improved as a result of the snow depth assimilation routine the effects of snow depth retrieval errors and observability i e sensor swath width and cloud attenuation effects on the snow density estimates were comparable to those for the swe estimates it should be noted that there is a trade off between the sensor swath width and data accuracy especially in mountainous areas rugged terrain may add more error and uncertainty to the snow depth retrievals from lidar measurements given a larger sensor swath width due to a larger scan angle although the snow depth retrieval uncertainties resulting from the effects of landscape characteristics and sensor swath widths were not explicitly analyzed fig 3 provides useful information for determining the allowable snow depth error range of the selected sensor swath width in order to provide improved estimates of swe via assimilation rather than a narrower sensor swath width with smaller measurement errors in mountainous areas for example the largest swath width i e 170 km with σerror 0 80 m led to better estimates of swe in terms of the domain averaged rmse than the narrowest swath width i e icesat 2 sampling geometry with σerror 0 02 m 3 1 2 spatial and temporal patterns maps of swe rmse relative to the synthetic truth from the ol and da runs for the 170 km swath width and cloud attenuation cases as well as their differences computed as rmseda rmseol are presented in fig 5 large swe estimation errors in the ol fig 5a were observed during relatively deep snow conditions in the synthetic truth fig 5j when the bias corrected trmm mean precipitation exhibited a dry bias see fig 2c and d in contrast the large ol swe errors were also witnessed during relatively shallow snow conditions in the synthetic truth when the trmm mean precipitation yielded a wet bias da significantly reduced these estimation errors fig 5 the largest improvements in swe estimates and snow depth by construct were achieved in high elevation regions as shown in fig 6 where relatively deep snow conditions are found da efficacy decreased as the snow depth observation error increased and marginal degradation of swe estimates positive values in fig 6 was witnessed in low elevation regions i e 1 3 km elevation 2 5 km especially when σerror 0 80 m but da was still effective in improving swe estimates in high elevation areas fig 7 a shows the time series of the domain averaged swe for the da experiments assimilating synthetic snow depth retrievals with a sensor swath width of 170 km that includes cloud effects across a range of observation errors fig 7b uses a fixed observation error standard deviation of 0 10 m but includes both cloud free results along with results accounting for cloud attenuation it should be noted in fig 7a that considerable improvements in swe estimates were achieved during both the snow accumulation and snow ablation periods when σerror 0 60 m assimilation of the snow depth retrievals with σerror 0 70 m and σerror 0 80 m only marginally improved swe estimates during the snow accumulation period but could not improve the snow ablation timing fig 7b shows that when σerror 0 10 m larger swath width scenarios outperformed the smaller swath width scenarios and that cloud attenuation effects significantly reduced the efficacy of the da framework 3 2 idealized observation scenarios 3 2 1 domain averaged statistics the domain averaged rmse domain averaged r and percentages of model grid cells improved or degraded by da in terms of swe rmse under the idealized observation scenario were plotted in fig 8 a 8b and 8c respectively compared to the ol case there was an 87 improvement in the domain averaged swe rmse achieved by assimilating synthetic snow depth retrievals with the smallest error i e σerror 0 02 m da improved the swe estimates by more than 58 when the snow depth error is within the reported range of airborne lidar snow depth i e 0 02 m σerror 0 30 m snow depth retrievals continued to add value to noah mp via assimilation for snow depth observation error standard deviations up to 0 60 m most notably in regions with relatively deep snow commonly found at higher altitudes however assimilating the synthetic lidar snow depth retrievals increased the domain averaged swe rmse relative to the ol when σerror 0 70 m and a 39 increase in the swe rmse occurred when the largest experimental error of σerror 0 90 m was applied these results quantitatively suggest that retrieval error standard deviations greater than 0 70 m during idealized observing conditions result in a deleterious amount of noise being incorporated into the a posteriori swe estimates that makes the model worse than if no assimilation had been conducted i e open loop the results also highlight how correlation coefficients r between the synthetic swe truth and the estimated swe were considerably improved by assimilating the synthetic snow depth retrievals fig 8b the domain averaged r decreased as σerror increased and da began to degrade the correlation compared to the ol once σerror 0 60 m fig 8b even though swe rmse still experienced improvements fig 8a the da procedure improved swe estimates for more than 74 of model grid cells within the study domain when σerror 0 30 m fig 8c as σerror increased the da framework yielded a more mixed performance with respect to the number of improved and degraded grid cells da improved swe estimates for more than half i e 55 of model grid cells up to σerror 0 60 m but more than half of model grid cells were degraded by da when the snow depth retrievals contained larger amounts of error i e σerror 0 70 m 3 2 2 spatial and temporal patterns the performance gains using the idealized snow depth retrievals and the improvements in modeled swe via assimilation were rapidly reduced as the snow depth retrieval error increased fig 9 c e g and i compared to the swath limited cloud attenuated cases fig 5 the idealized cases exhibited greater improvements in the swe estimates when σerror was small fig 9c and e whereas more pronounced degradations were observed when σerror was large fig 9g and i similar performance patterns were also witnessed when the swe rmse differences between the da and ol cases i e rmseda rmseol were computed for different elevation bands fig 10 this behavior is further discussed in section 3 3 where an error standard deviation threshold of the hypothetical spaceborne lidar snow depth retrievals are suggested figure 11 shows the time series of the domain averaged ensemble mean swe from the ol and da experiments along with the synthetic truth it should be noted here that noah mp without assimilation i e ol significantly overestimated swe mainly due to errors in the precipitation boundary conditions and model structure i e physics and parameterizations and that this swe estimation error was significantly reduced by assimilating the synthetic lidar snow depth retrievals during both the snow accumulation and snow ablation periods the magnitude and timing of snow ablation runoff were well reproduced in the da cases that assimilated the snow depth observations with small errors i e σerror 0 30 m even though the peak swe was slightly overestimated when the assimilated snow depth observations contained relatively large errors i e σerror 0 70 m da further extended the ablation season beyond that contained in the ol 3 3 snow depth retrieval error standard deviation threshold overall based on the domain averaged da evaluation statistics fig 3 from the swath limited cloud attenuated observation scenarios in western colorado the lidar retrievals added value to the swe estimates via assimilation when σerror 0 80 m while a smaller σerror i e σerror 0 50 m was required under the idealized viewing conditions i e infinite swath width in the absence of cloud cover in order to improve swe estimates with respect to rmse r and both the snow accumulation magnitude and snow ablation timing as shown in fig 3 the da experimental results in general showed that assimilation of a larger number of snow depth retrievals i e when using a larger sensor swath width in the absence of clouds resulted in better estimates of swe however in fig 12 a reversal of the da performance between the idealized i e full coverage in space and time and realistic i e assuming 170 km swath width cloud attenuation effects sensor viewing scenarios was observed at σerror 0 60 m for the domain averaged swe rmse fig 12a and the percentage of improved grid cells fig 12c and at σerror 0 50 m for the domain averaged r fig 12b this implies that spaceborne lidar snow depth retrievals containing σerror 0 50 m may degrade swe estimates via assimilation when a sensor swath width greater than 170 km is used under cloud free conditions as more random error is incorporated into the a posteriori estimates of swe therefore we would suggest σerror 0 40 m as a conservative error threshold i e upper limit of the snow depth retrieval error that adds value to the swe estimates when using the data assimilation framework although a larger error limit σerror 0 80 m was obtained in the swath limited cloud attenuated observation scenarios 3 4 total runoff estimation snowmelt contributes significantly to total surface and subsurface runoff in mountainous regions griessinger et al 2016 hall 1988 thus an improved estimation of swe via assimilation should enhance the prediction of total runoff e g clark et al 2006 griessinger et al 2016 stigter et al 2017 sun et al 2004 in this section the added value of synthetic spaceborne lidar snow depth retrievals on total runoff estimation was also analyzed figure 13 shows that time integrated total runoff within the study domain was significantly overestimated in the ol during the snow ablation period due to the large overestimation of swe as shown in fig 7 and it was improved by assimilating the synthetic lidar snow depth retrievals for all error assumptions i e 0 02 m σerror 0 90 m larger improvements occurred during the cloud free experiments but improvements still occurred when realistic cloud attenuation effects were introduced although the snow depth retrievals containing the smallest error i e σerror 0 02 m with the largest swath width i e 170 km in the absence of cloud cover achieved the greatest improvement in swe estimates via assimilation as shown in fig 3 it underestimated the time integrated total runoff by about 7 4 relative to the synthetic truth fig 13b this may be attributed to noah mp model structure errors relative to jules especially model physics and parameterizations related to snow melt infiltration and surface and subsurface runoff given the structure of the fraternal twin experiment on the other hand application of the smallest observation error led to the largest improvements in estimates of both swe and total runoff when an identical twin experiment i e in the absence of model structure error via use of the same noah mp lsm for both the nature run and da results not shown here was conducted the percent difference between the simulated and observed synthetic truth total runoff was within 50 of the synthetic truth of total runoff for the da cases using sensor swath widths of 70 km 120 km and 170 km when σerror 0 02 m as shown in fig 13b alternatively the total runoff difference was within the 50 range only in the da case using the 170 km swath width under cloud free conditions when σerror 0 40 m the total runoff difference exceeded the 50 range fig 13b for all experimental scenarios when σerror greater than 0 40 m or when using narrow swath widths i e icesat 2 sampling geometry or 20 km swath width scenario assimilation of the synthetic lidar snow depth retrievals was also effective in increasing the nash sutcliffe efficiency nse for runoff compared to the ol across the ranges of σerror and sensor swath widths used in this study fig 13c overall higher nse values were obtained by da when using a smaller σerror and a larger sensor swath width however the response of the runoff nse to σerror was nonlinear for σerror 0 40 m with sensor swath widths of 70 km 120 km and 170 km when a relatively large amount of the swe was updated during the assimilation fig 14 shows that snowmelt driven runoff was largely overestimated by the model during the end of snow season due to the swe overestimation which was largely mitigated using da routine especially when given a smaller σerror and a larger sensor swath width assimilation of the synthetic lidar snow depth retrievals significantly reduced the runoff bias but exhibited low skill in improving the temporal variability of runoff leading to low nse values 0 2 4 summary and conclusions a synthetic study for a hypothetical spaceborne lidar snow depth retrieval assimilation system was conducted over western colorado as part of an osse to study swe and snowmelt runoff characterization a total of 121 data assimilation experiments were conducted using nasa lis to address a number of research questions associated with the error characteristics of the snow depth retrievals sensor swath widths and the impact of clouds on sensor viewability of a hypothetical spaceborne snow lidar the results from the synthetic fraternal twin experiment were analyzed for a single snow season from 01 december 2005 to 30 april 2006 assimilation of the idealized snow depth retrievals i e infinite swath width in the absence of cloud cover was effective at improving swe estimates with respect to the domain averaged swe rmse correlation coefficient the percentage of improved model grid cells and both the snow accumulation magnitude and snow ablation timing when the prescribed snow depth error standard deviation was 0 50 m or less i e σerror 0 50 m while explicit consideration of the effects of the sensor swath width limitations and cloud cover attenuation on the availability of the snow depth retrievals significantly reduced da effectiveness improvements in the swe estimates were observed up to σerror 0 80 m for the swath limited cloud attenuated observation scenarios significant improvements p 0 05 in the total runoff estimates during the snow ablation period resulting from the enhanced swe estimates by da were also observed in general assimilation of a greater number of snow depth observations when using a larger sensor swath width under cloud free conditions led to better estimates of swe when σerror 0 60 m however at larger snow depth retrieval errors the da framework degraded the modeled swe estimates when a greater number of observations were assimilated because more random error was incorporated into the a posteriori estimates this deleterious behavior in da performance was witnessed for both the idealized and realistic sensor viewing scenarios more specifically the realistic i e swath limited and cloud attenuated cases outperformed the idealized i e infinite swath width in the absence of cloud cover cases when σerror 0 60 m for the domain averaged swe rmse and σerror 0 50 m for the domain averaged r based on this behavior in da performance a conservative error threshold of σerror 0 40 m i e a value slightly larger than the range of the reported airborne lidar snow depth errors is recommended here as an upper threshold of retrieval error in the design of spaceborne lidar snow depth retrievals in order to add utility to an assimilation system in the context of terrestrial snow across western colorado the results obtained in this study also have promising implications for multi sensor data assimilation in order to further enhance land surface snow estimates noticeable improvements in the swe estimates through synthetic lidar snow depth retrieval assimilation were found in high elevation regions where relatively deep snow exists this is the opposite result to that obtained in kwon et al 2019 in which passive microwave brightness temperature spectral differences δt b were assimilated into the same noah mp model over high mountain asia results showed that the δt b assimilation was ineffective for deep snow conditions i e swe greater than 100 to 200 mm mainly due to the passive microwave signal saturation issue to this end lidar and microwave radiometry could potentially complement one another within a multi variate assimilation procedure for example passive microwave radiation is not significantly attenuated by cloud cover whereas lidar is alternatively lidar can accurately measure snow depth during wet snow conditions whereas passive microwave retrievals cannot kim et al 2017 margulis et al 2019 simultaneous assimilation of these two disparate data sets i e microwave δt b and lidar snow depth should also be explored in future studies we acknowledge several limitations of this study that need to be addressed in future studies first the suggested threshold value on the snow depth retrieval error standard deviation is influenced by the specific choice of meteorological boundary conditions land surface models spatial and temporal domains and perturbation parameter values applied to the atmospheric boundary conditions and model state variables used in this particular study future studies should explore these contributing factors in order to further constrain these findings second as previously mentioned a spatially constant σerror was applied across the study domain which likely affected the results presented in this study future studies should conduct more refined experiments to discern spatially distributed σerror thresholds e g for different land cover types third a cost evaluation of a spaceborne lidar snow mission design has not been conducted here because the osse herein assumed that technical limitations are beyond the scope of this current paper however obtaining wall to wall coverage of global snow observations via spaceborne lidar will require a lot of power and thus a presumably exorbitant cost under current technical capabilities therefore a follow up osse should evaluate the cost for the suggested scientific requirements finally river discharge estimates were not presented due to the lack of a dynamic river routing scheme in the lsms used in this study in order to draw more complete hydrological implications from the experiments a coupled lsm river routing model needs to be explored despite these limitations this study suggests two promising aspects first even in the narrowest viewing scenarios using the sampling geometry of the currently operating spaceborne lidar mission i e icesat 2 assimilation of lidar based snow depth retrievals can improve the swe estimates when σerror is less than the suggested threshold although the magnitude of improvement is relatively small second advancements in technical capabilities such as improvements in sensor viewability i e larger swath width with a utilitarian degree of accuracy i e σerror 0 40 m can lead to significant improvements in modeled swe estimates when the model and observations are merged via assimilation these findings suggest that it is worthwhile to further scientific investigations into satellite based lidar missions for the purpose of global swe monitoring credit authorship contribution statement yonghwan kwon conceptualization formal analysis investigation methodology validation visualization writing original draft writing review editing yeosang yoon methodology software writing review editing barton a forman conceptualization methodology funding acquisition supervision writing review editing sujay v kumar conceptualization methodology software writing review editing lizhao wang data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the tat c development team for providing their tools and data this work was supported by the nasa advanced information systems technology aist program grants 80nssc17k0254 and 80nssc20k0210 
4345,this study quantifies the level of observational accuracy required from a spaceborne light detection and ranging lidar snow depth retrieval mission for enabling beneficial impacts for snow estimation the study is conducted over a region in western colorado using a suite of observing system simulation experiments osses the joint uk land environment simulator version 5 0 jules v5 0 is employed to simulate a suite of idealized lidar observations considering a range of lidar snow depth retrieval errors different hypothetical sensor swath widths and the impact of cloud cover on observability these simulated observations are then assimilated into the noah land surface model with multi parameterization options version 3 6 noah mp v3 6 model this data assimilation setup is used to systematically evaluate the potential utility of lidar observations for improving modeled snow water equivalent swe estimates and water budget variables such as runoff results from the osse runs show that in general assimilation of synthetic lidar observations provide beneficial impacts when the lidar snow depth retrieval error standard deviation σerror is below 60 cm based on comparisons between the realistic i e swath limited and cloud attenuated case and the idealized i e infinite swath width in the absence of cloud cover case this study concludes that observations with a conservative error standard deviation threshold of 40 cm i e upper limit of the snow depth retrieval error that adds value to the swe estimates via assimilation are needed for improving modeled snow estimates more than a 33 reduction in swe root mean square errors and more than a 15 increase in correlation coefficients are achieved when σerror 40 cm using a 170 km sensor swath width in the presence of cloud attenuation effects further the integrated hydrologic response as represented by total surface and subsurface runoff estimates during the snow ablation season are also enhanced when assimilating synthetic lidar snow depth retrievals with errors below this level keywords snow water equivalent lidar snow depth retrieval error swath width synthetic fraternal twin nasa land information system 1 introduction snow water equivalent swe is a key hydrological variable that impacts snowmelt runoff and river discharge in snow dominated basins and hence water availability for human and ecosystem needs however our knowledge of the spatial and temporal distribution of swe across the globe is limited especially in mountainous regions where snow is commonly found bales et al 2006 although in situ measurements provide accurate swe data interpolating or extrapolating these measurements in data sparse regions is problematic because of the significant spatial variability commonly witnessed in swe clark et al 2011b remote sensing platforms can provide spatially distributed observations though they are subject to measurement noise and errors associated with the retrieval algorithms one approach toward enhancing our understanding of swe and its spatiotemporal distribution is a data assimilation da framework that systematically merges the strengths of remote sensing observations and land surface model lsm simulations into a unified framework previous studies have shown that da is a promising means of improving swe and snow depth estimates by assimilating snow cover fraction scf e g rodell and houser 2004 su et al 2008 xue et al 2019 zaitchik and rodell 2009 microwave brightness temperature t b e g andreadis and lettenmaier 2012 durand et al 2009 kim et al 2019 kwon et al 2015 2016 2017 xue et al 2018 t b based swe snow depth retrievals e g dong et al 2007 kumar et al 2014 liu et al 2013 and terrestrial water storage tws data e g forman et al 2012 kumar et al 2016 zaitchik et al 2008 into lsms however several factors weaken the relationships between these variables i e scf t b or tws and swe and as a result often degrade da performance for example robust snow depletion relationships linking scf to swe have not yet been established nor can scf provide useful information on swe variations when the ground is fully covered with snow de lannoy et al 2012 zaitchik and rodell 2009 analogously t b observations are of limited value especially at 36 5 ghz once swe information saturates when reaching a threshold swe value ranging from 100 to 200 mm derksen 2008 de sève et al 1997 kwon et al 2019 mätzler 1994 and is further adversely affected by the presence of wet snow changes in snow grain size the presence of forest cover and proximity to open water bodies e g lakes and rivers finally improving swe estimates by using tws retrievals i e vertically integrated amount of freshwater found above and below the earth s surface including canopy water snow surface water storage soil moisture and groundwater is complicated as the correlation between swe and tws is non trivial and is significantly influenced by variations in other hydrological components that are not snow related in some regions bahrami et al 2020 the requirement of groundwater schemes in lsms kumar et al 2016 and coarse spatial horizontal and temporal resolutions of the data are additional drawbacks of assimilating the tws retrievals for swe estimation more recent work harnessing the nasa airborne snow observatory aso has yielded unprecedented snow depth data for mountain basins painter et al 2016 using an airborne scanning light detection and ranging lidar system lidar has the potential to provide high quality snow depth data during wet snow conditions when most microwave based estimation techniques tend to fail kim et al 2017 margulis et al 2019 furthermore because the majority of swe variations are largely driven by snow depth variations sturm et al 2010 it is expected that the utilization of lidar based snow depth observations within a da framework will not only significantly improve snow depth estimates but also swe estimates by association e g hedrick et al 2018 margulis et al 2019 however airborne lidar measurements are sparse in time and limited in spatial coverage hence global coverage using lidar requires a viable space based snow observing mission that currently does not exist spaceborne lidar can measure snow depth from space but compared to airborne lidar the accuracy of spaceborne lidar measurements will be affected by additional error sources such as scattering effects of cloud cover and aerosol particles moller et al 2017 russell et al 1982 coupled with pointing errors associated with the large distance between the lidar and the ground surface hunt et al 2009 therefore prior to implementing a space based lidar snow mission it is necessary to first quantify the accuracy requirements of spaceborne lidar in generating snow depth retrievals that in turn add sufficient utility to hydrological applications in addition to the feasible error characteristics of the lidar based snow depth retrievals the sensor resolution sensor swath width and repeat cycle are important factors that will dictate the scientific utility of the measurement products collected by spaceborne lidar and as a result must be explored when considering a space based lidar snow mission with the goal of quantifying the level of possible improvements in swe a hypothetical space based snow lidar system that measures snow depth is considered as part of an observing system simulation experiment osse namely the osse here conducts a synthetic fraternal twin experiment using the joint uk land environment simulator version 5 0 jules v5 0 best et al 2011 clark et al 2011a and noah lsm with multi parameterization options version 3 6 noah mp v3 6 niu et al 2011 yang et al 2011 within the nasa land information system lis kumar et al 2006 2008a peters lidard et al 2007 to explore the following research questions 1 what is the added value to modeled swe estimation associated with the assimilation of lidar based snow depth retrievals 2 what is the upper limit of error in a hypothetical spaceborne lidar snow depth retrieval that still adds value to the modeled swe estimates 3 how is the da performance influenced by the sensor swath width and the presence of cloud cover for lidar measurements and 4 does the assimilation of lidar retrievals of snow depth translate into enhanced skill at predicting total surface and subsurface runoff during the snow ablation season and if so to what level of retrieval error in short the goal of this exercise is to help answer the question that if a spaceborne lidar system for snow estimation were to be developed in the future what sensor error characteristics are required such that the lidar based retrievals add value to land surface model estimates 2 methods 2 1 land information system lis and land surface models the nasa lis is a comprehensive software framework for land surface modeling lis is an ideal framework for conducting da experiments e g de lannoy et al 2010 fang et al 2018 hall et al 2010 kumar et al 2008b 2009 as it encapsulates a variety of satellite and ground based observations advanced lsms lis lsm and sequential and non sequential da algorithms lis da in this study we employed jules v5 0 and noah mp v3 6 which are prognostic lsms embedded within lis to simulate snow state variables such as swe and snow depth fig 1 shows the structure of the experiment explained in detail in section 2 3 2 2 1 1 jules jules is a community lsm based on the met office surface exchange scheme moses cox et al 1999 model in jules the land surface is composed of grid cells such that land surface heterogeneity in a grid cell is represented by subgrid tiles which have different land surface types nine subgrid land surface types are considered in jules five plant functional types broadleaf trees needleleaf trees c3 temperate grass c4 tropical grass and shrubs and four non vegetation types urban inland water bare soil and land ice the surface energy balance is calculated for each land surface type in a given grid cell and then the grid cell mean flux is determined by weighting the values from each surface type elevation bands are also introduced for each surface type by adjusting the atmospheric forcing and surface energy balance in order to minimize spurious occurrences of sublimation and snowmelt a multilayer snowpack is used in jules and the snow layers are merged or subdivided based on the layer thickness jules simulates snowmelt refreezing of liquid water and a reduction in snow depth resulting from snow compaction liquid water is retained within the snow layers while excess water percolates to the lower layers the soil column is vertically divided into four layers with default thicknesses of 10 cm 25 cm 65 cm and 200 cm from top to bottom with a total soil depth of 3 m to capture soil temperature variations on sub daily to annual time scales best et al 2005 snow melt or precipitation at the soil surface infiltrates into the soil column or alternatively becomes surface runoff infiltration excess surface runoff is determined from the soil hydraulic conductivity which is estimated based on van genuchten 1980 with consideration of frozen soil effects cox et al 1999 2 1 2 noah mp noah mp is largely based on the original noah lsm however representations of land atmosphere interactions and hydrological processes were augmented such that multiple parameterization options were added to the model in noah mp a model grid cell is composed of a vegetation canopy layer a snowpack layer a soil layer and an unconfined aquifer layer subgrid land surface heterogeneity is represented using a semitile scheme niu et al 2011 incoming shortwave radiation is simulated based on a modified two stream approximation dickinson 1983 sellers 1985 with the assumption of evenly distributed vegetation canopies over the entire grid cell other energy components including longwave radiation latent heat flux sensible heat flux and ground heat flux are calculated separately for vegetated and non vegetated areas noah mp represents the snowpack using multiple layers up to three snow layers depending on the total snow depth analogously noah mp discretizes the soil column into four separate layers with soil thicknesses of 10 cm 30 cm 60 cm and 100 cm from top to bottom noah mp is capable of simulating snow destructive and melt metamorphisms snow layer compaction by overburden and snowmelt refreeze cycles surface runoff and groundwater discharge are computed using a simple topmodel based runoff model niu et al 2007 saturation excess surface runoff which is the main component of total surface runoff is estimated by summing the amount of rainfall snowmelt and dew encountering saturated areas the fraction of the saturated areas within a model grid cell is computed by considering inundated lowland areas where the water table depth is zero along with impermeable areas associated with frozen soil niu and yang 2006 2 2 data assimilation in this study the 1 dimensional ensemble kalman filter enkf method evensen 1994 reichle et al 2002 is employed to assimilate synthetic spaceborne lidar based snow depth retrievals into noah mp the enkf has been widely applied in many atmospheric and hydrologic studies because of its robustness efficient computation and ease of implementation keppenne 2000 enkf implementation consists of two steps 1 a forecast step and 2 an update step during the forecast step an ensemble of state vectors i e swe and snow depth is propagated by noah mp until observations i e synthetic snow depth retrievals become available each ensemble member is generated by perturbing the meteorological boundary conditions model initial conditions and model prognostic variables based on the assumption of a gaussian distribution the ensemble distribution implicitly represents the uncertainty of the model simulations during the update step each forecasted state variable a priori is updated to a new value a posteriori as follows 1 x i a x i b k y h x i b where xa is the updated model states a posteriori xb is the forecasted model states a priori subscript i denotes the ensemble member k is the kalman gain y is the observation and h is the observation operator that transforms the a priori state variables into observation space the kalman gain which weighs the model estimates and the predicted observations according to their error covariances is given by 2 k c o v x i b h x i b c o v h x i b h x i b r 1 where cov xi b hxi b is the error cross covariance of the model simulated states xi b with the predicted observations hxi b cov hxi b hxi b is the error covariance of the predicted observations and r is the covariance of the observation error see section 2 3 3 for details on the prescribed snow depth observation error standard deviations 2 3 experimental design 2 3 1 study area and model setup experiments were conducted over western colorado fig 2 fig 2 includes maps of elevation dominant land cover type and mean merra 2 modern era retrospective analysis for research and applications version 2 bosilovich et al 2015 precipitation and mean trmm tropical rainfall measuring mission trmm 3b42v7 huffman et al 2007 precipitation over the western colorado domain the digital elevation estimates fig 2a were derived from the shuttle radar topography mission srtm elevation data farr et al 2007 and the dominant land cover types fig 2b were obtained from the terra moderate resolution imaging spectroradiometer modis sensor based international geosphere biosphere programme igbp land classification map friedl et al 2002 both of which were used for land surface characterization in noah mp during the experiments the elevation of the study area ranges from 1 314 m to 4 215 m and is mostly composed of grasslands 39 6 forests 33 8 and shrublands 20 3 mid elevation regions 2500 m to 3500 m are dominated by forests while lower elevation regions 2500 m are dominated by grasslands and shrublands about 39 33 19 and 9 of higher elevation regions greater than 3500 m are covered with grasslands shrublands forests and barren or sparsely vegetated land cover types respectively large precipitation rates were observed in the central northern part of the study domain especially in the merra 2 precipitation product the study area was discretized into grid cells with a horizontal spatial resolution of 0 01 on an equidistant cylindrical projection grid jules and noah mp were initialized by spinning up a single replicate simulation from 1 may 2002 to 1 january 2005 after that for noah mp a 20 member ensemble run was further spun up from 1 january to 1 december 2005 using this ensemble to establish the initial conditions the ol and da cases were run from 1 december 2005 to 30 april 2006 this particular simulation period was selected in order to reduce computational expense without sacrificing simulation of the entire snow season that is there was no significant snowfall prior to december 1 nor was there significant melt driven surface runoff after may 1 in either the nature run or the ol hence the selection of this simulation period makes the set of experiments tractable while still enabling the simulation of both the snow accumulation and snow ablation seasons a model time step of 15 min was used and daily averaged model outputs were saved for subsequent analysis for all experiments the noah mp options of physical parameterization schemes were applied as listed in table 1 2 3 2 synthetic fraternal twin experiment the synthetic fraternal twin experiment was composed of a nature run a k a synthetic truth open loop ol and da scenarios fig 1 within the fraternal twin experiment model structure errors resulting from model physics and parameterizations were implicitly considered based on the differences between two different lsms jules as used for the nature run and noah mp as used for the ol and da cases during the nature run jules was forced by meteorological fields from merra 2 nominal estimates i e expected value of likely distributions of swe snow depth and total runoff were produced using a single replicate deterministic simulation these nominal states were considered as the truth and used during the validation of the ol and da results it is important to note that the synthetic truth need not be the actual truth but rather a reasonable representation of the true system variability the synthetic snow depth retrievals a k a synthetic observations were then created by adding random errors i e white gaussian noise with zero mean and prescribed standard deviation see section 2 3 3 for details to the synthetic snow depth truth in order to generate the synthetic observations it was assumed that the observation error was temporally and spatially horizontally uncorrelated subsampling of the synthetic snow depth retrievals in space and time was further conducted as to explicitly consider sensor swath width limitations and the effect of cloud attenuation see section 2 3 4 for details on land surface observability and hence observability i e data availability of the snow depth retrievals in the ol and da cases noah mp was similarly forced by merra 2 except that the precipitation was changed merra 2 precipitation was replaced by the trmm 3b42v7 satellite precipitation product huffman et al 2007 after applying a monthly bias correction factor which was derived by dividing the average temporally and spatially merra 2 precipitation by the average trmm precipitation for each month see kwon et al 2019 for details it is seen in fig 2c and 2d that as compared to the merra 2 precipitation estimates the bias corrected trmm precipitation used for the ol and da cases has a dry bias at high elevations while it has a wet bias at low elevations using the bias correction procedure the domain averaged climatological precipitation of trmm was matched to that of merra 2 however considerable differences in space and time still exist that serve as a reasonable proxy for the true errors potentially encountered by an operational assimilation system furthermore the nonlinear response of snow dynamics to precipitation and its errors results in significant differences in modeled swe estimates forman and reichle 2013 which is expected to be mitigated via the update equation highlighted in section 2 2 ensemble stochastic simulations for both the ol i e without assimilation and da i e with assimilation experiments were generated by perturbing the meteorological forcing boundary conditions i e precipitation shortwave radiation and longwave radiation table 2 and model prognostic variables i e swe and snow depth table 2 for the da experiments the prior ensemble of swe and snow depth were updated by assimilating the synthetic snow depth retrievals for these experiments in lis da the enkf scheme was employed note that only snow depth was directly updated during the assimilation whereas swe snow layer ice content and snow liquid water content were adjusted depending on the amount of snow depth applied during the update by assuming a constant snow density diagnostic variable calculated as the ratio of swe and snow depth and a constant snow temperature before and after the update 2 3 3 synthetic lidar snow depth retrieval error lidar measures the distance to a target by computing the elapsed time between emitted and received pulses snow depth is retrieved by differencing the snow free and snow covered surface elevations acquired by lidar at two different dates deems et al 2006 lidar snow depth retrieval error sources include topography vegetation laser scan angle and pulse rate interactions of laser light with the snow surface procedures creating the gridded dataset i e digital elevation model dem and horizontal resolution of the resulting snow depth retrieval deems and painter 2006 deems et al 2013 reported vertical errors of airborne lidar snow depth data range from 2 to 30 cm e g deems and painter 2006 harpold et al 2014 painter et al 2016 however in the context of spaceborne lidar relative to airborne lidar the errors will presumably be larger due to an increase in pointing errors in the suite of synthetic da experiments conducted here the error standard deviations of spaceborne lidar snow depth retrievals were treated as a range of feasible values including 0 02 0 10 0 15 0 20 0 30 0 40 0 50 0 60 0 70 0 80 and 0 90 m the smaller errors i e 0 02 to 0 30 m were based on the reported airborne lidar snow depth errors and the larger errors i e 0 40 to 0 90 m were used to consider additional possible error sources in the context of spaceborne lidar measurements such as cloud cover aerosol particles and a large distance to the ground surface hunt et al 2009 moller et al 2017 russell et al 1982 lidar based snow depth retrievals could have a high spatial resolution on the order of tens of meters depending on the particular lidar design however given the spaceborne context of this study and consideration of the increase in pointing errors it was assumed that spaceborne lidar snow depth products used in this study have a horizontal resolution of 0 01 spatially and temporally uncorrelated random errors drawn from a gaussian distribution with zero mean and the prescribed error standard deviation were added to the synthetic snow depth truth simulated by jules to generate the synthetic spaceborne lidar snow depth retrievals the same observation error standard deviation was used in the enkf scheme during the assimilation as expressed in equation 2 the observation error standard deviation was applied uniformly to all grid cells within the study area although the spatial distribution of snow depth retrieval uncertainty was represented by randomly drawn errors the effect of landscape characteristics such as forest land cover and rugged terrain on the observation error was not explicitly considered in the current study however the range of observation error standard deviations explored here implicitly contain these errors for values at the higher end 2 3 4 subsampling of the synthetic lidar snow depth retrievals a two step subsampling procedure was used to generate realistic albeit synthetic in design snow depth retrievals 1 subsampling with a realistic satellite viewing area and 2 subsampling with a realistic cloud mask in the first step observations within the satellite viewing area defined by the given orbital configuration and specified swath width were extracted from the synthetic truth after being corrupted with the specified observation error the viewable region of the hypothetical lidar satellite was generated using the trade space analysis tool for constellations tat c le moigne et al 2017 orbital simulator with specified sensor swath widths of 20 70 120 and 170 km in a sun synchronous polar orbit satellite altitude of 500 km and inclination angle of 92 similar to icesat 2 ice cloud and land elevation satellite 2 the existing sampling geometry of icesat 2 markus et al 2017 which includes three pairs of beams with a pair width of 90 m i e one grid width and with each pair being separated by approximately three km was also explored in the osse please note that the osse in this paper considers future spaceborne snow lidar missions beyond the capability of the currently operating missions and thus the experimental scenarios include larger swath width cases in a hypothetical environment in the second step a cloud mask using an optical depth threshold of 0 4 ackerman et al 2008 obtained from the moderate resolution imaging spectroradiometer modis terra daily surface reflectance data l2g global 1 km in mod09ga vermote and wolfe 2015 was further applied to the subsamples produced in the first step in order to account for cloud attenuation effects resulting repeat cycles of the hypothetical lidar satellite within the study domain are summarized in table 3 which were obtained from tat c it should be noted here that the overpass frequency decreases considerably as the swath width decreases and the presence of cloud cover significantly reduces the viewability of the land surface by the lidar especially for relatively narrow swath widths i e icesat2 20 km and 70 km these two factors i e swath width limitations and cloud attenuation effects greatly influence the performance of synthetic snow depth observability and thus the performance of the da framework in order to explore the effects of sensor swath width limitation and cloud attenuation i e cloud mask enforced in conjunction with the lidar snow depth retrieval errors a total of 121 da experiments were carried out as summarized in table 4 3 results and discussion this section presents results from experiments employing realistic viewing scenarios section 3 1 that consider the marginal and synergistic effects of sensor swath width limitations cloud attenuation effects and observation snow depth retrieval errors and those from experiments employing idealized viewing scenarios i e infinite swath width in the absence of cloud cover section 3 2 the idealized scenario serves as an upper bound on lidar observability and helps to assess the marginal losses to lidar utility associated with swath width limitations and cloud attenuation effects 3 1 realistic observation scenarios 3 1 1 domain averaged statistics the performance of the da framework in estimating swe under the realistic observation scenario see table 4 for experimental conditions is presented in fig 3 root mean square errors rmses fig 3a and correlation coefficients r fig 3b were calculated by comparing the estimated swe from the ol and da runs against the synthetic swe truth for each model grid cell and then spatially averaged across the study area as shown in fig 3a the domain averaged swe rmse increased as the observation error standard deviation herein σerror for simplicity of the synthetic lidar snow depth retrievals increased when the σerror 0 80 m da reduced the domain averaged swe rmse relative to the ol swe rmse 61 2 mm given a larger sensor swath width and cloud free conditions i e greater number of available observations da greatly reduced the swe rmse however as the observation error standard deviation was further increased beyond 0 80 m the snow depth retrievals added no value to noah mp swe estimates using the data assimilation framework rather a slight but non negligible degradation was observed e g 2 8 increase in the domain averaged swe rmse in the da case of the 170 km swath width as the swath width increased under the large error assumption da degradation continued to increase this feature is due to more random noise being incorporated into the a posteriori estimates across larger regions of space as the swath width increases although the swe rmse was reduced by da when σerror 0 80 m there was a convergence of the da performance between cloud free and cloud attenuated cases at σerror 0 70 m after which the cloud attenuated cases that were assimilating fewer observations across space exhibited a smaller rmse than that for the cloud free cases assimilation of the synthetic lidar snow depth retrievals also improved the domain averaged r between the da based swe estimates and true swe when σerror 0 80 m especially as more observations were made available when using a larger sensor swath width in the absence of clouds fig 3b marginal improvements in the domain averaged r were also seen even for σerror 0 90 m it is worth noting that the snow depth retrievals using the sampling geometry of the currently operating mission i e icesat 2 also added value to the swe estimates via assimilation although the improvement was relatively small i e 6 9 reduction in the swe rmse and 4 1 increase in r when σerror 0 02 m fig 3a and b respectively compared to the larger swath width cases with large retrieval errors the smaller number of available snow depth retrievals given the relatively narrow icesat 2 sampling geometry led to less random noise being incorporated into the a posteriori estimates and therefore the degradation in the da performance as the retrieval error increased was minimal as previously mentioned only snow depth was directly updated by assimilating the synthetic snow depth retrievals an updated swe is then computed based on the model s snow density at each timestep the lsm updates snow density as a ratio of the updated swe and updated snow depth fig 4 shows that snow density was also improved as a result of the snow depth assimilation routine the effects of snow depth retrieval errors and observability i e sensor swath width and cloud attenuation effects on the snow density estimates were comparable to those for the swe estimates it should be noted that there is a trade off between the sensor swath width and data accuracy especially in mountainous areas rugged terrain may add more error and uncertainty to the snow depth retrievals from lidar measurements given a larger sensor swath width due to a larger scan angle although the snow depth retrieval uncertainties resulting from the effects of landscape characteristics and sensor swath widths were not explicitly analyzed fig 3 provides useful information for determining the allowable snow depth error range of the selected sensor swath width in order to provide improved estimates of swe via assimilation rather than a narrower sensor swath width with smaller measurement errors in mountainous areas for example the largest swath width i e 170 km with σerror 0 80 m led to better estimates of swe in terms of the domain averaged rmse than the narrowest swath width i e icesat 2 sampling geometry with σerror 0 02 m 3 1 2 spatial and temporal patterns maps of swe rmse relative to the synthetic truth from the ol and da runs for the 170 km swath width and cloud attenuation cases as well as their differences computed as rmseda rmseol are presented in fig 5 large swe estimation errors in the ol fig 5a were observed during relatively deep snow conditions in the synthetic truth fig 5j when the bias corrected trmm mean precipitation exhibited a dry bias see fig 2c and d in contrast the large ol swe errors were also witnessed during relatively shallow snow conditions in the synthetic truth when the trmm mean precipitation yielded a wet bias da significantly reduced these estimation errors fig 5 the largest improvements in swe estimates and snow depth by construct were achieved in high elevation regions as shown in fig 6 where relatively deep snow conditions are found da efficacy decreased as the snow depth observation error increased and marginal degradation of swe estimates positive values in fig 6 was witnessed in low elevation regions i e 1 3 km elevation 2 5 km especially when σerror 0 80 m but da was still effective in improving swe estimates in high elevation areas fig 7 a shows the time series of the domain averaged swe for the da experiments assimilating synthetic snow depth retrievals with a sensor swath width of 170 km that includes cloud effects across a range of observation errors fig 7b uses a fixed observation error standard deviation of 0 10 m but includes both cloud free results along with results accounting for cloud attenuation it should be noted in fig 7a that considerable improvements in swe estimates were achieved during both the snow accumulation and snow ablation periods when σerror 0 60 m assimilation of the snow depth retrievals with σerror 0 70 m and σerror 0 80 m only marginally improved swe estimates during the snow accumulation period but could not improve the snow ablation timing fig 7b shows that when σerror 0 10 m larger swath width scenarios outperformed the smaller swath width scenarios and that cloud attenuation effects significantly reduced the efficacy of the da framework 3 2 idealized observation scenarios 3 2 1 domain averaged statistics the domain averaged rmse domain averaged r and percentages of model grid cells improved or degraded by da in terms of swe rmse under the idealized observation scenario were plotted in fig 8 a 8b and 8c respectively compared to the ol case there was an 87 improvement in the domain averaged swe rmse achieved by assimilating synthetic snow depth retrievals with the smallest error i e σerror 0 02 m da improved the swe estimates by more than 58 when the snow depth error is within the reported range of airborne lidar snow depth i e 0 02 m σerror 0 30 m snow depth retrievals continued to add value to noah mp via assimilation for snow depth observation error standard deviations up to 0 60 m most notably in regions with relatively deep snow commonly found at higher altitudes however assimilating the synthetic lidar snow depth retrievals increased the domain averaged swe rmse relative to the ol when σerror 0 70 m and a 39 increase in the swe rmse occurred when the largest experimental error of σerror 0 90 m was applied these results quantitatively suggest that retrieval error standard deviations greater than 0 70 m during idealized observing conditions result in a deleterious amount of noise being incorporated into the a posteriori swe estimates that makes the model worse than if no assimilation had been conducted i e open loop the results also highlight how correlation coefficients r between the synthetic swe truth and the estimated swe were considerably improved by assimilating the synthetic snow depth retrievals fig 8b the domain averaged r decreased as σerror increased and da began to degrade the correlation compared to the ol once σerror 0 60 m fig 8b even though swe rmse still experienced improvements fig 8a the da procedure improved swe estimates for more than 74 of model grid cells within the study domain when σerror 0 30 m fig 8c as σerror increased the da framework yielded a more mixed performance with respect to the number of improved and degraded grid cells da improved swe estimates for more than half i e 55 of model grid cells up to σerror 0 60 m but more than half of model grid cells were degraded by da when the snow depth retrievals contained larger amounts of error i e σerror 0 70 m 3 2 2 spatial and temporal patterns the performance gains using the idealized snow depth retrievals and the improvements in modeled swe via assimilation were rapidly reduced as the snow depth retrieval error increased fig 9 c e g and i compared to the swath limited cloud attenuated cases fig 5 the idealized cases exhibited greater improvements in the swe estimates when σerror was small fig 9c and e whereas more pronounced degradations were observed when σerror was large fig 9g and i similar performance patterns were also witnessed when the swe rmse differences between the da and ol cases i e rmseda rmseol were computed for different elevation bands fig 10 this behavior is further discussed in section 3 3 where an error standard deviation threshold of the hypothetical spaceborne lidar snow depth retrievals are suggested figure 11 shows the time series of the domain averaged ensemble mean swe from the ol and da experiments along with the synthetic truth it should be noted here that noah mp without assimilation i e ol significantly overestimated swe mainly due to errors in the precipitation boundary conditions and model structure i e physics and parameterizations and that this swe estimation error was significantly reduced by assimilating the synthetic lidar snow depth retrievals during both the snow accumulation and snow ablation periods the magnitude and timing of snow ablation runoff were well reproduced in the da cases that assimilated the snow depth observations with small errors i e σerror 0 30 m even though the peak swe was slightly overestimated when the assimilated snow depth observations contained relatively large errors i e σerror 0 70 m da further extended the ablation season beyond that contained in the ol 3 3 snow depth retrieval error standard deviation threshold overall based on the domain averaged da evaluation statistics fig 3 from the swath limited cloud attenuated observation scenarios in western colorado the lidar retrievals added value to the swe estimates via assimilation when σerror 0 80 m while a smaller σerror i e σerror 0 50 m was required under the idealized viewing conditions i e infinite swath width in the absence of cloud cover in order to improve swe estimates with respect to rmse r and both the snow accumulation magnitude and snow ablation timing as shown in fig 3 the da experimental results in general showed that assimilation of a larger number of snow depth retrievals i e when using a larger sensor swath width in the absence of clouds resulted in better estimates of swe however in fig 12 a reversal of the da performance between the idealized i e full coverage in space and time and realistic i e assuming 170 km swath width cloud attenuation effects sensor viewing scenarios was observed at σerror 0 60 m for the domain averaged swe rmse fig 12a and the percentage of improved grid cells fig 12c and at σerror 0 50 m for the domain averaged r fig 12b this implies that spaceborne lidar snow depth retrievals containing σerror 0 50 m may degrade swe estimates via assimilation when a sensor swath width greater than 170 km is used under cloud free conditions as more random error is incorporated into the a posteriori estimates of swe therefore we would suggest σerror 0 40 m as a conservative error threshold i e upper limit of the snow depth retrieval error that adds value to the swe estimates when using the data assimilation framework although a larger error limit σerror 0 80 m was obtained in the swath limited cloud attenuated observation scenarios 3 4 total runoff estimation snowmelt contributes significantly to total surface and subsurface runoff in mountainous regions griessinger et al 2016 hall 1988 thus an improved estimation of swe via assimilation should enhance the prediction of total runoff e g clark et al 2006 griessinger et al 2016 stigter et al 2017 sun et al 2004 in this section the added value of synthetic spaceborne lidar snow depth retrievals on total runoff estimation was also analyzed figure 13 shows that time integrated total runoff within the study domain was significantly overestimated in the ol during the snow ablation period due to the large overestimation of swe as shown in fig 7 and it was improved by assimilating the synthetic lidar snow depth retrievals for all error assumptions i e 0 02 m σerror 0 90 m larger improvements occurred during the cloud free experiments but improvements still occurred when realistic cloud attenuation effects were introduced although the snow depth retrievals containing the smallest error i e σerror 0 02 m with the largest swath width i e 170 km in the absence of cloud cover achieved the greatest improvement in swe estimates via assimilation as shown in fig 3 it underestimated the time integrated total runoff by about 7 4 relative to the synthetic truth fig 13b this may be attributed to noah mp model structure errors relative to jules especially model physics and parameterizations related to snow melt infiltration and surface and subsurface runoff given the structure of the fraternal twin experiment on the other hand application of the smallest observation error led to the largest improvements in estimates of both swe and total runoff when an identical twin experiment i e in the absence of model structure error via use of the same noah mp lsm for both the nature run and da results not shown here was conducted the percent difference between the simulated and observed synthetic truth total runoff was within 50 of the synthetic truth of total runoff for the da cases using sensor swath widths of 70 km 120 km and 170 km when σerror 0 02 m as shown in fig 13b alternatively the total runoff difference was within the 50 range only in the da case using the 170 km swath width under cloud free conditions when σerror 0 40 m the total runoff difference exceeded the 50 range fig 13b for all experimental scenarios when σerror greater than 0 40 m or when using narrow swath widths i e icesat 2 sampling geometry or 20 km swath width scenario assimilation of the synthetic lidar snow depth retrievals was also effective in increasing the nash sutcliffe efficiency nse for runoff compared to the ol across the ranges of σerror and sensor swath widths used in this study fig 13c overall higher nse values were obtained by da when using a smaller σerror and a larger sensor swath width however the response of the runoff nse to σerror was nonlinear for σerror 0 40 m with sensor swath widths of 70 km 120 km and 170 km when a relatively large amount of the swe was updated during the assimilation fig 14 shows that snowmelt driven runoff was largely overestimated by the model during the end of snow season due to the swe overestimation which was largely mitigated using da routine especially when given a smaller σerror and a larger sensor swath width assimilation of the synthetic lidar snow depth retrievals significantly reduced the runoff bias but exhibited low skill in improving the temporal variability of runoff leading to low nse values 0 2 4 summary and conclusions a synthetic study for a hypothetical spaceborne lidar snow depth retrieval assimilation system was conducted over western colorado as part of an osse to study swe and snowmelt runoff characterization a total of 121 data assimilation experiments were conducted using nasa lis to address a number of research questions associated with the error characteristics of the snow depth retrievals sensor swath widths and the impact of clouds on sensor viewability of a hypothetical spaceborne snow lidar the results from the synthetic fraternal twin experiment were analyzed for a single snow season from 01 december 2005 to 30 april 2006 assimilation of the idealized snow depth retrievals i e infinite swath width in the absence of cloud cover was effective at improving swe estimates with respect to the domain averaged swe rmse correlation coefficient the percentage of improved model grid cells and both the snow accumulation magnitude and snow ablation timing when the prescribed snow depth error standard deviation was 0 50 m or less i e σerror 0 50 m while explicit consideration of the effects of the sensor swath width limitations and cloud cover attenuation on the availability of the snow depth retrievals significantly reduced da effectiveness improvements in the swe estimates were observed up to σerror 0 80 m for the swath limited cloud attenuated observation scenarios significant improvements p 0 05 in the total runoff estimates during the snow ablation period resulting from the enhanced swe estimates by da were also observed in general assimilation of a greater number of snow depth observations when using a larger sensor swath width under cloud free conditions led to better estimates of swe when σerror 0 60 m however at larger snow depth retrieval errors the da framework degraded the modeled swe estimates when a greater number of observations were assimilated because more random error was incorporated into the a posteriori estimates this deleterious behavior in da performance was witnessed for both the idealized and realistic sensor viewing scenarios more specifically the realistic i e swath limited and cloud attenuated cases outperformed the idealized i e infinite swath width in the absence of cloud cover cases when σerror 0 60 m for the domain averaged swe rmse and σerror 0 50 m for the domain averaged r based on this behavior in da performance a conservative error threshold of σerror 0 40 m i e a value slightly larger than the range of the reported airborne lidar snow depth errors is recommended here as an upper threshold of retrieval error in the design of spaceborne lidar snow depth retrievals in order to add utility to an assimilation system in the context of terrestrial snow across western colorado the results obtained in this study also have promising implications for multi sensor data assimilation in order to further enhance land surface snow estimates noticeable improvements in the swe estimates through synthetic lidar snow depth retrieval assimilation were found in high elevation regions where relatively deep snow exists this is the opposite result to that obtained in kwon et al 2019 in which passive microwave brightness temperature spectral differences δt b were assimilated into the same noah mp model over high mountain asia results showed that the δt b assimilation was ineffective for deep snow conditions i e swe greater than 100 to 200 mm mainly due to the passive microwave signal saturation issue to this end lidar and microwave radiometry could potentially complement one another within a multi variate assimilation procedure for example passive microwave radiation is not significantly attenuated by cloud cover whereas lidar is alternatively lidar can accurately measure snow depth during wet snow conditions whereas passive microwave retrievals cannot kim et al 2017 margulis et al 2019 simultaneous assimilation of these two disparate data sets i e microwave δt b and lidar snow depth should also be explored in future studies we acknowledge several limitations of this study that need to be addressed in future studies first the suggested threshold value on the snow depth retrieval error standard deviation is influenced by the specific choice of meteorological boundary conditions land surface models spatial and temporal domains and perturbation parameter values applied to the atmospheric boundary conditions and model state variables used in this particular study future studies should explore these contributing factors in order to further constrain these findings second as previously mentioned a spatially constant σerror was applied across the study domain which likely affected the results presented in this study future studies should conduct more refined experiments to discern spatially distributed σerror thresholds e g for different land cover types third a cost evaluation of a spaceborne lidar snow mission design has not been conducted here because the osse herein assumed that technical limitations are beyond the scope of this current paper however obtaining wall to wall coverage of global snow observations via spaceborne lidar will require a lot of power and thus a presumably exorbitant cost under current technical capabilities therefore a follow up osse should evaluate the cost for the suggested scientific requirements finally river discharge estimates were not presented due to the lack of a dynamic river routing scheme in the lsms used in this study in order to draw more complete hydrological implications from the experiments a coupled lsm river routing model needs to be explored despite these limitations this study suggests two promising aspects first even in the narrowest viewing scenarios using the sampling geometry of the currently operating spaceborne lidar mission i e icesat 2 assimilation of lidar based snow depth retrievals can improve the swe estimates when σerror is less than the suggested threshold although the magnitude of improvement is relatively small second advancements in technical capabilities such as improvements in sensor viewability i e larger swath width with a utilitarian degree of accuracy i e σerror 0 40 m can lead to significant improvements in modeled swe estimates when the model and observations are merged via assimilation these findings suggest that it is worthwhile to further scientific investigations into satellite based lidar missions for the purpose of global swe monitoring credit authorship contribution statement yonghwan kwon conceptualization formal analysis investigation methodology validation visualization writing original draft writing review editing yeosang yoon methodology software writing review editing barton a forman conceptualization methodology funding acquisition supervision writing review editing sujay v kumar conceptualization methodology software writing review editing lizhao wang data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the tat c development team for providing their tools and data this work was supported by the nasa advanced information systems technology aist program grants 80nssc17k0254 and 80nssc20k0210 
4346,field pumping tests are frequently encountered with variable pumping rates and the high velocity non darcian region near the pumping well is often time dependent leading to special drawdown behaviors that could not be soundly explained by the classical analytical well hydraulics models considering the commonly encountered situation of exponential decay in rates a two region darcian and non darcian flow model with time dependent critical radius which separates the darcian and non darcian regions is constructed and the corresponding numerical method is applied to analyze the characteristics of aquifer drawdown and the critical radius simulation results revealed that the critical radius and drawdown may reach their local maximum value at the intermediate times and then decrease for a period of time a larger decay coefficient leads to an earlier deviation in the drawdown and critical radius for the near well non darcian region the time drawdown curves for different decay coefficients have a common critical point i e the early deflection point while the curves for different inertial force coefficients have different critical points and a larger inertial force coefficient results in a larger critical time besides a larger inertial force coefficient may result in larger extreme points of drawdowns and experience a shorter time from the critical point to the extreme points considering the special deflection characteristics of drawdown a new deflection point method is proposed to estimate the inertial force coefficient storage coefficient and hydraulic conductivity of the confined aquifer the applicability and robustness of this new method were demonstrated by a synthetic pumping test keywords pumping tests exponentially decayed rates non darcian flow two region parameter estimation deflection point method 1 introduction non darcian flow has been investigated to simulate the groundwater for many decades teh and nie 2002 camacho v et al 1998 rodriguez r and camacho v 2005 şen 1987 1989 hassanizadeh and gray 1987 which considers a non linear relationship between hydraulic gradient and specific discharge because of the high velocity near the pumping well many studies indicated that the non darcian flow effect is likely to occur here which has a great influence on the drawdown and parameter estimation of aquifers birpinar and sen 2004 mathias and todman 2010 quinn et al 2013 one can find that many previous studies assumed the non darcian flow occurs throughout the study domain however the flow far from the pumping well could be darian because of relatively low velocities bear and jacob 1975 therefore the aforementioned fully non darcian flow models or commonly fully darcian flow models can not well capture the hydraulic characteristics of darcian and non darcian flow regions coexisting recently a new two region flow model has been proposed to deal with the coexistence problem of darcian and non darcian flow regions basak 1978 huyakorn and dudgeon 1976 for example huyakorn and dudgeon 1976 used the galerkin finite element method to analyze the two region flow in confined and unconfined aquifers and proposed a new type curve method to estimate the in situ hydraulic parameters basak 1978 presented the steady state analytical solution for both fully penetrating and non penetrating wells and compared the simulated hydraulic heads and discharge with that obtained from the fully darcian flow model şen 1988 used the boltzmann transform to obtain analytical solutions for unsteady state two region well flow problems and developed a type curve matching method to analyze the in situ data from the rosevale area in australia this similar problem was investigated by wen et al 2008 who proposed a linearization method to deal with the nonlinear term in the governing equation for non darcian flow considering the time dependent variation of darcian and non darcian flow regions wang et al 2014 used the finite difference method to solve the two region model for transient flow to a well all researches mentioned above assumed that the pumping rate is constant however field pumping tests are usually difficult to keep at a constant rate in general the pumping rate tends to decrease with time at early times due to various reasons such as the friction between water and pipe motor heating and self adjustment of the constant rate pump etc young et al 2002 then the pumping rate gradually reaches a relatively constant value sen and altunkaynak 2004 pointed out that during the period of pumping this decreasing phenomenon of pumping rate is very common in developing countries some studies also showed that this variable rate pumping could increase the sensitivities of hydraulic parameters to observed drawdown compared with constant rate pumping butler and mcelwee 1990 li et al 2020 besides the drawdown responses induced by these variable rate pumping tests are different from that of the constant rate pumping tests in this study a finite difference method is used to investigate the two region darcian and non darcian flow to a pumping well in a confined aquifer where the pumping rate is considered to exponentially decrease with time the critical radius separating the darcian and non darcian regions is assumed to vary with time the critical radius and drawdown behaviors caused by exponentially decayed rates will be explored meanwhile a new parameter estimation method will be proposed and demonstrated through a synthetic pumping test 2 model and solution method the model assumptions of this study are mostly similar to that of wang et al 2014 except that the pumping rate exponentially decreases with time by referring to wen et al 2017 the well boundary condition with the consideration of wellbore storage can be expressed as 1 2 π r w m q n r t r r w π r c 2 d s w t dt q 2 q 1 q 2 e α t where r is the radial distance from the pumping well l r w is the effective radius of the well l r c is the radius of well casing l t is the pumping time t m is the aquifer thickness l q n is the specific discharge l t of the non darcian region s w is the drawdown inside the well l q 1 and q 2 are the initial and final pumping rates respectively l3 t α is decay coefficient of the exponential pumping rate t 1 note that q 2 is not equal to 0 by introducing the dimensionless variables listed in table a 1 of supplementary material sm a dimensionless two region darcian and non darcian model for exponentially decayed pumping tests with time dependent critical radius which separates darcian and non darcian flow regions have been constructed see the model introduction of sm besides two important variables involving the exponentially decayed pumping rates are introduced i e φ and γ φ q 1 q 2 is the pumping rate ratio a larger φ implies a larger magnitude of the drop in the pumping rate γ smα k is the dimensionless decay coefficient a larger γ indicates a faster decay of the pumping rate considering the non linearity problem of the model investigated here it may be difficult to obtain an exact analytical solution thus a finite difference method is used to solve this problem which is similar to the way of wang et al 2014 but it is mainly assumed that the pumping rate of well boundary condition exponentially decays with time a new matlab program named tmetcr two region darcian and non darcian flow model associated with exponentially decayed pumping rates and time dependent critical radius is developed to simulate the aquifer drawdown and critical radius 3 results and discussions 3 1 comparison of drawdown time behavior between different models a simple fully darcian exponential rate model zhuang et al 2019 is first introduced to test the accuracy of the numerical solutions in this study to compare with the solutions of zhuang et al 2019 the dimensionless inertial force coefficient is set to be a very small value β d 1 10 5 to weaken the non darcian effect on the drawdown the comparison between the analytical solutions of zhuang et al 2019 and the numerical solutions of this study when β d 1 10 5 is shown in fig 1 it is clear to see that the numerical solutions agree very well with the analytical solutions the two region flow solutions with the dimensionless decay coefficients γ 0 and γ have also been included in fig 1 as a reference note that the curves of γ 0 and γ represent the constant rate solutions of q d 2 and q d 1 respectively wang et al 2014 it can be found that the solutions of the two region exponential rate model this study approach the upper curve γ 0 at early times then at intermediate times deviate from the upper curve and finally approach the lower curve γ at late times this implies that the early drawdown is mainly affected by the initial pumping rate q 1 while the late drawdown is mainly affected by the final pumping rate q 2 the comparison between the solutions of the two region exponential rate models and those of zhuang et al 2019 and wang et al 2014 also indicates the developed tmetcr program has enough accuracy and the numerical solution in this study is validated furthermore the solutions of the fully non darcian flow model with exponentially decayed rates have also been shown in fig 1 one can find that at early times the drawdown of the two region flow model this study is smaller than that of the fully darcian flow model and slightly larger than that of the fully non darcian flow model however at late times the drawdown of the two region flow model is larger than that of the fully darcian flow model and smaller than that of the fully non darcian flow model this is because when the time of constant rate pumping is long enough the entire aquifer system approaches the quasi steady state and the inertial force coefficient of non darcian flow models represents the resistance of flow where a larger resistance leads to a larger drawdown thus the solutions of the fully non darcian flow model and two region flow model will be larger than that of the fully darcian flow model at late times affected by the smaller drawdown in the darcian flow region the drawdown of the two region flow model at late times will be also smaller than that of the fully non darcian flow model 3 2 dimensionless critical radius time behavior neglecting the wellbore storage effect the effects of different dimensionless inertial force coefficients β d and different dimensionless decay coefficients γ on the dimensionless critical radius r cd are analyzed fig 2 a depicts the impact of the parameter β d on the r cd with γ 1 10 2 β d 5 10 2 1 10 1 5 10 1 and 1 0 respectively significant differences have been found in the different β d curves at early times where a larger β d results in a smaller r cd with the increase of time r cd reaches its maximum for a larger β d the time for r cd to reach the maximum value is longer at the intermediate times r cd is mainly affected by the reduction trend of pumping rate and decreases with time it is obvious that at late times r cd is not affected by β d this might be because the critical radius at late times is mainly controlled by the pumping rate q 2 fig 2b shows the impact of parameter γ on r cd with β d 1 0 γ 1 10 3 1 10 2 and 1 10 1 respectively from this figure one can find that all the curves for different γ approach the same asymptotic value at early and late times while some differences have been found at intermediate times the reason for the differences is that a larger γ representing a larger decay coefficient α indicates that there is less time for q d to exponentially decrease from the initial rate to the final rate thus one can see an earlier deviation for a larger γ besides the cases considering the constant rate pumping wang et al 2014 have also been depicted in this figure as a reference it is shown that the curve of r cd induced by the exponentially decayed rates pumping approaches that of constant rate pumping γ 0 at early times and approaches that of constant rate pumping γ at late times this implies that r cd for different γ values is mainly dominated by early pumping rates while at late times it is dominated by late pumping rates when the wellbore storage is considered the dimensionless critical radius r cd for different β d and γ has also been depicted in fig s1 of sm one can find that the r cd t d curves are similar in shape to those with neglecting wellbore storage except that at early times the r cd values considering the wellbore storage fig s1 are smaller than that neglecting wellbore storage fig 2 this is due to the existence of the wellbore storage effect li et al 2020 3 3 dimensionless drawdown time behavior as mentioned in section 3 2 the critical radius is an important parameter to reflect the location separating the non darcian and darcian regions it indicates that when the pumping rate exponentially decreases with time r cd varies with time and reaches the maximum at the intermediate times as reflected in fig 2 the maximums of r cd for different β d and γ are about 3 0 and 3 8 respectively thus two observation locations i e r d 6 10 1 and r d 4 0 will be selected to investigate the dimensionless drawdown time behaviors in the time dependent two region darcian and non darcian system where the flow at r d 6 10 1 will experience two flow patterns from darcian flow to non darcian flow while the flow at r d 4 0 will experience only one darcian flow pattern fig 3 a shows the dimensionless time drawdown curves for different dimensionless decay coefficients γ at r d 6 10 1 with neglecting wellbore storage it can be seen that at early times the drawdown for different γ increases with time however when the pumping time is longer there is an obvious decreasing trend even though the pumping has been going on during this period these decreasing features also appear in the fully darcian flow models and fully non darcian flow models of decreasing pumping rate li et al 2020 zhuang et al 2020 a larger γ value results in an earlier deviation of drawdown which is similar to the effect of γ on the critical radius besides the dimensionless time drawdown curves at r d 4 0 are also shown in fig s2 of sm comparing fig 3a and fig s2 one can find that there is a common deflection point in the curves of fig 3a at the early times however there is no deflection point in the curves of fig s2 at r d 4 0 because the flow here is always darcian flow similarly the effect of the dimensionless decay coefficient γ on the dimensionless drawdown considering the wellbore storage has also been depicted in the fig s3 of the sm it can be found that the drawdown features are similar to those neglecting the wellbore storage except that the drawdown with considering the wellbore storage is smaller than that with neglecting the wellbore storage and the time for drawdown to from the first deflection point to extreme points is shorter when considering wellbore storage effect the dimensionless inertial force coefficient β d is an important parameter to describe the non darcian flow effect fig 3b is the dimensionless drawdown versus the dimensionless time in the non darcian flow region from this figure one can see that the curve of β d 5 10 1 or 1 0 has a deflection point and a larger β d will result in an obvious deflection and a larger critical time obviously the early deflection point is related to the critical specific discharge so this point is also called the critical point later an interesting observation is that at intermediate and late times there are local maximum and minimum points for different β d values and a larger β d will lead to larger drawdowns of extreme points and experience a shorter time from the critical point to the extreme points these observations are not found in the two region darcian and non darcian flow model under constant rate pumping wang et al 2014 fig s4 of sm represents the dimensionless time drawdown curves at r d 4 0 in the darcian flow region obviously there is no deflection point in the curves besides all the drawdown curves for different β d will approach the same asymptotic curve at late times the asymptotic curve is identical to that of zhuang et al 2019 for the fully darcian flow case moreover the dimensionless drawdown with wellbore storage has also been analyzed in fig s5 of sm since the features are similar to those with neglecting wellbore storage they will not be repeated here 4 deflection point method for parameter estimation as shown in fig 3b for different dimensionless inertial force coefficients β d the dimensionless time drawdown curves in the non darcian flow region have obvious deflection characteristics at early times thus it may be feasible to estimate the aquifer parameters by considering these deflection points which is similar to the parameter estimation methods of zhuang et al 2019 and wen et al 2017 however zhuang et al 2019 and wen et al 2017 only considered the fully darcian model and used local extreme points at intermediate and late times to conduct parameter estimation when the time dependent non darcian flow region is considered the drawdown characteristics of the local extreme points are different from those of the fully darcian flow model therefore two deflection points at early and late times including the critical point and local minimum point are used to estimate the aquifer parameters in this section assuming that the coordinates of the critical point and local minimum point are t cd s cd and t zd s zd respectively then one can obtain the relationship between the deflection time ratio εt t zd t cd and the dimensionless decay coefficient γ as shown in fig 4 a it can be seen that for different β d εt decreases almost linearly with γ in the log log paper and a larger β d results in a smaller εt for a given γ from the definition of the dimensionless time t d kt sm one has εt t zd t cd t z t c it indicates for a specific pumping test constant k s and m εt can be determined by the measured times t z and t c of local minimum point and critical point besides the deflection drawdown ratio εs and the dimensionless drawdown s zd of the local minimum point vary approximately linearly with γ as shown in fig 4 where εs s zd s cd s z s c compared with the effect of β d on the εt a larger β d will result in a smaller εs and a larger s zd according to the above curves features of critical point and local minimum point a new deflection point method is proposed to estimate the aquifer parameters the implementation steps of this method are summarized as follows 1 for a field pumping test the radial distance from the pumping well r and aquifer thickness m are known and then one can obtain the value of r d besides by using an exponential function to approximate the measured pumping rate data the initial and final rates q 1 and q 2 and decay coefficient α are obtained thus one can determine the pumping rate ratio φ q 1 q 2 taking r d 6 10 1 as an example the relationships of εt γ εs γ and s zd γ for different β d are derived fig 4 2 according to the measured time drawdown curve one can obtain the coordinates of the critical point and local minimum point which are t c s c and t z s z then one can calculate the values of εt t z t c and εs s z s c obviously the calculated εt and εs will correspond to a specific β d and γ for this pumping case 3 after the determination of β d and γ the corresponding s zd value can also be obtained from the curves of s zd γ then from the definitions of s zd and β d one can estimate the hydraulic conductivity k s zd q 2 2πms z and inertial force coefficient β 2πm 2 β d q 2 on this basis the storage coefficient s γk mα can also be determined by the definitions of γ 5 a synthetic case study a synthetic pumping test is considered to investigate the applicability of this method in this case the pumping rate of an infinitesimal diameter well is assumed to exponentially decrease with time the initial and final pumping rates q 1 and q 2 and decay coefficient α are set to be 2 513 m3 s 0 628 m3 s and 5 10 3 s 1 respectively the thickness of the confined aquifer is m 10 m and the critical specific discharge q c 1 10 3 m s assuming that the inertial force coefficient β hydraulic conductivity k and storage coefficient s are known i e β 1 103 s m k 1 10 3 m s and s 5 10 3 it is easy to simulate the time drawdown data at any radial distance r considering the measured errors caused by equipment and noise in the field test 5 and 3 magnitude random errors are added to the simulated drawdowns of r 5 m respectively fig s6 of sm the dimensionless parameters can be calculated as q cd 1 0 r d 5 10 1 and φ 4 0 the relationship between the deflection time ratio and deflection drawdown ratio εt εs with different dimensionless inertial force coefficients β d and dimensionless decay coefficients γ and the relationship between dimensionless local minimum drawdown s zd and γ for different β d are presented in fig 5 the parameter estimation process of the local extreme point method zhuang et al 2019 is also shown in fig s7 of sm the variables required for parameter evaluation of this study and zhuang et al 2019 are also shown in table a 2 of sm table 1 summarizes the estimation results under two kinds of random errors 5 and 3 one can find that the deflection point method proposed in this study produces excellent s estimates and slightly smaller k estimates compared with the real hydraulic parameters and a smaller magnitude of random errors results in estimates that are closer to the real parameter this also means that the k estimates by the deflection point method are more affected by the random error than s estimates compared with the deflection point method the parameter estimates given by zhuang et al 2019 differ greatly from the real parameters where the estimated s is almost one order of magnitude lower than the real s obviously the estimated parameters of the deflection point method are still slightly different from the true values the main reason may be the measured drawdown error caused by noise and instrument which makes it difficult to determine the true critical point and local minimum point this leads to a difference between and real γ and estimated γ by the deflection time ratio εt and deflection drawdown ratio εs however the uncertainty of parameters caused by the external environment is inevitable 6 conclusion considering the common situation of exponential decay in pumping rates a two region darcian and non darcian exponential rate model with time dependent critical radius was established and the aquifer drawdown and critical radius behaviors were analyzed by the finite difference method a new deflection point method was proposed to estimate the aquifer parameters several findings can be drawn from this study 1 at intermediate times the critical radius and drawdown may reach their local maximum and decrease for some time depending on different inertial force coefficients and decay coefficients a larger decay coefficient leads to an earlier deviation in the drawdown and critical radius for the observation well in the non darcian flow region there is a common critical point i e the early deflection point for different decay coefficients however when the inertial force coefficient value changes the critical points are different and a larger inertial force coefficient results in a larger critical time besides a larger inertial force coefficient results in larger drawdowns of extreme points and experiences a shorter time from the critical point to the extreme points 2 the deflection time ratio and deflection drawdown ratio as well as local minimum drawdown about the critical point and local minimum point change approximately linearly with the decay coefficient in a log log paper a larger inertial force coefficient results in a smaller deflection time ratio and a smaller deflection drawdown ratio or a larger local minimum drawdown 3 considering the characteristics of the critical point and local minimum point in the drawdown time curves a new deflection point method is proposed to estimate the inertial force coefficient storage coefficient and hydraulic conductivity the estimated results are compared with that of the local extreme point method zhuang et al 2019 based on the fully darcian flow model which shows that the fully darcian flow model greatly underestimates the storage coefficient declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this study was supported by the national natural science foundation of china grant nos 41902244 and 91747204 the natural sciences foundation of jiangsu province grant no bk20190497 and the china postdoctoral science foundation grant no 2021m690866 the constructive suggestions of the editor and two anonymous reviewers are also gratefully acknowledged appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126712 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4346,field pumping tests are frequently encountered with variable pumping rates and the high velocity non darcian region near the pumping well is often time dependent leading to special drawdown behaviors that could not be soundly explained by the classical analytical well hydraulics models considering the commonly encountered situation of exponential decay in rates a two region darcian and non darcian flow model with time dependent critical radius which separates the darcian and non darcian regions is constructed and the corresponding numerical method is applied to analyze the characteristics of aquifer drawdown and the critical radius simulation results revealed that the critical radius and drawdown may reach their local maximum value at the intermediate times and then decrease for a period of time a larger decay coefficient leads to an earlier deviation in the drawdown and critical radius for the near well non darcian region the time drawdown curves for different decay coefficients have a common critical point i e the early deflection point while the curves for different inertial force coefficients have different critical points and a larger inertial force coefficient results in a larger critical time besides a larger inertial force coefficient may result in larger extreme points of drawdowns and experience a shorter time from the critical point to the extreme points considering the special deflection characteristics of drawdown a new deflection point method is proposed to estimate the inertial force coefficient storage coefficient and hydraulic conductivity of the confined aquifer the applicability and robustness of this new method were demonstrated by a synthetic pumping test keywords pumping tests exponentially decayed rates non darcian flow two region parameter estimation deflection point method 1 introduction non darcian flow has been investigated to simulate the groundwater for many decades teh and nie 2002 camacho v et al 1998 rodriguez r and camacho v 2005 şen 1987 1989 hassanizadeh and gray 1987 which considers a non linear relationship between hydraulic gradient and specific discharge because of the high velocity near the pumping well many studies indicated that the non darcian flow effect is likely to occur here which has a great influence on the drawdown and parameter estimation of aquifers birpinar and sen 2004 mathias and todman 2010 quinn et al 2013 one can find that many previous studies assumed the non darcian flow occurs throughout the study domain however the flow far from the pumping well could be darian because of relatively low velocities bear and jacob 1975 therefore the aforementioned fully non darcian flow models or commonly fully darcian flow models can not well capture the hydraulic characteristics of darcian and non darcian flow regions coexisting recently a new two region flow model has been proposed to deal with the coexistence problem of darcian and non darcian flow regions basak 1978 huyakorn and dudgeon 1976 for example huyakorn and dudgeon 1976 used the galerkin finite element method to analyze the two region flow in confined and unconfined aquifers and proposed a new type curve method to estimate the in situ hydraulic parameters basak 1978 presented the steady state analytical solution for both fully penetrating and non penetrating wells and compared the simulated hydraulic heads and discharge with that obtained from the fully darcian flow model şen 1988 used the boltzmann transform to obtain analytical solutions for unsteady state two region well flow problems and developed a type curve matching method to analyze the in situ data from the rosevale area in australia this similar problem was investigated by wen et al 2008 who proposed a linearization method to deal with the nonlinear term in the governing equation for non darcian flow considering the time dependent variation of darcian and non darcian flow regions wang et al 2014 used the finite difference method to solve the two region model for transient flow to a well all researches mentioned above assumed that the pumping rate is constant however field pumping tests are usually difficult to keep at a constant rate in general the pumping rate tends to decrease with time at early times due to various reasons such as the friction between water and pipe motor heating and self adjustment of the constant rate pump etc young et al 2002 then the pumping rate gradually reaches a relatively constant value sen and altunkaynak 2004 pointed out that during the period of pumping this decreasing phenomenon of pumping rate is very common in developing countries some studies also showed that this variable rate pumping could increase the sensitivities of hydraulic parameters to observed drawdown compared with constant rate pumping butler and mcelwee 1990 li et al 2020 besides the drawdown responses induced by these variable rate pumping tests are different from that of the constant rate pumping tests in this study a finite difference method is used to investigate the two region darcian and non darcian flow to a pumping well in a confined aquifer where the pumping rate is considered to exponentially decrease with time the critical radius separating the darcian and non darcian regions is assumed to vary with time the critical radius and drawdown behaviors caused by exponentially decayed rates will be explored meanwhile a new parameter estimation method will be proposed and demonstrated through a synthetic pumping test 2 model and solution method the model assumptions of this study are mostly similar to that of wang et al 2014 except that the pumping rate exponentially decreases with time by referring to wen et al 2017 the well boundary condition with the consideration of wellbore storage can be expressed as 1 2 π r w m q n r t r r w π r c 2 d s w t dt q 2 q 1 q 2 e α t where r is the radial distance from the pumping well l r w is the effective radius of the well l r c is the radius of well casing l t is the pumping time t m is the aquifer thickness l q n is the specific discharge l t of the non darcian region s w is the drawdown inside the well l q 1 and q 2 are the initial and final pumping rates respectively l3 t α is decay coefficient of the exponential pumping rate t 1 note that q 2 is not equal to 0 by introducing the dimensionless variables listed in table a 1 of supplementary material sm a dimensionless two region darcian and non darcian model for exponentially decayed pumping tests with time dependent critical radius which separates darcian and non darcian flow regions have been constructed see the model introduction of sm besides two important variables involving the exponentially decayed pumping rates are introduced i e φ and γ φ q 1 q 2 is the pumping rate ratio a larger φ implies a larger magnitude of the drop in the pumping rate γ smα k is the dimensionless decay coefficient a larger γ indicates a faster decay of the pumping rate considering the non linearity problem of the model investigated here it may be difficult to obtain an exact analytical solution thus a finite difference method is used to solve this problem which is similar to the way of wang et al 2014 but it is mainly assumed that the pumping rate of well boundary condition exponentially decays with time a new matlab program named tmetcr two region darcian and non darcian flow model associated with exponentially decayed pumping rates and time dependent critical radius is developed to simulate the aquifer drawdown and critical radius 3 results and discussions 3 1 comparison of drawdown time behavior between different models a simple fully darcian exponential rate model zhuang et al 2019 is first introduced to test the accuracy of the numerical solutions in this study to compare with the solutions of zhuang et al 2019 the dimensionless inertial force coefficient is set to be a very small value β d 1 10 5 to weaken the non darcian effect on the drawdown the comparison between the analytical solutions of zhuang et al 2019 and the numerical solutions of this study when β d 1 10 5 is shown in fig 1 it is clear to see that the numerical solutions agree very well with the analytical solutions the two region flow solutions with the dimensionless decay coefficients γ 0 and γ have also been included in fig 1 as a reference note that the curves of γ 0 and γ represent the constant rate solutions of q d 2 and q d 1 respectively wang et al 2014 it can be found that the solutions of the two region exponential rate model this study approach the upper curve γ 0 at early times then at intermediate times deviate from the upper curve and finally approach the lower curve γ at late times this implies that the early drawdown is mainly affected by the initial pumping rate q 1 while the late drawdown is mainly affected by the final pumping rate q 2 the comparison between the solutions of the two region exponential rate models and those of zhuang et al 2019 and wang et al 2014 also indicates the developed tmetcr program has enough accuracy and the numerical solution in this study is validated furthermore the solutions of the fully non darcian flow model with exponentially decayed rates have also been shown in fig 1 one can find that at early times the drawdown of the two region flow model this study is smaller than that of the fully darcian flow model and slightly larger than that of the fully non darcian flow model however at late times the drawdown of the two region flow model is larger than that of the fully darcian flow model and smaller than that of the fully non darcian flow model this is because when the time of constant rate pumping is long enough the entire aquifer system approaches the quasi steady state and the inertial force coefficient of non darcian flow models represents the resistance of flow where a larger resistance leads to a larger drawdown thus the solutions of the fully non darcian flow model and two region flow model will be larger than that of the fully darcian flow model at late times affected by the smaller drawdown in the darcian flow region the drawdown of the two region flow model at late times will be also smaller than that of the fully non darcian flow model 3 2 dimensionless critical radius time behavior neglecting the wellbore storage effect the effects of different dimensionless inertial force coefficients β d and different dimensionless decay coefficients γ on the dimensionless critical radius r cd are analyzed fig 2 a depicts the impact of the parameter β d on the r cd with γ 1 10 2 β d 5 10 2 1 10 1 5 10 1 and 1 0 respectively significant differences have been found in the different β d curves at early times where a larger β d results in a smaller r cd with the increase of time r cd reaches its maximum for a larger β d the time for r cd to reach the maximum value is longer at the intermediate times r cd is mainly affected by the reduction trend of pumping rate and decreases with time it is obvious that at late times r cd is not affected by β d this might be because the critical radius at late times is mainly controlled by the pumping rate q 2 fig 2b shows the impact of parameter γ on r cd with β d 1 0 γ 1 10 3 1 10 2 and 1 10 1 respectively from this figure one can find that all the curves for different γ approach the same asymptotic value at early and late times while some differences have been found at intermediate times the reason for the differences is that a larger γ representing a larger decay coefficient α indicates that there is less time for q d to exponentially decrease from the initial rate to the final rate thus one can see an earlier deviation for a larger γ besides the cases considering the constant rate pumping wang et al 2014 have also been depicted in this figure as a reference it is shown that the curve of r cd induced by the exponentially decayed rates pumping approaches that of constant rate pumping γ 0 at early times and approaches that of constant rate pumping γ at late times this implies that r cd for different γ values is mainly dominated by early pumping rates while at late times it is dominated by late pumping rates when the wellbore storage is considered the dimensionless critical radius r cd for different β d and γ has also been depicted in fig s1 of sm one can find that the r cd t d curves are similar in shape to those with neglecting wellbore storage except that at early times the r cd values considering the wellbore storage fig s1 are smaller than that neglecting wellbore storage fig 2 this is due to the existence of the wellbore storage effect li et al 2020 3 3 dimensionless drawdown time behavior as mentioned in section 3 2 the critical radius is an important parameter to reflect the location separating the non darcian and darcian regions it indicates that when the pumping rate exponentially decreases with time r cd varies with time and reaches the maximum at the intermediate times as reflected in fig 2 the maximums of r cd for different β d and γ are about 3 0 and 3 8 respectively thus two observation locations i e r d 6 10 1 and r d 4 0 will be selected to investigate the dimensionless drawdown time behaviors in the time dependent two region darcian and non darcian system where the flow at r d 6 10 1 will experience two flow patterns from darcian flow to non darcian flow while the flow at r d 4 0 will experience only one darcian flow pattern fig 3 a shows the dimensionless time drawdown curves for different dimensionless decay coefficients γ at r d 6 10 1 with neglecting wellbore storage it can be seen that at early times the drawdown for different γ increases with time however when the pumping time is longer there is an obvious decreasing trend even though the pumping has been going on during this period these decreasing features also appear in the fully darcian flow models and fully non darcian flow models of decreasing pumping rate li et al 2020 zhuang et al 2020 a larger γ value results in an earlier deviation of drawdown which is similar to the effect of γ on the critical radius besides the dimensionless time drawdown curves at r d 4 0 are also shown in fig s2 of sm comparing fig 3a and fig s2 one can find that there is a common deflection point in the curves of fig 3a at the early times however there is no deflection point in the curves of fig s2 at r d 4 0 because the flow here is always darcian flow similarly the effect of the dimensionless decay coefficient γ on the dimensionless drawdown considering the wellbore storage has also been depicted in the fig s3 of the sm it can be found that the drawdown features are similar to those neglecting the wellbore storage except that the drawdown with considering the wellbore storage is smaller than that with neglecting the wellbore storage and the time for drawdown to from the first deflection point to extreme points is shorter when considering wellbore storage effect the dimensionless inertial force coefficient β d is an important parameter to describe the non darcian flow effect fig 3b is the dimensionless drawdown versus the dimensionless time in the non darcian flow region from this figure one can see that the curve of β d 5 10 1 or 1 0 has a deflection point and a larger β d will result in an obvious deflection and a larger critical time obviously the early deflection point is related to the critical specific discharge so this point is also called the critical point later an interesting observation is that at intermediate and late times there are local maximum and minimum points for different β d values and a larger β d will lead to larger drawdowns of extreme points and experience a shorter time from the critical point to the extreme points these observations are not found in the two region darcian and non darcian flow model under constant rate pumping wang et al 2014 fig s4 of sm represents the dimensionless time drawdown curves at r d 4 0 in the darcian flow region obviously there is no deflection point in the curves besides all the drawdown curves for different β d will approach the same asymptotic curve at late times the asymptotic curve is identical to that of zhuang et al 2019 for the fully darcian flow case moreover the dimensionless drawdown with wellbore storage has also been analyzed in fig s5 of sm since the features are similar to those with neglecting wellbore storage they will not be repeated here 4 deflection point method for parameter estimation as shown in fig 3b for different dimensionless inertial force coefficients β d the dimensionless time drawdown curves in the non darcian flow region have obvious deflection characteristics at early times thus it may be feasible to estimate the aquifer parameters by considering these deflection points which is similar to the parameter estimation methods of zhuang et al 2019 and wen et al 2017 however zhuang et al 2019 and wen et al 2017 only considered the fully darcian model and used local extreme points at intermediate and late times to conduct parameter estimation when the time dependent non darcian flow region is considered the drawdown characteristics of the local extreme points are different from those of the fully darcian flow model therefore two deflection points at early and late times including the critical point and local minimum point are used to estimate the aquifer parameters in this section assuming that the coordinates of the critical point and local minimum point are t cd s cd and t zd s zd respectively then one can obtain the relationship between the deflection time ratio εt t zd t cd and the dimensionless decay coefficient γ as shown in fig 4 a it can be seen that for different β d εt decreases almost linearly with γ in the log log paper and a larger β d results in a smaller εt for a given γ from the definition of the dimensionless time t d kt sm one has εt t zd t cd t z t c it indicates for a specific pumping test constant k s and m εt can be determined by the measured times t z and t c of local minimum point and critical point besides the deflection drawdown ratio εs and the dimensionless drawdown s zd of the local minimum point vary approximately linearly with γ as shown in fig 4 where εs s zd s cd s z s c compared with the effect of β d on the εt a larger β d will result in a smaller εs and a larger s zd according to the above curves features of critical point and local minimum point a new deflection point method is proposed to estimate the aquifer parameters the implementation steps of this method are summarized as follows 1 for a field pumping test the radial distance from the pumping well r and aquifer thickness m are known and then one can obtain the value of r d besides by using an exponential function to approximate the measured pumping rate data the initial and final rates q 1 and q 2 and decay coefficient α are obtained thus one can determine the pumping rate ratio φ q 1 q 2 taking r d 6 10 1 as an example the relationships of εt γ εs γ and s zd γ for different β d are derived fig 4 2 according to the measured time drawdown curve one can obtain the coordinates of the critical point and local minimum point which are t c s c and t z s z then one can calculate the values of εt t z t c and εs s z s c obviously the calculated εt and εs will correspond to a specific β d and γ for this pumping case 3 after the determination of β d and γ the corresponding s zd value can also be obtained from the curves of s zd γ then from the definitions of s zd and β d one can estimate the hydraulic conductivity k s zd q 2 2πms z and inertial force coefficient β 2πm 2 β d q 2 on this basis the storage coefficient s γk mα can also be determined by the definitions of γ 5 a synthetic case study a synthetic pumping test is considered to investigate the applicability of this method in this case the pumping rate of an infinitesimal diameter well is assumed to exponentially decrease with time the initial and final pumping rates q 1 and q 2 and decay coefficient α are set to be 2 513 m3 s 0 628 m3 s and 5 10 3 s 1 respectively the thickness of the confined aquifer is m 10 m and the critical specific discharge q c 1 10 3 m s assuming that the inertial force coefficient β hydraulic conductivity k and storage coefficient s are known i e β 1 103 s m k 1 10 3 m s and s 5 10 3 it is easy to simulate the time drawdown data at any radial distance r considering the measured errors caused by equipment and noise in the field test 5 and 3 magnitude random errors are added to the simulated drawdowns of r 5 m respectively fig s6 of sm the dimensionless parameters can be calculated as q cd 1 0 r d 5 10 1 and φ 4 0 the relationship between the deflection time ratio and deflection drawdown ratio εt εs with different dimensionless inertial force coefficients β d and dimensionless decay coefficients γ and the relationship between dimensionless local minimum drawdown s zd and γ for different β d are presented in fig 5 the parameter estimation process of the local extreme point method zhuang et al 2019 is also shown in fig s7 of sm the variables required for parameter evaluation of this study and zhuang et al 2019 are also shown in table a 2 of sm table 1 summarizes the estimation results under two kinds of random errors 5 and 3 one can find that the deflection point method proposed in this study produces excellent s estimates and slightly smaller k estimates compared with the real hydraulic parameters and a smaller magnitude of random errors results in estimates that are closer to the real parameter this also means that the k estimates by the deflection point method are more affected by the random error than s estimates compared with the deflection point method the parameter estimates given by zhuang et al 2019 differ greatly from the real parameters where the estimated s is almost one order of magnitude lower than the real s obviously the estimated parameters of the deflection point method are still slightly different from the true values the main reason may be the measured drawdown error caused by noise and instrument which makes it difficult to determine the true critical point and local minimum point this leads to a difference between and real γ and estimated γ by the deflection time ratio εt and deflection drawdown ratio εs however the uncertainty of parameters caused by the external environment is inevitable 6 conclusion considering the common situation of exponential decay in pumping rates a two region darcian and non darcian exponential rate model with time dependent critical radius was established and the aquifer drawdown and critical radius behaviors were analyzed by the finite difference method a new deflection point method was proposed to estimate the aquifer parameters several findings can be drawn from this study 1 at intermediate times the critical radius and drawdown may reach their local maximum and decrease for some time depending on different inertial force coefficients and decay coefficients a larger decay coefficient leads to an earlier deviation in the drawdown and critical radius for the observation well in the non darcian flow region there is a common critical point i e the early deflection point for different decay coefficients however when the inertial force coefficient value changes the critical points are different and a larger inertial force coefficient results in a larger critical time besides a larger inertial force coefficient results in larger drawdowns of extreme points and experiences a shorter time from the critical point to the extreme points 2 the deflection time ratio and deflection drawdown ratio as well as local minimum drawdown about the critical point and local minimum point change approximately linearly with the decay coefficient in a log log paper a larger inertial force coefficient results in a smaller deflection time ratio and a smaller deflection drawdown ratio or a larger local minimum drawdown 3 considering the characteristics of the critical point and local minimum point in the drawdown time curves a new deflection point method is proposed to estimate the inertial force coefficient storage coefficient and hydraulic conductivity the estimated results are compared with that of the local extreme point method zhuang et al 2019 based on the fully darcian flow model which shows that the fully darcian flow model greatly underestimates the storage coefficient declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this study was supported by the national natural science foundation of china grant nos 41902244 and 91747204 the natural sciences foundation of jiangsu province grant no bk20190497 and the china postdoctoral science foundation grant no 2021m690866 the constructive suggestions of the editor and two anonymous reviewers are also gratefully acknowledged appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126712 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4347,over recent decades hydrologists have proposed a variety of methods to predict discharge in ungauged catchments and significant progress has been made in the field of hydrological model parameter regionalization however uncertainties from both hydrological models and regionalization methods make it a challenge to draw clear conclusions for some questions in regionalization e g the best performing regionalization method the optimal number of donor catchments and the optimal efficiency threshold of donor catchments in this study for the first time we made an attempt to address such questions in one paper through a comprehensive evaluation of model performance by using five regionalization methods with two weighting schemes two averaging options five efficiency thresholds and four lumped hydrological models over a broad set of 3444 catchments under varying hydroclimatic conditions in north america the results show that 1 spatial proximity with the inverse distance weighting method and the output average option spi out generally performs better than or comparable to other regionalization methods for different climate regions and hydrological models while the global mean method performs the worst 2 the rank of different regionalization methods is similar among different climatic regions and hydrological models compared to catchments with other climates regionalization methods perform worst in the arid regions 3 the selection of five donors is relatively efficient for distance attributes based regionalization approaches with the output averaging option disregarding the efficiency threshold 4 the differences of median kling gupta efficiency values among thresholds of all 0 6 and 0 7 are no more than 0 05 for each regionalization method however the regionalization performance significantly deteriorates from using efficiency thresholds of 0 7 to 0 9 due to the significant reduction of available donor catchments thus the poorly calibrated catchments may need to be included in the regionalization process especially when the number of catchments is insufficient keywords regionalization ungauged catchments runoff prediction hydrological models uncertainty 1 introduction in the past few decades hydrological models have become the most popular and common solution for runoff prediction however hydrological models need to be calibrated with observed discharge data which are not available for ungauged catchments jin et al 2009 xu 1999 considering that many catchments of interest lack flow measurements the international association of hydrological sciences established the decade of 2003 2012 on predictions in ungauged basins pub at the 23rd international congress of geophysics and geodesy sivapalan et al 2003 xu et al 2005 tremendous efforts and progress have been made in pub because of this event blöschl et al 2013 guo et al 2021 hrachowitz et al 2013 parajka et al 2013 yang et al 2020 zanial et al 2018 varied and extensive outcomes of runoff predictions in ungauged basins have been achieved and the one that was most commonly used is regionalization blöschl et al 2013 guo et al 2021 hrachowitz et al 2013 zanial et al 2018 by using the regionalization methods the parameter sets of hydrological models on gauged catchments called donors can be transferred to a target ungauged catchment following different procedures according to most previous studies guo et al 2021 he et al 2011 regionalization methods can be classified into four categories arithmetic mean method jin et al 2009 oudin et al 2008 distance attributes based method spatial proximity and physical similarity yang et al 2020 regression based method e g one step regression sequential regression and two step regression samaniego et al 2010 samaniego et al 2017 xu 2003 yang et al 2020 and hydrological signature based approach yadav et al 2007 numerous studies have compared various regionalization methods li et al 2010 oudin et al 2008 yang et al 2018 yang et al 2020 however the conclusion for the best performing method was not consistent li et al 2010 oudin et al 2008 yang et al 2018 yang et al 2020 for example li et al 2010 used the xinanjiang xaj model over 210 australian catchments and found that the spatial proximity approach provided the best regionalization solution merz and blöschl 2004 reported the same conclusion in their study over austria however yang et al 2018 reported that the physical similarity methods performed best runoff simulations based on more than 100 catchments in norway in addition young 2006 found that the regression method showed the most satisfactory results over 260 catchments in the united kingdom parajka et al 2013 made a comprehensive comparison of regionalization methods based on 34 studies reported in the literature and concluded that distance attributes based approaches generally performed better than the regression method there are some reasons why the best performing methods vary among these studies 1 there is high diversity and heterogeneity in different study catchments 2 different hydrological models with various structures and concepts may affect the performance of the regionalization approach and 3 the choice of the number of donor catchments the density of gauged catchments and the use of poorly calibrated catchments as donors can affect the performance of regionalized models oudin et al 2008 even though the selection of donor catchments is the key in regionalization several important issues about the selection of donor catchments are rarely investigated or no consistent conclusion has been drawn such as the most efficient number of donor catchments used for distance attributes based approaches the influence of the efficiency threshold when the model efficiency of a catchment was below the threshold the catchment was not used as a donor catchment to predict runoff for ungauged catchments on the selection of donor catchments and the performance of various regionalization methods for example some studies garambois et al 2015 waseem et al 2015 found that using donor catchments with poorly calibrated runoff could result in high uncertainty in regionalization while others arsenault and brissette 2014 oudin et al 2008 concluded that only using catchments with well calibrated runoff would not guarantee good performance in pseudo ungauged catchments in addition some of the above studies arsenault and brissette 2014 merz and blöschl 2004 only considered one efficiency threshold to exclude poor performance donors and the other oudin et al 2008 did not consider the influence of the different number of donor catchments under different efficiency thresholds therefore the first aim of this study is to investigate the impact of the efficiency threshold and the number of donor catchments on regionalization performance moreover the existing comparisons of regionalization methods are fragmented with limitations in the number of catchments hydrological models and specific regions by summarizing 34 regionalization studies parajka et al 2013 concluded that regionalization performances vary among regions some studies bao et al 2012 yang et al 2019 investigated the performance of regionalization methods between different climate regions for example bao et al 2012 investigated the performance of regionalization methods over 55 catchments in china under multiple hydro climatic conditions i e humid semi humid and arid however only two regionalization methods and one hydrological model were used yang et al 2020 investigated the regionalization performance over different climatic regions by using 86 catchments distributed throughout norway i e oceanic continental and polar tundra regions however arid regions which account for a large percentage of the ungauged regions in the world were not included in the comparison closer appraisal of the influence of different climate conditions on ungauged regionalization is instrumental in the quality of regionalization therefore the second aim of this study is to investigate the performance dependence of multiple regionalization methods on climatic regions to find appropriate regionalization methods for runoff prediction over ungauged catchments overall this study first quantifies the impact of efficiency thresholds on the performance of regionalization methods the regionalization behavior is then evaluated over different climate regions specifically combinations of five widely used regionalization methods two averaging options and two weighting methods 14 regionalization combinations are compared by using four conceptual hydrological models over 3444 north american catchments with highly varying hydroclimatic characteristics the rest of the paper is structured as follows the study area data the hydrological models the regionalization methods and the efficiency thresholds are introduced in section 2 the results are shown in section 3 and the discussion and conclusions are presented in sections 4 and 5 respectively 2 material and methods 2 1 study area in this study 3444 gauged catchments were selected from north america 467 in canada and 2977 in the continental united states arsenault et al 2016 arsenault et al 2020 the study region embraces various climatic zones from savanna in the lowlands of central america to ice fields in northern canada adequately representing spatial climate variability fig 1 shows the distribution of the studied catchments and climate classification extracted from the world map of köppen geiger climate classification 1976 2000 kottek et al 2006 the drainage area of catchments ranges from 302 to 188 470 km2 and covers most of the continental united states and southern and central canada except for the prairies due to the lack of measurements and areas where rivers are regulated 2 2 data for runoff simulation the meteorological data used in this study were daily precipitation and air temperature which were extracted from the santa clara daily database for the united states and natural resources canada gridded climate data product for canada covering the 1950 2010 period arsenault et al 2020 daily discharge data of the catchments in canada and the united states were from the canadian model parameter experiment canopex database and the united states geological survey usgs database arsenault et al 2016 arsenault et al 2020 respectively the length of observed discharge varies from 20 years minimum in these databases to over 60 years for different catchments besides the hydrometeorological data for runoff simulation 13 catchment descriptors classified as climate index terrain characteristics land use and soil characteristics were selected and used in regionalization methods table 1 the aridity and potential evaporation were derived from the global aridity and pet database zomer et al 2008 terrain characteristics land uses and soil characteristics were taken from the hydro1k database usgs 2004 the globcover land cover maps bontemps et al 2011 and the harmonized world soil database harmonized world soil database version 1 1 fao and isric 2012 respectively these catchment descriptors were selected based on the work of he et al 2011 in which they counted the number of times that catchment descriptors were used in a review of regionalization methods besides the commonly used catchment attributes the soil clay content and water holding capacity which are infrequently used in regionalization but have a significant influence on the snow melting process were added in this study garambois et al 2015 räisänen et al 2015 the correlation coefficients between catchment descriptors were calculated to investigate the interdependencies of the selected catchment descriptors fig 2 the results show that the largest correlation coefficient between two catchment descriptors came from the topsoil clay fraction and subsoil clay fraction 0 87 followed by the mean slope and mean elevation 0 66 the topsoil clay fraction and subsoil clay fraction represent the percentage of clay in the topsoil 0 30 cm and subsoil 30 100 cm respectively both of them can significantly affect the snow melting process and soil infiltration capability garambois et al 2015 mamedov et al 2001 räisänen et al 2015 these two descriptors with relatively high correlation coefficients are retained in our study due to their significance but it is recommended in future or other studies to regroup and select independent descriptors 2 3 hydrological models in this study four conceptual models were used for regionalization comparison although distributed physically based models can also be used for runoff simulations in ungauged catchments razavi and coulibaly 2013 this is because the high requirement of considerable input data and the huge computation make it difficult to carry out a regionalization study with distributed physically based models with such a large number of catchments besides some studies have shown that lumped conceptual models perform as well as distributed physically based models in simulating outlet flow of catchments and are often preferred in regionalization li and zhang 2017 the four conceptual hydrological models are génie rural à 4 paramètres journalier gr4j simple lumped conceptual rainfall runoff model simhyd xinanjiang model xaj and the hydrological model of école de technologie supérieure hmets all of which work at the daily time step these hydrological models are chosen mainly based on their structural diversity and reasonable performance in previous regionalization studies li et al 2010 yang et al 2020 zhang and chiew 2009 the number of free parameters for these four conceptual hydrological models varies from 6 to 21 table a 1 table a 2 summarizes the main characteristics of the four hydrological models a brief explanation of each model is provided as follows gr4j is a simple parsimonious model with four free parameters perrin and littlewood 2000 perrin et al 2003 in the gr4j model the transformation of rain into flow is carried out utilizing two reservoirs and a routing production boumenni et al 2017 it has been widely involved in regionalization studies all over the world such as in france oudin et al 2008 china li et al 2014 australia zhang et al 2014 zhang et al 2016 and norway yang et al 2020 considering that the runoff in most catchments is seasonally snow dominated in this study the snow module cemaneige which was developed by valéry 2010 is incorporated into gr4j this snow module allows estimation of snowmelt and simulation of snowpack evolution by using two parameters and the coupling of gr4j and cemaneige has been tested by some other studies hublart et al 2015 yang et al 2020 the total number of parameters becomes six the simhyd model proposed by chiew et al 2002 and chiew 2010 is a simplified version of the hydrolog model which contains three storages for interception loss soil moisture and groundwater and a routing process simhyd is a commonly used rainfall runoff model and has been used to estimate runoff in ungauged catchments in different climate regions zhang and chiew 2009 as with gr4j the snow module cemaneige is incorporated into the original version for snowmelt simulations so the total number of parameters becomes 11 in this study the xaj model developed in a humid region in china by zhao et al 1980 and zhao 1992 consists of evapotranspiration calculation runoff production runoff separation and flow routing it has been applied in many regionalization studies li and zhang 2017 yang et al 2019 yang et al 2020 zhang and chiew 2009 as with gr4j the snow module cemaneige is incorporated into the original version for snowmelt simulations so there are 17 model parameters in total for the xaj model in this application hmets a hydrological model that uses two reservoirs for saturated and vadose zones was developed and modified by école de technologie supérieure brissette 2010 chen et al 2011 chen et al 2018 martel et al 2017 shen et al 2018 it simulates all main hydrological processes including snow accumulation snowmelt and refreezing evapotranspiration infiltration and flow routing there are 21 parameters for the hmets model in this application in hydrological modeling the meteorological data needed are daily precipitation air temperature and potential evapotranspiration since there is no potential evapotranspiration ep data available for the study the oudin formulation oudin et al 2005 is used to calculate daily potential evapotranspiration by using the mean daily air temperature and the latitude of the catchment center table a 1 summarizes the parameters of all hydrological models used in this study in addition in model comparison of the study we divided the gr4j and simhyd in the model group of fewer parameters less than 12 and the xaj and hmets in the model group of more parameters since gr4j and simhyd are commonly considered as parsimonious hydrological models 2 4 model calibration and evaluation criteria the objective function used for hydrological model calibration was kling gupta efficiency kge in this study gupta et al 2009 kge is a modified version of the nash sutcliffe efficiency nse metric that corrects nse s underestimation variability in the goodness of fit function gupta et al 2009 in addition the commonly used nse and accuracy of volume estimate ave which is defined here as one minus volume error were also used to evaluate the simulation results vis et al 2015 1 kge 1 r 1 2 q sim q obs 1 2 cv sim cv obs 1 2 2 nse 1 q sim q obs 2 q obs q obs 2 3 ave 1 ve 1 q obs q sim q obs where q obs and q sim represent observed and simulated runoff respectively q obs and q sim represent mean observed and simulated runoff respectively r is the pearson correlation between observed and simulated runoff and cv obs and cv sim are the standard deviation of observed and simulated discharges respectively the parameters of hydrological models were optimized by using the shuffled complex evolution sce ua optimization algorithm duan et al 1992 duan et al 1993 to avoid the influence of non stationarity of climate time series on model performance and the potential impact of climate change on the parameters stability the odd years were used for model calibration and the even years were used for validation for each catchment the initial parameter values are consistent i e the mean value of upper and lower boundaries of parameters in addition the upper and lower boundaries of each parameter are the same for all catchments in order to consider the influence of equifinality of different hydrological models all models were calibrated 10 times with different initial random seeds the normalization factor eq 4 was calculated to illustrate the distribution of model parameters for the 10 calibrations 4 normalization f a c t o r ca l max i c a l min i b o u top i b o u bottom i where i represents the ith model parameter ca l max i and ca l min i are the maximum and minimum parameter values among the 10 calibrations respectively and bo u top i and bo u bottom i are the top and bottom limits of the ith parameter during model calibration respectively the closer the normalization factor is to 1 the larger the parameter spaces are in the 10 calibrations 2 5 regionalization methods the regionalization methods used in this study included the global mean method distance attributes based methods spatial proximity and physical similarity and regression based method he et al 2011 as the most commonly used methods in the previous regionalization studies these methods show great performance in ungauged runoff prediction jin et al 2008 li et al 2010 merz and blöschl 2004 oudin et al 2008 yang et al 2018 yang et al 2019 the global mean method is a relatively simple regionalization method generally the arithmetic mean of the parameters of all donor gauged catchments is directly applied to the target ungauged catchments for the distance attributes based methods the parameters can be directly transferred from the donor gauged catchments to the target ungauged catchments the key to these methods is to find the closest or most similar donor gauged catchments to the target ungauged catchments there are three widely used methods in this group of approaches 1 spatial proximity the foundational assumption of this method is that nearby catchments should have similar behaviors in this study the distance dtd between donor and target catchments was calculated by using the haversine formula abebe et al 2020 the haversine formula abebe et al 2020 determines the great circle distance between two points on a sphere given their longitudes and latitudes and is widely used in previous studies sarddar et al 2006 setyorini and ramayanti 2019 as the earth is nearly spherical the haversine formula provides a good approximation of the distance between two points of the earth surface with a less than 0 3 error on average movable type scripts 2021 http www movable type co uk scripts latlong html 5 d td 2 r arcsin s i n 2 ϕ t ϕ d 2 cos ϕ t cos ϕ d s i n 2 λ t λ d 2 where r is the average radius of the earth 6378 137 km t and d represent target and donor catchments respectively and ϕ t ϕ d and λ t λ d represent the latitude and longitude of the outlet of the target and donor catchments respectively in radians 2 physical similarity the foundational assumption of this approach is that catchments with similar attributes should show similar hydrological behaviors the similarity index in this study was calculated by burn and boorman 1993 6 si td i 1 k cd d i cd t i δ cd i where cd is the catchment descriptor t and d represent target and donor catchments respectively k is the total number of catchment descriptors and δ cd i represents the range of the ith catchment descriptor 3 physical similarity considering distance in this method the distance dtd between donor and target catchments was used as additional information in calculating the similarity index to select donor catchments in order to avoid a catchment far from the target catchment being selected as a donor catchment then the spatial proximity and physical similarity methods are combined to improve the regionalization results samuel et al 2011 viviroli and seibert 2015 yang et al 2018 in addition when there is more than one donor catchment there are two averaging options to transfer the model parameters from donor catchments in the study 1 parameter averaging a set of parameters applied in target catchments is computed as the mean of model parameter sets from each donor catchment 2 output averaging the model parameter sets from each donor catchment are used for hydrological modeling in target catchments individually and then the outputs are averaged as the result of target catchments in addition some weighting approaches were proposed in previous studies parajka et al 2007 yang et al 2018 in this study we used two methods the arithmetic mean am and inverse distance weighting idw methods to combine the model parameters or outputs for example for the spatial proximity method the donor catchments were given different weights according to the rank of distance when using the idw method for the physical similarity method considering distance the donor catchments were given different weights according to the rank of similarity when using the idw method furthermore the multiple linear regression method is used in this study in which the relationships among model parameters and the selected catchment descriptors are established using multiple linear regression and then derived parameters for target catchments by using these functions it should be noted that the regression function was built for each model parameter burn and boorman 1993 xu 2003 2 6 performance of regionalization methods under different efficiency thresholds in the study we examined the influence of the efficiency threshold values on the regionalization performance first of all we defined a threshold of model efficiency in the calibration period all 0 6 0 7 0 8 0 9 when the efficiency was below the threshold the catchment was not used as a donor catchment to predict runoff for ungauged catchments the threshold all means that no catchment was excluded from the donor catchments all catchments whether poorly or well calibrated were considered these thresholds were chosen because of their importance in hydrological simulations for example the threshold of 0 7 is commonly used in previous studies for the selection of possible donors arsenault and brissette 2014 oudin et al 2008 in addition kge of 0 6 or higher is generally considered a satisfactory simulation of hydrological models choi et al 2021 the kge of 0 8 and 0 9 represent good and very good simulation respectively peña et al 2020 poméon et al 2018 in addition the threshold all is used as a benchmark to evaluate performance with other thresholds therefore these thresholds were chosen to evaluate the influence of the performance of possible donor catchments on regionalization methods all regionalization methods used in this study are summarized in table 2 in total 14 combination approaches were involved in the current research to evaluate the performance of regionalization methods the leave one out cross validation has been used in this study as in many other studies oudin et al 2008 yang et al 2019 yang et al 2020 3 results 3 1 hydrological model performance fig 3 shows the cumulative density function curves of kge nse and ave shilgalis 1988 for all hydrological models over 3444 catchments the cumulative density function curves show the percentage of catchments where the values exceed the given value in both calibration and validation periods the upper and lower boundaries come from xaj and hmets respectively in which the kge value of 80 of the catchments is higher than 0 75 and 0 6 similar ranking results are obtained for nse values when using ave as a metric the upper and lower boundaries come from simhyd and xaj respectively the 21 parameter hmets overall performed the worst in this study the spatial variation of kge is shown in fig 4 for calibration where we can see that there are more than 50 catchments with kge value over 0 8 and more than 10 with kge value over 0 9 for all hydrological models the model performance in eastern and humid catchments is better compared to other parts of north america the normalization factor value of each parameter is shown in fig 5 for four hydrological models generally the median value of the normalization factor is smaller than 0 2 for all parameters of gr4j and only two parameters out of 11 have a higher median normalization factor value more than 0 4 for simhyd however the median value of the normalization factor is larger than 0 2 for most parameters of xaj and hmets these results illustrate that all four models are subjected to the effects of parameter equifinality the issue of equifinality is more problematic for models with more parameters xaj and hmets than those with fewer parameters gr4j and simhyd the interdependencies of model parameters were calculated to investigate the possible overparameterization of hydrological models fig 6 shows the mean correlation coefficient for all calibrated parameters over all 3444 catchments the largest correlation coefficient values between the two parameters are 0 4 for gr4j x1 and x2 0 52 for simhyd coeff and sq 0 57 for xaj n and k and 0 66 for hmets α1 and β1 with an increased number of model parameters the largest correlation coefficient value between two parameters increases this is consistent with the consensus that when multiple parameters are involved the interrelationships and interactions among model parameters can be even more complex li and vu 2015 wang et al 2019 3 2 impact of efficiency thresholds on regionalization methods 3 2 1 the optimal setting of distance attributes based regionalization methods for illustrative purposes the median kge value of donor numbers ranging from one to 20 under different efficiency thresholds for the hmets is shown in fig 7 and similar results for other models see fig a 1 generally the performance of hydrological modeling is improved from one to multiple donor catchments for all hydrological models however the optimal number was slightly different in averaging options and hydrological models specifically the optimal number of donor catchments ranges from four to seven for output averaging and from one to five for parameter averaging even though the efficiency threshold is increased to 0 9 and no more than 25 catchments left as valid donor catchments table 3 the optimal number of donor catchments is still around five for output averaging the largest difference of kge values between five donors and the optimal number of donors is no more than 0 05 for output averaging therefore the selection of five donor catchments may be efficient for output averaging using more than five donor catchments is computationally expensive while limited improvement is achieved for hydrological modeling however for parameter averaging the optimal number of donor catchments varies greatly for different hydrological models under various efficiency thresholds thus a consistent conclusion cannot be drawn on the optimal number of donor catchments for this averaging option in addition after achieving the optimized number for parameter averaging methods from one to five the performance of regionalization gets worse with the increased number of donors for models with more parameters xaj and hmets more than 12 parameters however this phenomenon is not obvious when using output averaging for each model and after reaching the optimal number the performance is almost constant for the output averaging option for most cases even though the number of donor catchments increases to 20 for models with more parameters xaj and hmets the information carried by the parameters will be ignored with parameter averaging when there are more than five donor catchments in this case the model performance will be close to that of the global mean method with an increasing number of donor catchments fig 7 and fig a 1 also show that the idw approach performs better than the am approach for all distance attributes based regionalization methods and all hydrological models under different efficiency thresholds this is consistent with the results from arsenault and brissette 2014 and zhang et al 2016 although the study of yang et al 2018 found no significant difference between weighting approaches over norway this is probably because the distance or similarity difference among our study catchments is relatively large so the choice of weighting approaches plays a more important role in this case the idw method which considers the weighting fraction of distance or similarity performs better besides the weighting scheme of idw minimizes the farthest or least similar donors so their negative impact is reduced in addition we can see from fig 7 and fig a 1 that different averaging options greatly affect the performance of hydrological models for all cases the output averaging option outperforms the parameter averaging option which is consistent with previous studies of samuel et al 2011 li et al 2014 and yang et al 2020 parameter averaging takes the mean value of each parameter set as its value thus neglecting the information content carried by the calibrated model parameters as a set however output averaging uses the hydrological behavior of a donor catchment as characterized by its entire parameter set thus relatively reducing this phenomenon another reason is due to the effect of equifinality we are not able to find the optimal values for individual parameters this indicates that it is worth considering the interaction of parameters and taking the calibrated parameter set as a whole in regionalization yang et al 2018 yang et al 2020 3 2 2 regionalization performance under different efficiency thresholds it can be seen from fig 7 and fig a 1 that the performance of each distance attributes based regionalization method under the all threshold is slightly better than or the same as that under other thresholds the distribution of kge from regionalization methods under a threshold of 0 9 has the smallest median value which indicates that the performance of regionalization methods under a threshold of 0 9 is the worst the differences of median kge values among thresholds of all 0 6 and 0 7 are no more than 0 05 for each regionalization method however the regionalization performance deteriorates from the thresholds of 0 7 to 0 9 the same conclusion can be drawn by the global mean and regression methods fig 8 this is probably attributable to the number and particular location of gauged catchments considered table 3 for example when using a threshold of 0 90 only 531 gr4j 580 simhyd 830 xaj and 345 hmets donor catchments out of the 3444 catchments are available for use and these are mainly located on the west coast and in the eastern part of the united states fig 4 the loss of donor catchment brings the loss of information for regionalization with an increased threshold of model efficiency the density of the catchment decreases and it becomes difficult to determine the most appropriate regionalization method between physical similarity and spatial proximity the same conclusion was also drawn in oudin et al 2008 as it concluded that it is impossible to decide which approach is the most appropriate when the streaming network density is lower than 60 stations per 100 000 km2 table 4 shows the median kge values of spi out psi out and psdi out methods under different efficiency thresholds at the optimal number of donor catchments the output averaging and idw weighting options are selected since the combination of these two methods appears to produce the best simulations overall spatial proximity performs better than physical similarity and physical similarity method considering distance for all thresholds except the threshold of 0 9 under the threshold of 0 9 psdi out marginally outperforms spi out for all hydrological models however the spi out still outperforms psi out for most hydrological models except simhyd this result supports the claim that a dense network of basins may favor spatial proximity arsenault and brissette 2014 oudin et al 2008 the method that combines spatial proximity and physical similarity psdi out is recommended for regions with a low density of gauging stations 3 3 evaluation of regionalization methods 3 3 1 comparison of regionalization performance over 3444 catchments fig 9 shows the performance comparison of different regionalization methods under the all threshold this threshold was chosen because of the appreciable performance of the different methods under this threshold the optimal donor catchments are used for each distance attributes based regionalization method in comparison the performance of calibrated cal hydrological models is considered as the upper benchmark for regionalization methods differences were found among regionalization methods for example the median kge value of spi out is the largest and that of the global mean method is the lowest which indicates that spi out outperforms all other regionalization methods for all hydrological models and the global mean method produces the worst result in addition with an increased number of model parameters the cumulative density function curves of regionalization methods become looser which indicates that the performance tends to be more similar for hydrological models with fewer parameters this result is consistent with yang et al 2020 it was shown that the difference in the performance of regionalization methods was smaller for models with fewer tunable parameters i e gr4j and wasmod with 6 and 8 parameters respectively than those with more parameters i e hbv and xaj with 13 and 17 parameters respectively overall the difference in performance is small for distance attributes based regionalization methods spatial proximity physical similarity and physical similarity method considering distance the same results have been shown in other regionalization studies arsenault and brissette 2014 li et al 2014 li and zhang 2017 oudin et al 2008 yang et al 2020 this is possibly due to the use of multiple donor catchments multiple donor catchments can provide more information than single donor catchments however it is easy to pick up the same donors by different distance attributes based regionalization methods when using multiple donor catchments especially for regions with high stream gauge network density and similar hydroclimatological conditions li et al 2014 to further reveal the joint performance of different regionalization methods and hydrological models table 5 shows the median values of kge nse and ave over all 3444 catchments for all regionalization methods and models the graphic demonstration of the comparison results is shown in fig 10 it is seen that 1 the best and worst performing regionalization methods are consistent among models and evaluation criteria for example in terms of kge nse and ave the best and worst performing methods for all models are spi out 0 67 0 59 0 91 and global mean 0 27 0 14 0 68 respectively 2 the performance difference among hydrological models for the two best performing regionalization methods spi out spa out in terms of kge nse and ave 0 0 0 01 0 0 is small 3 the best and worst performing hydrological models are consistent among regionalization methods for all evaluation criteria for example the two best and one worst performing models in terms of kge nse and ave are gr4j and xaj and hmets 4 the performance difference among regionalization methods is smaller for models with fewer parameters gr4j and simhyd and larger for models with more parameters hmets and xaj in particular the largest performance difference of 14 methods is 0 37 kge for hmets 0 45 nse for xaj and 0 23 ave for hmets similarly for gr4j the values are 0 27 kge 0 24 nse and 0 14 ave as for regionalization methods the largest performance difference of four hydrological models comes from the global mean method 0 13 kge 0 2 nse and 0 09 ave the least performance difference among the four hydrological models comes from spi out 0 03 kge 0 04 nse and 0 003 ave therefore it can be concluded that the impact of the selection of hydrological models is smaller compared to regionalization methods gr4j is ranked first among the models in this study in terms of its good stable performance among the regionalization methods and evaluation criteria spi out is ranked first among the regionalization methods although the difference with spa out is minor 3 3 2 comparison of regionalization performance between nested and non nested catchments it is generally believed that there are strong regional similarities in nested catchments and the use of parameters transposed from nested neighbors results in better regionalization performance merz and blöschl 2004 yao et al 2014 the 2977 catchments from usgs were used to investigate the influence of nested donor catchments on regionalization performance among the 2977 catchments 2370 have nested catchments and the other 607 have not table 6 shows the median kge values of different regionalization methods in nested and non nested catchments the numbers in bold represent the highest median kge values among different regionalization methods under each situation the results show that hydrological models perform better at nested catchments than non nested catchments for all methods one of the main reasons might be that more information is brought by nested catchments in regionalization 3 3 3 comparison of regionalization performance for different climatic regions fig 11 shows the best performing regionalization approach for each catchment for gr4j spi out spa out and spi show the best performance for 506 483 and 303 catchments respectively the other regionalization approaches show the best performance with the number of catchments ranging from 100 gm to 289 spa for gr4j there is no method that systematically outperforms the others over north america similar results are obtained in other models this may be partly because of the varied climatic conditions in this study therefore it is worth investigating whether climatic conditions would affect the performance of regionalization methods and whether the best performing regionalization methods are climate dependent according to the world map of köppen geiger climate classification the 3444 catchments used in this study can be classified as four main climate types arid warm temperate snow and arctic the median kge values of all regionalization methods for different climate types are shown in fig 12 it is found that the methods perform much worse for the arid region than the other three regions in warm temperate and snow regions the best performing method is consistently spi out in arid and arctic regions the best performing method is either spi out or spa out in addition the performance differences of regionalization methods for arid and arctic regions are more significant than those for warm temperate and snow regions as for hydrological models gr4j shows the best performance in most cases while hmets shows the worst performance for warm temperate snow and arctic regions but outperforms xaj for the arid region in general the gr4j and simhyd with spatial proximity method with output average option have the best performance in all different climate regions 4 discussion 4 1 selection of donor catchments this study evaluated the impact of efficiency thresholds on the performance of regionalization methods the results fig 7 fig a 1 and fig 8 show that the median kge values of thresholds of all 0 6 and 0 7 are close to each other however deteriorates of regionalization performance can be seen from thresholds of 0 7 to 0 9 which indicates a loss of information between those thresholds the loss of information may be caused by the increased mean distance between the donor and ungauged catchments fig 13 shows the performance of regionalization methods for different mean distances between the donor and ungauged catchments under the all threshold there are 2490 catchments with a mean distance no more than 50 km 780 catchments with a mean distance between 50 km and 100 km 113 catchments with a mean distance between 100 km and 150 km and 61 catchments with a mean distance more than 150 km with the increased mean distance between the donor and ungauged catchments the performance of the distance attributes based methods more or less deteriorates and the spi out method deteriorates more than that of psi out and psdi out except the median value of ave for simhyd when using the threshold of 0 9 no more than 25 of the 3444 catchments can be chosen as donor catchments and the mean distance between the donor and ungauged catchments increases for most of the pseudo ungauged catchments therefore the performance of regionalization methods under the threshold of 0 9 declines remarkably which implies that for the ungauged catchment it is more important to choose a donor that are more similar or closer to the ungauged catchment than to choose a better performed donor catchment similar conclusion was also drawn in oudin et al 2008 4 2 impact of climatic conditions on regionalization performance according to the median kge values of regionalization methods in different climate regions fig 12 spi out generally performs better than or the same as the other regionalization methods for all hydrological models this indicates that the ranking of regionalization methods is independent of the climatic region this conclusion is consistent with that reported by yang et al 2020 however in our study the regionalization performance in the arid region was substantially worse compared to the other regions in addition the performance differences of regionalization methods and hydrological models in the arid region are also larger than in other regions this may be partly because of the complexity of the infiltration and runoff yield characteristics in the arid region as shown in other studies beck et al 2016 ghebrehiwot and kozlov 2019 both infiltration excess and saturation excess runoff processes exist for most catchments in arid regions in addition extreme hydrological events floods and droughts and the high degree of variability in hydrological rainfall streamflow and meteorological temperature radiation humidity etc variables challenge the use of regionalization methods in arid regions previous studies li and zhang 2017 patil and stieglitz 2015 showed that nearby catchments in dry runoff dominated regions tend to exhibit less hydrological similarity than in more humid regions this highlights the need to improve the hydrological models and regionalization methods to provide better hydrological predictions for ungauged catchments in arid regions ghebrehiwot and kozlov 2019 4 3 contribution of uncertainty from hydrological model structures model parameter sets and regionalization methods multiple uncertainty sources exist in regionalization e g input data model structures model parameters regionalization methods and output data a better understanding of the uncertainty contributions of different uncertainty sources to the total uncertainty in regionalization can provide guidance to reduce the uncertainty in runoff prediction for ungauged catchments bastola et al 2008 fan et al 2020 wagener and wheater 2006 however investigating and quantifying all sources of uncertainty is a challenge for such a large number of catchments therefore the uncertainty contributions of three uncertainty sources which are closely related to parameters in regionalization i e hydrological model structures model parameter sets and regionalization methods were calculated by using the analysis of variance anova fan et al 2020 giuntoli et al 2015 wang et al 2020a wang et al 2020b fig a 2 shows the schematic plot of the uncertainty sources in regionalization including four hydrological models 10 sets of model parameters calibrated with different initial random seeds and 12 regionalization approaches ignoring the re and gm approaches for their poor performance due to relatively efficient performance five and three donor catchments are used for each distance attributes based regionalization method for output averaging and parameter averaging respectively in total an ensemble of 480 hydrological simulations was obtained for each catchment the total variance of runoff vt can be decomposed into the four different contributions as 7 vt v h m v h m p v r m v i where vhm vhmp vrm and vi respectively represent the variance contributed by effects of different hydrological models different parameter sets of each hydrological model different regionalization methods and the interactions between different sources the uncertainty contribution is defined as the percentage of the variance of each source to the overall variance table 7 shows the mean percentage of contribution from each uncertainty source to overall uncertainty for different climate regions in terms of kge and nse the choice of regionalization method contributes the most uncertainty for the warm temperate snow and arctic regions besides the regionalization method the interaction of different sources is also a large uncertainty contributor followed by the hydrological model for the arid region the interaction of different sources contributes the most uncertainty followed by hydrological models and regionalization methods in terms of ave the uncertainty contribution of regionalization methods is the largest for warm temperate and snow regions followed by interaction and hydrological models while in arctic and arid regions the largest uncertainty contribution comes from interaction followed by hydrological models and regionalization methods the equifinality of model parameters is considered to be one of the main issues in hydrological model regionalization since many acceptable parameter sets exist and produce the same similar results in calibration and validation this study shows the use of different parameter sets for hydrological models always contributes the least uncertainty in this study a similar conclusion was also drawn by arsenault and brissette 2014 i e equifinality does not contribute significantly to the overall uncertainty when the parameter sets are used however for methods that emphasize the individual parameters instead of the model output or complete parameter sets the influence of different parameter values should not be ignored arsenault and brissette 2014 yang et al 2020 even though this study produced some solid conclusions for the regionalization there are some limitations that need to be acknowledged due to the computational load for a large domain over north america only lumped hydrological models were used studies with distributed physically based models are needed to further evaluate regionalization performance in addition there are multiple uncertainty sources in regionalization only three uncertainty sources that are closely related to the parameters in regionalization were considered due to the large number of catchments used in this study however the uncertainty caused by the input data for the hydrological modeling in the data scarce regions can t be ignored therefore further studies are recommended to evaluate the influence of other uncertainty sources on regionalization 5 conclusion aiming to find optimal settings of regionalization methods and appropriate regionalization methods for runoff prediction over ungauged catchments under different climate regions this study conducted a comprehensive evaluation by using 14 regionalization combinations and 4 conceptual hydrological models over 3444 catchments in north america the following conclusions can be drawn the spi out method offers the best results with the largest kge value while the global mean method performs the worst for different climate regions and hydrological models the overall difference in performance is small for distance attributes based regionalization methods spatial proximity physical similarity and physical similarity method considering distance clear differences can be found in different climatic regions the hydrological modeling and regionalization methods perform worst in the arid regions the rank of performance of different regionalization methods is independent of the climatic region and hydrological models in general the gr4j and simhyd with spatial proximity method with output average option have the best performance in all different climate regions the optimal number of donor catchments is around five for the output averaging option no matter the efficiency threshold using more than five donor catchments does not significantly increase the performance of the regionalization method when catchment density is low for example see the efficiency threshold under 0 9 however clear conclusions cannot be drawn on the optimal number of donor catchments for the parameter averaging option a deterioration of the performance of regionalization methods is shown from the efficiency thresholds of 0 7 to 0 9 only using well calibrated catchments as donors does not guarantee a good performance of runoff prediction in ungauged catchments it is more important to choose donor catchments that are more similar or closer to the ungauged catchment than to choose better performed ones in the calibration process declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was partially supported by the national key research and development program of china no 2017yfa0603704 the national natural science foundation of china grant no 52079093 the hubei provincial natural science foundation of china grant no 2020cfa100 the overseas expertise introduction project for discipline innovation 111 project grant no b18037 and the research council of norway frinatek project 274310 appendix 
4347,over recent decades hydrologists have proposed a variety of methods to predict discharge in ungauged catchments and significant progress has been made in the field of hydrological model parameter regionalization however uncertainties from both hydrological models and regionalization methods make it a challenge to draw clear conclusions for some questions in regionalization e g the best performing regionalization method the optimal number of donor catchments and the optimal efficiency threshold of donor catchments in this study for the first time we made an attempt to address such questions in one paper through a comprehensive evaluation of model performance by using five regionalization methods with two weighting schemes two averaging options five efficiency thresholds and four lumped hydrological models over a broad set of 3444 catchments under varying hydroclimatic conditions in north america the results show that 1 spatial proximity with the inverse distance weighting method and the output average option spi out generally performs better than or comparable to other regionalization methods for different climate regions and hydrological models while the global mean method performs the worst 2 the rank of different regionalization methods is similar among different climatic regions and hydrological models compared to catchments with other climates regionalization methods perform worst in the arid regions 3 the selection of five donors is relatively efficient for distance attributes based regionalization approaches with the output averaging option disregarding the efficiency threshold 4 the differences of median kling gupta efficiency values among thresholds of all 0 6 and 0 7 are no more than 0 05 for each regionalization method however the regionalization performance significantly deteriorates from using efficiency thresholds of 0 7 to 0 9 due to the significant reduction of available donor catchments thus the poorly calibrated catchments may need to be included in the regionalization process especially when the number of catchments is insufficient keywords regionalization ungauged catchments runoff prediction hydrological models uncertainty 1 introduction in the past few decades hydrological models have become the most popular and common solution for runoff prediction however hydrological models need to be calibrated with observed discharge data which are not available for ungauged catchments jin et al 2009 xu 1999 considering that many catchments of interest lack flow measurements the international association of hydrological sciences established the decade of 2003 2012 on predictions in ungauged basins pub at the 23rd international congress of geophysics and geodesy sivapalan et al 2003 xu et al 2005 tremendous efforts and progress have been made in pub because of this event blöschl et al 2013 guo et al 2021 hrachowitz et al 2013 parajka et al 2013 yang et al 2020 zanial et al 2018 varied and extensive outcomes of runoff predictions in ungauged basins have been achieved and the one that was most commonly used is regionalization blöschl et al 2013 guo et al 2021 hrachowitz et al 2013 zanial et al 2018 by using the regionalization methods the parameter sets of hydrological models on gauged catchments called donors can be transferred to a target ungauged catchment following different procedures according to most previous studies guo et al 2021 he et al 2011 regionalization methods can be classified into four categories arithmetic mean method jin et al 2009 oudin et al 2008 distance attributes based method spatial proximity and physical similarity yang et al 2020 regression based method e g one step regression sequential regression and two step regression samaniego et al 2010 samaniego et al 2017 xu 2003 yang et al 2020 and hydrological signature based approach yadav et al 2007 numerous studies have compared various regionalization methods li et al 2010 oudin et al 2008 yang et al 2018 yang et al 2020 however the conclusion for the best performing method was not consistent li et al 2010 oudin et al 2008 yang et al 2018 yang et al 2020 for example li et al 2010 used the xinanjiang xaj model over 210 australian catchments and found that the spatial proximity approach provided the best regionalization solution merz and blöschl 2004 reported the same conclusion in their study over austria however yang et al 2018 reported that the physical similarity methods performed best runoff simulations based on more than 100 catchments in norway in addition young 2006 found that the regression method showed the most satisfactory results over 260 catchments in the united kingdom parajka et al 2013 made a comprehensive comparison of regionalization methods based on 34 studies reported in the literature and concluded that distance attributes based approaches generally performed better than the regression method there are some reasons why the best performing methods vary among these studies 1 there is high diversity and heterogeneity in different study catchments 2 different hydrological models with various structures and concepts may affect the performance of the regionalization approach and 3 the choice of the number of donor catchments the density of gauged catchments and the use of poorly calibrated catchments as donors can affect the performance of regionalized models oudin et al 2008 even though the selection of donor catchments is the key in regionalization several important issues about the selection of donor catchments are rarely investigated or no consistent conclusion has been drawn such as the most efficient number of donor catchments used for distance attributes based approaches the influence of the efficiency threshold when the model efficiency of a catchment was below the threshold the catchment was not used as a donor catchment to predict runoff for ungauged catchments on the selection of donor catchments and the performance of various regionalization methods for example some studies garambois et al 2015 waseem et al 2015 found that using donor catchments with poorly calibrated runoff could result in high uncertainty in regionalization while others arsenault and brissette 2014 oudin et al 2008 concluded that only using catchments with well calibrated runoff would not guarantee good performance in pseudo ungauged catchments in addition some of the above studies arsenault and brissette 2014 merz and blöschl 2004 only considered one efficiency threshold to exclude poor performance donors and the other oudin et al 2008 did not consider the influence of the different number of donor catchments under different efficiency thresholds therefore the first aim of this study is to investigate the impact of the efficiency threshold and the number of donor catchments on regionalization performance moreover the existing comparisons of regionalization methods are fragmented with limitations in the number of catchments hydrological models and specific regions by summarizing 34 regionalization studies parajka et al 2013 concluded that regionalization performances vary among regions some studies bao et al 2012 yang et al 2019 investigated the performance of regionalization methods between different climate regions for example bao et al 2012 investigated the performance of regionalization methods over 55 catchments in china under multiple hydro climatic conditions i e humid semi humid and arid however only two regionalization methods and one hydrological model were used yang et al 2020 investigated the regionalization performance over different climatic regions by using 86 catchments distributed throughout norway i e oceanic continental and polar tundra regions however arid regions which account for a large percentage of the ungauged regions in the world were not included in the comparison closer appraisal of the influence of different climate conditions on ungauged regionalization is instrumental in the quality of regionalization therefore the second aim of this study is to investigate the performance dependence of multiple regionalization methods on climatic regions to find appropriate regionalization methods for runoff prediction over ungauged catchments overall this study first quantifies the impact of efficiency thresholds on the performance of regionalization methods the regionalization behavior is then evaluated over different climate regions specifically combinations of five widely used regionalization methods two averaging options and two weighting methods 14 regionalization combinations are compared by using four conceptual hydrological models over 3444 north american catchments with highly varying hydroclimatic characteristics the rest of the paper is structured as follows the study area data the hydrological models the regionalization methods and the efficiency thresholds are introduced in section 2 the results are shown in section 3 and the discussion and conclusions are presented in sections 4 and 5 respectively 2 material and methods 2 1 study area in this study 3444 gauged catchments were selected from north america 467 in canada and 2977 in the continental united states arsenault et al 2016 arsenault et al 2020 the study region embraces various climatic zones from savanna in the lowlands of central america to ice fields in northern canada adequately representing spatial climate variability fig 1 shows the distribution of the studied catchments and climate classification extracted from the world map of köppen geiger climate classification 1976 2000 kottek et al 2006 the drainage area of catchments ranges from 302 to 188 470 km2 and covers most of the continental united states and southern and central canada except for the prairies due to the lack of measurements and areas where rivers are regulated 2 2 data for runoff simulation the meteorological data used in this study were daily precipitation and air temperature which were extracted from the santa clara daily database for the united states and natural resources canada gridded climate data product for canada covering the 1950 2010 period arsenault et al 2020 daily discharge data of the catchments in canada and the united states were from the canadian model parameter experiment canopex database and the united states geological survey usgs database arsenault et al 2016 arsenault et al 2020 respectively the length of observed discharge varies from 20 years minimum in these databases to over 60 years for different catchments besides the hydrometeorological data for runoff simulation 13 catchment descriptors classified as climate index terrain characteristics land use and soil characteristics were selected and used in regionalization methods table 1 the aridity and potential evaporation were derived from the global aridity and pet database zomer et al 2008 terrain characteristics land uses and soil characteristics were taken from the hydro1k database usgs 2004 the globcover land cover maps bontemps et al 2011 and the harmonized world soil database harmonized world soil database version 1 1 fao and isric 2012 respectively these catchment descriptors were selected based on the work of he et al 2011 in which they counted the number of times that catchment descriptors were used in a review of regionalization methods besides the commonly used catchment attributes the soil clay content and water holding capacity which are infrequently used in regionalization but have a significant influence on the snow melting process were added in this study garambois et al 2015 räisänen et al 2015 the correlation coefficients between catchment descriptors were calculated to investigate the interdependencies of the selected catchment descriptors fig 2 the results show that the largest correlation coefficient between two catchment descriptors came from the topsoil clay fraction and subsoil clay fraction 0 87 followed by the mean slope and mean elevation 0 66 the topsoil clay fraction and subsoil clay fraction represent the percentage of clay in the topsoil 0 30 cm and subsoil 30 100 cm respectively both of them can significantly affect the snow melting process and soil infiltration capability garambois et al 2015 mamedov et al 2001 räisänen et al 2015 these two descriptors with relatively high correlation coefficients are retained in our study due to their significance but it is recommended in future or other studies to regroup and select independent descriptors 2 3 hydrological models in this study four conceptual models were used for regionalization comparison although distributed physically based models can also be used for runoff simulations in ungauged catchments razavi and coulibaly 2013 this is because the high requirement of considerable input data and the huge computation make it difficult to carry out a regionalization study with distributed physically based models with such a large number of catchments besides some studies have shown that lumped conceptual models perform as well as distributed physically based models in simulating outlet flow of catchments and are often preferred in regionalization li and zhang 2017 the four conceptual hydrological models are génie rural à 4 paramètres journalier gr4j simple lumped conceptual rainfall runoff model simhyd xinanjiang model xaj and the hydrological model of école de technologie supérieure hmets all of which work at the daily time step these hydrological models are chosen mainly based on their structural diversity and reasonable performance in previous regionalization studies li et al 2010 yang et al 2020 zhang and chiew 2009 the number of free parameters for these four conceptual hydrological models varies from 6 to 21 table a 1 table a 2 summarizes the main characteristics of the four hydrological models a brief explanation of each model is provided as follows gr4j is a simple parsimonious model with four free parameters perrin and littlewood 2000 perrin et al 2003 in the gr4j model the transformation of rain into flow is carried out utilizing two reservoirs and a routing production boumenni et al 2017 it has been widely involved in regionalization studies all over the world such as in france oudin et al 2008 china li et al 2014 australia zhang et al 2014 zhang et al 2016 and norway yang et al 2020 considering that the runoff in most catchments is seasonally snow dominated in this study the snow module cemaneige which was developed by valéry 2010 is incorporated into gr4j this snow module allows estimation of snowmelt and simulation of snowpack evolution by using two parameters and the coupling of gr4j and cemaneige has been tested by some other studies hublart et al 2015 yang et al 2020 the total number of parameters becomes six the simhyd model proposed by chiew et al 2002 and chiew 2010 is a simplified version of the hydrolog model which contains three storages for interception loss soil moisture and groundwater and a routing process simhyd is a commonly used rainfall runoff model and has been used to estimate runoff in ungauged catchments in different climate regions zhang and chiew 2009 as with gr4j the snow module cemaneige is incorporated into the original version for snowmelt simulations so the total number of parameters becomes 11 in this study the xaj model developed in a humid region in china by zhao et al 1980 and zhao 1992 consists of evapotranspiration calculation runoff production runoff separation and flow routing it has been applied in many regionalization studies li and zhang 2017 yang et al 2019 yang et al 2020 zhang and chiew 2009 as with gr4j the snow module cemaneige is incorporated into the original version for snowmelt simulations so there are 17 model parameters in total for the xaj model in this application hmets a hydrological model that uses two reservoirs for saturated and vadose zones was developed and modified by école de technologie supérieure brissette 2010 chen et al 2011 chen et al 2018 martel et al 2017 shen et al 2018 it simulates all main hydrological processes including snow accumulation snowmelt and refreezing evapotranspiration infiltration and flow routing there are 21 parameters for the hmets model in this application in hydrological modeling the meteorological data needed are daily precipitation air temperature and potential evapotranspiration since there is no potential evapotranspiration ep data available for the study the oudin formulation oudin et al 2005 is used to calculate daily potential evapotranspiration by using the mean daily air temperature and the latitude of the catchment center table a 1 summarizes the parameters of all hydrological models used in this study in addition in model comparison of the study we divided the gr4j and simhyd in the model group of fewer parameters less than 12 and the xaj and hmets in the model group of more parameters since gr4j and simhyd are commonly considered as parsimonious hydrological models 2 4 model calibration and evaluation criteria the objective function used for hydrological model calibration was kling gupta efficiency kge in this study gupta et al 2009 kge is a modified version of the nash sutcliffe efficiency nse metric that corrects nse s underestimation variability in the goodness of fit function gupta et al 2009 in addition the commonly used nse and accuracy of volume estimate ave which is defined here as one minus volume error were also used to evaluate the simulation results vis et al 2015 1 kge 1 r 1 2 q sim q obs 1 2 cv sim cv obs 1 2 2 nse 1 q sim q obs 2 q obs q obs 2 3 ave 1 ve 1 q obs q sim q obs where q obs and q sim represent observed and simulated runoff respectively q obs and q sim represent mean observed and simulated runoff respectively r is the pearson correlation between observed and simulated runoff and cv obs and cv sim are the standard deviation of observed and simulated discharges respectively the parameters of hydrological models were optimized by using the shuffled complex evolution sce ua optimization algorithm duan et al 1992 duan et al 1993 to avoid the influence of non stationarity of climate time series on model performance and the potential impact of climate change on the parameters stability the odd years were used for model calibration and the even years were used for validation for each catchment the initial parameter values are consistent i e the mean value of upper and lower boundaries of parameters in addition the upper and lower boundaries of each parameter are the same for all catchments in order to consider the influence of equifinality of different hydrological models all models were calibrated 10 times with different initial random seeds the normalization factor eq 4 was calculated to illustrate the distribution of model parameters for the 10 calibrations 4 normalization f a c t o r ca l max i c a l min i b o u top i b o u bottom i where i represents the ith model parameter ca l max i and ca l min i are the maximum and minimum parameter values among the 10 calibrations respectively and bo u top i and bo u bottom i are the top and bottom limits of the ith parameter during model calibration respectively the closer the normalization factor is to 1 the larger the parameter spaces are in the 10 calibrations 2 5 regionalization methods the regionalization methods used in this study included the global mean method distance attributes based methods spatial proximity and physical similarity and regression based method he et al 2011 as the most commonly used methods in the previous regionalization studies these methods show great performance in ungauged runoff prediction jin et al 2008 li et al 2010 merz and blöschl 2004 oudin et al 2008 yang et al 2018 yang et al 2019 the global mean method is a relatively simple regionalization method generally the arithmetic mean of the parameters of all donor gauged catchments is directly applied to the target ungauged catchments for the distance attributes based methods the parameters can be directly transferred from the donor gauged catchments to the target ungauged catchments the key to these methods is to find the closest or most similar donor gauged catchments to the target ungauged catchments there are three widely used methods in this group of approaches 1 spatial proximity the foundational assumption of this method is that nearby catchments should have similar behaviors in this study the distance dtd between donor and target catchments was calculated by using the haversine formula abebe et al 2020 the haversine formula abebe et al 2020 determines the great circle distance between two points on a sphere given their longitudes and latitudes and is widely used in previous studies sarddar et al 2006 setyorini and ramayanti 2019 as the earth is nearly spherical the haversine formula provides a good approximation of the distance between two points of the earth surface with a less than 0 3 error on average movable type scripts 2021 http www movable type co uk scripts latlong html 5 d td 2 r arcsin s i n 2 ϕ t ϕ d 2 cos ϕ t cos ϕ d s i n 2 λ t λ d 2 where r is the average radius of the earth 6378 137 km t and d represent target and donor catchments respectively and ϕ t ϕ d and λ t λ d represent the latitude and longitude of the outlet of the target and donor catchments respectively in radians 2 physical similarity the foundational assumption of this approach is that catchments with similar attributes should show similar hydrological behaviors the similarity index in this study was calculated by burn and boorman 1993 6 si td i 1 k cd d i cd t i δ cd i where cd is the catchment descriptor t and d represent target and donor catchments respectively k is the total number of catchment descriptors and δ cd i represents the range of the ith catchment descriptor 3 physical similarity considering distance in this method the distance dtd between donor and target catchments was used as additional information in calculating the similarity index to select donor catchments in order to avoid a catchment far from the target catchment being selected as a donor catchment then the spatial proximity and physical similarity methods are combined to improve the regionalization results samuel et al 2011 viviroli and seibert 2015 yang et al 2018 in addition when there is more than one donor catchment there are two averaging options to transfer the model parameters from donor catchments in the study 1 parameter averaging a set of parameters applied in target catchments is computed as the mean of model parameter sets from each donor catchment 2 output averaging the model parameter sets from each donor catchment are used for hydrological modeling in target catchments individually and then the outputs are averaged as the result of target catchments in addition some weighting approaches were proposed in previous studies parajka et al 2007 yang et al 2018 in this study we used two methods the arithmetic mean am and inverse distance weighting idw methods to combine the model parameters or outputs for example for the spatial proximity method the donor catchments were given different weights according to the rank of distance when using the idw method for the physical similarity method considering distance the donor catchments were given different weights according to the rank of similarity when using the idw method furthermore the multiple linear regression method is used in this study in which the relationships among model parameters and the selected catchment descriptors are established using multiple linear regression and then derived parameters for target catchments by using these functions it should be noted that the regression function was built for each model parameter burn and boorman 1993 xu 2003 2 6 performance of regionalization methods under different efficiency thresholds in the study we examined the influence of the efficiency threshold values on the regionalization performance first of all we defined a threshold of model efficiency in the calibration period all 0 6 0 7 0 8 0 9 when the efficiency was below the threshold the catchment was not used as a donor catchment to predict runoff for ungauged catchments the threshold all means that no catchment was excluded from the donor catchments all catchments whether poorly or well calibrated were considered these thresholds were chosen because of their importance in hydrological simulations for example the threshold of 0 7 is commonly used in previous studies for the selection of possible donors arsenault and brissette 2014 oudin et al 2008 in addition kge of 0 6 or higher is generally considered a satisfactory simulation of hydrological models choi et al 2021 the kge of 0 8 and 0 9 represent good and very good simulation respectively peña et al 2020 poméon et al 2018 in addition the threshold all is used as a benchmark to evaluate performance with other thresholds therefore these thresholds were chosen to evaluate the influence of the performance of possible donor catchments on regionalization methods all regionalization methods used in this study are summarized in table 2 in total 14 combination approaches were involved in the current research to evaluate the performance of regionalization methods the leave one out cross validation has been used in this study as in many other studies oudin et al 2008 yang et al 2019 yang et al 2020 3 results 3 1 hydrological model performance fig 3 shows the cumulative density function curves of kge nse and ave shilgalis 1988 for all hydrological models over 3444 catchments the cumulative density function curves show the percentage of catchments where the values exceed the given value in both calibration and validation periods the upper and lower boundaries come from xaj and hmets respectively in which the kge value of 80 of the catchments is higher than 0 75 and 0 6 similar ranking results are obtained for nse values when using ave as a metric the upper and lower boundaries come from simhyd and xaj respectively the 21 parameter hmets overall performed the worst in this study the spatial variation of kge is shown in fig 4 for calibration where we can see that there are more than 50 catchments with kge value over 0 8 and more than 10 with kge value over 0 9 for all hydrological models the model performance in eastern and humid catchments is better compared to other parts of north america the normalization factor value of each parameter is shown in fig 5 for four hydrological models generally the median value of the normalization factor is smaller than 0 2 for all parameters of gr4j and only two parameters out of 11 have a higher median normalization factor value more than 0 4 for simhyd however the median value of the normalization factor is larger than 0 2 for most parameters of xaj and hmets these results illustrate that all four models are subjected to the effects of parameter equifinality the issue of equifinality is more problematic for models with more parameters xaj and hmets than those with fewer parameters gr4j and simhyd the interdependencies of model parameters were calculated to investigate the possible overparameterization of hydrological models fig 6 shows the mean correlation coefficient for all calibrated parameters over all 3444 catchments the largest correlation coefficient values between the two parameters are 0 4 for gr4j x1 and x2 0 52 for simhyd coeff and sq 0 57 for xaj n and k and 0 66 for hmets α1 and β1 with an increased number of model parameters the largest correlation coefficient value between two parameters increases this is consistent with the consensus that when multiple parameters are involved the interrelationships and interactions among model parameters can be even more complex li and vu 2015 wang et al 2019 3 2 impact of efficiency thresholds on regionalization methods 3 2 1 the optimal setting of distance attributes based regionalization methods for illustrative purposes the median kge value of donor numbers ranging from one to 20 under different efficiency thresholds for the hmets is shown in fig 7 and similar results for other models see fig a 1 generally the performance of hydrological modeling is improved from one to multiple donor catchments for all hydrological models however the optimal number was slightly different in averaging options and hydrological models specifically the optimal number of donor catchments ranges from four to seven for output averaging and from one to five for parameter averaging even though the efficiency threshold is increased to 0 9 and no more than 25 catchments left as valid donor catchments table 3 the optimal number of donor catchments is still around five for output averaging the largest difference of kge values between five donors and the optimal number of donors is no more than 0 05 for output averaging therefore the selection of five donor catchments may be efficient for output averaging using more than five donor catchments is computationally expensive while limited improvement is achieved for hydrological modeling however for parameter averaging the optimal number of donor catchments varies greatly for different hydrological models under various efficiency thresholds thus a consistent conclusion cannot be drawn on the optimal number of donor catchments for this averaging option in addition after achieving the optimized number for parameter averaging methods from one to five the performance of regionalization gets worse with the increased number of donors for models with more parameters xaj and hmets more than 12 parameters however this phenomenon is not obvious when using output averaging for each model and after reaching the optimal number the performance is almost constant for the output averaging option for most cases even though the number of donor catchments increases to 20 for models with more parameters xaj and hmets the information carried by the parameters will be ignored with parameter averaging when there are more than five donor catchments in this case the model performance will be close to that of the global mean method with an increasing number of donor catchments fig 7 and fig a 1 also show that the idw approach performs better than the am approach for all distance attributes based regionalization methods and all hydrological models under different efficiency thresholds this is consistent with the results from arsenault and brissette 2014 and zhang et al 2016 although the study of yang et al 2018 found no significant difference between weighting approaches over norway this is probably because the distance or similarity difference among our study catchments is relatively large so the choice of weighting approaches plays a more important role in this case the idw method which considers the weighting fraction of distance or similarity performs better besides the weighting scheme of idw minimizes the farthest or least similar donors so their negative impact is reduced in addition we can see from fig 7 and fig a 1 that different averaging options greatly affect the performance of hydrological models for all cases the output averaging option outperforms the parameter averaging option which is consistent with previous studies of samuel et al 2011 li et al 2014 and yang et al 2020 parameter averaging takes the mean value of each parameter set as its value thus neglecting the information content carried by the calibrated model parameters as a set however output averaging uses the hydrological behavior of a donor catchment as characterized by its entire parameter set thus relatively reducing this phenomenon another reason is due to the effect of equifinality we are not able to find the optimal values for individual parameters this indicates that it is worth considering the interaction of parameters and taking the calibrated parameter set as a whole in regionalization yang et al 2018 yang et al 2020 3 2 2 regionalization performance under different efficiency thresholds it can be seen from fig 7 and fig a 1 that the performance of each distance attributes based regionalization method under the all threshold is slightly better than or the same as that under other thresholds the distribution of kge from regionalization methods under a threshold of 0 9 has the smallest median value which indicates that the performance of regionalization methods under a threshold of 0 9 is the worst the differences of median kge values among thresholds of all 0 6 and 0 7 are no more than 0 05 for each regionalization method however the regionalization performance deteriorates from the thresholds of 0 7 to 0 9 the same conclusion can be drawn by the global mean and regression methods fig 8 this is probably attributable to the number and particular location of gauged catchments considered table 3 for example when using a threshold of 0 90 only 531 gr4j 580 simhyd 830 xaj and 345 hmets donor catchments out of the 3444 catchments are available for use and these are mainly located on the west coast and in the eastern part of the united states fig 4 the loss of donor catchment brings the loss of information for regionalization with an increased threshold of model efficiency the density of the catchment decreases and it becomes difficult to determine the most appropriate regionalization method between physical similarity and spatial proximity the same conclusion was also drawn in oudin et al 2008 as it concluded that it is impossible to decide which approach is the most appropriate when the streaming network density is lower than 60 stations per 100 000 km2 table 4 shows the median kge values of spi out psi out and psdi out methods under different efficiency thresholds at the optimal number of donor catchments the output averaging and idw weighting options are selected since the combination of these two methods appears to produce the best simulations overall spatial proximity performs better than physical similarity and physical similarity method considering distance for all thresholds except the threshold of 0 9 under the threshold of 0 9 psdi out marginally outperforms spi out for all hydrological models however the spi out still outperforms psi out for most hydrological models except simhyd this result supports the claim that a dense network of basins may favor spatial proximity arsenault and brissette 2014 oudin et al 2008 the method that combines spatial proximity and physical similarity psdi out is recommended for regions with a low density of gauging stations 3 3 evaluation of regionalization methods 3 3 1 comparison of regionalization performance over 3444 catchments fig 9 shows the performance comparison of different regionalization methods under the all threshold this threshold was chosen because of the appreciable performance of the different methods under this threshold the optimal donor catchments are used for each distance attributes based regionalization method in comparison the performance of calibrated cal hydrological models is considered as the upper benchmark for regionalization methods differences were found among regionalization methods for example the median kge value of spi out is the largest and that of the global mean method is the lowest which indicates that spi out outperforms all other regionalization methods for all hydrological models and the global mean method produces the worst result in addition with an increased number of model parameters the cumulative density function curves of regionalization methods become looser which indicates that the performance tends to be more similar for hydrological models with fewer parameters this result is consistent with yang et al 2020 it was shown that the difference in the performance of regionalization methods was smaller for models with fewer tunable parameters i e gr4j and wasmod with 6 and 8 parameters respectively than those with more parameters i e hbv and xaj with 13 and 17 parameters respectively overall the difference in performance is small for distance attributes based regionalization methods spatial proximity physical similarity and physical similarity method considering distance the same results have been shown in other regionalization studies arsenault and brissette 2014 li et al 2014 li and zhang 2017 oudin et al 2008 yang et al 2020 this is possibly due to the use of multiple donor catchments multiple donor catchments can provide more information than single donor catchments however it is easy to pick up the same donors by different distance attributes based regionalization methods when using multiple donor catchments especially for regions with high stream gauge network density and similar hydroclimatological conditions li et al 2014 to further reveal the joint performance of different regionalization methods and hydrological models table 5 shows the median values of kge nse and ave over all 3444 catchments for all regionalization methods and models the graphic demonstration of the comparison results is shown in fig 10 it is seen that 1 the best and worst performing regionalization methods are consistent among models and evaluation criteria for example in terms of kge nse and ave the best and worst performing methods for all models are spi out 0 67 0 59 0 91 and global mean 0 27 0 14 0 68 respectively 2 the performance difference among hydrological models for the two best performing regionalization methods spi out spa out in terms of kge nse and ave 0 0 0 01 0 0 is small 3 the best and worst performing hydrological models are consistent among regionalization methods for all evaluation criteria for example the two best and one worst performing models in terms of kge nse and ave are gr4j and xaj and hmets 4 the performance difference among regionalization methods is smaller for models with fewer parameters gr4j and simhyd and larger for models with more parameters hmets and xaj in particular the largest performance difference of 14 methods is 0 37 kge for hmets 0 45 nse for xaj and 0 23 ave for hmets similarly for gr4j the values are 0 27 kge 0 24 nse and 0 14 ave as for regionalization methods the largest performance difference of four hydrological models comes from the global mean method 0 13 kge 0 2 nse and 0 09 ave the least performance difference among the four hydrological models comes from spi out 0 03 kge 0 04 nse and 0 003 ave therefore it can be concluded that the impact of the selection of hydrological models is smaller compared to regionalization methods gr4j is ranked first among the models in this study in terms of its good stable performance among the regionalization methods and evaluation criteria spi out is ranked first among the regionalization methods although the difference with spa out is minor 3 3 2 comparison of regionalization performance between nested and non nested catchments it is generally believed that there are strong regional similarities in nested catchments and the use of parameters transposed from nested neighbors results in better regionalization performance merz and blöschl 2004 yao et al 2014 the 2977 catchments from usgs were used to investigate the influence of nested donor catchments on regionalization performance among the 2977 catchments 2370 have nested catchments and the other 607 have not table 6 shows the median kge values of different regionalization methods in nested and non nested catchments the numbers in bold represent the highest median kge values among different regionalization methods under each situation the results show that hydrological models perform better at nested catchments than non nested catchments for all methods one of the main reasons might be that more information is brought by nested catchments in regionalization 3 3 3 comparison of regionalization performance for different climatic regions fig 11 shows the best performing regionalization approach for each catchment for gr4j spi out spa out and spi show the best performance for 506 483 and 303 catchments respectively the other regionalization approaches show the best performance with the number of catchments ranging from 100 gm to 289 spa for gr4j there is no method that systematically outperforms the others over north america similar results are obtained in other models this may be partly because of the varied climatic conditions in this study therefore it is worth investigating whether climatic conditions would affect the performance of regionalization methods and whether the best performing regionalization methods are climate dependent according to the world map of köppen geiger climate classification the 3444 catchments used in this study can be classified as four main climate types arid warm temperate snow and arctic the median kge values of all regionalization methods for different climate types are shown in fig 12 it is found that the methods perform much worse for the arid region than the other three regions in warm temperate and snow regions the best performing method is consistently spi out in arid and arctic regions the best performing method is either spi out or spa out in addition the performance differences of regionalization methods for arid and arctic regions are more significant than those for warm temperate and snow regions as for hydrological models gr4j shows the best performance in most cases while hmets shows the worst performance for warm temperate snow and arctic regions but outperforms xaj for the arid region in general the gr4j and simhyd with spatial proximity method with output average option have the best performance in all different climate regions 4 discussion 4 1 selection of donor catchments this study evaluated the impact of efficiency thresholds on the performance of regionalization methods the results fig 7 fig a 1 and fig 8 show that the median kge values of thresholds of all 0 6 and 0 7 are close to each other however deteriorates of regionalization performance can be seen from thresholds of 0 7 to 0 9 which indicates a loss of information between those thresholds the loss of information may be caused by the increased mean distance between the donor and ungauged catchments fig 13 shows the performance of regionalization methods for different mean distances between the donor and ungauged catchments under the all threshold there are 2490 catchments with a mean distance no more than 50 km 780 catchments with a mean distance between 50 km and 100 km 113 catchments with a mean distance between 100 km and 150 km and 61 catchments with a mean distance more than 150 km with the increased mean distance between the donor and ungauged catchments the performance of the distance attributes based methods more or less deteriorates and the spi out method deteriorates more than that of psi out and psdi out except the median value of ave for simhyd when using the threshold of 0 9 no more than 25 of the 3444 catchments can be chosen as donor catchments and the mean distance between the donor and ungauged catchments increases for most of the pseudo ungauged catchments therefore the performance of regionalization methods under the threshold of 0 9 declines remarkably which implies that for the ungauged catchment it is more important to choose a donor that are more similar or closer to the ungauged catchment than to choose a better performed donor catchment similar conclusion was also drawn in oudin et al 2008 4 2 impact of climatic conditions on regionalization performance according to the median kge values of regionalization methods in different climate regions fig 12 spi out generally performs better than or the same as the other regionalization methods for all hydrological models this indicates that the ranking of regionalization methods is independent of the climatic region this conclusion is consistent with that reported by yang et al 2020 however in our study the regionalization performance in the arid region was substantially worse compared to the other regions in addition the performance differences of regionalization methods and hydrological models in the arid region are also larger than in other regions this may be partly because of the complexity of the infiltration and runoff yield characteristics in the arid region as shown in other studies beck et al 2016 ghebrehiwot and kozlov 2019 both infiltration excess and saturation excess runoff processes exist for most catchments in arid regions in addition extreme hydrological events floods and droughts and the high degree of variability in hydrological rainfall streamflow and meteorological temperature radiation humidity etc variables challenge the use of regionalization methods in arid regions previous studies li and zhang 2017 patil and stieglitz 2015 showed that nearby catchments in dry runoff dominated regions tend to exhibit less hydrological similarity than in more humid regions this highlights the need to improve the hydrological models and regionalization methods to provide better hydrological predictions for ungauged catchments in arid regions ghebrehiwot and kozlov 2019 4 3 contribution of uncertainty from hydrological model structures model parameter sets and regionalization methods multiple uncertainty sources exist in regionalization e g input data model structures model parameters regionalization methods and output data a better understanding of the uncertainty contributions of different uncertainty sources to the total uncertainty in regionalization can provide guidance to reduce the uncertainty in runoff prediction for ungauged catchments bastola et al 2008 fan et al 2020 wagener and wheater 2006 however investigating and quantifying all sources of uncertainty is a challenge for such a large number of catchments therefore the uncertainty contributions of three uncertainty sources which are closely related to parameters in regionalization i e hydrological model structures model parameter sets and regionalization methods were calculated by using the analysis of variance anova fan et al 2020 giuntoli et al 2015 wang et al 2020a wang et al 2020b fig a 2 shows the schematic plot of the uncertainty sources in regionalization including four hydrological models 10 sets of model parameters calibrated with different initial random seeds and 12 regionalization approaches ignoring the re and gm approaches for their poor performance due to relatively efficient performance five and three donor catchments are used for each distance attributes based regionalization method for output averaging and parameter averaging respectively in total an ensemble of 480 hydrological simulations was obtained for each catchment the total variance of runoff vt can be decomposed into the four different contributions as 7 vt v h m v h m p v r m v i where vhm vhmp vrm and vi respectively represent the variance contributed by effects of different hydrological models different parameter sets of each hydrological model different regionalization methods and the interactions between different sources the uncertainty contribution is defined as the percentage of the variance of each source to the overall variance table 7 shows the mean percentage of contribution from each uncertainty source to overall uncertainty for different climate regions in terms of kge and nse the choice of regionalization method contributes the most uncertainty for the warm temperate snow and arctic regions besides the regionalization method the interaction of different sources is also a large uncertainty contributor followed by the hydrological model for the arid region the interaction of different sources contributes the most uncertainty followed by hydrological models and regionalization methods in terms of ave the uncertainty contribution of regionalization methods is the largest for warm temperate and snow regions followed by interaction and hydrological models while in arctic and arid regions the largest uncertainty contribution comes from interaction followed by hydrological models and regionalization methods the equifinality of model parameters is considered to be one of the main issues in hydrological model regionalization since many acceptable parameter sets exist and produce the same similar results in calibration and validation this study shows the use of different parameter sets for hydrological models always contributes the least uncertainty in this study a similar conclusion was also drawn by arsenault and brissette 2014 i e equifinality does not contribute significantly to the overall uncertainty when the parameter sets are used however for methods that emphasize the individual parameters instead of the model output or complete parameter sets the influence of different parameter values should not be ignored arsenault and brissette 2014 yang et al 2020 even though this study produced some solid conclusions for the regionalization there are some limitations that need to be acknowledged due to the computational load for a large domain over north america only lumped hydrological models were used studies with distributed physically based models are needed to further evaluate regionalization performance in addition there are multiple uncertainty sources in regionalization only three uncertainty sources that are closely related to the parameters in regionalization were considered due to the large number of catchments used in this study however the uncertainty caused by the input data for the hydrological modeling in the data scarce regions can t be ignored therefore further studies are recommended to evaluate the influence of other uncertainty sources on regionalization 5 conclusion aiming to find optimal settings of regionalization methods and appropriate regionalization methods for runoff prediction over ungauged catchments under different climate regions this study conducted a comprehensive evaluation by using 14 regionalization combinations and 4 conceptual hydrological models over 3444 catchments in north america the following conclusions can be drawn the spi out method offers the best results with the largest kge value while the global mean method performs the worst for different climate regions and hydrological models the overall difference in performance is small for distance attributes based regionalization methods spatial proximity physical similarity and physical similarity method considering distance clear differences can be found in different climatic regions the hydrological modeling and regionalization methods perform worst in the arid regions the rank of performance of different regionalization methods is independent of the climatic region and hydrological models in general the gr4j and simhyd with spatial proximity method with output average option have the best performance in all different climate regions the optimal number of donor catchments is around five for the output averaging option no matter the efficiency threshold using more than five donor catchments does not significantly increase the performance of the regionalization method when catchment density is low for example see the efficiency threshold under 0 9 however clear conclusions cannot be drawn on the optimal number of donor catchments for the parameter averaging option a deterioration of the performance of regionalization methods is shown from the efficiency thresholds of 0 7 to 0 9 only using well calibrated catchments as donors does not guarantee a good performance of runoff prediction in ungauged catchments it is more important to choose donor catchments that are more similar or closer to the ungauged catchment than to choose better performed ones in the calibration process declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was partially supported by the national key research and development program of china no 2017yfa0603704 the national natural science foundation of china grant no 52079093 the hubei provincial natural science foundation of china grant no 2020cfa100 the overseas expertise introduction project for discipline innovation 111 project grant no b18037 and the research council of norway frinatek project 274310 appendix 
4348,simplified analytical models of the single well push pull swpp test have been widely used to estimate the regional flow velocity and the aquifer porosity where the simplifications refer to that the dispersion effect is negligible and the flow is steady state during the entire swpp test however the errors caused by such assumptions have not been investigated thoroughly in this study numerical modeling of the swpp test without above mentioned simplifications and the field experimental data will be employed to test the applicability of the simplified analytical models the numerical simulation is based on a mathematical model composed of a two dimensional transient flow and transport model which will be solved by the finite element method the results indicate that errors increase with the increasing dispersivity when using the simplified analytical models to estimate both regional flow velocity and porosity the errors refer to the relative difference between the input parameters of the numerical modeling and the estimated parameters by the simplified models such errors also depend on the input values of regional groundwater velocity drift time of the swpp test and aquifer porosity specifically the errors caused by the simplified models of estimating regional groundwater velocity decrease with increasing input regional groundwater velocity increasing input drift time and decreasing input porosity the errors produced by the simplified models of estimating porosity decrease with increasing input regional groundwater velocity increasing input drift time and decreasing input porosity field in situ experiments show that the fitness of the observed breakthrough curves btcs by the numerical modeling is far better than the simplified analytical models the estimated regional flow velocity by the numerical modeling of this study is closer to the estimated values by previous other studies keywords parameter estimation flow velocity porosity radial dispersion 1 introduction groundwater flow is the driving force of solute transport in the subsurface and the accuracy of the estimated groundwater flow velocity is critical to evaluate the physical chemical and biological processes of the contaminants to date two methods have been widely used to determine the in situ groundwater flow velocity the first one is based on detailed information of hydraulic head spatial distribution and hydraulic conductivity so darcy s law can be used to compute the specific discharge rønde et al 2017 zhou et al 2001 on the basis of this one needs additional information of the effective porosity to determine the groundwater flow velocity bayer raich et al 2019 kalbus et al 2006 for the first method to succeed several preparation steps are mandatory first multiple monitoring wells at least three are needed to map the hydraulic head spatial distribution so the hydraulic gradient can be computed second pumping tests or slug tests should be conducted to obtain the hydraulic conductivity information third the effective porosity information should also be known and the effective porosity is often measured by conducting a column tracer test using a core extracted from the field one problem associated with this method is that it is unknown in priori if the effective porosity measured in the laboratory column test is a faithful representative of the effective porosity in actual field setting this can be attributed to a number of reasons for instance the dimensionality of flow in the column test is one dimensional while the actual dimensionality of flow in the field may be three dimensional second the scale of column test is often much smaller than the scale of flow and transport in the field third extraction of core from the field transportation of the extracted core to the laboratory and installation of core in the column can all lead to change of core structures because of these reasons the measured effective porosity in the column test may not be representative of the in situ effective porosity in summary one can see that the first method of measuring the groundwater flow velocity is time consuming expensive and could be unreliable the second method is the in situ tracer test it could be conducted using either a multi well or a single well setting the multi well tracer test needs at least two wells where one well is used to inject a tracer and the other is used to monitor the tracer concentrations englert 2003 vincenzi et al 2009 as for the single well tracer test which is also named the single well push pull swpp test hereinafter both injecting and observing operations are conducted in the same well for instance a pulse of tracer is injected into a targeted aquifer by the well after the regional flow drifts the tracer away from the point of injection for a certain duration the tracer is pumped back through the same well the concentration is sampled during the extraction phase to obtain the observed breakthrough curves btcs in the wellbore the groundwater flow velocity could be estimated by using a proper mathematical model to interpret the observed btcs leap and kaplan 1988 li et al 2019 comparing with other methods the swpp test is efficient and less expensive however the mathematical model is often complex and must be established properly based on rigorous physical principles and solved accurately which is not always straightforward because of its lower computational cost and advantages over the numerical modeling which may suffer from numerical errors caused by many issues such as discretization numerical oscillation numerical dispersion etc analytical solutions are preferred if they are amendable to estimate the aquifer parameters and groundwater flow velocity gelhar and collins 1971 huang et al 2010 and chen et al 2017 derived the analytical solutions of the swpp test for the fully and partially penetrating wells respectively wang et al 2018 extended their analytical solutions by considering the mixing effect in the wellbore novakowski 1992 however these analytical solutions of the swpp test assumed that the regional flow velocity was negligible when the regional groundwater flow is included it is extremely challenge to find the analytical solution of the swpp test leap and kaplan 1988 proposed a simplified model of the swpp test to estimate the regional groundwater flow the simplifications used by leap and kaplan 1988 mainly include that the dispersion effect is negligible and the flow is steady state during the entire swpp test based on the leap and kaplan 1988 hall et al 1991 proposed a simplified model to compute the effective porosity one additional simplification of hall et al 1991 is that the time of the tracer transport during the injection phase is very short so it can be ignored the work of hall et al 1991 has been improved by paradis et al 2018 and paradis et al 2019 by considering a finite tracer transport time during the injection phase although the simplified models mentioned above have been widely used to estimate the regional flow velocity in the field applications such as stephens et al 1998 kim et al 2019 matsumoto et al 2020 and so on the limitations and the accuracy of these models have not been fully investigated li et al 2019 employed numerical modeling to test the applicability of the simplified models and concluded that the model of leap and kaplan 1988 might underestimate the regional groundwater velocity however the parameter of t a as shown in eq 1 in the model of li et al 2019 represents the time corresponding to a peak value of the observed btcs in the wellbore as shown in figs 3 and 4 of li et al 2019 which is different from the definition of t a in leap and kaplan 1988 t a should represent the time elapsed from the start of pumping until the center of mass of tracer pumped back to the wellbore hall et al 1991 kim et al 2019 leap and kaplan 1988 matsumoto et al 2020 paradis et al 2019 meanwhile we find that the regional flow velocities estimated by the simplified models are different when different drift times are used in the swpp test based on the study of matsumoto et al 2020 this is inconsistent with the physical reality because the estimated regional groundwater flow velocity should not depend on the drift time utilized in the swpp test therefore in this study we will revisit the simplified models by leap and kaplan 1988 hall et al 1991 and paradis et al 2019 using a specially designed high resolution finite element numerical modeling the high resolution implies that the numerical errors of the numerical modeling have been controlled to a negligible level the field data by matsumoto et al 2020 will be used to test the accuracy of the simplified models 2 simplified models of the swpp test in previous studies fig 1 shows the schematic diagram of the center of the mass movement in the swpp test with the regional flow field the swpp test contains three phases an injection phase a drift phase and an extraction phase the parameters related to the flow and transport could be estimated by interpreting the observed btcs in the wellbore in the extraction phase leap and kaplan 1988 proposed a simplified model of the swpp test to estimate the regional flow velocity 1 v a q ext t α π θ b 1 2 t dri t α where v a represents the estimated values of the actual regional velocity v a lt 1 of groundwater flow q ext is extraction rate l3t 1 t dri is the duration t of the drift phase t α is time t from the start of the extraction phase to the return of the center of the mass of the injected solute into the wellbore b is the aquifer thickness l θ is aquifer porosity dimensionless hall et al 1991 proposed a simplified model to estimate the aquifer porosity 2 θ π b k x 2 dh dx 2 t dri t α 2 q ext t α where θ represents the estimated porosity of θ dimensionless k x is hydraulic conductivity lt 1 along x axis and k x t x b where tx is the transmissivity l2t 1 along x axis dh dx is the hydraulic gradient dimensionless along the x axis recently paradis et al 2019 revised the model of hall et al 1991 and proposed the following equation to estimate the aquifer porosity 3 θ π b k x 2 dh dx 2 t inj t dri t α 2 q ext t α where t inj is the duration t of the injection phase it is worthwhile noting that the simplified models of eqs 1 3 were derived based on two assumptions i the dispersive transport effect is ignored and ii the flow is in the steady state during the entire swpp test as mentioned in the introduction such simplified models have been widely used to determine the regional flow velocity and aquifer porosity however the robustness and accuracy of these models has never been thoroughly examined 3 numerical modeling of the swpp test 3 1 mathematical model in this study a two dimensional numerical modeling without invoking those simplifications as used in the simplified models will be employed to examine the simplified models of the swpp test eqs 1 3 in the conceptual model a fully penetrating well is located at the center of the aquifer with the length of l the width of l and the thickness of b as shown in figure s1 the length of l can be set sufficiently far from the test well so that the lateral boundary conditions would not affect the result of swpp test the mathematical model associated with the numerical modeling of solute transport around a swpp well under a transient flow field is 4a s h t x t x h x y t y h y x y d t 0 4b r b θ v i r t d r π r w 2 d h w dt q 4c h x y t x 0 h 1 4d h x y t x l h 2 4e s x y t y y 0 0 4f s x y t y y l 0 4g h x y t t 0 h 0 5a c t x d xx c x d xy c y y d yx c x d yy c y x cv x y cv y x y d t 0 5b r v a c d r c x i d r 2 π r w v a c w 5c c x y t x 0 c x y t x l c x y t y 0 c x y t y l 0 5d c r t t 0 0 where h is hydraulic head l h 0 is initial hydraulic head l h 1 and h 2 are constant hydraulic heads l h w is the hydraulic head l in the well x and y represent the space l in cartesian coordinates r is the radial distance from the well center l and v i x 2 y 2 d is a domain excluding the borehole r is the path around the borehole t is time t r w is well radius l v x and v y are the actual flow velocities lt 1 along x and y axis respectively v i is the total flow velocity lt 1 and v i v x 2 v y 2 q is wellbore flow rate l3t 1 which is different in the different phases of the swpp test t y is the aquifer transmissivity l2t 1 along the y axis respectively s is storativity dimensionless c is solute concentration ml 3 in the aquifer d xx d xy d yx and d yy are the components of the dispersion coefficient l2t 1 tensor d r is the radial dispersion coefficient l2t 1 α is the aquifer dispersivity l c w is the solute concentration ml 3 in the wellbore in this study the mathematical model of the swpp test is composed of a two dimensional transient flow model of eqs 4a 4 g and a two dimensional transient transport model of eqs 5a 5d in the flow model eq 4a represents the governing equation of mass balance for flow eq 4b is inner boundary condition at the wellbore where the first term on the left side of eq 4b represents the water flux around the well screen and the second term on the left side of eq 4b represents the wellbore storage eqs 4c 4f are outer boundary conditions of the aquifer and eq 4g is initial condition in the solute transport model eq 5a represents the governing equation of mass balance of transport eq 5b is inner boundary condition at the wellbore where the first term and second term on the left side of eq 5b represent the advective flux and dispersive flux respectively eq 5c are outer boundary conditions of the aquifer and eq 5d is initial condition the flow and transport models are connected through the groundwater flow velocity v x and v y 6a v x k x s x 6b v y k y s y where k y is the hydraulic conductivity lt 1 along the y axes and k y t y b as shown in fig 1 the swpp test is composed of three phases and one has 7 q q inj 0 t t inj 0 t inj t t inj t dri q ext t inj t dri t t inj t dri t ext where q inj is flow rate l3t 1 of the well in the injection phase t ext is time t of the extraction phase the mathematical model of this study is not only an extension of the models used in leap and kaplan 1988 hall et al 1991 and paradis et al 2019 but also an extension of many other models used in the numerical modeling of the swpp test such as li et al 2019 zhao et al 2018 and so on which ignored the wellbore storage when r w s and d x approaches zero and q is too small to influence the regional flow field the mathematical model of this study reduces to the simplified models discussed above another point to note is that the model of eqs 4 7 still has some limitations for instance such a model is established based on the linear flow and transport laws e g darcy s law and fick s law which work for the homogeneous porous medium where horizontal flow happens in reality 70 of the world s aquifers are in bedrock and many of the remaining are in fractured clay or have substantial facies variation dürr et al 2005 these aquifers can be highly heterogeneous and the vertical flow may occur and sometime even becomes dominant in ambient conditions between conductive fractures at different depths birkholzer and tsang 1998 this phenomenon could not be described by the model of eqs 4 7 alternatively packers could be used to isolate a small interval and then do a swpp test to determine the regional flow velocity maldaner et al 2018 in summary there are two questions that should be answered in the future investigations using this study as a reference firstly how will the field heterogeneity and facies variation affect the swpp test results secondly how will the possible vertical flow affect the swpp test results in bedrock aquifers 3 2 numerical solution the governing equations of eq 4a and eq 5a could be solved by many software packages such as modflow mt3d zheng 1992 tough pruess 1987 comsol multiphysics li et al 2009 and so on while comsol multiphysics is more flexible to handle the inner boundary conditions and it will be employed in this study one notable point is that the numerical solution may contain errors e g numerical dispersion and numerical oscillation which relates to the discretization of the grid system as the analytical solution of eqs 4 5 is not available the analytical solution of wang et al 2018 will be employed to guide the spatial discretization of the numerical modeling we find that the numerical error is negligible when the number of elements in the grid system is 5416 further increase of number of cells above 5416 does not improve the performance of the numerical modelling but requires greater computational time so the number of elements used in this investigation is set at 5416 the detailed information of the numerical modeling could be seen in supplementary materials 3 3 calculation of t α in eqs 1 3 one may find that t α is a key parameter and it is obtained based on the observation btcs leap and kaplan 1988 pointed out t α represents the time that the center of mass of the injected solute arrived at the wellbore however li et al 2019 assumed that t α was the time corresponding to the peak value of the observed btcs in the wellbore fig 2a 2b show btcs with t α under different regional groundwater velocities e g v a 1 5 10 6 ms 1 2 0 10 6 ms 1 2 5 10 6 ms 1 3 0 10 6 ms 1 3 5 10 6 ms 1 4 0 10 6 ms 1 4 5 10 6 ms 1 and v a 5 0 10 6 ms 1 in the numerical modeling the regional flow velocity of v a is computed by 8 v a k x h x y t x l h x y t x 0 θ l when q 0 in the swpp test and the flow is steady state one has v a v x in order to withdraw the injected tracer two sets of extraction rates are employed e g q ext 15 m3d 1 used in fig 2a and q ext 30 m3d 1 used in fig 2b the other parameters are b 10 m s s 0 0001 t x t y 100 m2d 1 r w 0 01 m θ 0 3 α l 0 02 m q inj 30 m3d 1 t inj 1 h t dri 36 h t ext 72 h and h 2 15 m fig 3a 3h represent the concentration contour maps sp represents the stagnation point where the flow velocity is zero the curve of ds e g dividing streamline is the boundary of the capture zone one may find that the definition of t α in li et al 2019 is questionable and the reason could explained as follows figs 2 and 3 show that the configuration of the btcs depends on the spatial relationship between the plume of the injected tracer and the sp location of the swpp test at the beginning of the extraction phase or the end of the drift phase when the plume of the injected tracer passes through sp btc is unimodal and the time corresponding to the btc vertex is not zero as shown in fig 2b otherwise when the solute plume is still within the capture zone at the beginning of the extraction phase btc monotonically decreases with time as shown in fig 2a and the time corresponding to the btc vertex is zero as a result the model of li et al 2019 could not work for the cases in fig 2a because of t α 0 therefore the definition of t α in leap and kaplan 1988 seems reasonable how does the model of leap and kaplan 1988 perform in estimating the regional flow velocity will be examined in the following section 4 examination of the simplified models 4 1 examination of the simplified models by numerical modeling as the mathematical model of the numerical modeling is closer to reality than the analytical solutions in the sense that it does not invoke the assumptions employed in the simplified model it will serve as the benchmark in this study after the confirmation that the numerical errors have been controlled in a negligible level the key idea behind examining the simplified models is that btc in the wellbore is firstly produced by the numerical modeling when the regional flow velocity v a and porosity θ are given then v a is estimated after using the simplified models of eq 1 to interpret the computed btc in the wellbore if v a is close to v a it implies that the simplified model of eq 1 performs faithfully to recover the input value of v a thus is reliable similarly θ could be computed using eq 2 or eq 3 based on the computed btc in the wellbore by the numerical modeling if θ is close to θ it means that the simplified models of eq 2 or eq 3 work satisfactorily to recover the input value of θ as mentioned in section 2 the dispersion effect is ignored in the simplified models of eqs 1 3 to test the influence of the dispersivity on the simplified models in estimation of v a and θ six sets of the values are employed as shown in tables 1a and 1b because of the regional flow field the injected solute could not be withdrawn by a small well extraction rate when the dispersivity is sufficiently large thus two sets of q ext are introduced tables 1a and 1b indicate that errors of both the estimated regional flow velocity and estimated porosity by the simplified models increase with the increasing dispersivity where the errors are quantified by the absolute values of the different of the estimated value and the input value over the input value 9a error v a v a v a v a 9b error θ θ θ θ comparing θ estimated by hall et al 1991 and paradis et al 2019 we find that the model of paradis et al 2019 performs better in estimation of porosity than hall et al 1991 however the errors of paradis et al 2019 are still considerable even for a relatively small dispersivity e g error v a 14 3 and error θ 19 3 when α l 0 01 m in addition we also investigate the influence of the input values of regional groundwater velocity drift time and aquifer porosity on the simplified models and the comparison between the input and estimated values of velocity and porosity are shown in tables 2 3 and 4 respectively from these tables we find that the input values of all these parameters could affect the accuracy of the velocity and porosity estimation by the simplified models and error θ by eq 3 is smaller than that by eq 2 tables 2a 3a and 4a show that the errors of v a decreases with increasing v a increasing t dri and decreasing θ respectively tables 2b 3b and 4b shows that the errors of θ decreases with increasing v a increasing t dri and decreasing θ respectively 4 2 examination of the simplified models by the field swpp test experiments to determine the regional flow velocity of the sedimentary coastal basin in the horonobe area in hokkaido japan matsumoto et al 2020 conducted a series of the swpp tests the site location is 300 m away from the coastline and the geomorphology could be characterized by a flat moorland where a part of the study area is converted to farmland by decreasing the water table by the artificial drains ikawa et al 2014 sakai et al 2011 and sakai et al 2012 conducted some hydrogeological surveys in the horonobe area they found that the groundwater in the confined aquifer was not directly from the land surface rainfall instead it was mainly from the eastern hilly area and western sand dune the test well is located at latitude 44 59 40 7 n and longitude 141 41 16 3 e wgs84 and fully penetrates the target confined aquifer which consists of silty fine sand coarse and medium grained sand vertically ranging from the depths of 91 4 to 99 0 m hebig et al 2016 hebig et al 2015 the confined aquifer is overlaid and underlaid by the aquitards consisting of silty fine sand and silt and mudstone the detailed geological information of the test well could be seen in fig 1 of matsumoto et al 2020 in this study the confined aquifer is approximately treated as a homogeneous porous medium three types of chemicals are used as tracers e g non reactive uranine u isotope of hydrogen δ d and isotope of oxygen δ 18 o and five sets of drift time are employed for the swpp tests t dri 0 d 10 d 37 d 739d and 1802 d respectively the parameters in this experiment are b 7 6 m r w 0 03 m θ 0 3 q inj 7 2 m3d 1 t inj 180 min q ext 7 2 m3d 1 and t ext 2040 min the detailed procedure of the experiment could be seen in matsumoto et al 2020 in matsumoto et al 2020 the regional flow velocity was estimated by eq 1 we found that different drift times used in the swpp test could result in different estimated v a e g v a 3 4 10 7 ms 1 when t dri 10 d in fig 4a and v a 1 0 10 7 ms 1 when t dri 37 d in fig 4b in this study numerical modeling will be employed to estimate the regional flow velocity based on the field experimental data by matsumoto et al 2020 as the injected tracer could not be fully withdrawn in the case of t dri 739 d and 1802 d due to the effect of the regional flow field we choose the data of t dri 10 d and 37 d to test the simplified models used by matsumoto et al 2020 fig 4a and 4b show the fitness of the observed btcs in the wellbore by the simplified models and the numerical modeling of this study the curves of best fitted btc by matsumoto et al 2020 is produced by the numerical modeling where the regional flow velocity is v a 3 4 10 7 ms 1 in fig 4a and v a 1 0 10 7 ms 1 in fig 4b these two values of the flow velocity were estimated by the simplified models in matsumoto et al 2020 one may find that the difference between the observed and computed btcs is obvious then the regional flow velocity is estimated by the numerical modeling of this study using the trial and error method and v a 2 54 10 9 ms 1 is recovered for both fig 4a and fig 4b we find that the fitness of the observed btcs by numerical modeling of this study is better than the simplified models by matsumoto et al 2020 additionally the estimated velocity of this study is closer to v a 3 17 10 9 ms 1 v a 0 1 myear 1 which was estimated by previous studies although the numerical model of this study performs well in interpreting the observation data conducted in sedimentary basin of hokkaido japan the estimated regional flow velocity values might not represent the real value this is because the accuracy of the estimated values is not only dependent on the test operations but also on the choice of the mathematical models used to interpret the observation data during the test in this study the numerical model contained an assumption that the aquifer is homogeneous to test or improve the methodology of the experiment conducted in sedimentary basin of hokkaido japan the equipment of aquavision could be used to directly measure the flow velocity in the wellbore meanwhile the multi well test could be conducted if the measured and estimated v a by different methods are almost the same it could be used to represent v a 5 summary and conclusions the swpp test has been widely used to estimate the regional flow velocity and the aquifer porosity as the analytical solutions of the swpp test with regional flow field are not available simplified models have been proposed before by a number of investigators however the errors caused by the assumptions included in these simplified models have not been fully investigated in this study the numerical modeling is employed to check the influence of aquifer dispersivity regional groundwater velocity drift time and aquifer porosity on such errors field experimental data by matsumoto et al 2020 is employed to test the simplified models and the numerical modeling the following conclusions could be drawn 1 errors produced by the simplified models increase with the increasing dispersivity for both estimated regional flow velocity and porosity 2 errors caused by the simplified models are related to the regional groundwater velocity the drift time of the swpp test and the aquifer porosity 3 the numerical modeling performs better than the simplified models when interpreting the field experimental data 4 the simplified models are valid when the regional flow velocity is smaller than 1 5 10 6 ms 1 credit authorship contribution statement quanrong wang conceptualization methodology writing original draft aohan jin software hongbin zhan writing review editing yu chen wenguang shi hui liu yu wang declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was partially supported by programs of natural science foundation of china no 41772252 no 41972250 and no 41502229 innovative research groups of the national nature science foundation of china no 41521001 the 111 program state administration of foreign experts affairs the ministry of education of china no b18049 the fundamental research funds for the central universities and china university of geosciences wuhan no cuggc07 we thank the editor associate editor and anonymous reviewers for their constructive comments which help improve the quality of the paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126711 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4348,simplified analytical models of the single well push pull swpp test have been widely used to estimate the regional flow velocity and the aquifer porosity where the simplifications refer to that the dispersion effect is negligible and the flow is steady state during the entire swpp test however the errors caused by such assumptions have not been investigated thoroughly in this study numerical modeling of the swpp test without above mentioned simplifications and the field experimental data will be employed to test the applicability of the simplified analytical models the numerical simulation is based on a mathematical model composed of a two dimensional transient flow and transport model which will be solved by the finite element method the results indicate that errors increase with the increasing dispersivity when using the simplified analytical models to estimate both regional flow velocity and porosity the errors refer to the relative difference between the input parameters of the numerical modeling and the estimated parameters by the simplified models such errors also depend on the input values of regional groundwater velocity drift time of the swpp test and aquifer porosity specifically the errors caused by the simplified models of estimating regional groundwater velocity decrease with increasing input regional groundwater velocity increasing input drift time and decreasing input porosity the errors produced by the simplified models of estimating porosity decrease with increasing input regional groundwater velocity increasing input drift time and decreasing input porosity field in situ experiments show that the fitness of the observed breakthrough curves btcs by the numerical modeling is far better than the simplified analytical models the estimated regional flow velocity by the numerical modeling of this study is closer to the estimated values by previous other studies keywords parameter estimation flow velocity porosity radial dispersion 1 introduction groundwater flow is the driving force of solute transport in the subsurface and the accuracy of the estimated groundwater flow velocity is critical to evaluate the physical chemical and biological processes of the contaminants to date two methods have been widely used to determine the in situ groundwater flow velocity the first one is based on detailed information of hydraulic head spatial distribution and hydraulic conductivity so darcy s law can be used to compute the specific discharge rønde et al 2017 zhou et al 2001 on the basis of this one needs additional information of the effective porosity to determine the groundwater flow velocity bayer raich et al 2019 kalbus et al 2006 for the first method to succeed several preparation steps are mandatory first multiple monitoring wells at least three are needed to map the hydraulic head spatial distribution so the hydraulic gradient can be computed second pumping tests or slug tests should be conducted to obtain the hydraulic conductivity information third the effective porosity information should also be known and the effective porosity is often measured by conducting a column tracer test using a core extracted from the field one problem associated with this method is that it is unknown in priori if the effective porosity measured in the laboratory column test is a faithful representative of the effective porosity in actual field setting this can be attributed to a number of reasons for instance the dimensionality of flow in the column test is one dimensional while the actual dimensionality of flow in the field may be three dimensional second the scale of column test is often much smaller than the scale of flow and transport in the field third extraction of core from the field transportation of the extracted core to the laboratory and installation of core in the column can all lead to change of core structures because of these reasons the measured effective porosity in the column test may not be representative of the in situ effective porosity in summary one can see that the first method of measuring the groundwater flow velocity is time consuming expensive and could be unreliable the second method is the in situ tracer test it could be conducted using either a multi well or a single well setting the multi well tracer test needs at least two wells where one well is used to inject a tracer and the other is used to monitor the tracer concentrations englert 2003 vincenzi et al 2009 as for the single well tracer test which is also named the single well push pull swpp test hereinafter both injecting and observing operations are conducted in the same well for instance a pulse of tracer is injected into a targeted aquifer by the well after the regional flow drifts the tracer away from the point of injection for a certain duration the tracer is pumped back through the same well the concentration is sampled during the extraction phase to obtain the observed breakthrough curves btcs in the wellbore the groundwater flow velocity could be estimated by using a proper mathematical model to interpret the observed btcs leap and kaplan 1988 li et al 2019 comparing with other methods the swpp test is efficient and less expensive however the mathematical model is often complex and must be established properly based on rigorous physical principles and solved accurately which is not always straightforward because of its lower computational cost and advantages over the numerical modeling which may suffer from numerical errors caused by many issues such as discretization numerical oscillation numerical dispersion etc analytical solutions are preferred if they are amendable to estimate the aquifer parameters and groundwater flow velocity gelhar and collins 1971 huang et al 2010 and chen et al 2017 derived the analytical solutions of the swpp test for the fully and partially penetrating wells respectively wang et al 2018 extended their analytical solutions by considering the mixing effect in the wellbore novakowski 1992 however these analytical solutions of the swpp test assumed that the regional flow velocity was negligible when the regional groundwater flow is included it is extremely challenge to find the analytical solution of the swpp test leap and kaplan 1988 proposed a simplified model of the swpp test to estimate the regional groundwater flow the simplifications used by leap and kaplan 1988 mainly include that the dispersion effect is negligible and the flow is steady state during the entire swpp test based on the leap and kaplan 1988 hall et al 1991 proposed a simplified model to compute the effective porosity one additional simplification of hall et al 1991 is that the time of the tracer transport during the injection phase is very short so it can be ignored the work of hall et al 1991 has been improved by paradis et al 2018 and paradis et al 2019 by considering a finite tracer transport time during the injection phase although the simplified models mentioned above have been widely used to estimate the regional flow velocity in the field applications such as stephens et al 1998 kim et al 2019 matsumoto et al 2020 and so on the limitations and the accuracy of these models have not been fully investigated li et al 2019 employed numerical modeling to test the applicability of the simplified models and concluded that the model of leap and kaplan 1988 might underestimate the regional groundwater velocity however the parameter of t a as shown in eq 1 in the model of li et al 2019 represents the time corresponding to a peak value of the observed btcs in the wellbore as shown in figs 3 and 4 of li et al 2019 which is different from the definition of t a in leap and kaplan 1988 t a should represent the time elapsed from the start of pumping until the center of mass of tracer pumped back to the wellbore hall et al 1991 kim et al 2019 leap and kaplan 1988 matsumoto et al 2020 paradis et al 2019 meanwhile we find that the regional flow velocities estimated by the simplified models are different when different drift times are used in the swpp test based on the study of matsumoto et al 2020 this is inconsistent with the physical reality because the estimated regional groundwater flow velocity should not depend on the drift time utilized in the swpp test therefore in this study we will revisit the simplified models by leap and kaplan 1988 hall et al 1991 and paradis et al 2019 using a specially designed high resolution finite element numerical modeling the high resolution implies that the numerical errors of the numerical modeling have been controlled to a negligible level the field data by matsumoto et al 2020 will be used to test the accuracy of the simplified models 2 simplified models of the swpp test in previous studies fig 1 shows the schematic diagram of the center of the mass movement in the swpp test with the regional flow field the swpp test contains three phases an injection phase a drift phase and an extraction phase the parameters related to the flow and transport could be estimated by interpreting the observed btcs in the wellbore in the extraction phase leap and kaplan 1988 proposed a simplified model of the swpp test to estimate the regional flow velocity 1 v a q ext t α π θ b 1 2 t dri t α where v a represents the estimated values of the actual regional velocity v a lt 1 of groundwater flow q ext is extraction rate l3t 1 t dri is the duration t of the drift phase t α is time t from the start of the extraction phase to the return of the center of the mass of the injected solute into the wellbore b is the aquifer thickness l θ is aquifer porosity dimensionless hall et al 1991 proposed a simplified model to estimate the aquifer porosity 2 θ π b k x 2 dh dx 2 t dri t α 2 q ext t α where θ represents the estimated porosity of θ dimensionless k x is hydraulic conductivity lt 1 along x axis and k x t x b where tx is the transmissivity l2t 1 along x axis dh dx is the hydraulic gradient dimensionless along the x axis recently paradis et al 2019 revised the model of hall et al 1991 and proposed the following equation to estimate the aquifer porosity 3 θ π b k x 2 dh dx 2 t inj t dri t α 2 q ext t α where t inj is the duration t of the injection phase it is worthwhile noting that the simplified models of eqs 1 3 were derived based on two assumptions i the dispersive transport effect is ignored and ii the flow is in the steady state during the entire swpp test as mentioned in the introduction such simplified models have been widely used to determine the regional flow velocity and aquifer porosity however the robustness and accuracy of these models has never been thoroughly examined 3 numerical modeling of the swpp test 3 1 mathematical model in this study a two dimensional numerical modeling without invoking those simplifications as used in the simplified models will be employed to examine the simplified models of the swpp test eqs 1 3 in the conceptual model a fully penetrating well is located at the center of the aquifer with the length of l the width of l and the thickness of b as shown in figure s1 the length of l can be set sufficiently far from the test well so that the lateral boundary conditions would not affect the result of swpp test the mathematical model associated with the numerical modeling of solute transport around a swpp well under a transient flow field is 4a s h t x t x h x y t y h y x y d t 0 4b r b θ v i r t d r π r w 2 d h w dt q 4c h x y t x 0 h 1 4d h x y t x l h 2 4e s x y t y y 0 0 4f s x y t y y l 0 4g h x y t t 0 h 0 5a c t x d xx c x d xy c y y d yx c x d yy c y x cv x y cv y x y d t 0 5b r v a c d r c x i d r 2 π r w v a c w 5c c x y t x 0 c x y t x l c x y t y 0 c x y t y l 0 5d c r t t 0 0 where h is hydraulic head l h 0 is initial hydraulic head l h 1 and h 2 are constant hydraulic heads l h w is the hydraulic head l in the well x and y represent the space l in cartesian coordinates r is the radial distance from the well center l and v i x 2 y 2 d is a domain excluding the borehole r is the path around the borehole t is time t r w is well radius l v x and v y are the actual flow velocities lt 1 along x and y axis respectively v i is the total flow velocity lt 1 and v i v x 2 v y 2 q is wellbore flow rate l3t 1 which is different in the different phases of the swpp test t y is the aquifer transmissivity l2t 1 along the y axis respectively s is storativity dimensionless c is solute concentration ml 3 in the aquifer d xx d xy d yx and d yy are the components of the dispersion coefficient l2t 1 tensor d r is the radial dispersion coefficient l2t 1 α is the aquifer dispersivity l c w is the solute concentration ml 3 in the wellbore in this study the mathematical model of the swpp test is composed of a two dimensional transient flow model of eqs 4a 4 g and a two dimensional transient transport model of eqs 5a 5d in the flow model eq 4a represents the governing equation of mass balance for flow eq 4b is inner boundary condition at the wellbore where the first term on the left side of eq 4b represents the water flux around the well screen and the second term on the left side of eq 4b represents the wellbore storage eqs 4c 4f are outer boundary conditions of the aquifer and eq 4g is initial condition in the solute transport model eq 5a represents the governing equation of mass balance of transport eq 5b is inner boundary condition at the wellbore where the first term and second term on the left side of eq 5b represent the advective flux and dispersive flux respectively eq 5c are outer boundary conditions of the aquifer and eq 5d is initial condition the flow and transport models are connected through the groundwater flow velocity v x and v y 6a v x k x s x 6b v y k y s y where k y is the hydraulic conductivity lt 1 along the y axes and k y t y b as shown in fig 1 the swpp test is composed of three phases and one has 7 q q inj 0 t t inj 0 t inj t t inj t dri q ext t inj t dri t t inj t dri t ext where q inj is flow rate l3t 1 of the well in the injection phase t ext is time t of the extraction phase the mathematical model of this study is not only an extension of the models used in leap and kaplan 1988 hall et al 1991 and paradis et al 2019 but also an extension of many other models used in the numerical modeling of the swpp test such as li et al 2019 zhao et al 2018 and so on which ignored the wellbore storage when r w s and d x approaches zero and q is too small to influence the regional flow field the mathematical model of this study reduces to the simplified models discussed above another point to note is that the model of eqs 4 7 still has some limitations for instance such a model is established based on the linear flow and transport laws e g darcy s law and fick s law which work for the homogeneous porous medium where horizontal flow happens in reality 70 of the world s aquifers are in bedrock and many of the remaining are in fractured clay or have substantial facies variation dürr et al 2005 these aquifers can be highly heterogeneous and the vertical flow may occur and sometime even becomes dominant in ambient conditions between conductive fractures at different depths birkholzer and tsang 1998 this phenomenon could not be described by the model of eqs 4 7 alternatively packers could be used to isolate a small interval and then do a swpp test to determine the regional flow velocity maldaner et al 2018 in summary there are two questions that should be answered in the future investigations using this study as a reference firstly how will the field heterogeneity and facies variation affect the swpp test results secondly how will the possible vertical flow affect the swpp test results in bedrock aquifers 3 2 numerical solution the governing equations of eq 4a and eq 5a could be solved by many software packages such as modflow mt3d zheng 1992 tough pruess 1987 comsol multiphysics li et al 2009 and so on while comsol multiphysics is more flexible to handle the inner boundary conditions and it will be employed in this study one notable point is that the numerical solution may contain errors e g numerical dispersion and numerical oscillation which relates to the discretization of the grid system as the analytical solution of eqs 4 5 is not available the analytical solution of wang et al 2018 will be employed to guide the spatial discretization of the numerical modeling we find that the numerical error is negligible when the number of elements in the grid system is 5416 further increase of number of cells above 5416 does not improve the performance of the numerical modelling but requires greater computational time so the number of elements used in this investigation is set at 5416 the detailed information of the numerical modeling could be seen in supplementary materials 3 3 calculation of t α in eqs 1 3 one may find that t α is a key parameter and it is obtained based on the observation btcs leap and kaplan 1988 pointed out t α represents the time that the center of mass of the injected solute arrived at the wellbore however li et al 2019 assumed that t α was the time corresponding to the peak value of the observed btcs in the wellbore fig 2a 2b show btcs with t α under different regional groundwater velocities e g v a 1 5 10 6 ms 1 2 0 10 6 ms 1 2 5 10 6 ms 1 3 0 10 6 ms 1 3 5 10 6 ms 1 4 0 10 6 ms 1 4 5 10 6 ms 1 and v a 5 0 10 6 ms 1 in the numerical modeling the regional flow velocity of v a is computed by 8 v a k x h x y t x l h x y t x 0 θ l when q 0 in the swpp test and the flow is steady state one has v a v x in order to withdraw the injected tracer two sets of extraction rates are employed e g q ext 15 m3d 1 used in fig 2a and q ext 30 m3d 1 used in fig 2b the other parameters are b 10 m s s 0 0001 t x t y 100 m2d 1 r w 0 01 m θ 0 3 α l 0 02 m q inj 30 m3d 1 t inj 1 h t dri 36 h t ext 72 h and h 2 15 m fig 3a 3h represent the concentration contour maps sp represents the stagnation point where the flow velocity is zero the curve of ds e g dividing streamline is the boundary of the capture zone one may find that the definition of t α in li et al 2019 is questionable and the reason could explained as follows figs 2 and 3 show that the configuration of the btcs depends on the spatial relationship between the plume of the injected tracer and the sp location of the swpp test at the beginning of the extraction phase or the end of the drift phase when the plume of the injected tracer passes through sp btc is unimodal and the time corresponding to the btc vertex is not zero as shown in fig 2b otherwise when the solute plume is still within the capture zone at the beginning of the extraction phase btc monotonically decreases with time as shown in fig 2a and the time corresponding to the btc vertex is zero as a result the model of li et al 2019 could not work for the cases in fig 2a because of t α 0 therefore the definition of t α in leap and kaplan 1988 seems reasonable how does the model of leap and kaplan 1988 perform in estimating the regional flow velocity will be examined in the following section 4 examination of the simplified models 4 1 examination of the simplified models by numerical modeling as the mathematical model of the numerical modeling is closer to reality than the analytical solutions in the sense that it does not invoke the assumptions employed in the simplified model it will serve as the benchmark in this study after the confirmation that the numerical errors have been controlled in a negligible level the key idea behind examining the simplified models is that btc in the wellbore is firstly produced by the numerical modeling when the regional flow velocity v a and porosity θ are given then v a is estimated after using the simplified models of eq 1 to interpret the computed btc in the wellbore if v a is close to v a it implies that the simplified model of eq 1 performs faithfully to recover the input value of v a thus is reliable similarly θ could be computed using eq 2 or eq 3 based on the computed btc in the wellbore by the numerical modeling if θ is close to θ it means that the simplified models of eq 2 or eq 3 work satisfactorily to recover the input value of θ as mentioned in section 2 the dispersion effect is ignored in the simplified models of eqs 1 3 to test the influence of the dispersivity on the simplified models in estimation of v a and θ six sets of the values are employed as shown in tables 1a and 1b because of the regional flow field the injected solute could not be withdrawn by a small well extraction rate when the dispersivity is sufficiently large thus two sets of q ext are introduced tables 1a and 1b indicate that errors of both the estimated regional flow velocity and estimated porosity by the simplified models increase with the increasing dispersivity where the errors are quantified by the absolute values of the different of the estimated value and the input value over the input value 9a error v a v a v a v a 9b error θ θ θ θ comparing θ estimated by hall et al 1991 and paradis et al 2019 we find that the model of paradis et al 2019 performs better in estimation of porosity than hall et al 1991 however the errors of paradis et al 2019 are still considerable even for a relatively small dispersivity e g error v a 14 3 and error θ 19 3 when α l 0 01 m in addition we also investigate the influence of the input values of regional groundwater velocity drift time and aquifer porosity on the simplified models and the comparison between the input and estimated values of velocity and porosity are shown in tables 2 3 and 4 respectively from these tables we find that the input values of all these parameters could affect the accuracy of the velocity and porosity estimation by the simplified models and error θ by eq 3 is smaller than that by eq 2 tables 2a 3a and 4a show that the errors of v a decreases with increasing v a increasing t dri and decreasing θ respectively tables 2b 3b and 4b shows that the errors of θ decreases with increasing v a increasing t dri and decreasing θ respectively 4 2 examination of the simplified models by the field swpp test experiments to determine the regional flow velocity of the sedimentary coastal basin in the horonobe area in hokkaido japan matsumoto et al 2020 conducted a series of the swpp tests the site location is 300 m away from the coastline and the geomorphology could be characterized by a flat moorland where a part of the study area is converted to farmland by decreasing the water table by the artificial drains ikawa et al 2014 sakai et al 2011 and sakai et al 2012 conducted some hydrogeological surveys in the horonobe area they found that the groundwater in the confined aquifer was not directly from the land surface rainfall instead it was mainly from the eastern hilly area and western sand dune the test well is located at latitude 44 59 40 7 n and longitude 141 41 16 3 e wgs84 and fully penetrates the target confined aquifer which consists of silty fine sand coarse and medium grained sand vertically ranging from the depths of 91 4 to 99 0 m hebig et al 2016 hebig et al 2015 the confined aquifer is overlaid and underlaid by the aquitards consisting of silty fine sand and silt and mudstone the detailed geological information of the test well could be seen in fig 1 of matsumoto et al 2020 in this study the confined aquifer is approximately treated as a homogeneous porous medium three types of chemicals are used as tracers e g non reactive uranine u isotope of hydrogen δ d and isotope of oxygen δ 18 o and five sets of drift time are employed for the swpp tests t dri 0 d 10 d 37 d 739d and 1802 d respectively the parameters in this experiment are b 7 6 m r w 0 03 m θ 0 3 q inj 7 2 m3d 1 t inj 180 min q ext 7 2 m3d 1 and t ext 2040 min the detailed procedure of the experiment could be seen in matsumoto et al 2020 in matsumoto et al 2020 the regional flow velocity was estimated by eq 1 we found that different drift times used in the swpp test could result in different estimated v a e g v a 3 4 10 7 ms 1 when t dri 10 d in fig 4a and v a 1 0 10 7 ms 1 when t dri 37 d in fig 4b in this study numerical modeling will be employed to estimate the regional flow velocity based on the field experimental data by matsumoto et al 2020 as the injected tracer could not be fully withdrawn in the case of t dri 739 d and 1802 d due to the effect of the regional flow field we choose the data of t dri 10 d and 37 d to test the simplified models used by matsumoto et al 2020 fig 4a and 4b show the fitness of the observed btcs in the wellbore by the simplified models and the numerical modeling of this study the curves of best fitted btc by matsumoto et al 2020 is produced by the numerical modeling where the regional flow velocity is v a 3 4 10 7 ms 1 in fig 4a and v a 1 0 10 7 ms 1 in fig 4b these two values of the flow velocity were estimated by the simplified models in matsumoto et al 2020 one may find that the difference between the observed and computed btcs is obvious then the regional flow velocity is estimated by the numerical modeling of this study using the trial and error method and v a 2 54 10 9 ms 1 is recovered for both fig 4a and fig 4b we find that the fitness of the observed btcs by numerical modeling of this study is better than the simplified models by matsumoto et al 2020 additionally the estimated velocity of this study is closer to v a 3 17 10 9 ms 1 v a 0 1 myear 1 which was estimated by previous studies although the numerical model of this study performs well in interpreting the observation data conducted in sedimentary basin of hokkaido japan the estimated regional flow velocity values might not represent the real value this is because the accuracy of the estimated values is not only dependent on the test operations but also on the choice of the mathematical models used to interpret the observation data during the test in this study the numerical model contained an assumption that the aquifer is homogeneous to test or improve the methodology of the experiment conducted in sedimentary basin of hokkaido japan the equipment of aquavision could be used to directly measure the flow velocity in the wellbore meanwhile the multi well test could be conducted if the measured and estimated v a by different methods are almost the same it could be used to represent v a 5 summary and conclusions the swpp test has been widely used to estimate the regional flow velocity and the aquifer porosity as the analytical solutions of the swpp test with regional flow field are not available simplified models have been proposed before by a number of investigators however the errors caused by the assumptions included in these simplified models have not been fully investigated in this study the numerical modeling is employed to check the influence of aquifer dispersivity regional groundwater velocity drift time and aquifer porosity on such errors field experimental data by matsumoto et al 2020 is employed to test the simplified models and the numerical modeling the following conclusions could be drawn 1 errors produced by the simplified models increase with the increasing dispersivity for both estimated regional flow velocity and porosity 2 errors caused by the simplified models are related to the regional groundwater velocity the drift time of the swpp test and the aquifer porosity 3 the numerical modeling performs better than the simplified models when interpreting the field experimental data 4 the simplified models are valid when the regional flow velocity is smaller than 1 5 10 6 ms 1 credit authorship contribution statement quanrong wang conceptualization methodology writing original draft aohan jin software hongbin zhan writing review editing yu chen wenguang shi hui liu yu wang declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was partially supported by programs of natural science foundation of china no 41772252 no 41972250 and no 41502229 innovative research groups of the national nature science foundation of china no 41521001 the 111 program state administration of foreign experts affairs the ministry of education of china no b18049 the fundamental research funds for the central universities and china university of geosciences wuhan no cuggc07 we thank the editor associate editor and anonymous reviewers for their constructive comments which help improve the quality of the paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126711 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4349,the climate change initiative cci program of the european space agency esa esa cci provides a global surface soil moisture sm product by merging the information from various active and passive sensors on board for the period of 1971 2014 this study aims to assimilate this surface sm product into a recently developed model namely statistical soil moisture profile ssmp model to investigate the efficacy of this combination in developing a vertical soil moisture profile database over a climatologically vast area such as indian mainland the ssmp model is a spatially varying statistical framework that couples the memory and forcing of sm from the overlying layers and utilizes the information of hydrologic soil groups hsgs that makes it spatially transferable the model estimates sm at four depths i e 10 20 51 and 102 cm using the surface sm information 0 5 cm the developed database is named as esa cci driven vertical soil moisture profile root zone database edvsmpd and the simulated values are validated with observed sm data at many monitoring stations across india maintained by india meteorological department imd as an exemplary demonstration of the utility of the data basin scale reconstruction of the historical agricultural droughts and its spatial distribution using the developed edvsmpd product is illustrated for a medium sized drought stricken river basin namely wardha in the central part of india the resulting sm product for a considerable length of period more than 30 years will be immensely useful for many hydro climatological studies keywords soil moisture remote sensing data assimilation statistical soil moisture profile ssmp model esa cci esa cci driven vertical soil moisture profile root zone database edvsmpd 1 introduction the soil moisture sm studies over the indian region emphasized on the feedback and coupling between sm and monsoon rainfall and their effects on seasonal and interannual variability using numerical simulations douville et al 2001 koster et al 2004 lodh et al 2013 the pre monsoon sm condition influences the monsoon onset and precipitation asharaf et al 2012 as well as persistence of sm anomalies influencing the atmospheric circulation shukla and mintz 1982 regional climate model simulations showed that sm memory lengths increase with soil depth and considerable geographical variability exist during monsoon asharaf and ahrens 2013 another study by singh et al 2019 showed the geographical variations during monsoon using indian remote sensing satellite data to study the spatial and temporal variations of monthly sm the soil moisture drought variability in a changing climate in india was investigated by mishra et al 2014 using vic model simulated soil moisture the reanalysis products from merra era interim and the ncep cfsr were assessed in the context of monsoon season droughts over the indian region by shah and mishra 2014 hence consistent multi layer sm variability information over the indian subcontinent is essential to better understanding of the surface atmosphere interaction in relation to the monsoon agricultural drought monitoring studies and different numerical modeling applications indian economy is primarily based on rainfed agriculture dependent on soil type and available soil moisture moreover 16 of india s geographic area mostly arid semiarid and subhumid is prone to drought which experiences it recurrently with different intensities among the different types of droughts agricultural drought has the more direct and immediate socio economic impact mishra and singh 2010 since it directly influences the crop yield and hence agricultural production panu and sharma 2002 this drought is mainly caused by soil moisture deficits and can be assessed more accurately by drought indices based on soil moisture information mukherjee et al 2018 however the scarcity in global consistent and long term time series of reliable soil moisture data required to derive the drought indices has prevented their operational use till date sheffield et al 2004 the availability of quality sm data at large scale and fine resolution is sparse over the indian region till date despite the access of several global sm data products based on satellite observations reanalysis land data assimilation etc at hand sathyanadh et al 2017 nayak et al 2018 created a high resolution 4 km and 3 hourly sm product for 2001 2014 during indian monsoon seasons using a land data assimilation system ldas the dataset was able to capture the inter annual intraseasonal and diurnal variations under different monsoon conditions and enhanced the simulations of heavy rain events over indian monsoon region when used to initialize the mesoscale model in another study singh et al 2019 investigated the spatio temporal variability of sm over a significantly large area 500 km2 in a tropical basin in india eighty three sm monitoring locations were selected having 56 days of observed records to identify the optimal sampling design for regional scale soil moisture assessment however the requirement of monitoring stations for continental scale assessment will be very high for the entire indian mainland most of the aforementioned studies deal with the surface sm only 0 10 cm however an assessment of soil moisture variation below the surface layer at least up to root zone depth is important in agricultural and irrigation management practices especially in semiarid and arid regions because of its impact on the production and health status of crops and salinization vereecken et al 2008 besides the sm profile information has many important applications in many fields of studies such as estimating evaporation and evapotranspiration wang et al 2013 brown et al 2014 flood forecasting nied et al 2014 salathé et al 2014 forecasting water supply in groundwater systems barnett et al 2005 estimation of denudation processes including landslides ekinci et al 2013 modeling ecosystem functions tague et al 2009 along with different climatological studies as discussed above the sm for the unsaturated zone can be obtained from national center for environmental prediction ncep climate forecast system reanalysis cfsr saha et al 2010 modern era retrospective analysis for research and applications merra european center for medium range weather forecasting ecmwf reanalysis interim era i saha et al 2010 dee et al 2011 and it is observed that all reanalysis data captured the seasonal cycle for each water content component shrivastava et al 2016 more recent studies investigated the effects of physical controls on the spatial variability of soil moisture and developed hydrological connectivity that is important for land surface model for better assessment of spatial variations of soil moisture kim and mohanty 2017 however these models and data products are highly dependent on their forcing parameters and the non linear model physics it is also observed that the comparison of different reanalysis datasets to evaluate their accuracies loew et al 2013 showed significant differences in the climatology over the indian region of evaporation and soil moisture field the association between sm values at different soil layers and the stochastic features of sm dynamics were also studied by cross correlation method and vector auto regression var method kim and kim 2007 kim 2009 kim et al 2011 mahmood et al 2012 later vertical sm profile information was obtained from the surface sm information through coupling its memory temporal persistence and forcing input from overlying layers by using the auto regressive model with exogenous arx input pal et al 2016 however the above mentioned studies did not investigate the spatial transferability of the proposed approaches another study by pal and maity 2020 developed a spatially varying statistical soil moisture profile ssmp model by coupling the memory and forcing based on the box jenkins approach as shown in pal et al 2016 to estimate the vertical sm profile from the surface sm information the study developed the spatially varying ssmp model for four hydrological soil groups hsgs to impart spatial transferability the hsg specific ssmp model explores the spatial transferability as it demonstrates the effects of the physical controls viz soil texture hydraulic conductivity runoff and infiltration however this ssmp model coupling the sm information at different layers requires the accurate large scale surface sm estimation to obtain a reliable estimation of vertical sm profile characterization of distribution and quantity of surface sm at a local and global scale by microwave active and passive remote sensing influenced by the dielectric properties of the soil is a potential alternative for expensive in situ monitoring networks to obtain the surface sm estimation recently the european space agency climate change initiative esa cci program developed a combined remotely sensed global data set of surface sm product retrieved from passive and active microwave sensors on board various satellites liu et al 2012 wagner et al 2012 http www esa soilmoisture cci org however the resulting combined sm product represents approximately the top few millimeters to centimeters of the soil depending on frequency used kuria et al 2007 hence the availability of this large scale satellite based surface sm product and spatially transferable stochastic model to couple the sm at different depths indicates a potential benefit of assimilating the microwave based surface sm information into the statistical framework of ssmp model to obtain large scale fine resolution spatially varying vertical sm profile database this is the overall objective of this study specifically the objective includes a thorough investigation of the efficiency of assimilating the esa cci surface sm product into the hsg specific ssmp model to prepare a spatially varying vertical sm profile database across the entire indian mainland the data product is named as esa cci driven vertical soil moisture profile root zone database which is abbreviated as edvsmpd the database is validated with respect to observed records of soil moisture at various stations across india maintained by india meteorological department imd finally the usefulness of the outcome of the study i e the vertical sm profile database edvsmpd for different hydrological agricultural and climatological studies is also outlined as an example an analysis pertaining to reconstruction of the historical agricultural droughts using the developed edvsmpd product is illustrated for a medium sized river basin namely wardha in the drought stricken central part of india 2 data used the esa released the first multi decadal satellite observed sm dataset as a part of its cci program in 2012 for global scale liu et al 2012 wagner et al 2012 http www esa soilmoisture cci org this product named esa cci sm combines the sm retrievals from four passive and two active coarse resolution microwave sensors into a global data set in a synergistic way the four passive sensors are namely nimbus 7 scanning multi channel microwave radiometer smmr special sensor microwave imagers ssm i of the defense meteorological satellite program dmsp tropical rainfall measuring mission trmm microwave imager tmi and advanced microwave scanning radiometer earth observing system amsr e and the two active sensors are european remote sensing satellites ers 1 and 2 active microwave instrument ami wind scatterometer and the advanced scatterometer ascat onboard the meteorological operational satellite a metop a the esa cci sm combines single sensor active and passive microwave sm products into three harmonized products which are a merged active a merged passive and a combined active passive microwave product the present study uses the sm data from esa cci sm product version 2 2 which covers a period of 1978 2014 as surface sm values in terms of volumetric water content dorigo et al 2015 active products are retrieved using the tu wien water retrieval package warp algorithm wagner et al 1999 it is a change detection approach that retrieves sm as degree of saturation by scaling radar backscatter measurements between the historically lowest completely dry and highest observed values saturated at each grid location the backscatter contribution of vegetation is corrected using the multi antenna multi incidence angle capability of the ers and ascat scatterometers vreugdenhil et al 2016 a threshold based decision tree algorithm is applied to incidence angle normalized backscatter measurements in frozen or freezing thawing conditions naeimi et al 2012 passive products are retrieved using the land parameter retrieval model lprm algorithm owe et al 2008 based on the radiative transfer model and applicable to a wide range of frequencies i e 1 20 ghz for c band and higher frequency sensors the data is filtered using ka band based temperature for frozen conditions holmes et al 2009 for smos l band retrievals the filtering is based on the radio frequency interference rfi the esa cci sm algorithms merge these pre processed l2 data that is gridded active or passive soil moisture products for the merging the products were rescaled against sm from a land surface modeling product gldas noah rodell et al 2004 using cumulative distribution function cdf matching since the units of the two data sets are different i e volumetric soil moisture m3 m3 and degree of saturation these data are resampled to a 0 25 regular grid using a hamming window approach and to daily time stamps 00 00 utc using a nearest neighbour search thus spatial resolution of the resulting merged product is 0 25 0 25 latitude longitude and represents approximately the top few millimeters to centimeters from surface kuria et al 2007 this resolution is purely guided by the data from the esa cci program though the recently available surface soil moisture data from soil moisture and ocean salinity smos 2010 soil moisture active passive smap 2015 or sentinel 2015 have much finer resolution but are only available for the recent years on the contrary the temporal coverage of esa cci sm product is from 1978 to 2014 which is sufficiently long that is essential for many hydroclimatic studies the grid wise hsg information is collected from central ground water board cgwb 2007 which classified the entire india into four major hsgs at 0 5 0 5 resolution spanning between 8 to 37 5 n and 68 to 97 5 e as shown in fig 1 it can be noticed that the hsg a is scattered to various parts across india whereas hsg b is mainly concentrated to northern india especially gangetic basin along with maximum parts of north east india and south india except the coastal regions the coastal regions and some of north western india arid region are mainly consisting of hsg c hsg d is completely concentrated in the middle and western region of india the weekly in situ sm data from 25 monitoring stations of india meteorological department imd across different hsgs in india fig 1 during 1991 2006 available are used for validation of the model estimated sm product the sm values are measured using standard gravimetric method at the depths of 0 7 5 15 30 45 and 60 cm imd 2009 the data is procured from national data centre ndc of imd pune india 3 methodology this paper attempts to assimilate the satellite based surface sm data into the hsg specific ssmp model to develop a three dimensional vertical sm profile map for india in brief the methodology of this study mainly follows three steps firstly the satellite based surface sm data is procured and pre processed from esa cci sm product for entire india and grid wise hsg information for entire india is collected from cgwb the second step is grid wise identification of hsg across the study area and accordingly the application of the ssmp model proposed by pal and maity 2020 finally the model performance is validated with the ground data obtained from imd the following sections provide a brief description of the pre processing of esa cci sm product and development of ssmp model 3 1 missing value treatment this section discusses about the missing values observed in the esa cci sm product which is used as surface sm values for the study area treating the missing value is essential in the present study for the application of the proposed approach since the number of missing values greater than the memory or forcing order present in the time series would hinder the model application the fraction of the missing values to the total length of record in each grid of the study area for the complete length of time series data is shown in fig 3 for each grid the fraction is computed as the ratio of the sum of number of missing values present in complete time series length to the length of sm time series data the range of the fraction is estimated to be 0 42 to 1 hence it can be said that missing values are almost for half of the days of total time series length which is a shortcoming of the input dataset the sm values at missing time steps are obtained by interpolation from sm values available at previous and succeeding days of those missing steps the piecewise cubic hermite interpolating polynomial pchip interpolation method is used to obtain the sm values fritsch and carlson 1980 kahaner et al 1989 however it is understood that the use of interpolation to sm values in daily scale will certainly lead to erroneous outcome hence while the interpolation is a requirement to use the esa cci surface sm data in the proposed ssmp model the study has ignored the missing values at time steps where the surface sm values are not available for previous 20 threshold selected in the present study days during the development of vertical sm profile map over entire india which is discussed in detail in the following sections the threshold length of days is selected such that the length is long enough to fill up maximum number of missing values and short enough to capture the soil moisture trend provided there is no rainfall within this period however the interpolated values at time steps where the esa cci sm product for surface are available for any steps within previous 20 days the interpolated values are considered in the study 3 2 ssmp model development the sm at deeper layers have been estimated from the surface sm information by coupling the memory and forcing shown in pal et al 2016 for a point location however the scope of spatial transferability of the proposed model based on box jenkins approach using an arx model was not investigated as the next step pal and maity 2020 developed a spatially varying ssmp model to estimate the vertical sm profile from surface sm information for four hsgs the development of the spatially varying ssmp model is based on the box jenkins approach shown in pal et al 2016 by coupling the memory and forcing components of sm the study used observed sm data from five depths i e 5 10 20 51 and 102 cm depths from three sm networks operated by international soil moisture network ismn for model development as well as for spatial transferability investigation the incorporation of hsg information into the proposed ssmp model helps to represent the effects of the physical controls viz soil texture hydraulic conductivity runoff and infiltration thus enabling the scope of spatial transferability the spatial transferability is investigated by applying the developed ssmp models to new locations it is important to mention that during the spatial validation deviation in mean dm for the surface layer has to be computed and the model estimated sm values are dm corrected to match the different sm regimes of the new locations and model developing stations the dm checks the bias of the model by trying to match the mean of the surface sm of the model developing stations and the new locations the dm is computed by estimating the mean of the surface sm of all the model developing stations of a specific hsg and then subtracting the mean sm of surface layer of the target station from it the unit of dm corrected soil moisture is same as the predicted soil moisture i e m3 m3 the model performances during the spatial validation encourage the developed ssmp models to be applied in different study area to obtain the vertical sm profile estimation the mathematical description of the spatially varying ssmp model is provided in pal and maity 2020 however a brief step wise description of the model development and spatial validation is presented as following the complete methodology is shown in fig 2 and hsg specific ssmp models are shown in table 1 table 2 model development step 1 the observed sm infromation from five depths i e 5 10 20 51 and 102 cm are obtained from soil climate analysis network scan u s climate reference network uscrn and snowpacktelemetry snotel networks from the international soil moisture network ismn dorigo et al 2011 covering a total of 171 stations for model development and spatial validation the available stations are categorized into four hsgs from the web soil survey wss https websoilsurvey sc egov usda gov app homepage htm step 2 the observed sm data is transformed to normal distribution through non parametric kernel density approach the data transformation is the requirement of ssmp model since it is based on the box jenkins approach which requires the data to follow normal distribution moreover to focus on the spatial transferability the data should be transformed to a common probability distribution form since the sm data at different locations mostly do not follow the same range and distribution the corresponding estimated sm values are obtained by back transformation step 3 the coupling approach is applied to the transformed data obtained from the observed data of each model development station of all four hsgs for four depth pairs the adjoining layers i e 5 10 cm 10 20 cm 20 51 cm and 51 102 cm the coupling approach at a location is represented by the following equation 1 s m k t i 1 p a i s m k t i j d q d 1 b j s m k 1 t j e t where s m k t is the transformed standard normal variate of sm at target depth k at time step t s m k t i are the transformed standard normal variates of sm at target depth at previous time steps where i 1 2 p s m k 1 t j are the transformed standard normal variates of sm of the overlying layer at previous time steps where j 0 1 q 1 the coefficients and orders of memory and forcing are represented as a i and b j and p and q respectively and e t represents the white noise the relative delay between the input sm time series and the output sm time series is represented as d which is considered to be zero at daily scale in the present study the complete mathematical description of the estimation of model parameters i e the model orders and model coefficients are shown in pal et al 2016 step 4 as discussed in the last step for each depth pair of each station of all four hsgs the model at a location is developed and the model orders are obtained the median value of the different model orders across the stations obtained in that process is assigned as the model order of that particular depth pair of that hsg the models with the assigned model orders are reapplied to all depth pairs of all the stations for a particular hsg finally the mean of the coefficients obtained corresponding to each depth pair across the stations of that particular hsg is allocated as the specific coefficient for that particular depth pair and hsg the stationarity is checked before finalizing the set of ssmp model as averaging the coefficients of different box jenkins models may lead to non stationarity spatial validation step 1 the hsgs are identified for the new stations and the observed surface sm values are transformed to standard normal variates using non parametric kernel density approach data transformation to apply ssmp models step 2 for each hsg a reference cdf plot applying the kernel distribution is prepared with the complete data from all model developing stations corresponding to that particular hsg for each deeper layers to use in the ungauged stations step 3 according to the hsg of the new station the ssmp model is applied and the estimated sm values are obtained by back transformation using the reference cdf for corresponding depth and hsg step 4 finally the back transformed values for the deeper layers of the target stations obtained after applying the ssmp models are dm corrected by adding the obtained dm whereas the detail of data collection is already provided discussion of model application and validation is presented along with results in the following section 4 results and discussions 4 1 3 dimensional vertical sm profile map for entire indian mainland the hsg specific ssmp models are developed for four depths considering adjoining depths as pairs 5 10 10 20 20 51 and 51 102 cm to apply the spatially varying model to the esa cci surface sm the first step is to identify the hsgs at the desired grid points where the esa cci sm product are available as mentioned before the hsg information of entire india is provided by cgwb at 0 5 0 5 resolution from 8 to 37 5 n and 68 to 97 5 e and the esa cci sm product is available at 0 25 0 25 for global scale hence for the present study the esa cci sm data is obtained for 8 125 to 37 875 n and 68 125 to 97 875 e since the hsg and the sm product grid points do not coincide hsg information at the target grid points where esa cci sm data is available is picked out from the hsg map the identification of the hsg information is followed by the application of ssmp models to each grid points over entire india according to the hsg of that point for all depths and all the days to obtain the sm vertical profile database finally the model application ends with the dm correction of estimated sm to obtain the final sm product for deeper layers as suggested by pal and maity 2020 at each grid point the dm is computed and estimated sm values for the deeper layers of the target stations are dm corrected by adding the obtained dm it is worthwhile to mention that these dm corrected sm values are the final product of the ssmp model the estimated sm represents this final dm corrected sm and the estimated sm values before dm correction is mentioned hereafter in the manuscript wherever necessary for discussion considering as a typical example fig 4 shows the estimated sm values at 5 10 20 51 and 102 cm for entire india on december 28 29 30 and 31 2014 the white patches in the sm map at 5 cm depths shows the missing values for that depth for that particular date however it can be noticed that for the same day the number of grid cells with missing values shown for deeper layers i e 10 20 51 and 102 cm are more than the surface layers as discussed before the replacement of the missing values with interpolated values in esa cci surface sm may introduce error in the data to be applied in the ssmp model and subsequently in the sm output at every layer hence the study uses a threshold for the number of days with continuous missing values it is fixed at 20 days in other words for a particular day and particular grid point if the observed satellite based surface sm values are entirely unavailable for previous 20 days the estimated sm at deeper layers for that particular day and grid point are discarded these are not included in the derived product and thus not shown in the map despite the shortcomings of having missing values as a descendant of esa cci sm product the advantages of the developed vertical soil moisture profile data product edvsmpd are multifold firstly the multi decadal length of the time series with high spatial and temporal resolutions is very useful for climate change studies however the studies on small basins may not even suffer from the missing values and long data set will be highly useful for climate related studies secondly the efficacy of the esa cci sm product is well established by several studies that have validated the esa cci sm product against in situ soil moisture observations by comparing it against ground based observations from various sites around the globe dorigo et al 2015 fang et al 2016 an et al 2016 shen et al 2016 mao et al 2017 dorigo et al 2017 moreover the widespread applications of the esa cci soil moisture product in different fields such as climate variability and change shrivastava et al 2017 unnikrishnan et al 2017 land atmosphere interactions li et al 2017 park et al 2017 global biogeochemical cycles and ecology he et al 2017 tang et al 2017 hydrological and land surface modelling asoka et al 2017 heimhuber et al 2017 drought applications cammalleri et al 2017 das and maity 2015 yan et al 2017 mcnally et al 2017 and hydrometeorological applications zhan et al 2017 to improve our earth system understanding are well recognized by the climate science community dorigo et al 2017 hence these advantages of having the long temporal global coverage and its well alignment with the ground observations make the use of esa cci sm product highly potential over different products available thus the quality and usefulness of the ssmp model estimated sm at 10 20 51 and 102 cm depths for entire indian mainland at 0 25 0 25 named as esa cci driven vertical soil moisture profile root zone database edvsmpd is equally beneficial for many studies this dataset is made available in the open repository of mendeley data pal and maity 2021 url https data mendeley com datasets 78c9yggmmg draft a 06084c38 4436 4b71 beb3 90944769751e 4 2 validation of vertical sm profile database the validation of the obtained product i e the three dimensional sm database for entire india mainland is carried out with the observed sm values provided by the india meteorological department imd the imd has provided the in situ sm information at surface 0 7 5 cm and deeper layers 15 30 45 and 60 cm depths for bare land and crop land areas at 48 stations across india at an interval of 7 days all these data sets are procured from national data centre ndc of imd pune india soil moisture values have been measured using standard gravimetric method imd 2009 hence validation of the estimated sm at deeper layers is done by comparing the observed in situ data and the model estimated sm data at the locations of imd monitoring stations however in this process two major concerns are 1 the locations of the stations of ground observation data do not coincide with the grid points where esa cci sm data are available 2 the depths where in situ sm data are measured 0 7 5 15 30 45 and 60 cm do not match the depths 5 10 20 51 and 102 cm for which the ssmp models provide the sm information thus validation with the observed data is restricted to the limited availability of observed soil moisture data at different depths over entire india mainland to cope with this the interpolation has been performed spatially and depth wise the spatial interpolation is inevitable in this case since the esa cci sm product is gridded data and is not available for point locations however the amount of error could be controlled during interpolation with the higher spatial resolution of gridded input data firstly to obtain the satellite based data at the imd stations where in situ sm data are measured the observed esa cci sm product at surface is bilinearly interpolated from surrounding four corner grid points of the target location subsequently the ssmp model is applied to the interpolated surface esa sm data at target imd station to estimate the soil moisture at 5 10 20 51 and 102 cm depths to obtain the vertical soil moisture profile since the depths of in situ soil moisture measurements at imd stations are different from the ssmp model estimated depths for validation along the depth the sm values at the observed imd depths i e at 7 5 15 30 45 and 60 cm are picked up from model estimated vertical soil moisture profile the model estimated sm data at 7 5 15 30 45 and 60 cm are obtained from the interpolation of modelled sm values from 5 and 10 cm 10 and 20 cm 20 and 51 cm 20 and 51 cm and 51 and 102 cm respectively the spatial interpolation by this bilinear method and the depth wise interpolation are schematically described in fig 5 the study of the validation was performed at 25 imd stations from the total of 48 stations all over india the selection of 25 stations among 48 stations for validation is based on the availability of esa cci sm product on the surrounding four corner grid points of the target stations on the dates of in situ measurements the distribution of selected 25 stations among different four hsgs are hsg a 4 stations hsg b 11 stations hsg c 4 stations and hsg d 6 as shown in fig 1 fig 6 shows the scatter plots of the observed and estimated sm at 7 5 15 30 45 and 60 cm depths of each hsg for each hsg the scatter plots are prepared between estimated and observed sm for all days available at each station for all four hsgs the comparison of scatter plots of all the depths of all hsgs shows that there is a positive linear association between the observed and estimated sm values however for hsg b c and d the ssmp models tend to over estimate the sm values for all depths yet considering the complexities involved in model validation as discussed above the model estimated sm values can be well accepted the model performances are shown for the two cases i e estimated sm values before dm correction and the final sm product i e estimated sm values after dm correction to show the role of dm correction in application of ssmp model fig 7 shows the model performances of all the depths of all hsgs in terms of correlation coefficient cc root mean square error rmse mean absolute error mae and bias the equations describing the computation of these performance metrics are provided in the appendix from the model performance it can be observed that the cc values across the four hsgs at their observed five depths are moderate to low i e in the range of 0 192 to 0 520 for dm corrected sm values it remains almost unaltered if the dm correction is not applied the model performance enhancement due to this dm correction is explicitly visible in the error metrics i e the rmse mae and bias the followings are the ranges of rmse mae and bias respectively across the hsgs and all depths without applying the dm correction 0 090 0 190 0 069 0 178 and 0 017 0 173 the same metrics improve after applying the dm correction such as rmse 0 095 to 0 159 mae 0 075 to 0 138 and bias 0 047 to 0 118 this comparison of model performances clearly shows the expected improvement of model performances with the dm correction the acceptable performance during validation was also ensured by pal and maity 2020 specifically for spatial validation the deviations from observed sm values were in the order of 0 04 0 12 rmse across the depths and hsgs this outcome strengthens the applicability of the ssmp model to new locations considering the uncertainties and complexities involved 5 overall utility of the developed dataset and a short illustration it is needless to mention the significant role played by the soil moisture in the land and atmosphere interaction by controlling the segregation between infiltration and runoff famiglietti et al 1998 pielke 2001 pal and maity 2020 this in turn underlines the usefulness of the developed database edvsmpd for different studies across a vast region like indian mainland mainly the edvsmpd will be directly useful to the hydrological agricultural and climatological studies in hydrological studies it will be useful for the studies related to the variability of evapotranspiration and runoff seneviratne et al 2010 flood or drought brocca et al 2012 and forecasting water supply in groundwater systems barnett et al 2005 in climatological studies the response of soil moisture to evapotranspiration is significant for temperature variability occurrence and persistence of heatwaves miralles et al 2014 and for generation and location of precipitation guillod et al 2015 moreover the mesoscale atmospheric circulation patterns can be induced by the regional gradients in soil moisture condition taylor et al 2012 in agricultural studies the long term trend of this edvsmpd would be useful for large scale analysis of agricultural drought cropping pattern agricultural yield and soil plant interaction rodriguez iturbe 2000 laio et al 2001 rodriguez iturbe et al 2001 as an illustrative example the potential use of the edvsmpd for the reconstruction of historical agricultural droughts for a rainfed drought prone river basin is presented in this section the wardha river basin upto upper wardha dam situated in the central belt of india wrb is selected as the study area as it is frequently hit by droughts due to vagaries in rainfall maity et al 2021 the wrb is a part of the godavari river basin with a hilly and forested catchment area of 4326 km2 variation of rainfall should be detectible on the long term soil moisture memory of the basin as the continued meteorological drought translates to agricultural drought the deficit in soil moisture content would trigger the agricultural droughts which can be assessed more accurately by drought indices based on soil moisture content hence in this section we explore the potential use of the edvsmpd for assessing the agricultural drought by computing the empirical standardized soil moisture essmi index carrão et al 2016 and relate its values to agricultural drought intensity for the study basin the essmi is based on the works developed previously by sheffield et al 2004 and dutra et al 2008 who fit beta and normal probability density function pdf to soil moisture values respectively however to develop the essmi an empirical pdf epdf is fit to the edvsmpd product with a non parametric kernel density estimator kde silverman 1986 the nonparametric estimator is selected 1 to avoid the assumption of the existence of representative parametric distributions farahmand and aghakouchak 2015 2 to shun the bias problems due to relatively small sample data sets sienz et al 2012 and 3 to allow for boundary bias correction of statistical data distributions supported on finite intervals bouezmarni et al 2011 the observed soil moisture at a location is standardized by essmi during a period of time e g monthly seasonally or half yearly with respect to the soil moisture climatology for the same period of time at that location the essmi results correspond to percentiles of the fitted probability distribution the negative values of the essmi indicate drier periods than normal and positive values correspond to wetter period than normal the categorical classification of droughts based on the different ranges of essmi values developed by mckee et al 1993 is as follows essmi 2 indicates extreme wet condition 1 5 essmi 2 indicates severe wet 1 essmi 1 5 indicates moderate wet 1 essmi 1 indicates near normal condition 1 5 essmi 1 indicates moderate dry 2 essmi 1 5 indicates severe dry conditions and essmi 2 indicates extreme dry condition finally drought conditions are checked for their correspondences with the historical vagaries of rainfall over the basin the rainfall anomaly data across the study basin is used for checking the correspondence with estimated essmi series initially the computations are carried out with the basin averaged essmi and rainfall anomaly series for comparison the basin averaged sm values help to avoid issues related to missing values comparatively easily with the help of values from adjoining grid cells considering the basin as a whole it may be noted that the presence of missing values is inevitable as a derivative of the source data i e esa cci sm product another major concern for considering the basin averaged value is the difference in spatial resolutions of rainfall data era 5 with 0 1 0 1 and essmi values esa cci sm product with 0 25 0 25 this analysis attempts to show the basin averaged temporal variation of rainfall anomaly and essmi values if they correspond to each other for different temporal scales considered however said above the necessity to showcase the utility of the high resolution data set is also realized hence one relatively dry year 1991 and one relatively wet year 1998 are considered for illustrating the grid wise variations of essmi and rainfall anomaly across the study basin at various temporal scales 5 1 data and method for reconstruction of agricultural drought series in this section detailed descriptions for computation of essmi series from edvsmpd rainfall anomaly along with their spatio temporal variations are presented 5 1 1 computation of essmi the sm values at the depths 5 10 20 51 and 102 cm are extracted from the complete database edvsmpd to compute the basin averaged sm series for the entire depth the basin averaged sm for wrb are obtained for the period of january 1988 to december 2014 since the edvsmp for wrb over the period of 1978 to 1987 consists of missing values consequently the essmi series is calculated using the values of basin averaged total soil moisture values for the time periods of 1 month monthly 3 months seasonal and 6 months half yearly over the considered period of 1988 to 2014 the step wise descriptions of calculating the essmi series are as follows a an empirical probability density function epdf is fitted to the long term record of total edvsmpd of the wrb i e xt1 xt2 xtn this is performed for an averaging timescale of t months where t is typically 1 3 6 or 12 months collected over n years the total edvsmpd estimates for wrb is computed for different timescales by averaging daily values over the corresponding t months the values of t are considered as 1 3 and 6 months over 27 years 1988 to 2014 b the non exceedance probability of the basin averaged total sm xt is computed related to the respective epdf that is by estimating the cumulative probability f xt of the averaged total sm estimate xt c the non exceedance probability is transformed to the standard normal variable z mean 0 and variance 1 and the essmi value is computed d each epdf for timescale and grid point is estimated by using a nonparametric kde silverman 1986 given independent and identically distributed observations x 1 x 2 x n having a common pdf f x the general kde is defined as 2 f h x 1 nh i 1 n k x x i h where k is kernel function window and h is the bandwidth smoothing parameter the density estimator f h x depends on the value of bandwidth h and mildly on k usually k is chosen to the gaussian function mean 0 and variance 1 as wilks 2005 3 k x 1 2 π e x 2 2 5 1 2 rainfall data for correspondence with drought series the grid wise rainfall data set is obtained from 5th generation of european centre for medium range weather forecasts ecmwf reanalysis product era5 url https www ecmwf int en forecasts datasets reanalysis datasets era5 for the required period of 1988 2014 the era5 provides high resolution estimates for a large number of atmospheric land and oceanic variables at various temporal scales i e sub daily to monthly subsequently the basin averaged monthly seasonal and half yearly rainfall values are computed as similar to the essmi time periods and compared to the essmi series to evaluate its ability to identify the agricultural droughts 5 2 reconstruction of the basin scale agricultural droughts and its correspondence with historical rainfall anomaly series to evaluate the spatio temporal consistency of the essmi for drought characterization we used the index to classify the edvsmpd values into dry and wet years in the period between 1988 and 2014 in wrb the epdf was fitted by using kde to the time series 27 year period between 1988 and 2014 of edvsmpd for wrb total sm for the time periods of 1 month monthly 3 months seasonal and 6 months half yearly the time series of monthly seasonal and half yearly basin averaged essmi values and corresponding rainfall anomaly are presented in fig 8 the half yearly essmi values appear to indicate a prolonged drought period between the years 1991 to 1997 when the basin experienced mostly moderate and severe drought intensities with a few aberrations of near normal conditions in the years of 1994 to 1996 these are more explicit in monthly and seasonal values of essmi where for few months and seasons during 1994 to 1996 the essmi values lie in the near normal range of 1 to 1 for the periods of 2002 to 2009 the essmi values remain to be 0 indicating a relatively dry condition although within the range of near normal state except for the severe drought in 2005 once our experiments are in line with the monthly seasonal and half yearly variations of the rainfall anomaly over the basin it is noticeably evident that for the identified dry periods i e 1991 to 1997 and 2002 to 2009 the rainfall was lesser than the long term mean rainfall indicated by the negative rainfall anomaly for most of the time period the variations show that only for the monsoon months the rainfall were slightly greater or almost equal to the long term monthly mean rainfall where the anomaly values were positive however the seasonal and half yearly variations clearly show the lesser amount of rainfall than the long term seasonal and half yearly mean for the rest of the time periods in fact the near normal conditions in the years of 1994 to 1996 can be attributed to the fact that the rainfall were higher than long term mean rainfall in the preceding years i e 1993 and 1995 respectively which are visible from fig 8 the negative rainfall anomaly values i e lesser rainfall than the long term mean for monthly seasonal and half yearly time periods can justify the next relatively dry spells seen during 2002 to 2009 in contrast the wet conditions due to more rainfall than the long term mean indicated by positive rainfall anomalies are also distinctly identified with higher essmi values in the time periods of 1998 to 2000 and 2010 to 2014 respectively thus it may be concluded that the basin averaged essmi index can explicitly indicate the dry wet conditions the above discussion represents the utility of edvsmpd considering the basin averaged essmi series due to the small size of the study basin and it helps to show how well the basin averaged temporal variations of rainfall and essmi values correspond to each other however to portray the better utility of the developed fine resolution database i e edvsmpd in grid wise spatial variation one of the dry and wet events as identified from the basin averaged comparison assessment are picked out the spatial variations of essmi and rainfall values for different time periods throughout the basin is presented in fig 9 it illustrates the spatial variations grid wise as available of monthly seasonally 3 months and half yearly 6 months essmi and rainfall anomaly values for a typical dry year 1991 on the left and a typical wet year 1998 on the right the dry wet conditions of the basin can be easily visualized by the colour tone of the figure where the blue and yellow sides represent the wet and dry conditions respectively in case of 1991 it is explicitly noted that the basin averaged essmi values for 1 month july 3 months july to september and 6 months july to december months are 1 29 1 90 and 1 62 respectively these values of essmi represent moderate and severe dry conditions throughout the basin according to the categorical classification of the essmi values for the same time periods the rainfall anomaly values are noted as 0 33 0 93 and 0 88 respectively showing less rainfall than the long term average rainfall throughout the basin on the other hand in case of 1998 the spatial variations of essmi and rainfall anomaly values for a month january season january to march and 6 months january to june indicate wetter situations the basin averaged essmi values for 1 3 and 6 months are 1 87 1 99 and 1 60 respectively such values indicate a severe wet condition throughout the basin for this case the higher rainfall anomaly values i e 1 59 1 50 and 0 36 for the three temporal scale respectively indicate above normal w r t long term average rainfall throughout the basin therefore the analyses portray an evident of association between the grid wise spatial variations of the essmi series and rainfall over the basin similar to the observation in case of basin averaged values however spatial variation of essmi is highly important and useful in many applications including agriculture moreover the above investigation shows that the essmi computed by sm data set for a small basin with lesser amount of missing values can identify the prolonged periods of drought events as well as the wet spells this ability to characterize the drought wet events with the developed high resolution database i e edvsmpd is extremely useful to many other hydrological and climate related studies and agricultural applications which may be considered as the future scope 6 conclusions the present study develops a vertical sm profile database esa cci driven vertical soil moisture profile root zone database edvsmpd for entire indian mainland by assimilating the remotely sensed surface data into a stochastic framework the study applies the hsg specific ssmp model to develop the vertical sm profile database using the surface sm data from climate change initiative cci program of european space agency esa esa cci sm product to obtain sm values at four depths i e 10 20 51 and 102 cm the edvsmpd product is available in the open repository of mendeley data pal and maity 2021 url https data mendeley com datasets 78c9yggmmg draft a 06084c38 4436 4b71 beb3 90944769751e the resulting edvsmpd is validated with the observed sm data at 25 monitoring stations maintained by imd the model performances during validation show the acceptable effectiveness of the combination of this satellite surface sm data product and the ssmp model the results also aid to infer that the ssmp models perform well for all four hsgs across the depths the study also demonstrated the historical reconstruction of agricultural drought for a rainfed basin namely wardha river basin wrb using the edvsmpd product the essmi which is a soil moisture based drought characterizing index is calculated using the edvsmpd for the wrb the computed essmi for three different time periods i e 1 3 and 6 months successfully identified the dry and wet periods over the basin for a period of 27 years between 1988 and 2014 the results also align with the rainfall variations for the same time period and obtained from era5 the deficit in rainfall lesser than the long term mean incurred a long dry period over the basin between the period of 1991 to 1997 which was distinctly identified by the corresponding essmi values it is further shown that the high spatial resolution of the developed database i e edvsmpd is very important and extremely useful in many applications including agriculture hydrological and climate studies thus the data product developed in this study over a large spatial extent of entire indian mainland will be immensely useful for many hydroclimatic studies it is true that the developed product consists of missing values which is descendent of esa cci sm product still the utility of the edvsmpd product cannot be denied and will be immensely beneficial in many fields of studies especially for basin scales where number of missing values could be less credit authorship contribution statement manali pal formal analysis methodology investigation writing original draft rajib maity conceptualization investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is partially supported by a research project sponsored by the space application centre sac indian space research organization isro govt of india ref no iit sric ce vir 2016 17 88 appendix computation of performance metrics the performances of the selected models during the training and testing periods are evaluated by different performance statistics namely correlation coefficient cc root mean square error rmse mean absolute error mae and the bias the cc is a measure of the linear correlation between the observed and modelled variables it varies between 1 to 1 it can be expressed by the following equation a1 cc i 1 n s m i obs s m obs s m i sim s m sim i 1 n s m i obs s m obs 2 s m i sim s m sim 2 where s m i obs and s m i sim are the observed and estimated values respectively the rmse is expressed in the same units of the input data as following a2 rmse 1 n i 1 n s m i sim s m i obs 2 1 2 the mean absolute error mae measures the average magnitude of the errors in a set of predictions without considering their direction and are less sensitive to outliers the mae is computed by the following equation a3 mae 1 n i 1 n s m i obs s m i sim the bias is computed as the difference between population mean of the estimated sm values and the mean of observed sm values 
4349,the climate change initiative cci program of the european space agency esa esa cci provides a global surface soil moisture sm product by merging the information from various active and passive sensors on board for the period of 1971 2014 this study aims to assimilate this surface sm product into a recently developed model namely statistical soil moisture profile ssmp model to investigate the efficacy of this combination in developing a vertical soil moisture profile database over a climatologically vast area such as indian mainland the ssmp model is a spatially varying statistical framework that couples the memory and forcing of sm from the overlying layers and utilizes the information of hydrologic soil groups hsgs that makes it spatially transferable the model estimates sm at four depths i e 10 20 51 and 102 cm using the surface sm information 0 5 cm the developed database is named as esa cci driven vertical soil moisture profile root zone database edvsmpd and the simulated values are validated with observed sm data at many monitoring stations across india maintained by india meteorological department imd as an exemplary demonstration of the utility of the data basin scale reconstruction of the historical agricultural droughts and its spatial distribution using the developed edvsmpd product is illustrated for a medium sized drought stricken river basin namely wardha in the central part of india the resulting sm product for a considerable length of period more than 30 years will be immensely useful for many hydro climatological studies keywords soil moisture remote sensing data assimilation statistical soil moisture profile ssmp model esa cci esa cci driven vertical soil moisture profile root zone database edvsmpd 1 introduction the soil moisture sm studies over the indian region emphasized on the feedback and coupling between sm and monsoon rainfall and their effects on seasonal and interannual variability using numerical simulations douville et al 2001 koster et al 2004 lodh et al 2013 the pre monsoon sm condition influences the monsoon onset and precipitation asharaf et al 2012 as well as persistence of sm anomalies influencing the atmospheric circulation shukla and mintz 1982 regional climate model simulations showed that sm memory lengths increase with soil depth and considerable geographical variability exist during monsoon asharaf and ahrens 2013 another study by singh et al 2019 showed the geographical variations during monsoon using indian remote sensing satellite data to study the spatial and temporal variations of monthly sm the soil moisture drought variability in a changing climate in india was investigated by mishra et al 2014 using vic model simulated soil moisture the reanalysis products from merra era interim and the ncep cfsr were assessed in the context of monsoon season droughts over the indian region by shah and mishra 2014 hence consistent multi layer sm variability information over the indian subcontinent is essential to better understanding of the surface atmosphere interaction in relation to the monsoon agricultural drought monitoring studies and different numerical modeling applications indian economy is primarily based on rainfed agriculture dependent on soil type and available soil moisture moreover 16 of india s geographic area mostly arid semiarid and subhumid is prone to drought which experiences it recurrently with different intensities among the different types of droughts agricultural drought has the more direct and immediate socio economic impact mishra and singh 2010 since it directly influences the crop yield and hence agricultural production panu and sharma 2002 this drought is mainly caused by soil moisture deficits and can be assessed more accurately by drought indices based on soil moisture information mukherjee et al 2018 however the scarcity in global consistent and long term time series of reliable soil moisture data required to derive the drought indices has prevented their operational use till date sheffield et al 2004 the availability of quality sm data at large scale and fine resolution is sparse over the indian region till date despite the access of several global sm data products based on satellite observations reanalysis land data assimilation etc at hand sathyanadh et al 2017 nayak et al 2018 created a high resolution 4 km and 3 hourly sm product for 2001 2014 during indian monsoon seasons using a land data assimilation system ldas the dataset was able to capture the inter annual intraseasonal and diurnal variations under different monsoon conditions and enhanced the simulations of heavy rain events over indian monsoon region when used to initialize the mesoscale model in another study singh et al 2019 investigated the spatio temporal variability of sm over a significantly large area 500 km2 in a tropical basin in india eighty three sm monitoring locations were selected having 56 days of observed records to identify the optimal sampling design for regional scale soil moisture assessment however the requirement of monitoring stations for continental scale assessment will be very high for the entire indian mainland most of the aforementioned studies deal with the surface sm only 0 10 cm however an assessment of soil moisture variation below the surface layer at least up to root zone depth is important in agricultural and irrigation management practices especially in semiarid and arid regions because of its impact on the production and health status of crops and salinization vereecken et al 2008 besides the sm profile information has many important applications in many fields of studies such as estimating evaporation and evapotranspiration wang et al 2013 brown et al 2014 flood forecasting nied et al 2014 salathé et al 2014 forecasting water supply in groundwater systems barnett et al 2005 estimation of denudation processes including landslides ekinci et al 2013 modeling ecosystem functions tague et al 2009 along with different climatological studies as discussed above the sm for the unsaturated zone can be obtained from national center for environmental prediction ncep climate forecast system reanalysis cfsr saha et al 2010 modern era retrospective analysis for research and applications merra european center for medium range weather forecasting ecmwf reanalysis interim era i saha et al 2010 dee et al 2011 and it is observed that all reanalysis data captured the seasonal cycle for each water content component shrivastava et al 2016 more recent studies investigated the effects of physical controls on the spatial variability of soil moisture and developed hydrological connectivity that is important for land surface model for better assessment of spatial variations of soil moisture kim and mohanty 2017 however these models and data products are highly dependent on their forcing parameters and the non linear model physics it is also observed that the comparison of different reanalysis datasets to evaluate their accuracies loew et al 2013 showed significant differences in the climatology over the indian region of evaporation and soil moisture field the association between sm values at different soil layers and the stochastic features of sm dynamics were also studied by cross correlation method and vector auto regression var method kim and kim 2007 kim 2009 kim et al 2011 mahmood et al 2012 later vertical sm profile information was obtained from the surface sm information through coupling its memory temporal persistence and forcing input from overlying layers by using the auto regressive model with exogenous arx input pal et al 2016 however the above mentioned studies did not investigate the spatial transferability of the proposed approaches another study by pal and maity 2020 developed a spatially varying statistical soil moisture profile ssmp model by coupling the memory and forcing based on the box jenkins approach as shown in pal et al 2016 to estimate the vertical sm profile from the surface sm information the study developed the spatially varying ssmp model for four hydrological soil groups hsgs to impart spatial transferability the hsg specific ssmp model explores the spatial transferability as it demonstrates the effects of the physical controls viz soil texture hydraulic conductivity runoff and infiltration however this ssmp model coupling the sm information at different layers requires the accurate large scale surface sm estimation to obtain a reliable estimation of vertical sm profile characterization of distribution and quantity of surface sm at a local and global scale by microwave active and passive remote sensing influenced by the dielectric properties of the soil is a potential alternative for expensive in situ monitoring networks to obtain the surface sm estimation recently the european space agency climate change initiative esa cci program developed a combined remotely sensed global data set of surface sm product retrieved from passive and active microwave sensors on board various satellites liu et al 2012 wagner et al 2012 http www esa soilmoisture cci org however the resulting combined sm product represents approximately the top few millimeters to centimeters of the soil depending on frequency used kuria et al 2007 hence the availability of this large scale satellite based surface sm product and spatially transferable stochastic model to couple the sm at different depths indicates a potential benefit of assimilating the microwave based surface sm information into the statistical framework of ssmp model to obtain large scale fine resolution spatially varying vertical sm profile database this is the overall objective of this study specifically the objective includes a thorough investigation of the efficiency of assimilating the esa cci surface sm product into the hsg specific ssmp model to prepare a spatially varying vertical sm profile database across the entire indian mainland the data product is named as esa cci driven vertical soil moisture profile root zone database which is abbreviated as edvsmpd the database is validated with respect to observed records of soil moisture at various stations across india maintained by india meteorological department imd finally the usefulness of the outcome of the study i e the vertical sm profile database edvsmpd for different hydrological agricultural and climatological studies is also outlined as an example an analysis pertaining to reconstruction of the historical agricultural droughts using the developed edvsmpd product is illustrated for a medium sized river basin namely wardha in the drought stricken central part of india 2 data used the esa released the first multi decadal satellite observed sm dataset as a part of its cci program in 2012 for global scale liu et al 2012 wagner et al 2012 http www esa soilmoisture cci org this product named esa cci sm combines the sm retrievals from four passive and two active coarse resolution microwave sensors into a global data set in a synergistic way the four passive sensors are namely nimbus 7 scanning multi channel microwave radiometer smmr special sensor microwave imagers ssm i of the defense meteorological satellite program dmsp tropical rainfall measuring mission trmm microwave imager tmi and advanced microwave scanning radiometer earth observing system amsr e and the two active sensors are european remote sensing satellites ers 1 and 2 active microwave instrument ami wind scatterometer and the advanced scatterometer ascat onboard the meteorological operational satellite a metop a the esa cci sm combines single sensor active and passive microwave sm products into three harmonized products which are a merged active a merged passive and a combined active passive microwave product the present study uses the sm data from esa cci sm product version 2 2 which covers a period of 1978 2014 as surface sm values in terms of volumetric water content dorigo et al 2015 active products are retrieved using the tu wien water retrieval package warp algorithm wagner et al 1999 it is a change detection approach that retrieves sm as degree of saturation by scaling radar backscatter measurements between the historically lowest completely dry and highest observed values saturated at each grid location the backscatter contribution of vegetation is corrected using the multi antenna multi incidence angle capability of the ers and ascat scatterometers vreugdenhil et al 2016 a threshold based decision tree algorithm is applied to incidence angle normalized backscatter measurements in frozen or freezing thawing conditions naeimi et al 2012 passive products are retrieved using the land parameter retrieval model lprm algorithm owe et al 2008 based on the radiative transfer model and applicable to a wide range of frequencies i e 1 20 ghz for c band and higher frequency sensors the data is filtered using ka band based temperature for frozen conditions holmes et al 2009 for smos l band retrievals the filtering is based on the radio frequency interference rfi the esa cci sm algorithms merge these pre processed l2 data that is gridded active or passive soil moisture products for the merging the products were rescaled against sm from a land surface modeling product gldas noah rodell et al 2004 using cumulative distribution function cdf matching since the units of the two data sets are different i e volumetric soil moisture m3 m3 and degree of saturation these data are resampled to a 0 25 regular grid using a hamming window approach and to daily time stamps 00 00 utc using a nearest neighbour search thus spatial resolution of the resulting merged product is 0 25 0 25 latitude longitude and represents approximately the top few millimeters to centimeters from surface kuria et al 2007 this resolution is purely guided by the data from the esa cci program though the recently available surface soil moisture data from soil moisture and ocean salinity smos 2010 soil moisture active passive smap 2015 or sentinel 2015 have much finer resolution but are only available for the recent years on the contrary the temporal coverage of esa cci sm product is from 1978 to 2014 which is sufficiently long that is essential for many hydroclimatic studies the grid wise hsg information is collected from central ground water board cgwb 2007 which classified the entire india into four major hsgs at 0 5 0 5 resolution spanning between 8 to 37 5 n and 68 to 97 5 e as shown in fig 1 it can be noticed that the hsg a is scattered to various parts across india whereas hsg b is mainly concentrated to northern india especially gangetic basin along with maximum parts of north east india and south india except the coastal regions the coastal regions and some of north western india arid region are mainly consisting of hsg c hsg d is completely concentrated in the middle and western region of india the weekly in situ sm data from 25 monitoring stations of india meteorological department imd across different hsgs in india fig 1 during 1991 2006 available are used for validation of the model estimated sm product the sm values are measured using standard gravimetric method at the depths of 0 7 5 15 30 45 and 60 cm imd 2009 the data is procured from national data centre ndc of imd pune india 3 methodology this paper attempts to assimilate the satellite based surface sm data into the hsg specific ssmp model to develop a three dimensional vertical sm profile map for india in brief the methodology of this study mainly follows three steps firstly the satellite based surface sm data is procured and pre processed from esa cci sm product for entire india and grid wise hsg information for entire india is collected from cgwb the second step is grid wise identification of hsg across the study area and accordingly the application of the ssmp model proposed by pal and maity 2020 finally the model performance is validated with the ground data obtained from imd the following sections provide a brief description of the pre processing of esa cci sm product and development of ssmp model 3 1 missing value treatment this section discusses about the missing values observed in the esa cci sm product which is used as surface sm values for the study area treating the missing value is essential in the present study for the application of the proposed approach since the number of missing values greater than the memory or forcing order present in the time series would hinder the model application the fraction of the missing values to the total length of record in each grid of the study area for the complete length of time series data is shown in fig 3 for each grid the fraction is computed as the ratio of the sum of number of missing values present in complete time series length to the length of sm time series data the range of the fraction is estimated to be 0 42 to 1 hence it can be said that missing values are almost for half of the days of total time series length which is a shortcoming of the input dataset the sm values at missing time steps are obtained by interpolation from sm values available at previous and succeeding days of those missing steps the piecewise cubic hermite interpolating polynomial pchip interpolation method is used to obtain the sm values fritsch and carlson 1980 kahaner et al 1989 however it is understood that the use of interpolation to sm values in daily scale will certainly lead to erroneous outcome hence while the interpolation is a requirement to use the esa cci surface sm data in the proposed ssmp model the study has ignored the missing values at time steps where the surface sm values are not available for previous 20 threshold selected in the present study days during the development of vertical sm profile map over entire india which is discussed in detail in the following sections the threshold length of days is selected such that the length is long enough to fill up maximum number of missing values and short enough to capture the soil moisture trend provided there is no rainfall within this period however the interpolated values at time steps where the esa cci sm product for surface are available for any steps within previous 20 days the interpolated values are considered in the study 3 2 ssmp model development the sm at deeper layers have been estimated from the surface sm information by coupling the memory and forcing shown in pal et al 2016 for a point location however the scope of spatial transferability of the proposed model based on box jenkins approach using an arx model was not investigated as the next step pal and maity 2020 developed a spatially varying ssmp model to estimate the vertical sm profile from surface sm information for four hsgs the development of the spatially varying ssmp model is based on the box jenkins approach shown in pal et al 2016 by coupling the memory and forcing components of sm the study used observed sm data from five depths i e 5 10 20 51 and 102 cm depths from three sm networks operated by international soil moisture network ismn for model development as well as for spatial transferability investigation the incorporation of hsg information into the proposed ssmp model helps to represent the effects of the physical controls viz soil texture hydraulic conductivity runoff and infiltration thus enabling the scope of spatial transferability the spatial transferability is investigated by applying the developed ssmp models to new locations it is important to mention that during the spatial validation deviation in mean dm for the surface layer has to be computed and the model estimated sm values are dm corrected to match the different sm regimes of the new locations and model developing stations the dm checks the bias of the model by trying to match the mean of the surface sm of the model developing stations and the new locations the dm is computed by estimating the mean of the surface sm of all the model developing stations of a specific hsg and then subtracting the mean sm of surface layer of the target station from it the unit of dm corrected soil moisture is same as the predicted soil moisture i e m3 m3 the model performances during the spatial validation encourage the developed ssmp models to be applied in different study area to obtain the vertical sm profile estimation the mathematical description of the spatially varying ssmp model is provided in pal and maity 2020 however a brief step wise description of the model development and spatial validation is presented as following the complete methodology is shown in fig 2 and hsg specific ssmp models are shown in table 1 table 2 model development step 1 the observed sm infromation from five depths i e 5 10 20 51 and 102 cm are obtained from soil climate analysis network scan u s climate reference network uscrn and snowpacktelemetry snotel networks from the international soil moisture network ismn dorigo et al 2011 covering a total of 171 stations for model development and spatial validation the available stations are categorized into four hsgs from the web soil survey wss https websoilsurvey sc egov usda gov app homepage htm step 2 the observed sm data is transformed to normal distribution through non parametric kernel density approach the data transformation is the requirement of ssmp model since it is based on the box jenkins approach which requires the data to follow normal distribution moreover to focus on the spatial transferability the data should be transformed to a common probability distribution form since the sm data at different locations mostly do not follow the same range and distribution the corresponding estimated sm values are obtained by back transformation step 3 the coupling approach is applied to the transformed data obtained from the observed data of each model development station of all four hsgs for four depth pairs the adjoining layers i e 5 10 cm 10 20 cm 20 51 cm and 51 102 cm the coupling approach at a location is represented by the following equation 1 s m k t i 1 p a i s m k t i j d q d 1 b j s m k 1 t j e t where s m k t is the transformed standard normal variate of sm at target depth k at time step t s m k t i are the transformed standard normal variates of sm at target depth at previous time steps where i 1 2 p s m k 1 t j are the transformed standard normal variates of sm of the overlying layer at previous time steps where j 0 1 q 1 the coefficients and orders of memory and forcing are represented as a i and b j and p and q respectively and e t represents the white noise the relative delay between the input sm time series and the output sm time series is represented as d which is considered to be zero at daily scale in the present study the complete mathematical description of the estimation of model parameters i e the model orders and model coefficients are shown in pal et al 2016 step 4 as discussed in the last step for each depth pair of each station of all four hsgs the model at a location is developed and the model orders are obtained the median value of the different model orders across the stations obtained in that process is assigned as the model order of that particular depth pair of that hsg the models with the assigned model orders are reapplied to all depth pairs of all the stations for a particular hsg finally the mean of the coefficients obtained corresponding to each depth pair across the stations of that particular hsg is allocated as the specific coefficient for that particular depth pair and hsg the stationarity is checked before finalizing the set of ssmp model as averaging the coefficients of different box jenkins models may lead to non stationarity spatial validation step 1 the hsgs are identified for the new stations and the observed surface sm values are transformed to standard normal variates using non parametric kernel density approach data transformation to apply ssmp models step 2 for each hsg a reference cdf plot applying the kernel distribution is prepared with the complete data from all model developing stations corresponding to that particular hsg for each deeper layers to use in the ungauged stations step 3 according to the hsg of the new station the ssmp model is applied and the estimated sm values are obtained by back transformation using the reference cdf for corresponding depth and hsg step 4 finally the back transformed values for the deeper layers of the target stations obtained after applying the ssmp models are dm corrected by adding the obtained dm whereas the detail of data collection is already provided discussion of model application and validation is presented along with results in the following section 4 results and discussions 4 1 3 dimensional vertical sm profile map for entire indian mainland the hsg specific ssmp models are developed for four depths considering adjoining depths as pairs 5 10 10 20 20 51 and 51 102 cm to apply the spatially varying model to the esa cci surface sm the first step is to identify the hsgs at the desired grid points where the esa cci sm product are available as mentioned before the hsg information of entire india is provided by cgwb at 0 5 0 5 resolution from 8 to 37 5 n and 68 to 97 5 e and the esa cci sm product is available at 0 25 0 25 for global scale hence for the present study the esa cci sm data is obtained for 8 125 to 37 875 n and 68 125 to 97 875 e since the hsg and the sm product grid points do not coincide hsg information at the target grid points where esa cci sm data is available is picked out from the hsg map the identification of the hsg information is followed by the application of ssmp models to each grid points over entire india according to the hsg of that point for all depths and all the days to obtain the sm vertical profile database finally the model application ends with the dm correction of estimated sm to obtain the final sm product for deeper layers as suggested by pal and maity 2020 at each grid point the dm is computed and estimated sm values for the deeper layers of the target stations are dm corrected by adding the obtained dm it is worthwhile to mention that these dm corrected sm values are the final product of the ssmp model the estimated sm represents this final dm corrected sm and the estimated sm values before dm correction is mentioned hereafter in the manuscript wherever necessary for discussion considering as a typical example fig 4 shows the estimated sm values at 5 10 20 51 and 102 cm for entire india on december 28 29 30 and 31 2014 the white patches in the sm map at 5 cm depths shows the missing values for that depth for that particular date however it can be noticed that for the same day the number of grid cells with missing values shown for deeper layers i e 10 20 51 and 102 cm are more than the surface layers as discussed before the replacement of the missing values with interpolated values in esa cci surface sm may introduce error in the data to be applied in the ssmp model and subsequently in the sm output at every layer hence the study uses a threshold for the number of days with continuous missing values it is fixed at 20 days in other words for a particular day and particular grid point if the observed satellite based surface sm values are entirely unavailable for previous 20 days the estimated sm at deeper layers for that particular day and grid point are discarded these are not included in the derived product and thus not shown in the map despite the shortcomings of having missing values as a descendant of esa cci sm product the advantages of the developed vertical soil moisture profile data product edvsmpd are multifold firstly the multi decadal length of the time series with high spatial and temporal resolutions is very useful for climate change studies however the studies on small basins may not even suffer from the missing values and long data set will be highly useful for climate related studies secondly the efficacy of the esa cci sm product is well established by several studies that have validated the esa cci sm product against in situ soil moisture observations by comparing it against ground based observations from various sites around the globe dorigo et al 2015 fang et al 2016 an et al 2016 shen et al 2016 mao et al 2017 dorigo et al 2017 moreover the widespread applications of the esa cci soil moisture product in different fields such as climate variability and change shrivastava et al 2017 unnikrishnan et al 2017 land atmosphere interactions li et al 2017 park et al 2017 global biogeochemical cycles and ecology he et al 2017 tang et al 2017 hydrological and land surface modelling asoka et al 2017 heimhuber et al 2017 drought applications cammalleri et al 2017 das and maity 2015 yan et al 2017 mcnally et al 2017 and hydrometeorological applications zhan et al 2017 to improve our earth system understanding are well recognized by the climate science community dorigo et al 2017 hence these advantages of having the long temporal global coverage and its well alignment with the ground observations make the use of esa cci sm product highly potential over different products available thus the quality and usefulness of the ssmp model estimated sm at 10 20 51 and 102 cm depths for entire indian mainland at 0 25 0 25 named as esa cci driven vertical soil moisture profile root zone database edvsmpd is equally beneficial for many studies this dataset is made available in the open repository of mendeley data pal and maity 2021 url https data mendeley com datasets 78c9yggmmg draft a 06084c38 4436 4b71 beb3 90944769751e 4 2 validation of vertical sm profile database the validation of the obtained product i e the three dimensional sm database for entire india mainland is carried out with the observed sm values provided by the india meteorological department imd the imd has provided the in situ sm information at surface 0 7 5 cm and deeper layers 15 30 45 and 60 cm depths for bare land and crop land areas at 48 stations across india at an interval of 7 days all these data sets are procured from national data centre ndc of imd pune india soil moisture values have been measured using standard gravimetric method imd 2009 hence validation of the estimated sm at deeper layers is done by comparing the observed in situ data and the model estimated sm data at the locations of imd monitoring stations however in this process two major concerns are 1 the locations of the stations of ground observation data do not coincide with the grid points where esa cci sm data are available 2 the depths where in situ sm data are measured 0 7 5 15 30 45 and 60 cm do not match the depths 5 10 20 51 and 102 cm for which the ssmp models provide the sm information thus validation with the observed data is restricted to the limited availability of observed soil moisture data at different depths over entire india mainland to cope with this the interpolation has been performed spatially and depth wise the spatial interpolation is inevitable in this case since the esa cci sm product is gridded data and is not available for point locations however the amount of error could be controlled during interpolation with the higher spatial resolution of gridded input data firstly to obtain the satellite based data at the imd stations where in situ sm data are measured the observed esa cci sm product at surface is bilinearly interpolated from surrounding four corner grid points of the target location subsequently the ssmp model is applied to the interpolated surface esa sm data at target imd station to estimate the soil moisture at 5 10 20 51 and 102 cm depths to obtain the vertical soil moisture profile since the depths of in situ soil moisture measurements at imd stations are different from the ssmp model estimated depths for validation along the depth the sm values at the observed imd depths i e at 7 5 15 30 45 and 60 cm are picked up from model estimated vertical soil moisture profile the model estimated sm data at 7 5 15 30 45 and 60 cm are obtained from the interpolation of modelled sm values from 5 and 10 cm 10 and 20 cm 20 and 51 cm 20 and 51 cm and 51 and 102 cm respectively the spatial interpolation by this bilinear method and the depth wise interpolation are schematically described in fig 5 the study of the validation was performed at 25 imd stations from the total of 48 stations all over india the selection of 25 stations among 48 stations for validation is based on the availability of esa cci sm product on the surrounding four corner grid points of the target stations on the dates of in situ measurements the distribution of selected 25 stations among different four hsgs are hsg a 4 stations hsg b 11 stations hsg c 4 stations and hsg d 6 as shown in fig 1 fig 6 shows the scatter plots of the observed and estimated sm at 7 5 15 30 45 and 60 cm depths of each hsg for each hsg the scatter plots are prepared between estimated and observed sm for all days available at each station for all four hsgs the comparison of scatter plots of all the depths of all hsgs shows that there is a positive linear association between the observed and estimated sm values however for hsg b c and d the ssmp models tend to over estimate the sm values for all depths yet considering the complexities involved in model validation as discussed above the model estimated sm values can be well accepted the model performances are shown for the two cases i e estimated sm values before dm correction and the final sm product i e estimated sm values after dm correction to show the role of dm correction in application of ssmp model fig 7 shows the model performances of all the depths of all hsgs in terms of correlation coefficient cc root mean square error rmse mean absolute error mae and bias the equations describing the computation of these performance metrics are provided in the appendix from the model performance it can be observed that the cc values across the four hsgs at their observed five depths are moderate to low i e in the range of 0 192 to 0 520 for dm corrected sm values it remains almost unaltered if the dm correction is not applied the model performance enhancement due to this dm correction is explicitly visible in the error metrics i e the rmse mae and bias the followings are the ranges of rmse mae and bias respectively across the hsgs and all depths without applying the dm correction 0 090 0 190 0 069 0 178 and 0 017 0 173 the same metrics improve after applying the dm correction such as rmse 0 095 to 0 159 mae 0 075 to 0 138 and bias 0 047 to 0 118 this comparison of model performances clearly shows the expected improvement of model performances with the dm correction the acceptable performance during validation was also ensured by pal and maity 2020 specifically for spatial validation the deviations from observed sm values were in the order of 0 04 0 12 rmse across the depths and hsgs this outcome strengthens the applicability of the ssmp model to new locations considering the uncertainties and complexities involved 5 overall utility of the developed dataset and a short illustration it is needless to mention the significant role played by the soil moisture in the land and atmosphere interaction by controlling the segregation between infiltration and runoff famiglietti et al 1998 pielke 2001 pal and maity 2020 this in turn underlines the usefulness of the developed database edvsmpd for different studies across a vast region like indian mainland mainly the edvsmpd will be directly useful to the hydrological agricultural and climatological studies in hydrological studies it will be useful for the studies related to the variability of evapotranspiration and runoff seneviratne et al 2010 flood or drought brocca et al 2012 and forecasting water supply in groundwater systems barnett et al 2005 in climatological studies the response of soil moisture to evapotranspiration is significant for temperature variability occurrence and persistence of heatwaves miralles et al 2014 and for generation and location of precipitation guillod et al 2015 moreover the mesoscale atmospheric circulation patterns can be induced by the regional gradients in soil moisture condition taylor et al 2012 in agricultural studies the long term trend of this edvsmpd would be useful for large scale analysis of agricultural drought cropping pattern agricultural yield and soil plant interaction rodriguez iturbe 2000 laio et al 2001 rodriguez iturbe et al 2001 as an illustrative example the potential use of the edvsmpd for the reconstruction of historical agricultural droughts for a rainfed drought prone river basin is presented in this section the wardha river basin upto upper wardha dam situated in the central belt of india wrb is selected as the study area as it is frequently hit by droughts due to vagaries in rainfall maity et al 2021 the wrb is a part of the godavari river basin with a hilly and forested catchment area of 4326 km2 variation of rainfall should be detectible on the long term soil moisture memory of the basin as the continued meteorological drought translates to agricultural drought the deficit in soil moisture content would trigger the agricultural droughts which can be assessed more accurately by drought indices based on soil moisture content hence in this section we explore the potential use of the edvsmpd for assessing the agricultural drought by computing the empirical standardized soil moisture essmi index carrão et al 2016 and relate its values to agricultural drought intensity for the study basin the essmi is based on the works developed previously by sheffield et al 2004 and dutra et al 2008 who fit beta and normal probability density function pdf to soil moisture values respectively however to develop the essmi an empirical pdf epdf is fit to the edvsmpd product with a non parametric kernel density estimator kde silverman 1986 the nonparametric estimator is selected 1 to avoid the assumption of the existence of representative parametric distributions farahmand and aghakouchak 2015 2 to shun the bias problems due to relatively small sample data sets sienz et al 2012 and 3 to allow for boundary bias correction of statistical data distributions supported on finite intervals bouezmarni et al 2011 the observed soil moisture at a location is standardized by essmi during a period of time e g monthly seasonally or half yearly with respect to the soil moisture climatology for the same period of time at that location the essmi results correspond to percentiles of the fitted probability distribution the negative values of the essmi indicate drier periods than normal and positive values correspond to wetter period than normal the categorical classification of droughts based on the different ranges of essmi values developed by mckee et al 1993 is as follows essmi 2 indicates extreme wet condition 1 5 essmi 2 indicates severe wet 1 essmi 1 5 indicates moderate wet 1 essmi 1 indicates near normal condition 1 5 essmi 1 indicates moderate dry 2 essmi 1 5 indicates severe dry conditions and essmi 2 indicates extreme dry condition finally drought conditions are checked for their correspondences with the historical vagaries of rainfall over the basin the rainfall anomaly data across the study basin is used for checking the correspondence with estimated essmi series initially the computations are carried out with the basin averaged essmi and rainfall anomaly series for comparison the basin averaged sm values help to avoid issues related to missing values comparatively easily with the help of values from adjoining grid cells considering the basin as a whole it may be noted that the presence of missing values is inevitable as a derivative of the source data i e esa cci sm product another major concern for considering the basin averaged value is the difference in spatial resolutions of rainfall data era 5 with 0 1 0 1 and essmi values esa cci sm product with 0 25 0 25 this analysis attempts to show the basin averaged temporal variation of rainfall anomaly and essmi values if they correspond to each other for different temporal scales considered however said above the necessity to showcase the utility of the high resolution data set is also realized hence one relatively dry year 1991 and one relatively wet year 1998 are considered for illustrating the grid wise variations of essmi and rainfall anomaly across the study basin at various temporal scales 5 1 data and method for reconstruction of agricultural drought series in this section detailed descriptions for computation of essmi series from edvsmpd rainfall anomaly along with their spatio temporal variations are presented 5 1 1 computation of essmi the sm values at the depths 5 10 20 51 and 102 cm are extracted from the complete database edvsmpd to compute the basin averaged sm series for the entire depth the basin averaged sm for wrb are obtained for the period of january 1988 to december 2014 since the edvsmp for wrb over the period of 1978 to 1987 consists of missing values consequently the essmi series is calculated using the values of basin averaged total soil moisture values for the time periods of 1 month monthly 3 months seasonal and 6 months half yearly over the considered period of 1988 to 2014 the step wise descriptions of calculating the essmi series are as follows a an empirical probability density function epdf is fitted to the long term record of total edvsmpd of the wrb i e xt1 xt2 xtn this is performed for an averaging timescale of t months where t is typically 1 3 6 or 12 months collected over n years the total edvsmpd estimates for wrb is computed for different timescales by averaging daily values over the corresponding t months the values of t are considered as 1 3 and 6 months over 27 years 1988 to 2014 b the non exceedance probability of the basin averaged total sm xt is computed related to the respective epdf that is by estimating the cumulative probability f xt of the averaged total sm estimate xt c the non exceedance probability is transformed to the standard normal variable z mean 0 and variance 1 and the essmi value is computed d each epdf for timescale and grid point is estimated by using a nonparametric kde silverman 1986 given independent and identically distributed observations x 1 x 2 x n having a common pdf f x the general kde is defined as 2 f h x 1 nh i 1 n k x x i h where k is kernel function window and h is the bandwidth smoothing parameter the density estimator f h x depends on the value of bandwidth h and mildly on k usually k is chosen to the gaussian function mean 0 and variance 1 as wilks 2005 3 k x 1 2 π e x 2 2 5 1 2 rainfall data for correspondence with drought series the grid wise rainfall data set is obtained from 5th generation of european centre for medium range weather forecasts ecmwf reanalysis product era5 url https www ecmwf int en forecasts datasets reanalysis datasets era5 for the required period of 1988 2014 the era5 provides high resolution estimates for a large number of atmospheric land and oceanic variables at various temporal scales i e sub daily to monthly subsequently the basin averaged monthly seasonal and half yearly rainfall values are computed as similar to the essmi time periods and compared to the essmi series to evaluate its ability to identify the agricultural droughts 5 2 reconstruction of the basin scale agricultural droughts and its correspondence with historical rainfall anomaly series to evaluate the spatio temporal consistency of the essmi for drought characterization we used the index to classify the edvsmpd values into dry and wet years in the period between 1988 and 2014 in wrb the epdf was fitted by using kde to the time series 27 year period between 1988 and 2014 of edvsmpd for wrb total sm for the time periods of 1 month monthly 3 months seasonal and 6 months half yearly the time series of monthly seasonal and half yearly basin averaged essmi values and corresponding rainfall anomaly are presented in fig 8 the half yearly essmi values appear to indicate a prolonged drought period between the years 1991 to 1997 when the basin experienced mostly moderate and severe drought intensities with a few aberrations of near normal conditions in the years of 1994 to 1996 these are more explicit in monthly and seasonal values of essmi where for few months and seasons during 1994 to 1996 the essmi values lie in the near normal range of 1 to 1 for the periods of 2002 to 2009 the essmi values remain to be 0 indicating a relatively dry condition although within the range of near normal state except for the severe drought in 2005 once our experiments are in line with the monthly seasonal and half yearly variations of the rainfall anomaly over the basin it is noticeably evident that for the identified dry periods i e 1991 to 1997 and 2002 to 2009 the rainfall was lesser than the long term mean rainfall indicated by the negative rainfall anomaly for most of the time period the variations show that only for the monsoon months the rainfall were slightly greater or almost equal to the long term monthly mean rainfall where the anomaly values were positive however the seasonal and half yearly variations clearly show the lesser amount of rainfall than the long term seasonal and half yearly mean for the rest of the time periods in fact the near normal conditions in the years of 1994 to 1996 can be attributed to the fact that the rainfall were higher than long term mean rainfall in the preceding years i e 1993 and 1995 respectively which are visible from fig 8 the negative rainfall anomaly values i e lesser rainfall than the long term mean for monthly seasonal and half yearly time periods can justify the next relatively dry spells seen during 2002 to 2009 in contrast the wet conditions due to more rainfall than the long term mean indicated by positive rainfall anomalies are also distinctly identified with higher essmi values in the time periods of 1998 to 2000 and 2010 to 2014 respectively thus it may be concluded that the basin averaged essmi index can explicitly indicate the dry wet conditions the above discussion represents the utility of edvsmpd considering the basin averaged essmi series due to the small size of the study basin and it helps to show how well the basin averaged temporal variations of rainfall and essmi values correspond to each other however to portray the better utility of the developed fine resolution database i e edvsmpd in grid wise spatial variation one of the dry and wet events as identified from the basin averaged comparison assessment are picked out the spatial variations of essmi and rainfall values for different time periods throughout the basin is presented in fig 9 it illustrates the spatial variations grid wise as available of monthly seasonally 3 months and half yearly 6 months essmi and rainfall anomaly values for a typical dry year 1991 on the left and a typical wet year 1998 on the right the dry wet conditions of the basin can be easily visualized by the colour tone of the figure where the blue and yellow sides represent the wet and dry conditions respectively in case of 1991 it is explicitly noted that the basin averaged essmi values for 1 month july 3 months july to september and 6 months july to december months are 1 29 1 90 and 1 62 respectively these values of essmi represent moderate and severe dry conditions throughout the basin according to the categorical classification of the essmi values for the same time periods the rainfall anomaly values are noted as 0 33 0 93 and 0 88 respectively showing less rainfall than the long term average rainfall throughout the basin on the other hand in case of 1998 the spatial variations of essmi and rainfall anomaly values for a month january season january to march and 6 months january to june indicate wetter situations the basin averaged essmi values for 1 3 and 6 months are 1 87 1 99 and 1 60 respectively such values indicate a severe wet condition throughout the basin for this case the higher rainfall anomaly values i e 1 59 1 50 and 0 36 for the three temporal scale respectively indicate above normal w r t long term average rainfall throughout the basin therefore the analyses portray an evident of association between the grid wise spatial variations of the essmi series and rainfall over the basin similar to the observation in case of basin averaged values however spatial variation of essmi is highly important and useful in many applications including agriculture moreover the above investigation shows that the essmi computed by sm data set for a small basin with lesser amount of missing values can identify the prolonged periods of drought events as well as the wet spells this ability to characterize the drought wet events with the developed high resolution database i e edvsmpd is extremely useful to many other hydrological and climate related studies and agricultural applications which may be considered as the future scope 6 conclusions the present study develops a vertical sm profile database esa cci driven vertical soil moisture profile root zone database edvsmpd for entire indian mainland by assimilating the remotely sensed surface data into a stochastic framework the study applies the hsg specific ssmp model to develop the vertical sm profile database using the surface sm data from climate change initiative cci program of european space agency esa esa cci sm product to obtain sm values at four depths i e 10 20 51 and 102 cm the edvsmpd product is available in the open repository of mendeley data pal and maity 2021 url https data mendeley com datasets 78c9yggmmg draft a 06084c38 4436 4b71 beb3 90944769751e the resulting edvsmpd is validated with the observed sm data at 25 monitoring stations maintained by imd the model performances during validation show the acceptable effectiveness of the combination of this satellite surface sm data product and the ssmp model the results also aid to infer that the ssmp models perform well for all four hsgs across the depths the study also demonstrated the historical reconstruction of agricultural drought for a rainfed basin namely wardha river basin wrb using the edvsmpd product the essmi which is a soil moisture based drought characterizing index is calculated using the edvsmpd for the wrb the computed essmi for three different time periods i e 1 3 and 6 months successfully identified the dry and wet periods over the basin for a period of 27 years between 1988 and 2014 the results also align with the rainfall variations for the same time period and obtained from era5 the deficit in rainfall lesser than the long term mean incurred a long dry period over the basin between the period of 1991 to 1997 which was distinctly identified by the corresponding essmi values it is further shown that the high spatial resolution of the developed database i e edvsmpd is very important and extremely useful in many applications including agriculture hydrological and climate studies thus the data product developed in this study over a large spatial extent of entire indian mainland will be immensely useful for many hydroclimatic studies it is true that the developed product consists of missing values which is descendent of esa cci sm product still the utility of the edvsmpd product cannot be denied and will be immensely beneficial in many fields of studies especially for basin scales where number of missing values could be less credit authorship contribution statement manali pal formal analysis methodology investigation writing original draft rajib maity conceptualization investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is partially supported by a research project sponsored by the space application centre sac indian space research organization isro govt of india ref no iit sric ce vir 2016 17 88 appendix computation of performance metrics the performances of the selected models during the training and testing periods are evaluated by different performance statistics namely correlation coefficient cc root mean square error rmse mean absolute error mae and the bias the cc is a measure of the linear correlation between the observed and modelled variables it varies between 1 to 1 it can be expressed by the following equation a1 cc i 1 n s m i obs s m obs s m i sim s m sim i 1 n s m i obs s m obs 2 s m i sim s m sim 2 where s m i obs and s m i sim are the observed and estimated values respectively the rmse is expressed in the same units of the input data as following a2 rmse 1 n i 1 n s m i sim s m i obs 2 1 2 the mean absolute error mae measures the average magnitude of the errors in a set of predictions without considering their direction and are less sensitive to outliers the mae is computed by the following equation a3 mae 1 n i 1 n s m i obs s m i sim the bias is computed as the difference between population mean of the estimated sm values and the mean of observed sm values 
