index,text
6825,as one of the largest contiguous karst regions in the world southwest china is vulnerable to soil erosion because of its unique geology and inappropriate land use understanding the linkages between geological conditions land cover patterns and sediment yield is thus of paramount importance to effectively control sediment delivery in heterogeneous karst watersheds the objective of this study was to examine how the specific sediment yield was related to lithology and landscape variables for 40 karst watersheds in southwest china due to these watershed variables were highly codependent partial least squares regression plsr was applied to elucidate the relationship between the sediment yield and 30 lithology and landscape variables the first order controls were determined by calculating the variable importance for the projection vip predictors with vip scores larger than 1 were considered to be the most influential predictors of the plsr model results indicated that the lithology and landscape indeed exerted substantial influence on sediment yield explained variance 66 8 for the investigated 40 watersheds specifically the first dominant factor for sediment yield was karst coverage vip 2 19 followed by dolomite coverage vip 1 42 landscape shape index vip 1 33 patch richness vip 1 23 relative patch richness vip 1 23 number of patches vip 1 22 and simpson s diversity index vip 1 03 the plsr technique enabled the elimination of codependency among the variables and facilitated a more unbiased view of the control factors for sediment yield therefore this approach is recommended as a useful tool for identifying the dominant factors controlling sediment yield in heterogeneous karst watersheds keywords soil erosion earth critical zone partial least squares regression landscape ecology ecohydrology 1 introduction soil erosion by water resulted in the removal of soil material by the processes of detachment and transportation causing on site land degradation while deposition of the eroded sediment can cause negative downstream off site impacts syvitski et al 2005 zhang et al 2009 duan et al 2016 borrelli et al 2017 soil erosion and associated sediment transport has become a serious social and environmental concern throughout the world especially in karst regions of southwest china which is a typically ecologically fragile zone experiencing severe soil erosion jiang et al 2014 wang et al 2015 li et al 2016 karst regions approximately comprises between 7 and 12 of the earth s continental surface and the southwest china represents one of the largest contiguous karst areas in the world hartmann et al 2015 li et al 2017a the special geological conditions and the unsustainable intensive land use on a fragile karst geo ecological environment were two important factors affecting the occurrence and intensity of the soil erosion peng and wang 2012 dai et al 2017 thus knowledge of the relationship between sediment yield and its controlling factors is crucial to developing a variety of watershed management practices such as soil and water conservation land use planning and river restoration the special geological conditions can greatly affect the hydrological characteristic of a karst system and thus may influence sediment yield jukić and denić jukić 2015 li et al 2017b southwest china is featured by thin soils overlying highly irregular epikarst surface with high infiltration capacity which play an important role in the generation of overland flow and underground lateral flow peng and wang 2012 hartmann et al 2015 a part of the precipitation is rapidly transferred through the epikarst zone via the network of conduits but the rest of it remains in the epikarst zone and subsequently slowly percolates or evaporates perrin et al 2003 aquilina et al 2006 on the one hand the epikarst zone is characterized by a substantial storage capacity and hence can reduce runoff and enhance evaporation jukić and denićjukić 2009 on the other hand the eroded sediment generally blocked the karst conduits or the sinkholes in the bottom of the karst depression resulting in large amounts of sediment deposited in the karst watersheds jiang et al 2014 li et al 2017b under this special geological condition the very low soil formation rate created a fragile and vulnerable environment that was susceptible to deforestation and soil erosion feng et al 2014 jiang et al 2014 generally the carbonate rocks are highly soluble and very difficult to generate much soil dai et al 2017 li et al 2017b the low soil formation rate in this region was mainly caused by the low content of silicate mineral in carbonate rock jiang et al 2014 the spatial distribution pattern of carbonate rocks had a significant effect on rocky desertification which is a process of land degradation involving serious soil erosion wang et al 2004b the severe rocky desertification generally occurred in the carbonate rocks continuously distributed area while the scattered or interspersed carbonate rocks area had a slight rocky desertification wang et al 2004a the annual soil loss can reach the amount of soil formed in 60 years implying a significant imbalance between soil loss and soil formation rate peng and wang 2012 feng et al 2014 in some severe rocky desertification areas almost all of the surface soil was lost and only little soil was available to be eroded jiang et al 2014 therefore soil erosion may be highly linked to the geologic conditions of fragile karst systems landscape heterogeneity generally led to variations in ecological and hydrological conditions thereby altering sediment production transport and delivery to rivers bakker et al 2008 yang et al 2012 ai et al 2015 in karst regions of southwest china landscapes including discontinuously distributed soil and fragmented ecological spaces suitable for plants were highly heterogeneous yue et al 2013 furthermore the landscape structures were closely related to the distribution of rocky desertification which was the ultimate result of deforestation and soil loss in the carbonate rock areas jiang et al 2014 the fractional cover of exposed carbonate rocks and vegetation could represent the land surface symptoms of rocky desertification wang et al 2004a yue et al 2013 consequently in karst regions this highly heterogeneous landscape affected the connectivity between sediment source and sink and sediment transport capacity was different for different land cover types lithological factors and landscape metrics were generally used to depict the geological conditions and landscape characteristics respectively many studies have quantified the relationship between lithology landscape and sediment yield or stream water contaminants in non karst areas haregeweyn et al 2005 de vente and poesen 2005 bakker et al 2008 lee et al 2009 ouyang et al 2010 onderka et al 2012 huang et al 2013 shi et al 2013 shi et al 2014 ai et al 2015 due to the special geological conditions coupled with highly heterogeneous landscapes the dominant erosion controls in karst areas and non karst areas were probably different however the effects of lithology and landscape variables on sediment yield is not yet fully quantified in karst regions furthermore the lithology and landscape variables are highly co linear or co dependent which can result in redundancy onderka et al 2012 shi et al 2013 zhou et al 2017 therefore a partial least squares regression plsr model which can handle highly correlated noise corrupted datasets by explicitly assuming the dependency among independent variable abdi 2010 carrascal et al 2010 is introduced in this study to evaluate the influence of lithology and landscape variables on sediment yield in karst watersheds the objectives of this study were to determine how the specific sediment yield was related to lithology and landscape variables and then to detect the dominant controls of sediment yield using plsr technique for 40 heterogeneous karst watersheds in southwest china 2 materials and methods 2 1 study area the study area is located in the wujiang and xijiang watershed where the typical karst landscape is widespread the wujiang river is the largest tributary on the southern bank of the upper reaches of the yangtze river fig 1 wujiang river originates from wumeng ranges on the yunnan guizhou plateau and flows through yunnan guizhou chongqing and hubei provinces with a total length of 1037 km this watershed has an elevation between 113 m and 2888 m and drains an area of 8 79 104 km2 26 09 13 30 12 1 n 104 15 35 109 20 6 e with a mean annual water and sediment discharge of 48 5 km3 and 2 4 107 t 1955 2011 respectively this region is characterized by the subtropical monsoon humid climate with annual precipitation ranges from 1100 to 1300 mm 75 of which occurs in the wet season from may to october the mean annual temperature is 12 3 c with hot summer and cold winter the xijiang river is the major tributary of the pearl river that is the second largest chinese river after the yangtze river in terms of water discharge and is the largest contributor of sediment to south china sea this river originates from yunnan province flows through guizhou guangxi and guangdong province finally entering into the south china sea fig 1 the main stream of the river is 2214 km long and has a watershed area of 35 3 104 km2 21 36 17 27 00 21 n 102 16 52 113 23 51 e the xijiang river watershed experiences a subtropical and tropical monsoon climate straddling the tropic of cancer with the mean annual temperature and precipitation of 18 c and 1470 mm respectively precipitation distribution during a year is uneven and more than 80 of which occurs during the wet season from april to october this region is mainly underlain by carbonate rocks representing approximately 43 5 of the total watershed area fig 2 a altogether 11 and 29 sub watersheds were selected in wujiang river and xijiang river watershed respectively these watersheds are corresponding to 40 hydrological stations fig 1 table 1 2 2 data the sediment yield data 2009 2012 for 40 hydrological stations were obtained from hydrological yearbooks of the people s republic of china the annual sediment yield data was extracted from the higher resolution daily average sediment yield data the reliability and homogeneity of the data have been checked and firmly controlled before its release the digital elevation model dem with a resolution of 30 m was acquired from the geospatial data cloud according to information of the 40 hydrological stations the corresponding 40 watersheds boundary was extracted from the dem by hydrologic modeling using arcgis fig 1 the geological map was provided by the institute of geochemistry chinese academy of sciences fig 2a the 1 100 000 scale land use database of the 2009 was obtained from the resource and environmental science data center chinese academy of sciences http www resdc cn fig 2b 2 3 potential influencing factors data regarding the potential influencing factors were extracted from each watershed to describe lithology and landscape variables altogether 30 variables were regarded as potential factors influencing the sediment yield the descriptions and abbreviations of the 30 variables were presented in table 2 these selected variables have been widely used in previous studies de vente and poesen 2005 ouyang et al 2010 de vente et al 2011 yang et al 2012 shi et al 2013 uuemaa et al 2013 shi et al 2014 the lithology variables including the percentage of carbonate rock karst dolomite and limestone table 2 the carbonate rock included the pure dolomite pure limestone and the mixture of the dolomite and limestone the selected 27 landscape variables were divided into five classes area index shape index diversity index spatial configuration index and fragmentation index ouyang et al 2010 mcgarigal et al 2012 several variables were calculated within each class table 2 all the landscape variables were obtained from the land use map using the fragstats 4 2 which is widely accepted for landscape metrics quantification mcgarigal et al 2012 shi et al 2013 prior to the plsr a preliminary analysis bivariate scatterplots in fig 3 showed that many of the variable are collinear thus the variables that potentially controlling sediment yield may be not truly independent variables 2 4 plsr plsr is a robust multivariate regression method that is particularly appropriate for analyzing data with correlated noisy and many independent variables shi et al 2014 ma et al 2015 to accommodate the highly correlated variables we constructed a plsr model to determine the relationship between a set of predictor data independent xn m which includes n observations rows and m variables columns and a response vector dependent yn 1 in this plsr model the independent variables were the selected lithology and landscape variables and the dependent variable was the mean annual sediment yield during 2009 2012 to avoid over fitting and achieve an optimal balance between the explained variation in the response r 2 and the predictive ability of the model q 2 cross validation was introduced to determine the appropriate number of components in the plsr model carrascal et al 2010 plsr model is considered to provide good predictions when r 2 is greater than 0 5 trap et al 2013 unlike r 2 q 2 will decline as model become increasingly over fitted q 2 cum is defined as the cumulative q 2 over all the selected plsr components the root mean square error of cross validation rmsecv is also determined to provide useful information for calibrating and developing the regression model the optimal plsr model generally had the maximum q 2 cum and the minimal rmsecv which were computed using the following equations 1 q 2 1 0 p r e s s s s 2 press i 1 n p i o i 2 3 ss i 1 n p i o i 2 4 q 2 c u m 1 0 p r e s s s s k k 1 2 m 5 rmsecv press n where press indicates the prediction error sum of squares ss indicates the residual sum of squares p i is the predicted sediment yield for the leave one out sample pi and oi are the predicted and observed sediment yield m is the number of plsr components and n is the number of samples n 40 the variable importance of projection vip and regression coefficients rcs are the two important parameters to reflect the importance of a predictor for both the independent and the dependent variables shi et al 2013 fang et al 2015 terms with large vip values are the most significant and relevant in explaining the dependent variable generally predictor with vip value greater than 1 is considered as the most influential predictors of the model onderka et al 2012 rcs indicate the direction and strength of the impact of each independent variable in the plsr model the detailed information of the plsr technique can be found in the previous studies abdi 2010 li et al 2017c plsr was performed with simca p 13 0 software umetrics ab sweden 3 results 3 1 characteristics of sediment yield table 1 shows that the mean annual sediment yield of the 40 watersheds varied substantially from 2 0 t km 2 y 1 to 245 5 t km 2 y 1 for the period from 2009 to 2012 interestingly the sediment yield decreased with the watershed area for example a low annual sediment yield 2 0 t km 2 y 1 was found in no 20 watershed 104772 km2 while a high annual sediment yield 211 7 t km 2 y 1 was observed in no 37 watershed 2744 km2 the mean sediment yield for all the watersheds is 91 22 t km 2 y 1 the high value of coefficient of variation cv greater than 100 indicated a strong variability in the sediment yield table 3 3 2 characteristics of lithology and landscape variables the lithology and landscape variables generally exhibited a broad variation table 3 for lithology variables karst coverage values ranged from 0 34 to 93 18 with a mean value of 53 04 karst coverage showed moderate variability 10 cv 100 while the dolomite coverage and limestone coverage demonstrated strong variability cv greater than 100 table 3 for landscape variables the number of patches np varied substantially from 57 to 26072 and the landscape shape index lsi also ranged widely from 6 14 to 108 40 interestingly the cv values of np lsi and patch richness density prd were all very high greater than 100 indicating that these variables showed a greater variation than the other landscape variables the low values of cv 10 indicated a weak variability in mean shape index shape mean fractal dimension index frac perimeter area fractal dimension pafrac and patch cohesion index cohesion table 3 among all the 30 lithology and landscape variables ten variables were randomly selected to conducted a pearson correlation analysis fig 3 obviously most of the variables were significantly correlated with each other p 0 05 for example there is a significant correlation between kc and the other nine variables additionally shannon s diversity index shdi simpson s diversity index sidi shannon s evenness index shei and contagion index contag were strongly correlated with each other fig 3 these results implied that many variables were co linear 3 3 relating lithology and landscape variables to sediment yield table 4 summarizes the optimal plsr model for sediment yield of 40 watersheds the first component only accounted for 26 4 of the total variance in sediment yield the addition of the second component enhanced the model explained variance to 51 2 the first three and fourth components cumulatively explained 61 8 and 66 8 of sediment yield variability respectively inserting additional components to the plsr models cannot greatly improve the explained variance and resulted in lower predictive ability indicating that the adding component was not significantly correlated with the residuals of the predicted variable furthermore the prediction error decreased with the component numbers and the minimum rmsecv was also observed with four components table 4 fig 4 exhibits the weights of the predictors in the first and second components the largest patch index lpi mean patch area mps and mean euclidian nearest neighbor distance enn dominated the first component on the positive side while shape and mean radius of gyration gyrate dominated the second component on the positive side the karst coverage with negative plsr weights dominated both the first and second components of the annual sediment yield although the plsr weights fig 4 indicated how important the lithology and landscape variables were to the sediment yield a more comprehensive and convenient expression of the relative importance of the variables can be obtained by exploring their vip values the key variables responsible for the variation in sediment yield were kc vip 2 19 dolomite coverage dc vip 1 42 lsi vip 1 33 patch richness pr vip 1 23 relative patch richness rpr vip 1 23 np vip 1 22 and shdi vip 1 03 fig 5 fig 6 presents the scatter plots of the observed and predicted sediment yield values using the optimal plsr model the predicted sediment yield values showed good agreement with the observed values with the q 2 and r 2 of 0 552 and 0 668 respectively fig 6a some points however were far from 1 1 line when sediment yield was greater than 160 t km 2 y 1 4 discussion in this study it is important to note that the sediment yield of the 40 karst watersheds ranged from 1 17 to 427 t km 2 y 1 table 3 which were much lower than non karst areas specifically in non karst areas of the northern ethiopia due to the intensive human activities the mean sediment yield was approximately 1170 t km 2 y 1 haregeweyn et al 2005 in the black soil region of china the sediment yield for an entire watershed was about 830 t km 2 y 1 fang et al 2013 in the northern rocky mountain area of china the estimated mean sediment yield was about 1250 and 1100 t km 2 y 1 for the periods of 1963 2011 and 1998 2011 respectively zhang et al 2017 in red soil region of south china the mean sediment yield of wangjiaqiao watershed was 8036 t km 2 y 1 and the annual soil loss of pingtonghe and liushahe watersheds were 1674 and 1510 t km 2 y 1 respectively fang et al 2015 in a serious erosion region of the loess plateau the mean sediment yield rate can reach up to 5000 to 10 000 t ha 1 yr 1 wei et al 2007 wang et al 2015 zhao et al 2015 although the karst watersheds generated relatively lower sediment yield compared with non karst areas the soil erosion risk is still very high in karst watersheds dissolving 25 m thick of pure carbonate rock material for 2000 8000 years is required to form 1 cm of soil jiang et al 2014 li et al 2016 because of the low soil formation rate from the carbonate bedrocks some studies have indicated that the soil loss tolerance of the karst areas is only 30 68 t km 2 yr 1 peng and wang 2012 feng et al 2014 for the periods from 2009 to 2012 the annual sediment yield values greater than 30 and 68 t km 2 y 1 accounted for 63 and 34 respectively fig 7 this implied that greater attention still should be paid to control sediment delivery in heterogeneous karst watersheds in consideration of the highly co dependent data the plsr in conjunction with the variable influence of the projection approach was utilized to identify the relative importance of lithology and landscape variables on sediment yield because the vip value for a predictor 1 is considered to be of minor importance for sediment yield prediction onderka et al 2012 shi et al 2014 further discussion is only restricted to the ones greater than 1 fig 5 lithology exerted substantial influence on annual sediment yield the most important variable for sediment yield was karst coverage which had a negative regression coefficient r 2 0 35 p 0 01 fig 8 implying that sediment yield decreased with karst coverage for example the karst coverage for no 12 watershed and its adjacent no 13 watershed were 4 5 and 72 5 respectively while the corresponding sediment yield was 245 5 t km 2 y 1and 7 5 t km 2 y 1 table 1 fig 2a in this region the hydrogeological features of a karst complex included a porous rock matrix fissures fractures and a network of solution conduits embedded in karst aquifers hartmann et al 2015 jukić and denić jukić 2015 largely carbonized rock coverage watersheds have richly exposed epikarst fissures and fractures to enhance the permeability of the bedrock wang et al 2004b zhang et al 2014 li et al 2017c generally most rainfall rapidly infiltrated into soil epikarst systems through the fissures and fractures hence hindering surface runoff formation peng and wang 2012 li et al 2017a the eroded soils from hillslopes usually filled in the karst conduits and blocked the drainage outlets in karst depressions jiang et al 2014 the high amounts of eroded sediment were deposited before it could be transported to the surface water li et al 2017b greater proportion of the carbonate rock often store more rainfall and generated smaller runoff and thus a relatively smaller amount of sediment is transported by overland flow furthermore most of soft sediments covering on karst rock outcrops were removed by soil erosion wang et al 2004b peng and wang 2012 the bare and stony epikarst was appeared and further led to rocky desertification jiang et al 2014 hartmann et al 2015 that is no enough soil was left to be eroded in karst areas especially in a karst watershed with a large proportion of carbonate rock this explained why an inverse relationship was observed between sediment yield and karst coverage based on observations in 23 karst watersheds zhang et al 2014 showed that the watershed with a large proportion of carbonate rock usually had a low value of runoff coefficient our previous studies also found that the runoff decreased with the increase of carbonized rock area in five karst watersheds li et al 2017c the annual sediment yield was also strongly influenced by landscape in particular landscape shape index lsi diversity index shdi pr and rd and area index np were highly linked to sediment yield fig 5 for the shape index the interaction of patch shape and size could greatly influence a number of important ecological processes and thus on soil erosion the lsi metric was a standardized measure of the total edge adjusted for the size of the landscape and was widely applicable in landscape ecological research ouyang et al 2010 mcgarigal et al 2012 shi et al 2013 ai et al 2015 zhou et al 2017 lsi metric exhibited negative relationship with the sediment yield which was accordance with the findings of ouyang et al 2010 that the larger shape generally intensified the soil erosion the diversity index is a landscape level indicator to quantify landscape composition for describing the landscape richness and evenness mcgarigal et al 2012 the shdi metric increased as the number of different land cover types this implied that sediment yield was likely enhanced when different land use types were greatly interspersed or the number of types increased this result is inconsistent with the conclusion of some previous studies that shdi of land uses was positively correlated with water quality measures in non karst areas lee et al 2009 huang et al 2013 the special geological condition was probably responsible for this difference the area index represented a loose collection of metrics that managed with the size of patches and could affect myriad processes mcgarigal et al 2012 the pd negatively correlated with sediment yield fig 5 indicating that the higher pd led to less erosion the pd metric was normally used to reflect the degree of fragmentation of the focal patch type uuemaa et al 2005 lee et al 2009 ai et al 2015 a watershed with the highly fragmented landscape could prevent soil erosion by disturbing the formation and transportation of sediment shi et al 2013 the patch reduced the soil erosion principally by the hardness of patch edge this result was consistent with the results of ouyang et al 2010 that more complicated patch and patch edge could prevent soil erosion in non karst areas shi et al 2013 also investigated the relationship between the spatial configurations of land cover landscape metrics and the sediment yield they found that only the landscape metrics could account for as much as 74 of the variation in sediment yield in heterogeneous karst watersheds if we only considered the land cover patterns landscape metrics only explained 34 2 of the sediment yield variability and the prediction result was quite poor fig 6b an improvement was detected in the plsr model q 2 0 552 r 2 0 668 when the lithology characteristics was added fig 6a therefore it is important to highlight that lithology was a very important factor controlling sediment yield in heterogeneous karst watersheds this study showed a strong influence of lithology and landscape characteristics on the sediment yield in heterogeneous karst watersheds although our objective was not to develop a prediction model rather to identify the dominant variables controlling sediment yield at 40 sub watersheds the results of this study suggest that some lithology and landscape variables such as kc dc lsi np and shdi which can be easily calculated from a geological and land use map can considerably enhance the predictability of sediment yield in watershed with no sufficient data monitored tramblay et al 2010 shi et al 2013 ai et al 2015 the plsr technique can partially eliminates codependency among the variables reduce noise in the data and further explain the largest amount of variation in the dependent variables therefore it can be regarded as a novel and beneficial model abdi 2010 onderka et al 2012 shi et al 2014 li et al 2017c this study however still had some limitations in heterogeneous karst watersheds the soil erosion process is quite complicated and sediment yield was also greatly influenced by soil properties and geomorphological features verstraeten et al 2003 de vente et al 2011 xin et al 2011 zhang et al 2015 to yield a more in depth understanding of the sediment transport processes in karst watersheds we should consider more variables that potentially controlled sediment yield in the future studies 5 conclusions the objective of this study was to quantify the relative importance of the lithology and landscape variables on annual sediment yield in heterogeneous karst watersheds using plsr approach which can facilitate partially eliminating the co dependency among explanatory variables results showed that lithology and landscape variables could account for as much as 66 8 of the total variance in sediment yield this implied that annual sediment yield was closely related to lithology and landscape characteristics within a watershed the karst coverage kc dolomite coverage dc landscape shape index lsi patch richness pr relative patch richness rpr number of patches np and simpson s diversity index shdi were the dominant factors controlling watershed sediment yield due to the special geology in the karst areas greater proportion of the carbonate rock often had a lower sediment yield higher patch numbers can prevent soil erosion by disturbing the formation and transportation of sediment in these heterogeneous karst watersheds if only the land cover patterns were considered landscape variables can just explain 34 2 of the sediment yield variability thus we must take into consideration of lithology when identifying the dominant factors influencing sediment yield in karst watersheds this study highlights the usefulness of the plsr model in determining the linkages between lithology landscape variables and sediment yield and hence can be helpful for decision makers allocating effective soil conservation measures and making better choices regarding watershed management acknowledgments this study was supported by the state key program of national natural science foundation of china 41730748 national natural science foundation of china 41601299 cas interdisciplinary innovation team and the youth innovation team project of isa cas 2017qncxtd xxl 
6825,as one of the largest contiguous karst regions in the world southwest china is vulnerable to soil erosion because of its unique geology and inappropriate land use understanding the linkages between geological conditions land cover patterns and sediment yield is thus of paramount importance to effectively control sediment delivery in heterogeneous karst watersheds the objective of this study was to examine how the specific sediment yield was related to lithology and landscape variables for 40 karst watersheds in southwest china due to these watershed variables were highly codependent partial least squares regression plsr was applied to elucidate the relationship between the sediment yield and 30 lithology and landscape variables the first order controls were determined by calculating the variable importance for the projection vip predictors with vip scores larger than 1 were considered to be the most influential predictors of the plsr model results indicated that the lithology and landscape indeed exerted substantial influence on sediment yield explained variance 66 8 for the investigated 40 watersheds specifically the first dominant factor for sediment yield was karst coverage vip 2 19 followed by dolomite coverage vip 1 42 landscape shape index vip 1 33 patch richness vip 1 23 relative patch richness vip 1 23 number of patches vip 1 22 and simpson s diversity index vip 1 03 the plsr technique enabled the elimination of codependency among the variables and facilitated a more unbiased view of the control factors for sediment yield therefore this approach is recommended as a useful tool for identifying the dominant factors controlling sediment yield in heterogeneous karst watersheds keywords soil erosion earth critical zone partial least squares regression landscape ecology ecohydrology 1 introduction soil erosion by water resulted in the removal of soil material by the processes of detachment and transportation causing on site land degradation while deposition of the eroded sediment can cause negative downstream off site impacts syvitski et al 2005 zhang et al 2009 duan et al 2016 borrelli et al 2017 soil erosion and associated sediment transport has become a serious social and environmental concern throughout the world especially in karst regions of southwest china which is a typically ecologically fragile zone experiencing severe soil erosion jiang et al 2014 wang et al 2015 li et al 2016 karst regions approximately comprises between 7 and 12 of the earth s continental surface and the southwest china represents one of the largest contiguous karst areas in the world hartmann et al 2015 li et al 2017a the special geological conditions and the unsustainable intensive land use on a fragile karst geo ecological environment were two important factors affecting the occurrence and intensity of the soil erosion peng and wang 2012 dai et al 2017 thus knowledge of the relationship between sediment yield and its controlling factors is crucial to developing a variety of watershed management practices such as soil and water conservation land use planning and river restoration the special geological conditions can greatly affect the hydrological characteristic of a karst system and thus may influence sediment yield jukić and denić jukić 2015 li et al 2017b southwest china is featured by thin soils overlying highly irregular epikarst surface with high infiltration capacity which play an important role in the generation of overland flow and underground lateral flow peng and wang 2012 hartmann et al 2015 a part of the precipitation is rapidly transferred through the epikarst zone via the network of conduits but the rest of it remains in the epikarst zone and subsequently slowly percolates or evaporates perrin et al 2003 aquilina et al 2006 on the one hand the epikarst zone is characterized by a substantial storage capacity and hence can reduce runoff and enhance evaporation jukić and denićjukić 2009 on the other hand the eroded sediment generally blocked the karst conduits or the sinkholes in the bottom of the karst depression resulting in large amounts of sediment deposited in the karst watersheds jiang et al 2014 li et al 2017b under this special geological condition the very low soil formation rate created a fragile and vulnerable environment that was susceptible to deforestation and soil erosion feng et al 2014 jiang et al 2014 generally the carbonate rocks are highly soluble and very difficult to generate much soil dai et al 2017 li et al 2017b the low soil formation rate in this region was mainly caused by the low content of silicate mineral in carbonate rock jiang et al 2014 the spatial distribution pattern of carbonate rocks had a significant effect on rocky desertification which is a process of land degradation involving serious soil erosion wang et al 2004b the severe rocky desertification generally occurred in the carbonate rocks continuously distributed area while the scattered or interspersed carbonate rocks area had a slight rocky desertification wang et al 2004a the annual soil loss can reach the amount of soil formed in 60 years implying a significant imbalance between soil loss and soil formation rate peng and wang 2012 feng et al 2014 in some severe rocky desertification areas almost all of the surface soil was lost and only little soil was available to be eroded jiang et al 2014 therefore soil erosion may be highly linked to the geologic conditions of fragile karst systems landscape heterogeneity generally led to variations in ecological and hydrological conditions thereby altering sediment production transport and delivery to rivers bakker et al 2008 yang et al 2012 ai et al 2015 in karst regions of southwest china landscapes including discontinuously distributed soil and fragmented ecological spaces suitable for plants were highly heterogeneous yue et al 2013 furthermore the landscape structures were closely related to the distribution of rocky desertification which was the ultimate result of deforestation and soil loss in the carbonate rock areas jiang et al 2014 the fractional cover of exposed carbonate rocks and vegetation could represent the land surface symptoms of rocky desertification wang et al 2004a yue et al 2013 consequently in karst regions this highly heterogeneous landscape affected the connectivity between sediment source and sink and sediment transport capacity was different for different land cover types lithological factors and landscape metrics were generally used to depict the geological conditions and landscape characteristics respectively many studies have quantified the relationship between lithology landscape and sediment yield or stream water contaminants in non karst areas haregeweyn et al 2005 de vente and poesen 2005 bakker et al 2008 lee et al 2009 ouyang et al 2010 onderka et al 2012 huang et al 2013 shi et al 2013 shi et al 2014 ai et al 2015 due to the special geological conditions coupled with highly heterogeneous landscapes the dominant erosion controls in karst areas and non karst areas were probably different however the effects of lithology and landscape variables on sediment yield is not yet fully quantified in karst regions furthermore the lithology and landscape variables are highly co linear or co dependent which can result in redundancy onderka et al 2012 shi et al 2013 zhou et al 2017 therefore a partial least squares regression plsr model which can handle highly correlated noise corrupted datasets by explicitly assuming the dependency among independent variable abdi 2010 carrascal et al 2010 is introduced in this study to evaluate the influence of lithology and landscape variables on sediment yield in karst watersheds the objectives of this study were to determine how the specific sediment yield was related to lithology and landscape variables and then to detect the dominant controls of sediment yield using plsr technique for 40 heterogeneous karst watersheds in southwest china 2 materials and methods 2 1 study area the study area is located in the wujiang and xijiang watershed where the typical karst landscape is widespread the wujiang river is the largest tributary on the southern bank of the upper reaches of the yangtze river fig 1 wujiang river originates from wumeng ranges on the yunnan guizhou plateau and flows through yunnan guizhou chongqing and hubei provinces with a total length of 1037 km this watershed has an elevation between 113 m and 2888 m and drains an area of 8 79 104 km2 26 09 13 30 12 1 n 104 15 35 109 20 6 e with a mean annual water and sediment discharge of 48 5 km3 and 2 4 107 t 1955 2011 respectively this region is characterized by the subtropical monsoon humid climate with annual precipitation ranges from 1100 to 1300 mm 75 of which occurs in the wet season from may to october the mean annual temperature is 12 3 c with hot summer and cold winter the xijiang river is the major tributary of the pearl river that is the second largest chinese river after the yangtze river in terms of water discharge and is the largest contributor of sediment to south china sea this river originates from yunnan province flows through guizhou guangxi and guangdong province finally entering into the south china sea fig 1 the main stream of the river is 2214 km long and has a watershed area of 35 3 104 km2 21 36 17 27 00 21 n 102 16 52 113 23 51 e the xijiang river watershed experiences a subtropical and tropical monsoon climate straddling the tropic of cancer with the mean annual temperature and precipitation of 18 c and 1470 mm respectively precipitation distribution during a year is uneven and more than 80 of which occurs during the wet season from april to october this region is mainly underlain by carbonate rocks representing approximately 43 5 of the total watershed area fig 2 a altogether 11 and 29 sub watersheds were selected in wujiang river and xijiang river watershed respectively these watersheds are corresponding to 40 hydrological stations fig 1 table 1 2 2 data the sediment yield data 2009 2012 for 40 hydrological stations were obtained from hydrological yearbooks of the people s republic of china the annual sediment yield data was extracted from the higher resolution daily average sediment yield data the reliability and homogeneity of the data have been checked and firmly controlled before its release the digital elevation model dem with a resolution of 30 m was acquired from the geospatial data cloud according to information of the 40 hydrological stations the corresponding 40 watersheds boundary was extracted from the dem by hydrologic modeling using arcgis fig 1 the geological map was provided by the institute of geochemistry chinese academy of sciences fig 2a the 1 100 000 scale land use database of the 2009 was obtained from the resource and environmental science data center chinese academy of sciences http www resdc cn fig 2b 2 3 potential influencing factors data regarding the potential influencing factors were extracted from each watershed to describe lithology and landscape variables altogether 30 variables were regarded as potential factors influencing the sediment yield the descriptions and abbreviations of the 30 variables were presented in table 2 these selected variables have been widely used in previous studies de vente and poesen 2005 ouyang et al 2010 de vente et al 2011 yang et al 2012 shi et al 2013 uuemaa et al 2013 shi et al 2014 the lithology variables including the percentage of carbonate rock karst dolomite and limestone table 2 the carbonate rock included the pure dolomite pure limestone and the mixture of the dolomite and limestone the selected 27 landscape variables were divided into five classes area index shape index diversity index spatial configuration index and fragmentation index ouyang et al 2010 mcgarigal et al 2012 several variables were calculated within each class table 2 all the landscape variables were obtained from the land use map using the fragstats 4 2 which is widely accepted for landscape metrics quantification mcgarigal et al 2012 shi et al 2013 prior to the plsr a preliminary analysis bivariate scatterplots in fig 3 showed that many of the variable are collinear thus the variables that potentially controlling sediment yield may be not truly independent variables 2 4 plsr plsr is a robust multivariate regression method that is particularly appropriate for analyzing data with correlated noisy and many independent variables shi et al 2014 ma et al 2015 to accommodate the highly correlated variables we constructed a plsr model to determine the relationship between a set of predictor data independent xn m which includes n observations rows and m variables columns and a response vector dependent yn 1 in this plsr model the independent variables were the selected lithology and landscape variables and the dependent variable was the mean annual sediment yield during 2009 2012 to avoid over fitting and achieve an optimal balance between the explained variation in the response r 2 and the predictive ability of the model q 2 cross validation was introduced to determine the appropriate number of components in the plsr model carrascal et al 2010 plsr model is considered to provide good predictions when r 2 is greater than 0 5 trap et al 2013 unlike r 2 q 2 will decline as model become increasingly over fitted q 2 cum is defined as the cumulative q 2 over all the selected plsr components the root mean square error of cross validation rmsecv is also determined to provide useful information for calibrating and developing the regression model the optimal plsr model generally had the maximum q 2 cum and the minimal rmsecv which were computed using the following equations 1 q 2 1 0 p r e s s s s 2 press i 1 n p i o i 2 3 ss i 1 n p i o i 2 4 q 2 c u m 1 0 p r e s s s s k k 1 2 m 5 rmsecv press n where press indicates the prediction error sum of squares ss indicates the residual sum of squares p i is the predicted sediment yield for the leave one out sample pi and oi are the predicted and observed sediment yield m is the number of plsr components and n is the number of samples n 40 the variable importance of projection vip and regression coefficients rcs are the two important parameters to reflect the importance of a predictor for both the independent and the dependent variables shi et al 2013 fang et al 2015 terms with large vip values are the most significant and relevant in explaining the dependent variable generally predictor with vip value greater than 1 is considered as the most influential predictors of the model onderka et al 2012 rcs indicate the direction and strength of the impact of each independent variable in the plsr model the detailed information of the plsr technique can be found in the previous studies abdi 2010 li et al 2017c plsr was performed with simca p 13 0 software umetrics ab sweden 3 results 3 1 characteristics of sediment yield table 1 shows that the mean annual sediment yield of the 40 watersheds varied substantially from 2 0 t km 2 y 1 to 245 5 t km 2 y 1 for the period from 2009 to 2012 interestingly the sediment yield decreased with the watershed area for example a low annual sediment yield 2 0 t km 2 y 1 was found in no 20 watershed 104772 km2 while a high annual sediment yield 211 7 t km 2 y 1 was observed in no 37 watershed 2744 km2 the mean sediment yield for all the watersheds is 91 22 t km 2 y 1 the high value of coefficient of variation cv greater than 100 indicated a strong variability in the sediment yield table 3 3 2 characteristics of lithology and landscape variables the lithology and landscape variables generally exhibited a broad variation table 3 for lithology variables karst coverage values ranged from 0 34 to 93 18 with a mean value of 53 04 karst coverage showed moderate variability 10 cv 100 while the dolomite coverage and limestone coverage demonstrated strong variability cv greater than 100 table 3 for landscape variables the number of patches np varied substantially from 57 to 26072 and the landscape shape index lsi also ranged widely from 6 14 to 108 40 interestingly the cv values of np lsi and patch richness density prd were all very high greater than 100 indicating that these variables showed a greater variation than the other landscape variables the low values of cv 10 indicated a weak variability in mean shape index shape mean fractal dimension index frac perimeter area fractal dimension pafrac and patch cohesion index cohesion table 3 among all the 30 lithology and landscape variables ten variables were randomly selected to conducted a pearson correlation analysis fig 3 obviously most of the variables were significantly correlated with each other p 0 05 for example there is a significant correlation between kc and the other nine variables additionally shannon s diversity index shdi simpson s diversity index sidi shannon s evenness index shei and contagion index contag were strongly correlated with each other fig 3 these results implied that many variables were co linear 3 3 relating lithology and landscape variables to sediment yield table 4 summarizes the optimal plsr model for sediment yield of 40 watersheds the first component only accounted for 26 4 of the total variance in sediment yield the addition of the second component enhanced the model explained variance to 51 2 the first three and fourth components cumulatively explained 61 8 and 66 8 of sediment yield variability respectively inserting additional components to the plsr models cannot greatly improve the explained variance and resulted in lower predictive ability indicating that the adding component was not significantly correlated with the residuals of the predicted variable furthermore the prediction error decreased with the component numbers and the minimum rmsecv was also observed with four components table 4 fig 4 exhibits the weights of the predictors in the first and second components the largest patch index lpi mean patch area mps and mean euclidian nearest neighbor distance enn dominated the first component on the positive side while shape and mean radius of gyration gyrate dominated the second component on the positive side the karst coverage with negative plsr weights dominated both the first and second components of the annual sediment yield although the plsr weights fig 4 indicated how important the lithology and landscape variables were to the sediment yield a more comprehensive and convenient expression of the relative importance of the variables can be obtained by exploring their vip values the key variables responsible for the variation in sediment yield were kc vip 2 19 dolomite coverage dc vip 1 42 lsi vip 1 33 patch richness pr vip 1 23 relative patch richness rpr vip 1 23 np vip 1 22 and shdi vip 1 03 fig 5 fig 6 presents the scatter plots of the observed and predicted sediment yield values using the optimal plsr model the predicted sediment yield values showed good agreement with the observed values with the q 2 and r 2 of 0 552 and 0 668 respectively fig 6a some points however were far from 1 1 line when sediment yield was greater than 160 t km 2 y 1 4 discussion in this study it is important to note that the sediment yield of the 40 karst watersheds ranged from 1 17 to 427 t km 2 y 1 table 3 which were much lower than non karst areas specifically in non karst areas of the northern ethiopia due to the intensive human activities the mean sediment yield was approximately 1170 t km 2 y 1 haregeweyn et al 2005 in the black soil region of china the sediment yield for an entire watershed was about 830 t km 2 y 1 fang et al 2013 in the northern rocky mountain area of china the estimated mean sediment yield was about 1250 and 1100 t km 2 y 1 for the periods of 1963 2011 and 1998 2011 respectively zhang et al 2017 in red soil region of south china the mean sediment yield of wangjiaqiao watershed was 8036 t km 2 y 1 and the annual soil loss of pingtonghe and liushahe watersheds were 1674 and 1510 t km 2 y 1 respectively fang et al 2015 in a serious erosion region of the loess plateau the mean sediment yield rate can reach up to 5000 to 10 000 t ha 1 yr 1 wei et al 2007 wang et al 2015 zhao et al 2015 although the karst watersheds generated relatively lower sediment yield compared with non karst areas the soil erosion risk is still very high in karst watersheds dissolving 25 m thick of pure carbonate rock material for 2000 8000 years is required to form 1 cm of soil jiang et al 2014 li et al 2016 because of the low soil formation rate from the carbonate bedrocks some studies have indicated that the soil loss tolerance of the karst areas is only 30 68 t km 2 yr 1 peng and wang 2012 feng et al 2014 for the periods from 2009 to 2012 the annual sediment yield values greater than 30 and 68 t km 2 y 1 accounted for 63 and 34 respectively fig 7 this implied that greater attention still should be paid to control sediment delivery in heterogeneous karst watersheds in consideration of the highly co dependent data the plsr in conjunction with the variable influence of the projection approach was utilized to identify the relative importance of lithology and landscape variables on sediment yield because the vip value for a predictor 1 is considered to be of minor importance for sediment yield prediction onderka et al 2012 shi et al 2014 further discussion is only restricted to the ones greater than 1 fig 5 lithology exerted substantial influence on annual sediment yield the most important variable for sediment yield was karst coverage which had a negative regression coefficient r 2 0 35 p 0 01 fig 8 implying that sediment yield decreased with karst coverage for example the karst coverage for no 12 watershed and its adjacent no 13 watershed were 4 5 and 72 5 respectively while the corresponding sediment yield was 245 5 t km 2 y 1and 7 5 t km 2 y 1 table 1 fig 2a in this region the hydrogeological features of a karst complex included a porous rock matrix fissures fractures and a network of solution conduits embedded in karst aquifers hartmann et al 2015 jukić and denić jukić 2015 largely carbonized rock coverage watersheds have richly exposed epikarst fissures and fractures to enhance the permeability of the bedrock wang et al 2004b zhang et al 2014 li et al 2017c generally most rainfall rapidly infiltrated into soil epikarst systems through the fissures and fractures hence hindering surface runoff formation peng and wang 2012 li et al 2017a the eroded soils from hillslopes usually filled in the karst conduits and blocked the drainage outlets in karst depressions jiang et al 2014 the high amounts of eroded sediment were deposited before it could be transported to the surface water li et al 2017b greater proportion of the carbonate rock often store more rainfall and generated smaller runoff and thus a relatively smaller amount of sediment is transported by overland flow furthermore most of soft sediments covering on karst rock outcrops were removed by soil erosion wang et al 2004b peng and wang 2012 the bare and stony epikarst was appeared and further led to rocky desertification jiang et al 2014 hartmann et al 2015 that is no enough soil was left to be eroded in karst areas especially in a karst watershed with a large proportion of carbonate rock this explained why an inverse relationship was observed between sediment yield and karst coverage based on observations in 23 karst watersheds zhang et al 2014 showed that the watershed with a large proportion of carbonate rock usually had a low value of runoff coefficient our previous studies also found that the runoff decreased with the increase of carbonized rock area in five karst watersheds li et al 2017c the annual sediment yield was also strongly influenced by landscape in particular landscape shape index lsi diversity index shdi pr and rd and area index np were highly linked to sediment yield fig 5 for the shape index the interaction of patch shape and size could greatly influence a number of important ecological processes and thus on soil erosion the lsi metric was a standardized measure of the total edge adjusted for the size of the landscape and was widely applicable in landscape ecological research ouyang et al 2010 mcgarigal et al 2012 shi et al 2013 ai et al 2015 zhou et al 2017 lsi metric exhibited negative relationship with the sediment yield which was accordance with the findings of ouyang et al 2010 that the larger shape generally intensified the soil erosion the diversity index is a landscape level indicator to quantify landscape composition for describing the landscape richness and evenness mcgarigal et al 2012 the shdi metric increased as the number of different land cover types this implied that sediment yield was likely enhanced when different land use types were greatly interspersed or the number of types increased this result is inconsistent with the conclusion of some previous studies that shdi of land uses was positively correlated with water quality measures in non karst areas lee et al 2009 huang et al 2013 the special geological condition was probably responsible for this difference the area index represented a loose collection of metrics that managed with the size of patches and could affect myriad processes mcgarigal et al 2012 the pd negatively correlated with sediment yield fig 5 indicating that the higher pd led to less erosion the pd metric was normally used to reflect the degree of fragmentation of the focal patch type uuemaa et al 2005 lee et al 2009 ai et al 2015 a watershed with the highly fragmented landscape could prevent soil erosion by disturbing the formation and transportation of sediment shi et al 2013 the patch reduced the soil erosion principally by the hardness of patch edge this result was consistent with the results of ouyang et al 2010 that more complicated patch and patch edge could prevent soil erosion in non karst areas shi et al 2013 also investigated the relationship between the spatial configurations of land cover landscape metrics and the sediment yield they found that only the landscape metrics could account for as much as 74 of the variation in sediment yield in heterogeneous karst watersheds if we only considered the land cover patterns landscape metrics only explained 34 2 of the sediment yield variability and the prediction result was quite poor fig 6b an improvement was detected in the plsr model q 2 0 552 r 2 0 668 when the lithology characteristics was added fig 6a therefore it is important to highlight that lithology was a very important factor controlling sediment yield in heterogeneous karst watersheds this study showed a strong influence of lithology and landscape characteristics on the sediment yield in heterogeneous karst watersheds although our objective was not to develop a prediction model rather to identify the dominant variables controlling sediment yield at 40 sub watersheds the results of this study suggest that some lithology and landscape variables such as kc dc lsi np and shdi which can be easily calculated from a geological and land use map can considerably enhance the predictability of sediment yield in watershed with no sufficient data monitored tramblay et al 2010 shi et al 2013 ai et al 2015 the plsr technique can partially eliminates codependency among the variables reduce noise in the data and further explain the largest amount of variation in the dependent variables therefore it can be regarded as a novel and beneficial model abdi 2010 onderka et al 2012 shi et al 2014 li et al 2017c this study however still had some limitations in heterogeneous karst watersheds the soil erosion process is quite complicated and sediment yield was also greatly influenced by soil properties and geomorphological features verstraeten et al 2003 de vente et al 2011 xin et al 2011 zhang et al 2015 to yield a more in depth understanding of the sediment transport processes in karst watersheds we should consider more variables that potentially controlled sediment yield in the future studies 5 conclusions the objective of this study was to quantify the relative importance of the lithology and landscape variables on annual sediment yield in heterogeneous karst watersheds using plsr approach which can facilitate partially eliminating the co dependency among explanatory variables results showed that lithology and landscape variables could account for as much as 66 8 of the total variance in sediment yield this implied that annual sediment yield was closely related to lithology and landscape characteristics within a watershed the karst coverage kc dolomite coverage dc landscape shape index lsi patch richness pr relative patch richness rpr number of patches np and simpson s diversity index shdi were the dominant factors controlling watershed sediment yield due to the special geology in the karst areas greater proportion of the carbonate rock often had a lower sediment yield higher patch numbers can prevent soil erosion by disturbing the formation and transportation of sediment in these heterogeneous karst watersheds if only the land cover patterns were considered landscape variables can just explain 34 2 of the sediment yield variability thus we must take into consideration of lithology when identifying the dominant factors influencing sediment yield in karst watersheds this study highlights the usefulness of the plsr model in determining the linkages between lithology landscape variables and sediment yield and hence can be helpful for decision makers allocating effective soil conservation measures and making better choices regarding watershed management acknowledgments this study was supported by the state key program of national natural science foundation of china 41730748 national natural science foundation of china 41601299 cas interdisciplinary innovation team and the youth innovation team project of isa cas 2017qncxtd xxl 
6826,a deterministic geometric approach the fractal multifractal fm method is proposed to temporally downscale disaggregate rainfall and streamflow records the applicability of the fm approach is tested on 1 two sets of rainfall records one from laikakota bolivia and the other from tinkham washington usa and 2 two distinct sets of streamflow records for water years 2005 and 2008 from the sacramento river california usa for the purpose of validation the available daily records are first aggregated into weekly biweekly and monthly records and then the fm method is applied to downscale such sets back into the daily scale the results indicate that the fm method coupled with a threshold to capture the high intermittency of rainfall and a smoothing parameter to get the milder texture of streamflow readily generates daily series over a year based on weekly biweekly and monthly accumulated information which reasonably preserves the time evolution of the records especially for streamflow and captures a variety of key statistical attributes e g autocorrelation histogram and entropy it is argued that the fm deterministic downscalings may enhance and or supplement available stochastic disaggregation methods keywords disaggregation fractal multifractal deterministic rainfall streamflow list of acronyms x τ t τ observed records at scale τ x τ t τ fm fitted set at scale τ a x τ t τ observed accumulated records at scale τ a x τ t τ fm fitted accumulated set at scale τ r τ t τ observed rainfall at scale τ a r τ t τ observed accumulated rainfall at scale τ q τ t τ observed streamflow at scale τ a q τ t τ observed accumulated streamflow at scale τ rmse a τ root mean square error in accumulated sets at scale τ maxe a τ maximum error in accumulated sets at scale τ re a c root mean square error in accumulated sets at coarse scale me a c maximum error in accumulated sets at coarse scale nse d c nash sutcliffe efficiency for data at coarse scale re a f root mean square error in accumulated record at fine daily scale me a f maximum error in accumulated record at fine daily scale nse d f nash sutcliffe efficiency for data at fine daily scale nsea nash sutcliffe efficiency for autocorrelation nseh nash sutcliffe efficiency for histogram nsee nash sutcliffe efficiency for entropy nz number of zeros in a rainfall set p d 90 percent histogram mass in fm fitted records corresponding to 90 in observed data 1 introduction the general lack of high resolution hydrologic information both in time and in space limits our ability in the proper design simulation and operation of many water resources infrastructures such as those associated with flood control and urban drainage a common practice to overcome this problem is to disaggregate downscale information available at a coarse scale into finer scales through some downscaling techniques such disaggregation approaches are generally designed to preserve some basic statistical characteristics of the records including low order moments autocorrelations power spectra and multifractal properties among others a large number of temporal disaggregation approaches and models exist in the literature very early disaggregation models were generally based on statistical notions e g pattision 1965 grace and eagleson 1966 bras and rodriguez iturbe 1976 that preserve suitable moments some key contributions in this area are as follows valencia and schaake 1972 1973 introduced a linear disaggregation model aimed at the preservation of low order moments at various scales yearly monthly and daily however this model does not account for the rather skewed distributions and highly intermittent character of rainfall subsequently mejia and roussellee 1976 tao and delleur 1976 hoshi and burges 1979 todini 1980 stedinger and vogel 1984 hershenhorn and woolhiser 1987 and connolly et al 1998 among others popularized such a linear disaggregation model with important modifications to the underlying notions and implementation procedures despite the improvements in these models and their applications limitations in such approaches continue to be highlighted for instance this class of models in truth belongs to a class of parametric techniques that requires prior assumptions about the probability distributions of the model parameters e g alvisi et al 2015 looking for an improved approach koutsoyiannis and xanthopoulos 1990 introduced a single site dynamic disaggregation model as a step wise procedure which accounts for low level variables to combine rainfall model with markovian structures and normal or gamma distributions employing such a model koutsoyiannis 1992 converted a sequential simulation model into a disaggregation model so that the output could explicitly preserve second order statistics of low level variables at the finer time scale later on koutsoyiannis 1994 noted that these models are not applicable for short scale rainfall disaggregation but that they could be improved by making use of properties of gamma distributions he also suggested the possibility to link them with a markovian structure relying on only three parameters and that this notion could be used to solve the engineering problems that seek defining a design storm however zarris et al 1998 argued that such an approach defined for flood frequency curves may not be adequate for continuous sets in light of the fact that natural records as measured around the world and commonly used in scientific investigations are rather complex and intricate the late great mathematician benoit mandelbrot suggested that geophysical records could exhibit a form of statistical self similarity that possibly bridges various temporal and spatial scales via a concept now known as multifractality mandelbrot 1982 1989 following such a lead a number of studies have implemented stochastic fractal multifractal theories in order to deal with the erratic and intermittent patterns of rainfall streamflow and other geophysical sets at hand see for example gupta and waymire 1990 tessier et al 1993 and lovejoy and schertzer 2013 among others using these notions olsson 1998 evaluated the possibility of modeling and disaggregating temporal rainfall using a multiplicative cascade model which had the ability to preserve the scaling behavior of the records this model was subsequently tested by olsson and berndtsson 1998 who showed that the model may account for seasonal non stationarities such was also considered by güntner et al 2001 who by studying issues regarding the transferability of parameters identified the reasons why the autocorrelation function may be underestimated and why the model may overestimate extreme events while classical and multifractal stochastic disaggregation models produce reasonable realizations of rainfall and streamflow processes other approaches have also been tried searching for better outcomes for instance lall 1995 proposed a nonparametric procedure that captures the nonlinearities present in the records and kumar et al 2000 employed such a method to disaggregate daily streamflow and to approximate the probability distribution of a disaggregated streamflow vector at multiple sites based on such nonparametric notions prairie et al 2007 proposed a technique for space time disaggregation of streamflow which ended up stressing that the nonlinear character of streamflow and other hydrologic processes cannot be disaggregated using traditional techniques due to a high dimensionality problem continuing with alternative approaches and in recognition of the presence of chaotic behavior in geophysical processes e g lorenz 1963 and in their transformation between different scales sivakumar 2001 explored the presence of chaos in rainfall time series observed at four different temporal scales in the leaf river basin mississippi usa using phase space reconstruction and correlation dimension the outcomes of such a study led sivakumar et al 2001 to investigate the possibility of using chaos theory to transform rainfall from one scale to another analyzing the dimensionality of the weights of the rainfall distribution between any two scales using the correlation dimension method and identifying the presence of chaotic behavior in such weights sivakumar et al 2001 also proposed a chaotic model for rainfall disaggregation based on an approach that uses local approximation in the reconstructed phase space sivakumar et al 2004 subsequently employed this approach to disaggregate streamflow in the mississippi river basin at st louis missouri usa despite the encouraging outcomes from chaos theory based studies in hydrology some criticisms of such studies have been raised see schertzer et al 2002 and sivakumar et al 2002 for a discussion a comprehensive account of the applications of chaos theory in hydrology including for rainfall and streamflow disaggregation is presented in sivakumar 2017 on a systematic practical setting lanza et al 2001 reviewed several works on rainfall downscaling techniques and pointed out that direct validation of downscaling approaches is problematic due to a lack of reliable measurements pointing out that the absence of high resolution rainfall records clearly introduces uncertainties in the rainfall runoff processes involved they emphasized the need to conduct standard synthetic tests in order to fully compare the different approaches koutsoyiannis 2003 and koutsoyiannis et al 2003 provided a general overview of the development of rainfall disaggregation models most of which generate synthetic time series for partial durations recently an ensemble downscaling method has been proposed by combining different sources of information for instance liu et al 2016 introduced an approach that couples a bayesian model and ensembles from three statistical downscaling methods to provide a scientific basis for the study of runoff response to climate change one based on a support vector machine aimed at capturing nonlinear regression relationships between variables another on a weather generator scheme to yield long time series as needed in the risk analysis of climate change and a third based on statistical downscaling model as a decision support tool such a study demonstrated the better performance of the ensemble downscaling method based on bayesian model averaging than a single statistical downscaling approach the downscaling techniques summarized above could be based on either stochastic or dynamical models however either type of models has its own limitations stochastic techniques e g regression models weather generators are based on simplified assumptions require substantially long records and large number of parameters and are seldom capable of preserving the finer details present in hydrologic records dynamical techniques on the other hand turn out to be computationally intensive see fowler et al 2007 for details especially in the context of downscaling approaches in time and space for global climate model outputs to deal with the intricacies inherent in natural records puente 1996 had earlier introduced the notion that a given seemingly random set could be represented as a fractal transformation of a multifractal measure as a consequence a procedure named the fractal multifractal fm method was introduced which besides being assigned a physical interpretation cortis et al 2013 a is capable of producing a vast class of patterns defined over one and higher dimensions that look like natural sets and b gives sets that may be conditioned to capture the overall trends and inherent details present on available records beyond the preservation of some relevant statistical attributes such as moments autocorrelation function power spectrum and multifractal spectrum upon its discovery the fm method has been found useful in various applications that include among others a the encoding of various rainfall events lasting a few hours e g puente and obregón 1996 cortis et al 2009 2013 huang et al 2013 b the modeling of spatial contamination patterns in groundwater puente et al 2001a b c the encoding of daily precipitation maskey et al 2016a puente et al 2018 d the encoding of streamflow gathered daily over a year maskey et al 2016b and e the simulation of daily rainfall maskey et al 2016c and of daily streamflow maskey et al 2017 the encouraging outcomes from these applications suggest the possibility of using the fm approach also for temporal downscaling of hydrologic data herein we propose an fm approach for downscaling rainfall and streamflow records we validate the approach 1 on rainfall using one year of data each from laikakota bolivia and tinkham washington state usa and 2 on streamflow employing two different years of data from the sacramento river california usa having available daily records at such sites we first aggregate such data to weekly biweekly and monthly scales and then use the fm method to disaggregate to daily scale to compare with the original records the rest of this article is organized as follows section 2 re visits the original fractal multifractal approach and presents adaptations used here to encode both rainfall and streamflow sets section 3 explains how the fm method is used in order to define specific downscales section 4 presents the results and discussion for the obtained disaggregated patterns for rainfall and section 5 reports such for streamflow section 6 summarizes the findings and provides remarks for further research 2 the fractal multifractal method and adaptations for rainfall and streamflow according to the fm framework geophysical records may be represented geometrically and in a system theoretic sense as outputs derived distributions produced by a complex system defined by a fractal interpolating function when the inputs to the system are also complex multifractal measures puente 1996 this section briefly explains the fm approach and provides adaptations of the original notions that allow the method to be used to represent highly intermittent records e g daily rainfall sets and mildly intermittent records e g daily streamflow sets 2 1 theoretical framework following barnsley 1988 a fractal interpolating function f defined from x into y i e f x y and passing through n 1 pre specified points x n y n satisfying x 0 x 1 x n is obtained iterating n simple affine maps from the plane to the plane i e from x y to x y of the special form 1 w n x y a n 0 c n d n x y e n f n n 1 n when these maps are constrained so that they contract the space in x 2 w n x 0 y 0 x n 1 y n 1 w n x n y n x n y n i e so that the n th map compresses the first and last interpolating points into inner interpolating points when the parameters d n are less than one in magnitude the iterations of such maps w n indeed define point by point the graph g of a function f i e g x f x x x 0 x n by doing so a set becomes the unique fixed point of the maps w n as successive calculations of images already in g in any order remain in the same graph i e g n 1 n w n g the conditions defined in eq 2 yield simple systems of linear equations that allow finding the coefficients a n c n e n and f n in terms of the coordinates by which the fractal interpolating function passes i e x n y n and also the parameters d n which given their usage in eq 1 are also known as vertical scalings barnsley 1988 at the end specifying the interpolating points and the scaling parameters allows defining via iterations a convoluted function f whose graph has a fractal dimension d 1 2 and hence its notation in a practical setting the graph of such a function f may be found indeed point by point iterating in any order the affine maps w n ultimately sampling the unique attractor g following a procedure known in the literature as the chaos game barnsley 1988 such a process starts at a point within g say an interpolating point and progresses as per arbitrary coin tosses or iterating proportions assigned to the n maps after enough iterations the process not only converges to the graph of a function f but also induces a unique invariant measure a distribution over g as well the latter when projected over the x and y coordinates yields interesting histograms that typically exhibit non trivial intermittencies and possesses multifractal properties these sets turn out to be inherent to the calculations and may be displayed at arbitrary scales just by varying the size and number of bins used to get the histograms while the natural projection over x is a deterministic multinomial multifractal measure dx generated via a multiplicative cascade e g mandelbrot 1989 puente 1996 the projections dy over y are deterministic derived distributions of dx via a fractal function f which typically resemble complex natural patterns puente 1996 2004 these notions turn out to be akin to a generalization of the description of turbulent dissipation as a random binomial multifractal meneveau and sreenivasan 1987 and also to the construction of other intermittent sets as random realizations of levy processes from universal multifractals lovejoy and schertzer 2013 as mentioned earlier the outcomes produced by the fractal multifractal method could also be interpreted physically as specific realizations of a non trivial multiplicative cascade process in a way that a generic derived measure dy represents a suitable geometric entity to represent natural phenomena cortis et al 2013 these abstract ideas are further illustrated next as used to represent both highly intermittent rainfall sets and mildly intermittent streamflow series so that the reader may better follow the notions the next sections will be based on specific numerical examples 2 2 fm representation of rainfall sets fig 1 illustrates how the fm notions may be used to model highly intermittent sets as shown there is a fractal function f 1 passing through the four interpolating points 0 0 0 28 1 12 0 78 2 62 1 1 shown as filled circles and induced via the iteration of the three maps 3 w 1 x y 0 28 0 1 75 0 63 x y 4 w 2 x y 0 50 0 3 89 0 14 x y 0 28 0 78 5 w 3 x y 0 22 0 3 63 0 27 x y 1 12 2 63 playing the chaos game according to proportions in order 52 2 and 46 these maps all having the structure of eq 1 and with coefficients defined while satisfying the contracting conditions in eq 2 have vertical scalings d 1 0 63 d 2 0 14 and d 3 0 27 and transform the domain 0 1 in x into the sub intervals in order 0 0 28 0 28 0 78 and 0 78 1 as shown in the figure the iterations induce in addition to the fractal function f 1 whose graph g 1 has a low fractal dimension of 1 03 projected histograms d x 1 and d y 1 of obtained values over x and y respectively which may be obtained at an arbitrary resolution just by having a suitable number of bins over which chaos game numerical calculations are grouped 273 bins for this particular example while d x 1 the horizontal input i e x vs d x 1 is a deterministic multinomial multifractal having almost a zero value in the middle due to the 2 weight assigned to map w 2 d y 1 the output plotted vertically i e y vs d y 1 is a deterministic derived measure i e d y 1 f 1 1 d x 1 in which a d y 1 value at a given level y is the sum of all events over x corresponding to such a level the object d y 1 akin to a distribution can therefore be explained as a transformation of a multiplicative cascade yielding in this example a highly intermittent set that resembles rainfall records gathered daily when y denotes time and d y 1 rainfall intensity fig 1 also includes on the right a set that results from an adaptation of the method which yields other derived sets that may be used to further approximate rainfall records containing yet additional intermittency and many more zeroes such an object named d y v to acknowledge a vertical cutoff i e in the y coordinate is naturally found from d y 1 by discarding traces below a threshold ϕ v as marked in the center plot this new set shown re normalized so that it integrates to one as d y 1 may be adjusted so that it better preserves natural records maskey et al 2016a 2016c 2 3 fm representation of streamflow sets fig 2 depicts the construction of a mildly intermittent derived distribution as before another fractal function f 2 passing through the four interpolating points marked 0 0 0 27 4 72 0 91 2 40 1 1 is defined via the iteration of the three maps and distinct from those used earlier given by 6 w 1 x y 0 27 0 5 24 0 52 x y 7 w 2 x y 0 64 0 2 63 0 31 x y 0 27 4 72 8 w 3 x y 0 09 0 4 28 0 87 x y 0 91 2 4 used according to the proportions in order 24 44 and 32 these maps all having the simple structure of eq 1 and with coefficients satisfying the contracting conditions in eq 2 have scalings d 1 0 52 d 2 0 31 and d 3 0 87 their iteration according to the aforementioned proportions result in the fractal function f 2 whose graph as seen requires more ink than the previous f 1 as its graph g 2 has a larger fractal dimension of 1 33 while the shown input d x 2 is still a rather intermittent multinomial multifractal no longer with close to zero values however the new output derived distribution d y 2 computed this time over 365 bins is smoother than d y 1 before as the bulkier fractal function f 2 adds an increasing number of events over x i e d y 2 f 2 1 d x 2 as such the deterministic histogram d y 2 i e y vs d y 2 becomes suitable for modeling mildly intermittent records like streamflow data gathered daily once again with y denoting time and d y 2 discharge fig 2 also includes on its rightmost plot a further adaptation for the encoding of streamflow records which consists of finding a new object d y s just for appearance purposes by performing local smoothing on the histogram d y 2 maskey et al 2016b 2017 in practice the modeling of a given rainfall or streamflow set requires the solution of an inverse problem over plausible fm parameters namely a the interpolating points through which a fractal interpolating function passes here assumed without lack of generality that the first and last points are 0 0 and 1 1 b the vertical scalings d n c the iteration frequencies associated with each map in chaos game calculations one minus the number of maps and d a vertical threshold for rainfall modeling or a smoothing parameter for streamflow calculations hence the usage of fractal functions defined via three affine maps as shall be used herein based on our previous experience requires a total of 10 fm parameters four interpolating coordinates x 1 y 1 x 2 y 2 three scalings d 1 d 2 and d 3 two iteration frequencies p 1 and p 2 p 3 1 p 1 p 2 and one extra parameter for the adaptation as defined above 3 fm temporal downscaling methodology this section describes the approach used herein to downscale disaggregate a given temporal set either rainfall or streamflow using the fm approach it also includes information pertaining to the evaluation of goodness of the proposed approach 3 1 from coarse to fine scales as explained in section 1 there is a multitude of methods that may be employed to disaggregate both rainfall and streamflow records here we propose based on the success of the fm notions maskey et al 2016a b puente et al 2018 an alternative geometric approach for temporal disaggregation from a coarse resolution week biweek or month to a fine resolution day as follows 1 given records depths or volumes at a coarse resolution say every τ days and for a total of n periods x τ t τ such a set is first normalized so that it integrates to one then its corresponding accumulated set i e mass function a x τ t τ is upgraded so that a x τ 1 0 and in such a way that a x τ m τ 1 where m τ n 2 2 with the normalized accumulated records at resolution τ a x τ t τ specified such a set becomes a target for a suitable representation via the fm approach this entails finding the best fm parameters θ τ minimizing the square errors of the available m τ accumulated values and following a numerical optimization approach 3 if the calculations are performed in such a way that internal fm computations happen at the daily scale i e employing precisely n τ bins in chaos game histogram calculations while accumulating at the τ scale for optimization purposes the implicit derived measure dy within the procedure and at the daily scale would automatically be an estimate for downscaling the normalized information at the fine scale 4 when such a set is de normalized by the total depth or volume for such a coarse set a disaggregated fm representation of the geophysical process is found in the present study these notions are tested for downscaling rainfall and streamflow records from resolutions of τ 7 weekly 14 biweekly and 30 days monthly into daily sets certainly the notions could also be used in a similar fashion to obtain temporal downscales involving arbitrary scales that is finer than daily 3 2 solution strategy the computation of fractal functions and projections associated with the fm approach happens to be a rather efficient procedure however as there are no analytical formulas for the derived measures finding an fm representation for a given set requires a numerical scheme for solving an inverse optimization problem as illustrated in section 2 the search space when iterating three maps requires searching in 10 dimensions but such is no obstacle for finding suitable solutions based on our experience a heuristic optimization scheme a generalized version of the particle swarm optimization algorithm may be used to find a close solution of an fm inverse problem fernández martinez et al 2010 huang et al 2013 maskey et al 2016a in particular and to circumvent the dimensionality of the search procedure the searches for the highly intermittent rainfall and mildly intermittent streamflow records herein are performed as follows while the rainfall records employ 200 randomly generated swarms made up of 500 fm parameter values the smoother streamflow sets use 100 randomly selected swarms containing only 300 fm parameter sets then all such swarms are allowed to evolve having all members as leaders for 300 iterations for rainfall and only 80 for streamflow at the end the best solution found over all swarms even if a local optima is considered to be the optimal solution as shall be seen the notions yield reasonable results and finding such parameters only takes a day of computation for rainfall and 4 h for streamflow on a personal computer as mentioned in section 3 1 the objective function used in the calculations is defined as in previous studies e g obregón et al 2002a b huang et al 2012 2013 maskey et al 2016a b specifically the l 2 norm i e the root mean square error of the coarse accumulated records every τ days vs the accumulated fm approximations also every τ days over the number of such periods over a water year is minimized mathematically such an objective function is defined as 9 rmse a τ 1 m τ t τ 1 m τ a x τ t τ ax τ t τ 2 where m τ is the number of periods in increments of τ days and a x τ t τ and a x τ t τ are the accumulated records and accumulated fm related fits as defined in section 3 1 attempting to ensure that fm solutions share similar geometrical features with a target set the aforementioned objective function is penalized so that a the maximum deviations between the measured and the fm fitted records maxe a τ should not exceed a value of 10 on any given period considered and b the discrepancy between the length of the fm data set and that of the observed set from beginning to end and over the periods should be less than 5 of that of the observed set for downscaling of rainfall an additional penalty is imposed so that the number of zeros no rain events present in the fm representation will not be more than 10 of those in the actual set 3 3 assessment of model performance to validate the quality of the proposed fm approach in the context of downscaling observed data sets at the daily scale are employed this readily allows calculation of aggregated sets at a scale τ to be fitted by the fm method and then the performance of the disaggregation notions is validated using the original records at the finer resolution the performance evaluation is done in terms of various statistics not included in the optimization exercise and also extended to the daily fm sets such include the root mean square error the maximum error in the accumulated set and the nash sutcliffe efficiency for the implied data both at the τ coarse scale employed in the optimization re a c me a c and nse d c and at the disaggregated daily fine scale re a f me a f and ns ed f moreover comparison visual validation is made by plotting the implied records at the distinct scales and by including at the daily scale only the autocorrelation function ρ histogram h and rényi entropy function e which are further compared in terms of nash sutcliffe efficiency values herein the rényi entropy function for the daily data is defined as 10 e 1 1 q log t 1 n x t q where x t is the rainfall or streamflow intensity or discharge value for day t observed or fitted n is the number of days of activity in a year and q is a weight that varies from 5 to 5 for streamflow and from 0 1 to 5 1 for rainfall in order to avoid the presence of zero values the well known nash sutcliffe efficiency nash and sutcliffe 1970 for data sets or a given statistic is defined in a general sense as 11 nse 1 i 1 s r i r i 2 i 1 s r i r 2 where r i is the ith statistical value or value for an observed set r is the mean of such a statistic or value over the total number of statistics values considered s and r i is the ith statistic fitted value for an fm downscaled set 4 downscaling of rainfall records to establish the applicability of the fm based downscaling approach in the context of rainfall records 7 14 and 30 day accumulated records i e weekly biweekly and monthly scales computed from available daily records are analyzed at two sites one from laikakota bolivia for water year 1966 from september 1 1965 to may 31 1966 and spanning 273 days and the other from tinkham washington state usa for water year 1995 from october 1 1994 to september 30 1995 and spanning the whole 365 days as mentioned before rainfall data sets are normalized so that the accumulated volume becomes a unity prior to using the fm method at all scales as experience suggests that the inherent complexity in the daily sets may itself be achieved by the fm method employing three maps plus further trimming below a threshold maskey et al 2016a highly intermittent representations as in fig 1 are employed that rely on the 10 fm parameters defined by the end of section 2 yielding at the daily scale a compression ratio of 27 1 for laikakota and 37 1 for tinkham here the parameters including a vertical threshold are to be obtained numerically as explained in section 3 2 4 1 rainfall set from laikakota bolivia fig 3 presents the implementation of the fm method to the rainfall set from laikakota bolivia the two graphs on the top right portray respectively the measured daily rainfall set for water year 1966 and the corresponding accumulated rainfall over the water year comprising 273 days as may be seen the records exhibit noticeable intermittency contain three major peaks and have at least six distinct regions of sustained lack of rain the rough accumulated rain profile dips below the average slope line first but it then crosses it and remains above it at about four months into the season the next three rows in fig 3 present the results for 7 day 14 day and 30 day rainfall data shown in these plots are the real sets in black and the fm representations in gray including both the records and corresponding accumulated profiles the fm fittings at the 7 14 and 30 day scale are shown on the left and the corresponding fm downscales at the daily scale are depicted on the right an observant reader may notice that the construction of the derived measure d y v in fig 1 corresponds after due flipping to the 7 day downscale results in fig 3 i e the set shown on the third column and second row of the figure the actual values of the fm parameters for such sets at various disaggregation scales are included in the first three rows of appendix a the next three rows in fig 3 present the results for 7 day 14 day and 30 day rainfall data shown in these plots are the real sets in black and the fm representations in red including both the records and corresponding accumulated profiles the fm fittings at the 7 14 and 30 day scale are shown on the left and the corresponding fm downscales at the daily scale are depicted on the right an observant reader may notice that the construction of the derived measure d y v in fig 1 corresponds after due flipping to the 7 day downscale results in fig 3 i e the set shown on the third column and second row of the figure the actual values of the fm parameters for such sets at various disaggregation scales are included in the first three rows of appendix a as clearly seen in fig 3 for the accumulated rainfall plots t τ vs a r τ all optimized fm representations fit the accumulated records at all scales reasonably well although the overall geometries on the first column of the graph do show some imperfections in fitting the data itself their overall shapes follow closely the records and accumulated sets in gray on the second column this implies that the penalties imposed while doing the searches as described in section 3 2 are satisfied as may be verified from table 1 the root mean square errors at a coarse resolution obtained for the accumulated sets re a c are certainly rather small as they are in order 3 1 2 8 and 3 1 for fm representations at the 7 14 and 30 day scales the goodness of the fits may also be seen in the magnitude of the maximum errors in accumulated sets me a c which are for increasing scales 8 7 6 0 and 6 3 with the more complex set at the 7 day scale providing the largest deviation due to noticeable disparities by the end of the records as seen in the second column and second row in fig 3 the closer renderings on biweekly and monthly scales are corroborated by the positive nash sutcliffe efficiencies for the data in table 1 nse d c which are non trivial to achieve for such highly intermittent records maskey et al 2016a however the value of zero for such an attribute at the 7 day aggregation scale confirms the complexity of rain at the weekly scale as clearly seen in fig 3 for the accumulated rainfall plots t τ vs a r τ all optimized fm representations fit the accumulated records at all scales reasonably well although the overall geometries on the first column of the graph do show some imperfections in fitting the data itself their overall shapes follow closely the records and accumulated sets in red on the second column this implies that the penalties imposed while doing the searches as described in section 3 2 are satisfied as may be verified from table 1 the root mean square errors at a coarse resolution obtained for the accumulated sets re a c are certainly rather small as they are in order 3 1 2 8 and 3 1 for fm representations at the 7 14 and 30 day scales the goodness of the fits may also be seen in the magnitude of the maximum errors in accumulated sets me a c which are for increasing scales 8 7 6 0 and 6 3 with the more complex set at the 7 day scale providing the largest deviation due to noticeable disparities by the end of the records as seen in the second column and second row in fig 3 the closer renderings on biweekly and monthly scales are corroborated by the positive nash sutcliffe efficiencies for the data in table 1 nse d c which are non trivial to achieve for such highly intermittent records maskey et al 2016a however the value of zero for such an attribute at the 7 day aggregation scale confirms the complexity of rain at the weekly scale the third column and from the second to the fourth rows of fig 3 show the specific fm downscaling patterns obtained at the daily scale as may be seen the downscaled sets have intermittent textures similar to that of the original records and a reasonable following of the accumulated records this is especially the case for the fm disaggregations found from data gathered every 7 and 14 days as may be corroborated from the statistical information in table 1 sixth to eigth columns although the root mean square errors at the daily finer scale re a f remain close to the values found from the optimization exercises at the coarser resolutions from 3 to 4 3 the performance steadily degrades when the starting records to be fitted are coarser specifically the maximum errors in accumulated sets at the daily scale me a f increase from 8 7 up to 11 3 at the 30 day scale and the nash sutcliffe efficiencies for the daily rainfall data nse d f decay and become increasingly negative indicating the intrinsic difficulty in approximating rainfall sets notice that while these trends are to be expected for a coarser scale implies usage of less information a comparison with an fm encoding of the actual set at the daily scale is required to truly gauge the goodness of an fm disaggregation as the latter i e optimizing at the daily scale may be achieved with re a f and me a f values of 1 4 and 4 4 respectively maskey et al 2016a the obtained downscaled patterns having statistics that are at least twice such numbers see table 1 are not as tight to the records as possible notice however that the obtained patterns even from accumulated data every 30 days do look reasonable see fig 3 which implies that they may be considered at least as suitable simulations of the highly variable rainfall data at the site fig 4 shows the statistical information regarding the obtained daily downscales at laikakota as compared with the daily records such are left to right the autocorrelation function i e lag vs ρ the histogram i e bins vs h with a total of 10 bins based on the scale of the records and placing an fm value larger than the maximum in the last bin if needed and the rényi entropy function i e q vs e for the three fm daily sets presented in fig 3 in the same order 7 14 and 30 day scales from top to bottom as may be seen this information corroborates that all fm based downscales in gray are comparable as a their autocorrelation functions follow the overall decay present in the records black b their histograms are rather close to the one of the records with the one from 7 days being a bit better and c their entropies exhibit similar decays even if they are noticeably imperfect with the one based on 30 days being less biased these trends are reflected in the nash sutcliffe efficiencies for these attributes see table 1 a negative values for autocorrelations nsea that reflect the high variability and near zero values for correlations b values close to one hundred percent for histograms nseh and c medium numbers for entropies nsee with the fm representation based on 30 day aggregations being better as seen graphically fig 4 shows the statistical information regarding the obtained daily downscales at laikakota as compared with the daily records such are left to right the autocorrelation function i e lag vs ρ the histogram i e bins vs h with a total of 10 bins based on the scale of the records and placing an fm value larger than the maximum in the last bin if needed and the rényi entropy function i e q vs e for the three fm daily sets presented in fig 3 in the same order 7 14 and 30 day scales from top to bottom as may be seen this information corroborates that all fm based downscales in red are comparable as a their autocorrelation functions follow the overall decay present in the records black b their histograms are rather close to the one of the records with the one from 7 days being a bit better and c their entropies exhibit similar decays even if they are noticeably imperfect with the one based on 30 days being less biased these trends are reflected in the nash sutcliffe efficiencies for these attributes see table 1 a negative values for autocorrelations nsea that reflect the high variability and near zero values for correlations b values close to one hundred percent for histograms nseh and c medium numbers for entropies nsee with the fm representation based on 30 day aggregations being better as seen graphically finally it is worth comparing the three downscaled sets at the laikakota site based on some extreme information for both large and small values in this regard the last two columns in table 1 include first for large values the percent histogram mass in fm sets corresponding to the 90 decile of the records p d 90 and second for small values the number of zeros in a set nz comparing observed records with fm downscales with the former shown in parentheses as seen and as hinted from the histograms the fm downscaled set from records every 7 days is a bit better in p d 90 as instead of fitting the prescribed 90 the other two fm representations have higher but close values of 93 and 92 regarding the number of zeros the set found via 14 days is found to be better 163 vs 174 with the other disaggregation scales yielding sets having more zeros than those found in the records 201 and 202 vs 174 4 2 rainfall set from tinkham washington figs 5 and 6 show the counterparts of figs 3 and 4 for rainfall records gathered in tinkham washington state for water year 1995 as seen at the daily scale first row of fig 5 this series made of 365 values when compared with the one for laikakota in fig 3 appears to be more complex this highly intermittent set contains many up and down swings and has a large peak within the first two months which is followed by a collection of several peaks exhibiting mainly a decreasing trend until the middle of the water year as may be seen on the left of fig 5 when the records are aggregated over 7 14 and 30 days the decaying trend from the main peak to the future remains but as expected the increased smoothing makes the patterns less variable similar to the case for laikakota usage of a threshold on a derived measure obtained via a fractal function generated by the iteration of three maps as in fig 1 but with parameters different from such a figure results in reasonable fm representations at the 7 14 and 30 day resolutions first and second columns of the bottom three rows in fig 5 with fm parameters included in the fourth to sixth rows of appendix a even though the locations of the fm peaks in gray are not identical to those of the records in black and the actual magnitudes are overestimated especially at the 14 day resolution all sets do exhibit similar textures and result in very close fittings of the accumulated records such reasonable fittings on coarser scales are supported by the smaller values of re a c and me a c see table 1 for tinkham with 2 9 and 8 2 at the weekly scale 3 0 and 9 6 at the biweekly scale and 2 0 and 4 8 at the monthly scale notice how these numbers are comparable to those found for the laikakota site even if the records for tinkham reflect a longer water year length equal to the whole calendar year the closer renderings on biweekly and monthly scales give rise as previously found for laikakota to positive nash sutcliffe efficiencies at those scales see nse d c but the negative value obtained at the 7 day scale confirms the complex nature of the records similar to the case for laikakota usage of a threshold on a derived measure obtained via a fractal function generated by the iteration of three maps as in fig 1 but with parameters different from such a figure results in reasonable fm representations at the 7 14 and 30 day resolutions first and second columns of the bottom three rows in fig 5 with fm parameters included in the fourth to sixth rows of appendix a even though the locations of the fm peaks in red are not identical to those of the records in black and the actual magnitudes are overestimated especially at the 14 day resolution all sets do exhibit similar textures and result in very close fittings of the accumulated records such reasonable fittings on coarser scales are supported by the smaller values of re a c and me a c see table 1 for tinkham with 2 9 and 8 2 at the weekly scale 3 0 and 9 6 at the biweekly scale and 2 0 and 4 8 at the monthly scale notice how these numbers are comparable to those found for the laikakota site even if the records for tinkham reflect a longer water year length equal to the whole calendar year the closer renderings on biweekly and monthly scales give rise as previously found for laikakota to positive nash sutcliffe efficiencies at those scales see nse d c but the negative value obtained at the 7 day scale confirms the complex nature of the records although noticeable differences in daily downscales at all resolutions are observed in the third column of fig 5 the last column there reveals that all disaggregated fm representations using exactly the same parameters optimized at the coarser scales yield equally good accumulated sets certainly to the naked eye the three fm mass functions follow the accumulated trends well and such is reflected by the rather small and similar values of re a f and me a f see center of table 1 which are close to those obtained by the optimization exercise with values of about 3 0 and 9 6 respectively these numbers when compared with encodings of the daily records themselves reveal that the downscaled sets do not follow the accumulated records as closely as it may be modeled by an fm fit at the daily scale this is the case as the smallest re a f and me a f values possible via the fm approach are 1 1 and 4 4 maskey et al 2016a which once again are less than half of what the downscaled sets portrayed in fig 5 yield this result is consistent with what was reported earlier for the rainfall set from laikakota although the accumulated sets look similar surely the naked eye cannot be fooled while comparing the fm sets themselves on the third column in fig 5 as mentioned earlier these sets are clearly different and no doubt exhibit distinct intermittencies in this regard what was found at laikakota extends to tinkham regarding the nash sutcliffe efficiency of the records at the finer resolution such a statistic nse d f reflects the complexity of the records and the fm sets and degrades with an increased scale of the records from 27 at the weekly scale to 111 at the monthly scale see table 1 which as mentioned earlier is not uncommon even while encoding the information maskey et al 2016a as illustrated in fig 6 for the tinkham rainfall set the quickly decaying autocorrelation function the concentration of the histogram on small values and the decrease of the rényi entropy function are nicely preserved for this rainfall set by all fm representations these features not included in the optimization exercise give rise to low nash sutcliffe efficiencies for autocorrelations nsea once again due to rather small statistically insignificant oscillatory values and to high nash sutcliffe efficiencies for both the histogram and the entropy function nseh and nsee with values that are higher than 98 and 56 respectively and with the set based on the biweekly scale yielding a remarkable preservation of the entropy see table 1 as may be seen on the last columns of table 1 for the extreme information related to the tinkham sets the large values at a 90 level p d 90 are overestimated by the fm downscales at the weekly and biweekly scales 95 and 91 respectively although such is perfectly fitted at the monthly scale as found for laikakota there is no clear relation between the fitting of large and small values for the number of zeros recorded in the set 198 days may be under or over estimated by the fm representations i e 199 192 and 226 days see table 1 altogether however the obtained downscales may be termed adequate to represent rainfall at this site at the daily scale 4 3 remarks on rainfall downscaling the above analysis and results of downscaling of rainfall data from three coarser scales weekly biweekly and monthly to daily scale for the two distinct sites in different countries laikakota bolivia and tinkham washington state usa reveal that the fm approach is capable of representing the overall trends and intermittent features of the rather complex rainfall records in a reasonable albeit imperfect way although the nash sutcliffe values obtained for the downscaled data at the daily scale may be negative compared to the positive values of greater than 63 8 for the weekly aggregated records found from daily encodings maskey et al 2016a the geometric shapes of the downscaled data do provide relevant and certainly useful information at the very least from a simulation point of view clearly the usage of other solutions of the optimization exercise provides yet other alternative fm representations for various scales that may also be used in practical applications for planning and design purposes fig 7 illustrates such an idea based on the weekly scale at the tinkham site for three other solutions of the associated inverse problem as included in the seventh to ninth rows in appendix a and from top to bottom as in the figure the modeled daily sets in fig 7 have similar textures to those shown in fig 5 and their statistical features not presented here are also found to be in reasonable agreement with those presented in table 1 for the other sets all these results suggest that the fm approach yields sensible realizations akin to random ones obtained via stochastic disaggregation methods even if the magnitude of the peaks shown is smaller these therefore are clearly alternative representations that while following the overall location of the rain throughout the year still maintain the highly intermittent nature of the records 5 downscaling of streamflow sets this section reports the analysis of streamflow downscaling using the fm approach for this purpose streamflow data from the sacramento river measured near freeport california usgs station 11447650 is considered similar to what was done for rainfall in the previous section the fm approach is applied to downscale streamflow to the daily scale from 7 14 and 30 day aggregated sets two different water years having distinct geometries are considered to validate the method years 2005 and 2008 both from october 1 to september 30 of the following year for the daily data set and consequently the aggregated 7 14 and 30 days a constant base flow equal to the minimum in the records is subtracted from the raw daily data so that the fm approach may better fit those records after normalizing an obtained streamflow sets downscaling of streamflow is attempted using a fractal interpolating function based on the iteration of three maps adding a local smoothing just for appearance purposes and based on our previous experience maskey et al 2016b of 5 days as illustrated in fig 2 at the end the fm representations depend on only 9 free parameters as the smoothing is always set at the 5 day level the representations whose parameters are included in the last six rows of appendix a hence correspond to a compression ratio at the daily scale of 365 9 or 40 1 to further illustrate the abilities of the fm approach to disaggregate streamflow and perhaps other mildly intermittent hydrologic records the results that follow include a modification to the definition of optimality at the coarse scale while calculations are guided by the same objective function as in the rainfall studies earlier i e the root mean square error of accumulated coarse data re a c and subject to due penalties the best results are defined herein from the minimum of the maximum error in accumulated coarse data me a c this is done in the spirit of the kolmogorov smirnov test for comparing two distributions and as a means of performing a sensitivity analysis on the choice of the objective function figs 8 and 9 present the streamflow downscaling results for water year 2005 and figs 10 and 11 include the results for water year 2008 figs 8 11 are similar to figs 3 6 presented earlier for rainfall with the distinction that the observed records at the fine scale are now plotted on top of the obtained downscales for the two water years while figs 8 and 10 present the original daily data sets and their accumulated sets with actual records in black and fm representations in gray figs 9 and 11 display their respective autocorrelation histogram and entropy in what follows a step by step description of the obtained fm downscaled sets for the two water years is presented figs 8 and 9 present the streamflow downscaling results for water year 2005 and figs 10 and 11 include the results for water year 2008 figs 8 11 are similar to figs 3 6 presented earlier for rainfall with the distinction that the observed records at the fine scale are now plotted on top of the obtained downscales for the two water years while figs 8 and 10 present the original daily data sets and their accumulated sets with actual records in black and fm representations in red figs 9 and 11 display their respective autocorrelation histogram and entropy in what follows a step by step description of the obtained fm downscaled sets for the two water years is presented 5 1 streamflow set from the sacramento river water year 2005 fig 8 shows the original data in black at the daily scale right and the aggregated weekly biweekly and monthly data of streamflow records minus base flow for the water year 2005 as seen these records are much less intermittent when compared to the rainfall sets studied earlier and contain at the resolutions shown three main peaks located around the central portion of the water year with the last one being the largest fig 8 also includes the three optimal fm representations in gray found from the three coarse scales left blocks and the corresponding fm disaggregations in gray at the daily scale right blocks notice the rather faithful fm fits for all coarse scales on the left which result in accurate preservations of the main peaks in the sets this is corroborated by the error measures included in table 1 third horizontal block fig 8 shows the original data in black at the daily scale right and the aggregated weekly biweekly and monthly data of streamflow records minus base flow for the water year 2005 as seen these records are much less intermittent when compared to the rainfall sets studied earlier and contain at the resolutions shown three main peaks located around the central portion of the water year with the last one being the largest fig 8 also includes the three optimal fm representations in red found from the three coarse scales left blocks and the corresponding fm disaggregations in red at the daily scale right blocks notice the rather faithful fm fits for all coarse scales on the left which result in accurate preservations of the main peaks in the sets this is corroborated by the error measures included in table 1 third horizontal block as seen the root mean square error in accumulated sets re a c and maximum error in accumulated sets me a c the new optimal are always less than a mere 0 7 and 3 9 for all coarse representations and the nash sutcliffe efficiencies for those coarse records at all scales nse d c are always above a healthy 84 of all coarse representations and somewhat surprisingly given the opposite trends found in rainfall the one found for weekly records is the best with re a c equal to 0 7 and me a c equal to just 1 5 this is certainly much better than what was found for rainfall data i e four times in the former and about 6 times in the latter attribute altogether the nash sutcliffe efficiencies nse d c do increase with coarser records as reported in the rainfall cases before fig 8 also shows right blocks the downscaled patterns at the daily scale as seen the obtained set based on the weekly scale top gives the best following of the major peaks as the first one is missed just by a few days and the two others are preserved almost perfectly in timing and magnitude the daily representations emanating from 14 and 30 days do exhibit patterns that follow the main peaks but with noticeable over estimation for instance the one from the biweekly scale over predicts the second peak while the one from the monthly scale over predicts the third peak altogether the accumulated daily sets from the downscaled sets rather closely follow those at the fine scale i e the original daily records this is confirmed in table 1 third block center columns for the statistics at the fine scale re a f and me a f which are less than 1 2 and 3 9 respectively and comparable to what is found while encoding the daily records themselves notice that errors at the coarse and fine scales corresponding to the 7 day scale are identical i e re a c r e a f 0 7 and me a c m e a f 1 5 indicating an excellent preservation of the accumulated records by such downscales observe also that while the maximum accumulated errors are maintained for the other two sets i e me a c m e a f the process of disaggregation degrades the root mean square errors on the accumulated streamflow i e re a c r e a f obviously the downscaled daily data from the 7 day scale most closely resembles the original daily flows and such is also reflected by the nash sutcliffe efficiency for the daily disaggregated data n s ed f which remains high at a rather healthy 73 the statistical attributes in fig 9 further imply that the fm based disaggregation approach performs very well at all aggregation scales considered notice the close following of the record s autocorrelation function and histogram albeit not perfect and the rather close fits and almost perfect of the entropy function this is also reflected in table 1 third block right columns by the rather high nash sutcliffe efficiency indices for such attributes that are quite close to 100 and the excellent fit of the extreme records at the 90 level it is worth mentioning that it is hard to distinguish the quality of the three downscales just based on these statistics an indication that the geometric fm method provides good downscales for this water year 5 2 streamflow set from the sacramento river water year 2008 fig 10 presents the key graphs of the results of fm fits and downscales for water year 2008 as seen the original daily records in black contain three sharp peaks in succession which remain at the 7 day scale but that are smoothed out at the 14 and 30 day scales as observed on the left blocks in fig 10 the fm representations of the coarse records are excellent both in accumulated records and in the data with the latter particularly good for the two smoothed sets i e 14 day and 30 day this is reflected in table 1 last block left columns by comparable and small values of re a c and me a c i e less than 0 8 and 2 5 respectively and by nse d c values that range as the aggregation increases from 82 to 95 to 98 certainly remarkable numbers regarding the downscaled daily comparisons right block of fig 10 while the accumulated sets yield by eye very similar behavior corroborated by close values of re a f and me a f which are close to those at the coarse resolution and to those found from fm encodings of the daily set see central columns of the last block on table 1 the sets themselves have varying qualities as follows the disaggregated pattern found for 7 days emanating from an fm fit that captures well the last two sharp peaks not surprisingly preserves the timing and overall shape of the same peaks the pattern associated with the 14 day scale yields essentially similar shapes at the fine right and coarse left resolutions and as a consequence it misses the structure of the three peaks even if the overall volume is correct finally the downscaled daily set based on the 30 day fm disaggregation surprisingly captures the overall sense of the three peaks on the daily records curiously the optimal solution spanning from the 30 day scale is equally good as the one done on a weekly basis as is seen in table 1 for the ns d f attribute which exceeds a rather high magnitude of 72 in both cases the graphs in fig 11 show the statistical information of the fm downscaled data and the pertinent statistical qualifiers are presented in table 1 last horizontal block right columns as seen all the autocorrelations generally follow the overall decay in the records although they miss the first noticeable dip the nsea values are rather good with greater than 92 and better than what was reported earlier for the 2005 streamflow set the histograms for the downscaled data for water year 2008 show in general more variation than those for water year 2005 and degrade in quality as the scale is increased contrary to what was found for water year 2005 the nseh values decay from 89 to 78 and to 73 and as such the set implied by the 30 day scale no longer competes with the one based on 7 days although the p d 90 values are close to one another 89 vs 87 as seen in fig 11 and table 1 all sets provide close fittings of the entropy function of the records with nsee values in excess of a high 91 in summary the application of the fm based disaggregation model to streamflow records yield very good results and much better than what was found for rainfall these very good results for streamflow are to be expected given the smoother nature of the records when compared to rainfall 6 concluding remarks this study has proposed a deterministic geometric fractal multifractal fm approach to downscale hydrologic records specifically rainfall and streamflow the proposed approach for temporal downscaling is an adaptation of the original fm approach for encoding of records puente 1996 which adds a threshold for rainfall and local smoothing for streamflow by studying two rainfall records from laikakota bolivia and tinkham washington state usa and two streamflow records from the sacramento river usa the fm based method has been shown to be an effective and efficient tool for downscaling especially for streamflow sets as the notions are based on accumulated records it is envisioned that the geometric downscaling approach may also be applied using data gathered at a coarse scale over not just one but multiple years the results from this study clearly indicate that the deterministic fm geometric procedure when coupled with an effective optimization procedure for the inverse problem for a given target set at a coarse resolution not only encodes coarse scale records i e weekly biweekly and monthly but also generates plausible downscale representations at least for simulation purposes at the finer scale i e daily such a novel approach yielding compression ratios as high as 37 1 for rainfall sets and 40 1 for streamflow records may therefore supplement existing stochastic downscaling methods supporting the notion of hidden determinism in natural complexity puente 1996 puente and sivakumar 2007 the proposed downscaling technique in conjunction with simulations that may be obtained via the fm approach maskey et al 2016c 2017 may certainly increase the flexibility for generating time series in a multisite or multi season framework as done by other approaches e g salas et al 1995 as the same number of fm parameters define both coarse and fine sets the evolution of the inherent complexity in the physical processes may be studied based on them it is envisioned that a sensible application of the fm based disaggregation could be the temporal downscaling of coarse scale outputs from global circulation models gcms to catchment scale hydrologic variables in order to assess the impacts of climate change on hydrology and water resources in a region acknowledgements the research leading to this article was supported by a jastro award provided to the first author by the university of california davis we are thankful to ministerio de medio ambiente y agua bolivia for providing rainfall records gathered at laikakota and also to the team of national resource conservation service for the availability of rainfall records in its web portal bellie sivakumar acknowledges the financial support from the australian research council arc through the future fellowship grant awarded to him ft110100328 the team of usgs service is also greatly appreciated for making the historical streamflow records available in its web portal comments from anonymous reviewers helped us improve the manuscript and are gratefully acknowledged appendix a 
6826,a deterministic geometric approach the fractal multifractal fm method is proposed to temporally downscale disaggregate rainfall and streamflow records the applicability of the fm approach is tested on 1 two sets of rainfall records one from laikakota bolivia and the other from tinkham washington usa and 2 two distinct sets of streamflow records for water years 2005 and 2008 from the sacramento river california usa for the purpose of validation the available daily records are first aggregated into weekly biweekly and monthly records and then the fm method is applied to downscale such sets back into the daily scale the results indicate that the fm method coupled with a threshold to capture the high intermittency of rainfall and a smoothing parameter to get the milder texture of streamflow readily generates daily series over a year based on weekly biweekly and monthly accumulated information which reasonably preserves the time evolution of the records especially for streamflow and captures a variety of key statistical attributes e g autocorrelation histogram and entropy it is argued that the fm deterministic downscalings may enhance and or supplement available stochastic disaggregation methods keywords disaggregation fractal multifractal deterministic rainfall streamflow list of acronyms x τ t τ observed records at scale τ x τ t τ fm fitted set at scale τ a x τ t τ observed accumulated records at scale τ a x τ t τ fm fitted accumulated set at scale τ r τ t τ observed rainfall at scale τ a r τ t τ observed accumulated rainfall at scale τ q τ t τ observed streamflow at scale τ a q τ t τ observed accumulated streamflow at scale τ rmse a τ root mean square error in accumulated sets at scale τ maxe a τ maximum error in accumulated sets at scale τ re a c root mean square error in accumulated sets at coarse scale me a c maximum error in accumulated sets at coarse scale nse d c nash sutcliffe efficiency for data at coarse scale re a f root mean square error in accumulated record at fine daily scale me a f maximum error in accumulated record at fine daily scale nse d f nash sutcliffe efficiency for data at fine daily scale nsea nash sutcliffe efficiency for autocorrelation nseh nash sutcliffe efficiency for histogram nsee nash sutcliffe efficiency for entropy nz number of zeros in a rainfall set p d 90 percent histogram mass in fm fitted records corresponding to 90 in observed data 1 introduction the general lack of high resolution hydrologic information both in time and in space limits our ability in the proper design simulation and operation of many water resources infrastructures such as those associated with flood control and urban drainage a common practice to overcome this problem is to disaggregate downscale information available at a coarse scale into finer scales through some downscaling techniques such disaggregation approaches are generally designed to preserve some basic statistical characteristics of the records including low order moments autocorrelations power spectra and multifractal properties among others a large number of temporal disaggregation approaches and models exist in the literature very early disaggregation models were generally based on statistical notions e g pattision 1965 grace and eagleson 1966 bras and rodriguez iturbe 1976 that preserve suitable moments some key contributions in this area are as follows valencia and schaake 1972 1973 introduced a linear disaggregation model aimed at the preservation of low order moments at various scales yearly monthly and daily however this model does not account for the rather skewed distributions and highly intermittent character of rainfall subsequently mejia and roussellee 1976 tao and delleur 1976 hoshi and burges 1979 todini 1980 stedinger and vogel 1984 hershenhorn and woolhiser 1987 and connolly et al 1998 among others popularized such a linear disaggregation model with important modifications to the underlying notions and implementation procedures despite the improvements in these models and their applications limitations in such approaches continue to be highlighted for instance this class of models in truth belongs to a class of parametric techniques that requires prior assumptions about the probability distributions of the model parameters e g alvisi et al 2015 looking for an improved approach koutsoyiannis and xanthopoulos 1990 introduced a single site dynamic disaggregation model as a step wise procedure which accounts for low level variables to combine rainfall model with markovian structures and normal or gamma distributions employing such a model koutsoyiannis 1992 converted a sequential simulation model into a disaggregation model so that the output could explicitly preserve second order statistics of low level variables at the finer time scale later on koutsoyiannis 1994 noted that these models are not applicable for short scale rainfall disaggregation but that they could be improved by making use of properties of gamma distributions he also suggested the possibility to link them with a markovian structure relying on only three parameters and that this notion could be used to solve the engineering problems that seek defining a design storm however zarris et al 1998 argued that such an approach defined for flood frequency curves may not be adequate for continuous sets in light of the fact that natural records as measured around the world and commonly used in scientific investigations are rather complex and intricate the late great mathematician benoit mandelbrot suggested that geophysical records could exhibit a form of statistical self similarity that possibly bridges various temporal and spatial scales via a concept now known as multifractality mandelbrot 1982 1989 following such a lead a number of studies have implemented stochastic fractal multifractal theories in order to deal with the erratic and intermittent patterns of rainfall streamflow and other geophysical sets at hand see for example gupta and waymire 1990 tessier et al 1993 and lovejoy and schertzer 2013 among others using these notions olsson 1998 evaluated the possibility of modeling and disaggregating temporal rainfall using a multiplicative cascade model which had the ability to preserve the scaling behavior of the records this model was subsequently tested by olsson and berndtsson 1998 who showed that the model may account for seasonal non stationarities such was also considered by güntner et al 2001 who by studying issues regarding the transferability of parameters identified the reasons why the autocorrelation function may be underestimated and why the model may overestimate extreme events while classical and multifractal stochastic disaggregation models produce reasonable realizations of rainfall and streamflow processes other approaches have also been tried searching for better outcomes for instance lall 1995 proposed a nonparametric procedure that captures the nonlinearities present in the records and kumar et al 2000 employed such a method to disaggregate daily streamflow and to approximate the probability distribution of a disaggregated streamflow vector at multiple sites based on such nonparametric notions prairie et al 2007 proposed a technique for space time disaggregation of streamflow which ended up stressing that the nonlinear character of streamflow and other hydrologic processes cannot be disaggregated using traditional techniques due to a high dimensionality problem continuing with alternative approaches and in recognition of the presence of chaotic behavior in geophysical processes e g lorenz 1963 and in their transformation between different scales sivakumar 2001 explored the presence of chaos in rainfall time series observed at four different temporal scales in the leaf river basin mississippi usa using phase space reconstruction and correlation dimension the outcomes of such a study led sivakumar et al 2001 to investigate the possibility of using chaos theory to transform rainfall from one scale to another analyzing the dimensionality of the weights of the rainfall distribution between any two scales using the correlation dimension method and identifying the presence of chaotic behavior in such weights sivakumar et al 2001 also proposed a chaotic model for rainfall disaggregation based on an approach that uses local approximation in the reconstructed phase space sivakumar et al 2004 subsequently employed this approach to disaggregate streamflow in the mississippi river basin at st louis missouri usa despite the encouraging outcomes from chaos theory based studies in hydrology some criticisms of such studies have been raised see schertzer et al 2002 and sivakumar et al 2002 for a discussion a comprehensive account of the applications of chaos theory in hydrology including for rainfall and streamflow disaggregation is presented in sivakumar 2017 on a systematic practical setting lanza et al 2001 reviewed several works on rainfall downscaling techniques and pointed out that direct validation of downscaling approaches is problematic due to a lack of reliable measurements pointing out that the absence of high resolution rainfall records clearly introduces uncertainties in the rainfall runoff processes involved they emphasized the need to conduct standard synthetic tests in order to fully compare the different approaches koutsoyiannis 2003 and koutsoyiannis et al 2003 provided a general overview of the development of rainfall disaggregation models most of which generate synthetic time series for partial durations recently an ensemble downscaling method has been proposed by combining different sources of information for instance liu et al 2016 introduced an approach that couples a bayesian model and ensembles from three statistical downscaling methods to provide a scientific basis for the study of runoff response to climate change one based on a support vector machine aimed at capturing nonlinear regression relationships between variables another on a weather generator scheme to yield long time series as needed in the risk analysis of climate change and a third based on statistical downscaling model as a decision support tool such a study demonstrated the better performance of the ensemble downscaling method based on bayesian model averaging than a single statistical downscaling approach the downscaling techniques summarized above could be based on either stochastic or dynamical models however either type of models has its own limitations stochastic techniques e g regression models weather generators are based on simplified assumptions require substantially long records and large number of parameters and are seldom capable of preserving the finer details present in hydrologic records dynamical techniques on the other hand turn out to be computationally intensive see fowler et al 2007 for details especially in the context of downscaling approaches in time and space for global climate model outputs to deal with the intricacies inherent in natural records puente 1996 had earlier introduced the notion that a given seemingly random set could be represented as a fractal transformation of a multifractal measure as a consequence a procedure named the fractal multifractal fm method was introduced which besides being assigned a physical interpretation cortis et al 2013 a is capable of producing a vast class of patterns defined over one and higher dimensions that look like natural sets and b gives sets that may be conditioned to capture the overall trends and inherent details present on available records beyond the preservation of some relevant statistical attributes such as moments autocorrelation function power spectrum and multifractal spectrum upon its discovery the fm method has been found useful in various applications that include among others a the encoding of various rainfall events lasting a few hours e g puente and obregón 1996 cortis et al 2009 2013 huang et al 2013 b the modeling of spatial contamination patterns in groundwater puente et al 2001a b c the encoding of daily precipitation maskey et al 2016a puente et al 2018 d the encoding of streamflow gathered daily over a year maskey et al 2016b and e the simulation of daily rainfall maskey et al 2016c and of daily streamflow maskey et al 2017 the encouraging outcomes from these applications suggest the possibility of using the fm approach also for temporal downscaling of hydrologic data herein we propose an fm approach for downscaling rainfall and streamflow records we validate the approach 1 on rainfall using one year of data each from laikakota bolivia and tinkham washington state usa and 2 on streamflow employing two different years of data from the sacramento river california usa having available daily records at such sites we first aggregate such data to weekly biweekly and monthly scales and then use the fm method to disaggregate to daily scale to compare with the original records the rest of this article is organized as follows section 2 re visits the original fractal multifractal approach and presents adaptations used here to encode both rainfall and streamflow sets section 3 explains how the fm method is used in order to define specific downscales section 4 presents the results and discussion for the obtained disaggregated patterns for rainfall and section 5 reports such for streamflow section 6 summarizes the findings and provides remarks for further research 2 the fractal multifractal method and adaptations for rainfall and streamflow according to the fm framework geophysical records may be represented geometrically and in a system theoretic sense as outputs derived distributions produced by a complex system defined by a fractal interpolating function when the inputs to the system are also complex multifractal measures puente 1996 this section briefly explains the fm approach and provides adaptations of the original notions that allow the method to be used to represent highly intermittent records e g daily rainfall sets and mildly intermittent records e g daily streamflow sets 2 1 theoretical framework following barnsley 1988 a fractal interpolating function f defined from x into y i e f x y and passing through n 1 pre specified points x n y n satisfying x 0 x 1 x n is obtained iterating n simple affine maps from the plane to the plane i e from x y to x y of the special form 1 w n x y a n 0 c n d n x y e n f n n 1 n when these maps are constrained so that they contract the space in x 2 w n x 0 y 0 x n 1 y n 1 w n x n y n x n y n i e so that the n th map compresses the first and last interpolating points into inner interpolating points when the parameters d n are less than one in magnitude the iterations of such maps w n indeed define point by point the graph g of a function f i e g x f x x x 0 x n by doing so a set becomes the unique fixed point of the maps w n as successive calculations of images already in g in any order remain in the same graph i e g n 1 n w n g the conditions defined in eq 2 yield simple systems of linear equations that allow finding the coefficients a n c n e n and f n in terms of the coordinates by which the fractal interpolating function passes i e x n y n and also the parameters d n which given their usage in eq 1 are also known as vertical scalings barnsley 1988 at the end specifying the interpolating points and the scaling parameters allows defining via iterations a convoluted function f whose graph has a fractal dimension d 1 2 and hence its notation in a practical setting the graph of such a function f may be found indeed point by point iterating in any order the affine maps w n ultimately sampling the unique attractor g following a procedure known in the literature as the chaos game barnsley 1988 such a process starts at a point within g say an interpolating point and progresses as per arbitrary coin tosses or iterating proportions assigned to the n maps after enough iterations the process not only converges to the graph of a function f but also induces a unique invariant measure a distribution over g as well the latter when projected over the x and y coordinates yields interesting histograms that typically exhibit non trivial intermittencies and possesses multifractal properties these sets turn out to be inherent to the calculations and may be displayed at arbitrary scales just by varying the size and number of bins used to get the histograms while the natural projection over x is a deterministic multinomial multifractal measure dx generated via a multiplicative cascade e g mandelbrot 1989 puente 1996 the projections dy over y are deterministic derived distributions of dx via a fractal function f which typically resemble complex natural patterns puente 1996 2004 these notions turn out to be akin to a generalization of the description of turbulent dissipation as a random binomial multifractal meneveau and sreenivasan 1987 and also to the construction of other intermittent sets as random realizations of levy processes from universal multifractals lovejoy and schertzer 2013 as mentioned earlier the outcomes produced by the fractal multifractal method could also be interpreted physically as specific realizations of a non trivial multiplicative cascade process in a way that a generic derived measure dy represents a suitable geometric entity to represent natural phenomena cortis et al 2013 these abstract ideas are further illustrated next as used to represent both highly intermittent rainfall sets and mildly intermittent streamflow series so that the reader may better follow the notions the next sections will be based on specific numerical examples 2 2 fm representation of rainfall sets fig 1 illustrates how the fm notions may be used to model highly intermittent sets as shown there is a fractal function f 1 passing through the four interpolating points 0 0 0 28 1 12 0 78 2 62 1 1 shown as filled circles and induced via the iteration of the three maps 3 w 1 x y 0 28 0 1 75 0 63 x y 4 w 2 x y 0 50 0 3 89 0 14 x y 0 28 0 78 5 w 3 x y 0 22 0 3 63 0 27 x y 1 12 2 63 playing the chaos game according to proportions in order 52 2 and 46 these maps all having the structure of eq 1 and with coefficients defined while satisfying the contracting conditions in eq 2 have vertical scalings d 1 0 63 d 2 0 14 and d 3 0 27 and transform the domain 0 1 in x into the sub intervals in order 0 0 28 0 28 0 78 and 0 78 1 as shown in the figure the iterations induce in addition to the fractal function f 1 whose graph g 1 has a low fractal dimension of 1 03 projected histograms d x 1 and d y 1 of obtained values over x and y respectively which may be obtained at an arbitrary resolution just by having a suitable number of bins over which chaos game numerical calculations are grouped 273 bins for this particular example while d x 1 the horizontal input i e x vs d x 1 is a deterministic multinomial multifractal having almost a zero value in the middle due to the 2 weight assigned to map w 2 d y 1 the output plotted vertically i e y vs d y 1 is a deterministic derived measure i e d y 1 f 1 1 d x 1 in which a d y 1 value at a given level y is the sum of all events over x corresponding to such a level the object d y 1 akin to a distribution can therefore be explained as a transformation of a multiplicative cascade yielding in this example a highly intermittent set that resembles rainfall records gathered daily when y denotes time and d y 1 rainfall intensity fig 1 also includes on the right a set that results from an adaptation of the method which yields other derived sets that may be used to further approximate rainfall records containing yet additional intermittency and many more zeroes such an object named d y v to acknowledge a vertical cutoff i e in the y coordinate is naturally found from d y 1 by discarding traces below a threshold ϕ v as marked in the center plot this new set shown re normalized so that it integrates to one as d y 1 may be adjusted so that it better preserves natural records maskey et al 2016a 2016c 2 3 fm representation of streamflow sets fig 2 depicts the construction of a mildly intermittent derived distribution as before another fractal function f 2 passing through the four interpolating points marked 0 0 0 27 4 72 0 91 2 40 1 1 is defined via the iteration of the three maps and distinct from those used earlier given by 6 w 1 x y 0 27 0 5 24 0 52 x y 7 w 2 x y 0 64 0 2 63 0 31 x y 0 27 4 72 8 w 3 x y 0 09 0 4 28 0 87 x y 0 91 2 4 used according to the proportions in order 24 44 and 32 these maps all having the simple structure of eq 1 and with coefficients satisfying the contracting conditions in eq 2 have scalings d 1 0 52 d 2 0 31 and d 3 0 87 their iteration according to the aforementioned proportions result in the fractal function f 2 whose graph as seen requires more ink than the previous f 1 as its graph g 2 has a larger fractal dimension of 1 33 while the shown input d x 2 is still a rather intermittent multinomial multifractal no longer with close to zero values however the new output derived distribution d y 2 computed this time over 365 bins is smoother than d y 1 before as the bulkier fractal function f 2 adds an increasing number of events over x i e d y 2 f 2 1 d x 2 as such the deterministic histogram d y 2 i e y vs d y 2 becomes suitable for modeling mildly intermittent records like streamflow data gathered daily once again with y denoting time and d y 2 discharge fig 2 also includes on its rightmost plot a further adaptation for the encoding of streamflow records which consists of finding a new object d y s just for appearance purposes by performing local smoothing on the histogram d y 2 maskey et al 2016b 2017 in practice the modeling of a given rainfall or streamflow set requires the solution of an inverse problem over plausible fm parameters namely a the interpolating points through which a fractal interpolating function passes here assumed without lack of generality that the first and last points are 0 0 and 1 1 b the vertical scalings d n c the iteration frequencies associated with each map in chaos game calculations one minus the number of maps and d a vertical threshold for rainfall modeling or a smoothing parameter for streamflow calculations hence the usage of fractal functions defined via three affine maps as shall be used herein based on our previous experience requires a total of 10 fm parameters four interpolating coordinates x 1 y 1 x 2 y 2 three scalings d 1 d 2 and d 3 two iteration frequencies p 1 and p 2 p 3 1 p 1 p 2 and one extra parameter for the adaptation as defined above 3 fm temporal downscaling methodology this section describes the approach used herein to downscale disaggregate a given temporal set either rainfall or streamflow using the fm approach it also includes information pertaining to the evaluation of goodness of the proposed approach 3 1 from coarse to fine scales as explained in section 1 there is a multitude of methods that may be employed to disaggregate both rainfall and streamflow records here we propose based on the success of the fm notions maskey et al 2016a b puente et al 2018 an alternative geometric approach for temporal disaggregation from a coarse resolution week biweek or month to a fine resolution day as follows 1 given records depths or volumes at a coarse resolution say every τ days and for a total of n periods x τ t τ such a set is first normalized so that it integrates to one then its corresponding accumulated set i e mass function a x τ t τ is upgraded so that a x τ 1 0 and in such a way that a x τ m τ 1 where m τ n 2 2 with the normalized accumulated records at resolution τ a x τ t τ specified such a set becomes a target for a suitable representation via the fm approach this entails finding the best fm parameters θ τ minimizing the square errors of the available m τ accumulated values and following a numerical optimization approach 3 if the calculations are performed in such a way that internal fm computations happen at the daily scale i e employing precisely n τ bins in chaos game histogram calculations while accumulating at the τ scale for optimization purposes the implicit derived measure dy within the procedure and at the daily scale would automatically be an estimate for downscaling the normalized information at the fine scale 4 when such a set is de normalized by the total depth or volume for such a coarse set a disaggregated fm representation of the geophysical process is found in the present study these notions are tested for downscaling rainfall and streamflow records from resolutions of τ 7 weekly 14 biweekly and 30 days monthly into daily sets certainly the notions could also be used in a similar fashion to obtain temporal downscales involving arbitrary scales that is finer than daily 3 2 solution strategy the computation of fractal functions and projections associated with the fm approach happens to be a rather efficient procedure however as there are no analytical formulas for the derived measures finding an fm representation for a given set requires a numerical scheme for solving an inverse optimization problem as illustrated in section 2 the search space when iterating three maps requires searching in 10 dimensions but such is no obstacle for finding suitable solutions based on our experience a heuristic optimization scheme a generalized version of the particle swarm optimization algorithm may be used to find a close solution of an fm inverse problem fernández martinez et al 2010 huang et al 2013 maskey et al 2016a in particular and to circumvent the dimensionality of the search procedure the searches for the highly intermittent rainfall and mildly intermittent streamflow records herein are performed as follows while the rainfall records employ 200 randomly generated swarms made up of 500 fm parameter values the smoother streamflow sets use 100 randomly selected swarms containing only 300 fm parameter sets then all such swarms are allowed to evolve having all members as leaders for 300 iterations for rainfall and only 80 for streamflow at the end the best solution found over all swarms even if a local optima is considered to be the optimal solution as shall be seen the notions yield reasonable results and finding such parameters only takes a day of computation for rainfall and 4 h for streamflow on a personal computer as mentioned in section 3 1 the objective function used in the calculations is defined as in previous studies e g obregón et al 2002a b huang et al 2012 2013 maskey et al 2016a b specifically the l 2 norm i e the root mean square error of the coarse accumulated records every τ days vs the accumulated fm approximations also every τ days over the number of such periods over a water year is minimized mathematically such an objective function is defined as 9 rmse a τ 1 m τ t τ 1 m τ a x τ t τ ax τ t τ 2 where m τ is the number of periods in increments of τ days and a x τ t τ and a x τ t τ are the accumulated records and accumulated fm related fits as defined in section 3 1 attempting to ensure that fm solutions share similar geometrical features with a target set the aforementioned objective function is penalized so that a the maximum deviations between the measured and the fm fitted records maxe a τ should not exceed a value of 10 on any given period considered and b the discrepancy between the length of the fm data set and that of the observed set from beginning to end and over the periods should be less than 5 of that of the observed set for downscaling of rainfall an additional penalty is imposed so that the number of zeros no rain events present in the fm representation will not be more than 10 of those in the actual set 3 3 assessment of model performance to validate the quality of the proposed fm approach in the context of downscaling observed data sets at the daily scale are employed this readily allows calculation of aggregated sets at a scale τ to be fitted by the fm method and then the performance of the disaggregation notions is validated using the original records at the finer resolution the performance evaluation is done in terms of various statistics not included in the optimization exercise and also extended to the daily fm sets such include the root mean square error the maximum error in the accumulated set and the nash sutcliffe efficiency for the implied data both at the τ coarse scale employed in the optimization re a c me a c and nse d c and at the disaggregated daily fine scale re a f me a f and ns ed f moreover comparison visual validation is made by plotting the implied records at the distinct scales and by including at the daily scale only the autocorrelation function ρ histogram h and rényi entropy function e which are further compared in terms of nash sutcliffe efficiency values herein the rényi entropy function for the daily data is defined as 10 e 1 1 q log t 1 n x t q where x t is the rainfall or streamflow intensity or discharge value for day t observed or fitted n is the number of days of activity in a year and q is a weight that varies from 5 to 5 for streamflow and from 0 1 to 5 1 for rainfall in order to avoid the presence of zero values the well known nash sutcliffe efficiency nash and sutcliffe 1970 for data sets or a given statistic is defined in a general sense as 11 nse 1 i 1 s r i r i 2 i 1 s r i r 2 where r i is the ith statistical value or value for an observed set r is the mean of such a statistic or value over the total number of statistics values considered s and r i is the ith statistic fitted value for an fm downscaled set 4 downscaling of rainfall records to establish the applicability of the fm based downscaling approach in the context of rainfall records 7 14 and 30 day accumulated records i e weekly biweekly and monthly scales computed from available daily records are analyzed at two sites one from laikakota bolivia for water year 1966 from september 1 1965 to may 31 1966 and spanning 273 days and the other from tinkham washington state usa for water year 1995 from october 1 1994 to september 30 1995 and spanning the whole 365 days as mentioned before rainfall data sets are normalized so that the accumulated volume becomes a unity prior to using the fm method at all scales as experience suggests that the inherent complexity in the daily sets may itself be achieved by the fm method employing three maps plus further trimming below a threshold maskey et al 2016a highly intermittent representations as in fig 1 are employed that rely on the 10 fm parameters defined by the end of section 2 yielding at the daily scale a compression ratio of 27 1 for laikakota and 37 1 for tinkham here the parameters including a vertical threshold are to be obtained numerically as explained in section 3 2 4 1 rainfall set from laikakota bolivia fig 3 presents the implementation of the fm method to the rainfall set from laikakota bolivia the two graphs on the top right portray respectively the measured daily rainfall set for water year 1966 and the corresponding accumulated rainfall over the water year comprising 273 days as may be seen the records exhibit noticeable intermittency contain three major peaks and have at least six distinct regions of sustained lack of rain the rough accumulated rain profile dips below the average slope line first but it then crosses it and remains above it at about four months into the season the next three rows in fig 3 present the results for 7 day 14 day and 30 day rainfall data shown in these plots are the real sets in black and the fm representations in gray including both the records and corresponding accumulated profiles the fm fittings at the 7 14 and 30 day scale are shown on the left and the corresponding fm downscales at the daily scale are depicted on the right an observant reader may notice that the construction of the derived measure d y v in fig 1 corresponds after due flipping to the 7 day downscale results in fig 3 i e the set shown on the third column and second row of the figure the actual values of the fm parameters for such sets at various disaggregation scales are included in the first three rows of appendix a the next three rows in fig 3 present the results for 7 day 14 day and 30 day rainfall data shown in these plots are the real sets in black and the fm representations in red including both the records and corresponding accumulated profiles the fm fittings at the 7 14 and 30 day scale are shown on the left and the corresponding fm downscales at the daily scale are depicted on the right an observant reader may notice that the construction of the derived measure d y v in fig 1 corresponds after due flipping to the 7 day downscale results in fig 3 i e the set shown on the third column and second row of the figure the actual values of the fm parameters for such sets at various disaggregation scales are included in the first three rows of appendix a as clearly seen in fig 3 for the accumulated rainfall plots t τ vs a r τ all optimized fm representations fit the accumulated records at all scales reasonably well although the overall geometries on the first column of the graph do show some imperfections in fitting the data itself their overall shapes follow closely the records and accumulated sets in gray on the second column this implies that the penalties imposed while doing the searches as described in section 3 2 are satisfied as may be verified from table 1 the root mean square errors at a coarse resolution obtained for the accumulated sets re a c are certainly rather small as they are in order 3 1 2 8 and 3 1 for fm representations at the 7 14 and 30 day scales the goodness of the fits may also be seen in the magnitude of the maximum errors in accumulated sets me a c which are for increasing scales 8 7 6 0 and 6 3 with the more complex set at the 7 day scale providing the largest deviation due to noticeable disparities by the end of the records as seen in the second column and second row in fig 3 the closer renderings on biweekly and monthly scales are corroborated by the positive nash sutcliffe efficiencies for the data in table 1 nse d c which are non trivial to achieve for such highly intermittent records maskey et al 2016a however the value of zero for such an attribute at the 7 day aggregation scale confirms the complexity of rain at the weekly scale as clearly seen in fig 3 for the accumulated rainfall plots t τ vs a r τ all optimized fm representations fit the accumulated records at all scales reasonably well although the overall geometries on the first column of the graph do show some imperfections in fitting the data itself their overall shapes follow closely the records and accumulated sets in red on the second column this implies that the penalties imposed while doing the searches as described in section 3 2 are satisfied as may be verified from table 1 the root mean square errors at a coarse resolution obtained for the accumulated sets re a c are certainly rather small as they are in order 3 1 2 8 and 3 1 for fm representations at the 7 14 and 30 day scales the goodness of the fits may also be seen in the magnitude of the maximum errors in accumulated sets me a c which are for increasing scales 8 7 6 0 and 6 3 with the more complex set at the 7 day scale providing the largest deviation due to noticeable disparities by the end of the records as seen in the second column and second row in fig 3 the closer renderings on biweekly and monthly scales are corroborated by the positive nash sutcliffe efficiencies for the data in table 1 nse d c which are non trivial to achieve for such highly intermittent records maskey et al 2016a however the value of zero for such an attribute at the 7 day aggregation scale confirms the complexity of rain at the weekly scale the third column and from the second to the fourth rows of fig 3 show the specific fm downscaling patterns obtained at the daily scale as may be seen the downscaled sets have intermittent textures similar to that of the original records and a reasonable following of the accumulated records this is especially the case for the fm disaggregations found from data gathered every 7 and 14 days as may be corroborated from the statistical information in table 1 sixth to eigth columns although the root mean square errors at the daily finer scale re a f remain close to the values found from the optimization exercises at the coarser resolutions from 3 to 4 3 the performance steadily degrades when the starting records to be fitted are coarser specifically the maximum errors in accumulated sets at the daily scale me a f increase from 8 7 up to 11 3 at the 30 day scale and the nash sutcliffe efficiencies for the daily rainfall data nse d f decay and become increasingly negative indicating the intrinsic difficulty in approximating rainfall sets notice that while these trends are to be expected for a coarser scale implies usage of less information a comparison with an fm encoding of the actual set at the daily scale is required to truly gauge the goodness of an fm disaggregation as the latter i e optimizing at the daily scale may be achieved with re a f and me a f values of 1 4 and 4 4 respectively maskey et al 2016a the obtained downscaled patterns having statistics that are at least twice such numbers see table 1 are not as tight to the records as possible notice however that the obtained patterns even from accumulated data every 30 days do look reasonable see fig 3 which implies that they may be considered at least as suitable simulations of the highly variable rainfall data at the site fig 4 shows the statistical information regarding the obtained daily downscales at laikakota as compared with the daily records such are left to right the autocorrelation function i e lag vs ρ the histogram i e bins vs h with a total of 10 bins based on the scale of the records and placing an fm value larger than the maximum in the last bin if needed and the rényi entropy function i e q vs e for the three fm daily sets presented in fig 3 in the same order 7 14 and 30 day scales from top to bottom as may be seen this information corroborates that all fm based downscales in gray are comparable as a their autocorrelation functions follow the overall decay present in the records black b their histograms are rather close to the one of the records with the one from 7 days being a bit better and c their entropies exhibit similar decays even if they are noticeably imperfect with the one based on 30 days being less biased these trends are reflected in the nash sutcliffe efficiencies for these attributes see table 1 a negative values for autocorrelations nsea that reflect the high variability and near zero values for correlations b values close to one hundred percent for histograms nseh and c medium numbers for entropies nsee with the fm representation based on 30 day aggregations being better as seen graphically fig 4 shows the statistical information regarding the obtained daily downscales at laikakota as compared with the daily records such are left to right the autocorrelation function i e lag vs ρ the histogram i e bins vs h with a total of 10 bins based on the scale of the records and placing an fm value larger than the maximum in the last bin if needed and the rényi entropy function i e q vs e for the three fm daily sets presented in fig 3 in the same order 7 14 and 30 day scales from top to bottom as may be seen this information corroborates that all fm based downscales in red are comparable as a their autocorrelation functions follow the overall decay present in the records black b their histograms are rather close to the one of the records with the one from 7 days being a bit better and c their entropies exhibit similar decays even if they are noticeably imperfect with the one based on 30 days being less biased these trends are reflected in the nash sutcliffe efficiencies for these attributes see table 1 a negative values for autocorrelations nsea that reflect the high variability and near zero values for correlations b values close to one hundred percent for histograms nseh and c medium numbers for entropies nsee with the fm representation based on 30 day aggregations being better as seen graphically finally it is worth comparing the three downscaled sets at the laikakota site based on some extreme information for both large and small values in this regard the last two columns in table 1 include first for large values the percent histogram mass in fm sets corresponding to the 90 decile of the records p d 90 and second for small values the number of zeros in a set nz comparing observed records with fm downscales with the former shown in parentheses as seen and as hinted from the histograms the fm downscaled set from records every 7 days is a bit better in p d 90 as instead of fitting the prescribed 90 the other two fm representations have higher but close values of 93 and 92 regarding the number of zeros the set found via 14 days is found to be better 163 vs 174 with the other disaggregation scales yielding sets having more zeros than those found in the records 201 and 202 vs 174 4 2 rainfall set from tinkham washington figs 5 and 6 show the counterparts of figs 3 and 4 for rainfall records gathered in tinkham washington state for water year 1995 as seen at the daily scale first row of fig 5 this series made of 365 values when compared with the one for laikakota in fig 3 appears to be more complex this highly intermittent set contains many up and down swings and has a large peak within the first two months which is followed by a collection of several peaks exhibiting mainly a decreasing trend until the middle of the water year as may be seen on the left of fig 5 when the records are aggregated over 7 14 and 30 days the decaying trend from the main peak to the future remains but as expected the increased smoothing makes the patterns less variable similar to the case for laikakota usage of a threshold on a derived measure obtained via a fractal function generated by the iteration of three maps as in fig 1 but with parameters different from such a figure results in reasonable fm representations at the 7 14 and 30 day resolutions first and second columns of the bottom three rows in fig 5 with fm parameters included in the fourth to sixth rows of appendix a even though the locations of the fm peaks in gray are not identical to those of the records in black and the actual magnitudes are overestimated especially at the 14 day resolution all sets do exhibit similar textures and result in very close fittings of the accumulated records such reasonable fittings on coarser scales are supported by the smaller values of re a c and me a c see table 1 for tinkham with 2 9 and 8 2 at the weekly scale 3 0 and 9 6 at the biweekly scale and 2 0 and 4 8 at the monthly scale notice how these numbers are comparable to those found for the laikakota site even if the records for tinkham reflect a longer water year length equal to the whole calendar year the closer renderings on biweekly and monthly scales give rise as previously found for laikakota to positive nash sutcliffe efficiencies at those scales see nse d c but the negative value obtained at the 7 day scale confirms the complex nature of the records similar to the case for laikakota usage of a threshold on a derived measure obtained via a fractal function generated by the iteration of three maps as in fig 1 but with parameters different from such a figure results in reasonable fm representations at the 7 14 and 30 day resolutions first and second columns of the bottom three rows in fig 5 with fm parameters included in the fourth to sixth rows of appendix a even though the locations of the fm peaks in red are not identical to those of the records in black and the actual magnitudes are overestimated especially at the 14 day resolution all sets do exhibit similar textures and result in very close fittings of the accumulated records such reasonable fittings on coarser scales are supported by the smaller values of re a c and me a c see table 1 for tinkham with 2 9 and 8 2 at the weekly scale 3 0 and 9 6 at the biweekly scale and 2 0 and 4 8 at the monthly scale notice how these numbers are comparable to those found for the laikakota site even if the records for tinkham reflect a longer water year length equal to the whole calendar year the closer renderings on biweekly and monthly scales give rise as previously found for laikakota to positive nash sutcliffe efficiencies at those scales see nse d c but the negative value obtained at the 7 day scale confirms the complex nature of the records although noticeable differences in daily downscales at all resolutions are observed in the third column of fig 5 the last column there reveals that all disaggregated fm representations using exactly the same parameters optimized at the coarser scales yield equally good accumulated sets certainly to the naked eye the three fm mass functions follow the accumulated trends well and such is reflected by the rather small and similar values of re a f and me a f see center of table 1 which are close to those obtained by the optimization exercise with values of about 3 0 and 9 6 respectively these numbers when compared with encodings of the daily records themselves reveal that the downscaled sets do not follow the accumulated records as closely as it may be modeled by an fm fit at the daily scale this is the case as the smallest re a f and me a f values possible via the fm approach are 1 1 and 4 4 maskey et al 2016a which once again are less than half of what the downscaled sets portrayed in fig 5 yield this result is consistent with what was reported earlier for the rainfall set from laikakota although the accumulated sets look similar surely the naked eye cannot be fooled while comparing the fm sets themselves on the third column in fig 5 as mentioned earlier these sets are clearly different and no doubt exhibit distinct intermittencies in this regard what was found at laikakota extends to tinkham regarding the nash sutcliffe efficiency of the records at the finer resolution such a statistic nse d f reflects the complexity of the records and the fm sets and degrades with an increased scale of the records from 27 at the weekly scale to 111 at the monthly scale see table 1 which as mentioned earlier is not uncommon even while encoding the information maskey et al 2016a as illustrated in fig 6 for the tinkham rainfall set the quickly decaying autocorrelation function the concentration of the histogram on small values and the decrease of the rényi entropy function are nicely preserved for this rainfall set by all fm representations these features not included in the optimization exercise give rise to low nash sutcliffe efficiencies for autocorrelations nsea once again due to rather small statistically insignificant oscillatory values and to high nash sutcliffe efficiencies for both the histogram and the entropy function nseh and nsee with values that are higher than 98 and 56 respectively and with the set based on the biweekly scale yielding a remarkable preservation of the entropy see table 1 as may be seen on the last columns of table 1 for the extreme information related to the tinkham sets the large values at a 90 level p d 90 are overestimated by the fm downscales at the weekly and biweekly scales 95 and 91 respectively although such is perfectly fitted at the monthly scale as found for laikakota there is no clear relation between the fitting of large and small values for the number of zeros recorded in the set 198 days may be under or over estimated by the fm representations i e 199 192 and 226 days see table 1 altogether however the obtained downscales may be termed adequate to represent rainfall at this site at the daily scale 4 3 remarks on rainfall downscaling the above analysis and results of downscaling of rainfall data from three coarser scales weekly biweekly and monthly to daily scale for the two distinct sites in different countries laikakota bolivia and tinkham washington state usa reveal that the fm approach is capable of representing the overall trends and intermittent features of the rather complex rainfall records in a reasonable albeit imperfect way although the nash sutcliffe values obtained for the downscaled data at the daily scale may be negative compared to the positive values of greater than 63 8 for the weekly aggregated records found from daily encodings maskey et al 2016a the geometric shapes of the downscaled data do provide relevant and certainly useful information at the very least from a simulation point of view clearly the usage of other solutions of the optimization exercise provides yet other alternative fm representations for various scales that may also be used in practical applications for planning and design purposes fig 7 illustrates such an idea based on the weekly scale at the tinkham site for three other solutions of the associated inverse problem as included in the seventh to ninth rows in appendix a and from top to bottom as in the figure the modeled daily sets in fig 7 have similar textures to those shown in fig 5 and their statistical features not presented here are also found to be in reasonable agreement with those presented in table 1 for the other sets all these results suggest that the fm approach yields sensible realizations akin to random ones obtained via stochastic disaggregation methods even if the magnitude of the peaks shown is smaller these therefore are clearly alternative representations that while following the overall location of the rain throughout the year still maintain the highly intermittent nature of the records 5 downscaling of streamflow sets this section reports the analysis of streamflow downscaling using the fm approach for this purpose streamflow data from the sacramento river measured near freeport california usgs station 11447650 is considered similar to what was done for rainfall in the previous section the fm approach is applied to downscale streamflow to the daily scale from 7 14 and 30 day aggregated sets two different water years having distinct geometries are considered to validate the method years 2005 and 2008 both from october 1 to september 30 of the following year for the daily data set and consequently the aggregated 7 14 and 30 days a constant base flow equal to the minimum in the records is subtracted from the raw daily data so that the fm approach may better fit those records after normalizing an obtained streamflow sets downscaling of streamflow is attempted using a fractal interpolating function based on the iteration of three maps adding a local smoothing just for appearance purposes and based on our previous experience maskey et al 2016b of 5 days as illustrated in fig 2 at the end the fm representations depend on only 9 free parameters as the smoothing is always set at the 5 day level the representations whose parameters are included in the last six rows of appendix a hence correspond to a compression ratio at the daily scale of 365 9 or 40 1 to further illustrate the abilities of the fm approach to disaggregate streamflow and perhaps other mildly intermittent hydrologic records the results that follow include a modification to the definition of optimality at the coarse scale while calculations are guided by the same objective function as in the rainfall studies earlier i e the root mean square error of accumulated coarse data re a c and subject to due penalties the best results are defined herein from the minimum of the maximum error in accumulated coarse data me a c this is done in the spirit of the kolmogorov smirnov test for comparing two distributions and as a means of performing a sensitivity analysis on the choice of the objective function figs 8 and 9 present the streamflow downscaling results for water year 2005 and figs 10 and 11 include the results for water year 2008 figs 8 11 are similar to figs 3 6 presented earlier for rainfall with the distinction that the observed records at the fine scale are now plotted on top of the obtained downscales for the two water years while figs 8 and 10 present the original daily data sets and their accumulated sets with actual records in black and fm representations in gray figs 9 and 11 display their respective autocorrelation histogram and entropy in what follows a step by step description of the obtained fm downscaled sets for the two water years is presented figs 8 and 9 present the streamflow downscaling results for water year 2005 and figs 10 and 11 include the results for water year 2008 figs 8 11 are similar to figs 3 6 presented earlier for rainfall with the distinction that the observed records at the fine scale are now plotted on top of the obtained downscales for the two water years while figs 8 and 10 present the original daily data sets and their accumulated sets with actual records in black and fm representations in red figs 9 and 11 display their respective autocorrelation histogram and entropy in what follows a step by step description of the obtained fm downscaled sets for the two water years is presented 5 1 streamflow set from the sacramento river water year 2005 fig 8 shows the original data in black at the daily scale right and the aggregated weekly biweekly and monthly data of streamflow records minus base flow for the water year 2005 as seen these records are much less intermittent when compared to the rainfall sets studied earlier and contain at the resolutions shown three main peaks located around the central portion of the water year with the last one being the largest fig 8 also includes the three optimal fm representations in gray found from the three coarse scales left blocks and the corresponding fm disaggregations in gray at the daily scale right blocks notice the rather faithful fm fits for all coarse scales on the left which result in accurate preservations of the main peaks in the sets this is corroborated by the error measures included in table 1 third horizontal block fig 8 shows the original data in black at the daily scale right and the aggregated weekly biweekly and monthly data of streamflow records minus base flow for the water year 2005 as seen these records are much less intermittent when compared to the rainfall sets studied earlier and contain at the resolutions shown three main peaks located around the central portion of the water year with the last one being the largest fig 8 also includes the three optimal fm representations in red found from the three coarse scales left blocks and the corresponding fm disaggregations in red at the daily scale right blocks notice the rather faithful fm fits for all coarse scales on the left which result in accurate preservations of the main peaks in the sets this is corroborated by the error measures included in table 1 third horizontal block as seen the root mean square error in accumulated sets re a c and maximum error in accumulated sets me a c the new optimal are always less than a mere 0 7 and 3 9 for all coarse representations and the nash sutcliffe efficiencies for those coarse records at all scales nse d c are always above a healthy 84 of all coarse representations and somewhat surprisingly given the opposite trends found in rainfall the one found for weekly records is the best with re a c equal to 0 7 and me a c equal to just 1 5 this is certainly much better than what was found for rainfall data i e four times in the former and about 6 times in the latter attribute altogether the nash sutcliffe efficiencies nse d c do increase with coarser records as reported in the rainfall cases before fig 8 also shows right blocks the downscaled patterns at the daily scale as seen the obtained set based on the weekly scale top gives the best following of the major peaks as the first one is missed just by a few days and the two others are preserved almost perfectly in timing and magnitude the daily representations emanating from 14 and 30 days do exhibit patterns that follow the main peaks but with noticeable over estimation for instance the one from the biweekly scale over predicts the second peak while the one from the monthly scale over predicts the third peak altogether the accumulated daily sets from the downscaled sets rather closely follow those at the fine scale i e the original daily records this is confirmed in table 1 third block center columns for the statistics at the fine scale re a f and me a f which are less than 1 2 and 3 9 respectively and comparable to what is found while encoding the daily records themselves notice that errors at the coarse and fine scales corresponding to the 7 day scale are identical i e re a c r e a f 0 7 and me a c m e a f 1 5 indicating an excellent preservation of the accumulated records by such downscales observe also that while the maximum accumulated errors are maintained for the other two sets i e me a c m e a f the process of disaggregation degrades the root mean square errors on the accumulated streamflow i e re a c r e a f obviously the downscaled daily data from the 7 day scale most closely resembles the original daily flows and such is also reflected by the nash sutcliffe efficiency for the daily disaggregated data n s ed f which remains high at a rather healthy 73 the statistical attributes in fig 9 further imply that the fm based disaggregation approach performs very well at all aggregation scales considered notice the close following of the record s autocorrelation function and histogram albeit not perfect and the rather close fits and almost perfect of the entropy function this is also reflected in table 1 third block right columns by the rather high nash sutcliffe efficiency indices for such attributes that are quite close to 100 and the excellent fit of the extreme records at the 90 level it is worth mentioning that it is hard to distinguish the quality of the three downscales just based on these statistics an indication that the geometric fm method provides good downscales for this water year 5 2 streamflow set from the sacramento river water year 2008 fig 10 presents the key graphs of the results of fm fits and downscales for water year 2008 as seen the original daily records in black contain three sharp peaks in succession which remain at the 7 day scale but that are smoothed out at the 14 and 30 day scales as observed on the left blocks in fig 10 the fm representations of the coarse records are excellent both in accumulated records and in the data with the latter particularly good for the two smoothed sets i e 14 day and 30 day this is reflected in table 1 last block left columns by comparable and small values of re a c and me a c i e less than 0 8 and 2 5 respectively and by nse d c values that range as the aggregation increases from 82 to 95 to 98 certainly remarkable numbers regarding the downscaled daily comparisons right block of fig 10 while the accumulated sets yield by eye very similar behavior corroborated by close values of re a f and me a f which are close to those at the coarse resolution and to those found from fm encodings of the daily set see central columns of the last block on table 1 the sets themselves have varying qualities as follows the disaggregated pattern found for 7 days emanating from an fm fit that captures well the last two sharp peaks not surprisingly preserves the timing and overall shape of the same peaks the pattern associated with the 14 day scale yields essentially similar shapes at the fine right and coarse left resolutions and as a consequence it misses the structure of the three peaks even if the overall volume is correct finally the downscaled daily set based on the 30 day fm disaggregation surprisingly captures the overall sense of the three peaks on the daily records curiously the optimal solution spanning from the 30 day scale is equally good as the one done on a weekly basis as is seen in table 1 for the ns d f attribute which exceeds a rather high magnitude of 72 in both cases the graphs in fig 11 show the statistical information of the fm downscaled data and the pertinent statistical qualifiers are presented in table 1 last horizontal block right columns as seen all the autocorrelations generally follow the overall decay in the records although they miss the first noticeable dip the nsea values are rather good with greater than 92 and better than what was reported earlier for the 2005 streamflow set the histograms for the downscaled data for water year 2008 show in general more variation than those for water year 2005 and degrade in quality as the scale is increased contrary to what was found for water year 2005 the nseh values decay from 89 to 78 and to 73 and as such the set implied by the 30 day scale no longer competes with the one based on 7 days although the p d 90 values are close to one another 89 vs 87 as seen in fig 11 and table 1 all sets provide close fittings of the entropy function of the records with nsee values in excess of a high 91 in summary the application of the fm based disaggregation model to streamflow records yield very good results and much better than what was found for rainfall these very good results for streamflow are to be expected given the smoother nature of the records when compared to rainfall 6 concluding remarks this study has proposed a deterministic geometric fractal multifractal fm approach to downscale hydrologic records specifically rainfall and streamflow the proposed approach for temporal downscaling is an adaptation of the original fm approach for encoding of records puente 1996 which adds a threshold for rainfall and local smoothing for streamflow by studying two rainfall records from laikakota bolivia and tinkham washington state usa and two streamflow records from the sacramento river usa the fm based method has been shown to be an effective and efficient tool for downscaling especially for streamflow sets as the notions are based on accumulated records it is envisioned that the geometric downscaling approach may also be applied using data gathered at a coarse scale over not just one but multiple years the results from this study clearly indicate that the deterministic fm geometric procedure when coupled with an effective optimization procedure for the inverse problem for a given target set at a coarse resolution not only encodes coarse scale records i e weekly biweekly and monthly but also generates plausible downscale representations at least for simulation purposes at the finer scale i e daily such a novel approach yielding compression ratios as high as 37 1 for rainfall sets and 40 1 for streamflow records may therefore supplement existing stochastic downscaling methods supporting the notion of hidden determinism in natural complexity puente 1996 puente and sivakumar 2007 the proposed downscaling technique in conjunction with simulations that may be obtained via the fm approach maskey et al 2016c 2017 may certainly increase the flexibility for generating time series in a multisite or multi season framework as done by other approaches e g salas et al 1995 as the same number of fm parameters define both coarse and fine sets the evolution of the inherent complexity in the physical processes may be studied based on them it is envisioned that a sensible application of the fm based disaggregation could be the temporal downscaling of coarse scale outputs from global circulation models gcms to catchment scale hydrologic variables in order to assess the impacts of climate change on hydrology and water resources in a region acknowledgements the research leading to this article was supported by a jastro award provided to the first author by the university of california davis we are thankful to ministerio de medio ambiente y agua bolivia for providing rainfall records gathered at laikakota and also to the team of national resource conservation service for the availability of rainfall records in its web portal bellie sivakumar acknowledges the financial support from the australian research council arc through the future fellowship grant awarded to him ft110100328 the team of usgs service is also greatly appreciated for making the historical streamflow records available in its web portal comments from anonymous reviewers helped us improve the manuscript and are gratefully acknowledged appendix a 
6827,monthly streamflow prediction can offer important information for optimal management of water resources flood mitigation and drought warning the semi humid and semi arid wei river basin in china was selected as a case study in this study a modified empirical mode decomposition support vector machine m emdsvm model was proposed to improve monthly streamflow prediction accuracy the accuracy was improved by introducing polynomial fitting to amend the error caused by the boundary effect existing in the counting process of empirical mode decomposition emd meanwhile the computational process of the emd was analyzed to confirm the decomposition method for the emd the root mean square errors mean absolute error mean absolute percentage error and nash sutcliffe efficiency coefficient were adopted as the standards to evaluate the performance of the artificial neural network ann svm wa svm emd svm and m emdsvm models meanwhile the performance of the m emdsvm model with different lengths of training dataset was compared and analyzed moreover the monthly streamflow series with various non stationary levels were simulated to investigate the prediction capacity of the m emdsvm model results indicated that 1 the ann model had the worst performance among the five models at all stations whereas the emd svm model performed better than the wa svm with better metric values 2 for strong non stationary series the performance of the m emdsvm model was superior to the emd svm 3 for weak non stationary series the performance of the m emdsvm model was similar with the emd svm generally the findings of this study showed that more accurate prediction of strong non stationary streamflow could be achieved using the proposed modified emd svm model than single svm model keywords support vector machine modified empirical mode decomposition monthly streamflow prediction non stationary 1 introduction the accurate prediction of streamflow is of great significance for utilization and management of sustainable water resources reliable streamflow prediction is particularly important for hydrological operations e g efficient operation and planning of reservoirs optimal operation of hydropower stations for understanding regional water resources carrying capacity and for environmental protection solomatine and shrestha 2009 guo et al 2011 huang et al 2014a b fang et al 2017 hence a large number of studies have been conducted to investigate streamflow prediction in recent decades typically numerical models with a physical basis are utilized to predict streamflow bittelli et al 2010 partington et al 2012 they quantify streamflow through a governing equation that is based on proper assumptions and boundary conditions however these models require a large amount of accurate data for parameter calibration actually it is extremely difficult to gain adequate and accurate data for some un surveyed areas which leads to poor model performance and high uncertainty yoon et al 2011 numerous studies have been focused on the investigation of time series models e g auto regressive ar moving average ma and multiple linear regression mlr models for streamflow prediction salas 1980 wu et al 2009 these are based on the hypothesis that a linear relationship exists between the input and output of these models thus their performance is poor without the important information hidden in the nonlinear relationship because artificial neural networks anns have good performance in dealing with nonlinear time series there are numerous ann applications for streamflow prediction yoon et al 2007 guo et al 2011 however the anns also have some drawbacks e g slow learning and traps related to local minimization value and over fitting that make it difficult to obtain satisfactory results when dealing with complex hydrological processes the use of a support vector machine svm was proposed by cortes and vapnik 1995 svm is based on vapnik chervonenkis vc dimension theory and the structural risk minimization principle which can theoretically overcome part convergence and achieve a globally optimal solution svm has proven an effective prediction tool and has been widely applied in the hydrological field in recent decades lafdani et al 2013 introduced an svm model for prediction of daily suspended load while liu and lu 2014 adopted the svm model to predict the water quality in an agricultural nonpoint source polluted river streamflow is influenced by a large number of factors such as precipitation temperature climatic conditions and so on and is characterized by nonlinear non stationary and uncertain conditions especially in extreme climates huang et al 2016a b liu et al 2019a fang et al 2019 thus a monthly streamflow series is composed of trend periodic and noise components zhang et al 2015 in some former studies bittelli et al 2010 streamflow series were predicted directly without data preprocessing which may cause the loss of some important information contained in the original time series chou and wang 2004 suggested that it is difficult to reflect the change mechanisms of streamflow series using a prediction model established using only one mixed frequency component therefore it is necessary to preprocess monthly streamflow time series to improve prediction accuracy in other studies armstrong 1989 temraz et al 1996 zou and yang 2004 gulhane et al 2005 hibon and evgeniou 2005 streamflow time series was decomposed into different components that were then used as input for developing streamflow prediction models although the method of decomposition is empirical in nature anderson 1927 put forward a theory that noise was represented intuitively through decomposing the time series into several components a method of extracting period and trend components from time series was proposed by frisch 1931 then macaulay 1931 constructed a time series decomposition procedure as time went on fourier analysis and associated spectrum analysis created by wiener 1949 became widely used for decomposing stationary time series however the principles of these methods involve analyzing time series in the frequency domain which leads to loss of important information regarding instantaneous frequency boashash 1992 in order to decompose non stationary time series analyzing the time series in time and frequency domains simultaneously was attempted using window fourier transform wft nawab and quatieri 1988 however because of the existence of a single fixed window during the decomposition process wft can only grasp the low frequency events or noise in a given moment karthikeyan and kumar 2013 the complete information of a time series should contain low frequency and noise simultaneously thus the concept of a wavelet was proposed by morlet et al 1982 the wavelet approach solved the two main drawbacks of fourier analysis i e the infinite domain of sine and cosine waves and lack of time frequency localization thus it has been extensively applied in hydrological analysis in recent years kisi 2010 nourani et al 2011a nourani et al 2011b mehr et al 2013 liu et al 2014 shoaib et al 2015 2016 moosavi et al 2017 the concept of empirical mode decomposition emd proposed by huang et al 1998 is a non stationary time series analysis technique emd is based on the theory of local scale separation and does not need predetermined basis functions which is totally different from wavelet analysis and almost all the other decomposition techniques huang et al 1998 lee and ouarda 2010 kim and oh 2013 thus emd could adaptively decompose a time series into a series of frequency components referred to as intrinsic mode functions imfs harmonics analysis is not required for emd analysis due to the adaptive basic properties therefore compared with the wavelet approach emd is an ideal method for analyzing nonlinear and non stationary data huang and wu 2008 because they are influenced by the changing environment monthly streamflow series is complexly nonlinear and non stationary huang et al 2014a hence in this study emd was adopted to deal with the data preprocessing instead of wavelets however emd has a boundary effect and huang et al 1998 proposed a solution by adding artificial time series to extend the raw time series called characteristic waves at both boundaries for eliminating boundary effect at present artificial intelligence algorithms and reproduction of the period of time series are the most common methods for making characteristic waves karthikeyan and kumar 2013 however the neural network extending method requires a large amount of data to train the model and the networks also need to be adjusted according to the different data types used the mirror extension algorithm is an effective method employed to reproduce the period of a time series but this algorithm requires that the end of the time series be extreme points thus there are some restrictions when these two methods are applied to hydrological prediction in this paper an improved polynomial fitting method was employed to eliminate the end effect the extreme values of the end point are obtained by fitting the extreme points near the end of the time series however there were two decomposition methods that the training and validation datasets were decomposed altogether or separately to choose for emd and the computational process of emd will be analyzed to confirm which method is suitable for emd as mentioned above emd has been widely used in data preprocessing for streamflow prediction and the prediction accuracy has been improved however the current question is whether the degree of improvement in prediction accuracy using emd to eliminate noise varies in relation to different streamflow series e g highly nonstationary or weakly nonstationary time series to the best of our knowledge few studies have been focused on this question therefore the degree of improvement was studied systematically in this study meanwhile the performance of different length of 50 60 70 80 and 90 of monthly streamflow data series acted as training period of m emdsvm model was compared to analyze what will be the effect on modeling results if the length of dataset changed the primary objectives of the present study were 1 to propose a modified model of streamflow prediction that improves the emd based support vector machine emd svm by employing a modified multivariate fitting function to eliminate the boundary effect of traditional emd 2 to choose a suitable decomposed method for emd 3 to discuss systematically the degree of improvement in prediction accuracy from using emd as the data preprocessing tool for different types of streamflow series 4 to confirm the suitability of choosing 80 of data series acted as training period in the rest of this paper section 2 describes details of the study area and data feature section 3 provides a detailed introduction to the methodology mentioned above including wa emd and svm in section 4 the results of the case study are presented and discussed while the conclusions drawn from this research are given in section 5 2 study area and data the wei river basin wrb was chosen as the study area in this paper fig 1 the wei river is the largest tributary of the yellow river and has a total length of 818 km and total area of 1 35 105 km2 the topography and the geomorphology of the wrb are complex and the elevation decreases from the western loess hilly gully area to the eastern guanzhong plain the wrb is located in a representative semi arid and semi humid zone high temperatures and rainy weather takes place frequently in summer while the weather in winter is cold and rainless the annual precipitation of the wrb is about 559 mm zhang et al 2008 liu et al 2018 2019b and the average annual evaporation from water surfaces is 660 1600 mm huang et al 2014c zhang et al 2015 the wei river system is developed and there are many tributaries on both sides of the river the average annual water resources in the wrb are 1 11 1010 m3 of which the natural river streamflow is 1 00 1010 m3 the groundwater resources amount to 6 99 109 m3 the repeated calculation amount is 5 97 109 m3 it is worth mentioning that the wrb is an important grain producing area and an important economic development zone in the the belt and road construction in china considered with the climate these mean that the water security issues in the wrb are particularly critical therefore long term streamflow prediction in the wrb has great significance for the regional economy and for water resource security the monthly streamflow data from huaxian xianyang and zhangjiashan hydrological stations in the wrb were employed in this study these stations have monthly streamflow data covering january 1960 through december 2010 which was obtained from hydrologic manual the data quality was strictly controlled during its release the digital features of the annual streamflow at the three hydrological stations are exhibited in table 1 table 1 shows that the inter annual variation at xianyang station is very significant and the inter annual variation at zhangjiashan station is relatively weak in this paper the monthly streamflow data covering january 1960 to december 2000 were selected for the training period while data covering january 2001 to december 2010 were selected for the validation period 3 methodologies 3 1 empirical mode decomposition emd emd is an adaptive and powerful method proposed by huang et al 1998 for the analysis of the nonlinear and non stationary data it is the main component of the hilbert huang transform hht which provided a new method for data analysis huang and wu 2008 in general many studies utilize the hht and wavelet analysis wa to analyze a time series however wa was derived from mathematical theory while hht was born of practical experience the emd method has been employed to decompose the time series x t into some orthogonal and band limited functions ci t i 1 m called intrinsic mode functions imfs the remainder works as r t representing the overall trend of the original sequence then the original time series could be expressed as the sum of all imfs and residual items as follows 1 x t i 1 m c i t r t note that the adaptivity of emd to local variation allows the imfs to have clear physical meaning regarding instantaneous frequency and amplitude therefore emd can effectively deal with nonlinear and non stationary data by its ability to decompose a time series into subseries having physical meanings of time and frequency huang and wu 2008 however no nonlinear data series can be explained by simple linear superposition therefore the description of nonlinear data series with linear stacking has no physical significance nevertheless emd provides an effective explanation of nonlinear data series with physical subseries therefore emd can efficiently obtain important information about nonlinear and non stationary data huang et al 1998 kijewski correa and kareem 2007 lee and ouarda 2011 according to the definition of imf all imfs should satisfy the two following conditions 1 in the whole data segment the difference between the number of extreme points and the number of zero crossings must be zero or at most differ by one and 2 at any point the average value of the envelope formed by the local maximum points and the envelope formed by the local minimum points must be zero the imfs are produced by sifting the raw data which is an iterative process the main aim of the emd function is to eliminate the influence of noise and to find the periodic component of the streamflow sequence the details of the iterative procedures are described in huang et al 1998 and huang et al 2014b the iterative processes are repeated until the stop condition is satisfied huang et al 1998 employed the standard deviation sd as the imf stop condition the sdk is defined as follows 2 sd k t 0 t h 1 k 1 t h 1 k t 2 h 1 k 1 2 t according to huang et al 1998 when the value of sdk falls in the interval 0 2 0 3 then c1 t h1k is specified which is the first imf many tests show that when sdk is within 0 2 0 3 the imfs obtained by iteration have enough physical meaning meanwhile the residual component has the monotonicity character meanwhile the condition if is monotonicity or not was employed as the stop condition during the iteration process and the total decomposition process combining with the two stop conditions the optimal number of imf s could be obtained with an adaptive method however there is a boundary effect problem in the emd process pointed out by huang et al 1998 it is impossible for the maximum and minimum to exist simultaneously at the end of an original sequence that is a boundary fluctuation phenomenon will appear in the emd process and the error caused by the boundary fluctuation will contaminate the whole sequence by the iterative process thus boundary processing is crucial to the emd process the failure of which might cause invalidity of the decomposed imf due to the boundary fluctuation propagating throughout the whole data set huang 2002 proposed that at the two ends of the signal and according to the amplitude and frequency of the boundary signal two characteristic waves be added details of the processes can be found in huang 2002 a large number of studies have been carried out to eliminate the influence of the boundary effect on emd some of these corrective methods have been accepted such as those proposed by huang 2002 via the characteristic wave method the slope method dätig and schlurmann 2004 the extremum continuation method huang et al 2003 the extremum image continuation method rilling et al 2003 and the artificial neural network method however the ann method is prone to a local minima problem and the speed of this method will obviously be slow when the amount of predicted data is large the mirror extension method needs to cut the raw data in order to put the mirror at the extreme point therefore this method is not effective in dealing with short sequences according to principle these methods can be divided into two categories extreme value data extension and waveform extension for this paper an improved method was adopted to extend the extremum of the sequence in order to eliminate the boundary effect two maxima and minima were extended from both ends of the data the algorithm is as follows the number of sequences containing maxima and minima is m and n m m 1 m 2 m i n n 1 n 2 n j respectively the positions of the maximum and minimum points in a sequence composed of maximum and minimum are im m m 1 m 2 m i and in n n 1 n 2 n j respectively the positions of the maximum and minimum points in the original sequence are tm and tn respectively the length of the original is g g 1 2 g the value of the maximum and minimum is u i i 1 2 m and v j j 1 2 n in this paper the slope method was used to extend the maximum and minimum values the calculation process is displayed as follows 3 u 0 u 1 k t m 0 t m 1 4 v 0 v 1 k t n 0 t n 1 5 u m 1 u m k t m i 1 t m i 6 v n 1 v n k t n j 1 t n j eqs 3 to 6 were applied to determine the values of the maximum and minimum that were extended at both ends of the sequence in which the values of tm 0 and tn 0 are 1 and the values of tm i 1 and tm j 1 are g 7 u 0 u 0 u 0 x 1 x 1 u 0 x 1 8 v 0 v 0 v 0 x 1 x 1 v 0 x 1 9 u m 1 u m 1 u m 1 x g x g u m 1 x g 10 v m 1 v m 1 v m 1 x g x g v m 1 x g then eqs 7 and 8 were employed to confirm the final values of u 0 v 0 and u m 1 v m 1 determining the positions of continuation extreme points at left end of the data 11 k 1 t m 2 t m 1 i m 1 i n 1 t n 2 t n 1 i m 1 i n 1 2 t m 1 t n 1 m n 1 eq 11 is used to determine the number of items contained in the first characteristic wave 12 t m 0 t m 1 k 1 δ t 13 t m 1 t m 1 2 k 1 δ t 14 t n 0 t n 1 k 1 δ t 15 t n 1 t n 1 2 k 1 δ t 16 u 1 u 0 17 v 1 v 0 eqs 12 to 15 are used to determine the positions of two maximum and minimum that extended t the left point where t is the minimum positive integer that makes the values of tm 1 1 and tn 1 1 the method of extension of extreme value at the right end is in line with the method discussed above a new set of extreme sequences is generated by the extreme value continuation method described above then the new extreme value sequences are substituted into the iterative process to decompose the time series in this paper an improved emd is proposed based on the extreme value continuation method mentioned above it is important to note that the fitting curve in the modified emd needs to be cut out according to the position and length of the original sequence however there were two decomposition methods that the training and validation datasets were decomposed altogether or separately can be chose by emd as mentioned above the main computational process of emd was that firstly the extreme points of data series were picked out secondly the upper and lower envelopes were obtained by fitting extreme points with cubic spline curve finally the imfs and residual item were generated by sifting process by studying the emd s computational process earnestly it can be found that there was a certain probability of mutual information sharing during the spline curve fitting process in second step of emd s computational process and there is no probability in other steps then the upper and lower envelopes of overall decomposition method have been compared with that of piecewise decomposition method to further learn whether the mutual information sharing phenomenon occur or not the cubic spline curve of emd with different decomposition methods of monthly streamflow series at huaxian hydrological station were shown in fig 2 it can be found from fig 2 that there was almost no difference between the upper and lower envelopes for overall decomposition method and piecewise decomposition method except for the breakpoint location the difference of breakpoint location was caused only by the end effect of emd and there was no mutual information sharing during emd s counting process no matter which decomposing method been used in this study the main goal was to eliminate the end effect of emd by proposing a linear extremum extension method however the number of imfs of emd will change with varying the length of data series thus the number of imfs may be different between training and validation dataset using piecewise decomposition method which will make the emd svm fail to work at the same time the error caused by end effect will happen twice which will reduce the prediction accuracy of emd svm thus the method of overall decomposition was chose in this study 3 2 wavelet analysis wa the concept of the wavelet transform was first proposed in 1974 by j morlet an engineer who is engaged in oil signal processing in france unlike fourier transform ft wa is a local transformation of time and frequency can effectively fetch information from time series through multi scale refinement analysis on time series using scaling and translation daubechies 1990 torrence and compo 1998 a detailed introduction of the difference between wa and ft was demonstrated by sifuzzaman et al 2009 the comprehensive and detailed information of wa can be found in labat 2005 nourani et al 2014 sang 2013 wa has been proved was an availably decomposition tool for analyzing time series and applied in runoff time series analysis as period and trend et al kisi 2010 nourani et al 2011 2012 danandeh mehr et al 2013b yarar 2014 shoaib et al 2015 2016 moosavi et al 2017 the decomposition level of original streamflow series was 6 which is the same with the number of imfs the mother wavelet db5 was employed in this study 3 3 genetic algorithm ga the genetic algorithm was proposed by john holland in the early 1970 s which is based on the concepts of natural selection and natural genetics the basic idea of ga is to introduce the natural law of survival of the fittest into computer programming to obtain the optimal solution a set of chromosomes is called a population that represents the solution set according to the fitness function of choice and by genetic selection crossover and mutation a number of individuals an individual acts as a chromosome of the primary population were selected to generate a new generation population with good fitness value finally an individual with optimal fitness is though evolving that is the optimal solution or the suboptimal solution thus ga could obtain global optimal solution or suboptimal solution in the short time with the strong ability of global parallel search therefore the ga was employed to optimize the penalty factor c and kernel function g of svr in this paper the optimization of svm parameters c and g based on ga is dependent on its fitness function the definition of the fitness function as follow 18 min f c g 1 n i 1 n y i y 2 s t c c min c max g g min g max eq 18 is used as the fitness function of ga to optimize the parameters c and g of svm in which yi is the i th observed value during training period and yi is the i th prediction value of svm since the details of the ga have been documented in a large number of papers and books wang 1991 ritzel and wayland eheart 1994 franchini 1996 franchini and galeati 1997 vasques et al 2000 sharif and wardlaw 2000 khu et al 2001 the counting process of ga was omitted in this paper a sensitivity analysis on different parameters values have been conducted to optimize the parameters of ga in this study in which the different parameter values were determined by referring to related studies vasques et al 2000 sharif and wardlaw 2000 khu et al 2001 eiben and smit 2011 it should be noted that miller and goldberg 1995 pointed out that increased selection pressure can be provided by simply increasing the tournament size as the winner from a larger tournament will on average have a higher fitness than the winner of a smaller tournament therefore the parameter tournament size was selected instead of selection pressure in this present study ultimately the values of the maximum generation crossover percentage mutation rate and tournament size were selected as 200 0 9 0 01 and 4 respectively 3 4 support vector machine svm the support vector machine svm is one of the most effective tools in the prediction field and was created by vapnik 1995 unlike traditional machine learning svm simplifies complex problems by mapping the complex nonlinear problem input factors into high dimension space with kernel functions to transform the complex nonlinear problems into linear problems the main idea of svm is to establish a classification hyperplane as the decision surface so that the separation edge between the positive case and the counter example is maximized svm is based on statistical learning theory more precisely svm is the approximate representation of structural risk minimization because a large number of papers and books have described svm theory in detail vapnik and vapnik 1998 carrier et al 2013 ch et al 2013 he et al 2014 fang et al 2018a the description of svm is omitted from this paper the advantage of svm is to neatly solve the inner product operation in the high dimensional space by introducing kernel function so the prediction accuracy would be enhanced with appropriate kernel function generally the effective kernel functions of svm are linear polynomial sigmoid radial basis function rbf and so on in this paper rbf is employed as the kernel function 19 k x x j exp x x j 2 2 σ 2 where σ represents the gaussian noise level of standard deviation 3 5 the modified emd based svm prediction model the modified emd was adopted to decompose monthly streamflow series that consisted of one residual series and several imfs then the residual series and imfs were modeled by the svm model respectively then the summation of the prediction output of subseries make up the prediction monthly streamflow series in addition the ga was employed to optimize svm parameters to increase the prediction accuracy the specific algorithm processes of the m emdsvm prediction model are displayed in fig 3 in this paper 80 of the input and output data january 1960 to december 2000 was used for the training sets of svm and the last 20 january 2001 to december 2010 was selected as the validation sets during the modeling process with m emdsvm note that the details of the computing process for all three stations were consistent given space limitations details of only the computing process used for the huaxian station will be shown in the next section 3 6 heuristic segmentation algorithm the heuristic segmentation algorithm was an effective mutation detection tool for nonlinear and non stationary streamflow series and was proposed by bernaola galván et al 2001 since the details of the heuristic segmentation algorithm have been introduced in a large number of papers and books gong et al 2006 chen and xie 2008 huang et al 2014b 2016 the counting process of the algorithm was omitted in this paper in general the value of parameter p 0 should fall between 0 5 and 0 95 and the value of parameter l 0 must be greater than or equal to 25 huang et al 2016 3 7 four indicators used for comparison of performance the root mean square error rmse the mean absolute error mae the mean absolute percentage error mape and the nash sutcliffe efficiency coefficient nse were employed as an evaluation index system to measure the performances of the ann svm emd svm and m emdsvm models the rmse mae mape and nse are defined as 20 rmse 1 n i 1 n y i y i 2 21 mae 1 n i 1 n y i y i 22 mape 1 n i 1 n y i y i y i 100 23 nse 1 i 1 n y i y i 2 i 1 n y i y 2 the rmse is an ideal error index used to evaluate the fitness of high streamflow values the mae measures the absolute value of overall errors the mape is an error index that can be used to compare errors that differ in level and the nse evaluates the power of the hydrological model yoon et al 2011 huang et al 2014a fang et al 2018b here n denotes the total number of data sets meanwhile the line chart scatter diagram and taylor diagram were also employed to evaluate the performances of those models in this present study 4 results and discussion 4 1 identification of the possible change point of the three hydrological stations the heuristic segmentation algorithm was employed to detect the abrupt change point of the annual streamflow series at huaxian station and its result is shown in fig 3 it is obviously from fig 4 that the t value is largest in 1990 and that the p tmax value of this point is 0 99 this is greater than the critical value 0 95 therefore the year of 1990 is the abrupt change point in the annual streamflow series in the area above huaxian station meanwhile it can be also seen that the abrupt change point of the annual streamflow series in the basin above xianyang station is 1993 whose p tmax value is 0 98 and that there is no abrupt change point in the annual streamflow series in the basin above zhangjiashan station the annual streamflow series of the three hydrological stations are presented in fig 5 fig 5 shows that the fluctuation of annual streamflow at huaxian is the most obvious among the three stations and that the fluctuation of annual streamflow at xianyang station is obviously weaker than at huanxian station however the fluctuation of annual streamflow at zhangjiashan station is the weakest meanwhile ns ding yi ming 2010 an index of non stationarity level of time series was employed to quantitative calculate the non stationarity level of streamflow series at huaxian station and xianyang station and zhangjiashan station whose value is between 0 and 1 and the non stationarity level is proportional to the value of ns the values of ns at huaxian station and xianyang station and zhangjiashan station were 0 81 0 80 and 0 47 respectively and ns huaxian ns xianyang ns zhangjiashan the result of ns shown that the non stationarity level of streamflow series at huaxian station and xianyang station was stronger than that at zhangjiashan station through the analysis above it was determined that the non stationary component of the annual streamflow at huaxian and xianyang stations is strong and that of huaxian station is stronger than of xianyang station at the same time the non stationary component of the annual streamflow at zhangjiashan station is weakest among the three stations in this paper the monthly streamflow at huaxian xianyang and zhangjiashan hydrological stations was used to verify the prediction accuracy of the m emdsvm model and to explore the prediction performance for different kinds of monthly streamflow series 4 2 the original series decomposed the monthly streamflow obtained from the hydrologic manual was decomposed by the modified emd the emd and the wa which were introduced in section 2 the decomposition results of the monthly streamflow series at huaxian xianyang and zhangjiashan hydrological stations are exhibited in figs 6 to 8 respectively it can be seen from fig 6 that the monthly streamflow at huaxian hydrologic station was decomposed into six imfs and one residual based on the emd and m emd respectively the imf1 is an extremely irregular component of the monthly streamflow series meanwhile the high irregular also can be found in first level subseries d1 of wa in fig 6 which further proves that the monthly streamflow series is nonlinear and nonstationary it is usually difficult to predict highly nonlinear and nonstationary time series accurately hence pre processing the initial series before prediction is necessary the fig 6 shows that the energy contained in imfs of m emd becomes purer and the trend of residual terms becomes more obvious using the modified emd method it proves that the m emd can effectively eliminate the modal confusion caused by the end effect of the emd however the last level subseries of wa still contains periodic components that proved the shortage of physical mechanism during the wavelet decomposition process it indicated that the capacity of decomposition of wa inferior to emd and wa was not the best choice for hybrid model for prediction problems du et al 2017 quilty and adamowski 2018 the results obtained at huaxian and zhangjiashan stations are similar to those at huaxian station in figs 7 and 8 it is worth mentioning that the r values of the three stations has an obvious downward trend which is closely linked with the increasing water demand on the guanzhong plain this shows that the monthly streamflow in the wrb has exhibited a remarkable decline the belt and road program promoted the rapid economic development of this basin leading to a large demand for water resources however the decrease in monthly streamflow threatens the water security of the belt and road therefore it is critically important to predict streamflow accurately to provide the information needed by local governments to make scientific long term planning for water resources 4 3 determining the input variables the input variables of models are selected from the following eight scenarios which are demonstrated in table 2 where x t 1 x t 2 x t 3 x t 4 x t 5 x t 6 x t 7 x t 8 x t 9 x t 10 x t 11 and x t 12 are the streamflow at retardation time of 1 2 3 4 5 6 7 8 9 10 11 and 12 months respectively the best input combination of each subseries can be found from eight scenarios with four evaluation indicators rmse mae mape and nse 4 4 method for parameter selection because the monthly streamflow series is highly nonlinear and nonstationary the emd the m emd and wa were employed to decompose the time series into various subseries which represent different frequencies and trend components contained in the monthly streamflow series the subseries at the three hydrologic stations shown in fig 6 were chosen as the input variables for svm model respectively the svm model is sensitive to the parameters c and g thus it is important to obtain the optimal parameters in this study a genetic algorithm ga was employed to optimize the value of c and g fig 9 shows one of the optimization process and the optimal parameters of the svm model obtained through the ga at huaxian station ultimately the optimal parameters c and g exhibited in table 3 in this paper an ideal non sensitivity coefficient was obtained by experimental analysis whose value was 0 001 4 5 comparative analysis the prediction of the time series was conducted using the svm model with the input variables of each subseries respectively then the output variables of each subseries was added this is the modeling procedure of the wa svm emd svm and m emdsvm the evaluation results of subseries decomposed by wa emd and m emd at huaxian hydrological station are shown in table 4 it can be found from table 4 that the prediction performance of s1 is poor in three models m emdsvm emd svm and wa svm in terms of mape values 14 28 21 50 and 257 40 and nse values 44 76 50 37 and 65 79 the s1 subseries is highest frequency portion of runoff time series see fig 6 and its prediction was difficult however the performance of s1 in emd svm was poorer than wa svm which was because that the frequency of s1 decomposed by emd and m emd was higher than that of wa in other words wa has poor adaptivity because the necessary of mother wavelet which made the subseries do not have physical meaning thus it was further proved the decomposition capacity of emd was stronger than that of wa due to the physical mechanism of emd simultaneously the superior of the m emd is also can be found from table 4 with the worst performance of s1 and the best performance of other subsequence the same results can also be obtained at xianyang hydrological station and zhangjiashan hydrological station see tables 5 and 6 4 5 1 performances of five models in strong non stationary monthly streamflow prediction the performances of the modified model proposing in this paper were compared with that of the single svm and artificial neural network models meanwhile the prediction ability of non stationary and non linear monthly streamflow of emd svm and m emdsvm was composed with that of wa svm the evaluation results obtained by the five models in predicting strong non stationary monthly streamflow series at huaxian were exhibited in table 7 and figs 10 13 it can be obtained from table 7 that the ann model has poor performance compared with the other models the svm model shows good performance reducing the rmse mae and mape values by 9 96 13 13 and 2 35 compared with the ann model the wa svm model has better performance and was superior to the svm model reducing the rmse mae and mape values by 45 29 38 95 and 35 38 compared with the ann the emd svm model has even better performance and was superior to the svm model its better performance for rmse mae mape and nse was indicated by their values 0 02 0 67 19 17 and 97 01 respectively reducing the rmse mae and mape values by 99 28 61 05 and 72 66 compared with the svm model the m emdsvm shows the best performance among the five models and outperforms the svm wa svm and emd svm models in all standard statistical indicators reducing the rmse mae and mape values by 99 64 82 56 and 88 08 compared with the svm model the ann model shows the minimum value of nse while the svm is 61 21 which is less than 29 57 of wa svm 58 49 of emd svm and 62 52 of m emdsvm fig 10 shows the streamflow prediction at huaxian station based on the ann svm wa svm emd svm and m emdsvm models in the validation period overall the ann model has the worst performance among five models and the svm model performed better than the ann being similar with table 7 the wa svm has better performance than the ann and svm but worse than the emd svm and m emdsvm the emd svm and m emdsvm predicted well the monthly streamflow series in the validation period and m emdsvm performed best among five models moreover fig 11 shows a scatter plot of the streamflow predictions by the five models at huaxian station indicating that ann has the worst performance with the smallest r squared value and that m emdsvm has the best performance in prediction the strong non stationary monthly sequences linear trend nearest to the 45 degree line among the five models furthermore fig 12 shows the taylor diagram of streamflow prediction performance at huaxian station for the ann svm wa svm emd svm and m emdsvm models in the validation period it can be seen from fig 12 that the ann shows the worst performance and the performance of the wa svm was better than ann and svm meanwhile both of the emd svm and m emdsvm performed better than wa svm the point representing the m emdsvm was most close to the point representing observation among the five models which proved the superiority of the m emdsvm in monthly streamflow prediction the performances of the five models obtained in fig 12 were consistent with those obtained in table 7 and figs 10 11 from the above figures and table it can be found that the svm performed better than ann because the svm model uses statistical learning theory of the vapnik chervonenkis vc dimension theory and structural risk minimization principle it was able to overcome issues with the local minima and over fitting hence its performance is better than the ann model this finding was also obtained by wang et al 2009 and kalteh 2013 however with the effect of human activities and climatic variation monthly streamflow become nonlinear non stationary and complex meanwhile the main information would be lost directly using the original streamflow series as input variate of model thus the performances of svm and ann were the worst among the five models meanwhile the wa svm has better performance than the ann and svm but worse than the emd svm and m emdsvm in strong non stationary monthly streamflow prediction which proved the effectiveness of preprocessing strategy for monthly streamflow prediction the wa model needs predetermined basis functions to do decomposition calculation which makes it have poor adaptability and lack of physical mechanism however emd could adaptively decompose a time series into a series of frequency components without predetermined basis functions harmonics analysis is not required for emd analysis due to the adaptive basic properties compared with the wavelet approach emd is an ideal method for analyzing nonlinear and non stationary data thus in view of emd could solve the problem lacking physical meaning of wa perfectly emd has been employed to build the hybrid model for non stationary monthly streamflow prediction instead of wa meanwhile it can be seen from table 7 and figs 10 12 that the performances of the emd svm were better than wa svm which further proved the superiority of emd visually meanwhile the emd has been improved with a modified multivariate fitting function to eliminate the boundary effect of traditional emd which makes the imfs and r become purer this resulted in decrease of the rmse mae and mape values by 50 00 55 22 and 56 39 compared with the emd svm model as indicated in section 4 1 both of xianyang station and huaxian station belong to strong non stationary streamflow the monthly streamflow was also simulated by the five models the results obtained from table 8 and figs 13 15 at xianyang station were consistent with those at huaxian station specifically the performance of the ann model is the worst among the five models and the m emdsvm model has the best performance among all the models with the minimum rmse mae and mape values and the largest nse values with the rmse mae and mape decreased by 50 00 17 14 and 24 14 compared with the emd svm model table 8 the performance of the wa svm is inferior to emd svm 4 5 2 performances of five models in weak non stationary monthly streamflow prediction the evaluation results obtained using these five models for predicting the weak non stationary monthly streamflow series at zhangjiashan station were displayed in table 9 and figs 16 18 table 9 shows that the performances of the ann model and svm model are consistent with that in tables 7 and 8 it can be found that the performance of the wa svm is better than the ann and svm being similar with the term of strong non stationary monthly streamflow prediction the performance of wa svm is poorer than emd svm and m emdsvm it was determined from table 9 that the predictions of emd svm and m emdsvm for weak non stationary monthly streamflow series are good and that their rmse mae mape and nse values are basically the same fig 16 illustrates the streamflow prediction at zhangjiashan station based on the five models in the validation period it is can be observed that the ann and svm models have poor performances and the performance of wa svm was better than the ann and svm meanwhile the monthly streamflow was well simulated by the emd svm and m emdsvm models and their performances are better than the wa svm fig 17 shows a scatter plot of the streamflow predictions by the five models for zhangjiashan station it can be seen that the emd svm and m emdsvm models have better performances and the performances of them were both better than the wa svm at zhangjiashan station however the prediction accuracy of the m emdsvm model does not have clearly improved for weak non stationary monthly streamflow series moreover fig 18 illustrates a taylor diagram of streamflow prediction at zhangjiashan station based on the five models in the validation period it can be seen that the ann and svm models have poor performances and the performance of the wa svm was better than them the monthly streamflow was well simulated by the emd svm and m emdsvm models and their performances are better than the wa svm meanwhile the points of the emd svm and m emdsvm were almost close together which further indicates the prediction accuracy of the m emdsvm model does not clearly improved in weak non stationary streamflow series similarly the performances of the five models obtained in fig 18 were consistent with those in table 9 and figs 16 17 from the above figures and tables it can be found that the performance of the emd svm was better than the single svm model the emd decomposition has obvious effects on the non stationary monthly streamflow series and can strikingly improve the prediction accuracy the weak non stationary monthly streamflow series contains fewer noise components hence the influence of the end effect on the emd model in the prediction accuracy of monthly streamflow was relatively weak however the svm model performs well in prediction of non stationary sequences thus similar prediction accuracy can be obtained when using the m emdsvm and the emd svm model to predict weak non stationary sequences however the noise components contained in strong non stationary sequences are larger than those in weak non stationary sequences hence their influence on the end effect in the emd model for prediction of monthly streamflow series could not be ignored therefore the m emdsvm can further improve the prediction accuracy and greatly reduce the prediction error when dealing with strong non stationary monthly streamflow sequences however the wa has poor adaptability and presupposed subseries numbers which indicated the wa is lack of physical meaning moreover du et al 2017 found that wa also has future data issue caused by boundary condition occurring during developing process which makes the subseries of wa contain future information then quilty and adamowski 2018 developed an improvement strategy to solve the future data by removing the future information containing in training set however the development strategies mentioned in quilty and adamowski 2018 are not be adopted and the dwt which has been proved to have future values deficiency du et al 2017 quilty and adamowski 2018 was employed as a reference decomposition method in this present study it should be noted that the emd was selected as main technology because of its better adaptability and more solid physical mechanism compared with the wa given that the major objective of this study is to improve the emd svm by employing a modified multivariate fitting function in order to eliminate the boundary effect of traditional emd the deficiency of the dwt method mentioned by du et al 2017 and quilty and adamowski 2018 was overlooked at present du et al 2017 and quilty and adamowski 2018 found that these hybrid models consisting of the dwt caused higher prediction performance than actual situation because of the future values contained in subseries nevertheless the performance of the m emdsvm has been proved to be better than the wa svm in this present study which further verified the robustness of the improved emd svm note that the improvement strategy proposed by quilty and adamowski 2018 was so interesting that the performances of the m emdsvm will be compared with the wa svm by following the development strategies mentioned by quilty and adamowski 2018 for non stationary streamflow prediction in the future study 4 6 discussion in order to check the suitability of the scene that 80 as training period and 20 as validation period different lengths of 50 60 70 80 and 90 whole monthly streamflow data series has been employed as training period of m emdsvm model which is proven to have the best performances among the five models and the corresponding remain period as validation period the values of nse of different training period at huaxian xianyang and zhangjiashan stations are exhibited in table 10 it can be seen that the prediction performance changed with the length of training period increasing at three stations the prediction accuracy of 50 monthly streamflow data series was lower and prediction accuracy increasing with the length of training period increasing between 60 and 80 the machine learning obtains main information hidden in data series by analyzing data series and builds prediction model with obtained information the longer the sequence length the more information the sequence contains however the sample of monthly streamflow always is small thus the prediction performance of monthly streamflow will increase with the length of training period increase see table 10 the prediction performances of 70 80 and 90 data series are all good which means training period containing 70 of the length of data series already can provide enough information for getting high prediction accuracy however machine learning including svm model has overfitting problem when training period contain mass data thus the prediction performances of 90 monthly streamflow series less than that of 80 which because the 90 monthly streamflow series employed as the training period caused the overfitting problem of model the prediction performance of 80 data series was best among the five lengths of training period which proved the suitability of the scene that 80 as training period and 20 as validation period this scene also has been adopted by some previous studies karthikeyan and kumar 2013 huang et al 2014a zhao et al 2017 5 conclusions the prediction accuracy and ability of the m emdsvm was explored by simulating monthly streamflow series with weak or strong non stationarity in the wrb in the present study the performance of the wa svm was inferior to the emd svm due to its poor adaptability caused by mother wavelet and presupposed subseries numbers the emd svm performed better in predicting the weak non stationary streamflow series at zhangjiashan station compared with the ann and svm alone and wa svm the performance of the m emdsvm model was similar to that with the emd svm model therefore the m emdsvm model did not obviously improve the accuracy in predicting weak non stationary series in addition the five models were employed to predict the monthly streamflow series with strong non stationary series at huaxian station the performance of the m emdsvm model was the best among the five models moreover the results of the m emdsvm model at xianyang station were similar with those at huaxian station note that the nse values of the m emdsvm model were as high as 99 48 and 98 57 at huaxian and xianyang stations respectively which further improved the high stability of the m emdsvm model for strong non stationary monthly streamflow series thus the m emdsvm model has good stability and high prediction accuracy for strong non stationary streamflow series therefore this study provides a superior choice for predicting monthly streamflow series because the influence of climate change and human activities on streamflow is intensifying providing a model with high prediction accuracy and good stability is extremely meaningful for optimal reservoir operation and regional water resources management acknowledgements this study was jointly funded by the national key research and development program of china grant number 2017yfc0405900 the national natural science foundation of china grant number 51709221 the planning project of science and technology of water resources of shaanxi grant numbers 2015slkj 27 and 2017slkj 19 the china scholarship council grant number 201608610170 the open research fund of state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research grant number iwhr skl kf201803 and the doctorate innovation funding of xi an university of technology grant number 310 252071712 declaration of competing interest none 
6827,monthly streamflow prediction can offer important information for optimal management of water resources flood mitigation and drought warning the semi humid and semi arid wei river basin in china was selected as a case study in this study a modified empirical mode decomposition support vector machine m emdsvm model was proposed to improve monthly streamflow prediction accuracy the accuracy was improved by introducing polynomial fitting to amend the error caused by the boundary effect existing in the counting process of empirical mode decomposition emd meanwhile the computational process of the emd was analyzed to confirm the decomposition method for the emd the root mean square errors mean absolute error mean absolute percentage error and nash sutcliffe efficiency coefficient were adopted as the standards to evaluate the performance of the artificial neural network ann svm wa svm emd svm and m emdsvm models meanwhile the performance of the m emdsvm model with different lengths of training dataset was compared and analyzed moreover the monthly streamflow series with various non stationary levels were simulated to investigate the prediction capacity of the m emdsvm model results indicated that 1 the ann model had the worst performance among the five models at all stations whereas the emd svm model performed better than the wa svm with better metric values 2 for strong non stationary series the performance of the m emdsvm model was superior to the emd svm 3 for weak non stationary series the performance of the m emdsvm model was similar with the emd svm generally the findings of this study showed that more accurate prediction of strong non stationary streamflow could be achieved using the proposed modified emd svm model than single svm model keywords support vector machine modified empirical mode decomposition monthly streamflow prediction non stationary 1 introduction the accurate prediction of streamflow is of great significance for utilization and management of sustainable water resources reliable streamflow prediction is particularly important for hydrological operations e g efficient operation and planning of reservoirs optimal operation of hydropower stations for understanding regional water resources carrying capacity and for environmental protection solomatine and shrestha 2009 guo et al 2011 huang et al 2014a b fang et al 2017 hence a large number of studies have been conducted to investigate streamflow prediction in recent decades typically numerical models with a physical basis are utilized to predict streamflow bittelli et al 2010 partington et al 2012 they quantify streamflow through a governing equation that is based on proper assumptions and boundary conditions however these models require a large amount of accurate data for parameter calibration actually it is extremely difficult to gain adequate and accurate data for some un surveyed areas which leads to poor model performance and high uncertainty yoon et al 2011 numerous studies have been focused on the investigation of time series models e g auto regressive ar moving average ma and multiple linear regression mlr models for streamflow prediction salas 1980 wu et al 2009 these are based on the hypothesis that a linear relationship exists between the input and output of these models thus their performance is poor without the important information hidden in the nonlinear relationship because artificial neural networks anns have good performance in dealing with nonlinear time series there are numerous ann applications for streamflow prediction yoon et al 2007 guo et al 2011 however the anns also have some drawbacks e g slow learning and traps related to local minimization value and over fitting that make it difficult to obtain satisfactory results when dealing with complex hydrological processes the use of a support vector machine svm was proposed by cortes and vapnik 1995 svm is based on vapnik chervonenkis vc dimension theory and the structural risk minimization principle which can theoretically overcome part convergence and achieve a globally optimal solution svm has proven an effective prediction tool and has been widely applied in the hydrological field in recent decades lafdani et al 2013 introduced an svm model for prediction of daily suspended load while liu and lu 2014 adopted the svm model to predict the water quality in an agricultural nonpoint source polluted river streamflow is influenced by a large number of factors such as precipitation temperature climatic conditions and so on and is characterized by nonlinear non stationary and uncertain conditions especially in extreme climates huang et al 2016a b liu et al 2019a fang et al 2019 thus a monthly streamflow series is composed of trend periodic and noise components zhang et al 2015 in some former studies bittelli et al 2010 streamflow series were predicted directly without data preprocessing which may cause the loss of some important information contained in the original time series chou and wang 2004 suggested that it is difficult to reflect the change mechanisms of streamflow series using a prediction model established using only one mixed frequency component therefore it is necessary to preprocess monthly streamflow time series to improve prediction accuracy in other studies armstrong 1989 temraz et al 1996 zou and yang 2004 gulhane et al 2005 hibon and evgeniou 2005 streamflow time series was decomposed into different components that were then used as input for developing streamflow prediction models although the method of decomposition is empirical in nature anderson 1927 put forward a theory that noise was represented intuitively through decomposing the time series into several components a method of extracting period and trend components from time series was proposed by frisch 1931 then macaulay 1931 constructed a time series decomposition procedure as time went on fourier analysis and associated spectrum analysis created by wiener 1949 became widely used for decomposing stationary time series however the principles of these methods involve analyzing time series in the frequency domain which leads to loss of important information regarding instantaneous frequency boashash 1992 in order to decompose non stationary time series analyzing the time series in time and frequency domains simultaneously was attempted using window fourier transform wft nawab and quatieri 1988 however because of the existence of a single fixed window during the decomposition process wft can only grasp the low frequency events or noise in a given moment karthikeyan and kumar 2013 the complete information of a time series should contain low frequency and noise simultaneously thus the concept of a wavelet was proposed by morlet et al 1982 the wavelet approach solved the two main drawbacks of fourier analysis i e the infinite domain of sine and cosine waves and lack of time frequency localization thus it has been extensively applied in hydrological analysis in recent years kisi 2010 nourani et al 2011a nourani et al 2011b mehr et al 2013 liu et al 2014 shoaib et al 2015 2016 moosavi et al 2017 the concept of empirical mode decomposition emd proposed by huang et al 1998 is a non stationary time series analysis technique emd is based on the theory of local scale separation and does not need predetermined basis functions which is totally different from wavelet analysis and almost all the other decomposition techniques huang et al 1998 lee and ouarda 2010 kim and oh 2013 thus emd could adaptively decompose a time series into a series of frequency components referred to as intrinsic mode functions imfs harmonics analysis is not required for emd analysis due to the adaptive basic properties therefore compared with the wavelet approach emd is an ideal method for analyzing nonlinear and non stationary data huang and wu 2008 because they are influenced by the changing environment monthly streamflow series is complexly nonlinear and non stationary huang et al 2014a hence in this study emd was adopted to deal with the data preprocessing instead of wavelets however emd has a boundary effect and huang et al 1998 proposed a solution by adding artificial time series to extend the raw time series called characteristic waves at both boundaries for eliminating boundary effect at present artificial intelligence algorithms and reproduction of the period of time series are the most common methods for making characteristic waves karthikeyan and kumar 2013 however the neural network extending method requires a large amount of data to train the model and the networks also need to be adjusted according to the different data types used the mirror extension algorithm is an effective method employed to reproduce the period of a time series but this algorithm requires that the end of the time series be extreme points thus there are some restrictions when these two methods are applied to hydrological prediction in this paper an improved polynomial fitting method was employed to eliminate the end effect the extreme values of the end point are obtained by fitting the extreme points near the end of the time series however there were two decomposition methods that the training and validation datasets were decomposed altogether or separately to choose for emd and the computational process of emd will be analyzed to confirm which method is suitable for emd as mentioned above emd has been widely used in data preprocessing for streamflow prediction and the prediction accuracy has been improved however the current question is whether the degree of improvement in prediction accuracy using emd to eliminate noise varies in relation to different streamflow series e g highly nonstationary or weakly nonstationary time series to the best of our knowledge few studies have been focused on this question therefore the degree of improvement was studied systematically in this study meanwhile the performance of different length of 50 60 70 80 and 90 of monthly streamflow data series acted as training period of m emdsvm model was compared to analyze what will be the effect on modeling results if the length of dataset changed the primary objectives of the present study were 1 to propose a modified model of streamflow prediction that improves the emd based support vector machine emd svm by employing a modified multivariate fitting function to eliminate the boundary effect of traditional emd 2 to choose a suitable decomposed method for emd 3 to discuss systematically the degree of improvement in prediction accuracy from using emd as the data preprocessing tool for different types of streamflow series 4 to confirm the suitability of choosing 80 of data series acted as training period in the rest of this paper section 2 describes details of the study area and data feature section 3 provides a detailed introduction to the methodology mentioned above including wa emd and svm in section 4 the results of the case study are presented and discussed while the conclusions drawn from this research are given in section 5 2 study area and data the wei river basin wrb was chosen as the study area in this paper fig 1 the wei river is the largest tributary of the yellow river and has a total length of 818 km and total area of 1 35 105 km2 the topography and the geomorphology of the wrb are complex and the elevation decreases from the western loess hilly gully area to the eastern guanzhong plain the wrb is located in a representative semi arid and semi humid zone high temperatures and rainy weather takes place frequently in summer while the weather in winter is cold and rainless the annual precipitation of the wrb is about 559 mm zhang et al 2008 liu et al 2018 2019b and the average annual evaporation from water surfaces is 660 1600 mm huang et al 2014c zhang et al 2015 the wei river system is developed and there are many tributaries on both sides of the river the average annual water resources in the wrb are 1 11 1010 m3 of which the natural river streamflow is 1 00 1010 m3 the groundwater resources amount to 6 99 109 m3 the repeated calculation amount is 5 97 109 m3 it is worth mentioning that the wrb is an important grain producing area and an important economic development zone in the the belt and road construction in china considered with the climate these mean that the water security issues in the wrb are particularly critical therefore long term streamflow prediction in the wrb has great significance for the regional economy and for water resource security the monthly streamflow data from huaxian xianyang and zhangjiashan hydrological stations in the wrb were employed in this study these stations have monthly streamflow data covering january 1960 through december 2010 which was obtained from hydrologic manual the data quality was strictly controlled during its release the digital features of the annual streamflow at the three hydrological stations are exhibited in table 1 table 1 shows that the inter annual variation at xianyang station is very significant and the inter annual variation at zhangjiashan station is relatively weak in this paper the monthly streamflow data covering january 1960 to december 2000 were selected for the training period while data covering january 2001 to december 2010 were selected for the validation period 3 methodologies 3 1 empirical mode decomposition emd emd is an adaptive and powerful method proposed by huang et al 1998 for the analysis of the nonlinear and non stationary data it is the main component of the hilbert huang transform hht which provided a new method for data analysis huang and wu 2008 in general many studies utilize the hht and wavelet analysis wa to analyze a time series however wa was derived from mathematical theory while hht was born of practical experience the emd method has been employed to decompose the time series x t into some orthogonal and band limited functions ci t i 1 m called intrinsic mode functions imfs the remainder works as r t representing the overall trend of the original sequence then the original time series could be expressed as the sum of all imfs and residual items as follows 1 x t i 1 m c i t r t note that the adaptivity of emd to local variation allows the imfs to have clear physical meaning regarding instantaneous frequency and amplitude therefore emd can effectively deal with nonlinear and non stationary data by its ability to decompose a time series into subseries having physical meanings of time and frequency huang and wu 2008 however no nonlinear data series can be explained by simple linear superposition therefore the description of nonlinear data series with linear stacking has no physical significance nevertheless emd provides an effective explanation of nonlinear data series with physical subseries therefore emd can efficiently obtain important information about nonlinear and non stationary data huang et al 1998 kijewski correa and kareem 2007 lee and ouarda 2011 according to the definition of imf all imfs should satisfy the two following conditions 1 in the whole data segment the difference between the number of extreme points and the number of zero crossings must be zero or at most differ by one and 2 at any point the average value of the envelope formed by the local maximum points and the envelope formed by the local minimum points must be zero the imfs are produced by sifting the raw data which is an iterative process the main aim of the emd function is to eliminate the influence of noise and to find the periodic component of the streamflow sequence the details of the iterative procedures are described in huang et al 1998 and huang et al 2014b the iterative processes are repeated until the stop condition is satisfied huang et al 1998 employed the standard deviation sd as the imf stop condition the sdk is defined as follows 2 sd k t 0 t h 1 k 1 t h 1 k t 2 h 1 k 1 2 t according to huang et al 1998 when the value of sdk falls in the interval 0 2 0 3 then c1 t h1k is specified which is the first imf many tests show that when sdk is within 0 2 0 3 the imfs obtained by iteration have enough physical meaning meanwhile the residual component has the monotonicity character meanwhile the condition if is monotonicity or not was employed as the stop condition during the iteration process and the total decomposition process combining with the two stop conditions the optimal number of imf s could be obtained with an adaptive method however there is a boundary effect problem in the emd process pointed out by huang et al 1998 it is impossible for the maximum and minimum to exist simultaneously at the end of an original sequence that is a boundary fluctuation phenomenon will appear in the emd process and the error caused by the boundary fluctuation will contaminate the whole sequence by the iterative process thus boundary processing is crucial to the emd process the failure of which might cause invalidity of the decomposed imf due to the boundary fluctuation propagating throughout the whole data set huang 2002 proposed that at the two ends of the signal and according to the amplitude and frequency of the boundary signal two characteristic waves be added details of the processes can be found in huang 2002 a large number of studies have been carried out to eliminate the influence of the boundary effect on emd some of these corrective methods have been accepted such as those proposed by huang 2002 via the characteristic wave method the slope method dätig and schlurmann 2004 the extremum continuation method huang et al 2003 the extremum image continuation method rilling et al 2003 and the artificial neural network method however the ann method is prone to a local minima problem and the speed of this method will obviously be slow when the amount of predicted data is large the mirror extension method needs to cut the raw data in order to put the mirror at the extreme point therefore this method is not effective in dealing with short sequences according to principle these methods can be divided into two categories extreme value data extension and waveform extension for this paper an improved method was adopted to extend the extremum of the sequence in order to eliminate the boundary effect two maxima and minima were extended from both ends of the data the algorithm is as follows the number of sequences containing maxima and minima is m and n m m 1 m 2 m i n n 1 n 2 n j respectively the positions of the maximum and minimum points in a sequence composed of maximum and minimum are im m m 1 m 2 m i and in n n 1 n 2 n j respectively the positions of the maximum and minimum points in the original sequence are tm and tn respectively the length of the original is g g 1 2 g the value of the maximum and minimum is u i i 1 2 m and v j j 1 2 n in this paper the slope method was used to extend the maximum and minimum values the calculation process is displayed as follows 3 u 0 u 1 k t m 0 t m 1 4 v 0 v 1 k t n 0 t n 1 5 u m 1 u m k t m i 1 t m i 6 v n 1 v n k t n j 1 t n j eqs 3 to 6 were applied to determine the values of the maximum and minimum that were extended at both ends of the sequence in which the values of tm 0 and tn 0 are 1 and the values of tm i 1 and tm j 1 are g 7 u 0 u 0 u 0 x 1 x 1 u 0 x 1 8 v 0 v 0 v 0 x 1 x 1 v 0 x 1 9 u m 1 u m 1 u m 1 x g x g u m 1 x g 10 v m 1 v m 1 v m 1 x g x g v m 1 x g then eqs 7 and 8 were employed to confirm the final values of u 0 v 0 and u m 1 v m 1 determining the positions of continuation extreme points at left end of the data 11 k 1 t m 2 t m 1 i m 1 i n 1 t n 2 t n 1 i m 1 i n 1 2 t m 1 t n 1 m n 1 eq 11 is used to determine the number of items contained in the first characteristic wave 12 t m 0 t m 1 k 1 δ t 13 t m 1 t m 1 2 k 1 δ t 14 t n 0 t n 1 k 1 δ t 15 t n 1 t n 1 2 k 1 δ t 16 u 1 u 0 17 v 1 v 0 eqs 12 to 15 are used to determine the positions of two maximum and minimum that extended t the left point where t is the minimum positive integer that makes the values of tm 1 1 and tn 1 1 the method of extension of extreme value at the right end is in line with the method discussed above a new set of extreme sequences is generated by the extreme value continuation method described above then the new extreme value sequences are substituted into the iterative process to decompose the time series in this paper an improved emd is proposed based on the extreme value continuation method mentioned above it is important to note that the fitting curve in the modified emd needs to be cut out according to the position and length of the original sequence however there were two decomposition methods that the training and validation datasets were decomposed altogether or separately can be chose by emd as mentioned above the main computational process of emd was that firstly the extreme points of data series were picked out secondly the upper and lower envelopes were obtained by fitting extreme points with cubic spline curve finally the imfs and residual item were generated by sifting process by studying the emd s computational process earnestly it can be found that there was a certain probability of mutual information sharing during the spline curve fitting process in second step of emd s computational process and there is no probability in other steps then the upper and lower envelopes of overall decomposition method have been compared with that of piecewise decomposition method to further learn whether the mutual information sharing phenomenon occur or not the cubic spline curve of emd with different decomposition methods of monthly streamflow series at huaxian hydrological station were shown in fig 2 it can be found from fig 2 that there was almost no difference between the upper and lower envelopes for overall decomposition method and piecewise decomposition method except for the breakpoint location the difference of breakpoint location was caused only by the end effect of emd and there was no mutual information sharing during emd s counting process no matter which decomposing method been used in this study the main goal was to eliminate the end effect of emd by proposing a linear extremum extension method however the number of imfs of emd will change with varying the length of data series thus the number of imfs may be different between training and validation dataset using piecewise decomposition method which will make the emd svm fail to work at the same time the error caused by end effect will happen twice which will reduce the prediction accuracy of emd svm thus the method of overall decomposition was chose in this study 3 2 wavelet analysis wa the concept of the wavelet transform was first proposed in 1974 by j morlet an engineer who is engaged in oil signal processing in france unlike fourier transform ft wa is a local transformation of time and frequency can effectively fetch information from time series through multi scale refinement analysis on time series using scaling and translation daubechies 1990 torrence and compo 1998 a detailed introduction of the difference between wa and ft was demonstrated by sifuzzaman et al 2009 the comprehensive and detailed information of wa can be found in labat 2005 nourani et al 2014 sang 2013 wa has been proved was an availably decomposition tool for analyzing time series and applied in runoff time series analysis as period and trend et al kisi 2010 nourani et al 2011 2012 danandeh mehr et al 2013b yarar 2014 shoaib et al 2015 2016 moosavi et al 2017 the decomposition level of original streamflow series was 6 which is the same with the number of imfs the mother wavelet db5 was employed in this study 3 3 genetic algorithm ga the genetic algorithm was proposed by john holland in the early 1970 s which is based on the concepts of natural selection and natural genetics the basic idea of ga is to introduce the natural law of survival of the fittest into computer programming to obtain the optimal solution a set of chromosomes is called a population that represents the solution set according to the fitness function of choice and by genetic selection crossover and mutation a number of individuals an individual acts as a chromosome of the primary population were selected to generate a new generation population with good fitness value finally an individual with optimal fitness is though evolving that is the optimal solution or the suboptimal solution thus ga could obtain global optimal solution or suboptimal solution in the short time with the strong ability of global parallel search therefore the ga was employed to optimize the penalty factor c and kernel function g of svr in this paper the optimization of svm parameters c and g based on ga is dependent on its fitness function the definition of the fitness function as follow 18 min f c g 1 n i 1 n y i y 2 s t c c min c max g g min g max eq 18 is used as the fitness function of ga to optimize the parameters c and g of svm in which yi is the i th observed value during training period and yi is the i th prediction value of svm since the details of the ga have been documented in a large number of papers and books wang 1991 ritzel and wayland eheart 1994 franchini 1996 franchini and galeati 1997 vasques et al 2000 sharif and wardlaw 2000 khu et al 2001 the counting process of ga was omitted in this paper a sensitivity analysis on different parameters values have been conducted to optimize the parameters of ga in this study in which the different parameter values were determined by referring to related studies vasques et al 2000 sharif and wardlaw 2000 khu et al 2001 eiben and smit 2011 it should be noted that miller and goldberg 1995 pointed out that increased selection pressure can be provided by simply increasing the tournament size as the winner from a larger tournament will on average have a higher fitness than the winner of a smaller tournament therefore the parameter tournament size was selected instead of selection pressure in this present study ultimately the values of the maximum generation crossover percentage mutation rate and tournament size were selected as 200 0 9 0 01 and 4 respectively 3 4 support vector machine svm the support vector machine svm is one of the most effective tools in the prediction field and was created by vapnik 1995 unlike traditional machine learning svm simplifies complex problems by mapping the complex nonlinear problem input factors into high dimension space with kernel functions to transform the complex nonlinear problems into linear problems the main idea of svm is to establish a classification hyperplane as the decision surface so that the separation edge between the positive case and the counter example is maximized svm is based on statistical learning theory more precisely svm is the approximate representation of structural risk minimization because a large number of papers and books have described svm theory in detail vapnik and vapnik 1998 carrier et al 2013 ch et al 2013 he et al 2014 fang et al 2018a the description of svm is omitted from this paper the advantage of svm is to neatly solve the inner product operation in the high dimensional space by introducing kernel function so the prediction accuracy would be enhanced with appropriate kernel function generally the effective kernel functions of svm are linear polynomial sigmoid radial basis function rbf and so on in this paper rbf is employed as the kernel function 19 k x x j exp x x j 2 2 σ 2 where σ represents the gaussian noise level of standard deviation 3 5 the modified emd based svm prediction model the modified emd was adopted to decompose monthly streamflow series that consisted of one residual series and several imfs then the residual series and imfs were modeled by the svm model respectively then the summation of the prediction output of subseries make up the prediction monthly streamflow series in addition the ga was employed to optimize svm parameters to increase the prediction accuracy the specific algorithm processes of the m emdsvm prediction model are displayed in fig 3 in this paper 80 of the input and output data january 1960 to december 2000 was used for the training sets of svm and the last 20 january 2001 to december 2010 was selected as the validation sets during the modeling process with m emdsvm note that the details of the computing process for all three stations were consistent given space limitations details of only the computing process used for the huaxian station will be shown in the next section 3 6 heuristic segmentation algorithm the heuristic segmentation algorithm was an effective mutation detection tool for nonlinear and non stationary streamflow series and was proposed by bernaola galván et al 2001 since the details of the heuristic segmentation algorithm have been introduced in a large number of papers and books gong et al 2006 chen and xie 2008 huang et al 2014b 2016 the counting process of the algorithm was omitted in this paper in general the value of parameter p 0 should fall between 0 5 and 0 95 and the value of parameter l 0 must be greater than or equal to 25 huang et al 2016 3 7 four indicators used for comparison of performance the root mean square error rmse the mean absolute error mae the mean absolute percentage error mape and the nash sutcliffe efficiency coefficient nse were employed as an evaluation index system to measure the performances of the ann svm emd svm and m emdsvm models the rmse mae mape and nse are defined as 20 rmse 1 n i 1 n y i y i 2 21 mae 1 n i 1 n y i y i 22 mape 1 n i 1 n y i y i y i 100 23 nse 1 i 1 n y i y i 2 i 1 n y i y 2 the rmse is an ideal error index used to evaluate the fitness of high streamflow values the mae measures the absolute value of overall errors the mape is an error index that can be used to compare errors that differ in level and the nse evaluates the power of the hydrological model yoon et al 2011 huang et al 2014a fang et al 2018b here n denotes the total number of data sets meanwhile the line chart scatter diagram and taylor diagram were also employed to evaluate the performances of those models in this present study 4 results and discussion 4 1 identification of the possible change point of the three hydrological stations the heuristic segmentation algorithm was employed to detect the abrupt change point of the annual streamflow series at huaxian station and its result is shown in fig 3 it is obviously from fig 4 that the t value is largest in 1990 and that the p tmax value of this point is 0 99 this is greater than the critical value 0 95 therefore the year of 1990 is the abrupt change point in the annual streamflow series in the area above huaxian station meanwhile it can be also seen that the abrupt change point of the annual streamflow series in the basin above xianyang station is 1993 whose p tmax value is 0 98 and that there is no abrupt change point in the annual streamflow series in the basin above zhangjiashan station the annual streamflow series of the three hydrological stations are presented in fig 5 fig 5 shows that the fluctuation of annual streamflow at huaxian is the most obvious among the three stations and that the fluctuation of annual streamflow at xianyang station is obviously weaker than at huanxian station however the fluctuation of annual streamflow at zhangjiashan station is the weakest meanwhile ns ding yi ming 2010 an index of non stationarity level of time series was employed to quantitative calculate the non stationarity level of streamflow series at huaxian station and xianyang station and zhangjiashan station whose value is between 0 and 1 and the non stationarity level is proportional to the value of ns the values of ns at huaxian station and xianyang station and zhangjiashan station were 0 81 0 80 and 0 47 respectively and ns huaxian ns xianyang ns zhangjiashan the result of ns shown that the non stationarity level of streamflow series at huaxian station and xianyang station was stronger than that at zhangjiashan station through the analysis above it was determined that the non stationary component of the annual streamflow at huaxian and xianyang stations is strong and that of huaxian station is stronger than of xianyang station at the same time the non stationary component of the annual streamflow at zhangjiashan station is weakest among the three stations in this paper the monthly streamflow at huaxian xianyang and zhangjiashan hydrological stations was used to verify the prediction accuracy of the m emdsvm model and to explore the prediction performance for different kinds of monthly streamflow series 4 2 the original series decomposed the monthly streamflow obtained from the hydrologic manual was decomposed by the modified emd the emd and the wa which were introduced in section 2 the decomposition results of the monthly streamflow series at huaxian xianyang and zhangjiashan hydrological stations are exhibited in figs 6 to 8 respectively it can be seen from fig 6 that the monthly streamflow at huaxian hydrologic station was decomposed into six imfs and one residual based on the emd and m emd respectively the imf1 is an extremely irregular component of the monthly streamflow series meanwhile the high irregular also can be found in first level subseries d1 of wa in fig 6 which further proves that the monthly streamflow series is nonlinear and nonstationary it is usually difficult to predict highly nonlinear and nonstationary time series accurately hence pre processing the initial series before prediction is necessary the fig 6 shows that the energy contained in imfs of m emd becomes purer and the trend of residual terms becomes more obvious using the modified emd method it proves that the m emd can effectively eliminate the modal confusion caused by the end effect of the emd however the last level subseries of wa still contains periodic components that proved the shortage of physical mechanism during the wavelet decomposition process it indicated that the capacity of decomposition of wa inferior to emd and wa was not the best choice for hybrid model for prediction problems du et al 2017 quilty and adamowski 2018 the results obtained at huaxian and zhangjiashan stations are similar to those at huaxian station in figs 7 and 8 it is worth mentioning that the r values of the three stations has an obvious downward trend which is closely linked with the increasing water demand on the guanzhong plain this shows that the monthly streamflow in the wrb has exhibited a remarkable decline the belt and road program promoted the rapid economic development of this basin leading to a large demand for water resources however the decrease in monthly streamflow threatens the water security of the belt and road therefore it is critically important to predict streamflow accurately to provide the information needed by local governments to make scientific long term planning for water resources 4 3 determining the input variables the input variables of models are selected from the following eight scenarios which are demonstrated in table 2 where x t 1 x t 2 x t 3 x t 4 x t 5 x t 6 x t 7 x t 8 x t 9 x t 10 x t 11 and x t 12 are the streamflow at retardation time of 1 2 3 4 5 6 7 8 9 10 11 and 12 months respectively the best input combination of each subseries can be found from eight scenarios with four evaluation indicators rmse mae mape and nse 4 4 method for parameter selection because the monthly streamflow series is highly nonlinear and nonstationary the emd the m emd and wa were employed to decompose the time series into various subseries which represent different frequencies and trend components contained in the monthly streamflow series the subseries at the three hydrologic stations shown in fig 6 were chosen as the input variables for svm model respectively the svm model is sensitive to the parameters c and g thus it is important to obtain the optimal parameters in this study a genetic algorithm ga was employed to optimize the value of c and g fig 9 shows one of the optimization process and the optimal parameters of the svm model obtained through the ga at huaxian station ultimately the optimal parameters c and g exhibited in table 3 in this paper an ideal non sensitivity coefficient was obtained by experimental analysis whose value was 0 001 4 5 comparative analysis the prediction of the time series was conducted using the svm model with the input variables of each subseries respectively then the output variables of each subseries was added this is the modeling procedure of the wa svm emd svm and m emdsvm the evaluation results of subseries decomposed by wa emd and m emd at huaxian hydrological station are shown in table 4 it can be found from table 4 that the prediction performance of s1 is poor in three models m emdsvm emd svm and wa svm in terms of mape values 14 28 21 50 and 257 40 and nse values 44 76 50 37 and 65 79 the s1 subseries is highest frequency portion of runoff time series see fig 6 and its prediction was difficult however the performance of s1 in emd svm was poorer than wa svm which was because that the frequency of s1 decomposed by emd and m emd was higher than that of wa in other words wa has poor adaptivity because the necessary of mother wavelet which made the subseries do not have physical meaning thus it was further proved the decomposition capacity of emd was stronger than that of wa due to the physical mechanism of emd simultaneously the superior of the m emd is also can be found from table 4 with the worst performance of s1 and the best performance of other subsequence the same results can also be obtained at xianyang hydrological station and zhangjiashan hydrological station see tables 5 and 6 4 5 1 performances of five models in strong non stationary monthly streamflow prediction the performances of the modified model proposing in this paper were compared with that of the single svm and artificial neural network models meanwhile the prediction ability of non stationary and non linear monthly streamflow of emd svm and m emdsvm was composed with that of wa svm the evaluation results obtained by the five models in predicting strong non stationary monthly streamflow series at huaxian were exhibited in table 7 and figs 10 13 it can be obtained from table 7 that the ann model has poor performance compared with the other models the svm model shows good performance reducing the rmse mae and mape values by 9 96 13 13 and 2 35 compared with the ann model the wa svm model has better performance and was superior to the svm model reducing the rmse mae and mape values by 45 29 38 95 and 35 38 compared with the ann the emd svm model has even better performance and was superior to the svm model its better performance for rmse mae mape and nse was indicated by their values 0 02 0 67 19 17 and 97 01 respectively reducing the rmse mae and mape values by 99 28 61 05 and 72 66 compared with the svm model the m emdsvm shows the best performance among the five models and outperforms the svm wa svm and emd svm models in all standard statistical indicators reducing the rmse mae and mape values by 99 64 82 56 and 88 08 compared with the svm model the ann model shows the minimum value of nse while the svm is 61 21 which is less than 29 57 of wa svm 58 49 of emd svm and 62 52 of m emdsvm fig 10 shows the streamflow prediction at huaxian station based on the ann svm wa svm emd svm and m emdsvm models in the validation period overall the ann model has the worst performance among five models and the svm model performed better than the ann being similar with table 7 the wa svm has better performance than the ann and svm but worse than the emd svm and m emdsvm the emd svm and m emdsvm predicted well the monthly streamflow series in the validation period and m emdsvm performed best among five models moreover fig 11 shows a scatter plot of the streamflow predictions by the five models at huaxian station indicating that ann has the worst performance with the smallest r squared value and that m emdsvm has the best performance in prediction the strong non stationary monthly sequences linear trend nearest to the 45 degree line among the five models furthermore fig 12 shows the taylor diagram of streamflow prediction performance at huaxian station for the ann svm wa svm emd svm and m emdsvm models in the validation period it can be seen from fig 12 that the ann shows the worst performance and the performance of the wa svm was better than ann and svm meanwhile both of the emd svm and m emdsvm performed better than wa svm the point representing the m emdsvm was most close to the point representing observation among the five models which proved the superiority of the m emdsvm in monthly streamflow prediction the performances of the five models obtained in fig 12 were consistent with those obtained in table 7 and figs 10 11 from the above figures and table it can be found that the svm performed better than ann because the svm model uses statistical learning theory of the vapnik chervonenkis vc dimension theory and structural risk minimization principle it was able to overcome issues with the local minima and over fitting hence its performance is better than the ann model this finding was also obtained by wang et al 2009 and kalteh 2013 however with the effect of human activities and climatic variation monthly streamflow become nonlinear non stationary and complex meanwhile the main information would be lost directly using the original streamflow series as input variate of model thus the performances of svm and ann were the worst among the five models meanwhile the wa svm has better performance than the ann and svm but worse than the emd svm and m emdsvm in strong non stationary monthly streamflow prediction which proved the effectiveness of preprocessing strategy for monthly streamflow prediction the wa model needs predetermined basis functions to do decomposition calculation which makes it have poor adaptability and lack of physical mechanism however emd could adaptively decompose a time series into a series of frequency components without predetermined basis functions harmonics analysis is not required for emd analysis due to the adaptive basic properties compared with the wavelet approach emd is an ideal method for analyzing nonlinear and non stationary data thus in view of emd could solve the problem lacking physical meaning of wa perfectly emd has been employed to build the hybrid model for non stationary monthly streamflow prediction instead of wa meanwhile it can be seen from table 7 and figs 10 12 that the performances of the emd svm were better than wa svm which further proved the superiority of emd visually meanwhile the emd has been improved with a modified multivariate fitting function to eliminate the boundary effect of traditional emd which makes the imfs and r become purer this resulted in decrease of the rmse mae and mape values by 50 00 55 22 and 56 39 compared with the emd svm model as indicated in section 4 1 both of xianyang station and huaxian station belong to strong non stationary streamflow the monthly streamflow was also simulated by the five models the results obtained from table 8 and figs 13 15 at xianyang station were consistent with those at huaxian station specifically the performance of the ann model is the worst among the five models and the m emdsvm model has the best performance among all the models with the minimum rmse mae and mape values and the largest nse values with the rmse mae and mape decreased by 50 00 17 14 and 24 14 compared with the emd svm model table 8 the performance of the wa svm is inferior to emd svm 4 5 2 performances of five models in weak non stationary monthly streamflow prediction the evaluation results obtained using these five models for predicting the weak non stationary monthly streamflow series at zhangjiashan station were displayed in table 9 and figs 16 18 table 9 shows that the performances of the ann model and svm model are consistent with that in tables 7 and 8 it can be found that the performance of the wa svm is better than the ann and svm being similar with the term of strong non stationary monthly streamflow prediction the performance of wa svm is poorer than emd svm and m emdsvm it was determined from table 9 that the predictions of emd svm and m emdsvm for weak non stationary monthly streamflow series are good and that their rmse mae mape and nse values are basically the same fig 16 illustrates the streamflow prediction at zhangjiashan station based on the five models in the validation period it is can be observed that the ann and svm models have poor performances and the performance of wa svm was better than the ann and svm meanwhile the monthly streamflow was well simulated by the emd svm and m emdsvm models and their performances are better than the wa svm fig 17 shows a scatter plot of the streamflow predictions by the five models for zhangjiashan station it can be seen that the emd svm and m emdsvm models have better performances and the performances of them were both better than the wa svm at zhangjiashan station however the prediction accuracy of the m emdsvm model does not have clearly improved for weak non stationary monthly streamflow series moreover fig 18 illustrates a taylor diagram of streamflow prediction at zhangjiashan station based on the five models in the validation period it can be seen that the ann and svm models have poor performances and the performance of the wa svm was better than them the monthly streamflow was well simulated by the emd svm and m emdsvm models and their performances are better than the wa svm meanwhile the points of the emd svm and m emdsvm were almost close together which further indicates the prediction accuracy of the m emdsvm model does not clearly improved in weak non stationary streamflow series similarly the performances of the five models obtained in fig 18 were consistent with those in table 9 and figs 16 17 from the above figures and tables it can be found that the performance of the emd svm was better than the single svm model the emd decomposition has obvious effects on the non stationary monthly streamflow series and can strikingly improve the prediction accuracy the weak non stationary monthly streamflow series contains fewer noise components hence the influence of the end effect on the emd model in the prediction accuracy of monthly streamflow was relatively weak however the svm model performs well in prediction of non stationary sequences thus similar prediction accuracy can be obtained when using the m emdsvm and the emd svm model to predict weak non stationary sequences however the noise components contained in strong non stationary sequences are larger than those in weak non stationary sequences hence their influence on the end effect in the emd model for prediction of monthly streamflow series could not be ignored therefore the m emdsvm can further improve the prediction accuracy and greatly reduce the prediction error when dealing with strong non stationary monthly streamflow sequences however the wa has poor adaptability and presupposed subseries numbers which indicated the wa is lack of physical meaning moreover du et al 2017 found that wa also has future data issue caused by boundary condition occurring during developing process which makes the subseries of wa contain future information then quilty and adamowski 2018 developed an improvement strategy to solve the future data by removing the future information containing in training set however the development strategies mentioned in quilty and adamowski 2018 are not be adopted and the dwt which has been proved to have future values deficiency du et al 2017 quilty and adamowski 2018 was employed as a reference decomposition method in this present study it should be noted that the emd was selected as main technology because of its better adaptability and more solid physical mechanism compared with the wa given that the major objective of this study is to improve the emd svm by employing a modified multivariate fitting function in order to eliminate the boundary effect of traditional emd the deficiency of the dwt method mentioned by du et al 2017 and quilty and adamowski 2018 was overlooked at present du et al 2017 and quilty and adamowski 2018 found that these hybrid models consisting of the dwt caused higher prediction performance than actual situation because of the future values contained in subseries nevertheless the performance of the m emdsvm has been proved to be better than the wa svm in this present study which further verified the robustness of the improved emd svm note that the improvement strategy proposed by quilty and adamowski 2018 was so interesting that the performances of the m emdsvm will be compared with the wa svm by following the development strategies mentioned by quilty and adamowski 2018 for non stationary streamflow prediction in the future study 4 6 discussion in order to check the suitability of the scene that 80 as training period and 20 as validation period different lengths of 50 60 70 80 and 90 whole monthly streamflow data series has been employed as training period of m emdsvm model which is proven to have the best performances among the five models and the corresponding remain period as validation period the values of nse of different training period at huaxian xianyang and zhangjiashan stations are exhibited in table 10 it can be seen that the prediction performance changed with the length of training period increasing at three stations the prediction accuracy of 50 monthly streamflow data series was lower and prediction accuracy increasing with the length of training period increasing between 60 and 80 the machine learning obtains main information hidden in data series by analyzing data series and builds prediction model with obtained information the longer the sequence length the more information the sequence contains however the sample of monthly streamflow always is small thus the prediction performance of monthly streamflow will increase with the length of training period increase see table 10 the prediction performances of 70 80 and 90 data series are all good which means training period containing 70 of the length of data series already can provide enough information for getting high prediction accuracy however machine learning including svm model has overfitting problem when training period contain mass data thus the prediction performances of 90 monthly streamflow series less than that of 80 which because the 90 monthly streamflow series employed as the training period caused the overfitting problem of model the prediction performance of 80 data series was best among the five lengths of training period which proved the suitability of the scene that 80 as training period and 20 as validation period this scene also has been adopted by some previous studies karthikeyan and kumar 2013 huang et al 2014a zhao et al 2017 5 conclusions the prediction accuracy and ability of the m emdsvm was explored by simulating monthly streamflow series with weak or strong non stationarity in the wrb in the present study the performance of the wa svm was inferior to the emd svm due to its poor adaptability caused by mother wavelet and presupposed subseries numbers the emd svm performed better in predicting the weak non stationary streamflow series at zhangjiashan station compared with the ann and svm alone and wa svm the performance of the m emdsvm model was similar to that with the emd svm model therefore the m emdsvm model did not obviously improve the accuracy in predicting weak non stationary series in addition the five models were employed to predict the monthly streamflow series with strong non stationary series at huaxian station the performance of the m emdsvm model was the best among the five models moreover the results of the m emdsvm model at xianyang station were similar with those at huaxian station note that the nse values of the m emdsvm model were as high as 99 48 and 98 57 at huaxian and xianyang stations respectively which further improved the high stability of the m emdsvm model for strong non stationary monthly streamflow series thus the m emdsvm model has good stability and high prediction accuracy for strong non stationary streamflow series therefore this study provides a superior choice for predicting monthly streamflow series because the influence of climate change and human activities on streamflow is intensifying providing a model with high prediction accuracy and good stability is extremely meaningful for optimal reservoir operation and regional water resources management acknowledgements this study was jointly funded by the national key research and development program of china grant number 2017yfc0405900 the national natural science foundation of china grant number 51709221 the planning project of science and technology of water resources of shaanxi grant numbers 2015slkj 27 and 2017slkj 19 the china scholarship council grant number 201608610170 the open research fund of state key laboratory of simulation and regulation of water cycle in river basin china institute of water resources and hydropower research grant number iwhr skl kf201803 and the doctorate innovation funding of xi an university of technology grant number 310 252071712 declaration of competing interest none 
6828,a fully three dimensional hydrodynamic implicit numerical algorithm has been proposed for simultaneous simulation of fluid density variation and water table gradient in saturated porous media unlike the most of the performed researches that primarily restricted to solute transport simulation in confined or unconfined aquifers without proceeding to forecast water table transient situation the proposed model can truly handle corresponding problems in an unconfined aquifer having sharp water table gradient the algorithm is based upon a staggered finite volume scheme on an unstructured triangular mesh in the plane and structured grid in vertical that solves the most general form of darcy equation without limiting assumptions not expressed as a function of the groundwater potential but presented in term of the water pressure avoiding the excessive computational efforts an efficient and simple algorithm has been proposed to discretize flow equations track the water table position and determine salinity distribution a line iterative method has been utilized efficiently in a way that resultant linear equations system splits into a series of tri diagonal square matrix systems whereby the direct together with iterative procedure employed simultaneously to achieve problem unknowns prediction of passive scalar salinity quantity has been achieved efficiently by employing the advantageous time splitting algorithm this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena performance of the 3d model has been validated against a range of problems comparison between numerical results analytical solutions and experimental data demonstrates that the model represents well the simultaneous effects of fluid density variation and water table gradient processes keywords finite volume algorithm unstructured triangular grid density dependent darcy equation water table tracking solute transport 1 introduction the combination of darcy law and continuity equation presents a partial differential equation that relates the dependent variable as the pressure to the independent variables the hydraulic conductivity and the fluid density a high non linearity of density dependent darcy equation expressed as a function of the water pressure is caused by the dependence of hydraulic conductivity and soil water pressure on the fluid density the transport of solutes equation in the soil when water flow is transient and soil properties and initial condition are non uniform has this non linearity as well so numerical solution strategy of these equations is still a subject to research density dependent flows in the subsurface have also become a common issue in the hydrology and others disciplines on the other among those are saltwater intrusion and up coning in coastal aquifers where deeper saltwater is overlain by freshwater barlow 2003 these flows are rotational and hydrodynamic instability to the non uniqueness of the solution is inherent in the mathematical and physical models of such systems johannsen et al 2006 many analytical methods have been developed in order to describe density dependent flows but cannot be able to present flow dynamic and or salinity distributions without a wide range of simplifications a number of this analytical approaches has been discussed in dagan and bear 1968 and bear 1972 based on the sharp interface assumption the two broad categories can be distinguished the first uses the dupuit assumption which imposes strict vertical equilibrium and therefore only allows horizontal flows chappelear hirasaki 1976 lake 1989 bakker 1999 kacimov 2002 the second category uses a small perturbation approach in which the interface location is not allowed to change in space muskat 1949 using the vertical equilibrium assumption nordbotten and celia 2006 introduced extended approach with a variety of correction factors but method have been restricted to the linear variation of vertical flow in the confined aquifer paster and dagan 2008 derived an analytical solution using the boundary layer approximation and estimated the salinity of pumped water from a confined aquifer however their solution has been limited to a fully penetrating well in homogenous constant thickness confined aquifers of semi infinite areal extent therefore its application is limited to ideal situations recent researches focus on numerical schemes as well as experimental works to simulate density dependent subsurface flows more efficiently laboratory experiments have been used extensively to consider density dependent phenomena in porous media simmons et al 2001 goswami clement 2007 werner et al 2009 shi et al 2011 chang et al 2011 however their investigations have been limited to solute transport simulation no one of which to the best of our knowledge presenting saltwater up coning in the unconfined aquifer with water table variations diersch et al 1984 where among the first to numerically model variable density and dispersion effects for saltwater up coning below pumping well da costa and wilson 1979 developed a galerkin finite element model for freshwater and saltwater flows in a single aquifer layer huyakorn et al 1996 developed numerical models for layered aquifer system software package d3f have been applied by johannsen et al 2006 to simulate saltwater freshwater fingering instabilities in a saturated porous medium shi et al 2011 presented a 1d numerical sharp interface model to determine saltwater and freshwater withdrawal rates at a pumping well results have been compared with transient salinity breakthroughs in a sand tank using the available rstd computer code oz et al 2014 simulated the dynamics location and the geometry of the interfaces and the density driven circulation flows within a stratified saltwater body in the most of above mentioned numerical techniques the models primarily restricted to solute transport simulation in confined or unconfined aquifers without proceed to forecast water table transient situation at the same time in the present research a fully 3d hydrodynamic finite volume numerical algorithm in an unstructured triangular grid has been proposed for density dependent subsurface flows in an unconfined aquifer having sharp water table gradient as well in this regard avoiding the excessive computational efforts an efficient and simple algorithm has been applied to discretize density dependent darcy equations and track the phreatic line position so that the water table elevation as one of the problems unknown can be obtained along with other unknowns i e velocities and pressure fields in the presenting study the advantages of line iterative method have been utilized in a way that linear equations system which has been formed by discretized governing flow equations split into a series tri diagonal square matrix systems whereby the direct together with iterative procedure employed simultaneously to achieve more efficient solution method time splitting method of yanenko 1971 which makes it possible to deploy the most efficient numerical technique for each of individual processes in the transport of contaminant has been utilized whereby the third order upstream center quickest scheme employed for advection terms while the second order semi implicit crank nicolson as well as explicit numerical schemes have been applied for diffusion terms in the plane and z direction respectively section 2 presents the governing equations grid layout system is described in section 3 the numerical method is explained in section 4 numerical approach for transport equation explains in section 5 in section 6 details of the model application to flow problems involving relatively intense density difference and high gradient of water table position are also given with the model being shown to give accurate and realistic predictions in this way the model is validated by four test cases 2 mathematical formulation the groundwater saturated flow equation is obtained by combining the continuity equation with darcy s law these equations describe three dimensional movement of groundwater in its most general form as a consequence under the incompressibility of water and porous media condition the flow equations are expressed as a function of the water pressure not in term of the groundwater potential in the following form 1 u 0 2 u k g 1 ρ p g u velocity vector p pressure k hydraulic conductivity ρ fluid density and g acceleration due to gravity the transport of solute through the porous medium is controlled by advection diffusion and source or sink processes if we assume the density does not depend on pressure but only on salinity and temperature the conservation of solute mass may be written as bear 1972 3 c t u c υ t c c 0 t c is the instantaneous salinity c 0 t variation of salinity from the sink or source terms and υ t is hydrodynamic dispersion molecular diffusion and mechanical dispersion are combined to define the latter parameter by the following formula fetter and fetter 1999 4 a υ t ν α t u i α l α t u u u 4 b α l a 0 u ν 1 ρ ρ 0 ρ ν is molecular diffusion in porous media α l the longitudinal dispersivity α t the transverse dispersivity i the unit vector a 0 the constant coefficient u the real velocity and the others parameters have been defined in the previous sections it is important to note the coupling between the solute transport and flow equations is through the linear equation of state 3 grid layout an unstructured triangular mesh in the plane and structured grid in the vertical has been deployed to cover the solution domain and enable arbitrary and complex geometries fig 1 using the mesh vertex layout the unknown variables have been positioned at the center of the vertexes of a cell and the control volume is an irregular shape surrounding the corresponding vertex as shown in fig 2 a a control volume is formed by connecting the center of the circum circles of the same elements the local coordinates are employed to determine the components of vector variables normal to the edges as defined in fig 2b where x y coordinates in cartesian system λ η local coordinates the position of the velocity vector components in the horizontal and vertical directions along with other scalar quantities such as salinity and pressure in the current staggered grid layout system can be shown in fig 2 as well the number of cells in each column at each time step is determined in accordance with the water surface elevation 4 numerical method for main flow equations the first step in the numerical solution of flow from porous media is to extract the governing equations in the local coordinate system defined for the computational grid it can be shown that the eqs 1 and 2 would be rewritten in the local coordinate system defined in fig 2 as 5 w z δ λ s e u 0 6 u k g 1 ρ p η 7 w k g 1 ρ p z g δ λ and s e length of the mth edge and the area of control volume in the plane respectively w and u vertical and local longitudinal velocity respectively and other parameters are the same as described in the foregoing sections it should be noted u is the normal velocity at the edge of a control volume as shown in fig 2 and can be calculated in term of the cartesian coordinates parameters as follow 8 u u c o s θ v s i n θ u v are velocity components in cartesian coordinates system and are interpolated from the same velocities on the nodes located on two sides of the edge θ is the angle between local λ η and cartesian coordinates system a fully 3d implicit numerical scheme has been proposed to solve flow governing equations for this purpose eq 6 and eq 7 for momentum together with the continuity eq 5 are solved simultaneously a finite volume approach is used to discretize the governing equations whereby mass is fully conserved according to the conventional finite volume method the discrete form of p η might be written as eq 9 in which function values in adjacent grid points are employed to evaluate the derivative and the precision of estimation is o δ η 3 similar relations can be written for other derivative not to be repeated here for the sake of brevity 9 p η p i p j δ η o δ η 3 using this discrete form of derivative darcy equations can be discretized in the local coordinate system defined in fig 2 as 10 u i j n 1 k i j g 1 ρ i j n p i k n 1 p j k n 1 δ η i j o δ η 3 11 w i k δ n 1 k i k δ g 1 ρ i k δ n p i k δ 1 2 n 1 p i k δ 1 2 n 1 δ z g o δ z 3 δ is equal to 1 2 or 1 2 for upstream and downstream vertical velocity faces respectively δ η is the distance from the nodes located on the two side of the edge in the plane δ z is space interval in the z direction employing the continuity equation 5 in a particular control volume its discrete form is obtained as 13 w i k 1 2 n 1 w i k 1 2 n 1 1 s e i k j 1 j n u i j n 1 δ λ i j δ z 0 considering the staggered grid layout selected for the present study as illustrated in fig 2 all velocities are positioned between two pressure points taking the advantage of which each unknown velocity in eqs 10 and 11 may be defined as a function of its neighboring unknown pressures values by inserting the obtained velocities in the discretized continuity equation 13 all velocities are eliminated and for each control volume an equation is created in term of the cell s and its surrounding unknown pressure values 4 1 surface cells treatment the formulation expresses so far are valid for all inner control volumes i e the ones not located on the free surface for the cells containing free surface a special treatment is required to be implemented which has been proposed here to complete the formulations eliminating the infiltration and evaporation effects on the phreatic surface and employing the continuity equation in ith column gives 14 n v i nk i ξ i n 1 ξ i n δ t 1 s e i nk i j 1 j n u i j δ λ i j d i j w i nk i 1 2 n 1 nk i is the number of cells in the ith column n v is effective porosity and ξ is the free surface elevation which has been considered in the center of top layer cells as shown in fig 3 it is necessary to explain d has been defined as ξ δz 2 which would be seen in fig 3 such expression causes nonlinear property various approximations can be used to represent the derivatives when the first order forward approximation is used for the time derivative and the value of the u and w variables are expressed from n 1 time level the resulted algebraic equation which includes more than one unknown is known as an implicit method however in order to avoid any non linearity of resulted coefficients matrix variable d has been approximated from known time step n in the current research in order to track free surface more accurately the surface position has not been considered to remain in a specific layer in this way before proceeding to the next time step the number of vertical cells as well as the thickness of the upper layer are updated according to water table given at that time level in the current research where the subsurface flows are concerned a simple relation has been employed based on the assumption that the dynamic pressure at the top layer between the water table and the center of the upper cell is negligible as 15 ξ i n 1 p i nk i n 1 g ρ i nk i n substituting the velocities u n 1 and w n 1 from eqs 10 and 11 as well as water level from eq 15 into eq 14 the velocities are eliminated and the pressure equation of the surface cells is obtained experiences has shown that the proposed technique has shown a perfect performance in presenting the phreatic line in porous media the mentioned method has been successful in surface tracking in free surface domain as well as long as no intense curvature exists one of such experiences can be found from references shokri et al 2018 4 2 system solution algorithm pressure equation for the surface cells together with those of the lower layers result in a relation in which unknown pressure at each node at time step n 1 is a function of the upper and lower as well as surrounding nodes in the plane at the same time step this will end up in n equations with n unknowns n being the number of nodes in the computational domain as below 16 p i k n 1 a i k 1 p i k 1 n 1 a i k 1 p i k 1 n 1 j 1 j n a i j p j k n 1 j n is the number cells in the plane surrounding ith node the point gauss seidel method can be considered as the first option for solving the resulting equation system however it has a slow convergence and requires a considerable computational effort accordingly it cannot be used in real world terrain and practical large scale application cases where the dimensions of the resulting matrix would be exceptionally large consequently a line iterative efficient method has been proposed in the current research to solve system of equations for this purpose the unknown pressures in the z direction are calculated based on the new time level n 1 whereas surrounding pressures can be expressed by known values of the previous time step or iteration n α this will result in a tri diagonal square matrix system in terms of the pressures as an alternative of eq 16 as follow which can be solved by a direct matrix solver 17 a i k 1 p i k 1 n 1 a i k 2 p i k n 1 a i k 3 p i k 1 n 1 a i k 0 a i k 1 a i k 2 a i k 3 and a i k 0 is a 1d coefficient vector for the pressure in ith column the details of which for inner cells can be calculated in term of known values of the previous time step or iteration n α as follow 18 a i k 1 1 g δ z k i k 1 2 ρ i k 1 2 n a i k 2 a i k 1 a i k 3 δ z g s e i k j 1 j n k i j ρ i j n δ λ i j δ η i j a i k 3 1 g δ z k i k 1 2 ρ i k 1 2 n a i k 0 k i k 1 2 k i k 1 2 δ z g s e i k j 1 j n k i j ρ i j n δ λ i j δ η i j p j k n α for surface cells these coefficients may be derived as an alternative of eq 18 19 a i nk i 1 1 g δ z k i nk i 1 2 ρ i nk i 1 2 a i nk i 2 a i nk i 1 a i nk i 3 n v i k g δ t ρ i nk i 1 g s e i nk i j 1 j n k i j ρ i j δ λ i j δ η i j d i j a i nk i 3 0 a i nk i 0 k i nk i 1 2 n v i nk i ξ i n δ t 1 g s e i nk i j 1 j n d i j k i j ρ i j δ λ i j δ η i j p j nk i n α to solve tri diagonal square matrix system a double sweep thomas algorithm can be applied the details of this solution method have been described in hoffman and chiang 2005 since determining unknown pressure p for all columns they are replaced with those in the previous iteration n α this procedure is repeated until pressure difference between two successive steps become sufficiently small and criterion for convergence achieved after the solution of unknown pressure longitudinal and vertical velocities u w and free surface elevation are updated by back substitution in eqs 10 11 and 13 respectively the hydrodynamic dispersion in porous media is then estimated from eq 4 the transport equation for the salinity 3 is eventually solved using the fractional step time splitting algorithm yanenko 1971 the details of which will be described in subsequent sections 4 3 boundary conditions the control volume of the boundary points will have a different shape from the inner ones as shown in fig 4 for the numerical scheme discussed above boundary nodes are treated same as inner nodes in the main computational algorithm boundaries may be considered as a solid boundary b open boundary with known velocity and c boundary with known pressure to take the effect of these boundaries correctly into account the coefficients in the eq 17 has to be modified as a i k 1 1 0 a i k 1 0 a i k 1 0 k i k 1 1 2 f o r b o t t o m s o l i d b o u n d a r y a i k 0 a i k 0 u khown s e i k δ λ δ z f o r h o r i z e n t a l v e l o c i t y b o u n d a r y u khown is the known boundary velocity which has to be set to zero for solid boundaries the rest coefficients not to be changed for the known pressure boundaries the coefficients defined by eq 17 has to be modified as a i k 2 1 a i k 3 p khown and the rest of the coefficients set to zero 5 numerical approaches for transport equation it can be shown that the eq 3 would be rewritten in the local coordinate system defined in fig 2 as 20 c t δ λ s e u c w c z δ λ s e υ t c η z υ t c z c 0 t prediction of distribution of any contaminant concentration in flow conditions requires the advection diffusion equation to be solved numerically reliable predictions of these concentrations need an accurate numerical scheme for this equation a solution of 3d salinity transport equation has been achieved efficiently in the current research by employing the effective time splitting algorithm for more detailed explanations consider the transport equation defined for the local coordinate system described by eq 20 according to which the change of quantity c in time defined by c t is due to five other terms contributed in the equation each having their own portion in c t to be equated numerically by δ c δ t therefore one can define δ c δ i c in which δ i c is the change of c in time due to each of the mentioned five terms as 21 a δ 1 c δ t c 1 c n δ t δ λ s e u c 21 b δ 2 c δ t c 2 c 1 δ t δ λ s e υ t c η 21 c δ 3 c δ t c 3 c 2 δ t w c z 21 d δ 4 c δ t c 4 c 3 δ t z υ t c z 21 e δ 5 c δ t c n 1 c 4 δ t c 0 t c 0 t is an additional possible source term may be involved in the transport equation such as pumping or injection it can easily be verified that they are equivalent to the transport eq 20 by a simple summation so to obtain the value of the salinity in new time step n 1 four intermediate values are calculated by numerical solution of the corresponding term which considered as the initial condition of the next equation the above mentioned numerical technique consists of three major steps in the first step two first equations 21 a and 21 b covering the triangular grid in plane and in second step two second equations 21 c and 21 d in z direction are solved to include the advection and diffusion transport terms in the final stage of the procedure the source term eq 21 e is considered to achieve the salinity in new time step this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena 5 1 solution approach in unstructured triangular grid many investigations have been undertaken to implement higher order accurate numerical methods for unstructured triangular meshes and come out with various new advection schemes among them ollivier gooch and van altena 2002 wilders and fotia 2002 namin 1997 and namin et al 2004 can be mentioned the third order upstream center quickest scheme has been deployed to solve the advection part of transport equation 21 a in the current study for more detailed explanations consider a quadratic shape function for c x y t in the following the advection flux f adv passing the mth edge can be defined as 22 f adv 1 δ t δ η 2 u η δ t δ η 2 c x y t d η 1 δ t δ η 2 u η δ t δ η 2 a 1 η 2 a 2 η a 3 d η i f u η 0 1 δ t δ η 2 δ η 2 u η δ t a 1 η 2 a 2 η a 3 d η i f u η 0 c x y t is the distribution of concentration in the upstream grid u η is the velocity component normal to the edge δ η 2 is the distance from mth edge to the upstream grid and a 1 a 2 a 3 are quadratic polynomial coefficients that can be calculated in term of local derivatives as 23 a 1 1 2 2 c η 2 a 2 c η a 3 c i δ η 2 24 2 c η 2 for the sake of brevity the final result obtained from eq 22 have been represented here as follows 24 f adv 1 δ t a 1 3 r 1 3 s 1 3 a 2 2 r 1 2 s 1 2 a 3 r 1 s 1 i f u η 0 1 δ t a 1 3 r 2 3 s 2 3 a 2 2 r 2 2 s 2 2 a 3 r 2 s 2 i f u η 0 r 1 δ η 2 s 1 δ η 2 u η δ t r 2 δ η 2 and s 2 δ η 2 u η δ t in the presence of a lateral velocity the flux term may be modified using the lateral gradient of the concentration details of additional explanation of which can be found from namin et al 2004 reference this modification can be calculated as 25 f adv f adv 1 2 u η u λ δ λ δ t 2 c λ the diffusion flux f dif can be defined as 26 f dif υ t c η υ t i j c i n c j n δ η υ t i j is the hydrodynamic dispersion coefficient the mth edge this equation provides a second order numerical scheme for the diffusion term 21 b that sufficiently accurate for most porous media flow calculations since such applications are often referred to as low velocity problems the derivatives in eq 23 and 25 can be calculated as 27 c η cos θ c x sin θ c y 2 c η 2 cos 2 θ 2 c x 2 sin 2 θ 2 c y 2 2 cos θ sin θ 2 c x y c λ sin θ c x cos θ c y θ is the angle between cartesian coordinates system x y and local coordinates λ η defined in fig 2 the derivatives on the right hand side of eq 27 are interpolated from the same derivatives on the two sides of the edge the derivatives on the nodes are computed in terms of the one lower derivatives on the edges of node s control volume using the parametric equation of a plane passing each element 5 2 solution in z direction the quickest scheme has been also applied for numerical solution of advection part of transport equation 21 c in the z direction not to be repeated for the sake of brevity moreover a crank nicolson 1947 implicit scheme has been deployed for diffusion part 21 d these two parts of transport equation has been accounted using one dimension solver 5 3 boundary conditions for transport equation in the control volume of the boundary points fig 4 fluxes passing through in boundary line are calculated in a similar manner the fluxes passing through the other control volume faces but the values being divided into two parts to contribute to two end points of the line in the control volume 6 model validations to verify the introduced numerical model the numerical results are validated through a comparison with four experimental and analytical cases these cases are a solid body rotation of a cut off cylinder as well as a gaussian cone b three dimensional modeling of variable density flow in saturated porous media conducted by oswald and kinzelbach 2004 c experimental saltwater intrusion data conducted by shi et al 2011 and d saltwater up coning in an unconfined aquifer 6 1 transport model test case solid body rotation of the cut off cylinder zalesak 1979 which have a sharp gradient in the concentration distribution and the gaussian cone with a smoother gradient are two well known benchmark test problems used to evaluate the performance of the numerical model for solving the advection equation namin 1997 a 1100 1100 m2 square has been considered as the computational domain filled with 24 590 unstructured triangles having 12 496 nodes and 37 085 sides the cut off cylinder with a base diameter of 2 r 300 m has been defined as 28 c x y 0 for π r o r x x m r 4 x y m r 4 y x m r 4 1 for a l l o t h e r c o n d i t i o n x m 300 m and y m 250 m are the coordinates of the center of the base circle and π x x m 2 y y m 2 the gaussian cone has been expressed as c x y e x p π 2 2 σ 2 σ are chosen to be 25 a constant velocity field are assumed to be rotating with an angular velocity of ω 2 π 60 around the point x 0 500 and y 0 500 as follow which gives a complete rotation in 600 sec 29 u y y 0 ω v x x 0 ω fig 5 a b and c shows the results of gaussian cone test for the third order quicket advection scheme with proposed modification in 3d plane and vertical section respectively corresponding results for cut off cylinder test can be observed in fig 5 d e and f to compare the performance of the higher order above mentioned numerical scheme more apparently in addition to the analytical solution the results of the two famous numerical methods known as 1st order donor cell and 2nd order lax wendroff are also presented in fig 5c and 5d as well as can be seen the utilized scheme has resulted in a noticeable improvement in the outcomes the relatively large peak errors are caused by the sharp concentration gradient and relatively low grid resolution it can be seen that the symmetric shape of the initial condition relatively well preserved further calculations show that the mass balance is also maintained 6 2 experimental results reported by oswald and kinzelbach 2004 time dependent experimental results for a three dimensional density dependent flow problem in confined porous media reported by oswald and kinzelbach 2004 have been used according to which a cubic container of glass beads with 20 cm inner side length is considered as the test domain detailed of setup geometry procedure experimental time and flow parameters and etc have been presented in oswald and kinzelbach 2004 reference the initial condition has been obtained by a stable layering of the saltwater with 1072 2 k g m 3 fluid density below freshwater affected by recharge and discharge of water equal to 1 89 m l s at the top the hydraulic conductivity and effective porosity of the mentioned experiment have been reported to be 9 325 mm s and 0 372 respectively the longitudinal sections of the computational domain have been filled with an unstructured mesh of grid size of the order of 1 cm when the grid spacing in the z direction is taken as 0 5 c m and a time interval of δ t 1 s e c is taken into account similar to experiment a constant head and no flux has been forced in the four inlet cells for flow and salinity respectively whereas a known flow rate 1 89 m l s and no salinity flux has been applied in the 25 outlet cells all other boundaries have been considered as solid wall boundary condition the experimental and numerical evolution of the relative concentrations in a vertical diagonal cross section including salinity distribution and streamline together with the velocity vectors have been plotted in fig 6 the simulated breakthrough curves in the outlet have been plotted against the related measured values which can be seen in fig 7 however the simulated breakthrough curve by efflow software differs much from the measured one but the present study results have an appropriate agreement a very close agreement between experimental and current numerical outputs confirms the general performance of the model for forecasting the up coning phenomenon in the confined situation 6 3 experimental data conducted by shi et al 2011 shi et al 2011 has performed a series of laboratory experiments on the hydrodynamic behavior of the saltwater intrusion in porous media especially suited for comparison with results from numerical modeling a conceptual diagram of the setup as well as details of experimental procedure would be found from this reference the porous media section has been characterized by the 43 cm length 18 cm height a porosity of 30 and hydraulic conductivity of 44 1 m day two fully penetrating wells s1 and f3 of 5 cm diameter have been used to discharge a flow rate of 6 and 7 m l m i n respectively the concentration of saline water has been kept constant at 57 14 kg m3 equivalent to a density of 1040 kg m3 during the experiments the 43 cm length of the porous media section has been considered as the computational domain filled with the unstructured triangles of the size of 1 cm where the grid spacing in the z direction is taken as 0 5 c m and a time interval of δ t 1 s e c is taken into account similar to experiments a flow rate of 8 2 m l m i n has been used as the upstream boundary condition where water level of 18 cm has been considered for the downstream at all other boundaries no flux boundary condition has been applied for salinity in order to simulate the pumping rate from the wells the source or sink has been treated as eq 30 while these terms i e c 0 t have been re written in the mass conservation of salinity equation as eq 31 giving 30 w z δ λ s e u q n s e d z 31 c 0 t q n c s e d z q is the pumping rate n is the number of cells that q has been extracted from which and the other parameters have been defined in previous sections it is worthy to mention that to avoid any probable instability in the all over solution procedures the parameter c in eq 31 has been discretized implicitly the position of saline waterfront at the steady flow condition has been forecasted by the proposed model and shown in fig 8 together with the data of shi et al 2011 an appropriate agreement would be concluded between experimental and simulated results confirming the general performance of the model in predicting the vertical and horizontal movement of the solute transport in the porous media 6 4 comparison with developed axisymmetric model the vertical upward movement of saltwater saltwater up coning towards a pumping well where the water surface as well as the fluid density varies in an unconfined aquifer has been considered as the last test case it is noted the analysis of saltwater up coning beneath a pumping well in a coastal aquifer has been studied for many decades and includes the classic work of bear and dagan 1964 bear 1972 1979 and nordbotten and celia 2006 although various researches have been conducted to simulate this case in the confined aquifer as mentioned above to the authors knowledge there is no 3d modeling of up coning in the presence of water table gradient as well as density differences in an unconfined aquifer under homogeneous conditions groundwater flow to an extraction well exhibits radial symmetry and axisymmetric modeling which allows you to analyze 3d domain two dimensionally can be deployed as can be seen in fig 9 a the input is two dimensional but because of the rotational symmetry you are in fact analyzing a symmetric three dimensional problem to achieve the better results arc length corresponding to control volume in fig 9b has been selected to be equal to grid spacing in the x direction utilizing this suitability two dimensional laterally averaged numerical model in vertical plane has been developed and considered as a benchmark to validate the 3d proposed model in this way one partially penetrating well with 15 l s pumping rate has been simulated and the numerical results compared with the exact solution of the 2dv axisymmetric model the porosity and the hydraulic conductivity of aquifer with 22 5 m height and 200 m diameter have been regarded to be 8 64 m d a y and 0 2 respectively initially the aquifer has been considered to be filled with 3 75 m of saltwater and 18 75 m of freshwater to create a stratified subsurface system a cylinder shape has been considered as the 3d computational domain and the mesh size in the longitudinal sections as can be seen in fig 10 varied smoothly from 1 m in the vicinity of the well to 10 m towards the aquifer boundary thereby creating a total node number nnod 2007 an element number nele 3950 and a side number nsid 5956 it has to be noted that the solute and flow discharge from the well can be exerted from eqs 30 and 31 the known head equal to 22 5 m and no flux have been applied for flow and salinity model as the aquifer boundary condition respectively the sharp interface of saltwater position has been forecasted by the 3d proposed model and shown in figs 11 and 12 together with related exact values of the 2dv model reasonable matches were obtained for all three salinity contour lines the 3d numerical model slightly overestimated the interface for the 10 salinity contour whereas contour for 100 salinity has been underestimated various factors may have caused the mismatch including slightly higher numerical diffusion in the 3d model the pumping induced drawdown in the vertical diagonal cross section of a 3d domain has been given in fig 13 and compared with a 2dv axisymmetric model as well as dupuit theory results the numerical evolution of the relative concentrations in a vertical diagonal cross section including salinity distribution together with the velocity vectors have been plotted against the related values resulting from the proposed analytical procedure which can be seen in fig 14 7 conclusions a fully 3d implicit hydrodynamic finite volume numerical algorithm has been developed to simulate density dependent flows in saturated porous media the most common application of which being saltwater intrusion and up coning problems the most general form of darcy equation without limiting assumption such as dupuit hypothesis not to be expressed as a function of the groundwater potential but presented in term of the water pressure has been employed as governing flow equations to cover and enable arbitrary and complex geometries an unstructured triangular mesh has been deployed in the plane sections of the 3d domain avoiding the excessive computational efforts an efficient and simple finite volume algorithm has been applied to discretize flow equations and track the phreatic line position so that the water table elevation as one of the problems unknown can be obtained along with other unknowns the surface position has not been considered to remain in a specific layer so the number of cells in each column have been variably adjusted in accordance with the water table elevation the proposed technique has shown a perfect performance in presenting the phreatic line in porous media taking advantages of the thomas algorithm a line iterative method have been utilized efficiently in a way that linear equations system splits into a series of tri diagonal square matrix systems whereby the direct together with iterative procedure employed to achieve problem unknowns moreover prediction of passive scalar salinity quantity has been achieved simply by employing effective time splitting algorithm this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena unlike the most of the mentioned researches that primarily restricted to solute transport simulation in confined or unconfined aquifers without proceeding to forecast water table transient situation the proposed model can truly handle corresponding problems in the unconfined aquifer having sharp water table gradient a series of tests have been undertaken to verify capabilities of the numerical model for the solute transport test numerical results show that the model prediction generally agrees well with the analytical solutions the model has been applied to simulate three dimensional flow dynamic and saline transport in saturated porous media and detailed comparison have been made between model predicted and laboratory measured transient salinity distribution the close agreement of the results with those of oswald and kinzelbach 2004 indicates to the capability of the model in simulating 3d saltwater up coning problems in the test of salinity interface a saltwater intrusion problem subjecting to discharge from two wells the position of saline water front at the steady flow condition has been forecasted by the proposed model and presented together with the data of shi et al 2011 an appropriate agreement would be concluded between experimental and simulated results the ability of the model in predicting the water table as well as salinity interface within unconfined aquifer has been examined in the last test case the depression cone of groundwater table position as well as the evolution of the relative concentrations in a vertical diagonal cross section has been forecasted by the proposed model and shown together with related analytical values that supports the capability of the model for the simulation of this problems 
6828,a fully three dimensional hydrodynamic implicit numerical algorithm has been proposed for simultaneous simulation of fluid density variation and water table gradient in saturated porous media unlike the most of the performed researches that primarily restricted to solute transport simulation in confined or unconfined aquifers without proceeding to forecast water table transient situation the proposed model can truly handle corresponding problems in an unconfined aquifer having sharp water table gradient the algorithm is based upon a staggered finite volume scheme on an unstructured triangular mesh in the plane and structured grid in vertical that solves the most general form of darcy equation without limiting assumptions not expressed as a function of the groundwater potential but presented in term of the water pressure avoiding the excessive computational efforts an efficient and simple algorithm has been proposed to discretize flow equations track the water table position and determine salinity distribution a line iterative method has been utilized efficiently in a way that resultant linear equations system splits into a series of tri diagonal square matrix systems whereby the direct together with iterative procedure employed simultaneously to achieve problem unknowns prediction of passive scalar salinity quantity has been achieved efficiently by employing the advantageous time splitting algorithm this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena performance of the 3d model has been validated against a range of problems comparison between numerical results analytical solutions and experimental data demonstrates that the model represents well the simultaneous effects of fluid density variation and water table gradient processes keywords finite volume algorithm unstructured triangular grid density dependent darcy equation water table tracking solute transport 1 introduction the combination of darcy law and continuity equation presents a partial differential equation that relates the dependent variable as the pressure to the independent variables the hydraulic conductivity and the fluid density a high non linearity of density dependent darcy equation expressed as a function of the water pressure is caused by the dependence of hydraulic conductivity and soil water pressure on the fluid density the transport of solutes equation in the soil when water flow is transient and soil properties and initial condition are non uniform has this non linearity as well so numerical solution strategy of these equations is still a subject to research density dependent flows in the subsurface have also become a common issue in the hydrology and others disciplines on the other among those are saltwater intrusion and up coning in coastal aquifers where deeper saltwater is overlain by freshwater barlow 2003 these flows are rotational and hydrodynamic instability to the non uniqueness of the solution is inherent in the mathematical and physical models of such systems johannsen et al 2006 many analytical methods have been developed in order to describe density dependent flows but cannot be able to present flow dynamic and or salinity distributions without a wide range of simplifications a number of this analytical approaches has been discussed in dagan and bear 1968 and bear 1972 based on the sharp interface assumption the two broad categories can be distinguished the first uses the dupuit assumption which imposes strict vertical equilibrium and therefore only allows horizontal flows chappelear hirasaki 1976 lake 1989 bakker 1999 kacimov 2002 the second category uses a small perturbation approach in which the interface location is not allowed to change in space muskat 1949 using the vertical equilibrium assumption nordbotten and celia 2006 introduced extended approach with a variety of correction factors but method have been restricted to the linear variation of vertical flow in the confined aquifer paster and dagan 2008 derived an analytical solution using the boundary layer approximation and estimated the salinity of pumped water from a confined aquifer however their solution has been limited to a fully penetrating well in homogenous constant thickness confined aquifers of semi infinite areal extent therefore its application is limited to ideal situations recent researches focus on numerical schemes as well as experimental works to simulate density dependent subsurface flows more efficiently laboratory experiments have been used extensively to consider density dependent phenomena in porous media simmons et al 2001 goswami clement 2007 werner et al 2009 shi et al 2011 chang et al 2011 however their investigations have been limited to solute transport simulation no one of which to the best of our knowledge presenting saltwater up coning in the unconfined aquifer with water table variations diersch et al 1984 where among the first to numerically model variable density and dispersion effects for saltwater up coning below pumping well da costa and wilson 1979 developed a galerkin finite element model for freshwater and saltwater flows in a single aquifer layer huyakorn et al 1996 developed numerical models for layered aquifer system software package d3f have been applied by johannsen et al 2006 to simulate saltwater freshwater fingering instabilities in a saturated porous medium shi et al 2011 presented a 1d numerical sharp interface model to determine saltwater and freshwater withdrawal rates at a pumping well results have been compared with transient salinity breakthroughs in a sand tank using the available rstd computer code oz et al 2014 simulated the dynamics location and the geometry of the interfaces and the density driven circulation flows within a stratified saltwater body in the most of above mentioned numerical techniques the models primarily restricted to solute transport simulation in confined or unconfined aquifers without proceed to forecast water table transient situation at the same time in the present research a fully 3d hydrodynamic finite volume numerical algorithm in an unstructured triangular grid has been proposed for density dependent subsurface flows in an unconfined aquifer having sharp water table gradient as well in this regard avoiding the excessive computational efforts an efficient and simple algorithm has been applied to discretize density dependent darcy equations and track the phreatic line position so that the water table elevation as one of the problems unknown can be obtained along with other unknowns i e velocities and pressure fields in the presenting study the advantages of line iterative method have been utilized in a way that linear equations system which has been formed by discretized governing flow equations split into a series tri diagonal square matrix systems whereby the direct together with iterative procedure employed simultaneously to achieve more efficient solution method time splitting method of yanenko 1971 which makes it possible to deploy the most efficient numerical technique for each of individual processes in the transport of contaminant has been utilized whereby the third order upstream center quickest scheme employed for advection terms while the second order semi implicit crank nicolson as well as explicit numerical schemes have been applied for diffusion terms in the plane and z direction respectively section 2 presents the governing equations grid layout system is described in section 3 the numerical method is explained in section 4 numerical approach for transport equation explains in section 5 in section 6 details of the model application to flow problems involving relatively intense density difference and high gradient of water table position are also given with the model being shown to give accurate and realistic predictions in this way the model is validated by four test cases 2 mathematical formulation the groundwater saturated flow equation is obtained by combining the continuity equation with darcy s law these equations describe three dimensional movement of groundwater in its most general form as a consequence under the incompressibility of water and porous media condition the flow equations are expressed as a function of the water pressure not in term of the groundwater potential in the following form 1 u 0 2 u k g 1 ρ p g u velocity vector p pressure k hydraulic conductivity ρ fluid density and g acceleration due to gravity the transport of solute through the porous medium is controlled by advection diffusion and source or sink processes if we assume the density does not depend on pressure but only on salinity and temperature the conservation of solute mass may be written as bear 1972 3 c t u c υ t c c 0 t c is the instantaneous salinity c 0 t variation of salinity from the sink or source terms and υ t is hydrodynamic dispersion molecular diffusion and mechanical dispersion are combined to define the latter parameter by the following formula fetter and fetter 1999 4 a υ t ν α t u i α l α t u u u 4 b α l a 0 u ν 1 ρ ρ 0 ρ ν is molecular diffusion in porous media α l the longitudinal dispersivity α t the transverse dispersivity i the unit vector a 0 the constant coefficient u the real velocity and the others parameters have been defined in the previous sections it is important to note the coupling between the solute transport and flow equations is through the linear equation of state 3 grid layout an unstructured triangular mesh in the plane and structured grid in the vertical has been deployed to cover the solution domain and enable arbitrary and complex geometries fig 1 using the mesh vertex layout the unknown variables have been positioned at the center of the vertexes of a cell and the control volume is an irregular shape surrounding the corresponding vertex as shown in fig 2 a a control volume is formed by connecting the center of the circum circles of the same elements the local coordinates are employed to determine the components of vector variables normal to the edges as defined in fig 2b where x y coordinates in cartesian system λ η local coordinates the position of the velocity vector components in the horizontal and vertical directions along with other scalar quantities such as salinity and pressure in the current staggered grid layout system can be shown in fig 2 as well the number of cells in each column at each time step is determined in accordance with the water surface elevation 4 numerical method for main flow equations the first step in the numerical solution of flow from porous media is to extract the governing equations in the local coordinate system defined for the computational grid it can be shown that the eqs 1 and 2 would be rewritten in the local coordinate system defined in fig 2 as 5 w z δ λ s e u 0 6 u k g 1 ρ p η 7 w k g 1 ρ p z g δ λ and s e length of the mth edge and the area of control volume in the plane respectively w and u vertical and local longitudinal velocity respectively and other parameters are the same as described in the foregoing sections it should be noted u is the normal velocity at the edge of a control volume as shown in fig 2 and can be calculated in term of the cartesian coordinates parameters as follow 8 u u c o s θ v s i n θ u v are velocity components in cartesian coordinates system and are interpolated from the same velocities on the nodes located on two sides of the edge θ is the angle between local λ η and cartesian coordinates system a fully 3d implicit numerical scheme has been proposed to solve flow governing equations for this purpose eq 6 and eq 7 for momentum together with the continuity eq 5 are solved simultaneously a finite volume approach is used to discretize the governing equations whereby mass is fully conserved according to the conventional finite volume method the discrete form of p η might be written as eq 9 in which function values in adjacent grid points are employed to evaluate the derivative and the precision of estimation is o δ η 3 similar relations can be written for other derivative not to be repeated here for the sake of brevity 9 p η p i p j δ η o δ η 3 using this discrete form of derivative darcy equations can be discretized in the local coordinate system defined in fig 2 as 10 u i j n 1 k i j g 1 ρ i j n p i k n 1 p j k n 1 δ η i j o δ η 3 11 w i k δ n 1 k i k δ g 1 ρ i k δ n p i k δ 1 2 n 1 p i k δ 1 2 n 1 δ z g o δ z 3 δ is equal to 1 2 or 1 2 for upstream and downstream vertical velocity faces respectively δ η is the distance from the nodes located on the two side of the edge in the plane δ z is space interval in the z direction employing the continuity equation 5 in a particular control volume its discrete form is obtained as 13 w i k 1 2 n 1 w i k 1 2 n 1 1 s e i k j 1 j n u i j n 1 δ λ i j δ z 0 considering the staggered grid layout selected for the present study as illustrated in fig 2 all velocities are positioned between two pressure points taking the advantage of which each unknown velocity in eqs 10 and 11 may be defined as a function of its neighboring unknown pressures values by inserting the obtained velocities in the discretized continuity equation 13 all velocities are eliminated and for each control volume an equation is created in term of the cell s and its surrounding unknown pressure values 4 1 surface cells treatment the formulation expresses so far are valid for all inner control volumes i e the ones not located on the free surface for the cells containing free surface a special treatment is required to be implemented which has been proposed here to complete the formulations eliminating the infiltration and evaporation effects on the phreatic surface and employing the continuity equation in ith column gives 14 n v i nk i ξ i n 1 ξ i n δ t 1 s e i nk i j 1 j n u i j δ λ i j d i j w i nk i 1 2 n 1 nk i is the number of cells in the ith column n v is effective porosity and ξ is the free surface elevation which has been considered in the center of top layer cells as shown in fig 3 it is necessary to explain d has been defined as ξ δz 2 which would be seen in fig 3 such expression causes nonlinear property various approximations can be used to represent the derivatives when the first order forward approximation is used for the time derivative and the value of the u and w variables are expressed from n 1 time level the resulted algebraic equation which includes more than one unknown is known as an implicit method however in order to avoid any non linearity of resulted coefficients matrix variable d has been approximated from known time step n in the current research in order to track free surface more accurately the surface position has not been considered to remain in a specific layer in this way before proceeding to the next time step the number of vertical cells as well as the thickness of the upper layer are updated according to water table given at that time level in the current research where the subsurface flows are concerned a simple relation has been employed based on the assumption that the dynamic pressure at the top layer between the water table and the center of the upper cell is negligible as 15 ξ i n 1 p i nk i n 1 g ρ i nk i n substituting the velocities u n 1 and w n 1 from eqs 10 and 11 as well as water level from eq 15 into eq 14 the velocities are eliminated and the pressure equation of the surface cells is obtained experiences has shown that the proposed technique has shown a perfect performance in presenting the phreatic line in porous media the mentioned method has been successful in surface tracking in free surface domain as well as long as no intense curvature exists one of such experiences can be found from references shokri et al 2018 4 2 system solution algorithm pressure equation for the surface cells together with those of the lower layers result in a relation in which unknown pressure at each node at time step n 1 is a function of the upper and lower as well as surrounding nodes in the plane at the same time step this will end up in n equations with n unknowns n being the number of nodes in the computational domain as below 16 p i k n 1 a i k 1 p i k 1 n 1 a i k 1 p i k 1 n 1 j 1 j n a i j p j k n 1 j n is the number cells in the plane surrounding ith node the point gauss seidel method can be considered as the first option for solving the resulting equation system however it has a slow convergence and requires a considerable computational effort accordingly it cannot be used in real world terrain and practical large scale application cases where the dimensions of the resulting matrix would be exceptionally large consequently a line iterative efficient method has been proposed in the current research to solve system of equations for this purpose the unknown pressures in the z direction are calculated based on the new time level n 1 whereas surrounding pressures can be expressed by known values of the previous time step or iteration n α this will result in a tri diagonal square matrix system in terms of the pressures as an alternative of eq 16 as follow which can be solved by a direct matrix solver 17 a i k 1 p i k 1 n 1 a i k 2 p i k n 1 a i k 3 p i k 1 n 1 a i k 0 a i k 1 a i k 2 a i k 3 and a i k 0 is a 1d coefficient vector for the pressure in ith column the details of which for inner cells can be calculated in term of known values of the previous time step or iteration n α as follow 18 a i k 1 1 g δ z k i k 1 2 ρ i k 1 2 n a i k 2 a i k 1 a i k 3 δ z g s e i k j 1 j n k i j ρ i j n δ λ i j δ η i j a i k 3 1 g δ z k i k 1 2 ρ i k 1 2 n a i k 0 k i k 1 2 k i k 1 2 δ z g s e i k j 1 j n k i j ρ i j n δ λ i j δ η i j p j k n α for surface cells these coefficients may be derived as an alternative of eq 18 19 a i nk i 1 1 g δ z k i nk i 1 2 ρ i nk i 1 2 a i nk i 2 a i nk i 1 a i nk i 3 n v i k g δ t ρ i nk i 1 g s e i nk i j 1 j n k i j ρ i j δ λ i j δ η i j d i j a i nk i 3 0 a i nk i 0 k i nk i 1 2 n v i nk i ξ i n δ t 1 g s e i nk i j 1 j n d i j k i j ρ i j δ λ i j δ η i j p j nk i n α to solve tri diagonal square matrix system a double sweep thomas algorithm can be applied the details of this solution method have been described in hoffman and chiang 2005 since determining unknown pressure p for all columns they are replaced with those in the previous iteration n α this procedure is repeated until pressure difference between two successive steps become sufficiently small and criterion for convergence achieved after the solution of unknown pressure longitudinal and vertical velocities u w and free surface elevation are updated by back substitution in eqs 10 11 and 13 respectively the hydrodynamic dispersion in porous media is then estimated from eq 4 the transport equation for the salinity 3 is eventually solved using the fractional step time splitting algorithm yanenko 1971 the details of which will be described in subsequent sections 4 3 boundary conditions the control volume of the boundary points will have a different shape from the inner ones as shown in fig 4 for the numerical scheme discussed above boundary nodes are treated same as inner nodes in the main computational algorithm boundaries may be considered as a solid boundary b open boundary with known velocity and c boundary with known pressure to take the effect of these boundaries correctly into account the coefficients in the eq 17 has to be modified as a i k 1 1 0 a i k 1 0 a i k 1 0 k i k 1 1 2 f o r b o t t o m s o l i d b o u n d a r y a i k 0 a i k 0 u khown s e i k δ λ δ z f o r h o r i z e n t a l v e l o c i t y b o u n d a r y u khown is the known boundary velocity which has to be set to zero for solid boundaries the rest coefficients not to be changed for the known pressure boundaries the coefficients defined by eq 17 has to be modified as a i k 2 1 a i k 3 p khown and the rest of the coefficients set to zero 5 numerical approaches for transport equation it can be shown that the eq 3 would be rewritten in the local coordinate system defined in fig 2 as 20 c t δ λ s e u c w c z δ λ s e υ t c η z υ t c z c 0 t prediction of distribution of any contaminant concentration in flow conditions requires the advection diffusion equation to be solved numerically reliable predictions of these concentrations need an accurate numerical scheme for this equation a solution of 3d salinity transport equation has been achieved efficiently in the current research by employing the effective time splitting algorithm for more detailed explanations consider the transport equation defined for the local coordinate system described by eq 20 according to which the change of quantity c in time defined by c t is due to five other terms contributed in the equation each having their own portion in c t to be equated numerically by δ c δ t therefore one can define δ c δ i c in which δ i c is the change of c in time due to each of the mentioned five terms as 21 a δ 1 c δ t c 1 c n δ t δ λ s e u c 21 b δ 2 c δ t c 2 c 1 δ t δ λ s e υ t c η 21 c δ 3 c δ t c 3 c 2 δ t w c z 21 d δ 4 c δ t c 4 c 3 δ t z υ t c z 21 e δ 5 c δ t c n 1 c 4 δ t c 0 t c 0 t is an additional possible source term may be involved in the transport equation such as pumping or injection it can easily be verified that they are equivalent to the transport eq 20 by a simple summation so to obtain the value of the salinity in new time step n 1 four intermediate values are calculated by numerical solution of the corresponding term which considered as the initial condition of the next equation the above mentioned numerical technique consists of three major steps in the first step two first equations 21 a and 21 b covering the triangular grid in plane and in second step two second equations 21 c and 21 d in z direction are solved to include the advection and diffusion transport terms in the final stage of the procedure the source term eq 21 e is considered to achieve the salinity in new time step this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena 5 1 solution approach in unstructured triangular grid many investigations have been undertaken to implement higher order accurate numerical methods for unstructured triangular meshes and come out with various new advection schemes among them ollivier gooch and van altena 2002 wilders and fotia 2002 namin 1997 and namin et al 2004 can be mentioned the third order upstream center quickest scheme has been deployed to solve the advection part of transport equation 21 a in the current study for more detailed explanations consider a quadratic shape function for c x y t in the following the advection flux f adv passing the mth edge can be defined as 22 f adv 1 δ t δ η 2 u η δ t δ η 2 c x y t d η 1 δ t δ η 2 u η δ t δ η 2 a 1 η 2 a 2 η a 3 d η i f u η 0 1 δ t δ η 2 δ η 2 u η δ t a 1 η 2 a 2 η a 3 d η i f u η 0 c x y t is the distribution of concentration in the upstream grid u η is the velocity component normal to the edge δ η 2 is the distance from mth edge to the upstream grid and a 1 a 2 a 3 are quadratic polynomial coefficients that can be calculated in term of local derivatives as 23 a 1 1 2 2 c η 2 a 2 c η a 3 c i δ η 2 24 2 c η 2 for the sake of brevity the final result obtained from eq 22 have been represented here as follows 24 f adv 1 δ t a 1 3 r 1 3 s 1 3 a 2 2 r 1 2 s 1 2 a 3 r 1 s 1 i f u η 0 1 δ t a 1 3 r 2 3 s 2 3 a 2 2 r 2 2 s 2 2 a 3 r 2 s 2 i f u η 0 r 1 δ η 2 s 1 δ η 2 u η δ t r 2 δ η 2 and s 2 δ η 2 u η δ t in the presence of a lateral velocity the flux term may be modified using the lateral gradient of the concentration details of additional explanation of which can be found from namin et al 2004 reference this modification can be calculated as 25 f adv f adv 1 2 u η u λ δ λ δ t 2 c λ the diffusion flux f dif can be defined as 26 f dif υ t c η υ t i j c i n c j n δ η υ t i j is the hydrodynamic dispersion coefficient the mth edge this equation provides a second order numerical scheme for the diffusion term 21 b that sufficiently accurate for most porous media flow calculations since such applications are often referred to as low velocity problems the derivatives in eq 23 and 25 can be calculated as 27 c η cos θ c x sin θ c y 2 c η 2 cos 2 θ 2 c x 2 sin 2 θ 2 c y 2 2 cos θ sin θ 2 c x y c λ sin θ c x cos θ c y θ is the angle between cartesian coordinates system x y and local coordinates λ η defined in fig 2 the derivatives on the right hand side of eq 27 are interpolated from the same derivatives on the two sides of the edge the derivatives on the nodes are computed in terms of the one lower derivatives on the edges of node s control volume using the parametric equation of a plane passing each element 5 2 solution in z direction the quickest scheme has been also applied for numerical solution of advection part of transport equation 21 c in the z direction not to be repeated for the sake of brevity moreover a crank nicolson 1947 implicit scheme has been deployed for diffusion part 21 d these two parts of transport equation has been accounted using one dimension solver 5 3 boundary conditions for transport equation in the control volume of the boundary points fig 4 fluxes passing through in boundary line are calculated in a similar manner the fluxes passing through the other control volume faces but the values being divided into two parts to contribute to two end points of the line in the control volume 6 model validations to verify the introduced numerical model the numerical results are validated through a comparison with four experimental and analytical cases these cases are a solid body rotation of a cut off cylinder as well as a gaussian cone b three dimensional modeling of variable density flow in saturated porous media conducted by oswald and kinzelbach 2004 c experimental saltwater intrusion data conducted by shi et al 2011 and d saltwater up coning in an unconfined aquifer 6 1 transport model test case solid body rotation of the cut off cylinder zalesak 1979 which have a sharp gradient in the concentration distribution and the gaussian cone with a smoother gradient are two well known benchmark test problems used to evaluate the performance of the numerical model for solving the advection equation namin 1997 a 1100 1100 m2 square has been considered as the computational domain filled with 24 590 unstructured triangles having 12 496 nodes and 37 085 sides the cut off cylinder with a base diameter of 2 r 300 m has been defined as 28 c x y 0 for π r o r x x m r 4 x y m r 4 y x m r 4 1 for a l l o t h e r c o n d i t i o n x m 300 m and y m 250 m are the coordinates of the center of the base circle and π x x m 2 y y m 2 the gaussian cone has been expressed as c x y e x p π 2 2 σ 2 σ are chosen to be 25 a constant velocity field are assumed to be rotating with an angular velocity of ω 2 π 60 around the point x 0 500 and y 0 500 as follow which gives a complete rotation in 600 sec 29 u y y 0 ω v x x 0 ω fig 5 a b and c shows the results of gaussian cone test for the third order quicket advection scheme with proposed modification in 3d plane and vertical section respectively corresponding results for cut off cylinder test can be observed in fig 5 d e and f to compare the performance of the higher order above mentioned numerical scheme more apparently in addition to the analytical solution the results of the two famous numerical methods known as 1st order donor cell and 2nd order lax wendroff are also presented in fig 5c and 5d as well as can be seen the utilized scheme has resulted in a noticeable improvement in the outcomes the relatively large peak errors are caused by the sharp concentration gradient and relatively low grid resolution it can be seen that the symmetric shape of the initial condition relatively well preserved further calculations show that the mass balance is also maintained 6 2 experimental results reported by oswald and kinzelbach 2004 time dependent experimental results for a three dimensional density dependent flow problem in confined porous media reported by oswald and kinzelbach 2004 have been used according to which a cubic container of glass beads with 20 cm inner side length is considered as the test domain detailed of setup geometry procedure experimental time and flow parameters and etc have been presented in oswald and kinzelbach 2004 reference the initial condition has been obtained by a stable layering of the saltwater with 1072 2 k g m 3 fluid density below freshwater affected by recharge and discharge of water equal to 1 89 m l s at the top the hydraulic conductivity and effective porosity of the mentioned experiment have been reported to be 9 325 mm s and 0 372 respectively the longitudinal sections of the computational domain have been filled with an unstructured mesh of grid size of the order of 1 cm when the grid spacing in the z direction is taken as 0 5 c m and a time interval of δ t 1 s e c is taken into account similar to experiment a constant head and no flux has been forced in the four inlet cells for flow and salinity respectively whereas a known flow rate 1 89 m l s and no salinity flux has been applied in the 25 outlet cells all other boundaries have been considered as solid wall boundary condition the experimental and numerical evolution of the relative concentrations in a vertical diagonal cross section including salinity distribution and streamline together with the velocity vectors have been plotted in fig 6 the simulated breakthrough curves in the outlet have been plotted against the related measured values which can be seen in fig 7 however the simulated breakthrough curve by efflow software differs much from the measured one but the present study results have an appropriate agreement a very close agreement between experimental and current numerical outputs confirms the general performance of the model for forecasting the up coning phenomenon in the confined situation 6 3 experimental data conducted by shi et al 2011 shi et al 2011 has performed a series of laboratory experiments on the hydrodynamic behavior of the saltwater intrusion in porous media especially suited for comparison with results from numerical modeling a conceptual diagram of the setup as well as details of experimental procedure would be found from this reference the porous media section has been characterized by the 43 cm length 18 cm height a porosity of 30 and hydraulic conductivity of 44 1 m day two fully penetrating wells s1 and f3 of 5 cm diameter have been used to discharge a flow rate of 6 and 7 m l m i n respectively the concentration of saline water has been kept constant at 57 14 kg m3 equivalent to a density of 1040 kg m3 during the experiments the 43 cm length of the porous media section has been considered as the computational domain filled with the unstructured triangles of the size of 1 cm where the grid spacing in the z direction is taken as 0 5 c m and a time interval of δ t 1 s e c is taken into account similar to experiments a flow rate of 8 2 m l m i n has been used as the upstream boundary condition where water level of 18 cm has been considered for the downstream at all other boundaries no flux boundary condition has been applied for salinity in order to simulate the pumping rate from the wells the source or sink has been treated as eq 30 while these terms i e c 0 t have been re written in the mass conservation of salinity equation as eq 31 giving 30 w z δ λ s e u q n s e d z 31 c 0 t q n c s e d z q is the pumping rate n is the number of cells that q has been extracted from which and the other parameters have been defined in previous sections it is worthy to mention that to avoid any probable instability in the all over solution procedures the parameter c in eq 31 has been discretized implicitly the position of saline waterfront at the steady flow condition has been forecasted by the proposed model and shown in fig 8 together with the data of shi et al 2011 an appropriate agreement would be concluded between experimental and simulated results confirming the general performance of the model in predicting the vertical and horizontal movement of the solute transport in the porous media 6 4 comparison with developed axisymmetric model the vertical upward movement of saltwater saltwater up coning towards a pumping well where the water surface as well as the fluid density varies in an unconfined aquifer has been considered as the last test case it is noted the analysis of saltwater up coning beneath a pumping well in a coastal aquifer has been studied for many decades and includes the classic work of bear and dagan 1964 bear 1972 1979 and nordbotten and celia 2006 although various researches have been conducted to simulate this case in the confined aquifer as mentioned above to the authors knowledge there is no 3d modeling of up coning in the presence of water table gradient as well as density differences in an unconfined aquifer under homogeneous conditions groundwater flow to an extraction well exhibits radial symmetry and axisymmetric modeling which allows you to analyze 3d domain two dimensionally can be deployed as can be seen in fig 9 a the input is two dimensional but because of the rotational symmetry you are in fact analyzing a symmetric three dimensional problem to achieve the better results arc length corresponding to control volume in fig 9b has been selected to be equal to grid spacing in the x direction utilizing this suitability two dimensional laterally averaged numerical model in vertical plane has been developed and considered as a benchmark to validate the 3d proposed model in this way one partially penetrating well with 15 l s pumping rate has been simulated and the numerical results compared with the exact solution of the 2dv axisymmetric model the porosity and the hydraulic conductivity of aquifer with 22 5 m height and 200 m diameter have been regarded to be 8 64 m d a y and 0 2 respectively initially the aquifer has been considered to be filled with 3 75 m of saltwater and 18 75 m of freshwater to create a stratified subsurface system a cylinder shape has been considered as the 3d computational domain and the mesh size in the longitudinal sections as can be seen in fig 10 varied smoothly from 1 m in the vicinity of the well to 10 m towards the aquifer boundary thereby creating a total node number nnod 2007 an element number nele 3950 and a side number nsid 5956 it has to be noted that the solute and flow discharge from the well can be exerted from eqs 30 and 31 the known head equal to 22 5 m and no flux have been applied for flow and salinity model as the aquifer boundary condition respectively the sharp interface of saltwater position has been forecasted by the 3d proposed model and shown in figs 11 and 12 together with related exact values of the 2dv model reasonable matches were obtained for all three salinity contour lines the 3d numerical model slightly overestimated the interface for the 10 salinity contour whereas contour for 100 salinity has been underestimated various factors may have caused the mismatch including slightly higher numerical diffusion in the 3d model the pumping induced drawdown in the vertical diagonal cross section of a 3d domain has been given in fig 13 and compared with a 2dv axisymmetric model as well as dupuit theory results the numerical evolution of the relative concentrations in a vertical diagonal cross section including salinity distribution together with the velocity vectors have been plotted against the related values resulting from the proposed analytical procedure which can be seen in fig 14 7 conclusions a fully 3d implicit hydrodynamic finite volume numerical algorithm has been developed to simulate density dependent flows in saturated porous media the most common application of which being saltwater intrusion and up coning problems the most general form of darcy equation without limiting assumption such as dupuit hypothesis not to be expressed as a function of the groundwater potential but presented in term of the water pressure has been employed as governing flow equations to cover and enable arbitrary and complex geometries an unstructured triangular mesh has been deployed in the plane sections of the 3d domain avoiding the excessive computational efforts an efficient and simple finite volume algorithm has been applied to discretize flow equations and track the phreatic line position so that the water table elevation as one of the problems unknown can be obtained along with other unknowns the surface position has not been considered to remain in a specific layer so the number of cells in each column have been variably adjusted in accordance with the water table elevation the proposed technique has shown a perfect performance in presenting the phreatic line in porous media taking advantages of the thomas algorithm a line iterative method have been utilized efficiently in a way that linear equations system splits into a series of tri diagonal square matrix systems whereby the direct together with iterative procedure employed to achieve problem unknowns moreover prediction of passive scalar salinity quantity has been achieved simply by employing effective time splitting algorithm this has allowed designing and applying different numerical schemes more compatible with the mathematical and physical properties of the corresponding phenomena unlike the most of the mentioned researches that primarily restricted to solute transport simulation in confined or unconfined aquifers without proceeding to forecast water table transient situation the proposed model can truly handle corresponding problems in the unconfined aquifer having sharp water table gradient a series of tests have been undertaken to verify capabilities of the numerical model for the solute transport test numerical results show that the model prediction generally agrees well with the analytical solutions the model has been applied to simulate three dimensional flow dynamic and saline transport in saturated porous media and detailed comparison have been made between model predicted and laboratory measured transient salinity distribution the close agreement of the results with those of oswald and kinzelbach 2004 indicates to the capability of the model in simulating 3d saltwater up coning problems in the test of salinity interface a saltwater intrusion problem subjecting to discharge from two wells the position of saline water front at the steady flow condition has been forecasted by the proposed model and presented together with the data of shi et al 2011 an appropriate agreement would be concluded between experimental and simulated results the ability of the model in predicting the water table as well as salinity interface within unconfined aquifer has been examined in the last test case the depression cone of groundwater table position as well as the evolution of the relative concentrations in a vertical diagonal cross section has been forecasted by the proposed model and shown together with related analytical values that supports the capability of the model for the simulation of this problems 
6829,many studies have shown that k has more favourable effects on soil water infiltration than na which is a result of specific ion effects or hofmeister effects in this study we employed four alkali metal cation species li na k and cs to determine how the particle interactions influence the water infiltration in a soil with permanent surface charges moreover the defined hofmeister energy was employed to characterize the specific ion effects the dlvo force plus the hydration force between two adjacent soil particles mainly determines water infiltration rate through affecting the soil pore size distribution which exhibits strong specific ion effects the hydration force may originate from the surface hydration of soil particles and the hydration of cations in the double layer the hydration pressure between adjacent soil particles was complexly influenced by electrolyte concentration debye length cationic distribution in the double layer through the hofmeister energy of cation keywords electrostatic repulsion hydration force hofmeister series soil water movement 1 introduction water movement in soil is a hot topic in environmental and agricultural fields jayawardane et al 2011 the decreasing ionic concentration and cation type like sodium in soil solution can result in the degradation of soil structure le bissonnais 2016 rengasamy et al 2016 a reduction in electrolyte concentration could result in the increase of clay swelling and dispersion mcneal et al 1966 which further changes the pore size distribution jayawardane and beattie 1979 marchuk and marchuk 2018 and eventually decrease soil water infiltrability in addition soil water infiltrability could also be decreased when ions present in the order ca2 mg2 k na laurenson et al 2011 marchuk and marchuk 2018 rengasamy 2002 the structure and stability of soil aggregates determine soil water infiltrability the mechanisms of soil aggregate breakdown include inner forces between soil particles such as electrostatic hydration and van der waals interactions hu et al 2018 trefalt et al 2017 as well as outer forces such as raindrop impact the shearing force of flowing water differential swelling osmotic stress and soil tillage carmi et al 2018 luo et al 2018b or and ghezzehei 2002 the electrostatic interactions between soil particles play crucial roles in soil aggregate stability hu et al 2018 2015b and strongly influence soil water movement yu et al 2016a therefore to some extent soil aggregate stability and soil water movement could be described by the derjaguin landau verwey overbeek dlvo theories churaev and derjaguin 1985 ducker and pashley 1992 in addition to the coulombic effects specific ion effects contribute to particle interactions boström et al 2001 dos santos and levin 2011 liu et al 2014 luo et al 2018a and therefore to aggregate stability porous state and water infiltrability of soil for decades soil scientists have also identified specific ion effects when determining sorption capacity and selectivity coefficients for cs relative to k in soil or sediments bolt 1979 cremers et al 1988 de koning et al 2007 specific ion effects are closely related to the specific properties of ions including size electron shell number and polarization parsons et al 2011 parsons and ninham 2010 rios carvajal et al 2018 classically the influence of specific ion effects on particle aggregation and soil water infiltrability is attributed to ionic hydration however the fundamental reason for specific ion effects is not hydration but quantum fluctuation forces that cause london lifshitz dispersion forces parsons et al 2011 even hydration itself is determined by quantum fluctuation forces or dispersion forces parsons et al 2011 progress has been made in explaining specific ion effects but their origin is still a matter of debate dos santos and levin 2011 krishnamoorthy et al 2018 kunz et al 2004a b levin et al 2009 ninham and yaminsky 1997 parsons et al 2011 petrache et al 2006 a non classical induction force of adsorbed cations was found to be the origin of specific ion effects in soil and clay systems liu et al 2017 2016 2014 non classically polarized cations could increase the coulomb interaction forces between cations and the clay surface and then decrease the strength of the electric field around clay particles and the electrostatic repulsive force between adjacent particles in aggregates finally increase soil aggregate stability hu et al 2015a li et al 2015b xu et al 2015 considering soil water infiltrability is determined by the structure and stability of soil aggregates it is important to investigate the specific ion effects of soil water infiltrability the aims of this report are the evaluation of the influence of specific ion effects i on electrical repulsive and hydration pressure betweem soil particles and ii on the infiltration of water into soil 2 materials and methods 2 1 sample preparation samples of the purplish soil belonging to the regosol reference soil group fao 2015 and to the entisol order soil survey staff 1999 were collected at chongqing china the utilized soil mainly contain permanent surface charges the surface charge number and specific surface area determined by the approach suggested by li et al 2011 were 16 0 cmol kg 1 and 48 0 m2 g 1 respectively the method of li et al 2011 is based on a model of the cation exchange equilibrium derived from the nonlinear poisson boltzmann equation considering the specific ion effects the soil has a loamy textural class with a clay and sand content of 37 9 and 14 2 respectively the semi quantitative mineralogy of soil was analyzed by the bioelements analysis laboratory in southwest university china with an x ray diffractometer xd 3 beijing purkinje general instrument co ltd beijing china the main clay minerals in the soils were montmorillonite 5 5 vermiculite 8 3 mica 14 5 kaolinite 5 0 illite 8 6 quartz 24 2 potash feldspar 1 7 soda feldspar 31 4 the bulk density was 1 33 g cm 3 the organic matter content was 12 3 g kg 1 determined by a standard potassium dichromate digest method and the ph solution soil ratio 5 1 was 7 11 to calculate the interaction forces between soil particles the soil samples were firstly saturated with li na k and cs using licl nacl kcl and cscl respectively and then air dried to obtain the saturated samples 500 g aliquots of air dried soil were introduced into a 5 l beaker and washed successively by dispersion agitation centrifugation and decantation with three portions of 5 l licl nacl kcl or cscl at 0 5 mol l 1 respectively and then with three portions of deionized water to remove residual metal cations in soil bulk solutions the soil washing with deionzed water does not influence the cation adsorption at soil particle surface since the concentration of metal cations is much higher than that of proton from water in bulk solutions next each cationic saturated soil sample was dried under a temperature of 60 c crushed and passed through a 1 mm sieve for the following experiments 2 2 determination of surface properties of soil particles the combined method suggested by li et al 2011 for determining surface properties was employed to determine surface charge density knowing the surface charge density of a soil the surface potentials φ 0 under different concentrations ranging from 0 00001 to 1 0 mol l 1 of licl nacl kcl and cscl can be calculated li et al 2004 when specific ion effects are present the surface potential of soil for a 1 1 electrolyte can be determined du et al 2016 2017 1 φ 0 2 r t γ f ln 1 a 1 a where κ n t s c 0 1 4 1 a 4 1 exp 1 a and κ 2 f 2 z 2 c 0 ε 0 ε r r t where γ defined as γ 1 w h 0 f φ 0 is the effective charge coefficient of counterion fφ 0 j mol 1 is the coulomb mean potential energy at the surface w h 0 j mol 1 here referred to as hofmeister energy is the additive potential energy arising from specific effects at the surface r j mol 1 k 1 is the universal gas constant t k is the absolute temperature z is the valence of the counter ion f c mol 1 is the faraday constant ε 0 is the vacuum permittivity ε r is the static relative permittivity of water which is 80 c 0 mol m 3 is the equilibrium concentration of a monovalent cation in bulk solution s m2 g 1 is the specific surface area n t mol g 1 is the cation exchange capacity and a is a temporary parameter defined as a tanh zfφ 0 4rt κ 1 reflects the debye length in double layer 2 3 calculations of particle interaction forces once the surface potential is determined the potential at the middle of the overlapping position of the electric double layers edls of two adjacent particles φ d 2 can be calculated hou et al 2009 li et al 2009 2013 2 π 2 1 1 2 2 e 2 z i f φ d 2 rt 3 8 2 e 4 z i f φ d 2 rt arcsin e z i f φ z i f φ d 2 2 r t 1 4 d κ e z i f φ d 2 2 r t where d nm is the distance between two adjacent particles the electrostatic repulsive pressure p e d pa can be calculated based on the φ d 2 hou et al 2009 li et al 2009 2013 3 p e d 2 r t c 0 cosh f φ d 2 rt 1 the van der waals attractive pressure p vdw d pa can be estimated li et al 2009 2013 4 p vdw d a 0 6 π d 3 where a j is the hamaker constant for soil and clay the hamaker constant under vacuum is approximately 12 10 20 j while in aqueous solution this value is 7 8 10 20 j li et al 2009 2013 the dlvo forces are the sum of the electrostatic repulsive and the van der waals attractive force p dlvo d p e d p vdw d 2 4 water movement experiments a rectangular plexiglass column 20 cm height with a scale in millimeters 3 cm width and 1 cm thickness was used in the experiments a porous clapboard was fixed to the bottom end of the column to support the soil sample to maintain a constant bulk density the soil samples were transferred into the column by adding in small increments and then packing with a tamper according to the methods described by smiles et al 2012 and yu et al 2016a overall approximately 63 0 g soils were added and packed to a bulk density of 1 05 g cm 3 porous clapboards were also set on the soil surface of the upper end of the soil column to produce a stable flow of soil water the infiltration solutions at concentration ranging from 0 00001 to 1 0 mol l 1 were added into the space at the top of the column and a constant height of 4 cm hydraulic head was maintained using a mariotte bottle the position of the wetting front was recorded through the scale on the rectangular plexiglass column at different infiltration times the soil water infiltration rate ir is estimated by the velocity of the wetting front advance wu et al 2016 the final infiltration time is 60 150 min which was ascertained by the maximum position of the wetting front about 20 cm if the wetting front does not reach the bottom of soil column the maximum infiltration time is set to 150 min the relationships between ir and dlvo forces were best fitted by a exponential function ir aexp bp dlvo where a and b are constants to be estimated 2 5 computed tomography ct scan to determine the soil pore size distribution the ct measurements of soil columns were conducted the soil cylindrical column was 3 diameter 3 height cm with the pretreated soil sample in section 2 1 the packing method was the same as in the water movement experiment the soil columns were wetted by 0 01 mol l 1 corresponding licl nacl kcl and cscl solutions respectively the soil column was scanned by ct when the position of wetting front reached 3 cm perusal the ct scanner is ct nanotom s phoenix nanotoms ge usa at the institute of soil scicences chinese academy of sciences the peak scan potential was 100 kv and the current was 100 μa a 0 2 mm cu filter was used to reduce the beam hardening effect the distances the source sample and the sample detector were 30 cm and 20 cm respectively the initial scan position was 0 2 cm from top of the column the thickness of scanning was 13 μm 1000 images were generated for each column scan the resolution of the scanners output device was 660 660 with each voxel representing a volume of 13 μm 13 μm 13 μm image processing and visualization were conducted with the open source software imagej ver 1 47 a region of interest was selected from the central part of soil cores to avoid artifacts at the boundary region caused by sampling procedures of image processing and subsequent analyses were identical for the region of interest of soil cores a three dimensional median filter was used to reduce noise before image segmentation pore size distribution was obtained by morphological opening operations briefly pores smaller than a certain size were removed by erosion followed by dilation using a spherical structuring element which is called opening a detailed description to this method is given by zhou et al 2016 it is worth mentioning that the ct scanning was not applied to the samples used for the percolation experiments due to the column required by ct scanning cylindrical is different from the one prismatic measured by soil infiltration furthermore although the ct scanning was detected under one electrolyte concentration 0 01 mol l 1 the relationships among interactions between soil particles pore size distribution and water infiltrability in soil column can be investigated for the presence of different alkali metal cations 3 results and discussion 3 1 the soil water infiltrability in different alkali metal cation systems experimental results describing the relationship between electrolyte concentration and the ir for li na k and cs are shown in fig 1 it can be seen the ir exhibits rapid growth at first and then shifts to slow growth with increasing electrolyte concentration there is a critical concentration approximate 0 05 0 1 mol l 1 emerging for each cation species at the intersection point conversely the largest value of ir for each cation species was quite different fig 1 being 1 8 4 3 5 2 and 13 0 cm h 1 for li na k and cs systems respectively the increasing trends of the ir curves vs ion concentration for li na k and cs systems were markedly different which show that the ir increased with electrolyte concentration as follows li na k cs in addition for the same bulk solution concentration there were large differences of ir in both 0 001 and 1 0 mol l 1li na k and cs systems as the showed in table 1 these findings indicate that the specific ion effects on soil water infiltrability were very strong interestingly as electrolyte concentration decreased the magnitude of the differences in the ir sharply increased indicating more pronounced specific ion effects at smaller electrolyte concentration 3 2 surface potential of soil particles as influenced by specific ion effects the experimental results showed that there were strong hofmeister effects in soil water infiltrability in other words soil water infiltrability was highly dependent on the cationic composition of soil in this section we reveal physical insight regarding the observed hofmeister effects on soil water infiltrability liu et al 2013a determined the relative effective charge coefficient between two cation species and found that γ k γ na 1 646 and γ na γ li 1 11 li et al 2015a determined the absolute effective charge coefficient of na to be γ na 1 18 thus γ k 1 94 and γ li 1 06 li et al 2015a also determined the relative effective charge coefficient between cs and k and found that γ cs γ k 1 475 thus γ cs 2 86 the surface potential was calculated from eq 1 fig 2 and the hofmeister energies at x 0 could be estimated to be 0 06fφ 0 0 18fφ 0 0 94 fφ 0 and 1 68fφ 0 for li na k and cs respectively as shown in fig 2 specific ion effects decrease the surface potential for a given electrolyte concentration the stronger the specific ion effects is the more the surface potential is decreased 3 3 the dlvo forces of soil particles as influenced by specific ion effects in classical dlvo theory the electric field strength and the corresponding electrostatic force are determined by the electrolyte concentration and type without regard to the ionic volume ionic hydration and dispersion forces therefore for the four monovalent cations li na k and cs under given conditions the electric field strength and net inter particle pressure between adjacent soil particles are the same and can be described equally by the same force distribution equation in space however as shown in fig 3 the distributions of net repulsive pressure p dlvo between the surfaces of two adjacent particles in the aggregate for the presence of li na k and cs are quite different specifically for a given cationic concentration the net repulsive pressure was in the order of cs k na li and the net attractive pressure was in the order of cs k na li for example under the cationic concentration of 0 00001 mol l 1 the net pressures at a distance of 1 5 nm between the two adjacent particle surfaces were 15 3 10 6 3 01 and 7 69 105 pa in the presence of li na k and cs respectively correspondingly under a cationic concentrations of 0 5 mol l 1 the net pressures at a distance of 1 5 nm between two adjacent particle surfaces were 1 18 4 48 11 3 and 12 3 105 pa in the presence of li na k and cs respectively previous studies have shown that the net dlvo pressure determines soil aggregate stability hu et al 2015b and then strongly affect soil water movement yu et al 2016a fig 3 shows the first maxima of net dlvo pressure in li and na systems arise at a distance of d 1 5 nm which are much higher than that in k and cs therefore the effects of net dlvo pressure at d 1 5 nm on ir are investigated fig 4 a shows the change in the net dlvo pressure at a distance of d 1 5 nm pnet with electrolyte concentration while fig 4b shows the change in the ir with electrolyte concentration as shown in fig 4a a cationic concentration of 0 01 mol l 1 logc 0 2 was an approximate critical point for all the four cations in the p dlvo logc 0 relationship specifically at cationic concentrations lower than 0 01 mol l 1 as the cation concentration decreased from 0 01 mol l 1 to 0 00001 mol l 1 the net dlvo pressure changed very little for a given cation e g li changed by only 1 8 105 pa however for cationic concentrations higher than 0 01 mol l 1 as the cation concentration decreased from 1 mol l 1 to 0 01 mol l 1 the net dlvo pressure changed greatly e g li changed by 17 105 pa as shown in fig 4b 0 01 mol l 1 cationic concentration logc 0 2 was also an approximate critical point for all the four cations in the ir logc 0 relationship specifically for cationic concentrations lower than 0 01 mol l 1 as cation concentration decreased from 0 01 mol l 1 to 0 00001 mol l 1 logc 0 equals from 2 to 5 the ir changed very little for a given cation e g the cs changed by only 1 28 cm h 1 however for cationic concentrations higher than 0 01 mol l 1 as the cation concentration decreased from 1 mol l 1 to 0 01 mol l 1 logc 0 equals from 0 to 2 the ir changed greatly e g the cs changed by 5 68 cm h 1 fig 4a and 4b show that the small change in the net dlvo pressure corresponded to the small change in ir and vice versa conversely these figures also show that a stronger net repulsive pressure is associated with a lower ir and vice versa overall these findings indicate that the net pressure of dlvo at a distance of 1 5 nm between adjacent particle surfaces is closely related to the ir 3 4 effect of the net pressure of dlvo hydration between particle surfaces on the soil water infiltration rate the data shown in fig 4 could be used to establish the relationship of the ir and net pressure of dlvo at a distance of 1 5 nm between adjacent particle surfaces fig 5 fig 5 is actually fig 1 with the x axis of electrolyte concentration replaced by the corresponding net pressure of dlvo at a distance of 1 5 nm if soil water movement mainly determined by the interactions between soil particles the irs in different alkali metals are a function of p dlvo comparison of these figures reveals that the four absolutely different curves for li na k and cs shown in fig 1 could be approximately unified to one exponential curve with r 2 0 6963 as shown in fig 5 these findings imply that soil water infiltrability was directly affected by the interaction pressure between adjacent soil particles in aggregates rather than the electrolyte concentration however as shown in fig 5 the distribution of each cation bore its own pattern and do not obey the exponential fitting curve systematically a relatively small r 2 value in addition the pearson s rank correlation analysis was done with spss version 18 0 data for each correlation consists of the experimental ir and theoretical p dlvo the data in table 2 imply that a general exponential equation exists in these cations due to the significant correlations p 0 05 between experimental data in different alkali metals and exponential curve this is because hydration forces are also important in particle interactions goldberg et al 2008 leng 2012 pashley 1981 therefore the exponential equation for investigating soil particles interactions taking hydration force into account could be expressed as 5 ir a e b p dlvo p h where ir cm h 1 is the soil water infiltration rate p dlvo 105 pa is the dlvo pressure at d 1 5 nm between adjacent particle surfaces p h is the hydration pressure at d 1 5 nm between adjacent particle surfaces and a and b are two constants given the distance between adjacent particle surfaces d 1 5 nm leng 2012 reported p h 2 35 106 pa in 1 mol l 1 k solution while goldberg et al 2008 indicated p h 0 pa in 0 1 mol l 1 cs solution respectively introducing the corresponding p dlvo and ir data table 3 obtained from figs 4 and 1 into eq 5 an equation set could be derived the constants a and b could be further calculated therefore eq 5 can be expressed as 6 ir 7 701 e 3 428 10 7 p dlvo p h the ir and p dlvo are known under different concentrations of various cation species based on the experiments and theoretical calculations the p h therefore could be estimated by eq 6 as shown in fig 6 furthermore the hydration pressures in li na k and cs between particles were estimated by pashley 1982 using a double exponential decay 7 f h r a 1 e d d 1 a 2 e d d 2 where f h is the hydration force between a plane and a sphere of radius r the constants a 1 a 2 d 1 and d 2 are showed in table a1 in appendix pashley 1982 according to the derjaguin approximation the p h can be calculated from the potential energy per unit area e between two planar surfaces 8 p h e d fh 2 π r d the calculations of p h at 1 5 nm between soil particles are also showed in fig 6 with open circles in different cations at corresponding concentration fig 6 shows that the strength of hydration pressure was in the order of li na k cs which is in accordance with the results of other experiments aqvist 1990 chai et al 2008 goldberg et al 2008 however the intensities of the theoretical calculations using eq 8 are smaller than that of the esimation using eq 6 the difference between them may result from the difference of surface hydration between soil particles and mica particles in the forthcoming studies the effects of hydration force on the soil water infiltration will be systematically investigated through the directly measurement of the forces between soil particles additionally when cationic or electrolyte concentration was lower than 0 001 mol l 1 logc 0 3 the hydration pressure approached the strongest for each cation species this hydration pressure may be attributed to the hydrations of both soil particles and cations a large number of negative charges at the soil particle surface produce a strong electric field which could further attract water dipoles and result in surface hydration of soil particles moreover if there was only surface hydration of soil particles but not cation hydration influenced by the electric field strength in the double layer the highest total hydration pressure would expected at the lowest cationic concentration of 0 00001 mol l 1 in this study at least in theory because of the strongest electric field strength in addition the total hydration pressure at a cationic concentration of 1 mol l 1 would be lowest because of the weakest electric field strength as can be seen from fig 6 this was true only for cs but false for li na and k the lowest pressures appeared at respectively 0 3 mol l 1li 0 1 mol l 1 na and 0 06 mol l 1 k although the size effect of alkali metal cations on the cation surface interactions and particle particle interactions were very weak at relatively low concentrations liu et al 2017 2012 it may become important at high electrolyte concentrations for a given cation species the cationic hydration pressure between two adjacent particles is not constant but strongly influenced by the distribution of cations in the double layer since the debye length κ 1 in eq 1 is large at relatively low electrolyte concentrations the number of the cations distributed in the space of x 0 0 75 nm d 2 1 5 2 nm will be relatively small thus the observed cationic hydration pressure will be relatively weak even though the corresponding surface hydration is relatively strong as the electrolyte concentration increases the debye length κ 1 and the surface hydration pressure decrease due to the reduction of water molecular induction as the electric field in the double layer weakens yu et al 2016b nevertheless the cationic hydration pressure might increase because the number of cations distributed in the space of x 0 0 75 nm increases however if the electrolyte concentration was so high that the debye length became 0 75 nm the cation would be dehydrated and its hydration pressure at d 1 5 nm approximately disappeared correspondingly leng 2012 meanwhile the surface hydration pressure of soil particle decreased because the electric field sharply decays near surface yu et al 2016b therefore the total hydration pressure will be greatly influenced by the electrolyte concentration through affecting the electric field in the double layer in addition the surface potentials φ 0 eq 1 are strongly affected by the hofmeister effects γ values for different cations thus the potential distribution in the double layer φ x is correspondingly influenced liu et al 2013b and electric field in the double layer e dφ dx was affected by the hofmeister energies of cation surface interactions peng et al 2018 therefore the total hydration pressure will be influenced by the hofmeister energies for the four equally charged cations as a result the total hydration pressure change with cationic concentration inevitably exhibits complex patterns as shown in fig 6 3 5 effect of the net pressure of dlvo hydration between particle surfaces on the soil pore size distribution the pore size distribution of soil column in 0 01 mol l 1li na k and cs was determined by ct scan and the result was showed in fig 7 the amount of small soil pore space e g 0 08 0 2 0 2 0 3 mm in li and na is much greater than those in k and cs systems and the series follows li na k cs on the contrary the percentages of large soil pore with 1 mm in li na k and cs are 22 8 40 2 56 4 and 59 9 respectively indicating an opposite series of li na k cs fig 7 the soil porosity is determined by the interaction forces between soil particles including dlvo and hydration forces fig 8 the p net p dlvo p h at 1 5 nm distance between particle surfaces can be estimated by eq 6 based on the experimental ir the data in fig 8 show that the soil pore size distribution strongly depends on the sum of dlvo and hydration pressures which are affected by the hofmeister energies of cations at the soil water interface based on the theoretical calculation of electrostatic repulsive pressure the percentages of 1 mm soil pore decrease with increasing p net positive value represents repulsion while the percentages of 0 5 mm soil pore increase with increasing p net meanwhile the percentages of 0 4 0 5 mm soil pore are approximately constant with different p net values the breakdown of soil aggregate increases with increasing p net hu et al 2015b therefore the released small soil particles would block up the large pores in soil column leading to decrease in 1 mm soil pore percentages but increase in small pores percentages in 0 01 mol l 1 ion concentration for example the p net at 1 5 nm distance between particle surfaces in li na k and cs decrease 87 8 34 0 18 8 and 1 0 105 pa respectively the corresponding percentages of 1 mm soil pore increases 22 8 40 2 56 4 and 59 9 respectively while those of 0 08 0 2 mm soil pore decreases 15 0 12 7 3 6 and 2 6 respectively fig 8 it is also worth noting that the intensity of 1 mm soil pore percentages increase in li na k and cs are different furthermore the amount of soil pore depends on the ion type small soil pore for example 0 08 0 2 mm in li is more than that in cs and the sequence is li na k cs while the contrary to the large soil pore fig 7 the effects of soil pore size distribution different interval of 0 08 mm equivalent diameter on the ir are showed in fig 9 the ir increases with increasing the percentage of 1 mm soil pore but decreases with increasing the percentage of 1 mm soil pore fig 9 it can be conclude that water infiltration in soil column is determined by the soil pore size distribution specially the 1 mm large soil pore as seen from fig 10 and the ir can be directly linked to the capillary pressure as it is dependent on the interaction forces between soil particles furthermore the osmotic force can also affect the water infiltration luo et al 2018b however the osmotic forces for a given concentration in alkali metals are identical thus it is insignificant in the specific ion effects on soil water infiltration the combined result in figs 7 10 implies that the dlvo and hydration forces between soil particles considering the specific ion effects determine the soil pore size distribution and then determine the soil water infiltrability 4 conclusions in this study strong specific ion effects were observed in soil water infiltrability for li na k and cs specifically for the same soil containing li na k and cs the maximum of ir were 1 8 4 3 5 2 and 13 0 cm h 1 respectively these findings indicate that 1 the soil water infiltration rate strongly depended on the dlvo and hydration forces between adjacent soil particles 2 the intense specific ion effects influenced both dlvo and hydration forces which are affected by hofmeister energies of cations at the soil water interface and 3 the dlvo and hydration forces between soil particles determine the soil pore distribution the hydration forces originated from surface hydration of soil particles and cationic hydration in the double layer most importantly the hydration pressure between adjacent soil particles was complexly influenced by electrolyte concentration debye length and cationic distribution in the double layer the debye length and the cationic distribution were strongly influenced by the hofmeister energies of cations acknowledgments this work was supported by the national natural science foundation of china 41101223 41530855 41501240 and 41877026 the natural science foundation project of cq cstc grant no cstc2018jcyjax0354 and cstc2018jcyjax0318 the scientific and technological research program of chongqing municipal education commission grant no kj1501115 appendix 
6829,many studies have shown that k has more favourable effects on soil water infiltration than na which is a result of specific ion effects or hofmeister effects in this study we employed four alkali metal cation species li na k and cs to determine how the particle interactions influence the water infiltration in a soil with permanent surface charges moreover the defined hofmeister energy was employed to characterize the specific ion effects the dlvo force plus the hydration force between two adjacent soil particles mainly determines water infiltration rate through affecting the soil pore size distribution which exhibits strong specific ion effects the hydration force may originate from the surface hydration of soil particles and the hydration of cations in the double layer the hydration pressure between adjacent soil particles was complexly influenced by electrolyte concentration debye length cationic distribution in the double layer through the hofmeister energy of cation keywords electrostatic repulsion hydration force hofmeister series soil water movement 1 introduction water movement in soil is a hot topic in environmental and agricultural fields jayawardane et al 2011 the decreasing ionic concentration and cation type like sodium in soil solution can result in the degradation of soil structure le bissonnais 2016 rengasamy et al 2016 a reduction in electrolyte concentration could result in the increase of clay swelling and dispersion mcneal et al 1966 which further changes the pore size distribution jayawardane and beattie 1979 marchuk and marchuk 2018 and eventually decrease soil water infiltrability in addition soil water infiltrability could also be decreased when ions present in the order ca2 mg2 k na laurenson et al 2011 marchuk and marchuk 2018 rengasamy 2002 the structure and stability of soil aggregates determine soil water infiltrability the mechanisms of soil aggregate breakdown include inner forces between soil particles such as electrostatic hydration and van der waals interactions hu et al 2018 trefalt et al 2017 as well as outer forces such as raindrop impact the shearing force of flowing water differential swelling osmotic stress and soil tillage carmi et al 2018 luo et al 2018b or and ghezzehei 2002 the electrostatic interactions between soil particles play crucial roles in soil aggregate stability hu et al 2018 2015b and strongly influence soil water movement yu et al 2016a therefore to some extent soil aggregate stability and soil water movement could be described by the derjaguin landau verwey overbeek dlvo theories churaev and derjaguin 1985 ducker and pashley 1992 in addition to the coulombic effects specific ion effects contribute to particle interactions boström et al 2001 dos santos and levin 2011 liu et al 2014 luo et al 2018a and therefore to aggregate stability porous state and water infiltrability of soil for decades soil scientists have also identified specific ion effects when determining sorption capacity and selectivity coefficients for cs relative to k in soil or sediments bolt 1979 cremers et al 1988 de koning et al 2007 specific ion effects are closely related to the specific properties of ions including size electron shell number and polarization parsons et al 2011 parsons and ninham 2010 rios carvajal et al 2018 classically the influence of specific ion effects on particle aggregation and soil water infiltrability is attributed to ionic hydration however the fundamental reason for specific ion effects is not hydration but quantum fluctuation forces that cause london lifshitz dispersion forces parsons et al 2011 even hydration itself is determined by quantum fluctuation forces or dispersion forces parsons et al 2011 progress has been made in explaining specific ion effects but their origin is still a matter of debate dos santos and levin 2011 krishnamoorthy et al 2018 kunz et al 2004a b levin et al 2009 ninham and yaminsky 1997 parsons et al 2011 petrache et al 2006 a non classical induction force of adsorbed cations was found to be the origin of specific ion effects in soil and clay systems liu et al 2017 2016 2014 non classically polarized cations could increase the coulomb interaction forces between cations and the clay surface and then decrease the strength of the electric field around clay particles and the electrostatic repulsive force between adjacent particles in aggregates finally increase soil aggregate stability hu et al 2015a li et al 2015b xu et al 2015 considering soil water infiltrability is determined by the structure and stability of soil aggregates it is important to investigate the specific ion effects of soil water infiltrability the aims of this report are the evaluation of the influence of specific ion effects i on electrical repulsive and hydration pressure betweem soil particles and ii on the infiltration of water into soil 2 materials and methods 2 1 sample preparation samples of the purplish soil belonging to the regosol reference soil group fao 2015 and to the entisol order soil survey staff 1999 were collected at chongqing china the utilized soil mainly contain permanent surface charges the surface charge number and specific surface area determined by the approach suggested by li et al 2011 were 16 0 cmol kg 1 and 48 0 m2 g 1 respectively the method of li et al 2011 is based on a model of the cation exchange equilibrium derived from the nonlinear poisson boltzmann equation considering the specific ion effects the soil has a loamy textural class with a clay and sand content of 37 9 and 14 2 respectively the semi quantitative mineralogy of soil was analyzed by the bioelements analysis laboratory in southwest university china with an x ray diffractometer xd 3 beijing purkinje general instrument co ltd beijing china the main clay minerals in the soils were montmorillonite 5 5 vermiculite 8 3 mica 14 5 kaolinite 5 0 illite 8 6 quartz 24 2 potash feldspar 1 7 soda feldspar 31 4 the bulk density was 1 33 g cm 3 the organic matter content was 12 3 g kg 1 determined by a standard potassium dichromate digest method and the ph solution soil ratio 5 1 was 7 11 to calculate the interaction forces between soil particles the soil samples were firstly saturated with li na k and cs using licl nacl kcl and cscl respectively and then air dried to obtain the saturated samples 500 g aliquots of air dried soil were introduced into a 5 l beaker and washed successively by dispersion agitation centrifugation and decantation with three portions of 5 l licl nacl kcl or cscl at 0 5 mol l 1 respectively and then with three portions of deionized water to remove residual metal cations in soil bulk solutions the soil washing with deionzed water does not influence the cation adsorption at soil particle surface since the concentration of metal cations is much higher than that of proton from water in bulk solutions next each cationic saturated soil sample was dried under a temperature of 60 c crushed and passed through a 1 mm sieve for the following experiments 2 2 determination of surface properties of soil particles the combined method suggested by li et al 2011 for determining surface properties was employed to determine surface charge density knowing the surface charge density of a soil the surface potentials φ 0 under different concentrations ranging from 0 00001 to 1 0 mol l 1 of licl nacl kcl and cscl can be calculated li et al 2004 when specific ion effects are present the surface potential of soil for a 1 1 electrolyte can be determined du et al 2016 2017 1 φ 0 2 r t γ f ln 1 a 1 a where κ n t s c 0 1 4 1 a 4 1 exp 1 a and κ 2 f 2 z 2 c 0 ε 0 ε r r t where γ defined as γ 1 w h 0 f φ 0 is the effective charge coefficient of counterion fφ 0 j mol 1 is the coulomb mean potential energy at the surface w h 0 j mol 1 here referred to as hofmeister energy is the additive potential energy arising from specific effects at the surface r j mol 1 k 1 is the universal gas constant t k is the absolute temperature z is the valence of the counter ion f c mol 1 is the faraday constant ε 0 is the vacuum permittivity ε r is the static relative permittivity of water which is 80 c 0 mol m 3 is the equilibrium concentration of a monovalent cation in bulk solution s m2 g 1 is the specific surface area n t mol g 1 is the cation exchange capacity and a is a temporary parameter defined as a tanh zfφ 0 4rt κ 1 reflects the debye length in double layer 2 3 calculations of particle interaction forces once the surface potential is determined the potential at the middle of the overlapping position of the electric double layers edls of two adjacent particles φ d 2 can be calculated hou et al 2009 li et al 2009 2013 2 π 2 1 1 2 2 e 2 z i f φ d 2 rt 3 8 2 e 4 z i f φ d 2 rt arcsin e z i f φ z i f φ d 2 2 r t 1 4 d κ e z i f φ d 2 2 r t where d nm is the distance between two adjacent particles the electrostatic repulsive pressure p e d pa can be calculated based on the φ d 2 hou et al 2009 li et al 2009 2013 3 p e d 2 r t c 0 cosh f φ d 2 rt 1 the van der waals attractive pressure p vdw d pa can be estimated li et al 2009 2013 4 p vdw d a 0 6 π d 3 where a j is the hamaker constant for soil and clay the hamaker constant under vacuum is approximately 12 10 20 j while in aqueous solution this value is 7 8 10 20 j li et al 2009 2013 the dlvo forces are the sum of the electrostatic repulsive and the van der waals attractive force p dlvo d p e d p vdw d 2 4 water movement experiments a rectangular plexiglass column 20 cm height with a scale in millimeters 3 cm width and 1 cm thickness was used in the experiments a porous clapboard was fixed to the bottom end of the column to support the soil sample to maintain a constant bulk density the soil samples were transferred into the column by adding in small increments and then packing with a tamper according to the methods described by smiles et al 2012 and yu et al 2016a overall approximately 63 0 g soils were added and packed to a bulk density of 1 05 g cm 3 porous clapboards were also set on the soil surface of the upper end of the soil column to produce a stable flow of soil water the infiltration solutions at concentration ranging from 0 00001 to 1 0 mol l 1 were added into the space at the top of the column and a constant height of 4 cm hydraulic head was maintained using a mariotte bottle the position of the wetting front was recorded through the scale on the rectangular plexiglass column at different infiltration times the soil water infiltration rate ir is estimated by the velocity of the wetting front advance wu et al 2016 the final infiltration time is 60 150 min which was ascertained by the maximum position of the wetting front about 20 cm if the wetting front does not reach the bottom of soil column the maximum infiltration time is set to 150 min the relationships between ir and dlvo forces were best fitted by a exponential function ir aexp bp dlvo where a and b are constants to be estimated 2 5 computed tomography ct scan to determine the soil pore size distribution the ct measurements of soil columns were conducted the soil cylindrical column was 3 diameter 3 height cm with the pretreated soil sample in section 2 1 the packing method was the same as in the water movement experiment the soil columns were wetted by 0 01 mol l 1 corresponding licl nacl kcl and cscl solutions respectively the soil column was scanned by ct when the position of wetting front reached 3 cm perusal the ct scanner is ct nanotom s phoenix nanotoms ge usa at the institute of soil scicences chinese academy of sciences the peak scan potential was 100 kv and the current was 100 μa a 0 2 mm cu filter was used to reduce the beam hardening effect the distances the source sample and the sample detector were 30 cm and 20 cm respectively the initial scan position was 0 2 cm from top of the column the thickness of scanning was 13 μm 1000 images were generated for each column scan the resolution of the scanners output device was 660 660 with each voxel representing a volume of 13 μm 13 μm 13 μm image processing and visualization were conducted with the open source software imagej ver 1 47 a region of interest was selected from the central part of soil cores to avoid artifacts at the boundary region caused by sampling procedures of image processing and subsequent analyses were identical for the region of interest of soil cores a three dimensional median filter was used to reduce noise before image segmentation pore size distribution was obtained by morphological opening operations briefly pores smaller than a certain size were removed by erosion followed by dilation using a spherical structuring element which is called opening a detailed description to this method is given by zhou et al 2016 it is worth mentioning that the ct scanning was not applied to the samples used for the percolation experiments due to the column required by ct scanning cylindrical is different from the one prismatic measured by soil infiltration furthermore although the ct scanning was detected under one electrolyte concentration 0 01 mol l 1 the relationships among interactions between soil particles pore size distribution and water infiltrability in soil column can be investigated for the presence of different alkali metal cations 3 results and discussion 3 1 the soil water infiltrability in different alkali metal cation systems experimental results describing the relationship between electrolyte concentration and the ir for li na k and cs are shown in fig 1 it can be seen the ir exhibits rapid growth at first and then shifts to slow growth with increasing electrolyte concentration there is a critical concentration approximate 0 05 0 1 mol l 1 emerging for each cation species at the intersection point conversely the largest value of ir for each cation species was quite different fig 1 being 1 8 4 3 5 2 and 13 0 cm h 1 for li na k and cs systems respectively the increasing trends of the ir curves vs ion concentration for li na k and cs systems were markedly different which show that the ir increased with electrolyte concentration as follows li na k cs in addition for the same bulk solution concentration there were large differences of ir in both 0 001 and 1 0 mol l 1li na k and cs systems as the showed in table 1 these findings indicate that the specific ion effects on soil water infiltrability were very strong interestingly as electrolyte concentration decreased the magnitude of the differences in the ir sharply increased indicating more pronounced specific ion effects at smaller electrolyte concentration 3 2 surface potential of soil particles as influenced by specific ion effects the experimental results showed that there were strong hofmeister effects in soil water infiltrability in other words soil water infiltrability was highly dependent on the cationic composition of soil in this section we reveal physical insight regarding the observed hofmeister effects on soil water infiltrability liu et al 2013a determined the relative effective charge coefficient between two cation species and found that γ k γ na 1 646 and γ na γ li 1 11 li et al 2015a determined the absolute effective charge coefficient of na to be γ na 1 18 thus γ k 1 94 and γ li 1 06 li et al 2015a also determined the relative effective charge coefficient between cs and k and found that γ cs γ k 1 475 thus γ cs 2 86 the surface potential was calculated from eq 1 fig 2 and the hofmeister energies at x 0 could be estimated to be 0 06fφ 0 0 18fφ 0 0 94 fφ 0 and 1 68fφ 0 for li na k and cs respectively as shown in fig 2 specific ion effects decrease the surface potential for a given electrolyte concentration the stronger the specific ion effects is the more the surface potential is decreased 3 3 the dlvo forces of soil particles as influenced by specific ion effects in classical dlvo theory the electric field strength and the corresponding electrostatic force are determined by the electrolyte concentration and type without regard to the ionic volume ionic hydration and dispersion forces therefore for the four monovalent cations li na k and cs under given conditions the electric field strength and net inter particle pressure between adjacent soil particles are the same and can be described equally by the same force distribution equation in space however as shown in fig 3 the distributions of net repulsive pressure p dlvo between the surfaces of two adjacent particles in the aggregate for the presence of li na k and cs are quite different specifically for a given cationic concentration the net repulsive pressure was in the order of cs k na li and the net attractive pressure was in the order of cs k na li for example under the cationic concentration of 0 00001 mol l 1 the net pressures at a distance of 1 5 nm between the two adjacent particle surfaces were 15 3 10 6 3 01 and 7 69 105 pa in the presence of li na k and cs respectively correspondingly under a cationic concentrations of 0 5 mol l 1 the net pressures at a distance of 1 5 nm between two adjacent particle surfaces were 1 18 4 48 11 3 and 12 3 105 pa in the presence of li na k and cs respectively previous studies have shown that the net dlvo pressure determines soil aggregate stability hu et al 2015b and then strongly affect soil water movement yu et al 2016a fig 3 shows the first maxima of net dlvo pressure in li and na systems arise at a distance of d 1 5 nm which are much higher than that in k and cs therefore the effects of net dlvo pressure at d 1 5 nm on ir are investigated fig 4 a shows the change in the net dlvo pressure at a distance of d 1 5 nm pnet with electrolyte concentration while fig 4b shows the change in the ir with electrolyte concentration as shown in fig 4a a cationic concentration of 0 01 mol l 1 logc 0 2 was an approximate critical point for all the four cations in the p dlvo logc 0 relationship specifically at cationic concentrations lower than 0 01 mol l 1 as the cation concentration decreased from 0 01 mol l 1 to 0 00001 mol l 1 the net dlvo pressure changed very little for a given cation e g li changed by only 1 8 105 pa however for cationic concentrations higher than 0 01 mol l 1 as the cation concentration decreased from 1 mol l 1 to 0 01 mol l 1 the net dlvo pressure changed greatly e g li changed by 17 105 pa as shown in fig 4b 0 01 mol l 1 cationic concentration logc 0 2 was also an approximate critical point for all the four cations in the ir logc 0 relationship specifically for cationic concentrations lower than 0 01 mol l 1 as cation concentration decreased from 0 01 mol l 1 to 0 00001 mol l 1 logc 0 equals from 2 to 5 the ir changed very little for a given cation e g the cs changed by only 1 28 cm h 1 however for cationic concentrations higher than 0 01 mol l 1 as the cation concentration decreased from 1 mol l 1 to 0 01 mol l 1 logc 0 equals from 0 to 2 the ir changed greatly e g the cs changed by 5 68 cm h 1 fig 4a and 4b show that the small change in the net dlvo pressure corresponded to the small change in ir and vice versa conversely these figures also show that a stronger net repulsive pressure is associated with a lower ir and vice versa overall these findings indicate that the net pressure of dlvo at a distance of 1 5 nm between adjacent particle surfaces is closely related to the ir 3 4 effect of the net pressure of dlvo hydration between particle surfaces on the soil water infiltration rate the data shown in fig 4 could be used to establish the relationship of the ir and net pressure of dlvo at a distance of 1 5 nm between adjacent particle surfaces fig 5 fig 5 is actually fig 1 with the x axis of electrolyte concentration replaced by the corresponding net pressure of dlvo at a distance of 1 5 nm if soil water movement mainly determined by the interactions between soil particles the irs in different alkali metals are a function of p dlvo comparison of these figures reveals that the four absolutely different curves for li na k and cs shown in fig 1 could be approximately unified to one exponential curve with r 2 0 6963 as shown in fig 5 these findings imply that soil water infiltrability was directly affected by the interaction pressure between adjacent soil particles in aggregates rather than the electrolyte concentration however as shown in fig 5 the distribution of each cation bore its own pattern and do not obey the exponential fitting curve systematically a relatively small r 2 value in addition the pearson s rank correlation analysis was done with spss version 18 0 data for each correlation consists of the experimental ir and theoretical p dlvo the data in table 2 imply that a general exponential equation exists in these cations due to the significant correlations p 0 05 between experimental data in different alkali metals and exponential curve this is because hydration forces are also important in particle interactions goldberg et al 2008 leng 2012 pashley 1981 therefore the exponential equation for investigating soil particles interactions taking hydration force into account could be expressed as 5 ir a e b p dlvo p h where ir cm h 1 is the soil water infiltration rate p dlvo 105 pa is the dlvo pressure at d 1 5 nm between adjacent particle surfaces p h is the hydration pressure at d 1 5 nm between adjacent particle surfaces and a and b are two constants given the distance between adjacent particle surfaces d 1 5 nm leng 2012 reported p h 2 35 106 pa in 1 mol l 1 k solution while goldberg et al 2008 indicated p h 0 pa in 0 1 mol l 1 cs solution respectively introducing the corresponding p dlvo and ir data table 3 obtained from figs 4 and 1 into eq 5 an equation set could be derived the constants a and b could be further calculated therefore eq 5 can be expressed as 6 ir 7 701 e 3 428 10 7 p dlvo p h the ir and p dlvo are known under different concentrations of various cation species based on the experiments and theoretical calculations the p h therefore could be estimated by eq 6 as shown in fig 6 furthermore the hydration pressures in li na k and cs between particles were estimated by pashley 1982 using a double exponential decay 7 f h r a 1 e d d 1 a 2 e d d 2 where f h is the hydration force between a plane and a sphere of radius r the constants a 1 a 2 d 1 and d 2 are showed in table a1 in appendix pashley 1982 according to the derjaguin approximation the p h can be calculated from the potential energy per unit area e between two planar surfaces 8 p h e d fh 2 π r d the calculations of p h at 1 5 nm between soil particles are also showed in fig 6 with open circles in different cations at corresponding concentration fig 6 shows that the strength of hydration pressure was in the order of li na k cs which is in accordance with the results of other experiments aqvist 1990 chai et al 2008 goldberg et al 2008 however the intensities of the theoretical calculations using eq 8 are smaller than that of the esimation using eq 6 the difference between them may result from the difference of surface hydration between soil particles and mica particles in the forthcoming studies the effects of hydration force on the soil water infiltration will be systematically investigated through the directly measurement of the forces between soil particles additionally when cationic or electrolyte concentration was lower than 0 001 mol l 1 logc 0 3 the hydration pressure approached the strongest for each cation species this hydration pressure may be attributed to the hydrations of both soil particles and cations a large number of negative charges at the soil particle surface produce a strong electric field which could further attract water dipoles and result in surface hydration of soil particles moreover if there was only surface hydration of soil particles but not cation hydration influenced by the electric field strength in the double layer the highest total hydration pressure would expected at the lowest cationic concentration of 0 00001 mol l 1 in this study at least in theory because of the strongest electric field strength in addition the total hydration pressure at a cationic concentration of 1 mol l 1 would be lowest because of the weakest electric field strength as can be seen from fig 6 this was true only for cs but false for li na and k the lowest pressures appeared at respectively 0 3 mol l 1li 0 1 mol l 1 na and 0 06 mol l 1 k although the size effect of alkali metal cations on the cation surface interactions and particle particle interactions were very weak at relatively low concentrations liu et al 2017 2012 it may become important at high electrolyte concentrations for a given cation species the cationic hydration pressure between two adjacent particles is not constant but strongly influenced by the distribution of cations in the double layer since the debye length κ 1 in eq 1 is large at relatively low electrolyte concentrations the number of the cations distributed in the space of x 0 0 75 nm d 2 1 5 2 nm will be relatively small thus the observed cationic hydration pressure will be relatively weak even though the corresponding surface hydration is relatively strong as the electrolyte concentration increases the debye length κ 1 and the surface hydration pressure decrease due to the reduction of water molecular induction as the electric field in the double layer weakens yu et al 2016b nevertheless the cationic hydration pressure might increase because the number of cations distributed in the space of x 0 0 75 nm increases however if the electrolyte concentration was so high that the debye length became 0 75 nm the cation would be dehydrated and its hydration pressure at d 1 5 nm approximately disappeared correspondingly leng 2012 meanwhile the surface hydration pressure of soil particle decreased because the electric field sharply decays near surface yu et al 2016b therefore the total hydration pressure will be greatly influenced by the electrolyte concentration through affecting the electric field in the double layer in addition the surface potentials φ 0 eq 1 are strongly affected by the hofmeister effects γ values for different cations thus the potential distribution in the double layer φ x is correspondingly influenced liu et al 2013b and electric field in the double layer e dφ dx was affected by the hofmeister energies of cation surface interactions peng et al 2018 therefore the total hydration pressure will be influenced by the hofmeister energies for the four equally charged cations as a result the total hydration pressure change with cationic concentration inevitably exhibits complex patterns as shown in fig 6 3 5 effect of the net pressure of dlvo hydration between particle surfaces on the soil pore size distribution the pore size distribution of soil column in 0 01 mol l 1li na k and cs was determined by ct scan and the result was showed in fig 7 the amount of small soil pore space e g 0 08 0 2 0 2 0 3 mm in li and na is much greater than those in k and cs systems and the series follows li na k cs on the contrary the percentages of large soil pore with 1 mm in li na k and cs are 22 8 40 2 56 4 and 59 9 respectively indicating an opposite series of li na k cs fig 7 the soil porosity is determined by the interaction forces between soil particles including dlvo and hydration forces fig 8 the p net p dlvo p h at 1 5 nm distance between particle surfaces can be estimated by eq 6 based on the experimental ir the data in fig 8 show that the soil pore size distribution strongly depends on the sum of dlvo and hydration pressures which are affected by the hofmeister energies of cations at the soil water interface based on the theoretical calculation of electrostatic repulsive pressure the percentages of 1 mm soil pore decrease with increasing p net positive value represents repulsion while the percentages of 0 5 mm soil pore increase with increasing p net meanwhile the percentages of 0 4 0 5 mm soil pore are approximately constant with different p net values the breakdown of soil aggregate increases with increasing p net hu et al 2015b therefore the released small soil particles would block up the large pores in soil column leading to decrease in 1 mm soil pore percentages but increase in small pores percentages in 0 01 mol l 1 ion concentration for example the p net at 1 5 nm distance between particle surfaces in li na k and cs decrease 87 8 34 0 18 8 and 1 0 105 pa respectively the corresponding percentages of 1 mm soil pore increases 22 8 40 2 56 4 and 59 9 respectively while those of 0 08 0 2 mm soil pore decreases 15 0 12 7 3 6 and 2 6 respectively fig 8 it is also worth noting that the intensity of 1 mm soil pore percentages increase in li na k and cs are different furthermore the amount of soil pore depends on the ion type small soil pore for example 0 08 0 2 mm in li is more than that in cs and the sequence is li na k cs while the contrary to the large soil pore fig 7 the effects of soil pore size distribution different interval of 0 08 mm equivalent diameter on the ir are showed in fig 9 the ir increases with increasing the percentage of 1 mm soil pore but decreases with increasing the percentage of 1 mm soil pore fig 9 it can be conclude that water infiltration in soil column is determined by the soil pore size distribution specially the 1 mm large soil pore as seen from fig 10 and the ir can be directly linked to the capillary pressure as it is dependent on the interaction forces between soil particles furthermore the osmotic force can also affect the water infiltration luo et al 2018b however the osmotic forces for a given concentration in alkali metals are identical thus it is insignificant in the specific ion effects on soil water infiltration the combined result in figs 7 10 implies that the dlvo and hydration forces between soil particles considering the specific ion effects determine the soil pore size distribution and then determine the soil water infiltrability 4 conclusions in this study strong specific ion effects were observed in soil water infiltrability for li na k and cs specifically for the same soil containing li na k and cs the maximum of ir were 1 8 4 3 5 2 and 13 0 cm h 1 respectively these findings indicate that 1 the soil water infiltration rate strongly depended on the dlvo and hydration forces between adjacent soil particles 2 the intense specific ion effects influenced both dlvo and hydration forces which are affected by hofmeister energies of cations at the soil water interface and 3 the dlvo and hydration forces between soil particles determine the soil pore distribution the hydration forces originated from surface hydration of soil particles and cationic hydration in the double layer most importantly the hydration pressure between adjacent soil particles was complexly influenced by electrolyte concentration debye length and cationic distribution in the double layer the debye length and the cationic distribution were strongly influenced by the hofmeister energies of cations acknowledgments this work was supported by the national natural science foundation of china 41101223 41530855 41501240 and 41877026 the natural science foundation project of cq cstc grant no cstc2018jcyjax0354 and cstc2018jcyjax0318 the scientific and technological research program of chongqing municipal education commission grant no kj1501115 appendix 
