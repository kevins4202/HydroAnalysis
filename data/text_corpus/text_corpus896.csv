index,text
4480,spatial geostatistical interpolation of point measurements of streambed attributes in the hyporheic zone may be constrained by the streambed anisotropy and data density and spatial distribution may significantly impact the results spatial clustering and low spatial data density can be caused by bedrock outcropping at the streambed limiting installation of in stream piezometers this study examines parameter error variability of the geostatistical interpolation using anisotropic interpolation methods and increasing the data density by adding left censored values i e data below measurement limit to locations where measurements were limited by exposed bedrock lining the streambed the reduction in relative standard error of the interpolation was determined for the spatial distributions of streambed attributes including hydraulic conductivity seepage flux and mercury solute flux measured in two different years along a study reach in east fork poplar creek tennessee usa two methods to impute the left censored values were compared including the conventional half the detection limit substitution method and the stochastic approximation of expectation maximization saem algorithm which both had comparable results imputing left censored data increased the data density to recommended ranges reduced data clustering increased the spatial dependence for some attributes and reduced the standard error for each of the three attributes for the reach considered herein addition of the left censored values resulted in a larger error reduction than the consideration of anisotropy within the interpolation which confirms the benefit of data addition to increase data density within data limited river corridors keywords hyporheic geostatistics kriging piezometer left censored data 1 introduction selection of a suitable mapping method for spatial interpolation under data limited conditions can be challenging krivoruchko 2011 especially for constrained environments such as streams and rivers naganna et al 2017 the spatial distribution of hydrogeomorphic characteristics of streams and rivers tends to be anisotropic as fluid flow and sediment transport are primarily unidirectional and sediment erosion and deposition generally leads to heterogeneous deposits brunner et al 2017 accordingly the spatial distribution of measurements and the values of measured streambed attributes have an inherent anisotropy chen 2000 2004 ghysels et al 2018 landon et al 2001 lu et al 2012 spatial autocorrelation considered in geostatistical interpolation is a spatial dependence on a data distribution and anisotropy yeh et al 2015 several of the prior papers containing streambed attribute mapping used methods other than geostatistics for interpolation and most commonly used a multiquadratic radial basis function method genereux et al 2008 gilmore et al 2016a 2016b kennedy et al 2009a 2009b 2008 2010 which does not necessarily consider spatial statistics as geostatistical methods do other published papers containing streambed attribute mapping have applied isotropic geostatistical mapping of piezometer streambed sediment data abimbola et al 2020 ghysels et al 2018 korus et al 2020 naganna et al 2017 song et al 2016 wu et al 2016 2015 there is a lack of research comparing geostatistical and non geostatistical interpolation methods for streambed sediment attributes and there is a lack of investigation into the need to consider anisotropy within streambed sediment attribute interpolation methods as illustrated in a recent review brunner et al 2017 there have been many geostatistical studies applied to river groundwater interactions that have been used to model heterogeneous sedimentary structures which include for example development of statistical and or multidimensional sequences of geological facies to represent subsurface material heterogeneities engdahl et al 2010 pryshlak et al 2015 constraining uncertainties in such heterogeneous model development can be challenging due to data limitations additional methods are needed to decrease errors and uncertainty in geostatistical interpolation and this is particularly true for data limited environments such as streambed hyporheic attribute mapping kennedy et al 2008 clustering and density of data could impact feasibility of geostatistical interpolation of measured properties within hyporheic zones of rivers and streams since the channel geometry and directional flow of water may produce spatial correlations that are not explained by euclidean distance peterson and hoef 2014 data density defines the number of measurement locations per unit area and data clustering characterizes how close or far measurement locations are away from other sampling locations those two data characteristics are critical to minimize the variance and optimize accuracy in the geostatistical interpolation results these characteristics are particularly important for geostatistical interpolation of the hydraulic interaction between groundwater and surface water in the hyporheic zone of rivers and streams since elongate stream channel morphology may constrain data spatial distributions bethune et al 2015 brunner et al 2017 freitas 2015 sebok et al 2015 weatherill 2014 interest in the effect of sampling density and spatial distribution on the accuracy of geostatistical interpolations of streambed attributes has increased recently with interest in hyporheic zone exchange characterization brunner et al 2017 naganna et al 2017 shrivastava et al 2020 kennedy et al 2008 found that a sampling density of about 0 05 points m2 was sufficient to reduce error in streambed sediment vertical hydraulic conductivity kv to 10 or less genereux et al 2008 also compared the spatial variability of kv and found no significant interpolation differences between 0 025 points m2 and 0 13 points m2 sampling densities nevertheless the effect of sampling design or the spatial distribution of measurement points on geostatistical interpolation of streambed attributes has not been thoroughly investigated sampling design and selection of sampling locations to measure streambed attributes has generally been based on random selection kennedy et al 2008 or equally spaced grids with measurement points located on the right center or left side of a stream genereux et al 2008 kennedy et al 2008 leahy 2007 reyes 2009 kennedy et al 2008 addressed the effect of sampling design on the accuracy of the spatial interpolation of streambed attributes by comparing likelihood of error in average streambed attributes using three sampling designs including random sampling and two structured designs that created subsets of equal numbers of points from left center and right side of the stream and found that sampling design had a negligible effect on uncertainty compared to the data density the most common methods to quantify streambed kv and other attributes requires auger drilling and piezometer installation in order to acquire measurements by the slug test falling head or constant head permeameter methods abimbola et al 2020 borna et al 2018 chen 2000 2004 cheng et al 2011 genereux et al 2008 ghysels et al 2018 gilmore et al 2016a 2016b kennedy et al 2009a 2009b 2008 2010 korus et al 2020 landon et al 2001 levy et al 2011 lu et al 2012 sebok et al 2015 song et al 2016 wu et al 2016 2015 and fewer studies use hydraulic manometers kelly and murdoch 2003 winter et al 1988 and grain size distribution methods chen 2000 landon et al 2001 however measurement of streambed attributes can be challenging depending on the geomorphology of the streambed the natural and artificial obstacles and inherent limitations in methods for example bedrock outcropping at the streambed without significant overlying unconsolidated streambed sediment limits in stream piezometer installation point measurements may be below lower limits of measurement and these factors can impose spatial clustering and decreased data density advances in methods for increasing data density to decrease errors and uncertainty are needed particularly for hyporheic attribute mapping when streambeds have intermittent bedrock outcropping data addition has been used to increase data density and it has a rich history in a number of fields including epidemiology and life expectancy astronomy occupational health chemistry and environmental science helsel 2010 left censored data are measurements that are not quantitative because responses are below method quantification limits they are typically considered semi quantitative estimated values assuming a statistical distribution estimation and addition of left censored data has been an active area of research for environmental data especially water quality for over half a century cohen 1950 1957 gleit 1985 helsel 2010 wen 1994 despite prior criticisms regarding accuracy and bias substitution has been one of the most commonly used left censored estimation method which typically uses half of the lower detection or measurement limit helsel 2010 zhang et al 2004 one half of the lower detection limit substitution is based on the simple arithmetic average of the lower detection limit and zero however there are a number of data estimation methods other than substitution including the maximum likelihood estimator mle kaplan meier km and regression order statistics ros appropriateness and effectiveness of these methods has been discussed with varied results a brief synopsis of cited works is provided below and for full discussion see helsel 2010 and zhang et al 2004 generally researchers have found most of these methods work well within certain conditions for example when the percent left censored to total data number is low e g less than 30 antweiler and taylor 2008 gibbons 1996 substitution with expected value works well gleit 1985 substitution with one half the detection limit out performs other methods and mle is not effective for small data sets clarke 1998 zhang et al 2004 mle is also effective with known statistical distributions whereas km and ros are more effective for unknown distributions helsel 2010 lastly substitution is not effective when the detection limit is variable helsel 2010 yun and qian 2015 and mle is not effective when skewness of the observed data is significant shoari et al 2015 very few studies focused on groundwater chemistry have included estimated left censored data for attribute mapping and spatial statistical analyses huang et al 2019 kim et al 2011 mcgrory et al 2017 munoz et al 2017 the estimation of left censored data for these studies varied from using half the detection limit mcgrory et al 2017 ros munoz et al 2017 and substituting zero for non detected locations huang et al 2019 kim et al 2011 additionally a few studies created and inserted absence non occurrence samples in groundwater potential mapping using machine learning models corsini et al 2009 naghibi and pourghasemi 2015 rahmati et al 2019 others used the substitution method to increase data density and improve the accuracy of landslide susceptibility models gorsevski et al 2006 hong et al 2018 nefeslioglu et al 2008 we are unaware of any left censored method that takes into account spatial structure aside from the stochastic approximation of expectation maximization saem proposed by delyon et al 1999 saem has been used to estimate left censored values for different research fields including medical barbosa 2016 samson et al 2007 snoeck et al 2010 and environmental lachos et al 2017 ordoñez cuastumal 2017 to our knowledge adding left censored values to increase streambed sediment characterization data density for evaluation of hyporheic zone exchange has not been previously investigated the main objective of this study was to assess the effect of increasing data density with the addition of left censored values on spatially interpolated 2d horizontal distribution of hydraulic and solute transport attributes of streambed sediments the left censored values were added to the locations where bedrock outcropped at the streambed and piezometer installation was not possible and these results with addition of left censored values were compared to interpolation results without addition of left censored values the effect of imputing the left censored values using half the detection limit for i e substitute method versus using saem algorithm was evaluated and compared a second objective was to assess the impact of considering 2d horizontal anisotropy within the kriging geostatistical method compared to the typical isotropic kriging method on the interpolated results assessment of these different geostatistical interpolation approaches was based on minimization of the attribute average prediction standard error 2 materials and methods 2 1 site description east fork poplar creek efpc in eastern tennessee usa is impaired with dissolved mercury hg contamination brooks et al 2017 the study site is a reach located about 5 4 km upstream from the mouth of the creek and was approximately 265 m long with an average width of 10 m fig 1 recent studies have suggested that flow exchange between surface water and the hyporheic zone contributes to hg load in the surface water emphasizing the importance of quantifying the spatial distribution of the streambed attributes demers et al 2018 southworth et al 2013 characterization of hydraulic exchange and solute transport attributes of the streambed sediments is a critical consideration for effective implementation of remedial strategies for mitigating contaminant impacts to the efpc as well as other stream or river systems the forested landscape in the study reach provides heavy canopy cover over the channel in the spring and summer shales and carbonate rock i e dolomite and limestone are the dominant lithologies underlying the efpc watershed sections of the channel streambed consist of bedrock outcrops with little to no overlying sediment brooks et al 2017 rucker et al 2021 where unconsolidated sediments line the channel materials range in size from large stones to silt clay usda particle size class trace element analyses suggested localized areas of stream bank erosion contribute sediments to the efpc channel brooks et al 2017 dickson et al 2019 visually the streambed bathymetry changed notably between summer 2017 and 2018 following major rain and accompanying flood events in april 2017 and february 2018 fig s1 in supplemental information those two events likely had significant impact on the hydraulic solute transport and other properties measured for streambed sediments 2 2 streambed attribute point measurement vertical hydraulic gradients and streambed kv were measured using instream piezometers during the summer seasons of 2017 and 2018 here piezometers were actually miniature wells with a well screen installed in the streambed sediments and they were constructed of pvc pipe with 3 18 cm outer diameter and 2 54 cm inner diameter the piezometers were built from two sections connected by a 5 1 cm female female connector the perforated bottom section 30 48 cm of the piezometer was augured in the streambed sediment and consisted of a 15 24 cm perforated section 0 0254 cm slot size the length of the unperforated upper section of the piezometers above the sediment was cut to length based on the depth of the water column the piezometers were then allowed to equilibrate for at least four hours prior to recording the data to measure the hydraulic head gradient between the surface water and streambed porewater a pressure transducer aquistar ct2x0 was placed within the piezometer where the tip of the pressure transducer was level with the surface of the streambed sediment and another was fixed to the same elevation within the stream and the hydraulic head difference was determined by subtracting the water level height within the piezometer and the height of the stream surface the hydraulic gradient was determined by dividing the head difference by the distance from the riverbed surface to the middle of the screen interval positive values indicated an upward gradient suggesting streambed porewater could discharge to the surface water to determine vertical hydraulic conductivity and seepage flux slug tests were performed in each piezometer or miniature well by rapidly adding 250 ml of creek water and monitoring transient pressure changes in the well above the screen using the pressure transducer the resulting data i e hydraulic head change over time was analyzed following bouwer and rice 1976 1 k h r c 2 l n r e r w 2 l 1 t l n h 0 h t where kh is horizontal hydraulic conductivity l t rc is the inside radius l of the piezometer pipe re is effective radius l of the piezometer over which the hydraulic head or h l is dissipated rw is the horizontal distance l from the piezometer pipe center to the streambed sediment l is height l of screen zone of the piezometer h0 is the vertical distance l between the water level in piezometer and static water level in aquifer at time t0 and ht is the vertical distance l between water level in piezometer and the static water level in streambed sediment porewater at time t this equation has been commonly applied for this type of hydraulic property estimation ghysels et al 2018 maurya et al 2018 petersen et al 2020 ronde et al 2017 zhang et al 2019 and the recommended guidelines were followed to avoid errors batu 1998 kv was estimated with the relationship kh 10 kv commonly used for fluvial and alluvial sediments baxter et al 2003 butler and healey 1998 chen 2004 domenico and schwartz 1997 ghysels et al 2018 landon et al 2001 yeh et al 2015 this vertical anisotropy was not verified due to limits of the streambed sediment thickness seepage flux was calculated as the product of kv with the hydraulic gradient 2 3 hg sampling analysis and flux estimates water samples were collected from the surface water and the piezometers filtered with 0 2 μm polyethersulfone pes filters preserved with concentrated hydrochloric acid 0 5 v v trace metal grade and analyzed for total aqueous hg concentration following established methods epa 2002 dissolved hg flux was estimated as the product of hg aqueous concentrations collected from pore water within the piezometers and seepage flux this approach is commonly used to assess solute mass discharge into streams during baseflow conditions carroll et al 2003 ronde et al 2017 2 4 estimation of left censored attributes two methods were used to estimate the left censored attributes the substitute method was applied by imputing half the detection limit of the attribute as the left censored value calver 2001 stated that the lowest kv value for bedrock lining a river channel was 1x10 8 m sec which was consistent with expected values for limestone domenico and schwartz 1997 thus a value of 1x10 8 m sec was selected as the left censored value for limestone bedrock where piezometers could not be installed and where kv values were below the measurement lower limit we assumed that the left censored value for the differential head was 0 0127 m which was half the resolution value or lower limit for the ct2x smart sensor pressure transducer 0 0034 of the full scale or burst pressure 1000 psi approx 2000 ft or 60 m the left censored value for seepage flux was selected to be 1 27x10 10 m s i e determined as product of left censored hydraulic conductivity and gradient values for hg concentration we assigned the left censored value of half the method detection limit i e 1 62 ng l so for hg flux the left censored value was determined to be 810 ng m3 multiplied by 1 27x10 10 m s 1 03x10 7 ng m2 s 1 the second method used to estimate the left censored values was the saem algorithm which is based on estimating the parameters of a spatial regression model the saem approach was used to produced conditional simulations of left censored observations and then obtain a predictor for data at unsampled sites by taking the weighted mean of kriging predictors using importance sampling based on the location of the left censored data lachos et al 2017 ordoñez cuastumal 2017 the algorithm is implemented in the package censspatial available in the r software barbosa 2016 2 5 sampling design the study reach had several areas of the streambed with limestone outcrop without unconsolidated sediments and other sections with relatively thick unconsolidated sediments rucker et al 2021 bedrock outcrops were more pronounced on the thalwag and northern side of the efpc preventing piezometer installation in those locations piezometer installation and measurement locations were not predetermined as either random or using a gridded sampling design limitations in streambed sediment thickness required that piezometer installation location decisions were made in the field based on maximizing spatial coverage while balancing installation feasibility the locations used for installation of piezometers were selected in real time where the thickness of streambed sediments was larger than approximately 0 15 m which was an operationally defined minimum thickness required for piezometer installation left censored data locations were generally selected based on visual observations of limestone bedrock lining the streambed and by measurement of sediment thickness by augering a left censored location was added at each location where bedrock was visible and augering was not possible flood induced changes to sediment distribution in the stream channel between piezometer installation and data collection dates in 2017 and 2018 affected the spatial location of piezometer installation and measurement in consecutive years fig 1 however the number of piezometers was relatively consistent and the area of investigation was consistent between these two years of site characterization the piezometer locations were georeferenced using a trimble vx spatial station robotic a rtk gps and a measuring tape to quantify the effect of data sampling location on the interpolation prediction error and to evaluate if the spatial distribution of the data was clustered random or dispersed the average nearest neighbor index was estimated and used to compare the sampling distributions collected in 2017 and 2018 before and after adding the left censored values the average nearest neighbor tool in arcgis version 10 5 1 was used to define the type of spatial distribution of the sampling points before and after adding the left censored values the average nearest neighbor index is expressed as the ratio of the observed mean distance to the expected mean distance eqs 2 6 2 ann d o d e 3 d o i 1 n d i n 4 d e 0 5 n a where do is observed mean distance between each feature and its nearest neighbor de is the expected mean distance between the features given in a random pattern di is the distance between feature i and its nearest neighboring feature n is the total number of features a is the area of a minimum rectangle around all features the expected distance is the average distance between neighbors in a hypothetical random distribution if the ann index is less than 1 the pattern exhibits clustering and if the index is greater than 1 the trend is toward dispersion the z score and p value are used to determine the significance of the spatial distribution where z score represents the standard deviation and p value represents a numerical approximation of the area under the curve for a known distribution limited by the test statistic 5 z d o d e se 6 se 0 26136 n 2 a the z scores and p values returned by the pattern analysis determines whether or not the null hypothesis of a complete spatial randomness can be rejected 2 6 spatial mapping of streambed attributes in geostatistical interpolation data exploration is the first step completed to ensure that spatial data dependency i e values closer together usually should be more alike than values further apart and stationarity i e similar statistical properties and data variability everywhere are met arcgis geostatistical analyst tool was used which provides a collection of models and tools for spatial data exploration identification of data anomalies optimal prediction evaluation of prediction uncertainty and surface creation continuous semivariograms were fit to the observed data using the geostatistical analyst using the default optimized model the semivariogram that provided the best fit i e minimized root mean square deviation to the data and gave the lowest prediction errors was the stable model wackernagel 2013 7 γ h c 1 e x p n a r a where γ h l2 t2 is the semi variance at distance h l c is the sill l2 t2 r is a distance parameter and a is an empirical parameter should be greater than zero and less than or equal to two for the stable model most geostatistical models assume that the data are correlated and stationary yeh et al 2015 we compared and evaluated the effect of adding left censored data on the stationarity and the correlation of the data set semivariograms have been used to address this question and to quantify those two characteristics analyzing the semivariograms for intrinsic stationarity was considered by autocorrelation using the ratio between nugget and sill α as suggested by cambardella et al 1994 if the nugget to sill ratio was less than 0 25 the variable has strong spatial dependence between 0 25 and 0 75 the variable has moderate spatial dependence and greater than 0 75 the variable shows only weak spatial dependence directional anisotropy has also been quantified with the original data set and after adding the left censored values here we considered 2d horizontal directional anisotropy anisotropy relative to the vertical was not considered because the horizontally distributed data would not support 3d evaluations and the limited thickness of the unconsolidated sediments overlying the bedrock in the study site did not warrant 3d evaluation testing for the directional autocorrelation and anisotropy of the data was completed by enabling the anisotropy function in the geostatistical wizard within arcgis 10 5 1 by enabling the anisotropy function 2d major and minor semi axes were calculated for each attribute allowing for calculation of the major axis to minor axis ratio and the directional orientation of those axes 3 results and discussion 3 1 data distribution hydraulic gradient and vertical hydraulic conductivity were measured using streambed piezometers over a spatial domain of approximately 3666 m2 in efpc fig 1 a total number of 37 piezometer locations in 2017 and 40 piezometer locations in 2018 were used to characterize streambed attributes this equates to 37 points over a domain of 3666 m2 or 0 0101 points m2 in 2017 and 40 points over a domain of 3666 m2 or 0 011 points m2 in 2018 without addition of left censored data these data densities were significantly lower than those suggested for use in previous studies genereux et al 2008 compared the spatial variability in kv at 46 locations in a larger 262 5 m reach and at 54 and 62 locations in two smaller 62 5 m reaches in west bear creek in north carolina where they also found no significant differences in the estimated attributes between sampling density of 0 025 points m2 and 0 13 points m2 kennedy et al 2008 indicated that a sampling density of about 0 05 points m2 was sufficient to reduce the error in kriged estimates of kv to 10 or less reyes 2009 studied streambed hydraulic attributes and nitrate flux in the neuse river with a sampling density that varied from 0 02 to 0 052 points m2 with a model error of 12 for the interpolated kv and this sampling density was assumed to be sufficient sebok et al 2015 found no significant differences in kh kv and vertical hydraulic gradient between straight and meander reaches in holtum stream with sampling densities of 2 points m2 10 points in 5 m2 and 1 point m2 30 points in 30 m2 song et al 2016 found a negative correlation between sampling density and the modeling error for interpolated contour maps of streambed kv and head gradient in the beiluo river china modeling errors decreased from 8 to 1 at data densities of 0 156 points m2 and 0 273 points m2 respectively as noted above data densities for this study collected in both 2017 and 2018 without addition of left censored data were lower than recommended data densities in all of these prior publications forty three left censored values were added to the 2017 data for a final data set of 80 values of which 54 were imputed values based on methods described previously twenty seven values were added to the 2018 data set for a final data set of 67 values of which 40 were imputed consequently the data density increased from 0 0101 points m2 and 0 011 points m2 to 0 0218 points m2 and 0 0183 points m2 in 2017 and 2018 respectively the data density including the imputed values were within the lower yet acceptable range suggested by reyes 2009 and genereux et al 2008 these results confirm that imputing left censored data where bedrock outcrops along the streambed can be used to increase streambed attribute property data to reach minimum data density requirements determined by previous researchers 3 2 average nearest neighbor ratio analysis the average nearest neighbor ratio was used to compare data location clustering with and without addition of the left censored values to determine the effect of sampling location on the average prediction standard error of the interpolated results in 2017 and 2018 table 1 and fig s2 for the 2017 dataset sample locations had average nearest neighbor ratios of 1 07 and 0 9 with and without left censored data respectively the nearest neighbor ratios for 2018 data were 0 59 and 0 61 with and without left censored data respectively these results suggested that data distribution was random in 2017 and was clustered in 2018 before and after adding the left censored data the z score and p score measures the statistical significance and these were used to determine whether or not to reject the null hypothesis which states that the features are randomly distributed the alternate hypothesis is that the features are not randomly distributed and may be impacted by clustering or dispersion the z score and p score for the 2017 data with left censored data 1 12 and 0 26 and without left censored data 1 13 and 0 26 suggested that the pattern was not significantly different from a random spatial distribution table 1 alternatively the z score and p score for the 2018 data with left censored data 6 48 and 0 00 and without left censored data 4 78 and 0 00 suggested that for these datasets the null hypothesis was rejected in favor of the alternate hypothesis at the efpc within the study reach the intermittent outcropping of bedrock at the streambed constrained not only the data density but also the data distribution which led to less random and increased clustering of the sampling designs we expect this to be a common issue for many streambed characterization investigations 3 3 descriptive statistics a t test to evaluate the means of the attributes was conducted with a 0 05 significance level to evaluate if the data obtained in 2017 and 2018 were independent data sets or not the null hypothesis was that the means from 2017 measurements were similar to those from 2018 measurement for all attributes the results rejected the null hypothesis and this result indicated that the means were different for all attributes between the two years the variation in the mean values for the attributes can be explained with scouring and deposition of sediments after the two major rain events occurred in summer 2018 which carried maximum discharges of 8 19 m3 sec and 4 69 m3 sec three important requirements for ordinary kriging are a constant trend function a constant variogram across the entire area of interest and the target variable follows approximately a normal distribution most normality tests require a specific sample size or data density including the widely used the shapiro wilk test and kolmogorov smirnov test with skewness and kurtosis bowman and foster 1993 ahad et al 2011 suggested that a sample size of 40 to 77 counts was sufficient to test the data normality by different statistical methods in this study the number of measurements was 37 points in 2017 and 40 points in 2018 close to the lower cutoff value for assessing normality we used the skewness kurtosis and the difference between the mean and median to evaluate the normality of the measured data perfectly normally distributed data has a kurtosis value of 3 westfall 2014 a smaller difference between the mean and median also indicates that the distribution is closer to a normal distribution negative values for skew indicate a left skewed distribution and positive value indicate a right skewed distribution in general a skewness less than 1 or greater than 1 indicates that the distribution is highly skewed between 1 and 0 5 or between 0 5 and 1 indicates that the distribution is moderately skewed and between 0 5 and 0 5 indicates that the distribution is approximately symmetric çalıyurt 2019 summary statistics for kv seepage flux and hg flux measured in summer of 2017 and 2018 are summarized in table 2 skewness and kurtosis did not differ greatly for kv and the natural log of kv ln kv in 2017 with a skewness less than 0 5 and kurtosis slightly less than 3 the skewness values of kv and ln kv suggested that the distributions were approximately symmetrical for ln kv the mean of the distribution was closer to the median and therefore the ln of kv was used to estimate the spatial interpolation for kv measured in 2018 the skewness decreased with the ln transformation from 0 91 to 0 59 also suggesting the skewness shifted from right to left also mean kv was closer to the median compared to the kv without transformation and therefore kv values without ln transformation were used to estimate the spatial distribution the ln transformation for the seepage flux estimated in 2017 had the undesired effect of increasing skewness and kurtosis therefore the values without ln transformation were used to estimate the spatial distribution however for all the other attributes measured in the two years the ln transformation provided a closer match to the normal distribution thus the ln transformation was used for kv and hg flux estimated in 2017 and all three attributes estimated in 2018 the untransformed values of seepage flux estimated in 2017 were used for the spatial interpolation for that attribute although the trend of the distribution was not consistent for all attributes the distribution closer to normality was selected to fulfill a requirement for ordinary kriging by using an approximately normal distribution to estimate the spatial distribution of the attributes 3 4 spatial autocorrelation and semivariograms analysis ordinary kriging was used to interpolate streambed attributes as the data displayed no trend and the semivariograms exhibited local stationarity before and after adding the left censored values data were modeled comparing two contrasting assumptions in the first assumption the data were assumed to be isotropic and were assumed to be anisotropic in the second assumption this comparison for horizontal isotopy versus anisotropy was made for the data for each of the two years both with and without imputed left censored data semivariograms were created for each of the four interpolation scenarios isotropic without left censored data isotropic with left censored data anisotropic without left censored data and anisotropic with left censored data fig s3 to s6 the semivariogram parameters including correlation length i e range sill and nugget for each of the four interpolation methods and the three attributes are summarized in table 3 the range distance where data have statistical dependence was notably increased in most anisotropic semivariograms compared to the similar isotropic semivariogram indicating that autocorrelation varied in different directions however the seepage flux range measured in 2018 remained relatively low for isotropic anisotropic and before and after adding the left censored data compared to the 265 m length of the study reach since seepage flux is a function of the hydraulic gradient and kv the correlation length of seepage flux does not necessarily match that for kv and was affected by the correlation length of hydraulic gradient additionally imputing left censored data resulted in significant increases in range length for both isotropic and anisotropic results for data collected in both 2017 and 2018 the nugget effect generally occurs when measurements are different at very short distances ideally the closer the sampling points the less disparate the measurements should be with this difference approaching zero at the zero distance between samples the nugget effect was negligible for kv measured in 2018 for both the isotropic and anisotropic models before adding left censored data table 3 overall the nugget effect for all attributes was lower than the sill generally a large nugget relative to the sill is problematic and could indicate too much noise without significant spatial correlation matzke et al 2014 the spatial data correlation was quantified using the nugget to sill ratio α as suggested by cambardella et al 1994 most attributes had a moderate spatial dependency 25 α 75 except for 2017 and 2018 hg flux and 2018 kv which before adding the left censored data had a low spatial dependency α 25 table 3 upon addition of the left censored data relative to results without left censored data all of the attributes had increases in spatial dependency this result may be in part attributed to the above noted increase in data density to the minimum requirements suggested by previous researchers these results also confirm that imputed left censored values can support and enhance spatial structure and spatial correlation as opposed to inhibiting spatial connectivity this enhancement of spatial dependence seems to be an effective method for improving interpolation when geostatistical methods are used 2d directional autocorrelation indicated that data were correlated in different directions which suggested that the variability of the streambed attributes varied with direction i e anisotropy the length of the major axis to length of the minor axis ratio λ ranged between 1 53 and 3 00 with the lowest ratios for the attributes before adding the left censored data i e 1 53 and 1 6 for hg flux measured in 2017 and seepage flux measured in 2018 respectively table 4 these two attributes also had shorter range lengths which indicates they were the least spatially correlated among all attributes with least anisotropy adding the left censored values increased λ for these two attributes to 2 99 and 2 65 respectively and these changes resulted in notable decreases in the range and variability of the λ values upon addition of the left censored values table 4 the direction of anisotropy or autocorrelation θ as azimuth with north as 0 east as 90 south as 180 and west as 270 was relatively consistent for most attributes having major direction aligned with the orientation of the stream channel just south of east and north of west other researchers have also noted that the largest kv correlation can be aligned with the direction of the stream channel abimbola et al 2020 ghysels et al 2018 upon addition of left censored data 2017 kv seepage flux and hg flux changed major direction from just south of east to just north of east which was attributed to the locations of the imputed left censored data as indicated by the average nearest neighbor index analysis clustering of the measured attributes was reduced for both years by the addition of the left censored data which explains the shift in the anisotropy direction the above noted enhancements of spatial dependence in part were also attributed to these reductions in clustering upon imputing with left censored data these additions of left censored data both increase data density and decrease data clustering and both result in improvements in interpolation when geostatistical methods are used the attributes were anisotropic before and after adding the left censored values however the anisotropy ratio was relatively low compared to some strongly anisotropic porous media kessler et al 2013 tonina et al 2016 at the efpc within the study reach the stream exhibited only a minor amount of meandering and also relatively low streambed sediment attribute interpolation anisotropy since prior research has noted increased heterogeneity and anisotropy within meander bends relative to straight channels borna et al 2018 ghysels et al 2018 sebok et al 2015 song et al 2016 we posit that streambed sediment attribute interpolation anisotropy may vary with stream geomorphology and some streams may have more significant streambed attribute anisotropy than was shown here for efpc 3 5 evaluation of spatial interpolation methods the ordinary kriging average prediction standard error which represents the standard deviation of the prediction for any individual point was determined to evaluate and compare all interpolation methods in general the kriged values without the left censored data and assuming isotropy had the highest spatially averaged i e over study reach prediction standard error values among all approaches and anisotropic kriged values upon addition of left censored data had lower average prediction standard errors fig 2 considering anisotropy and including the imputed left censored data reduced the average prediction standard error by between 83 1 hg flux measured in 2017 to 29 8 kv measured in 2017 the consistently high average prediction standard error values for the isotropic geostatistical model without left censored data indicated that this interpolation method was not very effective and the error reduction suggests that the effectiveness of the geostatistical interpolation was improved with addition of left censored data and also with consideration of anisotropy within the interpolation the reduction in error was larger with addition of left censored data relative to the difference between anisotropic and isotropic kriging which is consistent with the relatively low amount of horizontal directional variability in the stream however both of these resulted in error reductions and we posit that anisotropy consideration in streambed sediment attribute kriging have increased importance in other stream systems including those with increased channel curvature or tortuosity borna et al 2018 sebok et al 2015 song et al 2016 the significant reductions in error due to imputing left censored data was also consistent with the increase in data density to the range recommended by prior publications fig 2 also shows the left censored values imputed using the substitute method and saem algorithm had very similar results and similar average prediction standard errors for all attributes for example using the anisotropic model and after adding the left censored values the relative prediction standard error for ln hg flux measured in 2017 using the substitute method was 40 8 and was 40 5 using the saem algorithm and for ln hg flux measured in 2018 was 64 3 using the substitute method and 65 2 using the saem algorithm ln kv measured in 2018 had the highest difference between the relative prediction standard errors estimated using the substitute method and saem algorithm as 2 74 which was considered only a minor deviation these results confirm that these two differing left censored value estimation methods provided comparable and consistent results this is an interesting finding when considering that saem takes spatial variability into consideration we suggest that this provides additional justification for the application of these results as imputed values for geostatistical interpolation 3 6 spatial distribution analysis measurement locations varied significantly in 2017 and 2018 controlled by the distribution of streambed sediment additional sediment existed in the upstream and downstream in the two years however only a very thin veneer of sediment existed around mid stream in 2018 which limited installation of the piezometers and characterization of streambed attributes fig 1 the locations of maximum and minimum attribute values also varied significantly between the two years the measured kv before adding left censored values varied over one order of magnitude for both years varying between 4 30x10 7 m s and 4 37x10 6 m s in 2017 and between 2 47x10 7 m s and 5 50x10 6 m s in 2018 similar to kv the measured seepage flux before adding left censored values ranged over one order of magnitude the minimum and maximum measured values varied between 1 29x10 7 m s and 7 48x10 6 m s in 2017 and between 2 52x10 7 m s and 7 13x10 6 m s in 2018 the range for hg flux spanned over two orders of magnitude with a minimum value of 3 04x10 3 ng m2 s and a maximum value of 3 80x10 1 ng m2 s in 2017 and a minimum value of 3 00x10 3 ng m2 s and a maximum value of 1 77x10 1 ng m2 s in 2018 contour plots of geostatistical interpolation results are presented for kv seepage flux and hg flux in figs 3 4 and 5 respectively the t test as noted above revealed that the mean of all attributes was different between the two years and the spatial distributions shown in these contour plots differed significantly between the two years the spatial distribution of the streambed attributes showed distinct spatial and temporal differences between the 2017 and 2018 results including the locations of maximum and minimum kriged attributes figs 3 5 for example before adding the left censored data higher kv values between 2 99x10 6 m s and 4 55x10 6 m s were mostly located at the east upstream and west downstream of the study reach and lower kv values between 1 83x10 7 m s and 1 37x10 6 m s were located in between mid reach those higher kv locations fig 3a the upstream section of the reach had lower kv values in 2018 between 1 83x10 7 m s and 1 37x10 6 m s compared to a range between 2 29x10 6 m s and 4 55x10 6 m s in 2017 fig 3b we attribute these transient changes in streambed sediment attributes to erosion deposition and sediment transport and redistribution processes which can have significant implications for hyporheic zone characterization especially in streams that are prone to flash flooding such as the efpc brooks et al 2017 dickson et al 2019 levy et al 2011 this type of transient streambed kv changes due to sediment erosion transport and redistribution has been documented recently by several researchers genereux et al 2008 kennedy et al 2009b korus et al 2020 levy et al 2011 shrivastava et al 2020 wu et al 2015 the kriging distributions also showed differences between the attributes before and after adding the left censored data figs 3 5 adding left censored data notably changed the kv distribution mostly decreasing the values along the majority of the reach fig 3c relative to the distribution without left censored data collected in 2017 fig 3a a larger portion of mid stream during 2017 had a lower kv values between 1 0x10 8 m s and 1 37x10 6 m s compared to a range 2 29x10 6 m s to 2 98x10 6 m s before adding the left censored data upstream and downstream also had mostly lower kv values during 2017 between 1 38x10 6 m s and 1 58x10 6 m s after adding the left censored data compared to a range 3x10 6 m s to 4 55x10 6 m s before adding the left censored data for the 2018 results kv values before adding the left censored data were mostly larger within the mid reach section of the study area varying between 2 29x10 6 m s and 2 98x10 6 m s and the lower values were located at the east upstream and west downstream portions of the study reach fig 3b the larger kv region within the mid reach was decreased in extent upon addition of left censored data fig 3d in addition to lowering kv in some areas the addition of left censored data increased the refinement of the spatial variability the spatial distribution trend of seepage flux fig 4 was similar to that of kv fig 3 in both years upstream and downstream had the highest seepage flux values in 2017 fig 4a between 2 60x10 6 m s and 4 47x10 6 m s and mid stream had lower values between 1 53x10 6 m s and 2 06x10 6 m s for the 2018 data fig 4b the upstream part of the reach had lower seepage flux values as consistent with the above noted zone of lower kv and seepage flux ranged between 4 48x10 7 m s and 1 14x10 6 m s the range of seepage flux values notably decreased after adding the left censored values with greater decreases noted in mid stream in 2017 fig 4c and upstream in 2018 fig 4d where a denser cluster of data points existed after adding the left censored values similar to the kv results the addition of left censored values reduced the seepage flux magnitude at locations where they were added and also seemed to have increased the refinement of the spatial variability compared to the spatial distributions without the left censored data the spatial distribution of hg flux was also notably differed between 2017 and 2018 fig 5 most of the reach in 2018 had hg flux values ranged between 2 35x10 1 ng m2 s and 9 93x10 1 ng m2 s and most of the reach in 2017 had hg flux values about an order of magnitude lower than 2018 for the results without left censored data the upstream and downstream portions of the reach had the highest hg flux values in 2017 fig 5a whereas the upstream and downstream zones did not have the higher hg flux values in 2018 fig 5b the elevated hg flux in the upstream and downstream ends of the reach for the 2017 dataset was consist with the elevated kv and seepage flux in those locations noted above several locations of hg flux were decreased after adding the left censored values especially in mid stream part of the reach for 2017 fig 5c and in the upstream part of the reach in 2018 fig 5d which was consistent with the above noted trends for seepage flux the addition of left censored values reduced the hg flux magnitude at locations where they were added and addition of left censored data seems to have increased the refinement of the spatial distribution of the lower range of hg flux within the reach thus imputing of left censored values within geostatistical interpolation may be more sensitive to identifying and characterizing the spatial distributions of the lower magnitudes for attributes which might be more suitable for mapping lower or minimum value locations than mapping maximum value locations as noted above the variability in the spatial structure over time can be attributed to variability in seasonal changes in sediment erosion transport and deposition within the streambed most temporal variabilities in streambed attributes such as kv in rivers and streams are typically attributed to variability in streambed lithology and texture as a result of erosion and depositional processes genereux et al 2008 kennedy et al 2009b korus et al 2020 levy et al 2011 shrivastava et al 2020 wu et al 2015 we speculate that anomalously high precipitation and efpc flow rate events that occurred in january and february of 2018 have altered the spatial distribution of streambed sediment causing the variability in kv distribution as indicated in the similarities of the contour map spatial distributions the hg flux and seepage flux distributions were highly dependent on the kv distributions and all three streambed attribute spatial distributions were modified between summer of 2017 and summer of 2018 which we attribute to erosion and deposition of the unconsolidated sediments relative prediction standard error contour maps percentage unit were created by dividing the prediction standard error by the mean using ordinary kriging for kv seepage flux and hg flux in figs 6 7 and 8 respectively the spatial structure of the attributes was noticeably different from the spatial structure of the standard error the results indicate that standard error was generally higher in areas where measurements were sparse and where measurements differed substantially from their neighbors the relative prediction standard error was notably higher in areas with lower sampling density figs 6 8 for the 2017 data kv had a relative prediction standard error that ranged up to 40 before adding the left censored values fig 6a compared to up to 30 after adding the left censored values fig 6c for the 2018 data with and without imputed left censored data fig 6b and fig 6d the kv distributions generally had a larger relative prediction standard error range compared to the results for the 2017 data fig 6a and fig 6c respectively for the 2018 data and before adding the left censored values the relative prediction standard error of kv ranged between 61 and 80 compared to a range between approximately zero and 60 after adding the left censored values these relative prediction standard error reductions upon addition of left censored data are also consistent with results presented in fig 2 and these reductions in error illustrate the potential for geostatistical interpolation improvements upon addition of left censored data especially when they allow data density and distribution to increase to ranges that are recommended as minimum requirements by the above noted previous publications similar trends to those described above for kv were also observed in the relative prediction standard error for seepage flux before and after adding the left censored values for each of the two years fig 7 the addition of the left censored values have resulted in a notable decrease in the relative prediction standard error also consistent with fig 2 and the spatial distribution of the error was comparable between kv and seepage flux which again illustrates the impact of kv on the seepage flux results inspection of fig 8 indicates that the hg flux standard error distribution for 2017 and 2018 results without addition of left censored data was larger than that of the kv and the seepage flux especially within the portions of the reach without point measurements upon addition of left censored data fig 8c and 8d the hg flux standard errors were reduced significantly across the entire study reach for both years figs 6 8 along with fig 2 confirm that the standard error was generally lower for kv and seepage flux in 2017 compared to 2018 whereas error magnitudes were more similar between 2017 and 2018 for the hg flux results the standard error reductions occurred consistently and were significant for each of the three streambed sediment attributes and for each of the years investigated which can be attributed to both the increased number and density of data points and their spatial distribution with less clustering also the 2018 data locations were clustered which also contributes to the large error in between data points compared to 2017 the data clustering may explain the significant errors especially around the banks and mid reach in 2018 where sampling was limited ideally a random or dispersed spatial distribution would ensure that the interpolation would provide a more continuous function describing the data which would lower the interpolation errors addition of left censored data has been shown herein to increase the data density and areal coverage of the spatial distribution into locations where piezometer data collection was limited by the consolidated limestone bedrock outcrop sections of the streambed and these data density and data clustering limitations can be common for many streams and rivers especially within lower order stream systems 4 summary and conclusions this investigation assessed the effects of considering anisotropy and of increasing data density with the addition of left censored values on geostatistically interpolated 2d horizontal distributions of kv seepage flux and hg flux as three hydraulic and solute transport attributes of streambed sediments streambed hydraulic and solute transport attribute measurement and characterization are critical for evaluation of hyporheic zone exchange which is now recognized for its control over various hydrobiogeochemical processes impacts in terms of relative interpolation prediction standard errors were examined using in stream piezometer point measurements collected over two years time within a 265 m study reach area of the efpc where intermittent locations of exposed bedrock lining a streambed inhibited data density and spatial distribution of measured streambed attributes the impact of anisotropy in the data and its consideration in the geospatial interpolation method was examined for the three measured streambed attributes measured within two separate years before and after adding the left censored values after confirming the data was stationary in both cases these three streambed attributes were confirmed to have anisotropic distributions generally aligned with the stream channel direction consideration of this anisotropy within the interpolation approach reduced average prediction standard error even with minimal meander curvature within the study area reach and the isotropic interpolation without addition of left censored data consistently had larger errors for all attributes which confirms that anisotropy should be used within the interpolation of these anisotropic data addition of the left censored data increased the data density to reach the minimum recommended by previous studies the clustering was reduced through addition of the left censored data upon addition of left censored data the spatial dependence for some attributes was increased and there was also increased the consistency of the spatial dependence addition of left censored data seems to have also increased the refinement of the spatial distribution of the lower range for some streambed attributes the anisotropic ordinary kriging generally had reduced average prediction standard errors after adding the left censored values for the efpc reach considered herein addition of the left censored values resulted in a larger error reduction than the consideration of anisotropy relative to isotropic kriging which confirms the benefit of data addition to increase data density within data limited environments these techniques of increasing the data density by adding left censored values may seem straightforward but we confirmed that the case study presented was not impacted by limitations including the potential to alter the stationarity and correlation of the original dataset which may violate the underlying assumptions for using geostatistical methods to interpolate attribute values adding imputed data values can improve the overall analysis but practitioners are cautioned to verify the data still conform to the underlying assumptions of the analysis and limit the amount of imputed data relative to measured data e g 30 there may be limitations for geostatistical applications to streambed sediments and characterization of the statistical distributions of riverbed structures is important for exchange fluxes for example a recent paper by tang et al 2015 compared ensemble kalman filter for estimation of riverbed hydraulic conductivities they included a comparison of multigaussian and non multigaussian properties and their results concluded that differences between the simulations were small and non multigaussian riverbed properties seem to be of less importance for subsurface flow than non multigaussian aquifer properties there is still a need to examine these types of limitations in the context of solute transport in streambed systems credit authorship contribution statement ruba a m mohamed conceptualization data curation data curation formal analysis investigation methodology writing original draft scott c brooks conceptualization methodology investigation resources data curation writing review editing supervision project administration funding acquisition chia hsing tsai methodology data curation tanzila ahmed methodology data curation dale f rucker conceptualization methodology investigation resources data curation writing review editing project administration funding acquisition april l ulery conceptualization methodology investigation resources data curation writing review editing project administration funding acquisition eric m pierce conceptualization methodology supervision project administration funding acquisition kenneth c carroll conceptualization methodology investigation resources funding acquisition investigation project administration supervision validation visualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the department of energy doe minority serving institution partnership program msipp managed by the savannah river national laboratory additional support was provided by the usda national institute of food and agriculture hatch project 1023257 and the plant environmental science department at nmsu which is greatly appreciated a portion of this research was sponsored by the office of biological and environmental research within the office of science of the u s doe as part of the critical interfaces science focus area project at the oak ridge national laboratory ornl the doe will provide public access to these results of federally sponsored research in accordance with the doe public access plan http energy gov downloads doe public access plan ornl is managed by ut battelle llc under contract no de ac05 00or22725 with doe we appreciate the assistance of kenneth lowe michael jones nikki jones justin milavec autumn pearson chris kubicki and amanda lara we thank the anonymous reviewers for their comments which improved the clarity of this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126474 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4480,spatial geostatistical interpolation of point measurements of streambed attributes in the hyporheic zone may be constrained by the streambed anisotropy and data density and spatial distribution may significantly impact the results spatial clustering and low spatial data density can be caused by bedrock outcropping at the streambed limiting installation of in stream piezometers this study examines parameter error variability of the geostatistical interpolation using anisotropic interpolation methods and increasing the data density by adding left censored values i e data below measurement limit to locations where measurements were limited by exposed bedrock lining the streambed the reduction in relative standard error of the interpolation was determined for the spatial distributions of streambed attributes including hydraulic conductivity seepage flux and mercury solute flux measured in two different years along a study reach in east fork poplar creek tennessee usa two methods to impute the left censored values were compared including the conventional half the detection limit substitution method and the stochastic approximation of expectation maximization saem algorithm which both had comparable results imputing left censored data increased the data density to recommended ranges reduced data clustering increased the spatial dependence for some attributes and reduced the standard error for each of the three attributes for the reach considered herein addition of the left censored values resulted in a larger error reduction than the consideration of anisotropy within the interpolation which confirms the benefit of data addition to increase data density within data limited river corridors keywords hyporheic geostatistics kriging piezometer left censored data 1 introduction selection of a suitable mapping method for spatial interpolation under data limited conditions can be challenging krivoruchko 2011 especially for constrained environments such as streams and rivers naganna et al 2017 the spatial distribution of hydrogeomorphic characteristics of streams and rivers tends to be anisotropic as fluid flow and sediment transport are primarily unidirectional and sediment erosion and deposition generally leads to heterogeneous deposits brunner et al 2017 accordingly the spatial distribution of measurements and the values of measured streambed attributes have an inherent anisotropy chen 2000 2004 ghysels et al 2018 landon et al 2001 lu et al 2012 spatial autocorrelation considered in geostatistical interpolation is a spatial dependence on a data distribution and anisotropy yeh et al 2015 several of the prior papers containing streambed attribute mapping used methods other than geostatistics for interpolation and most commonly used a multiquadratic radial basis function method genereux et al 2008 gilmore et al 2016a 2016b kennedy et al 2009a 2009b 2008 2010 which does not necessarily consider spatial statistics as geostatistical methods do other published papers containing streambed attribute mapping have applied isotropic geostatistical mapping of piezometer streambed sediment data abimbola et al 2020 ghysels et al 2018 korus et al 2020 naganna et al 2017 song et al 2016 wu et al 2016 2015 there is a lack of research comparing geostatistical and non geostatistical interpolation methods for streambed sediment attributes and there is a lack of investigation into the need to consider anisotropy within streambed sediment attribute interpolation methods as illustrated in a recent review brunner et al 2017 there have been many geostatistical studies applied to river groundwater interactions that have been used to model heterogeneous sedimentary structures which include for example development of statistical and or multidimensional sequences of geological facies to represent subsurface material heterogeneities engdahl et al 2010 pryshlak et al 2015 constraining uncertainties in such heterogeneous model development can be challenging due to data limitations additional methods are needed to decrease errors and uncertainty in geostatistical interpolation and this is particularly true for data limited environments such as streambed hyporheic attribute mapping kennedy et al 2008 clustering and density of data could impact feasibility of geostatistical interpolation of measured properties within hyporheic zones of rivers and streams since the channel geometry and directional flow of water may produce spatial correlations that are not explained by euclidean distance peterson and hoef 2014 data density defines the number of measurement locations per unit area and data clustering characterizes how close or far measurement locations are away from other sampling locations those two data characteristics are critical to minimize the variance and optimize accuracy in the geostatistical interpolation results these characteristics are particularly important for geostatistical interpolation of the hydraulic interaction between groundwater and surface water in the hyporheic zone of rivers and streams since elongate stream channel morphology may constrain data spatial distributions bethune et al 2015 brunner et al 2017 freitas 2015 sebok et al 2015 weatherill 2014 interest in the effect of sampling density and spatial distribution on the accuracy of geostatistical interpolations of streambed attributes has increased recently with interest in hyporheic zone exchange characterization brunner et al 2017 naganna et al 2017 shrivastava et al 2020 kennedy et al 2008 found that a sampling density of about 0 05 points m2 was sufficient to reduce error in streambed sediment vertical hydraulic conductivity kv to 10 or less genereux et al 2008 also compared the spatial variability of kv and found no significant interpolation differences between 0 025 points m2 and 0 13 points m2 sampling densities nevertheless the effect of sampling design or the spatial distribution of measurement points on geostatistical interpolation of streambed attributes has not been thoroughly investigated sampling design and selection of sampling locations to measure streambed attributes has generally been based on random selection kennedy et al 2008 or equally spaced grids with measurement points located on the right center or left side of a stream genereux et al 2008 kennedy et al 2008 leahy 2007 reyes 2009 kennedy et al 2008 addressed the effect of sampling design on the accuracy of the spatial interpolation of streambed attributes by comparing likelihood of error in average streambed attributes using three sampling designs including random sampling and two structured designs that created subsets of equal numbers of points from left center and right side of the stream and found that sampling design had a negligible effect on uncertainty compared to the data density the most common methods to quantify streambed kv and other attributes requires auger drilling and piezometer installation in order to acquire measurements by the slug test falling head or constant head permeameter methods abimbola et al 2020 borna et al 2018 chen 2000 2004 cheng et al 2011 genereux et al 2008 ghysels et al 2018 gilmore et al 2016a 2016b kennedy et al 2009a 2009b 2008 2010 korus et al 2020 landon et al 2001 levy et al 2011 lu et al 2012 sebok et al 2015 song et al 2016 wu et al 2016 2015 and fewer studies use hydraulic manometers kelly and murdoch 2003 winter et al 1988 and grain size distribution methods chen 2000 landon et al 2001 however measurement of streambed attributes can be challenging depending on the geomorphology of the streambed the natural and artificial obstacles and inherent limitations in methods for example bedrock outcropping at the streambed without significant overlying unconsolidated streambed sediment limits in stream piezometer installation point measurements may be below lower limits of measurement and these factors can impose spatial clustering and decreased data density advances in methods for increasing data density to decrease errors and uncertainty are needed particularly for hyporheic attribute mapping when streambeds have intermittent bedrock outcropping data addition has been used to increase data density and it has a rich history in a number of fields including epidemiology and life expectancy astronomy occupational health chemistry and environmental science helsel 2010 left censored data are measurements that are not quantitative because responses are below method quantification limits they are typically considered semi quantitative estimated values assuming a statistical distribution estimation and addition of left censored data has been an active area of research for environmental data especially water quality for over half a century cohen 1950 1957 gleit 1985 helsel 2010 wen 1994 despite prior criticisms regarding accuracy and bias substitution has been one of the most commonly used left censored estimation method which typically uses half of the lower detection or measurement limit helsel 2010 zhang et al 2004 one half of the lower detection limit substitution is based on the simple arithmetic average of the lower detection limit and zero however there are a number of data estimation methods other than substitution including the maximum likelihood estimator mle kaplan meier km and regression order statistics ros appropriateness and effectiveness of these methods has been discussed with varied results a brief synopsis of cited works is provided below and for full discussion see helsel 2010 and zhang et al 2004 generally researchers have found most of these methods work well within certain conditions for example when the percent left censored to total data number is low e g less than 30 antweiler and taylor 2008 gibbons 1996 substitution with expected value works well gleit 1985 substitution with one half the detection limit out performs other methods and mle is not effective for small data sets clarke 1998 zhang et al 2004 mle is also effective with known statistical distributions whereas km and ros are more effective for unknown distributions helsel 2010 lastly substitution is not effective when the detection limit is variable helsel 2010 yun and qian 2015 and mle is not effective when skewness of the observed data is significant shoari et al 2015 very few studies focused on groundwater chemistry have included estimated left censored data for attribute mapping and spatial statistical analyses huang et al 2019 kim et al 2011 mcgrory et al 2017 munoz et al 2017 the estimation of left censored data for these studies varied from using half the detection limit mcgrory et al 2017 ros munoz et al 2017 and substituting zero for non detected locations huang et al 2019 kim et al 2011 additionally a few studies created and inserted absence non occurrence samples in groundwater potential mapping using machine learning models corsini et al 2009 naghibi and pourghasemi 2015 rahmati et al 2019 others used the substitution method to increase data density and improve the accuracy of landslide susceptibility models gorsevski et al 2006 hong et al 2018 nefeslioglu et al 2008 we are unaware of any left censored method that takes into account spatial structure aside from the stochastic approximation of expectation maximization saem proposed by delyon et al 1999 saem has been used to estimate left censored values for different research fields including medical barbosa 2016 samson et al 2007 snoeck et al 2010 and environmental lachos et al 2017 ordoñez cuastumal 2017 to our knowledge adding left censored values to increase streambed sediment characterization data density for evaluation of hyporheic zone exchange has not been previously investigated the main objective of this study was to assess the effect of increasing data density with the addition of left censored values on spatially interpolated 2d horizontal distribution of hydraulic and solute transport attributes of streambed sediments the left censored values were added to the locations where bedrock outcropped at the streambed and piezometer installation was not possible and these results with addition of left censored values were compared to interpolation results without addition of left censored values the effect of imputing the left censored values using half the detection limit for i e substitute method versus using saem algorithm was evaluated and compared a second objective was to assess the impact of considering 2d horizontal anisotropy within the kriging geostatistical method compared to the typical isotropic kriging method on the interpolated results assessment of these different geostatistical interpolation approaches was based on minimization of the attribute average prediction standard error 2 materials and methods 2 1 site description east fork poplar creek efpc in eastern tennessee usa is impaired with dissolved mercury hg contamination brooks et al 2017 the study site is a reach located about 5 4 km upstream from the mouth of the creek and was approximately 265 m long with an average width of 10 m fig 1 recent studies have suggested that flow exchange between surface water and the hyporheic zone contributes to hg load in the surface water emphasizing the importance of quantifying the spatial distribution of the streambed attributes demers et al 2018 southworth et al 2013 characterization of hydraulic exchange and solute transport attributes of the streambed sediments is a critical consideration for effective implementation of remedial strategies for mitigating contaminant impacts to the efpc as well as other stream or river systems the forested landscape in the study reach provides heavy canopy cover over the channel in the spring and summer shales and carbonate rock i e dolomite and limestone are the dominant lithologies underlying the efpc watershed sections of the channel streambed consist of bedrock outcrops with little to no overlying sediment brooks et al 2017 rucker et al 2021 where unconsolidated sediments line the channel materials range in size from large stones to silt clay usda particle size class trace element analyses suggested localized areas of stream bank erosion contribute sediments to the efpc channel brooks et al 2017 dickson et al 2019 visually the streambed bathymetry changed notably between summer 2017 and 2018 following major rain and accompanying flood events in april 2017 and february 2018 fig s1 in supplemental information those two events likely had significant impact on the hydraulic solute transport and other properties measured for streambed sediments 2 2 streambed attribute point measurement vertical hydraulic gradients and streambed kv were measured using instream piezometers during the summer seasons of 2017 and 2018 here piezometers were actually miniature wells with a well screen installed in the streambed sediments and they were constructed of pvc pipe with 3 18 cm outer diameter and 2 54 cm inner diameter the piezometers were built from two sections connected by a 5 1 cm female female connector the perforated bottom section 30 48 cm of the piezometer was augured in the streambed sediment and consisted of a 15 24 cm perforated section 0 0254 cm slot size the length of the unperforated upper section of the piezometers above the sediment was cut to length based on the depth of the water column the piezometers were then allowed to equilibrate for at least four hours prior to recording the data to measure the hydraulic head gradient between the surface water and streambed porewater a pressure transducer aquistar ct2x0 was placed within the piezometer where the tip of the pressure transducer was level with the surface of the streambed sediment and another was fixed to the same elevation within the stream and the hydraulic head difference was determined by subtracting the water level height within the piezometer and the height of the stream surface the hydraulic gradient was determined by dividing the head difference by the distance from the riverbed surface to the middle of the screen interval positive values indicated an upward gradient suggesting streambed porewater could discharge to the surface water to determine vertical hydraulic conductivity and seepage flux slug tests were performed in each piezometer or miniature well by rapidly adding 250 ml of creek water and monitoring transient pressure changes in the well above the screen using the pressure transducer the resulting data i e hydraulic head change over time was analyzed following bouwer and rice 1976 1 k h r c 2 l n r e r w 2 l 1 t l n h 0 h t where kh is horizontal hydraulic conductivity l t rc is the inside radius l of the piezometer pipe re is effective radius l of the piezometer over which the hydraulic head or h l is dissipated rw is the horizontal distance l from the piezometer pipe center to the streambed sediment l is height l of screen zone of the piezometer h0 is the vertical distance l between the water level in piezometer and static water level in aquifer at time t0 and ht is the vertical distance l between water level in piezometer and the static water level in streambed sediment porewater at time t this equation has been commonly applied for this type of hydraulic property estimation ghysels et al 2018 maurya et al 2018 petersen et al 2020 ronde et al 2017 zhang et al 2019 and the recommended guidelines were followed to avoid errors batu 1998 kv was estimated with the relationship kh 10 kv commonly used for fluvial and alluvial sediments baxter et al 2003 butler and healey 1998 chen 2004 domenico and schwartz 1997 ghysels et al 2018 landon et al 2001 yeh et al 2015 this vertical anisotropy was not verified due to limits of the streambed sediment thickness seepage flux was calculated as the product of kv with the hydraulic gradient 2 3 hg sampling analysis and flux estimates water samples were collected from the surface water and the piezometers filtered with 0 2 μm polyethersulfone pes filters preserved with concentrated hydrochloric acid 0 5 v v trace metal grade and analyzed for total aqueous hg concentration following established methods epa 2002 dissolved hg flux was estimated as the product of hg aqueous concentrations collected from pore water within the piezometers and seepage flux this approach is commonly used to assess solute mass discharge into streams during baseflow conditions carroll et al 2003 ronde et al 2017 2 4 estimation of left censored attributes two methods were used to estimate the left censored attributes the substitute method was applied by imputing half the detection limit of the attribute as the left censored value calver 2001 stated that the lowest kv value for bedrock lining a river channel was 1x10 8 m sec which was consistent with expected values for limestone domenico and schwartz 1997 thus a value of 1x10 8 m sec was selected as the left censored value for limestone bedrock where piezometers could not be installed and where kv values were below the measurement lower limit we assumed that the left censored value for the differential head was 0 0127 m which was half the resolution value or lower limit for the ct2x smart sensor pressure transducer 0 0034 of the full scale or burst pressure 1000 psi approx 2000 ft or 60 m the left censored value for seepage flux was selected to be 1 27x10 10 m s i e determined as product of left censored hydraulic conductivity and gradient values for hg concentration we assigned the left censored value of half the method detection limit i e 1 62 ng l so for hg flux the left censored value was determined to be 810 ng m3 multiplied by 1 27x10 10 m s 1 03x10 7 ng m2 s 1 the second method used to estimate the left censored values was the saem algorithm which is based on estimating the parameters of a spatial regression model the saem approach was used to produced conditional simulations of left censored observations and then obtain a predictor for data at unsampled sites by taking the weighted mean of kriging predictors using importance sampling based on the location of the left censored data lachos et al 2017 ordoñez cuastumal 2017 the algorithm is implemented in the package censspatial available in the r software barbosa 2016 2 5 sampling design the study reach had several areas of the streambed with limestone outcrop without unconsolidated sediments and other sections with relatively thick unconsolidated sediments rucker et al 2021 bedrock outcrops were more pronounced on the thalwag and northern side of the efpc preventing piezometer installation in those locations piezometer installation and measurement locations were not predetermined as either random or using a gridded sampling design limitations in streambed sediment thickness required that piezometer installation location decisions were made in the field based on maximizing spatial coverage while balancing installation feasibility the locations used for installation of piezometers were selected in real time where the thickness of streambed sediments was larger than approximately 0 15 m which was an operationally defined minimum thickness required for piezometer installation left censored data locations were generally selected based on visual observations of limestone bedrock lining the streambed and by measurement of sediment thickness by augering a left censored location was added at each location where bedrock was visible and augering was not possible flood induced changes to sediment distribution in the stream channel between piezometer installation and data collection dates in 2017 and 2018 affected the spatial location of piezometer installation and measurement in consecutive years fig 1 however the number of piezometers was relatively consistent and the area of investigation was consistent between these two years of site characterization the piezometer locations were georeferenced using a trimble vx spatial station robotic a rtk gps and a measuring tape to quantify the effect of data sampling location on the interpolation prediction error and to evaluate if the spatial distribution of the data was clustered random or dispersed the average nearest neighbor index was estimated and used to compare the sampling distributions collected in 2017 and 2018 before and after adding the left censored values the average nearest neighbor tool in arcgis version 10 5 1 was used to define the type of spatial distribution of the sampling points before and after adding the left censored values the average nearest neighbor index is expressed as the ratio of the observed mean distance to the expected mean distance eqs 2 6 2 ann d o d e 3 d o i 1 n d i n 4 d e 0 5 n a where do is observed mean distance between each feature and its nearest neighbor de is the expected mean distance between the features given in a random pattern di is the distance between feature i and its nearest neighboring feature n is the total number of features a is the area of a minimum rectangle around all features the expected distance is the average distance between neighbors in a hypothetical random distribution if the ann index is less than 1 the pattern exhibits clustering and if the index is greater than 1 the trend is toward dispersion the z score and p value are used to determine the significance of the spatial distribution where z score represents the standard deviation and p value represents a numerical approximation of the area under the curve for a known distribution limited by the test statistic 5 z d o d e se 6 se 0 26136 n 2 a the z scores and p values returned by the pattern analysis determines whether or not the null hypothesis of a complete spatial randomness can be rejected 2 6 spatial mapping of streambed attributes in geostatistical interpolation data exploration is the first step completed to ensure that spatial data dependency i e values closer together usually should be more alike than values further apart and stationarity i e similar statistical properties and data variability everywhere are met arcgis geostatistical analyst tool was used which provides a collection of models and tools for spatial data exploration identification of data anomalies optimal prediction evaluation of prediction uncertainty and surface creation continuous semivariograms were fit to the observed data using the geostatistical analyst using the default optimized model the semivariogram that provided the best fit i e minimized root mean square deviation to the data and gave the lowest prediction errors was the stable model wackernagel 2013 7 γ h c 1 e x p n a r a where γ h l2 t2 is the semi variance at distance h l c is the sill l2 t2 r is a distance parameter and a is an empirical parameter should be greater than zero and less than or equal to two for the stable model most geostatistical models assume that the data are correlated and stationary yeh et al 2015 we compared and evaluated the effect of adding left censored data on the stationarity and the correlation of the data set semivariograms have been used to address this question and to quantify those two characteristics analyzing the semivariograms for intrinsic stationarity was considered by autocorrelation using the ratio between nugget and sill α as suggested by cambardella et al 1994 if the nugget to sill ratio was less than 0 25 the variable has strong spatial dependence between 0 25 and 0 75 the variable has moderate spatial dependence and greater than 0 75 the variable shows only weak spatial dependence directional anisotropy has also been quantified with the original data set and after adding the left censored values here we considered 2d horizontal directional anisotropy anisotropy relative to the vertical was not considered because the horizontally distributed data would not support 3d evaluations and the limited thickness of the unconsolidated sediments overlying the bedrock in the study site did not warrant 3d evaluation testing for the directional autocorrelation and anisotropy of the data was completed by enabling the anisotropy function in the geostatistical wizard within arcgis 10 5 1 by enabling the anisotropy function 2d major and minor semi axes were calculated for each attribute allowing for calculation of the major axis to minor axis ratio and the directional orientation of those axes 3 results and discussion 3 1 data distribution hydraulic gradient and vertical hydraulic conductivity were measured using streambed piezometers over a spatial domain of approximately 3666 m2 in efpc fig 1 a total number of 37 piezometer locations in 2017 and 40 piezometer locations in 2018 were used to characterize streambed attributes this equates to 37 points over a domain of 3666 m2 or 0 0101 points m2 in 2017 and 40 points over a domain of 3666 m2 or 0 011 points m2 in 2018 without addition of left censored data these data densities were significantly lower than those suggested for use in previous studies genereux et al 2008 compared the spatial variability in kv at 46 locations in a larger 262 5 m reach and at 54 and 62 locations in two smaller 62 5 m reaches in west bear creek in north carolina where they also found no significant differences in the estimated attributes between sampling density of 0 025 points m2 and 0 13 points m2 kennedy et al 2008 indicated that a sampling density of about 0 05 points m2 was sufficient to reduce the error in kriged estimates of kv to 10 or less reyes 2009 studied streambed hydraulic attributes and nitrate flux in the neuse river with a sampling density that varied from 0 02 to 0 052 points m2 with a model error of 12 for the interpolated kv and this sampling density was assumed to be sufficient sebok et al 2015 found no significant differences in kh kv and vertical hydraulic gradient between straight and meander reaches in holtum stream with sampling densities of 2 points m2 10 points in 5 m2 and 1 point m2 30 points in 30 m2 song et al 2016 found a negative correlation between sampling density and the modeling error for interpolated contour maps of streambed kv and head gradient in the beiluo river china modeling errors decreased from 8 to 1 at data densities of 0 156 points m2 and 0 273 points m2 respectively as noted above data densities for this study collected in both 2017 and 2018 without addition of left censored data were lower than recommended data densities in all of these prior publications forty three left censored values were added to the 2017 data for a final data set of 80 values of which 54 were imputed values based on methods described previously twenty seven values were added to the 2018 data set for a final data set of 67 values of which 40 were imputed consequently the data density increased from 0 0101 points m2 and 0 011 points m2 to 0 0218 points m2 and 0 0183 points m2 in 2017 and 2018 respectively the data density including the imputed values were within the lower yet acceptable range suggested by reyes 2009 and genereux et al 2008 these results confirm that imputing left censored data where bedrock outcrops along the streambed can be used to increase streambed attribute property data to reach minimum data density requirements determined by previous researchers 3 2 average nearest neighbor ratio analysis the average nearest neighbor ratio was used to compare data location clustering with and without addition of the left censored values to determine the effect of sampling location on the average prediction standard error of the interpolated results in 2017 and 2018 table 1 and fig s2 for the 2017 dataset sample locations had average nearest neighbor ratios of 1 07 and 0 9 with and without left censored data respectively the nearest neighbor ratios for 2018 data were 0 59 and 0 61 with and without left censored data respectively these results suggested that data distribution was random in 2017 and was clustered in 2018 before and after adding the left censored data the z score and p score measures the statistical significance and these were used to determine whether or not to reject the null hypothesis which states that the features are randomly distributed the alternate hypothesis is that the features are not randomly distributed and may be impacted by clustering or dispersion the z score and p score for the 2017 data with left censored data 1 12 and 0 26 and without left censored data 1 13 and 0 26 suggested that the pattern was not significantly different from a random spatial distribution table 1 alternatively the z score and p score for the 2018 data with left censored data 6 48 and 0 00 and without left censored data 4 78 and 0 00 suggested that for these datasets the null hypothesis was rejected in favor of the alternate hypothesis at the efpc within the study reach the intermittent outcropping of bedrock at the streambed constrained not only the data density but also the data distribution which led to less random and increased clustering of the sampling designs we expect this to be a common issue for many streambed characterization investigations 3 3 descriptive statistics a t test to evaluate the means of the attributes was conducted with a 0 05 significance level to evaluate if the data obtained in 2017 and 2018 were independent data sets or not the null hypothesis was that the means from 2017 measurements were similar to those from 2018 measurement for all attributes the results rejected the null hypothesis and this result indicated that the means were different for all attributes between the two years the variation in the mean values for the attributes can be explained with scouring and deposition of sediments after the two major rain events occurred in summer 2018 which carried maximum discharges of 8 19 m3 sec and 4 69 m3 sec three important requirements for ordinary kriging are a constant trend function a constant variogram across the entire area of interest and the target variable follows approximately a normal distribution most normality tests require a specific sample size or data density including the widely used the shapiro wilk test and kolmogorov smirnov test with skewness and kurtosis bowman and foster 1993 ahad et al 2011 suggested that a sample size of 40 to 77 counts was sufficient to test the data normality by different statistical methods in this study the number of measurements was 37 points in 2017 and 40 points in 2018 close to the lower cutoff value for assessing normality we used the skewness kurtosis and the difference between the mean and median to evaluate the normality of the measured data perfectly normally distributed data has a kurtosis value of 3 westfall 2014 a smaller difference between the mean and median also indicates that the distribution is closer to a normal distribution negative values for skew indicate a left skewed distribution and positive value indicate a right skewed distribution in general a skewness less than 1 or greater than 1 indicates that the distribution is highly skewed between 1 and 0 5 or between 0 5 and 1 indicates that the distribution is moderately skewed and between 0 5 and 0 5 indicates that the distribution is approximately symmetric çalıyurt 2019 summary statistics for kv seepage flux and hg flux measured in summer of 2017 and 2018 are summarized in table 2 skewness and kurtosis did not differ greatly for kv and the natural log of kv ln kv in 2017 with a skewness less than 0 5 and kurtosis slightly less than 3 the skewness values of kv and ln kv suggested that the distributions were approximately symmetrical for ln kv the mean of the distribution was closer to the median and therefore the ln of kv was used to estimate the spatial interpolation for kv measured in 2018 the skewness decreased with the ln transformation from 0 91 to 0 59 also suggesting the skewness shifted from right to left also mean kv was closer to the median compared to the kv without transformation and therefore kv values without ln transformation were used to estimate the spatial distribution the ln transformation for the seepage flux estimated in 2017 had the undesired effect of increasing skewness and kurtosis therefore the values without ln transformation were used to estimate the spatial distribution however for all the other attributes measured in the two years the ln transformation provided a closer match to the normal distribution thus the ln transformation was used for kv and hg flux estimated in 2017 and all three attributes estimated in 2018 the untransformed values of seepage flux estimated in 2017 were used for the spatial interpolation for that attribute although the trend of the distribution was not consistent for all attributes the distribution closer to normality was selected to fulfill a requirement for ordinary kriging by using an approximately normal distribution to estimate the spatial distribution of the attributes 3 4 spatial autocorrelation and semivariograms analysis ordinary kriging was used to interpolate streambed attributes as the data displayed no trend and the semivariograms exhibited local stationarity before and after adding the left censored values data were modeled comparing two contrasting assumptions in the first assumption the data were assumed to be isotropic and were assumed to be anisotropic in the second assumption this comparison for horizontal isotopy versus anisotropy was made for the data for each of the two years both with and without imputed left censored data semivariograms were created for each of the four interpolation scenarios isotropic without left censored data isotropic with left censored data anisotropic without left censored data and anisotropic with left censored data fig s3 to s6 the semivariogram parameters including correlation length i e range sill and nugget for each of the four interpolation methods and the three attributes are summarized in table 3 the range distance where data have statistical dependence was notably increased in most anisotropic semivariograms compared to the similar isotropic semivariogram indicating that autocorrelation varied in different directions however the seepage flux range measured in 2018 remained relatively low for isotropic anisotropic and before and after adding the left censored data compared to the 265 m length of the study reach since seepage flux is a function of the hydraulic gradient and kv the correlation length of seepage flux does not necessarily match that for kv and was affected by the correlation length of hydraulic gradient additionally imputing left censored data resulted in significant increases in range length for both isotropic and anisotropic results for data collected in both 2017 and 2018 the nugget effect generally occurs when measurements are different at very short distances ideally the closer the sampling points the less disparate the measurements should be with this difference approaching zero at the zero distance between samples the nugget effect was negligible for kv measured in 2018 for both the isotropic and anisotropic models before adding left censored data table 3 overall the nugget effect for all attributes was lower than the sill generally a large nugget relative to the sill is problematic and could indicate too much noise without significant spatial correlation matzke et al 2014 the spatial data correlation was quantified using the nugget to sill ratio α as suggested by cambardella et al 1994 most attributes had a moderate spatial dependency 25 α 75 except for 2017 and 2018 hg flux and 2018 kv which before adding the left censored data had a low spatial dependency α 25 table 3 upon addition of the left censored data relative to results without left censored data all of the attributes had increases in spatial dependency this result may be in part attributed to the above noted increase in data density to the minimum requirements suggested by previous researchers these results also confirm that imputed left censored values can support and enhance spatial structure and spatial correlation as opposed to inhibiting spatial connectivity this enhancement of spatial dependence seems to be an effective method for improving interpolation when geostatistical methods are used 2d directional autocorrelation indicated that data were correlated in different directions which suggested that the variability of the streambed attributes varied with direction i e anisotropy the length of the major axis to length of the minor axis ratio λ ranged between 1 53 and 3 00 with the lowest ratios for the attributes before adding the left censored data i e 1 53 and 1 6 for hg flux measured in 2017 and seepage flux measured in 2018 respectively table 4 these two attributes also had shorter range lengths which indicates they were the least spatially correlated among all attributes with least anisotropy adding the left censored values increased λ for these two attributes to 2 99 and 2 65 respectively and these changes resulted in notable decreases in the range and variability of the λ values upon addition of the left censored values table 4 the direction of anisotropy or autocorrelation θ as azimuth with north as 0 east as 90 south as 180 and west as 270 was relatively consistent for most attributes having major direction aligned with the orientation of the stream channel just south of east and north of west other researchers have also noted that the largest kv correlation can be aligned with the direction of the stream channel abimbola et al 2020 ghysels et al 2018 upon addition of left censored data 2017 kv seepage flux and hg flux changed major direction from just south of east to just north of east which was attributed to the locations of the imputed left censored data as indicated by the average nearest neighbor index analysis clustering of the measured attributes was reduced for both years by the addition of the left censored data which explains the shift in the anisotropy direction the above noted enhancements of spatial dependence in part were also attributed to these reductions in clustering upon imputing with left censored data these additions of left censored data both increase data density and decrease data clustering and both result in improvements in interpolation when geostatistical methods are used the attributes were anisotropic before and after adding the left censored values however the anisotropy ratio was relatively low compared to some strongly anisotropic porous media kessler et al 2013 tonina et al 2016 at the efpc within the study reach the stream exhibited only a minor amount of meandering and also relatively low streambed sediment attribute interpolation anisotropy since prior research has noted increased heterogeneity and anisotropy within meander bends relative to straight channels borna et al 2018 ghysels et al 2018 sebok et al 2015 song et al 2016 we posit that streambed sediment attribute interpolation anisotropy may vary with stream geomorphology and some streams may have more significant streambed attribute anisotropy than was shown here for efpc 3 5 evaluation of spatial interpolation methods the ordinary kriging average prediction standard error which represents the standard deviation of the prediction for any individual point was determined to evaluate and compare all interpolation methods in general the kriged values without the left censored data and assuming isotropy had the highest spatially averaged i e over study reach prediction standard error values among all approaches and anisotropic kriged values upon addition of left censored data had lower average prediction standard errors fig 2 considering anisotropy and including the imputed left censored data reduced the average prediction standard error by between 83 1 hg flux measured in 2017 to 29 8 kv measured in 2017 the consistently high average prediction standard error values for the isotropic geostatistical model without left censored data indicated that this interpolation method was not very effective and the error reduction suggests that the effectiveness of the geostatistical interpolation was improved with addition of left censored data and also with consideration of anisotropy within the interpolation the reduction in error was larger with addition of left censored data relative to the difference between anisotropic and isotropic kriging which is consistent with the relatively low amount of horizontal directional variability in the stream however both of these resulted in error reductions and we posit that anisotropy consideration in streambed sediment attribute kriging have increased importance in other stream systems including those with increased channel curvature or tortuosity borna et al 2018 sebok et al 2015 song et al 2016 the significant reductions in error due to imputing left censored data was also consistent with the increase in data density to the range recommended by prior publications fig 2 also shows the left censored values imputed using the substitute method and saem algorithm had very similar results and similar average prediction standard errors for all attributes for example using the anisotropic model and after adding the left censored values the relative prediction standard error for ln hg flux measured in 2017 using the substitute method was 40 8 and was 40 5 using the saem algorithm and for ln hg flux measured in 2018 was 64 3 using the substitute method and 65 2 using the saem algorithm ln kv measured in 2018 had the highest difference between the relative prediction standard errors estimated using the substitute method and saem algorithm as 2 74 which was considered only a minor deviation these results confirm that these two differing left censored value estimation methods provided comparable and consistent results this is an interesting finding when considering that saem takes spatial variability into consideration we suggest that this provides additional justification for the application of these results as imputed values for geostatistical interpolation 3 6 spatial distribution analysis measurement locations varied significantly in 2017 and 2018 controlled by the distribution of streambed sediment additional sediment existed in the upstream and downstream in the two years however only a very thin veneer of sediment existed around mid stream in 2018 which limited installation of the piezometers and characterization of streambed attributes fig 1 the locations of maximum and minimum attribute values also varied significantly between the two years the measured kv before adding left censored values varied over one order of magnitude for both years varying between 4 30x10 7 m s and 4 37x10 6 m s in 2017 and between 2 47x10 7 m s and 5 50x10 6 m s in 2018 similar to kv the measured seepage flux before adding left censored values ranged over one order of magnitude the minimum and maximum measured values varied between 1 29x10 7 m s and 7 48x10 6 m s in 2017 and between 2 52x10 7 m s and 7 13x10 6 m s in 2018 the range for hg flux spanned over two orders of magnitude with a minimum value of 3 04x10 3 ng m2 s and a maximum value of 3 80x10 1 ng m2 s in 2017 and a minimum value of 3 00x10 3 ng m2 s and a maximum value of 1 77x10 1 ng m2 s in 2018 contour plots of geostatistical interpolation results are presented for kv seepage flux and hg flux in figs 3 4 and 5 respectively the t test as noted above revealed that the mean of all attributes was different between the two years and the spatial distributions shown in these contour plots differed significantly between the two years the spatial distribution of the streambed attributes showed distinct spatial and temporal differences between the 2017 and 2018 results including the locations of maximum and minimum kriged attributes figs 3 5 for example before adding the left censored data higher kv values between 2 99x10 6 m s and 4 55x10 6 m s were mostly located at the east upstream and west downstream of the study reach and lower kv values between 1 83x10 7 m s and 1 37x10 6 m s were located in between mid reach those higher kv locations fig 3a the upstream section of the reach had lower kv values in 2018 between 1 83x10 7 m s and 1 37x10 6 m s compared to a range between 2 29x10 6 m s and 4 55x10 6 m s in 2017 fig 3b we attribute these transient changes in streambed sediment attributes to erosion deposition and sediment transport and redistribution processes which can have significant implications for hyporheic zone characterization especially in streams that are prone to flash flooding such as the efpc brooks et al 2017 dickson et al 2019 levy et al 2011 this type of transient streambed kv changes due to sediment erosion transport and redistribution has been documented recently by several researchers genereux et al 2008 kennedy et al 2009b korus et al 2020 levy et al 2011 shrivastava et al 2020 wu et al 2015 the kriging distributions also showed differences between the attributes before and after adding the left censored data figs 3 5 adding left censored data notably changed the kv distribution mostly decreasing the values along the majority of the reach fig 3c relative to the distribution without left censored data collected in 2017 fig 3a a larger portion of mid stream during 2017 had a lower kv values between 1 0x10 8 m s and 1 37x10 6 m s compared to a range 2 29x10 6 m s to 2 98x10 6 m s before adding the left censored data upstream and downstream also had mostly lower kv values during 2017 between 1 38x10 6 m s and 1 58x10 6 m s after adding the left censored data compared to a range 3x10 6 m s to 4 55x10 6 m s before adding the left censored data for the 2018 results kv values before adding the left censored data were mostly larger within the mid reach section of the study area varying between 2 29x10 6 m s and 2 98x10 6 m s and the lower values were located at the east upstream and west downstream portions of the study reach fig 3b the larger kv region within the mid reach was decreased in extent upon addition of left censored data fig 3d in addition to lowering kv in some areas the addition of left censored data increased the refinement of the spatial variability the spatial distribution trend of seepage flux fig 4 was similar to that of kv fig 3 in both years upstream and downstream had the highest seepage flux values in 2017 fig 4a between 2 60x10 6 m s and 4 47x10 6 m s and mid stream had lower values between 1 53x10 6 m s and 2 06x10 6 m s for the 2018 data fig 4b the upstream part of the reach had lower seepage flux values as consistent with the above noted zone of lower kv and seepage flux ranged between 4 48x10 7 m s and 1 14x10 6 m s the range of seepage flux values notably decreased after adding the left censored values with greater decreases noted in mid stream in 2017 fig 4c and upstream in 2018 fig 4d where a denser cluster of data points existed after adding the left censored values similar to the kv results the addition of left censored values reduced the seepage flux magnitude at locations where they were added and also seemed to have increased the refinement of the spatial variability compared to the spatial distributions without the left censored data the spatial distribution of hg flux was also notably differed between 2017 and 2018 fig 5 most of the reach in 2018 had hg flux values ranged between 2 35x10 1 ng m2 s and 9 93x10 1 ng m2 s and most of the reach in 2017 had hg flux values about an order of magnitude lower than 2018 for the results without left censored data the upstream and downstream portions of the reach had the highest hg flux values in 2017 fig 5a whereas the upstream and downstream zones did not have the higher hg flux values in 2018 fig 5b the elevated hg flux in the upstream and downstream ends of the reach for the 2017 dataset was consist with the elevated kv and seepage flux in those locations noted above several locations of hg flux were decreased after adding the left censored values especially in mid stream part of the reach for 2017 fig 5c and in the upstream part of the reach in 2018 fig 5d which was consistent with the above noted trends for seepage flux the addition of left censored values reduced the hg flux magnitude at locations where they were added and addition of left censored data seems to have increased the refinement of the spatial distribution of the lower range of hg flux within the reach thus imputing of left censored values within geostatistical interpolation may be more sensitive to identifying and characterizing the spatial distributions of the lower magnitudes for attributes which might be more suitable for mapping lower or minimum value locations than mapping maximum value locations as noted above the variability in the spatial structure over time can be attributed to variability in seasonal changes in sediment erosion transport and deposition within the streambed most temporal variabilities in streambed attributes such as kv in rivers and streams are typically attributed to variability in streambed lithology and texture as a result of erosion and depositional processes genereux et al 2008 kennedy et al 2009b korus et al 2020 levy et al 2011 shrivastava et al 2020 wu et al 2015 we speculate that anomalously high precipitation and efpc flow rate events that occurred in january and february of 2018 have altered the spatial distribution of streambed sediment causing the variability in kv distribution as indicated in the similarities of the contour map spatial distributions the hg flux and seepage flux distributions were highly dependent on the kv distributions and all three streambed attribute spatial distributions were modified between summer of 2017 and summer of 2018 which we attribute to erosion and deposition of the unconsolidated sediments relative prediction standard error contour maps percentage unit were created by dividing the prediction standard error by the mean using ordinary kriging for kv seepage flux and hg flux in figs 6 7 and 8 respectively the spatial structure of the attributes was noticeably different from the spatial structure of the standard error the results indicate that standard error was generally higher in areas where measurements were sparse and where measurements differed substantially from their neighbors the relative prediction standard error was notably higher in areas with lower sampling density figs 6 8 for the 2017 data kv had a relative prediction standard error that ranged up to 40 before adding the left censored values fig 6a compared to up to 30 after adding the left censored values fig 6c for the 2018 data with and without imputed left censored data fig 6b and fig 6d the kv distributions generally had a larger relative prediction standard error range compared to the results for the 2017 data fig 6a and fig 6c respectively for the 2018 data and before adding the left censored values the relative prediction standard error of kv ranged between 61 and 80 compared to a range between approximately zero and 60 after adding the left censored values these relative prediction standard error reductions upon addition of left censored data are also consistent with results presented in fig 2 and these reductions in error illustrate the potential for geostatistical interpolation improvements upon addition of left censored data especially when they allow data density and distribution to increase to ranges that are recommended as minimum requirements by the above noted previous publications similar trends to those described above for kv were also observed in the relative prediction standard error for seepage flux before and after adding the left censored values for each of the two years fig 7 the addition of the left censored values have resulted in a notable decrease in the relative prediction standard error also consistent with fig 2 and the spatial distribution of the error was comparable between kv and seepage flux which again illustrates the impact of kv on the seepage flux results inspection of fig 8 indicates that the hg flux standard error distribution for 2017 and 2018 results without addition of left censored data was larger than that of the kv and the seepage flux especially within the portions of the reach without point measurements upon addition of left censored data fig 8c and 8d the hg flux standard errors were reduced significantly across the entire study reach for both years figs 6 8 along with fig 2 confirm that the standard error was generally lower for kv and seepage flux in 2017 compared to 2018 whereas error magnitudes were more similar between 2017 and 2018 for the hg flux results the standard error reductions occurred consistently and were significant for each of the three streambed sediment attributes and for each of the years investigated which can be attributed to both the increased number and density of data points and their spatial distribution with less clustering also the 2018 data locations were clustered which also contributes to the large error in between data points compared to 2017 the data clustering may explain the significant errors especially around the banks and mid reach in 2018 where sampling was limited ideally a random or dispersed spatial distribution would ensure that the interpolation would provide a more continuous function describing the data which would lower the interpolation errors addition of left censored data has been shown herein to increase the data density and areal coverage of the spatial distribution into locations where piezometer data collection was limited by the consolidated limestone bedrock outcrop sections of the streambed and these data density and data clustering limitations can be common for many streams and rivers especially within lower order stream systems 4 summary and conclusions this investigation assessed the effects of considering anisotropy and of increasing data density with the addition of left censored values on geostatistically interpolated 2d horizontal distributions of kv seepage flux and hg flux as three hydraulic and solute transport attributes of streambed sediments streambed hydraulic and solute transport attribute measurement and characterization are critical for evaluation of hyporheic zone exchange which is now recognized for its control over various hydrobiogeochemical processes impacts in terms of relative interpolation prediction standard errors were examined using in stream piezometer point measurements collected over two years time within a 265 m study reach area of the efpc where intermittent locations of exposed bedrock lining a streambed inhibited data density and spatial distribution of measured streambed attributes the impact of anisotropy in the data and its consideration in the geospatial interpolation method was examined for the three measured streambed attributes measured within two separate years before and after adding the left censored values after confirming the data was stationary in both cases these three streambed attributes were confirmed to have anisotropic distributions generally aligned with the stream channel direction consideration of this anisotropy within the interpolation approach reduced average prediction standard error even with minimal meander curvature within the study area reach and the isotropic interpolation without addition of left censored data consistently had larger errors for all attributes which confirms that anisotropy should be used within the interpolation of these anisotropic data addition of the left censored data increased the data density to reach the minimum recommended by previous studies the clustering was reduced through addition of the left censored data upon addition of left censored data the spatial dependence for some attributes was increased and there was also increased the consistency of the spatial dependence addition of left censored data seems to have also increased the refinement of the spatial distribution of the lower range for some streambed attributes the anisotropic ordinary kriging generally had reduced average prediction standard errors after adding the left censored values for the efpc reach considered herein addition of the left censored values resulted in a larger error reduction than the consideration of anisotropy relative to isotropic kriging which confirms the benefit of data addition to increase data density within data limited environments these techniques of increasing the data density by adding left censored values may seem straightforward but we confirmed that the case study presented was not impacted by limitations including the potential to alter the stationarity and correlation of the original dataset which may violate the underlying assumptions for using geostatistical methods to interpolate attribute values adding imputed data values can improve the overall analysis but practitioners are cautioned to verify the data still conform to the underlying assumptions of the analysis and limit the amount of imputed data relative to measured data e g 30 there may be limitations for geostatistical applications to streambed sediments and characterization of the statistical distributions of riverbed structures is important for exchange fluxes for example a recent paper by tang et al 2015 compared ensemble kalman filter for estimation of riverbed hydraulic conductivities they included a comparison of multigaussian and non multigaussian properties and their results concluded that differences between the simulations were small and non multigaussian riverbed properties seem to be of less importance for subsurface flow than non multigaussian aquifer properties there is still a need to examine these types of limitations in the context of solute transport in streambed systems credit authorship contribution statement ruba a m mohamed conceptualization data curation data curation formal analysis investigation methodology writing original draft scott c brooks conceptualization methodology investigation resources data curation writing review editing supervision project administration funding acquisition chia hsing tsai methodology data curation tanzila ahmed methodology data curation dale f rucker conceptualization methodology investigation resources data curation writing review editing project administration funding acquisition april l ulery conceptualization methodology investigation resources data curation writing review editing project administration funding acquisition eric m pierce conceptualization methodology supervision project administration funding acquisition kenneth c carroll conceptualization methodology investigation resources funding acquisition investigation project administration supervision validation visualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the department of energy doe minority serving institution partnership program msipp managed by the savannah river national laboratory additional support was provided by the usda national institute of food and agriculture hatch project 1023257 and the plant environmental science department at nmsu which is greatly appreciated a portion of this research was sponsored by the office of biological and environmental research within the office of science of the u s doe as part of the critical interfaces science focus area project at the oak ridge national laboratory ornl the doe will provide public access to these results of federally sponsored research in accordance with the doe public access plan http energy gov downloads doe public access plan ornl is managed by ut battelle llc under contract no de ac05 00or22725 with doe we appreciate the assistance of kenneth lowe michael jones nikki jones justin milavec autumn pearson chris kubicki and amanda lara we thank the anonymous reviewers for their comments which improved the clarity of this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126474 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4481,machine learning ml techniques can be valuable for modelling the faecal contamination in the rivers to overcome the limitations of the process based models however this approach requires large sufficient data for training and validation processes to avoid the over fitting problem this study attempts to overcome the small dataset limitation by relying on the data augmentation techniques to that end adaptive boosting adaboost models were trained and integrated into the data augmentation method to generate 600 virtual samples based on 40 original datasets the results revealed that the proposed method significantly improved the accuracy rmse 0 716ln colony forming unit cfu 100 ml and generalization ability of the adaboost model for predicting the faecal coliform in the rivers compared to the baseline model developed only with a small dataset rmse 2 348ln cfu 100 ml however the study showed that generating and using too many virtual data could deteriorate the generalization ability of the ml model and the optimal virtual datasets are about 337 415 virtual samples globally the results of this study provide new insights to improve the prediction accuracy of the health risk related to the faecal coliforms in raw water used for drinking purposes under a small dataset the developed method can broaden the application of ml to water resources and environmental sciences when it is impossible to get a large dataset required by ml models keywords faecal coliform rivers adaboost model data augmentation prediction accuracy generalization ability 1 introduction the outbreak of the coronavirus disease in 2019 across the world makes microbial pollution an interesting topic for research worldwide the microbial water pollution is commonly evaluated by faecal indicator bacteria fib including faecal coliforms fc such as escherichia coli and faecal streptococci fs such as enterococcus feacalis although these indicators do not confirm the presence of the pathogenic organisms in the water they are considered as the main proxies in evaluating the microbial water standards pachepsky et al 2016 pachepsky and shelton 2011 senkbeil et al 2019 wen et al 2020 these indicators have been considered a suitable indicator for evaluating the risk of microbial pollution in water resources singh et al 2020 uprety et al 2020 accordingly a higher concentration of the fib in the water resources indicates a low hygiene quality of the aquatic environment and therefore a high risk to human health when the water is used for drinking recreation irrigation and fishing purposes besides several international organizations such as the world health organisation who the european environment agency eea and the national health and medical research council nhmrc of australia use the fc as one of the drinking water quality indices faecal contamination of the water resources is caused by agricultural runoff sewage and human and animal faeces holcomb et al 2020 khan et al 2018 wu 2019 therefore predicting and evaluating the fc at watershed and stream scales is crucial to assess and manage the health risk related to the pathogen pollution of the water sources for this purpose understanding various combinations of the factors fate and transport processes has led to the development of process based models that are capable to simulate the responses of the hydro aquatic systems to microbial pollution the soil and water assessment tool swat and hydrological simulation program fortran hspf are the main watershed based models largely used in modelling the fc transport and fate cho et al 2016 yagow et al 2013 kim et al 2014 niazi et al 2015 pandey et al 2016 rolle et al 2012 although the watershed based models can be fruitful tools in predicting the faecal contamination of the water resources their limitations were reviewed by benham et al 2006 and oliver et al 2009 specifically the data availability is one of the limitations in the wide application of the watershed based models because of the high cost for the analysing and sampling protocols besides these models need a continuous time series of data for calibration and validation processes meanwhile there is often a mismatch between the objectives of the water quality monitoring data and of those required for building these models particularly in developing countries additionally several process based models have been developed based on the biological adsorption sedimentation re suspension advection and dispersion processes to predict the faecal contamination in the stream and river systems bai and lung 2005 jamieson et al 2005 steets and holden 2003 wilkinson et al 1995 these models need a large number of parameters and data that can be the main source of the uncertainties for this reason it is challenging to predict the faecal contamination of the water sources with this approach under missing data moreover the literature shows that there are few applications in modelling the response of the river responses to faecal contamination using this approach indeed the response of the rivers to faecal contamination is typically non linear and highly complex as it depends on the weather environmental morphological conditions of the river and watershed scales zhang et al 2020 to overcome the limitation of the process based models the machine learning models could be powerful tools for predicting the responses of the river to the microbial pollution and thereby improving the accurate prediction of the fc in the rivers machine learning ml models are divided into two groups supervised and unsupervised the first group includes methods that can be useful for classification and regression problems according to the type of input and output variables indeed the supervised models rely on the training and validation processes using the archived data rather than the explanation of the mechanism of the processes that affect the fate and transport of the fc in the water and consequently they could be valuable for the areas with poor data in some cases there is a need to evaluate the magnitude of the faecal contamination to manage the health risk and to protect the water bodies rather than to understand its process the selection of the appropriate regression or classification ml models generally is based on the objective of the study the regression models numerically predict the real value of the water quality index while the classification ones directly predict the class or the status of the water resources according to a categorization chen et al 2020a regarding the prediction of the fib in the water mohammed et al 2018 applied and compared the random forest adaptive neuro fuzzy inference system anfis and non linear zero inflated models to predict the fib in the raw water intake for drinking purposes in norway choi and seo 2018 used classification models to predict the fc level in the north han river south korea however artificial neural network ann and genetic algorithm approaches have been investigated and showed being a powerful tool in predicting the fc concentration in water bodies duvvuri and anmala 2019 sbahi et al 2020 tufail et al 2008 wang and deng 2019 zhang et al 2015 ensemble learning techniques are powerful ml models that can be applied to either classification or regression problems as they are capable to model complex systems with high dimensions zhang and ma 2012 these methods showed being more accurate ml models compared to traditional statistical methods in water resource studies chen et al 2020b martínez santos and renard 2019 the most popular ensemble ml models is adaptive boosting adaboost model freund and schapire 1996 this bosting method generates base models weak learners iteratively using observation weights where the prediction model is constructed from a combination of base models however the adaboost model for regression drucker 1997 has been applied and showed its superiority compared to other ml models in different research fields for instance zhao et al 2013 found that the adaboost is better than the support vector regression svr and ann models in predicting the short term ionospheric walker and jiang 2019 applied the adaboost model for the prediction of demand driven acquisition and found that it is highly accurate than the linear regression model saghafi and arabloo 2017 demonstrated that the adaboost model provided high prediction accuracy for modelling the co2 solubility compared to the ann and svr models recently el bilali and taleb 2020 and el bilali et al 2020a found that this model has provided good performances in predicting the irrigation water quality parameters with high prediction accuracy compared to random forest ann and svr models these studies justify the need to consider this model for predicting the faecal coliform in rivers under a small dataset problem overall the literature shows that there is little focus on the prediction of microbial water quality using ml models this may be due to the commonly known issue that the ml models require big archived data for development procedures to overcome this issue in ml techniques the researchers have developed and designed several data augmentation methods to improve the prediction accuracy of the ml models even with a small dataset these approaches are categorised as follow 1 the feature extraction based approach 2 accumulating generator operator ago that based on the gray theory e g box gray model 1 1 bgm 1 1 chang et al 2015 gray bootstrap method wang et al 2014 and 3 virtual sample generation vsg approach niyogi et al 1998 that includes several methods abdul lateh et al 2017 arslan et al 2019 chen et al 2017 he et al 2018 interestingly all these methods have been applied and showed that the virtual samples improve the performances of the prediction model compared to the baseline model using the original data however their applicability and strengths differ from one field to another and from one task to another indeed the feature extraction based method is suitable for medicine studies to reducing the dimensionality of data with missing observations espezua et al 2015 zhang et al 2019 nevertheless the ago and vsg approaches are outstanding and popular technologies for generating virtual data for regression tasks chen et al 2017 he et al 2018 wang et al 2014 indeed the application of these methods is limited for industrial and medicines fields so far however some studies applied data augmentation methods and showed being a new insight into environmental studies for instance xu et al 2020a xu et al 2020b developed random standard deviation sampling rsds and dnn models and showed a good improvement of the forecasting model by generating 20 000 virtual samples and developing dnn models with 16 layers and 100 neurons in hidden layers xu et al 2020a xu et al 2020b developed a predictive model to evaluate the water quality for recreation purposes based on artificial datasets and classification ml models these methods have been applied and assessed for the dataset which is often low with fewer than five input variables besides they are complex and do not allow the user to exploit all data obtained from the experiments dataset and are vulnerable to generating inappropriate virtual samples especially for studies with high input variables besides running some methods requires an important time of about 4 min because of the big virtual data generation however the data augmentation approach is under exploration and could be improved by research worldwide and therefore there is a need to explore and assess this approach for different fields using fast computation tools with reasonable virtual data in this paper we attempt to develop a new data augmentation method to enhance the generalization ability of the adaboost model for regression task with high input variables and to overcome some limitations for generating the appropriate virtual output variables the literature shows that there is a focus on the prediction of fc in beach water rather than freshwater resources additionally there are few studies investigating the ml model for predicting the river response to faecal contamination by wastewater discharges indeed due to the high cost of laboratory analysis and sampling protocol it is not easy to get a large dataset required for ml development particularly for biological indicators in river and stream systems therefore new data augmentation procedures should be developed and investigated to overcome the shortage of data limitation and broaden the application of ml models in modelling hydrological systems this study aims at predicting the river responses to the faecal contamination by evaluating the efficiency of the data augmentation based adaboost model on small dataset circumstances to achieve this we attempt to develop a data augmentation method based on adding gaussian noises to the input variables wherein the adaboost model is embedded to generate a virtual dataset for enhancing the training process to improve the prediction accuracy the overall objective of this study is to evaluate the health risk by predicting the fc concentrations in the raw water mainly caused by wastewater discharges under semi arid conditions to help decision makers implement the appropriate river restoration strategies in the bouregreg watershed morocco this objective can be carried out by developing and investigating a predictive adaboost model for modelling the river responses to the faecal contaminations based on the data augmentation method 2 methods and materials 2 1 case study 2 1 1 study area the study area is the downstream part of the bouregreg watershed and is located in the northwest of morocco this watershed is the main water resource for drinking purposes with an annual average of 200 mm3 this water is mobilized by the reservoir of the sidi mohammed ben abdellah smba dam located a few kilometres from the outlet of the watershed however this reservoir is confronting several problems including sedimentation with annual 3 65 mm3 el bilali et al 2020b as well as water pollution mainly caused by wastewater discharges indeed domestic wastewater discharges upstream of the reservoir significantly increase the public health risk related to drinking and recreation purposes during critical periods therefore modelling the fc transport throughout the main river reaches can be valuable for the evaluation of the magnitude of the faecal contamination to manage the risk for this purpose the case study aims at predicting the river responses to the faecal contamination caused by domestic wastewater discharges fig 1 presents the study area location and the wastewater discharges as well as the used monitoring stations 2 1 2 data collection machine learning development requires observed data for training and validation processes to that end as presented in fig 1 twenty three monitoring stations were used for sampling and analysing during the two periods february 1 to 15 2018 and august 1 to 13 2018 a total of 40 samples from the monitoring stations fig 2 are collected the ph hanna hi 2211 electrical conductivity ec hanna hi 8633 and dissolved oxygen do hach 2100q are measured and recorded in situ using the portable multiparameter instrument meanwhile biological oxygen demand bod chemical oxygen demand cod total suspended solid tss total phosphorus tp and fc parameters are measured and analysed in the laboratory the bod was determined by the monomeric method with a respirometer types wtw according to the afnor standard nf t90 103 the cod was determined by the dichromate open reflux method according to the afnor standards nf t90 101 the total suspended solids tss were identified by filtration whatman circular filters of 47 mm in diameter and 0 45 μm of porosity according to french standard methods afnor 2005 t90 105 for bacteriological analysis samples were taken in strict aseptic techniques to prevent any accidental contamination each sample was made ready in sterile flasks collected samples were stored in a cooler 4 c and then transmitted to the laboratory on the same day for analysis they were analysed by the membrane filtration mf method risica and grande 2000 indeed the european drinking water directive 98 83 ec 1998 defines reference methods for the enumeration of microbiological parameters in drinking water the method defined for enumeration of faecal coliforms and e coli is mf on lactose ttc agar with tergitol 7 chapman 1951 as described in iso 9308 1 2000 filtration devices were treated by using a burner to ensure proper sterilization and to prevent cross contamination among samples for the detection and enumeration of faecal coliforms fc 100 ml of each sample are filtered throughout a 0 45 μm membrane filter and then the filters were transferred to ttc tergitol 7 agar plates after an incubation period at 44 5 0 2 c for 18 24 h the yellow and or violet colonies with yellow halo were counted as fc results were expressed by colony forming units cfu per 100 ml of sample the weather data are provided by the river basin agency of bouregreg and chaouia these data include the air temperature ta relative humidity rh and solar radiation h all these parameters are measured at the hydro metrological station at the smba reservoir in this study we introduced the data of the river reach characteristics namely length l in km slop s and the percentage of the river segment length that crosses the forest and or the matorral areas lfs the last parameter was selected based on the presence of the pastoral activities in the forest and in matorral areas adjacent to the rivers that can be a nonpoint source of faecal contamination caused by the animal faeces table 1 presents the statistical characteristics minimum maximum mean and standard deviation sd of the 40 samples used in this study 2 2 adaptive boosting adaboost model adaptive boosting adaboost is an ensemble machine learning model it is a tree based model that is introduced by freund and schapire 1997 for a system dataset s xi yi i 1 2 3 n where each xi is in some instance x and each yi is in some label y and for a series of round m the algorithm initializes the distribution d or weight as follow 1 d i 1 1 n f o r i 1 n then for j 1 to m adaboost algorithm builds weak models or learners hj from the training dataset using d that minimizes ε j and satisfies ε j 0 5 conditions ε j is a weighted error of the jth model and is given by eq 2 2 ε j i h j x i y i d i j the weight confidence αj of the jth model is calculated by eq 3 3 α j 1 2 ln 1 ε j ε j the distributions for next iteration were updated as follow 3 d i j 1 e y i h j x i α j d i j 4 d i j 1 d i j 1 i 1 n d i j 1 the prediction for new dataset is achieved by the weighted average of the models hj as follow 6 h x j m α j h j x the adaboost model can be used for classification and regression tasks however in this study we used adaboost r2 algorithm for regression drucker 1997 in python environment using anaconda software platform 2 3 proposed method in machine learning models the generalization ability is as important as the prediction accuracy during the training testing process to evaluate the model suitability for simulation purposes however the over fitting problem can be resolved by tuning the ml models during the training process selecting the informative and causal features and or using the data augmentation method when the dataset is small the objective of this method is to improve the generalization ability and the performances of the prediction model using virtual samples generated from a small dataset in this sub section we introduce the proposed methodology developed in detail starting from the selection of the informative features development of an initial ml model and virtual sample generation and then the training process of adaboost models with the cumulative of the combined virtual and original datasets 2 3 1 data analysis and feature selections an exploratory data analysis eda was carried out to investigate the relationship between all variables using the original data collected from twenty river reaches and their importance for modelling the faecal coliforms in the rivers the selection of the informative variables for developing ml to model complex systems is a crucial step to have a good generalization ability of the models indeed using separate and more important variables improves the prediction accuracy and the generalization ability of the models kuhn and johnson 2019 in this study the selection process was carried out by the evaluation of the variable ranks using the relieff algorithm to select the feature importance kira and rendell 1992 and correlation matrix analysis based on the eda the most important input features were selected 2 3 2 developing an integrated method considering dn as a small arbitrary training dataset n 50 dn xi yi i 1 2 3 n xi xi1 xi2 xi3 xip t is the i th row of matrix inputs and yi yi1 yi2 yi3 yiq t is the i th row of the output vectors q 1 for regression the original small data dn is randomly divided into two sub datasets training dataset dtrain xi yi i 1 2 3 ntrain and testing dataset dtest xi yi i 1 2 3 ntes t in general directly using the dtrain for developing an ml model provides unacceptable performances for simulation due to the over fitting problem and the low generalization ability therefore a virtual sample generation vsg is required to overcome this challenge for enhancing the prediction accuracy of the model to achieve this 600 gaussian noises were calculated from a standard normal distribution and randomly assigned to the input variables of the training dataset dtrain arslan et al 2019 yang et al 2011 although this method is easy for generating the virtual input data it is limited to sampling appropriate virtual output data directly especially for regression problems with high input variables generally the virtual output data for regression tasks are calculated by the initial prediction model trained by the original small training dataset chen et al 2017 he et al 2018 xu et al 2020a 2020b although the baseline model is fragile and not generalizable it has a partial capability to predict appropriate virtual output data indeed to generate the appropriate virtual output li and lin 2006 and li and wen 2014 have suggested the predicting ml model baseline model with mean absolute percentage error mape less than 10 however what about if the performances of the initial model are weak this may affect the sampling process for the generation of the appropriate virtual output and therefore the final model performances to overcome this issue we attempt to develop and explore a new methodology by an integration of the ml model progressively in the calculation of the virtual output variables to improve the prediction accuracy of the ml models in other words the proposed method consists of generating a number of sub samples of input output virtual data that are used for progressive training of the models through several stages rather than one global virtual sample that is directly used for developing the final model hence the initial adaboost model ml0 is trained and evaluated using 75 dtrain and 25 dtest of the original dataset for training and testing processes respectively besides we used the cross validation method to enhance the generalisation ability of the model during the training process then the model is used to calculate the virtual outputs associated with the first sub group inputs the combined data is used for training a new model that is used to calculate the second virtual outputs and so on the proposed method can be summarized as follow step 1 train and evaluate the initial adaboost model ml0 basing on the original training dataset dtrain and dtest respectively step 2 generate random gaussian noises and calculate the virtual input data by adding randomly the noises to the original inputs xip as given by following equation 7 x vipj x ip ε ipj i 1 2 3 n train however to generate nv row of virtual samples it should repeat this step using the eq 7 for nv ntrain times as for the first time in generating the virtual input variables the i th row of virtual matrix inputs is xvi xvi1 xvi2 xvi3 xvip t where j 1 2 3 nv and xvip is the virtual input data corresponded to the original variable xip and ε ip is the gaussian noise assigned randomly to the variable xip in this research we generated nv 600 virtual samples xvj xvj1 xvj2 xvj3 xvjp t i 1 2 3 600 then the xvi is divided into 12 sub groups of virtual input variables noted that xv50 k k 1 2 3 12 are sub groups with similar size of 50 rows of virtual input data this operation was carried out to improve the model progressively rather than using only one step as it useful to reduce the vulnerability of the baseline model mape more than 10 for generating output data besides this procedure is valuable to evaluate the effect of the virtual samples on the model performance however the number of sub group can be determined by trial procedure step 3 obtain the virtual output data yv50 1 corresponded to the virtual input of sub group xv50 1 using the initial ml0 model according to the equation 8 we have therefore the first sample of virtual pair input output data dv1 8 y v 50 1 f ml 0 x v 50 1 step 4 form synthetic data dsyn1 by combining the original dataset dtrain and dv1 and train a new adaboost ml1 model thereby the virtual output yv50 2 corresponded to the virtual input of sub group xv50 2 is calculated and so on hence the 3th and 4th steps are repeated iteratively where the cumulative data dtrain and dvi 1 are combined dsyn i and used for training a new adaboost model mli step 5 stop step 4 if the good prediction accuracy and or stability of the mli models are is checked based on the above description and analysis using this method can progressively avoid the effects of the low performances of the initial model on the calculation of the appropriate virtual output variable and consequently the combination of the observed and virtual data will enhance the prediction accuracy along with the training steps to that end at each step the model mli is evaluated by a testing procedure using the testing dataset dtest however fig 2 shows the flowchart of the developed method 2 3 3 evaluation the efficiency of the proposed method was evaluated by six statistical parameters namely root mean square error rmse mean absolute error mae mean absolute percentage error mape coefficient of determination r 2 generalization ability ga yoon et al 2011 and error improving rate eir chen et al 2017 the computing equations are as follow 9 rmse y i y i 2 n 10 mape 100 n y i y i y i 11 mae 1 n y i y i where yi is the observed value y i is the predicted value n is the sample number considered generally the generalization ability is considered the most crucial challenge to evaluate the suitability of a machine model for simulation purposes therefore at each step the ga and eir were evaluated to assess the influence of the virtual data on the prediction accuracy of the developed model and the efficiency of the proposed method to overcome the small dataset limitation sequentially these evaluation metrics are given by eqs 12 and 13 the ga values of about 1 indicate the model is generalizable valuable and suitable for forecasting and simulation purposes however if ga is higher than unity indicating that the model is over fitted while if it is less than unity the model is undertrained 12 ga rmse validation rmse training 13 eir mape before mape after mape before 100 3 result and discussions 3 1 exploratory data analysis fig 3 a presents the spearman correlation matrix of all used variables this figure shows that the do relatively is well correlated with cod bod tp and ln fc parameters with negative r 0 74 0 74 0 85 and 0 65 respectively also the ln fc positively is correlated with tp bod and cod parameters meanwhile the cod parameter is correlated with bod and tp parameters with positive r 0 99 and 0 80 respectively regarding the other variables they generally presented a coefficient of correlation of less than 0 50 in absolute value fig 3b presents the relieff scores of all variables this figure shows that the tp faecal coliform at upstream boundary conditions ln fci and do parameters unanimously were considered as the most important variables with rank ranges from 0 324 to 0 340 for modelling the fc in the rivers meanwhile the climatic factors segment characteristics length and slope organic matter and physical parameters of water quality have a score ranges from 0 266 to 0 104 all the results related to the importance of the features are confirmed by several old and recent studies recently seo et al 2019 have shown the relationships between the faecal coliform and the do phosphorus matter organic ec and tss in the river water besides sinaga et al 2016 found that faecal coliform growth depends positively on the phosphorus in the water as for the climatic features their effects on faecal contamination in rivers and watersheds have been investigated and reinforced by several studies islam et al 2017 xu et al 2019 importantly sinton et al 2002 and šolić and krstulović 1992 found that solar radiation is a determinant factor controlling the survival rates of the faecal coliform in the freshwater and seawater respectively concerning the faecal coliform concentration at upstream boundaries fci gao et al 2015 showed that it is a determinant factor that controls the distribution of the faecal bacteria downstream besides the slope and length of the river segment are evaluated as important features for modelling faecal contamination as a decrease or increase in the river slope decreases or increases the faecal concentration in the water by the suspension re suspension effect however based on the relieff scores and spearman correlation matrix it was observed that there is no significant difference between the rank values of the cod and bod variables besides these variables are highly correlated consequently we can delete the bod parameter from the input variable vectors for predicting faecal contamination in the rivers 3 2 evaluation of the model on small dataset problem to examine the modelling feasibility of the river responses to the faecal contamination using an ml model with a small dataset the adaboost model performances were evaluated using the original data of 40 samples 30 samples were used for the training testing process with k fold cross validation cv 5 while the remained data was used for validation and generalization ability evaluation the tuning process of the model was carried out through the trial procedure during the training phase by changing the cv 2 5 and 10 estimator number and the learning rate the selected hyper parameters and functions for best model performances were learning rate lr 0 1 estimator number 50 and square as the loss function table 2 presents the initial adaboost model performances for the training and validation phases this table shows that the adaboost model provided high performances during training phase with r2 0 98 rmse 0 605ln cfu 100ml mape 4 and mae 0 2701ln cfu 100 ml meanwhile as for the validation process the model relatively presented moderate performances with r2 0 48 rmse 2 348ln cfu 100 ml mape 16 and mae 1 604ln cfu 100 ml for a data range from 14 65 to 5 07ln cfu 100 ml these results presented in table 2 show that the model is under trained and has a low generalization ability with ga 3 88 as it is observed important discrepancies between the performance results during the training and validation processes yoon et al 2011 fig 4 illustrates the scatter plot of the observed and simulated ln fc values from this figure it was observed an important discrepancy between the observed and simulated values for the outlier values since the used statistical performances are sensitive to the extreme values it could be valuable to investigate the effects of the outlier values on the prediction accuracy therefore the model performances were evaluated after removing the outlier values of the ln fc more than 10 ln cfu 100 ml 1 from the validation dataset the r2 and rmse were slightly improved to 0 62 and 2 27ln cfu 100 ml 1 respectively meanwhile the removal of the outlier values from the training dataset does not show any improvement in the prediction accuracy however these investigations confirmed that the initial model ml0 still presented worst performances during the validation process compared to those for the training phase and therefore it is not useful for prediction purposes of the faecal coliform in the rivers this imbalanced accuracy is due to the over fitting problem caused by the small data size used for training besides the mape value was evaluated by about 16 such a result is not in agreement with the suggestions of li and lin 2006 and li and wen 2014 to generate the appropriate virtual output variable consequently the proposed method can be valuable to enhance the prediction accuracy by the training process of model series using the cumulative of the combined virtual and original dataset 3 3 integrated method performance results in order to further evaluate and compare the proposed integrated method performances in improving the prediction accuracy and the generalization ability of the adaboost model for predicting the faecal coliform in rivers the 13 models were trained and run using dtrain and cumulative virtual dataset following the steps of the method described above at each run and testing process the r 2 rmse mae ga and eir were evaluated besides the effects of the virtual data size on these indicators were evaluated during the training process of the adaboost models with the new data we select similar parameters and cross validation procedure cv 5 estimator number 50 and learning rate 0 1 used in the initial model ml0 development where the tuning process did not improve the model performances table 3 presents the maximum mean and minimum of the performances of the trained adaboost models with the combined dataset during the training and validation processes it is observed a significant improvement of the prediction accuracy between the initial model ml0 and the models re trained by a combined data after adding gaussian noises with r 2 ranges from 0 548 to 0 952 during the validation process compared to 0 48 for the baseline model results importantly these results demonstrate that the proposed method is valuable to augment the small original dataset in order to improve the machine learning model performance however generating large virtual samples can affect model performances as well as the calculation cost macallister et al 2020 therefore there is a crucial need to determine an optimal range of virtual datasets for model accuracy and stability to explore how the cumulative virtual samples affect the adaboost model results we calculate the performances at each step of the developed approach fig 5 illustrates the performances rmse mae and r2 of the adaboost models for different cumulative virtual samples during training and validation processes during the training process it was observed that for the first use of the virtual sample of size up to 50 the performances are decreased compared to the baseline results r2 from 0 98 to 0 83 rmse from 0 605 to 1 821ln cfu 100 ml 1 and mae from 0 270 to 0 892ln cfu 100 ml 1 fig 5a however after this step the performances are progressively improved with slight fluctuations and then they stabilised about the initial model performances furthermore the trend line analysis shows that the performance indicators of the adaboost models linearly increase with an increase in the virtual dataset for the training phase fig 5a with r2 values of about 0 37 0 42 and 0 54 for r2 rmse and mae respectively this indicates that the virtual data size has not any negative influence on the model performances during the training process as for the validation phase fig 5b shows a significant improvement in the prediction accuracy of the models retrained by cumulative virtual samples however a noticeable fluctuation of the model accuracies was observed along with the virtual data size with the increase of the cumulative virtual samples from 50 to 600 significantly the r2 increased and the maximum of r2 reached 0 952 at 250 virtual datasets table 3 and fig 5b meanwhile the rmse and mae significantly decreased and reached 0 716 and 0 519 ln cfu 100 ml 1 respectively obviously using a virtual dataset of fewer than 100 samples significantly cannot improve the adaboost model performances for predicting the faecal coliform in the rivers from fig 5b it can be seen that the model performances during the validation process depend on the virtual dataset sizes according to polynomial equations of degrees 2 with r2 ranges from 0 62 to 0 70 such results confirm that there is an optimal virtual data size for enhancing ml model performances under a small dataset problem however according to these equations fig 5b the optimal virtual datasets using r2 maximum rmse minimum and mae minimum as objective functions are 400 415 and 337 samples respectively furthermore fig 6 illustrates the generalisation ability ga of the adaboost models and the error improving rate eir of the proposed method for the cumulative virtual datasets that varied from 50 to 600 from this figure it is observed that from 150 to 250 virtual samples the models become more generalizable with a slight fluctuation of ga of about 1 interestingly for the virtual data from 250 to 350 samples the adaboost models presented good ga and prediction accuracy moreover the eir reached 52 at 200 samples with a minimum about of 9 and an average value about of 29 this result is in agreement with chen et al 2017 findings where they found that the average of eir varies from 15 72 to 37 47 for virtual data augmentation from 100 to 400 samples using extreme learning machine model however as shown in figs 5b and 6 we found that when the virtual data reached 400 the adaboost model performances significantly decreased during the validation process and their ga become deteriorated ga about 2 indicating that blindly augmenting limited virtual dataset could not guarantee the improvement of the accuracy this may be due to the fact the calculation and assigning the gaussian noises to the features were conducted randomly and therefore it is likely the virtual samples become redundant additionally as reported by macallister et al 2020 generating too many virtual samples can affect the model results as well as it can dramatically affect the ga also xu et al 2020a xu et al 2020b found that after 28 000 virtual datasets the dnn model results become deteriorated it was observed that there is no agreement of the previous studies about the optimal threshold of the virtual dataset this may be due to the model structures the selected input features and the original data size therefore an optimal balance between the prediction accuracy ga and virtual data size can be identified by the trial and error procedure 3 4 practical implications and limitations the small dataset related to the faecal coliform concentration in the water usually is due to two main reasons first of all insufficient funding sources to get the data that need analysis in the laboratory and second the impossibility to get sufficient data due to the limited numbers of the system to be modelled or the change in the baseline system in this study the developed integrated approach provided new insights in modelling the faecal contamination of the rivers using the adaboost model under small data for example this approach can serve as a powerful tool for predicting the impacts of the new domestic wastewater discharges on the water quality to evaluate the health risk and to define the appropriate measures mitigations the engineers can carry out quite enough measurements of the water along the river and generate a virtual dataset using the developed approach to train and test the adaboost model then they can simulate different faecal contamination scenarios and optimize the depollution strategy globally the developed approach can enhance the modelling studies of the faecal contamination of the rivers using ml models and therefore overcome some drawbacks of the process based models however it should be noted that the virtual data augmentation using the proposed method or the others does not guarantee the consistent enhancement of the ml model performances particularly if the modellers use non causal input variables specifically the prediction accuracy and the generalization ability of ml models depend not only on the dataset size but more on the informative input variables kuhn and johnson 2019 hence selecting the causal and important inputs that contribute to the physical process to be modelled is a crucial phase while developing ml models in this study we used most of the causal variables controlling the fc in the rivers however the river discharge and the groundwater interaction information which are important factors for predicting the fc concentrations in the rivers are not included in this study due to the missing of detailed data during the critical periods these factors should be considered while developing future models because it is likely they would improve the prediction accuracy 4 conclusion and further research paths to resolve the shortage of data limitation in applying the ml models we developed and integrated gaussian noise based data augmentation and the adaboost model to generate virtual data for the enhancement of the prediction accuracy of faecal coliform in the rivers the results showed that the generated virtual data using the proposed method have significantly improved the accuracy and the generalization ability of the forecasting adaboost model compared to the baseline results to sum up the methodology developed is a powerful and suitable tool for predicting faecal coliform contaminations using the adaboost ml model with a small dataset it could be an effective tool to enlarge the application of machine learning models and to overcome the small data issue in this study the proposed method was checked only by the adaboost model therefore future works could focus on the exploration of other ml models using the developed method while dealing with the small data problem thus further investigations should be carried out to confirm and evaluate the proposed method for modelling the fc under different conditions and input dataset availability besides the application of the data augmentation methods in environmental sciences could be valuable in the application of ml models when sufficient data is impossible to get it furthermore the optimal virtual data size is determined by the trial error method so far so it is required to optimize the method for determining the optimal range of virtual data to improve the prediction accuracy of ml models on the small sample problem credit authorship contribution statement ali el bilali writing original draft conceptualization visualization formal analysis abdeslam taleb supervision writing review editing formal analysis moulay abdellah bahlaoui writing review editing supervision youssef brouziyne writing review editing formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research is supported by the river basin agency of bouregrge and chaouia in morocco by providing the required data data availability all used data and materials are available on request 
4481,machine learning ml techniques can be valuable for modelling the faecal contamination in the rivers to overcome the limitations of the process based models however this approach requires large sufficient data for training and validation processes to avoid the over fitting problem this study attempts to overcome the small dataset limitation by relying on the data augmentation techniques to that end adaptive boosting adaboost models were trained and integrated into the data augmentation method to generate 600 virtual samples based on 40 original datasets the results revealed that the proposed method significantly improved the accuracy rmse 0 716ln colony forming unit cfu 100 ml and generalization ability of the adaboost model for predicting the faecal coliform in the rivers compared to the baseline model developed only with a small dataset rmse 2 348ln cfu 100 ml however the study showed that generating and using too many virtual data could deteriorate the generalization ability of the ml model and the optimal virtual datasets are about 337 415 virtual samples globally the results of this study provide new insights to improve the prediction accuracy of the health risk related to the faecal coliforms in raw water used for drinking purposes under a small dataset the developed method can broaden the application of ml to water resources and environmental sciences when it is impossible to get a large dataset required by ml models keywords faecal coliform rivers adaboost model data augmentation prediction accuracy generalization ability 1 introduction the outbreak of the coronavirus disease in 2019 across the world makes microbial pollution an interesting topic for research worldwide the microbial water pollution is commonly evaluated by faecal indicator bacteria fib including faecal coliforms fc such as escherichia coli and faecal streptococci fs such as enterococcus feacalis although these indicators do not confirm the presence of the pathogenic organisms in the water they are considered as the main proxies in evaluating the microbial water standards pachepsky et al 2016 pachepsky and shelton 2011 senkbeil et al 2019 wen et al 2020 these indicators have been considered a suitable indicator for evaluating the risk of microbial pollution in water resources singh et al 2020 uprety et al 2020 accordingly a higher concentration of the fib in the water resources indicates a low hygiene quality of the aquatic environment and therefore a high risk to human health when the water is used for drinking recreation irrigation and fishing purposes besides several international organizations such as the world health organisation who the european environment agency eea and the national health and medical research council nhmrc of australia use the fc as one of the drinking water quality indices faecal contamination of the water resources is caused by agricultural runoff sewage and human and animal faeces holcomb et al 2020 khan et al 2018 wu 2019 therefore predicting and evaluating the fc at watershed and stream scales is crucial to assess and manage the health risk related to the pathogen pollution of the water sources for this purpose understanding various combinations of the factors fate and transport processes has led to the development of process based models that are capable to simulate the responses of the hydro aquatic systems to microbial pollution the soil and water assessment tool swat and hydrological simulation program fortran hspf are the main watershed based models largely used in modelling the fc transport and fate cho et al 2016 yagow et al 2013 kim et al 2014 niazi et al 2015 pandey et al 2016 rolle et al 2012 although the watershed based models can be fruitful tools in predicting the faecal contamination of the water resources their limitations were reviewed by benham et al 2006 and oliver et al 2009 specifically the data availability is one of the limitations in the wide application of the watershed based models because of the high cost for the analysing and sampling protocols besides these models need a continuous time series of data for calibration and validation processes meanwhile there is often a mismatch between the objectives of the water quality monitoring data and of those required for building these models particularly in developing countries additionally several process based models have been developed based on the biological adsorption sedimentation re suspension advection and dispersion processes to predict the faecal contamination in the stream and river systems bai and lung 2005 jamieson et al 2005 steets and holden 2003 wilkinson et al 1995 these models need a large number of parameters and data that can be the main source of the uncertainties for this reason it is challenging to predict the faecal contamination of the water sources with this approach under missing data moreover the literature shows that there are few applications in modelling the response of the river responses to faecal contamination using this approach indeed the response of the rivers to faecal contamination is typically non linear and highly complex as it depends on the weather environmental morphological conditions of the river and watershed scales zhang et al 2020 to overcome the limitation of the process based models the machine learning models could be powerful tools for predicting the responses of the river to the microbial pollution and thereby improving the accurate prediction of the fc in the rivers machine learning ml models are divided into two groups supervised and unsupervised the first group includes methods that can be useful for classification and regression problems according to the type of input and output variables indeed the supervised models rely on the training and validation processes using the archived data rather than the explanation of the mechanism of the processes that affect the fate and transport of the fc in the water and consequently they could be valuable for the areas with poor data in some cases there is a need to evaluate the magnitude of the faecal contamination to manage the health risk and to protect the water bodies rather than to understand its process the selection of the appropriate regression or classification ml models generally is based on the objective of the study the regression models numerically predict the real value of the water quality index while the classification ones directly predict the class or the status of the water resources according to a categorization chen et al 2020a regarding the prediction of the fib in the water mohammed et al 2018 applied and compared the random forest adaptive neuro fuzzy inference system anfis and non linear zero inflated models to predict the fib in the raw water intake for drinking purposes in norway choi and seo 2018 used classification models to predict the fc level in the north han river south korea however artificial neural network ann and genetic algorithm approaches have been investigated and showed being a powerful tool in predicting the fc concentration in water bodies duvvuri and anmala 2019 sbahi et al 2020 tufail et al 2008 wang and deng 2019 zhang et al 2015 ensemble learning techniques are powerful ml models that can be applied to either classification or regression problems as they are capable to model complex systems with high dimensions zhang and ma 2012 these methods showed being more accurate ml models compared to traditional statistical methods in water resource studies chen et al 2020b martínez santos and renard 2019 the most popular ensemble ml models is adaptive boosting adaboost model freund and schapire 1996 this bosting method generates base models weak learners iteratively using observation weights where the prediction model is constructed from a combination of base models however the adaboost model for regression drucker 1997 has been applied and showed its superiority compared to other ml models in different research fields for instance zhao et al 2013 found that the adaboost is better than the support vector regression svr and ann models in predicting the short term ionospheric walker and jiang 2019 applied the adaboost model for the prediction of demand driven acquisition and found that it is highly accurate than the linear regression model saghafi and arabloo 2017 demonstrated that the adaboost model provided high prediction accuracy for modelling the co2 solubility compared to the ann and svr models recently el bilali and taleb 2020 and el bilali et al 2020a found that this model has provided good performances in predicting the irrigation water quality parameters with high prediction accuracy compared to random forest ann and svr models these studies justify the need to consider this model for predicting the faecal coliform in rivers under a small dataset problem overall the literature shows that there is little focus on the prediction of microbial water quality using ml models this may be due to the commonly known issue that the ml models require big archived data for development procedures to overcome this issue in ml techniques the researchers have developed and designed several data augmentation methods to improve the prediction accuracy of the ml models even with a small dataset these approaches are categorised as follow 1 the feature extraction based approach 2 accumulating generator operator ago that based on the gray theory e g box gray model 1 1 bgm 1 1 chang et al 2015 gray bootstrap method wang et al 2014 and 3 virtual sample generation vsg approach niyogi et al 1998 that includes several methods abdul lateh et al 2017 arslan et al 2019 chen et al 2017 he et al 2018 interestingly all these methods have been applied and showed that the virtual samples improve the performances of the prediction model compared to the baseline model using the original data however their applicability and strengths differ from one field to another and from one task to another indeed the feature extraction based method is suitable for medicine studies to reducing the dimensionality of data with missing observations espezua et al 2015 zhang et al 2019 nevertheless the ago and vsg approaches are outstanding and popular technologies for generating virtual data for regression tasks chen et al 2017 he et al 2018 wang et al 2014 indeed the application of these methods is limited for industrial and medicines fields so far however some studies applied data augmentation methods and showed being a new insight into environmental studies for instance xu et al 2020a xu et al 2020b developed random standard deviation sampling rsds and dnn models and showed a good improvement of the forecasting model by generating 20 000 virtual samples and developing dnn models with 16 layers and 100 neurons in hidden layers xu et al 2020a xu et al 2020b developed a predictive model to evaluate the water quality for recreation purposes based on artificial datasets and classification ml models these methods have been applied and assessed for the dataset which is often low with fewer than five input variables besides they are complex and do not allow the user to exploit all data obtained from the experiments dataset and are vulnerable to generating inappropriate virtual samples especially for studies with high input variables besides running some methods requires an important time of about 4 min because of the big virtual data generation however the data augmentation approach is under exploration and could be improved by research worldwide and therefore there is a need to explore and assess this approach for different fields using fast computation tools with reasonable virtual data in this paper we attempt to develop a new data augmentation method to enhance the generalization ability of the adaboost model for regression task with high input variables and to overcome some limitations for generating the appropriate virtual output variables the literature shows that there is a focus on the prediction of fc in beach water rather than freshwater resources additionally there are few studies investigating the ml model for predicting the river response to faecal contamination by wastewater discharges indeed due to the high cost of laboratory analysis and sampling protocol it is not easy to get a large dataset required for ml development particularly for biological indicators in river and stream systems therefore new data augmentation procedures should be developed and investigated to overcome the shortage of data limitation and broaden the application of ml models in modelling hydrological systems this study aims at predicting the river responses to the faecal contamination by evaluating the efficiency of the data augmentation based adaboost model on small dataset circumstances to achieve this we attempt to develop a data augmentation method based on adding gaussian noises to the input variables wherein the adaboost model is embedded to generate a virtual dataset for enhancing the training process to improve the prediction accuracy the overall objective of this study is to evaluate the health risk by predicting the fc concentrations in the raw water mainly caused by wastewater discharges under semi arid conditions to help decision makers implement the appropriate river restoration strategies in the bouregreg watershed morocco this objective can be carried out by developing and investigating a predictive adaboost model for modelling the river responses to the faecal contaminations based on the data augmentation method 2 methods and materials 2 1 case study 2 1 1 study area the study area is the downstream part of the bouregreg watershed and is located in the northwest of morocco this watershed is the main water resource for drinking purposes with an annual average of 200 mm3 this water is mobilized by the reservoir of the sidi mohammed ben abdellah smba dam located a few kilometres from the outlet of the watershed however this reservoir is confronting several problems including sedimentation with annual 3 65 mm3 el bilali et al 2020b as well as water pollution mainly caused by wastewater discharges indeed domestic wastewater discharges upstream of the reservoir significantly increase the public health risk related to drinking and recreation purposes during critical periods therefore modelling the fc transport throughout the main river reaches can be valuable for the evaluation of the magnitude of the faecal contamination to manage the risk for this purpose the case study aims at predicting the river responses to the faecal contamination caused by domestic wastewater discharges fig 1 presents the study area location and the wastewater discharges as well as the used monitoring stations 2 1 2 data collection machine learning development requires observed data for training and validation processes to that end as presented in fig 1 twenty three monitoring stations were used for sampling and analysing during the two periods february 1 to 15 2018 and august 1 to 13 2018 a total of 40 samples from the monitoring stations fig 2 are collected the ph hanna hi 2211 electrical conductivity ec hanna hi 8633 and dissolved oxygen do hach 2100q are measured and recorded in situ using the portable multiparameter instrument meanwhile biological oxygen demand bod chemical oxygen demand cod total suspended solid tss total phosphorus tp and fc parameters are measured and analysed in the laboratory the bod was determined by the monomeric method with a respirometer types wtw according to the afnor standard nf t90 103 the cod was determined by the dichromate open reflux method according to the afnor standards nf t90 101 the total suspended solids tss were identified by filtration whatman circular filters of 47 mm in diameter and 0 45 μm of porosity according to french standard methods afnor 2005 t90 105 for bacteriological analysis samples were taken in strict aseptic techniques to prevent any accidental contamination each sample was made ready in sterile flasks collected samples were stored in a cooler 4 c and then transmitted to the laboratory on the same day for analysis they were analysed by the membrane filtration mf method risica and grande 2000 indeed the european drinking water directive 98 83 ec 1998 defines reference methods for the enumeration of microbiological parameters in drinking water the method defined for enumeration of faecal coliforms and e coli is mf on lactose ttc agar with tergitol 7 chapman 1951 as described in iso 9308 1 2000 filtration devices were treated by using a burner to ensure proper sterilization and to prevent cross contamination among samples for the detection and enumeration of faecal coliforms fc 100 ml of each sample are filtered throughout a 0 45 μm membrane filter and then the filters were transferred to ttc tergitol 7 agar plates after an incubation period at 44 5 0 2 c for 18 24 h the yellow and or violet colonies with yellow halo were counted as fc results were expressed by colony forming units cfu per 100 ml of sample the weather data are provided by the river basin agency of bouregreg and chaouia these data include the air temperature ta relative humidity rh and solar radiation h all these parameters are measured at the hydro metrological station at the smba reservoir in this study we introduced the data of the river reach characteristics namely length l in km slop s and the percentage of the river segment length that crosses the forest and or the matorral areas lfs the last parameter was selected based on the presence of the pastoral activities in the forest and in matorral areas adjacent to the rivers that can be a nonpoint source of faecal contamination caused by the animal faeces table 1 presents the statistical characteristics minimum maximum mean and standard deviation sd of the 40 samples used in this study 2 2 adaptive boosting adaboost model adaptive boosting adaboost is an ensemble machine learning model it is a tree based model that is introduced by freund and schapire 1997 for a system dataset s xi yi i 1 2 3 n where each xi is in some instance x and each yi is in some label y and for a series of round m the algorithm initializes the distribution d or weight as follow 1 d i 1 1 n f o r i 1 n then for j 1 to m adaboost algorithm builds weak models or learners hj from the training dataset using d that minimizes ε j and satisfies ε j 0 5 conditions ε j is a weighted error of the jth model and is given by eq 2 2 ε j i h j x i y i d i j the weight confidence αj of the jth model is calculated by eq 3 3 α j 1 2 ln 1 ε j ε j the distributions for next iteration were updated as follow 3 d i j 1 e y i h j x i α j d i j 4 d i j 1 d i j 1 i 1 n d i j 1 the prediction for new dataset is achieved by the weighted average of the models hj as follow 6 h x j m α j h j x the adaboost model can be used for classification and regression tasks however in this study we used adaboost r2 algorithm for regression drucker 1997 in python environment using anaconda software platform 2 3 proposed method in machine learning models the generalization ability is as important as the prediction accuracy during the training testing process to evaluate the model suitability for simulation purposes however the over fitting problem can be resolved by tuning the ml models during the training process selecting the informative and causal features and or using the data augmentation method when the dataset is small the objective of this method is to improve the generalization ability and the performances of the prediction model using virtual samples generated from a small dataset in this sub section we introduce the proposed methodology developed in detail starting from the selection of the informative features development of an initial ml model and virtual sample generation and then the training process of adaboost models with the cumulative of the combined virtual and original datasets 2 3 1 data analysis and feature selections an exploratory data analysis eda was carried out to investigate the relationship between all variables using the original data collected from twenty river reaches and their importance for modelling the faecal coliforms in the rivers the selection of the informative variables for developing ml to model complex systems is a crucial step to have a good generalization ability of the models indeed using separate and more important variables improves the prediction accuracy and the generalization ability of the models kuhn and johnson 2019 in this study the selection process was carried out by the evaluation of the variable ranks using the relieff algorithm to select the feature importance kira and rendell 1992 and correlation matrix analysis based on the eda the most important input features were selected 2 3 2 developing an integrated method considering dn as a small arbitrary training dataset n 50 dn xi yi i 1 2 3 n xi xi1 xi2 xi3 xip t is the i th row of matrix inputs and yi yi1 yi2 yi3 yiq t is the i th row of the output vectors q 1 for regression the original small data dn is randomly divided into two sub datasets training dataset dtrain xi yi i 1 2 3 ntrain and testing dataset dtest xi yi i 1 2 3 ntes t in general directly using the dtrain for developing an ml model provides unacceptable performances for simulation due to the over fitting problem and the low generalization ability therefore a virtual sample generation vsg is required to overcome this challenge for enhancing the prediction accuracy of the model to achieve this 600 gaussian noises were calculated from a standard normal distribution and randomly assigned to the input variables of the training dataset dtrain arslan et al 2019 yang et al 2011 although this method is easy for generating the virtual input data it is limited to sampling appropriate virtual output data directly especially for regression problems with high input variables generally the virtual output data for regression tasks are calculated by the initial prediction model trained by the original small training dataset chen et al 2017 he et al 2018 xu et al 2020a 2020b although the baseline model is fragile and not generalizable it has a partial capability to predict appropriate virtual output data indeed to generate the appropriate virtual output li and lin 2006 and li and wen 2014 have suggested the predicting ml model baseline model with mean absolute percentage error mape less than 10 however what about if the performances of the initial model are weak this may affect the sampling process for the generation of the appropriate virtual output and therefore the final model performances to overcome this issue we attempt to develop and explore a new methodology by an integration of the ml model progressively in the calculation of the virtual output variables to improve the prediction accuracy of the ml models in other words the proposed method consists of generating a number of sub samples of input output virtual data that are used for progressive training of the models through several stages rather than one global virtual sample that is directly used for developing the final model hence the initial adaboost model ml0 is trained and evaluated using 75 dtrain and 25 dtest of the original dataset for training and testing processes respectively besides we used the cross validation method to enhance the generalisation ability of the model during the training process then the model is used to calculate the virtual outputs associated with the first sub group inputs the combined data is used for training a new model that is used to calculate the second virtual outputs and so on the proposed method can be summarized as follow step 1 train and evaluate the initial adaboost model ml0 basing on the original training dataset dtrain and dtest respectively step 2 generate random gaussian noises and calculate the virtual input data by adding randomly the noises to the original inputs xip as given by following equation 7 x vipj x ip ε ipj i 1 2 3 n train however to generate nv row of virtual samples it should repeat this step using the eq 7 for nv ntrain times as for the first time in generating the virtual input variables the i th row of virtual matrix inputs is xvi xvi1 xvi2 xvi3 xvip t where j 1 2 3 nv and xvip is the virtual input data corresponded to the original variable xip and ε ip is the gaussian noise assigned randomly to the variable xip in this research we generated nv 600 virtual samples xvj xvj1 xvj2 xvj3 xvjp t i 1 2 3 600 then the xvi is divided into 12 sub groups of virtual input variables noted that xv50 k k 1 2 3 12 are sub groups with similar size of 50 rows of virtual input data this operation was carried out to improve the model progressively rather than using only one step as it useful to reduce the vulnerability of the baseline model mape more than 10 for generating output data besides this procedure is valuable to evaluate the effect of the virtual samples on the model performance however the number of sub group can be determined by trial procedure step 3 obtain the virtual output data yv50 1 corresponded to the virtual input of sub group xv50 1 using the initial ml0 model according to the equation 8 we have therefore the first sample of virtual pair input output data dv1 8 y v 50 1 f ml 0 x v 50 1 step 4 form synthetic data dsyn1 by combining the original dataset dtrain and dv1 and train a new adaboost ml1 model thereby the virtual output yv50 2 corresponded to the virtual input of sub group xv50 2 is calculated and so on hence the 3th and 4th steps are repeated iteratively where the cumulative data dtrain and dvi 1 are combined dsyn i and used for training a new adaboost model mli step 5 stop step 4 if the good prediction accuracy and or stability of the mli models are is checked based on the above description and analysis using this method can progressively avoid the effects of the low performances of the initial model on the calculation of the appropriate virtual output variable and consequently the combination of the observed and virtual data will enhance the prediction accuracy along with the training steps to that end at each step the model mli is evaluated by a testing procedure using the testing dataset dtest however fig 2 shows the flowchart of the developed method 2 3 3 evaluation the efficiency of the proposed method was evaluated by six statistical parameters namely root mean square error rmse mean absolute error mae mean absolute percentage error mape coefficient of determination r 2 generalization ability ga yoon et al 2011 and error improving rate eir chen et al 2017 the computing equations are as follow 9 rmse y i y i 2 n 10 mape 100 n y i y i y i 11 mae 1 n y i y i where yi is the observed value y i is the predicted value n is the sample number considered generally the generalization ability is considered the most crucial challenge to evaluate the suitability of a machine model for simulation purposes therefore at each step the ga and eir were evaluated to assess the influence of the virtual data on the prediction accuracy of the developed model and the efficiency of the proposed method to overcome the small dataset limitation sequentially these evaluation metrics are given by eqs 12 and 13 the ga values of about 1 indicate the model is generalizable valuable and suitable for forecasting and simulation purposes however if ga is higher than unity indicating that the model is over fitted while if it is less than unity the model is undertrained 12 ga rmse validation rmse training 13 eir mape before mape after mape before 100 3 result and discussions 3 1 exploratory data analysis fig 3 a presents the spearman correlation matrix of all used variables this figure shows that the do relatively is well correlated with cod bod tp and ln fc parameters with negative r 0 74 0 74 0 85 and 0 65 respectively also the ln fc positively is correlated with tp bod and cod parameters meanwhile the cod parameter is correlated with bod and tp parameters with positive r 0 99 and 0 80 respectively regarding the other variables they generally presented a coefficient of correlation of less than 0 50 in absolute value fig 3b presents the relieff scores of all variables this figure shows that the tp faecal coliform at upstream boundary conditions ln fci and do parameters unanimously were considered as the most important variables with rank ranges from 0 324 to 0 340 for modelling the fc in the rivers meanwhile the climatic factors segment characteristics length and slope organic matter and physical parameters of water quality have a score ranges from 0 266 to 0 104 all the results related to the importance of the features are confirmed by several old and recent studies recently seo et al 2019 have shown the relationships between the faecal coliform and the do phosphorus matter organic ec and tss in the river water besides sinaga et al 2016 found that faecal coliform growth depends positively on the phosphorus in the water as for the climatic features their effects on faecal contamination in rivers and watersheds have been investigated and reinforced by several studies islam et al 2017 xu et al 2019 importantly sinton et al 2002 and šolić and krstulović 1992 found that solar radiation is a determinant factor controlling the survival rates of the faecal coliform in the freshwater and seawater respectively concerning the faecal coliform concentration at upstream boundaries fci gao et al 2015 showed that it is a determinant factor that controls the distribution of the faecal bacteria downstream besides the slope and length of the river segment are evaluated as important features for modelling faecal contamination as a decrease or increase in the river slope decreases or increases the faecal concentration in the water by the suspension re suspension effect however based on the relieff scores and spearman correlation matrix it was observed that there is no significant difference between the rank values of the cod and bod variables besides these variables are highly correlated consequently we can delete the bod parameter from the input variable vectors for predicting faecal contamination in the rivers 3 2 evaluation of the model on small dataset problem to examine the modelling feasibility of the river responses to the faecal contamination using an ml model with a small dataset the adaboost model performances were evaluated using the original data of 40 samples 30 samples were used for the training testing process with k fold cross validation cv 5 while the remained data was used for validation and generalization ability evaluation the tuning process of the model was carried out through the trial procedure during the training phase by changing the cv 2 5 and 10 estimator number and the learning rate the selected hyper parameters and functions for best model performances were learning rate lr 0 1 estimator number 50 and square as the loss function table 2 presents the initial adaboost model performances for the training and validation phases this table shows that the adaboost model provided high performances during training phase with r2 0 98 rmse 0 605ln cfu 100ml mape 4 and mae 0 2701ln cfu 100 ml meanwhile as for the validation process the model relatively presented moderate performances with r2 0 48 rmse 2 348ln cfu 100 ml mape 16 and mae 1 604ln cfu 100 ml for a data range from 14 65 to 5 07ln cfu 100 ml these results presented in table 2 show that the model is under trained and has a low generalization ability with ga 3 88 as it is observed important discrepancies between the performance results during the training and validation processes yoon et al 2011 fig 4 illustrates the scatter plot of the observed and simulated ln fc values from this figure it was observed an important discrepancy between the observed and simulated values for the outlier values since the used statistical performances are sensitive to the extreme values it could be valuable to investigate the effects of the outlier values on the prediction accuracy therefore the model performances were evaluated after removing the outlier values of the ln fc more than 10 ln cfu 100 ml 1 from the validation dataset the r2 and rmse were slightly improved to 0 62 and 2 27ln cfu 100 ml 1 respectively meanwhile the removal of the outlier values from the training dataset does not show any improvement in the prediction accuracy however these investigations confirmed that the initial model ml0 still presented worst performances during the validation process compared to those for the training phase and therefore it is not useful for prediction purposes of the faecal coliform in the rivers this imbalanced accuracy is due to the over fitting problem caused by the small data size used for training besides the mape value was evaluated by about 16 such a result is not in agreement with the suggestions of li and lin 2006 and li and wen 2014 to generate the appropriate virtual output variable consequently the proposed method can be valuable to enhance the prediction accuracy by the training process of model series using the cumulative of the combined virtual and original dataset 3 3 integrated method performance results in order to further evaluate and compare the proposed integrated method performances in improving the prediction accuracy and the generalization ability of the adaboost model for predicting the faecal coliform in rivers the 13 models were trained and run using dtrain and cumulative virtual dataset following the steps of the method described above at each run and testing process the r 2 rmse mae ga and eir were evaluated besides the effects of the virtual data size on these indicators were evaluated during the training process of the adaboost models with the new data we select similar parameters and cross validation procedure cv 5 estimator number 50 and learning rate 0 1 used in the initial model ml0 development where the tuning process did not improve the model performances table 3 presents the maximum mean and minimum of the performances of the trained adaboost models with the combined dataset during the training and validation processes it is observed a significant improvement of the prediction accuracy between the initial model ml0 and the models re trained by a combined data after adding gaussian noises with r 2 ranges from 0 548 to 0 952 during the validation process compared to 0 48 for the baseline model results importantly these results demonstrate that the proposed method is valuable to augment the small original dataset in order to improve the machine learning model performance however generating large virtual samples can affect model performances as well as the calculation cost macallister et al 2020 therefore there is a crucial need to determine an optimal range of virtual datasets for model accuracy and stability to explore how the cumulative virtual samples affect the adaboost model results we calculate the performances at each step of the developed approach fig 5 illustrates the performances rmse mae and r2 of the adaboost models for different cumulative virtual samples during training and validation processes during the training process it was observed that for the first use of the virtual sample of size up to 50 the performances are decreased compared to the baseline results r2 from 0 98 to 0 83 rmse from 0 605 to 1 821ln cfu 100 ml 1 and mae from 0 270 to 0 892ln cfu 100 ml 1 fig 5a however after this step the performances are progressively improved with slight fluctuations and then they stabilised about the initial model performances furthermore the trend line analysis shows that the performance indicators of the adaboost models linearly increase with an increase in the virtual dataset for the training phase fig 5a with r2 values of about 0 37 0 42 and 0 54 for r2 rmse and mae respectively this indicates that the virtual data size has not any negative influence on the model performances during the training process as for the validation phase fig 5b shows a significant improvement in the prediction accuracy of the models retrained by cumulative virtual samples however a noticeable fluctuation of the model accuracies was observed along with the virtual data size with the increase of the cumulative virtual samples from 50 to 600 significantly the r2 increased and the maximum of r2 reached 0 952 at 250 virtual datasets table 3 and fig 5b meanwhile the rmse and mae significantly decreased and reached 0 716 and 0 519 ln cfu 100 ml 1 respectively obviously using a virtual dataset of fewer than 100 samples significantly cannot improve the adaboost model performances for predicting the faecal coliform in the rivers from fig 5b it can be seen that the model performances during the validation process depend on the virtual dataset sizes according to polynomial equations of degrees 2 with r2 ranges from 0 62 to 0 70 such results confirm that there is an optimal virtual data size for enhancing ml model performances under a small dataset problem however according to these equations fig 5b the optimal virtual datasets using r2 maximum rmse minimum and mae minimum as objective functions are 400 415 and 337 samples respectively furthermore fig 6 illustrates the generalisation ability ga of the adaboost models and the error improving rate eir of the proposed method for the cumulative virtual datasets that varied from 50 to 600 from this figure it is observed that from 150 to 250 virtual samples the models become more generalizable with a slight fluctuation of ga of about 1 interestingly for the virtual data from 250 to 350 samples the adaboost models presented good ga and prediction accuracy moreover the eir reached 52 at 200 samples with a minimum about of 9 and an average value about of 29 this result is in agreement with chen et al 2017 findings where they found that the average of eir varies from 15 72 to 37 47 for virtual data augmentation from 100 to 400 samples using extreme learning machine model however as shown in figs 5b and 6 we found that when the virtual data reached 400 the adaboost model performances significantly decreased during the validation process and their ga become deteriorated ga about 2 indicating that blindly augmenting limited virtual dataset could not guarantee the improvement of the accuracy this may be due to the fact the calculation and assigning the gaussian noises to the features were conducted randomly and therefore it is likely the virtual samples become redundant additionally as reported by macallister et al 2020 generating too many virtual samples can affect the model results as well as it can dramatically affect the ga also xu et al 2020a xu et al 2020b found that after 28 000 virtual datasets the dnn model results become deteriorated it was observed that there is no agreement of the previous studies about the optimal threshold of the virtual dataset this may be due to the model structures the selected input features and the original data size therefore an optimal balance between the prediction accuracy ga and virtual data size can be identified by the trial and error procedure 3 4 practical implications and limitations the small dataset related to the faecal coliform concentration in the water usually is due to two main reasons first of all insufficient funding sources to get the data that need analysis in the laboratory and second the impossibility to get sufficient data due to the limited numbers of the system to be modelled or the change in the baseline system in this study the developed integrated approach provided new insights in modelling the faecal contamination of the rivers using the adaboost model under small data for example this approach can serve as a powerful tool for predicting the impacts of the new domestic wastewater discharges on the water quality to evaluate the health risk and to define the appropriate measures mitigations the engineers can carry out quite enough measurements of the water along the river and generate a virtual dataset using the developed approach to train and test the adaboost model then they can simulate different faecal contamination scenarios and optimize the depollution strategy globally the developed approach can enhance the modelling studies of the faecal contamination of the rivers using ml models and therefore overcome some drawbacks of the process based models however it should be noted that the virtual data augmentation using the proposed method or the others does not guarantee the consistent enhancement of the ml model performances particularly if the modellers use non causal input variables specifically the prediction accuracy and the generalization ability of ml models depend not only on the dataset size but more on the informative input variables kuhn and johnson 2019 hence selecting the causal and important inputs that contribute to the physical process to be modelled is a crucial phase while developing ml models in this study we used most of the causal variables controlling the fc in the rivers however the river discharge and the groundwater interaction information which are important factors for predicting the fc concentrations in the rivers are not included in this study due to the missing of detailed data during the critical periods these factors should be considered while developing future models because it is likely they would improve the prediction accuracy 4 conclusion and further research paths to resolve the shortage of data limitation in applying the ml models we developed and integrated gaussian noise based data augmentation and the adaboost model to generate virtual data for the enhancement of the prediction accuracy of faecal coliform in the rivers the results showed that the generated virtual data using the proposed method have significantly improved the accuracy and the generalization ability of the forecasting adaboost model compared to the baseline results to sum up the methodology developed is a powerful and suitable tool for predicting faecal coliform contaminations using the adaboost ml model with a small dataset it could be an effective tool to enlarge the application of machine learning models and to overcome the small data issue in this study the proposed method was checked only by the adaboost model therefore future works could focus on the exploration of other ml models using the developed method while dealing with the small data problem thus further investigations should be carried out to confirm and evaluate the proposed method for modelling the fc under different conditions and input dataset availability besides the application of the data augmentation methods in environmental sciences could be valuable in the application of ml models when sufficient data is impossible to get it furthermore the optimal virtual data size is determined by the trial error method so far so it is required to optimize the method for determining the optimal range of virtual data to improve the prediction accuracy of ml models on the small sample problem credit authorship contribution statement ali el bilali writing original draft conceptualization visualization formal analysis abdeslam taleb supervision writing review editing formal analysis moulay abdellah bahlaoui writing review editing supervision youssef brouziyne writing review editing formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research is supported by the river basin agency of bouregrge and chaouia in morocco by providing the required data data availability all used data and materials are available on request 
4482,limitations in current infiltration modeling approaches hamper the evaluation of the effects of complex rainfall pattern and slope gradient on soil infiltration and runoff in presence of a water table wt although they can markedly alter the hydrologic processes to fill the gap the smith et al 1993 s infiltration model was modified and a modeling framework was then developed to simulate the rainfall infiltration runoff process in presence of a wt the model was tested against experimental infiltration and runoff data at two different constant inflow rates and wt depths good agreements between the modeled and observed results were found in infiltration and runoff rates for two cases the model was evaluated under complex rainfall patterns and the results showed that the model performs well in the infiltration rate and the soil water redistribution predictions with an increasing of slope gradient the decrease of runoff rate tends to become more prominent under steady rainfall pattern but the trend becomes more complicated under complex rainfall patterns the model was compared with hydrus 1d and shallow water table infiltration algorithm swingo and found that both the model and hydrus 1d can well predict the soil infiltration rate and soil water redistribution in presence of a shallow wt for the silt loam sandy loam and clay swingo is likely to overestimate the ponding time and the infiltration rate but underestimate the time to column saturation for clayey soils with a shallow wt the model is expected to produce a more realistic and accurate approach for infiltration and runoff prediction in presence of a wt keywords groundwater level soil water redistribution slope gradient time varying rainfall hydrus 1d swingo 1 introduction the shallow water table wt is a principal feature of lands with shallow aquifers which widely exists in the humid coastal flat areas floodplains near water bodies and soils with limiting horizons resulting in perched wts e g novakowski and gillham 1988 slavich et al 2002 zhang and chui 2017 bhaskar et al 2018 bizhanimanzar et al 2019 capillary effects from a shallow wt result in nonuniform initial soil moisture conditions that are closely associated with the surface and subsurface water sediment and pollutants movement gillham 1984 basha 2011 roldin et al 2013 yao et al 2018 bradley et al 2019 zhang and chui 2019 for instance lauvernet and muñoz carpena 2018 and fox et al 2018 found that the shallow wt significantly affects the performance of vegetative filter strips on water sediment and pesticide reduction thus accurately modeling the soil infiltration process in the shallow wt conditions is important for the hydrology pedology agriculture and environmental sciences the infiltration process with the presence of a shallow wt is very complex which can be affected by a wide variety of factors related to rainfall soil and topography etc shirmohammadi and skaggs 1984 salvucci and entekhabi 1995 basha 2000a 2000b fox et al 2018 muñoz carpena et al 2018 the rainfall pattern is found to play a significant role on soil infiltration in presence of a shallow wt melone et al 2006 flammini et al 2018 for instance a significant variability of rainfall intensity and a frequently rainfall hiatus during the complex rainfall pattern can lead to many redistribution periods of soil water corradini et al 1994 1997 moreover the variation of soil water content profile could be more complicated due to the presence of a shallow wt novakowski and gillham 1988 in addition to rainfall pattern slope gradient as an important topographical feature can affect the infiltration process chen and young 2006 morbidelli et al 2018 philip 1957 wang et al 2018 and the slope together with a shallow wt are widely seen in the riparian areas zhang et al 2017 zhao et al 2018 gomes et al 2019 puntenney desmond et al 2020 comparing to a horizontal surface a slope can directly change the received rainfall volume on the surface the hydraulic head at the wetting front and the spatial variability of shallow wt morbidelli et al 2016 wu et al 2017 first steeper slopes with the same slope length receive a decreased amount of rainfall given that all raindrops fall vertically which can directly affect the infiltration and runoff generation chen and young 2006 second the hydraulic head at the wetting front becomes smaller with an increasing slope gradient and the soil infiltration capacity tends to decrease on steep slopes wu et al 2018 third the wt is usually shallower at downslope than upslope positions this can affect the soil water profile at different slope positions but was usually neglected in previous studies fox et al 2018 despite the significant influence of rainfall pattern and slope on soil infiltration most of the previous infiltration models cannot estimate infiltration in presence of a wt during a complex rainfall event or on a sloping surface for example existing physically based infiltration models e g chen and young 2006 green 1911 philip 1957 smith et al 1993 were derived for a uniform initial soil moisture profile these models are not suitable to describe the infiltration process above a wt when the initial soil water condition is non uniform chu 1997 craig et al 2010 liu et al 2011 lai et al 2015 and muñoz carpena et al 2018 modified the green ampt model to account for the presence of a wt these single event approaches consider the initial soil moisture profile due to the wt based on the equilibrium hydrostatic condition moreover to date the slope gradient is not taken into account in the infiltration models with a shallow wt these models treat all land surfaces as horizontal planes even though surfaces may be inclining chu 1997 craig et al 2010 liu et al 2011 lai et al 2015 muñoz carpena et al 2018 yao et al 2018 the received rainfall amount on the surface and the hydraulic head of wetting front cannot change with slope gradients in majority of models and these may overestimate the soil infiltration rate on steep slopes chen and young 2006 although the richards equation solvers such as the widely used infiltration software package hydrus richards 1931 basha 2000a 2000b 2011 šimůnek and van genuchten 2008 šimůnek et al 2016 can describe infiltration and moisture redistribution in presence of a wt for complex rainfall patterns and different slope gradients they do not have a general analytical solution and its application in real world systems requires intensive computation moreover solving the richards equation is complicated in addition to numerically solving the partial differential equation it also involves representing the soil column with a fine resolution grid assigning proper values to a set of model parameters for each computational grid and determining the boundary and initial conditions such as soil water contents for the entire soil profile which are often difficult to obtain although the soil can be assumed as homogeneous and using the same parameters for all soil layers solving the partial differential equation with dense computational grids may produce errors in mass conservation or even numerical instability e g for coarse soils and highly dynamic boundary conditions vogel et al 2000 seibert et al 2003 alternatively soil infiltration in presence of a wt is often modeled in practical hydrologic models using simpler physically based approaches e g ogden et al 2015 fernández pato et al 2016 muñoz carpena et al 2018 yao et al 2018 bizhanimanzar et al 2019 which have the advantages of less parameters and higher computational efficiency and can be more conveniently applied in large scale models for watershed or regional hydrologic and or other related environmental processes in fact the impacts of complex rainfall pattern and slope gradient were considered in a few physically based infiltration models without the wt for instance smith et al 1993 proposed a conceptual model hereafter called smith corradini melone model or scm model for infiltration and redistribution during storms which was used for hillslope and watershed hydrologic modeling in many studies e g chen et al 2013 2016 dunkerley 2018 wu et al 2019 2020 wu and chen 2020 this conceptual model is further extended to consider complex multiple rainfall events corradini et al 1994 and use the same ordinary differential equation for both infiltration and redistribution corradini et al 1997 for the slope wu et al 2018 quantified and explained the direct physical effects of slope angle on infiltration and runoff generation by extending the scm infiltration equations onto sloping surfaces thus the scm infiltration model was chosen to be modified for presence of a shallow wt the aims of the present study were to 1 extend the scm infiltration solution to soils bounded by a wt with no initial ponding 2 analyze the impacts of rainfall patterns and slope gradient on soil infiltration with a shallow wt and 3 compare the modified scm model with previous models for infiltration prediction in presence of a wt these efforts are expected to produce a more realistic and accurate approach for infiltration and runoff prediction on the slope surfaces with high variability of rainfall intensity 2 modeling approach to simulate the rainfall infiltration runoff process with a shallow wt the modeling approach generally includes two components namely the soil infiltration and runoff modules for the soil infiltration module the scm infiltration model was modified to account for the impact of shallow wt note that the scm infiltration model has been extended by corradini et al 1994 1997 and wu et al 2018 to consider complex rainfall patterns and slope gradient for the runoff module the widely used one dimensional diffusive wave model was chosen to model the overland flow routing process the coordinates and z are defined in the downslope and normal directions the wt is assumed to be parallel with sloping surface 2 1 modification to the scm infiltration model with a shallow wt the capillary effect can substantially affect the initial distribution of the soil water content and ultimately modify the soil infiltration process as shown in fig 1 the soil water initial condition in the model is set to hydrostatic equilibrium with a wt the initial soil water content θ i and soil matric potential ψ are different for different soil depths a linear relationship between soil matric potential and soil depth z positive downwards from the surface is assumed whereby the nonuniform water content of the soil is described by the soil water characteristic curve jury et al 1991 1 θ z i ψ z ψ b 1 λ θ s θ r θ r ψ z z z w where θ z i is the initial soil water content at different soil depths ψ b is the air entry head m θ s is the saturated volumetric water content θ r is the residual volumetric water content λ is empirical coefficient z is the shallow wt depth m and z w is the lowest point in the wetting profile m with the presence of a shallow wt the original method for the cumulative infiltration depth should be modified this is performed by introducing a shape factor η θ 0 i into the mass conservation equation see fig 1 2 i 0 z w θ z θ z i d z θ 0 θ 0 i z w β θ 0 θ z w i θ 0 i z w η θ 0 i where i is the cumulative infiltration depth m θ z is the soil water content at different soil depths θ 0 is the soil water content at the soil surface θ 0 i is the initial soil water content at the soil surface β θ 0 is a shape factor for the moisture profile modified by infiltration η θ 0 i is a shape factor accounting for the initial moisture profile due to the shallow wt which is the major difference with the original model with the shape factor the scm infiltration approach can reflect the soil water profile more accurately than the green ampt model according to smith et al 1993 and corradini et al 1994 1997 β θ 0 is related to both θ 0 and θ 0 i which can be expressed as β θ 0 0 6 θ 0 θ 0 i θ s θ r 0 4 in comparison η θ 0 i is determined by the initial soil water profile above a wt as an equilibrium hydrostatic condition to determine the expression of η θ 0 i we have chosen four typical soils from the manual of hydrus 1d to show the variation of η θ 0 i for different soil types for each soil type the values of η θ 0 i were calculated for 10 different wt depths from 0 1 to 1 0 m because the initial water content profiles are different for different wt depths we found that η θ 0 i shows a linear increase trend with the initial water content of surface soil θ 0 i which can be expressed as η θ 0 i c 1 θ 0 i θ r θ s θ r c 2 for all soil types it suggests that once the soil type i e soil hydraulic properties is determined c 1 and c 2 can be directly determined based on the linear fitting between η θ 0 i and θ 0 i θ r θ s θ r the details about the value of η θ 0 i for different soils can be found in discussion section taking the slope into consideration the infiltration rate i 0 perpendicular to the surface can be expressed as 3 i 0 di dt k z w i cos γ where t is time s k z w i is the initial soil hydraulic conductivity at soil depth z w m s γ is the slope angle the only change on sloping surfaces is to replace k z w i with k z w i cos γ and cos γ reflects the slope effect on the hydraulic head at the wetting front that can change the water content profile along the normal direction differentiation with respect to time and substitution of 2 into 3 lead to 4 i 0 z w β θ 0 d θ 0 dt θ 0 θ 0 i β θ 0 d z w dt θ 0 θ 0 i z w d β θ 0 d θ 0 d θ 0 dt z w η θ 0 i d θ z w i d z w d z w dt θ z w i θ 0 i η θ 0 i d z w dt k z w i cos γ the function β θ 0 may be treated as having a constant slope corradini et al 1997 and we set d β θ 0 d θ 0 σ the second fourth and fifth terms on the right side of 4 represent the profile elongation at a given θ 0 its sum with k z w i gives the downward flux which can be approximated by a depth integrated from q d of the darcy law thus we take 5 q d ψ z w i ψ 0 θ 0 θ 0 i β θ 0 d z w dt z w η θ 0 i d θ z w i d z w θ z w i θ 0 i η θ 0 i d z w dt k z w i cos γ p s z ψ z w ψ 0 k ψ d ψ k 0 cos γ where ψ z w i is the initial capillary head at soil depth z w ψ 0 is the capillary head at soil surface which equals to ψ z 0 k 0 is k θ 0 and p s is a quantity depending on the profile shape and linked with β and η it is evident with different shallow wts the variation of η can directly change the p s and thus affect the downward flux the integral in the last term of eq 5 is the capillary drive g note that with a shallow wt the initial soil water content varies notably with soil depth and the lower bound in integration has been modified to the initial capillary head at soil depth z w 6 g ψ z w i ψ 0 1 k s ψ z w i ψ 0 k ψ d ψ with the above simplifications eqs 4 and 5 are combined and solved for d θ 0 dt 7 d θ 0 dt i 0 k 0 cos γ p s g ψ z w i ψ 0 k s z w z w θ 0 θ 0 i σ β θ 0 since z w i θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i this substitution may be made to obtain 8 d θ 0 dt θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i i θ 0 θ 0 i σ β θ 0 i 0 k 0 cos γ θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i p s g ψ z w i ψ 0 k s i in the eq 8 θ z w i ψ z w i η θ 0 i and p s are closely related to the shallow wt which is the main difference with the original scm infiltration model during a complex pattern rainfall the infiltration and soil water redistribution processes are simulated by the modified scm model as follows corradini et al 1994 1997 for the condition with an unsaturated surface θ 0 θ s i 0 p cos γ and i is initially accumulated from p cos γ where p is the rainfall intensity m s when θ 0 θ s we have d θ 0 dt 0 and we can derive i 0 by eq 8 that represents the infiltration capacity and i accumulates from i 0 after the wetting front approaches the wt see fig 1 we have z w z and ψ i z w 0 i 0 and i can be also derived by eq 8 when the rainfall stops eq 8 with i 0 0 can be used to estimate the decrease of θ 0 with time and the wetted profile redistributes which is one of the major improvements comparing to the model of muñoz carpena et al 2018 similar with chen and young 2006 and wu et al 2018 the use of p cos γ means that a decrease rainfall amount is received on the steep slopes for the vertical rainfall direction following chen et al 2013 the numerical solution of eq 8 was sought by the standard runge kutta fourth order rk4 approach 2 2 overland flow model after obtaining soil infiltration rate by the modified scm model the one dimensional diffusive wave approximation lighthill and whitham 1955 has been applied to simulate overland flow or surface runoff the governing equations can be written as 9 h t q x p cos γ i 0 10 s 0 h s s f 11 q 1 n h 5 3 s f 1 2 where h is the flow depth m t is time s q is the unit flow discharge m2 s i 0 is the infiltration rate through the soil surface m s s 0 is the slope gradient s f is the friction slope s is the flow direction in the coordinate system and n is manning s friction coefficient eqs 9 11 were solved numerically using the finite difference and newton iteration method 2 3 hydrus 1d to evaluate the model effectiveness we compared the simulated results of the modified scm model to those of hydrus 1d that directly solves the richards equation the governing equation of hydrus 1d can be expressed as šimůnek and van genuchten 2008 šimůnek et al 2016 12 θ t k ψ z ψ z cos α where α is the angle between the flow direction and the vertical axis i e α 0 for vertical flow 90 for horizontal flow and 0 less than 90 α for inclined flow in the present study α is equal to the slope angle γ the model parameters boundary and initial conditions of hydrus 1d are the same as these of the modified scm model 2 4 data for model evaluation the data set for model evaluation was obtained from a laboratory experiment conducted in the north carolina state university raleigh united states fox et al 2018 the experiment was conducted in a soil box with dimensions of 1 0 m wide 2 0 m long and 0 7 m deep based on the setup used by fox et al 2011 a 7 0 slope was used for all experiments the laboratory soil box was designed to allow the control of the wt level in the soil profile two different soils were used in the experiment the first soil was a silt loam with 19 4 sand 58 3 silt and 22 3 clay which was packed into the box to a bulk density of 1 40 g cm3 the other soil was a sandy loam with 54 9 sand 41 4 silt and 3 7 clay the soil was packed to a bulk density of 1 35 g cm3 during the experiment the wt level was controlled to model the different shallow wt condition which were set to be 0 32 and 0 40 m below the surface for the silt loam and the sandy loam respectively the inflow was applied at a constant rate using a peristaltic pump the inflow rate for the silt loam experiment was set as 60 cm3 s and the inflow duration was 120 min comparatively the inflow rate for the sandy loam was set as 50 cm3 s and the inflow duration was 60 min the outflow runoff was collected by a lateral flume draining to a collector and measured using a weighing scale every 5 s to provide the key parameters for modeling the neural network prediction module in hydrus 1d was used to estimate the soil hydraulic properties through the soil textural percentages and bulk density of two different soils šimůnek and van genuchten 2008 šimůnek et al 2016 the method is widely used in hydrological modeling practices e g hilten et al 2008 kornelsen and coulibaly 2014 thus the soil hydraulic properties of two soils are considered known and we only need to calibrate and validate the manning s roughness for the two datasets from fox et al 2018 the predicted hydraulic properties of the two soils are shown in table 1 note that the calibrated manning s friction coefficient was quite large due to the influence of vegetative filter strips in fox et al 2018 the time step used for both the modified scm model and hydrus 1d was 0 1 s the spatial step size is 0 1 m for the present model which satisfies the courant friedrichs lewy cfl condition to evaluate the model four tests were performed and the boundary conditions of different scenarios were summed up in table 2 3 model evaluation and application 3 1 model calibration and validation fig 2 shows the observed outflow rate and infiltration rate compared with the simulated results by the modified scm model for the two different soils these results show that the modified scm model reproduced the observed results fairly well it indicates that the proposed modeling approach can accurately simulate the soil infiltration and surface runoff processes with the presence of a shallow wt for the two types of soils the maximum relative error occurs early in the process at the time when surface ponding occurs this is possibly because the modified scm model adopts a similarity profile with a distortable shape see fig 1 and eq 2 which may affect the prediction of surface ponding 3 2 model application during two unsteady rainfall patterns since the performance of the original scm model during complex rainfall patterns has been evaluated in many previous studies e g corradini et al 1994 1997 chen et al 2013 wu et al 2019 the modified scm model can be applied to simulate the rainfall infiltration process under two different rainfall patterns with a wt on a horizonal surface the soil hydraulic properties of two typical soils are shown in table 1 the first rainfall is an intermittent rainfall which is characterized by two uniform rainfall periods and a rainfall hiatus the rainfall intensity and the simulated infiltration rate over time for two different wt depths and two different soil types are shown in fig 3 for the silt loam case see fig 3a the infiltration rate is equal to the rainfall intensity and no runoff occurs on the surface at the very beginning of the first rainfall period 0 t 120 min of the intermittent rainfall with a wt depth of 0 1 m then the infiltration rate tends to decrease sharply in a very short duration once the wetting front reaches the wt at t 12 min the infiltration rate remains unchanged with time during the rainfall hiatus the infiltration rate decreases to 0 cm h with a continual redistribution of soil water content for the second rainfall period 360 t 480 min of the intermittent rainfall the variation of infiltration rate is similar to that of the first rainfall period this is because the surface soil water content is very close to the initial soil water content due to the soil water redistribution during the rainfall hiatus for a deeper wt depth of 0 5 m see fig 3b the wetting front does not reach the wt and the variation of infiltration rate is slightly different between the first and second rainfall periods this indicates that the variation of surface soil water content during the rainfall hiatus affects the surface ponding and soil infiltration process which cannot be neglected or oversimplified for the silt loam in comparison for the sandy loam case see fig 3c and 3d the trends of infiltration rate versus time for two different wt depths are almost the same as those of the silt loam the only difference is that the surface ponding of sandy loam occurs earlier than that of silt loam and the wt depth has a slighter impact on infiltration process this is possibly because for the sandy loam the gravitational potential plays a more significant role than the matric potential during the soil infiltration process moreover when the wetting front reaches the wt the infiltration rate is also determined by the gravitational potential consequently the infiltration rate of saturated soil is almost the same before or after the wetting front reaches the wt the second rainfall series is a natural rainfall pattern and the rainfall rate versus time can be obtained from bagarello and ferro 2010 or wu et al 2019 fig 4 shows the rainfall intensity and the simulated infiltration rate over time for two different wt depths and two different soil types for the silt loam case see fig 4a and b we can easily find that the infiltration rate varies greatly with the complex rainfall pattern the infiltration rate with a deep wt depth is much larger than that with a shallow wt depth especially after surface ponding occurs this is because the wetting front reaches the wt rapidly with a shallower wt depth which then decreases the soil matric suction and restrains the soil infiltration rate moreover comparing to the intermittent rainfall see fig 3 the difference of the infiltration rate between two different wt depths becomes more prominent during the rainfall pattern with high temporal variability it suggests that the wt depth plays a significant role on the infiltration process for the silt loam especially during the complex rainfall pattern for the sandy loam case see fig 4c and d the surface ponding occurs more rapidly than the silt loam and the infiltration rate varies only slightly during the complex rainfall pattern moreover the infiltration rates are almost the same for different wt depths since in both cases the wetting front does not reach the wt it indicates that if the wetting front does not reach the wt the effect of shallow wt depth on infiltration rate is negligible to validate the capability of the modified scm model during the complex rainfall pattern the simulated infiltration rate of the modified scm model was compared to that by hydrus 1d with the same soil hydraulic properties see figs 3 and 4 hydrus 1d is a widely used software for simulating water flow and solute transport based on solving the richards equation which can predict the soil infiltration accurately under the complex rainfall patterns šimůnek and van genuchten 2008 šimůnek et al 2016 the results show that the modified scm model reproduces the simulated infiltration and soil water redistribution processes of hydrus 1d fairly well for different rainfall patterns water depths and soil types the cumulative infiltration depth the time to ponding and the time to column saturation i e the time that the wetting front reaches the wt for the modified scm model and hydrus 1d are also very close for the cases with a wt depth of 0 1 m as shown in table 3 the maximum differences of the cumulative infiltration depth the time to ponding and the time to column saturation are only 1 5 mm 1 1 min and 3 0 min respectively it indicates that the model can account for the impacts of the complex rainfall pattern on the soil water redistribution and soil infiltration with the presence of a shallow wt moreover for the second rainfall pattern the wetting front of silt loam can reach the wt while the wetting front of sandy loam cannot it means that for the silt loam the shallow wt condition is easier to influence the infiltration process than the sandy loam 3 3 model application on slopes since the slope gradient may play a significant role on both infiltration and runoff processes with a shallow wt the modified scm model was directly applied to analyze the potential slope effect on the variation of runoff rate taking the silt loam as an example see table 1 fig 5 shows the simulated rainfall runoff process for three slope gradients for the steady rainfall the runoff rate generally becomes smaller with an increase in slope gradient see fig 5a and b moreover the decrease of runoff rate tends to become more prominent on steep slopes for the case with wt depth of 0 1 m under steady rainfall at t 30 min see fig 5a the difference of runoff rate is 0 2 cm3 s between s0 7 and 21 which increases to 0 41 cm3 s between s0 21 and 35 many previous studies also found the similar results e g poesen 1984 assouline and ben hur 2006 chen and young 2006 ribolzi et al 2011 in comparison under the complex rainfall pattern the variation of runoff rate with slope gradient becomes more complicated see fig 5c and d in the stage with an increasing runoff rate the slope gradient has a positive effect on the runoff rate while it becomes a negative effect when the runoff rate tends to decrease with time this is because the slope effects on runoff rate is twofold on the one hand the increase slope gradient can directly increase the overland flow discharge see eq 11 and decrease the infiltration rate see eq 7 both have a positive impact on the runoff rate on the other hand the increase of slope gradient decreases the received rainfall amount per unit area which can decrease the runoff rate directly it indicates that under steady rainfalls the decrease of receive rainfall amount play a dominant role on the runoff rate while under unsteady rainfalls the dominant factor may shift among the above three factors the impact of shallow wt depth on the slope effects was also considered comparing the runoff process with different wt depths see fig 5a and b we can find that the slope effect on the rainfall runoff is slightly sensitive to wt depth for instance the difference of the runoff rate between s0 7 and 35 at t 30 min is 0 74 cm3 s for the 0 1 m wt depth which is 0 59 cm3 s for the 0 5 m wt depth under steady rainfall for the cases of unsteady rainfall in fig 5c and d the differences of the runoff rate between s0 7 and 35 at t 14 min are 3 15 cm3 s for 0 1 m wt depth and 1 99 cm3 s for 0 5 m wt depth respectively this indicates that the shallow wt also affects the slope effects on infiltration and runoff rate 4 discussions 4 1 comparing the modified scm model with previous models to examine the performance of the modified scm model to simulate the infiltration process with a wt during the complex rainfall pattern the results of the modified scm model was compared to those of two widely used models one of them is a modified green ampt infiltration solution shallow water table infiltration algorithm swingo proposed by muñoz carpena et al 2018 and the other one is hydrus 1d both have an ability to simulate the infiltration process with a wt under unsteady rainfall taking the clay in muñoz carpena et al 2018 as an example the soil hydraulic parameters for the three models are listed in table 4 for the parameters of three models swingo has the advantages of minimum model parameters followed by the modified scm model and hydrus 1d fig 6 shows the infiltration rates computed by the modified scm model hydrus 1d and swingo respectively under two rainfall patterns in muñoz carpena et al 2018 we found a similar trend in the modified scm model versus that in hydrus 1d with respect to the infiltration rate while swingo is likely to overestimate the infiltration rate under both steady and unsteady rainfalls at the very beginning of the rainfall event the simulated infiltration rates by the modified scm model and hydrus 1d are equal to the rainfall intensity because the soil is not ponded the time to surface ponding is less than 3 min and the infiltration rate tends to decrease sharply after surface ponding which then remains almost unchanged with time moreover it should be noted that in both the modified scm model and hydrus 1d the wetting fronts did not reach the wt and the wetting front depths are about 28 5 cm for the steady rainfall and 38 9 cm for the unsteady rainfall respectively in comparison swingo overestimated ponding time but underestimated the time when the wetting front reached the wt which caused a large prediction error in the infiltration rate during the steady and unsteady rainfalls for example the time to column saturation simulated by swingo is 300 and 308 3 min respectively for the steady and unsteady rainfalls which is much smaller than those in the modified scm model and hydrus 1d this is possibly because swingo is an extension of the green ampt model and it also assumes a saturated piston infiltration green 1911 muñoz carpena et al 2018 in clayey soils the soil water profiles during the infiltration can be quite different from a piston flow as assumed by the model this may reduce the model performance and cause an overestimation of the time to reach surface ponding moreover the large ponding time means that more water would infiltrate into the soil at the beginning of rainfall event which then results in an underestimation of the time to column saturation it indicated that the soil water redistribution is one of the key issues for accurately predicting the soil infiltration note that the above results are only valid for the clayey soil while for the coarser soil e g sand the soil water profile during the infiltration may be closer to the piston infiltration and the simulation error of swingo may decrease 4 2 the value of η for different soil types the η is an important shape factor for the modified soil infiltration model the value of η depends on the nonuniform initial water content profile caused by the capillary effect from wt in general the value of η can be assigned based on the initial soil water content profile which is independent of the soil infiltration process for a given wt depth the initial water content profile is closely related to the soil hydraulic properties and soil types and we can develop a relationship between η and the water content of surface soil four typical soils obtained from hydrus 1d šimůnek and van genuchten 2008 were selected to show the variation of η for different soil types and the results are shown in table 5 it is evident that there is a linear relationship between η and θ 0 i for different soil types moreover for the same θ 0 i the value of η is quite different for different soil types it suggests that the value of η should be determined based on the soil hydraulic properties before applying the model for different soil types 4 3 limitations for model performance evaluation directly comparing the simulated results to the observed data is better than comparing simulated results to output of another simulation model however to date very few experimental studies focused on the rainfall infiltration runoff process with a shallow wt under complex rainfall pattern we cannot find an appropriate dataset to directly evaluate the model performance on infiltration simulation under complex rainfall pattern with a shallow wt note that many previous infiltration models were evaluated by comparing the simulated results to those of richards equation basha 2011 lai et al 2015 muñoz carpena et al 2018 thus we compared the simulated infiltration process under complex rainfall patterns of the modified scm model to that of hydrus 1d with the same model parameters this is because hydrus 1d is widely used to solve the richards equation šimůnek and van genuchten 2008 šimůnek et al 2016 and its performance under complex rainfall patterns has been examined by many previous studies e g jiang et al 2010 yi and fan 2016 without experimental data this is a practical way to verify the reliability of the modified scm model under complex rainfall patterns the slope effect on infiltration process with a wt was not fully addressed in the modified scm model on the one hand the lateral subsurface flow and varying wt depth may occur in the slope which can modify the soil water content profile at different position previous studies also found that the lateral subsurface flow may potentially change the soil water redistribution by moving the infiltrated water from upslope to downslope e g freeze 1972 blume et al 2009 muñoz carpena et al 2018 on the other hand for a horizonal wt the distance between soil surface and wt on the slope tends to increase from the downslope to the upslope which may further complicate the soil water redistribution during a rainfall event further studies are worth to reveal how the lateral subsurface flow and varying wt depth on slopes affect the slope infiltration process in presence of a wt moreover the modified scm model is developed for the problem of point infiltration in the presence of a constant shallow wt for higher dimensional problems the shallow wt and the soil hydraulic properties vary greatly with time and space taking a watershed as an example it can be divided into many grids and the soil hydraulic properties and the variable shallow wt should be provided for each grid during the event thus the modified scm model can be directly applied to simulate the soil infiltration process for each grid of the watershed which provides a possible solution for higher dimensional problems 5 conclusions the scm infiltration model was modified to account for the impact of a shallow wt the modified scm infiltration model and a diffusive wave overland flow model are coupled for modeling hillslope rainfall infiltration runoff process in presence of a shallow wt the model is calibrated and validated against laboratory observed slope infiltration and runoff data with different inflow rates and wt depths of the silt loam and sandy loam and good agreements are found in infiltration and runoff processes the model can be operated to determine infiltration and soil water redistribution in presence of a shallow wt under realistic variable rainfall and slope conditions with a shallow wt the runoff rate generally decreases with slope gradient and the trend tends to become more prominent on steep slopes under steady rainfall patterns however under complex rainfall patterns the slope effect becomes more complicated and the increasing slope gradient has either a positive effect or a negative effect on the runoff rate moreover the slope effect on soil infiltration is slightly affected by the wt depth with an increase of wt depth the variation of runoff rate is more significant with slope gradient the modified scm infiltration algorithm has almost the same accuracy in predicting the infiltration rate time to ponding and time to column saturation in comparison with the solution of hydrus 1d for the silt loam sandy loam and clay however swingo is likely to overestimate the ponding time and the infiltration rate but underestimate the time to column saturation for clayey soils with a shallow wt credit authorship contribution statement songbai wu conceptualization methodology software validation writing original draft ting fong may chui conceptualization writing review editing supervision funding acquisition li chen conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by hong kong scholars program xj2019043 china postdoctoral science foundation 2018 m633555 and shaanxi province postdoctoral science foundation 
4482,limitations in current infiltration modeling approaches hamper the evaluation of the effects of complex rainfall pattern and slope gradient on soil infiltration and runoff in presence of a water table wt although they can markedly alter the hydrologic processes to fill the gap the smith et al 1993 s infiltration model was modified and a modeling framework was then developed to simulate the rainfall infiltration runoff process in presence of a wt the model was tested against experimental infiltration and runoff data at two different constant inflow rates and wt depths good agreements between the modeled and observed results were found in infiltration and runoff rates for two cases the model was evaluated under complex rainfall patterns and the results showed that the model performs well in the infiltration rate and the soil water redistribution predictions with an increasing of slope gradient the decrease of runoff rate tends to become more prominent under steady rainfall pattern but the trend becomes more complicated under complex rainfall patterns the model was compared with hydrus 1d and shallow water table infiltration algorithm swingo and found that both the model and hydrus 1d can well predict the soil infiltration rate and soil water redistribution in presence of a shallow wt for the silt loam sandy loam and clay swingo is likely to overestimate the ponding time and the infiltration rate but underestimate the time to column saturation for clayey soils with a shallow wt the model is expected to produce a more realistic and accurate approach for infiltration and runoff prediction in presence of a wt keywords groundwater level soil water redistribution slope gradient time varying rainfall hydrus 1d swingo 1 introduction the shallow water table wt is a principal feature of lands with shallow aquifers which widely exists in the humid coastal flat areas floodplains near water bodies and soils with limiting horizons resulting in perched wts e g novakowski and gillham 1988 slavich et al 2002 zhang and chui 2017 bhaskar et al 2018 bizhanimanzar et al 2019 capillary effects from a shallow wt result in nonuniform initial soil moisture conditions that are closely associated with the surface and subsurface water sediment and pollutants movement gillham 1984 basha 2011 roldin et al 2013 yao et al 2018 bradley et al 2019 zhang and chui 2019 for instance lauvernet and muñoz carpena 2018 and fox et al 2018 found that the shallow wt significantly affects the performance of vegetative filter strips on water sediment and pesticide reduction thus accurately modeling the soil infiltration process in the shallow wt conditions is important for the hydrology pedology agriculture and environmental sciences the infiltration process with the presence of a shallow wt is very complex which can be affected by a wide variety of factors related to rainfall soil and topography etc shirmohammadi and skaggs 1984 salvucci and entekhabi 1995 basha 2000a 2000b fox et al 2018 muñoz carpena et al 2018 the rainfall pattern is found to play a significant role on soil infiltration in presence of a shallow wt melone et al 2006 flammini et al 2018 for instance a significant variability of rainfall intensity and a frequently rainfall hiatus during the complex rainfall pattern can lead to many redistribution periods of soil water corradini et al 1994 1997 moreover the variation of soil water content profile could be more complicated due to the presence of a shallow wt novakowski and gillham 1988 in addition to rainfall pattern slope gradient as an important topographical feature can affect the infiltration process chen and young 2006 morbidelli et al 2018 philip 1957 wang et al 2018 and the slope together with a shallow wt are widely seen in the riparian areas zhang et al 2017 zhao et al 2018 gomes et al 2019 puntenney desmond et al 2020 comparing to a horizontal surface a slope can directly change the received rainfall volume on the surface the hydraulic head at the wetting front and the spatial variability of shallow wt morbidelli et al 2016 wu et al 2017 first steeper slopes with the same slope length receive a decreased amount of rainfall given that all raindrops fall vertically which can directly affect the infiltration and runoff generation chen and young 2006 second the hydraulic head at the wetting front becomes smaller with an increasing slope gradient and the soil infiltration capacity tends to decrease on steep slopes wu et al 2018 third the wt is usually shallower at downslope than upslope positions this can affect the soil water profile at different slope positions but was usually neglected in previous studies fox et al 2018 despite the significant influence of rainfall pattern and slope on soil infiltration most of the previous infiltration models cannot estimate infiltration in presence of a wt during a complex rainfall event or on a sloping surface for example existing physically based infiltration models e g chen and young 2006 green 1911 philip 1957 smith et al 1993 were derived for a uniform initial soil moisture profile these models are not suitable to describe the infiltration process above a wt when the initial soil water condition is non uniform chu 1997 craig et al 2010 liu et al 2011 lai et al 2015 and muñoz carpena et al 2018 modified the green ampt model to account for the presence of a wt these single event approaches consider the initial soil moisture profile due to the wt based on the equilibrium hydrostatic condition moreover to date the slope gradient is not taken into account in the infiltration models with a shallow wt these models treat all land surfaces as horizontal planes even though surfaces may be inclining chu 1997 craig et al 2010 liu et al 2011 lai et al 2015 muñoz carpena et al 2018 yao et al 2018 the received rainfall amount on the surface and the hydraulic head of wetting front cannot change with slope gradients in majority of models and these may overestimate the soil infiltration rate on steep slopes chen and young 2006 although the richards equation solvers such as the widely used infiltration software package hydrus richards 1931 basha 2000a 2000b 2011 šimůnek and van genuchten 2008 šimůnek et al 2016 can describe infiltration and moisture redistribution in presence of a wt for complex rainfall patterns and different slope gradients they do not have a general analytical solution and its application in real world systems requires intensive computation moreover solving the richards equation is complicated in addition to numerically solving the partial differential equation it also involves representing the soil column with a fine resolution grid assigning proper values to a set of model parameters for each computational grid and determining the boundary and initial conditions such as soil water contents for the entire soil profile which are often difficult to obtain although the soil can be assumed as homogeneous and using the same parameters for all soil layers solving the partial differential equation with dense computational grids may produce errors in mass conservation or even numerical instability e g for coarse soils and highly dynamic boundary conditions vogel et al 2000 seibert et al 2003 alternatively soil infiltration in presence of a wt is often modeled in practical hydrologic models using simpler physically based approaches e g ogden et al 2015 fernández pato et al 2016 muñoz carpena et al 2018 yao et al 2018 bizhanimanzar et al 2019 which have the advantages of less parameters and higher computational efficiency and can be more conveniently applied in large scale models for watershed or regional hydrologic and or other related environmental processes in fact the impacts of complex rainfall pattern and slope gradient were considered in a few physically based infiltration models without the wt for instance smith et al 1993 proposed a conceptual model hereafter called smith corradini melone model or scm model for infiltration and redistribution during storms which was used for hillslope and watershed hydrologic modeling in many studies e g chen et al 2013 2016 dunkerley 2018 wu et al 2019 2020 wu and chen 2020 this conceptual model is further extended to consider complex multiple rainfall events corradini et al 1994 and use the same ordinary differential equation for both infiltration and redistribution corradini et al 1997 for the slope wu et al 2018 quantified and explained the direct physical effects of slope angle on infiltration and runoff generation by extending the scm infiltration equations onto sloping surfaces thus the scm infiltration model was chosen to be modified for presence of a shallow wt the aims of the present study were to 1 extend the scm infiltration solution to soils bounded by a wt with no initial ponding 2 analyze the impacts of rainfall patterns and slope gradient on soil infiltration with a shallow wt and 3 compare the modified scm model with previous models for infiltration prediction in presence of a wt these efforts are expected to produce a more realistic and accurate approach for infiltration and runoff prediction on the slope surfaces with high variability of rainfall intensity 2 modeling approach to simulate the rainfall infiltration runoff process with a shallow wt the modeling approach generally includes two components namely the soil infiltration and runoff modules for the soil infiltration module the scm infiltration model was modified to account for the impact of shallow wt note that the scm infiltration model has been extended by corradini et al 1994 1997 and wu et al 2018 to consider complex rainfall patterns and slope gradient for the runoff module the widely used one dimensional diffusive wave model was chosen to model the overland flow routing process the coordinates and z are defined in the downslope and normal directions the wt is assumed to be parallel with sloping surface 2 1 modification to the scm infiltration model with a shallow wt the capillary effect can substantially affect the initial distribution of the soil water content and ultimately modify the soil infiltration process as shown in fig 1 the soil water initial condition in the model is set to hydrostatic equilibrium with a wt the initial soil water content θ i and soil matric potential ψ are different for different soil depths a linear relationship between soil matric potential and soil depth z positive downwards from the surface is assumed whereby the nonuniform water content of the soil is described by the soil water characteristic curve jury et al 1991 1 θ z i ψ z ψ b 1 λ θ s θ r θ r ψ z z z w where θ z i is the initial soil water content at different soil depths ψ b is the air entry head m θ s is the saturated volumetric water content θ r is the residual volumetric water content λ is empirical coefficient z is the shallow wt depth m and z w is the lowest point in the wetting profile m with the presence of a shallow wt the original method for the cumulative infiltration depth should be modified this is performed by introducing a shape factor η θ 0 i into the mass conservation equation see fig 1 2 i 0 z w θ z θ z i d z θ 0 θ 0 i z w β θ 0 θ z w i θ 0 i z w η θ 0 i where i is the cumulative infiltration depth m θ z is the soil water content at different soil depths θ 0 is the soil water content at the soil surface θ 0 i is the initial soil water content at the soil surface β θ 0 is a shape factor for the moisture profile modified by infiltration η θ 0 i is a shape factor accounting for the initial moisture profile due to the shallow wt which is the major difference with the original model with the shape factor the scm infiltration approach can reflect the soil water profile more accurately than the green ampt model according to smith et al 1993 and corradini et al 1994 1997 β θ 0 is related to both θ 0 and θ 0 i which can be expressed as β θ 0 0 6 θ 0 θ 0 i θ s θ r 0 4 in comparison η θ 0 i is determined by the initial soil water profile above a wt as an equilibrium hydrostatic condition to determine the expression of η θ 0 i we have chosen four typical soils from the manual of hydrus 1d to show the variation of η θ 0 i for different soil types for each soil type the values of η θ 0 i were calculated for 10 different wt depths from 0 1 to 1 0 m because the initial water content profiles are different for different wt depths we found that η θ 0 i shows a linear increase trend with the initial water content of surface soil θ 0 i which can be expressed as η θ 0 i c 1 θ 0 i θ r θ s θ r c 2 for all soil types it suggests that once the soil type i e soil hydraulic properties is determined c 1 and c 2 can be directly determined based on the linear fitting between η θ 0 i and θ 0 i θ r θ s θ r the details about the value of η θ 0 i for different soils can be found in discussion section taking the slope into consideration the infiltration rate i 0 perpendicular to the surface can be expressed as 3 i 0 di dt k z w i cos γ where t is time s k z w i is the initial soil hydraulic conductivity at soil depth z w m s γ is the slope angle the only change on sloping surfaces is to replace k z w i with k z w i cos γ and cos γ reflects the slope effect on the hydraulic head at the wetting front that can change the water content profile along the normal direction differentiation with respect to time and substitution of 2 into 3 lead to 4 i 0 z w β θ 0 d θ 0 dt θ 0 θ 0 i β θ 0 d z w dt θ 0 θ 0 i z w d β θ 0 d θ 0 d θ 0 dt z w η θ 0 i d θ z w i d z w d z w dt θ z w i θ 0 i η θ 0 i d z w dt k z w i cos γ the function β θ 0 may be treated as having a constant slope corradini et al 1997 and we set d β θ 0 d θ 0 σ the second fourth and fifth terms on the right side of 4 represent the profile elongation at a given θ 0 its sum with k z w i gives the downward flux which can be approximated by a depth integrated from q d of the darcy law thus we take 5 q d ψ z w i ψ 0 θ 0 θ 0 i β θ 0 d z w dt z w η θ 0 i d θ z w i d z w θ z w i θ 0 i η θ 0 i d z w dt k z w i cos γ p s z ψ z w ψ 0 k ψ d ψ k 0 cos γ where ψ z w i is the initial capillary head at soil depth z w ψ 0 is the capillary head at soil surface which equals to ψ z 0 k 0 is k θ 0 and p s is a quantity depending on the profile shape and linked with β and η it is evident with different shallow wts the variation of η can directly change the p s and thus affect the downward flux the integral in the last term of eq 5 is the capillary drive g note that with a shallow wt the initial soil water content varies notably with soil depth and the lower bound in integration has been modified to the initial capillary head at soil depth z w 6 g ψ z w i ψ 0 1 k s ψ z w i ψ 0 k ψ d ψ with the above simplifications eqs 4 and 5 are combined and solved for d θ 0 dt 7 d θ 0 dt i 0 k 0 cos γ p s g ψ z w i ψ 0 k s z w z w θ 0 θ 0 i σ β θ 0 since z w i θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i this substitution may be made to obtain 8 d θ 0 dt θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i i θ 0 θ 0 i σ β θ 0 i 0 k 0 cos γ θ 0 θ 0 i β θ 0 θ z w i θ 0 i η θ 0 i p s g ψ z w i ψ 0 k s i in the eq 8 θ z w i ψ z w i η θ 0 i and p s are closely related to the shallow wt which is the main difference with the original scm infiltration model during a complex pattern rainfall the infiltration and soil water redistribution processes are simulated by the modified scm model as follows corradini et al 1994 1997 for the condition with an unsaturated surface θ 0 θ s i 0 p cos γ and i is initially accumulated from p cos γ where p is the rainfall intensity m s when θ 0 θ s we have d θ 0 dt 0 and we can derive i 0 by eq 8 that represents the infiltration capacity and i accumulates from i 0 after the wetting front approaches the wt see fig 1 we have z w z and ψ i z w 0 i 0 and i can be also derived by eq 8 when the rainfall stops eq 8 with i 0 0 can be used to estimate the decrease of θ 0 with time and the wetted profile redistributes which is one of the major improvements comparing to the model of muñoz carpena et al 2018 similar with chen and young 2006 and wu et al 2018 the use of p cos γ means that a decrease rainfall amount is received on the steep slopes for the vertical rainfall direction following chen et al 2013 the numerical solution of eq 8 was sought by the standard runge kutta fourth order rk4 approach 2 2 overland flow model after obtaining soil infiltration rate by the modified scm model the one dimensional diffusive wave approximation lighthill and whitham 1955 has been applied to simulate overland flow or surface runoff the governing equations can be written as 9 h t q x p cos γ i 0 10 s 0 h s s f 11 q 1 n h 5 3 s f 1 2 where h is the flow depth m t is time s q is the unit flow discharge m2 s i 0 is the infiltration rate through the soil surface m s s 0 is the slope gradient s f is the friction slope s is the flow direction in the coordinate system and n is manning s friction coefficient eqs 9 11 were solved numerically using the finite difference and newton iteration method 2 3 hydrus 1d to evaluate the model effectiveness we compared the simulated results of the modified scm model to those of hydrus 1d that directly solves the richards equation the governing equation of hydrus 1d can be expressed as šimůnek and van genuchten 2008 šimůnek et al 2016 12 θ t k ψ z ψ z cos α where α is the angle between the flow direction and the vertical axis i e α 0 for vertical flow 90 for horizontal flow and 0 less than 90 α for inclined flow in the present study α is equal to the slope angle γ the model parameters boundary and initial conditions of hydrus 1d are the same as these of the modified scm model 2 4 data for model evaluation the data set for model evaluation was obtained from a laboratory experiment conducted in the north carolina state university raleigh united states fox et al 2018 the experiment was conducted in a soil box with dimensions of 1 0 m wide 2 0 m long and 0 7 m deep based on the setup used by fox et al 2011 a 7 0 slope was used for all experiments the laboratory soil box was designed to allow the control of the wt level in the soil profile two different soils were used in the experiment the first soil was a silt loam with 19 4 sand 58 3 silt and 22 3 clay which was packed into the box to a bulk density of 1 40 g cm3 the other soil was a sandy loam with 54 9 sand 41 4 silt and 3 7 clay the soil was packed to a bulk density of 1 35 g cm3 during the experiment the wt level was controlled to model the different shallow wt condition which were set to be 0 32 and 0 40 m below the surface for the silt loam and the sandy loam respectively the inflow was applied at a constant rate using a peristaltic pump the inflow rate for the silt loam experiment was set as 60 cm3 s and the inflow duration was 120 min comparatively the inflow rate for the sandy loam was set as 50 cm3 s and the inflow duration was 60 min the outflow runoff was collected by a lateral flume draining to a collector and measured using a weighing scale every 5 s to provide the key parameters for modeling the neural network prediction module in hydrus 1d was used to estimate the soil hydraulic properties through the soil textural percentages and bulk density of two different soils šimůnek and van genuchten 2008 šimůnek et al 2016 the method is widely used in hydrological modeling practices e g hilten et al 2008 kornelsen and coulibaly 2014 thus the soil hydraulic properties of two soils are considered known and we only need to calibrate and validate the manning s roughness for the two datasets from fox et al 2018 the predicted hydraulic properties of the two soils are shown in table 1 note that the calibrated manning s friction coefficient was quite large due to the influence of vegetative filter strips in fox et al 2018 the time step used for both the modified scm model and hydrus 1d was 0 1 s the spatial step size is 0 1 m for the present model which satisfies the courant friedrichs lewy cfl condition to evaluate the model four tests were performed and the boundary conditions of different scenarios were summed up in table 2 3 model evaluation and application 3 1 model calibration and validation fig 2 shows the observed outflow rate and infiltration rate compared with the simulated results by the modified scm model for the two different soils these results show that the modified scm model reproduced the observed results fairly well it indicates that the proposed modeling approach can accurately simulate the soil infiltration and surface runoff processes with the presence of a shallow wt for the two types of soils the maximum relative error occurs early in the process at the time when surface ponding occurs this is possibly because the modified scm model adopts a similarity profile with a distortable shape see fig 1 and eq 2 which may affect the prediction of surface ponding 3 2 model application during two unsteady rainfall patterns since the performance of the original scm model during complex rainfall patterns has been evaluated in many previous studies e g corradini et al 1994 1997 chen et al 2013 wu et al 2019 the modified scm model can be applied to simulate the rainfall infiltration process under two different rainfall patterns with a wt on a horizonal surface the soil hydraulic properties of two typical soils are shown in table 1 the first rainfall is an intermittent rainfall which is characterized by two uniform rainfall periods and a rainfall hiatus the rainfall intensity and the simulated infiltration rate over time for two different wt depths and two different soil types are shown in fig 3 for the silt loam case see fig 3a the infiltration rate is equal to the rainfall intensity and no runoff occurs on the surface at the very beginning of the first rainfall period 0 t 120 min of the intermittent rainfall with a wt depth of 0 1 m then the infiltration rate tends to decrease sharply in a very short duration once the wetting front reaches the wt at t 12 min the infiltration rate remains unchanged with time during the rainfall hiatus the infiltration rate decreases to 0 cm h with a continual redistribution of soil water content for the second rainfall period 360 t 480 min of the intermittent rainfall the variation of infiltration rate is similar to that of the first rainfall period this is because the surface soil water content is very close to the initial soil water content due to the soil water redistribution during the rainfall hiatus for a deeper wt depth of 0 5 m see fig 3b the wetting front does not reach the wt and the variation of infiltration rate is slightly different between the first and second rainfall periods this indicates that the variation of surface soil water content during the rainfall hiatus affects the surface ponding and soil infiltration process which cannot be neglected or oversimplified for the silt loam in comparison for the sandy loam case see fig 3c and 3d the trends of infiltration rate versus time for two different wt depths are almost the same as those of the silt loam the only difference is that the surface ponding of sandy loam occurs earlier than that of silt loam and the wt depth has a slighter impact on infiltration process this is possibly because for the sandy loam the gravitational potential plays a more significant role than the matric potential during the soil infiltration process moreover when the wetting front reaches the wt the infiltration rate is also determined by the gravitational potential consequently the infiltration rate of saturated soil is almost the same before or after the wetting front reaches the wt the second rainfall series is a natural rainfall pattern and the rainfall rate versus time can be obtained from bagarello and ferro 2010 or wu et al 2019 fig 4 shows the rainfall intensity and the simulated infiltration rate over time for two different wt depths and two different soil types for the silt loam case see fig 4a and b we can easily find that the infiltration rate varies greatly with the complex rainfall pattern the infiltration rate with a deep wt depth is much larger than that with a shallow wt depth especially after surface ponding occurs this is because the wetting front reaches the wt rapidly with a shallower wt depth which then decreases the soil matric suction and restrains the soil infiltration rate moreover comparing to the intermittent rainfall see fig 3 the difference of the infiltration rate between two different wt depths becomes more prominent during the rainfall pattern with high temporal variability it suggests that the wt depth plays a significant role on the infiltration process for the silt loam especially during the complex rainfall pattern for the sandy loam case see fig 4c and d the surface ponding occurs more rapidly than the silt loam and the infiltration rate varies only slightly during the complex rainfall pattern moreover the infiltration rates are almost the same for different wt depths since in both cases the wetting front does not reach the wt it indicates that if the wetting front does not reach the wt the effect of shallow wt depth on infiltration rate is negligible to validate the capability of the modified scm model during the complex rainfall pattern the simulated infiltration rate of the modified scm model was compared to that by hydrus 1d with the same soil hydraulic properties see figs 3 and 4 hydrus 1d is a widely used software for simulating water flow and solute transport based on solving the richards equation which can predict the soil infiltration accurately under the complex rainfall patterns šimůnek and van genuchten 2008 šimůnek et al 2016 the results show that the modified scm model reproduces the simulated infiltration and soil water redistribution processes of hydrus 1d fairly well for different rainfall patterns water depths and soil types the cumulative infiltration depth the time to ponding and the time to column saturation i e the time that the wetting front reaches the wt for the modified scm model and hydrus 1d are also very close for the cases with a wt depth of 0 1 m as shown in table 3 the maximum differences of the cumulative infiltration depth the time to ponding and the time to column saturation are only 1 5 mm 1 1 min and 3 0 min respectively it indicates that the model can account for the impacts of the complex rainfall pattern on the soil water redistribution and soil infiltration with the presence of a shallow wt moreover for the second rainfall pattern the wetting front of silt loam can reach the wt while the wetting front of sandy loam cannot it means that for the silt loam the shallow wt condition is easier to influence the infiltration process than the sandy loam 3 3 model application on slopes since the slope gradient may play a significant role on both infiltration and runoff processes with a shallow wt the modified scm model was directly applied to analyze the potential slope effect on the variation of runoff rate taking the silt loam as an example see table 1 fig 5 shows the simulated rainfall runoff process for three slope gradients for the steady rainfall the runoff rate generally becomes smaller with an increase in slope gradient see fig 5a and b moreover the decrease of runoff rate tends to become more prominent on steep slopes for the case with wt depth of 0 1 m under steady rainfall at t 30 min see fig 5a the difference of runoff rate is 0 2 cm3 s between s0 7 and 21 which increases to 0 41 cm3 s between s0 21 and 35 many previous studies also found the similar results e g poesen 1984 assouline and ben hur 2006 chen and young 2006 ribolzi et al 2011 in comparison under the complex rainfall pattern the variation of runoff rate with slope gradient becomes more complicated see fig 5c and d in the stage with an increasing runoff rate the slope gradient has a positive effect on the runoff rate while it becomes a negative effect when the runoff rate tends to decrease with time this is because the slope effects on runoff rate is twofold on the one hand the increase slope gradient can directly increase the overland flow discharge see eq 11 and decrease the infiltration rate see eq 7 both have a positive impact on the runoff rate on the other hand the increase of slope gradient decreases the received rainfall amount per unit area which can decrease the runoff rate directly it indicates that under steady rainfalls the decrease of receive rainfall amount play a dominant role on the runoff rate while under unsteady rainfalls the dominant factor may shift among the above three factors the impact of shallow wt depth on the slope effects was also considered comparing the runoff process with different wt depths see fig 5a and b we can find that the slope effect on the rainfall runoff is slightly sensitive to wt depth for instance the difference of the runoff rate between s0 7 and 35 at t 30 min is 0 74 cm3 s for the 0 1 m wt depth which is 0 59 cm3 s for the 0 5 m wt depth under steady rainfall for the cases of unsteady rainfall in fig 5c and d the differences of the runoff rate between s0 7 and 35 at t 14 min are 3 15 cm3 s for 0 1 m wt depth and 1 99 cm3 s for 0 5 m wt depth respectively this indicates that the shallow wt also affects the slope effects on infiltration and runoff rate 4 discussions 4 1 comparing the modified scm model with previous models to examine the performance of the modified scm model to simulate the infiltration process with a wt during the complex rainfall pattern the results of the modified scm model was compared to those of two widely used models one of them is a modified green ampt infiltration solution shallow water table infiltration algorithm swingo proposed by muñoz carpena et al 2018 and the other one is hydrus 1d both have an ability to simulate the infiltration process with a wt under unsteady rainfall taking the clay in muñoz carpena et al 2018 as an example the soil hydraulic parameters for the three models are listed in table 4 for the parameters of three models swingo has the advantages of minimum model parameters followed by the modified scm model and hydrus 1d fig 6 shows the infiltration rates computed by the modified scm model hydrus 1d and swingo respectively under two rainfall patterns in muñoz carpena et al 2018 we found a similar trend in the modified scm model versus that in hydrus 1d with respect to the infiltration rate while swingo is likely to overestimate the infiltration rate under both steady and unsteady rainfalls at the very beginning of the rainfall event the simulated infiltration rates by the modified scm model and hydrus 1d are equal to the rainfall intensity because the soil is not ponded the time to surface ponding is less than 3 min and the infiltration rate tends to decrease sharply after surface ponding which then remains almost unchanged with time moreover it should be noted that in both the modified scm model and hydrus 1d the wetting fronts did not reach the wt and the wetting front depths are about 28 5 cm for the steady rainfall and 38 9 cm for the unsteady rainfall respectively in comparison swingo overestimated ponding time but underestimated the time when the wetting front reached the wt which caused a large prediction error in the infiltration rate during the steady and unsteady rainfalls for example the time to column saturation simulated by swingo is 300 and 308 3 min respectively for the steady and unsteady rainfalls which is much smaller than those in the modified scm model and hydrus 1d this is possibly because swingo is an extension of the green ampt model and it also assumes a saturated piston infiltration green 1911 muñoz carpena et al 2018 in clayey soils the soil water profiles during the infiltration can be quite different from a piston flow as assumed by the model this may reduce the model performance and cause an overestimation of the time to reach surface ponding moreover the large ponding time means that more water would infiltrate into the soil at the beginning of rainfall event which then results in an underestimation of the time to column saturation it indicated that the soil water redistribution is one of the key issues for accurately predicting the soil infiltration note that the above results are only valid for the clayey soil while for the coarser soil e g sand the soil water profile during the infiltration may be closer to the piston infiltration and the simulation error of swingo may decrease 4 2 the value of η for different soil types the η is an important shape factor for the modified soil infiltration model the value of η depends on the nonuniform initial water content profile caused by the capillary effect from wt in general the value of η can be assigned based on the initial soil water content profile which is independent of the soil infiltration process for a given wt depth the initial water content profile is closely related to the soil hydraulic properties and soil types and we can develop a relationship between η and the water content of surface soil four typical soils obtained from hydrus 1d šimůnek and van genuchten 2008 were selected to show the variation of η for different soil types and the results are shown in table 5 it is evident that there is a linear relationship between η and θ 0 i for different soil types moreover for the same θ 0 i the value of η is quite different for different soil types it suggests that the value of η should be determined based on the soil hydraulic properties before applying the model for different soil types 4 3 limitations for model performance evaluation directly comparing the simulated results to the observed data is better than comparing simulated results to output of another simulation model however to date very few experimental studies focused on the rainfall infiltration runoff process with a shallow wt under complex rainfall pattern we cannot find an appropriate dataset to directly evaluate the model performance on infiltration simulation under complex rainfall pattern with a shallow wt note that many previous infiltration models were evaluated by comparing the simulated results to those of richards equation basha 2011 lai et al 2015 muñoz carpena et al 2018 thus we compared the simulated infiltration process under complex rainfall patterns of the modified scm model to that of hydrus 1d with the same model parameters this is because hydrus 1d is widely used to solve the richards equation šimůnek and van genuchten 2008 šimůnek et al 2016 and its performance under complex rainfall patterns has been examined by many previous studies e g jiang et al 2010 yi and fan 2016 without experimental data this is a practical way to verify the reliability of the modified scm model under complex rainfall patterns the slope effect on infiltration process with a wt was not fully addressed in the modified scm model on the one hand the lateral subsurface flow and varying wt depth may occur in the slope which can modify the soil water content profile at different position previous studies also found that the lateral subsurface flow may potentially change the soil water redistribution by moving the infiltrated water from upslope to downslope e g freeze 1972 blume et al 2009 muñoz carpena et al 2018 on the other hand for a horizonal wt the distance between soil surface and wt on the slope tends to increase from the downslope to the upslope which may further complicate the soil water redistribution during a rainfall event further studies are worth to reveal how the lateral subsurface flow and varying wt depth on slopes affect the slope infiltration process in presence of a wt moreover the modified scm model is developed for the problem of point infiltration in the presence of a constant shallow wt for higher dimensional problems the shallow wt and the soil hydraulic properties vary greatly with time and space taking a watershed as an example it can be divided into many grids and the soil hydraulic properties and the variable shallow wt should be provided for each grid during the event thus the modified scm model can be directly applied to simulate the soil infiltration process for each grid of the watershed which provides a possible solution for higher dimensional problems 5 conclusions the scm infiltration model was modified to account for the impact of a shallow wt the modified scm infiltration model and a diffusive wave overland flow model are coupled for modeling hillslope rainfall infiltration runoff process in presence of a shallow wt the model is calibrated and validated against laboratory observed slope infiltration and runoff data with different inflow rates and wt depths of the silt loam and sandy loam and good agreements are found in infiltration and runoff processes the model can be operated to determine infiltration and soil water redistribution in presence of a shallow wt under realistic variable rainfall and slope conditions with a shallow wt the runoff rate generally decreases with slope gradient and the trend tends to become more prominent on steep slopes under steady rainfall patterns however under complex rainfall patterns the slope effect becomes more complicated and the increasing slope gradient has either a positive effect or a negative effect on the runoff rate moreover the slope effect on soil infiltration is slightly affected by the wt depth with an increase of wt depth the variation of runoff rate is more significant with slope gradient the modified scm infiltration algorithm has almost the same accuracy in predicting the infiltration rate time to ponding and time to column saturation in comparison with the solution of hydrus 1d for the silt loam sandy loam and clay however swingo is likely to overestimate the ponding time and the infiltration rate but underestimate the time to column saturation for clayey soils with a shallow wt credit authorship contribution statement songbai wu conceptualization methodology software validation writing original draft ting fong may chui conceptualization writing review editing supervision funding acquisition li chen conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by hong kong scholars program xj2019043 china postdoctoral science foundation 2018 m633555 and shaanxi province postdoctoral science foundation 
4483,recently floods are occurring more frequently every year around the world due to increased anthropogenic activities and climate change there is a need to develop accurate models for flood susceptibility prediction and mapping which can be helpful in developing more efficient flood management plans in this study the partial decision tree part classifier and the adaboost bagging dagging and random subspace ensembles learning techniques were combined to develop novel gis based ensemble computational models abpart bpart dpart and rsspart for flood susceptibility mapping in the quang binh province vietnam in total 351 flood locations were used in the model study this data was divided into a 70 30 ratio for model training 70 255 locations and 30 96 locations for model validation ten flood influencing factors namely elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology were used for the development of models the oner feature selection method was used to select and prioritize important factors for the spatial modeling the results revealed that land use geology and slope are the most important conditioning factors in the occurrence of floods in the study area standard statistical methods including the roc curve auc were used for the performance evaluation of models results indicated that the performance of all models was good auc 0 9 and rsspart auc 0 959 outperformed the others thus the rsspart model can be used for accurately predicting and mapping flood susceptibility keywords machine learning decision trees oner feature selection geographic information system gis vietnam 1 introduction floods are among the most common natural events occurring in most parts of the world damaging properties and causing huge loss of life costache et al 2020 they occur when the amount of precipitation surpasses the capacity of reservoirs liu et al 2018 mohamed 2019 and river channels in the coastal areas floods occur due to tropical cyclones and tsunami waves minh et al 2018 wang et al 2014 zhang et al 2020b in mountainous areas floods also occur when snow melts rapidly causing flash floods climate change is considered one of the main causes of change in flooding patterns intensity and magnitude hens et al 2018 van thanh et al 2017 as a consequence of the increasing intensity floods can cause sudden morphological changes in the area due to rapid erosion and landslides van tu et al 2016 causes of high flood risk in vietnam include tropical cyclones typhoons dense river networks and long coastal areas overall vietnam is highly susceptible to severe storms and floods and is ranked eighth among the ten countries with the highest number of weather events thao et al 2020 anthropogenic activities such as deforestation land use pattern change and city development increase the flood risk in vietnam most of the flood susceptible areas in vietnam are densely populated thus there is a constant risk of loss of life and property in such areas therefore spatial modeling of flood events to prevent and control the harmful risks of future floods will be of great help wu et al 2010 in view of this advanced modeling techniques are needed to accurately identify high flood susceptible areas for risk management henriksen et al 2018 so far many studies have been done to develop reliable flood susceptibility maps using remote sensing techniques and geographic information system gis nowadays machine learning ml techniques are being employed in conjunction with gis to address many environmental problems akay and taş 2020 such as develop flood susceptibility mapping some of the techniques used for flood spatial modeling are artificial neural network ann support vector machine svm random forest rf and boosted trees bt classification and regression trees crt adaptive network based fuzzy inference system anfis naïve bayes nb quick unbiased efficient statistical tree quest and genetic algorithm for rule set production garp darabi et al 2019 lee et al 2017 in recent years hybrid and ensemble ml models have emerged as they outperformed single models in terms of prediction accuracy zenggang et al 2019 many ensemble learning techniques such as adaboost bagging dagging and random subspace ensembles have been recently used to improve the predictive accuracies of natural pham et al 2020a 2021 tran et al 2020 tuyen et al 2021 in this study we have used partial decision tree part as a base classifier in developing ensemble models abpart bpart dpart and rsspart which used adaboost bagging dagging and random subspace algorithms respectively as optimization techniques for the flood susceptibility mapping in quang binh province of vietnam this study reports the first application of the part classifier in developing new ensemble models for flood susceptibility prediction and mapping 2 study area and data used 2 1 study area description the quang binh province with an area of about 800 km2 and a population of 887600 is located in the north central coastal region of vietnam fig 1 this province was selected as a case study because it is one of the most flood prone areas in vietnam luu et al 2019 it is located in the tropical monsoon region having a transitional climate of the north and the south of vietnam son et al 2017 with relatively cold winters in the north and a typical tropical climate in the south maximum rainfall is concentrated in three months of september october and november and coincides with floods and storms occurring in the province van thang et al 2019 recent hazardous flood events occurred in the years 1995 1999 2007 2008 2010 and 2016 2 2 flood inventory floods have frequently occurred in the area and affected the life property and socio economic conditions of the province fig 2 a flood inventory map was constructed using the flood marks data obtained from the quang binh centre for hydrometeorological forecasting in total 321 flood events that occurred in 2007 2010 and 2016 were considered in this study fig 1 in 2007 within three days from 3 to 7th october 2007 flood caused 4 fatalities 69 injuries and 26 597 houses flooded and damaged nasa 2007 the 2010 year flood event caused 74 fatalities flooded and damaged 188 628 houses besides affecting agriculture transportation and fisheries united nations vietnam 2010 in the year 2016 flood event in october 2016 caused 18 fatalities 13 injuries flooding and damage of 71 251 besides damage of infrastructure in quang binh province echo 2016 2 3 flood conditioning factors in this study ten flood conditioning factors were selected based on the local geo environment conditions and literature survey for the flood susceptibility modeling studies bui et al 2019 pham et al 2021 2020e luu et al 2020 these factors are elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology table 1 and fig 3 that are described as follows 2 4 elevation the elevation map was extracted from the 30 m resolution shuttle radar topography mission srtm digital elevation model dem version 3 collected from earth data platform https search earthdata nasa gov search of quang binh province fig 3a and table 1 this factor is important in flood modeling as it affects precipitation and flow conditions ahmadlou et al 2018 the elevation map was classified into seven class intervals using the natural break classification method for the model study fig 3a 2 5 slope steep slopes increase the speed of surface run off and reduce the infiltration in the soil agassi et al 1990 the slope angle map was derived from the dem map and classified into seven classes the slope angle map of the study area ranges from 0 to 77 52 fig 3b and table 1 river valleys and low lying areas are affected by floods 2 6 curvature another topographic factor curvature was extracted from the dem map the curvature represents convex concave and flat surfaces indicating positive negative and zero surfaces respectively chapi et al 2017 this factor is related to the run off on the curved surface thus surface flow manfreda et al 2014 thai pham et al 2019 fig 3c and table 1 2 7 flow direction flow direction is a hydrological factor that shows the direction of the flow this factor map was created using arc hydro tool of arcgis and classified into five classes using the natural break classification method fig 3d and table 1 flow direction is important in assessing the area where surface flow will travel and cause flooding 2 8 flow accumulation flow accumulation represents the proportionality of water concentration during a flood nguyen et al 2019 the flow accumulation map was obtained from the flow direction map by using flow accumulation tool of arcgis this tool calculated accumulated flow in each upstream cell into downslope cells in the output raster fig 3e and table 1 2 9 river density river density is an important factor that directly affects flood occurrence bui et al 2019 liu et al 2021 quang binh province has a dense river system that includes five main river basins of roon gianh ly hoa dinh and nhat le the total length of the river system is 343 km and the total area of the river basins is 7 890 km2 the flow of water is equivalent to 4 billion m3 per year the river density factor is calculated by dividing river stream length m by a watershed area km2 the river density map was prepared and classified into seven classes fig 3f and table 1 2 10 distance from river the inundation areas are often located near the river basins due to an overflow of water from river banks terti et al 2017 we calculated the distance from river factor based on river system map using euclidian distance tool in arcgis pro the distance from river was classified into five classes using the manual classification method fig 3g and table 1 2 11 rainfall the rainfall distribution map is very important for developing a flood susceptibility map spekkers et al 2014 the annual rainfall distribution map was created based on 16 precipitation stations 10 in quang binh province and 6 in ha tinh and quang tri province the dataset of 31 years from 1986 to 2016 was used to generate the rainfall map of the research area using the inverse distance weighted idw method mair and fares 2011 fig 3h and table 1 2 12 land use a land use map shows the distribution of land use categories in the area this factor is an important factor in assessing anthropogenic activities impacts affecting run off and inundation hosseini et al 2020 we collected the land use map established in 2015 by the quang binh department of natural resources and environment the land use map includes ten categories woodland 1 1 water bodies 2 7 transportation 0 2 soil bare 1 2 residential areas 5 8 plants in residential areas 16 5 mining areas 0 1 forest 64 6 construction areas 2 5 and agricultural areas 5 3 fig 3i and table 1 2 13 geology geology affects erosion surface flow and infiltration based on the characteristics of the rocks and geological structures zhang et al 2020a we collected the geology map from the quang binh department of natural resources and environment which indicates 35 different geological categories fig 3j and table 2 3 methodology 3 1 methodological flowchart in the first step flood inventory and thematic maps elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology were created then the oner feature selection method was used to prioritize the flood conditioning factors frequency ratio method was applied to analyze spatial associations between floods and each class of the conditioning factors for the modeling process the flood locations were divided by a 70 30 ratio out of these 70 of the data was used for the training of the models and 30 for the validation further the ensemble learning techniques used in developing ensemble models were adaboost bagging dagging and random subspace and the partial decision tree part algorithm as a base classifier the models performance was evaluated using the standard statistical measures finally flood susceptibility maps were generated using the models in a gis environment the methodology adopted in this study is described in fig 4 3 2 methods used 3 2 1 frequency ratio fr in flood susceptibility research it is very important to quantify the importance of different conditioning factors on flood occurrence a very efficient way to carry out this analysis is represented by the computation of frequency ratio fr for each class category of the factors fr is a bivariate statistical model which is widely used in the literature for hazards susceptibility estimation costache and zaharia 2017 thanh et al 2020a fr values are achieved by applying the ratio between the percentage of flood pixels from a class category within the total flood pixels of the study area and the percentage of class category total pixels within the total pixels of the study area 1 fr npix 1 npix 2 n p i x 3 n p i x 4 where npix 1 is the total number of floods in a factor category npix 2 is the total pixels in a category n p i x 3 is the total flood pixels in the research area and n p i x 4 is the number of pixels in the research area 3 2 2 partial decision tree part in partial decision tree part a set of methods are used to compare the importance of a specific variable compared to the other variables based on multiple objectives and criteria da silva et al 2020 frank and witten 1998 preparing a straight relationship matrix is the vital benefit of the decision making process that is used to build relationships lee et al 2013 part is quick in prediction which contains branches to undefined sub trees by integrating construction and pruning operations to find stable sub tree which cannot be simplified further at this point tree building ceases and a single rule is formed in the part rules are inferred by repeatedly generating partial decision trees by separate and conquer rule learning technique frank and witten 1998 the main reason for selecting the part algorithm is given by its advantage represented by the use of the direct relation matrix to analyze the causal relationships between the variables frank and witten 1998 3 2 3 adaboost adaboost or adaptive boosting technique is a simple and general boosting method that iteratively produces individual classifiers whose main scope is the accurate classification of training data hong et al 2018 adaboost algorithm contains two principal sections the excess model and the stage by stage algorithm in the excess model there is an intense classifier that synthesizes the linear succession of feeble classifiers arabameri et al 2020a li et al 2020 the value of the final classifier is equal to a weighted sum obtained by using the ensemble predictions hong et al 2018 one of the most important advantages of the adaboost algorithm for which this method was selected for the present study is given by the fact that this algorithm in the classification process is able to remove some unimportant aspects of the training data and place them on top of the critical and crucial training data moreover the adaboost method is fundamentally a naive raising procedure of unable categorization way and this action can modify the data classification capability by decreasing both prejudice and variance the fact or quality of being different via successive training wu et al 2020 a comprehensive description of the mathematical relationships underlying this method is included in the published scientific work tang et al 2020 3 2 4 bagging bagging or bootstrap aggregating technique is an ensemble method based on bootstrapping procedure the positive privilege and at the same time the advantage of the bagging model is that it can reduce overfitting and accomplish well on powerful categories thanh et al 2020b another critical reason to use bagging classification is that it can easily control the training data so that to keep the most important information for the modeling procedure instead the bagging model similar to other hybrid models is sensitive to classification bias and fuss the numeral of classifiers super variables is set of series at ten as outside this value no betterment in the model efficiency was seen particularly the addendum phases were in the fulfillment of the bagging algorithm yousaf et al 2020 similar to the adaboost technique bagging is a very popular model natural hazards modeling hong et al 2018 wu et al 2020 3 2 5 dagging dagging is a reintegration technique which is used to enhance the prediction accuracy of single lone basis classifications kotsianti and kanellopoulos 2007 one of the advantages of the dagging algorithm is that it involves a specific number of disjoint samples alternate for bootstrap samples to obtain the base classifiers roy and saha 2021 in addition dagging creates separate and distinct folds of data and prepares a packet of data for a duplicate version of the basic learning algorithm kotsianti and kanellopoulos 2007 the boot instances are changed via splinter instances while the procedure is renewed the original classifier by dagging the hypothesis is that n instances are in the training dataset a dagging algorithm makes m datasets from the principal dataset every dataset has n instances nm n and varied datasets do not have identical instances chen and li 2020 hence m classification models can be obtained from m datasets when every classification model produces its anticipation class based on a certain inquiry example the class that achieves the most options is regarded as the anticipation class of the dagging model zhu et al 2016 even if dagging ensemble is not very frequently used in flood susceptibility studies islam et al 2021 it has been used in for landslide susceptibility modeling pham et al 2020c sahana et al 2020 3 2 6 random subspace rss random subspace rss technique is used to reduce the size of the formula foundation and refrain from information damage the main advantage of rss model is represented by the random selection of the feature subsets that results in low correlated multiple weak learners shin 2020 creating manifold subspaces from a genuine dataset belongs to three essential variables the number of properties r in a subspace the numeral of subspaces and the property weight w that results in the possibility to exploit the properties the weight of the w property can be calculated using information from the instance data properties if the property attribute f is linked to an outcome attribute y the obtaining information oi is a general index that can extend how much information from the f attribute can lead to a y result rss algorithm is a common technique used in natural hazards modeling chen et al 2019 luo et al 2019 pham et al 2020d 3 2 7 one rule oner feature selection method feature selection is recognized as the primary variable selection in the modeling process or electing substantial subsets that have a greater impact on the occurrence of an event such as a flood einicke et al 2018 feature selection techniques used to select the most significant predictor variables for 1 simplifying the model for exegesis by users 2 model time and training are less and 3 raised popularization by decreasing overfitting or diminution of variance when applying the characteristic choice way the basic premise is that the data includes several exclusives that are superfluous or unfitting and therefore can be deleted without endurance much damage to information superfluous and unfitting are two separate concepts one pertaining peculiarity might be waste in the attendance of another linked peculiarity with which it is forcefully associated sarangi et al 2020 oner abbreviated one rule is a modest yet precise classification algorithm that creates a rule for each anticipant in the data then opts this rule as its rule with the smallest whole error it does holte 1993 in this study oner was used as a feature selection to evaluate and rank the importance of each flood conditioning factor for flood susceptibility modeling for each factor this algorithm looks for a simple rule by determining the majority class for each factor s value thereafter the accuracy of a certain rule is evaluated and the factors are ranked and ordered according to the quality of the corresponding rules indicating by average merit am index pes and applications 2020 3 2 8 validation indicators the appraisal of spatial modeling results of flood events in the study area is done using both training and validation datasets to select the best model that can produce an accurate flood susceptibility map hosseini et al 2019 in this study we have used different statistical criteria to evaluate the performance of the models in the development of accurate flood susceptibility maps using part abpart bpart dpart and rsspart methods the statistical measure applied are receiver operating characteristic roc the area under the roc curve auc positive predictive value ppv negative predictive value npv sensitivity sst specificity spf accuracy acc kappa k and root mean square error rmse the statistical analysis is based on the true positive tp the false positive fp the false negative fn and the true negative tn values obtained by calculating the observed output and the projected output of the models ma et al 2021 zuo et al 2015 the indicators of ppv npv sst spf and acc are computed based on a bewilderment matrix that needs a threshold for example the cut off value jaafari et al 2019 in spatial modeling of flood occurrence the ppv is the ratio of rightly categorized flood pixels out of all pixels categorized as flood pixels the npv is the coefficient of pixels that were rightly categorized as non flood the sst is the portion of validly classified flood pixels out of all pixels that were validly ordered as flood pixels plus those imprecise ordered as non flood pixels the spf is the ratio of properly ordered non flood pixels out of all pixels the acc illustrates the entire performance of the forecasting model and is computed as the ratio of properly classified flood and non flood pixels in other words accuracy displays which part of the modeled amounts are true efron and tibshirani 1986 xue et al 2020 kappa is the degree of settlement amongst the model and the observed flood occurrence model jiang et al 2017 viera and garrett 2005 rmse represents the mean squares discrepancy amid the genuine real and anticipated amounts ghasemain et al 2020 tran and prakash 2020 van phong et al 2020 in general the rmse represents the error appraisement of models therefore low rmse amounts display further execution of the models pham et al 2020b sun et al 2021 zhang et al 2021 the roc curve is a graph that shows the cognitive capability of a double classification model with a different threshold for distinction hence the auc is usually calculated to the numerical value of the model s execution when classifying in a particular dataset kordestani et al 2019 the auc varies from 0 5 to 1 a good model is the one in which the auc is equal to or close to one while the incomplete model is close to 0 5 in the auc tien bui et al 2016 auc index classes includes 0 9 1 excellent 0 8 0 9 very good 0 7 0 8 good 0 6 0 7 moderate and 0 5 0 6 weak ozdemir 2020 ppv npv sst spf acc k and rmse can be given by 2 sst tp tp f n 3 spf tn tn f p 4 ppv tp fp t p 5 npv tn fn t n 6 k p p p exp 1 p exp 7 acc tp t n tp t n f p f n 8 r m s e i 1 n x a c t x p r e d 2 n where pexp is defined as the expected agreements pp is defined as the accuracy n is the total instance of observations xpred is the predicted value of observations and xact is the real output value of observations 4 results 4 1 frequency ratio in this study fr values were calculated for each factor class category table 3 in the fr analysis the value of 0 was assigned to each class category of the factors that lacks flood pixel the highest fr value 11 3 was calculated for the class 7 1648772 4501661 of flow accumulation table 3 this very high value is caused by the concentration of almost all flood pixels 99 37 within this class particularly in the case of land use predictor there are two categories mining areas and woodland without any flood pixels for which the fr is equal to 0 further very low fr was found for forests 0 06 and plants in residential areas 0 53 relatively high fr values are associated with residential areas 5 59 and construction areas 5 58 as they are predominantly impervious 4 2 feature selection analysis oner method was performed to select and prioritize the ten flood affecting factors considered in the model study fig 5 based on oner the am index was estimated for the factors affecting the flood event accordingly the factors were ranked from 1 to 10 the am values in the three factors land use 82 31 geology 79 81 slope 74 73 are the highest in affecting spatial flood modeling in comparison to other factors thus these factors have the most significant impact on the performance of the flood models on the other hand flow direction flow accumulation and distance from river factors with values of 47 68 50 98 and 57 77 respectively have the most negligible impact on flood modeling finally curvature am 65 18 elevation am 73 46 river density am 74 and rainfall am 74 52 are graded 4 to 7 in the modeling of floods in the study area from the feature selection results we can see that all ten factors contribute to flood modeling thus all these factors were used in this study for flood susceptibility modeling 4 3 analysis of the models in this study flood susceptibility maps were generated using the part abpart bpart dpart and rsspart models and the performance of the models was evaluated using the standard statistical measures namely ppv npv sst spf acc k and rmse table 4 and auc fig 6 the roc curves indicated that the performance of all the models was good 0 9 on both the training and validation datasets but the performance of the rsspart model was the highest on the validation datasets auc 0 959 whereas abpart model has the highest value of auc 0 994 on the training dataset values of other statistical parameters ppv 91 96 npv 89 66 sst 91 96 spf 89 66 acc 90 95 k 0 816 and lower rmse 0 286 also indicated that the rsspart ensemble model had the highest accuracy on validating datasets compared to the other models table 4 thus it can be concluded that the rsspart model is the best in predicting flood susceptibility areas zones 4 4 flood susceptibility mapping flood susceptibility maps generated using part abpart bpart dpart and rsspart models are presented in fig 7 more specifically using the training results of these models flood susceptibility indices were generated for all pixels of the study area and then these values were classified into five classes using the natural break classification method in arcgis the natural break method helps in grouping the similar values and maximizes the differences among the classes yalcin and gul 2017 this classification method has been also used in many previous studies related to the natural hazards susceptibility mapping arabameri et al 2020b hosseini et al 2019 it can be seen that the highest susceptibility of floods is in the area near the sea which is reasonable due to flat area near the coast fig 8 a shows the percentage of five flood susceptibility classes based on all five models fig 8 b shows the number of flood points falling in the five flood susceptibility classes fig 8 c presents the fr of flood occurrence in different flood susceptibility classes the results show that the highest percentage of flood occurrence according to all five models part abpart bpart dpart and rsspart used in the present study occurred in the very high susceptibility class the maps were validated using the fr analysis for flood susceptibility classes frfs it is seen that most high flood event locations located in very high flood occurrence classes in all the models rsspart 14 8 dpart 14 6 bpart 9 73 abpart 7 85 and part 7 46 however the map generated by the rsspart model with the highest frfs 14 8 was the best compared to others 5 discussion we have used five ml models in the present study namely part abpart bpart dpart and rsspart to generate flood susceptibility maps it was the first applicaton of part classifier for developing ensemble with adaboost bagging dagging and random subspace algorithms for the prediction of flood susceptibility areas in the quang binh province vietnam for the development of flood susceptibility models the selection of appropriate flood affecting factors features is essential the importance of flood affecting factors depends on the local geo environment factors and methodology adopted hosseini et al 2019 used rf model and found that the distance to stream is the most important factor followed by normalized differential vegetation index ndvi and drainage density based on am index radmehr and araghinejad 2014 gave importance to drainage density péter et al 2012 considered rainfall and topographic wetness index twi as the most important factor khosravi et al 2018 and truong et al 2018 studied different models with different models that deemed slope as the most important factor in flood susceptibility mapping in this study ten flood affecting factors were selected based on the geo environmental conditions of the area oner method was used for measuring the am of each one of the effective factors and for ranking them in terms of their importance on flood occurrence in the study area other researchers have also used oner method to select and prioritize important factors in similar studies nguyen et al 2020 results of the oner analysis suggested that all the factors have relevance in the flood occurrence and thereby can be used for flood susceptibility modeling however the most basic and influential factors in the modeling of floods were land use am 82 31 geology am 79 81 slope am 74 73 and these factors ranked from one to three in the modeling of floods in the study area another crucial factor for flood occurrence was the mean sum of annual rainfall which in this study ranked the fourth flood occurs in the area after the first saturation of ground that is the reason in most cases floods occur in later phases of rainy season floods can also happen with the sudden melting of glaciers in valleys or tsunamis in coastal areas typically associated with rainfalls floods occur mostly in valleys low lying areas near river banks run off is more where geological formations soil and rocks are impervious in the initial phases of rainfall itself there are many methods available for the interpolation of the rainfall data in this study we have used idw method which is a deterministic technique used by other researchers tomczak and analysis 1998 valent et al 2015 the validation process showed that the ensemble rsspart model performed the best in the testing phase auc 0 959 ppv 91 96 npv 89 66 sst 91 96 spf 89 66 acc 90 95 k 0 816 and lower rmse 0 286 this higher performance of can be attributed to the main characteristic of the rss technique that performs a random selection from the feature subsets and results in low correlated multiple weak learners shin 2020 6 concluding remarks in this study gis based ensemble computational approaches were developed to generate flood susceptibility maps of the quang binh province vietnam it was the first time the part was used as a base classifier for developing ensemble ml models for the mapping and prediction of flood susceptibility zones oner method was used to select and prioritize the ten flood affecting factors elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology for the modeling am index obtained from the oner method indicated that land use 82 31 geology 79 81 slope 74 73 factors largely influenced flood occurrence in the study area other factors also had relatively higher am values 47 68 to 74 52 hence they were also used for the flood susceptibility modeling validation results showed that the newly developed rsspart model with auc 0 959 outperformed the other models in predicting flood susceptible areas therefore the flood susceptibility map developed using this model is of high quality and can be used by planners and decision makers for more informed flood management planning the study showed that land use pattern plays a very important role in the flooding of the study area therefore anthropogenic activities should be appropriately planned to lessen and prevent the impact of floods the limitation of our study is that we have considered only fluvial floods in the modeling future works can apply these models to both pluvial and flash floods to provide a basis for comprehensive comparing the model performance credit authorship contribution statement chinh luu conceptualization methodology project administration funding acquisition data curation visualization investigation supervision software validation writing review editing writing original draft binh thai pham conceptualization methodology project administration funding acquisition data curation visualization investigation supervision software validation writing review editing writing original draft tran van phong data curation visualization investigation software validation writing original draft writing review editing romulus costache supervision software validation writing original draft writing review editing huu duy nguyen conceptualization methodology software writing original draft writing review editing validation supervision mahdis amiri conceptualization methodology software writing review editing validation supervision writing original draft quynh duy bui data curation visualization investigation writing original draft luan thanh nguyen data curation writing original draft hiep van le data curation writing original draft indra prakash supervision writing original draft writing review editing phan trong trinh supervision software validation writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this research is funded by vietnam national foundation for science and technology development nafosted under grant number 105 08 2019 319 
4483,recently floods are occurring more frequently every year around the world due to increased anthropogenic activities and climate change there is a need to develop accurate models for flood susceptibility prediction and mapping which can be helpful in developing more efficient flood management plans in this study the partial decision tree part classifier and the adaboost bagging dagging and random subspace ensembles learning techniques were combined to develop novel gis based ensemble computational models abpart bpart dpart and rsspart for flood susceptibility mapping in the quang binh province vietnam in total 351 flood locations were used in the model study this data was divided into a 70 30 ratio for model training 70 255 locations and 30 96 locations for model validation ten flood influencing factors namely elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology were used for the development of models the oner feature selection method was used to select and prioritize important factors for the spatial modeling the results revealed that land use geology and slope are the most important conditioning factors in the occurrence of floods in the study area standard statistical methods including the roc curve auc were used for the performance evaluation of models results indicated that the performance of all models was good auc 0 9 and rsspart auc 0 959 outperformed the others thus the rsspart model can be used for accurately predicting and mapping flood susceptibility keywords machine learning decision trees oner feature selection geographic information system gis vietnam 1 introduction floods are among the most common natural events occurring in most parts of the world damaging properties and causing huge loss of life costache et al 2020 they occur when the amount of precipitation surpasses the capacity of reservoirs liu et al 2018 mohamed 2019 and river channels in the coastal areas floods occur due to tropical cyclones and tsunami waves minh et al 2018 wang et al 2014 zhang et al 2020b in mountainous areas floods also occur when snow melts rapidly causing flash floods climate change is considered one of the main causes of change in flooding patterns intensity and magnitude hens et al 2018 van thanh et al 2017 as a consequence of the increasing intensity floods can cause sudden morphological changes in the area due to rapid erosion and landslides van tu et al 2016 causes of high flood risk in vietnam include tropical cyclones typhoons dense river networks and long coastal areas overall vietnam is highly susceptible to severe storms and floods and is ranked eighth among the ten countries with the highest number of weather events thao et al 2020 anthropogenic activities such as deforestation land use pattern change and city development increase the flood risk in vietnam most of the flood susceptible areas in vietnam are densely populated thus there is a constant risk of loss of life and property in such areas therefore spatial modeling of flood events to prevent and control the harmful risks of future floods will be of great help wu et al 2010 in view of this advanced modeling techniques are needed to accurately identify high flood susceptible areas for risk management henriksen et al 2018 so far many studies have been done to develop reliable flood susceptibility maps using remote sensing techniques and geographic information system gis nowadays machine learning ml techniques are being employed in conjunction with gis to address many environmental problems akay and taş 2020 such as develop flood susceptibility mapping some of the techniques used for flood spatial modeling are artificial neural network ann support vector machine svm random forest rf and boosted trees bt classification and regression trees crt adaptive network based fuzzy inference system anfis naïve bayes nb quick unbiased efficient statistical tree quest and genetic algorithm for rule set production garp darabi et al 2019 lee et al 2017 in recent years hybrid and ensemble ml models have emerged as they outperformed single models in terms of prediction accuracy zenggang et al 2019 many ensemble learning techniques such as adaboost bagging dagging and random subspace ensembles have been recently used to improve the predictive accuracies of natural pham et al 2020a 2021 tran et al 2020 tuyen et al 2021 in this study we have used partial decision tree part as a base classifier in developing ensemble models abpart bpart dpart and rsspart which used adaboost bagging dagging and random subspace algorithms respectively as optimization techniques for the flood susceptibility mapping in quang binh province of vietnam this study reports the first application of the part classifier in developing new ensemble models for flood susceptibility prediction and mapping 2 study area and data used 2 1 study area description the quang binh province with an area of about 800 km2 and a population of 887600 is located in the north central coastal region of vietnam fig 1 this province was selected as a case study because it is one of the most flood prone areas in vietnam luu et al 2019 it is located in the tropical monsoon region having a transitional climate of the north and the south of vietnam son et al 2017 with relatively cold winters in the north and a typical tropical climate in the south maximum rainfall is concentrated in three months of september october and november and coincides with floods and storms occurring in the province van thang et al 2019 recent hazardous flood events occurred in the years 1995 1999 2007 2008 2010 and 2016 2 2 flood inventory floods have frequently occurred in the area and affected the life property and socio economic conditions of the province fig 2 a flood inventory map was constructed using the flood marks data obtained from the quang binh centre for hydrometeorological forecasting in total 321 flood events that occurred in 2007 2010 and 2016 were considered in this study fig 1 in 2007 within three days from 3 to 7th october 2007 flood caused 4 fatalities 69 injuries and 26 597 houses flooded and damaged nasa 2007 the 2010 year flood event caused 74 fatalities flooded and damaged 188 628 houses besides affecting agriculture transportation and fisheries united nations vietnam 2010 in the year 2016 flood event in october 2016 caused 18 fatalities 13 injuries flooding and damage of 71 251 besides damage of infrastructure in quang binh province echo 2016 2 3 flood conditioning factors in this study ten flood conditioning factors were selected based on the local geo environment conditions and literature survey for the flood susceptibility modeling studies bui et al 2019 pham et al 2021 2020e luu et al 2020 these factors are elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology table 1 and fig 3 that are described as follows 2 4 elevation the elevation map was extracted from the 30 m resolution shuttle radar topography mission srtm digital elevation model dem version 3 collected from earth data platform https search earthdata nasa gov search of quang binh province fig 3a and table 1 this factor is important in flood modeling as it affects precipitation and flow conditions ahmadlou et al 2018 the elevation map was classified into seven class intervals using the natural break classification method for the model study fig 3a 2 5 slope steep slopes increase the speed of surface run off and reduce the infiltration in the soil agassi et al 1990 the slope angle map was derived from the dem map and classified into seven classes the slope angle map of the study area ranges from 0 to 77 52 fig 3b and table 1 river valleys and low lying areas are affected by floods 2 6 curvature another topographic factor curvature was extracted from the dem map the curvature represents convex concave and flat surfaces indicating positive negative and zero surfaces respectively chapi et al 2017 this factor is related to the run off on the curved surface thus surface flow manfreda et al 2014 thai pham et al 2019 fig 3c and table 1 2 7 flow direction flow direction is a hydrological factor that shows the direction of the flow this factor map was created using arc hydro tool of arcgis and classified into five classes using the natural break classification method fig 3d and table 1 flow direction is important in assessing the area where surface flow will travel and cause flooding 2 8 flow accumulation flow accumulation represents the proportionality of water concentration during a flood nguyen et al 2019 the flow accumulation map was obtained from the flow direction map by using flow accumulation tool of arcgis this tool calculated accumulated flow in each upstream cell into downslope cells in the output raster fig 3e and table 1 2 9 river density river density is an important factor that directly affects flood occurrence bui et al 2019 liu et al 2021 quang binh province has a dense river system that includes five main river basins of roon gianh ly hoa dinh and nhat le the total length of the river system is 343 km and the total area of the river basins is 7 890 km2 the flow of water is equivalent to 4 billion m3 per year the river density factor is calculated by dividing river stream length m by a watershed area km2 the river density map was prepared and classified into seven classes fig 3f and table 1 2 10 distance from river the inundation areas are often located near the river basins due to an overflow of water from river banks terti et al 2017 we calculated the distance from river factor based on river system map using euclidian distance tool in arcgis pro the distance from river was classified into five classes using the manual classification method fig 3g and table 1 2 11 rainfall the rainfall distribution map is very important for developing a flood susceptibility map spekkers et al 2014 the annual rainfall distribution map was created based on 16 precipitation stations 10 in quang binh province and 6 in ha tinh and quang tri province the dataset of 31 years from 1986 to 2016 was used to generate the rainfall map of the research area using the inverse distance weighted idw method mair and fares 2011 fig 3h and table 1 2 12 land use a land use map shows the distribution of land use categories in the area this factor is an important factor in assessing anthropogenic activities impacts affecting run off and inundation hosseini et al 2020 we collected the land use map established in 2015 by the quang binh department of natural resources and environment the land use map includes ten categories woodland 1 1 water bodies 2 7 transportation 0 2 soil bare 1 2 residential areas 5 8 plants in residential areas 16 5 mining areas 0 1 forest 64 6 construction areas 2 5 and agricultural areas 5 3 fig 3i and table 1 2 13 geology geology affects erosion surface flow and infiltration based on the characteristics of the rocks and geological structures zhang et al 2020a we collected the geology map from the quang binh department of natural resources and environment which indicates 35 different geological categories fig 3j and table 2 3 methodology 3 1 methodological flowchart in the first step flood inventory and thematic maps elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology were created then the oner feature selection method was used to prioritize the flood conditioning factors frequency ratio method was applied to analyze spatial associations between floods and each class of the conditioning factors for the modeling process the flood locations were divided by a 70 30 ratio out of these 70 of the data was used for the training of the models and 30 for the validation further the ensemble learning techniques used in developing ensemble models were adaboost bagging dagging and random subspace and the partial decision tree part algorithm as a base classifier the models performance was evaluated using the standard statistical measures finally flood susceptibility maps were generated using the models in a gis environment the methodology adopted in this study is described in fig 4 3 2 methods used 3 2 1 frequency ratio fr in flood susceptibility research it is very important to quantify the importance of different conditioning factors on flood occurrence a very efficient way to carry out this analysis is represented by the computation of frequency ratio fr for each class category of the factors fr is a bivariate statistical model which is widely used in the literature for hazards susceptibility estimation costache and zaharia 2017 thanh et al 2020a fr values are achieved by applying the ratio between the percentage of flood pixels from a class category within the total flood pixels of the study area and the percentage of class category total pixels within the total pixels of the study area 1 fr npix 1 npix 2 n p i x 3 n p i x 4 where npix 1 is the total number of floods in a factor category npix 2 is the total pixels in a category n p i x 3 is the total flood pixels in the research area and n p i x 4 is the number of pixels in the research area 3 2 2 partial decision tree part in partial decision tree part a set of methods are used to compare the importance of a specific variable compared to the other variables based on multiple objectives and criteria da silva et al 2020 frank and witten 1998 preparing a straight relationship matrix is the vital benefit of the decision making process that is used to build relationships lee et al 2013 part is quick in prediction which contains branches to undefined sub trees by integrating construction and pruning operations to find stable sub tree which cannot be simplified further at this point tree building ceases and a single rule is formed in the part rules are inferred by repeatedly generating partial decision trees by separate and conquer rule learning technique frank and witten 1998 the main reason for selecting the part algorithm is given by its advantage represented by the use of the direct relation matrix to analyze the causal relationships between the variables frank and witten 1998 3 2 3 adaboost adaboost or adaptive boosting technique is a simple and general boosting method that iteratively produces individual classifiers whose main scope is the accurate classification of training data hong et al 2018 adaboost algorithm contains two principal sections the excess model and the stage by stage algorithm in the excess model there is an intense classifier that synthesizes the linear succession of feeble classifiers arabameri et al 2020a li et al 2020 the value of the final classifier is equal to a weighted sum obtained by using the ensemble predictions hong et al 2018 one of the most important advantages of the adaboost algorithm for which this method was selected for the present study is given by the fact that this algorithm in the classification process is able to remove some unimportant aspects of the training data and place them on top of the critical and crucial training data moreover the adaboost method is fundamentally a naive raising procedure of unable categorization way and this action can modify the data classification capability by decreasing both prejudice and variance the fact or quality of being different via successive training wu et al 2020 a comprehensive description of the mathematical relationships underlying this method is included in the published scientific work tang et al 2020 3 2 4 bagging bagging or bootstrap aggregating technique is an ensemble method based on bootstrapping procedure the positive privilege and at the same time the advantage of the bagging model is that it can reduce overfitting and accomplish well on powerful categories thanh et al 2020b another critical reason to use bagging classification is that it can easily control the training data so that to keep the most important information for the modeling procedure instead the bagging model similar to other hybrid models is sensitive to classification bias and fuss the numeral of classifiers super variables is set of series at ten as outside this value no betterment in the model efficiency was seen particularly the addendum phases were in the fulfillment of the bagging algorithm yousaf et al 2020 similar to the adaboost technique bagging is a very popular model natural hazards modeling hong et al 2018 wu et al 2020 3 2 5 dagging dagging is a reintegration technique which is used to enhance the prediction accuracy of single lone basis classifications kotsianti and kanellopoulos 2007 one of the advantages of the dagging algorithm is that it involves a specific number of disjoint samples alternate for bootstrap samples to obtain the base classifiers roy and saha 2021 in addition dagging creates separate and distinct folds of data and prepares a packet of data for a duplicate version of the basic learning algorithm kotsianti and kanellopoulos 2007 the boot instances are changed via splinter instances while the procedure is renewed the original classifier by dagging the hypothesis is that n instances are in the training dataset a dagging algorithm makes m datasets from the principal dataset every dataset has n instances nm n and varied datasets do not have identical instances chen and li 2020 hence m classification models can be obtained from m datasets when every classification model produces its anticipation class based on a certain inquiry example the class that achieves the most options is regarded as the anticipation class of the dagging model zhu et al 2016 even if dagging ensemble is not very frequently used in flood susceptibility studies islam et al 2021 it has been used in for landslide susceptibility modeling pham et al 2020c sahana et al 2020 3 2 6 random subspace rss random subspace rss technique is used to reduce the size of the formula foundation and refrain from information damage the main advantage of rss model is represented by the random selection of the feature subsets that results in low correlated multiple weak learners shin 2020 creating manifold subspaces from a genuine dataset belongs to three essential variables the number of properties r in a subspace the numeral of subspaces and the property weight w that results in the possibility to exploit the properties the weight of the w property can be calculated using information from the instance data properties if the property attribute f is linked to an outcome attribute y the obtaining information oi is a general index that can extend how much information from the f attribute can lead to a y result rss algorithm is a common technique used in natural hazards modeling chen et al 2019 luo et al 2019 pham et al 2020d 3 2 7 one rule oner feature selection method feature selection is recognized as the primary variable selection in the modeling process or electing substantial subsets that have a greater impact on the occurrence of an event such as a flood einicke et al 2018 feature selection techniques used to select the most significant predictor variables for 1 simplifying the model for exegesis by users 2 model time and training are less and 3 raised popularization by decreasing overfitting or diminution of variance when applying the characteristic choice way the basic premise is that the data includes several exclusives that are superfluous or unfitting and therefore can be deleted without endurance much damage to information superfluous and unfitting are two separate concepts one pertaining peculiarity might be waste in the attendance of another linked peculiarity with which it is forcefully associated sarangi et al 2020 oner abbreviated one rule is a modest yet precise classification algorithm that creates a rule for each anticipant in the data then opts this rule as its rule with the smallest whole error it does holte 1993 in this study oner was used as a feature selection to evaluate and rank the importance of each flood conditioning factor for flood susceptibility modeling for each factor this algorithm looks for a simple rule by determining the majority class for each factor s value thereafter the accuracy of a certain rule is evaluated and the factors are ranked and ordered according to the quality of the corresponding rules indicating by average merit am index pes and applications 2020 3 2 8 validation indicators the appraisal of spatial modeling results of flood events in the study area is done using both training and validation datasets to select the best model that can produce an accurate flood susceptibility map hosseini et al 2019 in this study we have used different statistical criteria to evaluate the performance of the models in the development of accurate flood susceptibility maps using part abpart bpart dpart and rsspart methods the statistical measure applied are receiver operating characteristic roc the area under the roc curve auc positive predictive value ppv negative predictive value npv sensitivity sst specificity spf accuracy acc kappa k and root mean square error rmse the statistical analysis is based on the true positive tp the false positive fp the false negative fn and the true negative tn values obtained by calculating the observed output and the projected output of the models ma et al 2021 zuo et al 2015 the indicators of ppv npv sst spf and acc are computed based on a bewilderment matrix that needs a threshold for example the cut off value jaafari et al 2019 in spatial modeling of flood occurrence the ppv is the ratio of rightly categorized flood pixels out of all pixels categorized as flood pixels the npv is the coefficient of pixels that were rightly categorized as non flood the sst is the portion of validly classified flood pixels out of all pixels that were validly ordered as flood pixels plus those imprecise ordered as non flood pixels the spf is the ratio of properly ordered non flood pixels out of all pixels the acc illustrates the entire performance of the forecasting model and is computed as the ratio of properly classified flood and non flood pixels in other words accuracy displays which part of the modeled amounts are true efron and tibshirani 1986 xue et al 2020 kappa is the degree of settlement amongst the model and the observed flood occurrence model jiang et al 2017 viera and garrett 2005 rmse represents the mean squares discrepancy amid the genuine real and anticipated amounts ghasemain et al 2020 tran and prakash 2020 van phong et al 2020 in general the rmse represents the error appraisement of models therefore low rmse amounts display further execution of the models pham et al 2020b sun et al 2021 zhang et al 2021 the roc curve is a graph that shows the cognitive capability of a double classification model with a different threshold for distinction hence the auc is usually calculated to the numerical value of the model s execution when classifying in a particular dataset kordestani et al 2019 the auc varies from 0 5 to 1 a good model is the one in which the auc is equal to or close to one while the incomplete model is close to 0 5 in the auc tien bui et al 2016 auc index classes includes 0 9 1 excellent 0 8 0 9 very good 0 7 0 8 good 0 6 0 7 moderate and 0 5 0 6 weak ozdemir 2020 ppv npv sst spf acc k and rmse can be given by 2 sst tp tp f n 3 spf tn tn f p 4 ppv tp fp t p 5 npv tn fn t n 6 k p p p exp 1 p exp 7 acc tp t n tp t n f p f n 8 r m s e i 1 n x a c t x p r e d 2 n where pexp is defined as the expected agreements pp is defined as the accuracy n is the total instance of observations xpred is the predicted value of observations and xact is the real output value of observations 4 results 4 1 frequency ratio in this study fr values were calculated for each factor class category table 3 in the fr analysis the value of 0 was assigned to each class category of the factors that lacks flood pixel the highest fr value 11 3 was calculated for the class 7 1648772 4501661 of flow accumulation table 3 this very high value is caused by the concentration of almost all flood pixels 99 37 within this class particularly in the case of land use predictor there are two categories mining areas and woodland without any flood pixels for which the fr is equal to 0 further very low fr was found for forests 0 06 and plants in residential areas 0 53 relatively high fr values are associated with residential areas 5 59 and construction areas 5 58 as they are predominantly impervious 4 2 feature selection analysis oner method was performed to select and prioritize the ten flood affecting factors considered in the model study fig 5 based on oner the am index was estimated for the factors affecting the flood event accordingly the factors were ranked from 1 to 10 the am values in the three factors land use 82 31 geology 79 81 slope 74 73 are the highest in affecting spatial flood modeling in comparison to other factors thus these factors have the most significant impact on the performance of the flood models on the other hand flow direction flow accumulation and distance from river factors with values of 47 68 50 98 and 57 77 respectively have the most negligible impact on flood modeling finally curvature am 65 18 elevation am 73 46 river density am 74 and rainfall am 74 52 are graded 4 to 7 in the modeling of floods in the study area from the feature selection results we can see that all ten factors contribute to flood modeling thus all these factors were used in this study for flood susceptibility modeling 4 3 analysis of the models in this study flood susceptibility maps were generated using the part abpart bpart dpart and rsspart models and the performance of the models was evaluated using the standard statistical measures namely ppv npv sst spf acc k and rmse table 4 and auc fig 6 the roc curves indicated that the performance of all the models was good 0 9 on both the training and validation datasets but the performance of the rsspart model was the highest on the validation datasets auc 0 959 whereas abpart model has the highest value of auc 0 994 on the training dataset values of other statistical parameters ppv 91 96 npv 89 66 sst 91 96 spf 89 66 acc 90 95 k 0 816 and lower rmse 0 286 also indicated that the rsspart ensemble model had the highest accuracy on validating datasets compared to the other models table 4 thus it can be concluded that the rsspart model is the best in predicting flood susceptibility areas zones 4 4 flood susceptibility mapping flood susceptibility maps generated using part abpart bpart dpart and rsspart models are presented in fig 7 more specifically using the training results of these models flood susceptibility indices were generated for all pixels of the study area and then these values were classified into five classes using the natural break classification method in arcgis the natural break method helps in grouping the similar values and maximizes the differences among the classes yalcin and gul 2017 this classification method has been also used in many previous studies related to the natural hazards susceptibility mapping arabameri et al 2020b hosseini et al 2019 it can be seen that the highest susceptibility of floods is in the area near the sea which is reasonable due to flat area near the coast fig 8 a shows the percentage of five flood susceptibility classes based on all five models fig 8 b shows the number of flood points falling in the five flood susceptibility classes fig 8 c presents the fr of flood occurrence in different flood susceptibility classes the results show that the highest percentage of flood occurrence according to all five models part abpart bpart dpart and rsspart used in the present study occurred in the very high susceptibility class the maps were validated using the fr analysis for flood susceptibility classes frfs it is seen that most high flood event locations located in very high flood occurrence classes in all the models rsspart 14 8 dpart 14 6 bpart 9 73 abpart 7 85 and part 7 46 however the map generated by the rsspart model with the highest frfs 14 8 was the best compared to others 5 discussion we have used five ml models in the present study namely part abpart bpart dpart and rsspart to generate flood susceptibility maps it was the first applicaton of part classifier for developing ensemble with adaboost bagging dagging and random subspace algorithms for the prediction of flood susceptibility areas in the quang binh province vietnam for the development of flood susceptibility models the selection of appropriate flood affecting factors features is essential the importance of flood affecting factors depends on the local geo environment factors and methodology adopted hosseini et al 2019 used rf model and found that the distance to stream is the most important factor followed by normalized differential vegetation index ndvi and drainage density based on am index radmehr and araghinejad 2014 gave importance to drainage density péter et al 2012 considered rainfall and topographic wetness index twi as the most important factor khosravi et al 2018 and truong et al 2018 studied different models with different models that deemed slope as the most important factor in flood susceptibility mapping in this study ten flood affecting factors were selected based on the geo environmental conditions of the area oner method was used for measuring the am of each one of the effective factors and for ranking them in terms of their importance on flood occurrence in the study area other researchers have also used oner method to select and prioritize important factors in similar studies nguyen et al 2020 results of the oner analysis suggested that all the factors have relevance in the flood occurrence and thereby can be used for flood susceptibility modeling however the most basic and influential factors in the modeling of floods were land use am 82 31 geology am 79 81 slope am 74 73 and these factors ranked from one to three in the modeling of floods in the study area another crucial factor for flood occurrence was the mean sum of annual rainfall which in this study ranked the fourth flood occurs in the area after the first saturation of ground that is the reason in most cases floods occur in later phases of rainy season floods can also happen with the sudden melting of glaciers in valleys or tsunamis in coastal areas typically associated with rainfalls floods occur mostly in valleys low lying areas near river banks run off is more where geological formations soil and rocks are impervious in the initial phases of rainfall itself there are many methods available for the interpolation of the rainfall data in this study we have used idw method which is a deterministic technique used by other researchers tomczak and analysis 1998 valent et al 2015 the validation process showed that the ensemble rsspart model performed the best in the testing phase auc 0 959 ppv 91 96 npv 89 66 sst 91 96 spf 89 66 acc 90 95 k 0 816 and lower rmse 0 286 this higher performance of can be attributed to the main characteristic of the rss technique that performs a random selection from the feature subsets and results in low correlated multiple weak learners shin 2020 6 concluding remarks in this study gis based ensemble computational approaches were developed to generate flood susceptibility maps of the quang binh province vietnam it was the first time the part was used as a base classifier for developing ensemble ml models for the mapping and prediction of flood susceptibility zones oner method was used to select and prioritize the ten flood affecting factors elevation slope curvature flow direction flow accumulation river density distance from river rainfall land use and geology for the modeling am index obtained from the oner method indicated that land use 82 31 geology 79 81 slope 74 73 factors largely influenced flood occurrence in the study area other factors also had relatively higher am values 47 68 to 74 52 hence they were also used for the flood susceptibility modeling validation results showed that the newly developed rsspart model with auc 0 959 outperformed the other models in predicting flood susceptible areas therefore the flood susceptibility map developed using this model is of high quality and can be used by planners and decision makers for more informed flood management planning the study showed that land use pattern plays a very important role in the flooding of the study area therefore anthropogenic activities should be appropriately planned to lessen and prevent the impact of floods the limitation of our study is that we have considered only fluvial floods in the modeling future works can apply these models to both pluvial and flash floods to provide a basis for comprehensive comparing the model performance credit authorship contribution statement chinh luu conceptualization methodology project administration funding acquisition data curation visualization investigation supervision software validation writing review editing writing original draft binh thai pham conceptualization methodology project administration funding acquisition data curation visualization investigation supervision software validation writing review editing writing original draft tran van phong data curation visualization investigation software validation writing original draft writing review editing romulus costache supervision software validation writing original draft writing review editing huu duy nguyen conceptualization methodology software writing original draft writing review editing validation supervision mahdis amiri conceptualization methodology software writing review editing validation supervision writing original draft quynh duy bui data curation visualization investigation writing original draft luan thanh nguyen data curation writing original draft hiep van le data curation writing original draft indra prakash supervision writing original draft writing review editing phan trong trinh supervision software validation writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this research is funded by vietnam national foundation for science and technology development nafosted under grant number 105 08 2019 319 
4484,a multi isotopes approach involving the use of stable nitrate isotopes δ15nno3 and δ18ono3 combined with stable water isotopes δ18oh2o and δ2hh2o as tracers can help identify the nitrogen source and understand the transformation process in a river water system in this study we identify the potential impact of the n source in the effluent discharged from a wastewater treatment plant wwtp on the surrounding stream and clarified the seasonal variations in the isotope values of the effluent and stream water from 2019 to 2020 in south korea in addition we investigate the factors that led to the seasonal variations of the stable isotopes and evaluated the relationship between the uncertainty of the contribution ratio of the n sources and isotopic variations in the river water system to examine the potential impact of the inputs of n from the wwtp samples were obtained from the stream up and down with respect to the wwtp and wwtp influent and treated effluent once a month for the monthly effluent samples δ18oh2o and δ2hh2o ranged from 9 37 to 8 68 and from 65 29 to 59 37 respectively exhibiting isotopic depletion in wet season and enrichment in dry season moreover in the effluent δ15nno3 and δ18ono3 ranged from 10 56 to 16 60 and 4 86 to 0 35 respectively to clarify the seasonal variation in the effluent high resolution samples of the influent and treated effluent were obtained every day in september 2019 it is noted that δ15nno3 in the effluent was influenced by the n source instead of the seasonal variation although δ18ono3 exhibited a high dependence on the seasonal effects influenced by δ18oh2o when estimating the contribution of the effluent using isotope values to the water system uncertainty could arise due to these seasonal variations overall a multi isotope approach involving the combined use of stable nitrate isotopes δ15nno3 and δ18ono3 and stable water isotopes δ18oh2o and δ2hh2o as tracers can help evaluate the potential impact of n sources on water systems keywords wastewater treatment plant stable nitrate isotopes stable water isotopes multi isotope approach 1 introduction nitrogen is an essential element for plant growth and human diet however excessive supplies of nitrate no3 may lead to hypoxia and eutrophication in lake and coastal water as well as emission of the greenhouse gas nitrous oxide n2o through denitrification davidson 2012 sobota et al 2015 lin et al 2019 although nitrate can be naturally produced nitrate as nitrogen no3 n concentrations greater than 3 mg l generally indicate contamination madison and brunett 1985 and a recent nationwide study reported that no3 n concentrations higher than 1 mg l indicate human activity dubrovskyet al 2010 in particular the nitrogen input has rapidly increased in terrestrial ecosystems due to continuous population growth agriculture urbanization and the presence of nitrate contaminants in water has become a global environmental problem smil 1997 davidson 2012 xian et al 2016 to prevent the damage due to high nitrate concentrations the united states environmental protection agency us epa and world health organization who have specified that the concentration of no3 n in drinking water must be less than 10 mg l and 11 3 mg l respectively u s environmental protection agency 1991 world health organization 2004 in south korea treated effluents from wastewater treatment plants wwtp correspond to the largest proportion of nitrogen emission from point sources and account for 89 5 of the total amount of nitrogen discharged to point sources national institute of environmental research 2015 according to water quality monitoring data from 2007 to 2017 the nitrogen level in domestic rivers is relatively high compared with that in the organization for economic cooperation and development oecd member countries and the concentration of total nitrogen tn has been recently stagnant a decreasing trend in south korea korea environment institute 2018 therefore it was found that continuous management for decreasing nitrogen is necessary stable nitrate isotopes δ15nno3 and δ18ono3 can provide valuable insights into the nitrate sources transformations and mixing processes kendall 1998 xia et al 2018 lutz et al 2020 torres martínez et al 2021 the stable isotopic ratios of nitrogen and oxygen δ15nno3 and δ18ono3 values in the nitrate have distinguished values in various nitrogen sources such as atmospheric nitrogen no3 based fertilizers nh4 based fertilizers soil sewage and manure and thus represent an effective tool to identify the nitrogen source and flowpath in the water system kendall 1998 jung et al 2020 in particular the treated effluent is enriched in 15n relative to the residual nitrogen due to the volatilization and nitrification of nh4 and denitrification of no3 via the sewage treatment processes which may yield unique stable isotope values compared to those in other nitrogen sources in aquatic systems hood et al 2014 xue et al 2009 many researchers have attempted to examine the impact of the nitrogen source of treated effluent discharged from wwtps in the river water system by using nitrate isotopes sebilo et al 2006 considered the isotopic compositions of ammonium δ15nnh4 and nitrate δ15nno3 and δ18ono3 to identify the nitrogen source in the effluent and evaluated the nitrogen transformation process from this nitrogen source in the seine river france anisfeld et al 2007 calculated the contributions of treated effluent and atmospheric deposition by considering the stable nitrate isotopes δ15nno3 and δ18ono3 of the effluent in and precipitation at the quinnipiac and naugatuck rivers the us archana et al 2016 calculated the contribution of treated effluent from 68 wwtps corresponding to five treatment types to seawater from northeast hongkong by considering stable nitrate isotopes δ15nno3 and δ18ono3 xian et al 2016 investigated the variation in the isotopic signature of the influent and effluent at a wwtp in beijing china by considering stable nitrate isotopes δ15nno3 and δ18ono3 and calculated the contribution of these effluents to the surrounding rivers adebowale et al 2019 investigated the impact of n source from the wwtp near boneo in southeast australia on the surrounding groundwater by considering stable nitrate isotopes δ15nno3 and δ18ono3 lin et al 2019 investigated the impact of the n sources of the effluent and agricultural groundwater on the surrounding streams by using stable nitrate isotopes δ15nno3 and δ18ono3 in the illinois river system the us and the spatial and temporal variation of these nitrate sources however certain uncertainties are involved when the contribution of the nitrogen sources is calculated without considering the variation in the isotope value because the nitrate isotope changes continuously owing to the isotopic fractionation through the biogeochemical process xue et al 2009 kendall 1998 archana et al 2016 furthermore if the oxygen isotope values are similar and the nitrogen isotope values overlap in the case of nh4 based fertilizers sewage and manure sources the exact identification of the nitrogen sources through the isotopes may not be possible curt et al 2004 recently many studies were performed using a multi isotope approach combining nitrates with other stable isotopes δ13c δ34s δ11b and δ87sr 86sr which could provide additional information regarding the nitrate contaminant sources and mixing process aravena et al 1993 aravena and robertson 1998 widory et al 2004 kaown et al 2009 martinelli et al 2018 in particular stable water isotopic compositions only change via mixing with different water sources and fractionation processes associated with evaporation and condensation consequently the isotopic ratios in water can provide valuable information regarding the hydrologic processes dansgaard 1964 gat 1996 ingraham 1998 mcguire and mcdonnell 2007 jung et al 2020 therefore the multi isotope approach involving both stable water isotopes δ18oh2o and δ2hh2o with stable nitrate isotopes δ15nno3 and δ18ono3 can likely provide useful information regarding hydrological processes to track the flowpath of contaminants in groundwater jung et al 2020 consequently various studies were conducted using combined nitrate and water stable isotopes as tracers for the wastewater aravena et al 1993 considered δ15nno3 and δ18oh2o as well as the water chemistry na to effectively distinguish the plume of domestic septic systems from groundwater in the ontario region of canada moreover the residence time between the shallow unconfined aquifer and deep confined aquifer was defined yue et al 2013 analyzed the isotopic compositions of ammonium δ15nnh4 and nitrate δ15nno3 and δ18ono3 to differentiate between the source mixing of the wastewater and soil organic n in low and high flow seasons in the liao river basin china in addition the nitrogen transformation in the river was investigated by considering δ18oh2o in the river water torres martínez et al 2021 clarified the nitrogen contaminants and biogeochemical transformations by considering water and nitrate stable isotopes in the groundwater sites of comarca lagunera northern mexico in addition the contribution ratios of six nitrogen contaminants atmospheric deposition nh4 synthetic fertilizers no3 based fertilizers soil organic nitrogen sewage and manure were quantitatively calculated using the bayesian isotope mixing model jun et al 2005 identified nitrogen source inputs such as agricultural fertilizer animal waste and leakage of sewage by considering the δ18oh2o δ2hh2o and δ15nno3 values in the groundwater around the samgi stream a tributary of the bogang stream our study area according to a recent investigation of the korea water resources corporation 2018 the bogang stream which involves high biochemical oxygen demand bod concentrations owing to the presence of fertilizer manure and sewage is an example of a stream with numerous potential sources of contamination most of the existing studies that considered the nitrate and water stable isotopes as tracers attempted to identify the wastewater source and n transformation process in natural water systems but the nitrate isotopic signatures produced within the wastewater treatment system has not been studied moreover little information is presently available about water and nitrate isotopic signatures of effluent from wastewater treatment system therefore the present study was aimed at clarifying the potential impact of n source in the effluent discharged from a wwtp on the surrounding stream and the seasonal variation in the isotopic values of the effluent and stream water in addition we investigated the factors causing the stable isotopic variation in the effluent and stream water and evaluated the relationship between the uncertainty in the contribution ratio of the n sources and nitrate isotopic variations in the water system 2 study area and sampling 2 1 study area the study area is the jeungpyeong county in north chungcheong province in the center of the korean peninsula the geology of jeungpyeong county consists of quaternary alluvium sand about 20 m thick underlain by jurassic porphyritic granite korea agricultural and rural infrastructure corporation 2001 the considered wwtp is located in the jeungpyeong county and the effluent is released in the nearby bogang stream fig 1 the bogang stream which partially flows into the miho stream one of the tributary streams in the geumgang basins is approximately 19 85 km long and has a drainage area of 157 71 km2 daejeon regional construction management administration 2011 the bogang stream is surrounded by mountains so rainfall flows to the center of the basin and then flows out because the vadose zone is so shallow precipitation events quickly goes groundwater recharge and rises in the water table jun et al 2005 the major types of land use in jeungpyeong county can be classified into five categories forest 49 agricultural 28 residential 6 industrial 2 4 and livestock 0 4 as specified by the korean statistical information service https www data go kr the bogang stream predominantly pertains to agricultural and residential land use as illustrated in fig 1 2 2 sample acquisition to examine the behavior of both nitrate and water isotopes after the discharge of the effluent to the stream seven sampling points were chosen five at the jeungpyeong wwtp and two in the bogang stream fig 1 and sampling was performed using a 1 l sterilized sample bottle the five points in the wwtp corresponded to the 1 influent p1 2 distribution basin p2 3 state after the primary sedimentation p3 4 state after the secondary sedimentation p4 and 5 treated effluent p5 fig 1 the two sampling points in the bogang stream were located upstream sw 1 and downstream sw 2 of the tributary from which the effluent was discharged periodic sampling once a month from july 2019 to april 2020 was performed at the influent effluent sw 1 and sw 2 points moreover the influent and effluent were collected in 50 ml conical tubes every day at 10 00 am for one month in september 2019 to evaluate the variation trends in the water and nitrate stable isotopes during the investigation period all the samples were sent to the laboratory at the k water research institute in daejeon korea for measurement to be performed on the same day and refrigerated at 4 c until the analysis the samples for anions stable isotope analysis of nitrate 15nno3 and δ18ono3 and water δ2hh2o δ18oh2o were collected in high density polyethylene bottles and filtered using 0 45 μm membrane filters the daily precipitation and air temperature data for the jeungpyeong region during the study period were obtained from the database of the korea meteorological administration the concentrations of the nutrients bod chemical oxygen demand cod suspended solid ss total organic carbon toc tn total phosphorus tp no3 and nh4 and basic water quality parameters water temperature flux electrical conductivity ec and ph measured once a week at bantan bridge in the bogang stream were obtained from a database of the korea water environment information system the national water quality automatic monitoring network has been installed on the bantan bridge in the bogang stream near the jeoungpyeong wwtp in addition the water quality management data of the daily influent and effluent were provided from the jeungpyeong wwtp to identify the local meteoric waterline lmwl of jeungpyeong we identified the precipitation data n 227 from 1998 to 2016 of the cheongju station of the global network of isotopes in precipitation gnip of the international atomic energy agency iaea which is located 20 km away from jeungpyeong with both regions belonging to the north chungcheong province to analyze the water quality the temperature t dissolved oxygen do ec and ph were measured in situ immediately right after obtaining the water samples 2 3 analytical procedures all the samples were analyzed using the instruments at the k water research institute in daejeon south korea the concentrations of the major anions f cl no3 no2 po4 3 and so4 2 and nutrients were measured through an ion chromatography instrument ic 850 professional model metrohm ag switzerland with a precision of less than 3 the isotopic compositions of water δ18oh2o and δ2hh2o were analyzed at the k water research institute by using an l2130 i isotopic water liquid analyzer picarro inc sunnyvale ca usa through wavelength scanned cavity ring down spectroscopy ws crds for external calibration four international measurement standards were considered the second vienna standard mean ocean water vsmow2 δ18o 0 and δd 0 the second standard light antarctic precipitation slap2 δ18o 55 50 and δd 427 5 w 43156 δ18o 14 42 and δd 112 8 and usgs w 67400 s δ18o 1 97 and δd 1 2 the mean one standard deviation accuracy and precision of the δ18o and δ2h for each sample were less than 0 4 for δ18o and 0 5 for δ2h the stable nitrogen and oxygen isotopic ratios of nitrate δ15nno3 and δ18ono3 were measured using the bacterial denitrification method with pseudomonas chlororaphis coplen et al 2004 after the bacteria were injected into vials helium gas purged to remove atmospheric gas and retain anoxically the bacteria converted nitrate into nitrous oxide gas which is tripped into each vial the isotopic compositions of nitrous oxide were analyzed using an isotope ratio mass spectrometer gasbenchii delta v plus thermo fisher scientific usa the measured isotopic ratio was calibrated using based on the reported reference material values as follows böhlke et al 2003 for usgs34 δ15n 1 8 and δ18o 27 5 for usgs35 δ15n 2 7 and δ18o 57 5 for usgs32 δ15n 180 and δ18o 25 7 multiple replicate analyses indicated that the standard deviation was less than 0 24 for δ15n and 0 64 for δ18o respectively all the stable isotopic results were expressed as the delta notation δ in units of per mil relative to the international reference standard following eq 1 1 δ r s a m p l e r s t a n d a r d 1 1000 where r denotes the ratio of the heavy to light isotopes 2h 1h 18o 16o or 15n 14n and rsample and rstandard are the isotopic ratios in the sample and standard respectively the 2h 1h and 18o 16o ratios are reported as δ2h and δ18o with respect to the vsmow respectively whereas 15n 14n ratio of nitrate are reported as δ 15nno3 relative to the atmospheric nitrogen gas 2 4 contribution ratios of nitrogen sources a mass balance by mixing model was used to determine the proportions f1 and f2 from the nitrogen inputs between the upstream δ1 and effluent of the wwtp δ2 to the downstream δm the following mass balance eqs 2 and 3 was used to determine the contribution ratios of nitrate nitrogen and oxygen fn no3 or fo no3 according to previous analysis methods phillips and gregg 2003 2 δ m f 1 δ 1 f 2 δ 2 3 1 f 1 f 2 where m indicates 15nno3 or 18ono3 for the mixture 3 results 3 1 hydrometeorological and physicochemical analyses 3 1 1 hydrometeorological data the total precipitation from july 2019 to april 2020 in the study area was 832 5 mm wherein 54 8 of the total precipitation occurred during the rainy season july to september 2019 fig 2 a the air temperature decreased from 28 0 c in august 2019 to 5 7 c in january 2020 and then increased to 19 2 c in april 2020 the trend for the effluent water was similar to that of the air temperature fig 2a the average temperature of the influent increased to 25 0 c in august 2019 and later decreased to 14 4 c in january 2020 and the temperature trend for the effluent was similar fig 2a the low rate q of the stream ranged from 0 00 m3 s 1 in april 2020 to 2 55 m3 s 1 in august 2019 the pink circles in fig 2b represent the sampling dates the water volume of the output ranged from 18 467 m3 in april 2020 to 21 510 m3 in september 2019 fig 2b 3 1 2 water quality data the water quality data of the midstream water bantan bridge near the wwtp are summarized in table 1 from july 2019 to april 2020 the measured mean values standard deviation n 9 of the ph do and ec were 8 02 0 15 12 44 1 48 mg l 1 and 317 7 25 44 μs cm 1 respectively the mean value of the tn total dissolved nitrogen tdn n nh4 and no3 n concentrations were 2 58 1 09 mg l 1 2 48 mg 1 10 l 1 0 045 0 04 mg l 1 and 2 07 1 08 mg l 1 respectively http water nier go kr water environment information system no3 was the dominant n species average proportion of 77 for the tdn in the stream water compared to nh4 1 8 average the monthly water quality data for the upstream sw 1 n 9 and downstream sw 2 n 9 water of the wwtp are summarized in table 2 the mean no3 n concentration in sw 1 and sw 2 was 2 38 0 93 mg l 1 ranging from 0 70 to 3 75 mg l 1 and 2 63 0 89 mg l 1 ranging from 1 19 to 3 75 mg l 1 respectively the measured mean values n 3 of ec ph and do in sw 1 were 460 0 114 4 μs cm 1 7 5 0 3 and 10 6 0 2 mg l 1 and that of sw 2 were 552 8 156 3 μs cm 1 8 1 0 1 and 10 6 0 1 mg l 1 respectively for the monthly influent and effluent samples n 9 the measured mean values of temperature and ph were equally 20 0 0 2 c and 6 7 0 04 table 3 the mean values of do n 2 and ec n 3 in monthly influent and effluent samples were 2 8 1 5 mg l 1 and 1260 3 358 4 μs cm 1 and 10 1 0 5 mg l 1 and 802 9 153 7 μs cm 1 the tn and tp concentrations in monthly influent samples ranged from 39 84 to 51 44 46 57 3 06 mg l 1 and from 4 07 to 5 12 4 61 0 28 mg l 1 respectively table 3 no3 was the dominant n species 80 average for 10 months for the relatively lower tn in the effluent average 8 21 mg l 1 the no3 n concentrations for the monthly effluent ranged from 2 84 to 10 50 mg l 1 and the average concentration in the effluent was 7 46 mg l 1 table 3 the chemical data for the wastewater from each treatment process within the wwtp summarized in table s1 the no3 and so4 2 concentrations varied significantly in the treatment stages p 2 to p 4 unlike those for f and cl in the primary p 3 and secondary p 4 processes the no3 concentration increased and so4 2 concentration decreased the amount of dissolved organic carbon removal through the conventional activated sludge treatment varied between 66 and 84 however a report provided by the investigated wwtp showed that 98 9 99 4 of the bod removal was accomplished during the monitoring period the tn and tp concentrations for the daily samples n 30 of the influent ranged from 40 3 to 53 1 44 94 2 39 mg l 1 and from 3 86 to 4 96 4 37 0 20 mg l 1 table s2 exhibiting a wide range compared to the concentrations in the samples obtained monthly n 9 the mean no3 n concentrations for the daily effluent samples were 7 50 2 05 mg l 1 ranging from 4 35 to 13 35 mg l 1 in addition 13 of the daily effluent samples n 30 contained no3 n concentration that exceeded the maximum admissible limit 10 mg l 1 as n for drinking water to be considered safe as established by the who world health organization 2004 3 2 stable isotope data 3 2 1 stable isotopic compositions for water fig 3 a and b show the ranges for δ18o and δ2h of the water samples respectively for the monthly samples the δ18o and δ2h values for sw 1 ranged from 9 78 to 7 36 and from 70 67 to 51 98 respectively the δ18o and δ2h values for sw 2 ranged from 10 21 to 7 44 and from 73 43 to 52 52 the δ18o and δ2h values for the monthly effluent ranged from 9 37 to 8 68 and from 65 29 to 59 37 from july 2019 to april 2020 respectively the mean oxygen isotopic compositions of water in the effluent δ18oh2o 8 96 0 21 appeared to be more depleted than those of both sw 1 δ18oh2o 8 12 0 63 p 0 004 and sw 2 δ18oh2o 8 24 0 76 p 0 020 for the monthly samples for the influent samples acquired daily in september 2019 the mean values of δ18o and δ2h were 8 46 1 23 ranging from 12 18 to 5 46 and 60 68 6 25 ranging from 90 90 to 53 14 respectively for the short term daily effluent the mean values of δ18o and δ2h were 9 00 0 59 ranging from 11 55 to 8 47 and 62 63 4 89 ranging from 84 61 to 59 20 respectively 3 2 2 stable isotopic compositions of nitrate the value ranges of δ15nno3 and δ18ono3 for the stream water monthly sw 1 and 2 and effluent daily and monthly are presented in fig 3c and 3d respectively the δ15nno3 and δ18ono3 values of sw 1 ranged from 9 31 to 18 95 and from 0 13 to 5 39 respectively the δ15nno3 and δ18ono3 values of sw 2 ranged from 10 52 to 17 31 and from 0 13 to 5 39 respectively in our study for the effluents n 9 sampled monthly from july 2019 to april 2020 the δ15nno3 and δ18ono3 values ranged from 10 56 to 16 60 and from 4 86 to 0 35 respectively for the effluents n 30 sampled daily in september 2019 the 15nno3 and δ18ono3 values ranged from 9 07 to 17 33 and from 3 77 to 0 43 respectively 4 discussion 4 1 water sources and effect of treatment process understanding the stable water isotopes in precipitation which is the ultimate source of water to catchments is of significance with respect to the hydrologic cycle ingraham 1998 an isotopic technique widely used in isotope hydrology is to investigate the slope of the δ2h δ18o regression line and d excess defined asδ2h 8 δ18o lee et al 2010 fig 4 shows the linear relationship between two stable water isotopes compared to the local meteoric water line lmwl δ2h 8 29 δ18o 15 81 r2 0 91 from the nearest iaea station cheongju south korea on the δ18o vs δ2h diagram most samples except for certain influent samples were positioned directly on or close to the lmwl with the slopes of the best fit lines from the least square regression ranging from 7 42 to 8 29 r2 0 82 to 0 96 in general the displacement of the observations toward the right and away from the lmwl and lower slopes suggest that the sampled water underwent evaporative loss dansgaard 1964 lee et al 2010 the linear trend in the influent δ2h 4 24 δ18o 24 81 r2 0 83 reflects the occurrence of the evaporation process these observations indicate that the stream water and effluent are meteoric in origin and the influent may have undergone a certain amount of evaporation before and or during the treatment process and transport the evaporation was seen in 5 of the 30 influent samples sampled daily during the month of september this may be the reason why samples at a specific time cannot represent the whole of the influent reservoir having continuous flow in other words the influent is continuously flowing into the wwtp and we sampled influent and effluent samples almost simultaneously at a specific time therefore the input influent at the time can be such a stable water isotope value at a specific time point in addition this inflow volume is thought to be a smaller amount compared to the entire influent reservoir so it is thought that such evaporated isotopic signals are diluted and not observed in the effluent in order to examine the effect of the wwtp process on water isotopes variance analysis and t test analysis were conducted on the results of water isotope analysis on the influent and effluent of daily samples n 30 during september 2019 as a result the mean and variance of influent mean 8 46 and variance 1 56 and effluent mean 9 00 and variance 0 36 for 18oh2o show a little difference p 0 04 for t test for the results of 2hh2o the mean and variance of influent mean 60 68 and variance 40 45 and effluent mean 62 63 and variance 24 76 show less significant difference p 0 19 for t test than 18oh2o these results indicate that the wwtp process has no significant effect on the water isotope value 4 2 nitrate sources and potential impact of n source from wwtp on bogang stream generally wwtps are major point sources of inorganic nutrient compounds such as nh4 n no3 n no2 n and po4 3 p thus it is necessary to purify the influent before discharging it to the stream the wwtp in jeungpyeong has served over 37 000 people with a treatment capacity of approximately 20 000 m3 per day and the corresponding treated effluent thus considerably influences the nitrate inventory in the area the wwtp was built in 1998 and was not designed for the advanced treatment process however new technologies dnr daewoo nutrient removal see fig 5 for nitrate and phosphate removal were implemented in 2005 this approach is a modified variant of the standard activated sludge method and involves a sludge denitrification tank an anaerobic tank an anoxic tank and an aerobic tank fig 5 ammonium nitrogen is usually converted to nitrate by biological nitrification in the aerobic tank the nitrate nitrogen is removed by denitrification through internal transfer nitrifier recycling and sedimentation sludge transfer nitrogen can be removed from the recycled water through aerobic nitrification by following eq 4 4 2 n h 4 4 o 2 2 n o 3 2 h 2 o 4 h this step is followed by anaerobic heterotrophic denitrification 5 8 n o 3 5 c h 3 c o o h 8 h 4 n 2 10 c o 2 14 h 2 o or autotrophic denitrification 6 8 n o 3 5 h 2 s 4 n 2 5 s o 4 2 2 h 4 h 2 o this process is similar to that adopted at the virginia initiative plant and the anaerobic anoxic oxic process methods except for the installation of the sludge denitrification tank sludge storage tank due to this wwtp process transformation of n species was observed in the influent and effluent in the influent despite the high concentrations of tn the no3 and no2 concentrations of would be almost not observed because nh4 was the dominant n species in influents xian et al 2016 in contrast no3 in the effluent emerged as the product of the biochemical processes of nitrification within an aerobic zone with high do concentrations 9 54 mg l 1 the results indicated that nh4 in the influent was substantially reduced by the ammonia volatilization preceding nitrification and no3 gradually emerged as the dominant n species in the effluents owing to the wwtp treatment which directly contributed to the n source in the stream xian et al 2016 no3 n concentrations above 3 mg l 1 may indicate that the contamination is a result of anthropogenic activities madison and brunett 1985 applying this limit level to the stream water samples in the study area it was noted that 33 and 44 of the sw 1 and 2 samples exceeded the threshold respectively furthermore the no3 n concentrations of the daily and monthly effluent ranged from 2 84 to 13 35 mg l 1 with 95 of the samples exceeding the threshold value 3 mg l 1 indicating anthropogenic influence using a modified bi plot of δ15nno3 and δ18ono3 values suggested by kendall 1998 our data water samples were compatible with typical manure and sewage sourced nitrate fig 6 in previous studies the δ15nno3 and δ18ono3 values in treated wastewater were reported to range from 4 57 to 23 8 and from 5 4 to 16 1 respectively table 4 thus the nitrate isotope values of the effluent were also overlapped those reported previously to investigate the potential impact of n source from wwtp on bogang stream statistical analysis was conducted to verify whether the difference between the mean of sw 1 and sw 2 was significant the no3 n concentrations were not statistically different between sw 1 and sw 2 p 0 18 h0 the same table 2 it was noted that δ15nno3 in sw 1 was almost the same as that observed in sw 2 t test n 18 p 0 090 however δ18ono3 in sw 1 was higher than sw 2 t test n 18 p 0 001 these results indicated that the isotopic composition of the stream water could be influenced by the effluent with depleted δ18ono3 from 4 86 to 0 35 resulting from the biogeochemical process performed in the wwtp to estimate the contribution ratios of the two point sources between the upstream and effluent to the downstream we adopted a single isotope method and two source mixing models using the mass balance equations as specified in eqs 5 and 6 respectively for δ18ono3 elements phillips and gregg 2001 2003 we estimated the proportional contribution of δ18ono3 from the upstream sw 1 δ18ono3 4 46 2 50 and effluent δ18ono3 1 73 1 25 to the downstream sw 2 δ18ono3 2 64 1 66 in the jeungypyeong site the contribution rate of effluent was 7 29 27 13 4 3 seasonal variation in the stable water and nitrate isotopes fig 7 shows the seasonal variations in the stable water and nitrate isotopic compositions of the stream water and effluent samples the seasonal characteristics of stable water isotopes are valuable as they can provide information regarding the hydrological processes and affect the nitrate δ18o values moreover the seasonal variation in the stable nitrate isotopes is important as it can provide information regarding the change in the n source and attenuation in the watershed according to dansgaard 1964 the seasonal variations in the stable water isotopes in terms of the precipitation are related to the amount at low latitudes whereas the seasonal variation at high latitudes can be related to the temperature effect furthermore the stable water isotopes in the precipitation in the mid latitude regions are influenced by both effects albeit dominantly by amount effects in the summer dansgaard 1964 in particular an increase in the temperature and precipitation amount results in a heavier isotopic composition and lighter water isotopic composition respectively dansgaard 1964 according to the gnip stable water isotope data 1998 to 2016 of precipitation in the cheongju station which belongs to the north chungcheong province along with jeungpyeong the stable isotopic compositions in precipitation exhibit the distinct seasonal variation with depletion in the wet season 8 99 for δ18o and 64 00 for δ2h and enrichment in the dry season 7 88 for δ18o and 42 89 for δ2h furthermore we also observed that the stable isotopic compositions exhibited the highest depletion in june δ18oh2o 9 50 1 99 and δ2hh2o 67 91 15 33 from the gnip data the stable isotopic compositions of water exhibited seasonal variations with enrichment in the dry season november 2019 to march 2020 and depletion in the wet season july 2019 to october 2019 fig 7a c in addition variations in the nitrates and the corresponding isotopic compositions were observed in the stream water and effluent samples fig 7d f the no3 n concentrations of upstream sw 1 during the dry season average 3 05 mg l 1 were the same as those in the wet season average 2 09 mg l 1 t test n 8 p 0 76 the no3 n concentrations of downstream sw 2 during the dry season 3 47 mg l 1 were also the same as those in the wet season 2 08 mg l 1 t test n 8 p 0 65 this indicates that the nitrate concentration in the stream water cannot be observed the dilution effect by the intensive rainfall during the wet season during the study period the input water through precipitation during the wet season monthly average 136 25 mm was more than that during the dry season monthly average 47 92 mm fig 2a although the concentration range of the effluent was slightly wider than that of the stream water the no3 n concentration in the effluent did not show the seasonal trend in the dry season average 8 3 mg l 1 than that in the wet season average 6 5 mg l 1 t test n 8 p 0 90 the δ15nno3 of sw 1 and 2 during the wet season average 15 12 and 14 54 respectively were the same as those in the dry season average 15 17 and 14 37 t test n 8 p 0 51 and 0 46 respectively the δ15nno3 of effluent during the wet season average 12 52 were also the same as those in the dry season average 14 83 t test n 8 p 0 83 the δ18ono3 of sw 1 and 2 during the wet season average 4 46 and 2 62 respectively were the same as those in the dry season average 3 64 and 1 97 t test n 8 p 0 39 and 0 41 respectively however the δ18ono3 of effluent during the wet season average 2 65 was slightly lower than that in the dry season average 1 15 t test n 8 p 0 14 respectively fig 8 shows the keeling plot of the inverse no3 concentration 1 no3 and nitrate isotopes δ15nno3 and δ18o no3 values supported by a gaussian mixing model soto et al 2019 a negative linear correlation was observed between the inverse no3 concentration 1 no3 and nitrate isotopes δ15nno3 and δ18o no3 values of the monthly and daily treated effluents this finding implies that a high concentration nitrogen source with isotopically enriched nitrate isotope values δ15nno3 and δ18o no3 for the effluent was supplied as the influent to the wwtp fig 8a moreover end member mixing between the soil nh4 with depleted δ15nno3 4 to 11 and manure and sewage with enriched δ15nno3 4 to 30 likely occurred considering the surrounding land use type kendall 1998 to investigate the relationship between the stable nitrate isotopes and seasonal variations in the effluent t test and analysis of variance were performed on the monthly and daily effluent samples as a result the δ15nno3 in the monthly effluent average 13 82 and variance 3 69 for n 9 did not exhibit a significant difference with the daily effluent average 13 42 p 0 60 and variance 4 24 p 0 61 for n 30 however the δ18o no3 in the monthly effluent average 1 73 and variance 1 76 for n 9 exhibited a higher mean and variance than those of the daily effluent average 2 46 p 0 15 and variance 0 87 p 0 068 for n 30 this finding indicates that δ15nno3 in the effluent is influenced by the nitrogen source instead of the seasonal variation and δ18o no3 is significantly affected by the seasonal effects in particular when no3 is produced in the aeration tank of the wwtp process the oxygen atom originates from the ambient h2o as mentioned previously the stable water isotope exhibits seasonal variations which can lead to the seasonal variations in δ18o no3 this relationship between n the transformation and δ18o no3 in the wwtp process is clarified in the next section 4 4 oxygen isotopic composition of nitrate and nitrogen transformation in wwtps the biochemical transformation process occurring in wastewater treatment plants can be clarified considering water and nitrate isotopes the biological nitrogen removal processes used in wwtps involve the oxidation of ammonium nh4 to nitrate no3 nitrification and reduction with an organic matter to nitrogen gas n2 denitrification ma et al 2009 nitrite no2 is the intermediate of nitrification denitrification nitrification is a two step process involving ammonia nh3 oxidation to nitrite no2 and then to nitrate no3 through nitrifying bacteria buchwald et al 2012 boshers et al 2019 18ono3 nitrified is derived from one oxygen atom of the atmospheric oxygen and two other oxygen atoms of the ambient water andersson and hooper 1983 kumar et al 1983 hollocher 1984 voerkelius and schmidt 1990 durka et al 1994 kendall 1998 campbell et al 2002 pardo and kendall 2004 if these oxygen atoms are included without isotopic fractionation and the δ18o values of water and atmospheric sources are known the δ18o value of nitrate produced by nitrification can be calculated as following eq 7 7 δ 18 o n o 3 n i t r i f i e d 2 3 δ 18 o h 2 o 1 3 δ 18 o o 2 however δ18ono3 nitrified is more depleted than that predicted using eq 7 owing to the abiotic o atom exchange between the no2 and h2o 18εeq and the kinetic isotope effects for the incorporation of o atoms during nitrification snider et al 2010 fang et al 2012 buchwald et al 2012 boshers et al 2019 fig 9 a buchwald et al 2012 explained the full isotope systematics of nitrification by using equation 8 8 δ 18 o n o 3 n i t r i f i e d 2 3 1 3 x ao δ 18 o h 2 o 1 3 δ 18 o o 2 18 ε k o 2 18 ε k h 2 o 1 1 x ao 18 ε k h 2 o 2 2 3 18 ε eq x ao where the δ18o values of the substrates are δ18oo2 and δ18oh2o enrichment factors associated with the incorporation of these substrates during ammonia oxidation are 18εk o2 18εk h2o 1 and that during nitrite oxidation is 18εk h2o 2 and δ18o exchange between no2 and h2o is expressed as 18εeq casciotti et al 2010 snider et al 2010 the fraction of the nitrite oxygen atoms exchanged with h2o during nitrite oxidation x no is generally negligible kumar et al 1983 dispirito and hooper 1986 buchwald and casciotti 2010 although the total fraction of the nitrite oxygen atom exchanged with h2o during ammonia oxidation x ao is highly variable and depends on the organism and growth conditions dua et al 1979 andersson et al 1982 casciotti et al 2010 assuming that the dnr process is a type of batch test the δ18ono3 nitrified value produced by nitrification of the aeration tank can be determined using eq 8 the various parameters included in eq 8 can be determined with reference to the literature x ao 0 74 boshers et al 2019 18 ε k o 2 18 ε k h 2 o 1 7 5 boshers et al 2019 18 ε k h 2 o 2 22 5 applicable for experiments at room temperature boshers et al 2019 18 ε eq 13 casciotti and mcilvin 2007 and δ18oo2 24 2 kroopnick and craig 1972 in our study the oxygen isotope value of the influent δ18oh2o influent as the ambient water ranged from 12 18 to 5 46 with an average value of 8 46 fig 9b shows that δ18ono3 effluent avg value of 2 46 is often more enriched than expected from δ18ono3 nitrified avg value of 7 37 produced by nitrification in the aerobic tank based on the earlier mentioned parameters this finding indicates that the o kinetic isotope effects must be considered to account for denitrification the residual nitrate resulting from the o isotope fractionation effect through denitrification in the anoxic tank which is the subsequent process in the nitrification process is expected to be enriched in 18o the o isotope effect of denitrification can be demonstrated quantitatively by calculating the enrichment factor using the closed system rayleigh equation mariotti et al 1981 9 δ 18 o n o 3 d e n i t r i f i e d δ 18 o n o 3 n i t r i f i e d ε l n f where ε denotes the enrichment factor of isotope fractionation δ18ono3 nitrified denotes the initial δ18o value of the no3 δ18ono3 denitrified denotes the δ18o value of the residual no3 and f denotes the ratio of the no3 concentration at time t to that at the initial time the tn concentration in the primary treated water can be considered as the concentration of no3 because the nh4 which accounts for a major part of the nitrogen source in the anaerobic and anoxic tank is almost oxidized to no3 in the aeration tank by nitrification sun et al 2020 the f ratio is determined by the initial concentration of no3 produced by nitrification in the aeration tank and residual no3 concentration in the effluent the residual δ18ono3 denitrified in anoxic tank can be considered as δ18ono3 of the effluent if no process related to the o isotope fractionation occurs in the wwtp based on these parameters the enrichment factor of denitrification calculated using eq 9 ranges from 0 42 to 5 12 with an average value of 2 87 this value is lower than the enrichment factor calculated in previous studies under various environmental conditions ranging from 18 3 to 6 0 olleros 1983 böttcher et al 1990 mengis et al 1999 sebilo et al 2003 fukada et al 2003 lehmann et al 2003 this phenomenon can be explained by the fact the residence time in the anoxic tank is only 1 to 2 h and thus the time until the denitrification reaction reaches equilibrium is not sufficient 4 5 uncertainties in the nitrate source contribution although the nitrogen source in the treated effluent of the wwtp did not impact the surrounding stream water in this study the treated effluent has been regarded as a significant nitrogen source as the urban point source in other studies sebilo et al 2006 archana et al 2016 vrzel et al 2016 xian et al 2016 adebowale et al 2019 if the average value of the effluent is considered as an end member for the effluent from municipal wastewater an error occurs owing to the variation in the isotope ratio of the effluent the error in the estimation of the effluent fraction δxeff can be determined using eq 10 this value depends on x specifically the error increases proportionally with x jung et al 2020 10 δ x eff x eff c eff c s w 1 δ c eff where ceff is the mean isotope ratio in the effluent csw1 is the mean isotope ratio upstream and δceff is the isotopic variation range in the effluent in this study the 18ono3 values of effluents ranged from 4 86 to 0 35 for ten months july 2019 to april 2020 the estimated contribution of the effluent x is 27 in the sw 2 the error of x is 19 7 in recent decades siar has been used to quantify nitrogen sources as this tool can more accurately provide reliable estimations of different nitrogen sources xue et al 2012 ding et al 2014 kim et al 2015 torres martínez et al 2021 nevertheless to apply siar in various environments observation values are required for using the isotope databases and the presented findings can provide guidance for calculating the contribution of nitrate source in the area affected by the wastewater 5 summary using stable nitrate isotopes δ15nno3 and δ18ono3 in combination with stable water isotopes δ18oh2o and δ18hh2o we investigated the potential impacts of the n source in treated effluents on the surrounding stream and clarified the seasonal variation in the isotope values of effluent and stream water on the δ18o δ2h bi plots most samples except certain influent samples were positioned directly on or close to the lmwl with the slopes of the best fit lines from the least squares regression ranging from 7 42 to 8 29 r2 0 82 to 0 96 these results indicated that the stream water and effluent were meteoric in origin and the influent may have undergone a certain amount of evaporation before and or during the treatment process and transport stable water isotopes δ18oh2o and δ18hh2o in the stream water exhibited clear seasonal variations with enrichment in the dry season november 2019 to march 2020 and depletion in the wet season july 2019 to october 2019 insoutheast asia depletion in the stable water isotopic compositions in the precipitation occurs due to the amount effect during the monsoon season lee et al 2013 from july 2019 to may 2020 the period with the most depleted δ18oh2o and δ18hh2o in stream water was september 2019 by applying a modified bi plot of δ15nno3 and δ18ono3 values suggested by kendall 1998 the nitrate sources in the treated effluents and stream water were identified to be typical manure and sewage the mean isotopic compositions of the nitrate in the effluent 15nno3 13 82 1 81 δ18ono3 1 73 11 25 were lower than those of sw 1 δ15nno3 15 56 3 08 δ18ono3 4 46 2 5 and sw 2 δ15nno3 14 73 2 04 δ18ono3 2 64 1 66 for the monthly samples moreover seasonal variation in the δ18ono was observed in the monthly effluent the statistical analysis was conducted to verify whether the difference between the mean of sw 1 and sw 2 was significant it was observed that although δ15nno3 in sw 1 was almost the same as that measured in sw 2 δ18ono3 in sw 1 was higher than sw 2 these results indicated the n contaminant source from the effluent did not significantly affect the surrounding water system however δ18ono3 of the effluent depleted owing from the biogeochemical process in the wwtp likely could affect the surrounding stream comparing the short term and long term effluent samples it was noted that δ15nno3 in the effluent is influenced by the nitrogen source instead of the seasonal variation whereas δ18ono3 is primarily influenced by the seasonal effects this phenomenon occurs because when no3 is produced in the aeration tank of the wwtp process the oxygen atom originates from the ambient h2o although δ18oh2o and δ18hh2o in the influents were not sampled it can be assumed that the influent shows seasonal variations through the precipitation seasonality therefore the δ18ono3 in the effluents also could affect by seasonal variations of nearby water isotopes we estimated the contribution ratios from two point sources between the upstream and effluent to the downstream using two source mixing models we observed the contribution ratios using δ18ono3 from the effluent to the downstream was 27 in this mixing model the contribution ratio varies depending on the end member therefore when estimating the contribution of the effluents to the water system by considering the isotope values uncertainty may arise due to these seasonal variations this study is a database of potential sources needed as input data for calculating the contribution as an end member in this regard this study can provide guidance to evaluate the contribution ratio to potential sources including effluents in future studies credit authorship contribution statement hyejung jung methodology investigation writing original draft writing review editing visualization yun s kim project administration funding acquisition resources jisu yoo investigation data curation bumsung park investigation data curation jeonghoon lee conceptualization methodology supervision formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments thank you to all of the people at jeungpyeong sewage treatment plant for providing the measured water quality data in wwtp this research is supported by korea ministry of environment as a study on development of evaluation method for analysis of organic matter in public water area 2019 2020 this work was also supported by k water and partially supported by the national research council of science and technology nst grant of the korean government msip cap 17 05 kigam appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126488 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4484,a multi isotopes approach involving the use of stable nitrate isotopes δ15nno3 and δ18ono3 combined with stable water isotopes δ18oh2o and δ2hh2o as tracers can help identify the nitrogen source and understand the transformation process in a river water system in this study we identify the potential impact of the n source in the effluent discharged from a wastewater treatment plant wwtp on the surrounding stream and clarified the seasonal variations in the isotope values of the effluent and stream water from 2019 to 2020 in south korea in addition we investigate the factors that led to the seasonal variations of the stable isotopes and evaluated the relationship between the uncertainty of the contribution ratio of the n sources and isotopic variations in the river water system to examine the potential impact of the inputs of n from the wwtp samples were obtained from the stream up and down with respect to the wwtp and wwtp influent and treated effluent once a month for the monthly effluent samples δ18oh2o and δ2hh2o ranged from 9 37 to 8 68 and from 65 29 to 59 37 respectively exhibiting isotopic depletion in wet season and enrichment in dry season moreover in the effluent δ15nno3 and δ18ono3 ranged from 10 56 to 16 60 and 4 86 to 0 35 respectively to clarify the seasonal variation in the effluent high resolution samples of the influent and treated effluent were obtained every day in september 2019 it is noted that δ15nno3 in the effluent was influenced by the n source instead of the seasonal variation although δ18ono3 exhibited a high dependence on the seasonal effects influenced by δ18oh2o when estimating the contribution of the effluent using isotope values to the water system uncertainty could arise due to these seasonal variations overall a multi isotope approach involving the combined use of stable nitrate isotopes δ15nno3 and δ18ono3 and stable water isotopes δ18oh2o and δ2hh2o as tracers can help evaluate the potential impact of n sources on water systems keywords wastewater treatment plant stable nitrate isotopes stable water isotopes multi isotope approach 1 introduction nitrogen is an essential element for plant growth and human diet however excessive supplies of nitrate no3 may lead to hypoxia and eutrophication in lake and coastal water as well as emission of the greenhouse gas nitrous oxide n2o through denitrification davidson 2012 sobota et al 2015 lin et al 2019 although nitrate can be naturally produced nitrate as nitrogen no3 n concentrations greater than 3 mg l generally indicate contamination madison and brunett 1985 and a recent nationwide study reported that no3 n concentrations higher than 1 mg l indicate human activity dubrovskyet al 2010 in particular the nitrogen input has rapidly increased in terrestrial ecosystems due to continuous population growth agriculture urbanization and the presence of nitrate contaminants in water has become a global environmental problem smil 1997 davidson 2012 xian et al 2016 to prevent the damage due to high nitrate concentrations the united states environmental protection agency us epa and world health organization who have specified that the concentration of no3 n in drinking water must be less than 10 mg l and 11 3 mg l respectively u s environmental protection agency 1991 world health organization 2004 in south korea treated effluents from wastewater treatment plants wwtp correspond to the largest proportion of nitrogen emission from point sources and account for 89 5 of the total amount of nitrogen discharged to point sources national institute of environmental research 2015 according to water quality monitoring data from 2007 to 2017 the nitrogen level in domestic rivers is relatively high compared with that in the organization for economic cooperation and development oecd member countries and the concentration of total nitrogen tn has been recently stagnant a decreasing trend in south korea korea environment institute 2018 therefore it was found that continuous management for decreasing nitrogen is necessary stable nitrate isotopes δ15nno3 and δ18ono3 can provide valuable insights into the nitrate sources transformations and mixing processes kendall 1998 xia et al 2018 lutz et al 2020 torres martínez et al 2021 the stable isotopic ratios of nitrogen and oxygen δ15nno3 and δ18ono3 values in the nitrate have distinguished values in various nitrogen sources such as atmospheric nitrogen no3 based fertilizers nh4 based fertilizers soil sewage and manure and thus represent an effective tool to identify the nitrogen source and flowpath in the water system kendall 1998 jung et al 2020 in particular the treated effluent is enriched in 15n relative to the residual nitrogen due to the volatilization and nitrification of nh4 and denitrification of no3 via the sewage treatment processes which may yield unique stable isotope values compared to those in other nitrogen sources in aquatic systems hood et al 2014 xue et al 2009 many researchers have attempted to examine the impact of the nitrogen source of treated effluent discharged from wwtps in the river water system by using nitrate isotopes sebilo et al 2006 considered the isotopic compositions of ammonium δ15nnh4 and nitrate δ15nno3 and δ18ono3 to identify the nitrogen source in the effluent and evaluated the nitrogen transformation process from this nitrogen source in the seine river france anisfeld et al 2007 calculated the contributions of treated effluent and atmospheric deposition by considering the stable nitrate isotopes δ15nno3 and δ18ono3 of the effluent in and precipitation at the quinnipiac and naugatuck rivers the us archana et al 2016 calculated the contribution of treated effluent from 68 wwtps corresponding to five treatment types to seawater from northeast hongkong by considering stable nitrate isotopes δ15nno3 and δ18ono3 xian et al 2016 investigated the variation in the isotopic signature of the influent and effluent at a wwtp in beijing china by considering stable nitrate isotopes δ15nno3 and δ18ono3 and calculated the contribution of these effluents to the surrounding rivers adebowale et al 2019 investigated the impact of n source from the wwtp near boneo in southeast australia on the surrounding groundwater by considering stable nitrate isotopes δ15nno3 and δ18ono3 lin et al 2019 investigated the impact of the n sources of the effluent and agricultural groundwater on the surrounding streams by using stable nitrate isotopes δ15nno3 and δ18ono3 in the illinois river system the us and the spatial and temporal variation of these nitrate sources however certain uncertainties are involved when the contribution of the nitrogen sources is calculated without considering the variation in the isotope value because the nitrate isotope changes continuously owing to the isotopic fractionation through the biogeochemical process xue et al 2009 kendall 1998 archana et al 2016 furthermore if the oxygen isotope values are similar and the nitrogen isotope values overlap in the case of nh4 based fertilizers sewage and manure sources the exact identification of the nitrogen sources through the isotopes may not be possible curt et al 2004 recently many studies were performed using a multi isotope approach combining nitrates with other stable isotopes δ13c δ34s δ11b and δ87sr 86sr which could provide additional information regarding the nitrate contaminant sources and mixing process aravena et al 1993 aravena and robertson 1998 widory et al 2004 kaown et al 2009 martinelli et al 2018 in particular stable water isotopic compositions only change via mixing with different water sources and fractionation processes associated with evaporation and condensation consequently the isotopic ratios in water can provide valuable information regarding the hydrologic processes dansgaard 1964 gat 1996 ingraham 1998 mcguire and mcdonnell 2007 jung et al 2020 therefore the multi isotope approach involving both stable water isotopes δ18oh2o and δ2hh2o with stable nitrate isotopes δ15nno3 and δ18ono3 can likely provide useful information regarding hydrological processes to track the flowpath of contaminants in groundwater jung et al 2020 consequently various studies were conducted using combined nitrate and water stable isotopes as tracers for the wastewater aravena et al 1993 considered δ15nno3 and δ18oh2o as well as the water chemistry na to effectively distinguish the plume of domestic septic systems from groundwater in the ontario region of canada moreover the residence time between the shallow unconfined aquifer and deep confined aquifer was defined yue et al 2013 analyzed the isotopic compositions of ammonium δ15nnh4 and nitrate δ15nno3 and δ18ono3 to differentiate between the source mixing of the wastewater and soil organic n in low and high flow seasons in the liao river basin china in addition the nitrogen transformation in the river was investigated by considering δ18oh2o in the river water torres martínez et al 2021 clarified the nitrogen contaminants and biogeochemical transformations by considering water and nitrate stable isotopes in the groundwater sites of comarca lagunera northern mexico in addition the contribution ratios of six nitrogen contaminants atmospheric deposition nh4 synthetic fertilizers no3 based fertilizers soil organic nitrogen sewage and manure were quantitatively calculated using the bayesian isotope mixing model jun et al 2005 identified nitrogen source inputs such as agricultural fertilizer animal waste and leakage of sewage by considering the δ18oh2o δ2hh2o and δ15nno3 values in the groundwater around the samgi stream a tributary of the bogang stream our study area according to a recent investigation of the korea water resources corporation 2018 the bogang stream which involves high biochemical oxygen demand bod concentrations owing to the presence of fertilizer manure and sewage is an example of a stream with numerous potential sources of contamination most of the existing studies that considered the nitrate and water stable isotopes as tracers attempted to identify the wastewater source and n transformation process in natural water systems but the nitrate isotopic signatures produced within the wastewater treatment system has not been studied moreover little information is presently available about water and nitrate isotopic signatures of effluent from wastewater treatment system therefore the present study was aimed at clarifying the potential impact of n source in the effluent discharged from a wwtp on the surrounding stream and the seasonal variation in the isotopic values of the effluent and stream water in addition we investigated the factors causing the stable isotopic variation in the effluent and stream water and evaluated the relationship between the uncertainty in the contribution ratio of the n sources and nitrate isotopic variations in the water system 2 study area and sampling 2 1 study area the study area is the jeungpyeong county in north chungcheong province in the center of the korean peninsula the geology of jeungpyeong county consists of quaternary alluvium sand about 20 m thick underlain by jurassic porphyritic granite korea agricultural and rural infrastructure corporation 2001 the considered wwtp is located in the jeungpyeong county and the effluent is released in the nearby bogang stream fig 1 the bogang stream which partially flows into the miho stream one of the tributary streams in the geumgang basins is approximately 19 85 km long and has a drainage area of 157 71 km2 daejeon regional construction management administration 2011 the bogang stream is surrounded by mountains so rainfall flows to the center of the basin and then flows out because the vadose zone is so shallow precipitation events quickly goes groundwater recharge and rises in the water table jun et al 2005 the major types of land use in jeungpyeong county can be classified into five categories forest 49 agricultural 28 residential 6 industrial 2 4 and livestock 0 4 as specified by the korean statistical information service https www data go kr the bogang stream predominantly pertains to agricultural and residential land use as illustrated in fig 1 2 2 sample acquisition to examine the behavior of both nitrate and water isotopes after the discharge of the effluent to the stream seven sampling points were chosen five at the jeungpyeong wwtp and two in the bogang stream fig 1 and sampling was performed using a 1 l sterilized sample bottle the five points in the wwtp corresponded to the 1 influent p1 2 distribution basin p2 3 state after the primary sedimentation p3 4 state after the secondary sedimentation p4 and 5 treated effluent p5 fig 1 the two sampling points in the bogang stream were located upstream sw 1 and downstream sw 2 of the tributary from which the effluent was discharged periodic sampling once a month from july 2019 to april 2020 was performed at the influent effluent sw 1 and sw 2 points moreover the influent and effluent were collected in 50 ml conical tubes every day at 10 00 am for one month in september 2019 to evaluate the variation trends in the water and nitrate stable isotopes during the investigation period all the samples were sent to the laboratory at the k water research institute in daejeon korea for measurement to be performed on the same day and refrigerated at 4 c until the analysis the samples for anions stable isotope analysis of nitrate 15nno3 and δ18ono3 and water δ2hh2o δ18oh2o were collected in high density polyethylene bottles and filtered using 0 45 μm membrane filters the daily precipitation and air temperature data for the jeungpyeong region during the study period were obtained from the database of the korea meteorological administration the concentrations of the nutrients bod chemical oxygen demand cod suspended solid ss total organic carbon toc tn total phosphorus tp no3 and nh4 and basic water quality parameters water temperature flux electrical conductivity ec and ph measured once a week at bantan bridge in the bogang stream were obtained from a database of the korea water environment information system the national water quality automatic monitoring network has been installed on the bantan bridge in the bogang stream near the jeoungpyeong wwtp in addition the water quality management data of the daily influent and effluent were provided from the jeungpyeong wwtp to identify the local meteoric waterline lmwl of jeungpyeong we identified the precipitation data n 227 from 1998 to 2016 of the cheongju station of the global network of isotopes in precipitation gnip of the international atomic energy agency iaea which is located 20 km away from jeungpyeong with both regions belonging to the north chungcheong province to analyze the water quality the temperature t dissolved oxygen do ec and ph were measured in situ immediately right after obtaining the water samples 2 3 analytical procedures all the samples were analyzed using the instruments at the k water research institute in daejeon south korea the concentrations of the major anions f cl no3 no2 po4 3 and so4 2 and nutrients were measured through an ion chromatography instrument ic 850 professional model metrohm ag switzerland with a precision of less than 3 the isotopic compositions of water δ18oh2o and δ2hh2o were analyzed at the k water research institute by using an l2130 i isotopic water liquid analyzer picarro inc sunnyvale ca usa through wavelength scanned cavity ring down spectroscopy ws crds for external calibration four international measurement standards were considered the second vienna standard mean ocean water vsmow2 δ18o 0 and δd 0 the second standard light antarctic precipitation slap2 δ18o 55 50 and δd 427 5 w 43156 δ18o 14 42 and δd 112 8 and usgs w 67400 s δ18o 1 97 and δd 1 2 the mean one standard deviation accuracy and precision of the δ18o and δ2h for each sample were less than 0 4 for δ18o and 0 5 for δ2h the stable nitrogen and oxygen isotopic ratios of nitrate δ15nno3 and δ18ono3 were measured using the bacterial denitrification method with pseudomonas chlororaphis coplen et al 2004 after the bacteria were injected into vials helium gas purged to remove atmospheric gas and retain anoxically the bacteria converted nitrate into nitrous oxide gas which is tripped into each vial the isotopic compositions of nitrous oxide were analyzed using an isotope ratio mass spectrometer gasbenchii delta v plus thermo fisher scientific usa the measured isotopic ratio was calibrated using based on the reported reference material values as follows böhlke et al 2003 for usgs34 δ15n 1 8 and δ18o 27 5 for usgs35 δ15n 2 7 and δ18o 57 5 for usgs32 δ15n 180 and δ18o 25 7 multiple replicate analyses indicated that the standard deviation was less than 0 24 for δ15n and 0 64 for δ18o respectively all the stable isotopic results were expressed as the delta notation δ in units of per mil relative to the international reference standard following eq 1 1 δ r s a m p l e r s t a n d a r d 1 1000 where r denotes the ratio of the heavy to light isotopes 2h 1h 18o 16o or 15n 14n and rsample and rstandard are the isotopic ratios in the sample and standard respectively the 2h 1h and 18o 16o ratios are reported as δ2h and δ18o with respect to the vsmow respectively whereas 15n 14n ratio of nitrate are reported as δ 15nno3 relative to the atmospheric nitrogen gas 2 4 contribution ratios of nitrogen sources a mass balance by mixing model was used to determine the proportions f1 and f2 from the nitrogen inputs between the upstream δ1 and effluent of the wwtp δ2 to the downstream δm the following mass balance eqs 2 and 3 was used to determine the contribution ratios of nitrate nitrogen and oxygen fn no3 or fo no3 according to previous analysis methods phillips and gregg 2003 2 δ m f 1 δ 1 f 2 δ 2 3 1 f 1 f 2 where m indicates 15nno3 or 18ono3 for the mixture 3 results 3 1 hydrometeorological and physicochemical analyses 3 1 1 hydrometeorological data the total precipitation from july 2019 to april 2020 in the study area was 832 5 mm wherein 54 8 of the total precipitation occurred during the rainy season july to september 2019 fig 2 a the air temperature decreased from 28 0 c in august 2019 to 5 7 c in january 2020 and then increased to 19 2 c in april 2020 the trend for the effluent water was similar to that of the air temperature fig 2a the average temperature of the influent increased to 25 0 c in august 2019 and later decreased to 14 4 c in january 2020 and the temperature trend for the effluent was similar fig 2a the low rate q of the stream ranged from 0 00 m3 s 1 in april 2020 to 2 55 m3 s 1 in august 2019 the pink circles in fig 2b represent the sampling dates the water volume of the output ranged from 18 467 m3 in april 2020 to 21 510 m3 in september 2019 fig 2b 3 1 2 water quality data the water quality data of the midstream water bantan bridge near the wwtp are summarized in table 1 from july 2019 to april 2020 the measured mean values standard deviation n 9 of the ph do and ec were 8 02 0 15 12 44 1 48 mg l 1 and 317 7 25 44 μs cm 1 respectively the mean value of the tn total dissolved nitrogen tdn n nh4 and no3 n concentrations were 2 58 1 09 mg l 1 2 48 mg 1 10 l 1 0 045 0 04 mg l 1 and 2 07 1 08 mg l 1 respectively http water nier go kr water environment information system no3 was the dominant n species average proportion of 77 for the tdn in the stream water compared to nh4 1 8 average the monthly water quality data for the upstream sw 1 n 9 and downstream sw 2 n 9 water of the wwtp are summarized in table 2 the mean no3 n concentration in sw 1 and sw 2 was 2 38 0 93 mg l 1 ranging from 0 70 to 3 75 mg l 1 and 2 63 0 89 mg l 1 ranging from 1 19 to 3 75 mg l 1 respectively the measured mean values n 3 of ec ph and do in sw 1 were 460 0 114 4 μs cm 1 7 5 0 3 and 10 6 0 2 mg l 1 and that of sw 2 were 552 8 156 3 μs cm 1 8 1 0 1 and 10 6 0 1 mg l 1 respectively for the monthly influent and effluent samples n 9 the measured mean values of temperature and ph were equally 20 0 0 2 c and 6 7 0 04 table 3 the mean values of do n 2 and ec n 3 in monthly influent and effluent samples were 2 8 1 5 mg l 1 and 1260 3 358 4 μs cm 1 and 10 1 0 5 mg l 1 and 802 9 153 7 μs cm 1 the tn and tp concentrations in monthly influent samples ranged from 39 84 to 51 44 46 57 3 06 mg l 1 and from 4 07 to 5 12 4 61 0 28 mg l 1 respectively table 3 no3 was the dominant n species 80 average for 10 months for the relatively lower tn in the effluent average 8 21 mg l 1 the no3 n concentrations for the monthly effluent ranged from 2 84 to 10 50 mg l 1 and the average concentration in the effluent was 7 46 mg l 1 table 3 the chemical data for the wastewater from each treatment process within the wwtp summarized in table s1 the no3 and so4 2 concentrations varied significantly in the treatment stages p 2 to p 4 unlike those for f and cl in the primary p 3 and secondary p 4 processes the no3 concentration increased and so4 2 concentration decreased the amount of dissolved organic carbon removal through the conventional activated sludge treatment varied between 66 and 84 however a report provided by the investigated wwtp showed that 98 9 99 4 of the bod removal was accomplished during the monitoring period the tn and tp concentrations for the daily samples n 30 of the influent ranged from 40 3 to 53 1 44 94 2 39 mg l 1 and from 3 86 to 4 96 4 37 0 20 mg l 1 table s2 exhibiting a wide range compared to the concentrations in the samples obtained monthly n 9 the mean no3 n concentrations for the daily effluent samples were 7 50 2 05 mg l 1 ranging from 4 35 to 13 35 mg l 1 in addition 13 of the daily effluent samples n 30 contained no3 n concentration that exceeded the maximum admissible limit 10 mg l 1 as n for drinking water to be considered safe as established by the who world health organization 2004 3 2 stable isotope data 3 2 1 stable isotopic compositions for water fig 3 a and b show the ranges for δ18o and δ2h of the water samples respectively for the monthly samples the δ18o and δ2h values for sw 1 ranged from 9 78 to 7 36 and from 70 67 to 51 98 respectively the δ18o and δ2h values for sw 2 ranged from 10 21 to 7 44 and from 73 43 to 52 52 the δ18o and δ2h values for the monthly effluent ranged from 9 37 to 8 68 and from 65 29 to 59 37 from july 2019 to april 2020 respectively the mean oxygen isotopic compositions of water in the effluent δ18oh2o 8 96 0 21 appeared to be more depleted than those of both sw 1 δ18oh2o 8 12 0 63 p 0 004 and sw 2 δ18oh2o 8 24 0 76 p 0 020 for the monthly samples for the influent samples acquired daily in september 2019 the mean values of δ18o and δ2h were 8 46 1 23 ranging from 12 18 to 5 46 and 60 68 6 25 ranging from 90 90 to 53 14 respectively for the short term daily effluent the mean values of δ18o and δ2h were 9 00 0 59 ranging from 11 55 to 8 47 and 62 63 4 89 ranging from 84 61 to 59 20 respectively 3 2 2 stable isotopic compositions of nitrate the value ranges of δ15nno3 and δ18ono3 for the stream water monthly sw 1 and 2 and effluent daily and monthly are presented in fig 3c and 3d respectively the δ15nno3 and δ18ono3 values of sw 1 ranged from 9 31 to 18 95 and from 0 13 to 5 39 respectively the δ15nno3 and δ18ono3 values of sw 2 ranged from 10 52 to 17 31 and from 0 13 to 5 39 respectively in our study for the effluents n 9 sampled monthly from july 2019 to april 2020 the δ15nno3 and δ18ono3 values ranged from 10 56 to 16 60 and from 4 86 to 0 35 respectively for the effluents n 30 sampled daily in september 2019 the 15nno3 and δ18ono3 values ranged from 9 07 to 17 33 and from 3 77 to 0 43 respectively 4 discussion 4 1 water sources and effect of treatment process understanding the stable water isotopes in precipitation which is the ultimate source of water to catchments is of significance with respect to the hydrologic cycle ingraham 1998 an isotopic technique widely used in isotope hydrology is to investigate the slope of the δ2h δ18o regression line and d excess defined asδ2h 8 δ18o lee et al 2010 fig 4 shows the linear relationship between two stable water isotopes compared to the local meteoric water line lmwl δ2h 8 29 δ18o 15 81 r2 0 91 from the nearest iaea station cheongju south korea on the δ18o vs δ2h diagram most samples except for certain influent samples were positioned directly on or close to the lmwl with the slopes of the best fit lines from the least square regression ranging from 7 42 to 8 29 r2 0 82 to 0 96 in general the displacement of the observations toward the right and away from the lmwl and lower slopes suggest that the sampled water underwent evaporative loss dansgaard 1964 lee et al 2010 the linear trend in the influent δ2h 4 24 δ18o 24 81 r2 0 83 reflects the occurrence of the evaporation process these observations indicate that the stream water and effluent are meteoric in origin and the influent may have undergone a certain amount of evaporation before and or during the treatment process and transport the evaporation was seen in 5 of the 30 influent samples sampled daily during the month of september this may be the reason why samples at a specific time cannot represent the whole of the influent reservoir having continuous flow in other words the influent is continuously flowing into the wwtp and we sampled influent and effluent samples almost simultaneously at a specific time therefore the input influent at the time can be such a stable water isotope value at a specific time point in addition this inflow volume is thought to be a smaller amount compared to the entire influent reservoir so it is thought that such evaporated isotopic signals are diluted and not observed in the effluent in order to examine the effect of the wwtp process on water isotopes variance analysis and t test analysis were conducted on the results of water isotope analysis on the influent and effluent of daily samples n 30 during september 2019 as a result the mean and variance of influent mean 8 46 and variance 1 56 and effluent mean 9 00 and variance 0 36 for 18oh2o show a little difference p 0 04 for t test for the results of 2hh2o the mean and variance of influent mean 60 68 and variance 40 45 and effluent mean 62 63 and variance 24 76 show less significant difference p 0 19 for t test than 18oh2o these results indicate that the wwtp process has no significant effect on the water isotope value 4 2 nitrate sources and potential impact of n source from wwtp on bogang stream generally wwtps are major point sources of inorganic nutrient compounds such as nh4 n no3 n no2 n and po4 3 p thus it is necessary to purify the influent before discharging it to the stream the wwtp in jeungpyeong has served over 37 000 people with a treatment capacity of approximately 20 000 m3 per day and the corresponding treated effluent thus considerably influences the nitrate inventory in the area the wwtp was built in 1998 and was not designed for the advanced treatment process however new technologies dnr daewoo nutrient removal see fig 5 for nitrate and phosphate removal were implemented in 2005 this approach is a modified variant of the standard activated sludge method and involves a sludge denitrification tank an anaerobic tank an anoxic tank and an aerobic tank fig 5 ammonium nitrogen is usually converted to nitrate by biological nitrification in the aerobic tank the nitrate nitrogen is removed by denitrification through internal transfer nitrifier recycling and sedimentation sludge transfer nitrogen can be removed from the recycled water through aerobic nitrification by following eq 4 4 2 n h 4 4 o 2 2 n o 3 2 h 2 o 4 h this step is followed by anaerobic heterotrophic denitrification 5 8 n o 3 5 c h 3 c o o h 8 h 4 n 2 10 c o 2 14 h 2 o or autotrophic denitrification 6 8 n o 3 5 h 2 s 4 n 2 5 s o 4 2 2 h 4 h 2 o this process is similar to that adopted at the virginia initiative plant and the anaerobic anoxic oxic process methods except for the installation of the sludge denitrification tank sludge storage tank due to this wwtp process transformation of n species was observed in the influent and effluent in the influent despite the high concentrations of tn the no3 and no2 concentrations of would be almost not observed because nh4 was the dominant n species in influents xian et al 2016 in contrast no3 in the effluent emerged as the product of the biochemical processes of nitrification within an aerobic zone with high do concentrations 9 54 mg l 1 the results indicated that nh4 in the influent was substantially reduced by the ammonia volatilization preceding nitrification and no3 gradually emerged as the dominant n species in the effluents owing to the wwtp treatment which directly contributed to the n source in the stream xian et al 2016 no3 n concentrations above 3 mg l 1 may indicate that the contamination is a result of anthropogenic activities madison and brunett 1985 applying this limit level to the stream water samples in the study area it was noted that 33 and 44 of the sw 1 and 2 samples exceeded the threshold respectively furthermore the no3 n concentrations of the daily and monthly effluent ranged from 2 84 to 13 35 mg l 1 with 95 of the samples exceeding the threshold value 3 mg l 1 indicating anthropogenic influence using a modified bi plot of δ15nno3 and δ18ono3 values suggested by kendall 1998 our data water samples were compatible with typical manure and sewage sourced nitrate fig 6 in previous studies the δ15nno3 and δ18ono3 values in treated wastewater were reported to range from 4 57 to 23 8 and from 5 4 to 16 1 respectively table 4 thus the nitrate isotope values of the effluent were also overlapped those reported previously to investigate the potential impact of n source from wwtp on bogang stream statistical analysis was conducted to verify whether the difference between the mean of sw 1 and sw 2 was significant the no3 n concentrations were not statistically different between sw 1 and sw 2 p 0 18 h0 the same table 2 it was noted that δ15nno3 in sw 1 was almost the same as that observed in sw 2 t test n 18 p 0 090 however δ18ono3 in sw 1 was higher than sw 2 t test n 18 p 0 001 these results indicated that the isotopic composition of the stream water could be influenced by the effluent with depleted δ18ono3 from 4 86 to 0 35 resulting from the biogeochemical process performed in the wwtp to estimate the contribution ratios of the two point sources between the upstream and effluent to the downstream we adopted a single isotope method and two source mixing models using the mass balance equations as specified in eqs 5 and 6 respectively for δ18ono3 elements phillips and gregg 2001 2003 we estimated the proportional contribution of δ18ono3 from the upstream sw 1 δ18ono3 4 46 2 50 and effluent δ18ono3 1 73 1 25 to the downstream sw 2 δ18ono3 2 64 1 66 in the jeungypyeong site the contribution rate of effluent was 7 29 27 13 4 3 seasonal variation in the stable water and nitrate isotopes fig 7 shows the seasonal variations in the stable water and nitrate isotopic compositions of the stream water and effluent samples the seasonal characteristics of stable water isotopes are valuable as they can provide information regarding the hydrological processes and affect the nitrate δ18o values moreover the seasonal variation in the stable nitrate isotopes is important as it can provide information regarding the change in the n source and attenuation in the watershed according to dansgaard 1964 the seasonal variations in the stable water isotopes in terms of the precipitation are related to the amount at low latitudes whereas the seasonal variation at high latitudes can be related to the temperature effect furthermore the stable water isotopes in the precipitation in the mid latitude regions are influenced by both effects albeit dominantly by amount effects in the summer dansgaard 1964 in particular an increase in the temperature and precipitation amount results in a heavier isotopic composition and lighter water isotopic composition respectively dansgaard 1964 according to the gnip stable water isotope data 1998 to 2016 of precipitation in the cheongju station which belongs to the north chungcheong province along with jeungpyeong the stable isotopic compositions in precipitation exhibit the distinct seasonal variation with depletion in the wet season 8 99 for δ18o and 64 00 for δ2h and enrichment in the dry season 7 88 for δ18o and 42 89 for δ2h furthermore we also observed that the stable isotopic compositions exhibited the highest depletion in june δ18oh2o 9 50 1 99 and δ2hh2o 67 91 15 33 from the gnip data the stable isotopic compositions of water exhibited seasonal variations with enrichment in the dry season november 2019 to march 2020 and depletion in the wet season july 2019 to october 2019 fig 7a c in addition variations in the nitrates and the corresponding isotopic compositions were observed in the stream water and effluent samples fig 7d f the no3 n concentrations of upstream sw 1 during the dry season average 3 05 mg l 1 were the same as those in the wet season average 2 09 mg l 1 t test n 8 p 0 76 the no3 n concentrations of downstream sw 2 during the dry season 3 47 mg l 1 were also the same as those in the wet season 2 08 mg l 1 t test n 8 p 0 65 this indicates that the nitrate concentration in the stream water cannot be observed the dilution effect by the intensive rainfall during the wet season during the study period the input water through precipitation during the wet season monthly average 136 25 mm was more than that during the dry season monthly average 47 92 mm fig 2a although the concentration range of the effluent was slightly wider than that of the stream water the no3 n concentration in the effluent did not show the seasonal trend in the dry season average 8 3 mg l 1 than that in the wet season average 6 5 mg l 1 t test n 8 p 0 90 the δ15nno3 of sw 1 and 2 during the wet season average 15 12 and 14 54 respectively were the same as those in the dry season average 15 17 and 14 37 t test n 8 p 0 51 and 0 46 respectively the δ15nno3 of effluent during the wet season average 12 52 were also the same as those in the dry season average 14 83 t test n 8 p 0 83 the δ18ono3 of sw 1 and 2 during the wet season average 4 46 and 2 62 respectively were the same as those in the dry season average 3 64 and 1 97 t test n 8 p 0 39 and 0 41 respectively however the δ18ono3 of effluent during the wet season average 2 65 was slightly lower than that in the dry season average 1 15 t test n 8 p 0 14 respectively fig 8 shows the keeling plot of the inverse no3 concentration 1 no3 and nitrate isotopes δ15nno3 and δ18o no3 values supported by a gaussian mixing model soto et al 2019 a negative linear correlation was observed between the inverse no3 concentration 1 no3 and nitrate isotopes δ15nno3 and δ18o no3 values of the monthly and daily treated effluents this finding implies that a high concentration nitrogen source with isotopically enriched nitrate isotope values δ15nno3 and δ18o no3 for the effluent was supplied as the influent to the wwtp fig 8a moreover end member mixing between the soil nh4 with depleted δ15nno3 4 to 11 and manure and sewage with enriched δ15nno3 4 to 30 likely occurred considering the surrounding land use type kendall 1998 to investigate the relationship between the stable nitrate isotopes and seasonal variations in the effluent t test and analysis of variance were performed on the monthly and daily effluent samples as a result the δ15nno3 in the monthly effluent average 13 82 and variance 3 69 for n 9 did not exhibit a significant difference with the daily effluent average 13 42 p 0 60 and variance 4 24 p 0 61 for n 30 however the δ18o no3 in the monthly effluent average 1 73 and variance 1 76 for n 9 exhibited a higher mean and variance than those of the daily effluent average 2 46 p 0 15 and variance 0 87 p 0 068 for n 30 this finding indicates that δ15nno3 in the effluent is influenced by the nitrogen source instead of the seasonal variation and δ18o no3 is significantly affected by the seasonal effects in particular when no3 is produced in the aeration tank of the wwtp process the oxygen atom originates from the ambient h2o as mentioned previously the stable water isotope exhibits seasonal variations which can lead to the seasonal variations in δ18o no3 this relationship between n the transformation and δ18o no3 in the wwtp process is clarified in the next section 4 4 oxygen isotopic composition of nitrate and nitrogen transformation in wwtps the biochemical transformation process occurring in wastewater treatment plants can be clarified considering water and nitrate isotopes the biological nitrogen removal processes used in wwtps involve the oxidation of ammonium nh4 to nitrate no3 nitrification and reduction with an organic matter to nitrogen gas n2 denitrification ma et al 2009 nitrite no2 is the intermediate of nitrification denitrification nitrification is a two step process involving ammonia nh3 oxidation to nitrite no2 and then to nitrate no3 through nitrifying bacteria buchwald et al 2012 boshers et al 2019 18ono3 nitrified is derived from one oxygen atom of the atmospheric oxygen and two other oxygen atoms of the ambient water andersson and hooper 1983 kumar et al 1983 hollocher 1984 voerkelius and schmidt 1990 durka et al 1994 kendall 1998 campbell et al 2002 pardo and kendall 2004 if these oxygen atoms are included without isotopic fractionation and the δ18o values of water and atmospheric sources are known the δ18o value of nitrate produced by nitrification can be calculated as following eq 7 7 δ 18 o n o 3 n i t r i f i e d 2 3 δ 18 o h 2 o 1 3 δ 18 o o 2 however δ18ono3 nitrified is more depleted than that predicted using eq 7 owing to the abiotic o atom exchange between the no2 and h2o 18εeq and the kinetic isotope effects for the incorporation of o atoms during nitrification snider et al 2010 fang et al 2012 buchwald et al 2012 boshers et al 2019 fig 9 a buchwald et al 2012 explained the full isotope systematics of nitrification by using equation 8 8 δ 18 o n o 3 n i t r i f i e d 2 3 1 3 x ao δ 18 o h 2 o 1 3 δ 18 o o 2 18 ε k o 2 18 ε k h 2 o 1 1 x ao 18 ε k h 2 o 2 2 3 18 ε eq x ao where the δ18o values of the substrates are δ18oo2 and δ18oh2o enrichment factors associated with the incorporation of these substrates during ammonia oxidation are 18εk o2 18εk h2o 1 and that during nitrite oxidation is 18εk h2o 2 and δ18o exchange between no2 and h2o is expressed as 18εeq casciotti et al 2010 snider et al 2010 the fraction of the nitrite oxygen atoms exchanged with h2o during nitrite oxidation x no is generally negligible kumar et al 1983 dispirito and hooper 1986 buchwald and casciotti 2010 although the total fraction of the nitrite oxygen atom exchanged with h2o during ammonia oxidation x ao is highly variable and depends on the organism and growth conditions dua et al 1979 andersson et al 1982 casciotti et al 2010 assuming that the dnr process is a type of batch test the δ18ono3 nitrified value produced by nitrification of the aeration tank can be determined using eq 8 the various parameters included in eq 8 can be determined with reference to the literature x ao 0 74 boshers et al 2019 18 ε k o 2 18 ε k h 2 o 1 7 5 boshers et al 2019 18 ε k h 2 o 2 22 5 applicable for experiments at room temperature boshers et al 2019 18 ε eq 13 casciotti and mcilvin 2007 and δ18oo2 24 2 kroopnick and craig 1972 in our study the oxygen isotope value of the influent δ18oh2o influent as the ambient water ranged from 12 18 to 5 46 with an average value of 8 46 fig 9b shows that δ18ono3 effluent avg value of 2 46 is often more enriched than expected from δ18ono3 nitrified avg value of 7 37 produced by nitrification in the aerobic tank based on the earlier mentioned parameters this finding indicates that the o kinetic isotope effects must be considered to account for denitrification the residual nitrate resulting from the o isotope fractionation effect through denitrification in the anoxic tank which is the subsequent process in the nitrification process is expected to be enriched in 18o the o isotope effect of denitrification can be demonstrated quantitatively by calculating the enrichment factor using the closed system rayleigh equation mariotti et al 1981 9 δ 18 o n o 3 d e n i t r i f i e d δ 18 o n o 3 n i t r i f i e d ε l n f where ε denotes the enrichment factor of isotope fractionation δ18ono3 nitrified denotes the initial δ18o value of the no3 δ18ono3 denitrified denotes the δ18o value of the residual no3 and f denotes the ratio of the no3 concentration at time t to that at the initial time the tn concentration in the primary treated water can be considered as the concentration of no3 because the nh4 which accounts for a major part of the nitrogen source in the anaerobic and anoxic tank is almost oxidized to no3 in the aeration tank by nitrification sun et al 2020 the f ratio is determined by the initial concentration of no3 produced by nitrification in the aeration tank and residual no3 concentration in the effluent the residual δ18ono3 denitrified in anoxic tank can be considered as δ18ono3 of the effluent if no process related to the o isotope fractionation occurs in the wwtp based on these parameters the enrichment factor of denitrification calculated using eq 9 ranges from 0 42 to 5 12 with an average value of 2 87 this value is lower than the enrichment factor calculated in previous studies under various environmental conditions ranging from 18 3 to 6 0 olleros 1983 böttcher et al 1990 mengis et al 1999 sebilo et al 2003 fukada et al 2003 lehmann et al 2003 this phenomenon can be explained by the fact the residence time in the anoxic tank is only 1 to 2 h and thus the time until the denitrification reaction reaches equilibrium is not sufficient 4 5 uncertainties in the nitrate source contribution although the nitrogen source in the treated effluent of the wwtp did not impact the surrounding stream water in this study the treated effluent has been regarded as a significant nitrogen source as the urban point source in other studies sebilo et al 2006 archana et al 2016 vrzel et al 2016 xian et al 2016 adebowale et al 2019 if the average value of the effluent is considered as an end member for the effluent from municipal wastewater an error occurs owing to the variation in the isotope ratio of the effluent the error in the estimation of the effluent fraction δxeff can be determined using eq 10 this value depends on x specifically the error increases proportionally with x jung et al 2020 10 δ x eff x eff c eff c s w 1 δ c eff where ceff is the mean isotope ratio in the effluent csw1 is the mean isotope ratio upstream and δceff is the isotopic variation range in the effluent in this study the 18ono3 values of effluents ranged from 4 86 to 0 35 for ten months july 2019 to april 2020 the estimated contribution of the effluent x is 27 in the sw 2 the error of x is 19 7 in recent decades siar has been used to quantify nitrogen sources as this tool can more accurately provide reliable estimations of different nitrogen sources xue et al 2012 ding et al 2014 kim et al 2015 torres martínez et al 2021 nevertheless to apply siar in various environments observation values are required for using the isotope databases and the presented findings can provide guidance for calculating the contribution of nitrate source in the area affected by the wastewater 5 summary using stable nitrate isotopes δ15nno3 and δ18ono3 in combination with stable water isotopes δ18oh2o and δ18hh2o we investigated the potential impacts of the n source in treated effluents on the surrounding stream and clarified the seasonal variation in the isotope values of effluent and stream water on the δ18o δ2h bi plots most samples except certain influent samples were positioned directly on or close to the lmwl with the slopes of the best fit lines from the least squares regression ranging from 7 42 to 8 29 r2 0 82 to 0 96 these results indicated that the stream water and effluent were meteoric in origin and the influent may have undergone a certain amount of evaporation before and or during the treatment process and transport stable water isotopes δ18oh2o and δ18hh2o in the stream water exhibited clear seasonal variations with enrichment in the dry season november 2019 to march 2020 and depletion in the wet season july 2019 to october 2019 insoutheast asia depletion in the stable water isotopic compositions in the precipitation occurs due to the amount effect during the monsoon season lee et al 2013 from july 2019 to may 2020 the period with the most depleted δ18oh2o and δ18hh2o in stream water was september 2019 by applying a modified bi plot of δ15nno3 and δ18ono3 values suggested by kendall 1998 the nitrate sources in the treated effluents and stream water were identified to be typical manure and sewage the mean isotopic compositions of the nitrate in the effluent 15nno3 13 82 1 81 δ18ono3 1 73 11 25 were lower than those of sw 1 δ15nno3 15 56 3 08 δ18ono3 4 46 2 5 and sw 2 δ15nno3 14 73 2 04 δ18ono3 2 64 1 66 for the monthly samples moreover seasonal variation in the δ18ono was observed in the monthly effluent the statistical analysis was conducted to verify whether the difference between the mean of sw 1 and sw 2 was significant it was observed that although δ15nno3 in sw 1 was almost the same as that measured in sw 2 δ18ono3 in sw 1 was higher than sw 2 these results indicated the n contaminant source from the effluent did not significantly affect the surrounding water system however δ18ono3 of the effluent depleted owing from the biogeochemical process in the wwtp likely could affect the surrounding stream comparing the short term and long term effluent samples it was noted that δ15nno3 in the effluent is influenced by the nitrogen source instead of the seasonal variation whereas δ18ono3 is primarily influenced by the seasonal effects this phenomenon occurs because when no3 is produced in the aeration tank of the wwtp process the oxygen atom originates from the ambient h2o although δ18oh2o and δ18hh2o in the influents were not sampled it can be assumed that the influent shows seasonal variations through the precipitation seasonality therefore the δ18ono3 in the effluents also could affect by seasonal variations of nearby water isotopes we estimated the contribution ratios from two point sources between the upstream and effluent to the downstream using two source mixing models we observed the contribution ratios using δ18ono3 from the effluent to the downstream was 27 in this mixing model the contribution ratio varies depending on the end member therefore when estimating the contribution of the effluents to the water system by considering the isotope values uncertainty may arise due to these seasonal variations this study is a database of potential sources needed as input data for calculating the contribution as an end member in this regard this study can provide guidance to evaluate the contribution ratio to potential sources including effluents in future studies credit authorship contribution statement hyejung jung methodology investigation writing original draft writing review editing visualization yun s kim project administration funding acquisition resources jisu yoo investigation data curation bumsung park investigation data curation jeonghoon lee conceptualization methodology supervision formal analysis declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments thank you to all of the people at jeungpyeong sewage treatment plant for providing the measured water quality data in wwtp this research is supported by korea ministry of environment as a study on development of evaluation method for analysis of organic matter in public water area 2019 2020 this work was also supported by k water and partially supported by the national research council of science and technology nst grant of the korean government msip cap 17 05 kigam appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126488 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
