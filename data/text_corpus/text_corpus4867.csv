index,text
24335,human actions led to the worldwide decline of marine mammal populations in the 18th 19th centuries global adoption of protective legislation during the 20th century has recently allowed many marine mammal populations to recover this positive trend is particularly true of pinnipeds e g seals and sea lions whose recovering populations are increasingly in conflict with fisheries fisheries organisations have called for managed culls of sea lion populations to reduce competition for target fish species as well as damage to catch and fishing gear through operational interactions however despite widespread perceptions that sea lion populations are generally increasing to date culls have often been considered or implemented without quantitative evidence of their impacts on seal lion population viability this knowledge gap is particularly concerning given the expected increase in extreme climate conditions such as extreme el niño events which together with culls could push sea lion populations in some parts of the world into the extinction vortex here i develop stochastic matrix population models of the south american sea lion otaria flavescens parameterised through a combination of species specific field data and phylogenetic imputation using data from related species in the comadre animal matrix database using these models i project the impact of 1 three cull scenarios with different intensity and temporal frequency targeting adult females 2 extreme el niño events whose frequency is modelled using a markovian transition matrix and 3 the interaction of culls and extreme climate events on population dynamics i focus on the chilean population of o flavescens where recent increases in sea lion numbers have triggered widespread conflict with small scale fisheries and where sea lion populations will increasingly be affected by extreme el niño conditions i find that sea lion populations decline below minimum viable population sizes within 16 28 years under all scenarios involving culls and extreme climate events this research explicitly incorporates parameter uncertainty into population projections in so doing it illustrates the need for future research to collect stage specific annual population data to reduce uncertainty regarding marine mammal vital rates keywords chile el niño human wildlife conflict matrix population model otaria flavescens parameter uncertainty abbreviations mpm matrix population model data availability data will be made available on request 1 introduction human actions notably hunting led to the worldwide decline of marine mammal populations in the 18th 19th centuries gerber and hilborn 2001 fortunately the global adoption of protective legislation during the 20th century has allowed many populations to bounce back magera et al 2013 this is particularly true of pinnipeds including sea lions milano et al 2020 whose recovering populations are now increasingly in conflict with fisheries cook et al 2015 scordino 2010 the exact economic impacts of conflict between fisheries and sea lion populations are unknown regardless the perception that these impacts are large and increasing has led many fisheries organisations to call for managed culls of sea lion populations the expectation is that reducing sea lion numbers will reduce competition for target species i e biological or predatory interactions beverton 1985 and damage to catch and fishing gear i e operational interactions beverton 1985 however before managers can sanction population culls it is essential to understand the projected impacts of these culls on the viability of natural populations for a population to be viable it must be able to withstand stochastic perturbations e g environmental stochasticity or natural catastrophes in the long term given its specific biogeographic setting shaffer 1981 thus a robust population viability assessment of sea lions must incorporate the impact of future climate change which may have profound consequences for these animals de oliveira et al 2012 kovacs et al 2012 to date most pinniped demographic research has had a methodological focus with the objective of developing population models when demographic data are limited this includes work by kauhala et al 2012 who estimated demographic structure and mortality rates of the baltic grey seal population based on the age structure present in hunted grey seals halichoerus grypus and wielgus et al 2008 who used inverse methods to estimate demographic rates and asymptotic population growth rates for the california sea lion zalophus californianus other analyses have focused on assessing the impact of site selection and data aggregation decisions on estimates of population survival in grey seals engbo et al 2020 recently rossi et al 2021 used an integrated population model to assess the impact of sustainable harvest on grey seal populations in canada with the ultimate goal of reducing seal predation of key fish stocks while maintaining a viable grey seal population size in line with conservation goals finally silva et al 2021 have assessed the viability of harbor seal phoca vitulina populations in sweden and denmark under different hunting levels disease threat from epizootic outbreaks and reduction in fecundity due to xenobiotics by contrast the contribution of the current analysis is to assess the impact of managed culls in combination with extreme climate events as well as to explicitly incorporate uncertainty regarding vital rates into the model architecture this analysis therefore provides a first step towards understanding the potential impact of managed culls and extreme climate events on the population dynamics of a marine mammal species whose demographic parameters are highly uncertain here i overcome limitations in the availability of demographic data by building a stochastic demographic model that incorporates parameter uncertainty in a species that is at the center of much human wildlife conflict the south american sea lion otaria flavescens cappozzo and perrin 2009 specifically i explore the potential impacts of managed culls and projected climate change impacts on the population dynamics of o flavescens in chile recovery of this species o flavescens has led to widespread conflict with small scale fisheries davis et al 2021 particularly along the coast of chile although chile does not currently cull sea lion populations a moratorium on sea lion harvest expires in 2021 decreto exento no 31 2016 cl thus creating a legal loophole for which quantitative evidence is urgently missing culls of sea lion populations are widely demanded by fishing communities in this region davis et al 2021 and hence there is a need to assess their potential impacts on the species however this region is also affected by extreme el niño conditions which have previously had large negative impacts on pinniped populations in the north of chile and also in neighbouring peru de oliveira et al 2012 sepúlveda et al 2015 extreme el niño events are characterised by sea surface temperatures exceeding 28 c cai et al 2014 these conditions lead to large decreases in prey availability causing decreases in fecundity and increases in juvenile and adult sea lion mortality de oliveira et al 2012 to assess the impact of managed culls and extreme climate events on the chilean population of o flavescens i combine known and phylogenetically imputed vital rates i e stage specific survival σ maturation γ and reproduction ϕ for o flavescens to parameterise stochastic matrix population models i then project the o flavescens population under a range of scenarios and impacts scenarios include a base case scenario absent of any cull or extreme climate impacts as well as three cull scenarios with different intensity and temporal frequency targeting adult females and an extreme climate scenario where extreme el niño conditions impact sea lion vital rates at frequencies expected for the coming century finally i assess the combined impact of culls and extreme climate events on sea lion population size through time i hypothesise that the impact of managed culls or extreme climate events in isolation will not adversely affect the viability of this population however i expect that the population will decrease below a minimum viable population size thus become functionally extinct sensu shaffer 1981 under managed culls in combination with projected frequencies of extreme el niño conditions the findings of this research will provide quantitatively based recommendations for the management of human wildlife conflict between pinnipeds and fisheries 2 methods in what follows i provide an overview of the modelling framework followed by detailed information on the study species and of the demographic and climate modelling approaches to assess the impact of managed culls and extreme climate conditions on the population dynamics of a marine mammal on the west coast of south america i parameterised a stochastic matrix population model mpm hereafter for the south american sea lion otaria flavescens mpms combine information about the rates of survival σ maturation γ and reproduction ϕ i e vital rates experienced by individuals in discrete time within discrete stages e g juvenile adult in a population to produce a model describing the dynamics of the whole population caswell 2001 though initially mpms only considered age leslie 1945 now these models often include other predictors of vital rates such as developmental stage and or size crone et al 2011 allowing for a wider range of life cycles to be assessed e g species with shrinkage salguero gómez and casper 2010 mpms are a flexible tool that have been used in applications as diverse as assessing the impact of temporal environmental autocorrelation on population viability paniw et al 2018 or to develop optimal harvesting strategies gamelon et al 2012 because of their relative ease of construction analysis and interpretation griffith et al 2016 mpms have been developed for thousands of species salguero gómez et al 2015 salguero gómez et al 2016b including other pinniped species such as the endangered kuril harbour seal p vitulina stejnegeri in japan kobayashi et al 2014 and new zealand sea lion phocarctos hookeri in the southern pacific ocean meyer et al 2015 in this analysis i parameterised a mpm for o flavescens based on species specific vital rate data and vital rates imputed using phylogenetic comparative methods from other closely related pinniped species the resulting variance in these imputed vital rate estimates informed a distribution of matrix population models using a population vector of stage specific population estimates i then projected the population under different management and climate scenarios to assess the impacts of culls and extreme climate events on o flavescens population viability i conducted eight separate analyses of the population dynamics of o flavescens over a 30 year time horizon first i assessed a base case condition i without managed culls and in the absence of extreme climate impacts then i assessed the impact of three population cull scenarios ii 15 of adult females in year one iii 10 of adult females every year and iv 30 of adult females every five years these cull scenarios describe trade offs in culling effort and population impact through time as well as mimicking a range of harvest conditions previously considered in chile sepúlveda et al 2006 next i assessed the impact of extreme climate events v represented by extreme el niño conditions whose frequency i modelled using a markovian transition matrix and whose impacts on vital rates were informed by observations from previous extreme el niño years sielfeld and guzmán 2002 soto et al 2004 finally i assessed the combined impacts of the same three cull scenarios in combination with extreme climate events vi viii fig 1 below i describe each of these steps in more detail 2 1 study species the south american sea lion o flavescens is found along the south american coast from peru to brazil with a global population of 400 000 individuals of these 50 are found in chile dans et al 2004 oliva et al 2020 the species has been described as having plastic trophic habits with diet determined by local prey abundance hückstädt and antezana 2006 in chile prey species include anchovy engraulis ringens elephant fish callorhynchus callorhynchus and hake merluccius gayi hückstädt and antezana 2006 o flavescens is one of the largest and most sexually dimorphic otariids family otariidae describing pinnipeds with ears with adult males reaching 3 m in length and 300 350 kg and adult females reaching 2 m in length and weighing up to 150 kg cappozzo and perrin 2009 the species is polygynous with males attempting to mate with as many females as possible cappozzo and perrin 2009 in chile the ratio of adult males to females in 2019 was 1 11 oliva et al 2020 adult females typically produce one pup each year soto et al 2004 and the sex ratio at birth is 1 1 cappozzo and perrin 2009 in this analysis i adopted a simplified female only life cycle with pup and juvenile stages collapsed into a single juvenile stage this approach is consistent with several other studies that focused on female population dynamics e g barlow and boveng 1991 hadley et al 2006 lalas and bradshaw 2003 and allowed me to better accommodate the emergent uncertainty from the available field data than more complex life cycle models 2 1 1 vital rate estimation i combined species specific and imputed vital rates to parameterise stochastic mpms for o flavescens some information on vital rates for o flavescens was available from sepúlveda et al 2006 specifically these authors estimated juvenile adult maturation and adult fecundity for o flavescens populations in the central regions of chile other vital rates juvenile and adult survival needed to be imputed due to the lack of available field information following recent findings regarding the robustness of phylogenetic methods to impute vital rates and life history traits james et al 2020 johnson et al 2021 penone et al 2014 i imputed juvenile survival and adult female survival using the rphylopars package goolsby et al 2017 in r r core team 2021 this method imputes missing data across a set of phylogenetically related species 11 pinniped species in this case including the target species using a phylogeny and sparse trait matrix to simultaneously estimate phylogenetic and phenotypic trait covariance previous literature has shown that imputation methods based on traits and phylogeny are generally superior penone et al 2014 hence this approach was followed i sourced vital rates for 10 pinniped species from the comadre animal matrix database v 4 20 11 0 jones et al 2021 comadre houses 3321 mpms for 415 animals worldwide in the case of pinnipeds six of the 10 species contained 1 mpm while four species were represented by only 1 mpm available matrices described unmanipulated populations i e no experimental treatments for the variable number of stages in the 11 pinniped species to be consistent with my 2 stage life cycle fig 2 a i collapsed available matrices to 2 2 stages juveniles and adults following methods by salguero gomez and plotkin 2010 using the r package rage jones et al 2021 also using rage i estimated stage specific vital rates mean and standard deviation for each species for the six pinniped species with multiple mpm available i sampled 1000 estimates of each vital rate using the mean and standard deviation across the available mpms drawing from a truncated normal distribution 0 1 for survival and maturation and 0 for fecundity i sourced a phylogenetic tree for mammals from vertlife upham et al 2019 which i pruned to the 11 pinniped species with mpm data from comadre and o flavescens using r package ape paradis and schliep 2019 using rphylopars goolsby et al 2017 i imputed missing vital rates for o flavescens for each combination of the 1000 estimates of vital rates for females of related species i then parameterised mpms for each of these 1000 estimated vital rate values an evaluation of the imputation method is provided in the supplementary materials this evaluation shows that known vital rates can be successfully imputed but that estimates are better when only single vital rates are missing compared to pairs of vital rates previous findings have also shown that phylogenetic imputation performs well for vertebrates di marco et al 2021 james et al 2020 penone et al 2014 2 1 2 population data i combined a vector of stage specific population data with the mpms to project the population through time changes in the abundance of the chilean population of o flavescens as reported in government censuses and the published literature see caption for citations are shown in fig 2 stage specific population estimates for o flavescens from a post breeding census were available for 2019 from oliva et al 2020 in this most recent census 2019 for chile there were an estimated 78 709 adult females sd estimated in current study 1050 7 126 juveniles sd 223 and 29 827 pups sd 992 based on final reported values from oliva et al 2020 and assuming a sex ratio of 1 1 in pups and juveniles i calculated a combined pup and juvenile estimate for females hereafter referred to simply as juvenile of 18 477 these data provided a two stage population vector for 2019 of 78 709 adult females and 18 477 juvenile females for the entire chilean population fig 2 to understand the base case dynamics of o flavescens scenario i i projected the population of juvenile and adult females over 30 years 2019 2049 without any impacts of cull or extreme climate impacts to do so at time t 1 i sampled a single mpm from the 1000 estimated mpms and multiplied this matrix by the population vector in time t i iterated this process 1000 times 1 σ j 1 γ j ϕ σ j γ j σ a j a the top left hand term of the matrix describes the probability that a juvenile female j survives σ j but remains a juvenile in year t 1 the bottom left hand term of the matrix describes the probability that a juvenile female survives and matures γ j into an adult a in year t 1 the bottom right hand term of the matrix describes the probability an adult female survives σ a to year t 1 finally the top right hand term of the matrix describes the number of juvenile females that an average adult female contributes to the population each year ϕ the two element vector j a describes the population size of juvenile females and adult females in year t to evaluate whether the population of o flavescens will become functionally extinct during the modelled time horizon i assessed whether and at what point in time the projected population drops below a minimum viable population size mvp sensu shaffer 1981 i used a mvp value of 5000 breeding adults thought to be sufficient to ensure long term population persistence and to avoid evolutionary decay across a broad range of taxonomic groups traill et al 2010 based on the sex ratio observed in the chilean population 1 11 45 adult males to females this criterion implies an mvp for adult females of 4 598 individuals i quantified the time that quasi extinction was reached as the year when 95 of 1000 simulated projections produced a population size n below the mvp value morris and doak 2002 2 2 cull simulations i assessed the impact of three different cull scenarios on the population of o flavescens in chile over 30 years the three scenarios i considered were scenario ii cull 15 of adult females in year 1 only scenario iii cull 10 of adult females every year or scenario iv cull 30 of adult females every 5 years these cull levels mimic a range of harvest conditions previously considered in chile sepúlveda et al 2006 i simulated these culls on adult females rather than juveniles as culling in pinnipeds has historically targeted adults due to their better accessibility relative to juveniles particularly during the breeding season when adult females come to shore to pup to estimate the impact of managed culls i assessed the population dynamics of o flavescens as described previously but with the relevant proportion of the adult female population removed from the population vector at the appropriate time step e g year 1 in scenario ii and every five years for scenario iv 2 3 climate conditions in scenario v i assessed the impact of extreme climate events on the population of o flavescens in chile to model transitions between normal and extreme climate years i used a markovian transition matrix at each time step t i e each year climate is probabilistically assigned as normal or as an extreme climate year if t is a normal year then the mpm used to estimate the population in t 1 is drawn from the base case distribution if t is an extreme climate year the mpm is drawn from an extreme climate distribution here indicating a year with an extreme el niño event cai et al 2014 an event for which austral summer rainfall is greater than 5 mm per day these extreme el niño events which included the 1982 83 and 1997 98 el niño events are characterised by exceptional warming with sea surface temperatures exceeding 28 c extending into the eastern equatorial pacific cai et al 2014 these conditions lead to large decreases in prey availability de oliveira et al 2012 and cause widespread environmental disruptions in the pacific and beyond previous research in peru which neighbours chile to the north describes a 100 mortality of juveniles and 60 mortality of adults during the 1997 98 el niño soto et al 2004 decreases in fecundity of 95 were also observed during this period soto et al 2004 sielfeld and guzmán 2002 estimated similar levels of pup and juvenile mortality for populations in northern chile to represent these effects in my simulations i modified each of the 1000 previously estimated mpms as below 2 δ σ j 1 γ j ε ϕ δ σ j γ j ω σ a where δ indicates the impact of extreme climate events on juvenile survival ω indicates the impact on adult survival and ε indicates the impact on fecundity i parameterised these elements according to previous estimations as a 100 60 and 95 decrease in the respective vital rates soto et al 2004 this approach provided a distribution of matrix population models for extreme climate years the population projection was as previously described but this time a markovian transition matrix determined whether the population vector in t 1 was multiplied by a matrix from the base case e g normal climate years or extreme climate distribution of mpms el niño events typically last 12 18 months national oceanic and atmospheric administration 2022 and the frequency of extreme el niño events is predicted to increase under global warming cai et al 2018 relative to a control period 1891 1990 when the frequency of extreme el niño conditions was estimated at one event every 20 years under current and future climate conditions 1991 2090 extreme events are predicted to occur once every ten years cai et al 2014 i used this prediction to parameterise the markovian transition matrix when climate was normal for the population in time t the probability of climate transitioning to an extreme climate scenario in t 1 was 0 1 1 p fig 1 red panel when extreme climate conditions were prevalent in time t the probability of climate transitioning to good in t 1 was 0 5 1 q fig 1 red panel this transition is consistent with noaa observations of el niño durations 12 18 months 2 4 culls and climate in scenarios vi viii the previously described processes culls and extreme climate conditions were combined these separate stressors impact the population in a multiplicative fashion at t i culling removes a given proportion of adult females if the markovian transition matrix defines climate as extreme in this time period then the revised vector of juvenile and adult population size is multiplied by a mpm drawn from the extreme climate distribution which incorporates extreme climate impacts on population vital rates this approach allows me to assess impacts that are expressed at the individual level culls which remove individuals from the population with impacts observed at the broader population level the impact of extreme climate events on vital rates i assessed the same three cull scenarios ii iv and in each of these scenarios i incorporated extreme climate conditions as previously described in scenario v 2 5 transient dynamics transient dynamics the short term dynamics of a population perturbed from a stationary stable population structure provide further insight into the impact of different cull and extreme climate scenarios on the o flavescens populations capdevila et al 2020 stott et al 2011 specifically by assessing demographic amplification and demographic attenuation respectively how a population increases in size after disturbance or alternatively decreases in size after disturbance capdevila et al 2020 we can understand how far a disturbance perturbs a population away from its stationary equilibrium in this sense it is important to note that a population that fails to resist a disturbance will show a high value of attenuation and vice versa capdevila et al 2020 i assessed the largest and smallest population size e g maximum amplification and attenuation values as well as the 5th and 95th percentile population size observed across all scenario iterations 10 years into the projection i then assessed the percentage of model iterations that amplify or attenuate relative to the average base case scenario i population size at year 10 for all scenarios at that time point populations in all scenarios have been subject to disturbance either through culls extreme climate or both but importantly have not converged back to stationary equilibrium conditions 2 6 sensitivity analysis to identify how the population viability of o flavescens is affected by extreme el niño conditions i assessed the sensitivity of results to different extreme el niño impacts on vital rates for each of the vital rates i juvenile survival ii juvenile maturation iv adult survival and v fecundity i assessed a range of possible impacts varying from no impact to a 100 decrease in each vital rate i discretised this range of impacts into five levels 0 20 40 60 and 100 for each of the 1000 combinations of vital rates previously estimated i modified the relevant vital rate by each level of the discretisation and conducted the population projection as previously described for the extreme climate scenario scenario v 3 results vital rates mean and 95 ci for female o flavescens from available field data juvenile maturation γ and adult reproduction ϕ and estimated through phylogenetic imputation juvenile survival σ j and adult survival σ a are shown in table 1 note that female adult reproduction ϕ indicates reproduction of female pups only the population projections of scenarios i iv are exclusively derived from these vital rate estimates the population projections of scenarios v viii are derived from these estimates in combination with the distribution of vital rates corresponding to extreme climate events see table 3 based on these vital rates the average mpm 95 ci in square brackets estimated for o flavescens in chile is 0 495 0 491 0 499 0 100 0 100 0 100 0 248 0 246 0 250 0 802 0 793 0 811 this mpm describes a juvenile female as having a 50 chance of surviving and remaining a juvenile and a 25 chance of surviving and maturing to an adult adult females have an 80 chance of survival and contribute 0 1 juvenile females to the population each year based on this mpm the average long term growth rate for the female o flavescens population is 0 876 95 confidence interval 0 869 0 884 which suggests that the population will decrease over time the stage specific vital rate with the largest impact on the per capita population growth rate λ is adult survival table 2 a small proportional positive change of 0 001 in this vital rate will increase λ by 75 8 by contrast there is little impact on λ of perturbations to juvenile survival juvenile maturation or adult reproduction based on the estimated distribution of mpms the chilean population of o flavescens is projected to decline over the assessed 30 year time horizon specifically under the base case scenario i and based on the initial population vector of 78 709 adult females and 18 477 juvenile females the population projection for o flavescens in chile describes a population decline over the 30 year assessment period fig 3 i this result is consistent with the estimated value of λ 1 within this assessed time horizon 30 years the population falls below the mvp size of 4598 adult females assessed as 95 of iterations meeting this criteria this suggests that the population will not persist or avoid evolutionary decay within this time period the o flavescens population in chile is also projected to decrease below an mvp under all of the assessed cull scenarios scenarios ii iv fig 3 specifically the mvp threshold is reached in year 28 when 15 of adult females are culled in year 1 only scenario ii in year 17 when 10 of adult females are culled every year scenario iii and in year 20 when 30 of adult females are culled every five years scenario iv culling 10 of adult females each year therefore has the most extreme impact on the population viability of female o flavescens in chile by contrast a population cull of 15 of adult females in year one scenario ii has negligible impacts on the population relative to the base case scenario scenario i under the projected frequencies of extreme climate events scenario v 14 7 of model iterations decline to 100 adult females within 15 years fig 3 v however the population is not assessed as quasi extinct until year 22 an estimation of the vital rates mean and 95 ci that correspond with extreme climate conditions are shown in table 3 these are the base case estimates for juvenile survival σ j adult survival σ a and adult reproduction ϕ modified by δ ω and ε see fig 1 note that no observations are available for the impacts of extreme climate conditions on juvenile maturation however as this term is multiplied by 0 juvenile survival in the matrix population model this has no impact on extreme climate projections the average mpm 95 ci in square brackets for female o flavescens in chile derived from these extreme climate vital rates is 0 0 0 0 005 0 005 0 005 0 0 0 0 321 0 317 0 325 this mpm is estimated from the distribution of vital rates underlying table 3 e g vital rates that correspond with extreme climate conditions based on this mpm the average long term growth rate for the female o flavescens population under extreme climate conditions is 0 321 95 confidence interval 0 317 0 325 the combined impact of culls and extreme climate events is to speed up the population decline of o flavescens when the population of o flavescens in subjected to culls and extreme climate events scenarios vi viii the population reaches quasi extinction under all assessed cull regimes and declines much faster than in cull scenarios without extreme climate events fig 3 ii iv compared to vi viii under an initial cull of 15 of adult females in year one scenario vi extreme climate impacts lead to the population reaching quasi extinction in year 21 7 years earlier than in the cull only scenario ii quasi extinction is hastened by 1 year in the case of an annual cull of 10 of adult females to year 16 fig 3 vii and by 3 years in the case of a 30 cull of adult females every five years year 17 fig 3 viii an annual cull of 10 of adult females scenario vii remains the cull regime with the largest impact on population viability over the assessed time horizon when combined with extreme climate impacts it should also be noted that the proportion of simulated populations declining to very low numbers 100 adult females in the first 15 years increases in all cull scenarios with the combined impact of extreme climate events across scenarios vi viii between 14 7 and 29 3 of all iterations fall below 100 adult females within the first 15 years compared to 1 across scenarios i iv based on these results it is clear that the separate impacts of managed culls or extreme climate events would adversely affect the population of o flavescens in chile in all assessed scenarios the population declines below an mvp threshold over a 30 year time horizon when subject to culls scenarios ii iv or extreme climate events scenario v under the combined impacts of managed culls and extreme climate events the speed at which the population will become functionally extinct increases under all combined scenarios vi viii the population of o flavescens in chile falls below an mvp within 16 21 years an analysis of the transient dynamics observed in each of the eight scenarios indicates how far populations would be perturbed away from their stationary stable population structures by culls and or el niño climatic extremes the scenario where the greatest demographic amplification i e ability of the population to increase in size following a disturbance is observed in year 10 of the projected time horizon i e after all scenarios have experienced perturbation is scenario v table 4 this finding suggests that the female population of o flavescens will amplify most strongly after extreme climate events when there are no population culls the scenario where the highest attenuation i e decrease in population size is observed in year 10 is scenario vii this suggests that the female population of o flavescens would attenuate most strongly when subject to extreme climate events and a cull of 10 of adult females each year a similar result is demonstrated in an analysis of the percentage of model iterations that amplify or attenuate in year 10 relative to the average base case scenario i population table 5 amplification is highest in scenario ii where there are no climate impacts and a single cull of 15 of adult females in year 1 attenuation was greatest in scenarios iii and vii where 10 of adult females were culled each year without and with extreme climate events in keeping with the analysis of the elasticity of the per capita population growth rate λ a sensitivity analysis of the impact of extreme climate events on vital rates table 6 shows the greatest change in quasi extinction occurs when adult survival is impacted by climate specifically time to quasi extinction is increased to 25 or 26 years relative to 22 in scenario v when extreme climate events do not affect adult survival or only reduce adult survival by 20 table 3 shows the different levels of extreme climate event impacts that were assessed these range from no impact 0 decrease to a 100 decrease in the relevant vital rate value note that in this analysis non target vital rates were maintained at levels observed during extreme climate events see table 3 for vital rates other than adult survival there is little difference in the speed with which populations decrease below the mvp threshold irrespective of the assumed impacts of extreme climate events on each vital rate 4 discussion using stochastic matrix population models mpms in this mathematical exercise i show that the chilean population of the south american sea lion otaria flavescens could decline well below a minimum viable population mvp shaffer 1981 threshold over a 30 year time horizon based on the stochastic mpms i estimate a long term population growth rate for the chilean population of this species of 0 88 indicating a population decline of 12 every year in the absence of managed culls or extreme climate conditions this key finding contrasts with historically observed increases in the population from 1978 to 2012 one can speculate that legal protection from hunting allowed the o flavescens population to increase rapidly from the 1970 s e g from 40 000 individuals torres et al 2000b to the 2010 s 158 000 individuals oliva et al 2020 in a closed population the only way a population can increase is via reproduction overcompensating deaths we can therefore surmise that adult reproduction was high during this period however the recent decade has seen a slowing or even decline in this growth currently 130 000 individuals oliva et al 2020 in the current modelling exercise stochastic mpms were developed from available field data and phylogenetically imputed vital rates as adult reproduction was one of the vital rates available from field data we can deduce that this vital rate has decreased in recent years which is why the chilean population is no longer increasing to understand how the o flavescens population will respond to management culls and extreme climate events in the short term the long term population growth rate is insufficient we must use short term transient metrics the current analysis showed that the chilean o flavescens population attenuates e g decreases in population size when perturbed by either managed culls extreme climate conditions or a combination of the two in combination the long term population growth rate and transient metrics provide a more comprehensive perspective regarding how populations will respond over different time horizons and environmental conditions this understanding helps us plan management actions accordingly either for population control or protection this research shows that the speed of o flavescens population decline is expected to accelerate under managed culls and or expected frequencies of future extreme el niño events when managed culls and extreme el niño impacts are combined model simulations indicate populations will decrease below an mvp between 1 and 7 years faster than under managed culls alone based on these results the chilean population of o flavescens is unlikely to support a managed cull particularly given current expectations about the frequency of extreme climate events including el niño conditions a similar conclusion was reached by silva et al 2021 these authors found that harbor seal populations p vitulina in sweden and denmark could sustain modest hunting and infrequent epizootic events but that external stressors that reduced fecundity e g exposure to endocrine disruptors would leave seal populations vulnerable to rapid population decline in keeping with these results management efforts to reduce conflicts with fisheries in chile should avoid managed culls management of fisheries conflict with seals in scotland similarly switched focus from population reduction to targeting of individual seals found to be frequenting rivers and netting stations butler et al 2011 the new management approach reduced seal shooting by 60 and was considered a successful conflict management policy by the scottish government other alternative conflict management options may include capacity building schemes financial compensation or growth in eco tourism enterprises davis et al 2021 for example pinniped tourism has experienced strong growth in recent decades birtles et al 2001 public engagement with pinnipeds through tourism activities likely increases appreciation and desire to conserve these animals however it is worth noting that tourism can also have detrimental impacts on the animals involved páez rosas and guevara 2017 which must be minimised through appropriate guidelines and regulation kirkwood et al 2003 this analysis demonstrates that extreme climate events are expected to hasten the decline of o flavescens below an mvp value this finding indicates that the precautionary principle i e precautionary action despite scientific uncertainty resnik 2003 may need to be exercised when managing the population of o flavescens on the west coast of south american larger populations will be required to allow the population to buffer against extreme climate events a similar conclusion was reached by de oliveira et al 2012 in an assessment of the effective population size of o flavescens in peru which explicitly considered the impacts of the mating system and demographic variations caused by the 1998 98 extreme el niño event in this work the authors recommended a population of 7715 individuals to ensure the population was large enough to avoid inbreeding and retain sufficient adaptive genetic variation to survive future el niño events demographic simulations in the current analysis show considerable variation in the assessed population projections through time after 10 years the maximum and minimum population sizes observed across model iterations under all scenarios vary by at least one order of magnitude these fluctuations are due to the transient dynamics that originate when disturbances impact stage structured populations capdevila et al 2020 stott et al 2010 disturbances can change the total size of a population but also the relative number of individuals in each stage therein i e its population structure because the disturbance may kill more individuals in a given life cycle stage relative to other stages these changes in population structure can then lead to increased amplified or decreased attenuated growth in the short term as part of its transient dynamics caswell 2001 stott et al 2011 the population may recover its stationary equilibrium if and when the relative number of individuals in each life cycle stage returns to its pre disturbance i e asymptotic state in this context it is important to note that o flavescens similarly to other pinniped species is a slow species gaillard et al 1989 salguero gómez et al 2016 stearns 1992 meaning that it is long lived has long generation times and low reproductive output such slow species tend to have longer recovery times greater ability to resist disturbances i e lower attenuation and lower ability to amplify increase after a disturbance capdevila et al 2021 stott et al 2011 a recent assessment of how life history traits can predict a species intrinsic resilience capdevila et al 2021 found that species with longer generation times require longer recovery times post disturbance the authors also found generation time to be negatively correlated with resistance the inverse of how far populations attenuate after disturbance these findings can help explain why o flavescens populations in this analysis attenuate decrease so strongly after disturbance and show long recovery times a sensitivity analysis of the effects of extreme el niño events on o flavescens vital rates demonstrates that these events will be most damaging to sea lion populations when they decrease adult survival by contrast if adult survival can be buffered from extreme climate impacts perhaps through policies to reduce mortality through fisheries bycatch breen et al 2003 or reduce fishing pressure on prey species hennen 2006 sepúlveda et al 2011 then negative impacts on population viability will be reduced results showed that quasi extinction risk for the chilean o flavescens population is relatively insensitive to changes in the magnitude of extreme climate impacts on juvenile survival juvenile maturation and fecundity in this sensitivity analysis as in scenarios v viii extreme climate events do not occur every year hence even when extreme climate events have large negative impacts on sea lion vital rates e g 100 adult mortality this will not necessarily lead to an immediate population decline below the mvp size it is worth noting that the impact of extreme el niño events on vital rates was parameterised from northern populations in chile e g de oliveira et al 2012 soto et al 2004 it is unlikely that these impacts would be as severe for southern populations in chile however southerly populations of o flavescens may experience similar extreme population declines due to epizootic outbreaks silva et al 2021 or other stressors for example populations on the argentinian coast decreased by 93 between 1938 and 1975 due to unknown causes gerber and hilborn 2001 the large historical increases in population size of chilean o flavescens without doubt contribute to the widespread perceptions of fishers in chile that sea lion populations are currently too large and that they are rapidly increasing davis et al 2021 this dichotomy may be explained by a shifting baseline syndrome pauly 1995 i e fishers use the prevailing sea lion population size when they began fishing as their baseline irrespective of the status of the population relative to historical levels at that point although many sea lion populations around the world and in chile have not yet recovered to historical population abundance i e levels observed before widespread sealing in the 18th 19th centuries lotze et al 2011 magera et al 2013 many fishers began their careers in the years when sea lion populations were still small for example in chile over a third of fishers surveyed in a recent assessment of conflict with sea lions davis et al 2021 began fishing over 40 years ago when sea lion populations in chile were approximately a quarter of the size they are now fig 2 hence current increases in pinniped populations may be seen as unprecedented growth rather than a recovery towards historical levels the present study is one of the few existing demographic analyses to incorporate uncertainty in vital rates into population projections e g see paniw et al 2017 and to my knowledge the first one to do so in pinnipeds however results clearly point to the need for more annual stage based field data which would allow species specific vital rates to be estimated through inverse methods wielgus et al 2008 assuming that individual based records were not feasible note that despite the current modelling approach estimating a very narrow confidence interval around the long term growth rate mean 0 876 95 ci 0 869 and 0 884 this precision can be interpreted as certainty in the estimation i e due to large number of model iterations n 1000 rather than certainty in the approximation of the modelled estimate to the true long term growth rate this approximation will be improved by the addition of further annual stage based field data in particular more exact estimates of vital rates would allow a more complex life cycle to be assessed including a two sex model as male animals interact more often with fisheries kauhala et al 2012 a two sex model would permit more nuanced modelling of cull or population control measures in chile some level of illegal harvest of sea lions also occurs davis et al 2021 the impact of this mortality is not incorporated in the current analysis as reliable data for these activities remain elusive data on illegal mortality levels would allow a better estimate of vital rates and of the long term population growth rate conflict between marine mammals including sea lions and fisheries remains a highly contentious management issue davis et al 2021 ramos et al 2020 the present research provides quantitative evidence that this conflict may be best resolved independent of management culls a historically implemented approach in this context galatius et al 2020 mancilla gonzález 2018 perceptions of increases in sea lion populations may be an artefact of shifting baselines pauly 1995 or the saliency of short term transient population dynamics stott et al 2010 increases in the frequency of extreme climate events will leave sea lion populations vulnerable to extinction requiring larger populations to remain viable over time this precautionary but necessary approach is likely to exacerbate conflict with fisheries highlighting an urgent need to develop and test alternative conflict management solutions author contributions all aspects of this work were conceptualised analysed and written by the author kjd declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the ukri internal research england global challenges research support fund 0008129 to k j d supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110122 appendix supplementary materials image application 1 
24335,human actions led to the worldwide decline of marine mammal populations in the 18th 19th centuries global adoption of protective legislation during the 20th century has recently allowed many marine mammal populations to recover this positive trend is particularly true of pinnipeds e g seals and sea lions whose recovering populations are increasingly in conflict with fisheries fisheries organisations have called for managed culls of sea lion populations to reduce competition for target fish species as well as damage to catch and fishing gear through operational interactions however despite widespread perceptions that sea lion populations are generally increasing to date culls have often been considered or implemented without quantitative evidence of their impacts on seal lion population viability this knowledge gap is particularly concerning given the expected increase in extreme climate conditions such as extreme el niño events which together with culls could push sea lion populations in some parts of the world into the extinction vortex here i develop stochastic matrix population models of the south american sea lion otaria flavescens parameterised through a combination of species specific field data and phylogenetic imputation using data from related species in the comadre animal matrix database using these models i project the impact of 1 three cull scenarios with different intensity and temporal frequency targeting adult females 2 extreme el niño events whose frequency is modelled using a markovian transition matrix and 3 the interaction of culls and extreme climate events on population dynamics i focus on the chilean population of o flavescens where recent increases in sea lion numbers have triggered widespread conflict with small scale fisheries and where sea lion populations will increasingly be affected by extreme el niño conditions i find that sea lion populations decline below minimum viable population sizes within 16 28 years under all scenarios involving culls and extreme climate events this research explicitly incorporates parameter uncertainty into population projections in so doing it illustrates the need for future research to collect stage specific annual population data to reduce uncertainty regarding marine mammal vital rates keywords chile el niño human wildlife conflict matrix population model otaria flavescens parameter uncertainty abbreviations mpm matrix population model data availability data will be made available on request 1 introduction human actions notably hunting led to the worldwide decline of marine mammal populations in the 18th 19th centuries gerber and hilborn 2001 fortunately the global adoption of protective legislation during the 20th century has allowed many populations to bounce back magera et al 2013 this is particularly true of pinnipeds including sea lions milano et al 2020 whose recovering populations are now increasingly in conflict with fisheries cook et al 2015 scordino 2010 the exact economic impacts of conflict between fisheries and sea lion populations are unknown regardless the perception that these impacts are large and increasing has led many fisheries organisations to call for managed culls of sea lion populations the expectation is that reducing sea lion numbers will reduce competition for target species i e biological or predatory interactions beverton 1985 and damage to catch and fishing gear i e operational interactions beverton 1985 however before managers can sanction population culls it is essential to understand the projected impacts of these culls on the viability of natural populations for a population to be viable it must be able to withstand stochastic perturbations e g environmental stochasticity or natural catastrophes in the long term given its specific biogeographic setting shaffer 1981 thus a robust population viability assessment of sea lions must incorporate the impact of future climate change which may have profound consequences for these animals de oliveira et al 2012 kovacs et al 2012 to date most pinniped demographic research has had a methodological focus with the objective of developing population models when demographic data are limited this includes work by kauhala et al 2012 who estimated demographic structure and mortality rates of the baltic grey seal population based on the age structure present in hunted grey seals halichoerus grypus and wielgus et al 2008 who used inverse methods to estimate demographic rates and asymptotic population growth rates for the california sea lion zalophus californianus other analyses have focused on assessing the impact of site selection and data aggregation decisions on estimates of population survival in grey seals engbo et al 2020 recently rossi et al 2021 used an integrated population model to assess the impact of sustainable harvest on grey seal populations in canada with the ultimate goal of reducing seal predation of key fish stocks while maintaining a viable grey seal population size in line with conservation goals finally silva et al 2021 have assessed the viability of harbor seal phoca vitulina populations in sweden and denmark under different hunting levels disease threat from epizootic outbreaks and reduction in fecundity due to xenobiotics by contrast the contribution of the current analysis is to assess the impact of managed culls in combination with extreme climate events as well as to explicitly incorporate uncertainty regarding vital rates into the model architecture this analysis therefore provides a first step towards understanding the potential impact of managed culls and extreme climate events on the population dynamics of a marine mammal species whose demographic parameters are highly uncertain here i overcome limitations in the availability of demographic data by building a stochastic demographic model that incorporates parameter uncertainty in a species that is at the center of much human wildlife conflict the south american sea lion otaria flavescens cappozzo and perrin 2009 specifically i explore the potential impacts of managed culls and projected climate change impacts on the population dynamics of o flavescens in chile recovery of this species o flavescens has led to widespread conflict with small scale fisheries davis et al 2021 particularly along the coast of chile although chile does not currently cull sea lion populations a moratorium on sea lion harvest expires in 2021 decreto exento no 31 2016 cl thus creating a legal loophole for which quantitative evidence is urgently missing culls of sea lion populations are widely demanded by fishing communities in this region davis et al 2021 and hence there is a need to assess their potential impacts on the species however this region is also affected by extreme el niño conditions which have previously had large negative impacts on pinniped populations in the north of chile and also in neighbouring peru de oliveira et al 2012 sepúlveda et al 2015 extreme el niño events are characterised by sea surface temperatures exceeding 28 c cai et al 2014 these conditions lead to large decreases in prey availability causing decreases in fecundity and increases in juvenile and adult sea lion mortality de oliveira et al 2012 to assess the impact of managed culls and extreme climate events on the chilean population of o flavescens i combine known and phylogenetically imputed vital rates i e stage specific survival σ maturation γ and reproduction ϕ for o flavescens to parameterise stochastic matrix population models i then project the o flavescens population under a range of scenarios and impacts scenarios include a base case scenario absent of any cull or extreme climate impacts as well as three cull scenarios with different intensity and temporal frequency targeting adult females and an extreme climate scenario where extreme el niño conditions impact sea lion vital rates at frequencies expected for the coming century finally i assess the combined impact of culls and extreme climate events on sea lion population size through time i hypothesise that the impact of managed culls or extreme climate events in isolation will not adversely affect the viability of this population however i expect that the population will decrease below a minimum viable population size thus become functionally extinct sensu shaffer 1981 under managed culls in combination with projected frequencies of extreme el niño conditions the findings of this research will provide quantitatively based recommendations for the management of human wildlife conflict between pinnipeds and fisheries 2 methods in what follows i provide an overview of the modelling framework followed by detailed information on the study species and of the demographic and climate modelling approaches to assess the impact of managed culls and extreme climate conditions on the population dynamics of a marine mammal on the west coast of south america i parameterised a stochastic matrix population model mpm hereafter for the south american sea lion otaria flavescens mpms combine information about the rates of survival σ maturation γ and reproduction ϕ i e vital rates experienced by individuals in discrete time within discrete stages e g juvenile adult in a population to produce a model describing the dynamics of the whole population caswell 2001 though initially mpms only considered age leslie 1945 now these models often include other predictors of vital rates such as developmental stage and or size crone et al 2011 allowing for a wider range of life cycles to be assessed e g species with shrinkage salguero gómez and casper 2010 mpms are a flexible tool that have been used in applications as diverse as assessing the impact of temporal environmental autocorrelation on population viability paniw et al 2018 or to develop optimal harvesting strategies gamelon et al 2012 because of their relative ease of construction analysis and interpretation griffith et al 2016 mpms have been developed for thousands of species salguero gómez et al 2015 salguero gómez et al 2016b including other pinniped species such as the endangered kuril harbour seal p vitulina stejnegeri in japan kobayashi et al 2014 and new zealand sea lion phocarctos hookeri in the southern pacific ocean meyer et al 2015 in this analysis i parameterised a mpm for o flavescens based on species specific vital rate data and vital rates imputed using phylogenetic comparative methods from other closely related pinniped species the resulting variance in these imputed vital rate estimates informed a distribution of matrix population models using a population vector of stage specific population estimates i then projected the population under different management and climate scenarios to assess the impacts of culls and extreme climate events on o flavescens population viability i conducted eight separate analyses of the population dynamics of o flavescens over a 30 year time horizon first i assessed a base case condition i without managed culls and in the absence of extreme climate impacts then i assessed the impact of three population cull scenarios ii 15 of adult females in year one iii 10 of adult females every year and iv 30 of adult females every five years these cull scenarios describe trade offs in culling effort and population impact through time as well as mimicking a range of harvest conditions previously considered in chile sepúlveda et al 2006 next i assessed the impact of extreme climate events v represented by extreme el niño conditions whose frequency i modelled using a markovian transition matrix and whose impacts on vital rates were informed by observations from previous extreme el niño years sielfeld and guzmán 2002 soto et al 2004 finally i assessed the combined impacts of the same three cull scenarios in combination with extreme climate events vi viii fig 1 below i describe each of these steps in more detail 2 1 study species the south american sea lion o flavescens is found along the south american coast from peru to brazil with a global population of 400 000 individuals of these 50 are found in chile dans et al 2004 oliva et al 2020 the species has been described as having plastic trophic habits with diet determined by local prey abundance hückstädt and antezana 2006 in chile prey species include anchovy engraulis ringens elephant fish callorhynchus callorhynchus and hake merluccius gayi hückstädt and antezana 2006 o flavescens is one of the largest and most sexually dimorphic otariids family otariidae describing pinnipeds with ears with adult males reaching 3 m in length and 300 350 kg and adult females reaching 2 m in length and weighing up to 150 kg cappozzo and perrin 2009 the species is polygynous with males attempting to mate with as many females as possible cappozzo and perrin 2009 in chile the ratio of adult males to females in 2019 was 1 11 oliva et al 2020 adult females typically produce one pup each year soto et al 2004 and the sex ratio at birth is 1 1 cappozzo and perrin 2009 in this analysis i adopted a simplified female only life cycle with pup and juvenile stages collapsed into a single juvenile stage this approach is consistent with several other studies that focused on female population dynamics e g barlow and boveng 1991 hadley et al 2006 lalas and bradshaw 2003 and allowed me to better accommodate the emergent uncertainty from the available field data than more complex life cycle models 2 1 1 vital rate estimation i combined species specific and imputed vital rates to parameterise stochastic mpms for o flavescens some information on vital rates for o flavescens was available from sepúlveda et al 2006 specifically these authors estimated juvenile adult maturation and adult fecundity for o flavescens populations in the central regions of chile other vital rates juvenile and adult survival needed to be imputed due to the lack of available field information following recent findings regarding the robustness of phylogenetic methods to impute vital rates and life history traits james et al 2020 johnson et al 2021 penone et al 2014 i imputed juvenile survival and adult female survival using the rphylopars package goolsby et al 2017 in r r core team 2021 this method imputes missing data across a set of phylogenetically related species 11 pinniped species in this case including the target species using a phylogeny and sparse trait matrix to simultaneously estimate phylogenetic and phenotypic trait covariance previous literature has shown that imputation methods based on traits and phylogeny are generally superior penone et al 2014 hence this approach was followed i sourced vital rates for 10 pinniped species from the comadre animal matrix database v 4 20 11 0 jones et al 2021 comadre houses 3321 mpms for 415 animals worldwide in the case of pinnipeds six of the 10 species contained 1 mpm while four species were represented by only 1 mpm available matrices described unmanipulated populations i e no experimental treatments for the variable number of stages in the 11 pinniped species to be consistent with my 2 stage life cycle fig 2 a i collapsed available matrices to 2 2 stages juveniles and adults following methods by salguero gomez and plotkin 2010 using the r package rage jones et al 2021 also using rage i estimated stage specific vital rates mean and standard deviation for each species for the six pinniped species with multiple mpm available i sampled 1000 estimates of each vital rate using the mean and standard deviation across the available mpms drawing from a truncated normal distribution 0 1 for survival and maturation and 0 for fecundity i sourced a phylogenetic tree for mammals from vertlife upham et al 2019 which i pruned to the 11 pinniped species with mpm data from comadre and o flavescens using r package ape paradis and schliep 2019 using rphylopars goolsby et al 2017 i imputed missing vital rates for o flavescens for each combination of the 1000 estimates of vital rates for females of related species i then parameterised mpms for each of these 1000 estimated vital rate values an evaluation of the imputation method is provided in the supplementary materials this evaluation shows that known vital rates can be successfully imputed but that estimates are better when only single vital rates are missing compared to pairs of vital rates previous findings have also shown that phylogenetic imputation performs well for vertebrates di marco et al 2021 james et al 2020 penone et al 2014 2 1 2 population data i combined a vector of stage specific population data with the mpms to project the population through time changes in the abundance of the chilean population of o flavescens as reported in government censuses and the published literature see caption for citations are shown in fig 2 stage specific population estimates for o flavescens from a post breeding census were available for 2019 from oliva et al 2020 in this most recent census 2019 for chile there were an estimated 78 709 adult females sd estimated in current study 1050 7 126 juveniles sd 223 and 29 827 pups sd 992 based on final reported values from oliva et al 2020 and assuming a sex ratio of 1 1 in pups and juveniles i calculated a combined pup and juvenile estimate for females hereafter referred to simply as juvenile of 18 477 these data provided a two stage population vector for 2019 of 78 709 adult females and 18 477 juvenile females for the entire chilean population fig 2 to understand the base case dynamics of o flavescens scenario i i projected the population of juvenile and adult females over 30 years 2019 2049 without any impacts of cull or extreme climate impacts to do so at time t 1 i sampled a single mpm from the 1000 estimated mpms and multiplied this matrix by the population vector in time t i iterated this process 1000 times 1 σ j 1 γ j ϕ σ j γ j σ a j a the top left hand term of the matrix describes the probability that a juvenile female j survives σ j but remains a juvenile in year t 1 the bottom left hand term of the matrix describes the probability that a juvenile female survives and matures γ j into an adult a in year t 1 the bottom right hand term of the matrix describes the probability an adult female survives σ a to year t 1 finally the top right hand term of the matrix describes the number of juvenile females that an average adult female contributes to the population each year ϕ the two element vector j a describes the population size of juvenile females and adult females in year t to evaluate whether the population of o flavescens will become functionally extinct during the modelled time horizon i assessed whether and at what point in time the projected population drops below a minimum viable population size mvp sensu shaffer 1981 i used a mvp value of 5000 breeding adults thought to be sufficient to ensure long term population persistence and to avoid evolutionary decay across a broad range of taxonomic groups traill et al 2010 based on the sex ratio observed in the chilean population 1 11 45 adult males to females this criterion implies an mvp for adult females of 4 598 individuals i quantified the time that quasi extinction was reached as the year when 95 of 1000 simulated projections produced a population size n below the mvp value morris and doak 2002 2 2 cull simulations i assessed the impact of three different cull scenarios on the population of o flavescens in chile over 30 years the three scenarios i considered were scenario ii cull 15 of adult females in year 1 only scenario iii cull 10 of adult females every year or scenario iv cull 30 of adult females every 5 years these cull levels mimic a range of harvest conditions previously considered in chile sepúlveda et al 2006 i simulated these culls on adult females rather than juveniles as culling in pinnipeds has historically targeted adults due to their better accessibility relative to juveniles particularly during the breeding season when adult females come to shore to pup to estimate the impact of managed culls i assessed the population dynamics of o flavescens as described previously but with the relevant proportion of the adult female population removed from the population vector at the appropriate time step e g year 1 in scenario ii and every five years for scenario iv 2 3 climate conditions in scenario v i assessed the impact of extreme climate events on the population of o flavescens in chile to model transitions between normal and extreme climate years i used a markovian transition matrix at each time step t i e each year climate is probabilistically assigned as normal or as an extreme climate year if t is a normal year then the mpm used to estimate the population in t 1 is drawn from the base case distribution if t is an extreme climate year the mpm is drawn from an extreme climate distribution here indicating a year with an extreme el niño event cai et al 2014 an event for which austral summer rainfall is greater than 5 mm per day these extreme el niño events which included the 1982 83 and 1997 98 el niño events are characterised by exceptional warming with sea surface temperatures exceeding 28 c extending into the eastern equatorial pacific cai et al 2014 these conditions lead to large decreases in prey availability de oliveira et al 2012 and cause widespread environmental disruptions in the pacific and beyond previous research in peru which neighbours chile to the north describes a 100 mortality of juveniles and 60 mortality of adults during the 1997 98 el niño soto et al 2004 decreases in fecundity of 95 were also observed during this period soto et al 2004 sielfeld and guzmán 2002 estimated similar levels of pup and juvenile mortality for populations in northern chile to represent these effects in my simulations i modified each of the 1000 previously estimated mpms as below 2 δ σ j 1 γ j ε ϕ δ σ j γ j ω σ a where δ indicates the impact of extreme climate events on juvenile survival ω indicates the impact on adult survival and ε indicates the impact on fecundity i parameterised these elements according to previous estimations as a 100 60 and 95 decrease in the respective vital rates soto et al 2004 this approach provided a distribution of matrix population models for extreme climate years the population projection was as previously described but this time a markovian transition matrix determined whether the population vector in t 1 was multiplied by a matrix from the base case e g normal climate years or extreme climate distribution of mpms el niño events typically last 12 18 months national oceanic and atmospheric administration 2022 and the frequency of extreme el niño events is predicted to increase under global warming cai et al 2018 relative to a control period 1891 1990 when the frequency of extreme el niño conditions was estimated at one event every 20 years under current and future climate conditions 1991 2090 extreme events are predicted to occur once every ten years cai et al 2014 i used this prediction to parameterise the markovian transition matrix when climate was normal for the population in time t the probability of climate transitioning to an extreme climate scenario in t 1 was 0 1 1 p fig 1 red panel when extreme climate conditions were prevalent in time t the probability of climate transitioning to good in t 1 was 0 5 1 q fig 1 red panel this transition is consistent with noaa observations of el niño durations 12 18 months 2 4 culls and climate in scenarios vi viii the previously described processes culls and extreme climate conditions were combined these separate stressors impact the population in a multiplicative fashion at t i culling removes a given proportion of adult females if the markovian transition matrix defines climate as extreme in this time period then the revised vector of juvenile and adult population size is multiplied by a mpm drawn from the extreme climate distribution which incorporates extreme climate impacts on population vital rates this approach allows me to assess impacts that are expressed at the individual level culls which remove individuals from the population with impacts observed at the broader population level the impact of extreme climate events on vital rates i assessed the same three cull scenarios ii iv and in each of these scenarios i incorporated extreme climate conditions as previously described in scenario v 2 5 transient dynamics transient dynamics the short term dynamics of a population perturbed from a stationary stable population structure provide further insight into the impact of different cull and extreme climate scenarios on the o flavescens populations capdevila et al 2020 stott et al 2011 specifically by assessing demographic amplification and demographic attenuation respectively how a population increases in size after disturbance or alternatively decreases in size after disturbance capdevila et al 2020 we can understand how far a disturbance perturbs a population away from its stationary equilibrium in this sense it is important to note that a population that fails to resist a disturbance will show a high value of attenuation and vice versa capdevila et al 2020 i assessed the largest and smallest population size e g maximum amplification and attenuation values as well as the 5th and 95th percentile population size observed across all scenario iterations 10 years into the projection i then assessed the percentage of model iterations that amplify or attenuate relative to the average base case scenario i population size at year 10 for all scenarios at that time point populations in all scenarios have been subject to disturbance either through culls extreme climate or both but importantly have not converged back to stationary equilibrium conditions 2 6 sensitivity analysis to identify how the population viability of o flavescens is affected by extreme el niño conditions i assessed the sensitivity of results to different extreme el niño impacts on vital rates for each of the vital rates i juvenile survival ii juvenile maturation iv adult survival and v fecundity i assessed a range of possible impacts varying from no impact to a 100 decrease in each vital rate i discretised this range of impacts into five levels 0 20 40 60 and 100 for each of the 1000 combinations of vital rates previously estimated i modified the relevant vital rate by each level of the discretisation and conducted the population projection as previously described for the extreme climate scenario scenario v 3 results vital rates mean and 95 ci for female o flavescens from available field data juvenile maturation γ and adult reproduction ϕ and estimated through phylogenetic imputation juvenile survival σ j and adult survival σ a are shown in table 1 note that female adult reproduction ϕ indicates reproduction of female pups only the population projections of scenarios i iv are exclusively derived from these vital rate estimates the population projections of scenarios v viii are derived from these estimates in combination with the distribution of vital rates corresponding to extreme climate events see table 3 based on these vital rates the average mpm 95 ci in square brackets estimated for o flavescens in chile is 0 495 0 491 0 499 0 100 0 100 0 100 0 248 0 246 0 250 0 802 0 793 0 811 this mpm describes a juvenile female as having a 50 chance of surviving and remaining a juvenile and a 25 chance of surviving and maturing to an adult adult females have an 80 chance of survival and contribute 0 1 juvenile females to the population each year based on this mpm the average long term growth rate for the female o flavescens population is 0 876 95 confidence interval 0 869 0 884 which suggests that the population will decrease over time the stage specific vital rate with the largest impact on the per capita population growth rate λ is adult survival table 2 a small proportional positive change of 0 001 in this vital rate will increase λ by 75 8 by contrast there is little impact on λ of perturbations to juvenile survival juvenile maturation or adult reproduction based on the estimated distribution of mpms the chilean population of o flavescens is projected to decline over the assessed 30 year time horizon specifically under the base case scenario i and based on the initial population vector of 78 709 adult females and 18 477 juvenile females the population projection for o flavescens in chile describes a population decline over the 30 year assessment period fig 3 i this result is consistent with the estimated value of λ 1 within this assessed time horizon 30 years the population falls below the mvp size of 4598 adult females assessed as 95 of iterations meeting this criteria this suggests that the population will not persist or avoid evolutionary decay within this time period the o flavescens population in chile is also projected to decrease below an mvp under all of the assessed cull scenarios scenarios ii iv fig 3 specifically the mvp threshold is reached in year 28 when 15 of adult females are culled in year 1 only scenario ii in year 17 when 10 of adult females are culled every year scenario iii and in year 20 when 30 of adult females are culled every five years scenario iv culling 10 of adult females each year therefore has the most extreme impact on the population viability of female o flavescens in chile by contrast a population cull of 15 of adult females in year one scenario ii has negligible impacts on the population relative to the base case scenario scenario i under the projected frequencies of extreme climate events scenario v 14 7 of model iterations decline to 100 adult females within 15 years fig 3 v however the population is not assessed as quasi extinct until year 22 an estimation of the vital rates mean and 95 ci that correspond with extreme climate conditions are shown in table 3 these are the base case estimates for juvenile survival σ j adult survival σ a and adult reproduction ϕ modified by δ ω and ε see fig 1 note that no observations are available for the impacts of extreme climate conditions on juvenile maturation however as this term is multiplied by 0 juvenile survival in the matrix population model this has no impact on extreme climate projections the average mpm 95 ci in square brackets for female o flavescens in chile derived from these extreme climate vital rates is 0 0 0 0 005 0 005 0 005 0 0 0 0 321 0 317 0 325 this mpm is estimated from the distribution of vital rates underlying table 3 e g vital rates that correspond with extreme climate conditions based on this mpm the average long term growth rate for the female o flavescens population under extreme climate conditions is 0 321 95 confidence interval 0 317 0 325 the combined impact of culls and extreme climate events is to speed up the population decline of o flavescens when the population of o flavescens in subjected to culls and extreme climate events scenarios vi viii the population reaches quasi extinction under all assessed cull regimes and declines much faster than in cull scenarios without extreme climate events fig 3 ii iv compared to vi viii under an initial cull of 15 of adult females in year one scenario vi extreme climate impacts lead to the population reaching quasi extinction in year 21 7 years earlier than in the cull only scenario ii quasi extinction is hastened by 1 year in the case of an annual cull of 10 of adult females to year 16 fig 3 vii and by 3 years in the case of a 30 cull of adult females every five years year 17 fig 3 viii an annual cull of 10 of adult females scenario vii remains the cull regime with the largest impact on population viability over the assessed time horizon when combined with extreme climate impacts it should also be noted that the proportion of simulated populations declining to very low numbers 100 adult females in the first 15 years increases in all cull scenarios with the combined impact of extreme climate events across scenarios vi viii between 14 7 and 29 3 of all iterations fall below 100 adult females within the first 15 years compared to 1 across scenarios i iv based on these results it is clear that the separate impacts of managed culls or extreme climate events would adversely affect the population of o flavescens in chile in all assessed scenarios the population declines below an mvp threshold over a 30 year time horizon when subject to culls scenarios ii iv or extreme climate events scenario v under the combined impacts of managed culls and extreme climate events the speed at which the population will become functionally extinct increases under all combined scenarios vi viii the population of o flavescens in chile falls below an mvp within 16 21 years an analysis of the transient dynamics observed in each of the eight scenarios indicates how far populations would be perturbed away from their stationary stable population structures by culls and or el niño climatic extremes the scenario where the greatest demographic amplification i e ability of the population to increase in size following a disturbance is observed in year 10 of the projected time horizon i e after all scenarios have experienced perturbation is scenario v table 4 this finding suggests that the female population of o flavescens will amplify most strongly after extreme climate events when there are no population culls the scenario where the highest attenuation i e decrease in population size is observed in year 10 is scenario vii this suggests that the female population of o flavescens would attenuate most strongly when subject to extreme climate events and a cull of 10 of adult females each year a similar result is demonstrated in an analysis of the percentage of model iterations that amplify or attenuate in year 10 relative to the average base case scenario i population table 5 amplification is highest in scenario ii where there are no climate impacts and a single cull of 15 of adult females in year 1 attenuation was greatest in scenarios iii and vii where 10 of adult females were culled each year without and with extreme climate events in keeping with the analysis of the elasticity of the per capita population growth rate λ a sensitivity analysis of the impact of extreme climate events on vital rates table 6 shows the greatest change in quasi extinction occurs when adult survival is impacted by climate specifically time to quasi extinction is increased to 25 or 26 years relative to 22 in scenario v when extreme climate events do not affect adult survival or only reduce adult survival by 20 table 3 shows the different levels of extreme climate event impacts that were assessed these range from no impact 0 decrease to a 100 decrease in the relevant vital rate value note that in this analysis non target vital rates were maintained at levels observed during extreme climate events see table 3 for vital rates other than adult survival there is little difference in the speed with which populations decrease below the mvp threshold irrespective of the assumed impacts of extreme climate events on each vital rate 4 discussion using stochastic matrix population models mpms in this mathematical exercise i show that the chilean population of the south american sea lion otaria flavescens could decline well below a minimum viable population mvp shaffer 1981 threshold over a 30 year time horizon based on the stochastic mpms i estimate a long term population growth rate for the chilean population of this species of 0 88 indicating a population decline of 12 every year in the absence of managed culls or extreme climate conditions this key finding contrasts with historically observed increases in the population from 1978 to 2012 one can speculate that legal protection from hunting allowed the o flavescens population to increase rapidly from the 1970 s e g from 40 000 individuals torres et al 2000b to the 2010 s 158 000 individuals oliva et al 2020 in a closed population the only way a population can increase is via reproduction overcompensating deaths we can therefore surmise that adult reproduction was high during this period however the recent decade has seen a slowing or even decline in this growth currently 130 000 individuals oliva et al 2020 in the current modelling exercise stochastic mpms were developed from available field data and phylogenetically imputed vital rates as adult reproduction was one of the vital rates available from field data we can deduce that this vital rate has decreased in recent years which is why the chilean population is no longer increasing to understand how the o flavescens population will respond to management culls and extreme climate events in the short term the long term population growth rate is insufficient we must use short term transient metrics the current analysis showed that the chilean o flavescens population attenuates e g decreases in population size when perturbed by either managed culls extreme climate conditions or a combination of the two in combination the long term population growth rate and transient metrics provide a more comprehensive perspective regarding how populations will respond over different time horizons and environmental conditions this understanding helps us plan management actions accordingly either for population control or protection this research shows that the speed of o flavescens population decline is expected to accelerate under managed culls and or expected frequencies of future extreme el niño events when managed culls and extreme el niño impacts are combined model simulations indicate populations will decrease below an mvp between 1 and 7 years faster than under managed culls alone based on these results the chilean population of o flavescens is unlikely to support a managed cull particularly given current expectations about the frequency of extreme climate events including el niño conditions a similar conclusion was reached by silva et al 2021 these authors found that harbor seal populations p vitulina in sweden and denmark could sustain modest hunting and infrequent epizootic events but that external stressors that reduced fecundity e g exposure to endocrine disruptors would leave seal populations vulnerable to rapid population decline in keeping with these results management efforts to reduce conflicts with fisheries in chile should avoid managed culls management of fisheries conflict with seals in scotland similarly switched focus from population reduction to targeting of individual seals found to be frequenting rivers and netting stations butler et al 2011 the new management approach reduced seal shooting by 60 and was considered a successful conflict management policy by the scottish government other alternative conflict management options may include capacity building schemes financial compensation or growth in eco tourism enterprises davis et al 2021 for example pinniped tourism has experienced strong growth in recent decades birtles et al 2001 public engagement with pinnipeds through tourism activities likely increases appreciation and desire to conserve these animals however it is worth noting that tourism can also have detrimental impacts on the animals involved páez rosas and guevara 2017 which must be minimised through appropriate guidelines and regulation kirkwood et al 2003 this analysis demonstrates that extreme climate events are expected to hasten the decline of o flavescens below an mvp value this finding indicates that the precautionary principle i e precautionary action despite scientific uncertainty resnik 2003 may need to be exercised when managing the population of o flavescens on the west coast of south american larger populations will be required to allow the population to buffer against extreme climate events a similar conclusion was reached by de oliveira et al 2012 in an assessment of the effective population size of o flavescens in peru which explicitly considered the impacts of the mating system and demographic variations caused by the 1998 98 extreme el niño event in this work the authors recommended a population of 7715 individuals to ensure the population was large enough to avoid inbreeding and retain sufficient adaptive genetic variation to survive future el niño events demographic simulations in the current analysis show considerable variation in the assessed population projections through time after 10 years the maximum and minimum population sizes observed across model iterations under all scenarios vary by at least one order of magnitude these fluctuations are due to the transient dynamics that originate when disturbances impact stage structured populations capdevila et al 2020 stott et al 2010 disturbances can change the total size of a population but also the relative number of individuals in each stage therein i e its population structure because the disturbance may kill more individuals in a given life cycle stage relative to other stages these changes in population structure can then lead to increased amplified or decreased attenuated growth in the short term as part of its transient dynamics caswell 2001 stott et al 2011 the population may recover its stationary equilibrium if and when the relative number of individuals in each life cycle stage returns to its pre disturbance i e asymptotic state in this context it is important to note that o flavescens similarly to other pinniped species is a slow species gaillard et al 1989 salguero gómez et al 2016 stearns 1992 meaning that it is long lived has long generation times and low reproductive output such slow species tend to have longer recovery times greater ability to resist disturbances i e lower attenuation and lower ability to amplify increase after a disturbance capdevila et al 2021 stott et al 2011 a recent assessment of how life history traits can predict a species intrinsic resilience capdevila et al 2021 found that species with longer generation times require longer recovery times post disturbance the authors also found generation time to be negatively correlated with resistance the inverse of how far populations attenuate after disturbance these findings can help explain why o flavescens populations in this analysis attenuate decrease so strongly after disturbance and show long recovery times a sensitivity analysis of the effects of extreme el niño events on o flavescens vital rates demonstrates that these events will be most damaging to sea lion populations when they decrease adult survival by contrast if adult survival can be buffered from extreme climate impacts perhaps through policies to reduce mortality through fisheries bycatch breen et al 2003 or reduce fishing pressure on prey species hennen 2006 sepúlveda et al 2011 then negative impacts on population viability will be reduced results showed that quasi extinction risk for the chilean o flavescens population is relatively insensitive to changes in the magnitude of extreme climate impacts on juvenile survival juvenile maturation and fecundity in this sensitivity analysis as in scenarios v viii extreme climate events do not occur every year hence even when extreme climate events have large negative impacts on sea lion vital rates e g 100 adult mortality this will not necessarily lead to an immediate population decline below the mvp size it is worth noting that the impact of extreme el niño events on vital rates was parameterised from northern populations in chile e g de oliveira et al 2012 soto et al 2004 it is unlikely that these impacts would be as severe for southern populations in chile however southerly populations of o flavescens may experience similar extreme population declines due to epizootic outbreaks silva et al 2021 or other stressors for example populations on the argentinian coast decreased by 93 between 1938 and 1975 due to unknown causes gerber and hilborn 2001 the large historical increases in population size of chilean o flavescens without doubt contribute to the widespread perceptions of fishers in chile that sea lion populations are currently too large and that they are rapidly increasing davis et al 2021 this dichotomy may be explained by a shifting baseline syndrome pauly 1995 i e fishers use the prevailing sea lion population size when they began fishing as their baseline irrespective of the status of the population relative to historical levels at that point although many sea lion populations around the world and in chile have not yet recovered to historical population abundance i e levels observed before widespread sealing in the 18th 19th centuries lotze et al 2011 magera et al 2013 many fishers began their careers in the years when sea lion populations were still small for example in chile over a third of fishers surveyed in a recent assessment of conflict with sea lions davis et al 2021 began fishing over 40 years ago when sea lion populations in chile were approximately a quarter of the size they are now fig 2 hence current increases in pinniped populations may be seen as unprecedented growth rather than a recovery towards historical levels the present study is one of the few existing demographic analyses to incorporate uncertainty in vital rates into population projections e g see paniw et al 2017 and to my knowledge the first one to do so in pinnipeds however results clearly point to the need for more annual stage based field data which would allow species specific vital rates to be estimated through inverse methods wielgus et al 2008 assuming that individual based records were not feasible note that despite the current modelling approach estimating a very narrow confidence interval around the long term growth rate mean 0 876 95 ci 0 869 and 0 884 this precision can be interpreted as certainty in the estimation i e due to large number of model iterations n 1000 rather than certainty in the approximation of the modelled estimate to the true long term growth rate this approximation will be improved by the addition of further annual stage based field data in particular more exact estimates of vital rates would allow a more complex life cycle to be assessed including a two sex model as male animals interact more often with fisheries kauhala et al 2012 a two sex model would permit more nuanced modelling of cull or population control measures in chile some level of illegal harvest of sea lions also occurs davis et al 2021 the impact of this mortality is not incorporated in the current analysis as reliable data for these activities remain elusive data on illegal mortality levels would allow a better estimate of vital rates and of the long term population growth rate conflict between marine mammals including sea lions and fisheries remains a highly contentious management issue davis et al 2021 ramos et al 2020 the present research provides quantitative evidence that this conflict may be best resolved independent of management culls a historically implemented approach in this context galatius et al 2020 mancilla gonzález 2018 perceptions of increases in sea lion populations may be an artefact of shifting baselines pauly 1995 or the saliency of short term transient population dynamics stott et al 2010 increases in the frequency of extreme climate events will leave sea lion populations vulnerable to extinction requiring larger populations to remain viable over time this precautionary but necessary approach is likely to exacerbate conflict with fisheries highlighting an urgent need to develop and test alternative conflict management solutions author contributions all aspects of this work were conceptualised analysed and written by the author kjd declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the ukri internal research england global challenges research support fund 0008129 to k j d supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110122 appendix supplementary materials image application 1 
24336,process based forest landscape models flms rely on first principles to simulate ecological patterns and processes making them uniquely powerful for forecasting ecological dynamics under unprecedented climatic and disturbance regimes persistent challenges with any ecological forecasting model are calibration tuning the model and validation proofing the model as no actual future data exist from which to conduct a formal model validation model credibility is established through numerous tests against empirical datasets and comparisons with other types of models the purpose of this study was to establish more consistent and generalizable standards for calibrating and validating landis ii a widely used open source flm we reviewed methods gleaned from a wide variety of previous flm studies and advance some new techniques for evaluating the credibility of the model outputs we used publicly available data with full coverage for the united states us so that our methods will be generalizable to other landscapes in the us and we developed an ecologically meaningful set of validation metrics for evaluating the credibility of new applications we found that landis ii could be calibrated to reliably simulate empirical vegetation disturbance climate dynamics in diverse mountainous terrain and fire prone landscapes of the eastern cascade mountains we performed an inter model validation between landis ii and the forest vegetation simulator fvs demonstrating consistent projections of biomass dynamics for all tree dominated ecoregions in the study domain similarly simulated fires reliably approximated the empirical fire event size and severity patch size distributions based on observed fire activity from 1984 to 2019 by establishing rigorous transparent and repeatable standards for calibrating and validating flm dynamics we sought to remove some of the barriers to adapting landis ii to new landscapes and climates facilitate further validation of existing models and aid independent assessment of the credibility of forest landscape models keywords forest landscape models disturbance modeling process based modeling climate change carbon temperate forests wildfire vegetation interactions landis ii data availability data will be made available on request 1 introduction process based forest landscape models flms are a uniquely powerful tool for projecting the effects of future climate management disturbance and vegetation succession on forested landscapes gustafson 2013 the spatially explicit nature of flm simulations enables them to mechanistically represent inherently spatial processes such as wildfire insect outbreaks harvesting seed dispersal climate effects and their interactions keane et al 2015 loehman et al 2018 scheller et al 2018 maps generated by flms reveal how processes interact over space and time producing plausible visualizations of future landscapes mladenoff 2004 process based models differ from phenomenological models in that they are designed to simulate pattern by modeling ecological processes rather than by directly modeling the patterns themselves connolly et al 2017 phenomenological models typically use a mathematical function or statistical algorithm that can be fit to data to describe underlying processes hilborn and mangel 2013 although this can make phenomenological models more accurate under historical and contemporary conditions they generalize to novel futures with greater difficulty in contrast mechanistic models explicitly track the details of the fundamental components and processes of a biological or ecological system that are thought to give rise to a set of data otto and day 2011 connolly et al 2017 as rapid climatic and ecological changes continue to create novel landscapes and disturbance regimes process based flms are becoming indispensable for estimating ecological changes over the coming century shifley et al 2017 a persistent challenge with all flms is model calibration tuning the model and validation proofing the model as future data do not exist to compare with flm predictions it is not possible to empirically validate a future projection oreskes et al 1994 rastetter 1996 this point is sometimes wielded as evidence that future flms cannot be validated but this perspective ignores the more practical definition of validation that is well established in the literature sargent 1984 2013 rykiel 1996 rastetter 1996 he et al 2011 shifley et al 2009 in the context of ecological simulation models the term validation refers to qualitative and quantitative evaluations of the underlying model structure i e its conceptual validity sensu sargent 1984 and comparisons with independent data sources i e its operational validity sensu sargent 1984 open source community developed models e g landis ii facilitate both types of validation as users are free to examine model structure and contribute directly to model development in this sense validation is the iterative process of model development implementation and evaluation that helps process based models develop into a credible representation of ecological systems rykiel 1996 rastetter 1996 strategies to validate aspects of ecological simulation models can be grouped in several categories first outlined by rastetter 1996 1 comparing simulation model predictions to existing longitudinal data e g wang et al 2014 2 space for time substitutions e g ma et al 2017 3 past to present simulations e g flatley and fulé 2016 and 4 model comparisons with other flms e g keane et al 2004 petter et al 2020 each of these approaches has both merits and limitations longitudinal datasets are scarce and relatively short term 10 30 years relative to the temporal scope of many flm simulation horizons often 50 years space for time substitutions must rely on an assumption that sampled sites or landscapes are biogeoclimatically comparable only differing in stages of development or percentage of area in varied stages keane et al 2002 and the unavoidable problem of landscape pseudo replication can limit inferences of some comparisons hargrove and pickering 1992 depending on the nature of simulations past to present simulations may require subjective decisions about the historical landscape and assume that past dynamics are a legitimate future proxy cf keane et al 2018 loehman et al 2018 comparing the predictions of multiple flms offers no comparison against empirical data and there are limited means of determining which of the models is most reliable several other studies have validated landis ii applications using static empirical data e g see flanagan et al 2019 boulanger et al 2019 this is perhaps more of an empirical calibration because there is no direct assessment of model dynamics over time table 1 the focal model of this study is landis ii a spatially explicit flm with the capacity to interactively model wildfire silvicultural management forest succession and numerous disturbance processes landis ii is one of the most widely used flms with over 160 published applications www landis ii org publications and is highly adaptable to new landscapes as with many flms landis ii is often considered to be a process based model but it is actually a hybrid that incorporates phenomenological modeling with process modeling where processes are not yet fully understood or where computational limitations deter further complexity petter et al 2020 in this way landis ii harnesses strengths of phenomenological models e g simulating observed patterns while maintaining a high capacity to project future landscapes through process based and interactive succession and disturbance algorithms gustafson 2013 flatley and fulé 2016 liang et al 2018 landis ii is an open source community developed model and the landis ii developers strive to make the model broadly accessible to new researchers see www landis ii org but calibration and validation remain difficult processes particularly with more sophisticated extensions and methods employed in some prior published studies are neither sufficiently transparent nor repeatable the cost and time required to calibrate and validate landis ii applications inhibits development of new models for different landscapes and the recycling of established models and parameter sets can perpetuate underlying error and uncertainty across multiple studies developing rigorous and repeatable methods for systematic calibration and validation will make landis ii a more accessible modeling tool for new research applications and it will help researchers and end users evaluate the credibility and ecological validity of landis ii outputs although we focused this study on landis ii and two specific extensions we endeavored to make our methods and findings broadly relevant to other landis ii extensions and other flm platforms in this study we conducted an empirical evaluation of a newly developed landis ii application i e initialized and calibrated for a specific landscape with explicit consideration of the wildfire sub model scrpple social climate related pyrogenic processes and their landscape effects scheller et al 2019 we reviewed prior studies that have validated aspects of landis ii tables 1 and 2 and we examined the rigor of various validation methods we then used several generalizable methods to calibrate and validate a new landis ii application and we demonstrated the potential for landis ii to reliably model ecological dynamics in mountainous topo edaphically and ecologically diverse fire prone landscapes of the eastern cascade mountain range 2 objectives the purpose of this paper was to establish benchmark methods for calibrating and validating landis ii and similar flms using publicly available data provide detailed documentation of initialization methods that we employed to adapt a model framework to a new geography and develop set of ecologically meaningful standards for evaluating the credibility of model outputs we drew upon previous studies to develop an initial parameter set for our landis ii application to the eastern cascade region in north central washington state we calibrated forest structural characteristics using forest inventory and analysis data fia https www fia fs fed us successional dynamics using the forest vegetation simulator fvs https www fs fed us fvs and fire regime characteristics using monitoring trends in burn severity program mtbs https www mtbs gov we then tested the null hypothesis that this landis ii application was a reasonably realistic representation of reality by validating our model against empirical patterns of landscape dynamics based on longitudinal data and independent phenomenological models 3 methods 3 1 study area we conducted our study in the adjacent wenatchee and entiat subbasins on the eastern slope of the cascade range in north central washington state fig 1 a we applied a 5 km buffer around the watersheds to capture potential edge effects e g seed dispersal and migration of fire from surrounding areas resulting in a 6078 km2 study area fig 1 this area is characterized by steep highly dissected mountainous terrain with elevations ranging from 187 to 2870 m which create highly influential gradients in climate and weather patterns mean annual temperature 1980 2010 climate normals abatzoglou and brown 2012 ranges from 11 3 c at lower elevations to 1 2 c near the cascade crest and precipitation ranges from 0 2 m yr 1 to 2 9 m yr 1 along a similar elevation gradient the climate in both subbasins is humid continental with warm dry summers cold wet winters and most precipitation occurring as snow these broad gradients in precipitation and temperature along with finer scale topo edaphic complexity produce high beta diversity in plant community composition and forest structure within the watersheds fig 1 hessburg et al 2019 low elevation ecosystems are dominated by grasslands shrublands and sparse woodlands with a mix of dry south aspects and moist north aspects conifer forests at mid elevations which transition to subalpine forests alpine meadows and rock barrens at the highest elevations fig 1 hessburg et al 2000 douglas fir pseudotsuga menziesii comprises the greatest overall biomass in the moist mixed conifer zone while drought tolerant tree species including ponderosa pine pinus ponderosa dominate locally in dry forest sites historical fire regimes in the two subbasins were variable with low to moderate severity frequent fire regimes in grassland and mixed conifer forests at low to mid elevations and a mix of moderate and high severity fire regimes in upper montane moist mixed conifer and cold forests agee 1998 hessburg et al 2007 2016 2019 perry et al 2011 nearly a century of fire exclusion and intensive timber harvesting led to the accumulation of surface fuels forest densification compositional shifts towards less fire tolerant species and increased landscape homogeneity hessburg et al 1999 2005 2019 hessburg and agee 2003 hagmann et al 2021 fire has returned to the landscape in recent decades although contemporary fires are larger and more severe reilly et al 2017 haugo et al 2019 hagmann et al 2021 despite this recent surge in wildfire activity annual area burned is likely far below the pre settlement mean for this landscape haugo et al 2019 leenhouts 1998 parks et al 2015 ryan et al 2013 land ownership and management allocation in the study domain is mixed with actively managed forests at low and middle elevations and wildlands in middle and upper montane settings residential development is widespread at low to middle elevations and in valley bottoms the majority 80 of the study area is managed by the usda forest service and over half 56 of the study area is administratively withdrawn wildland designated as wilderness or roadless areas 3 2 model initialization in the current model application we used landis ii v7 0 mladenoff 2004 scheller et al 2007 with extensions necn v6 6 scheller et al 2011 and scrpple v3 0 scheller et al 2019 all analyses were performed in r v4 1 1 r core team 2021 using packages raster hijmans 2021 sf pebesma 2018 landscapemetrics hesselbarth et al 2019 and ggplot2 wickham 2016 3 2 1 vegetation data we generated maps of initial vegetation for the study domain using treemap a spatially imputed forest inventory dataset developed by riley et al 2021 treemap uses random forest imputation to develop a continuous map of the best fitting forest inventory analysis fia plot based on landfire http www landfire gov data layers including biophysical setting existing vegetation type vegetation height percent cover and disturbance layers for every 30 m raster cell within the united states we clipped this raster to the study domain and resampled it to 90 m spatial resolution using nearest neighbor interpolation cells that referenced fia plots outside of the pacific northwest 375 out of 4684 unique fia plot codes present in the imputed raster within our study domain were replaced with the value of a neighboring cell that referenced a fia plot from within the region we performed this replacement because although these foreign plots may have been representative according to the multi variate random forest imputation performed by riley et al 2021 their composition was not representative of the real world landscape that we were modeling and species specific life history traits i e dispersal distance fire tolerance life span are key parameters within landis ii if multiple neighboring cells referenced valid fia plots the most common cell value was used methods consistent with povak et al 2022 we then converted the fia tree lists into a landis ii acceptable format a look up table of age class and biomass by species present in each raster cell biomass was derived from the fia database which contains allometrically estimated biomass values for every tree tree age was determined based on tree cores taken from a subset of trees in each fia plot we used measured ages from 26 346 trees to parameterize a generalized linear regression model that employed tree diameter species and ecoregion to predict tree age for trees that were not cored 77 377 remaining trees the resulting landis ii initialization landscape was a 90 m raster where each cell value referenced a row in a text file containing biomass values associated with each species age combination hereafter cohort present at each site 3 2 2 climate data we used the multivariate adaptive constructed analogs maca abatzoglou and brown 2012 datasets to provide historical climate data minimum daily temperature maximum daily temperature precipitation relative humidity wind speed wind direction on a 4 km grid within the study domain we simulated a baseline future climate scenario by randomly resampling from the climate years 1980 2019 where within year climate was not altered we drew entire years rather than sampling days within years we preserved interannual temporal autocorrelation in this baseline climate scenario by sampling every 3 years as a new randomly sampled starting point a year between 1980 and 2019 and constraining the intermediate two years to be sampled from within 2 years of the initial starting year all climate variables temperature precipitation humidity wind speed wind direction were selected from the same sampled climate year climate is input into landis ii via an ecoregion map where each ecoregion is assigned a unique set of climate data unlike most prior landis ii extensions which use the ecoregion map to define ecological characteristics soil type fire regime etc the extensions we used for succession and fire necn v6 8 and scrpple v3 0 details below rely on continuous raster surfaces for all input variables except climate thus the ecoregion map in our model is used only to define distinct climatic regions we delineated ecoregions within the study domain by intersecting two data layers a vegetation cover type layer and a 10 digit hydrological units huc10 watersheds shapefile watershed boundary dataset for washington state 2019 we generated the vegetation cover type layer by classifying vegetation structure and composition based on biophysical setting existing vegetation type and landfire potential vegetation type our classification procedure resulted in eight distinct vegetation cover types grassland shrubland hardwood alpine meadow dry mixed conifer moist mixed conifer cold moist conifer and cold dry conifer forest intersecting this vegetation type layer with huc10 watersheds created 178 unique ecoregions fig 1 within which we calculated area weighted average climate values using 4 km maca climate rasters by classifying ecoregions according to vegetation cover type and terrain features this method implicitly represented variability in climate due to the prominent elevation gradients in the study domain 3 3 necn succession forest succession processes e g dispersal establishment growth competition and mortality were simulated using the net ecosystem carbon and nitrogen extension necn scheller et al 2011 the necn extension builds upon the century soil model parton 1996 and adapts it for landis ii we opted to use the necn succession extension because it explicitly tracks carbon dynamics among live dead and belowground carbon pools and allows variability in light water and limiting soil resources e g nitrogen to inform forest growth and successional dynamics growth is determined by a combination of species specific parameters e g optimal growing temperature curves maximum net primary production npp and site conditions leaf area index water availability soil resources mortality is modeled as a function of species level parameters e g longevity npp and maximum biomass probability of establishment is internally calculated at an annual time step and is dependent upon input weather data the succession algorithms within landis ii run at the cell level meaning that each cell in the raster has the potential to have a unique starting state and successional trajectory live cohorts can disperse to surrounding cells both adjacent and far away depending on user defined species specific dispersal distance parameters 3 3 1 soil data we used gridded ssurgo data gssurgo soil survey staff 2020 to derive the edaphic variables required for the necn succession extension since the soil maps required for necn differ from the raw soil variables provided by gssurgo we transformed combined and scaled the gssurgo data layers to generate necn ready layers see appendix b for these methods most soil input maps for the necn extension could be approximated from the gssurgo database but initial soil nitrogen was a key exception soil nitrogen data are not available in the gssurgo database instead we used a 1 km gridded total kjeldahl soil nitrogen layer derived from the national soil characterization database hargrove and hoffman 2004 3 3 2 species parameters we derived an initial set of species parameters based on previous landis ii studies tables a1 and a3 https www landis ii org projects for species that were not present in these previous studies parameters were set based on phylogenetically and functionally similar species we then adjusted the species parameters as necessary to improve consistency with values found in silvics of north america burns and honkala 1990 fire effects information system https www feis crs org feis empirical fia data and trait based fire tolerance scores stevens et al 2020 parameters were further calibrated to achieve reasonable model behavior tables a2 and a4 details in model calibration below 3 4 scrpple fire extension we modeled fire behavior and effects with the scrpple fire extension scheller et al 2019 a recently developed extension that does not rely on user defined parameters to constrain the shape of the fire size distribution thereby allowing the fire size and frequency distributions to respond dynamically to changing landscape pattern and future climate inputs scrpple also allows users to explicitly account for various fire management actions such as suppression wildland fire use i e prescribed natural wildfire and prescribed rx fire these management actions can be spatially allocated according to ignition type land ownership and biogeoclimatic setting fires spread from cell to cell via both edges and vertices and probability of spread is modeled as a function of topography fuels and weather wind speed wind direction and fire weather index canadian forest fire weather index fwi fire severity in scrpple is modeled as a multi scale process using nested equations site level i e cell severity is modeled as a function of site characteristics fuels climate soil and windspeed and severity values are scaled to approximate a spectral fire severity index e g differenced normalized burn ratio dnbr robbins et al 2022 cohort specific mortality rates are determined by a logistic model that relates site level severity species and age of individual cohorts to probability of mortality 3 4 1 ignition probability and suppression effort ignitions are generated within scrpple using a zero inflated poisson regression model to estimate the number of ignitions on each day of each year as a function of daily fire weather index fwi values ignitions are then spatially distributed throughout the landscape based on relative ignition frequency given by a gridded probability map although the probability map remains constant the probabilistic regression model produces a unique pattern of ignitions each year we used empirical data from the fire program analysis fire occurrence database fpa fod short 2017 to fit the zero inflated poisson models and generated maps of relative ignition density this dataset contains observed ignition date location cause and final fire size for all reported wildfires both accidental and natural ignitions of any size between the years 1992 2015 for the entire united states we calculated fwi using the maca climate dataset abatzoglou and brown 2012 using the cffdrs r package wang et al 2017 we applied kernel density estimation using the density ppp function from the spatstat r package baddeley et al 2015 to convert spatial points of ignition locations to raster maps of relative ignition probability we zoned likely suppression effectiveness based on land management designation for lightning ignitions minimal suppression effectiveness was applied to wilderness and roadless areas but applied light suppression effort within a 1 mile interior buffer to limit wilderness fire escapes we zoned actively managed public lands with moderate suppression and applied maximal suppression effort to all rural urban and private lands for accidental human ignitions we applied light and moderate suppression effort in wildlands and maximal suppression everywhere else 3 5 calibration and validation we use the term calibration to refer to the iterative adjustment of initial parameters and the term validation to refer to formal comparisons of model outputs to independent data sources e g empirical observations or other simulation models tables 1 and 2 these two terms are however inter related during calibration one adjusts the input parameters to achieve improved correspondence with the ecological patterns and processes that are being simulated thus requiring some form of validation to occur simultaneously in this study we define validation as a more formal process occurring after model calibration that involves comparing model outputs to a new set of independent data evaluating model behavior over longer time spans and or more rigorous goodness of fit tests 3 5 1 calibration we calibrated our landis ii application by iteratively adjusting the initial parameters until the model corresponded well with biomass dynamics modeled using the forest vegetation simulator fvs and empirical fire activity we performed exploratory sensitivity analyses to identify the parameters with the greatest influence on model performance subsequent calibration efforts were aimed at adjusting these key parameters the primary species level necn parameters were temperature sensitivity annual npp maximum biomass and longevity of each species for scrpple the most important parameters for calibration were the fire spread probability coefficients fire severity coefficients and the suppression effectiveness input table 3 5 2 biomass validation we used the eastern cascades variant of fvs to independently validate landis ii derived biomass dynamics e g a pseudo empirical inter model validation table 1 fvs is a distance independent individual tree growth and yield model that simulates stand level dynamics over time data used to build the height and diameter growth equations in each fvs variant came from geographically relevant forest inventories silviculture stand examinations and tree nutrition studies keyser and dixon 2008 to validate the biomass dynamics produced by necn we selected 100 fia plots 50 of the most abundant fia plots plus 50 random plots per vegetation cover type fig 1b we simulated 100 years of growth within fvs and compared mean biomass density outputs from fvs to those derived from landis ii with no wildfire disturbance 3 5 3 fire validation we performed an empirical validation table 2 of the scrpple fire extension by comparing our landis ii simulation outputs with the contemporary 1984 2019 fire regime within the study area we acquired maps of fire severity from the monitoring trends in burn severity mtbs program a publicly available dataset containing satellite derived severity maps for every fire 400 ha within the entire us since 1984 we then combined the mtbs fire severity data with the aforementioned fpa fod fire atlas short 2017 a spatial point dataset containing ignition date location cause and final fire size for all reported wildfires including fires 400 ha between the years 1992 2015 we used the combined fire atlas for metrics that did not require spatially explicit maps of severity e g fire event size distributions and we used the mtbs dataset alone for severity based summary metrics e g fire severity patch size distributions to avoid over representing the area of actual fires that were only partially contained within the study landscape we clipped the mtbs maps to the study domain and computed all metrics based on this constrained spatial extent the combined empirical fire dataset contained a total of 7727 ignitions 1287 fires 1 ha and 61 fires 400 ha 3 5 4 evaluation metrics we evaluated the overall validity of our landis ii application by calculating several summary metrics including biomass density the slope of the biomass trendline fire event size distribution fire severity distribution and the fire severity patch size distributions we evaluated goodness of fit gof by visually comparing these summary metrics to the empirical fire regime and the results of the fvs simulation we avoided formal statistical tests of gof for the fire size and severity patch size distributions because we were interested in whether our model reasonably approximated observed patterns since a simulation model may be sufficiently accurate without perfectly replicating empirical patterns rykiel 1996 we tested whether there was a temporal trend in the average patch size per severity class by fitting linear models one per severity class with year as the predictor variable and average patch area as the response variable 4 results 4 1 succession both landis ii and fvs projected increases in biomass in the absence of fire across all ecoregions and the models corresponded well in terms of absolute biomass values fig 2 average biomass density for the initial base landscape time 0 was 6 higher in landis ii than the average biomass density within the fia plots selected for the fvs simulation 128 mg ha 1 versus 121 mg ha 1 respectively by the end of the 100 year simulations average biomass density in landis ii was 8 6 higher compared with the biomass estimate generated through fvs 252 mg ha 1 versus 231 mg ha 1 respectively differences between the two models in projected biomass at year 100 were smallest in moist mixed conifer and cold moist conifer ecoregions the two ecoregions with the greatest biomass fig 2 the slope of the biomass trendline was consistent between the two models for all tree dominated ecoregions fig 3 in both models aboveground biomass increased at the greatest rate within the first several decades followed by an inflection point mid century and a gradual decline in the rate of biomass accretion although biomass continued to increase this pattern was evident across all ecoregions based on the fvs simulations but it differed for non forest ecoregions grassland shrubland and alpine meadow within the landis ii succession model where the rate of biomass accretion continued to increase over the entire simulation period the ecoregion with the greatest similarity between the two models was moist mixed conifer fig 3 the ecoregion with the greatest biomass density fig 2 and the greatest overall area within the study domain 30 4 2 wildfire with careful tuning of the scpple fire spread parameters we were able to simulate a fire regime that was a reasonable approximation of the empirical fire size distribution for the study domain fig 4 both fire size distributions declined logarithmically with many small fires and relatively few large fires a pattern typical of frequent fire landscapes one notable difference between simulated fires and the empirical data was that accidental human caused ignitions accounted for the majority of observed fires 300 ha while lightning ignitions accounted for most of the fires 300 ha in our simulations fig 4a we accepted this divergence from the historical record to account for anticipated increases in area burned by naturally ignited fires through wildland fire use over the coming century for smaller fires 300 ha the number of lightning fires was roughly equivalent to the number of fires started by accidental causes in both the landis ii simulation and the empirical fire record fig 4a suggesting a realistic ignition probability for both ignition types as expected the observed fire size distribution approximated a power law distribution linear decline in log10 log10 space mckenzie and kennedy 2012 moritz et al 2011 at spatial scales ranging from 1 to 10 000 ha fig 4b c simulated fires also exhibited a logarithmic decline in fire frequency as fire size increased but the trend was not strictly linear fig 4c instead the simulated fire size distribution was characterized by a steep negative slope for fires 20 ha a more moderate slope for fires 20 10 000 ha and a steep decline in frequency for fires 10 000 ha most of the area burned within the landis ii simulation burned at moderate severity while observed fires burned with roughly equal proportions of moderate and high severity fig 5 we note however that the site level severity value that which is analyzed in figs 5 7 and 8 note this has been re named dnbr in output maps generated by scrpple v3 2 produced by scrpple does not necessarily reflect the amount of mortality that each fire causes accordingly we summarized percent of cohorts killed for each fire event fig 6 we were not able to validate this with empirical data because tree mortality data are not available in the mtbs dataset but the mortality distribution produced by our landis ii simulation fit matched the ecological definition of a mixed severity fire regime sensu hessburg et al 2016 with a mix of low 0 25 mortality moderate 25 75 mortality and high 75 mortality severity fire effects figs 6 and 9 fire severity patch size distributions derived from simulated fires were a reasonable approximation of the empirical fire severity patch size distributions fig 7 most patches were 10 ha with 96 of all patches falling under 10 ha for both simulated fires and the mtbs record the average high severity patch sizes were slightly smaller in the landis ii simulated outputs compared with the mtbs data with mean patch sizes of 3 4 ha and 3 9 ha respectively neither dataset displayed a statistically significant trend in patch sizes over time i e the slope of the regression lines was not distinguishable from 0 although seven out of eight patches 10 ha occurred during the latter half of the mtbs fire record fig 8 low severity and unburned patches were restricted to smaller patch sizes while moderate and high severity patches occurred in small and large sizes for both the empirical and simulated fire records nearly all patches 10 ha burned at moderate or high severity figs 7 and 8 5 discussion previous studies have used a variety of methods to validate aspects of landis ii table 1 and these efforts have established credibility for landis ii applications in many contexts this study provides further evidence for the potential credibility of landis ii as we failed to reject the null hypothesis that a well tuned flm model can reliably simulate several key landscape scale ecological processes as forest landscape models flms gain attention as a credible means of projecting system level dynamics however there is a growing need to develop a more transparent and consistent framework for initializing calibrating and validating new model applications petter et al 2020 suárez muñoz et al 2021 building on previous efforts the methods we demonstrate in this study provide such a framework for validating flms that can be broadly applied to any landscape where full coverage calibration datasets are available e g eidenshink et al 2007 riley et al 2021 5 1 succession overall landis ii biomass dynamics corresponded well with fvs modeled projections fig 2 the two models were particularly well aligned in moist mixed conifer and cold moist conifer ecoregions which together comprised 62 of the biomass and 47 of the area within the study domain the phenomenological forest growth models contained within fvs were parameterized using longitudinal forest inventory data providing an empirical basis for projecting biomass dynamics over time we found that the process based algorithms contained within the necn extension matched trends in forest biomass accumulation over time fig 3 demonstrating the ability for necn to capture relevant tree growth competition mortality and forest succession processes previous studies have used longitudinal fia plot data to validate landis ii biomass dynamics wang et al 2014 jin et al 2016 ling et al 2020 but empirical validations are limited by the relatively short time span of longitudinal plot data rarely more than several decades compared with longer desired simulation lengths often 50 years by leveraging the tree growth and mortality models contained within fvs which were parameterized using repeat measurements and space for time substitutions of forest inventory data we were able to validate landis ii biomass dynamics over the entire 100 yr simulation period using a widely respected phenomenological forest growth model we do note that the phenomenological models contained within fvs are not necessarily more valid than the biomass algorithms in necn since neither necn nor fvs have been validated with empirical stand development data that span more than several decades the correspondence between these models bolsters confidence in their predictive capabilities but validations of long term 50 years biomass dynamics continue to be limited by a core lack of long term longitudinal data remotely derived datasets can help fill this need for longitudinal data of forest disturbances that can be detected by satellites but more elusive ecological processes such as tree growth competition and background mortality require precise field based forest inventory data to discern this underscores the importance of creating and maintaining longitudinal forest demography datasets e g lutz 2015 to support our capacity to project landscape dynamics over the coming decades the rate of biomass accretion in non forest ecoregions peaked within the first 20 years of the fvs simulation while landis ii projected that the rate of biomass accumulation would continue to increase throughout the 100 yr simulation period fig 3 a plausible reason for this difference is that in landis ii sites that begin as non forest can be colonized by tree species from nearby cells if site conditions are permissive mladenoff 2004 and we observed forest encroachment in our simulations this is in contrast to fvs which is aspatial and simulates natural regeneration without consideration of neighborhood influences e g dispersal from surrounding stands dixon 2002 the explicit consideration of multi scale neighborhood processes e g seed dispersal is a key advantage of landscape simulation models and it enables them to capture ecological dynamics that elude non spatial models such as fvs the accuracy of this result will require further examination however as landis ii may be projecting forest establishment in non forest sites that are in fact maintained as non forest by biogeoclimatic mechanisms edaphic limitations harsh microclimate herbivory etc that may not be well captured by our model 5 2 wildfire the simulated fire regime that we produced with scrpple was consistent with recent fire history in the wenatchee and entiat subbasins empirical fire regimes in this landscape are temporally and spatially variable and we were able to produce a mosaic of low moderate and high severity fire characteristic of mixed severity fire regimes in the area figs 5 7 maps of fires produced by scrpple were visually realistic with respect to topography and fuels breaks simulated fires mirrored natural wildfire behavior see povak et al 2018 in that they burned with complex shapes and patchy severity and topographic influences on fire spread and severity were intuitively patterned and readily apparent fig 9 the fire regimes produced by scrpple are an emergent property of interactions among weather fuels and topography as the fire regime created by scrpple is not based on an a priori fire size distribution as with some other fire models the model can simulate shifting fire regime dynamics feedback mechanisms and unforeseen system level behavior as we model fire activity under novel future climates this has created more potential for the model to produce surprising results and hence more opportunities for providing ecological insights regarding future climate fire vegetation dynamics table 2 the simulated fire size distribution was well aligned with the empirical fire size distribution but fire size and frequency alone are insufficient to characterizing the complex ecological impacts of fires agee 1998 collins et al 2017 to evaluate the full ecological impact of simulated fire events within the model we examined fire severity cohort mortality and the severity patch size distribution explicitly validating the severity and spatial pattern of the simulated fire regime helped us evaluate the ecological impact of simulated fire which is required to simulate landscape level dynamics such as ecological stability feedbacks and resilience future studies should consider fire severity and patch metrics e g figs 5 8 when calibrating and validating scrpple since the physical characteristics of a fire regime e g fire size and frequency do not reflect the actual impact of fire on fuels carbon and forest structure 5 2 1 fire size fire is a complex multi scale biophysical process scholl and taylor 2010 larson and churchill 2012 jeronimo et al 2019 furniss et al 2020b 2022 and realistically simulating fire behavior spread and severity is a long standing challenge keane et al 2004 the scrpple extension has greatly advanced the capacity of landis ii to simulate a dynamic wildfire regime but some aspects of realistic wildfire simulation remain elusive the fire spread algorithm in scrpple represents fine scale energy transfer from each cell to its adjacent cells thereby simulating the contagious nature of fire and producing spatially aggregated fire effects fig 9 however there are no mechanisms within scrpple or any landis ii fire extension to modify fire behavior as a function of fire size wildfire behavior changes as a function of fire size e g cansler and mckenzie 2014 povak et al 2020a creating positive feedbacks that drive large fires through fire altered wind dynamics broad scale preheating plume dominated events and long distance spotting these factors drive rare yet exceptionally large right tail fire events that have come to dominate total area burned in the western us coop et al 2022 and they are likely to continue to increase in their importance as climate drives increasing frequency and severity of large wildfires cansler and mckenzie 2014 although incorporating multi scale fire behaviors would increase model complexity and slow model runtime it would improve fidelity to the physical process of wildfire and this may help the model better represent evolving fire dynamics under warmer and drier future climates predicting fire behavior under novel fuel and weather conditions remains a challenge for mechanistic and phenomenological fire models alike e g stephens et al 2022 and there is a significant need for research that will improve our ability to reliably model fire behavior at multiple scales simulated fires showed a weaker power law fit compared with the empirical fire activity which followed a more linear trend for fires 10 000 ha fig 4c the distribution of simulated fires was concave due to a lower relative abundance of intermediate sized fires 10 1000 ha this pattern may be attributed to fire spread probabilities in scrpple being calculated based on daily weather values as the logistic form of the model tends to produce either very high or low spread probabilities as there is no sub daily weather to moderate spread rate as the day progresses and no clock to initiate the next weather day diurnal fluctuations in temperature and humidity have limited control over spread rates and this may have inhibited the production of more intermediate sized fires 5 2 2 fire severity a key advance made in scrpple is the development of multi level severity algorithms fire severity i e ecological impact of fire is modeled at both individual cohort trees within a cell and at the site or cell level site level severity is output in maps roughly approximating values of dnbr robbins et al 2022 facilitating empirical validations of ecologically meaningful aspects of fire behavior such as patch size distributions and spatial patterns in severity figs 7 9 table 2 these spatial metrics are central to the ecological function of fire agee 1998 collins et al 2017 and the sophistication of the severity algorithms is a notable strength of the scrpple fire model these severity models contained within scrpple are interrelated site level severity which is modeled as a function of climate fuels and windspeed is fed into the cohort mortality model as an independent variable this approach captures both bottom up and top down controls on fire severity e g povak et al 2020b and for this reason it is functionally appropriate however the relationship between these models is inverted in reality fine scale severity mortality of individual trees and patches drives variability in dnbr severity as detected with satellite imagery at the 30 m scale morgan et al 2014 harvey et al 2019 furniss et al 2020a although the current model structure is functional modifying the severity algorithms such that broad scale biogeoclimatic variables predict fire intensity which would then serve as a predictor for cohort mortality which in turn would be used to model site level severity would help the model structure better reflect the process of fire at these different scales 5 2 3 the problem of validation despite the growing number of studies that have explicitly validated aspects of landis ii tables 1 and 2 not all new flm applications are sufficiently validated or the validation methods may remain unpublished in these cases readers and researchers who are not personally familiar with the model developers are left to simply trust that the model application is credible the calibration and validation methods we describe in this study rely on publicly available full coverage datasets and are therefore generalizable to any other landscape where similar data exist we suggest these methods serve as a set of benchmark practices that others may use to inform their own model initialization methods these methods were developed to balance rigor with practicality while more intensive validation methods may be necessary in specific contexts not all flm users will have the resources to validate all aspects of their model with the maximal level of statistical rigor instead we found that visually evaluating goodness of fit to numerous ecologically meaningful metrics may be a good middle ground that is a viable way for new model users to validate model behavior and demonstrate the credibility of new model applications based on our synthesis of prior landis ii validation efforts and the results of this study we suggest a few best practices for establishing and evaluating the credibility of any given flm application 1 when applying a flm model to a new study domain many parameters may be inherited from previously developed models but key parameters should be calibrated this process should begin with sensitivity analyses either formal or informal e g simons legaard et al 2015 mckenzie et al 2019 to determine which critical parameters will be the focus of calibration efforts calibration then involves setting initial parameters comparing model outputs to empirical data or independent models tuning one or several parameters and re running the model this process is repeated for each parameter or set of related parameters deemed critical during the initial sensitivity analyses such an iterative calibration procedure can halt when model behavior is a reasonable representation of the processes of interest as over tuning cannot compensate for a residual amount of persistent uncertainty due to the fact that process based simulation models are approximations not replicas of reality 2 after calibration system level dynamics of the model should be more formally validated and the results made available for others to examine e g through publication if model outputs are highly variable multiple simulations may be averaged to account for various sources of stochasticity within the model although some qualitative validation is done throughout the calibration process this validation step may involve more rigorous goodness of fit tests comparing model outputs to different data sources or a more extensive evaluation of simulated landscapes using several different summary metrics tables 1 and 2 3 when using a previous flm application to address a new research topic the validation methods and assumptions of the initial model developers should be reconsidered for any new application additional validation may be necessary if prior efforts were insufficient or if they are not directly relevant to the new research topic validity of the model in a prior context does not guarantee the validity of the model in all future contexts if each iteration of a given model instance was validated in a new way established models will become more robust and reliable with usage these guidelines are already employed by many who use landis ii and other flms but we articulate them here to provide a resource for the modeling community that may assist future modeler developers in implementing rigorous transparent and repeatable methodology for calibrating and validating newly calibrated forest landscape models 6 conclusion process based forest landscape models flms are indispensable tools for forecasting forest dynamics under changing disturbance and climatic regimes when properly calibrated and validated these models can reliably simulate empirical trends in forest biomass fire spread and severity and vegetation disturbance patch dynamics validation is a critical step as new simulation models are built and as existing models are adapted to address new research questions in this study we synthesize the strengths and shortcomings of various validation methods to give readers researchers and end users consistent terminology with which to evaluate flms we demonstrated generalizable calibration methods based on publicly available full coverage datasets and established benchmark validation practices based on ecologically relevant summary metrics these advances lower the barrier to adapting landis ii to new landscapes and will enhance the overall rigor of landis ii modeling by synthesizing various validation methods that can be used to demonstrate the credibility of forest landscape models credit authorship contribution statement tucker furniss conceptualization methodology analysis writing editing and visualization paul hessburg funding acquisition conceptualization methodology editing and supervision nicholas povak conceptualization methodology editing and supervision r brion salter conceptualization methodology and editing mark wigmosta funding acquisition conceptualization methodology and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank robert scheller and zachary robbins for their helpful advice with landis ii and we thank two anonymous reviewers for their helpful comments on a prior draft of this manuscript this work was partially funded the us department of energy usdoe bioenergy technologies office de sc0017519 0005 and supported through an appointment of the senior author to the research participation program at the usda fs pacific northwest research station pnwrs administered by the oak ridge institute for science and education orise through an interagency agreement between the usdoe and the pnwrs any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government the views of the authors expressed herein do not represent the official views of the usdoe orise or the usda fs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110099 appendix supplementary materials image application 1 image application 2 
24336,process based forest landscape models flms rely on first principles to simulate ecological patterns and processes making them uniquely powerful for forecasting ecological dynamics under unprecedented climatic and disturbance regimes persistent challenges with any ecological forecasting model are calibration tuning the model and validation proofing the model as no actual future data exist from which to conduct a formal model validation model credibility is established through numerous tests against empirical datasets and comparisons with other types of models the purpose of this study was to establish more consistent and generalizable standards for calibrating and validating landis ii a widely used open source flm we reviewed methods gleaned from a wide variety of previous flm studies and advance some new techniques for evaluating the credibility of the model outputs we used publicly available data with full coverage for the united states us so that our methods will be generalizable to other landscapes in the us and we developed an ecologically meaningful set of validation metrics for evaluating the credibility of new applications we found that landis ii could be calibrated to reliably simulate empirical vegetation disturbance climate dynamics in diverse mountainous terrain and fire prone landscapes of the eastern cascade mountains we performed an inter model validation between landis ii and the forest vegetation simulator fvs demonstrating consistent projections of biomass dynamics for all tree dominated ecoregions in the study domain similarly simulated fires reliably approximated the empirical fire event size and severity patch size distributions based on observed fire activity from 1984 to 2019 by establishing rigorous transparent and repeatable standards for calibrating and validating flm dynamics we sought to remove some of the barriers to adapting landis ii to new landscapes and climates facilitate further validation of existing models and aid independent assessment of the credibility of forest landscape models keywords forest landscape models disturbance modeling process based modeling climate change carbon temperate forests wildfire vegetation interactions landis ii data availability data will be made available on request 1 introduction process based forest landscape models flms are a uniquely powerful tool for projecting the effects of future climate management disturbance and vegetation succession on forested landscapes gustafson 2013 the spatially explicit nature of flm simulations enables them to mechanistically represent inherently spatial processes such as wildfire insect outbreaks harvesting seed dispersal climate effects and their interactions keane et al 2015 loehman et al 2018 scheller et al 2018 maps generated by flms reveal how processes interact over space and time producing plausible visualizations of future landscapes mladenoff 2004 process based models differ from phenomenological models in that they are designed to simulate pattern by modeling ecological processes rather than by directly modeling the patterns themselves connolly et al 2017 phenomenological models typically use a mathematical function or statistical algorithm that can be fit to data to describe underlying processes hilborn and mangel 2013 although this can make phenomenological models more accurate under historical and contemporary conditions they generalize to novel futures with greater difficulty in contrast mechanistic models explicitly track the details of the fundamental components and processes of a biological or ecological system that are thought to give rise to a set of data otto and day 2011 connolly et al 2017 as rapid climatic and ecological changes continue to create novel landscapes and disturbance regimes process based flms are becoming indispensable for estimating ecological changes over the coming century shifley et al 2017 a persistent challenge with all flms is model calibration tuning the model and validation proofing the model as future data do not exist to compare with flm predictions it is not possible to empirically validate a future projection oreskes et al 1994 rastetter 1996 this point is sometimes wielded as evidence that future flms cannot be validated but this perspective ignores the more practical definition of validation that is well established in the literature sargent 1984 2013 rykiel 1996 rastetter 1996 he et al 2011 shifley et al 2009 in the context of ecological simulation models the term validation refers to qualitative and quantitative evaluations of the underlying model structure i e its conceptual validity sensu sargent 1984 and comparisons with independent data sources i e its operational validity sensu sargent 1984 open source community developed models e g landis ii facilitate both types of validation as users are free to examine model structure and contribute directly to model development in this sense validation is the iterative process of model development implementation and evaluation that helps process based models develop into a credible representation of ecological systems rykiel 1996 rastetter 1996 strategies to validate aspects of ecological simulation models can be grouped in several categories first outlined by rastetter 1996 1 comparing simulation model predictions to existing longitudinal data e g wang et al 2014 2 space for time substitutions e g ma et al 2017 3 past to present simulations e g flatley and fulé 2016 and 4 model comparisons with other flms e g keane et al 2004 petter et al 2020 each of these approaches has both merits and limitations longitudinal datasets are scarce and relatively short term 10 30 years relative to the temporal scope of many flm simulation horizons often 50 years space for time substitutions must rely on an assumption that sampled sites or landscapes are biogeoclimatically comparable only differing in stages of development or percentage of area in varied stages keane et al 2002 and the unavoidable problem of landscape pseudo replication can limit inferences of some comparisons hargrove and pickering 1992 depending on the nature of simulations past to present simulations may require subjective decisions about the historical landscape and assume that past dynamics are a legitimate future proxy cf keane et al 2018 loehman et al 2018 comparing the predictions of multiple flms offers no comparison against empirical data and there are limited means of determining which of the models is most reliable several other studies have validated landis ii applications using static empirical data e g see flanagan et al 2019 boulanger et al 2019 this is perhaps more of an empirical calibration because there is no direct assessment of model dynamics over time table 1 the focal model of this study is landis ii a spatially explicit flm with the capacity to interactively model wildfire silvicultural management forest succession and numerous disturbance processes landis ii is one of the most widely used flms with over 160 published applications www landis ii org publications and is highly adaptable to new landscapes as with many flms landis ii is often considered to be a process based model but it is actually a hybrid that incorporates phenomenological modeling with process modeling where processes are not yet fully understood or where computational limitations deter further complexity petter et al 2020 in this way landis ii harnesses strengths of phenomenological models e g simulating observed patterns while maintaining a high capacity to project future landscapes through process based and interactive succession and disturbance algorithms gustafson 2013 flatley and fulé 2016 liang et al 2018 landis ii is an open source community developed model and the landis ii developers strive to make the model broadly accessible to new researchers see www landis ii org but calibration and validation remain difficult processes particularly with more sophisticated extensions and methods employed in some prior published studies are neither sufficiently transparent nor repeatable the cost and time required to calibrate and validate landis ii applications inhibits development of new models for different landscapes and the recycling of established models and parameter sets can perpetuate underlying error and uncertainty across multiple studies developing rigorous and repeatable methods for systematic calibration and validation will make landis ii a more accessible modeling tool for new research applications and it will help researchers and end users evaluate the credibility and ecological validity of landis ii outputs although we focused this study on landis ii and two specific extensions we endeavored to make our methods and findings broadly relevant to other landis ii extensions and other flm platforms in this study we conducted an empirical evaluation of a newly developed landis ii application i e initialized and calibrated for a specific landscape with explicit consideration of the wildfire sub model scrpple social climate related pyrogenic processes and their landscape effects scheller et al 2019 we reviewed prior studies that have validated aspects of landis ii tables 1 and 2 and we examined the rigor of various validation methods we then used several generalizable methods to calibrate and validate a new landis ii application and we demonstrated the potential for landis ii to reliably model ecological dynamics in mountainous topo edaphically and ecologically diverse fire prone landscapes of the eastern cascade mountain range 2 objectives the purpose of this paper was to establish benchmark methods for calibrating and validating landis ii and similar flms using publicly available data provide detailed documentation of initialization methods that we employed to adapt a model framework to a new geography and develop set of ecologically meaningful standards for evaluating the credibility of model outputs we drew upon previous studies to develop an initial parameter set for our landis ii application to the eastern cascade region in north central washington state we calibrated forest structural characteristics using forest inventory and analysis data fia https www fia fs fed us successional dynamics using the forest vegetation simulator fvs https www fs fed us fvs and fire regime characteristics using monitoring trends in burn severity program mtbs https www mtbs gov we then tested the null hypothesis that this landis ii application was a reasonably realistic representation of reality by validating our model against empirical patterns of landscape dynamics based on longitudinal data and independent phenomenological models 3 methods 3 1 study area we conducted our study in the adjacent wenatchee and entiat subbasins on the eastern slope of the cascade range in north central washington state fig 1 a we applied a 5 km buffer around the watersheds to capture potential edge effects e g seed dispersal and migration of fire from surrounding areas resulting in a 6078 km2 study area fig 1 this area is characterized by steep highly dissected mountainous terrain with elevations ranging from 187 to 2870 m which create highly influential gradients in climate and weather patterns mean annual temperature 1980 2010 climate normals abatzoglou and brown 2012 ranges from 11 3 c at lower elevations to 1 2 c near the cascade crest and precipitation ranges from 0 2 m yr 1 to 2 9 m yr 1 along a similar elevation gradient the climate in both subbasins is humid continental with warm dry summers cold wet winters and most precipitation occurring as snow these broad gradients in precipitation and temperature along with finer scale topo edaphic complexity produce high beta diversity in plant community composition and forest structure within the watersheds fig 1 hessburg et al 2019 low elevation ecosystems are dominated by grasslands shrublands and sparse woodlands with a mix of dry south aspects and moist north aspects conifer forests at mid elevations which transition to subalpine forests alpine meadows and rock barrens at the highest elevations fig 1 hessburg et al 2000 douglas fir pseudotsuga menziesii comprises the greatest overall biomass in the moist mixed conifer zone while drought tolerant tree species including ponderosa pine pinus ponderosa dominate locally in dry forest sites historical fire regimes in the two subbasins were variable with low to moderate severity frequent fire regimes in grassland and mixed conifer forests at low to mid elevations and a mix of moderate and high severity fire regimes in upper montane moist mixed conifer and cold forests agee 1998 hessburg et al 2007 2016 2019 perry et al 2011 nearly a century of fire exclusion and intensive timber harvesting led to the accumulation of surface fuels forest densification compositional shifts towards less fire tolerant species and increased landscape homogeneity hessburg et al 1999 2005 2019 hessburg and agee 2003 hagmann et al 2021 fire has returned to the landscape in recent decades although contemporary fires are larger and more severe reilly et al 2017 haugo et al 2019 hagmann et al 2021 despite this recent surge in wildfire activity annual area burned is likely far below the pre settlement mean for this landscape haugo et al 2019 leenhouts 1998 parks et al 2015 ryan et al 2013 land ownership and management allocation in the study domain is mixed with actively managed forests at low and middle elevations and wildlands in middle and upper montane settings residential development is widespread at low to middle elevations and in valley bottoms the majority 80 of the study area is managed by the usda forest service and over half 56 of the study area is administratively withdrawn wildland designated as wilderness or roadless areas 3 2 model initialization in the current model application we used landis ii v7 0 mladenoff 2004 scheller et al 2007 with extensions necn v6 6 scheller et al 2011 and scrpple v3 0 scheller et al 2019 all analyses were performed in r v4 1 1 r core team 2021 using packages raster hijmans 2021 sf pebesma 2018 landscapemetrics hesselbarth et al 2019 and ggplot2 wickham 2016 3 2 1 vegetation data we generated maps of initial vegetation for the study domain using treemap a spatially imputed forest inventory dataset developed by riley et al 2021 treemap uses random forest imputation to develop a continuous map of the best fitting forest inventory analysis fia plot based on landfire http www landfire gov data layers including biophysical setting existing vegetation type vegetation height percent cover and disturbance layers for every 30 m raster cell within the united states we clipped this raster to the study domain and resampled it to 90 m spatial resolution using nearest neighbor interpolation cells that referenced fia plots outside of the pacific northwest 375 out of 4684 unique fia plot codes present in the imputed raster within our study domain were replaced with the value of a neighboring cell that referenced a fia plot from within the region we performed this replacement because although these foreign plots may have been representative according to the multi variate random forest imputation performed by riley et al 2021 their composition was not representative of the real world landscape that we were modeling and species specific life history traits i e dispersal distance fire tolerance life span are key parameters within landis ii if multiple neighboring cells referenced valid fia plots the most common cell value was used methods consistent with povak et al 2022 we then converted the fia tree lists into a landis ii acceptable format a look up table of age class and biomass by species present in each raster cell biomass was derived from the fia database which contains allometrically estimated biomass values for every tree tree age was determined based on tree cores taken from a subset of trees in each fia plot we used measured ages from 26 346 trees to parameterize a generalized linear regression model that employed tree diameter species and ecoregion to predict tree age for trees that were not cored 77 377 remaining trees the resulting landis ii initialization landscape was a 90 m raster where each cell value referenced a row in a text file containing biomass values associated with each species age combination hereafter cohort present at each site 3 2 2 climate data we used the multivariate adaptive constructed analogs maca abatzoglou and brown 2012 datasets to provide historical climate data minimum daily temperature maximum daily temperature precipitation relative humidity wind speed wind direction on a 4 km grid within the study domain we simulated a baseline future climate scenario by randomly resampling from the climate years 1980 2019 where within year climate was not altered we drew entire years rather than sampling days within years we preserved interannual temporal autocorrelation in this baseline climate scenario by sampling every 3 years as a new randomly sampled starting point a year between 1980 and 2019 and constraining the intermediate two years to be sampled from within 2 years of the initial starting year all climate variables temperature precipitation humidity wind speed wind direction were selected from the same sampled climate year climate is input into landis ii via an ecoregion map where each ecoregion is assigned a unique set of climate data unlike most prior landis ii extensions which use the ecoregion map to define ecological characteristics soil type fire regime etc the extensions we used for succession and fire necn v6 8 and scrpple v3 0 details below rely on continuous raster surfaces for all input variables except climate thus the ecoregion map in our model is used only to define distinct climatic regions we delineated ecoregions within the study domain by intersecting two data layers a vegetation cover type layer and a 10 digit hydrological units huc10 watersheds shapefile watershed boundary dataset for washington state 2019 we generated the vegetation cover type layer by classifying vegetation structure and composition based on biophysical setting existing vegetation type and landfire potential vegetation type our classification procedure resulted in eight distinct vegetation cover types grassland shrubland hardwood alpine meadow dry mixed conifer moist mixed conifer cold moist conifer and cold dry conifer forest intersecting this vegetation type layer with huc10 watersheds created 178 unique ecoregions fig 1 within which we calculated area weighted average climate values using 4 km maca climate rasters by classifying ecoregions according to vegetation cover type and terrain features this method implicitly represented variability in climate due to the prominent elevation gradients in the study domain 3 3 necn succession forest succession processes e g dispersal establishment growth competition and mortality were simulated using the net ecosystem carbon and nitrogen extension necn scheller et al 2011 the necn extension builds upon the century soil model parton 1996 and adapts it for landis ii we opted to use the necn succession extension because it explicitly tracks carbon dynamics among live dead and belowground carbon pools and allows variability in light water and limiting soil resources e g nitrogen to inform forest growth and successional dynamics growth is determined by a combination of species specific parameters e g optimal growing temperature curves maximum net primary production npp and site conditions leaf area index water availability soil resources mortality is modeled as a function of species level parameters e g longevity npp and maximum biomass probability of establishment is internally calculated at an annual time step and is dependent upon input weather data the succession algorithms within landis ii run at the cell level meaning that each cell in the raster has the potential to have a unique starting state and successional trajectory live cohorts can disperse to surrounding cells both adjacent and far away depending on user defined species specific dispersal distance parameters 3 3 1 soil data we used gridded ssurgo data gssurgo soil survey staff 2020 to derive the edaphic variables required for the necn succession extension since the soil maps required for necn differ from the raw soil variables provided by gssurgo we transformed combined and scaled the gssurgo data layers to generate necn ready layers see appendix b for these methods most soil input maps for the necn extension could be approximated from the gssurgo database but initial soil nitrogen was a key exception soil nitrogen data are not available in the gssurgo database instead we used a 1 km gridded total kjeldahl soil nitrogen layer derived from the national soil characterization database hargrove and hoffman 2004 3 3 2 species parameters we derived an initial set of species parameters based on previous landis ii studies tables a1 and a3 https www landis ii org projects for species that were not present in these previous studies parameters were set based on phylogenetically and functionally similar species we then adjusted the species parameters as necessary to improve consistency with values found in silvics of north america burns and honkala 1990 fire effects information system https www feis crs org feis empirical fia data and trait based fire tolerance scores stevens et al 2020 parameters were further calibrated to achieve reasonable model behavior tables a2 and a4 details in model calibration below 3 4 scrpple fire extension we modeled fire behavior and effects with the scrpple fire extension scheller et al 2019 a recently developed extension that does not rely on user defined parameters to constrain the shape of the fire size distribution thereby allowing the fire size and frequency distributions to respond dynamically to changing landscape pattern and future climate inputs scrpple also allows users to explicitly account for various fire management actions such as suppression wildland fire use i e prescribed natural wildfire and prescribed rx fire these management actions can be spatially allocated according to ignition type land ownership and biogeoclimatic setting fires spread from cell to cell via both edges and vertices and probability of spread is modeled as a function of topography fuels and weather wind speed wind direction and fire weather index canadian forest fire weather index fwi fire severity in scrpple is modeled as a multi scale process using nested equations site level i e cell severity is modeled as a function of site characteristics fuels climate soil and windspeed and severity values are scaled to approximate a spectral fire severity index e g differenced normalized burn ratio dnbr robbins et al 2022 cohort specific mortality rates are determined by a logistic model that relates site level severity species and age of individual cohorts to probability of mortality 3 4 1 ignition probability and suppression effort ignitions are generated within scrpple using a zero inflated poisson regression model to estimate the number of ignitions on each day of each year as a function of daily fire weather index fwi values ignitions are then spatially distributed throughout the landscape based on relative ignition frequency given by a gridded probability map although the probability map remains constant the probabilistic regression model produces a unique pattern of ignitions each year we used empirical data from the fire program analysis fire occurrence database fpa fod short 2017 to fit the zero inflated poisson models and generated maps of relative ignition density this dataset contains observed ignition date location cause and final fire size for all reported wildfires both accidental and natural ignitions of any size between the years 1992 2015 for the entire united states we calculated fwi using the maca climate dataset abatzoglou and brown 2012 using the cffdrs r package wang et al 2017 we applied kernel density estimation using the density ppp function from the spatstat r package baddeley et al 2015 to convert spatial points of ignition locations to raster maps of relative ignition probability we zoned likely suppression effectiveness based on land management designation for lightning ignitions minimal suppression effectiveness was applied to wilderness and roadless areas but applied light suppression effort within a 1 mile interior buffer to limit wilderness fire escapes we zoned actively managed public lands with moderate suppression and applied maximal suppression effort to all rural urban and private lands for accidental human ignitions we applied light and moderate suppression effort in wildlands and maximal suppression everywhere else 3 5 calibration and validation we use the term calibration to refer to the iterative adjustment of initial parameters and the term validation to refer to formal comparisons of model outputs to independent data sources e g empirical observations or other simulation models tables 1 and 2 these two terms are however inter related during calibration one adjusts the input parameters to achieve improved correspondence with the ecological patterns and processes that are being simulated thus requiring some form of validation to occur simultaneously in this study we define validation as a more formal process occurring after model calibration that involves comparing model outputs to a new set of independent data evaluating model behavior over longer time spans and or more rigorous goodness of fit tests 3 5 1 calibration we calibrated our landis ii application by iteratively adjusting the initial parameters until the model corresponded well with biomass dynamics modeled using the forest vegetation simulator fvs and empirical fire activity we performed exploratory sensitivity analyses to identify the parameters with the greatest influence on model performance subsequent calibration efforts were aimed at adjusting these key parameters the primary species level necn parameters were temperature sensitivity annual npp maximum biomass and longevity of each species for scrpple the most important parameters for calibration were the fire spread probability coefficients fire severity coefficients and the suppression effectiveness input table 3 5 2 biomass validation we used the eastern cascades variant of fvs to independently validate landis ii derived biomass dynamics e g a pseudo empirical inter model validation table 1 fvs is a distance independent individual tree growth and yield model that simulates stand level dynamics over time data used to build the height and diameter growth equations in each fvs variant came from geographically relevant forest inventories silviculture stand examinations and tree nutrition studies keyser and dixon 2008 to validate the biomass dynamics produced by necn we selected 100 fia plots 50 of the most abundant fia plots plus 50 random plots per vegetation cover type fig 1b we simulated 100 years of growth within fvs and compared mean biomass density outputs from fvs to those derived from landis ii with no wildfire disturbance 3 5 3 fire validation we performed an empirical validation table 2 of the scrpple fire extension by comparing our landis ii simulation outputs with the contemporary 1984 2019 fire regime within the study area we acquired maps of fire severity from the monitoring trends in burn severity mtbs program a publicly available dataset containing satellite derived severity maps for every fire 400 ha within the entire us since 1984 we then combined the mtbs fire severity data with the aforementioned fpa fod fire atlas short 2017 a spatial point dataset containing ignition date location cause and final fire size for all reported wildfires including fires 400 ha between the years 1992 2015 we used the combined fire atlas for metrics that did not require spatially explicit maps of severity e g fire event size distributions and we used the mtbs dataset alone for severity based summary metrics e g fire severity patch size distributions to avoid over representing the area of actual fires that were only partially contained within the study landscape we clipped the mtbs maps to the study domain and computed all metrics based on this constrained spatial extent the combined empirical fire dataset contained a total of 7727 ignitions 1287 fires 1 ha and 61 fires 400 ha 3 5 4 evaluation metrics we evaluated the overall validity of our landis ii application by calculating several summary metrics including biomass density the slope of the biomass trendline fire event size distribution fire severity distribution and the fire severity patch size distributions we evaluated goodness of fit gof by visually comparing these summary metrics to the empirical fire regime and the results of the fvs simulation we avoided formal statistical tests of gof for the fire size and severity patch size distributions because we were interested in whether our model reasonably approximated observed patterns since a simulation model may be sufficiently accurate without perfectly replicating empirical patterns rykiel 1996 we tested whether there was a temporal trend in the average patch size per severity class by fitting linear models one per severity class with year as the predictor variable and average patch area as the response variable 4 results 4 1 succession both landis ii and fvs projected increases in biomass in the absence of fire across all ecoregions and the models corresponded well in terms of absolute biomass values fig 2 average biomass density for the initial base landscape time 0 was 6 higher in landis ii than the average biomass density within the fia plots selected for the fvs simulation 128 mg ha 1 versus 121 mg ha 1 respectively by the end of the 100 year simulations average biomass density in landis ii was 8 6 higher compared with the biomass estimate generated through fvs 252 mg ha 1 versus 231 mg ha 1 respectively differences between the two models in projected biomass at year 100 were smallest in moist mixed conifer and cold moist conifer ecoregions the two ecoregions with the greatest biomass fig 2 the slope of the biomass trendline was consistent between the two models for all tree dominated ecoregions fig 3 in both models aboveground biomass increased at the greatest rate within the first several decades followed by an inflection point mid century and a gradual decline in the rate of biomass accretion although biomass continued to increase this pattern was evident across all ecoregions based on the fvs simulations but it differed for non forest ecoregions grassland shrubland and alpine meadow within the landis ii succession model where the rate of biomass accretion continued to increase over the entire simulation period the ecoregion with the greatest similarity between the two models was moist mixed conifer fig 3 the ecoregion with the greatest biomass density fig 2 and the greatest overall area within the study domain 30 4 2 wildfire with careful tuning of the scpple fire spread parameters we were able to simulate a fire regime that was a reasonable approximation of the empirical fire size distribution for the study domain fig 4 both fire size distributions declined logarithmically with many small fires and relatively few large fires a pattern typical of frequent fire landscapes one notable difference between simulated fires and the empirical data was that accidental human caused ignitions accounted for the majority of observed fires 300 ha while lightning ignitions accounted for most of the fires 300 ha in our simulations fig 4a we accepted this divergence from the historical record to account for anticipated increases in area burned by naturally ignited fires through wildland fire use over the coming century for smaller fires 300 ha the number of lightning fires was roughly equivalent to the number of fires started by accidental causes in both the landis ii simulation and the empirical fire record fig 4a suggesting a realistic ignition probability for both ignition types as expected the observed fire size distribution approximated a power law distribution linear decline in log10 log10 space mckenzie and kennedy 2012 moritz et al 2011 at spatial scales ranging from 1 to 10 000 ha fig 4b c simulated fires also exhibited a logarithmic decline in fire frequency as fire size increased but the trend was not strictly linear fig 4c instead the simulated fire size distribution was characterized by a steep negative slope for fires 20 ha a more moderate slope for fires 20 10 000 ha and a steep decline in frequency for fires 10 000 ha most of the area burned within the landis ii simulation burned at moderate severity while observed fires burned with roughly equal proportions of moderate and high severity fig 5 we note however that the site level severity value that which is analyzed in figs 5 7 and 8 note this has been re named dnbr in output maps generated by scrpple v3 2 produced by scrpple does not necessarily reflect the amount of mortality that each fire causes accordingly we summarized percent of cohorts killed for each fire event fig 6 we were not able to validate this with empirical data because tree mortality data are not available in the mtbs dataset but the mortality distribution produced by our landis ii simulation fit matched the ecological definition of a mixed severity fire regime sensu hessburg et al 2016 with a mix of low 0 25 mortality moderate 25 75 mortality and high 75 mortality severity fire effects figs 6 and 9 fire severity patch size distributions derived from simulated fires were a reasonable approximation of the empirical fire severity patch size distributions fig 7 most patches were 10 ha with 96 of all patches falling under 10 ha for both simulated fires and the mtbs record the average high severity patch sizes were slightly smaller in the landis ii simulated outputs compared with the mtbs data with mean patch sizes of 3 4 ha and 3 9 ha respectively neither dataset displayed a statistically significant trend in patch sizes over time i e the slope of the regression lines was not distinguishable from 0 although seven out of eight patches 10 ha occurred during the latter half of the mtbs fire record fig 8 low severity and unburned patches were restricted to smaller patch sizes while moderate and high severity patches occurred in small and large sizes for both the empirical and simulated fire records nearly all patches 10 ha burned at moderate or high severity figs 7 and 8 5 discussion previous studies have used a variety of methods to validate aspects of landis ii table 1 and these efforts have established credibility for landis ii applications in many contexts this study provides further evidence for the potential credibility of landis ii as we failed to reject the null hypothesis that a well tuned flm model can reliably simulate several key landscape scale ecological processes as forest landscape models flms gain attention as a credible means of projecting system level dynamics however there is a growing need to develop a more transparent and consistent framework for initializing calibrating and validating new model applications petter et al 2020 suárez muñoz et al 2021 building on previous efforts the methods we demonstrate in this study provide such a framework for validating flms that can be broadly applied to any landscape where full coverage calibration datasets are available e g eidenshink et al 2007 riley et al 2021 5 1 succession overall landis ii biomass dynamics corresponded well with fvs modeled projections fig 2 the two models were particularly well aligned in moist mixed conifer and cold moist conifer ecoregions which together comprised 62 of the biomass and 47 of the area within the study domain the phenomenological forest growth models contained within fvs were parameterized using longitudinal forest inventory data providing an empirical basis for projecting biomass dynamics over time we found that the process based algorithms contained within the necn extension matched trends in forest biomass accumulation over time fig 3 demonstrating the ability for necn to capture relevant tree growth competition mortality and forest succession processes previous studies have used longitudinal fia plot data to validate landis ii biomass dynamics wang et al 2014 jin et al 2016 ling et al 2020 but empirical validations are limited by the relatively short time span of longitudinal plot data rarely more than several decades compared with longer desired simulation lengths often 50 years by leveraging the tree growth and mortality models contained within fvs which were parameterized using repeat measurements and space for time substitutions of forest inventory data we were able to validate landis ii biomass dynamics over the entire 100 yr simulation period using a widely respected phenomenological forest growth model we do note that the phenomenological models contained within fvs are not necessarily more valid than the biomass algorithms in necn since neither necn nor fvs have been validated with empirical stand development data that span more than several decades the correspondence between these models bolsters confidence in their predictive capabilities but validations of long term 50 years biomass dynamics continue to be limited by a core lack of long term longitudinal data remotely derived datasets can help fill this need for longitudinal data of forest disturbances that can be detected by satellites but more elusive ecological processes such as tree growth competition and background mortality require precise field based forest inventory data to discern this underscores the importance of creating and maintaining longitudinal forest demography datasets e g lutz 2015 to support our capacity to project landscape dynamics over the coming decades the rate of biomass accretion in non forest ecoregions peaked within the first 20 years of the fvs simulation while landis ii projected that the rate of biomass accumulation would continue to increase throughout the 100 yr simulation period fig 3 a plausible reason for this difference is that in landis ii sites that begin as non forest can be colonized by tree species from nearby cells if site conditions are permissive mladenoff 2004 and we observed forest encroachment in our simulations this is in contrast to fvs which is aspatial and simulates natural regeneration without consideration of neighborhood influences e g dispersal from surrounding stands dixon 2002 the explicit consideration of multi scale neighborhood processes e g seed dispersal is a key advantage of landscape simulation models and it enables them to capture ecological dynamics that elude non spatial models such as fvs the accuracy of this result will require further examination however as landis ii may be projecting forest establishment in non forest sites that are in fact maintained as non forest by biogeoclimatic mechanisms edaphic limitations harsh microclimate herbivory etc that may not be well captured by our model 5 2 wildfire the simulated fire regime that we produced with scrpple was consistent with recent fire history in the wenatchee and entiat subbasins empirical fire regimes in this landscape are temporally and spatially variable and we were able to produce a mosaic of low moderate and high severity fire characteristic of mixed severity fire regimes in the area figs 5 7 maps of fires produced by scrpple were visually realistic with respect to topography and fuels breaks simulated fires mirrored natural wildfire behavior see povak et al 2018 in that they burned with complex shapes and patchy severity and topographic influences on fire spread and severity were intuitively patterned and readily apparent fig 9 the fire regimes produced by scrpple are an emergent property of interactions among weather fuels and topography as the fire regime created by scrpple is not based on an a priori fire size distribution as with some other fire models the model can simulate shifting fire regime dynamics feedback mechanisms and unforeseen system level behavior as we model fire activity under novel future climates this has created more potential for the model to produce surprising results and hence more opportunities for providing ecological insights regarding future climate fire vegetation dynamics table 2 the simulated fire size distribution was well aligned with the empirical fire size distribution but fire size and frequency alone are insufficient to characterizing the complex ecological impacts of fires agee 1998 collins et al 2017 to evaluate the full ecological impact of simulated fire events within the model we examined fire severity cohort mortality and the severity patch size distribution explicitly validating the severity and spatial pattern of the simulated fire regime helped us evaluate the ecological impact of simulated fire which is required to simulate landscape level dynamics such as ecological stability feedbacks and resilience future studies should consider fire severity and patch metrics e g figs 5 8 when calibrating and validating scrpple since the physical characteristics of a fire regime e g fire size and frequency do not reflect the actual impact of fire on fuels carbon and forest structure 5 2 1 fire size fire is a complex multi scale biophysical process scholl and taylor 2010 larson and churchill 2012 jeronimo et al 2019 furniss et al 2020b 2022 and realistically simulating fire behavior spread and severity is a long standing challenge keane et al 2004 the scrpple extension has greatly advanced the capacity of landis ii to simulate a dynamic wildfire regime but some aspects of realistic wildfire simulation remain elusive the fire spread algorithm in scrpple represents fine scale energy transfer from each cell to its adjacent cells thereby simulating the contagious nature of fire and producing spatially aggregated fire effects fig 9 however there are no mechanisms within scrpple or any landis ii fire extension to modify fire behavior as a function of fire size wildfire behavior changes as a function of fire size e g cansler and mckenzie 2014 povak et al 2020a creating positive feedbacks that drive large fires through fire altered wind dynamics broad scale preheating plume dominated events and long distance spotting these factors drive rare yet exceptionally large right tail fire events that have come to dominate total area burned in the western us coop et al 2022 and they are likely to continue to increase in their importance as climate drives increasing frequency and severity of large wildfires cansler and mckenzie 2014 although incorporating multi scale fire behaviors would increase model complexity and slow model runtime it would improve fidelity to the physical process of wildfire and this may help the model better represent evolving fire dynamics under warmer and drier future climates predicting fire behavior under novel fuel and weather conditions remains a challenge for mechanistic and phenomenological fire models alike e g stephens et al 2022 and there is a significant need for research that will improve our ability to reliably model fire behavior at multiple scales simulated fires showed a weaker power law fit compared with the empirical fire activity which followed a more linear trend for fires 10 000 ha fig 4c the distribution of simulated fires was concave due to a lower relative abundance of intermediate sized fires 10 1000 ha this pattern may be attributed to fire spread probabilities in scrpple being calculated based on daily weather values as the logistic form of the model tends to produce either very high or low spread probabilities as there is no sub daily weather to moderate spread rate as the day progresses and no clock to initiate the next weather day diurnal fluctuations in temperature and humidity have limited control over spread rates and this may have inhibited the production of more intermediate sized fires 5 2 2 fire severity a key advance made in scrpple is the development of multi level severity algorithms fire severity i e ecological impact of fire is modeled at both individual cohort trees within a cell and at the site or cell level site level severity is output in maps roughly approximating values of dnbr robbins et al 2022 facilitating empirical validations of ecologically meaningful aspects of fire behavior such as patch size distributions and spatial patterns in severity figs 7 9 table 2 these spatial metrics are central to the ecological function of fire agee 1998 collins et al 2017 and the sophistication of the severity algorithms is a notable strength of the scrpple fire model these severity models contained within scrpple are interrelated site level severity which is modeled as a function of climate fuels and windspeed is fed into the cohort mortality model as an independent variable this approach captures both bottom up and top down controls on fire severity e g povak et al 2020b and for this reason it is functionally appropriate however the relationship between these models is inverted in reality fine scale severity mortality of individual trees and patches drives variability in dnbr severity as detected with satellite imagery at the 30 m scale morgan et al 2014 harvey et al 2019 furniss et al 2020a although the current model structure is functional modifying the severity algorithms such that broad scale biogeoclimatic variables predict fire intensity which would then serve as a predictor for cohort mortality which in turn would be used to model site level severity would help the model structure better reflect the process of fire at these different scales 5 2 3 the problem of validation despite the growing number of studies that have explicitly validated aspects of landis ii tables 1 and 2 not all new flm applications are sufficiently validated or the validation methods may remain unpublished in these cases readers and researchers who are not personally familiar with the model developers are left to simply trust that the model application is credible the calibration and validation methods we describe in this study rely on publicly available full coverage datasets and are therefore generalizable to any other landscape where similar data exist we suggest these methods serve as a set of benchmark practices that others may use to inform their own model initialization methods these methods were developed to balance rigor with practicality while more intensive validation methods may be necessary in specific contexts not all flm users will have the resources to validate all aspects of their model with the maximal level of statistical rigor instead we found that visually evaluating goodness of fit to numerous ecologically meaningful metrics may be a good middle ground that is a viable way for new model users to validate model behavior and demonstrate the credibility of new model applications based on our synthesis of prior landis ii validation efforts and the results of this study we suggest a few best practices for establishing and evaluating the credibility of any given flm application 1 when applying a flm model to a new study domain many parameters may be inherited from previously developed models but key parameters should be calibrated this process should begin with sensitivity analyses either formal or informal e g simons legaard et al 2015 mckenzie et al 2019 to determine which critical parameters will be the focus of calibration efforts calibration then involves setting initial parameters comparing model outputs to empirical data or independent models tuning one or several parameters and re running the model this process is repeated for each parameter or set of related parameters deemed critical during the initial sensitivity analyses such an iterative calibration procedure can halt when model behavior is a reasonable representation of the processes of interest as over tuning cannot compensate for a residual amount of persistent uncertainty due to the fact that process based simulation models are approximations not replicas of reality 2 after calibration system level dynamics of the model should be more formally validated and the results made available for others to examine e g through publication if model outputs are highly variable multiple simulations may be averaged to account for various sources of stochasticity within the model although some qualitative validation is done throughout the calibration process this validation step may involve more rigorous goodness of fit tests comparing model outputs to different data sources or a more extensive evaluation of simulated landscapes using several different summary metrics tables 1 and 2 3 when using a previous flm application to address a new research topic the validation methods and assumptions of the initial model developers should be reconsidered for any new application additional validation may be necessary if prior efforts were insufficient or if they are not directly relevant to the new research topic validity of the model in a prior context does not guarantee the validity of the model in all future contexts if each iteration of a given model instance was validated in a new way established models will become more robust and reliable with usage these guidelines are already employed by many who use landis ii and other flms but we articulate them here to provide a resource for the modeling community that may assist future modeler developers in implementing rigorous transparent and repeatable methodology for calibrating and validating newly calibrated forest landscape models 6 conclusion process based forest landscape models flms are indispensable tools for forecasting forest dynamics under changing disturbance and climatic regimes when properly calibrated and validated these models can reliably simulate empirical trends in forest biomass fire spread and severity and vegetation disturbance patch dynamics validation is a critical step as new simulation models are built and as existing models are adapted to address new research questions in this study we synthesize the strengths and shortcomings of various validation methods to give readers researchers and end users consistent terminology with which to evaluate flms we demonstrated generalizable calibration methods based on publicly available full coverage datasets and established benchmark validation practices based on ecologically relevant summary metrics these advances lower the barrier to adapting landis ii to new landscapes and will enhance the overall rigor of landis ii modeling by synthesizing various validation methods that can be used to demonstrate the credibility of forest landscape models credit authorship contribution statement tucker furniss conceptualization methodology analysis writing editing and visualization paul hessburg funding acquisition conceptualization methodology editing and supervision nicholas povak conceptualization methodology editing and supervision r brion salter conceptualization methodology and editing mark wigmosta funding acquisition conceptualization methodology and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank robert scheller and zachary robbins for their helpful advice with landis ii and we thank two anonymous reviewers for their helpful comments on a prior draft of this manuscript this work was partially funded the us department of energy usdoe bioenergy technologies office de sc0017519 0005 and supported through an appointment of the senior author to the research participation program at the usda fs pacific northwest research station pnwrs administered by the oak ridge institute for science and education orise through an interagency agreement between the usdoe and the pnwrs any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government the views of the authors expressed herein do not represent the official views of the usdoe orise or the usda fs supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110099 appendix supplementary materials image application 1 image application 2 
24337,indirect surveillance methods such as remote cameras and acoustic monitoring are increasingly used in ecological surveys the time to deploy these devices includes initial setup possible maintenance retrieval and then a potentially large investment in the processing of the collected data thus costs will increase with both the number of sites at which devices are deployed and the time they remain in the field creating a trade off between these factors when aiming to maximise the number of sites with detections here we examine a scenario in which a target species occupies a proportion of the possible survey sites ψ establishing a new site has a fixed cost c each survey of a site entails a cost per unit of survey effort t there is imperfect detection of the species during each survey such that the probability of failing to detect the species with a unit of survey effort is q when the species is present and there is a total budget that can be allocated to establishing and surveying sites b we show that the expected number of sites with detections is maximised by surveying each site with a particular amount of survey effort v that depends only on q and c this analytical result can be used by researchers to optimise their survey effort prior to field work and provide opportunities for optimal allocation of their survey budget we illustrate the method with an application to surveys of the threatened leadbeater s possum gymnobelidus leadbeateri keywords imperfect detection occupancy studies species detection optimisation data availability data will be made available on request 1 introduction the likelihood of detecting a species in the field often has a probability less than 1 mackenzie et al 2002 guillera arroita et al 2010 karavarsamis and huggins 2019 such that non detection at a site can arise when a species is present but is simply not detected during that survey mackenzie et al 2002 tyre et al 2003 mackenzie and royle 2005 guillera arroita et al 2010 guillera arroita and lahoz monfort 2017 false negatives non detection of species that are present are common and previous studies have attempted to deal with these through statistical methods mackenzie et al 2002 tyre et al 2003 hoffman et al 2010 campos cerqueira and aide 2016 uncertainty in identification for example from a blurry camera trap image likely results in recording the species as absent which is then a missed or failed detection if the species was in fact present clement 2016 guillera arroita 2017 warton et al 2017 chambert et al 2018 in contrast false positives mistakenly recording a species that is absent as present are less common false positives can be accounted for by using only those observations in the study that have a high degree of certainty or specifically using occupancy models that account for false positives miller et al 2011 2012 chambert et al 2015 2018 we identified five key objectives which influence study design of surveillance studies although other objectives could be considered objective 1 maximising probability of detection at a single site objective 2 minimising standard error of estimates objective 3 maximising the number of sites with at least one detection objective 4 mapping species distribution and range objective 5 declaring species extinction or eradication previous studies have aimed to optimise surveys to address these various objectives tyre et al 2003 regan et al 2006 comte and grenouillet 2013 steenweg et al 2017 linden et al 2017 warton et al 2017 chambert et al 2018 rout et al 2018 however a limited number address optimising to maximise the number of sites with at least one detection which is the focus of this research studies that maximise the number of sites at which a species is detected have been undertaken in scenarios including the detection of invasive species hauser and mccarthy 2009 where there are multiple species being surveyed sanderlin et al 2014 where surveys stop after the first detection guillera arroita and lahoz monfort 2017 when species are declining ficetola et al 2018 when detectability varies across space and time moore and mccarthy 2016 or to maximise the detection probability of a species petitot et al 2014 these studies however do not consider the site establishment costs aside from moore and mccarthy 2016 who included travel cost per survey and determined the survey effort through numerical optimisation analytical solutions are not presented in the literature when site establishment costs exist as such here we focus on optimising the number of detections of a single species across multiple sites with a limited conservation budget with the aim of generating analytical solutions for the optimal survey effort when establishment costs exist for any given survey objective and with a limited budget a trade off exists between either increasing the number of sites sampled or increasing the amount of effort applied to each site shannon et al 2014 clement 2016 gálvez et al 2016 guillera arroita 2017 allocating more resources on a single site can improve the probability of detection at that site but may decrease number of sites with detections or total number of detections overall by reducing time spent at other sites hauser and mccarthy 2009 clement 2016 to maximise detections per unit of survey effort researchers may target areas with the highest probabilities of occupancy for longer periods of time to ensure that a detection is made if the survey aim is to instead maximise the number of sites where at least one detection is made then the trade off must be considered previous research indicates that fewer repeat site visits maximises detections if probability of occupancy is low or probability of detection is high moore et al 2014 when probability of occupancy is high or probability of detection is low it is more beneficial to survey fewer sampling units for longer periods in order to get the best possible survey outcomes moore and mccarthy 2016 surveys of the critically endangered leadbeater s possum g y m n o b e l i d u s l e a d b e a t e r i provide an example of survey objectives that aim to maximise the number of sites with at least one detection but where research into cost and effort is scarce leadbeater s possum occupies a small habitat range approximately 70 km by 95 km in the central highlands of victoria atlas of living australia 2021 to reduce the impacts of timber harvesting on this threatened species measures were introduced in 2014 to increase protection of leadbeater s possums and their habitat these included the establishment of 200 m radius timber harvesting protection zones thez around all new verified records as well as a three year survey program to locate new leadbeater s possum colonies for protection leadbeater s possum advisory group 2014 as of 2017 due to the addition of thez the existing formal reserve system for leadbeater s possum increased from 30 520 to 34 566 ha an increase of 13 which is estimated to have decreased the risk of the leadbeater s possum becoming extinct over the next 200 years within the reserve system by approximately 34 department of environment land water and planning with contribution from vicforests 2017 nelson et al 2017 conducted research into the survey effort required to achieve a high probability of detection at a single site through deployment of arboreal camera traps which has resulted in standardised survey protocols surveys are undertaken for a period of 3 4 weeks and with either 2 or 3 cameras per site nelson et al 2017 in this case each site entails fixed costs that are independent of the time taken to process data from the cameras these costs include deployment and retrieval costs of the cameras variable costs include the time taken to process and check images for the presence of the target species we assume that these variable costs are proportional to the number of images these costs may also be proportional to the length of deployment of the cameras but this is not always the case cameras can show large variation in the number of images they take even when out for the same survey period we start with a general method to develop the optimal solution for the survey effort required to maximise the number of sites with detections species detections are particularly important in the conservation of rare or threatened species or in understanding the range and spread of invasive species hoffman et al 2010 hauser and mccarthy 2009 whilst moore and mccarthy 2016 provide a method to numerically optimise the number of sites with detection here we seek analytical solutions where all sites have the same probability of presence and detection this will be in the form of an analytical solution for the case sites where establishment costs and probabilities of detection and occupancy are the same across all sites for the case study we will analyse detection data from nelson et al 2017 and cost data obtained from a survey conducted subsequent to the 2015 16 surveys once the protocol had been finalised and during a similar time period arthur rylah institute for environmental research unpublished data to investigate the optimal survey protocol for leadbeater s possum 2 methods 2 1 model development to develop the optimal solution for the survey effort required to maximise the number of sites with detections we suppose that probability of occupancy probability of detection and establishment costs are the same for each survey define n sites labelled 1 n up to n of the available sites will be surveyed and each site is surveyed with v survey effort per site probability of occupancy is denoted by ψ and p is the probability of detection of a species per unit of survey effort given that the species occupies the site the probability of a failed detection per survey is therefore q 1 p and the probability of failed detection given survey effort of v is q v the total budget for all surveys is denoted b with c equal to the establishment costs of each site and t the cost for each unit of survey effort such that the total budget is 1 b n c v t where n n and v 0 this can be rearranged to find the number of sites given a set budget and a chosen level of survey effort per site v 2 n b c v t when all sites are identical maximising the number of sites with at least one detection is equivalent to maximising 3 l n ψ 1 q v where l is the expected number of sites with detections given a total budget that is available to survey for a species there is a survey design choice of n or equivalently choice of v given that n and v are linked by eq 2 that maximises the expected number of detections per unit of survey effort the analysis therefore considered the following parameters that might influence the optimal choice of n or v b total budget allocated for the project or survey period c establishment cost of a site t cost of visiting surveying or processing a site for one unit of survey effort without loss of generality the units of cost are set such that t 1 n total number of sites ψ probability of occupancy q probability of failing to detect the target species q 1 p given a unit of survey effort at a site where the species occurs l expected number of sites with detections these parameters can be set prior to surveying based on values obtained from similar surveys habitat suitability models established costs or recommended methodology to find the optimal solution for v start with eq 3 and set a budget b and establishment cost c in standardised units so that t 1 this leads to 4 l b ψ 1 q v c v which can then be differentiated with respect to v and simplified to 5 l v b ψ 1 q v q v c v log q c v 2 the optimal solution for v can then be found when eq 5 is equal to 0 this occurs when 6 1 q v q v c v log q 0 although this can be rearranged for a straightforward solution for c which is shown as equation 13 in supplementary material this equation does not give the optimal solution for v eq 6 is an implicit function for v given that v occurs in both the terms q v and v but a solution for v can be found that involves the lambert w function we validated this solution by comparing the results to a numerical optimisation of the objective function eq 3 2 2 case study surveillance for leadbeater s possum in the central highlands of victoria australia since 2014 a large number of leadbeater s possum detection surveys have been undertaken in order to protect populations from harvesting practices through establishment of timber harvesting exclusion zones thez department of environment and primary industries 2014 leadbeater s possum advisory group 2014 nelson et al 2017 we used estimated detection rates that were obtained from targeted surveys in areas subject to timber harvesting utilising three cameras per site over a period of three to four weeks nelson et al 2017 initial parameters for our model were determined based on cost data ari unpublished data and probability of occupancy and detections from nelson et al 2017 this allowed us to examine the extent to which the protocol of deploying three cameras at each site for three to four weeks maximised the number of sites with at least one detection between september 2015 and april 2016 3 results 3 1 optimal solution when sites are identical the value of v that maximises the number of sites with at least one detection is 7 v 1 c log q w 1 q c e log q which is independent of total budget b and probability of occupancy ψ full working available in the supplementary material the w 1 in the resulting solution refers to the lower branch of the lambert w function and an introduction to this function can be found in supplementary material the solution from eq 7 corresponds to that obtained by maximising l numerically where v is treated as an integer fig 1 the difference between the two values is minimal across a range of values for q and is due to the optimal solution for v being expressed as a continuous value when in practice v may be discrete simply rounding the values for v calculated by the optimal solution would generate very similar results as this solution is independent of b and ψ the value of v will stay the same if these parameter values change in this scenario v will only change if either the establishment cost c of a site or the probability of failed detection per unit of survey effort q change fig 1 3 2 approximation of the optimal solution the optimal solution for identical sites relies on the lower bound of the lambert w function which is not a common function that is readily known or used by ecologists as such an approximation to the solution would be ideal for this solution to be more accessible in supplementary material we show that by using an approximation from chatzigeorgiou 2013 for the lower branch of the lambert w function for u 0 the function can be removed from the equation so that u log q c and f 1 1 2 u 2 3 u which in our case is equivalent to f 1 w 1 q c e this approximation can be substituted into the optimal solution for v by first transforming the equation such that w 1 q c e 1 2 u 2 3 u by substitution into v 1 c log q w 1 q c e log q the solution is now 8 v c 2 u u 3 u where u log q c full details of the approximation are available in supplementary material the approximation provides a more user friendly solution without the lambert w function which works well for low values of c and when q is high therefore detectability is low but it noticeably diverges from the true optimal solution eq 7 as c increases see supplementary material 3 3 case study surveillance for leadbeater s possum the initial parameter values were based on t 1 where t corresponds to the survey length of 28 days 1 2 days establishment costs of the site relative to this were c 6 2 that is the cost of establishing each site and deploying and retrieving cameras was 6 2 times the cost of processing 28 days of images these relative costs were based on visiting 56 sites with three cameras at each site the value for q varied based on the type of reconyx camera professional series pc900 professional covert ir hyperfire series hc600 covert ir or hc500 semi covert ir table 1 with both the hc500 and hc600 the probability of failed detection was 0 05 for a 28 day survey period with this value of q and c 6 2 the optimal v was calculated to be 1 04 note the units of v are scaled by the original survey length that defines q which in this case was 28 days so when v 1 04 the optimal survey length is 28 1 04 29 days this indicates that the recommended time spent surveying by ari in this case 28 1 2 days is close to the optimal solution the pc900 model had a probability of failed detection of 0 13 with an optimal v of 1 37 as such for this particular camera model the current method of 28 1 2 days should be multiplied by 1 37 to get the optimal solution of 38 1 2 days to reach the maximum number of sites with detections for the survey the optimal solution for the range of probabilities of failed detection in table 1 0 00 q 0 30 varies from v 0 8 to 2 0 fig 2 as q increases the optimal v also increases surveys which have higher probabilities of failed detection will need to run for longer to optimise the number of sites with detections 4 discussion prior to our study research into optimising survey effort across sites to maximise the number of sites with detections including site establishment costs has been limited studies such as moore and mccarthy 2016 rely on optimisation of the solution via numerical programming or a numerical approximation of a knapsack problem our study has developed an analytical solution to a subset of the problems analysed in moore and mccarthy 2016 where the value for q is the same across all sites this solution allows us to understand the factors that influence the optimal solution being q and c because the optimal survey effort v is calculated as a function of these two parameters in fact inspection of eq 7 shows that the optimal solution is such that the survey effort v should be chosen to ensure that the probability of failed detection over the course of the survey q v has a particular value that is a function of only the compound parameter q c the optimal solution when all sites are identical is an interesting case as the optimal v is independent of the total budget available for a survey b or the probability of occupancy ψ this makes sense as both b and ψ are constants such that eq 4 will inflate or deflate as these values change but the location of the optimal v will not move this is similar to findings from hauser and mccarthy 2009 where the optimal survey effort with a budget constraint depended on relative occupancy between sites as our analysis assumes the same occupancy this drops out of the resulting optimal solution similar to the findings of moore and mccarthy 2016 the optimal solution depends on the establishment cost c of a site although our site establishment costs are slightly different to their travel costs we further explored the sensitivity of the optimal expected number of sites with detections l o p t to changes in c and v available in supplementary material the probability of failed detection q 1 p was also an important factor in the optimal solution and this is consistent with previous studies that show that probability of detection is an important consideration when optimising survey effort hauser and mccarthy 2009 moore and mccarthy 2016 the optimal solution assumes that the probability of detection p and probability of occupancy ψ are the same for all sites these assumptions are unlikely in practice but might be necessary in order to simplify the process of survey design as these probabilities are likely to be unknown for each site within a survey location mackenzie and royle 2005 it is often the case that parameter estimates arise from prior surveys or output of occupancy or species distribution models that may not assign specific values of ψ or p to each individual site hence the optimal solution in this case is the simplest form that researchers can utilise to design studies with the least amount of knowledge required of each individual site 4 1 optimal surveys for leadbeater s possum ari survey protocols recommend surveys for leadbeater s possum are undertaken using two to three cameras per site and for a period of three or four weeks either 21 or 28 days 1 2 days nelson et al 2017 these survey protocols were developed based on analysis of detection probabilities to predict probability of occupancy alongside additional analysis of possum detections nelson et al 2017 the probability of detection for these studies was high between 0 87 and 0 95 which was due to the fact that these surveys were targeted to sites based on unsurveyed areas with a high probability of occupancy 0 65 locations that were near recently discovered colonies or records from the previous 15 years and known hotspots with a high density of records these survey protocols were designed with the objective of achieving a high probability of detection 0 95 at a site through this analysis nelson et al 2017 determined that the appropriate survey period was 28 days with a probability of failed detection of 0 05 this probability is of particular importance for leadbeater s possum conservation the aim of these surveys was to locate possums for protection by thez and false negatives would result in occupied habitat remaining available for timber harvesting for other surveys with different management objectives the consequence of false negatives may be more acceptable and so a reduction in survey effort at a single site so that more sites can be surveyed may be a more efficient approach our analysis shows that the chosen survey protocol is also close to optimal with respect to the objective of maximising sites with detections 4 2 limitations and future research whilst we were able to develop working solutions for three additional scenarios where the probability of occupancy or the establishment costs of a site varied or both varied at the same time these required numerical solutions rather than analytical solutions newman 2019 as such we have not included these solutions for the sake of brevity and intend to publish if when analytical solutions are found our optimal solution relies on the probability of detection across all sites being the same though ecologists are likely to face probabilities of detection that vary across a site due to either biotic or abiotic factors further development of the models to account for stochastic probabilities of detection would allow for their use in a wider range of contexts moore et al 2014 illustrates that stochasticity in the probability of detection should be accounted for when designing surveys where the detection rate is low therefore q is high because moore et al 2014 show that the solution would still contain the exponential q v and stochasticity just modifies the effective values for q and possibly c it does not appear that this would influence the optimal solution too much the cost structure that was applied to the model represents the simplest approach to the cost of surveillance by assuming that the cost of surveying will increase linearly with effort there are however other cost structures that would result in different scenarios and potentially different outcomes or prioritisation of sites our case study explored a scenario where cameras were left out for a set amount of time and assuming that processing costs were linearly related to this ie leaving the cameras out for longer resulting in more images collected and therefore more processing costs for some survey methods each survey may entail a differing cost structure such as the case of surveys that move on to a different site after the detection of the target is made for example presence only spotlighting surveys or thermal imaging although removal design is not as simple for camera surveys due to logistical constraints mackenzie and royle 2005 guillera arroita and lahoz monfort 2017 it would be of benefit to field test the optimal solutions determined by the analysis to evaluate the usefulness of applying these methods based on the optimal solution the expected number of sites with detections can be calculated this can then be tested through conducting the survey following the protocols determined by the solution if the expected number of sites with detections is reached then the optimal solution may be the most appropriate surveillance method for the survey it is however possible that this may happen by chance to determine the benefit of the analysis the key would be to determine whether the optimal solution works better than an alternative and whether the benefit of the optimal solution relative to the alternative is realised by utilising the optimal solution researchers can ensure that they are making the most of their conservation budgets which are often limited especially in the context of protecting threatened species the current ari survey protocols for leadbeater s possum are close to the optimal conditions for the survey objective which is detection of the species to establish zones of habitat protection whilst the models were tested on a camera trapping case study they are general solutions and can be used for optimisation of survey methods for any surveillance activities credit authorship contribution statement kevin d newman conceptualization methodology validation formal analysis writing original draft writing review editing visualisation jenny l nelson resources data curation writing review editing louise k durkin resources data curation writing review editing jemma k cripps resources data curation writing review editing michael a mccarthy supervision conceptualization methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data full mathematical solutions proofs and an explanation of the lambert w function are available as supplementary material supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110117 appendix b supplementary data the following is the supplementary material related to this article mmc s1 
24337,indirect surveillance methods such as remote cameras and acoustic monitoring are increasingly used in ecological surveys the time to deploy these devices includes initial setup possible maintenance retrieval and then a potentially large investment in the processing of the collected data thus costs will increase with both the number of sites at which devices are deployed and the time they remain in the field creating a trade off between these factors when aiming to maximise the number of sites with detections here we examine a scenario in which a target species occupies a proportion of the possible survey sites ψ establishing a new site has a fixed cost c each survey of a site entails a cost per unit of survey effort t there is imperfect detection of the species during each survey such that the probability of failing to detect the species with a unit of survey effort is q when the species is present and there is a total budget that can be allocated to establishing and surveying sites b we show that the expected number of sites with detections is maximised by surveying each site with a particular amount of survey effort v that depends only on q and c this analytical result can be used by researchers to optimise their survey effort prior to field work and provide opportunities for optimal allocation of their survey budget we illustrate the method with an application to surveys of the threatened leadbeater s possum gymnobelidus leadbeateri keywords imperfect detection occupancy studies species detection optimisation data availability data will be made available on request 1 introduction the likelihood of detecting a species in the field often has a probability less than 1 mackenzie et al 2002 guillera arroita et al 2010 karavarsamis and huggins 2019 such that non detection at a site can arise when a species is present but is simply not detected during that survey mackenzie et al 2002 tyre et al 2003 mackenzie and royle 2005 guillera arroita et al 2010 guillera arroita and lahoz monfort 2017 false negatives non detection of species that are present are common and previous studies have attempted to deal with these through statistical methods mackenzie et al 2002 tyre et al 2003 hoffman et al 2010 campos cerqueira and aide 2016 uncertainty in identification for example from a blurry camera trap image likely results in recording the species as absent which is then a missed or failed detection if the species was in fact present clement 2016 guillera arroita 2017 warton et al 2017 chambert et al 2018 in contrast false positives mistakenly recording a species that is absent as present are less common false positives can be accounted for by using only those observations in the study that have a high degree of certainty or specifically using occupancy models that account for false positives miller et al 2011 2012 chambert et al 2015 2018 we identified five key objectives which influence study design of surveillance studies although other objectives could be considered objective 1 maximising probability of detection at a single site objective 2 minimising standard error of estimates objective 3 maximising the number of sites with at least one detection objective 4 mapping species distribution and range objective 5 declaring species extinction or eradication previous studies have aimed to optimise surveys to address these various objectives tyre et al 2003 regan et al 2006 comte and grenouillet 2013 steenweg et al 2017 linden et al 2017 warton et al 2017 chambert et al 2018 rout et al 2018 however a limited number address optimising to maximise the number of sites with at least one detection which is the focus of this research studies that maximise the number of sites at which a species is detected have been undertaken in scenarios including the detection of invasive species hauser and mccarthy 2009 where there are multiple species being surveyed sanderlin et al 2014 where surveys stop after the first detection guillera arroita and lahoz monfort 2017 when species are declining ficetola et al 2018 when detectability varies across space and time moore and mccarthy 2016 or to maximise the detection probability of a species petitot et al 2014 these studies however do not consider the site establishment costs aside from moore and mccarthy 2016 who included travel cost per survey and determined the survey effort through numerical optimisation analytical solutions are not presented in the literature when site establishment costs exist as such here we focus on optimising the number of detections of a single species across multiple sites with a limited conservation budget with the aim of generating analytical solutions for the optimal survey effort when establishment costs exist for any given survey objective and with a limited budget a trade off exists between either increasing the number of sites sampled or increasing the amount of effort applied to each site shannon et al 2014 clement 2016 gálvez et al 2016 guillera arroita 2017 allocating more resources on a single site can improve the probability of detection at that site but may decrease number of sites with detections or total number of detections overall by reducing time spent at other sites hauser and mccarthy 2009 clement 2016 to maximise detections per unit of survey effort researchers may target areas with the highest probabilities of occupancy for longer periods of time to ensure that a detection is made if the survey aim is to instead maximise the number of sites where at least one detection is made then the trade off must be considered previous research indicates that fewer repeat site visits maximises detections if probability of occupancy is low or probability of detection is high moore et al 2014 when probability of occupancy is high or probability of detection is low it is more beneficial to survey fewer sampling units for longer periods in order to get the best possible survey outcomes moore and mccarthy 2016 surveys of the critically endangered leadbeater s possum g y m n o b e l i d u s l e a d b e a t e r i provide an example of survey objectives that aim to maximise the number of sites with at least one detection but where research into cost and effort is scarce leadbeater s possum occupies a small habitat range approximately 70 km by 95 km in the central highlands of victoria atlas of living australia 2021 to reduce the impacts of timber harvesting on this threatened species measures were introduced in 2014 to increase protection of leadbeater s possums and their habitat these included the establishment of 200 m radius timber harvesting protection zones thez around all new verified records as well as a three year survey program to locate new leadbeater s possum colonies for protection leadbeater s possum advisory group 2014 as of 2017 due to the addition of thez the existing formal reserve system for leadbeater s possum increased from 30 520 to 34 566 ha an increase of 13 which is estimated to have decreased the risk of the leadbeater s possum becoming extinct over the next 200 years within the reserve system by approximately 34 department of environment land water and planning with contribution from vicforests 2017 nelson et al 2017 conducted research into the survey effort required to achieve a high probability of detection at a single site through deployment of arboreal camera traps which has resulted in standardised survey protocols surveys are undertaken for a period of 3 4 weeks and with either 2 or 3 cameras per site nelson et al 2017 in this case each site entails fixed costs that are independent of the time taken to process data from the cameras these costs include deployment and retrieval costs of the cameras variable costs include the time taken to process and check images for the presence of the target species we assume that these variable costs are proportional to the number of images these costs may also be proportional to the length of deployment of the cameras but this is not always the case cameras can show large variation in the number of images they take even when out for the same survey period we start with a general method to develop the optimal solution for the survey effort required to maximise the number of sites with detections species detections are particularly important in the conservation of rare or threatened species or in understanding the range and spread of invasive species hoffman et al 2010 hauser and mccarthy 2009 whilst moore and mccarthy 2016 provide a method to numerically optimise the number of sites with detection here we seek analytical solutions where all sites have the same probability of presence and detection this will be in the form of an analytical solution for the case sites where establishment costs and probabilities of detection and occupancy are the same across all sites for the case study we will analyse detection data from nelson et al 2017 and cost data obtained from a survey conducted subsequent to the 2015 16 surveys once the protocol had been finalised and during a similar time period arthur rylah institute for environmental research unpublished data to investigate the optimal survey protocol for leadbeater s possum 2 methods 2 1 model development to develop the optimal solution for the survey effort required to maximise the number of sites with detections we suppose that probability of occupancy probability of detection and establishment costs are the same for each survey define n sites labelled 1 n up to n of the available sites will be surveyed and each site is surveyed with v survey effort per site probability of occupancy is denoted by ψ and p is the probability of detection of a species per unit of survey effort given that the species occupies the site the probability of a failed detection per survey is therefore q 1 p and the probability of failed detection given survey effort of v is q v the total budget for all surveys is denoted b with c equal to the establishment costs of each site and t the cost for each unit of survey effort such that the total budget is 1 b n c v t where n n and v 0 this can be rearranged to find the number of sites given a set budget and a chosen level of survey effort per site v 2 n b c v t when all sites are identical maximising the number of sites with at least one detection is equivalent to maximising 3 l n ψ 1 q v where l is the expected number of sites with detections given a total budget that is available to survey for a species there is a survey design choice of n or equivalently choice of v given that n and v are linked by eq 2 that maximises the expected number of detections per unit of survey effort the analysis therefore considered the following parameters that might influence the optimal choice of n or v b total budget allocated for the project or survey period c establishment cost of a site t cost of visiting surveying or processing a site for one unit of survey effort without loss of generality the units of cost are set such that t 1 n total number of sites ψ probability of occupancy q probability of failing to detect the target species q 1 p given a unit of survey effort at a site where the species occurs l expected number of sites with detections these parameters can be set prior to surveying based on values obtained from similar surveys habitat suitability models established costs or recommended methodology to find the optimal solution for v start with eq 3 and set a budget b and establishment cost c in standardised units so that t 1 this leads to 4 l b ψ 1 q v c v which can then be differentiated with respect to v and simplified to 5 l v b ψ 1 q v q v c v log q c v 2 the optimal solution for v can then be found when eq 5 is equal to 0 this occurs when 6 1 q v q v c v log q 0 although this can be rearranged for a straightforward solution for c which is shown as equation 13 in supplementary material this equation does not give the optimal solution for v eq 6 is an implicit function for v given that v occurs in both the terms q v and v but a solution for v can be found that involves the lambert w function we validated this solution by comparing the results to a numerical optimisation of the objective function eq 3 2 2 case study surveillance for leadbeater s possum in the central highlands of victoria australia since 2014 a large number of leadbeater s possum detection surveys have been undertaken in order to protect populations from harvesting practices through establishment of timber harvesting exclusion zones thez department of environment and primary industries 2014 leadbeater s possum advisory group 2014 nelson et al 2017 we used estimated detection rates that were obtained from targeted surveys in areas subject to timber harvesting utilising three cameras per site over a period of three to four weeks nelson et al 2017 initial parameters for our model were determined based on cost data ari unpublished data and probability of occupancy and detections from nelson et al 2017 this allowed us to examine the extent to which the protocol of deploying three cameras at each site for three to four weeks maximised the number of sites with at least one detection between september 2015 and april 2016 3 results 3 1 optimal solution when sites are identical the value of v that maximises the number of sites with at least one detection is 7 v 1 c log q w 1 q c e log q which is independent of total budget b and probability of occupancy ψ full working available in the supplementary material the w 1 in the resulting solution refers to the lower branch of the lambert w function and an introduction to this function can be found in supplementary material the solution from eq 7 corresponds to that obtained by maximising l numerically where v is treated as an integer fig 1 the difference between the two values is minimal across a range of values for q and is due to the optimal solution for v being expressed as a continuous value when in practice v may be discrete simply rounding the values for v calculated by the optimal solution would generate very similar results as this solution is independent of b and ψ the value of v will stay the same if these parameter values change in this scenario v will only change if either the establishment cost c of a site or the probability of failed detection per unit of survey effort q change fig 1 3 2 approximation of the optimal solution the optimal solution for identical sites relies on the lower bound of the lambert w function which is not a common function that is readily known or used by ecologists as such an approximation to the solution would be ideal for this solution to be more accessible in supplementary material we show that by using an approximation from chatzigeorgiou 2013 for the lower branch of the lambert w function for u 0 the function can be removed from the equation so that u log q c and f 1 1 2 u 2 3 u which in our case is equivalent to f 1 w 1 q c e this approximation can be substituted into the optimal solution for v by first transforming the equation such that w 1 q c e 1 2 u 2 3 u by substitution into v 1 c log q w 1 q c e log q the solution is now 8 v c 2 u u 3 u where u log q c full details of the approximation are available in supplementary material the approximation provides a more user friendly solution without the lambert w function which works well for low values of c and when q is high therefore detectability is low but it noticeably diverges from the true optimal solution eq 7 as c increases see supplementary material 3 3 case study surveillance for leadbeater s possum the initial parameter values were based on t 1 where t corresponds to the survey length of 28 days 1 2 days establishment costs of the site relative to this were c 6 2 that is the cost of establishing each site and deploying and retrieving cameras was 6 2 times the cost of processing 28 days of images these relative costs were based on visiting 56 sites with three cameras at each site the value for q varied based on the type of reconyx camera professional series pc900 professional covert ir hyperfire series hc600 covert ir or hc500 semi covert ir table 1 with both the hc500 and hc600 the probability of failed detection was 0 05 for a 28 day survey period with this value of q and c 6 2 the optimal v was calculated to be 1 04 note the units of v are scaled by the original survey length that defines q which in this case was 28 days so when v 1 04 the optimal survey length is 28 1 04 29 days this indicates that the recommended time spent surveying by ari in this case 28 1 2 days is close to the optimal solution the pc900 model had a probability of failed detection of 0 13 with an optimal v of 1 37 as such for this particular camera model the current method of 28 1 2 days should be multiplied by 1 37 to get the optimal solution of 38 1 2 days to reach the maximum number of sites with detections for the survey the optimal solution for the range of probabilities of failed detection in table 1 0 00 q 0 30 varies from v 0 8 to 2 0 fig 2 as q increases the optimal v also increases surveys which have higher probabilities of failed detection will need to run for longer to optimise the number of sites with detections 4 discussion prior to our study research into optimising survey effort across sites to maximise the number of sites with detections including site establishment costs has been limited studies such as moore and mccarthy 2016 rely on optimisation of the solution via numerical programming or a numerical approximation of a knapsack problem our study has developed an analytical solution to a subset of the problems analysed in moore and mccarthy 2016 where the value for q is the same across all sites this solution allows us to understand the factors that influence the optimal solution being q and c because the optimal survey effort v is calculated as a function of these two parameters in fact inspection of eq 7 shows that the optimal solution is such that the survey effort v should be chosen to ensure that the probability of failed detection over the course of the survey q v has a particular value that is a function of only the compound parameter q c the optimal solution when all sites are identical is an interesting case as the optimal v is independent of the total budget available for a survey b or the probability of occupancy ψ this makes sense as both b and ψ are constants such that eq 4 will inflate or deflate as these values change but the location of the optimal v will not move this is similar to findings from hauser and mccarthy 2009 where the optimal survey effort with a budget constraint depended on relative occupancy between sites as our analysis assumes the same occupancy this drops out of the resulting optimal solution similar to the findings of moore and mccarthy 2016 the optimal solution depends on the establishment cost c of a site although our site establishment costs are slightly different to their travel costs we further explored the sensitivity of the optimal expected number of sites with detections l o p t to changes in c and v available in supplementary material the probability of failed detection q 1 p was also an important factor in the optimal solution and this is consistent with previous studies that show that probability of detection is an important consideration when optimising survey effort hauser and mccarthy 2009 moore and mccarthy 2016 the optimal solution assumes that the probability of detection p and probability of occupancy ψ are the same for all sites these assumptions are unlikely in practice but might be necessary in order to simplify the process of survey design as these probabilities are likely to be unknown for each site within a survey location mackenzie and royle 2005 it is often the case that parameter estimates arise from prior surveys or output of occupancy or species distribution models that may not assign specific values of ψ or p to each individual site hence the optimal solution in this case is the simplest form that researchers can utilise to design studies with the least amount of knowledge required of each individual site 4 1 optimal surveys for leadbeater s possum ari survey protocols recommend surveys for leadbeater s possum are undertaken using two to three cameras per site and for a period of three or four weeks either 21 or 28 days 1 2 days nelson et al 2017 these survey protocols were developed based on analysis of detection probabilities to predict probability of occupancy alongside additional analysis of possum detections nelson et al 2017 the probability of detection for these studies was high between 0 87 and 0 95 which was due to the fact that these surveys were targeted to sites based on unsurveyed areas with a high probability of occupancy 0 65 locations that were near recently discovered colonies or records from the previous 15 years and known hotspots with a high density of records these survey protocols were designed with the objective of achieving a high probability of detection 0 95 at a site through this analysis nelson et al 2017 determined that the appropriate survey period was 28 days with a probability of failed detection of 0 05 this probability is of particular importance for leadbeater s possum conservation the aim of these surveys was to locate possums for protection by thez and false negatives would result in occupied habitat remaining available for timber harvesting for other surveys with different management objectives the consequence of false negatives may be more acceptable and so a reduction in survey effort at a single site so that more sites can be surveyed may be a more efficient approach our analysis shows that the chosen survey protocol is also close to optimal with respect to the objective of maximising sites with detections 4 2 limitations and future research whilst we were able to develop working solutions for three additional scenarios where the probability of occupancy or the establishment costs of a site varied or both varied at the same time these required numerical solutions rather than analytical solutions newman 2019 as such we have not included these solutions for the sake of brevity and intend to publish if when analytical solutions are found our optimal solution relies on the probability of detection across all sites being the same though ecologists are likely to face probabilities of detection that vary across a site due to either biotic or abiotic factors further development of the models to account for stochastic probabilities of detection would allow for their use in a wider range of contexts moore et al 2014 illustrates that stochasticity in the probability of detection should be accounted for when designing surveys where the detection rate is low therefore q is high because moore et al 2014 show that the solution would still contain the exponential q v and stochasticity just modifies the effective values for q and possibly c it does not appear that this would influence the optimal solution too much the cost structure that was applied to the model represents the simplest approach to the cost of surveillance by assuming that the cost of surveying will increase linearly with effort there are however other cost structures that would result in different scenarios and potentially different outcomes or prioritisation of sites our case study explored a scenario where cameras were left out for a set amount of time and assuming that processing costs were linearly related to this ie leaving the cameras out for longer resulting in more images collected and therefore more processing costs for some survey methods each survey may entail a differing cost structure such as the case of surveys that move on to a different site after the detection of the target is made for example presence only spotlighting surveys or thermal imaging although removal design is not as simple for camera surveys due to logistical constraints mackenzie and royle 2005 guillera arroita and lahoz monfort 2017 it would be of benefit to field test the optimal solutions determined by the analysis to evaluate the usefulness of applying these methods based on the optimal solution the expected number of sites with detections can be calculated this can then be tested through conducting the survey following the protocols determined by the solution if the expected number of sites with detections is reached then the optimal solution may be the most appropriate surveillance method for the survey it is however possible that this may happen by chance to determine the benefit of the analysis the key would be to determine whether the optimal solution works better than an alternative and whether the benefit of the optimal solution relative to the alternative is realised by utilising the optimal solution researchers can ensure that they are making the most of their conservation budgets which are often limited especially in the context of protecting threatened species the current ari survey protocols for leadbeater s possum are close to the optimal conditions for the survey objective which is detection of the species to establish zones of habitat protection whilst the models were tested on a camera trapping case study they are general solutions and can be used for optimisation of survey methods for any surveillance activities credit authorship contribution statement kevin d newman conceptualization methodology validation formal analysis writing original draft writing review editing visualisation jenny l nelson resources data curation writing review editing louise k durkin resources data curation writing review editing jemma k cripps resources data curation writing review editing michael a mccarthy supervision conceptualization methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data full mathematical solutions proofs and an explanation of the lambert w function are available as supplementary material supplementary material related to this article can be found online at https doi org 10 1016 j ecolmodel 2022 110117 appendix b supplementary data the following is the supplementary material related to this article mmc s1 
24338,species with temperature dependent sex determination tsd can experience biased sex ratios in natural conditions which raises questions the vulnerability of populations in the face of climate change studies addressing the adaptive significance tsd have been hampered by the difficulty of accurately estimating sex ratios under natural incubation conditions here we introduce the thermal reaction norm for sexualization a novel concept measuring the strength of masculinization or feminization of temperatures to model the effect of temperature for sex determination in tsd species we use hatchling sex ratio data and field incubation temperatures collected between 2002 and 2018 at a globally important loggerhead turtle caretta caretta nesting rookery the new parametrization makes possible the understanding of how temperature sensitive sex determination works we show that the temperature could influence the sexualization of the gonad earlier than what is currently recognized additionally we explore the results of several easy to implement proxies that have been used in literature our approach greatly outperforms previous ones in sex ratio prediction our results should help further studies to refine population wide primary sex ratio estimates of reptiles with tsd to adapt current conservation strategies and develop them in the future keywords climate change phenotypic plasticity embryonic development growth rate ectotherm incubation turtle sex ratio data availability data will be made available on request 1 introduction temperature dependent sex determination tsd in reptiles has fascinated several generations of researchers since it was first described in an agamid lizard charnier 1966 and later in turtles pieau 1972 when tsd occurs the sexual phenotype depends on environmental temperature experienced during embryonic development instead of being determined by genetic material as in genotypic sex determination gsd tsd is widespread among many non avian reptiles with all studied crocodilians exhibiting tsd along with the extant species of tuatara most chelonians and many lizards janzen and krenz 2004 in the nearly 60 years since the discovery of tsd progress has been made in understanding the interplay between hormones and temperatures to determine the sexual phenotype pieau and dorizzi 2004 and more recently the molecular pathways that control sex determination ge et al 2018 rhen and schroeder 2017 in contrast the evolutionary significance and the ecological consequences of tsd remain elusive girondot and pieau 1999 shine 1999 the occurrence of tsd is puzzling because it may constrain individuals to produce biased primary sex ratios hulin et al 2008 while it is known that in a large population natural selection favors individuals that allocate equally to both sexes fisher 1929 a hypothesis was proposed to explain the selection for tsd based on an interaction between sex and temperature in their effect on fitness charnov and bull 1977 or more recently based on demographic difference in age at maturity schwanz et al 2016 one of the main problems encountered in the study of the evolutionary significance and the ecological consequences of tsd is the lack of accurate and representative regional and population sex ratio estimates indeed having acceptable information on a life history trait in hand before addressing its biological implications is crucial the patterns of tsd reflect the relationships between constant incubation temperatures and sex ratios godfrey et al 2003 the pattern is technically the thermal reaction norm for sex ratio abreu grobois et al 2020 most turtles exhibit a cooler temperature male warmer female pattern of tsd the temperature that theoretically produces 50 of each sex is termed the pivotal temperature p and the range of temperatures that produce both sexes is termed the transitional range of temperatures trt mrosovsky and pieau 1991 given that p and trt are defined for constant incubation temperatures only mean incubation temperatures cannot be considered reliable for sex ratio prediction when temperature fluctuates in other words a more biologically relevant proxy must be used to predict the sex ratio of natural clutches fuentes et al 2017 to link sex ratio with temperatures under natural conditions several proxies have been proposed that can be grouped in two types 1 proxies based on incubation duration 2 proxies based on conversion of temperatures recorded in the nest into a constant temperature equivalent cte that predicts the sex ratio when projected onto the species or population specific pattern of tsd the use of incubation duration proxies type 1 relies on the observation that warmer incubation temperatures are correlated with a shorter incubation time however this correlation may be weak because temperature increases growth rate during all of incubation whereas it only affects sex determination during a specific period of development termed the thermosensitive period of development for sex determination tsp furthermore a sub lethal effect of high temperatures exists so that incubation may be prolonged at high albeit very feminizing temperatures incubation duration was widely used for predicting nest sex ratios since mrosovsky et al 1999 observed a high correlation r 0 85 between incubation duration and sex ratio the success of this method was based on the ease of incubation monitoring as compared to the gold standard of gonad histology but incubation duration has been shown to be one of the least reliable among a dozen tested fuentes et al 2017 intrinsic and extrinsic factors considered to convert fluctuating temperatures into a cte proxies type 2 can be very diverse fuentes et al 2017 to date the most refined cte model includes a thermal reaction norm of embryo and gonadal growth and cytochrome p450 aromatase activity in the freshwater turtle emys orbicularis for which the largest amount of embryological and molecular data is available girondot et al 2010 in most other species available information to populate the model is limited to the pattern of tsd at constant temperature abreu grobois et al 2020 and the thermal reaction norm of embryonic growth girondot and kaska 2014 these ctes are then converted into sex ratios by using the pattern of tsd determined at constant temperature when the tsd pattern is used these methods make the hypothesis that the feminizing effect is the same for any temperature high enough to yield 100 females at constant incubation temperature however it was demonstrated that the structure of ovaries of e orbicularis incubated at 35 c is somewhat different from those incubated at 30 c the cortex has more epithelial cells resulting from the multiplication germinal epithelial cells which is a criterion for stronger feminization of the gonad pieau 1978 while both 30 c and 35 c yield 100 females in this species girondot 1999 conversely when incubating at male producing temperatures a lower pharmacologic dose of estrogen is required to produce female hatchlings at 28 c than at 26 c in trachemys scripta wibbels et al 1991 contrary to the hypothetical basis of previous cte proxies these results indicate that the effect of temperature is a dose dependent phenomenon even when incubation occurs at 100 masculinizing or 100 feminizing incubation temperatures for these reasons if current cte models are all able to give a statistically significant correlation between predicted and observed sex ratios nevertheless they are suboptimal to explore new proxies here we take advantage of the availability of an exceptional database linking the temperature recorded in 151 caretta caretta nests with the verified sex of around 10 individuals from 142 of these nests we define several new weighting schemes to describe the sexualization of the gonad the thermal reaction norm for sexualization trns depicts the strength of feminization or masculinization effect for each temperature beyond its effect on growth the sensitivity of sexualization within the thermosensitive period of development for sex determination s tsp depicts the idea that the effect of temperature may vary within the tsp for example stronger effect at the beginning the middle or the end of the tsp furthermore we allow tsp location and duration to vary we fit the parameters defining the trns the s tsp and the limits of tsp to best describe observed sex ratios and we evaluate how these new proxies efficiently predict sex ratio compared to classical ones 2 materials and methods 2 1 temperature dependent sex determination pattern the temperature dependent sex determination tsd pattern describes the link between sex ratio and incubation temperature t it is estimated using experiments in which a set of eggs is incubated at various constant temperatures and the sex of hatchlings is determined using histology or analysis of gonads this relationship is modeled as a logistic function of sex ratio proportion of males that goes from 0 to 1 or reversely for proportion of females abreu grobois et al 2020 1 s r t 1 e s 1 p t 1 with t being the constant temperature of incubation p being pivotal temperature and the slope at t p being 1 4 s the s and p parameters are fitted using maximum likelihood with a binomial distribution for the observed number of males and females at each constant temperature we use a gaussian prior for p n 30 2 and a uniform prior for s u 100 100 data of constant temperature incubation experiments of c caretta eggs from the east coast of usa the same regional management unit as the monitored wild nests wallace et al 2010 were retrieved from the literature mrosovsky 1988 yntema and mrosovsky 1980 1982 the database with constant incubation temperatures and sex ratio for c caretta are included in the r package embryogrowth girondot 2021 2 2 sex ratios from natural nests temperatures were recorded during the total incubation for 151 loggerhead nests at six nesting beaches in florida usa between 2002 and 2018 hobo h8 temperature loggers accuracy 0 5 c resolution 0 4 c prior to 2006 and hobo u22 001 temperature dataloggers accuracy 0 2 c resolution 0 02 c onset computer corp bourne ma usa were placed in the middle of the clutch 45 cm deep and set to record temperatures at a frequency no less than hourly supplementary table s1 we were able to sample 1 to 33 turtles from 142 of these nests median 10 n 1315 they were raised for several months in seawater tanks until they reached a sufficient size for safe laparoscopy as described by wyneken et al 2007 post hatchlings were released offshore one week or more after sex identification we did not examine the gonads of any dead hatchlings from these nests a subset of the laparoscopically sexed turtles were biopsied further ensuring sex verification was consistent and correct the relationship between observed sex ratio and incubation duration average incubation temperature during the total incubation of during the middle third incubation duration was fitted using the same procedure as the pattern of sex determination see previous section 2 3 model for growth of embryos in natural nests we modeled the progression of the size of loggerhead embryos throughout incubation using an embryonic growth model that combines the thermal reaction norm for growth rate and a growth function fuentes et al 2017 girondot and kaska 2014 this model was fitted using maximum likelihood to best describe the observed straight carapace length scl of hatchlings according to nest temperature time series girondot and kaska 2014 biological temperature dependent reaction norms based on arrhenius and eyring s equations were formulated by schoolfield et al 1981 2 r t ρ 298 k t 298 e x p δ h a r 1 298 1 t 1 e x p δ h h r 1 t 1 2 h 1 t t being the temperature in k 298 k 24 85 c r t the development rate at temperature t time 1 r the universal gas constant j k 1 mol 1 δ h a the enthalpy of activation of the reaction catalyzed by the enzymes j mol 1 and δ h h the change in enthalpy associated with the high temperature inactivation of the enzymes j mol 1 the growth of embryos was modeled using a modification of the gompertz model proposed by laird 1964 let x 0 being the embryo size or mass at nesting time time 0 r t being the growth rate and s being the asymptotic size with lim t x t k 3 x t k e x p l n x 0 k e x p r t t note that hatching occurs generally before the time when the embryo reaches a size or mass k the k parameter can be viewed here simply as a way to account for slower growth at the end of incubation girondot and kaska 2014 parameters x 0 0 34 mm se 0 19 mm and k 47 mm se 3 59 mm and then rk k scl at emergence 1 209 were determined based on c caretta developmental table girondot et al 2018 parameters ρ 298 k were fitted using field incubation temperatures n 151 nests along with measures of the scl of hatchlings the scl mean 43 10 mm sd 1 86 of 202 hatchlings 110 in 2013 and 92 in 2016 was measured from several nests that incubated at the nesting beach in boca raton florida latitude 26 3617 n longitude 80 0695 w wgs 84 2 4 sexualization models the thermal reaction norm for sexualization trns links incubation temperature during the tsp and molecular mechanisms that determine sexualization of the developing embryo we model the trns using the general equation describing thermal reaction norms in development eq 1 schoolfield et al 1981 the sensitivity of sexualization during the thermosensitive period of development for sex determination s tsp is modeled as the density of a beta distribution b t s h a p e 1 s h a p e 2 with 0 t 1 and shape1 0 and shape2 0 the time t 0 is the beginning of tsp and t 1 is the end of tsp the use of a beta distribution has no mathematical justification but it has an ideal shape to model the influence of temperature during the tsp it can have different shapes like u n j or l with large flexibility depending on the values of the two parameters shape1 and shape2 the limits of the tsp vary depending on the values of the two parameters begintsp and endtsp with begintsp endtsp with scl at begin and end of tsp being b e g i n t s p s c l h a t c h i n g and e n d t s p s c l h a t c h i n g respectively the parameters of the sexualization models are obtained by fitting observed sex ratios with estimated sex ratio obtained by conversion of the recorded temperatures in natural nests into cte using the weighting scheme termed w hereafter cte w t t t begi ntsp endt sp t t δ time grow thra te t t trns t t s tsp t t begi ntsp endt sp δ time grow thra te t t trns t t s tsp t the sex ratio is then sr cte as given by eq 1 2 5 sex ratio proxies the different sex ratio proxies are classified depending on several criteria first is the delimitation of the thermosensitive period of development for sex determination that is either the period between 21 1 to 70 2 of final hatchling size or a fitted beginning and end of tsp using the parameters begintsp and endtsp second is the weighting scheme applied to temperatures during the chosen tsp either time growth rate the fitted trns or s tsp weighting scheme the weighting scheme can also be designed to integrate all these components third is the way the weighting scheme named w is applied which can be i to temperatures during the tsp producing a constant temperature equivalent cte that is converted into one sex ratio estimate using the pattern of sex determination eq 1 t t w t t c t e s r c t e p r e d i c t e d s e x r a t i o or ii iteratively to each temperature within the tsp to produce a series of sex ratio estimates that then are averaged using a weighting scheme to produce a probability of masculinization pm massey et al 2019 t t s r t t w s r t t p m p r e d i c t e d s e x r a t i o 2 6 parameterization the different parameters are first fitted using maximum likelihood the distribution of the output is a binomial distribution for the observed sex ratios and a gaussian distribution for the hatchling size for the tsd pattern and embryo growth thermal reaction norm confidence intervals are modeled with bayesian estimates using metropolis hastings algorithm hastings 1970 metropolis et al 1953 and a monte carlo markov chain mcmc with priors large enough not to constrain the posterior distribution the burn in value and number of iterations were defined after an initial run of 10 000 iterations raftery and lewis 1992 100 000 and 10 000 iterations were chosen for tsd pattern and embryo growth respectively convergence and stability of the total run were tested following heidelberger and welch 1983 standard errors for sexualization parameters trns s tsp begintsp and endtsp were evaluated using square root of the inverse of the hessian matrix running metropolis hastings algorithm with mcmc required a month time 2 7 model comparison after models are fitted using the same dataset they are compared using akaike information criterion corrected for small samples aicc burnham and anderson 2002 the akaike weight of a given model is the probability that it generated the observations among all model tested burnham and anderson 2002 models with aicc 2 are considered as competing models we also calculate the scaled r2 nagelkerke 1991 to measure the resemblance of observed and modelled sex ratios or observed sex ratios and the average incubation temperature or the incubation duration it should be noted that model selection is based on aicc and not on r2 all statistical analyses and modeling were performed using r 4 1 1 r core team 2021 with embryogrowth 8 2 package girondot 2021 3 results 3 1 tsd pattern and thermal reaction norm for embryo growth sex ratios obtained from incubation of 577 loggerhead turtle c caretta eggs from atlantic northwest regional management unit rmu wallace et al 2010 at 15 different constant temperatures were extracted from the literature mrosovsky 1988 yntema and mrosovsky 1980 1982 and used to fit the pattern of tsd fig 1 the pivotal temperature of fitted tsd patterns is 28 94 c 95 credible interval 28 80 29 07 c the lower limit of the trt5 is 27 07 c 95 credible interval 26 97 27 41 c and the upper limit of the trt5 is 30 82 c 95 credible interval 30 49 31 15 c the thermal reaction norm for embryo growth was fitted using temperature data in 151 natural nests from the same rookery the growth rate increases with temperature and reaches its maximum at 32 33 c fig 2 3 2 sex ratio proxies the sex ratio was available for 142 natural nests with 1314 sexed individuals the range of sexed individuals per nest is from 1 to 33 with a median of 10 the sex ratio is correlated with average nest incubation temperature r2 0 41 average nest incubation temperature during middle third of incubation r2 0 39 and incubation duration r2 0 33 table 1 alternative proxies of observed sex ratios have been sought the performance of each tested model for describing the observations are shown in table 1 models using cte perform better than those using pm the models that fit the tsp limits perform better than those that fix them at 21 1 and 70 2 of final hatchling size models with fitted tsp limits including both a thermal reaction norm of sexualization trns and a varying sensitivity of sexualization within the tsp s tsp are the best among those compared table 1 fig 3 shows the observed sex ratios relative to those predicted by the selected model scaled r2 0 84 the adjusted tsp is between 2 92 mm 2 89 2 95 and 24 09 mm 23 75 24 42 scl fig 4 incubation temperatures within the adjusted tsp are converted into a cte using the trns fig 5 and s tsp weighting schemes fig 4 the temperature that has the highest contribution to the weighting scheme is 30 1 c fig 5 the selected model named here trns tsp s tsp is the best by far as indicated by a aicc 32 85 when compared to the second best one 4 discussion primary sex ratio is an important life history parameter that must be investigated to describe population dynamics of species with temperature dependent sex determination tsd it permits assessing species vulnerability under current and future climate change constraints because an increase in incubation temperatures may jeopardize the production of both sexes patrício et al 2021 to predict hatchling sex ratio indirect methods using temperature based proxies are particularly convenient when the species of interest is not externally sexually dimorphic prior adult stage the new methods developed for the present study integrate the effect of thermal fluctuations on embryonic sex determination and predict sex ratios with much better accuracy than prior models investigating the thermal reaction norm for sexualization among reptiles with tsd will help to provide ecologically relevant hatchling sex ratio estimates and evaluate the viability of populations in the context of climate change additionally our results offer new insights into the mechanisms at play during temperature dependent sex determination previous methods namely the mean temperature either within the middle third of incubation or within the thermosensitive period tsp of development for sex determination the probability of masculinization pm and incubation duration yield largely inaccurate sex ratio predictions table 1 our new approach describes nest sex ratios with much greater accuracy r2 0 84 and should prove useful to estimate ecologically meaningful primary sex ratios it should be noted however that r2 alone is not a correct measure of the quality of fit it can be easily understood with a simple example let the observed sex ratios be 0 0 5 1 and the predicted ones be 1 0 5 0 or 0 2 0 5 0 8 in either case the coefficient of determination will be r2 1 whereas both predictions are wrong the correct solution is to use aicc statistics as it relies directly on the likelihood of the observations number of males and females according to different models results based on the comparison of aiccs indicate that our new model introducing the thermal reaction norm for sexualization trns and the sensitivity of sexualization within the tsp s tsp provides better sex ratio estimates than previous methods for c caretta same conclusion is reached if the 3 most masculinized nests are removed from the analyses table s2 and figure s1 in supplementary information it could be similar for other reptiles with tsd because similar molecular determinants and enzymatic mechanisms are at play radhakrishnan et al 2018 the position of the tsp was classically studied using temperature shifts between constant temperatures from these experiments it was concluded that tsp roughly occurs during the middle third of incubation at constant temperatures in all reptiles with tsd studied so far girondot et al 2018 the middle third of incubation at constant temperature 33 66 of incubation duration corresponds in c caretta to a range of embryo sizes that falls between 21 1 and 70 2 of the average size of a freshly emerged hatchling girondot et al 2018 however the power to assess the limits of tsp is dependent on the number of sexed embryos in each experiment our results corroborate previous concerns that the tsp does not match the middle third of incubation when incubation temperatures are not constant and that using the middle third of incubation duration to approximate the tsp substantially decreases the accuracy of sex ratio estimates in natural nests fuentes et al 2017 girondot et al 2018 the bias introduced by such an approximation is expected to be higher as the magnitude of thermal fluctuations increases georges et al 2004 fitting the position of the tsp greatly improves the performance of our model and the position found is somewhat surprising the end of the tsp is concordant with what is known from temperature shift experiments yntema and mrosovsky 1982 but the beginning is much early than expected before the stage when the gonads are formed furthermore the sensitivity of sexualization during tsp shows two peaks when temperature influences the sex determination at the beginning and the end of tsp fig 4 these results suggest a pre gonadogenesis sexual determination that conflicts the traditional view that the biochemical processes leading to sexual differentiation only occur within the gonad pieau and dorizzi 2004 however the pattern that we observe recalls what is described in fish with tsd when temperature sensitive period takes place before the onset of the histological differentiation of the gonads baroiller et al 2009 it is also concordant with sexually dimorphic expression in steroidogenic enzymes in brain development prior to gonad formation observed in the freshwater turtle with tsd t scripta elegans czerwinski et al 2016 it is possible that the criteria classically used to define the tsp using temperature shifts are too stringent and fail to capture a sexual trajectory that is established early or even before gonad development under male or female producing temperatures mork et al 2014 our study is the first to compare the output of the most widely used sex ratio prediction methods to actual sex ratios from natural clutches in turtles given the ethical practical and conservation related issues raised by the sacrifice of turtle hatchlings for gonad examination the use of predictive methods based on temperature recording with sufficient accuracy and resolution are bound to continue to spread in the future we urge further research building upon our study to validate the use of the thermal reaction norm of sexualization as a new link between incubation temperature and sex ratio undertaking such studies require at minimal the following data i in situ or natural like nest temperature profiles during the entire incubation period along with ii consistent hatchling or embryo measurements e g straight carapace length iii sex identification for a subsample of hatchlings from these nests and iv sex ratio data from constant temperature incubation experiments all information being gathered in the same population the recent development of promising sex identification methods tezak et al 2020 should considerably facilitate the access to sex ratio data our study shows a highly significant improvement of models currently used for sex ratio prediction in natural nests by focusing on a thermal reaction norm of sexualization trns given that similar tsd patterns can result from different trns studying the trns may also reveal a hidden source of variation among populations and offer new avenues for future research such avenues include what does the trns look like in type ii tsd species where females are produced at high and low incubation temperatures to what extent is the trns variable among populations and species how does the trns reflect local environmental conditions and help explain pivotal temperature and trt how does the trns evolve in response to natural selection answering these questions should further our understanding of the physiology of sex differentiation in tsd species refine evolutionary hypotheses about this curious but relatively common phenomenon and inform projections regarding the future prospects of imperiled populations author contribution jonathan monsinjon performed a first version of the analyses and wrote the initial version of the manuscript jeanette wyneken conducted the lab experiments and collected the field data marc girondot designed the model that he scripted in r language and performed the final version of the analyses jean michel guillon refined the model and checked for internal consistency of the methods all authors contributed to write the final version of the manuscript correspondence and requests for biological data should be addressed to j w and for statistical modeling to m g declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the gumbo limbo sea turtle program and particularly k rusenko and m d anderson for their essential help the loggerhead sex ratio studies were supported by the national save the sea turtle foundation the nelligan sea turtle research support fund and personal funds the work was conducted under florida marine turtle permit mtp073 to jw and approved by the florida atlantic university iacuc n warriach m young wideroff a lolavar b tezak and the sea turtle lab independent study students who provided essential assistance with this study the authors acknowledge the support of the virtual data initiative run by labex p2io and supported by université paris saclay for providing computing resources on its cloud infrastructure supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110119 appendix supplementary materials image application 1 
24338,species with temperature dependent sex determination tsd can experience biased sex ratios in natural conditions which raises questions the vulnerability of populations in the face of climate change studies addressing the adaptive significance tsd have been hampered by the difficulty of accurately estimating sex ratios under natural incubation conditions here we introduce the thermal reaction norm for sexualization a novel concept measuring the strength of masculinization or feminization of temperatures to model the effect of temperature for sex determination in tsd species we use hatchling sex ratio data and field incubation temperatures collected between 2002 and 2018 at a globally important loggerhead turtle caretta caretta nesting rookery the new parametrization makes possible the understanding of how temperature sensitive sex determination works we show that the temperature could influence the sexualization of the gonad earlier than what is currently recognized additionally we explore the results of several easy to implement proxies that have been used in literature our approach greatly outperforms previous ones in sex ratio prediction our results should help further studies to refine population wide primary sex ratio estimates of reptiles with tsd to adapt current conservation strategies and develop them in the future keywords climate change phenotypic plasticity embryonic development growth rate ectotherm incubation turtle sex ratio data availability data will be made available on request 1 introduction temperature dependent sex determination tsd in reptiles has fascinated several generations of researchers since it was first described in an agamid lizard charnier 1966 and later in turtles pieau 1972 when tsd occurs the sexual phenotype depends on environmental temperature experienced during embryonic development instead of being determined by genetic material as in genotypic sex determination gsd tsd is widespread among many non avian reptiles with all studied crocodilians exhibiting tsd along with the extant species of tuatara most chelonians and many lizards janzen and krenz 2004 in the nearly 60 years since the discovery of tsd progress has been made in understanding the interplay between hormones and temperatures to determine the sexual phenotype pieau and dorizzi 2004 and more recently the molecular pathways that control sex determination ge et al 2018 rhen and schroeder 2017 in contrast the evolutionary significance and the ecological consequences of tsd remain elusive girondot and pieau 1999 shine 1999 the occurrence of tsd is puzzling because it may constrain individuals to produce biased primary sex ratios hulin et al 2008 while it is known that in a large population natural selection favors individuals that allocate equally to both sexes fisher 1929 a hypothesis was proposed to explain the selection for tsd based on an interaction between sex and temperature in their effect on fitness charnov and bull 1977 or more recently based on demographic difference in age at maturity schwanz et al 2016 one of the main problems encountered in the study of the evolutionary significance and the ecological consequences of tsd is the lack of accurate and representative regional and population sex ratio estimates indeed having acceptable information on a life history trait in hand before addressing its biological implications is crucial the patterns of tsd reflect the relationships between constant incubation temperatures and sex ratios godfrey et al 2003 the pattern is technically the thermal reaction norm for sex ratio abreu grobois et al 2020 most turtles exhibit a cooler temperature male warmer female pattern of tsd the temperature that theoretically produces 50 of each sex is termed the pivotal temperature p and the range of temperatures that produce both sexes is termed the transitional range of temperatures trt mrosovsky and pieau 1991 given that p and trt are defined for constant incubation temperatures only mean incubation temperatures cannot be considered reliable for sex ratio prediction when temperature fluctuates in other words a more biologically relevant proxy must be used to predict the sex ratio of natural clutches fuentes et al 2017 to link sex ratio with temperatures under natural conditions several proxies have been proposed that can be grouped in two types 1 proxies based on incubation duration 2 proxies based on conversion of temperatures recorded in the nest into a constant temperature equivalent cte that predicts the sex ratio when projected onto the species or population specific pattern of tsd the use of incubation duration proxies type 1 relies on the observation that warmer incubation temperatures are correlated with a shorter incubation time however this correlation may be weak because temperature increases growth rate during all of incubation whereas it only affects sex determination during a specific period of development termed the thermosensitive period of development for sex determination tsp furthermore a sub lethal effect of high temperatures exists so that incubation may be prolonged at high albeit very feminizing temperatures incubation duration was widely used for predicting nest sex ratios since mrosovsky et al 1999 observed a high correlation r 0 85 between incubation duration and sex ratio the success of this method was based on the ease of incubation monitoring as compared to the gold standard of gonad histology but incubation duration has been shown to be one of the least reliable among a dozen tested fuentes et al 2017 intrinsic and extrinsic factors considered to convert fluctuating temperatures into a cte proxies type 2 can be very diverse fuentes et al 2017 to date the most refined cte model includes a thermal reaction norm of embryo and gonadal growth and cytochrome p450 aromatase activity in the freshwater turtle emys orbicularis for which the largest amount of embryological and molecular data is available girondot et al 2010 in most other species available information to populate the model is limited to the pattern of tsd at constant temperature abreu grobois et al 2020 and the thermal reaction norm of embryonic growth girondot and kaska 2014 these ctes are then converted into sex ratios by using the pattern of tsd determined at constant temperature when the tsd pattern is used these methods make the hypothesis that the feminizing effect is the same for any temperature high enough to yield 100 females at constant incubation temperature however it was demonstrated that the structure of ovaries of e orbicularis incubated at 35 c is somewhat different from those incubated at 30 c the cortex has more epithelial cells resulting from the multiplication germinal epithelial cells which is a criterion for stronger feminization of the gonad pieau 1978 while both 30 c and 35 c yield 100 females in this species girondot 1999 conversely when incubating at male producing temperatures a lower pharmacologic dose of estrogen is required to produce female hatchlings at 28 c than at 26 c in trachemys scripta wibbels et al 1991 contrary to the hypothetical basis of previous cte proxies these results indicate that the effect of temperature is a dose dependent phenomenon even when incubation occurs at 100 masculinizing or 100 feminizing incubation temperatures for these reasons if current cte models are all able to give a statistically significant correlation between predicted and observed sex ratios nevertheless they are suboptimal to explore new proxies here we take advantage of the availability of an exceptional database linking the temperature recorded in 151 caretta caretta nests with the verified sex of around 10 individuals from 142 of these nests we define several new weighting schemes to describe the sexualization of the gonad the thermal reaction norm for sexualization trns depicts the strength of feminization or masculinization effect for each temperature beyond its effect on growth the sensitivity of sexualization within the thermosensitive period of development for sex determination s tsp depicts the idea that the effect of temperature may vary within the tsp for example stronger effect at the beginning the middle or the end of the tsp furthermore we allow tsp location and duration to vary we fit the parameters defining the trns the s tsp and the limits of tsp to best describe observed sex ratios and we evaluate how these new proxies efficiently predict sex ratio compared to classical ones 2 materials and methods 2 1 temperature dependent sex determination pattern the temperature dependent sex determination tsd pattern describes the link between sex ratio and incubation temperature t it is estimated using experiments in which a set of eggs is incubated at various constant temperatures and the sex of hatchlings is determined using histology or analysis of gonads this relationship is modeled as a logistic function of sex ratio proportion of males that goes from 0 to 1 or reversely for proportion of females abreu grobois et al 2020 1 s r t 1 e s 1 p t 1 with t being the constant temperature of incubation p being pivotal temperature and the slope at t p being 1 4 s the s and p parameters are fitted using maximum likelihood with a binomial distribution for the observed number of males and females at each constant temperature we use a gaussian prior for p n 30 2 and a uniform prior for s u 100 100 data of constant temperature incubation experiments of c caretta eggs from the east coast of usa the same regional management unit as the monitored wild nests wallace et al 2010 were retrieved from the literature mrosovsky 1988 yntema and mrosovsky 1980 1982 the database with constant incubation temperatures and sex ratio for c caretta are included in the r package embryogrowth girondot 2021 2 2 sex ratios from natural nests temperatures were recorded during the total incubation for 151 loggerhead nests at six nesting beaches in florida usa between 2002 and 2018 hobo h8 temperature loggers accuracy 0 5 c resolution 0 4 c prior to 2006 and hobo u22 001 temperature dataloggers accuracy 0 2 c resolution 0 02 c onset computer corp bourne ma usa were placed in the middle of the clutch 45 cm deep and set to record temperatures at a frequency no less than hourly supplementary table s1 we were able to sample 1 to 33 turtles from 142 of these nests median 10 n 1315 they were raised for several months in seawater tanks until they reached a sufficient size for safe laparoscopy as described by wyneken et al 2007 post hatchlings were released offshore one week or more after sex identification we did not examine the gonads of any dead hatchlings from these nests a subset of the laparoscopically sexed turtles were biopsied further ensuring sex verification was consistent and correct the relationship between observed sex ratio and incubation duration average incubation temperature during the total incubation of during the middle third incubation duration was fitted using the same procedure as the pattern of sex determination see previous section 2 3 model for growth of embryos in natural nests we modeled the progression of the size of loggerhead embryos throughout incubation using an embryonic growth model that combines the thermal reaction norm for growth rate and a growth function fuentes et al 2017 girondot and kaska 2014 this model was fitted using maximum likelihood to best describe the observed straight carapace length scl of hatchlings according to nest temperature time series girondot and kaska 2014 biological temperature dependent reaction norms based on arrhenius and eyring s equations were formulated by schoolfield et al 1981 2 r t ρ 298 k t 298 e x p δ h a r 1 298 1 t 1 e x p δ h h r 1 t 1 2 h 1 t t being the temperature in k 298 k 24 85 c r t the development rate at temperature t time 1 r the universal gas constant j k 1 mol 1 δ h a the enthalpy of activation of the reaction catalyzed by the enzymes j mol 1 and δ h h the change in enthalpy associated with the high temperature inactivation of the enzymes j mol 1 the growth of embryos was modeled using a modification of the gompertz model proposed by laird 1964 let x 0 being the embryo size or mass at nesting time time 0 r t being the growth rate and s being the asymptotic size with lim t x t k 3 x t k e x p l n x 0 k e x p r t t note that hatching occurs generally before the time when the embryo reaches a size or mass k the k parameter can be viewed here simply as a way to account for slower growth at the end of incubation girondot and kaska 2014 parameters x 0 0 34 mm se 0 19 mm and k 47 mm se 3 59 mm and then rk k scl at emergence 1 209 were determined based on c caretta developmental table girondot et al 2018 parameters ρ 298 k were fitted using field incubation temperatures n 151 nests along with measures of the scl of hatchlings the scl mean 43 10 mm sd 1 86 of 202 hatchlings 110 in 2013 and 92 in 2016 was measured from several nests that incubated at the nesting beach in boca raton florida latitude 26 3617 n longitude 80 0695 w wgs 84 2 4 sexualization models the thermal reaction norm for sexualization trns links incubation temperature during the tsp and molecular mechanisms that determine sexualization of the developing embryo we model the trns using the general equation describing thermal reaction norms in development eq 1 schoolfield et al 1981 the sensitivity of sexualization during the thermosensitive period of development for sex determination s tsp is modeled as the density of a beta distribution b t s h a p e 1 s h a p e 2 with 0 t 1 and shape1 0 and shape2 0 the time t 0 is the beginning of tsp and t 1 is the end of tsp the use of a beta distribution has no mathematical justification but it has an ideal shape to model the influence of temperature during the tsp it can have different shapes like u n j or l with large flexibility depending on the values of the two parameters shape1 and shape2 the limits of the tsp vary depending on the values of the two parameters begintsp and endtsp with begintsp endtsp with scl at begin and end of tsp being b e g i n t s p s c l h a t c h i n g and e n d t s p s c l h a t c h i n g respectively the parameters of the sexualization models are obtained by fitting observed sex ratios with estimated sex ratio obtained by conversion of the recorded temperatures in natural nests into cte using the weighting scheme termed w hereafter cte w t t t begi ntsp endt sp t t δ time grow thra te t t trns t t s tsp t t begi ntsp endt sp δ time grow thra te t t trns t t s tsp t the sex ratio is then sr cte as given by eq 1 2 5 sex ratio proxies the different sex ratio proxies are classified depending on several criteria first is the delimitation of the thermosensitive period of development for sex determination that is either the period between 21 1 to 70 2 of final hatchling size or a fitted beginning and end of tsp using the parameters begintsp and endtsp second is the weighting scheme applied to temperatures during the chosen tsp either time growth rate the fitted trns or s tsp weighting scheme the weighting scheme can also be designed to integrate all these components third is the way the weighting scheme named w is applied which can be i to temperatures during the tsp producing a constant temperature equivalent cte that is converted into one sex ratio estimate using the pattern of sex determination eq 1 t t w t t c t e s r c t e p r e d i c t e d s e x r a t i o or ii iteratively to each temperature within the tsp to produce a series of sex ratio estimates that then are averaged using a weighting scheme to produce a probability of masculinization pm massey et al 2019 t t s r t t w s r t t p m p r e d i c t e d s e x r a t i o 2 6 parameterization the different parameters are first fitted using maximum likelihood the distribution of the output is a binomial distribution for the observed sex ratios and a gaussian distribution for the hatchling size for the tsd pattern and embryo growth thermal reaction norm confidence intervals are modeled with bayesian estimates using metropolis hastings algorithm hastings 1970 metropolis et al 1953 and a monte carlo markov chain mcmc with priors large enough not to constrain the posterior distribution the burn in value and number of iterations were defined after an initial run of 10 000 iterations raftery and lewis 1992 100 000 and 10 000 iterations were chosen for tsd pattern and embryo growth respectively convergence and stability of the total run were tested following heidelberger and welch 1983 standard errors for sexualization parameters trns s tsp begintsp and endtsp were evaluated using square root of the inverse of the hessian matrix running metropolis hastings algorithm with mcmc required a month time 2 7 model comparison after models are fitted using the same dataset they are compared using akaike information criterion corrected for small samples aicc burnham and anderson 2002 the akaike weight of a given model is the probability that it generated the observations among all model tested burnham and anderson 2002 models with aicc 2 are considered as competing models we also calculate the scaled r2 nagelkerke 1991 to measure the resemblance of observed and modelled sex ratios or observed sex ratios and the average incubation temperature or the incubation duration it should be noted that model selection is based on aicc and not on r2 all statistical analyses and modeling were performed using r 4 1 1 r core team 2021 with embryogrowth 8 2 package girondot 2021 3 results 3 1 tsd pattern and thermal reaction norm for embryo growth sex ratios obtained from incubation of 577 loggerhead turtle c caretta eggs from atlantic northwest regional management unit rmu wallace et al 2010 at 15 different constant temperatures were extracted from the literature mrosovsky 1988 yntema and mrosovsky 1980 1982 and used to fit the pattern of tsd fig 1 the pivotal temperature of fitted tsd patterns is 28 94 c 95 credible interval 28 80 29 07 c the lower limit of the trt5 is 27 07 c 95 credible interval 26 97 27 41 c and the upper limit of the trt5 is 30 82 c 95 credible interval 30 49 31 15 c the thermal reaction norm for embryo growth was fitted using temperature data in 151 natural nests from the same rookery the growth rate increases with temperature and reaches its maximum at 32 33 c fig 2 3 2 sex ratio proxies the sex ratio was available for 142 natural nests with 1314 sexed individuals the range of sexed individuals per nest is from 1 to 33 with a median of 10 the sex ratio is correlated with average nest incubation temperature r2 0 41 average nest incubation temperature during middle third of incubation r2 0 39 and incubation duration r2 0 33 table 1 alternative proxies of observed sex ratios have been sought the performance of each tested model for describing the observations are shown in table 1 models using cte perform better than those using pm the models that fit the tsp limits perform better than those that fix them at 21 1 and 70 2 of final hatchling size models with fitted tsp limits including both a thermal reaction norm of sexualization trns and a varying sensitivity of sexualization within the tsp s tsp are the best among those compared table 1 fig 3 shows the observed sex ratios relative to those predicted by the selected model scaled r2 0 84 the adjusted tsp is between 2 92 mm 2 89 2 95 and 24 09 mm 23 75 24 42 scl fig 4 incubation temperatures within the adjusted tsp are converted into a cte using the trns fig 5 and s tsp weighting schemes fig 4 the temperature that has the highest contribution to the weighting scheme is 30 1 c fig 5 the selected model named here trns tsp s tsp is the best by far as indicated by a aicc 32 85 when compared to the second best one 4 discussion primary sex ratio is an important life history parameter that must be investigated to describe population dynamics of species with temperature dependent sex determination tsd it permits assessing species vulnerability under current and future climate change constraints because an increase in incubation temperatures may jeopardize the production of both sexes patrício et al 2021 to predict hatchling sex ratio indirect methods using temperature based proxies are particularly convenient when the species of interest is not externally sexually dimorphic prior adult stage the new methods developed for the present study integrate the effect of thermal fluctuations on embryonic sex determination and predict sex ratios with much better accuracy than prior models investigating the thermal reaction norm for sexualization among reptiles with tsd will help to provide ecologically relevant hatchling sex ratio estimates and evaluate the viability of populations in the context of climate change additionally our results offer new insights into the mechanisms at play during temperature dependent sex determination previous methods namely the mean temperature either within the middle third of incubation or within the thermosensitive period tsp of development for sex determination the probability of masculinization pm and incubation duration yield largely inaccurate sex ratio predictions table 1 our new approach describes nest sex ratios with much greater accuracy r2 0 84 and should prove useful to estimate ecologically meaningful primary sex ratios it should be noted however that r2 alone is not a correct measure of the quality of fit it can be easily understood with a simple example let the observed sex ratios be 0 0 5 1 and the predicted ones be 1 0 5 0 or 0 2 0 5 0 8 in either case the coefficient of determination will be r2 1 whereas both predictions are wrong the correct solution is to use aicc statistics as it relies directly on the likelihood of the observations number of males and females according to different models results based on the comparison of aiccs indicate that our new model introducing the thermal reaction norm for sexualization trns and the sensitivity of sexualization within the tsp s tsp provides better sex ratio estimates than previous methods for c caretta same conclusion is reached if the 3 most masculinized nests are removed from the analyses table s2 and figure s1 in supplementary information it could be similar for other reptiles with tsd because similar molecular determinants and enzymatic mechanisms are at play radhakrishnan et al 2018 the position of the tsp was classically studied using temperature shifts between constant temperatures from these experiments it was concluded that tsp roughly occurs during the middle third of incubation at constant temperatures in all reptiles with tsd studied so far girondot et al 2018 the middle third of incubation at constant temperature 33 66 of incubation duration corresponds in c caretta to a range of embryo sizes that falls between 21 1 and 70 2 of the average size of a freshly emerged hatchling girondot et al 2018 however the power to assess the limits of tsp is dependent on the number of sexed embryos in each experiment our results corroborate previous concerns that the tsp does not match the middle third of incubation when incubation temperatures are not constant and that using the middle third of incubation duration to approximate the tsp substantially decreases the accuracy of sex ratio estimates in natural nests fuentes et al 2017 girondot et al 2018 the bias introduced by such an approximation is expected to be higher as the magnitude of thermal fluctuations increases georges et al 2004 fitting the position of the tsp greatly improves the performance of our model and the position found is somewhat surprising the end of the tsp is concordant with what is known from temperature shift experiments yntema and mrosovsky 1982 but the beginning is much early than expected before the stage when the gonads are formed furthermore the sensitivity of sexualization during tsp shows two peaks when temperature influences the sex determination at the beginning and the end of tsp fig 4 these results suggest a pre gonadogenesis sexual determination that conflicts the traditional view that the biochemical processes leading to sexual differentiation only occur within the gonad pieau and dorizzi 2004 however the pattern that we observe recalls what is described in fish with tsd when temperature sensitive period takes place before the onset of the histological differentiation of the gonads baroiller et al 2009 it is also concordant with sexually dimorphic expression in steroidogenic enzymes in brain development prior to gonad formation observed in the freshwater turtle with tsd t scripta elegans czerwinski et al 2016 it is possible that the criteria classically used to define the tsp using temperature shifts are too stringent and fail to capture a sexual trajectory that is established early or even before gonad development under male or female producing temperatures mork et al 2014 our study is the first to compare the output of the most widely used sex ratio prediction methods to actual sex ratios from natural clutches in turtles given the ethical practical and conservation related issues raised by the sacrifice of turtle hatchlings for gonad examination the use of predictive methods based on temperature recording with sufficient accuracy and resolution are bound to continue to spread in the future we urge further research building upon our study to validate the use of the thermal reaction norm of sexualization as a new link between incubation temperature and sex ratio undertaking such studies require at minimal the following data i in situ or natural like nest temperature profiles during the entire incubation period along with ii consistent hatchling or embryo measurements e g straight carapace length iii sex identification for a subsample of hatchlings from these nests and iv sex ratio data from constant temperature incubation experiments all information being gathered in the same population the recent development of promising sex identification methods tezak et al 2020 should considerably facilitate the access to sex ratio data our study shows a highly significant improvement of models currently used for sex ratio prediction in natural nests by focusing on a thermal reaction norm of sexualization trns given that similar tsd patterns can result from different trns studying the trns may also reveal a hidden source of variation among populations and offer new avenues for future research such avenues include what does the trns look like in type ii tsd species where females are produced at high and low incubation temperatures to what extent is the trns variable among populations and species how does the trns reflect local environmental conditions and help explain pivotal temperature and trt how does the trns evolve in response to natural selection answering these questions should further our understanding of the physiology of sex differentiation in tsd species refine evolutionary hypotheses about this curious but relatively common phenomenon and inform projections regarding the future prospects of imperiled populations author contribution jonathan monsinjon performed a first version of the analyses and wrote the initial version of the manuscript jeanette wyneken conducted the lab experiments and collected the field data marc girondot designed the model that he scripted in r language and performed the final version of the analyses jean michel guillon refined the model and checked for internal consistency of the methods all authors contributed to write the final version of the manuscript correspondence and requests for biological data should be addressed to j w and for statistical modeling to m g declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank the gumbo limbo sea turtle program and particularly k rusenko and m d anderson for their essential help the loggerhead sex ratio studies were supported by the national save the sea turtle foundation the nelligan sea turtle research support fund and personal funds the work was conducted under florida marine turtle permit mtp073 to jw and approved by the florida atlantic university iacuc n warriach m young wideroff a lolavar b tezak and the sea turtle lab independent study students who provided essential assistance with this study the authors acknowledge the support of the virtual data initiative run by labex p2io and supported by université paris saclay for providing computing resources on its cloud infrastructure supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110119 appendix supplementary materials image application 1 
24339,the nearshore waters of the laurentian great lakes have historically suffered from beach fouling and clogged water intakes due to proliferation of the native filamentous green alga cladophora a resurgence in nuisance growth of the alga has led to a demand for an improved model platform to better guide management the great lakes cladophora model glcm v3 predicts algal biomass g dry matter m 2 and stored phosphorus content p as of dry matter based on simulations forced by time series of incident light i water temperature t and water column soluble reactive phosphorus concentration srp μgp l 1 a particular strength of the glcm v3 is its foundation in ecologically sound biokinetic mechanisms supported by field and laboratory measurements these measurements advancing the credibility and reliability of the biokinetic framework include improved characterization of the growth and respiration responses to light and temperature addition of a self shading algorithm replacing an overly deterministic carrying capacity term a new treatment of phosphorus uptake based on radioisotope experiments additional observational support for droop based simulation of growth as a function of stored p and implementation of a new physiologically and physically driven sloughing function uncertainty associated with processes collectively termed environmental friction the i t and p growth forcing functions is reduced leaving the model sensitive to the maximum specific growth rate and the coefficient for extinction of photosynthetically active radiation through the algal mat the model was performance tested by multi lake erie huron ontario and michigan calibration employing a common set of biophysical coefficients this common set of calibration coefficients provides enhanced corroboration that glcm v3 is suitable for examining the phosphorus cladophora dynamic across the great lakes in particular it greatly strengthens the model s efficacy for establishing a phosphorus standard to maintain levels of algal biomass below those constituting a nuisance condition as per the great lakes water quality agreement of 2012 in addition the model structure can be applied to other lakes experiencing problems with attached filamentous algae graphical abstract image graphical abstract keywords cladophora laurentian great lakes model parameterization mechanistic modeling calibration growth rate phosphorus uptake sloughing cross site application ecosystem management data availability all data used in this study were either presented in the main manuscript or referenced published elsewhere all model equations and parameter estimates are presented in tables 1 introduction 1 1 balancing math and science dating back to the seminal work of streeter and phelps 1925 mathematical models have played a critical role in the evolution of water quality management key advances in the discipline accompanied the introduction of digital computing and more recently high performance computing chapra 2008 these mathematical revolutions set the stage for a deeper level of spatiotemporal resolution and an attendant improvement of our understanding of biophysical dynamics it is fair to say that the demand for mathematical assets supporting lake modeling has today largely been met the same cannot be said with respect to the development of the biokinetic algorithms and coefficients applied in these models consider the following example exploring the lineage of the maximum specific growth rate coefficient μmax applied in a mass balance model simulating the growth of a single phytoplankton group in lake superior white and matsumoto 2012 the authors cite as their source for μmax the value applied in a similarly purposed model of two phytoplankton groups in lake michigan chen et al 2002 those authors then cite modeling papers by bierman and dolan 1981 saginaw bay lake huron and scavia et al 1988 lake michigan as their source for μmax bierman and dolan 1981 provide the values of µmax used in their work for each of five phytoplankton groups but do not reference sources for that information noting only that coefficient choices were based on the literature scavia et al 1988 working with three phytoplankton groups diatoms flagellates and cyanobacteria indicate that values of μmax used in their model were derived from values of μmax measured by reynolds et al 1982 for flagellates in blelham tarn england by tilman et al 1982 and references therein for diatoms and cyanobacteria in lake michigan lake norrviken sweden lake windermere england and lake ohrid macedonia albania by reynolds 1984a 1984b for diatoms flagellates and cyanobacteria representing selected temperate lakes and sommer 1983 for diatoms and flagellates in lake constance germany switzerland austria this lineage of experimental studies dating back to the 1980s represents work undertaken in what might be termed the golden age of biokinetics chapra 2008 tracing of the origin and curation of a single coefficient established through measurements made in multiple studies and proceeding through four modeling exercises over three decades reveals that contemporary application of the μmax coefficient lies far distant from its origin in time technology and biogeography the challenge to establish coefficient values suitably grounded in measurement preferably specific to the study system remains an issue the distancing of models from their scientific foundation is of particular importance in management applications where a high degree of reliability and credibility must support the economic burdens of control measures based on model predictions chapra 2008 modelers often have the notion that as model complexity increases so too does its ability to fully represent nature and advance the reliability of its predictions but this comes at a price if increases in complexity are not supported by the field and laboratory studies required to credibly parameterize that complexity chapra 2008 the danger then is that the mathematics outpaces the foundation in science and model reliability suffers pauer et al 2018 that danger may only be mitigated by investing resources on the science side of the math science pairing chapra 2008 in this paper we seek to advance the ecological underpinnings of the great lakes cladophora model keeping pace with the math and establishing the credibility and reliability required to support management of nuisance algal growth in the great lakes 1 2 nuisance growth of cladophora a filamentous green alga native to the laurentian great lakes cladophora has been a subject of study for decades if not a century with reports of nuisance growth in lake erie from as early as the 1800s taft and kishler 1973 the alga grows attached to hard lake bottom surfaces such as rocks and boulders and to mussel shells colonising those substrates higgins et al 2008b whitton 1970 cladophora growth occurs seasonally from may to late september or early october with rapid biomass production in may and june a population collapse in summer and modest regrowth in late summer early fall as temperatures cool to once again pass through the optimal range higgins et al 2008a 2008b lorenz and herdendorf 1982 whitton 1970 the summer population collapse results in detachment of algal filaments sloughing with transport deposition and accumulation of algal debris along the shoreline cladophora fouls beaches and water intakes leading to losses of beneficial use at sites along the nearshore of the four lower lakes huron michigan erie and ontario a resurgence in nuisance growth kuczynski et al 2016 has fostered interest in the development and improvement of mathematical models supporting management bootsma et al 2015 the glcm last updated more than a decade ago merits revision to better serve ecosystem management in a dynamic multi stressor environment in addition to hard substrate for attachment cladophora requires specific conditions of temperature and light to initiate and sustain growth graham et al 1982 higgins et al 2006 simply stated temperature regulates the seasonal cycle of growth light mediates the depth of colonization and the limiting nutrient phosphorus p auer and canale 1982b 1982c canale and auer 1982a higgins et al 2008a 2008b neil and owen 1964 painter and kamaitis 1987 determines the maximum biomass both tributary and point source inputs of phosphorus have been identified as nourishing cladophora beds auer et al 1982c higgins et al 2012 with the magnitude and p richness of the discharge as subsequently influenced by mass transport defining the footprint of the area impacted huang et al 2019 auer et al 2021 1 3 phosphorus management in the great lakes pursuant to the mandate of the great lakes water quality agreement of 1972 phosphorus controls were implemented in the form of bans on p in soaps and detergents and limits on p concentrations in wastewater treatment plant wwtp effluents although the primary purpose of these controls was to curb cultural eutrophication in the open lake regulation also reduced reports of nuisance attached algal growth in the nearshore kuczynski et al 2016 levels of biomass density and p nutrition in cladophora decreased from pre p management 1970s to post p management years 1980s painter and kamaitis 1987 with conditions prevailing for 2 3 decades and into the 21st century kuczynski et al 2016 subsequent invasion of the four lower great lakes by dreissenid mussels zebra mussel dreissena polymorpha and quagga mussel dreissena rostriformis bugensis was accompanied by increases in water clarity offshore extension of colonization by cladophora and a resurgence in conditions of nuisance growth kuczynski et al 2016 nuisance conditions have been reported particularly from lakes michigan milwaukee wi and sleeping bear dunes national lakeshore mi and ontario pickering ajax whitby on and rochester ny the most recent great lakes water quality agreement international joint commission ijc 2012 calls for adoption of lake ecosystem objectives that will maintain levels of algal biomass below those constituting a nuisance condition through establishment of substance objectives and loading targets for phosphorus in nearshore and offshore waters 1 4 cladophora models development testing and application of the great lakes cladophora model v1 canale and auer 1982a is presented in a suite of seven papers authored by auer canale and colleagues and published in a special issue of the journal of great lakes research focusing on attached algae these works represent the first attempt to apply a mechanistic mass balance approach in simulating growth of the alga as a function of light temperature and nutrient status the model was applied in simulating the response of algal biomass density to changes in phosphorus loading from a wastewater treatment plant at harbor beach mi on lake huron canale and auer 1982b another platform based on the glcm v1 was developed by higgins 2005a termed the cladophora growth model cgm this framework accommodated the role of light below the algal canopy in mediating growth and the initiation of sloughing a second version of the great lakes cladophora model glcm v2 tomlinson et al 2010 modernized the coding platform added a graphical user interface revised algorithms and coefficients and applied the tool to data sets for lake huron calibration and lake michigan confirmation no field measurements or laboratory analyses were performed in support of glcm v2 development the cgm and the glcm v2 have been used to examine the effects of environmental perturbations on cladophora growth including the potential for climate change induced differences in the temperature regime malkin et al 2008 and increases in water clarity driven by water column filtration by mussels auer et al 2010 kuczynski et al 2016 malkin et al 2008 the mussel mediated resurgence in beach fouling by cladophora reflecting a 6 fold increase in post dreissenid production potential kuczynski et al 2016 their fig 8 has led to a call for improvements in mechanistic modeling of the alga to better inform management objectives bootsma et al 2015 the glcm is based on a mass balance approach where the ability of the alga to realize its maximum specific growth rate is limited by certain sources of environmental friction light temperature and nutrient availability and by sink term processes respiration and sloughing the maximum specific growth rate cannot be measured as cannot the efficiency of the perfect machine thus attention turns to characterization of the algorithms and coefficients describing environmental friction and sink processes shortfalls embedded in a model framework often lie hidden in under parameterization insufficient complexity over parameterization too much complexity and an inability to provide field and or laboratory validation of algorithms and or coefficients the challenge then lies in re examining the model s conceptual framework updating algorithms to better describe environmental friction and sink terms and improving estimates for model coefficients 2 objectives it is not only the passage of time and the evolution of technology that mandate advancement of the scientific foundation upon which glcm mathematics are applied but also the nature of the ecosystem now coinhabited by cladophora and dreissenid mussels hecky et al 2004 howell 2018 invasive dreissenids have had a profound impact on the light environment that impacts not only growth but also the timing of late summer detachment and attendant beach deposition kuczynski et al 2016 mussels have also influenced the nutrient environment by entraining and processing particulate matter releasing a significant fraction of its particulate phosphorus intake as soluble reactive phosphorus srp μgp l 1 ozersky et al 2013 the only form of the nutrient fully and freely available to algae reynolds 2006 thus particulate phosphorus has become a more important feature of the cladophora nutrient environment be it introduced through tributary and point source discharges auer et al 2021 or transported to the nearshore from the offshore zhou et al 2021 while dreissenids are not explicitly accommodated in the glcm they play a significant role in mediating the light and phosphorus forcing conditions that drive growth of the alga and attendant nuisance conditions thus a cladophora model supporting management application must carry a level of biokinetic rigor equal to the task here we present a new version of the great lakes cladophora model glcm v3 responding to the expressed need for development of an upgraded platform supporting phosphorus management bootsma et al 2015 our response focuses on objectives leading to better quantification of environmental friction i e the brakes on the maximum specific growth rate a key but indeterminable coefficient the glcm v3 incorporates features grounded in field observations and laboratory measurements applying ecologically sound mechanisms having utility across all four great lakes colonized by the alga 1 improved characterization of the light and temperature responses for rates of gross photosynthesis and light enhanced respiration 2 revision of the parameterization of phosphorus uptake to reflect the results of radioisotope measurements made at low ecologically meaningful srp levels and for low levels of stored p content 3 additional observations supporting mediation of growth by stored p 4 implementation of a physiologically and physically driven sloughing function based on near bottom current measurements and canopy modeling respectively 5 replacement of an overly deterministic approach for simulating carrying capacity with one using a self regulating canopy shading subroutine and 6 performance testing of the model for each of the four great lakes colonized by the alga in meeting these objectives we seek to establish a uniform set of model coefficients supporting simulation of cladophora biomass and phosphorus densities the resulting tool would be suitable for management applications across the great lakes and perhaps in other settings 3 model development and parameterization a model is an idealized representation of the response of a system to external stimuli model reliability increases as model complexity increases more fully describing the system under study reliability declines however when the conceptual formulation outpaces the understanding of the system arhonditsis et al 2019 chapra 2008 pauer et al 2018 the challenge is to retain model reliability as complexity increases by extending the scientific foundation supporting conceptual development chapra 2008 from its inception as v1 canale and auer 1982a the great lakes cladophora model has been supported by a robust effort to define kinetic relationships through field observations and laboratory measurements the subsequent development of the cladophora growth model cgm higgins 2005a evolution of the glcm v2 tomlinson et al 2010 and work presented here glcm v3 have retained this commitment to a science based foundation supporting the conceptual structure at its core the glcm v3 fig 1 is a mechanistic mass balance model simulating two state variables x the biomass density expressed as dry matter gdm m 2 and s the phosphorus density gp m 2 of the algal mat 1 d x d t μ g r o s s r l x and 2 d s d t ρ x r s l s an additional parameter stored p content also referred to as internal p cellular p tissue p and cell quota is calculated as the quotient of the phosphorus and biomass densities 3 q s x 100 where q stored phosphorus content of the alga gp gdm 1 expressed as net accrual of biomass and phosphorus density in the algal mat is determined as the balance between gains through gross growth for biomass density and p uptake for p density and losses of each to respiration and sloughing a third state variable srp may be accommodated in a linked fashion as a time series of concentrations input to the glcm v3 or by running the model in a coupled fashion within the larger framework of a mass transport phosphorus cladophora model additional details regarding parameterization of eqs 1 and 2 are provided subsequently where the focus lies on advancing the representation of physiological and physical processes in this manuscript we present the findings of field studies and laboratory experiments performed to advance the physiological and physical foundation for algorithms and coefficients driving simulation of cladophora growth a study site description and details of field sampling sample processing and analysis is provided in the supplementary material section 1 details of experimental protocols supporting laboratory measurement of rates of phosphorus uptake and mediation of growth and respiration by stored phosphorus are also provided in the supplementary material section 2 3 1 mediation of growth and respiration by light and temperature mediation of rates of growth and respiration occurs through attenuation of the maximum rate for each by environmental friction sub and supra optimal light intensities water temperatures and srp limitation external forcing conditions thus include seasonal variation in light intensity and water temperature vertical extinction of light through the water column and the algal mat and bioavailable p levels graham et al 1982 performed laboratory measurements of volumetric rates of gross photosynthesis and respiration mg o2 l 1 d 1 by p saturated cladophora over a matrix of light i and temperature t conditions volumetric rates of photosynthesis and respiration were converted to specific rates d 1 by applying the photosynthetic quotient 12 mg c per 32 mg o2 as used by auer and canale 1982c and measured carbon content for the algae samples kuczynski et al 2020 three dimensional response surfaces were then fit to the measured rates of photosynthesis and respiration offering a predictive capacity for rates at paired values of light and temperature prior efforts to fit a response surface to these results were successful except at the boundaries of the i and t ranges key regions with respect to growth limitation we re fit measurements seeking a better correspondence of predictions to measurements at those boundaries the effort to re fit the data included performance testing of the mediation functions and quantification of coefficient values i e maximum rates of gross photosynthesis and respiration algorithms describing the mediation of gross specific growth and specific respiration by light and temperature are summarized in table s1 of the supplementary material and the coefficient values embedded therein are provided in table 2 of the main manuscript fulfilling objective 1 3 1 1 fitting the gross specific growth rate response surface the gross specific growth rate μgross in eq 1 is a function of light temperature and soluble reactive phosphorus we defined μgross as a function of light and temperature based on experimental data from graham et al 1982 those authors measured growth and respiration rates in laboratory experiments with p saturated conditions over a light temperature matrix gradients of light and temperature 10 1200 μe m 2 s 1 and 1 35 c we fit curves μgross versus light for each discrete temperature slice interpolated between slices across temperature and then normalized the surface to result in the bivariate function f μ i t given p saturated conditions i e no limitation by srp the gross specific growth rate is defined as the product of the maximum gross specific growth rate coefficient and a dimensionless light and temperature mediation function 4 μ g r o s s i t μ m a x f μ i t note that f μ i t may be conceptualized as the ratio of μ g r o s s i t to μ m a x treatment of the light dependency of μ g r o s s i t in f μ i t is drawn from the work of platt et al 1980 as adopted for application to cladophora by kuczynski et al 2020 their fig 3 this light functionality substituted into eq 4 as two parenthetic terms yields an expression for calculating μ g r o s s i t for a range of discrete i values across a series of discrete t values 5 μ g r o s s i t μ g r o s s m a x t 1 e α μ g r o s s t i μ g r o s s m a x t e β μ g r o s s t i μ g r o s s m a x t calculations of μ g r o s s i t were made by applying eq 5 for paired values of i and t over a range of discrete values of i 6 8 values spanning 0 1200 μe m 2 s 1 and t 8 values 1 5 10 15 20 25 30 and 35 c values of the three coefficients μ g r o s s m a x t α μ g r o s s t and β μ g r o s s t were adjusted to achieve a best fit to measurements of μ g r o s s i t made in the laboratory over i t gradients as measured by graham et al 1982 values for those derived coefficients were fit to functions reflecting their temperature dependence 6 μ gross max t 0 34 t t 3 1 7 α μ gross t 0 55 1 e 0 001 0 55 t e 0 048 0 55 t 8 β μ gross t 10 17 t 9 3 the gross specific growth rate μ g r o s s i t for the surface was calculated by inputting values of t to eqs 6 8 and those results and values of i to eq 5 the resulting μ g r o s s i t surface was normalized by dividing by the maximum value of the fitted surface 0 288 d 1 to generate the final form of the dimensionless gross growth response surface f μ i t with values ranging from 0 to 1 fig 2 a 3 1 2 fitting the specific respiration rate response surface the specific respiration rate r in eq 1 is represented as the sum of light enhanced light period and basal dark period respiration 9 r r l e r b the specific rate of light enhanced respiration is defined as 10 r le r max f r i t note that f r i t may be conceptualized as the ratio of r l e to r m a x an adaptation of the platt et al 1980 equation similar to that adopted in eq 5 for gross growth is used here in determining r l e 11 r le r le max t 1 e α r t r le max t i the f r i t response surface was developed as for gross growth by adjusting the curve fitting parameters r l e m a x t and α r t to obtain a best fit to the laboratory measurements of graham et al 1982 the temperature dependence of those coefficients was determined to be 12 r le max t 0 10 1 03 t 20 and 13 α r t 0 00168 t t 2 5 permitting calculation of r l e by inputting values of t to eqs 12 and 13 and then those results and values of i to eq 11 the resulting rle surface was normalized by dividing by the maximum value of the fitted surface 0 187 d 1 to generate the final form of the dimensionless light enhanced respiration response surface f r i t with values ranging from 0 to 1 fig 2b the specific rate of basal or dark respiration depends only on temperature and is simulated using the simplified arrhenius equation 14 r b r b 20 θ t 20 eq 14 was fit to basal respiration rates measured by graham et al 1982 yielding values for the coefficients r b 20 and θ of 0 07 d 1 and 1 04 respectively kuczynski et al 2020 development of the f μ i t f r i t and r b functions is described in more detail by kuczynski et al 2020 3 2 mediation by phosphorus in the case of great lakes cladophora the limiting nutrient is phosphorus p mediation of cladophora growth and respiration by phosphorus may be conceptualized as a two step process the first step is acquisition of the nutrient through srp uptake ρ in eq 2 from the water column the second step is incorporation of p in the algal mat as structural material unavailable to support cellular processes and as polyphosphate bodies available for use in cellular processes stored p density s in eq 2 increases as p is taken up from the water column and decreases through respiration p excretion and sloughing of biomass the stored p content of the alga q in eq 3 varies with s but sloughing does not impact q as s and x are lost concurrently during detachment stored p content is the direct driver for nutrient limited growth and water column bioavailable p indirectly influences that process through uptake 3 2 1 stored p mediation by phosphorus uptake phosphorus uptake the source term in the s mass balance eq 2 contains a single coefficient the phosphorus uptake rate ρ which has been demonstrated to vary with both the water column srp concentration and the stored p level of the alga q in excess of its structural content the srp effect is stimulatory ρ increases as the srp concentration increases the q effect is inhibitory providing negative feedback on ρ as q increases stimulation by srp and inhibition by q are evident in results obtained by auer et al 1982a as shown in fig 3 a the algorithm describing the stimulatory behaviour is in the form of a michaelis menten equation 15 ρ ρ max srp k m srp here ρ increases linearly with srp before transitioning at an inflection point to a saturation response that asymptotically approaches the maximum phosphorus uptake rate ρ m a x fig 3a wet chemistry measurements of phosphorus uptake were made by auer and canale 1982b who examined a broad range of srp concentrations 10 1200 μgp l 1 in a successful effort to quantify the half saturation constant for p uptake k m there is less confidence however in measurements of ρ made by auer and canale 1982b at low srp concentrations 20 μgp l 1 due to limitations of the wet chemistry method at that time here we used radioisotope techniques in measuring ρ as a function of srp and q see supplementary material measurements were made over a range of environmentally meaningful srp concentrations 10 μgp l 1 using cladophora with different levels of stored p content these conditions are representative of great lakes waters dove and chapra 2015 and include those representative of sites proximate to point source discharges auer et al 2021 and in the benthic boundary layer at sites colonized by dreissenids dayton et al 2014 measurements of k m in cladophora are relatively few and exhibit considerable variability phosphorus uptake rates have been determined for the alga collected from saline systems e g peel inlet australia gordon et al 1981 and the baltic sea near stockholm sweden wallentinus 1984 yielding estimates of k m ranging 9 15 μgp l 1 in freshwater values for k m have been measured at 32 μgp l 1 e g in lake ontario rosemarin 1982 and ranging 15 86 μgp l 1 in the upper clark fork of the columbia river lohman and priscu 1992 a considerably broader range 30 250 μgp l 1 was reported for cladophora from lake huron by auer and canale 1982b where values for the coefficient increased as the stored p content of the alga decreased fig 3a the results of the radioisotope p uptake experiments performed in our study fig 3b confirm that michaelis menten kinetics serve well in representing the linear portion of the ρ srp relationship for environmentally significant srp concentrations methods applied in treating phosphorus uptake and mediation of growth by stored p content are provided in the supplementary material section 2 dependence of phosphorus uptake on the stored p content of the alga exerting an inhibitory effect on ρ with increasing levels of q is represented by defining ρ m a x as a function of q 16 ρ max a q b where a and b are fitting coefficients paired measurements of ρ m a x and q made by auer and canale 1982b by painter and kamaitis 1987 and in our study were fit to eq 18 yielding coefficient vales of a 0 012 d 1 and b 2 3 fig 3c the coefficients were determined by model calibration seeking the best fit to predicted biomass density x and stored p q measurements rather than to ρ max thus the apparent bias in fig 3c the bivariate phosphorus uptake relationship is illustrated in fig 3d demonstrating the role of negative feedback by q in limiting uptake when the stored p content increases additionally the significance of exposing algae with low q levels to elevated srp concentrations across the range of environmentally significant srp levels is demonstrated the results of laboratory measurements and algorithm refitting confirm the utility of the michaelis menten relationship supplemented with a q driven negative feedback mechanism in simulating rates of phosphorus uptake by cladophora and thus accomplishing our objective 2 3 2 2 growth mediation by stored phosphorus the influence of nutrient limitation on gross growth is accommodated by including a multiplicative stored phosphorus mediation function f q in eq 4 17 μ gross μ gross max f μ i t f q where f q phosphorus mediation function dimensionless the algorithm for respiration does not include a phosphorus mediation factor as it is assumed not to be influenced by nutrient limitation the form of f q used here is that of the droop equation droop 1968 18 f q 1 q m i n q which may be described as a rectangular hyperbola with f q 0 at q qmin when p is only present as structural material not as storage in accessible polyphosphate bodies then increasing linearly with q and asymptotically approaching f q 1 fig 4 the phosphorus content of the alga can vary widely from near qmin in p starved organisms to the point where p stored as polyphosphates is by a significant margin the most abundant q fraction for example p content ranged over almost an order of magnitude 0 028 0 230 on several dates across multiple sites in lake erie higgins 2005a those authors characterized the degree of p limitation in cladophora based on p content as critical 0 06 severe 0 06 0 10 moderate 0 10 0 16 and non p limited saturated 0 16 variation in p content can reflect intersite differences in light depth p discharges and intrasite variation due to seasonal changes in p discharge particularly for tributaries and over a shorter term as a result of p plume location particularly for effluents we fitted the droop function to paired measurements of the net specific growth rate μ n e t μ g r o s s r l and p content based on measurements made by auer and canale 1982b on lake huron and our efforts described here on lake ontario in 2015 and 2016 see supplementary material sections 1 and 2 2 for methods sensitivity analysis performed in our work described in section 4 6 identified q m i n as a particularly significant model coefficient regulating the rate at which growth increases with increasing stored p content and the position where growth transitions from p limited to p saturated conditions for example for algae with a q of 0 1 values of q m i n 0 03 0 04 and 0 05 give model predicted values of the normalized net growth rate of 0 5 0 6 and 0 7 respectively thus selection of a value for q m i n is an important step in model parameterization observationally minimum values of q have been identified as 0 028 0 040 higgins et al 2005c 0 045 tomlinson et al 2010 and 0 04 0 05 wong and clark 1976 auer and canale 1982b jackson and hamdy 1982 model applications have most often selected a value of 0 05 canale and auer 1982a higgins et al 2006 malkin et al 2008 tomlinson et al 2010 adopted a value at the lower end of the observed range 0 035 noting that q m i n would seldom if ever be observed in nature as algae with that stored p content would be non viable here we use a value of 0 04 consistent with values measured in field collections and our fit to the droop function fig 4 we recommend that the value of q m i n be examined over the range 0 028 0 050 in future glcm v3 applications measurements of μ n e t are represented by the phosphorus mediation function eq 18 multiplied by a maximum net growth rate μ n e t m a x fig 4a the droop function itself is a fit to those data and when normalized ranges from 0 to 1 fig 4b eq 18 was fitted to measurements of μ n e t and normalized using the value of μ n e t m a x 0 714 d 1 measured by auer and canale 1982b because no experiments were conducted using algae with high q 0 15 in this study this value is comparable to those reported by rosemarin 1982 painter and kamaitis 1987 and higgins et al 2008a and to output from of model simulations performed by fillingham 2015 we note that while similar to the fit used in the original glcm v1 the new fit favours results obtained for both the low q lake ontario samples unavailable at the lake huron site and the high q lake huron samples unavailable at the lake ontario site these results represent achievement of our objective 3 3 3 sloughing sloughing detachment of algal filaments has long been considered an important feature of cladophora modeling as its initiation signals the onset of the summer die off and attendant beach and water intake fouling today there is general agreement that both physiological filament senescence and physical wind driven shear stress processes play a role in mediating sloughing biggs and thomsen 1995 horner et al 1990 higgins et al 2008a tomlinson et al 2010 the treatment of sloughing has undergone a greater evolution in a modeling context than has any other process in the cladophora mass balance 3 3 1 physiological forcing of sloughing the first attempt to incorporate the complex sloughing mechanism in a model the glcm v1 canale and auer 1982a did not accommodate physiological forcing this shortfall was recognized however as simulation results failed to track observations of a striking decline in biomass density in late summer it was concluded that a metabolic imbalance negative net photosynthesis causes physiological deterioration of algal filaments however the science supporting a mechanistic incorporation of that process was not yet available agreement was later reached that exposure to sub optimal conditions of light and or temperature for a particular length of time would lead to senescence a loss of physical integrity and an increasing vulnerability to drag and turbulence induced detachment see horner et al 1990 thus subsequent efforts focused on mechanistically characterizing the senescence process with two schools of thought emerging the first of these was mediation by supra optimal light and temperature conditions graham et al 1982 identified an optimum temperature range for cladophora growth of 13 17 c with respiration exceeding photosynthesis in well lit environments at temperatures elevated beyond this range summer temperatures of 20 25 c are common in great lakes waters the resulting metabolic imbalance would then lead to senescence and vulnerability to detachment this approach was adopted in the next generation of cladophora models cgm higgins et al 2005b glcm v2 tomlinson et al 2010 the second mechanism was that of self shading i e the canopy effect here as biomass levels increase the thickness of the algal bed canopy increases and light is attenuated with depth in the bed extended periods of light limitation within the bed result in a metabolic imbalance at its base and the senescence process is initiated this second approach was adopted for the cgm by higgins et al 2008a cgm and more recently by kuczynski et al 2020 for incorporation in the glcm v3 application of either of these approaches required a means of initiating sloughing i e the point at which the loss of filament integrity becomes sufficiently manifest to engender detachment higgins et al 2005b cgm accomplished this by invoking catastrophic sloughing 90 of the standing crop daily at a threshold water temperature of 23 5 c tomlinson et al 2010 glcm v2 applied a function where the sloughing coefficient increased linearly from water temperatures of 13 to 17 c the optimum temperature range for growth graham et al 1982 and subsequently remaining at its maximum value higgins et al 2006 were the first to employ the canopy shading approach proposing a trigger initiated when model calculated respiratory losses at the base of the bed exceeded 40 of the biomass over a 10 day period and holding the loss rate at the maximum value established by higgins 2005a 3 3 2 physical forcing of sloughing the treatment of physical forcing of sloughing in cladophora models has historically been less complex than that for senescence focusing primarily on the means of representing near bottom turbulence conceptualization of the process progressively recognized that wind speed water column depth and the degree of senescence characterized the driving force for detachment thus high winds occurring over shallow depths later in the growing season would lead to the greatest incidence of sloughing the first treatment of the process canale and auer 1982a glcm v1 quantified sloughing loss as increasing to a maximum rate as wind speed turbulence and biomass density momentum of oscillating filaments increased subsequently higgins et al 2005b cgm modified the glcm v1 approach accommodating variation in wind driven turbulence due to fetch and water depth tomlinson et al 2010 extended this approach calculating a shear stress exceedance frequency based on wind speed fetch and water depth 3 3 3 advancing the treatment of sloughing in the glcm v3 moving forward from the work of higgins et al 2005b 2006 2008a and tomlinson et al 2010 we considered two features of the sloughing process the first of these is mechanistic treatment of the onset trigger point and time course of sloughing in response to a decline in physical integrity senescence the need to further investigate this physiological issue is first evident implicitly higgins et al 2008a tomlinson et al 2010 and explicitly higgins 2005a higgins et al 2006 in the work of others where the approach was well conceived but not mechanistic in nature the second is a field verification of the attenuation of near bottom turbulence as a function of depth a feature of the sloughing dynamic that has been incorporated in models but not supported by ground truth measurements the physiological processes that govern sloughing initially quantified empirically by higgins et al 2005b as a threshold phenomenon triggered by temperature was subsequently treated more mechanistically as being mediated by self shading within the canopy higgins et al 2008a in that work a critical algal density was calculated below which a negative energy balance occurs at the base of the mat leading to cellular deterioration weakening of filament strength and increased susceptibility to physical detachment building on the conceptualization of higgins et al 2008a and our mechanistic treatment of the canopy effect kuczynski et al 2020 we propose an algorithm containing physiological and physical factors providing a predictive mechanism for the onset of sloughing and a progressive approach to a maximum specific sloughing rate 19 l l m a x f 1 f 2 with a sigmoid function of the form 20 f 1 1 e 12 t d u r t 6 t s t a r t t m a x t s t a r t t m a x 1 the only model coefficient requiring parameterization in function f 1 is t d u r determined by calibration at 30 days the glcm v3 calculates the mean daily net specific growth rate at the bottom layer of a vertically segmented algal mat see section 4 5 to determine if positive net growth is occurring at that point under local light conditions incident light and water column and algal mat attenuation see section 4 5 sloughing is initiated t s t a r t when the daily net growth rate at the mat bottom is equal to or less than zero the sloughing rate then increases in a sigmoid fashion fig 5 over the period tdur bounded by t s t a r t and t m a x where the latter is the day of the year on which the maximum specific sloughing rate is achieved and maintained thereafter note that this formulation offers the user the opportunity to simulate the catastrophic sloughing event of higgins et al 2005b the linear manifestation of sloughing tomlinson et al 2010 or use field observations of the onset of sloughing and approach to a maximum rate fig 5 the mediation factor f 2 describes the attenuation of wind driven current speed a determinant of near bottom shear and drag forces with depth the analysis is based on tilt current meter tcm measurements of near bottom current velocities fig 6 providing a representation of the physical mediation of sloughing supported by ground truth measurements made in cladophora habitat see supplementary material section 1 the function describing attenuation of physical forcing with depth 21 f 2 a e b z c was parameterized by fitting paired measurements of current velocity and depth z using three fitting parameters a 0 4635 b 0 3054 and c 0 5365 the resulting curve was normalized to the current speed at z 0 yielding a relationship that describes attenuation of the physical factor velocity that drives sloughing as a function of depth fig 6 the glcm v3 advances the mechanistic treatment of sloughing by implementing a canopy shading subroutine that accommodates senescence as a process impacting filament vulnerability to detachment in addition we provided field verification of the how turbulence which drives detachment is attenuated with depth together the results of these efforts represent fulfilment of objective 4 we note that we use current speed as a surrogate for bottom shear stress the immediate physical component resulting in detachment the algorithm implemented in the glcm v3 does not view sloughing as a near immediate catastrophic phenomenon in response to physical factors such as velocity driven bottom shear stress but more as a process evolving over a period of days to weeks in response to deteriorating physiological conditions fig 5 it remains to quantify measure the time course t d u r of loss in filament integrity following initiation of a negative energy balance at the canopy base the physiological component resulting in detachment this latter feature is likely well described by the tensile strength of the algal filaments a metric that may be measured directly johnson et al 1996 on collections made over the growth season a comprehensive field and laboratory program treating this issue would include seasonally deployed cameras diver collected cladophora samples for quantification of biomass density stored p content and tensile strength light and scanning electron microscopy to determine epiphyte presence cell wall integrity and filament health 4 model implementation and testing the glcm v3 was implemented using a new formulation for carrying capacity in a self shading or canopy context section 4 1 the model was tested by means of a sensitivity analysis section 4 2 and its performance was tested against field measurements of state variables section 4 3 finally we identify challenges and potential for model improvement in the future section 4 4 4 1 model implementation in a canopy context negative feedback on growth as algal biomass approaches the carrying capacity has commonly been accommodated in cladophora modeling through application of the logistic model i e inclusion of a carrying capacity term canale and auer 1982a higgins 2005a tomlinson et al 2010 it has been recognized that this approach fails to reflect the significance of light attenuation through the algal canopy higgins 2005a 2008a kuczynski et al 2020 and is overly deterministic i e offers great latitude for tuning of the maximum biomass density in calibration and performance testing instead of a carrying capacity term we have adopted a canopy based approach in this work the physical framework for this approach consists of an algal canopy of n 1 centimeter layers in the vertical dimension specification of the initial condition for cladophora biomass density involves filling the canopy evenly layer by layer with biomass and capturing any remaining biomass in the topmost canopy layer kuczynski et al 2020 used a constant biomass density per centimeter mat layer height of 9 gdm m 2 cm 1 this however can result in unrealistically high total mat heights e g 50 cm or more for great lakes cladophora instead of using a constant biomass density per layer we calculated the mat height as a function of mat biomass density fig 7 fitted to unpublished measurements of s malkin 22 z m a t 1 9415 x 0 4138 where zmat algal mat height cm then the simulated canopy biomass density is divided by the mat height to determine the biomass density for each mat layer this approach results in a more tightly packed more dense algal mat at higher canopy biomass densities and a less tightly packed less dense algal mat at lower canopy biomass densities consistent with s malkin s measurements fig 7 for each time step the layer specific light intensity is calculated as described below and then net growth gross growth minus respiration and sloughing is calculated to quantify the incremental biomass accrual for each layer the cumulative change in biomass is the sum of the change in biomass in each layer and a new time step specific canopy biomass density is calculated that biomass density becomes the starting point for the next time step the resulting biomass is redistributed over the canopy as for the initial condition and a new canopy height is calculated changes in stored p content are handled concurrently in a similar fashion resulting in homogeneity in both biomass and stored p density across canopy layers model output takes the form of two daily times series cladophora biomass density x and stored p content q calculated from the phosphorus and biomass densities of the mat eq 3 environmental forcing conditions for calculating gross growth respiration and sloughing include hourly incident light i 0 daily water temperature t the soluble reactive phosphorus concentration s r p and depth z incident light is attenuated by water column and algal mat extinction coefficients to determine light at depth and within the algal canopy the beer lambert law is applied using site specific light extinction coefficients the sequential attenuation of incident light through the water column and through the algal mat is given by 23 i z i 0 e k e z e k alg z mat as z m a t increases light at the mat bottom decreases with a corresponding reduction in the net specific growth rate this has been called the canopy effect kuczynski et al 2020 and ultimately leads to senescence development and implementation of a self regulating canopy shading subroutine for simulation of carrying capacity thus meets objective 5 the glcm v3 is implemented by solving the differential equations for cladophora biomass density eq 1 and algal mat phosphorus density eq 2 using an euler integrator here with a time step of 0 01 d a summary of all model equations input requirements and recommended coefficient values is supplied as supplementary material section 3 4 2 sensitivity analysis a sensitivity analysis was conducted to identify model coefficients having the most significant effect on simulation behaviour the analysis also served in providing guidance for coefficient selection in model calibration and in identifying processes meriting future study a baseline model run was made using mean environmental forcing conditions table 1 and selected model coefficient values μ m a x 1 4 d 1 r m a x 0 5 d 1 r b m a x 0 07 d 1 k a l g 24 m 1 q m i n 0 04 ρ m a x 0 012 q 2 3 k m 125 µgp l 1 l m a x 0 08 d 1 and t d u r 30 d and initial conditions x 0 1 gdm m 2 and q 0 0 04 values are similar to those used by kuczynski et al 2020 in a base run simulation sensitivity analysis simulations were performed for a depth of 9 m over a period of 5 5 months day of year 122 to 289 or 1 may to 15 oct sensitivity of biomass density x and stored p content q calculated hourly was examined for a 20 adjustment of coefficient values tested individually fig 8 the sensitivity of the response was evaluated with respect to representative field measurements of maximum biomass density and maximum stored p content at a depth of 9 m the maximum modelled biomass density was most sensitive to the maximum specific growth rate μ m a x the coefficient for light extinction through the algal mat k a l g and the minimum stored p content q m i n the lower and upper bound for the maximum specific growth rate 1 12 and 1 68 d 1 resulted in a 54 7 decrease to 154 gdm m 2 and a 73 4 increase to 590 gdm m 2 respectively in the base case maximum biomass density the lower and upper bound k a l g values 19 2 and 28 8 m 1 resulted in a 65 0 increase to 561 gdm m 2 and a 34 7 decrease to 222 gdm m 2 respectively in the base case maximum modelled biomass density the lower and upper bound q m i n values 0 032 and 0 048 resulted in a 51 5 increase to 515 gdm m 2 and a 38 9 decrease to 208 gdm m 2 respectively in the base case maximum modelled biomass density perturbations of 20 for all other tested model coefficients resulted in less than a 35 change in maximum modelled biomass density the maximum modelled stored phosphorus content was sensitive to ρ m a x and k m and relatively insensitive less than 4 change with respect to all other tested coefficient perturbations increases and decreases in stored p with respect to the two named coefficients were all less than 10 fig 8 we also evaluated different fitted functions for the maximum uptake rate eq 15 i e functions describing the lower and upper bounds of the shaded area in fig 3c the lower bound for the q multiplier in the ρ m a x function 0 008 q 2 4 resulted in an 8 8 decrease in maximum biomass to 310 gdm m 2 and a 5 3 decrease to 0 10 in the maximum modelled stored p the upper bound for the q multiplier in the ρ m a x function 0 035 q 2 6 resulted in a 105 5 increase to 699 gdm m 2 in maximum biomass and a 64 9 increase to 0 178 in the maximum modelled stored p recommended model coefficient values are presented in table 2 4 3 performance testing the final objective of our research plan was to secure a multi lake calibration suitable for simulation of the magnitude and seasonality in biomass density and stored p content based on a uniform set of model coefficients that would limit tuning this approach applied here for lakes erie huron michigan and ontario provides a more rigorous confirmation than that for a single lake and demonstrates that the framework is appropriately parameterized and robust to accurately adapt across systems with different physical characteristics and trophic states performance criteria are those particularly important in management applications the maximum achievable biomass density the steady state stored p content and the timing of the onset of sloughing model performance may be assessed by employing subjective and or objective approaches chapra 2008 the subjective approach usually involves a visual examination of times series of the state variables here cladophora biomass x and stored p content q evaluating their magnitude maximum mean and time course of seasonal expression the objective approach uses quantitative measures of goodness of fit such as the coefficient of determination r2 in this application a subjective approach is used to examine the day to day tracking of x and q of interest in exploring model behaviour and an objective approach in examining seasonally averaged metrics of interest in a policy and regulatory context notably this is the first time that a cladophora model has been tested across the four great lakes colonized by the alga cladophora biomass density and stored p content were simulated and compared with published datasets from lake huron canale and auer 1982a lake michigan tomlinson et al 2010 lake erie higgins et al 2008a and lake ontario malkin et al 2008 results are shown in fig 9 these runs require user input of initial conditions for biomass and stored p content and time series of forcing conditions temperature incident light and light extinction factors and srp concentration see supplementary material table s2 it must be noted that the quality of the input forcing conditions strongly affects the goodness of fit of model output to observations data sets that were not collected specifically in support of model development often have gaps in these critical inputs glcm v3 simulations conducted for this work draw upon several different calibration and input data sources of varying quality e g method and precision in biomass density measurements and temporal resolution e g daily weekly or single srp measurements for a season model runs also require user specification or default values for biokinetic and physical coefficients μ m a x r m a x q m i n k a l g l m a x ρ m a x in model calibration a best fit of model output to measurements is sought while retaining coefficient adjustment within bounds determined by field observation or laboratory experimentation table 2 and guided by sensitivity analysis calibration was performed to yield a uniform set of values for these biokinetic coefficients leaving only k a l g as a lake specific calibration coefficient these uniform values excepting k a l g are retained in simulations across all four lakes the glcm v3 performed well in all capacities except in tracking short term variations in algal stored p content and to a lesser extent biomass density figs 9 and 10 temporal dynamics of stored p and biomass density are driven in large part by ambient srp concentrations and water column light extinction respectively we ascribe this shortfall to the availability of time series for ambient srp concentrations impacting stored p content and in some cases for k e impacting biomass density the best fits to algal biomass density and stored p content were obtained for lake michigan figs 9 and 10 where the monitoring program was designed to support development of the glcm v2 tomlinson et al 2010 the data set included weekly k e and near weekly srp measurements of environmental forcing conditions and weekly measurements of algal biomass and stored p content correlations between model output and observations algal biomass density r2 0 99 stored p content r2 0 89 intercepts set to zero for lake michigan were the best of the four sites measured values of stored p content ranged 0 05 0 15 gp per gdm expressed as and were well represented by model output figs 9 and 10 input and calibration data for the lake erie simulation included approximately fortnightly measurements of k e algal biomass density and stored p content higgins et al 2008a with k e values interpolated between sampling dates for use as model input as no srp time series was available a seasonal average concentration 2 0 μgp l 1 was applied model output fit observations of algal biomass density well figs 9 and 10 r2 0 95 intercept set to zero but tracked the range of stored p content 0 04 0 25 gp per gdm as poorly due to the unavailability of an srp times series and thus a largely invariant model predicted stored p content the lake ontario data set includes constant values for both k e 0 43 m 1 and srp 1 μgp l 1 and weekly measurements of algal biomass density and stored p content application of constant values for k e and srp limited the ability to track short term variations in algal biomass density and stored p content the correlation coefficient for algal biomass density was r2 0 85 intercept set to zero and simulation results captured the ascending limb of the biomass curve well there was little correlation r2 0 72 with intercept set to zero between model predictions and observations of stored p content the latter ranging 0 05 0 26 gp per gdm as but paired values clustered closely across the season fig 9 the lake huron data set canale and auer 1982a reported algal biomass density and stored p content on a weekly basis but used constant values retained here for k e 1 37 m 1 and srp 17 μgp l 1 the lake huron data set is the least robust of the four data sets used in testing model performance as it focused on a highly dynamic phosphorus footprint close proximity to a wastewater treatment plant and lacked contemporary technologies for recording k e and measuring srp at low ecologically meaningful concentrations esp important in describing the phosphorus uptake rate due to the degree of p saturation at that site however the glcm v3 fit the ascending and descending limbs of the biomass curve well at all but 3 of 11 measurements fig 9 and model output and measurements were well correlated fig 10 r2 0 95 intercept set to zero the broad range in stored p content observed at the lake huron site 0 2 0 5 gp per gdm as was not tracked well due to the use of a constant srp concentration at a spatially dynamic point p source site based on the results of performance testing of the glcm v3 described here for the four great lakes colonized by cladophora we consider objective 6 of our research plan to have been met the model performs well in predicting magnitude and timing of peak biomass and the onset of sloughing key features for model application in managing nuisance growth of cladophora 4 4 challenges and future work the opportunity to focus on a single species vis à vis the more common multi species assemblages of the phytoplankton community affords a particular benefit in modeling cladophora challenges do however remain for example quantification of the maximum specific growth rate coefficient μ m a x through field and laboratory measurement attracts the epistemic curiosity historically accorded a perpetual motion machine much as development of such a machine is considered impossible because friction and dissipative forces cannot be eliminated μ m a x cannot be measured directly because the forces of environmental friction e g respiration sloughing cannot be completely eliminated this is an untenable objective e g p 700 of droop 1968 yet μ m a x has been identified as a particularly important coefficient in the glcm v3 sensitivity analysis section 4 6 and fig 8 according to benedini and tsakiris 2013 the μ m a x coefficient used in attached algae or periphyton models for streams ranges 1 3 d 1 measurements and models specific to cladophora and other periphyton suggest rates ranging 0 1 2 7 d 1 table 2 the question then becomes do differences in estimates of μ m a x in cladophora reflect for example true intersite variation in the coefficient value or do they represent the cumulative uncertainty in resolving descriptors of environmental friction the inherent inability to measure μ m a x dictates that this coefficient will always be determined by calibration thus we seek to reduce uncertainty in quantifying environmental friction while discouraging overly deterministic tuning of μ m a x by limiting the range over which it may be varied in calibration table 2 a second challenge lies in specification of k a l g the coefficient for light extinction through the cladophora mat a coefficient to which the canopy effect self shading is especially sensitive section 4 6 fig 8 values for k a l g have been reported to vary from 10 to 30 m 1 in the great lakes higgins 2005a malkin et al 2008 and reach values as high as 150 7 m 1 in a riverine environment where the mat is more appressed flynn 2014 flynn et al 2018 values of k a l g are amenable to direct field measurement in lacustrine habitats wind driven turbulence may serve to suspend the canopy reducing the mat compression characteristic of quiescent conditions and leading to considerable variability in k a l g we recommend additional quantification of expected ranges in this coefficient and perhaps inclusion in the model of an algorithm describing the magnitude of its wind driven variation in a similar vein identification of the timing of the trigger for and temporal manifestation of sloughing merits attention section 3 3 5 conclusions the glcm v3 driven by algorithms grounded in ecological concepts and parameterized using field and laboratory derived kinetic coefficients serves well both visually fig 9 subjective evaluation and analytically fig 10 objective evaluation in tracking the late spring increase ascending limb mid summer maximum peak and late summer reduction descending limb in biomass density characteristic of the seasonal growth curve the model also performs well in characterizing the mean stored p content of the alga including intersite differences but does not satisfactorily resolve temporal variability figs 9 and 10 where well resolved time series of srp are unavailable however predicted levels of biomass density and stored p content match observations well when considered in terms of their mean standard deviation fig 11 we believe that the modeling approach presented here is drawing close to an optimum position on the complexity reliability spectrum chapra 2008 we recognize that our effort to parameterize and performance test the glcm v3 across four great lakes necessarily drew upon field measurements made in one case decades apart from the others and involves different investigators with their own suite of field techniques and analytical methods thus attention appropriately turns to improved characterization of model forcing conditions and the coefficients imbedded in model algorithms compared to the other three study sites considered here the lake michigan data set tomlinson et al 2010 is most robust due to its temporal sampling frequency improved method detection limits and available time series for srp and the water column light extinction coefficient k e it is anticipated that contemporary efforts to coordinate monitoring by government agencies will result in consistent methodologies and sampling plans strengthening this feature of cladophora studies we believe that we have significantly advanced the body of knowledge regarding algorithms and their coefficients specifically those for growth and respiration as a function of light and temperature the role of phosphorus uptake in mediating stored p content the manner in which nutrient content controls growth and the value of a canopy based approach in simulating carrying capacity and the onset and time course of sloughing we have successfully calibrated the model to fit algal biomass density and stored p content measurements from the four great lakes colonized by cladophora using a uniform cross lake set of model coefficients excepting only the maximum specific growth rate coefficient μ m a x and the coefficient for light attenuation through the algal canopy k a l g the first of these may not be directly determined while the latter is an excellent candidate for future study with respect to algorithms and coefficients the glcm v3 is very different from its predecessors advancements made on the modeling front will serve to complement improvements in monitoring this third version of the great lakes cladophora model can have considerable value in supporting future research on nuisance growth of the alga however it is in the determination of targets for phosphorus controls seeking management of nuisance cladophora growth in the great lakes that the tool finds its intended application the great lakes water quality agreement of 2012 requires that levels of algal biomass must be held below those constituting nuisance conditions we recommend that the glcm v3 be applied in conjunction with a hydrodynamic model and a biogeochemical model simulating nutrient cycling to establish relationships between seasonal maximum biomass and ambient phosphorus concentrations auer et al 2021 in turn regional targets can be determined for p loads and appropriate discharge mixing zones to curb cladophora growth the model also holds promise in addressing features of the dual challenge to balance concurrent oligotrophication and eutrophication concerns in the great lakes hecky and depinto 2020 zhou et al 2021 credit authorship contribution statement anika kuczynski conceptualization data curation formal analysis investigation methodology software validation visualization writing original draft writing review editing martin t auer conceptualization funding acquisition investigation methodology project administration resources formal analysis supervision writing original draft writing review editing william d taylor data curation formal analysis writing original draft writing review editing steven c chapra conceptualization methodology software writing review editing marcel dijkstra conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study and article are grounded in the pioneering work on mechanistic cladophora modeling by r p canale m t auer and colleagues and scientists including s n higgins s y malkin r e hecky s j guildford and colleagues radioisotope experiments were conducted at the ontario ministry of environment and climate change dorset environmental science centre and supported by an nserc canada discovery grant to w d taylor jennifer eikenberry performed the c analysis on algae samples terrianna bradley aubrey scott mary maggie stangis michelle nitz and hayden henderson were instrumental in completing the field and experimental laboratory work this work was funded in part through a research grant to michigan technological university from the town of ajax ontario supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110118 appendix supplementary materials image application 1 
24339,the nearshore waters of the laurentian great lakes have historically suffered from beach fouling and clogged water intakes due to proliferation of the native filamentous green alga cladophora a resurgence in nuisance growth of the alga has led to a demand for an improved model platform to better guide management the great lakes cladophora model glcm v3 predicts algal biomass g dry matter m 2 and stored phosphorus content p as of dry matter based on simulations forced by time series of incident light i water temperature t and water column soluble reactive phosphorus concentration srp μgp l 1 a particular strength of the glcm v3 is its foundation in ecologically sound biokinetic mechanisms supported by field and laboratory measurements these measurements advancing the credibility and reliability of the biokinetic framework include improved characterization of the growth and respiration responses to light and temperature addition of a self shading algorithm replacing an overly deterministic carrying capacity term a new treatment of phosphorus uptake based on radioisotope experiments additional observational support for droop based simulation of growth as a function of stored p and implementation of a new physiologically and physically driven sloughing function uncertainty associated with processes collectively termed environmental friction the i t and p growth forcing functions is reduced leaving the model sensitive to the maximum specific growth rate and the coefficient for extinction of photosynthetically active radiation through the algal mat the model was performance tested by multi lake erie huron ontario and michigan calibration employing a common set of biophysical coefficients this common set of calibration coefficients provides enhanced corroboration that glcm v3 is suitable for examining the phosphorus cladophora dynamic across the great lakes in particular it greatly strengthens the model s efficacy for establishing a phosphorus standard to maintain levels of algal biomass below those constituting a nuisance condition as per the great lakes water quality agreement of 2012 in addition the model structure can be applied to other lakes experiencing problems with attached filamentous algae graphical abstract image graphical abstract keywords cladophora laurentian great lakes model parameterization mechanistic modeling calibration growth rate phosphorus uptake sloughing cross site application ecosystem management data availability all data used in this study were either presented in the main manuscript or referenced published elsewhere all model equations and parameter estimates are presented in tables 1 introduction 1 1 balancing math and science dating back to the seminal work of streeter and phelps 1925 mathematical models have played a critical role in the evolution of water quality management key advances in the discipline accompanied the introduction of digital computing and more recently high performance computing chapra 2008 these mathematical revolutions set the stage for a deeper level of spatiotemporal resolution and an attendant improvement of our understanding of biophysical dynamics it is fair to say that the demand for mathematical assets supporting lake modeling has today largely been met the same cannot be said with respect to the development of the biokinetic algorithms and coefficients applied in these models consider the following example exploring the lineage of the maximum specific growth rate coefficient μmax applied in a mass balance model simulating the growth of a single phytoplankton group in lake superior white and matsumoto 2012 the authors cite as their source for μmax the value applied in a similarly purposed model of two phytoplankton groups in lake michigan chen et al 2002 those authors then cite modeling papers by bierman and dolan 1981 saginaw bay lake huron and scavia et al 1988 lake michigan as their source for μmax bierman and dolan 1981 provide the values of µmax used in their work for each of five phytoplankton groups but do not reference sources for that information noting only that coefficient choices were based on the literature scavia et al 1988 working with three phytoplankton groups diatoms flagellates and cyanobacteria indicate that values of μmax used in their model were derived from values of μmax measured by reynolds et al 1982 for flagellates in blelham tarn england by tilman et al 1982 and references therein for diatoms and cyanobacteria in lake michigan lake norrviken sweden lake windermere england and lake ohrid macedonia albania by reynolds 1984a 1984b for diatoms flagellates and cyanobacteria representing selected temperate lakes and sommer 1983 for diatoms and flagellates in lake constance germany switzerland austria this lineage of experimental studies dating back to the 1980s represents work undertaken in what might be termed the golden age of biokinetics chapra 2008 tracing of the origin and curation of a single coefficient established through measurements made in multiple studies and proceeding through four modeling exercises over three decades reveals that contemporary application of the μmax coefficient lies far distant from its origin in time technology and biogeography the challenge to establish coefficient values suitably grounded in measurement preferably specific to the study system remains an issue the distancing of models from their scientific foundation is of particular importance in management applications where a high degree of reliability and credibility must support the economic burdens of control measures based on model predictions chapra 2008 modelers often have the notion that as model complexity increases so too does its ability to fully represent nature and advance the reliability of its predictions but this comes at a price if increases in complexity are not supported by the field and laboratory studies required to credibly parameterize that complexity chapra 2008 the danger then is that the mathematics outpaces the foundation in science and model reliability suffers pauer et al 2018 that danger may only be mitigated by investing resources on the science side of the math science pairing chapra 2008 in this paper we seek to advance the ecological underpinnings of the great lakes cladophora model keeping pace with the math and establishing the credibility and reliability required to support management of nuisance algal growth in the great lakes 1 2 nuisance growth of cladophora a filamentous green alga native to the laurentian great lakes cladophora has been a subject of study for decades if not a century with reports of nuisance growth in lake erie from as early as the 1800s taft and kishler 1973 the alga grows attached to hard lake bottom surfaces such as rocks and boulders and to mussel shells colonising those substrates higgins et al 2008b whitton 1970 cladophora growth occurs seasonally from may to late september or early october with rapid biomass production in may and june a population collapse in summer and modest regrowth in late summer early fall as temperatures cool to once again pass through the optimal range higgins et al 2008a 2008b lorenz and herdendorf 1982 whitton 1970 the summer population collapse results in detachment of algal filaments sloughing with transport deposition and accumulation of algal debris along the shoreline cladophora fouls beaches and water intakes leading to losses of beneficial use at sites along the nearshore of the four lower lakes huron michigan erie and ontario a resurgence in nuisance growth kuczynski et al 2016 has fostered interest in the development and improvement of mathematical models supporting management bootsma et al 2015 the glcm last updated more than a decade ago merits revision to better serve ecosystem management in a dynamic multi stressor environment in addition to hard substrate for attachment cladophora requires specific conditions of temperature and light to initiate and sustain growth graham et al 1982 higgins et al 2006 simply stated temperature regulates the seasonal cycle of growth light mediates the depth of colonization and the limiting nutrient phosphorus p auer and canale 1982b 1982c canale and auer 1982a higgins et al 2008a 2008b neil and owen 1964 painter and kamaitis 1987 determines the maximum biomass both tributary and point source inputs of phosphorus have been identified as nourishing cladophora beds auer et al 1982c higgins et al 2012 with the magnitude and p richness of the discharge as subsequently influenced by mass transport defining the footprint of the area impacted huang et al 2019 auer et al 2021 1 3 phosphorus management in the great lakes pursuant to the mandate of the great lakes water quality agreement of 1972 phosphorus controls were implemented in the form of bans on p in soaps and detergents and limits on p concentrations in wastewater treatment plant wwtp effluents although the primary purpose of these controls was to curb cultural eutrophication in the open lake regulation also reduced reports of nuisance attached algal growth in the nearshore kuczynski et al 2016 levels of biomass density and p nutrition in cladophora decreased from pre p management 1970s to post p management years 1980s painter and kamaitis 1987 with conditions prevailing for 2 3 decades and into the 21st century kuczynski et al 2016 subsequent invasion of the four lower great lakes by dreissenid mussels zebra mussel dreissena polymorpha and quagga mussel dreissena rostriformis bugensis was accompanied by increases in water clarity offshore extension of colonization by cladophora and a resurgence in conditions of nuisance growth kuczynski et al 2016 nuisance conditions have been reported particularly from lakes michigan milwaukee wi and sleeping bear dunes national lakeshore mi and ontario pickering ajax whitby on and rochester ny the most recent great lakes water quality agreement international joint commission ijc 2012 calls for adoption of lake ecosystem objectives that will maintain levels of algal biomass below those constituting a nuisance condition through establishment of substance objectives and loading targets for phosphorus in nearshore and offshore waters 1 4 cladophora models development testing and application of the great lakes cladophora model v1 canale and auer 1982a is presented in a suite of seven papers authored by auer canale and colleagues and published in a special issue of the journal of great lakes research focusing on attached algae these works represent the first attempt to apply a mechanistic mass balance approach in simulating growth of the alga as a function of light temperature and nutrient status the model was applied in simulating the response of algal biomass density to changes in phosphorus loading from a wastewater treatment plant at harbor beach mi on lake huron canale and auer 1982b another platform based on the glcm v1 was developed by higgins 2005a termed the cladophora growth model cgm this framework accommodated the role of light below the algal canopy in mediating growth and the initiation of sloughing a second version of the great lakes cladophora model glcm v2 tomlinson et al 2010 modernized the coding platform added a graphical user interface revised algorithms and coefficients and applied the tool to data sets for lake huron calibration and lake michigan confirmation no field measurements or laboratory analyses were performed in support of glcm v2 development the cgm and the glcm v2 have been used to examine the effects of environmental perturbations on cladophora growth including the potential for climate change induced differences in the temperature regime malkin et al 2008 and increases in water clarity driven by water column filtration by mussels auer et al 2010 kuczynski et al 2016 malkin et al 2008 the mussel mediated resurgence in beach fouling by cladophora reflecting a 6 fold increase in post dreissenid production potential kuczynski et al 2016 their fig 8 has led to a call for improvements in mechanistic modeling of the alga to better inform management objectives bootsma et al 2015 the glcm is based on a mass balance approach where the ability of the alga to realize its maximum specific growth rate is limited by certain sources of environmental friction light temperature and nutrient availability and by sink term processes respiration and sloughing the maximum specific growth rate cannot be measured as cannot the efficiency of the perfect machine thus attention turns to characterization of the algorithms and coefficients describing environmental friction and sink processes shortfalls embedded in a model framework often lie hidden in under parameterization insufficient complexity over parameterization too much complexity and an inability to provide field and or laboratory validation of algorithms and or coefficients the challenge then lies in re examining the model s conceptual framework updating algorithms to better describe environmental friction and sink terms and improving estimates for model coefficients 2 objectives it is not only the passage of time and the evolution of technology that mandate advancement of the scientific foundation upon which glcm mathematics are applied but also the nature of the ecosystem now coinhabited by cladophora and dreissenid mussels hecky et al 2004 howell 2018 invasive dreissenids have had a profound impact on the light environment that impacts not only growth but also the timing of late summer detachment and attendant beach deposition kuczynski et al 2016 mussels have also influenced the nutrient environment by entraining and processing particulate matter releasing a significant fraction of its particulate phosphorus intake as soluble reactive phosphorus srp μgp l 1 ozersky et al 2013 the only form of the nutrient fully and freely available to algae reynolds 2006 thus particulate phosphorus has become a more important feature of the cladophora nutrient environment be it introduced through tributary and point source discharges auer et al 2021 or transported to the nearshore from the offshore zhou et al 2021 while dreissenids are not explicitly accommodated in the glcm they play a significant role in mediating the light and phosphorus forcing conditions that drive growth of the alga and attendant nuisance conditions thus a cladophora model supporting management application must carry a level of biokinetic rigor equal to the task here we present a new version of the great lakes cladophora model glcm v3 responding to the expressed need for development of an upgraded platform supporting phosphorus management bootsma et al 2015 our response focuses on objectives leading to better quantification of environmental friction i e the brakes on the maximum specific growth rate a key but indeterminable coefficient the glcm v3 incorporates features grounded in field observations and laboratory measurements applying ecologically sound mechanisms having utility across all four great lakes colonized by the alga 1 improved characterization of the light and temperature responses for rates of gross photosynthesis and light enhanced respiration 2 revision of the parameterization of phosphorus uptake to reflect the results of radioisotope measurements made at low ecologically meaningful srp levels and for low levels of stored p content 3 additional observations supporting mediation of growth by stored p 4 implementation of a physiologically and physically driven sloughing function based on near bottom current measurements and canopy modeling respectively 5 replacement of an overly deterministic approach for simulating carrying capacity with one using a self regulating canopy shading subroutine and 6 performance testing of the model for each of the four great lakes colonized by the alga in meeting these objectives we seek to establish a uniform set of model coefficients supporting simulation of cladophora biomass and phosphorus densities the resulting tool would be suitable for management applications across the great lakes and perhaps in other settings 3 model development and parameterization a model is an idealized representation of the response of a system to external stimuli model reliability increases as model complexity increases more fully describing the system under study reliability declines however when the conceptual formulation outpaces the understanding of the system arhonditsis et al 2019 chapra 2008 pauer et al 2018 the challenge is to retain model reliability as complexity increases by extending the scientific foundation supporting conceptual development chapra 2008 from its inception as v1 canale and auer 1982a the great lakes cladophora model has been supported by a robust effort to define kinetic relationships through field observations and laboratory measurements the subsequent development of the cladophora growth model cgm higgins 2005a evolution of the glcm v2 tomlinson et al 2010 and work presented here glcm v3 have retained this commitment to a science based foundation supporting the conceptual structure at its core the glcm v3 fig 1 is a mechanistic mass balance model simulating two state variables x the biomass density expressed as dry matter gdm m 2 and s the phosphorus density gp m 2 of the algal mat 1 d x d t μ g r o s s r l x and 2 d s d t ρ x r s l s an additional parameter stored p content also referred to as internal p cellular p tissue p and cell quota is calculated as the quotient of the phosphorus and biomass densities 3 q s x 100 where q stored phosphorus content of the alga gp gdm 1 expressed as net accrual of biomass and phosphorus density in the algal mat is determined as the balance between gains through gross growth for biomass density and p uptake for p density and losses of each to respiration and sloughing a third state variable srp may be accommodated in a linked fashion as a time series of concentrations input to the glcm v3 or by running the model in a coupled fashion within the larger framework of a mass transport phosphorus cladophora model additional details regarding parameterization of eqs 1 and 2 are provided subsequently where the focus lies on advancing the representation of physiological and physical processes in this manuscript we present the findings of field studies and laboratory experiments performed to advance the physiological and physical foundation for algorithms and coefficients driving simulation of cladophora growth a study site description and details of field sampling sample processing and analysis is provided in the supplementary material section 1 details of experimental protocols supporting laboratory measurement of rates of phosphorus uptake and mediation of growth and respiration by stored phosphorus are also provided in the supplementary material section 2 3 1 mediation of growth and respiration by light and temperature mediation of rates of growth and respiration occurs through attenuation of the maximum rate for each by environmental friction sub and supra optimal light intensities water temperatures and srp limitation external forcing conditions thus include seasonal variation in light intensity and water temperature vertical extinction of light through the water column and the algal mat and bioavailable p levels graham et al 1982 performed laboratory measurements of volumetric rates of gross photosynthesis and respiration mg o2 l 1 d 1 by p saturated cladophora over a matrix of light i and temperature t conditions volumetric rates of photosynthesis and respiration were converted to specific rates d 1 by applying the photosynthetic quotient 12 mg c per 32 mg o2 as used by auer and canale 1982c and measured carbon content for the algae samples kuczynski et al 2020 three dimensional response surfaces were then fit to the measured rates of photosynthesis and respiration offering a predictive capacity for rates at paired values of light and temperature prior efforts to fit a response surface to these results were successful except at the boundaries of the i and t ranges key regions with respect to growth limitation we re fit measurements seeking a better correspondence of predictions to measurements at those boundaries the effort to re fit the data included performance testing of the mediation functions and quantification of coefficient values i e maximum rates of gross photosynthesis and respiration algorithms describing the mediation of gross specific growth and specific respiration by light and temperature are summarized in table s1 of the supplementary material and the coefficient values embedded therein are provided in table 2 of the main manuscript fulfilling objective 1 3 1 1 fitting the gross specific growth rate response surface the gross specific growth rate μgross in eq 1 is a function of light temperature and soluble reactive phosphorus we defined μgross as a function of light and temperature based on experimental data from graham et al 1982 those authors measured growth and respiration rates in laboratory experiments with p saturated conditions over a light temperature matrix gradients of light and temperature 10 1200 μe m 2 s 1 and 1 35 c we fit curves μgross versus light for each discrete temperature slice interpolated between slices across temperature and then normalized the surface to result in the bivariate function f μ i t given p saturated conditions i e no limitation by srp the gross specific growth rate is defined as the product of the maximum gross specific growth rate coefficient and a dimensionless light and temperature mediation function 4 μ g r o s s i t μ m a x f μ i t note that f μ i t may be conceptualized as the ratio of μ g r o s s i t to μ m a x treatment of the light dependency of μ g r o s s i t in f μ i t is drawn from the work of platt et al 1980 as adopted for application to cladophora by kuczynski et al 2020 their fig 3 this light functionality substituted into eq 4 as two parenthetic terms yields an expression for calculating μ g r o s s i t for a range of discrete i values across a series of discrete t values 5 μ g r o s s i t μ g r o s s m a x t 1 e α μ g r o s s t i μ g r o s s m a x t e β μ g r o s s t i μ g r o s s m a x t calculations of μ g r o s s i t were made by applying eq 5 for paired values of i and t over a range of discrete values of i 6 8 values spanning 0 1200 μe m 2 s 1 and t 8 values 1 5 10 15 20 25 30 and 35 c values of the three coefficients μ g r o s s m a x t α μ g r o s s t and β μ g r o s s t were adjusted to achieve a best fit to measurements of μ g r o s s i t made in the laboratory over i t gradients as measured by graham et al 1982 values for those derived coefficients were fit to functions reflecting their temperature dependence 6 μ gross max t 0 34 t t 3 1 7 α μ gross t 0 55 1 e 0 001 0 55 t e 0 048 0 55 t 8 β μ gross t 10 17 t 9 3 the gross specific growth rate μ g r o s s i t for the surface was calculated by inputting values of t to eqs 6 8 and those results and values of i to eq 5 the resulting μ g r o s s i t surface was normalized by dividing by the maximum value of the fitted surface 0 288 d 1 to generate the final form of the dimensionless gross growth response surface f μ i t with values ranging from 0 to 1 fig 2 a 3 1 2 fitting the specific respiration rate response surface the specific respiration rate r in eq 1 is represented as the sum of light enhanced light period and basal dark period respiration 9 r r l e r b the specific rate of light enhanced respiration is defined as 10 r le r max f r i t note that f r i t may be conceptualized as the ratio of r l e to r m a x an adaptation of the platt et al 1980 equation similar to that adopted in eq 5 for gross growth is used here in determining r l e 11 r le r le max t 1 e α r t r le max t i the f r i t response surface was developed as for gross growth by adjusting the curve fitting parameters r l e m a x t and α r t to obtain a best fit to the laboratory measurements of graham et al 1982 the temperature dependence of those coefficients was determined to be 12 r le max t 0 10 1 03 t 20 and 13 α r t 0 00168 t t 2 5 permitting calculation of r l e by inputting values of t to eqs 12 and 13 and then those results and values of i to eq 11 the resulting rle surface was normalized by dividing by the maximum value of the fitted surface 0 187 d 1 to generate the final form of the dimensionless light enhanced respiration response surface f r i t with values ranging from 0 to 1 fig 2b the specific rate of basal or dark respiration depends only on temperature and is simulated using the simplified arrhenius equation 14 r b r b 20 θ t 20 eq 14 was fit to basal respiration rates measured by graham et al 1982 yielding values for the coefficients r b 20 and θ of 0 07 d 1 and 1 04 respectively kuczynski et al 2020 development of the f μ i t f r i t and r b functions is described in more detail by kuczynski et al 2020 3 2 mediation by phosphorus in the case of great lakes cladophora the limiting nutrient is phosphorus p mediation of cladophora growth and respiration by phosphorus may be conceptualized as a two step process the first step is acquisition of the nutrient through srp uptake ρ in eq 2 from the water column the second step is incorporation of p in the algal mat as structural material unavailable to support cellular processes and as polyphosphate bodies available for use in cellular processes stored p density s in eq 2 increases as p is taken up from the water column and decreases through respiration p excretion and sloughing of biomass the stored p content of the alga q in eq 3 varies with s but sloughing does not impact q as s and x are lost concurrently during detachment stored p content is the direct driver for nutrient limited growth and water column bioavailable p indirectly influences that process through uptake 3 2 1 stored p mediation by phosphorus uptake phosphorus uptake the source term in the s mass balance eq 2 contains a single coefficient the phosphorus uptake rate ρ which has been demonstrated to vary with both the water column srp concentration and the stored p level of the alga q in excess of its structural content the srp effect is stimulatory ρ increases as the srp concentration increases the q effect is inhibitory providing negative feedback on ρ as q increases stimulation by srp and inhibition by q are evident in results obtained by auer et al 1982a as shown in fig 3 a the algorithm describing the stimulatory behaviour is in the form of a michaelis menten equation 15 ρ ρ max srp k m srp here ρ increases linearly with srp before transitioning at an inflection point to a saturation response that asymptotically approaches the maximum phosphorus uptake rate ρ m a x fig 3a wet chemistry measurements of phosphorus uptake were made by auer and canale 1982b who examined a broad range of srp concentrations 10 1200 μgp l 1 in a successful effort to quantify the half saturation constant for p uptake k m there is less confidence however in measurements of ρ made by auer and canale 1982b at low srp concentrations 20 μgp l 1 due to limitations of the wet chemistry method at that time here we used radioisotope techniques in measuring ρ as a function of srp and q see supplementary material measurements were made over a range of environmentally meaningful srp concentrations 10 μgp l 1 using cladophora with different levels of stored p content these conditions are representative of great lakes waters dove and chapra 2015 and include those representative of sites proximate to point source discharges auer et al 2021 and in the benthic boundary layer at sites colonized by dreissenids dayton et al 2014 measurements of k m in cladophora are relatively few and exhibit considerable variability phosphorus uptake rates have been determined for the alga collected from saline systems e g peel inlet australia gordon et al 1981 and the baltic sea near stockholm sweden wallentinus 1984 yielding estimates of k m ranging 9 15 μgp l 1 in freshwater values for k m have been measured at 32 μgp l 1 e g in lake ontario rosemarin 1982 and ranging 15 86 μgp l 1 in the upper clark fork of the columbia river lohman and priscu 1992 a considerably broader range 30 250 μgp l 1 was reported for cladophora from lake huron by auer and canale 1982b where values for the coefficient increased as the stored p content of the alga decreased fig 3a the results of the radioisotope p uptake experiments performed in our study fig 3b confirm that michaelis menten kinetics serve well in representing the linear portion of the ρ srp relationship for environmentally significant srp concentrations methods applied in treating phosphorus uptake and mediation of growth by stored p content are provided in the supplementary material section 2 dependence of phosphorus uptake on the stored p content of the alga exerting an inhibitory effect on ρ with increasing levels of q is represented by defining ρ m a x as a function of q 16 ρ max a q b where a and b are fitting coefficients paired measurements of ρ m a x and q made by auer and canale 1982b by painter and kamaitis 1987 and in our study were fit to eq 18 yielding coefficient vales of a 0 012 d 1 and b 2 3 fig 3c the coefficients were determined by model calibration seeking the best fit to predicted biomass density x and stored p q measurements rather than to ρ max thus the apparent bias in fig 3c the bivariate phosphorus uptake relationship is illustrated in fig 3d demonstrating the role of negative feedback by q in limiting uptake when the stored p content increases additionally the significance of exposing algae with low q levels to elevated srp concentrations across the range of environmentally significant srp levels is demonstrated the results of laboratory measurements and algorithm refitting confirm the utility of the michaelis menten relationship supplemented with a q driven negative feedback mechanism in simulating rates of phosphorus uptake by cladophora and thus accomplishing our objective 2 3 2 2 growth mediation by stored phosphorus the influence of nutrient limitation on gross growth is accommodated by including a multiplicative stored phosphorus mediation function f q in eq 4 17 μ gross μ gross max f μ i t f q where f q phosphorus mediation function dimensionless the algorithm for respiration does not include a phosphorus mediation factor as it is assumed not to be influenced by nutrient limitation the form of f q used here is that of the droop equation droop 1968 18 f q 1 q m i n q which may be described as a rectangular hyperbola with f q 0 at q qmin when p is only present as structural material not as storage in accessible polyphosphate bodies then increasing linearly with q and asymptotically approaching f q 1 fig 4 the phosphorus content of the alga can vary widely from near qmin in p starved organisms to the point where p stored as polyphosphates is by a significant margin the most abundant q fraction for example p content ranged over almost an order of magnitude 0 028 0 230 on several dates across multiple sites in lake erie higgins 2005a those authors characterized the degree of p limitation in cladophora based on p content as critical 0 06 severe 0 06 0 10 moderate 0 10 0 16 and non p limited saturated 0 16 variation in p content can reflect intersite differences in light depth p discharges and intrasite variation due to seasonal changes in p discharge particularly for tributaries and over a shorter term as a result of p plume location particularly for effluents we fitted the droop function to paired measurements of the net specific growth rate μ n e t μ g r o s s r l and p content based on measurements made by auer and canale 1982b on lake huron and our efforts described here on lake ontario in 2015 and 2016 see supplementary material sections 1 and 2 2 for methods sensitivity analysis performed in our work described in section 4 6 identified q m i n as a particularly significant model coefficient regulating the rate at which growth increases with increasing stored p content and the position where growth transitions from p limited to p saturated conditions for example for algae with a q of 0 1 values of q m i n 0 03 0 04 and 0 05 give model predicted values of the normalized net growth rate of 0 5 0 6 and 0 7 respectively thus selection of a value for q m i n is an important step in model parameterization observationally minimum values of q have been identified as 0 028 0 040 higgins et al 2005c 0 045 tomlinson et al 2010 and 0 04 0 05 wong and clark 1976 auer and canale 1982b jackson and hamdy 1982 model applications have most often selected a value of 0 05 canale and auer 1982a higgins et al 2006 malkin et al 2008 tomlinson et al 2010 adopted a value at the lower end of the observed range 0 035 noting that q m i n would seldom if ever be observed in nature as algae with that stored p content would be non viable here we use a value of 0 04 consistent with values measured in field collections and our fit to the droop function fig 4 we recommend that the value of q m i n be examined over the range 0 028 0 050 in future glcm v3 applications measurements of μ n e t are represented by the phosphorus mediation function eq 18 multiplied by a maximum net growth rate μ n e t m a x fig 4a the droop function itself is a fit to those data and when normalized ranges from 0 to 1 fig 4b eq 18 was fitted to measurements of μ n e t and normalized using the value of μ n e t m a x 0 714 d 1 measured by auer and canale 1982b because no experiments were conducted using algae with high q 0 15 in this study this value is comparable to those reported by rosemarin 1982 painter and kamaitis 1987 and higgins et al 2008a and to output from of model simulations performed by fillingham 2015 we note that while similar to the fit used in the original glcm v1 the new fit favours results obtained for both the low q lake ontario samples unavailable at the lake huron site and the high q lake huron samples unavailable at the lake ontario site these results represent achievement of our objective 3 3 3 sloughing sloughing detachment of algal filaments has long been considered an important feature of cladophora modeling as its initiation signals the onset of the summer die off and attendant beach and water intake fouling today there is general agreement that both physiological filament senescence and physical wind driven shear stress processes play a role in mediating sloughing biggs and thomsen 1995 horner et al 1990 higgins et al 2008a tomlinson et al 2010 the treatment of sloughing has undergone a greater evolution in a modeling context than has any other process in the cladophora mass balance 3 3 1 physiological forcing of sloughing the first attempt to incorporate the complex sloughing mechanism in a model the glcm v1 canale and auer 1982a did not accommodate physiological forcing this shortfall was recognized however as simulation results failed to track observations of a striking decline in biomass density in late summer it was concluded that a metabolic imbalance negative net photosynthesis causes physiological deterioration of algal filaments however the science supporting a mechanistic incorporation of that process was not yet available agreement was later reached that exposure to sub optimal conditions of light and or temperature for a particular length of time would lead to senescence a loss of physical integrity and an increasing vulnerability to drag and turbulence induced detachment see horner et al 1990 thus subsequent efforts focused on mechanistically characterizing the senescence process with two schools of thought emerging the first of these was mediation by supra optimal light and temperature conditions graham et al 1982 identified an optimum temperature range for cladophora growth of 13 17 c with respiration exceeding photosynthesis in well lit environments at temperatures elevated beyond this range summer temperatures of 20 25 c are common in great lakes waters the resulting metabolic imbalance would then lead to senescence and vulnerability to detachment this approach was adopted in the next generation of cladophora models cgm higgins et al 2005b glcm v2 tomlinson et al 2010 the second mechanism was that of self shading i e the canopy effect here as biomass levels increase the thickness of the algal bed canopy increases and light is attenuated with depth in the bed extended periods of light limitation within the bed result in a metabolic imbalance at its base and the senescence process is initiated this second approach was adopted for the cgm by higgins et al 2008a cgm and more recently by kuczynski et al 2020 for incorporation in the glcm v3 application of either of these approaches required a means of initiating sloughing i e the point at which the loss of filament integrity becomes sufficiently manifest to engender detachment higgins et al 2005b cgm accomplished this by invoking catastrophic sloughing 90 of the standing crop daily at a threshold water temperature of 23 5 c tomlinson et al 2010 glcm v2 applied a function where the sloughing coefficient increased linearly from water temperatures of 13 to 17 c the optimum temperature range for growth graham et al 1982 and subsequently remaining at its maximum value higgins et al 2006 were the first to employ the canopy shading approach proposing a trigger initiated when model calculated respiratory losses at the base of the bed exceeded 40 of the biomass over a 10 day period and holding the loss rate at the maximum value established by higgins 2005a 3 3 2 physical forcing of sloughing the treatment of physical forcing of sloughing in cladophora models has historically been less complex than that for senescence focusing primarily on the means of representing near bottom turbulence conceptualization of the process progressively recognized that wind speed water column depth and the degree of senescence characterized the driving force for detachment thus high winds occurring over shallow depths later in the growing season would lead to the greatest incidence of sloughing the first treatment of the process canale and auer 1982a glcm v1 quantified sloughing loss as increasing to a maximum rate as wind speed turbulence and biomass density momentum of oscillating filaments increased subsequently higgins et al 2005b cgm modified the glcm v1 approach accommodating variation in wind driven turbulence due to fetch and water depth tomlinson et al 2010 extended this approach calculating a shear stress exceedance frequency based on wind speed fetch and water depth 3 3 3 advancing the treatment of sloughing in the glcm v3 moving forward from the work of higgins et al 2005b 2006 2008a and tomlinson et al 2010 we considered two features of the sloughing process the first of these is mechanistic treatment of the onset trigger point and time course of sloughing in response to a decline in physical integrity senescence the need to further investigate this physiological issue is first evident implicitly higgins et al 2008a tomlinson et al 2010 and explicitly higgins 2005a higgins et al 2006 in the work of others where the approach was well conceived but not mechanistic in nature the second is a field verification of the attenuation of near bottom turbulence as a function of depth a feature of the sloughing dynamic that has been incorporated in models but not supported by ground truth measurements the physiological processes that govern sloughing initially quantified empirically by higgins et al 2005b as a threshold phenomenon triggered by temperature was subsequently treated more mechanistically as being mediated by self shading within the canopy higgins et al 2008a in that work a critical algal density was calculated below which a negative energy balance occurs at the base of the mat leading to cellular deterioration weakening of filament strength and increased susceptibility to physical detachment building on the conceptualization of higgins et al 2008a and our mechanistic treatment of the canopy effect kuczynski et al 2020 we propose an algorithm containing physiological and physical factors providing a predictive mechanism for the onset of sloughing and a progressive approach to a maximum specific sloughing rate 19 l l m a x f 1 f 2 with a sigmoid function of the form 20 f 1 1 e 12 t d u r t 6 t s t a r t t m a x t s t a r t t m a x 1 the only model coefficient requiring parameterization in function f 1 is t d u r determined by calibration at 30 days the glcm v3 calculates the mean daily net specific growth rate at the bottom layer of a vertically segmented algal mat see section 4 5 to determine if positive net growth is occurring at that point under local light conditions incident light and water column and algal mat attenuation see section 4 5 sloughing is initiated t s t a r t when the daily net growth rate at the mat bottom is equal to or less than zero the sloughing rate then increases in a sigmoid fashion fig 5 over the period tdur bounded by t s t a r t and t m a x where the latter is the day of the year on which the maximum specific sloughing rate is achieved and maintained thereafter note that this formulation offers the user the opportunity to simulate the catastrophic sloughing event of higgins et al 2005b the linear manifestation of sloughing tomlinson et al 2010 or use field observations of the onset of sloughing and approach to a maximum rate fig 5 the mediation factor f 2 describes the attenuation of wind driven current speed a determinant of near bottom shear and drag forces with depth the analysis is based on tilt current meter tcm measurements of near bottom current velocities fig 6 providing a representation of the physical mediation of sloughing supported by ground truth measurements made in cladophora habitat see supplementary material section 1 the function describing attenuation of physical forcing with depth 21 f 2 a e b z c was parameterized by fitting paired measurements of current velocity and depth z using three fitting parameters a 0 4635 b 0 3054 and c 0 5365 the resulting curve was normalized to the current speed at z 0 yielding a relationship that describes attenuation of the physical factor velocity that drives sloughing as a function of depth fig 6 the glcm v3 advances the mechanistic treatment of sloughing by implementing a canopy shading subroutine that accommodates senescence as a process impacting filament vulnerability to detachment in addition we provided field verification of the how turbulence which drives detachment is attenuated with depth together the results of these efforts represent fulfilment of objective 4 we note that we use current speed as a surrogate for bottom shear stress the immediate physical component resulting in detachment the algorithm implemented in the glcm v3 does not view sloughing as a near immediate catastrophic phenomenon in response to physical factors such as velocity driven bottom shear stress but more as a process evolving over a period of days to weeks in response to deteriorating physiological conditions fig 5 it remains to quantify measure the time course t d u r of loss in filament integrity following initiation of a negative energy balance at the canopy base the physiological component resulting in detachment this latter feature is likely well described by the tensile strength of the algal filaments a metric that may be measured directly johnson et al 1996 on collections made over the growth season a comprehensive field and laboratory program treating this issue would include seasonally deployed cameras diver collected cladophora samples for quantification of biomass density stored p content and tensile strength light and scanning electron microscopy to determine epiphyte presence cell wall integrity and filament health 4 model implementation and testing the glcm v3 was implemented using a new formulation for carrying capacity in a self shading or canopy context section 4 1 the model was tested by means of a sensitivity analysis section 4 2 and its performance was tested against field measurements of state variables section 4 3 finally we identify challenges and potential for model improvement in the future section 4 4 4 1 model implementation in a canopy context negative feedback on growth as algal biomass approaches the carrying capacity has commonly been accommodated in cladophora modeling through application of the logistic model i e inclusion of a carrying capacity term canale and auer 1982a higgins 2005a tomlinson et al 2010 it has been recognized that this approach fails to reflect the significance of light attenuation through the algal canopy higgins 2005a 2008a kuczynski et al 2020 and is overly deterministic i e offers great latitude for tuning of the maximum biomass density in calibration and performance testing instead of a carrying capacity term we have adopted a canopy based approach in this work the physical framework for this approach consists of an algal canopy of n 1 centimeter layers in the vertical dimension specification of the initial condition for cladophora biomass density involves filling the canopy evenly layer by layer with biomass and capturing any remaining biomass in the topmost canopy layer kuczynski et al 2020 used a constant biomass density per centimeter mat layer height of 9 gdm m 2 cm 1 this however can result in unrealistically high total mat heights e g 50 cm or more for great lakes cladophora instead of using a constant biomass density per layer we calculated the mat height as a function of mat biomass density fig 7 fitted to unpublished measurements of s malkin 22 z m a t 1 9415 x 0 4138 where zmat algal mat height cm then the simulated canopy biomass density is divided by the mat height to determine the biomass density for each mat layer this approach results in a more tightly packed more dense algal mat at higher canopy biomass densities and a less tightly packed less dense algal mat at lower canopy biomass densities consistent with s malkin s measurements fig 7 for each time step the layer specific light intensity is calculated as described below and then net growth gross growth minus respiration and sloughing is calculated to quantify the incremental biomass accrual for each layer the cumulative change in biomass is the sum of the change in biomass in each layer and a new time step specific canopy biomass density is calculated that biomass density becomes the starting point for the next time step the resulting biomass is redistributed over the canopy as for the initial condition and a new canopy height is calculated changes in stored p content are handled concurrently in a similar fashion resulting in homogeneity in both biomass and stored p density across canopy layers model output takes the form of two daily times series cladophora biomass density x and stored p content q calculated from the phosphorus and biomass densities of the mat eq 3 environmental forcing conditions for calculating gross growth respiration and sloughing include hourly incident light i 0 daily water temperature t the soluble reactive phosphorus concentration s r p and depth z incident light is attenuated by water column and algal mat extinction coefficients to determine light at depth and within the algal canopy the beer lambert law is applied using site specific light extinction coefficients the sequential attenuation of incident light through the water column and through the algal mat is given by 23 i z i 0 e k e z e k alg z mat as z m a t increases light at the mat bottom decreases with a corresponding reduction in the net specific growth rate this has been called the canopy effect kuczynski et al 2020 and ultimately leads to senescence development and implementation of a self regulating canopy shading subroutine for simulation of carrying capacity thus meets objective 5 the glcm v3 is implemented by solving the differential equations for cladophora biomass density eq 1 and algal mat phosphorus density eq 2 using an euler integrator here with a time step of 0 01 d a summary of all model equations input requirements and recommended coefficient values is supplied as supplementary material section 3 4 2 sensitivity analysis a sensitivity analysis was conducted to identify model coefficients having the most significant effect on simulation behaviour the analysis also served in providing guidance for coefficient selection in model calibration and in identifying processes meriting future study a baseline model run was made using mean environmental forcing conditions table 1 and selected model coefficient values μ m a x 1 4 d 1 r m a x 0 5 d 1 r b m a x 0 07 d 1 k a l g 24 m 1 q m i n 0 04 ρ m a x 0 012 q 2 3 k m 125 µgp l 1 l m a x 0 08 d 1 and t d u r 30 d and initial conditions x 0 1 gdm m 2 and q 0 0 04 values are similar to those used by kuczynski et al 2020 in a base run simulation sensitivity analysis simulations were performed for a depth of 9 m over a period of 5 5 months day of year 122 to 289 or 1 may to 15 oct sensitivity of biomass density x and stored p content q calculated hourly was examined for a 20 adjustment of coefficient values tested individually fig 8 the sensitivity of the response was evaluated with respect to representative field measurements of maximum biomass density and maximum stored p content at a depth of 9 m the maximum modelled biomass density was most sensitive to the maximum specific growth rate μ m a x the coefficient for light extinction through the algal mat k a l g and the minimum stored p content q m i n the lower and upper bound for the maximum specific growth rate 1 12 and 1 68 d 1 resulted in a 54 7 decrease to 154 gdm m 2 and a 73 4 increase to 590 gdm m 2 respectively in the base case maximum biomass density the lower and upper bound k a l g values 19 2 and 28 8 m 1 resulted in a 65 0 increase to 561 gdm m 2 and a 34 7 decrease to 222 gdm m 2 respectively in the base case maximum modelled biomass density the lower and upper bound q m i n values 0 032 and 0 048 resulted in a 51 5 increase to 515 gdm m 2 and a 38 9 decrease to 208 gdm m 2 respectively in the base case maximum modelled biomass density perturbations of 20 for all other tested model coefficients resulted in less than a 35 change in maximum modelled biomass density the maximum modelled stored phosphorus content was sensitive to ρ m a x and k m and relatively insensitive less than 4 change with respect to all other tested coefficient perturbations increases and decreases in stored p with respect to the two named coefficients were all less than 10 fig 8 we also evaluated different fitted functions for the maximum uptake rate eq 15 i e functions describing the lower and upper bounds of the shaded area in fig 3c the lower bound for the q multiplier in the ρ m a x function 0 008 q 2 4 resulted in an 8 8 decrease in maximum biomass to 310 gdm m 2 and a 5 3 decrease to 0 10 in the maximum modelled stored p the upper bound for the q multiplier in the ρ m a x function 0 035 q 2 6 resulted in a 105 5 increase to 699 gdm m 2 in maximum biomass and a 64 9 increase to 0 178 in the maximum modelled stored p recommended model coefficient values are presented in table 2 4 3 performance testing the final objective of our research plan was to secure a multi lake calibration suitable for simulation of the magnitude and seasonality in biomass density and stored p content based on a uniform set of model coefficients that would limit tuning this approach applied here for lakes erie huron michigan and ontario provides a more rigorous confirmation than that for a single lake and demonstrates that the framework is appropriately parameterized and robust to accurately adapt across systems with different physical characteristics and trophic states performance criteria are those particularly important in management applications the maximum achievable biomass density the steady state stored p content and the timing of the onset of sloughing model performance may be assessed by employing subjective and or objective approaches chapra 2008 the subjective approach usually involves a visual examination of times series of the state variables here cladophora biomass x and stored p content q evaluating their magnitude maximum mean and time course of seasonal expression the objective approach uses quantitative measures of goodness of fit such as the coefficient of determination r2 in this application a subjective approach is used to examine the day to day tracking of x and q of interest in exploring model behaviour and an objective approach in examining seasonally averaged metrics of interest in a policy and regulatory context notably this is the first time that a cladophora model has been tested across the four great lakes colonized by the alga cladophora biomass density and stored p content were simulated and compared with published datasets from lake huron canale and auer 1982a lake michigan tomlinson et al 2010 lake erie higgins et al 2008a and lake ontario malkin et al 2008 results are shown in fig 9 these runs require user input of initial conditions for biomass and stored p content and time series of forcing conditions temperature incident light and light extinction factors and srp concentration see supplementary material table s2 it must be noted that the quality of the input forcing conditions strongly affects the goodness of fit of model output to observations data sets that were not collected specifically in support of model development often have gaps in these critical inputs glcm v3 simulations conducted for this work draw upon several different calibration and input data sources of varying quality e g method and precision in biomass density measurements and temporal resolution e g daily weekly or single srp measurements for a season model runs also require user specification or default values for biokinetic and physical coefficients μ m a x r m a x q m i n k a l g l m a x ρ m a x in model calibration a best fit of model output to measurements is sought while retaining coefficient adjustment within bounds determined by field observation or laboratory experimentation table 2 and guided by sensitivity analysis calibration was performed to yield a uniform set of values for these biokinetic coefficients leaving only k a l g as a lake specific calibration coefficient these uniform values excepting k a l g are retained in simulations across all four lakes the glcm v3 performed well in all capacities except in tracking short term variations in algal stored p content and to a lesser extent biomass density figs 9 and 10 temporal dynamics of stored p and biomass density are driven in large part by ambient srp concentrations and water column light extinction respectively we ascribe this shortfall to the availability of time series for ambient srp concentrations impacting stored p content and in some cases for k e impacting biomass density the best fits to algal biomass density and stored p content were obtained for lake michigan figs 9 and 10 where the monitoring program was designed to support development of the glcm v2 tomlinson et al 2010 the data set included weekly k e and near weekly srp measurements of environmental forcing conditions and weekly measurements of algal biomass and stored p content correlations between model output and observations algal biomass density r2 0 99 stored p content r2 0 89 intercepts set to zero for lake michigan were the best of the four sites measured values of stored p content ranged 0 05 0 15 gp per gdm expressed as and were well represented by model output figs 9 and 10 input and calibration data for the lake erie simulation included approximately fortnightly measurements of k e algal biomass density and stored p content higgins et al 2008a with k e values interpolated between sampling dates for use as model input as no srp time series was available a seasonal average concentration 2 0 μgp l 1 was applied model output fit observations of algal biomass density well figs 9 and 10 r2 0 95 intercept set to zero but tracked the range of stored p content 0 04 0 25 gp per gdm as poorly due to the unavailability of an srp times series and thus a largely invariant model predicted stored p content the lake ontario data set includes constant values for both k e 0 43 m 1 and srp 1 μgp l 1 and weekly measurements of algal biomass density and stored p content application of constant values for k e and srp limited the ability to track short term variations in algal biomass density and stored p content the correlation coefficient for algal biomass density was r2 0 85 intercept set to zero and simulation results captured the ascending limb of the biomass curve well there was little correlation r2 0 72 with intercept set to zero between model predictions and observations of stored p content the latter ranging 0 05 0 26 gp per gdm as but paired values clustered closely across the season fig 9 the lake huron data set canale and auer 1982a reported algal biomass density and stored p content on a weekly basis but used constant values retained here for k e 1 37 m 1 and srp 17 μgp l 1 the lake huron data set is the least robust of the four data sets used in testing model performance as it focused on a highly dynamic phosphorus footprint close proximity to a wastewater treatment plant and lacked contemporary technologies for recording k e and measuring srp at low ecologically meaningful concentrations esp important in describing the phosphorus uptake rate due to the degree of p saturation at that site however the glcm v3 fit the ascending and descending limbs of the biomass curve well at all but 3 of 11 measurements fig 9 and model output and measurements were well correlated fig 10 r2 0 95 intercept set to zero the broad range in stored p content observed at the lake huron site 0 2 0 5 gp per gdm as was not tracked well due to the use of a constant srp concentration at a spatially dynamic point p source site based on the results of performance testing of the glcm v3 described here for the four great lakes colonized by cladophora we consider objective 6 of our research plan to have been met the model performs well in predicting magnitude and timing of peak biomass and the onset of sloughing key features for model application in managing nuisance growth of cladophora 4 4 challenges and future work the opportunity to focus on a single species vis à vis the more common multi species assemblages of the phytoplankton community affords a particular benefit in modeling cladophora challenges do however remain for example quantification of the maximum specific growth rate coefficient μ m a x through field and laboratory measurement attracts the epistemic curiosity historically accorded a perpetual motion machine much as development of such a machine is considered impossible because friction and dissipative forces cannot be eliminated μ m a x cannot be measured directly because the forces of environmental friction e g respiration sloughing cannot be completely eliminated this is an untenable objective e g p 700 of droop 1968 yet μ m a x has been identified as a particularly important coefficient in the glcm v3 sensitivity analysis section 4 6 and fig 8 according to benedini and tsakiris 2013 the μ m a x coefficient used in attached algae or periphyton models for streams ranges 1 3 d 1 measurements and models specific to cladophora and other periphyton suggest rates ranging 0 1 2 7 d 1 table 2 the question then becomes do differences in estimates of μ m a x in cladophora reflect for example true intersite variation in the coefficient value or do they represent the cumulative uncertainty in resolving descriptors of environmental friction the inherent inability to measure μ m a x dictates that this coefficient will always be determined by calibration thus we seek to reduce uncertainty in quantifying environmental friction while discouraging overly deterministic tuning of μ m a x by limiting the range over which it may be varied in calibration table 2 a second challenge lies in specification of k a l g the coefficient for light extinction through the cladophora mat a coefficient to which the canopy effect self shading is especially sensitive section 4 6 fig 8 values for k a l g have been reported to vary from 10 to 30 m 1 in the great lakes higgins 2005a malkin et al 2008 and reach values as high as 150 7 m 1 in a riverine environment where the mat is more appressed flynn 2014 flynn et al 2018 values of k a l g are amenable to direct field measurement in lacustrine habitats wind driven turbulence may serve to suspend the canopy reducing the mat compression characteristic of quiescent conditions and leading to considerable variability in k a l g we recommend additional quantification of expected ranges in this coefficient and perhaps inclusion in the model of an algorithm describing the magnitude of its wind driven variation in a similar vein identification of the timing of the trigger for and temporal manifestation of sloughing merits attention section 3 3 5 conclusions the glcm v3 driven by algorithms grounded in ecological concepts and parameterized using field and laboratory derived kinetic coefficients serves well both visually fig 9 subjective evaluation and analytically fig 10 objective evaluation in tracking the late spring increase ascending limb mid summer maximum peak and late summer reduction descending limb in biomass density characteristic of the seasonal growth curve the model also performs well in characterizing the mean stored p content of the alga including intersite differences but does not satisfactorily resolve temporal variability figs 9 and 10 where well resolved time series of srp are unavailable however predicted levels of biomass density and stored p content match observations well when considered in terms of their mean standard deviation fig 11 we believe that the modeling approach presented here is drawing close to an optimum position on the complexity reliability spectrum chapra 2008 we recognize that our effort to parameterize and performance test the glcm v3 across four great lakes necessarily drew upon field measurements made in one case decades apart from the others and involves different investigators with their own suite of field techniques and analytical methods thus attention appropriately turns to improved characterization of model forcing conditions and the coefficients imbedded in model algorithms compared to the other three study sites considered here the lake michigan data set tomlinson et al 2010 is most robust due to its temporal sampling frequency improved method detection limits and available time series for srp and the water column light extinction coefficient k e it is anticipated that contemporary efforts to coordinate monitoring by government agencies will result in consistent methodologies and sampling plans strengthening this feature of cladophora studies we believe that we have significantly advanced the body of knowledge regarding algorithms and their coefficients specifically those for growth and respiration as a function of light and temperature the role of phosphorus uptake in mediating stored p content the manner in which nutrient content controls growth and the value of a canopy based approach in simulating carrying capacity and the onset and time course of sloughing we have successfully calibrated the model to fit algal biomass density and stored p content measurements from the four great lakes colonized by cladophora using a uniform cross lake set of model coefficients excepting only the maximum specific growth rate coefficient μ m a x and the coefficient for light attenuation through the algal canopy k a l g the first of these may not be directly determined while the latter is an excellent candidate for future study with respect to algorithms and coefficients the glcm v3 is very different from its predecessors advancements made on the modeling front will serve to complement improvements in monitoring this third version of the great lakes cladophora model can have considerable value in supporting future research on nuisance growth of the alga however it is in the determination of targets for phosphorus controls seeking management of nuisance cladophora growth in the great lakes that the tool finds its intended application the great lakes water quality agreement of 2012 requires that levels of algal biomass must be held below those constituting nuisance conditions we recommend that the glcm v3 be applied in conjunction with a hydrodynamic model and a biogeochemical model simulating nutrient cycling to establish relationships between seasonal maximum biomass and ambient phosphorus concentrations auer et al 2021 in turn regional targets can be determined for p loads and appropriate discharge mixing zones to curb cladophora growth the model also holds promise in addressing features of the dual challenge to balance concurrent oligotrophication and eutrophication concerns in the great lakes hecky and depinto 2020 zhou et al 2021 credit authorship contribution statement anika kuczynski conceptualization data curation formal analysis investigation methodology software validation visualization writing original draft writing review editing martin t auer conceptualization funding acquisition investigation methodology project administration resources formal analysis supervision writing original draft writing review editing william d taylor data curation formal analysis writing original draft writing review editing steven c chapra conceptualization methodology software writing review editing marcel dijkstra conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study and article are grounded in the pioneering work on mechanistic cladophora modeling by r p canale m t auer and colleagues and scientists including s n higgins s y malkin r e hecky s j guildford and colleagues radioisotope experiments were conducted at the ontario ministry of environment and climate change dorset environmental science centre and supported by an nserc canada discovery grant to w d taylor jennifer eikenberry performed the c analysis on algae samples terrianna bradley aubrey scott mary maggie stangis michelle nitz and hayden henderson were instrumental in completing the field and experimental laboratory work this work was funded in part through a research grant to michigan technological university from the town of ajax ontario supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2022 110118 appendix supplementary materials image application 1 
