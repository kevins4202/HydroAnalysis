index,text
23930,motivated by observations of fine scale vertical shear and its contribution to mixing in the tropical ocean this study explores the impact of vertical resolution in an ocean model on sea surface temperature in the tropical pacific ocean we conduct two model experiments that differ in the vertical discretization only with the grid spacing in one being significantly smaller than the other in the upper ocean we examine the temperature difference between the high and low vertical resolution experiments we find that the difference in the upper most layer is positive in the equatorial cold tongue and negative along the south american coast thus reducing the commonly seen cool and warm biases in the two regions respectively the change in the structure of the vertical diffusivity as determined by the k profile parameterization is identified as the primary cause in reducing the biases in the central equatorial pacific the change in the vertical diffusivity from low to high vertical resolution in the upper pycnocline results in a positive temperature difference that propagates eastward as an equatorial kelvin wave rising to the sea surface in the central and eastern regions to increase the sea surface temperature there in the far eastern equatorial pacific the change in the vertical diffusivity in the lower pycnocline produces a negative temperature difference that propagates poleward as coastal kelvin waves along the west coast of the american continent outcropping along the south american coast to reduce the sea surface temperature there the high vertical resolution experiment captures much of the small scale vertical velocity shear and resolves the fine details of the stratification in the upper ocean our analysis suggests that the shear generated turbulence is the primary contributor to the change in the vertical diffusivity in the central region whereas stratification is the dominant factor in the far eastern region keywords sea surface temperature fine scale velocity shear stratification vertical mixing pycnocline kelvin waves 1 introduction sea surface temperature sst the principal communicator of the ocean with the atmosphere plays a very important role in the tropical pacific yet many ocean models and coupled atmosphere ocean models often have difficulties in correctly reproducing its observed characteristics the cool bias of the cold tongue in the eastern equatorial pacific and the warm bias off the south american coast are two such examples the cool bias of the cold tongue is generally associated with too intense easterly trade winds in the western and central pacific it is difficult to determine the root cause of this bias because of the complex feedback mechanisms of the atmosphere ocean system but there have been many studies that try for example vannière et al 2014 investigated sst biases in the tropical pacific with a multitude of simulations using ocean only atmosphere only and coupled atmosphere ocean models they suggested that a cool bias in the subtropical regions could give rise to a cool bias in the equatorial cold tongue transmitted through advection by the subtropical cells stcs mccreary and lu 1994 and propagation by ocean waves this mechanism is supported by the analysis of burls et al 2017 using output from climate models that participate in the coupled model intercomparison project phase 5 cmip5 they found a high correlation in sst between the equatorial zone and the extra tropical subduction regions across the cmip5 models and a link between positive cloud albedo bias thus reduced shortwave radiation into the ocean and negative sst bias in extra tropical regions li and xie 2012 2014 by comparing cmip5 and cmip3 models with their corresponding atmosphere only models came to a similar conclusion that a high cloud coverage in the atmospheric models is correlated to a cool bias in the mean sst across all tropical oceans additionally li and xie 2012 2014 suggested that a shallow thermocline in the upwelling region of the equatorial pacific in the ocean components of the coupled models is the cause of a cool bias in the cold tongue and through the bjerknes 1969 feedback mechanism a positive bias in the easterly winds arises as a result the basis for this conclusion is that the wind bias does not exist in atmosphere only models forced with observed sst causes of the warm bias off the south american coast have been investigated by a number of studies as summarized in zuidema et al 2016 identifying inadequacies in the representation of low level clouds convection and winds in the atmospheric component and thermocline structure in the ocean component among others it is also recognized that model resolution in both the atmosphere and ocean is often a limiting factor in resolving the relevant processes in the climate models currently in use the message is clear from the studies mentioned above and many more that sst biases originate in both the ocean and the atmosphere components of a coupled model an error in one component can lead to errors in the other and these errors may be amplified through the strong coupling between the atmosphere and ocean ocean mixing plays an important role in modulating the temperature in the upper ocean observational studies show that ocean mixing exerts strong controls on the seasonal cycle of sst moum et al 2013 and is actively involved in the phase transitions of the el niño southern oscillation enso warner and moum 2019 at 140 w equator in ocean models equatorial pacific sst is highly sensitive to the specification of vertical mixing e g jochum 2009 richards et al 2009 zhu and zhang 2018 2019 along the equatorial pacific the application of a low background vertical diffusivity a parameterization of ocean mixing by unresolved processes usually leads to a warmer cold tongue through the sharpening of the thermocline meehl et al 2001 showed that models with a colder than observed temperature in the upper ocean tend to have a too shallow thermocline even though they may produce the observed thermocline intensity and el niño amplitude at low vertical diffusivity naturally an important prerequisite to reducing sst bias must be a realistic thermocline structure both its thickness and its depth jia et al 2015 undertook a systematic study of the impact of vertical diffusivity on the temperature structure of the equatorial pacific ocean they found that the depth and the thickness of the equatorial pycnocline thermocline can be altered by varying the vertical diffusivity with depth with ocean only model experiments sasaki et al 2012 demonstrated that an enhancement of the background vertical diffusivity within and above the thermocline both sharpens and deepens the thermocline and the cool bias of the cold tongue is reduced as a result this effect is amplified in a coupled atmosphere ocean model sasaki et al 2013 through the bjerknes feedback and sst shortwave flux feedback klein and hartmann 1993 the modeling studies by sasaki et al 2012 2013 were motivated by measurements taken in the western equatorial pacific richards et al 2012 2015 vertical velocity shear was observed to be dominated by flow features with small vertical scales 20 50 m contributing to an increase in vertical mixing within and above the thermocline in the eastern equatorial pacific the cold tongue region enhanced mixing in the thermocline has also been observed from argo float and the tropical ocean and atmosphere tao mooring measurements liu et al 2016 2019b identified numerous mixing events in the thermocline and attributed them to low richardson numbers resulting from shear associated with tropical instability waves tiws and the equatorial undercurrent euc furthermore liu et al 2019a 2020 found small vertical scale 10 50 m shear induced by the interaction between the equatorial current system and equatorial waves of different dynamic types and multiple time scales in the upper thermocline energetic motions with a vertical wavelength of 40 m referred to as a shear wave was reported by peters et al 1991 from observations taken on and off the equator along 140 w in april 1987 during the second cruise of the tropic heat program the large impact on the climate system shown by sasaki et al 2013 from a simple parameterization of vertical diffusivity warrants a further investigation into the characteristics of vertical mixing along the whole extent of the equatorial pacific in particular the contribution from shear at different vertical length scales in this study we address this issue by conducting numerical experiments with an ocean model at two vertical resolutions one that is comparable with those in many ocean models currently in use and the other that is significantly finer in the upper ocean through the use of a richardson number based scheme and by specifying a low background value for the vertical diffusivity the contribution to mixing from resolved shear at different vertical resolutions of the model experiments can then be compared and contrasted the present research may be considered as an extension of the two part study by furue et al 2015 and jia et al 2015 we apply the analysis method developed in furue et al 2015 to examine the difference in temperature structure and relate the difference to the change in the mixing structure resulting from an increase in vertical resolution based on the key findings of the two part study the details of our experimental design are described in section 2 we present our results in section 3 making connections among the changes in sst subsurface temperature vertical mixing structure stratification and vertical velocity shear as a result of an increase in vertical resolution we summarize and discuss our results and provide concluding remarks in section 4 2 experimental design we use a version of the massachusetts institute of technology general circulation model mitgcm marshall et al 1997 which solves the incompressible navier stokes equations discretized into finite volumes on a sphere the model configuration is an adaptation of that used by furue et al 2015 and jia et al 2015 for the tropical pacific with minor modifications the meridional extent of 26 s 30 n is maintained while the western boundary of the domain is extended westward to 32 e to include the tropical indian ocean for studies in the maritime continent region and the bay of bengal ocean depth is derived from the etopo2 database http www ngdc noaa gov mgg global etopo2 html with the continental boundaries determined by the 10 m bottom contour the model grid has a constant resolution of 1 3 in both the zonal and meridional directions in the vertical direction two schemes of discretization are used one with 51 layers and the other 187 layers the former has thicknesses ranging from 5 m in the upper 20 m to 510 m near the bottom and the latter from 3 m throughout the upper 402 m to 510 m for the deepest layer for simplicity we shall refer to the two schemes as low and high resolutions even though the low resolution is comparable to those in many ocean models presently in use e g griffies et al 2009 the increase from low to high resolutions is modest near the surface but is significant in the pycnocline and below for example the layer thickness in the depth range of 50 400 m varies from 10 to 30 m with an average around 21 m in the low resolution in contrast to a constant of 3 m in the high resolution subgrid scale horizontal mixing is parameterized by bi harmonic operators with constant coefficients of 3 1011 m4 s 1 for viscosity and 2 1010 m4 s 1 for tracer diffusion vertical mixing is specified with the k profile parameterization kpp of large et al 1994 in which the background coefficients are set to 1 10 6 m2 s 1 for both viscosity and diffusivity in the stratified ocean interior below the surface boundary layer the background coefficients in kpp as implemented in the mitgcm represent the part of mixing from unresolved internal wave activities additionally two more contributions are included in the ocean interior one from convective events when the stratification becomes unstable n 2 0 where n is the brunt väisälä frequency and another from resolved vertical shear when the local gradient richardson number ri is smaller than a predefined critical value 0 3 in our experiments the maximum values for the coefficients are set to 1 10 1 and 5 10 3 m2 s 1 for the convective and shear components respectively effect of double diffusion is not included the model uses the bulk formulae of large and pond 1981 1982 to compute the turbulent fluxes of momentum heat and fresh water at the ocean surface the necessary atmospheric variables come from the european center for medium range weather forecasts ecmwf interim reanalysis dee et al 2011 at a resolution of 1 0 the wind components at 10 m are at 6 hourly frequency other variables including radiative heat fluxes net shortwave and downward longwave air temperature at 2 m specific humidity at 1000 millibar and precipitation are averaged to daily values using these 6 hourly and daily fields from the period of 1 january 1979 to 31 december 2016 we generate a monthly climatology for our spin up experiment see below we also make use of sst from the same database for comparison with model sst section 3 1 for the open boundaries at 26 s and 30 n model variables temperature salinity and horizontal components of velocity are defined by a monthly climatology generated from the german partner of the consortium for estimating the circulation and climate of the ocean gecco reanalysis köhl et al 2007 köhl and stammer 2008 along each of the boundaries a buffer zone of 3 in width or 9 grid intervals is applied for model variables to transition from the gecco values at the boundary to that of the interior by way of restoring with time scales varying from 1 day to 20 days this is the same procedure as that used by furue et al 2015 and jia et al 2015 for the tropical pacific except that there is no longer the need for an open meridional boundary in the indian ocean with the westward extension of the domain the model is initialized with the climatological january state of gecco reanalysis and a spin up integration of 40 years is performed at low vertical resolution forced at surface with the monthly climatology of ecmwf interim the end state of the spin up experiment is then used to initialize two experiments at low and high vertical resolutions while the low vertical resolution experiment can simply continue from the end state of the spin up vertical interpolation of the spin up variables and gecco variables is needed for initialization and open boundary conditions for the high vertical resolution experiment we apply a linear scheme for the interpolation both the experiments are integrated for 40 years forced at the surface with the 6 hourly and daily ecmwf interim variables for the period of 1979 2018 we examine the effects of increased vertical resolution on ocean temperature by taking the difference between the two experiments using the low resolution as reference as in furue et al 2015 this temperature difference also referred to as temperature anomaly δ t is separated into dynamical and spiciness components δ t and δ t respectively below the directly forced ocean surface layer the two components have distinct properties δ t is generated by a pressure anomaly associated with the vertical displacement of density surfaces and is propagated by ocean waves δ t is always accompanied by a compensating salinity anomaly in such a way that they do not result in a change in density and is advected like a passive tracer by ocean flows a detailed description on the precise definitions calculation methods and physical properties of the two components can be found in appendix a of furue et al 2015 and an illustration of their pathways in the tropical pacific is shown in their fig 10 3 results in this section we show that the increase in vertical resolution in our model experiments does indeed reduce the cool sst bias in the equatorial cold tongue section 3 1 through warming in the upper pycnocline section 3 2 as the result of a change in the vertical mixing structure section 3 3 in the central region additionally in the far eastern region a change in the vertical mixing structure produces cooling in the lower pycnocline that reduces the warm sst bias along the south american coast the increased vertical resolution captures the small scale vertical velocity shear and resolves the fine details of the stratification in the upper ocean section 3 4 contributing to the changes in the vertical mixing structure 3 1 sst our reference the low vertical resolution experiment is essentially the same as the control run used by furue et al 2015 in which a comparison was made between modeled and observed fields along 160 w see their fig 2 the annual mean zonal component of velocity salinity and potential density were found to agree well in their large scale features these conclusions apply to our reference experiment as well since sst is the primary focus of this study we show in fig 1 a the temperature of the upper most layer taken as sst in the reference experiment b the sst bias in the reference experiment relative to the ecmwf interim observation based estimates and c the sst difference between the high and low vertical resolution experiments all averaged over 40 years 1979 2018 the large scale features of the tropical pacific sst are well reproduced in the reference experiment fig 1a including the warm pool in the west the equatorial cold tongue in the east and the contrast of warm and cool surface waters to the north and south of the equator off the west coast of the american continent when compared with the ecmwf interim we see the familiar biases that commonly occur in ocean models as discussed in the introduction a basin wide cool bias most pronounced in the equatorial cold tongue and the subtropical regions 15 20 s and 20 30 n the latter is not shown and an intense warm bias along the south american coast fig 1b the cool bias reaching 0 6 c on the equator near 130 w and the warm bias just over 1 c off the south american coast are within the ranges of those seen in ocean models e g griffies et al 2009 and coupled atmosphere ocean models e g burls et al 2017 the increase in vertical resolution alleviates the general cool bias of the domain and the warm bias along the south american coast fig 1c one of the notable effects from the increase in the model s vertical resolution is the equatorial warming in excess of 0 3 c correcting about 50 of the cold tongue bias there is a considerable interannual variability that is closely correlated with the phases of enso as shown in fig 2 during strong el niño events e g 1982 83 1987 88 1991 92 and 2015 16 warming in the eastern equatorial pacific is much enhanced in the developing phase followed by increased cooling in the recovering phase an exception is the 1997 98 event when the warming is only modestly enhanced but the actual event is strong in the model solutions fig 2 also shows that increased cooling tends to occur during la niña events e g 1988 89 1999 2000 and 2010 11 comparing b and c of fig 1 we see that the increase in vertical resolution also increases existing biases specifically the warm bias to the east of the galapagos islands near 90 w equator and the cool bias at the costa rica dome near 90 w 10 n in section 3 3 we show that the equatorial warming and the coastal cooling off the equator seen in fig 1c share the same cause a change in the vertical mixing structure 3 2 subsurface temperature fig 3 displays the temperature difference between the high and low vertical resolution experiments δ t and its components averaged over the first two years 1979 1980 along the equator 1 s 1 n average and 140 w overlaid with potential density contours from the reference experiment black and the high vertical resolution experiment green here we choose a time average of two years to allow the effects of change in vertical resolution to develop see fig 2 at this initial phase much of the difference happens within 10 of the equator along the equator fig 3 left there is a layered distribution of positive negative and positive anomalies in the upper lower and below the pycnocline respectively this pattern comes primarily from the dynamical component δ t the shift of the green contours towards the middle of the pycnocline approximated by the 24 5 σ θ relative to the black contours suggests a tightening of the pycnocline in the high vertical resolution experiment consistent with its definition δ t attains positive and negative signs in the upper and lower parts of the pycnocline respectively the deeper positive δ t results from the deepening of the 26 5 σ θ the spiciness component δ t is positive in the pycnocline and weakly negative below the upper pycnocline rises to the surface in the central and eastern regions bringing positive anomaly from both the components to increase sst there along 140 w it appears that the positive negative positive layers of δ t on the equator are bordered by stronger anomalies just off the equator fig 3 middle right maps of δ t on representative density surfaces fig 4 left panels show that this is likely the case for the two positive anomalies 23 5 and 26 5 σ θ for the negative anomaly 25 5 σ θ off equatorial influence is evident as discussed in furue et al 2015 the dynamical anomaly generated in the off equatorial regions propagates westward as rossby waves then equatorward as coastal kelvin waves and then eastward along the equator as equatorial kelvin waves the extension of the weaker negative δ t from the western boundary on 25 5 σ θ suggests a stronger background negative δ t modified by a positive δ t coming from the western boundary there is plenty of positive δ t on this density surface that converges at the western boundary and enters the equatorial waveguide anomalies in the off equatorial regions enter the equatorial waveguide on other density surfaces too as will be discussed later last paragraphs of this and next sections δ t in the western equatorial region on 23 5 σ θ experiences large changes during the time period of the experiments as a result of influences from the off equatorial regions for the 26 5 σ θ on the other hand the positive δ t along the equator is locally generated and appears to withstand negative influences from the west within the pycnocline the spiciness anomaly δ t along the equator is advected eastward in the euc fig 3 lower left the spiciness anomaly in the off equatorial regions can also reach the equator following the subsurface branches of the stcs the precise advective pathways differ in the two hemispheres as shown in furue et al 2015 their fig 10 for example the positive δ t on 25 5 σ θ fig 4 middle right in the southern hemisphere can reach the euc either directly in the middle of the ocean basin or by flowing first to the western boundary and then to the equator in the new guinea coastal current since part of this coastal current crosses the equator it brings the southern positive δ t into the euc on both sides of the equator in contrast the negative δ t in the northern hemisphere cannot reach the euc directly in mid basin because of the presence of the north equatorial countercurrent necc instead it flows to the western boundary in the north equatorial current nec then equatorward in the mindanao current and then eastward in the necc and along the northern flank of the euc thus not crossing the equator as time advances the interannual variability reflected in fig 2 at the surface is tightly linked to subsurface changes here we use the 2015 16 el niño event hu and fedorov 2016 levine and mcphaden 2016 zhang and gao 2017 as an example fig 5 shows the contrasting states during the developing phase 2015 and the recovering phase 2016 along the equator with the deepened and also tightened pycnocline in the eastern sector during the developing phase the upper positive δ t is significant and the positive δ t is strong together they increase sst during the recovering phase there is no longer an upper positive δ t and the pycnocline shoals sharply toward the east to reach the surface in the eastern sector bringing negative δ t to the surface to lower sst there δ t also appears to be much weakened with the maximum shifted westward and a sign reversal near 100 w the high connectedness of the equator with the off equatorial regions means that changes along the equator can also influence the rest of the basin in the tropical pacific the characteristic shape of the negative δ t on 25 5 σ θ in the eastern basin fig 4 middle left fanning out towards the eastern boundary see furue et al 2015 for more examples is typical of an anomaly carried by a series of propagating waves eastward equatorial kelvin waves poleward coastal kelvin waves and then westward rossby waves reflected off the eastern boundary in later years of the model experiments the negative δ t is much enhanced and the characteristic shape is more clearly defined in the domain not shown most importantly this subsurface negative δ t spans a wide density range at the eastern boundary fig 3 middle left fig 5 middle panels these density surfaces outcrop in the southeastern region bringing the negative δ t to cool the surface off the south american coast fig 1c similarly the positive δ t at the surface next to the eastern boundary east of galapagos islands near 90 w though shallow is persistent fig 3 middle left fig 5 middle panels and we may reasonably conclude that the warm sst bias along the eastern boundary in the equatorial region fig 1c results from its propagation via coastal kelvin waves its southward extension along the south american coast ends where it meets denser surface waters its northward extension ends where it meets the negative δ t at the costa rica dome the cooling at the costa rica dome near 90 w 10 n fig 1c occurs on lighter densities 24 5 σ θ thus cannot originate from the lower pycnocline at the equator in this area there is a negative δ t at the surface and in the upper pycnocline e g fig 4 upper left which grows with time and propagates westward as a rossby wave the anomaly reaches the western boundary and enters the equator dominating or reducing locally generated anomalies along its pathway comparing fig 3 middle left with fig 5 middle panels 23 5 σ θ its westward extension at the surface is limited because the affected densities are below the surface away from the domed region 3 3 vertical diffusivity the decomposition of δ t into dynamical and spiciness components is useful for understanding the behavior of the difference because of the distinct ways with which the two components spread in the ocean it is not always possible however to identify the source of an anomaly since δ t at any given location is determined by a combination of local and remote effects based on the characteristics of δ t distribution in the study domain here we make an attempt to deduce certain causes and effects by applying knowledges gained from prior studies furue et al 2015 and jia et al 2015 explored the impacts of vertical diffusion on the temperature structure of the equatorial pacific by conducting numerical experiments in which the background vertical diffusivity κ b was changed each time only in one subregion of the tropical pacific they found that the initial response of δ t follows closely the one dimensional 1 d balance of vertical diffusion within the forced region where κ b is changed considering the two leading terms only the 1 d equation of temperature anomaly can be written as δ t 1 d δ κ t 0 z z t δ κ z t 0 z t δ a t δ b t where δ κ is the change in vertical diffusivity relative to the reference value κ 0 t 0 is the temperature of the reference experiment subscript z represents the vertical derivative of a variable and t is the time scale that the above balance is assumed to be valid δ a t represents the response primarily to a change in the vertical diffusivity whereas δ b t is associated with the vertical variation of the change in vertical diffusivity strictly speaking the full vertical diffusivity consisting of the background value the convective part and the shear dependent part in the kpp scheme should be used in furue et al 2015 and jia et al 2015 only the change in κ b is considered in evaluating δ a t and δ b t for simplicity this is in fact a very good approximation since κ b is sufficiently large in the ocean interior in their experiments and the additional parts are generally inactive for the two experiments discussed in this study however the difference is in the convective and the shear dependent parts since the same background value is used for both the experiments fig 6 shows several fields in the 1 d diffusion equation along the equator averaged over 1 s 1 n evaluated using the two model solutions in this study the fields are averages over the first two years 1979 1980 similar to fig 3 this two year time scale is to give adequate time for the effects of high vertical resolution on vertical diffusivity to develop along the equator the vertical diffusivity as evaluated by the kpp scheme in the reference experiment κ 0 is highest in the surface boundary layer decreases with depth to a local minimum in the pycnocline increases moderately below the pycnocline and then decreases again to the predefined background value of 1 10 6 m2 s 1 at depth the low value in the pycnocline is typical of a richardson number based scheme as a result of high stratification combined with low shear in the core of the euc whereas the moderate increase below the pycnocline results from reduced stratification and increased shear in the lower part of the euc in the eastern basin where the lower pycnocline rises to the surface boundary layer the subsurface minimum is not as noticeable as in the western and central regions bathymetric features namely the maritime continent to the west of 140 e and the galapagos islands near 90 w enhance subsurface mixing the above description holds for the high vertical resolution experiment as well in detail however the change in vertical resolution generates large regional differences in vertical diffusivity the most dramatic effects are 1 the increase in the upper pycnocline through to the surface in the central region positive δ κ 2 the reduction in the lower pycnocline in the eastern region 3 the reduction above the pycnocline in the western region and 4 the increase below the pycnocline along approximately 26 5 σ θ across almost the whole equatorial extent based on the 1 d balance δ a t is negative in the upper ocean in the central region resulting from the positive δ κ and negative t 0 z z an effect often seen when there is an increase in vertical diffusivity in ocean models almost in the same region δ b t is negative in the thin layer at the surface and positive below implying negative and positive δ κ z respectively since t 0 z is generally positive the distribution of δ t 1 d suggests the dominance of δ b t highlighting the importance of the vertical variation of δ κ in jia et al 2015 δ t 1 d from the 1 d diffusion equation is also decomposed into dynamical and spiciness anomalies because δ κ in this study exhibits large vertical variations such a decomposition is problematic using the results of jia et al 2015 as a guide their figs 3 and 4 we may attribute both δ a t and δ b t mostly to the dynamical component along the equator in the off equatorial regions the spiciness component can be significant especially in regions where salinity has large variations such as salty south pacific subtropical water overlying fresher deeper water there is a strong resemblance in the warming of the upper pycnocline in the central region between δ t 1 d generated by the positive δ κ z in fig 6 and δ t in fig 3 middle left we also see an analogue of the δ t 1 d and δ t distributions to the two left panels of fig 7 in jia et al 2015 in which κ b increases upwards within the upper pycnocline in the western equatorial region their experiment eqwa differences in the details result primarily from the positioning of the anomalies along the equator and the propagating characteristics of the dynamical anomaly in eqwa the surface cooling is limited to the western region because it occurs on light density surfaces that outcrop there this is in contrast to the subsurface warming that propagates eastward away from the directly forced western region and outcrops in the eastern region in fig 3 middle left and fig 6 upper right the subsurface warming outcrops in the central and eastern regions wiping out the surface cooling to increase sst there although the 1 d approximation is only defined for the initial phase there are times when the signatures of δ t 1 d are identifiable in the later stages of the model experiments as well fig 7 shows δ t 1 d and its components in 2015 and 2016 comparing figs 5 and 7 there is a good correspondence between δ t 1 d and δ t in the warming of the upper pycnocline in 2015 by contrast the positive δ t 1 d in the upper pycnocline is not visible in δ t in 2016 indicating a stronger influence from remote effects see the last paragraph of this section the results above show clearly that the surface warming along the equator in the central region fig 1c is brought about by the warming in the upper pycnocline from a change in the structure of the vertical diffusivity the same argument can also explain the warming at the surface east of the galapagos islands 90 w and the cooling below 24 5 26 5 σ θ in the eastern region fig 3 middle left fig 6 upper right these anomalies are then carried poleward by coastal kelvin waves to influence sst along the eastern boundary as discussed in the last section another effect of the subsurface cooling is the suppression of the warm layer around 26 5 σ θ along the equator fig 3 middle left fig 5 middle panels there are positive patches of δ t 1 d in the western region fig 6 upper right fig 7 upper left and in the eastern region fig 7 upper right that generate the positive anomaly across almost the whole of the equatorial extent this positive anomaly however does not reach the off equatorial regions because it is eliminated by the negative anomaly at the eastern boundary the cooling at the costa rica dome and its westward influence is a good demonstration of the competing strengths of local versus remote changes there are patches of persistently negative δ t 1 d around 90 w 10 n fig 8 left panels initially the cooling effect is evident only locally fig 8 upper right as time progresses its strength increases and its influence expands westward middle and lower right panels along its pathway negative δ t is reduced in regions of positive δ t 1 d e g 130 w and 170 e and enhanced in regions of negative δ t 1 d 150 w and 140 e on this shallow density surface 22 5 σ θ its influence on the equator is limited to the western region on deeper surfaces e g 23 5 σ θ it affects the temperature structure of the upper pycnocline to a much larger extent during the developing el niño in 2015 the positive δ t 1 d region fig 7 upper left is shifted eastward and is strong enough to prevail over negative influence from the west to generate a positive δ t fig 5 middle left whereas during 2016 the patches of positive δ t 1 d in the central region fig 7 upper right appear to be overcome by negative influence from the west resulting in a negative δ t fig 5 middle right 3 4 stratification and vertical shear the analysis in section 3 3 shows clearly that the warming along the equator and the cooling off the south american coast at the sea surface in the high vertical resolution experiment result from a change in the structure of vertical mixing in the pycnocline at the equator above the background vertical diffusivity which is set to the same constant in the model experiments the kpp scheme computes the convective and shear components below the surface boundary layer based on stratification n 2 and local gradient richardson number ri respectively we may expect that the change in vertical resolution has impacted significantly the stratification and vertical shear and therefore ri in this section we examine the characteristics of these two quantities at 140 w and 85 w on the equator the former is located where δ t 1 d is positive in the upper pycnocline and the latter where δ t 1 d is negative in the lower pycnocline fig 9 left shows the contrast in n 2 at 140 w equator between the two resolutions and between 2015 and 2016 higher vertical resolution permits a sharper pycnocline in both 2015 and 2016 but the effect is much larger in 2015 during the developing el niño despite the sharp increase in stratification in 2015 above the middle of the pycnocline maximum n 2 both δ κ and δ κ z are positive fig 9 upper right corresponding to negative δ a t and positive δ b t fig 7 middle and lower left panels respectively suggesting that ri in the high vertical resolution experiment is not only less than the critical value of 0 3 indicating the presence of shear generated turbulence but also much less than that in the low vertical resolution experiment the convective contributions dashed curves are similar in the two resolution fig 10 displays the power spectra of the vertical shear of the meridional component of velocity φ v averaged over 2015 the enhancement of φ v from low to high vertical resolution is clearly evident at wave numbers lower than 0 05 cpm which is taken here as the highest possible wave number corresponding to the lowest possible wave length of 20 m resolved by the low vertical resolution experiment there is a significant temporal variability in the shear spectra in the model experiments fig 11 shows φ v as a function of time and wave length for the high vertical resolution experiment the values of φ v at all resolved length scales are higher during el niño march 2015 february 2016 than the months that follow the elevated values are consistent with the elevated westerly wind activity during el niño see natarov and richards 2019 who consider the generation of inertia gravity waves by wind variability close to the equator the temporal variability of φ v in the low vertical resolution experiment is similar to that shown in fig 11 but lower in amplitude at 85 w equator the pycnocline is much shallower and sharper than in the central and western regions see figs 5 and 7 and maximum n 2 occurs above 40 m with a larger value in the high vertical resolution experiment fig 12 left panels beneath the highly stratified surface layer stratification is very weak and often becomes unstable as indicated by the significant level of convective contribution fig 12 right panels dashed curves to the total vertical diffusivity κ v in both the experiments note that negative n 2 is not reflected in the time averaged profiles the power spectra of vertical velocity shear not shown is similar to that at 140 w that is the shear intensity is higher in the high vertical resolution experiment and during the 2015 2016 el niño despite the enhancement in shear with increased vertical resolution δ κ is largely negative at the subsurface suggesting that stratification plays a dominant part in determining κ v at this location with a larger contribution coming from the convective component in the low vertical resolution experiment n 2 0 red dashed curves 4 summary discussion and concluding remarks in this study we explore the impact of vertical resolution in an ocean model in reducing sst biases in the tropical pacific ocean by conducting two model experiments that differ in the vertical discretization with the resolution in one being significantly higher than in the other in the upper ocean we find that the difference in the upper most layer temperature taken as sst between the high and low vertical resolution experiments is positive in the equatorial cold tongue and negative along the south american coast thus reducing the commonly seen cool and warm biases in the two regions respectively in the central equatorial pacific going from low to high vertical resolution the increase in vertical diffusivity specifically the increase in the upward gradient of vertical diffusivity in the upper pycnocline results in a warm anomaly that propagates eastward and rises to the surface to increase sst in the equatorial cold tongue the change in the structure of the vertical diffusivity in turn is the result of an enhancement in the shear generated turbulence power spectra of the vertical shear of the meridional component of velocity at 140 w equator show a significant increase with increased vertical resolution at wavelengths resolved by both the resolutions 20 m furthermore the high vertical resolution experiment also captures much of the finer scale vertical velocity shear 20 m the reduction in the cool sst bias in the cold tongue seen in the model experiments highlights the important contribution of fine scale vertical shear to mixing this result is in line with the observational studies in the western equatorial pacific as shown by measurements made with both a high frequency 600 khz acoustic doppler current profiler operated in lowered model ladcp and a relatively low frequency 70 khz ship based adcp richards et al 2012 vertical shear as measured by the high resolution ladcp is dominated by high peaks at small vertical scales that are not captured by the low resolution adcp and these peaks are closely associated with enhanced turbulent kinetic energy dissipation rate estimated using data from a microstructure profiler in the far eastern equatorial pacific the change in vertical diffusivity from low to high vertical resolution in the lower pycnocline produces a cool anomaly that propagates poleward as coastal kelvin waves along the west coast of the american continent and outcrops along the south american coast to reduce sst there stratification appears to be the dominant factor in changing the structure of the vertical diffusivity as seen at 85 w we hypothesize that the increased vertical resolution helps resolve the fine details of the stratification which is particularly weak beneath the shallow and highly stratified surface layer by contrast the low vertical resolution with 6 layers ranging from 11 to 17 m in thickness in the depth range of 60 140 m the region with large changes in vertical diffusivity is unlikely to represent the weak stratification well the impact of subsurface temperature structure in the eastern equatorial pacific on sst off the south american coast comes as no surprise its basis was well laid out in furue et al 2015 their fig 10 the connection between the two regions is present though not discussed in jia et al 2015 our supplementary figure fig s1 is the same as fig 13 of jia et al 2015 with the eastern limit extended to 70 w for each case shown in the figure the temperature anomaly along the equator is shown in fig 12 of jia et al 2015 note the aforementioned connectivity in particular the contrast between the warm anomaly in the eqwd and eqed cases versus the cool anomaly in the others more examples can be seen in sasaki et al 2012 in the three experiments shown in fig 6a c of sasaki et al 2012 their mixing parameterization results in a positive temperature difference at subsurface of varying magnitude that extends all the way to the eastern boundary it is by no coincidence that we see warming including the relative magnitude off the south american coast in the corresponding experiments in their fig 5b d in view of the high connectivity in the tropical pacific whether through equatorial kelvin waves along the equator where sst in the cold tongue can be impacted by mixing in the pycnocline to the west or through coastal kelvin waves along the eastern boundary where sst along the south american coast can be impacted by mixing at the equator high vertical resolution measurements are much needed for an improved knowledge of shear generated turbulence in the central and eastern regions and a detailed description of the stratification in the far eastern region to illustrate the importance of high vertical resolution we have conducted model experiments at a relatively coarse horizontal resolution as a compromise between the demand for computation and the need for a basin scale domain to achieve the observed level of vertical shear an adequate horizontal resolution is also needed to demonstrate this point in fig 13 we compare φ v from model experiments to data collected using a high resolution 600 khz ladcp during a 4 day time series in august 2015 at 170 w 1 n from r v falkor cruise fk150728 the observations show a strongly peaked spectrum peaking around 50 m wavelength similar to spectra from measurements in the western equatorial pacific see richards et al 2015 the shear spectrum from the low vertical resolution experiment falls well below the observations the high vertical resolution experiment produces a spectrum that fills out much of the higher wavenumbers there remains however a marked deficit for wavelengths greater than 20 m for comparison we include the shear spectrum from a companion experiment where the model is downscaled in a region surrounding the location of the observations such that the horizontal resolution is 1 27 with the increased resolution in both the horizontal and vertical directions the model spectrum is now peaked around 50 m wavelength approaching that of the observations our results clearly show that adequate vertical resolution is required to capture relatively small vertical scale features in the equatorial ocean and that those features make an important contribution to vertical mixing which in turn impacts the larger scale ocean structure we suggest that more emphasis is put on resolving these scales in both models and observations and a better understanding is required of their spatial and temporal variability another possible benefit linked to an increase in vertical resolution in models is the likely reduction in numerical diffusion associated with advection schemes in a study of the formation mechanism of the pacific equatorial thermocline tatebe and hasumi 2010 showed that by reducing numerical diffusion in a model sst is increased in the central equatorial pacific and decreased along the south american coast their fig 9 in much the same way as shown in this study by explicit diffusion the reduction in numerical diffusion is achieved through the use of a highly accurate advection scheme the second order moment som scheme prather 1986 compared with a third order scheme that introduces much numerical diffusion in our model experiments we use the third order direct space time dst scheme as implemented in mitgcm since the same advection scheme is used in our experiments we may expect some but limited cancellation of the effect of numerical diffusion when we compute the difference in potential temperature between experiments a reduction in numerical diffusion will occur through the increase in vertical resolution and may have contributed to the changes in sst in addition to the explicit diffusion lastly we have conducted ocean only experiments coupled experiments are required to quantify the magnitude and temporal variability which can be done with atmospheric models of varying complexity see e g zhang et al 2020 we expect that coupling with the atmosphere will enhance the impact on the cold tongue sst as shown by sasaki et al 2013 credit authorship contribution statement yanli jia methodology formal analysis investigation writing original draft writing reviewing editing kelvin j richards conceptualization methodology investigation writing reviewing editing supervision funding acquisition h annamalai methodology investigation writing reviewing editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was funded by the national oceanic and atmospheric administration noaa grant number na18oar4310404 a pre field modeling study in support of the tropical pacific observing system tpos process studies a component of tpos 2020 we thank the support of the schmidt ocean institute and the captain and crew of the r v falkor cruise fk150728 in the collection of the ladcp data included in fig 13 we appreciate the time and effort of the editors and anonymous reviewers whose comments and suggestions helped improve the manuscript the authors wish to acknowledge use of the ferret program for analysis and graphics in this paper ferret is a product of noaa s pacific marine environmental laboratory information is available at http ferret pmel noaa gov ferret the technical support and advanced computing resources from the university of hawaii information technology services cyberinfrastructure are gratefully acknowledged appendix a supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ocemod 2020 101722 appendix a supplementary data the following is the supplementary material related to this article mmc s1 
23930,motivated by observations of fine scale vertical shear and its contribution to mixing in the tropical ocean this study explores the impact of vertical resolution in an ocean model on sea surface temperature in the tropical pacific ocean we conduct two model experiments that differ in the vertical discretization only with the grid spacing in one being significantly smaller than the other in the upper ocean we examine the temperature difference between the high and low vertical resolution experiments we find that the difference in the upper most layer is positive in the equatorial cold tongue and negative along the south american coast thus reducing the commonly seen cool and warm biases in the two regions respectively the change in the structure of the vertical diffusivity as determined by the k profile parameterization is identified as the primary cause in reducing the biases in the central equatorial pacific the change in the vertical diffusivity from low to high vertical resolution in the upper pycnocline results in a positive temperature difference that propagates eastward as an equatorial kelvin wave rising to the sea surface in the central and eastern regions to increase the sea surface temperature there in the far eastern equatorial pacific the change in the vertical diffusivity in the lower pycnocline produces a negative temperature difference that propagates poleward as coastal kelvin waves along the west coast of the american continent outcropping along the south american coast to reduce the sea surface temperature there the high vertical resolution experiment captures much of the small scale vertical velocity shear and resolves the fine details of the stratification in the upper ocean our analysis suggests that the shear generated turbulence is the primary contributor to the change in the vertical diffusivity in the central region whereas stratification is the dominant factor in the far eastern region keywords sea surface temperature fine scale velocity shear stratification vertical mixing pycnocline kelvin waves 1 introduction sea surface temperature sst the principal communicator of the ocean with the atmosphere plays a very important role in the tropical pacific yet many ocean models and coupled atmosphere ocean models often have difficulties in correctly reproducing its observed characteristics the cool bias of the cold tongue in the eastern equatorial pacific and the warm bias off the south american coast are two such examples the cool bias of the cold tongue is generally associated with too intense easterly trade winds in the western and central pacific it is difficult to determine the root cause of this bias because of the complex feedback mechanisms of the atmosphere ocean system but there have been many studies that try for example vannière et al 2014 investigated sst biases in the tropical pacific with a multitude of simulations using ocean only atmosphere only and coupled atmosphere ocean models they suggested that a cool bias in the subtropical regions could give rise to a cool bias in the equatorial cold tongue transmitted through advection by the subtropical cells stcs mccreary and lu 1994 and propagation by ocean waves this mechanism is supported by the analysis of burls et al 2017 using output from climate models that participate in the coupled model intercomparison project phase 5 cmip5 they found a high correlation in sst between the equatorial zone and the extra tropical subduction regions across the cmip5 models and a link between positive cloud albedo bias thus reduced shortwave radiation into the ocean and negative sst bias in extra tropical regions li and xie 2012 2014 by comparing cmip5 and cmip3 models with their corresponding atmosphere only models came to a similar conclusion that a high cloud coverage in the atmospheric models is correlated to a cool bias in the mean sst across all tropical oceans additionally li and xie 2012 2014 suggested that a shallow thermocline in the upwelling region of the equatorial pacific in the ocean components of the coupled models is the cause of a cool bias in the cold tongue and through the bjerknes 1969 feedback mechanism a positive bias in the easterly winds arises as a result the basis for this conclusion is that the wind bias does not exist in atmosphere only models forced with observed sst causes of the warm bias off the south american coast have been investigated by a number of studies as summarized in zuidema et al 2016 identifying inadequacies in the representation of low level clouds convection and winds in the atmospheric component and thermocline structure in the ocean component among others it is also recognized that model resolution in both the atmosphere and ocean is often a limiting factor in resolving the relevant processes in the climate models currently in use the message is clear from the studies mentioned above and many more that sst biases originate in both the ocean and the atmosphere components of a coupled model an error in one component can lead to errors in the other and these errors may be amplified through the strong coupling between the atmosphere and ocean ocean mixing plays an important role in modulating the temperature in the upper ocean observational studies show that ocean mixing exerts strong controls on the seasonal cycle of sst moum et al 2013 and is actively involved in the phase transitions of the el niño southern oscillation enso warner and moum 2019 at 140 w equator in ocean models equatorial pacific sst is highly sensitive to the specification of vertical mixing e g jochum 2009 richards et al 2009 zhu and zhang 2018 2019 along the equatorial pacific the application of a low background vertical diffusivity a parameterization of ocean mixing by unresolved processes usually leads to a warmer cold tongue through the sharpening of the thermocline meehl et al 2001 showed that models with a colder than observed temperature in the upper ocean tend to have a too shallow thermocline even though they may produce the observed thermocline intensity and el niño amplitude at low vertical diffusivity naturally an important prerequisite to reducing sst bias must be a realistic thermocline structure both its thickness and its depth jia et al 2015 undertook a systematic study of the impact of vertical diffusivity on the temperature structure of the equatorial pacific ocean they found that the depth and the thickness of the equatorial pycnocline thermocline can be altered by varying the vertical diffusivity with depth with ocean only model experiments sasaki et al 2012 demonstrated that an enhancement of the background vertical diffusivity within and above the thermocline both sharpens and deepens the thermocline and the cool bias of the cold tongue is reduced as a result this effect is amplified in a coupled atmosphere ocean model sasaki et al 2013 through the bjerknes feedback and sst shortwave flux feedback klein and hartmann 1993 the modeling studies by sasaki et al 2012 2013 were motivated by measurements taken in the western equatorial pacific richards et al 2012 2015 vertical velocity shear was observed to be dominated by flow features with small vertical scales 20 50 m contributing to an increase in vertical mixing within and above the thermocline in the eastern equatorial pacific the cold tongue region enhanced mixing in the thermocline has also been observed from argo float and the tropical ocean and atmosphere tao mooring measurements liu et al 2016 2019b identified numerous mixing events in the thermocline and attributed them to low richardson numbers resulting from shear associated with tropical instability waves tiws and the equatorial undercurrent euc furthermore liu et al 2019a 2020 found small vertical scale 10 50 m shear induced by the interaction between the equatorial current system and equatorial waves of different dynamic types and multiple time scales in the upper thermocline energetic motions with a vertical wavelength of 40 m referred to as a shear wave was reported by peters et al 1991 from observations taken on and off the equator along 140 w in april 1987 during the second cruise of the tropic heat program the large impact on the climate system shown by sasaki et al 2013 from a simple parameterization of vertical diffusivity warrants a further investigation into the characteristics of vertical mixing along the whole extent of the equatorial pacific in particular the contribution from shear at different vertical length scales in this study we address this issue by conducting numerical experiments with an ocean model at two vertical resolutions one that is comparable with those in many ocean models currently in use and the other that is significantly finer in the upper ocean through the use of a richardson number based scheme and by specifying a low background value for the vertical diffusivity the contribution to mixing from resolved shear at different vertical resolutions of the model experiments can then be compared and contrasted the present research may be considered as an extension of the two part study by furue et al 2015 and jia et al 2015 we apply the analysis method developed in furue et al 2015 to examine the difference in temperature structure and relate the difference to the change in the mixing structure resulting from an increase in vertical resolution based on the key findings of the two part study the details of our experimental design are described in section 2 we present our results in section 3 making connections among the changes in sst subsurface temperature vertical mixing structure stratification and vertical velocity shear as a result of an increase in vertical resolution we summarize and discuss our results and provide concluding remarks in section 4 2 experimental design we use a version of the massachusetts institute of technology general circulation model mitgcm marshall et al 1997 which solves the incompressible navier stokes equations discretized into finite volumes on a sphere the model configuration is an adaptation of that used by furue et al 2015 and jia et al 2015 for the tropical pacific with minor modifications the meridional extent of 26 s 30 n is maintained while the western boundary of the domain is extended westward to 32 e to include the tropical indian ocean for studies in the maritime continent region and the bay of bengal ocean depth is derived from the etopo2 database http www ngdc noaa gov mgg global etopo2 html with the continental boundaries determined by the 10 m bottom contour the model grid has a constant resolution of 1 3 in both the zonal and meridional directions in the vertical direction two schemes of discretization are used one with 51 layers and the other 187 layers the former has thicknesses ranging from 5 m in the upper 20 m to 510 m near the bottom and the latter from 3 m throughout the upper 402 m to 510 m for the deepest layer for simplicity we shall refer to the two schemes as low and high resolutions even though the low resolution is comparable to those in many ocean models presently in use e g griffies et al 2009 the increase from low to high resolutions is modest near the surface but is significant in the pycnocline and below for example the layer thickness in the depth range of 50 400 m varies from 10 to 30 m with an average around 21 m in the low resolution in contrast to a constant of 3 m in the high resolution subgrid scale horizontal mixing is parameterized by bi harmonic operators with constant coefficients of 3 1011 m4 s 1 for viscosity and 2 1010 m4 s 1 for tracer diffusion vertical mixing is specified with the k profile parameterization kpp of large et al 1994 in which the background coefficients are set to 1 10 6 m2 s 1 for both viscosity and diffusivity in the stratified ocean interior below the surface boundary layer the background coefficients in kpp as implemented in the mitgcm represent the part of mixing from unresolved internal wave activities additionally two more contributions are included in the ocean interior one from convective events when the stratification becomes unstable n 2 0 where n is the brunt väisälä frequency and another from resolved vertical shear when the local gradient richardson number ri is smaller than a predefined critical value 0 3 in our experiments the maximum values for the coefficients are set to 1 10 1 and 5 10 3 m2 s 1 for the convective and shear components respectively effect of double diffusion is not included the model uses the bulk formulae of large and pond 1981 1982 to compute the turbulent fluxes of momentum heat and fresh water at the ocean surface the necessary atmospheric variables come from the european center for medium range weather forecasts ecmwf interim reanalysis dee et al 2011 at a resolution of 1 0 the wind components at 10 m are at 6 hourly frequency other variables including radiative heat fluxes net shortwave and downward longwave air temperature at 2 m specific humidity at 1000 millibar and precipitation are averaged to daily values using these 6 hourly and daily fields from the period of 1 january 1979 to 31 december 2016 we generate a monthly climatology for our spin up experiment see below we also make use of sst from the same database for comparison with model sst section 3 1 for the open boundaries at 26 s and 30 n model variables temperature salinity and horizontal components of velocity are defined by a monthly climatology generated from the german partner of the consortium for estimating the circulation and climate of the ocean gecco reanalysis köhl et al 2007 köhl and stammer 2008 along each of the boundaries a buffer zone of 3 in width or 9 grid intervals is applied for model variables to transition from the gecco values at the boundary to that of the interior by way of restoring with time scales varying from 1 day to 20 days this is the same procedure as that used by furue et al 2015 and jia et al 2015 for the tropical pacific except that there is no longer the need for an open meridional boundary in the indian ocean with the westward extension of the domain the model is initialized with the climatological january state of gecco reanalysis and a spin up integration of 40 years is performed at low vertical resolution forced at surface with the monthly climatology of ecmwf interim the end state of the spin up experiment is then used to initialize two experiments at low and high vertical resolutions while the low vertical resolution experiment can simply continue from the end state of the spin up vertical interpolation of the spin up variables and gecco variables is needed for initialization and open boundary conditions for the high vertical resolution experiment we apply a linear scheme for the interpolation both the experiments are integrated for 40 years forced at the surface with the 6 hourly and daily ecmwf interim variables for the period of 1979 2018 we examine the effects of increased vertical resolution on ocean temperature by taking the difference between the two experiments using the low resolution as reference as in furue et al 2015 this temperature difference also referred to as temperature anomaly δ t is separated into dynamical and spiciness components δ t and δ t respectively below the directly forced ocean surface layer the two components have distinct properties δ t is generated by a pressure anomaly associated with the vertical displacement of density surfaces and is propagated by ocean waves δ t is always accompanied by a compensating salinity anomaly in such a way that they do not result in a change in density and is advected like a passive tracer by ocean flows a detailed description on the precise definitions calculation methods and physical properties of the two components can be found in appendix a of furue et al 2015 and an illustration of their pathways in the tropical pacific is shown in their fig 10 3 results in this section we show that the increase in vertical resolution in our model experiments does indeed reduce the cool sst bias in the equatorial cold tongue section 3 1 through warming in the upper pycnocline section 3 2 as the result of a change in the vertical mixing structure section 3 3 in the central region additionally in the far eastern region a change in the vertical mixing structure produces cooling in the lower pycnocline that reduces the warm sst bias along the south american coast the increased vertical resolution captures the small scale vertical velocity shear and resolves the fine details of the stratification in the upper ocean section 3 4 contributing to the changes in the vertical mixing structure 3 1 sst our reference the low vertical resolution experiment is essentially the same as the control run used by furue et al 2015 in which a comparison was made between modeled and observed fields along 160 w see their fig 2 the annual mean zonal component of velocity salinity and potential density were found to agree well in their large scale features these conclusions apply to our reference experiment as well since sst is the primary focus of this study we show in fig 1 a the temperature of the upper most layer taken as sst in the reference experiment b the sst bias in the reference experiment relative to the ecmwf interim observation based estimates and c the sst difference between the high and low vertical resolution experiments all averaged over 40 years 1979 2018 the large scale features of the tropical pacific sst are well reproduced in the reference experiment fig 1a including the warm pool in the west the equatorial cold tongue in the east and the contrast of warm and cool surface waters to the north and south of the equator off the west coast of the american continent when compared with the ecmwf interim we see the familiar biases that commonly occur in ocean models as discussed in the introduction a basin wide cool bias most pronounced in the equatorial cold tongue and the subtropical regions 15 20 s and 20 30 n the latter is not shown and an intense warm bias along the south american coast fig 1b the cool bias reaching 0 6 c on the equator near 130 w and the warm bias just over 1 c off the south american coast are within the ranges of those seen in ocean models e g griffies et al 2009 and coupled atmosphere ocean models e g burls et al 2017 the increase in vertical resolution alleviates the general cool bias of the domain and the warm bias along the south american coast fig 1c one of the notable effects from the increase in the model s vertical resolution is the equatorial warming in excess of 0 3 c correcting about 50 of the cold tongue bias there is a considerable interannual variability that is closely correlated with the phases of enso as shown in fig 2 during strong el niño events e g 1982 83 1987 88 1991 92 and 2015 16 warming in the eastern equatorial pacific is much enhanced in the developing phase followed by increased cooling in the recovering phase an exception is the 1997 98 event when the warming is only modestly enhanced but the actual event is strong in the model solutions fig 2 also shows that increased cooling tends to occur during la niña events e g 1988 89 1999 2000 and 2010 11 comparing b and c of fig 1 we see that the increase in vertical resolution also increases existing biases specifically the warm bias to the east of the galapagos islands near 90 w equator and the cool bias at the costa rica dome near 90 w 10 n in section 3 3 we show that the equatorial warming and the coastal cooling off the equator seen in fig 1c share the same cause a change in the vertical mixing structure 3 2 subsurface temperature fig 3 displays the temperature difference between the high and low vertical resolution experiments δ t and its components averaged over the first two years 1979 1980 along the equator 1 s 1 n average and 140 w overlaid with potential density contours from the reference experiment black and the high vertical resolution experiment green here we choose a time average of two years to allow the effects of change in vertical resolution to develop see fig 2 at this initial phase much of the difference happens within 10 of the equator along the equator fig 3 left there is a layered distribution of positive negative and positive anomalies in the upper lower and below the pycnocline respectively this pattern comes primarily from the dynamical component δ t the shift of the green contours towards the middle of the pycnocline approximated by the 24 5 σ θ relative to the black contours suggests a tightening of the pycnocline in the high vertical resolution experiment consistent with its definition δ t attains positive and negative signs in the upper and lower parts of the pycnocline respectively the deeper positive δ t results from the deepening of the 26 5 σ θ the spiciness component δ t is positive in the pycnocline and weakly negative below the upper pycnocline rises to the surface in the central and eastern regions bringing positive anomaly from both the components to increase sst there along 140 w it appears that the positive negative positive layers of δ t on the equator are bordered by stronger anomalies just off the equator fig 3 middle right maps of δ t on representative density surfaces fig 4 left panels show that this is likely the case for the two positive anomalies 23 5 and 26 5 σ θ for the negative anomaly 25 5 σ θ off equatorial influence is evident as discussed in furue et al 2015 the dynamical anomaly generated in the off equatorial regions propagates westward as rossby waves then equatorward as coastal kelvin waves and then eastward along the equator as equatorial kelvin waves the extension of the weaker negative δ t from the western boundary on 25 5 σ θ suggests a stronger background negative δ t modified by a positive δ t coming from the western boundary there is plenty of positive δ t on this density surface that converges at the western boundary and enters the equatorial waveguide anomalies in the off equatorial regions enter the equatorial waveguide on other density surfaces too as will be discussed later last paragraphs of this and next sections δ t in the western equatorial region on 23 5 σ θ experiences large changes during the time period of the experiments as a result of influences from the off equatorial regions for the 26 5 σ θ on the other hand the positive δ t along the equator is locally generated and appears to withstand negative influences from the west within the pycnocline the spiciness anomaly δ t along the equator is advected eastward in the euc fig 3 lower left the spiciness anomaly in the off equatorial regions can also reach the equator following the subsurface branches of the stcs the precise advective pathways differ in the two hemispheres as shown in furue et al 2015 their fig 10 for example the positive δ t on 25 5 σ θ fig 4 middle right in the southern hemisphere can reach the euc either directly in the middle of the ocean basin or by flowing first to the western boundary and then to the equator in the new guinea coastal current since part of this coastal current crosses the equator it brings the southern positive δ t into the euc on both sides of the equator in contrast the negative δ t in the northern hemisphere cannot reach the euc directly in mid basin because of the presence of the north equatorial countercurrent necc instead it flows to the western boundary in the north equatorial current nec then equatorward in the mindanao current and then eastward in the necc and along the northern flank of the euc thus not crossing the equator as time advances the interannual variability reflected in fig 2 at the surface is tightly linked to subsurface changes here we use the 2015 16 el niño event hu and fedorov 2016 levine and mcphaden 2016 zhang and gao 2017 as an example fig 5 shows the contrasting states during the developing phase 2015 and the recovering phase 2016 along the equator with the deepened and also tightened pycnocline in the eastern sector during the developing phase the upper positive δ t is significant and the positive δ t is strong together they increase sst during the recovering phase there is no longer an upper positive δ t and the pycnocline shoals sharply toward the east to reach the surface in the eastern sector bringing negative δ t to the surface to lower sst there δ t also appears to be much weakened with the maximum shifted westward and a sign reversal near 100 w the high connectedness of the equator with the off equatorial regions means that changes along the equator can also influence the rest of the basin in the tropical pacific the characteristic shape of the negative δ t on 25 5 σ θ in the eastern basin fig 4 middle left fanning out towards the eastern boundary see furue et al 2015 for more examples is typical of an anomaly carried by a series of propagating waves eastward equatorial kelvin waves poleward coastal kelvin waves and then westward rossby waves reflected off the eastern boundary in later years of the model experiments the negative δ t is much enhanced and the characteristic shape is more clearly defined in the domain not shown most importantly this subsurface negative δ t spans a wide density range at the eastern boundary fig 3 middle left fig 5 middle panels these density surfaces outcrop in the southeastern region bringing the negative δ t to cool the surface off the south american coast fig 1c similarly the positive δ t at the surface next to the eastern boundary east of galapagos islands near 90 w though shallow is persistent fig 3 middle left fig 5 middle panels and we may reasonably conclude that the warm sst bias along the eastern boundary in the equatorial region fig 1c results from its propagation via coastal kelvin waves its southward extension along the south american coast ends where it meets denser surface waters its northward extension ends where it meets the negative δ t at the costa rica dome the cooling at the costa rica dome near 90 w 10 n fig 1c occurs on lighter densities 24 5 σ θ thus cannot originate from the lower pycnocline at the equator in this area there is a negative δ t at the surface and in the upper pycnocline e g fig 4 upper left which grows with time and propagates westward as a rossby wave the anomaly reaches the western boundary and enters the equator dominating or reducing locally generated anomalies along its pathway comparing fig 3 middle left with fig 5 middle panels 23 5 σ θ its westward extension at the surface is limited because the affected densities are below the surface away from the domed region 3 3 vertical diffusivity the decomposition of δ t into dynamical and spiciness components is useful for understanding the behavior of the difference because of the distinct ways with which the two components spread in the ocean it is not always possible however to identify the source of an anomaly since δ t at any given location is determined by a combination of local and remote effects based on the characteristics of δ t distribution in the study domain here we make an attempt to deduce certain causes and effects by applying knowledges gained from prior studies furue et al 2015 and jia et al 2015 explored the impacts of vertical diffusion on the temperature structure of the equatorial pacific by conducting numerical experiments in which the background vertical diffusivity κ b was changed each time only in one subregion of the tropical pacific they found that the initial response of δ t follows closely the one dimensional 1 d balance of vertical diffusion within the forced region where κ b is changed considering the two leading terms only the 1 d equation of temperature anomaly can be written as δ t 1 d δ κ t 0 z z t δ κ z t 0 z t δ a t δ b t where δ κ is the change in vertical diffusivity relative to the reference value κ 0 t 0 is the temperature of the reference experiment subscript z represents the vertical derivative of a variable and t is the time scale that the above balance is assumed to be valid δ a t represents the response primarily to a change in the vertical diffusivity whereas δ b t is associated with the vertical variation of the change in vertical diffusivity strictly speaking the full vertical diffusivity consisting of the background value the convective part and the shear dependent part in the kpp scheme should be used in furue et al 2015 and jia et al 2015 only the change in κ b is considered in evaluating δ a t and δ b t for simplicity this is in fact a very good approximation since κ b is sufficiently large in the ocean interior in their experiments and the additional parts are generally inactive for the two experiments discussed in this study however the difference is in the convective and the shear dependent parts since the same background value is used for both the experiments fig 6 shows several fields in the 1 d diffusion equation along the equator averaged over 1 s 1 n evaluated using the two model solutions in this study the fields are averages over the first two years 1979 1980 similar to fig 3 this two year time scale is to give adequate time for the effects of high vertical resolution on vertical diffusivity to develop along the equator the vertical diffusivity as evaluated by the kpp scheme in the reference experiment κ 0 is highest in the surface boundary layer decreases with depth to a local minimum in the pycnocline increases moderately below the pycnocline and then decreases again to the predefined background value of 1 10 6 m2 s 1 at depth the low value in the pycnocline is typical of a richardson number based scheme as a result of high stratification combined with low shear in the core of the euc whereas the moderate increase below the pycnocline results from reduced stratification and increased shear in the lower part of the euc in the eastern basin where the lower pycnocline rises to the surface boundary layer the subsurface minimum is not as noticeable as in the western and central regions bathymetric features namely the maritime continent to the west of 140 e and the galapagos islands near 90 w enhance subsurface mixing the above description holds for the high vertical resolution experiment as well in detail however the change in vertical resolution generates large regional differences in vertical diffusivity the most dramatic effects are 1 the increase in the upper pycnocline through to the surface in the central region positive δ κ 2 the reduction in the lower pycnocline in the eastern region 3 the reduction above the pycnocline in the western region and 4 the increase below the pycnocline along approximately 26 5 σ θ across almost the whole equatorial extent based on the 1 d balance δ a t is negative in the upper ocean in the central region resulting from the positive δ κ and negative t 0 z z an effect often seen when there is an increase in vertical diffusivity in ocean models almost in the same region δ b t is negative in the thin layer at the surface and positive below implying negative and positive δ κ z respectively since t 0 z is generally positive the distribution of δ t 1 d suggests the dominance of δ b t highlighting the importance of the vertical variation of δ κ in jia et al 2015 δ t 1 d from the 1 d diffusion equation is also decomposed into dynamical and spiciness anomalies because δ κ in this study exhibits large vertical variations such a decomposition is problematic using the results of jia et al 2015 as a guide their figs 3 and 4 we may attribute both δ a t and δ b t mostly to the dynamical component along the equator in the off equatorial regions the spiciness component can be significant especially in regions where salinity has large variations such as salty south pacific subtropical water overlying fresher deeper water there is a strong resemblance in the warming of the upper pycnocline in the central region between δ t 1 d generated by the positive δ κ z in fig 6 and δ t in fig 3 middle left we also see an analogue of the δ t 1 d and δ t distributions to the two left panels of fig 7 in jia et al 2015 in which κ b increases upwards within the upper pycnocline in the western equatorial region their experiment eqwa differences in the details result primarily from the positioning of the anomalies along the equator and the propagating characteristics of the dynamical anomaly in eqwa the surface cooling is limited to the western region because it occurs on light density surfaces that outcrop there this is in contrast to the subsurface warming that propagates eastward away from the directly forced western region and outcrops in the eastern region in fig 3 middle left and fig 6 upper right the subsurface warming outcrops in the central and eastern regions wiping out the surface cooling to increase sst there although the 1 d approximation is only defined for the initial phase there are times when the signatures of δ t 1 d are identifiable in the later stages of the model experiments as well fig 7 shows δ t 1 d and its components in 2015 and 2016 comparing figs 5 and 7 there is a good correspondence between δ t 1 d and δ t in the warming of the upper pycnocline in 2015 by contrast the positive δ t 1 d in the upper pycnocline is not visible in δ t in 2016 indicating a stronger influence from remote effects see the last paragraph of this section the results above show clearly that the surface warming along the equator in the central region fig 1c is brought about by the warming in the upper pycnocline from a change in the structure of the vertical diffusivity the same argument can also explain the warming at the surface east of the galapagos islands 90 w and the cooling below 24 5 26 5 σ θ in the eastern region fig 3 middle left fig 6 upper right these anomalies are then carried poleward by coastal kelvin waves to influence sst along the eastern boundary as discussed in the last section another effect of the subsurface cooling is the suppression of the warm layer around 26 5 σ θ along the equator fig 3 middle left fig 5 middle panels there are positive patches of δ t 1 d in the western region fig 6 upper right fig 7 upper left and in the eastern region fig 7 upper right that generate the positive anomaly across almost the whole of the equatorial extent this positive anomaly however does not reach the off equatorial regions because it is eliminated by the negative anomaly at the eastern boundary the cooling at the costa rica dome and its westward influence is a good demonstration of the competing strengths of local versus remote changes there are patches of persistently negative δ t 1 d around 90 w 10 n fig 8 left panels initially the cooling effect is evident only locally fig 8 upper right as time progresses its strength increases and its influence expands westward middle and lower right panels along its pathway negative δ t is reduced in regions of positive δ t 1 d e g 130 w and 170 e and enhanced in regions of negative δ t 1 d 150 w and 140 e on this shallow density surface 22 5 σ θ its influence on the equator is limited to the western region on deeper surfaces e g 23 5 σ θ it affects the temperature structure of the upper pycnocline to a much larger extent during the developing el niño in 2015 the positive δ t 1 d region fig 7 upper left is shifted eastward and is strong enough to prevail over negative influence from the west to generate a positive δ t fig 5 middle left whereas during 2016 the patches of positive δ t 1 d in the central region fig 7 upper right appear to be overcome by negative influence from the west resulting in a negative δ t fig 5 middle right 3 4 stratification and vertical shear the analysis in section 3 3 shows clearly that the warming along the equator and the cooling off the south american coast at the sea surface in the high vertical resolution experiment result from a change in the structure of vertical mixing in the pycnocline at the equator above the background vertical diffusivity which is set to the same constant in the model experiments the kpp scheme computes the convective and shear components below the surface boundary layer based on stratification n 2 and local gradient richardson number ri respectively we may expect that the change in vertical resolution has impacted significantly the stratification and vertical shear and therefore ri in this section we examine the characteristics of these two quantities at 140 w and 85 w on the equator the former is located where δ t 1 d is positive in the upper pycnocline and the latter where δ t 1 d is negative in the lower pycnocline fig 9 left shows the contrast in n 2 at 140 w equator between the two resolutions and between 2015 and 2016 higher vertical resolution permits a sharper pycnocline in both 2015 and 2016 but the effect is much larger in 2015 during the developing el niño despite the sharp increase in stratification in 2015 above the middle of the pycnocline maximum n 2 both δ κ and δ κ z are positive fig 9 upper right corresponding to negative δ a t and positive δ b t fig 7 middle and lower left panels respectively suggesting that ri in the high vertical resolution experiment is not only less than the critical value of 0 3 indicating the presence of shear generated turbulence but also much less than that in the low vertical resolution experiment the convective contributions dashed curves are similar in the two resolution fig 10 displays the power spectra of the vertical shear of the meridional component of velocity φ v averaged over 2015 the enhancement of φ v from low to high vertical resolution is clearly evident at wave numbers lower than 0 05 cpm which is taken here as the highest possible wave number corresponding to the lowest possible wave length of 20 m resolved by the low vertical resolution experiment there is a significant temporal variability in the shear spectra in the model experiments fig 11 shows φ v as a function of time and wave length for the high vertical resolution experiment the values of φ v at all resolved length scales are higher during el niño march 2015 february 2016 than the months that follow the elevated values are consistent with the elevated westerly wind activity during el niño see natarov and richards 2019 who consider the generation of inertia gravity waves by wind variability close to the equator the temporal variability of φ v in the low vertical resolution experiment is similar to that shown in fig 11 but lower in amplitude at 85 w equator the pycnocline is much shallower and sharper than in the central and western regions see figs 5 and 7 and maximum n 2 occurs above 40 m with a larger value in the high vertical resolution experiment fig 12 left panels beneath the highly stratified surface layer stratification is very weak and often becomes unstable as indicated by the significant level of convective contribution fig 12 right panels dashed curves to the total vertical diffusivity κ v in both the experiments note that negative n 2 is not reflected in the time averaged profiles the power spectra of vertical velocity shear not shown is similar to that at 140 w that is the shear intensity is higher in the high vertical resolution experiment and during the 2015 2016 el niño despite the enhancement in shear with increased vertical resolution δ κ is largely negative at the subsurface suggesting that stratification plays a dominant part in determining κ v at this location with a larger contribution coming from the convective component in the low vertical resolution experiment n 2 0 red dashed curves 4 summary discussion and concluding remarks in this study we explore the impact of vertical resolution in an ocean model in reducing sst biases in the tropical pacific ocean by conducting two model experiments that differ in the vertical discretization with the resolution in one being significantly higher than in the other in the upper ocean we find that the difference in the upper most layer temperature taken as sst between the high and low vertical resolution experiments is positive in the equatorial cold tongue and negative along the south american coast thus reducing the commonly seen cool and warm biases in the two regions respectively in the central equatorial pacific going from low to high vertical resolution the increase in vertical diffusivity specifically the increase in the upward gradient of vertical diffusivity in the upper pycnocline results in a warm anomaly that propagates eastward and rises to the surface to increase sst in the equatorial cold tongue the change in the structure of the vertical diffusivity in turn is the result of an enhancement in the shear generated turbulence power spectra of the vertical shear of the meridional component of velocity at 140 w equator show a significant increase with increased vertical resolution at wavelengths resolved by both the resolutions 20 m furthermore the high vertical resolution experiment also captures much of the finer scale vertical velocity shear 20 m the reduction in the cool sst bias in the cold tongue seen in the model experiments highlights the important contribution of fine scale vertical shear to mixing this result is in line with the observational studies in the western equatorial pacific as shown by measurements made with both a high frequency 600 khz acoustic doppler current profiler operated in lowered model ladcp and a relatively low frequency 70 khz ship based adcp richards et al 2012 vertical shear as measured by the high resolution ladcp is dominated by high peaks at small vertical scales that are not captured by the low resolution adcp and these peaks are closely associated with enhanced turbulent kinetic energy dissipation rate estimated using data from a microstructure profiler in the far eastern equatorial pacific the change in vertical diffusivity from low to high vertical resolution in the lower pycnocline produces a cool anomaly that propagates poleward as coastal kelvin waves along the west coast of the american continent and outcrops along the south american coast to reduce sst there stratification appears to be the dominant factor in changing the structure of the vertical diffusivity as seen at 85 w we hypothesize that the increased vertical resolution helps resolve the fine details of the stratification which is particularly weak beneath the shallow and highly stratified surface layer by contrast the low vertical resolution with 6 layers ranging from 11 to 17 m in thickness in the depth range of 60 140 m the region with large changes in vertical diffusivity is unlikely to represent the weak stratification well the impact of subsurface temperature structure in the eastern equatorial pacific on sst off the south american coast comes as no surprise its basis was well laid out in furue et al 2015 their fig 10 the connection between the two regions is present though not discussed in jia et al 2015 our supplementary figure fig s1 is the same as fig 13 of jia et al 2015 with the eastern limit extended to 70 w for each case shown in the figure the temperature anomaly along the equator is shown in fig 12 of jia et al 2015 note the aforementioned connectivity in particular the contrast between the warm anomaly in the eqwd and eqed cases versus the cool anomaly in the others more examples can be seen in sasaki et al 2012 in the three experiments shown in fig 6a c of sasaki et al 2012 their mixing parameterization results in a positive temperature difference at subsurface of varying magnitude that extends all the way to the eastern boundary it is by no coincidence that we see warming including the relative magnitude off the south american coast in the corresponding experiments in their fig 5b d in view of the high connectivity in the tropical pacific whether through equatorial kelvin waves along the equator where sst in the cold tongue can be impacted by mixing in the pycnocline to the west or through coastal kelvin waves along the eastern boundary where sst along the south american coast can be impacted by mixing at the equator high vertical resolution measurements are much needed for an improved knowledge of shear generated turbulence in the central and eastern regions and a detailed description of the stratification in the far eastern region to illustrate the importance of high vertical resolution we have conducted model experiments at a relatively coarse horizontal resolution as a compromise between the demand for computation and the need for a basin scale domain to achieve the observed level of vertical shear an adequate horizontal resolution is also needed to demonstrate this point in fig 13 we compare φ v from model experiments to data collected using a high resolution 600 khz ladcp during a 4 day time series in august 2015 at 170 w 1 n from r v falkor cruise fk150728 the observations show a strongly peaked spectrum peaking around 50 m wavelength similar to spectra from measurements in the western equatorial pacific see richards et al 2015 the shear spectrum from the low vertical resolution experiment falls well below the observations the high vertical resolution experiment produces a spectrum that fills out much of the higher wavenumbers there remains however a marked deficit for wavelengths greater than 20 m for comparison we include the shear spectrum from a companion experiment where the model is downscaled in a region surrounding the location of the observations such that the horizontal resolution is 1 27 with the increased resolution in both the horizontal and vertical directions the model spectrum is now peaked around 50 m wavelength approaching that of the observations our results clearly show that adequate vertical resolution is required to capture relatively small vertical scale features in the equatorial ocean and that those features make an important contribution to vertical mixing which in turn impacts the larger scale ocean structure we suggest that more emphasis is put on resolving these scales in both models and observations and a better understanding is required of their spatial and temporal variability another possible benefit linked to an increase in vertical resolution in models is the likely reduction in numerical diffusion associated with advection schemes in a study of the formation mechanism of the pacific equatorial thermocline tatebe and hasumi 2010 showed that by reducing numerical diffusion in a model sst is increased in the central equatorial pacific and decreased along the south american coast their fig 9 in much the same way as shown in this study by explicit diffusion the reduction in numerical diffusion is achieved through the use of a highly accurate advection scheme the second order moment som scheme prather 1986 compared with a third order scheme that introduces much numerical diffusion in our model experiments we use the third order direct space time dst scheme as implemented in mitgcm since the same advection scheme is used in our experiments we may expect some but limited cancellation of the effect of numerical diffusion when we compute the difference in potential temperature between experiments a reduction in numerical diffusion will occur through the increase in vertical resolution and may have contributed to the changes in sst in addition to the explicit diffusion lastly we have conducted ocean only experiments coupled experiments are required to quantify the magnitude and temporal variability which can be done with atmospheric models of varying complexity see e g zhang et al 2020 we expect that coupling with the atmosphere will enhance the impact on the cold tongue sst as shown by sasaki et al 2013 credit authorship contribution statement yanli jia methodology formal analysis investigation writing original draft writing reviewing editing kelvin j richards conceptualization methodology investigation writing reviewing editing supervision funding acquisition h annamalai methodology investigation writing reviewing editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was funded by the national oceanic and atmospheric administration noaa grant number na18oar4310404 a pre field modeling study in support of the tropical pacific observing system tpos process studies a component of tpos 2020 we thank the support of the schmidt ocean institute and the captain and crew of the r v falkor cruise fk150728 in the collection of the ladcp data included in fig 13 we appreciate the time and effort of the editors and anonymous reviewers whose comments and suggestions helped improve the manuscript the authors wish to acknowledge use of the ferret program for analysis and graphics in this paper ferret is a product of noaa s pacific marine environmental laboratory information is available at http ferret pmel noaa gov ferret the technical support and advanced computing resources from the university of hawaii information technology services cyberinfrastructure are gratefully acknowledged appendix a supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j ocemod 2020 101722 appendix a supplementary data the following is the supplementary material related to this article mmc s1 
23931,shallow water equations swes are discretised on a regional spherical multiple cell smc grid the smc grid uses unstructured techniques with rectangular cells and supports multi resolutions like mesh refinement the numerical schemes on the 2 d smc grid are combinations of the conventional finite difference ones and flux form finite volume formulations in 1 d loops semi implicit schemes are used for both coriolis terms and potential energy gradients the water height equation is solved with a c grid mass conserving advection scheme and a diffusion term to suppress numerical instability mixed a and d grid schemes are applied on the momentum equation plus a weighted average to remove short waves boundary conditions are incorporated on all cell faces so that any cell could be wet or dry depending on whether its water height is positive approximations across refinement interfaces are explained a filling or flooding experiment on a four level 3 6 12 25 km mediterranean sea grid is used for demonstration the test is done by emptying the whole mediterranean sea at start and then filling the basins with flood water from selected river mouths and strait channels until the whole mediterranean sea is filled up this experiment illustrates that the swes model on the multi resolution smc grid can simulate the filling process as expected and restore a flat sea surface at the end another test is carried out to simulate possible tsunami waves when the flat sea surface is disturbed by volcanic eruptions or earthquake movements results indicate that vertical shift of sea surface at one site in the ionian sea may generate tsunami waves and orientation of the initial disturbance has a profound influence on the subsequent tsunami waves which could spread out to the whole mediterranean sea in a few hours further improvements are required to simulate real tsunamis and coastal surges keywords shallow water equations smc grid surge modelling tsunami waves mediterranean sea 1 introduction shallow water equations swes have been used widely for tests of numerical algorithms and different model grids williamson et al 1992 because they are a simple set of 2 d fluid dynamical equations swes also have many real applications such as numerical modelling of ocean storm surges and tsunami propagations for instance the slosh surge forecasting model glahn et al 2009 and several established operational tsunami warning systems behrens and dias 2015 are based on the swes routine surge forecasting is part of coastal hazard warning system in most weather forecasting centres over the world and tsunami studies are greatly accelerated after the 2004 indian ocean tsunami synolakis and bernard 2006 reviewed the history of tsunami studies before the 2004 indian ocean tsunami and emphasised the importance of developing tsunami inundation modelling tools for inundation forecasting and model validations with observations from different instruments a common requirement for coastal surge and tsunami warning is that both far field propagation and detailed coastal inundation need to be simulated this is a challenge to conventional model grids because limited computing resources prohibit both a large domain and a high resolution mesh in a single model a straightforward solution is by using nested grids and an alternative approach is building a multi resolution grid model finite element methods on unstructured triangular cell grids have been successfully applied in surge and tsunami models such as the application of the adcirc surge model musinguzi et al 2019 an unstructured triangular cell grid provides fine resolution near coastlines and inland waterways along with gradually relaxed coarser resolution cells offshore however this paradigm usually requires a lot of computing resources and may not meet the timeless requirement of surge forecasting and tsunami warning adaptive mesh refinement berger and oliger 1984 and its later improved quadtree technique popinet and rickard 2007 have also been successfully applied in tackling the large domain and high resolution conflict leveque et al 2011 demonstrated how finite volume algorithms are combined with adaptive mesh refinement techniques in simulation of transoceanic tsunami propagation and detailed modelling of inundation in refined coastal regions using the depth averaged swes popinet 2011 implemented a well balanced positive preserving scheme of audusse et al 2004 for swes on a quadtree adaptive grid to simulate tsunami waves it provides mesh refinement dynamically and flexible wetting and drying near coastal areas the original adaptive mesh refinement by berger and oliger 1984 and later application for tsunami waves by leveque et al 2011 are built on a base or coarse structured grid with block structured dynamic refinements the base grid is a rectangular mesh and contains masked land points when irregular coastlines are involved this drawback may be mitigated by combining static refinement near coastlines with the normal adaptive refinement in open seas as done by popinet and rickard 2007 the spherical multiple cell smc grid li 2011 2019 is a combination of the latitude longitude lat lon grid and unstructured grid technique it is adapted from the cartesian multiple cell unstructured grid li 2003 and added the longitudinal cell merging like a reduced grid gates and riegel 1962 as it uses the lat lon grid quadrilateral cells numerical modes are minimised and simple finite difference schemes on lat lon grids are retained it also supports static mesh refinement so coastal refinement could be achieved for resolving small islands and modelling coastal inundations flux form finite volume formulations are used to handle the multi resolution cells the smc grid has been used for resolving coastline details and small islands in an ocean surface wave model li 2012 ww3dg 2019 applications of this grid include both routine ocean surface wave forecasting in the uk met office li and saulter 2014 and arctic wave climate studies casas prat et al 2018 li et al 2019 swes have been discretised on a global smc grid and validated with classical tests by li 2018 including the steady zonal flow over flat or hill floor and the rossby haurwitz wave suggested by williamson et al 1992 and the unstable zonal jet proposed by galewsky et al 2004 this article presents work to adapt the swes model for a regional smc grid with improved boundary conditions a brief introduction of the smc grid is provided in section 2 for readers convenience plus some finite difference details across refinement interfaces swes discretisation on the smc grid is summarised in section 3 along with description of updated boundary conditions an experiment of filling the whole mediterranean sea is presented in section 4 to test the boundary conditions and to demonstrate dry wet changing over the whole model domain in section 5 the propagation and dissipation of an initial disturbance on a flat sea surface are simulated for assessment of the model stabilities and possible tsunami scenarios in the mediterranean sea the summary and conclusions follow in section 6 2 the medi36125 smc grid examples of global smc grids including the arctic are given by li 2012 2016 2019 with descriptions of how ocean surface waves propagate on them here a regional smc grid for the mediterranean sea will be used to summarise the smc grid techniques for the convenience of readers who are unfamiliar with ocean surface wave models smc grid is an unstructured mesh tessellated with rectangular cells the grid consists of a list of cells at multiple sizes of given unit increments of latitude δ φ and longitude δ λ as illustrated in fig 1 the solid red lines mark actual cells in the grid cell list and the red dots indicate their cell centres a unique 5 element integer array is assigned to each cell to hold its south west corner x y indices i j cell side x y increment δ i δ j and the cell floor bathymetric height b the x and y indices are measured in unit or size 1 cell increments δ φ and δ λ so cell centre latitude and longitude are given by φ j φ 0 j 0 5 δ j δ φ and λ i λ 0 i 0 5 δ i δ λ where λ 0 and φ 0 are the longitude and latitude of the x y coordinate origin for a global grid the origin of the grid can be set at zero meridian on the equator so both λ 0 and φ 0 are zero one restriction for building this grid is that resolution refinement is done by gradually halving the cells which is equivalent to the factor 2 refinement as classified by debreu and blayo 2008 as a result neighbouring cells can be either of the same size or doubled halved in size hence the name of multiple cell grid cells are merged longitudinally at high latitudes following the same rules in li 2011 to solve the polar problems there is no restriction on the domain shape as long as required domain area is covered by tightly paved cells neighbouring cells are not required to be side by side in memory as unstructured techniques are used in fact all selected cells are sorted by their sizes in a final cell list so that sub timesteps could be used for refined cells this makes the smc grid much more efficient than those triangle cell unstructured grids whose time step is restricted by the smallest cell for ocean surface wave models only cells over sea points are selected and land surface is removed completely out of the model calculation because cells are stored in an unstructured 1 d list their spatial relations are precalculated and stored in face arrays for each cell face a 7 element face array is used to mark the upstream centre and downstream cells in addition to its size and location indices the face arrays are grouped by two dimensions and sorted by their face sizes for use of sub timesteps propagation on the smc grid is calculated in two steps 1 individual flux across each cell face is calculated in a face loop based on pre calculated face array information 2 fluxes into each cell are accumulated in a temporary array and the net flux is used to update the cell value in a cell loop both the face and cell loops are divided into sub loops by their sizes and sub timesteps are used for refined face and cell sub loops li 2012 this sub loop technique makes the multi resolution smc grid more efficient than nested grids because of the removal of overlapping regions and boundary conditions in nested systems in addition the flexible refinement of the unstructured smc grid does not need to keep a whole rectangular sub domain at high resolution as in conventional nested grids for refinement interface such as a cell face between a coarse and two refined cells smc grid assumes a first order approximation that the coarse cell is uniform within its cell area and it could be divided into two halved cells of the same properties as the coarse cell such as velocity and water height this approximation avoids interpolations between different sized cells whose centres are unaligned due to the factor 2 refinement the dashed green lines in fig 1 indicate how the coarse cells marked by the solid red lines are divided into halved cells the green dots indicate the centres of those halved virtual cells which are aligned with the refined cells finite difference across such a refinement interface is then approximated by averaged differences between the halved cells and the refined cells in the propagation scheme the face flux is calculated on refined faces at a refinement interface in face loops these refined fluxes are automatically averaged for coarse cells in their net fluxes spatial gradients between different sized cells are also averaged in this way for coarse cells so for a coarse cell bounded by a coarse cell on the left and two refined cells on the right its cell gradient will be the average of one face gradient between the coarse cells and two refined face gradients between the halved virtual cells and the two refined cells this is equivalent to a space centred gradient scheme except that across the refinement interface the averaged difference is used this average may partially remove the short waves or noises caused by the refinement this approximation on refinement interface is used for all spatial schemes including advection diffusion average and gradient schemes on the smc grid fig 2 shows a regional smc grid for the mediterranean sea it has a base resolution of 25 km and 3 refined levels at approximately 12 6 and 3 km it will be referred to as medi36125 grid it cuts off other seas at the strait of gibraltar the suez canal and the istanbul channel its latitude and longitude increments at the finest resolution or for a size 1 cell are δ φ 0 029296875 and δ λ 0 0439453125 respectively which are roughly 3 km in the mediterranean sea the longitudinal increment is chosen so that merged cells at high latitudes are exact multiples of size 8 cells this is for consistency and easy comparison with a similar global grid li 2016 due to the finest resolution being about 3 km narrow passes especially those around the greek islands are expanded to link up all sea surfaces this is necessary for the following test because isolated sea basins could not be filled up the cell floor bathymetric depth at each cell is indicated by its edge colour and the deepest cell is 4632 m from the sea level the bathymetric depth is an integer in unit of a metre to keep the cell array to be an integer array if higher bathymetric resolution is required another unit like centimetre may be used apart from the mediterranean sea surface area the medi36125 grid also covers coastal area up to 10 m above sea level to allow surge inundations the one metre vertical resolution for the cell floor bathymetry is proportional to the horizontal resolution at 3 km which is enough for ocean surface wave models but is deemed too coarse for coastal flooding or storm surge it will be demonstrated later that small surges could only affect those cells with bottom floor aligned at the sea level while other coastal cells above sea level by 1 m or more will remain dry the filled red cells in fig 2 mark those cells with bathymetric floor at the sea level there are 195 cells whose bathymetric floor are at the sea level including 3 size 4 cells at the north end of the adriatic sea near venice and 3 in the nile delta near cairo these two areas will be used to show coastal surges there are 27 129 cells in total including 16232 6459 2601 and 1837 cells in size 1 2 4 and 8 respectively note that the finest size 1 cells are more than the sum of all other sized ones nevertheless the multi resolution grid is still much smaller than a uniform grid at size 1 resolution which would have as many as 201 252 size 1 cells or could be more than 7 times as large as the present medi36125 grid this reduction on total cell numbers by multi resolution cells will be significant when high resolution is required for some specific regions 3 discretisation of shallow water equations 3 1 equation set and numerical schemes the nonlinear swes used in this model follow ringler et al 2010 in a vector invariant form 1 h t h v κ h b i r cos φ λ j r φ 2 v t η k v g h b k 0 where h is the fluid thickness or the water column height t the time v u i υ j the fluid horizontal velocity on the earth s surface κ a diffusion coefficient b the bottom topography the horizontal gradient operator i and j the horizontal unit vectors of the local cartesian coordinates k the vertical unit vector r the radius of the earth φ the latitude λ the longitude g the gravity constant k v 2 2 the kinetic energy η f ξ the absolute vorticity f 2 ω sin φ the coriolis parameter ω the angular spinning speed of the earth and ξ is the relative vorticity defined as a diagnostic variable by 3 ξ k v the curvature terms are ignored because they are only significant near the poles where a new method will be used in this model to avoid the increased curvature the diffusion term in 1 is added for smoothing purpose and is applied to the total height h b so that a steady state at rest could be preserved for irregular ocean floors the momentum equation should be modified for the polar regions due to the invalid scalar assumption at high latitudes li 2018 a fixed map east direction is then introduced in the polar region to define the vector components li 2016 the map east system in the polar region can be approximated with a rotated grid with its rotated poles on the equator the conversion between the two direction systems is a simple rotation by an angle α from the map east direction to the local east direction the rotation coefficients are given by 4 cos α cos λ sin φ 1 cos λ cos φ 2 sin α sin λ 1 cos λ cos φ 2 the continuity eq 1 can be discretised straightforwardly on the smc grid as a scalar advection equation as in li 2011 if the water thickness is located at the cell centre and normal velocities on cell faces c grid the uno2 scheme li 2008 can be used to determine thickness fluxes so 1 is estimated by 5 h n 1 h n δ t a s f s l s where the superscript n represents the n th time level δ t denotes the time step a is the cell area f s the combined advection mid flux and the diffusion flux through the cell side s and l s the length of the cell side the summation is over all sides of the given cell and will automatically average fluxes through refined cell faces if the cell is bounded with refined cells as this is a 2 d model cell side and cell face will share the same meaning the momentum equations are discretised on a mixed a and d grid that is the velocity at each cell centre is solved by the prognostic equation 2 while relative vorticity 3 is integrated along cell sides with interpolated tangential velocity for stability purpose both the absolute vorticity term and the potential energy gradients are approximated by semi implicit schemes the momentum equation 2 can then be transformed into local cartesian component form as 6a u n 1 u n β n 2 υ n β n u n g y n 1 g x n 1 1 β n 2 6b υ n 1 υ n β n u n 1 u n g y n 1 where β n η n δ t 2 and the x direction gradient g x n 1 δ t i g h n 1 g b k n in low latitudes the component direction will be the same local east as in a lat lon grid in the polar regions the momentum equation 6 retains the same form except for that the gradient components are projected to the map east system instead of the local east system as it is crucial to get the coriolis parameter right in the absolute vorticity estimation walters et al 2009 the coriolis terms are calculated with the exact cell centre velocity components while the relative vorticity 3 is converted into cell side loop integration the stokes theorem with interpolated velocities on cell sides the relative vorticity loop integration is then approximated as a polygonal cell side summation 7 ξ k v 1 a s v s l s t where a is the area of the cell the subscript s indicates cell side l s t is the side length tangential vector that follows an anti clockwise circle around the given cell for a cell bounded with refined cells the sum will be over its refined interfaces as smc grid mass transportation 5 requires the normal velocity components on cell sides while the relative vorticity 7 needs the tangential velocity components on cell sides the cell centre velocity components solved with 6 are then interpolated on cell sides using their water thickness as weights 8 v s h v h v h h ε where h is the thickness for the downstream and upstream cells of the given cell side and ε is a negligibly positive value to avoid zero dividing when both cells have zero water height for refinement interfaces the face velocities are calculated between halved virtual cells and refined cells and they are centred on the refined interfaces the weighted interpolation 8 approximates the depth integrated method of kleptsova et al 2009 for stability with variable bathymetry as the velocity components are in the fixed direction system in the polar regions the component interpolation can be done as a true scalar interpolation at high latitudes without worrying about the increased curvatures the interpolated face velocities however must be rotated into the local east system in the polar regions using the rotation coefficients 4 the kinetic energy can be estimated directly with the cell centre velocity and then added to the potential energy for a combined gradient term calculation of the gradient terms in 6 requires a different formulation in the polar regions as the cell centre velocity components directions are in the map east system rather than the cell face normal directions in local east system the gradient term is first calculated in the local east system on each cell face and then rotated to the map east system in the polar regions before they are averaged for the cell centre gradients that is 9 g x n 1 δ t i e δ t l s s i l s n e e d e g h n 1 g b k n where l sn is the side length normal vector pointing from cell towards cell l s the total side length of the summed sides for the given cell e the energy of the two cells sharing the given face and d the distance between the two cell centres for a cell bounded with refined cells the cell centre gradient is automatically an average of the gradients between halved virtual cells and refined cells the gradient component direction vector i is the local east unit vector at low latitudes but changes to the map east direction in the polar regions for stability reasons it is important to use the n 1 time step potential energy gh n 1 for the energy gradient 9 this is done by simply integrating the thickness eq 5 first before calculating the gradient term 9 there is a known instability problem associated with the cell face velocity interpolation 8 from a grid velocity mcdonald and bates 1989 lin and rood 1997 weller et al 2009 despite using weighted interpolations the half cell approximation at refinement interfaces may also cause some oscillations in a strong jet case li 2018 besides false gravity waves could be generated due to mismatched representations of physical fields in numerical models mohebalhojeh and dritschel 2000 so an extra smoothing is needed to control these small numerical oscillations or spurious short waves a 1 2 1 weighted local average in each dimension is applied for the velocity components at selected intervals the average is equivalent to a diffusion term with a fourier number of 1 4 for one time step li 2008 the average intervals are selected to be just short enough for suppressing numerical instability and can be set to be different for polar and low latitude regions the water thickness field is smoothed by the built in flux form diffusion term in 1 for mass conservation purposes as the 1 2 1 average does not guarantee mass conservation to match the extra polar smoothing of the velocity components the diffusivity coefficient is specified as a polar biased function of the latitude 10 κ κ m 1 γ γ sin 2 ϕ κ m δ x m i n 2 2 δ t 0 γ 1 where γ is a tuneable parameter to control the polar bias and κ m is the maximum diffusivity which is limited by the stability requirement depending on the minimum grid length δ x m i n and time step δ t the 1 2 1 average for the momentum and the extra diffusion term in the mass conservation equation are necessary to keep the multi resolution model stable these extra smoothing are equivalent to the restricted step as mentioned by debreu and blayo 2008 3 2 boundary conditions boundary conditions may vary for different models for ocean surface wave models the zero boundary condition is required at coastlines for a global model a periodic condition is usually applied in the longitude direction the smc grid is originally developed for global wave models and the coastal zero boundary condition and the global periodic conditions are built into the face arrays this approach effectively changes any boundary face into an equivalent inner face so that a single loop covers all faces the periodic boundary condition is applied by linking the end cell with the start cell at one parallel circle in the face array the zero boundary condition at coastlines is achieved by bounding each coastal cell face with an empty cell in its face array if external boundary conditions are required at cut off lines such as the strait of gibraltar in this model they can be applied directly on selected boundary cells with an extra boundary condition loop just like in a conventional structured grid for this mediterranean sea model the cut off lines at the strait of gibraltar the suez canal and the istanbul channel are all assumed to be closed and treated the same way as other coastlines for the swes model vertical wall boundary conditions are applied at coastlines any coastal cell face is supposed to be bounded by the same inner cell on both sides in its face array so that water or energy flux out of the inner cell if any when the inner cell is wet will be automatically sent back into the inner cell this is equivalent to set the normal velocity to be zero at coastal boundary faces no water can leak through these real boundary faces for this reason any possible flooding zone must be included in the smc grid for the medi36125 grid the sea surface grid is extended to coastal area up to 10 m above sea level in order to simulate flooding any cell in this swes model is enabled to flip between wet and dry status as coastlines may move with flooding waters the cliff wall boundary conditions are extendedfor inner faces if required for this purpose a cell is deemed wet when its cell centre water height h is positive or h ε otherwise it is treated as a dry cell velocity is set to be zero at a dry cell centre without solving 6 any inner face bounded by two dry cells will be referred to as a dry face is simply skipped in face loops as illustrated in fig 3 this is equivalent to treating the area covered by the two dry cells as land area if a cell face is bounded by a wet cell and a dry cell and the dry cell floor is higher than the wet cell water level it will be treated as a vertical wall boundary face and referred to as a higher dry face in fig 3 if the dry cell floor is lower than the wet cell water level the face is considered a normal inner face just like any wet face bounded by two wet cells this ensures water from the wet cell can flow into the lower dry cell under gravity the wet to wet and wet to lower dry faces are marked as inner faces in fig 3 cliff wall boundary conditions are extended to those higher dry faces the cell side velocity interpolation 8 is modified for the higher dry faces by setting the normal velocity component to be zero and the tangential component to be equal to the value at the wet cell centre this is equivalent to the cliff wall boundary condition applied to all coastal faces the energy gradient term 9 is set to be zero at higher dry faces so the net momentum flux is zero across these boundary faces the weighted average for the momentum equation is limited among wet cells to avoid energy dissipation into dry cells this tangential velocity assignment and zero energy gradient on the higher dry boundary faces ensures the hollingsworth instability hollingsworth et al 1983 is avoided water mass advection fluxes through the higher dry faces are also zero because the normal velocity component is zero although the diffusion flux in 1 is proportional to the gradient of total water height h b it is only calculated between wet cells that is the diffusion flux through a higher dry face is also zero these zero advection and diffusion fluxes through higher dry faces ensure water mass is confined within low area otherwise water mass might be numerically pumped into higher dry cells violating the common sense that a lake at rest has a mirror flat surface 4 filling the mediterranean basins flooding a low area is a common phenomenon in real life and the process and final state are well known to us this filling experiment is designed to test whether the swes model could simulate the process of water flowing into low areas and reach a final flat surface state when water sources are exhausted all the mediterranean sea basins are emptied at the start except for a few source cells near river mouths and in strait channels water heights in those source cells are maintained at the sea level throughout the experiment to provide unlimited water sources water from these source cells will flow into low areas under the gravity force forming rapid streams or even water falls at the early stage the water flow will eventually slow down when the water level approaches the sea level and automatically switch off when all the mediterranean sea basins are filled up to the sea level it is expected that the initial water velocity may become quite large particularly in areas where the basin floors are steep in fact floor level differences between neighbouring cells in the medi36125 grid may exceed hundreds of metres and initial filling flows across these cells will be vertical falls higher than any water falls in the world to prevent the model from crashing out at the early stage due to possible very large flow speed a speed limit of 20 m s 1 is applied on each velocity component and this allows a reasonable time step to be used for the whole filling experiment a 30 s time step is used in this experiment and the maximum diffusivity is set to 6 0e5 m2 s 1 because the mediterranean sea is at low latitudes there is no need to change the default parameters for the polar regions which include γ 0 1 and average interval of 4 min fig 4a shows the initial state of the model and the water heights at those source cells are shown by the colour filled cells most of the source cell water columns are below 100 m as they are close to river mouths but there are a few over hundreds of metres highest 742 m particularly in the strait of gibraltar fig 4b shows the water depth after 24 h filling the waters from the strait of gibraltar and river rhone south of france first pool in the basin to the east of spain the water from river nile goes directly into the main basin in east mediterranean the water from venice flows a long way through the adriatic sea and pools in the ionian sea basin rivers vardar and strimon in north greece feed directly into the aegean sea and water from the black sea through istanbul channel pools in the sea of marmara first and then spills over a narrow channel into the aegean sea note the flow from river nile is not presented as continuous in fig 4a this is due to the positive filter for water height having thrown out some negative water heights and reset them to be zero because of the rapid flow speed in this area the advection may have resulted in some minor oscillations fig 4c shows the water depth after 10 day filling by this time water pooled in the west basin has spilt over the underwater ridge between sardinia and tunisia into the tyrrhenian sea to the southwest of italy waters from other sources have met in the central basin of ionian sea fig 4d is the water depth after 20 days by then waters from all sources have linked up after the tyrrhenian sea and ionian sea are linked up fig 4e is the water depth after 40 days filling and by this time the whole mediterranean sea is already filled up this is indicated by the maximum depth of 4632 m the final plot of fig 4f is the water depth after 100 days which is almost identical to fig 4e of the 40 days plot this confirms that the model stayed stable after the mediterranean sea is filled up the filling process may also be illustrated by the flow speed plots in fig 5 fig 5a shows the flow speed after 10 days water speeds close to source points are almost at the maximum speed as indicated by the red coloured cells remember the model has a velocity component limit of 20 m s 1 so the maximum speed is 28 28 m s 1 as indicated in the plot to avoid output underflow in the scientific notation small velocity components of absolute values below 1 0e 90 m s 1 are all saved as 1 0e 90 hence the minimum speed of 1 414e 90 m s 1 should be treated as zero speed only the istanbul water flow has almost stopped because the sea of marmara is nearly blocked by the narrow channel linking the aegean sea water is still flowing through the channel but very slowly the broken flow off the river nile delta reveals the large speed gradient there in fact they are water falls due to the sharp fall of the basin floor beyond the nile delta fig 5b shows the water speed after 20 days apart from the high speed near water sources the spilling flow from the tyrrhenian sea to the ionian sea is also quite rapid this is because the water source from the strait of gibraltar is much stronger than other sources and the west basins are filled up more quickly than the central and east basins fig 5c shows the water speed after 40 days by this time the filling has already completed so the maximum speed dropped to about 0 14 m s 1 this is probably an oscillation speed caused by gravity waves as small maximum speed around this order is maintained until the end of the model run of 200 days water flows have stopped by 40 days but gravity waves may linger a bit longer to estimate the filling rate the water volume in the mediterranean basins during the filling test is integrated at regular intervals and is shown in fig 6 water volume in each cell is measured by its floor area in steradian at the earth s radius multiplied by its water column height in metre so the total water volume is given in the unit of m sr taking the earth s radius as 6371 km 1 m sr is about 40590 km3 the initial water volume is not zero because of the source cells are filled up to the sea level during the whole test the initial volume is about 3 2e 3 m sr the filling rate is largest at the start and is almost a constant during the first few days this is because the water flow speed is limited by the maximum velocity component of 20 m s 1 after the initial rush the filling rate slows down due to the decrease of water level differences between the source cells and its neighbouring cells over just a month all the basins are almost filled up and the filling rate eventually becomes zero when the whole mediterranean sea is filled up to the sea level the total water volume remains constant afterwards to the end of the 200 days model run but only the first 50 days are shown here the total volume of the mediterranean basins up to the sea level is about 94 0 m sr as represented by the medi36125 grid although we could not do this experiment in the real world the filling processes presented here agree well with our expectation the experiment has demonstrated that the dry wet change over the whole sea area goes well and it is reasonable to expect that it will perform well in coastal regions 5 tsunami waves by initial disturbance propagation of gravity waves caused by an initial disturbance is also simulated in this regional smc grid swes model the time step and diffusion coefficient are set the same as used in the previous filling experiment the whole mediterranean sea is assumed to be at rest with a flat water surface at the sea level except for 4 size 8 cells to the east of the sicily island in the ionian sea a 5 m high water column is taken from 2 cells and added to its neighbouring 2 cells forming an initial disturbance of 5 m shift of the water surface as shown by the water height difference from the sea level in fig 7a the four disturbed size 8 cells cover an area about 60 50 km2 close to an area hit by a moderate earthquake the 5 m initial disturbance is of the same order as the 2004 indian ocean earthquake as estimated by pietrzak et al 2007 though the disturbed area is much smaller than the 2004 one the model is then let free to run until its flat surface is restored it is envisaged that gravity or tsunami waves may be generated by this initial water surface shift fig 7b shows the water height difference from the sea level after 1 h model time gravity waves of magnitude about 7 cm are visible within about 600 km from the initial disturbance site as shallow water gravity waves speed is approximately g h and the water depth in the ionian sea is about 3000 m the tsunami travels at about 170 m s 1 in the ionian sea and it covers roughly 600 km in one hour there are two wave crescent circles so the gravity wavelength is about 300 km which is a typical tsunami wavelength in open oceans where the water is over thousands of metres deep fig 7c is the water height difference after 4 h model time by then the tsunami waves have reached the coastlines of the whole mediterranean sea because the distance from the strait of gibraltar to the nile delta spans just over 2 time zones at the latitude of 35 n the mediterranean basin size from west to east could be estimated to be π r 6 cos 35 or about 2732 km which could be covered by the tsunami in about 4 5 h the maximum magnitudes of the tsunami waves have fallen below 1 cm after 4 h and it must be at centimetre order at coastlines these small tsunami surges are hardly visible by naked eyes and only manifest themselves in those cells with bottom floor at exactly the sea level to show this small surge effect an inset of the north end of the adriatic sea near venice is inserted in each plot in fig 7 the inset in fig 7a or the t 0 plot is cropped from the medi36125 grid plot fig 2 to show the filled red cells at the sea level the inset in fig 7b or t 1 h is an enlarged crop from the same plot as the tsunami waves have not reached this part yet at t 1 h the inset area is still at its initial state or flat at the sea level and the sea level cells marked red in fig 7a inset remain to be dry the first wave arrives at the venice coast in about 3 h and maintains the surge for another 3 h there while the first wave crescent comes and returns the inset in fig 7c or the t 4 h plot shows that the surge has inundated all the sea level cells in this area though the water height is not significant the small surge could not overcome the cliff walls at least 1 m high above sea level beyond the sea level cells and is reflected into the open sea another initial disturbance rotated by 90 from that in the previous experiment is used to illustrate the directional effect of the water shift fig 8a shows the rotated initial disturbance which is now with a 5 m dip on the west and a 5 m lump on the east side fig 8b shows the water height difference from the sea level after 1 h model time the maximum wave height difference is now about 16 cm more than doubled that of the previous test also note the tsunami waves travelling towards the west has a recession or trough in the front instead of a crescent surge in the first experiment the east travelling waves also reversed with a surge in the front though the wavelength looks close to that of the first experiment tsunami waves in the ionian sea travel faster than in the adriatic sea because of the ionian sea is much deeper than the adriatic sea the first wave arrives at the nile delta in about 1 5 h and maintains the surge there over an hour fig 8c shows the water height difference after 2 h when the first wave surge covers the nile delta area near cairo the maximum surge is about 4 cm which is higher than that of the first experiment but is still very small nevertheless the surge has turned the initial dry sea level cells in the nile delta area into wet cells when the surge passes this area the insets in fig 8 show the corresponding grid crop and enlarged crops from the same water height difference plots at t 1 and 2 h the filled red cells indicated by the inset in fig 8a remain dry in the t 1 h inset of fig 8b because the surge has not arrived yet by then the sea level cells become wet when the surge arrives as shown in the t 2 h inset of fig 8c though their water heights are quite small the differences between the two tests indicate that initial disturbance orientations have visible influences on the subsequent tsunami waves possible reasons for the small coastal surges in the initial disturbance tests may be due to the additional diffusion term and the second order advection scheme used in the water height equation popinet 2011 showed that the minmod scheme tends to be too dissipative for realistic tsunami modelling though it is very stable and gives reasonable results for dissipative systems the uno2 scheme li 2008 used in this model is a modification of the minmod scheme heinrich et al 2001 simulated the 1998 papua new guinea tsunami with a swes model including a bottom friction term as a viscous flow they stated that high resolution bathymetry up to 5 m accuracy and horizontal mesh close to 100 m resolution in the coastal area may be necessary to simulate the tsunami inundation the 3 km horizontal resolution of the medi36125 grid may be too coarse for this purpose behrens and dias 2015 reviewed numerical simulation of tsunami waves and pointed out that accurate simulation of tsunami wave is quite demanding due to its large span of spatial and temporal scales in deep ocean tsunami wave propagation may be approximated by shallow water equations but its transition to a bore or solitary wave train in shelf areas and then into breaking wave in coastal regions demands other mathematical and numerical treatments this is however beyond the scope of this study 6 summary and conclusions shallow water equations swes are discretised on a spherical multiple cell smc grid for the mediterranean sea the smc grid is an unstructured grid and retains finite difference schemes on conventional latitude longitude grid it uses merged cells at high latitudes to relax the cfl restriction on eulerian transport schemes and redefines vector components by a fixed reference direction near the poles to avoid the vector polar problems flux form finite volume formulations are included for multi resolution interfaces the a grid discretisation is applied on prognostic variables of the swes and cell centre velocity is interpolated onto cell faces using a weighted interpolation the mass conservation equation is solved with a non oscillatory advection scheme and momentum equations are estimated with semi implicit schemes for stability a 1 2 1 weighted average is applied on momentum equations and polar biased diffusion in mass conservation equation to suppress numerical noises a brief description of the unstructured smc grid is presented and finite difference schemes across refinement interfaces are described applications of different boundary conditions on the smc grid are explained for this swes model vertical wall boundary conditions are applied on all boundary faces and any wet cell face bounded by a dry cell whose floor is higher than the water surface of the wet cell this extended boundary condition allows any cell on this smc grid to flip between wet and dry states if required momentum calculations over dry cells are simply skipped and smoothing is restricted among wet cells for conservation purposes an experiment of filling the mediterranean sea basins is used to test this model and results demonstrate that the filling processes agree well with expectations the whole mediterranean sea is filled up to the sea level in about one month by water from river mouths and strait channels total water volume amounts to about 94 m sr another experiment is conducted to simulate tsunami waves caused by initial water surface disturbances it was shown that tsunami waves could travel at about 170 m s 1 and reach mediterranean coastlines in roughly 4 h if an earthquake disturbance occurred in the ionian sea the experiment also revealed that orientation of the initial disturbance has profound influence on the subsequent tsunami waves the coastal surges caused by the initial disturbances are quite small and surge inundations are only revealed by a few coastal cells with floor elevations aligned at the sea level there are several possible reasons for the small coastal surges in the initial disturbance tests coarse grid resolution and heavy smoothing may be responsible for it limitation of the swes to describe coastal bores and breaking waves may be another reason declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the author is grateful to dr andrew saulter met office uk for his encouragement and useful discussions the author s gratitude also extends to the three anonymous reviewers and the editor oliver fringer for their suggestions and comments to improve this article particularly for reviewer 1 s request to include the numerical details on cell refinement interfaces and reviewer 2 s scrutiny of typos and language issues the work is funded by the uk national weather service 
23931,shallow water equations swes are discretised on a regional spherical multiple cell smc grid the smc grid uses unstructured techniques with rectangular cells and supports multi resolutions like mesh refinement the numerical schemes on the 2 d smc grid are combinations of the conventional finite difference ones and flux form finite volume formulations in 1 d loops semi implicit schemes are used for both coriolis terms and potential energy gradients the water height equation is solved with a c grid mass conserving advection scheme and a diffusion term to suppress numerical instability mixed a and d grid schemes are applied on the momentum equation plus a weighted average to remove short waves boundary conditions are incorporated on all cell faces so that any cell could be wet or dry depending on whether its water height is positive approximations across refinement interfaces are explained a filling or flooding experiment on a four level 3 6 12 25 km mediterranean sea grid is used for demonstration the test is done by emptying the whole mediterranean sea at start and then filling the basins with flood water from selected river mouths and strait channels until the whole mediterranean sea is filled up this experiment illustrates that the swes model on the multi resolution smc grid can simulate the filling process as expected and restore a flat sea surface at the end another test is carried out to simulate possible tsunami waves when the flat sea surface is disturbed by volcanic eruptions or earthquake movements results indicate that vertical shift of sea surface at one site in the ionian sea may generate tsunami waves and orientation of the initial disturbance has a profound influence on the subsequent tsunami waves which could spread out to the whole mediterranean sea in a few hours further improvements are required to simulate real tsunamis and coastal surges keywords shallow water equations smc grid surge modelling tsunami waves mediterranean sea 1 introduction shallow water equations swes have been used widely for tests of numerical algorithms and different model grids williamson et al 1992 because they are a simple set of 2 d fluid dynamical equations swes also have many real applications such as numerical modelling of ocean storm surges and tsunami propagations for instance the slosh surge forecasting model glahn et al 2009 and several established operational tsunami warning systems behrens and dias 2015 are based on the swes routine surge forecasting is part of coastal hazard warning system in most weather forecasting centres over the world and tsunami studies are greatly accelerated after the 2004 indian ocean tsunami synolakis and bernard 2006 reviewed the history of tsunami studies before the 2004 indian ocean tsunami and emphasised the importance of developing tsunami inundation modelling tools for inundation forecasting and model validations with observations from different instruments a common requirement for coastal surge and tsunami warning is that both far field propagation and detailed coastal inundation need to be simulated this is a challenge to conventional model grids because limited computing resources prohibit both a large domain and a high resolution mesh in a single model a straightforward solution is by using nested grids and an alternative approach is building a multi resolution grid model finite element methods on unstructured triangular cell grids have been successfully applied in surge and tsunami models such as the application of the adcirc surge model musinguzi et al 2019 an unstructured triangular cell grid provides fine resolution near coastlines and inland waterways along with gradually relaxed coarser resolution cells offshore however this paradigm usually requires a lot of computing resources and may not meet the timeless requirement of surge forecasting and tsunami warning adaptive mesh refinement berger and oliger 1984 and its later improved quadtree technique popinet and rickard 2007 have also been successfully applied in tackling the large domain and high resolution conflict leveque et al 2011 demonstrated how finite volume algorithms are combined with adaptive mesh refinement techniques in simulation of transoceanic tsunami propagation and detailed modelling of inundation in refined coastal regions using the depth averaged swes popinet 2011 implemented a well balanced positive preserving scheme of audusse et al 2004 for swes on a quadtree adaptive grid to simulate tsunami waves it provides mesh refinement dynamically and flexible wetting and drying near coastal areas the original adaptive mesh refinement by berger and oliger 1984 and later application for tsunami waves by leveque et al 2011 are built on a base or coarse structured grid with block structured dynamic refinements the base grid is a rectangular mesh and contains masked land points when irregular coastlines are involved this drawback may be mitigated by combining static refinement near coastlines with the normal adaptive refinement in open seas as done by popinet and rickard 2007 the spherical multiple cell smc grid li 2011 2019 is a combination of the latitude longitude lat lon grid and unstructured grid technique it is adapted from the cartesian multiple cell unstructured grid li 2003 and added the longitudinal cell merging like a reduced grid gates and riegel 1962 as it uses the lat lon grid quadrilateral cells numerical modes are minimised and simple finite difference schemes on lat lon grids are retained it also supports static mesh refinement so coastal refinement could be achieved for resolving small islands and modelling coastal inundations flux form finite volume formulations are used to handle the multi resolution cells the smc grid has been used for resolving coastline details and small islands in an ocean surface wave model li 2012 ww3dg 2019 applications of this grid include both routine ocean surface wave forecasting in the uk met office li and saulter 2014 and arctic wave climate studies casas prat et al 2018 li et al 2019 swes have been discretised on a global smc grid and validated with classical tests by li 2018 including the steady zonal flow over flat or hill floor and the rossby haurwitz wave suggested by williamson et al 1992 and the unstable zonal jet proposed by galewsky et al 2004 this article presents work to adapt the swes model for a regional smc grid with improved boundary conditions a brief introduction of the smc grid is provided in section 2 for readers convenience plus some finite difference details across refinement interfaces swes discretisation on the smc grid is summarised in section 3 along with description of updated boundary conditions an experiment of filling the whole mediterranean sea is presented in section 4 to test the boundary conditions and to demonstrate dry wet changing over the whole model domain in section 5 the propagation and dissipation of an initial disturbance on a flat sea surface are simulated for assessment of the model stabilities and possible tsunami scenarios in the mediterranean sea the summary and conclusions follow in section 6 2 the medi36125 smc grid examples of global smc grids including the arctic are given by li 2012 2016 2019 with descriptions of how ocean surface waves propagate on them here a regional smc grid for the mediterranean sea will be used to summarise the smc grid techniques for the convenience of readers who are unfamiliar with ocean surface wave models smc grid is an unstructured mesh tessellated with rectangular cells the grid consists of a list of cells at multiple sizes of given unit increments of latitude δ φ and longitude δ λ as illustrated in fig 1 the solid red lines mark actual cells in the grid cell list and the red dots indicate their cell centres a unique 5 element integer array is assigned to each cell to hold its south west corner x y indices i j cell side x y increment δ i δ j and the cell floor bathymetric height b the x and y indices are measured in unit or size 1 cell increments δ φ and δ λ so cell centre latitude and longitude are given by φ j φ 0 j 0 5 δ j δ φ and λ i λ 0 i 0 5 δ i δ λ where λ 0 and φ 0 are the longitude and latitude of the x y coordinate origin for a global grid the origin of the grid can be set at zero meridian on the equator so both λ 0 and φ 0 are zero one restriction for building this grid is that resolution refinement is done by gradually halving the cells which is equivalent to the factor 2 refinement as classified by debreu and blayo 2008 as a result neighbouring cells can be either of the same size or doubled halved in size hence the name of multiple cell grid cells are merged longitudinally at high latitudes following the same rules in li 2011 to solve the polar problems there is no restriction on the domain shape as long as required domain area is covered by tightly paved cells neighbouring cells are not required to be side by side in memory as unstructured techniques are used in fact all selected cells are sorted by their sizes in a final cell list so that sub timesteps could be used for refined cells this makes the smc grid much more efficient than those triangle cell unstructured grids whose time step is restricted by the smallest cell for ocean surface wave models only cells over sea points are selected and land surface is removed completely out of the model calculation because cells are stored in an unstructured 1 d list their spatial relations are precalculated and stored in face arrays for each cell face a 7 element face array is used to mark the upstream centre and downstream cells in addition to its size and location indices the face arrays are grouped by two dimensions and sorted by their face sizes for use of sub timesteps propagation on the smc grid is calculated in two steps 1 individual flux across each cell face is calculated in a face loop based on pre calculated face array information 2 fluxes into each cell are accumulated in a temporary array and the net flux is used to update the cell value in a cell loop both the face and cell loops are divided into sub loops by their sizes and sub timesteps are used for refined face and cell sub loops li 2012 this sub loop technique makes the multi resolution smc grid more efficient than nested grids because of the removal of overlapping regions and boundary conditions in nested systems in addition the flexible refinement of the unstructured smc grid does not need to keep a whole rectangular sub domain at high resolution as in conventional nested grids for refinement interface such as a cell face between a coarse and two refined cells smc grid assumes a first order approximation that the coarse cell is uniform within its cell area and it could be divided into two halved cells of the same properties as the coarse cell such as velocity and water height this approximation avoids interpolations between different sized cells whose centres are unaligned due to the factor 2 refinement the dashed green lines in fig 1 indicate how the coarse cells marked by the solid red lines are divided into halved cells the green dots indicate the centres of those halved virtual cells which are aligned with the refined cells finite difference across such a refinement interface is then approximated by averaged differences between the halved cells and the refined cells in the propagation scheme the face flux is calculated on refined faces at a refinement interface in face loops these refined fluxes are automatically averaged for coarse cells in their net fluxes spatial gradients between different sized cells are also averaged in this way for coarse cells so for a coarse cell bounded by a coarse cell on the left and two refined cells on the right its cell gradient will be the average of one face gradient between the coarse cells and two refined face gradients between the halved virtual cells and the two refined cells this is equivalent to a space centred gradient scheme except that across the refinement interface the averaged difference is used this average may partially remove the short waves or noises caused by the refinement this approximation on refinement interface is used for all spatial schemes including advection diffusion average and gradient schemes on the smc grid fig 2 shows a regional smc grid for the mediterranean sea it has a base resolution of 25 km and 3 refined levels at approximately 12 6 and 3 km it will be referred to as medi36125 grid it cuts off other seas at the strait of gibraltar the suez canal and the istanbul channel its latitude and longitude increments at the finest resolution or for a size 1 cell are δ φ 0 029296875 and δ λ 0 0439453125 respectively which are roughly 3 km in the mediterranean sea the longitudinal increment is chosen so that merged cells at high latitudes are exact multiples of size 8 cells this is for consistency and easy comparison with a similar global grid li 2016 due to the finest resolution being about 3 km narrow passes especially those around the greek islands are expanded to link up all sea surfaces this is necessary for the following test because isolated sea basins could not be filled up the cell floor bathymetric depth at each cell is indicated by its edge colour and the deepest cell is 4632 m from the sea level the bathymetric depth is an integer in unit of a metre to keep the cell array to be an integer array if higher bathymetric resolution is required another unit like centimetre may be used apart from the mediterranean sea surface area the medi36125 grid also covers coastal area up to 10 m above sea level to allow surge inundations the one metre vertical resolution for the cell floor bathymetry is proportional to the horizontal resolution at 3 km which is enough for ocean surface wave models but is deemed too coarse for coastal flooding or storm surge it will be demonstrated later that small surges could only affect those cells with bottom floor aligned at the sea level while other coastal cells above sea level by 1 m or more will remain dry the filled red cells in fig 2 mark those cells with bathymetric floor at the sea level there are 195 cells whose bathymetric floor are at the sea level including 3 size 4 cells at the north end of the adriatic sea near venice and 3 in the nile delta near cairo these two areas will be used to show coastal surges there are 27 129 cells in total including 16232 6459 2601 and 1837 cells in size 1 2 4 and 8 respectively note that the finest size 1 cells are more than the sum of all other sized ones nevertheless the multi resolution grid is still much smaller than a uniform grid at size 1 resolution which would have as many as 201 252 size 1 cells or could be more than 7 times as large as the present medi36125 grid this reduction on total cell numbers by multi resolution cells will be significant when high resolution is required for some specific regions 3 discretisation of shallow water equations 3 1 equation set and numerical schemes the nonlinear swes used in this model follow ringler et al 2010 in a vector invariant form 1 h t h v κ h b i r cos φ λ j r φ 2 v t η k v g h b k 0 where h is the fluid thickness or the water column height t the time v u i υ j the fluid horizontal velocity on the earth s surface κ a diffusion coefficient b the bottom topography the horizontal gradient operator i and j the horizontal unit vectors of the local cartesian coordinates k the vertical unit vector r the radius of the earth φ the latitude λ the longitude g the gravity constant k v 2 2 the kinetic energy η f ξ the absolute vorticity f 2 ω sin φ the coriolis parameter ω the angular spinning speed of the earth and ξ is the relative vorticity defined as a diagnostic variable by 3 ξ k v the curvature terms are ignored because they are only significant near the poles where a new method will be used in this model to avoid the increased curvature the diffusion term in 1 is added for smoothing purpose and is applied to the total height h b so that a steady state at rest could be preserved for irregular ocean floors the momentum equation should be modified for the polar regions due to the invalid scalar assumption at high latitudes li 2018 a fixed map east direction is then introduced in the polar region to define the vector components li 2016 the map east system in the polar region can be approximated with a rotated grid with its rotated poles on the equator the conversion between the two direction systems is a simple rotation by an angle α from the map east direction to the local east direction the rotation coefficients are given by 4 cos α cos λ sin φ 1 cos λ cos φ 2 sin α sin λ 1 cos λ cos φ 2 the continuity eq 1 can be discretised straightforwardly on the smc grid as a scalar advection equation as in li 2011 if the water thickness is located at the cell centre and normal velocities on cell faces c grid the uno2 scheme li 2008 can be used to determine thickness fluxes so 1 is estimated by 5 h n 1 h n δ t a s f s l s where the superscript n represents the n th time level δ t denotes the time step a is the cell area f s the combined advection mid flux and the diffusion flux through the cell side s and l s the length of the cell side the summation is over all sides of the given cell and will automatically average fluxes through refined cell faces if the cell is bounded with refined cells as this is a 2 d model cell side and cell face will share the same meaning the momentum equations are discretised on a mixed a and d grid that is the velocity at each cell centre is solved by the prognostic equation 2 while relative vorticity 3 is integrated along cell sides with interpolated tangential velocity for stability purpose both the absolute vorticity term and the potential energy gradients are approximated by semi implicit schemes the momentum equation 2 can then be transformed into local cartesian component form as 6a u n 1 u n β n 2 υ n β n u n g y n 1 g x n 1 1 β n 2 6b υ n 1 υ n β n u n 1 u n g y n 1 where β n η n δ t 2 and the x direction gradient g x n 1 δ t i g h n 1 g b k n in low latitudes the component direction will be the same local east as in a lat lon grid in the polar regions the momentum equation 6 retains the same form except for that the gradient components are projected to the map east system instead of the local east system as it is crucial to get the coriolis parameter right in the absolute vorticity estimation walters et al 2009 the coriolis terms are calculated with the exact cell centre velocity components while the relative vorticity 3 is converted into cell side loop integration the stokes theorem with interpolated velocities on cell sides the relative vorticity loop integration is then approximated as a polygonal cell side summation 7 ξ k v 1 a s v s l s t where a is the area of the cell the subscript s indicates cell side l s t is the side length tangential vector that follows an anti clockwise circle around the given cell for a cell bounded with refined cells the sum will be over its refined interfaces as smc grid mass transportation 5 requires the normal velocity components on cell sides while the relative vorticity 7 needs the tangential velocity components on cell sides the cell centre velocity components solved with 6 are then interpolated on cell sides using their water thickness as weights 8 v s h v h v h h ε where h is the thickness for the downstream and upstream cells of the given cell side and ε is a negligibly positive value to avoid zero dividing when both cells have zero water height for refinement interfaces the face velocities are calculated between halved virtual cells and refined cells and they are centred on the refined interfaces the weighted interpolation 8 approximates the depth integrated method of kleptsova et al 2009 for stability with variable bathymetry as the velocity components are in the fixed direction system in the polar regions the component interpolation can be done as a true scalar interpolation at high latitudes without worrying about the increased curvatures the interpolated face velocities however must be rotated into the local east system in the polar regions using the rotation coefficients 4 the kinetic energy can be estimated directly with the cell centre velocity and then added to the potential energy for a combined gradient term calculation of the gradient terms in 6 requires a different formulation in the polar regions as the cell centre velocity components directions are in the map east system rather than the cell face normal directions in local east system the gradient term is first calculated in the local east system on each cell face and then rotated to the map east system in the polar regions before they are averaged for the cell centre gradients that is 9 g x n 1 δ t i e δ t l s s i l s n e e d e g h n 1 g b k n where l sn is the side length normal vector pointing from cell towards cell l s the total side length of the summed sides for the given cell e the energy of the two cells sharing the given face and d the distance between the two cell centres for a cell bounded with refined cells the cell centre gradient is automatically an average of the gradients between halved virtual cells and refined cells the gradient component direction vector i is the local east unit vector at low latitudes but changes to the map east direction in the polar regions for stability reasons it is important to use the n 1 time step potential energy gh n 1 for the energy gradient 9 this is done by simply integrating the thickness eq 5 first before calculating the gradient term 9 there is a known instability problem associated with the cell face velocity interpolation 8 from a grid velocity mcdonald and bates 1989 lin and rood 1997 weller et al 2009 despite using weighted interpolations the half cell approximation at refinement interfaces may also cause some oscillations in a strong jet case li 2018 besides false gravity waves could be generated due to mismatched representations of physical fields in numerical models mohebalhojeh and dritschel 2000 so an extra smoothing is needed to control these small numerical oscillations or spurious short waves a 1 2 1 weighted local average in each dimension is applied for the velocity components at selected intervals the average is equivalent to a diffusion term with a fourier number of 1 4 for one time step li 2008 the average intervals are selected to be just short enough for suppressing numerical instability and can be set to be different for polar and low latitude regions the water thickness field is smoothed by the built in flux form diffusion term in 1 for mass conservation purposes as the 1 2 1 average does not guarantee mass conservation to match the extra polar smoothing of the velocity components the diffusivity coefficient is specified as a polar biased function of the latitude 10 κ κ m 1 γ γ sin 2 ϕ κ m δ x m i n 2 2 δ t 0 γ 1 where γ is a tuneable parameter to control the polar bias and κ m is the maximum diffusivity which is limited by the stability requirement depending on the minimum grid length δ x m i n and time step δ t the 1 2 1 average for the momentum and the extra diffusion term in the mass conservation equation are necessary to keep the multi resolution model stable these extra smoothing are equivalent to the restricted step as mentioned by debreu and blayo 2008 3 2 boundary conditions boundary conditions may vary for different models for ocean surface wave models the zero boundary condition is required at coastlines for a global model a periodic condition is usually applied in the longitude direction the smc grid is originally developed for global wave models and the coastal zero boundary condition and the global periodic conditions are built into the face arrays this approach effectively changes any boundary face into an equivalent inner face so that a single loop covers all faces the periodic boundary condition is applied by linking the end cell with the start cell at one parallel circle in the face array the zero boundary condition at coastlines is achieved by bounding each coastal cell face with an empty cell in its face array if external boundary conditions are required at cut off lines such as the strait of gibraltar in this model they can be applied directly on selected boundary cells with an extra boundary condition loop just like in a conventional structured grid for this mediterranean sea model the cut off lines at the strait of gibraltar the suez canal and the istanbul channel are all assumed to be closed and treated the same way as other coastlines for the swes model vertical wall boundary conditions are applied at coastlines any coastal cell face is supposed to be bounded by the same inner cell on both sides in its face array so that water or energy flux out of the inner cell if any when the inner cell is wet will be automatically sent back into the inner cell this is equivalent to set the normal velocity to be zero at coastal boundary faces no water can leak through these real boundary faces for this reason any possible flooding zone must be included in the smc grid for the medi36125 grid the sea surface grid is extended to coastal area up to 10 m above sea level in order to simulate flooding any cell in this swes model is enabled to flip between wet and dry status as coastlines may move with flooding waters the cliff wall boundary conditions are extendedfor inner faces if required for this purpose a cell is deemed wet when its cell centre water height h is positive or h ε otherwise it is treated as a dry cell velocity is set to be zero at a dry cell centre without solving 6 any inner face bounded by two dry cells will be referred to as a dry face is simply skipped in face loops as illustrated in fig 3 this is equivalent to treating the area covered by the two dry cells as land area if a cell face is bounded by a wet cell and a dry cell and the dry cell floor is higher than the wet cell water level it will be treated as a vertical wall boundary face and referred to as a higher dry face in fig 3 if the dry cell floor is lower than the wet cell water level the face is considered a normal inner face just like any wet face bounded by two wet cells this ensures water from the wet cell can flow into the lower dry cell under gravity the wet to wet and wet to lower dry faces are marked as inner faces in fig 3 cliff wall boundary conditions are extended to those higher dry faces the cell side velocity interpolation 8 is modified for the higher dry faces by setting the normal velocity component to be zero and the tangential component to be equal to the value at the wet cell centre this is equivalent to the cliff wall boundary condition applied to all coastal faces the energy gradient term 9 is set to be zero at higher dry faces so the net momentum flux is zero across these boundary faces the weighted average for the momentum equation is limited among wet cells to avoid energy dissipation into dry cells this tangential velocity assignment and zero energy gradient on the higher dry boundary faces ensures the hollingsworth instability hollingsworth et al 1983 is avoided water mass advection fluxes through the higher dry faces are also zero because the normal velocity component is zero although the diffusion flux in 1 is proportional to the gradient of total water height h b it is only calculated between wet cells that is the diffusion flux through a higher dry face is also zero these zero advection and diffusion fluxes through higher dry faces ensure water mass is confined within low area otherwise water mass might be numerically pumped into higher dry cells violating the common sense that a lake at rest has a mirror flat surface 4 filling the mediterranean basins flooding a low area is a common phenomenon in real life and the process and final state are well known to us this filling experiment is designed to test whether the swes model could simulate the process of water flowing into low areas and reach a final flat surface state when water sources are exhausted all the mediterranean sea basins are emptied at the start except for a few source cells near river mouths and in strait channels water heights in those source cells are maintained at the sea level throughout the experiment to provide unlimited water sources water from these source cells will flow into low areas under the gravity force forming rapid streams or even water falls at the early stage the water flow will eventually slow down when the water level approaches the sea level and automatically switch off when all the mediterranean sea basins are filled up to the sea level it is expected that the initial water velocity may become quite large particularly in areas where the basin floors are steep in fact floor level differences between neighbouring cells in the medi36125 grid may exceed hundreds of metres and initial filling flows across these cells will be vertical falls higher than any water falls in the world to prevent the model from crashing out at the early stage due to possible very large flow speed a speed limit of 20 m s 1 is applied on each velocity component and this allows a reasonable time step to be used for the whole filling experiment a 30 s time step is used in this experiment and the maximum diffusivity is set to 6 0e5 m2 s 1 because the mediterranean sea is at low latitudes there is no need to change the default parameters for the polar regions which include γ 0 1 and average interval of 4 min fig 4a shows the initial state of the model and the water heights at those source cells are shown by the colour filled cells most of the source cell water columns are below 100 m as they are close to river mouths but there are a few over hundreds of metres highest 742 m particularly in the strait of gibraltar fig 4b shows the water depth after 24 h filling the waters from the strait of gibraltar and river rhone south of france first pool in the basin to the east of spain the water from river nile goes directly into the main basin in east mediterranean the water from venice flows a long way through the adriatic sea and pools in the ionian sea basin rivers vardar and strimon in north greece feed directly into the aegean sea and water from the black sea through istanbul channel pools in the sea of marmara first and then spills over a narrow channel into the aegean sea note the flow from river nile is not presented as continuous in fig 4a this is due to the positive filter for water height having thrown out some negative water heights and reset them to be zero because of the rapid flow speed in this area the advection may have resulted in some minor oscillations fig 4c shows the water depth after 10 day filling by this time water pooled in the west basin has spilt over the underwater ridge between sardinia and tunisia into the tyrrhenian sea to the southwest of italy waters from other sources have met in the central basin of ionian sea fig 4d is the water depth after 20 days by then waters from all sources have linked up after the tyrrhenian sea and ionian sea are linked up fig 4e is the water depth after 40 days filling and by this time the whole mediterranean sea is already filled up this is indicated by the maximum depth of 4632 m the final plot of fig 4f is the water depth after 100 days which is almost identical to fig 4e of the 40 days plot this confirms that the model stayed stable after the mediterranean sea is filled up the filling process may also be illustrated by the flow speed plots in fig 5 fig 5a shows the flow speed after 10 days water speeds close to source points are almost at the maximum speed as indicated by the red coloured cells remember the model has a velocity component limit of 20 m s 1 so the maximum speed is 28 28 m s 1 as indicated in the plot to avoid output underflow in the scientific notation small velocity components of absolute values below 1 0e 90 m s 1 are all saved as 1 0e 90 hence the minimum speed of 1 414e 90 m s 1 should be treated as zero speed only the istanbul water flow has almost stopped because the sea of marmara is nearly blocked by the narrow channel linking the aegean sea water is still flowing through the channel but very slowly the broken flow off the river nile delta reveals the large speed gradient there in fact they are water falls due to the sharp fall of the basin floor beyond the nile delta fig 5b shows the water speed after 20 days apart from the high speed near water sources the spilling flow from the tyrrhenian sea to the ionian sea is also quite rapid this is because the water source from the strait of gibraltar is much stronger than other sources and the west basins are filled up more quickly than the central and east basins fig 5c shows the water speed after 40 days by this time the filling has already completed so the maximum speed dropped to about 0 14 m s 1 this is probably an oscillation speed caused by gravity waves as small maximum speed around this order is maintained until the end of the model run of 200 days water flows have stopped by 40 days but gravity waves may linger a bit longer to estimate the filling rate the water volume in the mediterranean basins during the filling test is integrated at regular intervals and is shown in fig 6 water volume in each cell is measured by its floor area in steradian at the earth s radius multiplied by its water column height in metre so the total water volume is given in the unit of m sr taking the earth s radius as 6371 km 1 m sr is about 40590 km3 the initial water volume is not zero because of the source cells are filled up to the sea level during the whole test the initial volume is about 3 2e 3 m sr the filling rate is largest at the start and is almost a constant during the first few days this is because the water flow speed is limited by the maximum velocity component of 20 m s 1 after the initial rush the filling rate slows down due to the decrease of water level differences between the source cells and its neighbouring cells over just a month all the basins are almost filled up and the filling rate eventually becomes zero when the whole mediterranean sea is filled up to the sea level the total water volume remains constant afterwards to the end of the 200 days model run but only the first 50 days are shown here the total volume of the mediterranean basins up to the sea level is about 94 0 m sr as represented by the medi36125 grid although we could not do this experiment in the real world the filling processes presented here agree well with our expectation the experiment has demonstrated that the dry wet change over the whole sea area goes well and it is reasonable to expect that it will perform well in coastal regions 5 tsunami waves by initial disturbance propagation of gravity waves caused by an initial disturbance is also simulated in this regional smc grid swes model the time step and diffusion coefficient are set the same as used in the previous filling experiment the whole mediterranean sea is assumed to be at rest with a flat water surface at the sea level except for 4 size 8 cells to the east of the sicily island in the ionian sea a 5 m high water column is taken from 2 cells and added to its neighbouring 2 cells forming an initial disturbance of 5 m shift of the water surface as shown by the water height difference from the sea level in fig 7a the four disturbed size 8 cells cover an area about 60 50 km2 close to an area hit by a moderate earthquake the 5 m initial disturbance is of the same order as the 2004 indian ocean earthquake as estimated by pietrzak et al 2007 though the disturbed area is much smaller than the 2004 one the model is then let free to run until its flat surface is restored it is envisaged that gravity or tsunami waves may be generated by this initial water surface shift fig 7b shows the water height difference from the sea level after 1 h model time gravity waves of magnitude about 7 cm are visible within about 600 km from the initial disturbance site as shallow water gravity waves speed is approximately g h and the water depth in the ionian sea is about 3000 m the tsunami travels at about 170 m s 1 in the ionian sea and it covers roughly 600 km in one hour there are two wave crescent circles so the gravity wavelength is about 300 km which is a typical tsunami wavelength in open oceans where the water is over thousands of metres deep fig 7c is the water height difference after 4 h model time by then the tsunami waves have reached the coastlines of the whole mediterranean sea because the distance from the strait of gibraltar to the nile delta spans just over 2 time zones at the latitude of 35 n the mediterranean basin size from west to east could be estimated to be π r 6 cos 35 or about 2732 km which could be covered by the tsunami in about 4 5 h the maximum magnitudes of the tsunami waves have fallen below 1 cm after 4 h and it must be at centimetre order at coastlines these small tsunami surges are hardly visible by naked eyes and only manifest themselves in those cells with bottom floor at exactly the sea level to show this small surge effect an inset of the north end of the adriatic sea near venice is inserted in each plot in fig 7 the inset in fig 7a or the t 0 plot is cropped from the medi36125 grid plot fig 2 to show the filled red cells at the sea level the inset in fig 7b or t 1 h is an enlarged crop from the same plot as the tsunami waves have not reached this part yet at t 1 h the inset area is still at its initial state or flat at the sea level and the sea level cells marked red in fig 7a inset remain to be dry the first wave arrives at the venice coast in about 3 h and maintains the surge for another 3 h there while the first wave crescent comes and returns the inset in fig 7c or the t 4 h plot shows that the surge has inundated all the sea level cells in this area though the water height is not significant the small surge could not overcome the cliff walls at least 1 m high above sea level beyond the sea level cells and is reflected into the open sea another initial disturbance rotated by 90 from that in the previous experiment is used to illustrate the directional effect of the water shift fig 8a shows the rotated initial disturbance which is now with a 5 m dip on the west and a 5 m lump on the east side fig 8b shows the water height difference from the sea level after 1 h model time the maximum wave height difference is now about 16 cm more than doubled that of the previous test also note the tsunami waves travelling towards the west has a recession or trough in the front instead of a crescent surge in the first experiment the east travelling waves also reversed with a surge in the front though the wavelength looks close to that of the first experiment tsunami waves in the ionian sea travel faster than in the adriatic sea because of the ionian sea is much deeper than the adriatic sea the first wave arrives at the nile delta in about 1 5 h and maintains the surge there over an hour fig 8c shows the water height difference after 2 h when the first wave surge covers the nile delta area near cairo the maximum surge is about 4 cm which is higher than that of the first experiment but is still very small nevertheless the surge has turned the initial dry sea level cells in the nile delta area into wet cells when the surge passes this area the insets in fig 8 show the corresponding grid crop and enlarged crops from the same water height difference plots at t 1 and 2 h the filled red cells indicated by the inset in fig 8a remain dry in the t 1 h inset of fig 8b because the surge has not arrived yet by then the sea level cells become wet when the surge arrives as shown in the t 2 h inset of fig 8c though their water heights are quite small the differences between the two tests indicate that initial disturbance orientations have visible influences on the subsequent tsunami waves possible reasons for the small coastal surges in the initial disturbance tests may be due to the additional diffusion term and the second order advection scheme used in the water height equation popinet 2011 showed that the minmod scheme tends to be too dissipative for realistic tsunami modelling though it is very stable and gives reasonable results for dissipative systems the uno2 scheme li 2008 used in this model is a modification of the minmod scheme heinrich et al 2001 simulated the 1998 papua new guinea tsunami with a swes model including a bottom friction term as a viscous flow they stated that high resolution bathymetry up to 5 m accuracy and horizontal mesh close to 100 m resolution in the coastal area may be necessary to simulate the tsunami inundation the 3 km horizontal resolution of the medi36125 grid may be too coarse for this purpose behrens and dias 2015 reviewed numerical simulation of tsunami waves and pointed out that accurate simulation of tsunami wave is quite demanding due to its large span of spatial and temporal scales in deep ocean tsunami wave propagation may be approximated by shallow water equations but its transition to a bore or solitary wave train in shelf areas and then into breaking wave in coastal regions demands other mathematical and numerical treatments this is however beyond the scope of this study 6 summary and conclusions shallow water equations swes are discretised on a spherical multiple cell smc grid for the mediterranean sea the smc grid is an unstructured grid and retains finite difference schemes on conventional latitude longitude grid it uses merged cells at high latitudes to relax the cfl restriction on eulerian transport schemes and redefines vector components by a fixed reference direction near the poles to avoid the vector polar problems flux form finite volume formulations are included for multi resolution interfaces the a grid discretisation is applied on prognostic variables of the swes and cell centre velocity is interpolated onto cell faces using a weighted interpolation the mass conservation equation is solved with a non oscillatory advection scheme and momentum equations are estimated with semi implicit schemes for stability a 1 2 1 weighted average is applied on momentum equations and polar biased diffusion in mass conservation equation to suppress numerical noises a brief description of the unstructured smc grid is presented and finite difference schemes across refinement interfaces are described applications of different boundary conditions on the smc grid are explained for this swes model vertical wall boundary conditions are applied on all boundary faces and any wet cell face bounded by a dry cell whose floor is higher than the water surface of the wet cell this extended boundary condition allows any cell on this smc grid to flip between wet and dry states if required momentum calculations over dry cells are simply skipped and smoothing is restricted among wet cells for conservation purposes an experiment of filling the mediterranean sea basins is used to test this model and results demonstrate that the filling processes agree well with expectations the whole mediterranean sea is filled up to the sea level in about one month by water from river mouths and strait channels total water volume amounts to about 94 m sr another experiment is conducted to simulate tsunami waves caused by initial water surface disturbances it was shown that tsunami waves could travel at about 170 m s 1 and reach mediterranean coastlines in roughly 4 h if an earthquake disturbance occurred in the ionian sea the experiment also revealed that orientation of the initial disturbance has profound influence on the subsequent tsunami waves the coastal surges caused by the initial disturbances are quite small and surge inundations are only revealed by a few coastal cells with floor elevations aligned at the sea level there are several possible reasons for the small coastal surges in the initial disturbance tests coarse grid resolution and heavy smoothing may be responsible for it limitation of the swes to describe coastal bores and breaking waves may be another reason declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the author is grateful to dr andrew saulter met office uk for his encouragement and useful discussions the author s gratitude also extends to the three anonymous reviewers and the editor oliver fringer for their suggestions and comments to improve this article particularly for reviewer 1 s request to include the numerical details on cell refinement interfaces and reviewer 2 s scrutiny of typos and language issues the work is funded by the uk national weather service 
23932,the regional ocean modeling system roms 4 dimensional variational 4d var data assimilation system was used to compute ocean state estimates of the mid atlantic bight mab a three level nested grid configuration was employed with horizontal resolution successively enhanced from 7 km down to 800 m at the innermost nest this captures the dynamics on space and time scales ranging from the gulf stream western boundary current down to the rapidly evolving and energetic sub mesoscale circulation this is a companion study to levin et al 2020 which examined the overall impacts of the entire observing system on shelf break exchange this follow on study specifically focuseson the impact of the in situ elements of the ocean observing system on the 4d var analyses the particular focus here is on the pioneer array a high density observing system in the mab designed to measure the multi scale nature of shelf break exchange processes building on levin et al 2020 it is found that the relative impact of observations from different components of the pioneer array depends on the scales of motion that are resolved by each nested grid this is in apparent agreement with the linear theory of geostrophic adjustment despite the o 1 rossby number the synergy between the observations from different observing platforms has also been quantified by comparing the observation impacts with the sensitivity of the 4d var analyses to changes in the observing array it is found that while some observations do not have a significant direct impact on the analyses they nevertheless provide essential information about the presence of circulation features corroborating that measured by other sensors thus the individual parts of the observing system can borrow strength from each other finally the contribution of each component of the observing system to the expected error in the 4d var analyses was also quantified where the critical role played by the pioneer array moorings in resolving the sub mesoscale circulation is again highlighted keywords roms 4d var pioneer array mid atlantic bight observation impact observation sensitivity 1 introduction this study is the companion of levin et al 2020 hereafter part i in which analyses of the circulation in the mid atlantic bight mab were computed by combining ocean observations with an ocean model using state of the art methods of data assimilation the model used is the regional ocean modeling system roms in conjunction with a 4 dimensional variational 4d var data assimilation system the model configuration comprises a hierarchy of three nested grids fig 1 in which the resolution increases by a factor of 3 at each step ranging from 7 km down to 0 8 km circulation features resolved span a broad spectrum of motions ranging from the gulf stream western boundary current through an energetic mesoscale eddy field all the way down to the o 1 rossby number flows that characterize the inhomogeneous rapidly evolving and ephemeral sub mesoscale circulation these circulation regimes all present considerable challenges for any data assimilation system the observing system comprises a combination of remote sensing platforms that provide surface measurements of temperature sea level and ocean currents as well as in situ platforms such as moorings ships surface drifters profiling floats and piloted autonomous glider vehicles an important and unique component of the mab observing system is the pioneer array one component of the u s national science foundation s nsf ocean observatories initiative ooi gawarkiewicz et al 2018 the pioneer array was designed to deliver sustained multi scale observations in the vicinity of the mab shelf break see fig 1c to investigate the processes that control the exchange of water masses between the continental shelf and the continental slope and associated biological and biogeochemical interactions it is the pioneer array focus on shelf break exchange processes that is of particular relevance to this study and the companion part i in part i we explored the impact that observations from each element of the mab and gulf of maine gom observing systems have on different aspects of the 4d var state estimates a main focus of part i was on the performance of the 4d var system across the combination of nested grids and the relative impact of the different observing platforms on cross shelf exchange in this companion study we expand on the analyses of part i and concentrate in particular on the impact of observations from the pioneer array on the 4d var analyses while there are a variety of approaches that can be used to quantitatively assess the impact and information content of ocean observing systems oke et al 2015a b fujii et al 2019 the methodology used here is based on the adjoint approach of langland and baker 2004 that is used routinely at many operational weather forecasting centers to monitor the efficacy of global atmospheric observing systems see http ios jcsda org a related and complementary diagnostic is observation sensitivity analysis which quantifies the sensitivity of ocean state estimates to changes in the observations and observing systems trémolet 2008 there are many powerful extensions of this approach which include computing estimates of the expected analysis errors moore et al 2012 in each case the problem can be recast in such a way that the direct contribution or influence of each observation to the property under investigation can be computed we present several applications of this approach here in relation to the pioneer array focusing in some instances on the process of sub mesoscale frontogenesis in this follow on study to part i we explore in detail the impact of observations assimilated into a high resolution configuration of roms that resolves the sub mesoscale circulation there are few instances of 4d var at such high resolutions in the ocean and this is an important exploration of the impact that different components of the observing system play in shaping the circulation estimates in this dynamical regime as noted a particular focus is the high density pioneer array another novel aspect of this study is quantification of the degree of synergy between different components of the observing system here we draw on the concept of borrowing strength from the field of statistics the degree to which each component of the observing system is able to borrow strength is quantified here based on combining information from observation impact and observation sensitivity calculations in addition the extent to which different components of the pioneer array contribute to the reduction in the expected error of the 4d var analyses is also quantified perhaps rather surprisingly it is also demonstrated that despite the high rossby number regime of the resolved sub mesoscale circulations the relative impact of velocity and mass field observations with increasing model resolution can be explained using the linear theory of geostrophic adjustment a brief overview of the roms and 4d var configurations is presented in section 2 however the reader is directed to levin et al 2019 hereafter l19 and part i for a more thorough explanation of the system a description of the observations from the pioneer array and pertinent aspects of observation processing is presented in section 3 as described in part i the observation impact methodology used here involves targeted indexes that highlight different aspects of the circulation that are of interest the observation impact methodology is reviewed in section 4 along with the suite of circulation indexes that were employed section 5 presents an overview of the impact on each index of the observations from the various platforms that make up the pioneer array in contrast in section 6 we focus on some particular events namely the interaction of a gulf stream ring with the continental shelf and the formation of a sub mesoscale salinity front the ideas of observation sensitivity are brought to bear in section 7 as a means of quantifying the synergy within the 4d var algorithm between observations from different components of the observing system the observation sensitivity methodology is repurposed in section 8 to explore the contribution of each element of the pioneer array to the reduction in the expected error of the 4d var state estimates the paper ends with a summary and conclusions in section 9 2 configuration of roms and 4d var as discussed in part i the roms configuration used in this study comprises three nested grids as illustrated in fig 1 following part i the grid with the largest geographic extent will be referred to as g1 and has a horizontal resolution 7 km and 40 terrain following levels stretched so that the thickness of the surface most layers is in the range 0 1 1 8 m and 0 1 3 4 m near the bottom over the continental shelf the middle refined grid hereafter g2 is centered on the pioneer array with a horizontal resolution of 2 4 km also with 40 terrain following levels in the vertical the innermost refined grid hereafter g3 is likewise centered on the pioneer array with 40 levels in the vertical and 0 8 km horizontal resolution g1 was constrained at the open boundaries using data from the mercator oc é an global analysis lellouche et al 2018 with temperature and salinity adjusted to remove seasonal bias compared to the local regional climatology of fleming 2016 in regular forward simulations all three grids can be run using one or two way nesting harmonic tidal forcing mukai et al 2002 was added to the boundary ssh and depth averaged velocity data of g1 sea surface wind stress and heat and freshwater fluxes were derived on all three grids from 3 hourly national centers for environmental prediction ncep north american mesoscale nam forecast marine boundary layer conditions and standard bulk formulae of fairall et al 2003 daily river in flows were imposed at 22 discharge sites based on u s geological survey and water survey of canada observations and a statistical model that adjusts for ungauged portions of the watershed lopez et al 2020 wilkin et al 2018 full details of the grid configurations can be found in part i the configuration of the roms 4d var system is also described in detail in part i so only a summary of the important features will be presented here following the same notation as part i the roms state vector will be denoted by x and comprises all of the ocean grid point values of the roms prognostic variables namely temperature t salinity s two components of horizontal velocity u v and free surface height ζ if x b denotes the background state vector and x a is the 4d var analysis then 1 x a x b k y o h x b where y o denotes the vector of observations h is the observation operator that maps from state space to observation space and includes the nonlinear model and k is the kalman gain matrix in the application considered here the dual form of 4d var was used e g courtier 1997 in which case k b h t hb h t r 1 where b and r are the background error and observation error covariance matrices respectively and h represents the tangent linearization of the observation operator h in 4d var h includes the tangent linearization of the nonlinear model and h t includes the adjoint model the inverse of the stabilized representer matrix hb h t r 1 is evaluated iteratively using a conjugate gradient descent algorithm as described by gürol et al 2014 this procedure is equivalent to a truncated gauss newton method which takes the form of a sequence of linear minimization problems each such sequence is solved via several inner loop iterations while each separate sequence constitutes an outer loop in the 4d var calculations considered here two outer loops and seven inner loops were used on all three grids and a summary of the data assimilated is presented in table 1 for g1 and g2 the period jan 2014 dec 2017 was considered while for g3 the shorter interval jan 2014 dec 2015 was used because of the substantial computational effort required for this grid the data assimilation strategy employed was as follows 1 observations were first assimilated into g1 for the full 2014 17 period using a 3 day assimilation window and treating the model initial conditions surface forcing all components and open boundary conditions as control variables the background state estimate for each 3 day window was taken to be the analysis at the end of the previous cycle 2 step 1 was then repeated for grid g2 using the 4d var analyses from each cycle of g1 as the background open boundary conditions for each 4d var cycle of g2 as in g1 the initial conditions surface forcing and open boundary conditions were all adjusted during each 4d var cycle 3 step 2 was then repeated for grid g3 using the 4d var analyses from each cycle of g2 as the background open boundary conditions for each 4d var cycle of g3 in this case the 4d var window was reduced to 1 day and only the initial conditions and open boundary conditions were adjusted during each 4d var cycle as discussed in part i and described in moore et al 2011a the background error covariance b matrix was modeled following the diffusion operator approach of weaver and courtier 2001 the decorrelation length scales assumed in b for errors in each control variable are listed in table 2 and these parameter choices are discussed in l19 the observation error covariance matrix r was assumed to be a diagonal matrix and table 1 summarizes the errors and uncertainties that were assigned to measurements from each observing platform as discussed in l19 these errors reflect a combination of measurement error and errors of representativeness i e uncertainties associated with the ability of the model grid to resolve all of the processes that are captured by the observations quality control was performed during each 4d var cycle following andersson and järvinen 1999 where the innovation d i associated with each observation is compared to the standard error based on the assumed standard deviations of the background σ b and observation σ o errors if d i 2 γ 2 σ b 2 σ o 2 then the observation is rejected and not included in the analysis the threshold parameter γ is dependent on the type of observation and is given in table 2 for the analyses on each grid considered here the performance of the 4d var system on all three grids is discussed in detail by l19 and in part i therefore no particulars will be given here suffice to say that the data assimilation system performs well on all three grids across the range of circulation length scales resolved and is able to fit the model solution to the observations reliably 3 the pioneer array an important component of the observing system in the mab is the u s national science foundation nsf ocean observatories initiative ooi pioneer array and the impact of the observations from this array on the 4d var ocean circulation estimates will be the focus of this study the pioneer array comprises seven permanent moorings fig 2 that straddle the continental shelf break where measurements of temperature and salinity from profiling ctd and velocity from adcp are made through almost the full depth of the water column ranging from 130 m to 450 m the ctd sample rate gives centimeter scale vertical resolution adcp velocity is reported in 4 m or 8 m bins at shallow and deep sites respectively the mooring observations are complemented by multiple gliders that repeatedly sample along the nominal tracks shown in fig 2 although the actual paths followed are subject to the vagaries of remotely piloting slowly moving buoyancy driven gliders in a turbulent ocean gliders return temperature and salinity observations from the surface to 1000 m where the bathymetry allows fig 2 shows when in 2014 2017 the various observing assets were returning data on average data from ctd profilers were available about 60 of the time not including the late 2017 deployments at moorings 2 and 4 and for adcp about 75 of the time note that there was a protracted period of low data return across the array in early 2015 powered autonomous underwater vehicle auv deployments are also a component of the pioneer array design but none took place during the 2014 2017 period considered here in addition to pioneer the other observations noted in table 1 were assimilated if they fell into the domains spanned by the respective nested grids as demonstrated in sequel observations from remote sensing and other in situ platforms lend support to the measurements collected by the pioneer array and vice versa 4 observation impacts methodology and indexes the procedure used to evaluate the impact of the observations on each 4d var analysis follows the method originally developed by langland and baker 2004 the implementation in roms is described in some detail by l19 and in part i so again only a summary of the essential points will be presented here the impact of the observations on the analysis x a is quantified in terms of the influence that they have on an index i x that isolates some aspect of the circulation that is of interest following langland and baker 2004 the change in i due to assimilating the observations y o is given by δ i i x a i x b which to 1st order can be expressed as δ i y o h x b t k t i x x b where i x x b is a vector and represents the derivative of i with respect to each element of x evaluated using the background x b as described in part i the transposed kalman gain matrix can be reconstructed using the archived conjugate gradient descent vectors from each 4d var assimilation cycle it should be clear that δ i is given by the dot product of the innovation vector d y o h x b and the vector g k t i x x b which quantifies the impact of the observations on δ i since each element of d is uniquely associated with an individual observation so then are the corresponding elements of g such that the product d i g i represents the contribution aka impact of the i th observation to δ i following part i the chosen indexes i x target variations in the position of the mab shelf break front and the strength of the associated stratification and cross shelf transport in the vicinity of the pioneer array specifically we consider five indexes 2 i u s 1 s 2 h 0 u n u n d z d s 3 i u t ρ o c p a 1 s 1 s 2 h 0 u n u n t t d z d s 4 i u s 1 0 3 ρ o a 1 s 1 s 2 h 0 u n u n s s d z d s 5 i f ξ 1 ξ 2 η ξ η r ξ d ξ 6 i e v 1 g d ζ ρ ρ z d z d a the indexes i u i u t and i u s target the volume heat and salt transport respectively across a section of the h 200 m isobath defined by the integral s 1 s s d s which is nominally identified as the location of the continental shelf break the location of the vertical section chosen is indicated in each panel of fig 1 and cuts through the middle of the pioneer array in 2 4 u n corresponds to the component of the velocity that is locally normal to the section s an over bar denotes the time average over each assimilation cycle the tilde represents the mean seasonal cycle and a is the area of the cross section each index was evaluated using a finite difference approximation consistent with the appropriate model grid the index i f in 5 targets the location where the 34 5 isohaline intercepts the bathymetry a traditional proxy for the foot of the mab shelf break front beardsley et al 1985 linder and gawarkiewicz 1998 in 5 ξ η represents the local cartesian coordinates position of the foot of the front averaged in time over the particular 4d var cycle and η r ξ is a reference line chosen to be the seasonally varying climatological position of the front it follows then that the area defined by i f is proportional to the departure of the front position from its seasonal mean the endpoints ξ 1 and ξ 2 of the integral coincide with the east west limits of pioneer array glider operations fig 1 following simpson and bowers 1981 the index i e in 6 is the potential energy per unit volume that would be gained were the upper part of the water column to become vertically mixed and is hence a measure of the strength of the vertical stratification in 6 ρ and ρ are respectively the in situ and vertically averaged density both averaged over the assimilation window d is a chosen depth ζ is the free surface displacement and the area integral is performed over the pioneer array glider domain cf fig 1c the depth d was chosen to be the average depth of the front foot across the pioneer array glider domain in 6 v represents the volume encompassed by the integrals with the result that i e represents the energy per unit volume j m 3 that is required to completely vertically mix the upper d meters of the water column within the pioneer array glider operations box cf the red rectangle in fig 6 5 pioneer array observation impacts the relative impact of the various platforms that comprise the entire regional observing system table 1 on the target indexes introduced in section 4 is presented in part i l19 have also considered in some detail the impact of each remote sensing platform on a subset of the same indexes on the 4d var analyses of g1 in this section we will focus attention on the impact of the observations from the different instruments and platforms that make up the pioneer array as noted in section 2 the period jan 2014 dec 2015 is common to the 4d var analyses computed on all three grids with this in mind fig 3 shows the root mean square rms impact on i u averaged over all 2014 2015 4d var analysis cycles of the individual pioneer array moorings and gliders the mooring numbering used in fig 3 is as indicated in fig 2 which also gives the 8 character designations used by ooi the gliders are referred to by their ooi 5 character identifiers the impact of the temperature salinity and velocity measurements from each mooring are reported separately as are the impacts of the temperature and salinity observations from each glider as discussed in part i the parameters used to compute the observation error covariance matrix r and background error covariance matrix b are not the same on the three grids some of the differences in r are reflected in the observation impacts the observation error standard deviations σ o assumed for in situ temperature observations are similar across all three grids and range from 0 6 c on g1 to 0 4 c on g2 and g3 however as noted in part i a posteriori analysis of the innovation statistics following the diagnostics described by desroziers et al 2005 suggests that σ o should be closer to 1 c the a priori values of σ o for in situ salinity observations were assumed to 0 2 on g1 while the a posteriori innovation statistics indicate that 0 4 is a more appropriate choice a value of σ o 0 4 was therefore used for the in situ salinity observation errors in both g2 and g3 for velocity measurements the σ o on g1 was assumed to be 0 6 ms 1 for hf radar surface current estimates and 0 3 ms 1 for moorings these values were adjusted downwards to 0 1 ms 1 for hf radar observations and 0 04 ms 1 for moorings for both g2 and g3 which are more in line with the a posteriori innovation statistics the high computational cost of 4d var precludes a more detailed and controlled suite of experiments where for example the parameters of the data assimilation system are varied independently across the three grids therefore we must draw on what we have although the variations in the level of errors across the different grids provide an indication of their control on the impacts with this in mind fig 3a shows that by and large it is temperature and salinity observations from the glider platforms that have the largest impact on i u of the g1 analyses on the other hand the velocity observations from the pioneer array moorings have a relatively low impact on g1 because the 7 km horizontal resolution of this grid cannot adequately resolve the mooring array on g2 fig 3b shows that temperature observations from the gliders still exert a significant influence on i u however the impact of salinity observations on g2 is much reduced compared to g1 mainly because as noted above σ o for salinity was increased on g2 compared to g1 the observation error statistics assumed for salinity on g2 and g3 are similar so the impact of these data is alike on both grids however fig 3b indicates that velocity observations from the pioneer array moorings now play a more dominant role in shaping the circulation estimates on g2 some of the difference between the impact of velocity observations on g1 and g2 can be attributed to the reduction in σ o noted above even though the σ o for the mooring data on g3 are similar to those on g2 the impact of the velocity observations is higher still on g3 fig 3c in this case the mooring velocity observations exert more control over the transport increments because the resolution of g3 is high enough to resolve some of the sub mesoscale circulation features that are captured by the moorings see section 6 for more details the relative impact of the various pioneer observing platforms on i u t i u s i f and i e is qualitatively similar to that for i u not shown time series of the 2015 increments δ i for all five indexes on g3 are shown in fig 4 in each case the contribution of the different observation types to the increment during each 4d var cycle is also indicated the dominant impact of velocity observations on all of the indexes is very apparent fig 4 also shows that satellite sst and in situ temperature measurements also have a significant influence the latter almost exclusively associated with pioneer gliders and moorings the impact of altimetry is negligible on g3 since there are very few satellite overpasses so is not shown however as shown in part i satellite ssh does exert significant control on each index in g1 and g2 fig 4 reveals that the increments in several of the indexes are larger during the second half of 2015 in particular there are some periods of prolonged coherent increments such as july august and october indicating that the data were likely prompting the 4d var system to make more substantial changes to the state estimates during these periods than was typical we will focus on the latter october 2015 period in the next section and explore in some detail the circulation environment during that time 6 october 2015 case study 6 1 transport increments the increments in volume transport δ i u and heat transport δ i u t in figs 4a and 4b indicate that during october 2015 the 4d var system made coherent and sustained changes in cross shelf transport for several weeks similarly there were significant movements in the mab front during this same period as indicated by δ i f in this section we will focus on this period and explore in detail the impact of the individual assets of the pioneer array while fig 4 shows the index increments only for g3 the increments are broadly consistent across all three grids this is illustrated in fig 5 which shows time series of the total volume transport i u s 1 s 2 h 0 u n d z d s during october 2015 the total transport i u is displayed instead of the transport i u given by 2 to remove any differences between the seasonal variations u n on the three grids fig 5 also shows time series of δ i u δ i u for october 2015 for each grid on all three grids the transport i u is positive indicating onshore flow which 4d var acts to reduce during most cycles the increments on g2 and g3 are generally consistent with each other although they are somewhat smaller in g2 the time resolution differs because g3 uses a 1 day analysis interval whereas in g1 and g2 it is 3 days on g1 δ i u is more variable and onshore during the period 8 13 october whereas g2 and g3 indicate offshore increments during this time in the case of g1 observations that are remote from the target section exert a significant influence on all of the indexes as demonstrated in l19 and part i particularly observations in the vicinity of the gulf stream front and georges bank these influences are absent from g2 and g3 due to their smaller geographical extent which is one of the primary reasons why δ i u is not entirely consistent between g1 and grids g2 and g3 the other indexes display a similar behavior across the three grids not shown 6 2 the sub mesoscale environment to illustrate the circulation environment that develops during the focus period figs 6 and 7 show the 4d var surface circulation estimates for g2 and g3 on 8 october when a warm core ring is impinging on the continental shelf in the western vicinity of the pioneer array the ring entered the region in early september from the east having coalesced into a coherent anticyclonic feature from a modest positive geopotential anomaly shed from the gulf stream in august the intrusion of warm saline gulf stream waters onto the shelf north and east of the ring are apparent in both g2 and g3 figs 6c and 7c show the relative vorticity of the vertically averaged velocity on the same day normalized by the coriolis parameter i e the local rossby number a region of uniform negative vorticity identifies the center of the gulf stream ring which is flanked by filamentous vorticity features small scale structures are ubiquitous on the shelf in both grids the vorticity color bar has been saturated to highlight the complex circulation structure however the local rossby number is generally significantly larger than one over much of the domain indicative of a non linear circulation environment in the case of g3 fig 7c reveals numerous sub mesoscale fronts jets and filaments in the vicinity of the pioneer array fig 7d shows that at the western end of the target section and near the offshore pioneer moorings a complex pattern of confluent and diffluent flows 0 3 0 4 m s 1 has developed which promotes frontogenesis in this region and acts to draw out the vorticity filaments that are so evident in fig 7c indeed closer inspection of fig 7b reveals that at the boundary of the mesoscale circulation features in this same region a filament of less saline shelf water is being drawn offshore right through the pioneer mooring array and across the target section adjacent to and west of the low salinity tongue more saline gulf stream waters are being drawn onto the shelf and a front forms as evidenced by the sharp surface salinity gradient the complexity of the circulation at this time is further apparent in fig 8 which shows vertical sections on 8 october of the temperature salinity and the normal component of velocity along the target section following the 200 m isobath even though the net transport is onshore at this time cf fig 5e fig 8c indicates that there are variations in the flow along the section and at depth the signature of the mesoscale eddy field is evident in the thermocline structure in fig 8a while fig 8b shows that the tongue of fresher water that is drawn off the continental shelf between 71 w and 70 5 w cf fig 7b is confined mainly to the upper 10 20 m and is associated with a complicated interleaving salinity structure and stacked flows of alternating direction and strength which contribute to the formation of the aforementioned salinity front 6 3 pioneer array observation impacts time series of the contributions of the pioneer array temperature salinity and velocity observations to the cross shelf volume transport increments δ i u are shown in fig 9 for all three grids we caution against making particular inferences regarding how the impact of individual platforms varies during the month because of changes in instrument operations fig 2 including glider recovery and deployments such that the 6 gliders noted in fig 9 represent collectively only 3 months of data what fig 9 does show clearly once again is how the impact of the in situ temperature and salinity measurements from the various glider platforms diminishes as the horizontal grid resolution increases conversely as noted earlier the impact of the in situ velocity observations from the moorings increases from g1 to g3 the results of fig 9 are generally consistent for the other indexes also and we will postpone a broader discussion of these findings until section 7 6 3 1 moorings focusing first on the moorings fig 10 shows the cross shelf component of current as a function of depth and time as measured at each of the seven pioneer array mooring locations during october 2015 while measurements are made only at discrete depths the velocity data in fig 10 have been interpolated in the vertical for clarity at all mooring locations strong semi diurnal tidal currents of up to 0 5 m s 1 are very apparent superimposed on the tidal flows are lower frequency current reversals with periods upwards of a week or so the strong offshore flow associated with the low salinity tongue and front formation around 8 october cf fig 7b is very evident at moorings 3 and 7 but is waning and by around 10 october the flow has reversed and proceeds to oscillate weakly with a period of 7 days the impact of velocity observations from each mooring location on the g3 cross shelf volume transport increments δ i u is shown in fig 11 as a function of depth and time with the same format as fig 10 negative impacts indicate that observations at a particular depth and time lead to a reduction in the onshore transport or equivalently an increase in offshore transport and vice versa for positive impacts a striking feature of fig 11 is that the impact of the mooring velocity measurements is mostly negative consistent with fig 9i regardless of whether the observed currents are directed offshore or onshore the largest impacts generally coincide with the peak of the diurnal signal a particularly striking feature is that for moorings 3 and 7 the impacts are very strongly negative during the formation of the low salinity tongue and salinity front before 10 october while after that the impact of the measurements from these moorings is much smaller despite the significant onshore currents cf fig 10 6 3 2 gliders before looking in detail at the impact of individual pioneer gliders on the chosen indexes consider fig 12 which shows the rms vertically integrated impact on δ i u of temperature and salinity observations combined in each model grid cell during the period 2014 2015 for all three grids although the increasing grid resolution going from g1 to g3 is very apparent the overall spatial distribution of high and low impacts is broadly consistent across the three grids however more detailed structures emerge on the higher resolution grids this is also true for the other indexes not shown in particular hydrographic observations in the vicinity of the target section generally have the largest impact fig 9a d and g show that during the october 2015 focus period glider gl380 generally has a significant impact on δ i u during the period of frontogenesis in early october the track of gl380 during this time is shown in fig 7c and during the latter part of the deployment it follows the target section fig 13 shows vertical sections of the combined impact on δ i u of temperature and salinity observations collected by gl380 for the period 1 15 october for all three grids for clarity the impacts are plotted as a function of latitude longitude and depth from two different 3 dimensional perspectives and separately as a function of depth and time the impacts of gl380 on δ i u are generally consistent on g2 and g3 for instance in each case the impacts are mostly negative with largest impacts typically associated with near surface measurements positive impacts are mostly found at depth particularly seaward of the shelf break in the case of g1 the gl380 impacts are dominated by salinity observations cf fig 9b and elevated positive impacts are evident after 8 october while the glider is traversing the target section in all three cases the outbound leg into deep water during 1 4 october is associated with negative impacts while the return leg to shallower water 4 7 october is characterized by more positive impacts figs 12 and 13 reveal that the impact of individual glider measurements are described by a rich and detailed structure through space and time disentangling the full nature of this structure is an ongoing challenge not only because of the complex flow dynamics in the region but also because the circulation is continuously changing throughout each glider deployment 6 4 linear adjustment theory even though the rossby number is o 1 cf figs 6c and 7c the increasing impact of the pioneer array mooring velocity observations on the circulation estimates in the vicinity of the target section as grid resolution increases and the corresponding decline in the impact of hydrographic data is consistent with linear theory of adjustment following temperton 1973 the stream function ψ s resulting from the 2 dimensional geostrophic adjustment of an unbalanced circulation estimate derived from data assimilation can be expressed as 7 ψ s α ψ i 1 α f 1 ϕ i where ψ i and ϕ i are the initial estimates of the stream function and geopotential height respectively and f is the coriolis parameter eq 7 shows that the resulting flow field u ψ s y and v ψ s x is a linear combination of the initial estimates of the velocity field described by ψ i and the mass field represented by ϕ i the weighting factor α is given by 8 α a e 2 k 2 l 2 a e 2 k 2 l 2 1 where k and l are the zonal and meridional wave numbers respectively and a e is the rossby radius of deformation thus eq 8 shows that the relative weighting of the initial velocity field and mass field to the final balanced circulation depends on the scale of motion k 2 l 2 1 2 compared to the radius of deformation specifically when the length scale of motion is large compared to a e then a e 2 k 2 l 2 0 and α 0 and the final balanced circulation is determined by the initial mass field estimate ϕ i conversely when the length scale of motion is small compared to a e then a e 2 k 2 l 2 and α 1 and the final balanced circulation is determined by the initial velocity field estimate ψ i more generally this is simply an expression of the partitioning of potential and kinetic energy for the scale of motion considered large scale motions are typically dominated by potential energy so observations of the mass field i e t s and or ρ are most beneficial in contrast short scale motions are usually dominated by kinetic energy in which case observations of the velocity field are best however an important property of 8 as pointed out by temperton 1973 is that for inhomogeneous flow fields it is the shortest length scale that determines the weighting factor α this is illustrated in fig 14a which shows α as a function of λ x 2 π k and λ y 2 π l for a e 20 km fig 14a indicates that if a circulation feature is elongated in one direction the relative impact of velocity observations and mass field observations is determined by the shortest length scale when α 0 5 this can be thought of as the situation when energy is equipartitioned between potential and kinetic forms and this situation is shown in fig 14a also as a e 0 the α 0 5 contour collapses toward the λ x and λ y axes exacerbating the dominating influence of the shortest length scale of a flow feature even more these ideas are of particular relevance here because as fig 7c shows the circulation in the vicinity of the shelf break is dominated by sub mesoscale features with large horizontal aspect ratios thus it is the cross frontal and cross filament length scales that will dictate what type of observations will be most beneficial for recovering the circulation if linear adjustment theory holds fig 14b shows how the 1st baroclinic mode radius of deformation a e varies across the g3 domain in the deep ocean a e 20 km but it decreases rapidly across the continental slope with a e 5 km or less on the shelf most of the sub mesoscale features in fig 7c have cross front and cross filament length scales less than the radius of deformation on the shelf therefore based on 7 and 8 we expect observations of velocity to be more beneficial for recovering the circulation than hydrographic measurements this is consistent with the findings above even though the radius of deformation is in the same range on all three grids increasing the horizontal resolution going from g1 to g3 leads to the emergence of the sub mesoscale features that are captured by the pioneer array mooring observations these arguments would also account for the relatively low direct impact that hf radar observations have on the g1 circulation estimates as described by l19 in this case the horizontal resolution is 7 km which is larger than the radius of deformation on the shelf so the scales of motion that will be effectively resolved on g1 will have scales of motion larger than a e for which velocity observations will be least effective 7 observation synergy a summary of the rms impact of each observation type on all five indexes and across all three grids is shown in fig 15 during the october 2015 case study considered in detail in section 6 the overall decrease in the impact of satellite altimetry and in situ pioneer hydrographic observations from gliders and moorings going from g1 to g3 is apparent in all indexes as is the general increase in the impact of velocity observations from the pioneer moorings the trend in sst is less clear where the impact of these data is generally highest on g2 and lowest on g3 from the summary in fig 15 an overall picture begins to emerge about the potential value of the observing system as a whole and the relative contribution of its components such information is of course beneficial since it can provide guidance on how ocean observing systems could be most effectively expanded to target specific processes and how individual assets should perhaps be managed and prioritized while it is tempting to view the impacts in fig 15 as an indication of how each index would change on average if each data type was excluded from the 4d var analysis such an interpretation is misleading this is because the analysis x a depends not only on the measurement value and location of each observation but also on the interaction between the observations during the data assimilation process the interaction and synergy between different observations and observation platforms can be complicated and difficult to unravel e g daley 1991 but can be quantified using a variant of the observation impact methodology described in section 4 following moore et al 2011b suppose that we re express the analysis equation 1 as 9 x a x b k d where k d represents the entire data assimilation algorithm expressed as a function of the innovation vector d y o h x b as shown by moore et al 2011b and l19 a change δ y in the observation vector y o leads to a change δ i in the index i which to 1st order can be expressed as 10 δ i δ y t k y o t i x x b where k y o t represents the adjoint of the tangent linearization of the entire data assimilation system and i x x b represents the derivative of i with respect to x evaluated using the background x b as in section 4 it is tempting to invoke 1 here and conclude that k y o is simply the kalman gain matrix however it is important to remember that in any practical implementation of 4d var or any linear data assimilation algorithm applied to a large dimensional system like that considered here we can never iterate the system to complete convergence thus the effective gain matrix that is used to compute the analysis in 1 will not be the true kalman gain matrix therefore except in the rare case where 4d var is iterated to complete convergence then in general k y o k the roms 4d var system includes the capability to compute k y o t and from eq 10 it follows that the change in i associated with any change in the observations δ y can be computed from a single application of the adjoint of 4d var furthermore moore et al 2011b show that if the elements of δ y are chosen to be 1 times the innovation associated with specific observations then 10 can be used to compute the change in the index that occurs when these observations are excluded from the 4d var analysis this is a very powerful and efficient tool for performing observing system experiments oses without the need to repeat the costly 4d var calculations for each new configuration of the observing system since 10 indicates how a given index is influenced by changes in the observations or observing system it is referred to as observation sensitivity to illustrate this approach fig 16 shows time series of the change in cross shelf volume transport δ i u during the october 2015 case study period when individual components of the glider and mooring arrays are removed from the 4d var analysis independently during each data assimilation window a comparison of fig 16 presenting the observation sensitivity with fig 9 showing observation impact reveals that the actual δ i u that results from excluding a particular observing platform from the analysis is very different from what we would infer from the impacts for example fig 9a shows that during most 4d var cycles on g1 the direct impact of glider temperature observations is quite small conversely fig 16a indicates that when any individual glider is excluded from the 4d var analyses of g1 the changes in cross shelf transport can be quite significant a dramatic example is the 3 day assimilation cycle spanning the period 25 27 october on g2 fig 9d f show that the transport increment impact during this period is small and positive and that the impacts of each pioneer observing platform are generally benign conversely fig 16 d f reveal that several of the observing platforms will lead to large increments in transport if omitted from the analysis and that some assets have largely opposing influences on δ i u l19 explored these ideas in some detail with remote sensing observations on g1 they concluded that the seemingly contradictory nature of the results of observation impact and observation sensitivity can be understood in terms of borrowing strength a concept introduced by the princeton mathematician john tukey in the 1960s and 70s brillinger 2002 in other words while a particular observation y i say may not have an especially significant direct impact on δ i the observation y i nonetheless provides information that corroborates that from other measurements and in this way indirectly aids the assimilation process therefore if y i is excluded from the 4d var analysis the corroborating information that it provides will be lost leading to a much larger change in i than might otherwise be expected based on an observation impact calculation alone thus in this way other observations borrow strength from y i l19 argue that the degree to which different components of the observing system borrow strength from each other can be quantified using the ratio of the observation sensitivity to the observation impact drawing on this idea fig 17 shows the ratio b of the rms observation sensitivity to the rms observation impact for all indexes across all three grids and for all measurement types averaged over all 4d var cycles during october 2015 this ratio is a measure of the average change that actually occurs in each index when an observation is excluded from all 4d var analyses and that which might be expected to occur based on the observation impact alone a value of b 1 therefore indicates that on average the sensitivity and impact calculations predict similar changes in a given index if observations of this type are excluded from each 4d var cycle conversely values of b 1 b 1 indicate that the actual change in i will be larger smaller than expected based on the observation impact calculations therefore departures of b from a value of one can be viewed as an indicator of the level of borrowing strength note that the ratios shown in fig 17 for in situ temperature salinity and velocity data are for observations collected from the pioneer array only several striking features appear in fig 17 first in all but a few cases b 1 on all three grids indicating that all components of the observing system are borrowing strength from one another only in the case of satellite sst and altimetry do we see instances of b 1 for some of the indexes on g2 and g3 second in the case of velocity observations b is large on g1 10 indicating that while fig 15 shows a relatively modest direct impact of these data on all indexes the actual change that will occur in each i will be much larger than the impact implies if velocity observations are excluded from the 4d var analysis the values of b for velocity observations decrease for the transport indexes fig 17a c moving from g1 to g3 in contrast to the increasing impact of these data fig 15 a c therefore as the mooring velocity observations exert more of a direct influence on the sub mesoscale circulation environment the degree to which they lend strength to the other components of the observing system lessens however the distribution of information amongst the seven different pioneer array moorings implied by the observation impact and observation sensitivity calculations is different as seen by comparing figs 9i and fig 16i for i f and i e fig 17 shows that the ratio b increases for velocity observations going from g1 to g2 indicating that the indirect influence of these observations is enhanced further finally while b increases substantially between g1 and g3 for some observations this can be accompanied by a significant decrease in the direct observation impact for example fig 17 shows that b associated with satellite altimetry increases by 1 2 orders of magnitude between g1 and g3 however fig 15 reveals that there is a corresponding reduction in the direct impact of these data on each index therefore while the volume of altimetry observations diminishes considerably between g1 to g3 due to the reduction in the size of the geographical domain the few altimeters passes that cross g3 during october 2015 do nonetheless lend considerable strength to the other observing platforms figs 15 and 17 highlight the complex nature of the flow of observational information through the data assimilation system and efforts are ongoing to understand the mechanics of this process further 8 analysis error estimates having established the impact that different components of the observing system have on estimates of the cross shelf exchange it is important also to quantify the degree to which the observations contribute to the expected uncertainties in each of the target indexes i the expected analysis error covariance a of x a in 1 is given by a i kh b i kh t kr k t daley 1991 in practice however a is difficult to evaluate for 4d var systems and typically requires a monte carlo approach bennett 2002 ngodock et al 2020 or a low rank approximation fisher and courtier 1995 moore et al 2012 considered an alternative adjoint approach based on 10 specifically moore et al 2012 examined an infinite ensemble of δ i based on different realizations of perturbations to the innovations δ d δ y h δ x b where δ x b are perturbations in the background if δ y and δ x b are drawn from normal distributions with zero mean and covariance r and b respectively then for a single outer loop it can be shown that to 1st order a can be approximated as 11 a i k d h b i k d h t k d r k d t where k d t k y t is the adjoint of the 4d var system introduced in section 7 the expected error variance in any index i x a is then given by σ i 2 i x x b t a i x x b using 11 σ i 2 can be expressed as σ i 2 σ b 2 σ c 2 where a σ b 2 i x x b t b i x x b is the background error variance of i x b and b σ c 2 g t 2 hb i x x b hb h t g rg is the expected reduction in the error variance due to assimilating the observations where g k d t i x x b is the result of the observation sensitivity calculations in section 7 the correction term σ c 2 takes the form of a dot product of two vectors in observation space so the contribution of each observing platform to the expected reduction σ c 2 in the background error σ b 2 can be computed fig 18 shows time series of σ c 2 for each index from the g3 4d var analyses during october 2015 and the contribution of each type of observation also shown for reference are time series of the background error variance σ b 2 associated with i x b and the expected analysis error variance σ i 2 these statistics were computed for the 1st outer loop alone since as shown in part i the largest increments typically occur during this time it is possible to calculate the expected analysis errors for the 2nd outer loop also but such a computation is complicated and costly as shown by moore and arango 2020 it is important to appreciate that a will only be the true analysis error covariance matrix if both b and r are the true background and observation error covariance matrices since this is never the case we should not place too literal of an interpretation on a nonetheless the reduction σ c 2 σ b 2 σ i 2 in the background error variance is a useful guide for exploring the relative degree to which different observation platforms reduce uncertainties in each index for the majority of indexes fig 18 indicates that there is a modest reduction in the expected analysis error due to assimilating the observations the exception is i f for which there is no discernible decrease of the expected uncertainty in the position of the mab foot front due to data assimilation except during the 2nd week of oct fig 18 also shows that in situ observations from the pioneer array in combination contribute most to σ c 2 although during some cycles sst errors are important too given the focus in sections 6 and 7 on velocity observations from the pioneer array moorings fig 18 also shows the contribution to σ c 2 of these data alone from each mooring for the transport indexes i e i u i u t and i u s observations from the shelf break mooring 6 cf fig 2 contribute most to expected errors in each index on the other hand for i e the contributions to σ c 2 from the different moorings are generally more evenly distributed in the case of i f there are a few cycles during the first two weeks where moorings 1 and 4 have the largest influence on σ i 2 but as noted above σ c 2 is very small for this index it is also interesting to note that for some indexes there are opposing influences of different moorings on σ i 2 e g for i u t in fig 18d fig 18 provides a direct and quantitative measure of the role that each type of observation and observing platform plays in controlling the expected efficacy of the 4d var circulation estimates the particular focus here being on the position and strength of the mab front and environmental factors such as stratification that control cross shelf exchange 9 summary and conclusions this study is an extension of part i in which observations from remote sensing and in situ platforms were assimilated into a configuration of roms comprising three levels of telescoping nested grids centered on the mid atlantic bight in particular the impact of the different components of the mab and gulf of maine observing systems on analyses of cross shelf exchange was evaluated and assessed a critical element in the mab observing system is the nsf ooi pioneer array in this part ii our focus has been on the impact of the observations from the pioneer array on 4d var estimates of cross shelf exchange the impact of different types of observations was found to change across the three grids as discussed in part i the impact of the observations on each grid depends on several factors that include a the number and distribution of the observations b the background circulation which of course depends on the resolution of the grid c the background error covariance b and d the observation error covariance r differences in resolution limitations of the assimilation system and operational constraints dictate that the parameters used to compute b and r should vary across the three grids therefore some of the changes in the impact of the observations across the three grids can be attributed to different a priori choices of error statistics with this in mind it was found that temperature observations from the pioneer gliders typically have a significant impact on the cross shelf exchange on all three grids which is partly a reflection of similar levels of uncertainty assumed for the combined influences of instrument error and errors of representativeness salinity observations on the other hand are more impactful on g1 than on g2 and g3 this is partly because the errors assigned to salinity observations are smallest on g1 but as described in part i were subsequently reduced on g2 and g3 in accordance with a posteriori analysis of the innovation statistics however another factor that controls the impact of salinity and indeed temperature observations is the ensuing geostrophic adjustment process that acts to re establish a dynamic balance following the introduction of observations by the data assimilation the impact of velocity observations from the pioneer array moorings was found to increase with increasing resolution the increase in impact from g1 to g2 is partly associated with a reduction in the observation errors assigned to these data on g2 again in accordance with the a posteriori innovation statistics as described in part i a further increase in impact of velocity observations from the moorings was found on g3 compared to g2 which in this case is associated with the increase in horizontal resolution and the emergence of significant sub mesoscale variability to explore the impact of the observations on data assimilation spanning the different but connected dynamical circulation regimes captured by the three nested grids we focused attention on a 4 week window in 2015 during the interaction of a gulf stream ring with the continental shelf as captured by the 4d var analyses of g1 on g2 and g3 this same period is characterized by sub mesoscale frontogenesis in the vicinity of the pioneer array which appears to be initiated by the flow field that develops where several mesoscale eddies come together during this event velocity observations from the pioneer mooring array exert considerable influence on the g2 and g3 circulation estimates much more so than hydrographic measurements even though the local rossby number of the circulation is o 1 these findings are consistent with the linear theory of geostrophic adjustment also invoked in the early days of meteorological data assimilation to explain the relative effectiveness of wind and pressure observations for recovering the atmospheric state the synergy between the different types of observations during the 4d var estimation process was also explored by exploiting the complementary information provided by the observation impact and observation sensitivity calculations observation impact quantifies the actual contribution of each observation to the 4d var analysis while observation sensitivity dictates how the analysis must change if a specific observation is excluded from the 4d var procedure the ratio b of the observation sensitivity and observation impact can be used as an indicator of borrowing strength whereby data from say platform a for which b 1 provides important corroborating information that supports information gathered by other components of the observing system even if platform a per se has a relatively small directly measurable impact on the circulation finally we examined the contribution that each observing platform has on the expected uncertainty in the 4d var estimates of cross shelf exchange on g3 specifically the difference between the expected error variance of the 4d var analysis and the error variance of the background can be partitioned into the contribution associated with each observation for most indexes the pioneer array dominates the reduction in uncertainty of the circulation estimates and much of the time velocity observations from the pioneer moorings are the major contributor this again highlights the critical role that direct measurements of ocean currents play in our ability to estimate and potentially forecast the sub mesoscale environment this study demonstrates the extraordinary level of detailed information that can be teased from the application of the ideas that underpin the notion of observation impact and observation sensitivity we have only just begun to scratch the surface here clearly though routine monitoring of such information for carefully selected circulation indexes holds promise to provide an efficient and highly effective way of monitoring the veracity of not only the circulation estimates themselves but also the performance and efficacy of each component of the observing system such information will surely be useful for quantifying the socio economic impacts of in this case the ioos observing system and for efficient management of the existing observing system other potential spin offs of the work presented here which we are actively pursuing include repurposing of the 4d var adjoint calculations of section 8 to determine how the expected analysis error covariance will change when different components of the observing system are withheld and observing system design to augment existing observing systems such as the pioneer array and those maintained by ioos credit authorship contribution statement julia levin conceptualization methodology writing original draft writing review editing software validation formal analysis investigation data curation hernan g arango methodology writing original draft writing review editing software bruce laughlin software elias hunter data curation john wilkin conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration funding acquisition andrew m moore conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grants from the national science foundation united states of america oce 1459665 and oce 1459646 nasa united states of america nnx17ah58g and noaa united states of america na16nos0120020 pioneer array data were obtained from the nsf ocean observatories initiative data portal http ooinet oceanobservatories org 
23932,the regional ocean modeling system roms 4 dimensional variational 4d var data assimilation system was used to compute ocean state estimates of the mid atlantic bight mab a three level nested grid configuration was employed with horizontal resolution successively enhanced from 7 km down to 800 m at the innermost nest this captures the dynamics on space and time scales ranging from the gulf stream western boundary current down to the rapidly evolving and energetic sub mesoscale circulation this is a companion study to levin et al 2020 which examined the overall impacts of the entire observing system on shelf break exchange this follow on study specifically focuseson the impact of the in situ elements of the ocean observing system on the 4d var analyses the particular focus here is on the pioneer array a high density observing system in the mab designed to measure the multi scale nature of shelf break exchange processes building on levin et al 2020 it is found that the relative impact of observations from different components of the pioneer array depends on the scales of motion that are resolved by each nested grid this is in apparent agreement with the linear theory of geostrophic adjustment despite the o 1 rossby number the synergy between the observations from different observing platforms has also been quantified by comparing the observation impacts with the sensitivity of the 4d var analyses to changes in the observing array it is found that while some observations do not have a significant direct impact on the analyses they nevertheless provide essential information about the presence of circulation features corroborating that measured by other sensors thus the individual parts of the observing system can borrow strength from each other finally the contribution of each component of the observing system to the expected error in the 4d var analyses was also quantified where the critical role played by the pioneer array moorings in resolving the sub mesoscale circulation is again highlighted keywords roms 4d var pioneer array mid atlantic bight observation impact observation sensitivity 1 introduction this study is the companion of levin et al 2020 hereafter part i in which analyses of the circulation in the mid atlantic bight mab were computed by combining ocean observations with an ocean model using state of the art methods of data assimilation the model used is the regional ocean modeling system roms in conjunction with a 4 dimensional variational 4d var data assimilation system the model configuration comprises a hierarchy of three nested grids fig 1 in which the resolution increases by a factor of 3 at each step ranging from 7 km down to 0 8 km circulation features resolved span a broad spectrum of motions ranging from the gulf stream western boundary current through an energetic mesoscale eddy field all the way down to the o 1 rossby number flows that characterize the inhomogeneous rapidly evolving and ephemeral sub mesoscale circulation these circulation regimes all present considerable challenges for any data assimilation system the observing system comprises a combination of remote sensing platforms that provide surface measurements of temperature sea level and ocean currents as well as in situ platforms such as moorings ships surface drifters profiling floats and piloted autonomous glider vehicles an important and unique component of the mab observing system is the pioneer array one component of the u s national science foundation s nsf ocean observatories initiative ooi gawarkiewicz et al 2018 the pioneer array was designed to deliver sustained multi scale observations in the vicinity of the mab shelf break see fig 1c to investigate the processes that control the exchange of water masses between the continental shelf and the continental slope and associated biological and biogeochemical interactions it is the pioneer array focus on shelf break exchange processes that is of particular relevance to this study and the companion part i in part i we explored the impact that observations from each element of the mab and gulf of maine gom observing systems have on different aspects of the 4d var state estimates a main focus of part i was on the performance of the 4d var system across the combination of nested grids and the relative impact of the different observing platforms on cross shelf exchange in this companion study we expand on the analyses of part i and concentrate in particular on the impact of observations from the pioneer array on the 4d var analyses while there are a variety of approaches that can be used to quantitatively assess the impact and information content of ocean observing systems oke et al 2015a b fujii et al 2019 the methodology used here is based on the adjoint approach of langland and baker 2004 that is used routinely at many operational weather forecasting centers to monitor the efficacy of global atmospheric observing systems see http ios jcsda org a related and complementary diagnostic is observation sensitivity analysis which quantifies the sensitivity of ocean state estimates to changes in the observations and observing systems trémolet 2008 there are many powerful extensions of this approach which include computing estimates of the expected analysis errors moore et al 2012 in each case the problem can be recast in such a way that the direct contribution or influence of each observation to the property under investigation can be computed we present several applications of this approach here in relation to the pioneer array focusing in some instances on the process of sub mesoscale frontogenesis in this follow on study to part i we explore in detail the impact of observations assimilated into a high resolution configuration of roms that resolves the sub mesoscale circulation there are few instances of 4d var at such high resolutions in the ocean and this is an important exploration of the impact that different components of the observing system play in shaping the circulation estimates in this dynamical regime as noted a particular focus is the high density pioneer array another novel aspect of this study is quantification of the degree of synergy between different components of the observing system here we draw on the concept of borrowing strength from the field of statistics the degree to which each component of the observing system is able to borrow strength is quantified here based on combining information from observation impact and observation sensitivity calculations in addition the extent to which different components of the pioneer array contribute to the reduction in the expected error of the 4d var analyses is also quantified perhaps rather surprisingly it is also demonstrated that despite the high rossby number regime of the resolved sub mesoscale circulations the relative impact of velocity and mass field observations with increasing model resolution can be explained using the linear theory of geostrophic adjustment a brief overview of the roms and 4d var configurations is presented in section 2 however the reader is directed to levin et al 2019 hereafter l19 and part i for a more thorough explanation of the system a description of the observations from the pioneer array and pertinent aspects of observation processing is presented in section 3 as described in part i the observation impact methodology used here involves targeted indexes that highlight different aspects of the circulation that are of interest the observation impact methodology is reviewed in section 4 along with the suite of circulation indexes that were employed section 5 presents an overview of the impact on each index of the observations from the various platforms that make up the pioneer array in contrast in section 6 we focus on some particular events namely the interaction of a gulf stream ring with the continental shelf and the formation of a sub mesoscale salinity front the ideas of observation sensitivity are brought to bear in section 7 as a means of quantifying the synergy within the 4d var algorithm between observations from different components of the observing system the observation sensitivity methodology is repurposed in section 8 to explore the contribution of each element of the pioneer array to the reduction in the expected error of the 4d var state estimates the paper ends with a summary and conclusions in section 9 2 configuration of roms and 4d var as discussed in part i the roms configuration used in this study comprises three nested grids as illustrated in fig 1 following part i the grid with the largest geographic extent will be referred to as g1 and has a horizontal resolution 7 km and 40 terrain following levels stretched so that the thickness of the surface most layers is in the range 0 1 1 8 m and 0 1 3 4 m near the bottom over the continental shelf the middle refined grid hereafter g2 is centered on the pioneer array with a horizontal resolution of 2 4 km also with 40 terrain following levels in the vertical the innermost refined grid hereafter g3 is likewise centered on the pioneer array with 40 levels in the vertical and 0 8 km horizontal resolution g1 was constrained at the open boundaries using data from the mercator oc é an global analysis lellouche et al 2018 with temperature and salinity adjusted to remove seasonal bias compared to the local regional climatology of fleming 2016 in regular forward simulations all three grids can be run using one or two way nesting harmonic tidal forcing mukai et al 2002 was added to the boundary ssh and depth averaged velocity data of g1 sea surface wind stress and heat and freshwater fluxes were derived on all three grids from 3 hourly national centers for environmental prediction ncep north american mesoscale nam forecast marine boundary layer conditions and standard bulk formulae of fairall et al 2003 daily river in flows were imposed at 22 discharge sites based on u s geological survey and water survey of canada observations and a statistical model that adjusts for ungauged portions of the watershed lopez et al 2020 wilkin et al 2018 full details of the grid configurations can be found in part i the configuration of the roms 4d var system is also described in detail in part i so only a summary of the important features will be presented here following the same notation as part i the roms state vector will be denoted by x and comprises all of the ocean grid point values of the roms prognostic variables namely temperature t salinity s two components of horizontal velocity u v and free surface height ζ if x b denotes the background state vector and x a is the 4d var analysis then 1 x a x b k y o h x b where y o denotes the vector of observations h is the observation operator that maps from state space to observation space and includes the nonlinear model and k is the kalman gain matrix in the application considered here the dual form of 4d var was used e g courtier 1997 in which case k b h t hb h t r 1 where b and r are the background error and observation error covariance matrices respectively and h represents the tangent linearization of the observation operator h in 4d var h includes the tangent linearization of the nonlinear model and h t includes the adjoint model the inverse of the stabilized representer matrix hb h t r 1 is evaluated iteratively using a conjugate gradient descent algorithm as described by gürol et al 2014 this procedure is equivalent to a truncated gauss newton method which takes the form of a sequence of linear minimization problems each such sequence is solved via several inner loop iterations while each separate sequence constitutes an outer loop in the 4d var calculations considered here two outer loops and seven inner loops were used on all three grids and a summary of the data assimilated is presented in table 1 for g1 and g2 the period jan 2014 dec 2017 was considered while for g3 the shorter interval jan 2014 dec 2015 was used because of the substantial computational effort required for this grid the data assimilation strategy employed was as follows 1 observations were first assimilated into g1 for the full 2014 17 period using a 3 day assimilation window and treating the model initial conditions surface forcing all components and open boundary conditions as control variables the background state estimate for each 3 day window was taken to be the analysis at the end of the previous cycle 2 step 1 was then repeated for grid g2 using the 4d var analyses from each cycle of g1 as the background open boundary conditions for each 4d var cycle of g2 as in g1 the initial conditions surface forcing and open boundary conditions were all adjusted during each 4d var cycle 3 step 2 was then repeated for grid g3 using the 4d var analyses from each cycle of g2 as the background open boundary conditions for each 4d var cycle of g3 in this case the 4d var window was reduced to 1 day and only the initial conditions and open boundary conditions were adjusted during each 4d var cycle as discussed in part i and described in moore et al 2011a the background error covariance b matrix was modeled following the diffusion operator approach of weaver and courtier 2001 the decorrelation length scales assumed in b for errors in each control variable are listed in table 2 and these parameter choices are discussed in l19 the observation error covariance matrix r was assumed to be a diagonal matrix and table 1 summarizes the errors and uncertainties that were assigned to measurements from each observing platform as discussed in l19 these errors reflect a combination of measurement error and errors of representativeness i e uncertainties associated with the ability of the model grid to resolve all of the processes that are captured by the observations quality control was performed during each 4d var cycle following andersson and järvinen 1999 where the innovation d i associated with each observation is compared to the standard error based on the assumed standard deviations of the background σ b and observation σ o errors if d i 2 γ 2 σ b 2 σ o 2 then the observation is rejected and not included in the analysis the threshold parameter γ is dependent on the type of observation and is given in table 2 for the analyses on each grid considered here the performance of the 4d var system on all three grids is discussed in detail by l19 and in part i therefore no particulars will be given here suffice to say that the data assimilation system performs well on all three grids across the range of circulation length scales resolved and is able to fit the model solution to the observations reliably 3 the pioneer array an important component of the observing system in the mab is the u s national science foundation nsf ocean observatories initiative ooi pioneer array and the impact of the observations from this array on the 4d var ocean circulation estimates will be the focus of this study the pioneer array comprises seven permanent moorings fig 2 that straddle the continental shelf break where measurements of temperature and salinity from profiling ctd and velocity from adcp are made through almost the full depth of the water column ranging from 130 m to 450 m the ctd sample rate gives centimeter scale vertical resolution adcp velocity is reported in 4 m or 8 m bins at shallow and deep sites respectively the mooring observations are complemented by multiple gliders that repeatedly sample along the nominal tracks shown in fig 2 although the actual paths followed are subject to the vagaries of remotely piloting slowly moving buoyancy driven gliders in a turbulent ocean gliders return temperature and salinity observations from the surface to 1000 m where the bathymetry allows fig 2 shows when in 2014 2017 the various observing assets were returning data on average data from ctd profilers were available about 60 of the time not including the late 2017 deployments at moorings 2 and 4 and for adcp about 75 of the time note that there was a protracted period of low data return across the array in early 2015 powered autonomous underwater vehicle auv deployments are also a component of the pioneer array design but none took place during the 2014 2017 period considered here in addition to pioneer the other observations noted in table 1 were assimilated if they fell into the domains spanned by the respective nested grids as demonstrated in sequel observations from remote sensing and other in situ platforms lend support to the measurements collected by the pioneer array and vice versa 4 observation impacts methodology and indexes the procedure used to evaluate the impact of the observations on each 4d var analysis follows the method originally developed by langland and baker 2004 the implementation in roms is described in some detail by l19 and in part i so again only a summary of the essential points will be presented here the impact of the observations on the analysis x a is quantified in terms of the influence that they have on an index i x that isolates some aspect of the circulation that is of interest following langland and baker 2004 the change in i due to assimilating the observations y o is given by δ i i x a i x b which to 1st order can be expressed as δ i y o h x b t k t i x x b where i x x b is a vector and represents the derivative of i with respect to each element of x evaluated using the background x b as described in part i the transposed kalman gain matrix can be reconstructed using the archived conjugate gradient descent vectors from each 4d var assimilation cycle it should be clear that δ i is given by the dot product of the innovation vector d y o h x b and the vector g k t i x x b which quantifies the impact of the observations on δ i since each element of d is uniquely associated with an individual observation so then are the corresponding elements of g such that the product d i g i represents the contribution aka impact of the i th observation to δ i following part i the chosen indexes i x target variations in the position of the mab shelf break front and the strength of the associated stratification and cross shelf transport in the vicinity of the pioneer array specifically we consider five indexes 2 i u s 1 s 2 h 0 u n u n d z d s 3 i u t ρ o c p a 1 s 1 s 2 h 0 u n u n t t d z d s 4 i u s 1 0 3 ρ o a 1 s 1 s 2 h 0 u n u n s s d z d s 5 i f ξ 1 ξ 2 η ξ η r ξ d ξ 6 i e v 1 g d ζ ρ ρ z d z d a the indexes i u i u t and i u s target the volume heat and salt transport respectively across a section of the h 200 m isobath defined by the integral s 1 s s d s which is nominally identified as the location of the continental shelf break the location of the vertical section chosen is indicated in each panel of fig 1 and cuts through the middle of the pioneer array in 2 4 u n corresponds to the component of the velocity that is locally normal to the section s an over bar denotes the time average over each assimilation cycle the tilde represents the mean seasonal cycle and a is the area of the cross section each index was evaluated using a finite difference approximation consistent with the appropriate model grid the index i f in 5 targets the location where the 34 5 isohaline intercepts the bathymetry a traditional proxy for the foot of the mab shelf break front beardsley et al 1985 linder and gawarkiewicz 1998 in 5 ξ η represents the local cartesian coordinates position of the foot of the front averaged in time over the particular 4d var cycle and η r ξ is a reference line chosen to be the seasonally varying climatological position of the front it follows then that the area defined by i f is proportional to the departure of the front position from its seasonal mean the endpoints ξ 1 and ξ 2 of the integral coincide with the east west limits of pioneer array glider operations fig 1 following simpson and bowers 1981 the index i e in 6 is the potential energy per unit volume that would be gained were the upper part of the water column to become vertically mixed and is hence a measure of the strength of the vertical stratification in 6 ρ and ρ are respectively the in situ and vertically averaged density both averaged over the assimilation window d is a chosen depth ζ is the free surface displacement and the area integral is performed over the pioneer array glider domain cf fig 1c the depth d was chosen to be the average depth of the front foot across the pioneer array glider domain in 6 v represents the volume encompassed by the integrals with the result that i e represents the energy per unit volume j m 3 that is required to completely vertically mix the upper d meters of the water column within the pioneer array glider operations box cf the red rectangle in fig 6 5 pioneer array observation impacts the relative impact of the various platforms that comprise the entire regional observing system table 1 on the target indexes introduced in section 4 is presented in part i l19 have also considered in some detail the impact of each remote sensing platform on a subset of the same indexes on the 4d var analyses of g1 in this section we will focus attention on the impact of the observations from the different instruments and platforms that make up the pioneer array as noted in section 2 the period jan 2014 dec 2015 is common to the 4d var analyses computed on all three grids with this in mind fig 3 shows the root mean square rms impact on i u averaged over all 2014 2015 4d var analysis cycles of the individual pioneer array moorings and gliders the mooring numbering used in fig 3 is as indicated in fig 2 which also gives the 8 character designations used by ooi the gliders are referred to by their ooi 5 character identifiers the impact of the temperature salinity and velocity measurements from each mooring are reported separately as are the impacts of the temperature and salinity observations from each glider as discussed in part i the parameters used to compute the observation error covariance matrix r and background error covariance matrix b are not the same on the three grids some of the differences in r are reflected in the observation impacts the observation error standard deviations σ o assumed for in situ temperature observations are similar across all three grids and range from 0 6 c on g1 to 0 4 c on g2 and g3 however as noted in part i a posteriori analysis of the innovation statistics following the diagnostics described by desroziers et al 2005 suggests that σ o should be closer to 1 c the a priori values of σ o for in situ salinity observations were assumed to 0 2 on g1 while the a posteriori innovation statistics indicate that 0 4 is a more appropriate choice a value of σ o 0 4 was therefore used for the in situ salinity observation errors in both g2 and g3 for velocity measurements the σ o on g1 was assumed to be 0 6 ms 1 for hf radar surface current estimates and 0 3 ms 1 for moorings these values were adjusted downwards to 0 1 ms 1 for hf radar observations and 0 04 ms 1 for moorings for both g2 and g3 which are more in line with the a posteriori innovation statistics the high computational cost of 4d var precludes a more detailed and controlled suite of experiments where for example the parameters of the data assimilation system are varied independently across the three grids therefore we must draw on what we have although the variations in the level of errors across the different grids provide an indication of their control on the impacts with this in mind fig 3a shows that by and large it is temperature and salinity observations from the glider platforms that have the largest impact on i u of the g1 analyses on the other hand the velocity observations from the pioneer array moorings have a relatively low impact on g1 because the 7 km horizontal resolution of this grid cannot adequately resolve the mooring array on g2 fig 3b shows that temperature observations from the gliders still exert a significant influence on i u however the impact of salinity observations on g2 is much reduced compared to g1 mainly because as noted above σ o for salinity was increased on g2 compared to g1 the observation error statistics assumed for salinity on g2 and g3 are similar so the impact of these data is alike on both grids however fig 3b indicates that velocity observations from the pioneer array moorings now play a more dominant role in shaping the circulation estimates on g2 some of the difference between the impact of velocity observations on g1 and g2 can be attributed to the reduction in σ o noted above even though the σ o for the mooring data on g3 are similar to those on g2 the impact of the velocity observations is higher still on g3 fig 3c in this case the mooring velocity observations exert more control over the transport increments because the resolution of g3 is high enough to resolve some of the sub mesoscale circulation features that are captured by the moorings see section 6 for more details the relative impact of the various pioneer observing platforms on i u t i u s i f and i e is qualitatively similar to that for i u not shown time series of the 2015 increments δ i for all five indexes on g3 are shown in fig 4 in each case the contribution of the different observation types to the increment during each 4d var cycle is also indicated the dominant impact of velocity observations on all of the indexes is very apparent fig 4 also shows that satellite sst and in situ temperature measurements also have a significant influence the latter almost exclusively associated with pioneer gliders and moorings the impact of altimetry is negligible on g3 since there are very few satellite overpasses so is not shown however as shown in part i satellite ssh does exert significant control on each index in g1 and g2 fig 4 reveals that the increments in several of the indexes are larger during the second half of 2015 in particular there are some periods of prolonged coherent increments such as july august and october indicating that the data were likely prompting the 4d var system to make more substantial changes to the state estimates during these periods than was typical we will focus on the latter october 2015 period in the next section and explore in some detail the circulation environment during that time 6 october 2015 case study 6 1 transport increments the increments in volume transport δ i u and heat transport δ i u t in figs 4a and 4b indicate that during october 2015 the 4d var system made coherent and sustained changes in cross shelf transport for several weeks similarly there were significant movements in the mab front during this same period as indicated by δ i f in this section we will focus on this period and explore in detail the impact of the individual assets of the pioneer array while fig 4 shows the index increments only for g3 the increments are broadly consistent across all three grids this is illustrated in fig 5 which shows time series of the total volume transport i u s 1 s 2 h 0 u n d z d s during october 2015 the total transport i u is displayed instead of the transport i u given by 2 to remove any differences between the seasonal variations u n on the three grids fig 5 also shows time series of δ i u δ i u for october 2015 for each grid on all three grids the transport i u is positive indicating onshore flow which 4d var acts to reduce during most cycles the increments on g2 and g3 are generally consistent with each other although they are somewhat smaller in g2 the time resolution differs because g3 uses a 1 day analysis interval whereas in g1 and g2 it is 3 days on g1 δ i u is more variable and onshore during the period 8 13 october whereas g2 and g3 indicate offshore increments during this time in the case of g1 observations that are remote from the target section exert a significant influence on all of the indexes as demonstrated in l19 and part i particularly observations in the vicinity of the gulf stream front and georges bank these influences are absent from g2 and g3 due to their smaller geographical extent which is one of the primary reasons why δ i u is not entirely consistent between g1 and grids g2 and g3 the other indexes display a similar behavior across the three grids not shown 6 2 the sub mesoscale environment to illustrate the circulation environment that develops during the focus period figs 6 and 7 show the 4d var surface circulation estimates for g2 and g3 on 8 october when a warm core ring is impinging on the continental shelf in the western vicinity of the pioneer array the ring entered the region in early september from the east having coalesced into a coherent anticyclonic feature from a modest positive geopotential anomaly shed from the gulf stream in august the intrusion of warm saline gulf stream waters onto the shelf north and east of the ring are apparent in both g2 and g3 figs 6c and 7c show the relative vorticity of the vertically averaged velocity on the same day normalized by the coriolis parameter i e the local rossby number a region of uniform negative vorticity identifies the center of the gulf stream ring which is flanked by filamentous vorticity features small scale structures are ubiquitous on the shelf in both grids the vorticity color bar has been saturated to highlight the complex circulation structure however the local rossby number is generally significantly larger than one over much of the domain indicative of a non linear circulation environment in the case of g3 fig 7c reveals numerous sub mesoscale fronts jets and filaments in the vicinity of the pioneer array fig 7d shows that at the western end of the target section and near the offshore pioneer moorings a complex pattern of confluent and diffluent flows 0 3 0 4 m s 1 has developed which promotes frontogenesis in this region and acts to draw out the vorticity filaments that are so evident in fig 7c indeed closer inspection of fig 7b reveals that at the boundary of the mesoscale circulation features in this same region a filament of less saline shelf water is being drawn offshore right through the pioneer mooring array and across the target section adjacent to and west of the low salinity tongue more saline gulf stream waters are being drawn onto the shelf and a front forms as evidenced by the sharp surface salinity gradient the complexity of the circulation at this time is further apparent in fig 8 which shows vertical sections on 8 october of the temperature salinity and the normal component of velocity along the target section following the 200 m isobath even though the net transport is onshore at this time cf fig 5e fig 8c indicates that there are variations in the flow along the section and at depth the signature of the mesoscale eddy field is evident in the thermocline structure in fig 8a while fig 8b shows that the tongue of fresher water that is drawn off the continental shelf between 71 w and 70 5 w cf fig 7b is confined mainly to the upper 10 20 m and is associated with a complicated interleaving salinity structure and stacked flows of alternating direction and strength which contribute to the formation of the aforementioned salinity front 6 3 pioneer array observation impacts time series of the contributions of the pioneer array temperature salinity and velocity observations to the cross shelf volume transport increments δ i u are shown in fig 9 for all three grids we caution against making particular inferences regarding how the impact of individual platforms varies during the month because of changes in instrument operations fig 2 including glider recovery and deployments such that the 6 gliders noted in fig 9 represent collectively only 3 months of data what fig 9 does show clearly once again is how the impact of the in situ temperature and salinity measurements from the various glider platforms diminishes as the horizontal grid resolution increases conversely as noted earlier the impact of the in situ velocity observations from the moorings increases from g1 to g3 the results of fig 9 are generally consistent for the other indexes also and we will postpone a broader discussion of these findings until section 7 6 3 1 moorings focusing first on the moorings fig 10 shows the cross shelf component of current as a function of depth and time as measured at each of the seven pioneer array mooring locations during october 2015 while measurements are made only at discrete depths the velocity data in fig 10 have been interpolated in the vertical for clarity at all mooring locations strong semi diurnal tidal currents of up to 0 5 m s 1 are very apparent superimposed on the tidal flows are lower frequency current reversals with periods upwards of a week or so the strong offshore flow associated with the low salinity tongue and front formation around 8 october cf fig 7b is very evident at moorings 3 and 7 but is waning and by around 10 october the flow has reversed and proceeds to oscillate weakly with a period of 7 days the impact of velocity observations from each mooring location on the g3 cross shelf volume transport increments δ i u is shown in fig 11 as a function of depth and time with the same format as fig 10 negative impacts indicate that observations at a particular depth and time lead to a reduction in the onshore transport or equivalently an increase in offshore transport and vice versa for positive impacts a striking feature of fig 11 is that the impact of the mooring velocity measurements is mostly negative consistent with fig 9i regardless of whether the observed currents are directed offshore or onshore the largest impacts generally coincide with the peak of the diurnal signal a particularly striking feature is that for moorings 3 and 7 the impacts are very strongly negative during the formation of the low salinity tongue and salinity front before 10 october while after that the impact of the measurements from these moorings is much smaller despite the significant onshore currents cf fig 10 6 3 2 gliders before looking in detail at the impact of individual pioneer gliders on the chosen indexes consider fig 12 which shows the rms vertically integrated impact on δ i u of temperature and salinity observations combined in each model grid cell during the period 2014 2015 for all three grids although the increasing grid resolution going from g1 to g3 is very apparent the overall spatial distribution of high and low impacts is broadly consistent across the three grids however more detailed structures emerge on the higher resolution grids this is also true for the other indexes not shown in particular hydrographic observations in the vicinity of the target section generally have the largest impact fig 9a d and g show that during the october 2015 focus period glider gl380 generally has a significant impact on δ i u during the period of frontogenesis in early october the track of gl380 during this time is shown in fig 7c and during the latter part of the deployment it follows the target section fig 13 shows vertical sections of the combined impact on δ i u of temperature and salinity observations collected by gl380 for the period 1 15 october for all three grids for clarity the impacts are plotted as a function of latitude longitude and depth from two different 3 dimensional perspectives and separately as a function of depth and time the impacts of gl380 on δ i u are generally consistent on g2 and g3 for instance in each case the impacts are mostly negative with largest impacts typically associated with near surface measurements positive impacts are mostly found at depth particularly seaward of the shelf break in the case of g1 the gl380 impacts are dominated by salinity observations cf fig 9b and elevated positive impacts are evident after 8 october while the glider is traversing the target section in all three cases the outbound leg into deep water during 1 4 october is associated with negative impacts while the return leg to shallower water 4 7 october is characterized by more positive impacts figs 12 and 13 reveal that the impact of individual glider measurements are described by a rich and detailed structure through space and time disentangling the full nature of this structure is an ongoing challenge not only because of the complex flow dynamics in the region but also because the circulation is continuously changing throughout each glider deployment 6 4 linear adjustment theory even though the rossby number is o 1 cf figs 6c and 7c the increasing impact of the pioneer array mooring velocity observations on the circulation estimates in the vicinity of the target section as grid resolution increases and the corresponding decline in the impact of hydrographic data is consistent with linear theory of adjustment following temperton 1973 the stream function ψ s resulting from the 2 dimensional geostrophic adjustment of an unbalanced circulation estimate derived from data assimilation can be expressed as 7 ψ s α ψ i 1 α f 1 ϕ i where ψ i and ϕ i are the initial estimates of the stream function and geopotential height respectively and f is the coriolis parameter eq 7 shows that the resulting flow field u ψ s y and v ψ s x is a linear combination of the initial estimates of the velocity field described by ψ i and the mass field represented by ϕ i the weighting factor α is given by 8 α a e 2 k 2 l 2 a e 2 k 2 l 2 1 where k and l are the zonal and meridional wave numbers respectively and a e is the rossby radius of deformation thus eq 8 shows that the relative weighting of the initial velocity field and mass field to the final balanced circulation depends on the scale of motion k 2 l 2 1 2 compared to the radius of deformation specifically when the length scale of motion is large compared to a e then a e 2 k 2 l 2 0 and α 0 and the final balanced circulation is determined by the initial mass field estimate ϕ i conversely when the length scale of motion is small compared to a e then a e 2 k 2 l 2 and α 1 and the final balanced circulation is determined by the initial velocity field estimate ψ i more generally this is simply an expression of the partitioning of potential and kinetic energy for the scale of motion considered large scale motions are typically dominated by potential energy so observations of the mass field i e t s and or ρ are most beneficial in contrast short scale motions are usually dominated by kinetic energy in which case observations of the velocity field are best however an important property of 8 as pointed out by temperton 1973 is that for inhomogeneous flow fields it is the shortest length scale that determines the weighting factor α this is illustrated in fig 14a which shows α as a function of λ x 2 π k and λ y 2 π l for a e 20 km fig 14a indicates that if a circulation feature is elongated in one direction the relative impact of velocity observations and mass field observations is determined by the shortest length scale when α 0 5 this can be thought of as the situation when energy is equipartitioned between potential and kinetic forms and this situation is shown in fig 14a also as a e 0 the α 0 5 contour collapses toward the λ x and λ y axes exacerbating the dominating influence of the shortest length scale of a flow feature even more these ideas are of particular relevance here because as fig 7c shows the circulation in the vicinity of the shelf break is dominated by sub mesoscale features with large horizontal aspect ratios thus it is the cross frontal and cross filament length scales that will dictate what type of observations will be most beneficial for recovering the circulation if linear adjustment theory holds fig 14b shows how the 1st baroclinic mode radius of deformation a e varies across the g3 domain in the deep ocean a e 20 km but it decreases rapidly across the continental slope with a e 5 km or less on the shelf most of the sub mesoscale features in fig 7c have cross front and cross filament length scales less than the radius of deformation on the shelf therefore based on 7 and 8 we expect observations of velocity to be more beneficial for recovering the circulation than hydrographic measurements this is consistent with the findings above even though the radius of deformation is in the same range on all three grids increasing the horizontal resolution going from g1 to g3 leads to the emergence of the sub mesoscale features that are captured by the pioneer array mooring observations these arguments would also account for the relatively low direct impact that hf radar observations have on the g1 circulation estimates as described by l19 in this case the horizontal resolution is 7 km which is larger than the radius of deformation on the shelf so the scales of motion that will be effectively resolved on g1 will have scales of motion larger than a e for which velocity observations will be least effective 7 observation synergy a summary of the rms impact of each observation type on all five indexes and across all three grids is shown in fig 15 during the october 2015 case study considered in detail in section 6 the overall decrease in the impact of satellite altimetry and in situ pioneer hydrographic observations from gliders and moorings going from g1 to g3 is apparent in all indexes as is the general increase in the impact of velocity observations from the pioneer moorings the trend in sst is less clear where the impact of these data is generally highest on g2 and lowest on g3 from the summary in fig 15 an overall picture begins to emerge about the potential value of the observing system as a whole and the relative contribution of its components such information is of course beneficial since it can provide guidance on how ocean observing systems could be most effectively expanded to target specific processes and how individual assets should perhaps be managed and prioritized while it is tempting to view the impacts in fig 15 as an indication of how each index would change on average if each data type was excluded from the 4d var analysis such an interpretation is misleading this is because the analysis x a depends not only on the measurement value and location of each observation but also on the interaction between the observations during the data assimilation process the interaction and synergy between different observations and observation platforms can be complicated and difficult to unravel e g daley 1991 but can be quantified using a variant of the observation impact methodology described in section 4 following moore et al 2011b suppose that we re express the analysis equation 1 as 9 x a x b k d where k d represents the entire data assimilation algorithm expressed as a function of the innovation vector d y o h x b as shown by moore et al 2011b and l19 a change δ y in the observation vector y o leads to a change δ i in the index i which to 1st order can be expressed as 10 δ i δ y t k y o t i x x b where k y o t represents the adjoint of the tangent linearization of the entire data assimilation system and i x x b represents the derivative of i with respect to x evaluated using the background x b as in section 4 it is tempting to invoke 1 here and conclude that k y o is simply the kalman gain matrix however it is important to remember that in any practical implementation of 4d var or any linear data assimilation algorithm applied to a large dimensional system like that considered here we can never iterate the system to complete convergence thus the effective gain matrix that is used to compute the analysis in 1 will not be the true kalman gain matrix therefore except in the rare case where 4d var is iterated to complete convergence then in general k y o k the roms 4d var system includes the capability to compute k y o t and from eq 10 it follows that the change in i associated with any change in the observations δ y can be computed from a single application of the adjoint of 4d var furthermore moore et al 2011b show that if the elements of δ y are chosen to be 1 times the innovation associated with specific observations then 10 can be used to compute the change in the index that occurs when these observations are excluded from the 4d var analysis this is a very powerful and efficient tool for performing observing system experiments oses without the need to repeat the costly 4d var calculations for each new configuration of the observing system since 10 indicates how a given index is influenced by changes in the observations or observing system it is referred to as observation sensitivity to illustrate this approach fig 16 shows time series of the change in cross shelf volume transport δ i u during the october 2015 case study period when individual components of the glider and mooring arrays are removed from the 4d var analysis independently during each data assimilation window a comparison of fig 16 presenting the observation sensitivity with fig 9 showing observation impact reveals that the actual δ i u that results from excluding a particular observing platform from the analysis is very different from what we would infer from the impacts for example fig 9a shows that during most 4d var cycles on g1 the direct impact of glider temperature observations is quite small conversely fig 16a indicates that when any individual glider is excluded from the 4d var analyses of g1 the changes in cross shelf transport can be quite significant a dramatic example is the 3 day assimilation cycle spanning the period 25 27 october on g2 fig 9d f show that the transport increment impact during this period is small and positive and that the impacts of each pioneer observing platform are generally benign conversely fig 16 d f reveal that several of the observing platforms will lead to large increments in transport if omitted from the analysis and that some assets have largely opposing influences on δ i u l19 explored these ideas in some detail with remote sensing observations on g1 they concluded that the seemingly contradictory nature of the results of observation impact and observation sensitivity can be understood in terms of borrowing strength a concept introduced by the princeton mathematician john tukey in the 1960s and 70s brillinger 2002 in other words while a particular observation y i say may not have an especially significant direct impact on δ i the observation y i nonetheless provides information that corroborates that from other measurements and in this way indirectly aids the assimilation process therefore if y i is excluded from the 4d var analysis the corroborating information that it provides will be lost leading to a much larger change in i than might otherwise be expected based on an observation impact calculation alone thus in this way other observations borrow strength from y i l19 argue that the degree to which different components of the observing system borrow strength from each other can be quantified using the ratio of the observation sensitivity to the observation impact drawing on this idea fig 17 shows the ratio b of the rms observation sensitivity to the rms observation impact for all indexes across all three grids and for all measurement types averaged over all 4d var cycles during october 2015 this ratio is a measure of the average change that actually occurs in each index when an observation is excluded from all 4d var analyses and that which might be expected to occur based on the observation impact alone a value of b 1 therefore indicates that on average the sensitivity and impact calculations predict similar changes in a given index if observations of this type are excluded from each 4d var cycle conversely values of b 1 b 1 indicate that the actual change in i will be larger smaller than expected based on the observation impact calculations therefore departures of b from a value of one can be viewed as an indicator of the level of borrowing strength note that the ratios shown in fig 17 for in situ temperature salinity and velocity data are for observations collected from the pioneer array only several striking features appear in fig 17 first in all but a few cases b 1 on all three grids indicating that all components of the observing system are borrowing strength from one another only in the case of satellite sst and altimetry do we see instances of b 1 for some of the indexes on g2 and g3 second in the case of velocity observations b is large on g1 10 indicating that while fig 15 shows a relatively modest direct impact of these data on all indexes the actual change that will occur in each i will be much larger than the impact implies if velocity observations are excluded from the 4d var analysis the values of b for velocity observations decrease for the transport indexes fig 17a c moving from g1 to g3 in contrast to the increasing impact of these data fig 15 a c therefore as the mooring velocity observations exert more of a direct influence on the sub mesoscale circulation environment the degree to which they lend strength to the other components of the observing system lessens however the distribution of information amongst the seven different pioneer array moorings implied by the observation impact and observation sensitivity calculations is different as seen by comparing figs 9i and fig 16i for i f and i e fig 17 shows that the ratio b increases for velocity observations going from g1 to g2 indicating that the indirect influence of these observations is enhanced further finally while b increases substantially between g1 and g3 for some observations this can be accompanied by a significant decrease in the direct observation impact for example fig 17 shows that b associated with satellite altimetry increases by 1 2 orders of magnitude between g1 and g3 however fig 15 reveals that there is a corresponding reduction in the direct impact of these data on each index therefore while the volume of altimetry observations diminishes considerably between g1 to g3 due to the reduction in the size of the geographical domain the few altimeters passes that cross g3 during october 2015 do nonetheless lend considerable strength to the other observing platforms figs 15 and 17 highlight the complex nature of the flow of observational information through the data assimilation system and efforts are ongoing to understand the mechanics of this process further 8 analysis error estimates having established the impact that different components of the observing system have on estimates of the cross shelf exchange it is important also to quantify the degree to which the observations contribute to the expected uncertainties in each of the target indexes i the expected analysis error covariance a of x a in 1 is given by a i kh b i kh t kr k t daley 1991 in practice however a is difficult to evaluate for 4d var systems and typically requires a monte carlo approach bennett 2002 ngodock et al 2020 or a low rank approximation fisher and courtier 1995 moore et al 2012 considered an alternative adjoint approach based on 10 specifically moore et al 2012 examined an infinite ensemble of δ i based on different realizations of perturbations to the innovations δ d δ y h δ x b where δ x b are perturbations in the background if δ y and δ x b are drawn from normal distributions with zero mean and covariance r and b respectively then for a single outer loop it can be shown that to 1st order a can be approximated as 11 a i k d h b i k d h t k d r k d t where k d t k y t is the adjoint of the 4d var system introduced in section 7 the expected error variance in any index i x a is then given by σ i 2 i x x b t a i x x b using 11 σ i 2 can be expressed as σ i 2 σ b 2 σ c 2 where a σ b 2 i x x b t b i x x b is the background error variance of i x b and b σ c 2 g t 2 hb i x x b hb h t g rg is the expected reduction in the error variance due to assimilating the observations where g k d t i x x b is the result of the observation sensitivity calculations in section 7 the correction term σ c 2 takes the form of a dot product of two vectors in observation space so the contribution of each observing platform to the expected reduction σ c 2 in the background error σ b 2 can be computed fig 18 shows time series of σ c 2 for each index from the g3 4d var analyses during october 2015 and the contribution of each type of observation also shown for reference are time series of the background error variance σ b 2 associated with i x b and the expected analysis error variance σ i 2 these statistics were computed for the 1st outer loop alone since as shown in part i the largest increments typically occur during this time it is possible to calculate the expected analysis errors for the 2nd outer loop also but such a computation is complicated and costly as shown by moore and arango 2020 it is important to appreciate that a will only be the true analysis error covariance matrix if both b and r are the true background and observation error covariance matrices since this is never the case we should not place too literal of an interpretation on a nonetheless the reduction σ c 2 σ b 2 σ i 2 in the background error variance is a useful guide for exploring the relative degree to which different observation platforms reduce uncertainties in each index for the majority of indexes fig 18 indicates that there is a modest reduction in the expected analysis error due to assimilating the observations the exception is i f for which there is no discernible decrease of the expected uncertainty in the position of the mab foot front due to data assimilation except during the 2nd week of oct fig 18 also shows that in situ observations from the pioneer array in combination contribute most to σ c 2 although during some cycles sst errors are important too given the focus in sections 6 and 7 on velocity observations from the pioneer array moorings fig 18 also shows the contribution to σ c 2 of these data alone from each mooring for the transport indexes i e i u i u t and i u s observations from the shelf break mooring 6 cf fig 2 contribute most to expected errors in each index on the other hand for i e the contributions to σ c 2 from the different moorings are generally more evenly distributed in the case of i f there are a few cycles during the first two weeks where moorings 1 and 4 have the largest influence on σ i 2 but as noted above σ c 2 is very small for this index it is also interesting to note that for some indexes there are opposing influences of different moorings on σ i 2 e g for i u t in fig 18d fig 18 provides a direct and quantitative measure of the role that each type of observation and observing platform plays in controlling the expected efficacy of the 4d var circulation estimates the particular focus here being on the position and strength of the mab front and environmental factors such as stratification that control cross shelf exchange 9 summary and conclusions this study is an extension of part i in which observations from remote sensing and in situ platforms were assimilated into a configuration of roms comprising three levels of telescoping nested grids centered on the mid atlantic bight in particular the impact of the different components of the mab and gulf of maine observing systems on analyses of cross shelf exchange was evaluated and assessed a critical element in the mab observing system is the nsf ooi pioneer array in this part ii our focus has been on the impact of the observations from the pioneer array on 4d var estimates of cross shelf exchange the impact of different types of observations was found to change across the three grids as discussed in part i the impact of the observations on each grid depends on several factors that include a the number and distribution of the observations b the background circulation which of course depends on the resolution of the grid c the background error covariance b and d the observation error covariance r differences in resolution limitations of the assimilation system and operational constraints dictate that the parameters used to compute b and r should vary across the three grids therefore some of the changes in the impact of the observations across the three grids can be attributed to different a priori choices of error statistics with this in mind it was found that temperature observations from the pioneer gliders typically have a significant impact on the cross shelf exchange on all three grids which is partly a reflection of similar levels of uncertainty assumed for the combined influences of instrument error and errors of representativeness salinity observations on the other hand are more impactful on g1 than on g2 and g3 this is partly because the errors assigned to salinity observations are smallest on g1 but as described in part i were subsequently reduced on g2 and g3 in accordance with a posteriori analysis of the innovation statistics however another factor that controls the impact of salinity and indeed temperature observations is the ensuing geostrophic adjustment process that acts to re establish a dynamic balance following the introduction of observations by the data assimilation the impact of velocity observations from the pioneer array moorings was found to increase with increasing resolution the increase in impact from g1 to g2 is partly associated with a reduction in the observation errors assigned to these data on g2 again in accordance with the a posteriori innovation statistics as described in part i a further increase in impact of velocity observations from the moorings was found on g3 compared to g2 which in this case is associated with the increase in horizontal resolution and the emergence of significant sub mesoscale variability to explore the impact of the observations on data assimilation spanning the different but connected dynamical circulation regimes captured by the three nested grids we focused attention on a 4 week window in 2015 during the interaction of a gulf stream ring with the continental shelf as captured by the 4d var analyses of g1 on g2 and g3 this same period is characterized by sub mesoscale frontogenesis in the vicinity of the pioneer array which appears to be initiated by the flow field that develops where several mesoscale eddies come together during this event velocity observations from the pioneer mooring array exert considerable influence on the g2 and g3 circulation estimates much more so than hydrographic measurements even though the local rossby number of the circulation is o 1 these findings are consistent with the linear theory of geostrophic adjustment also invoked in the early days of meteorological data assimilation to explain the relative effectiveness of wind and pressure observations for recovering the atmospheric state the synergy between the different types of observations during the 4d var estimation process was also explored by exploiting the complementary information provided by the observation impact and observation sensitivity calculations observation impact quantifies the actual contribution of each observation to the 4d var analysis while observation sensitivity dictates how the analysis must change if a specific observation is excluded from the 4d var procedure the ratio b of the observation sensitivity and observation impact can be used as an indicator of borrowing strength whereby data from say platform a for which b 1 provides important corroborating information that supports information gathered by other components of the observing system even if platform a per se has a relatively small directly measurable impact on the circulation finally we examined the contribution that each observing platform has on the expected uncertainty in the 4d var estimates of cross shelf exchange on g3 specifically the difference between the expected error variance of the 4d var analysis and the error variance of the background can be partitioned into the contribution associated with each observation for most indexes the pioneer array dominates the reduction in uncertainty of the circulation estimates and much of the time velocity observations from the pioneer moorings are the major contributor this again highlights the critical role that direct measurements of ocean currents play in our ability to estimate and potentially forecast the sub mesoscale environment this study demonstrates the extraordinary level of detailed information that can be teased from the application of the ideas that underpin the notion of observation impact and observation sensitivity we have only just begun to scratch the surface here clearly though routine monitoring of such information for carefully selected circulation indexes holds promise to provide an efficient and highly effective way of monitoring the veracity of not only the circulation estimates themselves but also the performance and efficacy of each component of the observing system such information will surely be useful for quantifying the socio economic impacts of in this case the ioos observing system and for efficient management of the existing observing system other potential spin offs of the work presented here which we are actively pursuing include repurposing of the 4d var adjoint calculations of section 8 to determine how the expected analysis error covariance will change when different components of the observing system are withheld and observing system design to augment existing observing systems such as the pioneer array and those maintained by ioos credit authorship contribution statement julia levin conceptualization methodology writing original draft writing review editing software validation formal analysis investigation data curation hernan g arango methodology writing original draft writing review editing software bruce laughlin software elias hunter data curation john wilkin conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration funding acquisition andrew m moore conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grants from the national science foundation united states of america oce 1459665 and oce 1459646 nasa united states of america nnx17ah58g and noaa united states of america na16nos0120020 pioneer array data were obtained from the nsf ocean observatories initiative data portal http ooinet oceanobservatories org 
23933,the properties of the expected analysis and forecast error covariance matrices are explored using a novel method based on the tangent linearization and adjoint of a 4 dimensional variational 4d var data assimilation system the method is applied to the mesoscale circulation that develops in the presence of a baroclinically unstable mid latitude ocean temperature front using a series of paternal twin experiments that employ both strong and weak constraint 4d var adopting the traditional view of empirical orthogonal functions eofs of a covariance matrix as the semi major axes of a multi dimensional hyper ellipsoid variations in the volume of the analysis and forecast error hyper ellipsoids are explored which provides information about the flow of probability through state space the complementary variations in the expected total variance of the covariance matrix are also investigated two different kinds of behavior are identified that are associated with either the demise or growth of baroclinic instabilities in both cases the volume of the hyper ellipsoid decreases during the 4d var analysis cycle during the subsequent forecasts the volume of the forecast error hyper ellipsoid initially continues to collapse under both scenarios during this time the hyper ellipsoid becomes increasingly elongated along some of the semi major axes as forecast errors grow in preferential directions growth in these directions is controlled by the most unstable error modes and projection of forecast error on to the precursors of these modes has been shown previously to be characterized by upscale energy transfer and non normal processes for the case of the growing wave the forecast error hyper ellipsoid continues to collapse through to the end of the forecast period however for the decaying wave the hyper ellipsoid may undergo expansion at longer forecast lead times keywords 4d var error covariance adjoint methods baroclinic instability 1 introduction an important element of operational analysis and forecast systems for the ocean and atmosphere is the quantification of the errors and uncertainties in the resulting circulation estimates since many operational systems these days are based on an ensemble approach analysis and forecast ensembles provide a convenient means for estimating error covariance properties such approximations however are of reduced rank in nature and generally underestimate the actual errors for example some form of covariance inflation is typically required in ensemble kalman filters due to the limited number of members that are used e g anderson 2007 in addition localization is necessary to ameliorate spurious correlations and rank deficiency due to the limited ensemble size gaspari and cohn 1999 in variational data assimilation systems covariance information is difficult to compute ngodock et al 2020 but can be estimated from an approximation of the kalman gain matrix although it is typically an underestimate of the actual error covariance fisher and courtier 1995 the very large dimension of most geophysical problems of interest precludes the explicit computation of analysis and forecast error covariance matrices however many important properties of these covariances can be computed if it is possible to compute the product of the matrix with a vector in this paper we explore an alternative approach for computing the expected analysis and forecast error covariance which makes direct use of the tangent linear and adjoint of a 4 dimensional variational 4d var data assimilation system to compute a matrix vector product it should be stated at the outset that the approach used here is extraordinarily demanding computationally and is not suitable for a large operational analysis forecast system however as we will demonstrate our approach is of theoretical and mathematical interest because it has the desirable property of providing an explicit operator for the analysis and forecast error covariance which makes it very appealing despite the heavy computational burden in a conventional 4d var system recent developments in 4d var promise very substantial reductions in the computational cost fisher et al 2011 d amore et al 2014 arcucci et al 2015 fisher and gürol 2017 which could make the approach adopted here more tractable in large models in the future in light of the computationally heavy burden attention is restricted to an exploration of the properties of analysis and forecast error covariance in a small but very relevant computational domain specifically we will consider the expected covariance properties of errors that develop in the ocean mesoscale circulation environment that results from the adjustment of a baroclinically unstable temperature front at mid latitudes fronts are a common feature of the ocean circulation so the results presented here are of broad interest and generally applicable in many situations for example analysis and prediction of oceanic fronts and their incumbent eddies in coastal ocean environments is an important mandate of many operational forecasting centers because of the significant role that these circulation features play in controlling local air sea interactions the health of marine ecosystems and ocean acidification events therefore the results presented here have some potentially very practical applications a description of the mathematical formulation of the analysis and forecast error covariance in terms of the tangent linearization of the entire data assimilation system is presented in section 2 while section 3 describes the experimental set up used to explore the utility of the method introduced in section 2 the properties of the expected analysis and forecast errors for a frontal system are presented in sections 4 and 5 section 6 demonstrates the connection between the method used here and the closely related study of smith et al 2015 a summary and conclusions follow in section 7 2 methodology the approach developed for estimating the expected analysis and forecast error covariance is based on the work of moore et al 2012 hereafter mab using a 4d var approach for this reason the following discussion is focused on 4d var but the same methodology could in principle be applied to any linearized data assimilation algorithm 2 1 the expected analysis error covariance a standard notation will be adopted here ide et al 1997 where x represents the state vector of the system under consideration while x b and x a denote the background and analysis estimates of x respectively for any linear data assimilation system the best linear unbiased estimate blue aka analysis can be expressed as 1 x a x b k y o h x b where y o is the vector of observations and h is the observation operator that maps x b to the space time location of each datum the matrix k is the kalman gain and can be expressed as 2 k b h t hb h t r 1 where b and r are the background and observation error covariance matrices respectively and h is the linearized observation operator in the case of 4d var data are assimilated over a window in time and h also includes the nonlinear model while h represents the tangent linear model sampled at the observation points the adjoint model forced at the observation points is represented by h t in the case of strong constraint 4d var b b x and describes the statistics of the errors in the initial conditions for the weak constraint case errors in the model are also accounted for by augmenting the background error covariance matrix so that b d i a g b x q where q is the model error covariance matrix a schematic of a typical analysis forecast cycle for both flavors of 4d var is shown in fig 1 where the interval t τ 0 denotes the analysis window and t 0 t represents the forecast interval the analysis given by 1 is valid at the beginning of the analysis window and must be integrated forward in time to t 0 in order to make a forecast based on 1 and 2 the covariance of the expected errors in the analysis x a can be written as 3 a τ i kh b i kh t kr k t daley 1991 as in 1 this estimate of a is valid at time t τ the goal of 4d var is to identify the analysis x a τ that minimizes a cost function that is a quadratic measure of the weighted departures of x from the background and the observations because the resulting minimization problem is nonlinear it is common practice to apply the incremental approach of courtier et al 1994 where the estimation procedure is linearized about the background x b over the interval t τ 0 the resulting algorithm is equivalent to a gauss newton method lawless et al 2005 and comprises so called inner loops and outer loops the minimization of the non quadratic cost function proceeds via a sequence of linear minimization problems where the latter is accomplished during the inner loop iterations and identifies an increment δ x τ to x b τ following the completion of a sequence of inner loops the state vector estimate x τ is updated using the most recent increment during an outer loop and another linear minimization problem is solved via a new set of inner loops after n outer loops the analysis is given by 4 x a x b i 1 n δ x i and the expected analysis error covariance matrix is given by 5 a n τ i n 1 i k i h i 1 b i n 1 i k i h i 1 t j 1 n 1 i n j 1 i k i h i 1 k j k n r j 1 n 1 i n j 1 i k i h i 1 k j k n t where k i is the kalman gain resulting from outer loop i and h i 1 is the tangent linear observation operator linearized about x i 1 during the first outer loop h 0 h b which is the observation operator linearized about x b 2 2 analysis error covariances from the tangent linearization of 4d var belo pereira and berre 2006 and berre et al 2006 have demonstrated that estimates of the expected analysis error covariance matrix can be computed by perturbing an analysis x a to create an analysis ensemble each member of the analysis ensemble is generated by rerunning the data assimilation system using a perturbed background and perturbed observations the perturbations are drawn from normal distributions with zero mean and error covariances b and r respectively as shown by these authors the covariance of the resulting analysis ensemble mimics the covariance of the expected uncertainties in the unperturbed analysis x a in the case of 4d var this would be an estimate of a n τ in fig 1 and the original unperturbed analysis x a represents the ensemble mean by extending these ideas mab showed that as the size of the analysis ensemble approaches infinity the ensemble covariance can be expressed in terms of a tangent linearization of the data assimilation system and its adjoint in the context of the present work this would be the tangent linearization of the entire 4d var algorithm and the corresponding adjoint specifically any linear data assimilation system that solves for the blue in 1 can be generalized so that 6 x a x b k d where d y o h x b represents the innovation vector and k d denotes the data assimilation algorithm which in general will be a nonlinear function of d for example 4d var proceeds by minimizing the cost function using a conjugate gradient method an inherently nonlinear procedure based on d using 6 and following mab eq 5 can be re expressed as 7 a n τ i n 1 i k d i h i 1 b i n 1 i k d i h i 1 t j 1 n 1 i n j 1 i k d i h i 1 k d j k d n r j 1 n 1 i n j 1 i k d i h i 1 k d j k d n t where d i y o h x i 1 the operator k d i represents the tangent linearization of 4d var for outer loop i and k d i t is the corresponding adjoint in the case of a single outer loop eq 7 reduces to 8 a τ i k d h b b i k d h b t k d r k d t which was the case considered by mab for estimating the expected analysis error variance of several different circulation indices since 7 and 8 are based on a 1st order linearization of k d in 6 it is assumed that the influence of higher order terms on a n τ is negligible as noted in section 1 the explicit computation of all the elements of a would be prohibitively expensive given the very large dimension of most problems of interest however since the matrix in 7 and 8 is available as an operator in the form of fortran code important properties of the error covariance matrix can be quantified using iterative methods since all that is required is the ability to compute a matrix vector product the tangent linear operator k d and its adjoint k d t have considerable utility moore et al 2011a for example the operators can be used to quantify the sensitivity of the 4d var system to uncertainties in the system provide information about the impact of observations on the analyses and forecast e g trémolet 2008 yield information about the expected error variance in scalar functions mab or provide information about the stability and conditioning of the 4d var inversion procedure the latter arises from the useful properties of the tangent linearization and adjoint of the conjugate gradient method gratton et al 2014 in the investigations described in later sections it is important to note that k d and k d t were derived directly from the data assimilation fortran code using standard recipes e g giering and kaminski 1998 and each operator represents one complete outer loop evaluation of the tangent linear and adjoint of the 4d var system thus the computational cost of each of these operations is comparable to running 4d var however 7 represents an explicit operator for the expected analysis error covariance arising from an infinite ensemble and from which matrix vector products can be computed therefore various properties of the analysis error covariance matrix such as the total error variance i e the trace and empirical orthogonal functions eofs can be computed iteratively 2 3 forecast error covariance suppose now that the unperturbed analysis x a of section 2 2 is advanced to the end of the analysis window t 0 and used to initialize a forecast denoted x f as shown schematically in fig 1 for the interval 0 t similarly an ensemble of forecasts can be created each initialized from individual members of the analysis ensemble of section 2 2 the covariance of the forecast ensemble about the unperturbed forecast x f will mimic the covariance of the expected forecast errors under this scenario and neglecting for now model error a linear approximation of the expected forecast error covariance matrix f t during the forecast interval t 0 t illustrated in fig 1 is given by 9 f t m f 0 t a n 0 m f t t 0 where m f 0 t denotes the tangent linear model linearized about the forecast x f t m f t t 0 is the adjoint model where the reversed arguments indicate integration backward in time over the forecast interval and a n 0 is the analysis error covariance matrix at the end of the analysis window t 0 cf fig 1 in this framework the unperturbed forecast x f is equivalent to the ensemble mean and f t is the covariance of the infinite ensemble about the ensemble mean the analysis error covariance at t 0 is given by a n 0 m b τ 0 a n τ m b t 0 τ where a n τ is the expected analysis error covariance at the beginning of the analysis window given by 5 and m b τ 0 denotes the tangent linear model linearized about the background x b over the analysis window using 7 the expected forecast error covariance can be computed according to 10 f n t m f 0 t m b τ 0 a n τ m b t 0 τ m f t t 0 the covariance matrices in 3 and 9 are defined in terms of the l2 norm and as such cross covariances between different physical variables of the state vector will have mixed units e g m s 1 c while this is an acceptable definition of covariance the mixed units can render difficult a direct comparison of individual matrix elements and complicate the interpretation of the eofs alternatively a norm can be chosen whereby the elements of the resulting error covariance matrix all have the same units in numerical weather prediction it is common to use an energy norm to define the covariance of the forecast error ε e g buizza and palmer 1995 such that c e uε ε t u t where e denotes the expectation operator and u is an appropriate weight matrix so that all elements of the vector uε have the units of the square root of energy the choice of an energy norm is also appealing given the fundamental role that energy plays in our understanding of the underlying physical processes that govern the ocean circulation the very same processes that control the evolution of forecast errors therefore an energy norm described in appendix a was used in all of the computations reported here in which u is time invariant as in section 2 the various matrix operations in 10 are available as fortran code and various properties of f n t can be evaluated using iterative methods 3 experimental setup attention is confined here to the relatively simple yet dynamically relevant case of the adjustment of an ocean temperature front in a zonally re entrant channel and the subsequent relaxation toward a restratified water column a problem that has been studied extensively in the oceanographic literature e g boccaletti et al 2007 klein et al 2008 3 1 paternal twin models the model used was the regional ocean modeling system roms shchepetkin and mcwilliams 2005 it was configured for a flat bottomed zonally periodic channel 1000 km long 2000 km wide and 4000 m deep centered on 43 3 s two configurations of the model were considered model t with 2 5 km grid spacing in the horizontal and model f with 20 km horizontal grid spacing in both models 20 unevenly spaced levels were used in the vertical with spacing 20 m near the surface increasing to 700 m at the bottom both models employ 4th order horizontal and vertical advection for tracers and 3rd order upstream horizontal advection for momentum in conjunction with 4th order vertical advection of momentum horizontal mixing in the form of 2nd order eddy diffusivity and eddy viscosity was used that is parallel to the model σ levels with coefficients of eddy viscosity and diffusivity of 25 m2 s 1 in model t and 400 m2 s 1 in model f vertical mixing was parameterized using the k ε generic length scale formulation of umlauf and burchard 2003 with lower thresholds of 10 5 m2 s 1 for the vertical mixing coefficients of tracer and momentum in model t and 5 1 0 5 m2 s 1 in model f the time step in model t was 150 s compared to 1200 s in model f model t was used to simulate the true ocean circulation and following smith et al 2015 hereafter sma was initialized from rest with a meridional temperature front described by t y z t 0 t r y 1 z h 1 2 where t r y α f y erf y y 0 l f 0 with α 4 52 y is the cross channel distance z is depth f y is the coriolis parameter on a β plane with a value of f 0 at the central latitude 43 3 s l 80 km is the meridional scale of the temperature front h is the channel depth y 0 is the value of y at the mid point of the channel and t 0 12 c is the surface temperature at y 0 salinity was not included in the model calculations reported here instability growth was encouraged by adding small amplitude sinusoidal zonal wavenumber 1 and zonal wavenumber 2 perturbations to the initial condition for simplicity there is no surface forcing imposed in either model t or model f however the instability process was prolonged by weakly relaxing the solution to the initial temperature profile on a time scale of 50 days fig 2a d shows the evolution of the sst of the circulation that develops in model t between days 50 and 134 as noted in section 1 fronts are a common feature of the ocean circulation and occur on a wide range of scales ranging from the geostrophic regime down to the sub mesoscale here we concentrate on the quasi geostrophic regime which includes the formation of seasonal fronts such as sub polar and shelf break fronts and upwelling fronts such as those that form in eastern boundary current systems in the experiments presented here the presence of the front is taken as a given and we do not concern ourselves with the mechanism of frontogenesis although surface forcing is known to play a major role in many instances for example cross front ekman transport associated with along front winds can hasten the formation or demise of a front depending on the wind direction here we simply explore the collapse of a front after genesis and the subsequent relaxation toward a restratified ocean with this in mind fig 2a d illustrate very clearly the complex circulation that develops as a result of the baroclinic instabilities that ensue as the isotherms slump in an attempt to move toward a lower energy state initially the circulation is dominated by the development of a zonal wavenumber 2 instability which later gives way to a zonal wavenumber 1 feature model f was used as a surrogate for model t fig 2e h show the sst from the integration of model f initialized with the model t state vector on day 50 that was first subsampled on the model f grid comparison with fig 2a d indicates that the model f solution diverges from the parent model t circulation over time as anticipated the model f solution is less energetic than model t as illustrated in fig 2m which shows the time series of the domain integrated kinetic energy ke computed from the vertically integrated velocity during the period shown the model t ke continues on an upward trajectory indicating that the circulation has not yet reached an equilibrium the available potential energy ape is still being converted to ke as the instabilities develop conversely the model f ke asymptotes quickly and then undergoes a slow decline over time indicating that in this case the conversion of ape to ke is offset by dissipation recall that there is no surface forcing and the relaxation term is weak 3 2 strong and weak constraint 4d var the model t circulation between days 50 and 110 cf fig 2a d was used as a surrogate for the true ocean circulation this 60 day time interval was divided into 2 day windows and simulated observations drawn from model t during each window were assimilated into model f using 4d var during the resulting 30 analysis cycles the 4d var analysis at the end of each time window was used as the background estimate x b at the start of the next cycle the background circulation for the first cycle was chosen to be the model t circulation on day 49 subsampled on the model f grid the observations were all in the form of vertical profiles of temperature over the upper 1000 m of the water column only regularly spaced in the horizontal and in time observations were available at times corresponding the beginning middle and end of each 2 day analysis cycle and sampled every 60 km corresponding to every third model f horizontal grid point yielding 26 000 observations per 2 day assimilation window random observation errors with zero mean and a standard deviation of 0 1 c were added to each datum the observation errors were assumed to be mutually uncorrelated a reasonable assumption for independent vertical profiles so the observation error covariance matrix r is diagonal the diagonal elements of r correspond to an error standard deviation of 0 22 c a combination of the measurement error and an assumed error of representativeness with a standard deviation of 0 2 c the background error covariance matrix b was estimated using the identical twin experiments described by sma who used a similar model configuration with 10 km horizontal grid spacing specifically the standard deviations and typical correlation length scales of the background errors were computed from the sma circulation estimates and then used in the roms 4d var model for b which is based on the diffusion operator approach of weaver and courtier 2001 in addition the balance operator of weaver et al 2005 was also employed both strong and weak constraint 4d var experiments were performed in the strong constraint case model f is assumed to be free of errors and the 4d var control vector comprises only the model initial conditions however imperfections in model f arise from poor horizontal resolution and errors associated with imperfect parameterizations therefore in the case of weak constraint 4d var the control vector is augmented with a correction for model error η t that is applied at every grid point and every time step in model f similarly the background error covariance matrix b in 2 is replaced by d diag b q where q is the model error covariance matrix the matrix q describes the covariance of typical model errors that develop during each 2 day assimilation cycle to estimate a time invariant q model f was initialized at the start of each 2 day window with the model t solution on the same day sub sampled on the model f grid the difference between the model f solution two days later and the corresponding model t solution was then used to estimate the standard deviation of the model error and typical correlation length scales the latter employing the semi variogram approach of banerjee et al 2004 in this way q represents the statistics of typical model errors that develop during the 2 day assimilation windows during weak constraint 4d var experiments q was modeled using a diffusion operator as for b in practice the control vector corrections η t for model error were only computed every 2 h during the weak constraint experiments and linearly interpolated to times in between so a decorrelation time of 1 day was also assumed for model error to regularize the time evolution of model error corrections this time scale is consistent with the slow time evolution of the model f minus model t differences used to estimate q in all experiments homogeneous isotropic correlation functions were employed to model b and q specifically for b q the following correlation lengths were used 150 200 km for the free surface height 75 200 km for both horizontal velocity components and 65 200 km for temperature a vertical correlation length of 200 m was used for both b and q in all experiments the simulated observations were assimilated into model f using the dual formulation of strong and weak constraint 4d var described in detail by moore et al 2011b and gürol et al 2014 fig 2i l show the model f sst from the strong constraint 4d var analyses on selected days a comparison with the true solution fig 2a d confirms that data assimilation can recover the majority of the model t circulation features that are resolved by the model f grid the weak constraint circulation analyses are very similar to those in fig 2i l not shown data assimilation also energizes the circulation as shown in fig 2m which shows a time series of ke from both the strong and weak constraint analyses during each 4d var cycle ape is added by the observations thereby propping up the isotherms and leading to elevated ke through baroclinic conversion processes the discrete jumps in ke between 4d var cycles are very evident in fig 2m furthermore fig 2m also shows that the weak constraint forcing term η t often further energizes the analyses 4 properties of the error covariance matrix as discussed in section 2 the properties of the analysis and forecast error covariance matrices associated with the model f experiment are of interest these provide quantitative information about the veracity of the 4d var analyses and ensuing forecasts in this section we will first explore some general properties of the expected error covariance matrices arising from the infinite ensemble of perturbed 4d var analyses described in sections 2 2 and 2 3 the perturbed 4d var analyses are described in appendix b 4 1 the determinant the determinant of a covariance matrix can be expressed as the product of its eigenvalues furthermore the associated eigenvectors define the direction of the semi major axes of a multi dimensional hyper ellipsoid while the square root of each eigenvalue represents the axes lengths therefore the determinant of the covariance matrix is of interest because it is proportional to the squared volume of the hyper ellipsoid specifically the determinant of a covariance matrix is proportional to the squared hyper volume of all ocean states for which the error is smaller than one standard deviation therefore in the case of the analysis error covariance a smaller determinant indicates a more precise estimate of the ocean state from the data assimilation system as shown in section 4 3 the temporal evolution of the determinant of a covariance matrix also provides information about the flow of probability through the system as noted in appendix c for the large dimension problem considered here 105 it is not practical to explicitly compute the analysis and forecast error covariance matrices therefore as described in appendix c the determinants of the energy weighted analysis error covariance matrix u a n u t and forecast error covariance matrix u f n t u t were estimated using the monte carlo method of bai et al 1996 an approach that invokes the lanczos algorithm golub and van loan 1989 to estimate the eigenvectors of each matrix iteratively also the bai et al method places upper and lower bounds on the determinant estimates using the paternal twin approach described in section 3 the simulated observations from model t were assimilated into model f using a single outer loop and 25 inner loops a choice based on the experience of sma since a single outer loop is considered the subscript n will be dropped in the sequel if no data are assimilated k 0 and 3 reduces to a τ b the volume of the hyper ellipsoid d e t ub u t 1 2 is therefore a useful benchmark as noted in section 3 2 the balance operator of weaver et al 2005 was also employed in the parameterization of b however since the balance operator is only weakly flow dependent b varies very little from one data assimilation cycle to the next this is illustrated in fig 3a which shows an estimate of ln d e t ub u t 1 2 i e a measure of the natural log of the hyper ellipsoid volume based on the energy norm black circles because of the large dimension of the system considered here 105 the approach is computationally very demanding so estimates of the determinant were only computed every 4th analysis cycle the volume of the hyper ellipsoid defined by the expected analysis error covariance matrix at the beginning of each analysis cycle i e t τ in fig 1 is given up to a constant of proportionality by d e t ua τ u t 1 2 a time series of ln d e t u a τ u t 1 2 is shown in fig 3a dark blue circles for every 4th strong constraint 4d var cycle and indicates that the analysis error covariance hyper ellipsoid volume at time t τ is indistinguishable from that associated with b fig 3a red circles also shows a time series of the hyper ellipsoid volume defined by the expected analysis error variance at the end of the same strong constraint 4d var cycles i e t 0 which is given by d e t ua 0 u t 1 2 d e t u m b 0 τ a τ m b t τ 0 u t 1 2 the volume of the error hyper ellipsoid subspace can be seen to decrease in time during the analysis window following the usual operational practice the strong constraint 4d var analyses at the end of each analysis cycle t 0 in fig 1 were used as the initial conditions for each forecast cycle fig 3a also shows time series of the hyper ellipsoid volume defined by the expected forecast error covariance uf t u t for forecast lead times t of 2 green circles 6 magenta circles 12 cyan circles 18 red triangles 22 blue triangles 26 green triangles and 30 days orange circles duration fig 3a indicates that the forecast error covariance hyper ellipsoid volume generally collapses as the forecast lead time increases the exception is early on in the analysis forecast experiment during cycles 2 and 6 where there is an indication that the 30 day forecast error hyper ellipsoid expands again although for this case fig 3a indicates that the uncertainties are larger the properties of the circulation through time associated with this behavior will be explored later another remarkable feature of fig 3a is that for a given lead time the hyper ellipsoid volume varies very little from cycle to cycle excepting the 30 day forecasts the generally observed collapse of the hyper ellipsoid volume is consistent with a slow decline in the forecast circulation energy as illustrated in fig 2m which shows time series of ke for three representative cases in each example the ke slowly decreases over time and is at all times lower than that of the 4d var analysis on the same day 4 2 the trace the trace of the leading diagonal of the energy weighted analysis error covariance matrix ua u t and forecast error matrix uf t u t represents the expected total error variance in each case the trace of a matrix can additionally be expressed as the sum of the eigenvalues the trace of each covariance matrix was also estimated iteratively using the method of bai et al 1996 and time series are shown in fig 3b for every 4th analysis forecast cycle the trace estimates generally converge faster than the estimates of the determinant which is reflected in the smaller error bars in fig 3b fig 3b suggests two different types of behavior for the total variance during the first 10 15 cycles the total error variance decreases steadily from the background value through the analysis cycle and out to around forecast day 6 12 after which error variance increases again with increasing forecast lead time thus during these cycles while the volume of the hyper ellipsoid is collapsing cf fig 3a it is becoming very elongated in the direction of some semi major axes conversely after cycle 15 fig 3b shows that the total error variance generally decreases out to around forecast day 22 and significant elongation of the hyper ellipsoid is delayed the mechanics of this behavior are explored further in section 5 while it is computationally prohibitive to compute trace estimates for every analysis forecast cycle using the method of bai et al 1996 a less demanding approach can be used based on a randomized trace estimate method described by fisher and courtier 1995 in this case an estimate of the trace of the positive definite matrix c can be computed according to t r c 1 m i 1 m v t cv where v is a random vector drawn from the normal distribution n 0 1 and m is the sample size while this procedure is computationally less demanding than the method of bai et al 1996 the resulting trace estimates are less accurate nonetheless they provide useful information about the behavior of the total error variance during all cycles the percentage expected error in the trace estimate in this case is given by 100 2 m 1 2 in the following examples m 30 which yields trace estimates with an expected error 13 which is deemed adequate for exploring the general behavior of the total error variance since the trace estimates for different lead times are distinguishable the relative performance of the two trace estimation methods employed in this study is further documented in appendix c time series of the trace estimates using the alternative randomized trace estimate approach are shown in fig 3c for every 2 day strong constraint analysis forecast cycle and confirm the same general behavior noted above fig 3c also shows the total expected forecast error variance for forecasts initialized by analyses computed using weak constraint 4d var in general the forecast error variance displays behavior that is similar to forecasts initialized from the strong constraint analyses however there are some cycles where the response is quite different e g the 30 day forecasts for cycles 10 15 as noted earlier fig 2m indicates that the weak constraint circulation estimates are frequently more energetic than their strong constraint counterparts it is therefore reasonable to assume that during such times the model error forcing η t provides additional ape during the analysis cycle that in turn yields a more unstable forecast state and larger forecast error variance 4 3 the flow of probability the time evolution of the determinant of a covariance matrix provides quantitative information about the flow of probability through the analysis forecast system following the notation introduced in section 2 1 the time evolution of the forecast state vector x f can be represented as d x f d t m x f where m represents the non linear roms model if as before ε t denotes the error in the forecast then to 1st order 11 d ε d t φ f t ε t ς t where φ f m x x f is the jacobian of m describing the tangent linearization of m about x f and ς t represents model error ideally φ f would represent a linearization of m about the true state which of course is never known however as discussed in section 2 2 the evolution of perturbations around the reference forecast x f are used as a surrogate for describing forecast errors in which case x f represents the ensemble mean or more formally the expected value of x and φ f describes the time evolution of each member of the infinite ensemble of perturbations ε t it is well known gardiner 1985 that the probability density function pdf of the forecast errors ε ε i in 11 is described by the fokker planck equation 12 p t i 1 n a i p ε i 1 2 i 1 n j 1 n 2 q i j p ε i ε j where p p ε t ε 0 is the conditional probability of the error ε t given the initial condition ε 0 a i are the elements of the vector field a t generated by φ f i e a t d ε d t φ f t ε t and q i j are the elements of the model error covariance matrix q e ς ς t by analogy with the advection diffusion equation a t plays the role of a velocity that advects the mean of the pdf through state space and is commonly referred to as the drift vector or drift velocity since in general the divergence of the drift velocity does not vanish a t will also influence the width of the pdf the second term on the right hand side of 12 is associated with the stochastic forcing ς t in 11 and is referred to as diffusion since q q i j acts like a diffusion matrix that broadens the pdf following gardiner 1985 12 can be recast as p t i 1 n c i ε i where the vector c i a t p 1 2 j 1 n q i j p ε j is a probability current and i 1 n c i ε i is the total divergence the presence of stochastic model error ς t is only considered during the analysis cycle in the case of weak constraint 4d var since no allowance is made here for model error during a forecast it does not factor into the covariance calculations based on 7 thus we will drop the diffusion term from further analysis in this case q 0 and the time evolution of the forecast error covariance matrix uf t u t e uε t ε t t u t is given by 13 d uf u t d t u φ f u 1 uf u t uf u t u φ f u 1 t using jacobi s formula d d e t uf u t d t t r a d j uf u t d uf u t d t the cyclic properties of the trace and the associative property of determinants it can be shown that 14 d ln d e t f 1 2 d t t r φ f t which relates the time rate of change of the volume of the hyper ellipsoid defined by the forecast error covariance to the trace of the tangent linear model note that the result expressed by 14 is independent of the choice of u by virtue of the similarity invariance of u φ f u 1 choosing q i j 0 in 12 leads to liouville s equation where the rate of change of the pdf depends only on the drift velocity a t φ f t ε t the total divergence of the drift velocity is given by i 1 n a i ε i t r φ f which according to 14 controls the rate of change of volume of the hyper ellipsoid associated with the forecast error covariance matrix to illustrate this result fig 4a and b show time series of t r φ f based on 14 for cycles 2 and 26 near the beginning and end of the experiment period respectively the time rate of change of ln d e t f was estimated by fitting a 6th order polynomial to the data in fig 3a 1 1 from the associative properties of the determinant d ln d e t uf u t 1 2 d t 1 2 d ln d e t u 2 d e t f d t 1 2 d 2 ln det u ln d e t f d t d ln d e t f 1 2 d t for the case here where u is a time invariant diagonal matrix as shown in fig 3a the hyper ellipsoid volume collapses over time through to a forecast lead time 25 days thus in both cases t r φ f 0 through forecast lead time of 25 days indicating that the drift velocity a t associated with the probability current is convergent although the rate of convergence decreases with increasing lead time this suggests that probability becomes more concentrated in state space as the forecast lead time increases consistent with a collapse of the pdf in other words the volume of the sub space occupied by all possible forecast errors ε t is also decreasing this will be further quantified shortly while the drift velocity remains convergent beyond day 25 during cycle 26 fig 4a shows that it eventually becomes divergent in the case of cycle 2 consistent with fig 3a indicating that the probability density begins to decrease as the forecast error hyper ellipsoid subsequently expands 4 4 state space volume in the absence of stochastic model error i e ς t 0 solutions of 11 can be written in a compact form as ε t m f 0 t ε 0 where m f 0 t is the tangent linear propagator matrix introduced in section 2 1 similarly the forecast error covariance matrix can be expressed as uf t u t u m f f 0 m f t u t based on the associative property of determinants it is easy to show that 15 ln d e t m f 0 t 1 2 ln d e t f t d e t f 0 geometrically any matrix can be viewed as transforming a unit volume multi dimensional hyper cube into a multi dimensional parallelepiped which in turn is defined by the rows of the matrix the determinant of a matrix is then the volume of the resulting parallelepiped thus d e t m f 0 t in 15 represents the volume of state space occupied by the forecast errors ε t it also follows from 14 and 15 that d e t m f 0 t exp 0 t t r φ f τ d τ which is another form of the liouville equation arnold 1998 fig 4a and 4b show the time series of ln d e t m f 0 t for cycles 2 and 26 respectively in both cases the volume of state space occupied by the forecast errors decreases with increasing lead time although for cycle 2 there are signs of an increasing tendency around day 28 consistent with the transition in the drift velocity from convergent to divergent conditions therefore the sub space where the forecast errors reside becomes more certain in line with the concentration of probability and the collapse of the forecast error covariance hyper ellipsoid 5 empirical orthogonal functions in this section the topology of the space described by the expected analysis and forecast error covariance matrices is explored 5 1 geometric interpretation the directions in state space of the semi major axes of the hyper ellipsoids discussed in section 4 are represented by the eigenvectors of the error covariance matrices ua u t and uf t u t these same eigenvectors are more commonly referred to as empirical orthogonal functions eofs and the associated eigenvalues represent the error variance explained by each eof in the present case the dimension n of the hyper ellipsoid is o 105 which would also be the total number of eofs the eof spectrum for either ua u t or uf t u t can be calculated iteratively using the lanczos algorithm golub and van loan 1989 while the lanczos algorithm can provide an estimate of the entire eof spectrum the leading members of the spectrum typically emerge to acceptable precision first when the number of iterations is much less than n therefore this is a convenient way to reliably calculate the leading eofs fig 5a shows the eigenvalues associated with the leading 20 eofs of the expected analysis error covariance matrix at the beginning dark blue line and end red line of a representative strong constraint analysis cycle in both cases the leading portion of the eof spectrum is quite flat also shown in fig 5a are the eigenvalues of the leading eofs of the expected forecast error covariance for 2 6 12 and 30 day forecast lead times as the forecast lead time increases fig 5a reveals that the eof spectrum becomes increasingly peaked with the leading eof accounting for a larger fraction of the total variance fig 5b shows the eigenvalue λ 1 associated with the leading eof of ua τ u t ua 0 u t and uf t u t for t 2 30 days for each cycle for most cycles it is apparent that the amplitude of the leading eigenvalue decreases through the analysis cycle from t τ to t 0 and through the forecast cycle to t 2 days for t 2 days the leading eigenvalue increases with lead time also shown in fig 5b are the leading eigenvalues of uf t u t for 2 and 12 day forecasts initialized with weak constraint 4d var analyses the behavior is similar to that of the strong constraint cases although again some cycles 18 19 and 23 are remarkably different as noted in section 4 2 the weak constraint 4d var corrections for model error η t applied during the analysis cycle tend to energize further the forecast initial conditions cf fig 2m which in turn can influence the eof spectrum the cumulative variance explained by the leading 30 eofs of the expected analysis and forecast error covariance is shown in fig 5c for each strong constraint 4d var analysis forecast cycle in each case the randomized trace estimates of the total expected error variance from section 4 2 were used and error bounds are also indicated in fig 5c based on the expected 13 error in the trace estimates fig 5c shows that the fraction of variance explained by the leading eofs is typically low during the analysis cycle and for short forecast lead times this is consistent with the relatively flat nature of the spectrum fig 5a however the fraction of the total variance explained typically increases with increasing forecast lead time and for t 30 days is close to 100 fig 5c shows that while during some cycles the cumulative variance explained for the t 30 days case appears to exceed 100 the error bars in fig 5c indicate this can be attributed to the uncertainty in the total variance estimates additional calculations for selected cycles suggest that the fraction of explained error variance increases very slowly beyond the leading 30 or so eofs not shown the results presented here indicate that even though the hyper ellipsoid volume is collapsing as the forecast lead time increases cf fig 3a it is not collapsing uniformly in all directions in fact it is becoming more elongated along the directions described by the leading few eofs cf fig 5b furthermore as the forecast lead time increases most of the forecast error is described by a small number of growing directions cf fig 5c this agrees with experience in numerical weather prediction e g phillips 1986 houtekamer 1993 5 2 error structures the sea surface temperature structure of the leading eof at each stage of the analysis and forecast cycle for various lead times is shown in fig 6 for cycle 6 using strong constraint 4d var the sst analysis for this cycle is also indicated for reference in fig 6a fig 6b shows that the leading eof at the beginning of the analysis window t τ in fig 1 comprises coherent mesoscale structures however this eof accounts for only 0 5 of the total expected analysis error variance in the subspace constrained by 4d var on this day by the end of the analysis cycle t 0 in fig 1 the influence of the time evolution of the circulation on the leading covariance structure is evident in fig 6c at this time the eof comprises generally smaller scale structures that wrap around the meanders and eddies of the circulation although the explained variance is still only 0 5 as the forecast lead time increases fig 6 shows that the horizontal scale of the leading eofs decreases even further targeting specific areas of the evolving meanders in the circulation that are evident in the analysis of fig 6a furthermore the fraction of the variance explained by the leading eof increases with forecast lead time and in the case of a 30 day forecast fig 6g it is 42 for this particular cycle the leading eofs of uf u t can also account for much of the actual measured forecast error variance and structure for example fig 7a d shows the spatial distribution of the rms forecast errors for 12 day forecasts initialized from the strong constraint 4d var analyses from cycles 21 30 the forecast errors are computed relative to the 4d var analysis valid on the forecast day also shown in fig 7e h is the forecast error explained by the leading 30 eofs of the expected forecast error covariance matrix uf u t while the amplitude of the error is underestimated it is clear much of the structure of the actual forecast errors is captured by the leading 30 eofs even though they only capture 40 of the total variance cf fig 5c 5 3 forecast error variance as a predictor of forecast skill in operational ensemble numerical weather prediction systems the spread of the ensemble about the ensemble mean is used as a surrogate for the forecast error variance epstein 1969 leith 1974 and can be of considerable utility because under some circumstances it can be used as a predictor of the skill of the ensemble mean e g barker 1991 molteni et al 1996 specifically if the ensemble spread is small large this can be an a priori indicator of a skillful unskillful forecast however identification of robust forecast spread skill relationships so called reliability has generally proved elusive because such a relationship can depend on many factors for a perfect forecast model statistical considerations indicate that ensemble spread is only a good predictor of skill in cases where day to day variations in the spread are significant compared to the climatological variance houtekamer 1993 whitaker and loughe 1998 however even in this case the maximum correlation between the spread and skill that one can expect is 0 8 conversely when the day to day variations in ensemble spread are small compared to climatology there is generally a very low correlation between spread and skill the correlation between ensemble spread and forecast skill also depends on the choice of metrics used hopson 2014 furthermore imperfections in the forecast model compound the problem and it is generally necessary to calibrate the ensemble in some way to account for the influence of model error a review of the extensive literature on ensemble numerical weather prediction reveals a range of experiences regarding the relationship between spread and skill see grimit and mass 2007 for a review as noted in sections 2 2 and 2 3 for the experimental set up considered here x f represents the mean of an infinite ensemble of forecasts i e the expected value of x thus it is of interest to explore the extent to which the forecast error variance given by the diagonal elements of uf t u t aka the spread can be used as a predictor of the skill of x f fig 7i l show the total expected error variance i e spread in 12 day forecasts initialized from the strong constraint 4d var analyses of cycles 21 30 based on the leading 30 eofs of the forecast error covariance matrix a comparison with fig 7a d indicates that by and large regions of high spread generally correspond to areas where the forecast errors are largest while the agreement is not perfect it is encouraging further investigation is warranted to more formally quantify the relationship between forecast skill and expected forecast error variance for the circulation environment considered here this will be the subject of a future study 6 non normal and modal error growth 6 1 hessian singular vectors following ehrendorfer and tribbia 1997 the eofs of the forecast error covariance matrix uf t u t are in fact the left singular vectors of the matrix l t u m f 0 t a 0 1 2 where recall that m f 0 t is the propagator of the tangent linear model linearized about the forecast x f see fig 1 singular value decomposition of l yields 16 l t ψ i λ i 1 2 s ı l s ı λ i 1 2 ψ i where ψ i represent the eofs and s ı are the right singular vectors introducing the scaled singular vector s i a 0 1 2 s ı the associated eigenvalue problem for s i becomes m f t t 0 u t u m f 0 t s i λ i a 0 1 s i subject to the orthonormality condition s i t a 0 1 s j δ i j where δ i j is the kronecker delta function the vectors s i are referred to as the hessian singular vectors barkmeijer et al 1998 so called because a τ 1 is the hessian of the 4d var cost function for convenience the name is carried over here to a 1 at other times during the analysis window from the orthonormality condition the hessian singular vectors s i define a unit hyper sphere at the forecast start time t 0 however during the forecast interval the hessian singular vectors evolve into the eofs according to ψ i λ i 1 2 u m f 0 t s i and the unit hyper sphere evolves into the hyper ellipsoid described by the forecast error covariance discussed in section 4 therefore associated with each eof ψ i there is a unique hessian singular vector that over the forecast interval evolves into the eof sma demonstrated that for eofs like those shown in fig 6 the evolution of the hessian singular vectors proceeds via an upscale transfer of energy which means that the forecast errors move to larger scales over time to illustrate fig 8 shows the sst structure of the leading hessian singular vector and associated eof for a representative cycle and clearly displays the upscale transfer of energy in the forecast error sma also demonstrated that hessian singular vectors like that in fig 8a typically grow more rapidly than the most unstable eigenmodes of m f 0 t explored in section 6 2 indicating that the upscale transfer of energy is linked to the interference of the non normal eigenmodes of the underlying time evolving circulation which plays an essential role in forecast error growth 6 2 finite time normal modes the fastest growing eigenmodes of m f 0 t play an essential role in error growth as the forecast lead time increases the eigenvectors of m f 0 t in 10 are often referred to as finite time normal modes ftnms if we denote by ν i ξ i the complex eigenpairs of m f 0 t then υ i 2 is the factor by which any measure of the amplitude of ftnm ξ i changes over the time interval 0 t fig 9a shows υ 1 2 for the leading ftnm ξ 1 as a function of forecast lead time for two cycles that reflect the different behavior of the total variance cycle 9 where total variance first decreases and later increases and cycle 23 where total variance continually decreases with increasing lead time cf fig 3b and c error growth is possible in both cases since υ 1 2 1 in fig 9a for cycle 9 the growth factor υ 1 2 generally increases with lead time while for cycle 23 υ 1 2 changes very little with lead time for an unstable circulation we would usually expect υ 1 2 to increase steadily with forecast lead time and for the autonomous case υ 1 2 would increase exponentially with t therefore a more useful measure of ftnm growth is υ 1 2 t an indicator of the average growth rate fig 9b shows υ 1 2 t versus lead time t for the same two forecast cycles during forecast cycle 9 the average growth rate of ξ 1 decreases during the first 10 days remains low until around t 20 days and increases again for longer lead times this behavior is similar to that of the forecast error variance in fig 3b and c during the same cycle similarly the average growth rate of ξ 1 for forecast cycle 23 decreases with lead time t mirroring the behavior of the forecast error variance during this cycle in fig 3b and c the structure of the eofs for long forecast leads times is also controlled by the most unstable ftnms to illustrate this suppose for a moment that forecast error ε is due solely to the leading unstable ftnm in general the eigenvectors of m f 0 t will form complex conjugate pairs if the leading eigenmode is complex it must be combined with its complex conjugate to yield a real perturbation in which case ε t c t ξ 1 c t ξ 1 in this example where c t is the complex amplitude if we assume that the real and imaginary components of c t are gaussian random variables with zero mean and variance σ 2 then the forecast error covariance is given by e ε t ε t t 4 σ 2 r e ξ 1 r e ξ 1 t i m ξ 1 i m ξ 1 t this will be at most a rank 2 matrix and the two eofs will be given by linear combinations of the real and imaginary components of ξ 1 in the general case several of the leading ftnms will contribute to ε and the eofs will reflect the structure of several modes to illustrate fig 9c and d show the sst structure of the real component of ftnm ξ 3 and eof ψ 1 respectively for the 30 day forecast initialized from the 4d var analysis of cycle 10 in this case there are several growing ftnms with similar growth factors υ 2 is 40 31 12 and 6 for the leading four ftnms and the eof is clearly controlled by ξ 3 in this case fig 9e and f on the other hand show the sst of ξ 1 and eof ψ 2 which are very similar for shorter forecast lead times the link between the leading eof structures and the most unstable ftnms is less pronounced not shown the emergence of coherent and persistent error structures associated with the most unstable ftnms is also reflected in the properties of the auto covariance matrix of the forecast errors uf t t u t e uε t ε t t u t using again jacobi s formula the cyclic properties of the trace and 14 it follows that d ln d e t f t t d t d ln d e t f t f t 1 2 d t where f t and f t are the zero lag forecast error covariance matrices at time t and t respectively fig 4 includes time series of d ln d e t f 30 t d t versus t for 30 day forecasts during cycles 2 and 26 while the volume of the hyper ellipsoid d e t uf 30 t u t 1 2 behaves qualitatively like that associated with f t f t t in fig 3a not shown fig 4 reveals that the rate of change of volume increases as the covariance lag t t decreases therefore the coherence between the spatial structures of the forecast errors ε t at different lead times is increasing which is consistent with the emergence of the most unstable ftnms 6 3 non linearity the dynamics of perturbation growth in shear flows associated with normal modes and the interference of modes is a well understood process e g pedlosky 1979 farrell and ioannou 1996 and perturbations can grow by extracting energy from the underlying time evolving circulation via the familiar processes of baroclinic and barotropic energy conversion this is an appropriate and convenient framework for the evolution of forecast errors considered here since recall we are using energy as the common currency for the various components of the state vector to compute the error covariance matrix in general the same processes that control the formation of the eddies and meanders in model t are also responsible for the growth of forecast errors in model f with this in mind the evolution and properties of the forecast errors will depend on the degree of non linearity of the underlying reference forecast x f cf fig 1 since the processes involved act as the source of energy in the tangent linear model as a measure of the importance of non linearity fig 10a shows the mean local rossby number denoted ζ f averaged over a 400 km wide zonal strip centered in the middle of the model domain i e where the circulation variability is most energetic see fig 2 and computed from the daily averaged surface flow fig 10a indicates that non linearity has the greatest influence on the circulation during the first 10 15 analysis forecast cycles while ζ f reaches modest values 0 2 during these cycles this nonetheless represents a significant departure from the linear quasi geostrophic regime indeed maximum instantaneous in situ values of ζ f can be significantly larger and are o 1 in some cases not shown during this phase of the experiment fig 2a and b indicate that the growth of a zonal wavenumber 2 instability dominates the model t circulation beyond cycle 15 the mean rossby number is generally at or below 0 1 when maximum instantaneous in situ values of ζ f are also lower not shown for these analysis forecast cycles the model t circulation is dominated by the evolution of a zonal wavenumber 1 instability cf fig 2c and d despite the difference in resolution model f mimics the temporal evolution of ζ f for model t although as expected the rossby number is larger in model t not shown fig 10a indicates that the elevated rossby numbers during the first 10 15 cycles occur at short forecast lead times and then taper off suggesting that there will be significant sources of perturbation energy i e forecast error variance during the early phase of these forecasts the subsequent increase in total forecast error variance t r uf t u t i e energy at longer lead times during these analysis forecast cycles as revealed by fig 3b suggests that the stretching of the hyper ellipsoid and the increase in the associated hyper ellipsoid volume in a few cases is due to the sustained growth of perturbations that are excited early in the forecast period and that significantly project onto the fastest growing ftnms that eventually emerge as coherent patterns of error as shown by sma some of this growth is likely to be enhanced by non normal interference of the modes and an upscale transfer of forecast error variance as evidenced by the behavior of the hessian singular vectors discussed in section 6 1 fig 10b shows the spatial variations in the root mean square of ζ f for 12 day forecasts initialized from 4d var cycles 21 30 the regions of elevated rossby number in fig 10b correspond closely with the hot spots of high expected forecast error shown in fig 7i l the resemblance is striking for ssh fig 7i and sst fig 7j and confirms the role of non linearity in controlling local forecast error growth and forecast skill 7 summary and conclusions this paper focuses on the properties of the expected analysis and forecast error covariance matrices that result from 4d var data assimilation analyses of the mesoscale circulation environment that develops in the presence of a baroclinically unstable oceanic temperature front given the ubiquitous nature of this process in the ocean the findings of this work should be widely applicable a novel aspect of this study lies in the methodology used specifically the tangent linearization of the full data assimilation system and its adjoint were used to compute an explicit operator for the expected error covariance this has considerable appeal over other methods such as ensemble approaches that are commonly used to estimate analysis and forecast error covariance matrices since the covariance operator is free of the limitations associated with ensemble size localization methods etc the downside of our approach however is the considerable computational expense involved nevertheless the technique can be applied to modestly sized data assimilation problems of significant theoretical interest such as the case considered here a significant advantage of our method over that computed from an ensemble is that as noted in section 2 eqs 7 and 8 provide an explicit operator for the analysis error covariance matrix and eq 9 for the forecast error covariance matrix which can be used to interrogate intrinsic properties of the system as here using established methods and results of linear algebra our general findings are summarized in fig 11 which shows a schematic of the behavior of the forecast error covariance matrix for two representative forecast cycles that depict the two different scenarios identified these two scenarios are characterized by the development of baroclinically unstable waves with a wavelength corresponding to one channel width zonal wavenumber 1 and one half channel width zonal wavenumber 2 sma computed the growth rates of these two waves and found that the zonal wavenumber 2 instability has a faster growth rate and so it emerges first within the model simulations i scenario 1 the first scenario corresponds to the period spanned by the first half a dozen or so analysis forecast cycles the observed circulation environment is characterized by a fully developed zonal wavenumber 2 instability that subsequently decays during the time interval spanned by the ensuing 30 day forecasts the behavior of the forecast error covariance during this period is summarized in fig 11a using cycle 6 as a representative example fig 11a shows a time series of the forecast error energy for this cycle as a function of forecast lead time and computed from the difference between the forecast state and the 4d var analysis on the same day the initial and final time sst for the forecast are also shown in fig 11a and reveal the decay of the zonal wavenumber 2 instability during the forecast the forecast error grows out to a lead time 20 days after which time it levels off during the error growth phase of this forecast cycle the volume of the hyper ellipsoid associated with the forecast error covariance matrix decreases cf fig 3a which is associated with a convergent drift velocity in the liouville equation that describes the time evolution of the forecast error pdf cf fig 4a for cycle 2 which displays similar behavior to cycle 6 shown here at the same time the total forecast error variance decreases cf fig 3b and the hyper ellipsoid stretches along the directions described by the leading eofs as described in section 5 1 this initial phase of forecast error growth is illustrated schematically in fig 11a by the red ellipsoids during the period beyond forecast day 20 when the forecast error asymptotes to a more constant level the pdf drift velocity becomes divergent cf fig 4a and the forecast error covariance hyper ellipsoid begins to expand cf fig 3a at the same time the total forecast error variance increases cf fig 3b and the hyper ellipsoid is preferentially stretched along the directions associated with the fastest growing ftnms this phase of the forecast error development is also illustrated in fig 11a ii scenario 2 the second scenario in the experiments considered here corresponds to the growth and development of the zonal wavenumber 1 instability that follows after the decline of zonal wavenumber 2 the behavior of the forecast error covariance during this period is summarized in fig 11b using cycle 30 as a representative example the forecast error energy in this case increases during the entire forecast cycle as shown in fig 11b the initial and final time sst for the forecast are also shown in fig 11b and reveal the emergence of the wavenumber 1 instability during the entire forecast cycle in this case the volume of the forecast error covariance hyper ellipsoid decreases cf fig 3a and the pdf drift velocity in the liouville equation remains convergent cf fig 4b for cycle 26 which displays similar behavior to cycle 30 shown here the total forecast error variance at first decreases until around forecast day 18 and then slowly increases cf fig 3b throughout the forecast the hyper ellipsoid stretches along the directions described by the leading eofs as the fastest growing ftnm begin to emerge as illustrated schematically in fig 11b by the red ellipsoids the temporal behavior of hyper ellipsoid volume and total error variance can be further appreciated by appealing to a simple example consider the 2 2 covariance matrix c with eigenvectors λ 1 and λ 2 the total variance is given by λ 1 λ 2 and the determinant by λ 1 λ 2 in cases where the variations in λ 1 λ 2 and λ 1 λ 2 are positively correlated there is no significant restriction on the relative amplitude of λ 1 and λ 2 conversely during times when λ 1 λ 2 increases and λ 1 λ 2 decreases there must be a disparity in the amplitude of the eigenvalues therefore considerable stretching of the error ellipse associated with c will occur along one axis the same principle applies in higher dimensions and illustrates the geometric factors that control the variations in the topology of the hyper ellipsoid associated with the variations of the determinant and trace of the forecast error covariances in fig 3 the close connection between the eofs of forecast error and the ftnms also suggests a disparity in the spectrum of ftnm growth rates which in turn favors non normal forecast error growth due to the interference of the ftnms farrell and ioannou 1996 indeed sma confirmed that non normal growth occurs in this same system leading to up scale energy transfer in the forecast errors as the leading eofs and ftnms emerge cf fig 8 therefore in general forecast errors at small scales are liable to self organize into larger scale coherent structures the difference in the temporal evolution of the forecast error energy between the two cases considered in fig 11 deserves some further comment the leveling off of the forecast error energy in fig 11a may perhaps be associated with non linear saturation of the forecast error amplitude if that is the case then the forecast error covariance uf u t during this phase of the forecast would be largely time invariant i e stationary error statistics in which case the determinant and trace would remain constant in time this is at odds though with fig 3 however eq 13 which describes the time evolution of the forecast error covariance is predicated on the tangent linear assumption in this case the behavior of the total forecast error variance and hyper ellipsoid volume beyond forecast day 20 in fig 3 could perhaps be a symptom of linearization errors indeed the analysis in fig 9b does indicate that during the period under consideration the average growth rate of the leading ftnm receives a boost around forecast day 20 eq 14 provides additional evidence in that the eigenspectrum of the tangent linear operator φ f t comprises complex conjugate pairs of eigenvectors and eigenvalues the real part of the eigenvalues represents the instantaneous growth rate of forecast errors associated with these eigenvectors thus t r φ f equals twice the sum of the instantaneous growth rates of the instantaneous eigenvectors therefore the change in sign of t r φ f in fig 4a is indicative of a switch from predominantly decaying instantaneous modes of φ f to predominantly growing modes however for the non autonomous cases considered here there is no clear relationship between the instantaneous eigenvectors of φ f t and the ftnms of m f 0 t furthermore while fig 11a shows what we believe to be the behavior during a representative example of scenario 1 other forecast cycles during this period exhibit a decline in forecast error energy at a lead time beyond 20 days not shown which is inconsistent with non linear saturation of error amplitude besides it is by no means clear why the forecast error energy during scenario 2 would not saturate over the same forecast lead time if this is indeed the explanation for the behavior during scenario 1 further analysis of these issues and behaviors is clearly warranted there are some critical limitations of the present study that should be mentioned here first no attempt was made to account for model error in calculating the expected analysis and forecast error covariances model error is an unavoidable facet of all real forecast systems so including its influence in the approach presented here represents an important next step indeed the fokker planck equation 12 indicates that the addition of the diffusion term would introduce additional and important influences on the forecast error pdf nonetheless fig 7 shows that even when model errors are not accounted for the expected forecast error covariances can still faithfully describe actual error growth and predictability caution should be exercised here since even though the forecast model employed in this study is imperfect relative to the observed model the paternal twin approach adopted in our experiments is unlikely to mimic actual model errors truly a second limitation of our study is the absence of surface forcing as discussed in section 2 surface forcing can play an important role in frontogenesis and frontolysis the inclusion of forcing and the attendant uncertainties in our experiments would undoubtedly increase the diversity of possible ocean forecast states and enhance the forecast error covariance finally while the time scales in fig 11 refer to the experiments presented in this paper the very general nature of the dynamical processes at work in the circulation considered here suggest that fig 11 may apply more broadly across the range of scales that support the formation and decay of baroclinically unstable fronts while we can offer no specific guidance on how our findings may apply more generally across different space and time scales i e mesoscale or sub mesoscale scaling analysis may shed some light on this and would be a fascinating topic for further research as noted earlier our approach is computationally demanding the computational burden required for each calculation depends on the computational resources available so it is perhaps useful to report the computation time required in terms of the time taken to run a single outer loop 4d var iteration on the computer system available with this in mind let t a represent the cpu time required to perform a single outer loop of 4d var the expected analysis error covariance matrix a n given by 7 involves evaluations of the tangent linearization of the 4d var algorithm k d and its adjoint k d t for each outer loop the cpu requirements of each integration of k d and k d t is t a therefore for an arbitrary vector u a single matrix vector product a n u requires a cpu time 2 n j 1 n j t a where n is the number of outer loops the cost of a matrix vector product of f n t u based on 10 is comparable since the additional integrations of the tangent linear and adjoint models does not add significantly to the computational cost for the case n 1 in all of the examples considered here a single matrix vector product au or f t u is 3 times the cost of a single 4d var calculation the trace and determinant calculations of section 4 using the bai et al 1996 approach described in appendix c are the most costly calculations presented in this study each data point in fig 4a is based on a monte carlo of 900 separate evaluations of au or f t u which requires 2700 t a although the same monte carlo calculation can be used to estimate the trace associated with any f a and f f t such calculations would clearly be prohibitive for problems with a dimension much larger than considered here which is o 1 0 5 conversely the trace estimate calculations using the approach of fisher and courtier 1995 in appendix c are based on 30 separate evaluations of au or f t u which require 90 t a so are much more tractable even for larger problems the cpu time required to compute the eof calculations of section 5 depends on the number of leading members of the eigenspectrum that are desired as a rule of thumb computation of reliable estimates of the n leading eofs require 2n evaluations of au or f t u and 6 n t a this study represents an intersection between a state of the art ocean analysis forecast system and the abstract ideas about forecast error development exposed by linear algebra while our approach is very computationally demanding computer power continues to increase thus it is conceivable that such calculations could be performed for larger more realistic systems in the near future indeed when the roms tangent linear and adjoint models were first developed almost two decades ago moore et al 2004 some of the calculations presented here would not have been possible with the computing facilities available to us at that time there is potentially a wealth of additional information and a deeper understanding of ocean forecast system behavior that could be mined using the approaches described here therefore we should not feel intimidated by the dimension of the everyday forecast problems at hand credit authorship contribution statement andrew m moore conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration hernan g arango methodology writing original draft writing review editing software declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by a basic research challenge grant from the office of naval research usa n00014 10 1 0476 and by southwest universities research association sura usa as part of the coastal ocean modeling testbed comt na13nos0120139 project we are grateful to the four anonymous reviewers for their positive and helpful comments and to one of the reviewers for pointing out that sparse grid methods could possibly be used to reduce the computational cost of the trace and determinant calculations appendix a energy scaling for the error covariance if we denote by ε the vector of grid point values of errors in free surface elevation ε ζ the horizontal components of velocity ε u and ε v and temperature ε t then following smith et al 2015 u is defined such that e ε t u t uε is the total perturbation energy of the errors given by a 1 e g ρ 0 2 i j ε ζ i j 2 d a i j ρ 0 2 i j k ε u i j k 2 ε v i j k 2 h i j k d a i j ρ 0 2 α g n 0 2 i j k ε t i j 2 h i j k d a i j where g is the acceleration due to gravity ρ 0 1025 kg m 3 is the mean ocean density α 1 6 1 0 4 k 1 is the thermal expansion coefficient of sea water and n 0 3 2 1 0 3 s is a representative value of the brunt väisälä frequency the summations are performed over all roms grid cells in the horizontal i j and in the vertical k where d a i j is the horizontal grid cell area and h i j k is the grid cell thickness the first term in a 1 represents the perturbation potential energy associated with errors in surface elevation the second term is the perturbation kinetic energy due to errors in the horizontal velocity and the last term is the available perturbation potential energy associated with errors in the density recall that only temperature is included in the roms configuration used here and for convenience we have assumed a linear equation of state for the density errors ε ρ ρ 0 α ε t in addition since the grid used here has uniform grid spacing d a the error norm used in all calculations was actually e d a the energy per unit area therefore u is a diagonal matrix with elements given by g ρ 0 2 1 2 g ρ 0 h i j k 2 1 2 and ρ 0 h i j k 2 1 2 α g n 0 as appropriate appendix b covariance from perturbed 4d var analyses as described by gürol et al 2014 the inverse preconditioned stabilized representer matrix r 1 hb h t i 1 in 2 is factorized in the roms dual 4d var system using the lanczos formulation of the b restricted preconditioned conjugate gradient method of gratton and tshimanga 2009 according to b 1 r 1 hb h t i 1 v m t m 1 v m t hb h t where v m is the matrix of lanczos vectors v i arising from m inner loops and t m v m t hb h t r 1 hb h t i v m is a symmetric tridiagonal matrix each lanczos vector represents a conjugate gradient descent direction and the v i are orthonormal according to v m t hb h t v m i m the lanczos vectors v m span a limited subspace of the full control space and as such the subspace orthogonal to v m will not be constrained by 4d var as described in section 2 2 the expected analysis error covariance matrix can be derived by considering an ensemble of 4d var analyses where each ensemble member is computed by perturbing the background x b and the observations y o with perturbations drawn from gaussian distributions n 0 b and n 0 r respectively each set of perturbations leads to perturbations δ v m in the lanczos vectors while the perturbed lanczos vectors will span only a small subspace of the full control space each resulting v m defined by the ensemble will span a different set of subspaces therefore the resulting ensemble of 4d var analyses will span a larger subspace than any single analysis this is illustrated schematically in fig b 1a which shows the case for m 2 fig b 1a shows the directions of the lanczos vectors v 1 and v 2 for the original unperturbed 4d var analysis the subspace that is unconstrained by the 2 inner loops is denoted as v also shown in fig b 1a drawn to scale is the standard deviation of the range of the perturbed lanczos vectors that result from an infinite ensemble clearly some of the perturbed lanczos vectors will project significantly into v thus expanding the subspace spanned by 4d var however there will still be parts of the control space that are unconstrained by 4d var for example consider fig b 1b which shows the case of m 1 for illustrative purposes in this case the subspace unconstrained by 4d var has been divided into two denoted v 1 and v 2 as shown in fig b 1b the perturbed lanczos vectors provide information about v 1 while v 2 remains unconstrained appendix c iterative methods for estimating the determinant and trace of a matrix for the large dimension problem considered here 105 it is not practical to explicitly compute the analysis and forecast error covariance matrices therefore properties such as the determinant trace and eigenspectrum must be calculated using iterative approaches two approaches have been employed in this study the first is based on bai et al 1996 hereafter bfg and is used to estimate the determinant and trace of a matrix since it is based on the lanczos algorithm it can also be used to reliably compute the leading members of the eigenspectrum the second approach is based on fisher and courtier 1995 hereafter fc while this latter approach is more straightforward to implement than bfg it only yields an estimate of the matrix trace a comparison of the trace estimates obtained from the two independent approaches provides a check on the efficacy of the results c 1 the bfg approach the diagonal elements of the real square matrix c can be expressed as the inner product c i i e i t c e i where e i is i th column of the identity matrix furthermore if f c f λ is a smooth function of the eigenspectrum λ of c then e i t f λ e i yields the i th diagonal element of the associated matrix in bfg the trace of f c f λ is replaced by an integral which can then be estimated using different gauss quadrature rules specifically bfg have developed a monte carlo approach to estimate lower and upper bounds on the inner product i u t f c u then if f λ λ the inner product i will yield upper and lower bounds on t r c similarly f λ λ 1 can provide bounds on t r c 1 and f λ ln λ will yield bounds on t r ln c ln d e t c an ensemble of estimates of i j are computed by using different vectors for u j with elements of either 1 or 1 that are chosen at random with equal probability i e algorithm 2 of bfg for each choice of random vector u j the lanczos algorithm golub and van loan 1989 is used to estimate the eigenvalues λ i note that this application of the lanczos algorithm is distinct and separate from that used in the 4d var algorithm described in appendix b all that is required is a routine that evaluates the matrix vector product c u j the inner product estimate resulting from gauss quadrature is then given by i j k 1 m ω k 2 λ k where the weights ω k 2 are derived from the lanczos algorithm itself by applying different rules to the resulting gauss quadrature of the function f λ estimates on the upper u j and lower l j bounds for each i j can be computed using a monte carlo sample of size p the upper and lower bounds of f λ can be calculated as 1 p j p u j and 1 p j p l j respectively in the calculations presented in section 4 m 90 and p 10 p 20 for 30 day forecast lead times and the matrix vector product c u j for each sample member is computed using eq 8 or 10 as appropriate by employing the tangent linear and adjoint of the roms 4d var system c 2 the fc approach the method employed by fc is also based on a monte carlo approach to estimate t r c in this case t r c 1 q j q u j t c u j where q is the sample size and the elements of u are normally distributed as n 0 1 while the practical implementation of this approach is more straightforward than that of bfg it is limited to estimates of t r c the expected percentage error in the trace estimate is given by 100 2 q 1 2 in the calculations of section 4 a sample size q 30 was used which yields an expected error a little shy of 13 to reduce the error to say 1 would require a sample size of 5000 which is impractical a comparison of the bfg and fc estimates of t r ua u t for the expected analysis error covariance matrices a τ eq 8 and a 0 eq 9 and for the expected forecast error covariance matrices t r uf t u t eq 10 at various lead times t are shown in fig c 1 in all cases u defines the energy norm see appendix a for t 30 the two methods yield consistent estimates that fall close to the 1 1 line for t 30 the fc estimates are higher than those of bfg despite the disagreement for these longer lead forecasts fig 3b and c show that on the whole the time evolution of the trace estimates yielded by the two approaches is consistent therefore we feel confident that the bfg determinant estimates in fig 3a are reliable and that the evolution in time is robust 
23933,the properties of the expected analysis and forecast error covariance matrices are explored using a novel method based on the tangent linearization and adjoint of a 4 dimensional variational 4d var data assimilation system the method is applied to the mesoscale circulation that develops in the presence of a baroclinically unstable mid latitude ocean temperature front using a series of paternal twin experiments that employ both strong and weak constraint 4d var adopting the traditional view of empirical orthogonal functions eofs of a covariance matrix as the semi major axes of a multi dimensional hyper ellipsoid variations in the volume of the analysis and forecast error hyper ellipsoids are explored which provides information about the flow of probability through state space the complementary variations in the expected total variance of the covariance matrix are also investigated two different kinds of behavior are identified that are associated with either the demise or growth of baroclinic instabilities in both cases the volume of the hyper ellipsoid decreases during the 4d var analysis cycle during the subsequent forecasts the volume of the forecast error hyper ellipsoid initially continues to collapse under both scenarios during this time the hyper ellipsoid becomes increasingly elongated along some of the semi major axes as forecast errors grow in preferential directions growth in these directions is controlled by the most unstable error modes and projection of forecast error on to the precursors of these modes has been shown previously to be characterized by upscale energy transfer and non normal processes for the case of the growing wave the forecast error hyper ellipsoid continues to collapse through to the end of the forecast period however for the decaying wave the hyper ellipsoid may undergo expansion at longer forecast lead times keywords 4d var error covariance adjoint methods baroclinic instability 1 introduction an important element of operational analysis and forecast systems for the ocean and atmosphere is the quantification of the errors and uncertainties in the resulting circulation estimates since many operational systems these days are based on an ensemble approach analysis and forecast ensembles provide a convenient means for estimating error covariance properties such approximations however are of reduced rank in nature and generally underestimate the actual errors for example some form of covariance inflation is typically required in ensemble kalman filters due to the limited number of members that are used e g anderson 2007 in addition localization is necessary to ameliorate spurious correlations and rank deficiency due to the limited ensemble size gaspari and cohn 1999 in variational data assimilation systems covariance information is difficult to compute ngodock et al 2020 but can be estimated from an approximation of the kalman gain matrix although it is typically an underestimate of the actual error covariance fisher and courtier 1995 the very large dimension of most geophysical problems of interest precludes the explicit computation of analysis and forecast error covariance matrices however many important properties of these covariances can be computed if it is possible to compute the product of the matrix with a vector in this paper we explore an alternative approach for computing the expected analysis and forecast error covariance which makes direct use of the tangent linear and adjoint of a 4 dimensional variational 4d var data assimilation system to compute a matrix vector product it should be stated at the outset that the approach used here is extraordinarily demanding computationally and is not suitable for a large operational analysis forecast system however as we will demonstrate our approach is of theoretical and mathematical interest because it has the desirable property of providing an explicit operator for the analysis and forecast error covariance which makes it very appealing despite the heavy computational burden in a conventional 4d var system recent developments in 4d var promise very substantial reductions in the computational cost fisher et al 2011 d amore et al 2014 arcucci et al 2015 fisher and gürol 2017 which could make the approach adopted here more tractable in large models in the future in light of the computationally heavy burden attention is restricted to an exploration of the properties of analysis and forecast error covariance in a small but very relevant computational domain specifically we will consider the expected covariance properties of errors that develop in the ocean mesoscale circulation environment that results from the adjustment of a baroclinically unstable temperature front at mid latitudes fronts are a common feature of the ocean circulation so the results presented here are of broad interest and generally applicable in many situations for example analysis and prediction of oceanic fronts and their incumbent eddies in coastal ocean environments is an important mandate of many operational forecasting centers because of the significant role that these circulation features play in controlling local air sea interactions the health of marine ecosystems and ocean acidification events therefore the results presented here have some potentially very practical applications a description of the mathematical formulation of the analysis and forecast error covariance in terms of the tangent linearization of the entire data assimilation system is presented in section 2 while section 3 describes the experimental set up used to explore the utility of the method introduced in section 2 the properties of the expected analysis and forecast errors for a frontal system are presented in sections 4 and 5 section 6 demonstrates the connection between the method used here and the closely related study of smith et al 2015 a summary and conclusions follow in section 7 2 methodology the approach developed for estimating the expected analysis and forecast error covariance is based on the work of moore et al 2012 hereafter mab using a 4d var approach for this reason the following discussion is focused on 4d var but the same methodology could in principle be applied to any linearized data assimilation algorithm 2 1 the expected analysis error covariance a standard notation will be adopted here ide et al 1997 where x represents the state vector of the system under consideration while x b and x a denote the background and analysis estimates of x respectively for any linear data assimilation system the best linear unbiased estimate blue aka analysis can be expressed as 1 x a x b k y o h x b where y o is the vector of observations and h is the observation operator that maps x b to the space time location of each datum the matrix k is the kalman gain and can be expressed as 2 k b h t hb h t r 1 where b and r are the background and observation error covariance matrices respectively and h is the linearized observation operator in the case of 4d var data are assimilated over a window in time and h also includes the nonlinear model while h represents the tangent linear model sampled at the observation points the adjoint model forced at the observation points is represented by h t in the case of strong constraint 4d var b b x and describes the statistics of the errors in the initial conditions for the weak constraint case errors in the model are also accounted for by augmenting the background error covariance matrix so that b d i a g b x q where q is the model error covariance matrix a schematic of a typical analysis forecast cycle for both flavors of 4d var is shown in fig 1 where the interval t τ 0 denotes the analysis window and t 0 t represents the forecast interval the analysis given by 1 is valid at the beginning of the analysis window and must be integrated forward in time to t 0 in order to make a forecast based on 1 and 2 the covariance of the expected errors in the analysis x a can be written as 3 a τ i kh b i kh t kr k t daley 1991 as in 1 this estimate of a is valid at time t τ the goal of 4d var is to identify the analysis x a τ that minimizes a cost function that is a quadratic measure of the weighted departures of x from the background and the observations because the resulting minimization problem is nonlinear it is common practice to apply the incremental approach of courtier et al 1994 where the estimation procedure is linearized about the background x b over the interval t τ 0 the resulting algorithm is equivalent to a gauss newton method lawless et al 2005 and comprises so called inner loops and outer loops the minimization of the non quadratic cost function proceeds via a sequence of linear minimization problems where the latter is accomplished during the inner loop iterations and identifies an increment δ x τ to x b τ following the completion of a sequence of inner loops the state vector estimate x τ is updated using the most recent increment during an outer loop and another linear minimization problem is solved via a new set of inner loops after n outer loops the analysis is given by 4 x a x b i 1 n δ x i and the expected analysis error covariance matrix is given by 5 a n τ i n 1 i k i h i 1 b i n 1 i k i h i 1 t j 1 n 1 i n j 1 i k i h i 1 k j k n r j 1 n 1 i n j 1 i k i h i 1 k j k n t where k i is the kalman gain resulting from outer loop i and h i 1 is the tangent linear observation operator linearized about x i 1 during the first outer loop h 0 h b which is the observation operator linearized about x b 2 2 analysis error covariances from the tangent linearization of 4d var belo pereira and berre 2006 and berre et al 2006 have demonstrated that estimates of the expected analysis error covariance matrix can be computed by perturbing an analysis x a to create an analysis ensemble each member of the analysis ensemble is generated by rerunning the data assimilation system using a perturbed background and perturbed observations the perturbations are drawn from normal distributions with zero mean and error covariances b and r respectively as shown by these authors the covariance of the resulting analysis ensemble mimics the covariance of the expected uncertainties in the unperturbed analysis x a in the case of 4d var this would be an estimate of a n τ in fig 1 and the original unperturbed analysis x a represents the ensemble mean by extending these ideas mab showed that as the size of the analysis ensemble approaches infinity the ensemble covariance can be expressed in terms of a tangent linearization of the data assimilation system and its adjoint in the context of the present work this would be the tangent linearization of the entire 4d var algorithm and the corresponding adjoint specifically any linear data assimilation system that solves for the blue in 1 can be generalized so that 6 x a x b k d where d y o h x b represents the innovation vector and k d denotes the data assimilation algorithm which in general will be a nonlinear function of d for example 4d var proceeds by minimizing the cost function using a conjugate gradient method an inherently nonlinear procedure based on d using 6 and following mab eq 5 can be re expressed as 7 a n τ i n 1 i k d i h i 1 b i n 1 i k d i h i 1 t j 1 n 1 i n j 1 i k d i h i 1 k d j k d n r j 1 n 1 i n j 1 i k d i h i 1 k d j k d n t where d i y o h x i 1 the operator k d i represents the tangent linearization of 4d var for outer loop i and k d i t is the corresponding adjoint in the case of a single outer loop eq 7 reduces to 8 a τ i k d h b b i k d h b t k d r k d t which was the case considered by mab for estimating the expected analysis error variance of several different circulation indices since 7 and 8 are based on a 1st order linearization of k d in 6 it is assumed that the influence of higher order terms on a n τ is negligible as noted in section 1 the explicit computation of all the elements of a would be prohibitively expensive given the very large dimension of most problems of interest however since the matrix in 7 and 8 is available as an operator in the form of fortran code important properties of the error covariance matrix can be quantified using iterative methods since all that is required is the ability to compute a matrix vector product the tangent linear operator k d and its adjoint k d t have considerable utility moore et al 2011a for example the operators can be used to quantify the sensitivity of the 4d var system to uncertainties in the system provide information about the impact of observations on the analyses and forecast e g trémolet 2008 yield information about the expected error variance in scalar functions mab or provide information about the stability and conditioning of the 4d var inversion procedure the latter arises from the useful properties of the tangent linearization and adjoint of the conjugate gradient method gratton et al 2014 in the investigations described in later sections it is important to note that k d and k d t were derived directly from the data assimilation fortran code using standard recipes e g giering and kaminski 1998 and each operator represents one complete outer loop evaluation of the tangent linear and adjoint of the 4d var system thus the computational cost of each of these operations is comparable to running 4d var however 7 represents an explicit operator for the expected analysis error covariance arising from an infinite ensemble and from which matrix vector products can be computed therefore various properties of the analysis error covariance matrix such as the total error variance i e the trace and empirical orthogonal functions eofs can be computed iteratively 2 3 forecast error covariance suppose now that the unperturbed analysis x a of section 2 2 is advanced to the end of the analysis window t 0 and used to initialize a forecast denoted x f as shown schematically in fig 1 for the interval 0 t similarly an ensemble of forecasts can be created each initialized from individual members of the analysis ensemble of section 2 2 the covariance of the forecast ensemble about the unperturbed forecast x f will mimic the covariance of the expected forecast errors under this scenario and neglecting for now model error a linear approximation of the expected forecast error covariance matrix f t during the forecast interval t 0 t illustrated in fig 1 is given by 9 f t m f 0 t a n 0 m f t t 0 where m f 0 t denotes the tangent linear model linearized about the forecast x f t m f t t 0 is the adjoint model where the reversed arguments indicate integration backward in time over the forecast interval and a n 0 is the analysis error covariance matrix at the end of the analysis window t 0 cf fig 1 in this framework the unperturbed forecast x f is equivalent to the ensemble mean and f t is the covariance of the infinite ensemble about the ensemble mean the analysis error covariance at t 0 is given by a n 0 m b τ 0 a n τ m b t 0 τ where a n τ is the expected analysis error covariance at the beginning of the analysis window given by 5 and m b τ 0 denotes the tangent linear model linearized about the background x b over the analysis window using 7 the expected forecast error covariance can be computed according to 10 f n t m f 0 t m b τ 0 a n τ m b t 0 τ m f t t 0 the covariance matrices in 3 and 9 are defined in terms of the l2 norm and as such cross covariances between different physical variables of the state vector will have mixed units e g m s 1 c while this is an acceptable definition of covariance the mixed units can render difficult a direct comparison of individual matrix elements and complicate the interpretation of the eofs alternatively a norm can be chosen whereby the elements of the resulting error covariance matrix all have the same units in numerical weather prediction it is common to use an energy norm to define the covariance of the forecast error ε e g buizza and palmer 1995 such that c e uε ε t u t where e denotes the expectation operator and u is an appropriate weight matrix so that all elements of the vector uε have the units of the square root of energy the choice of an energy norm is also appealing given the fundamental role that energy plays in our understanding of the underlying physical processes that govern the ocean circulation the very same processes that control the evolution of forecast errors therefore an energy norm described in appendix a was used in all of the computations reported here in which u is time invariant as in section 2 the various matrix operations in 10 are available as fortran code and various properties of f n t can be evaluated using iterative methods 3 experimental setup attention is confined here to the relatively simple yet dynamically relevant case of the adjustment of an ocean temperature front in a zonally re entrant channel and the subsequent relaxation toward a restratified water column a problem that has been studied extensively in the oceanographic literature e g boccaletti et al 2007 klein et al 2008 3 1 paternal twin models the model used was the regional ocean modeling system roms shchepetkin and mcwilliams 2005 it was configured for a flat bottomed zonally periodic channel 1000 km long 2000 km wide and 4000 m deep centered on 43 3 s two configurations of the model were considered model t with 2 5 km grid spacing in the horizontal and model f with 20 km horizontal grid spacing in both models 20 unevenly spaced levels were used in the vertical with spacing 20 m near the surface increasing to 700 m at the bottom both models employ 4th order horizontal and vertical advection for tracers and 3rd order upstream horizontal advection for momentum in conjunction with 4th order vertical advection of momentum horizontal mixing in the form of 2nd order eddy diffusivity and eddy viscosity was used that is parallel to the model σ levels with coefficients of eddy viscosity and diffusivity of 25 m2 s 1 in model t and 400 m2 s 1 in model f vertical mixing was parameterized using the k ε generic length scale formulation of umlauf and burchard 2003 with lower thresholds of 10 5 m2 s 1 for the vertical mixing coefficients of tracer and momentum in model t and 5 1 0 5 m2 s 1 in model f the time step in model t was 150 s compared to 1200 s in model f model t was used to simulate the true ocean circulation and following smith et al 2015 hereafter sma was initialized from rest with a meridional temperature front described by t y z t 0 t r y 1 z h 1 2 where t r y α f y erf y y 0 l f 0 with α 4 52 y is the cross channel distance z is depth f y is the coriolis parameter on a β plane with a value of f 0 at the central latitude 43 3 s l 80 km is the meridional scale of the temperature front h is the channel depth y 0 is the value of y at the mid point of the channel and t 0 12 c is the surface temperature at y 0 salinity was not included in the model calculations reported here instability growth was encouraged by adding small amplitude sinusoidal zonal wavenumber 1 and zonal wavenumber 2 perturbations to the initial condition for simplicity there is no surface forcing imposed in either model t or model f however the instability process was prolonged by weakly relaxing the solution to the initial temperature profile on a time scale of 50 days fig 2a d shows the evolution of the sst of the circulation that develops in model t between days 50 and 134 as noted in section 1 fronts are a common feature of the ocean circulation and occur on a wide range of scales ranging from the geostrophic regime down to the sub mesoscale here we concentrate on the quasi geostrophic regime which includes the formation of seasonal fronts such as sub polar and shelf break fronts and upwelling fronts such as those that form in eastern boundary current systems in the experiments presented here the presence of the front is taken as a given and we do not concern ourselves with the mechanism of frontogenesis although surface forcing is known to play a major role in many instances for example cross front ekman transport associated with along front winds can hasten the formation or demise of a front depending on the wind direction here we simply explore the collapse of a front after genesis and the subsequent relaxation toward a restratified ocean with this in mind fig 2a d illustrate very clearly the complex circulation that develops as a result of the baroclinic instabilities that ensue as the isotherms slump in an attempt to move toward a lower energy state initially the circulation is dominated by the development of a zonal wavenumber 2 instability which later gives way to a zonal wavenumber 1 feature model f was used as a surrogate for model t fig 2e h show the sst from the integration of model f initialized with the model t state vector on day 50 that was first subsampled on the model f grid comparison with fig 2a d indicates that the model f solution diverges from the parent model t circulation over time as anticipated the model f solution is less energetic than model t as illustrated in fig 2m which shows the time series of the domain integrated kinetic energy ke computed from the vertically integrated velocity during the period shown the model t ke continues on an upward trajectory indicating that the circulation has not yet reached an equilibrium the available potential energy ape is still being converted to ke as the instabilities develop conversely the model f ke asymptotes quickly and then undergoes a slow decline over time indicating that in this case the conversion of ape to ke is offset by dissipation recall that there is no surface forcing and the relaxation term is weak 3 2 strong and weak constraint 4d var the model t circulation between days 50 and 110 cf fig 2a d was used as a surrogate for the true ocean circulation this 60 day time interval was divided into 2 day windows and simulated observations drawn from model t during each window were assimilated into model f using 4d var during the resulting 30 analysis cycles the 4d var analysis at the end of each time window was used as the background estimate x b at the start of the next cycle the background circulation for the first cycle was chosen to be the model t circulation on day 49 subsampled on the model f grid the observations were all in the form of vertical profiles of temperature over the upper 1000 m of the water column only regularly spaced in the horizontal and in time observations were available at times corresponding the beginning middle and end of each 2 day analysis cycle and sampled every 60 km corresponding to every third model f horizontal grid point yielding 26 000 observations per 2 day assimilation window random observation errors with zero mean and a standard deviation of 0 1 c were added to each datum the observation errors were assumed to be mutually uncorrelated a reasonable assumption for independent vertical profiles so the observation error covariance matrix r is diagonal the diagonal elements of r correspond to an error standard deviation of 0 22 c a combination of the measurement error and an assumed error of representativeness with a standard deviation of 0 2 c the background error covariance matrix b was estimated using the identical twin experiments described by sma who used a similar model configuration with 10 km horizontal grid spacing specifically the standard deviations and typical correlation length scales of the background errors were computed from the sma circulation estimates and then used in the roms 4d var model for b which is based on the diffusion operator approach of weaver and courtier 2001 in addition the balance operator of weaver et al 2005 was also employed both strong and weak constraint 4d var experiments were performed in the strong constraint case model f is assumed to be free of errors and the 4d var control vector comprises only the model initial conditions however imperfections in model f arise from poor horizontal resolution and errors associated with imperfect parameterizations therefore in the case of weak constraint 4d var the control vector is augmented with a correction for model error η t that is applied at every grid point and every time step in model f similarly the background error covariance matrix b in 2 is replaced by d diag b q where q is the model error covariance matrix the matrix q describes the covariance of typical model errors that develop during each 2 day assimilation cycle to estimate a time invariant q model f was initialized at the start of each 2 day window with the model t solution on the same day sub sampled on the model f grid the difference between the model f solution two days later and the corresponding model t solution was then used to estimate the standard deviation of the model error and typical correlation length scales the latter employing the semi variogram approach of banerjee et al 2004 in this way q represents the statistics of typical model errors that develop during the 2 day assimilation windows during weak constraint 4d var experiments q was modeled using a diffusion operator as for b in practice the control vector corrections η t for model error were only computed every 2 h during the weak constraint experiments and linearly interpolated to times in between so a decorrelation time of 1 day was also assumed for model error to regularize the time evolution of model error corrections this time scale is consistent with the slow time evolution of the model f minus model t differences used to estimate q in all experiments homogeneous isotropic correlation functions were employed to model b and q specifically for b q the following correlation lengths were used 150 200 km for the free surface height 75 200 km for both horizontal velocity components and 65 200 km for temperature a vertical correlation length of 200 m was used for both b and q in all experiments the simulated observations were assimilated into model f using the dual formulation of strong and weak constraint 4d var described in detail by moore et al 2011b and gürol et al 2014 fig 2i l show the model f sst from the strong constraint 4d var analyses on selected days a comparison with the true solution fig 2a d confirms that data assimilation can recover the majority of the model t circulation features that are resolved by the model f grid the weak constraint circulation analyses are very similar to those in fig 2i l not shown data assimilation also energizes the circulation as shown in fig 2m which shows a time series of ke from both the strong and weak constraint analyses during each 4d var cycle ape is added by the observations thereby propping up the isotherms and leading to elevated ke through baroclinic conversion processes the discrete jumps in ke between 4d var cycles are very evident in fig 2m furthermore fig 2m also shows that the weak constraint forcing term η t often further energizes the analyses 4 properties of the error covariance matrix as discussed in section 2 the properties of the analysis and forecast error covariance matrices associated with the model f experiment are of interest these provide quantitative information about the veracity of the 4d var analyses and ensuing forecasts in this section we will first explore some general properties of the expected error covariance matrices arising from the infinite ensemble of perturbed 4d var analyses described in sections 2 2 and 2 3 the perturbed 4d var analyses are described in appendix b 4 1 the determinant the determinant of a covariance matrix can be expressed as the product of its eigenvalues furthermore the associated eigenvectors define the direction of the semi major axes of a multi dimensional hyper ellipsoid while the square root of each eigenvalue represents the axes lengths therefore the determinant of the covariance matrix is of interest because it is proportional to the squared volume of the hyper ellipsoid specifically the determinant of a covariance matrix is proportional to the squared hyper volume of all ocean states for which the error is smaller than one standard deviation therefore in the case of the analysis error covariance a smaller determinant indicates a more precise estimate of the ocean state from the data assimilation system as shown in section 4 3 the temporal evolution of the determinant of a covariance matrix also provides information about the flow of probability through the system as noted in appendix c for the large dimension problem considered here 105 it is not practical to explicitly compute the analysis and forecast error covariance matrices therefore as described in appendix c the determinants of the energy weighted analysis error covariance matrix u a n u t and forecast error covariance matrix u f n t u t were estimated using the monte carlo method of bai et al 1996 an approach that invokes the lanczos algorithm golub and van loan 1989 to estimate the eigenvectors of each matrix iteratively also the bai et al method places upper and lower bounds on the determinant estimates using the paternal twin approach described in section 3 the simulated observations from model t were assimilated into model f using a single outer loop and 25 inner loops a choice based on the experience of sma since a single outer loop is considered the subscript n will be dropped in the sequel if no data are assimilated k 0 and 3 reduces to a τ b the volume of the hyper ellipsoid d e t ub u t 1 2 is therefore a useful benchmark as noted in section 3 2 the balance operator of weaver et al 2005 was also employed in the parameterization of b however since the balance operator is only weakly flow dependent b varies very little from one data assimilation cycle to the next this is illustrated in fig 3a which shows an estimate of ln d e t ub u t 1 2 i e a measure of the natural log of the hyper ellipsoid volume based on the energy norm black circles because of the large dimension of the system considered here 105 the approach is computationally very demanding so estimates of the determinant were only computed every 4th analysis cycle the volume of the hyper ellipsoid defined by the expected analysis error covariance matrix at the beginning of each analysis cycle i e t τ in fig 1 is given up to a constant of proportionality by d e t ua τ u t 1 2 a time series of ln d e t u a τ u t 1 2 is shown in fig 3a dark blue circles for every 4th strong constraint 4d var cycle and indicates that the analysis error covariance hyper ellipsoid volume at time t τ is indistinguishable from that associated with b fig 3a red circles also shows a time series of the hyper ellipsoid volume defined by the expected analysis error variance at the end of the same strong constraint 4d var cycles i e t 0 which is given by d e t ua 0 u t 1 2 d e t u m b 0 τ a τ m b t τ 0 u t 1 2 the volume of the error hyper ellipsoid subspace can be seen to decrease in time during the analysis window following the usual operational practice the strong constraint 4d var analyses at the end of each analysis cycle t 0 in fig 1 were used as the initial conditions for each forecast cycle fig 3a also shows time series of the hyper ellipsoid volume defined by the expected forecast error covariance uf t u t for forecast lead times t of 2 green circles 6 magenta circles 12 cyan circles 18 red triangles 22 blue triangles 26 green triangles and 30 days orange circles duration fig 3a indicates that the forecast error covariance hyper ellipsoid volume generally collapses as the forecast lead time increases the exception is early on in the analysis forecast experiment during cycles 2 and 6 where there is an indication that the 30 day forecast error hyper ellipsoid expands again although for this case fig 3a indicates that the uncertainties are larger the properties of the circulation through time associated with this behavior will be explored later another remarkable feature of fig 3a is that for a given lead time the hyper ellipsoid volume varies very little from cycle to cycle excepting the 30 day forecasts the generally observed collapse of the hyper ellipsoid volume is consistent with a slow decline in the forecast circulation energy as illustrated in fig 2m which shows time series of ke for three representative cases in each example the ke slowly decreases over time and is at all times lower than that of the 4d var analysis on the same day 4 2 the trace the trace of the leading diagonal of the energy weighted analysis error covariance matrix ua u t and forecast error matrix uf t u t represents the expected total error variance in each case the trace of a matrix can additionally be expressed as the sum of the eigenvalues the trace of each covariance matrix was also estimated iteratively using the method of bai et al 1996 and time series are shown in fig 3b for every 4th analysis forecast cycle the trace estimates generally converge faster than the estimates of the determinant which is reflected in the smaller error bars in fig 3b fig 3b suggests two different types of behavior for the total variance during the first 10 15 cycles the total error variance decreases steadily from the background value through the analysis cycle and out to around forecast day 6 12 after which error variance increases again with increasing forecast lead time thus during these cycles while the volume of the hyper ellipsoid is collapsing cf fig 3a it is becoming very elongated in the direction of some semi major axes conversely after cycle 15 fig 3b shows that the total error variance generally decreases out to around forecast day 22 and significant elongation of the hyper ellipsoid is delayed the mechanics of this behavior are explored further in section 5 while it is computationally prohibitive to compute trace estimates for every analysis forecast cycle using the method of bai et al 1996 a less demanding approach can be used based on a randomized trace estimate method described by fisher and courtier 1995 in this case an estimate of the trace of the positive definite matrix c can be computed according to t r c 1 m i 1 m v t cv where v is a random vector drawn from the normal distribution n 0 1 and m is the sample size while this procedure is computationally less demanding than the method of bai et al 1996 the resulting trace estimates are less accurate nonetheless they provide useful information about the behavior of the total error variance during all cycles the percentage expected error in the trace estimate in this case is given by 100 2 m 1 2 in the following examples m 30 which yields trace estimates with an expected error 13 which is deemed adequate for exploring the general behavior of the total error variance since the trace estimates for different lead times are distinguishable the relative performance of the two trace estimation methods employed in this study is further documented in appendix c time series of the trace estimates using the alternative randomized trace estimate approach are shown in fig 3c for every 2 day strong constraint analysis forecast cycle and confirm the same general behavior noted above fig 3c also shows the total expected forecast error variance for forecasts initialized by analyses computed using weak constraint 4d var in general the forecast error variance displays behavior that is similar to forecasts initialized from the strong constraint analyses however there are some cycles where the response is quite different e g the 30 day forecasts for cycles 10 15 as noted earlier fig 2m indicates that the weak constraint circulation estimates are frequently more energetic than their strong constraint counterparts it is therefore reasonable to assume that during such times the model error forcing η t provides additional ape during the analysis cycle that in turn yields a more unstable forecast state and larger forecast error variance 4 3 the flow of probability the time evolution of the determinant of a covariance matrix provides quantitative information about the flow of probability through the analysis forecast system following the notation introduced in section 2 1 the time evolution of the forecast state vector x f can be represented as d x f d t m x f where m represents the non linear roms model if as before ε t denotes the error in the forecast then to 1st order 11 d ε d t φ f t ε t ς t where φ f m x x f is the jacobian of m describing the tangent linearization of m about x f and ς t represents model error ideally φ f would represent a linearization of m about the true state which of course is never known however as discussed in section 2 2 the evolution of perturbations around the reference forecast x f are used as a surrogate for describing forecast errors in which case x f represents the ensemble mean or more formally the expected value of x and φ f describes the time evolution of each member of the infinite ensemble of perturbations ε t it is well known gardiner 1985 that the probability density function pdf of the forecast errors ε ε i in 11 is described by the fokker planck equation 12 p t i 1 n a i p ε i 1 2 i 1 n j 1 n 2 q i j p ε i ε j where p p ε t ε 0 is the conditional probability of the error ε t given the initial condition ε 0 a i are the elements of the vector field a t generated by φ f i e a t d ε d t φ f t ε t and q i j are the elements of the model error covariance matrix q e ς ς t by analogy with the advection diffusion equation a t plays the role of a velocity that advects the mean of the pdf through state space and is commonly referred to as the drift vector or drift velocity since in general the divergence of the drift velocity does not vanish a t will also influence the width of the pdf the second term on the right hand side of 12 is associated with the stochastic forcing ς t in 11 and is referred to as diffusion since q q i j acts like a diffusion matrix that broadens the pdf following gardiner 1985 12 can be recast as p t i 1 n c i ε i where the vector c i a t p 1 2 j 1 n q i j p ε j is a probability current and i 1 n c i ε i is the total divergence the presence of stochastic model error ς t is only considered during the analysis cycle in the case of weak constraint 4d var since no allowance is made here for model error during a forecast it does not factor into the covariance calculations based on 7 thus we will drop the diffusion term from further analysis in this case q 0 and the time evolution of the forecast error covariance matrix uf t u t e uε t ε t t u t is given by 13 d uf u t d t u φ f u 1 uf u t uf u t u φ f u 1 t using jacobi s formula d d e t uf u t d t t r a d j uf u t d uf u t d t the cyclic properties of the trace and the associative property of determinants it can be shown that 14 d ln d e t f 1 2 d t t r φ f t which relates the time rate of change of the volume of the hyper ellipsoid defined by the forecast error covariance to the trace of the tangent linear model note that the result expressed by 14 is independent of the choice of u by virtue of the similarity invariance of u φ f u 1 choosing q i j 0 in 12 leads to liouville s equation where the rate of change of the pdf depends only on the drift velocity a t φ f t ε t the total divergence of the drift velocity is given by i 1 n a i ε i t r φ f which according to 14 controls the rate of change of volume of the hyper ellipsoid associated with the forecast error covariance matrix to illustrate this result fig 4a and b show time series of t r φ f based on 14 for cycles 2 and 26 near the beginning and end of the experiment period respectively the time rate of change of ln d e t f was estimated by fitting a 6th order polynomial to the data in fig 3a 1 1 from the associative properties of the determinant d ln d e t uf u t 1 2 d t 1 2 d ln d e t u 2 d e t f d t 1 2 d 2 ln det u ln d e t f d t d ln d e t f 1 2 d t for the case here where u is a time invariant diagonal matrix as shown in fig 3a the hyper ellipsoid volume collapses over time through to a forecast lead time 25 days thus in both cases t r φ f 0 through forecast lead time of 25 days indicating that the drift velocity a t associated with the probability current is convergent although the rate of convergence decreases with increasing lead time this suggests that probability becomes more concentrated in state space as the forecast lead time increases consistent with a collapse of the pdf in other words the volume of the sub space occupied by all possible forecast errors ε t is also decreasing this will be further quantified shortly while the drift velocity remains convergent beyond day 25 during cycle 26 fig 4a shows that it eventually becomes divergent in the case of cycle 2 consistent with fig 3a indicating that the probability density begins to decrease as the forecast error hyper ellipsoid subsequently expands 4 4 state space volume in the absence of stochastic model error i e ς t 0 solutions of 11 can be written in a compact form as ε t m f 0 t ε 0 where m f 0 t is the tangent linear propagator matrix introduced in section 2 1 similarly the forecast error covariance matrix can be expressed as uf t u t u m f f 0 m f t u t based on the associative property of determinants it is easy to show that 15 ln d e t m f 0 t 1 2 ln d e t f t d e t f 0 geometrically any matrix can be viewed as transforming a unit volume multi dimensional hyper cube into a multi dimensional parallelepiped which in turn is defined by the rows of the matrix the determinant of a matrix is then the volume of the resulting parallelepiped thus d e t m f 0 t in 15 represents the volume of state space occupied by the forecast errors ε t it also follows from 14 and 15 that d e t m f 0 t exp 0 t t r φ f τ d τ which is another form of the liouville equation arnold 1998 fig 4a and 4b show the time series of ln d e t m f 0 t for cycles 2 and 26 respectively in both cases the volume of state space occupied by the forecast errors decreases with increasing lead time although for cycle 2 there are signs of an increasing tendency around day 28 consistent with the transition in the drift velocity from convergent to divergent conditions therefore the sub space where the forecast errors reside becomes more certain in line with the concentration of probability and the collapse of the forecast error covariance hyper ellipsoid 5 empirical orthogonal functions in this section the topology of the space described by the expected analysis and forecast error covariance matrices is explored 5 1 geometric interpretation the directions in state space of the semi major axes of the hyper ellipsoids discussed in section 4 are represented by the eigenvectors of the error covariance matrices ua u t and uf t u t these same eigenvectors are more commonly referred to as empirical orthogonal functions eofs and the associated eigenvalues represent the error variance explained by each eof in the present case the dimension n of the hyper ellipsoid is o 105 which would also be the total number of eofs the eof spectrum for either ua u t or uf t u t can be calculated iteratively using the lanczos algorithm golub and van loan 1989 while the lanczos algorithm can provide an estimate of the entire eof spectrum the leading members of the spectrum typically emerge to acceptable precision first when the number of iterations is much less than n therefore this is a convenient way to reliably calculate the leading eofs fig 5a shows the eigenvalues associated with the leading 20 eofs of the expected analysis error covariance matrix at the beginning dark blue line and end red line of a representative strong constraint analysis cycle in both cases the leading portion of the eof spectrum is quite flat also shown in fig 5a are the eigenvalues of the leading eofs of the expected forecast error covariance for 2 6 12 and 30 day forecast lead times as the forecast lead time increases fig 5a reveals that the eof spectrum becomes increasingly peaked with the leading eof accounting for a larger fraction of the total variance fig 5b shows the eigenvalue λ 1 associated with the leading eof of ua τ u t ua 0 u t and uf t u t for t 2 30 days for each cycle for most cycles it is apparent that the amplitude of the leading eigenvalue decreases through the analysis cycle from t τ to t 0 and through the forecast cycle to t 2 days for t 2 days the leading eigenvalue increases with lead time also shown in fig 5b are the leading eigenvalues of uf t u t for 2 and 12 day forecasts initialized with weak constraint 4d var analyses the behavior is similar to that of the strong constraint cases although again some cycles 18 19 and 23 are remarkably different as noted in section 4 2 the weak constraint 4d var corrections for model error η t applied during the analysis cycle tend to energize further the forecast initial conditions cf fig 2m which in turn can influence the eof spectrum the cumulative variance explained by the leading 30 eofs of the expected analysis and forecast error covariance is shown in fig 5c for each strong constraint 4d var analysis forecast cycle in each case the randomized trace estimates of the total expected error variance from section 4 2 were used and error bounds are also indicated in fig 5c based on the expected 13 error in the trace estimates fig 5c shows that the fraction of variance explained by the leading eofs is typically low during the analysis cycle and for short forecast lead times this is consistent with the relatively flat nature of the spectrum fig 5a however the fraction of the total variance explained typically increases with increasing forecast lead time and for t 30 days is close to 100 fig 5c shows that while during some cycles the cumulative variance explained for the t 30 days case appears to exceed 100 the error bars in fig 5c indicate this can be attributed to the uncertainty in the total variance estimates additional calculations for selected cycles suggest that the fraction of explained error variance increases very slowly beyond the leading 30 or so eofs not shown the results presented here indicate that even though the hyper ellipsoid volume is collapsing as the forecast lead time increases cf fig 3a it is not collapsing uniformly in all directions in fact it is becoming more elongated along the directions described by the leading few eofs cf fig 5b furthermore as the forecast lead time increases most of the forecast error is described by a small number of growing directions cf fig 5c this agrees with experience in numerical weather prediction e g phillips 1986 houtekamer 1993 5 2 error structures the sea surface temperature structure of the leading eof at each stage of the analysis and forecast cycle for various lead times is shown in fig 6 for cycle 6 using strong constraint 4d var the sst analysis for this cycle is also indicated for reference in fig 6a fig 6b shows that the leading eof at the beginning of the analysis window t τ in fig 1 comprises coherent mesoscale structures however this eof accounts for only 0 5 of the total expected analysis error variance in the subspace constrained by 4d var on this day by the end of the analysis cycle t 0 in fig 1 the influence of the time evolution of the circulation on the leading covariance structure is evident in fig 6c at this time the eof comprises generally smaller scale structures that wrap around the meanders and eddies of the circulation although the explained variance is still only 0 5 as the forecast lead time increases fig 6 shows that the horizontal scale of the leading eofs decreases even further targeting specific areas of the evolving meanders in the circulation that are evident in the analysis of fig 6a furthermore the fraction of the variance explained by the leading eof increases with forecast lead time and in the case of a 30 day forecast fig 6g it is 42 for this particular cycle the leading eofs of uf u t can also account for much of the actual measured forecast error variance and structure for example fig 7a d shows the spatial distribution of the rms forecast errors for 12 day forecasts initialized from the strong constraint 4d var analyses from cycles 21 30 the forecast errors are computed relative to the 4d var analysis valid on the forecast day also shown in fig 7e h is the forecast error explained by the leading 30 eofs of the expected forecast error covariance matrix uf u t while the amplitude of the error is underestimated it is clear much of the structure of the actual forecast errors is captured by the leading 30 eofs even though they only capture 40 of the total variance cf fig 5c 5 3 forecast error variance as a predictor of forecast skill in operational ensemble numerical weather prediction systems the spread of the ensemble about the ensemble mean is used as a surrogate for the forecast error variance epstein 1969 leith 1974 and can be of considerable utility because under some circumstances it can be used as a predictor of the skill of the ensemble mean e g barker 1991 molteni et al 1996 specifically if the ensemble spread is small large this can be an a priori indicator of a skillful unskillful forecast however identification of robust forecast spread skill relationships so called reliability has generally proved elusive because such a relationship can depend on many factors for a perfect forecast model statistical considerations indicate that ensemble spread is only a good predictor of skill in cases where day to day variations in the spread are significant compared to the climatological variance houtekamer 1993 whitaker and loughe 1998 however even in this case the maximum correlation between the spread and skill that one can expect is 0 8 conversely when the day to day variations in ensemble spread are small compared to climatology there is generally a very low correlation between spread and skill the correlation between ensemble spread and forecast skill also depends on the choice of metrics used hopson 2014 furthermore imperfections in the forecast model compound the problem and it is generally necessary to calibrate the ensemble in some way to account for the influence of model error a review of the extensive literature on ensemble numerical weather prediction reveals a range of experiences regarding the relationship between spread and skill see grimit and mass 2007 for a review as noted in sections 2 2 and 2 3 for the experimental set up considered here x f represents the mean of an infinite ensemble of forecasts i e the expected value of x thus it is of interest to explore the extent to which the forecast error variance given by the diagonal elements of uf t u t aka the spread can be used as a predictor of the skill of x f fig 7i l show the total expected error variance i e spread in 12 day forecasts initialized from the strong constraint 4d var analyses of cycles 21 30 based on the leading 30 eofs of the forecast error covariance matrix a comparison with fig 7a d indicates that by and large regions of high spread generally correspond to areas where the forecast errors are largest while the agreement is not perfect it is encouraging further investigation is warranted to more formally quantify the relationship between forecast skill and expected forecast error variance for the circulation environment considered here this will be the subject of a future study 6 non normal and modal error growth 6 1 hessian singular vectors following ehrendorfer and tribbia 1997 the eofs of the forecast error covariance matrix uf t u t are in fact the left singular vectors of the matrix l t u m f 0 t a 0 1 2 where recall that m f 0 t is the propagator of the tangent linear model linearized about the forecast x f see fig 1 singular value decomposition of l yields 16 l t ψ i λ i 1 2 s ı l s ı λ i 1 2 ψ i where ψ i represent the eofs and s ı are the right singular vectors introducing the scaled singular vector s i a 0 1 2 s ı the associated eigenvalue problem for s i becomes m f t t 0 u t u m f 0 t s i λ i a 0 1 s i subject to the orthonormality condition s i t a 0 1 s j δ i j where δ i j is the kronecker delta function the vectors s i are referred to as the hessian singular vectors barkmeijer et al 1998 so called because a τ 1 is the hessian of the 4d var cost function for convenience the name is carried over here to a 1 at other times during the analysis window from the orthonormality condition the hessian singular vectors s i define a unit hyper sphere at the forecast start time t 0 however during the forecast interval the hessian singular vectors evolve into the eofs according to ψ i λ i 1 2 u m f 0 t s i and the unit hyper sphere evolves into the hyper ellipsoid described by the forecast error covariance discussed in section 4 therefore associated with each eof ψ i there is a unique hessian singular vector that over the forecast interval evolves into the eof sma demonstrated that for eofs like those shown in fig 6 the evolution of the hessian singular vectors proceeds via an upscale transfer of energy which means that the forecast errors move to larger scales over time to illustrate fig 8 shows the sst structure of the leading hessian singular vector and associated eof for a representative cycle and clearly displays the upscale transfer of energy in the forecast error sma also demonstrated that hessian singular vectors like that in fig 8a typically grow more rapidly than the most unstable eigenmodes of m f 0 t explored in section 6 2 indicating that the upscale transfer of energy is linked to the interference of the non normal eigenmodes of the underlying time evolving circulation which plays an essential role in forecast error growth 6 2 finite time normal modes the fastest growing eigenmodes of m f 0 t play an essential role in error growth as the forecast lead time increases the eigenvectors of m f 0 t in 10 are often referred to as finite time normal modes ftnms if we denote by ν i ξ i the complex eigenpairs of m f 0 t then υ i 2 is the factor by which any measure of the amplitude of ftnm ξ i changes over the time interval 0 t fig 9a shows υ 1 2 for the leading ftnm ξ 1 as a function of forecast lead time for two cycles that reflect the different behavior of the total variance cycle 9 where total variance first decreases and later increases and cycle 23 where total variance continually decreases with increasing lead time cf fig 3b and c error growth is possible in both cases since υ 1 2 1 in fig 9a for cycle 9 the growth factor υ 1 2 generally increases with lead time while for cycle 23 υ 1 2 changes very little with lead time for an unstable circulation we would usually expect υ 1 2 to increase steadily with forecast lead time and for the autonomous case υ 1 2 would increase exponentially with t therefore a more useful measure of ftnm growth is υ 1 2 t an indicator of the average growth rate fig 9b shows υ 1 2 t versus lead time t for the same two forecast cycles during forecast cycle 9 the average growth rate of ξ 1 decreases during the first 10 days remains low until around t 20 days and increases again for longer lead times this behavior is similar to that of the forecast error variance in fig 3b and c during the same cycle similarly the average growth rate of ξ 1 for forecast cycle 23 decreases with lead time t mirroring the behavior of the forecast error variance during this cycle in fig 3b and c the structure of the eofs for long forecast leads times is also controlled by the most unstable ftnms to illustrate this suppose for a moment that forecast error ε is due solely to the leading unstable ftnm in general the eigenvectors of m f 0 t will form complex conjugate pairs if the leading eigenmode is complex it must be combined with its complex conjugate to yield a real perturbation in which case ε t c t ξ 1 c t ξ 1 in this example where c t is the complex amplitude if we assume that the real and imaginary components of c t are gaussian random variables with zero mean and variance σ 2 then the forecast error covariance is given by e ε t ε t t 4 σ 2 r e ξ 1 r e ξ 1 t i m ξ 1 i m ξ 1 t this will be at most a rank 2 matrix and the two eofs will be given by linear combinations of the real and imaginary components of ξ 1 in the general case several of the leading ftnms will contribute to ε and the eofs will reflect the structure of several modes to illustrate fig 9c and d show the sst structure of the real component of ftnm ξ 3 and eof ψ 1 respectively for the 30 day forecast initialized from the 4d var analysis of cycle 10 in this case there are several growing ftnms with similar growth factors υ 2 is 40 31 12 and 6 for the leading four ftnms and the eof is clearly controlled by ξ 3 in this case fig 9e and f on the other hand show the sst of ξ 1 and eof ψ 2 which are very similar for shorter forecast lead times the link between the leading eof structures and the most unstable ftnms is less pronounced not shown the emergence of coherent and persistent error structures associated with the most unstable ftnms is also reflected in the properties of the auto covariance matrix of the forecast errors uf t t u t e uε t ε t t u t using again jacobi s formula the cyclic properties of the trace and 14 it follows that d ln d e t f t t d t d ln d e t f t f t 1 2 d t where f t and f t are the zero lag forecast error covariance matrices at time t and t respectively fig 4 includes time series of d ln d e t f 30 t d t versus t for 30 day forecasts during cycles 2 and 26 while the volume of the hyper ellipsoid d e t uf 30 t u t 1 2 behaves qualitatively like that associated with f t f t t in fig 3a not shown fig 4 reveals that the rate of change of volume increases as the covariance lag t t decreases therefore the coherence between the spatial structures of the forecast errors ε t at different lead times is increasing which is consistent with the emergence of the most unstable ftnms 6 3 non linearity the dynamics of perturbation growth in shear flows associated with normal modes and the interference of modes is a well understood process e g pedlosky 1979 farrell and ioannou 1996 and perturbations can grow by extracting energy from the underlying time evolving circulation via the familiar processes of baroclinic and barotropic energy conversion this is an appropriate and convenient framework for the evolution of forecast errors considered here since recall we are using energy as the common currency for the various components of the state vector to compute the error covariance matrix in general the same processes that control the formation of the eddies and meanders in model t are also responsible for the growth of forecast errors in model f with this in mind the evolution and properties of the forecast errors will depend on the degree of non linearity of the underlying reference forecast x f cf fig 1 since the processes involved act as the source of energy in the tangent linear model as a measure of the importance of non linearity fig 10a shows the mean local rossby number denoted ζ f averaged over a 400 km wide zonal strip centered in the middle of the model domain i e where the circulation variability is most energetic see fig 2 and computed from the daily averaged surface flow fig 10a indicates that non linearity has the greatest influence on the circulation during the first 10 15 analysis forecast cycles while ζ f reaches modest values 0 2 during these cycles this nonetheless represents a significant departure from the linear quasi geostrophic regime indeed maximum instantaneous in situ values of ζ f can be significantly larger and are o 1 in some cases not shown during this phase of the experiment fig 2a and b indicate that the growth of a zonal wavenumber 2 instability dominates the model t circulation beyond cycle 15 the mean rossby number is generally at or below 0 1 when maximum instantaneous in situ values of ζ f are also lower not shown for these analysis forecast cycles the model t circulation is dominated by the evolution of a zonal wavenumber 1 instability cf fig 2c and d despite the difference in resolution model f mimics the temporal evolution of ζ f for model t although as expected the rossby number is larger in model t not shown fig 10a indicates that the elevated rossby numbers during the first 10 15 cycles occur at short forecast lead times and then taper off suggesting that there will be significant sources of perturbation energy i e forecast error variance during the early phase of these forecasts the subsequent increase in total forecast error variance t r uf t u t i e energy at longer lead times during these analysis forecast cycles as revealed by fig 3b suggests that the stretching of the hyper ellipsoid and the increase in the associated hyper ellipsoid volume in a few cases is due to the sustained growth of perturbations that are excited early in the forecast period and that significantly project onto the fastest growing ftnms that eventually emerge as coherent patterns of error as shown by sma some of this growth is likely to be enhanced by non normal interference of the modes and an upscale transfer of forecast error variance as evidenced by the behavior of the hessian singular vectors discussed in section 6 1 fig 10b shows the spatial variations in the root mean square of ζ f for 12 day forecasts initialized from 4d var cycles 21 30 the regions of elevated rossby number in fig 10b correspond closely with the hot spots of high expected forecast error shown in fig 7i l the resemblance is striking for ssh fig 7i and sst fig 7j and confirms the role of non linearity in controlling local forecast error growth and forecast skill 7 summary and conclusions this paper focuses on the properties of the expected analysis and forecast error covariance matrices that result from 4d var data assimilation analyses of the mesoscale circulation environment that develops in the presence of a baroclinically unstable oceanic temperature front given the ubiquitous nature of this process in the ocean the findings of this work should be widely applicable a novel aspect of this study lies in the methodology used specifically the tangent linearization of the full data assimilation system and its adjoint were used to compute an explicit operator for the expected error covariance this has considerable appeal over other methods such as ensemble approaches that are commonly used to estimate analysis and forecast error covariance matrices since the covariance operator is free of the limitations associated with ensemble size localization methods etc the downside of our approach however is the considerable computational expense involved nevertheless the technique can be applied to modestly sized data assimilation problems of significant theoretical interest such as the case considered here a significant advantage of our method over that computed from an ensemble is that as noted in section 2 eqs 7 and 8 provide an explicit operator for the analysis error covariance matrix and eq 9 for the forecast error covariance matrix which can be used to interrogate intrinsic properties of the system as here using established methods and results of linear algebra our general findings are summarized in fig 11 which shows a schematic of the behavior of the forecast error covariance matrix for two representative forecast cycles that depict the two different scenarios identified these two scenarios are characterized by the development of baroclinically unstable waves with a wavelength corresponding to one channel width zonal wavenumber 1 and one half channel width zonal wavenumber 2 sma computed the growth rates of these two waves and found that the zonal wavenumber 2 instability has a faster growth rate and so it emerges first within the model simulations i scenario 1 the first scenario corresponds to the period spanned by the first half a dozen or so analysis forecast cycles the observed circulation environment is characterized by a fully developed zonal wavenumber 2 instability that subsequently decays during the time interval spanned by the ensuing 30 day forecasts the behavior of the forecast error covariance during this period is summarized in fig 11a using cycle 6 as a representative example fig 11a shows a time series of the forecast error energy for this cycle as a function of forecast lead time and computed from the difference between the forecast state and the 4d var analysis on the same day the initial and final time sst for the forecast are also shown in fig 11a and reveal the decay of the zonal wavenumber 2 instability during the forecast the forecast error grows out to a lead time 20 days after which time it levels off during the error growth phase of this forecast cycle the volume of the hyper ellipsoid associated with the forecast error covariance matrix decreases cf fig 3a which is associated with a convergent drift velocity in the liouville equation that describes the time evolution of the forecast error pdf cf fig 4a for cycle 2 which displays similar behavior to cycle 6 shown here at the same time the total forecast error variance decreases cf fig 3b and the hyper ellipsoid stretches along the directions described by the leading eofs as described in section 5 1 this initial phase of forecast error growth is illustrated schematically in fig 11a by the red ellipsoids during the period beyond forecast day 20 when the forecast error asymptotes to a more constant level the pdf drift velocity becomes divergent cf fig 4a and the forecast error covariance hyper ellipsoid begins to expand cf fig 3a at the same time the total forecast error variance increases cf fig 3b and the hyper ellipsoid is preferentially stretched along the directions associated with the fastest growing ftnms this phase of the forecast error development is also illustrated in fig 11a ii scenario 2 the second scenario in the experiments considered here corresponds to the growth and development of the zonal wavenumber 1 instability that follows after the decline of zonal wavenumber 2 the behavior of the forecast error covariance during this period is summarized in fig 11b using cycle 30 as a representative example the forecast error energy in this case increases during the entire forecast cycle as shown in fig 11b the initial and final time sst for the forecast are also shown in fig 11b and reveal the emergence of the wavenumber 1 instability during the entire forecast cycle in this case the volume of the forecast error covariance hyper ellipsoid decreases cf fig 3a and the pdf drift velocity in the liouville equation remains convergent cf fig 4b for cycle 26 which displays similar behavior to cycle 30 shown here the total forecast error variance at first decreases until around forecast day 18 and then slowly increases cf fig 3b throughout the forecast the hyper ellipsoid stretches along the directions described by the leading eofs as the fastest growing ftnm begin to emerge as illustrated schematically in fig 11b by the red ellipsoids the temporal behavior of hyper ellipsoid volume and total error variance can be further appreciated by appealing to a simple example consider the 2 2 covariance matrix c with eigenvectors λ 1 and λ 2 the total variance is given by λ 1 λ 2 and the determinant by λ 1 λ 2 in cases where the variations in λ 1 λ 2 and λ 1 λ 2 are positively correlated there is no significant restriction on the relative amplitude of λ 1 and λ 2 conversely during times when λ 1 λ 2 increases and λ 1 λ 2 decreases there must be a disparity in the amplitude of the eigenvalues therefore considerable stretching of the error ellipse associated with c will occur along one axis the same principle applies in higher dimensions and illustrates the geometric factors that control the variations in the topology of the hyper ellipsoid associated with the variations of the determinant and trace of the forecast error covariances in fig 3 the close connection between the eofs of forecast error and the ftnms also suggests a disparity in the spectrum of ftnm growth rates which in turn favors non normal forecast error growth due to the interference of the ftnms farrell and ioannou 1996 indeed sma confirmed that non normal growth occurs in this same system leading to up scale energy transfer in the forecast errors as the leading eofs and ftnms emerge cf fig 8 therefore in general forecast errors at small scales are liable to self organize into larger scale coherent structures the difference in the temporal evolution of the forecast error energy between the two cases considered in fig 11 deserves some further comment the leveling off of the forecast error energy in fig 11a may perhaps be associated with non linear saturation of the forecast error amplitude if that is the case then the forecast error covariance uf u t during this phase of the forecast would be largely time invariant i e stationary error statistics in which case the determinant and trace would remain constant in time this is at odds though with fig 3 however eq 13 which describes the time evolution of the forecast error covariance is predicated on the tangent linear assumption in this case the behavior of the total forecast error variance and hyper ellipsoid volume beyond forecast day 20 in fig 3 could perhaps be a symptom of linearization errors indeed the analysis in fig 9b does indicate that during the period under consideration the average growth rate of the leading ftnm receives a boost around forecast day 20 eq 14 provides additional evidence in that the eigenspectrum of the tangent linear operator φ f t comprises complex conjugate pairs of eigenvectors and eigenvalues the real part of the eigenvalues represents the instantaneous growth rate of forecast errors associated with these eigenvectors thus t r φ f equals twice the sum of the instantaneous growth rates of the instantaneous eigenvectors therefore the change in sign of t r φ f in fig 4a is indicative of a switch from predominantly decaying instantaneous modes of φ f to predominantly growing modes however for the non autonomous cases considered here there is no clear relationship between the instantaneous eigenvectors of φ f t and the ftnms of m f 0 t furthermore while fig 11a shows what we believe to be the behavior during a representative example of scenario 1 other forecast cycles during this period exhibit a decline in forecast error energy at a lead time beyond 20 days not shown which is inconsistent with non linear saturation of error amplitude besides it is by no means clear why the forecast error energy during scenario 2 would not saturate over the same forecast lead time if this is indeed the explanation for the behavior during scenario 1 further analysis of these issues and behaviors is clearly warranted there are some critical limitations of the present study that should be mentioned here first no attempt was made to account for model error in calculating the expected analysis and forecast error covariances model error is an unavoidable facet of all real forecast systems so including its influence in the approach presented here represents an important next step indeed the fokker planck equation 12 indicates that the addition of the diffusion term would introduce additional and important influences on the forecast error pdf nonetheless fig 7 shows that even when model errors are not accounted for the expected forecast error covariances can still faithfully describe actual error growth and predictability caution should be exercised here since even though the forecast model employed in this study is imperfect relative to the observed model the paternal twin approach adopted in our experiments is unlikely to mimic actual model errors truly a second limitation of our study is the absence of surface forcing as discussed in section 2 surface forcing can play an important role in frontogenesis and frontolysis the inclusion of forcing and the attendant uncertainties in our experiments would undoubtedly increase the diversity of possible ocean forecast states and enhance the forecast error covariance finally while the time scales in fig 11 refer to the experiments presented in this paper the very general nature of the dynamical processes at work in the circulation considered here suggest that fig 11 may apply more broadly across the range of scales that support the formation and decay of baroclinically unstable fronts while we can offer no specific guidance on how our findings may apply more generally across different space and time scales i e mesoscale or sub mesoscale scaling analysis may shed some light on this and would be a fascinating topic for further research as noted earlier our approach is computationally demanding the computational burden required for each calculation depends on the computational resources available so it is perhaps useful to report the computation time required in terms of the time taken to run a single outer loop 4d var iteration on the computer system available with this in mind let t a represent the cpu time required to perform a single outer loop of 4d var the expected analysis error covariance matrix a n given by 7 involves evaluations of the tangent linearization of the 4d var algorithm k d and its adjoint k d t for each outer loop the cpu requirements of each integration of k d and k d t is t a therefore for an arbitrary vector u a single matrix vector product a n u requires a cpu time 2 n j 1 n j t a where n is the number of outer loops the cost of a matrix vector product of f n t u based on 10 is comparable since the additional integrations of the tangent linear and adjoint models does not add significantly to the computational cost for the case n 1 in all of the examples considered here a single matrix vector product au or f t u is 3 times the cost of a single 4d var calculation the trace and determinant calculations of section 4 using the bai et al 1996 approach described in appendix c are the most costly calculations presented in this study each data point in fig 4a is based on a monte carlo of 900 separate evaluations of au or f t u which requires 2700 t a although the same monte carlo calculation can be used to estimate the trace associated with any f a and f f t such calculations would clearly be prohibitive for problems with a dimension much larger than considered here which is o 1 0 5 conversely the trace estimate calculations using the approach of fisher and courtier 1995 in appendix c are based on 30 separate evaluations of au or f t u which require 90 t a so are much more tractable even for larger problems the cpu time required to compute the eof calculations of section 5 depends on the number of leading members of the eigenspectrum that are desired as a rule of thumb computation of reliable estimates of the n leading eofs require 2n evaluations of au or f t u and 6 n t a this study represents an intersection between a state of the art ocean analysis forecast system and the abstract ideas about forecast error development exposed by linear algebra while our approach is very computationally demanding computer power continues to increase thus it is conceivable that such calculations could be performed for larger more realistic systems in the near future indeed when the roms tangent linear and adjoint models were first developed almost two decades ago moore et al 2004 some of the calculations presented here would not have been possible with the computing facilities available to us at that time there is potentially a wealth of additional information and a deeper understanding of ocean forecast system behavior that could be mined using the approaches described here therefore we should not feel intimidated by the dimension of the everyday forecast problems at hand credit authorship contribution statement andrew m moore conceptualization methodology writing original draft writing review editing software validation formal analysis investigation resources project administration hernan g arango methodology writing original draft writing review editing software declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by a basic research challenge grant from the office of naval research usa n00014 10 1 0476 and by southwest universities research association sura usa as part of the coastal ocean modeling testbed comt na13nos0120139 project we are grateful to the four anonymous reviewers for their positive and helpful comments and to one of the reviewers for pointing out that sparse grid methods could possibly be used to reduce the computational cost of the trace and determinant calculations appendix a energy scaling for the error covariance if we denote by ε the vector of grid point values of errors in free surface elevation ε ζ the horizontal components of velocity ε u and ε v and temperature ε t then following smith et al 2015 u is defined such that e ε t u t uε is the total perturbation energy of the errors given by a 1 e g ρ 0 2 i j ε ζ i j 2 d a i j ρ 0 2 i j k ε u i j k 2 ε v i j k 2 h i j k d a i j ρ 0 2 α g n 0 2 i j k ε t i j 2 h i j k d a i j where g is the acceleration due to gravity ρ 0 1025 kg m 3 is the mean ocean density α 1 6 1 0 4 k 1 is the thermal expansion coefficient of sea water and n 0 3 2 1 0 3 s is a representative value of the brunt väisälä frequency the summations are performed over all roms grid cells in the horizontal i j and in the vertical k where d a i j is the horizontal grid cell area and h i j k is the grid cell thickness the first term in a 1 represents the perturbation potential energy associated with errors in surface elevation the second term is the perturbation kinetic energy due to errors in the horizontal velocity and the last term is the available perturbation potential energy associated with errors in the density recall that only temperature is included in the roms configuration used here and for convenience we have assumed a linear equation of state for the density errors ε ρ ρ 0 α ε t in addition since the grid used here has uniform grid spacing d a the error norm used in all calculations was actually e d a the energy per unit area therefore u is a diagonal matrix with elements given by g ρ 0 2 1 2 g ρ 0 h i j k 2 1 2 and ρ 0 h i j k 2 1 2 α g n 0 as appropriate appendix b covariance from perturbed 4d var analyses as described by gürol et al 2014 the inverse preconditioned stabilized representer matrix r 1 hb h t i 1 in 2 is factorized in the roms dual 4d var system using the lanczos formulation of the b restricted preconditioned conjugate gradient method of gratton and tshimanga 2009 according to b 1 r 1 hb h t i 1 v m t m 1 v m t hb h t where v m is the matrix of lanczos vectors v i arising from m inner loops and t m v m t hb h t r 1 hb h t i v m is a symmetric tridiagonal matrix each lanczos vector represents a conjugate gradient descent direction and the v i are orthonormal according to v m t hb h t v m i m the lanczos vectors v m span a limited subspace of the full control space and as such the subspace orthogonal to v m will not be constrained by 4d var as described in section 2 2 the expected analysis error covariance matrix can be derived by considering an ensemble of 4d var analyses where each ensemble member is computed by perturbing the background x b and the observations y o with perturbations drawn from gaussian distributions n 0 b and n 0 r respectively each set of perturbations leads to perturbations δ v m in the lanczos vectors while the perturbed lanczos vectors will span only a small subspace of the full control space each resulting v m defined by the ensemble will span a different set of subspaces therefore the resulting ensemble of 4d var analyses will span a larger subspace than any single analysis this is illustrated schematically in fig b 1a which shows the case for m 2 fig b 1a shows the directions of the lanczos vectors v 1 and v 2 for the original unperturbed 4d var analysis the subspace that is unconstrained by the 2 inner loops is denoted as v also shown in fig b 1a drawn to scale is the standard deviation of the range of the perturbed lanczos vectors that result from an infinite ensemble clearly some of the perturbed lanczos vectors will project significantly into v thus expanding the subspace spanned by 4d var however there will still be parts of the control space that are unconstrained by 4d var for example consider fig b 1b which shows the case of m 1 for illustrative purposes in this case the subspace unconstrained by 4d var has been divided into two denoted v 1 and v 2 as shown in fig b 1b the perturbed lanczos vectors provide information about v 1 while v 2 remains unconstrained appendix c iterative methods for estimating the determinant and trace of a matrix for the large dimension problem considered here 105 it is not practical to explicitly compute the analysis and forecast error covariance matrices therefore properties such as the determinant trace and eigenspectrum must be calculated using iterative approaches two approaches have been employed in this study the first is based on bai et al 1996 hereafter bfg and is used to estimate the determinant and trace of a matrix since it is based on the lanczos algorithm it can also be used to reliably compute the leading members of the eigenspectrum the second approach is based on fisher and courtier 1995 hereafter fc while this latter approach is more straightforward to implement than bfg it only yields an estimate of the matrix trace a comparison of the trace estimates obtained from the two independent approaches provides a check on the efficacy of the results c 1 the bfg approach the diagonal elements of the real square matrix c can be expressed as the inner product c i i e i t c e i where e i is i th column of the identity matrix furthermore if f c f λ is a smooth function of the eigenspectrum λ of c then e i t f λ e i yields the i th diagonal element of the associated matrix in bfg the trace of f c f λ is replaced by an integral which can then be estimated using different gauss quadrature rules specifically bfg have developed a monte carlo approach to estimate lower and upper bounds on the inner product i u t f c u then if f λ λ the inner product i will yield upper and lower bounds on t r c similarly f λ λ 1 can provide bounds on t r c 1 and f λ ln λ will yield bounds on t r ln c ln d e t c an ensemble of estimates of i j are computed by using different vectors for u j with elements of either 1 or 1 that are chosen at random with equal probability i e algorithm 2 of bfg for each choice of random vector u j the lanczos algorithm golub and van loan 1989 is used to estimate the eigenvalues λ i note that this application of the lanczos algorithm is distinct and separate from that used in the 4d var algorithm described in appendix b all that is required is a routine that evaluates the matrix vector product c u j the inner product estimate resulting from gauss quadrature is then given by i j k 1 m ω k 2 λ k where the weights ω k 2 are derived from the lanczos algorithm itself by applying different rules to the resulting gauss quadrature of the function f λ estimates on the upper u j and lower l j bounds for each i j can be computed using a monte carlo sample of size p the upper and lower bounds of f λ can be calculated as 1 p j p u j and 1 p j p l j respectively in the calculations presented in section 4 m 90 and p 10 p 20 for 30 day forecast lead times and the matrix vector product c u j for each sample member is computed using eq 8 or 10 as appropriate by employing the tangent linear and adjoint of the roms 4d var system c 2 the fc approach the method employed by fc is also based on a monte carlo approach to estimate t r c in this case t r c 1 q j q u j t c u j where q is the sample size and the elements of u are normally distributed as n 0 1 while the practical implementation of this approach is more straightforward than that of bfg it is limited to estimates of t r c the expected percentage error in the trace estimate is given by 100 2 q 1 2 in the calculations of section 4 a sample size q 30 was used which yields an expected error a little shy of 13 to reduce the error to say 1 would require a sample size of 5000 which is impractical a comparison of the bfg and fc estimates of t r ua u t for the expected analysis error covariance matrices a τ eq 8 and a 0 eq 9 and for the expected forecast error covariance matrices t r uf t u t eq 10 at various lead times t are shown in fig c 1 in all cases u defines the energy norm see appendix a for t 30 the two methods yield consistent estimates that fall close to the 1 1 line for t 30 the fc estimates are higher than those of bfg despite the disagreement for these longer lead forecasts fig 3b and c show that on the whole the time evolution of the trace estimates yielded by the two approaches is consistent therefore we feel confident that the bfg determinant estimates in fig 3a are reliable and that the evolution in time is robust 
23934,this paper investigates the performance of three different wave model source term packages in narrow fetch geometries the packages are used to model the sea state in a complex coastal system with narrow fjords on the west coast of norway the modelling system is based on the simulating waves nearshore swan wave model that is forced with winds from a nested atmospheric model and wave spectra from a regional wave model at the boundaries the performances of the recent st6 and two older swan white capping and wind input packages are evaluated by comparing modelled spectra and integrated wave parameters against five wave buoys the comparison covers long term statistics and two case studies of narrow fetch geometries i without swell and ii with swell wind sea conditions swan s original saturation based approach performs best in the fjord system in narrow fetch geometry without swell all packages overestimate the wave energy st6 shows the highest sensitivity to fetch geometry and local wind changes the results indicate that the st6 white capping is too weak to balance its strong wind input keywords waves white capping wind swell fjord st6 swan 1 introduction the development of infrastructure in coastal areas demands accurate information of environmental conditions such as winds and waves knowledge of the local wave climate is essential for a number of marine activities e g aquaculture and maritime and energy applications however the need for long term wave statistics with high spatial and temporal resolution cannot be fulfilled with measurements alone thus numerical simulations are essential to fill these gaps the accuracy of wave model predictions has been significantly improved in recent years e g cavaleri et al 2018 2020 several hindcast and reanalysis datasets have shown good quality in offshore conditions e g for the north atlantic reistad et al 2011 haakenstad et al 2020 and the north sea lavidas and polinder 2019 these advances are mainly due to improved source term formulations and more accurate wind fields from atmospheric models cavaleri et al 2018 the wave field estimates in coastal and semi enclosed areas are less accurate than offshore because of islands shallow waters tides tidal currents and complex orography that affects the quality of the wind forcing as discussed in several studies e g cavaleri and bertotti 2004 ardhuin et al 2007 pallares et al 2014 the orography affects the quality of local wind field estimates and in turn also the wave field estimates in complex coastal areas such as in fjord systems a high resolution atmospheric model can capture orographically steered wind that determines local wave growth christakos et al 2020a the quality of the lateral boundary wave conditions has a major impact on wave predictions in exposed shores christakos et al 2020a performed wave model simulations with and without wind forcing in a fjord system exposed to the open ocean the simulations excluding the extreme cases showed quite similar results in the outermost fjord locations illustrating the dominant role of boundary wave conditions over the locally generated wind sea for coastal applications there is also a need for a high resolution bathymetry inaccuracies in bathymetric data can affect processes such as dissipation due to bottom friction and depth induced wave breaking both of which are often a central part of the performance of nearshore wave models roland et al 2014 suggested a list of factors that affect the quality of modelled significant wave height they found that the second most important factor right after the accuracy of forcing fields is the source term formulations the source terms are empirical approximations of the processes that contribute to wind wave growth decay and spectral evolution in the case of wind generated waves in deep water the source terms are wind input wave dissipation and resonant nonlinear wave wave interaction what we will refer to as the komen approach to parameterize white capping dissipation is widely applied and well established in wave modelling it is based on the pressure pulse model of hasselmann 1974 which was parameterized for wave models by komen et al 1984 it is the default method in swan booij et al 1999 wam the wamdi group 1988 and mike21 sw dhi 2017 and it is an option in wavewatch iii the wavewatch iii development group 2016 and tomawac benoit et al 1997 tomawac 2020 in this approach the white capping dissipation is a function of the mean wavenumber and steepness in mixed wind sea swell conditions the komen approach dissipates more swell energy than in cases with no wind while also overestimating the wind sea height in the presence of swell because of its dependency on the mean wavenumber and steepness see van der westhuysen et al 2007 and references therein an alternative saturation based approach was introduced by alves and banner 2003 and developed further by van der westhuysen et al 2007 this approach removes the dependency on mean spectral steepness by instead employing the local spectral saturation van der westhuysen et al 2007 showed that modelling wave dissipation using a local saturation gave better results in mixed wind sea swell conditions than komen s approach this saturation based approach has also been incorporated in spectral wave models such as swan and tomawac in recent years new developments in white capping and wind input formulations known as st4 ardhuin et al 2010 and st6 babanin et al 2010 have been implemented mainly in wavewatch iii but also in swan for st6 compared to older approaches these formulations are more sophisticated and include newer features such as negative wind input and swell dissipation they also have a high number of tuning options thus allowing more advanced calibration the performance of st6 for open sea conditions have been reported in several works van vledder et al 2016 studied the wave conditions during a severe storm in the southern north sea they concluded that the st6 package gave the best model performance in terms of the spectral shape and several integrated wave parameters including the significant wave height and the spectral period t m 1 0 rogers et al 2012 zieger et al 2015 stopa et al 2015 liu et al 2019 and lavidas and polinder 2019 have tested the st6 source terms across a large number of idealized and real world applications however the new parameterization has not been extensively tested in coastal areas amarouche et al 2019 evaluated st6 and a combination of white capping formula by janssen 1991 and exponential wind growth by komen et al 1984 in the western mediterranean sea they advised the use of a calibrated version of the latter combination due to its better performance and shorter simulation period however in norwegian fjord areas stefanakos et al 2020 found that the wind input and white capping of janssen 1991 systematically overestimates the wave heights our overall objective is to find appropriate source term formulations in swan for white capping and wind input under narrow fetch conditions in semi sheltered seas the location of our investigation is a fjord system fig 1 on the west coast of norway which serves as an excellent example of narrow fetch geometry in the presence of strong wind forcing the wave climate on the west coast of norway is characterized by strong swell from the north atlantic ocean semedo et al 2014 christakos et al 2020b and frequent passages of extratropical systems in addition coastal phenomena such as low level jets christakos et al 2014 and wind channelling christakos et al 2020a induced by topography also affect the local wind sea creating a mixed sea state of wind sea and swell the narrow fetch in itself also affects the growth of the waves pettersson 2004 we base our assessment of the source terms on both long term statistics and two cases of narrow fetch geometries with i no swell and ii mixed wind sea swell three different formulations for white capping and wind input are evaluated against in situ measurements special attention is given to analysis of the different source terms related to the fetch geometry this is to our knowledge the first paper that studies the effect of the narrow fetch geometry on the performance of source term packages in different sea states the paper is organized as follows section 2 describes the modelling system followed by section 3 which describes the data and the methods employed in section 4 we present the overall model performance and selected case studies section 5 discusses our results in section 6 we end by summarizing and concluding our findings 2 description of the modelling system the study area fig 1 is described in christakos et al 2020a in sulafjorden buoys a b c and d breidsundet are deployed and buoy f in the fjord cross section of vartdalsfjorden voldsfjorden and rovdefjorden as shown in fig 1 sulafjorden is approximately 10 km long with an average width of 4 6 km because of its exposure to the norwegian sea the wave climate in sulafjorden is usually characterized by mixed wind sea and swell conditions while the inner parts of the fjord system such as location f are unaffected by swell the fjords are 200 700 m deep much deeper than the shelf area which is less than 100 m over most areas in storm conditions wave dissipation due to bottom friction and depth induced wave breaking occurs off the coast in shallow transitional waters before reaching the fjord system 2 1 the wave model swan the wave model swan is a third generation spectral model mainly developed for nearshore applications the swan wave model is also capable of reproducing fjord wave conditions christakos et al 2020a herman et al 2019 in this study the swan cycle iii version 41 20 is used as a spectral model it estimates the evolution of wave action density n e σ by applying the action balance equation 1 n t c x n x c y n y c σ n σ c θ n θ s σ here e is the wave spectral energy σ the intrinsic circular frequency in absence of a surface current σ ω 2 π f rad s 1 where f is the linear frequency hz and c x and c y are the group velocity vector components in geographical x y space the c σ and c θ represent the propagation in frequency direction σ θ space the term s represents the total source term consisting of in all six source terms in swan 2 s s in s ds s nl4 s nl3 s fric s brk here s in is the energy input by wind s ds is the dissipation induced by white capping s nl4 is the nonlinear wave energy transfer between quadruplets s nl3 is the triad nonlinear interaction s fric is the bottom friction and s brk is the depth induced wave breaking e g holthuijsen 2007 since our study is focused on relatively deep water areas the term for triads is switched off the wind input term contains a linear and an exponential growth term a sensitivity study not shown found that the linear term had only a minor effect on wave growth and is therefore neglected for our fjord applications we therefore focused on s in s ds and s nl4 2 1 1 the komen package in swan the current default white capping dissipation is the pressure pulse model of hasselmann 1974 formulated by komen et al 1984 and defined as e g swan team 2017 3 s ds komen σ θ c ds komen 1 δ δ k k s s pm p σ k k e σ θ here c ds komen 0 24 1 0 4 δ 1 and p 4 are tuning parameters k is the wavenumber and s k e tot is the mean spectral steepness e tot is the total energy of the wave spectrum i e the integral over all frequencies and directions the k and σ are the mean wavenumber and the mean circular frequency the s pm corresponds to the mean spectral steepness of a pierson moskowitz spectrum a study by rogers et al 2003 showed that δ 1 the default value in swan 41 20 improves the wave energy estimates over δ 0 5 proposed by komen et al 1994 the wind input term is estimated according to komen et al 1984 which in turn is based on experimental results by snyder et al 1981 4 s in snyder σ θ max 0 0 25 ρ a ρ w 28 u c cos θ θ w 1 σ e σ θ here u τ ρ a where τ is the wind stress is the friction velocity the estimation of u is made according to zijlema et al 2012 c is the phase speed of the wave component and ρ a and ρ w are the air and water densities respectively the direction of the spectral wave component is θ and θ w is the direction of the wind this white capping wind input package will hereafter be denoted komen eq 4 is based on field observations of weakly forced waves where u 5 the wind speed at 5 m height had values up to 8 m s 1 snyder et al 1981 for wind speed ranges of 2 12 m s 1 hasselmann and bösenberg 1991 came up with similar results to snyder et al 1981 thus we consider eq 4 appropriate for weak to moderate wind conditions but its validity is not proven for strong wind events 2 1 2 the westh package as an alternative to the komen approach van der westhuysen et al 2007 modified the saturation based method of alves and banner 2003 and implemented it in swan in contrast to the approach taken by komen et al 1984 this method expresses white capping without the s and k dependencies which are problematic in mixed wind sea and swell conditions this method is based on experimental results showing that white capping is associated with the nonlinear hydrodynamics within wave groups the formulation reads 5 s break westh σ θ c ds westh b k b r p 2 tanh k d 2 p 0 4 g k e σ θ here c ds westh 0 50 1 0 4 is the white capping parameter d is the water depth g is the acceleration due to gravity and b k e σ k 3 c g c g is the wave group velocity is the azimuthally integrated spectral saturation the latter is well correlated with the breaking probability banner et al 2002 when b k is below the threshold saturation level b r 1 75 1 0 3 there is no breaking but a background dissipation of wave component is present with p 0 when b k exceeds b r there is wave breaking and p equals a calibration exponent p 0 to give a smooth transition between these two conditions p is expressed as function of b k alves and banner 2003 the dissipation is separated into a breaking and a non breaking part swan team 2017 6 s ds westh σ θ f br σ s break westh 1 f br σ s ds non break the s ds non break term is expressed by eq 3 similar to the parameter p f br is a smooth transition function swan team 2017 the wind input applied in the saturation based parameterization is according to yan 1987 which combines the expressions by komen et al 1984 and plant 1982 7 s in yan σ θ c 1 u c 2 c 2 u c c 3 cos θ θ w c 4 σ e σ θ where c 1 4 1 0 2 c 2 5 52 1 0 3 c 3 5 2 1 0 5 c 4 3 02 1 0 4 are coefficients given by swan team 2017 for strong wind conditions i e young wind sea u c 0 1 the wave growth rate has a quadratic relation to the inverse wave age u c for weaker winds i e older sea u c 0 1 the relation becomes linear similar to komen the estimation of u is according to zijlema et al 2012 this package is activated in the swan model with the command gen3 westh and is hereafter denoted westh 2 1 3 the st6 package st6 is a recent formulation included in swan version 41 20 the package is also implemented in wavewatch iii as documented by zieger et al 2015 the st6 implementation in swan has only minor differences to that of wavewatch iii rogers et al 2012 swan team 2017 st6 is an observation based scheme that contains wave turbulence interaction swell decay positive and negative wind input and two phase white capping dissipation the wind input formulation is given as 8 s in st6 σ θ ρ a ρ w σ g b n w e σ θ where 9 g 2 8 1 tanh 10 b n w 11 here b n a σ e σ k 3 c g is the spectral saturation a measure of steepness and a is the narrowness of the directional distribution the narrowness is defined as a 1 0 2 π e σ θ e max σ d θ where e max σ is the maximum density over all directions but a is set to unity for dissipation calculations in swan in addition to the positive wind input st6 also allows a negative wind input component that reduces wave growth in the part of the spectrum that experiences adverse wind stress this is formulated as 10 w σ θ w 1 σ θ a 0 w 2 σ θ where w is expressed as the sum of the positive wind input 11 w 1 σ θ max 2 0 s ws u c cos θ θ w 1 and the adverse negative wind input 12 w 2 σ θ min 2 0 s ws u c cos θ θ w 1 here a 0 is a tuning parameter and s ws is a scaling parameter which is set to 32 in swan 41 20 there are three available formulations in st6 for the estimation of u c d u 10 where c d is the drag coefficient in the wave model following the swan notation the formulations are hwang default rogers et al 2012 fan fan et al 2012 and ecmwf guenther et al 1992 in the hwang formulation the drag coefficient is only a function of wind speed on the other hand fan and ecmwf use an iterative procedure for estimating u based on the actual seas state in fan formula u is a function of both wave age and wind speed whereas in ecwmf it is a function of air flow and wave induced stress the white capping term s ds st6 is the sum of two dissipation components t 1 and t 2 e g rogers et al 2012 the component t 1 is the inherent breaking related to instabilities of waves and t 2 is a cumulative term that describes the dissipation of shorter waves triggered by longer breaking waves 13 s ds st6 σ θ t 1 σ t 2 σ e σ θ here 14 t 1 σ a 1 a σ σ 2 π e σ e t σ e t σ p 1 and 15 t 2 σ a 2 σ 1 σ a σ 2 π e σ e t σ e t σ p 2 d σ the threshold spectral density is e t b nt a σ c g k 3 where b nt a 1 and a 2 are constants p 1 4 and p 2 4 are power coefficients and σ 1 is the first prognostic frequency a key feature of the st6 formulation is that there is no breaking unless the spectral energy density at that particular frequency σ exceeds the threshold e t σ 2 1 4 wave wave interactions bottom friction and depth limited breaking the four wave interactions quadruplet are modelled by the discrete interaction approximation dia by hasselmann et al 1985 nonlinear triad interaction is turned off since their effect is minor in our deep water area of interest the bottom friction is represented by the jonswap bottom friction hasselmann et al 1973 where c fric 0 067 m 2 s 3 is the bottom friction coefficient according to bouws and komen 1983 finally the depth limited wave breaking is represented by the formulation of battjes and janssen 1978 with default settings of α 1 and γ 0 73 3 data and methods the model was run in non stationary mode with spherical coordinates and a time step of 10 min with 4 iterations of the implicit scheme the spectrum is resolved by 36 directional bins 10 directional resolution and 32 logarithmically spaced frequencies from 0 04 to 1 hz the inner domain d2 with a grid resolution of 250 m 250 m red rectangle in the left panel of fig 1 is nested into the outer grid d1 of 1 km 1 km the simulation period is from october 1 2016 until april 30 2018 3 1 wind forcing because of the complex fjord topography a high resolution wind forcing is essential to faithfully reproduce local wind conditions such local features may have a considerable effect on the wave growth in a fjord as discussed by christakos et al 2020a and herman et al 2019 in our study the advanced research wrf skamarock et al 2008 state of the art numerical weather prediction model version 3 5 0 is applied to downscale the reanalysis era interim dee et al 2011 to a grid resolution of 0 5 km for the fjord system christakos et al 2020a this downscaled wind product is hereafter called wrf0 5 christakos et al 2020a showed that wrf0 5 slightly overestimated high wind speeds in the innermost locations of our study area but nevertheless performed better than other available wind products the era5 reanalysis hersbach et al 2020 the hindcast nora10 reistad et al 2011 and the operational numerical weather prediction model arome2 5 wind input to the wave model is linearly interpolated to the swan grid from the 10 m height wind of wrf0 5 3 2 boundary wave conditions the wave conditions at the grid boundaries of the outer model domain are obtained from the nora10 hindcast with 3 hourly temporal resolution information on the spectral nesting and interpolation in breivik et al 2009 the wave component of nora10 is a 10 km wam model forced with winds from the high resolution limited area model hirlam nested inside a 50 km north atlantic wam model forced by era 40 winds reistad et al 2011 the wave component is a modified version of the wam cycle 4 model guenther et al 1992 set up on a rotated latitude longitude grid similar to the rotated spherical grid used for hirlam the outer domain covers the north atlantic with a 50 km grid resolution thus allowing realistic swell propagation from the north atlantic to the norwegian coast twenty four directional bins and twenty five frequencies 0 0420 to 0 4137 hz are used for the nora10 model setup no offshore measurements are available to verify the spectralboundary conditions from nora10 but several studies have investigated the quality of the nora10 wave hindcast according to aarnes et al 2012 a low bias of significant wave height between nora10 and observations located in the north sea and the norwegian sea is observed bruserud et al 2016 found good agreement between nora10 and wave observations in the northern part of north sea 3 3 measurements measurements from seawatch wavescan buoys fugro 2012 available via met norway s thredds service furevik et al 2020 are used to evaluate the performance of the different source term packages the measurement data contains integrated wave parameters such as significant wave height peak wave period mean wave period mean wave direction as well as wind speed and wind direction in addition wave spectra are provided for specific storm cases by fugro oceanor as norway the buoy wind sensors are placed at 4 1 m above the sea level buoys d at 345 m water depth a at 375 m b at 325 m c at 450 m and f at 217 m are deployed in the fjord system as illustrated in fig 1 we used available measurement data from the following periods october 14 2016 april 30 2018 location d october 13 2016 april 30 2018 locations a b april 27 2017 april 30 2018 location c and november 29 2017 april 30 2018 location f 3 4 wave and fetch parameters we analyse the spectral wave parameters of significant wave height h s the mean period t m 01 the peak period t p and mean wave direction θ the model t m 01 is calculated by integrating up to maximum observed frequency we use the logarithmic wind profile to adjust the observed wind speed from 4 1 m to 10 m u 10 with a roughness length of 0 0002 m e g wang et al 2018 christakos et al 2020a to investigate how the complex fetch geometry of the fjord system affects the performance of the source term packages the dimensionless effective fetch x is calculated using the following equations 16 x g x eff u 10 2 where u 10 is the model 10 m wind speed at the buoy location and x eff is the effective fetch estimated in a 30 degree sector with 5 degree increments 17 x eff i 0 6 x i cos 2 ϕ i i 0 6 cos ϕ i here x i is the fetch in a straight line to the coast and ϕ i is the angle from the wind direction in sectors i 0 1 6 the dimensionless width is defined as 18 x w g x w u 10 2 here x w is the width distance across the fetch the x w is quantified because the narrowness of a basin restricts the growth of the wave height even if the fetch is long pettersson 2004 the right hand panel of fig 1 shows estimated x i and x w at location f similar estimation is performed for locations d a b and c not shown where unlimited fetches are excluded in our study finally the normalized bias of h s is defined as 19 nbi h s mod h s obs h s obs where h s mod and h s obs are the modelled and observed significant wave height the use of nbi allows comparisons between areas with different wave climate e g exposed versus sheltered fjord locations for the estimation of nbi only h s mod and h s obs values greater than 0 2 m are considered 4 overall model performance and fetch geometry taylor diagram of error metrics taylor 2001 for h s is illustrated in fig 2 the applied error metrics same definitions as in christakos et al 2020a are the correlation coefficient r normalized standard deviation nstd and normalized centred root mean square error crmse the different source term packages show similar performance at the most exposed locations d and a with good scores for error metrics with nstd close to 1 and r approximately 0 9 further into the fjords the model performance degrades 0 8 r 0 9 and nstd 1 1 with the worst performance at locations c and f westh yields the best results in terms of h s for most of the measurement locations d a b and c while st6 performs worst in location f we plot the nbi as a function of dimensionless fetch to investigate potential over under estimation related to the fetch geometry fig 3 in all the measurement locations the highest overestimation of h s is observed at short medium x and decreases as x increases as a power function for large x the different source term packages show near identical results for most of the domain in exposed locations a and b the performance of the different packages has a weak dependency on x since these areas are affected mainly by strong swell only for low x which are linked to high wind speeds we observe some dependency if judged by the fits to the data all three packages perform similarly for long fetches for short dimensionless fetches the westh package has the lowest nbi while st6 and komen coincide in the slightly more sheltered location c the fits of the westh and st6 packages still agree for the longest fetches slightly outperforming the komen package nonetheless for short fetches the behaviour at c is similar to that at a and b in the most sheltered location f nbi depends more strongly on x and we observe the highest nbi difference between the source packages the wave climate in this location is characterized by no swell and strong local wind sea which is affected as expected by the wind structure and the complex fetch geometry we identify three x ranges i short x 1 0 2 ii medium 1 0 2 x 1 0 4 and iii large x 1 0 4 the short range represents mainly very short fetches x 5 km the medium range 5 km x 21 km with moderate to strong winds contains the values with the highest overestimation by the different source term packages for all parameterizations the nbi tends to zero for the largest range low wind conditions although all packages overestimate h s at f st6 shows the highest overestimation in both short and medium ranges by up to approx 50 compared to komen this suggests that st6 feeds too much energy to the dominant frequency within these ranges a clear relation between nbi and x w is also evident in fig 4 the x w is an indication of how the width restricts the growth within the fjord similar to x the nbi is high for short medium x w while it tends to zero for large x w this indicates a degrading model performance when the fetch geometry becomes more narrow which is especially evident for st6 the majority of the high nbi at f cases are linked to southeast wave direction yellow fetches width in fig 1 which is characterized by strong wind channelling christakos et al 2020a all in all at f the dimensionless width is a better explanation for the model performance than the dimensionless effective fetch even though the effective fetch contains some information about the narrowness of the fetch geometry in the following we investigate two cases i narrow fetch geometry without swell and ii narrow fetch geometry with mixed wind sea swell case i focuses on the most problematic area location f where the highest differences between the packages are observed and a clear link between fjord geometry and nbi exists location f which is located at the junction between three narrow fjords can be considered a natural laboratory for very narrow fetch conditions the case ii presents a case of mixed sea state locations d a and b under strong wind forcing at semi closed and narrow fetch geometry 4 1 case i narrow fetch geometry with no swell on january 15 2018 offshore winds greater than 15 m s 1 from southeast generated a strong local wind sea in location f fig 5 during most of the time the dimensionless fetch is between 1 0 2 and 1 0 3 and the dimensionless width varies roughly from 70 and 350 at location f where high nbi is observed figs 3 and 4 although the complex orography caused wind channelling in the fjord the high resolution wrf model has been shown to reproduce such local effects well christakos et al 2020a the observed h s in location f reached 1 m with θ about 130 150 fig 5 the t p and t m 01 ranged from 2 5 to 4 s and 2 5 to 3 s respectively modelled and observed wind directions were in good agreement varying from 120 160 a slight overestimation of the modelled wind speed at buoy location f of about 2 3 m s 1 was observed however considering the complex fjord orography the quality of the wind forcing can be characterized as good regarding h s we see large differences between the different source term packages st6 exhibits the highest values of h s with up to 1 m difference compared to observations the default package komen shows the best performance with differences of at most 0 3 m compared to the observations similar results are observed for t p and t m 01 st6 shows the largest over estimation compared to the observed values the spatial variation of s in ds u 10 and h s is presented in fig 6 the spatial variation of s in ds reflects the u 10 variation channelling within the fjord as expected similarities in spatial variation between s in ds h s and t p not shown are observed up to 40 of the fjord area has h s 1 5 m and t p 4 5 s in the st6 simulations the respective area for komen and westh is much smaller and concentrated around buoy f to further analyse the model performance the source terms s in s ds s nl4 and their sum s in ds nl4 are plotted as a function of f for four selected times from january 14 2018 at 00 utc calm conditions to january 15 2018 at 09 utc peak of wind speed fig 7 st6 shows much higher s in peak levels than the other packages more specifically for the dominant waves the absolute values of s in and s ds are roughly an order of magnitude higher in st6 than in komen on january 15 2018 at 09 utc source terms of komen and westh show similar performance with the latter giving slightly higher values as expected s nl4 reflects the magnitude of s in and s ds consequently the sum s in ds nl4 in st6 shows the highest values about 3 times as high as in komen westh and komen shows similar values with the former being slightly higher the energy of the dominant waves is about 3 4 times as high in st6 as the observed values fig 8 top panel komen and westh overestimate the energy of the dominant waves by about 50 in addition st6 underestimates the peak frequency by about 0 1 hz while komen and westh underestimate it by about 0 05 hz the best performance is found with komen both in terms of peak energy density and the location of the peak frequency for the high frequency tail f 0 3 hz st6 matches the observations while komen and westh show too high energy densities the high energy overestimation of the dominant waves in st6 for such narrow fetch geometries merits further analysis for this reason we investigate the sensitivity of st6 on i wind drag formulations and ii the narrowness a i the wind drag formulations are used to scale the input wind forcing u 10 to u which is applied to s in applying ecmwf and fan wind drag formulas the density level at the peak has reduced by 15 and 23 respectively while there is no negative impact on the good performance of the spectral tail fig 8 top panel ii as mentioned in section 2 1 3 the narrowness a in s ds st6 is omitted by setting it to unity default using the actual a a 1 with the wind drag formulations by hwang fan we observe a reduction of the density level peak by about 33 50 fig 8 bottom panel thus almost matching the performance of the other packages however the use of the actual a yields an overestimation in the spectral tail the use of fan with a constant narrowness a 1 2 in s ds st6 shows similar results to when using a 1 for the dominant waves with only a small negative bias for the spectral tail 4 2 case ii narrow fetch geometry with mixed wind sea swell on december 26 2016 a severe winter storm known as urd passed the norwegian sea and reached the west coast of norway significant wave heights up to 6 m were recorded in location d fig 9 shows the time variation of the model and observed wind speed and wind direction for the storm urd at location d a and b the wind speed exceeded 15 m s 1 at location d and reached 20 m s 1 at locations a and b the model wind speed and direction agrees with observations at locations a and b but the wind speed is slightly overestimated at d h s reached 3 6 m at a and 2 2 m at b the peak wave period t p and the mean wave period t m 01 varied from 8 to 16 s and 4 to 10 s respectively the mean wave direction θ was westerly and northwesterly differences between the source term packages are observed mainly in h s which is over predicted by all packages but westh and komen perform best they show similar performance for θ being in good accord with observed values the packages behave nearly identically for t p following the observations the high variation in the observations is likely caused by statistical variability which is not expected to be reproduced by the model in sheltered locations swell energy is less dominant compared to wind sea thus the peak period is shifting between values of 8 s old wind sea and 16 s swell the model shows good performance for t m 01 with some deviations observed between the source term packages at location b westh and st6 agree on the mean period t m 01 showing slightly higher values than those of komen there are strong similarities in the spatial variation of s in ds magnitude fig 10 top komen and westh show similar s in ds values while the values of st6 are considerably higher especially in sulafjorden where strong wind channelling is observed fig 10 middle the s fric and s brk are significant only in the small shallow areas around islands off the fjord system not shown st6 shows the highest h s values offshore up to 10 7 m it also shows the deepest penetration of high waves into the sulafjorden followed by westh and then komen fig 10 bottom the lowest wave heights both offshore and within the fjord system are shown by komen differences are mainly seen within the fjord system where st6 shows higher h s because of larger s in ds values compared to komen and westh the spatial variation of t p shows insignificant differences between the packages along the coast since it is mainly affected by the boundary conditions not shown along the coast t p is 17 5 s while being below 5 s within the fjord system all the packages predict similarly the reduction of t p outside sulafjorden that are due to changes in the bathymetry differences in t p are mainly observed in sulafjorden where st6 shows a deeper penetration of longer waves within the fjord to compare the ability of the packages to model the observed shape of spectra fig 11 presents the average frequency spectra in the linear and the logarithmic scale in location d most exposed to the open sea the different packages show quite similar spectral shapes and magnitudes some differences are detected in the inlet of sulafjorden location a for frequencies f 0 1 hz and the differences are even more pronounced within sulafjorden location b for the high frequency tail f 0 3 hz the different source term packages perform quite similarly at location d deviations between the packages are detected at locations a and b where st6 and westh show the best performance when evaluated against observations 5 discussion the saturation based white capping approach westh provides the best model performance in terms of h s in locations where mixed wind sea swell conditions are observed this is in accordance with findings of van der westhuysen et al 2007 who showed that the saturation based formulation outperformed the pressure pulse approach of komen in such mixed conditions the results show a strong wind input in st6 which is particularly problematic in case i with the extremely narrow fetch geometry in narrow fetch geometry with no swell st6 captures the energy of the high frequency tail well but overestimates strongly the energy of the dominant waves yielding too high h s in these areas the fetch geometry plays a crucial role in wave dynamics within the medium fetch range fetches between 5 and 21 km under moderate to strong wind conditions all the applied packages perform quite poorly location f this overestimation is especially strong for st6 because of a strong s in which is unbalanced due to a weak s ds the highest nbi is found within the medium range about x 1 0 3 at narrow fetch geometry location f e g fetches at 20 km with a wind speed of about 14 m s 1 for much larger scales these dimensionless fetch values can be equivalent to a fetch of 100 km with wind speeds at 30 m s 1 large values of nbi are also detected at approx x w 300 in location f for fjord areas this represents widths of about 3 km with a wind speed of about 10 m s 1 if we scale it again to larger regions it is approximately equivalent to a width of 20 km with wind speeds of 25 m s 1 therefore the inaccuracies detected in this study might be relevant also for significantly larger water bodies during high winds several factors can cause the high energy observed in narrow fetches by st6 they can be grouped into two categories i direct factors which are related to the formulation of wind input and white capping and ii indirect factors that are connected to effects triggered by e g non linear interactions wind drag and forcing 5 1 i direct factors rogers et al 2012 found a problematic energy growth in st6 at the young wave age stage due to i the quadratic relationship between s in and inverse wave age and ii the dependency of s in on the spectral saturation b n eq 8 in komen s in has a linear dependency on the inverse wave age for all wind conditions in westh the relationship is linear for low winds and quadratic for stronger winds the linear relationship in komen potentially explains the relatively low s in values the source term formulations of westh and st6 use an isotropic spectral saturation according to ardhuin et al 2010 using adirection dependent saturation can allow for a control of directional spread and improve the overall results according to pettersson 2004 a narrow fetch geometry influences the directional distribution of the dominant waves hence an isotropic white capping might therefore not be fully appropriate for fjord wave modelling accounting for the directional spread in s ds st6 by using the actual narrowness a shows an improvement for the dominant waves but as discussed by rogers et al 2012 it leads to lower dissipation in the high frequencies in narrow fetch geometries selecting a constant not unity narrowness e g a 1 2 in case i can improve the performance for both the larger dominant and shorter waves babanin et al 2010 suggested that dependence between t 1 2 and the exceedance level e e t should be linear however rogers et al 2003 found that a nonlinear relationship obtained by setting p 1 p 2 4 the default in swan is essential to balance the strong s in in our case these default values seem to provide still too weak s ds and a further increase of nonlinearity by setting p 1 p 2 6 improves considerably the wave height estimates not shown however this increases the dissipation in high frequencies with a negative impact on spectral tail even if the model performance in exposed locations is generally good for st6 there are inaccuracies regarding the density peak level which describes the energy of the dominant waves rogers et al 2012 presents a third dissipation term t 3 in their study see also the cumulative steepness method csm by van vledder and hurdle 2002 and hurdle and van vledder 2004 which provides a formulation for the straining mechanism in contrast to t 2 this term accounts for the change of the short wave steepness by the underlying longer waves the effect can be considered important in the exposed fjord locations where short waves local wind sea coexist with non breaking larger waves swell or old wind sea its implementation in s ds may provide a better balance to strong s in under mixed swell wind sea conditions we expect that this term should have a minor effect on sheltered locations with weak or no swell however more observational studies and numerical simulations are required to investigate this effect the wind input in the applied packages assume a stable air sea boundary layer since changes in the air and sea temperatures or densities are not considered in their formulation ρ a ρ w is constant in swan this assumption might not be appropriate in our study area norwegian fjord climate is associated with i rapid changes in weather conditions e g sharp changes in air density by atmospheric front passages and ii proximity to land with fresh water discharges that influence the density ratio and consequently the wind input 5 2 ii indirect factors christakos et al 2020a found that wrf0 5 has an overall good performance in the fjord system however the evaluation is based on the 5 measurement locations and did not draw firm conclusions about the wind quality over the whole fjord system considering the complexity of the orography possible inaccuracies in wind forcing along the fjords are transferred to s in affecting the wave growth the energy growth in st6 is much stronger than in the other packages in contrast to older wind input formulations which add the bulk around the spectral peak the s in in st6 adds more energy to higher frequencies rogers et al 2012 this possibly affects the dia which in turn will redistribute energy to lower frequencies more vigorously growing the wave field faster compared to other formulations therefore the resulting high density level at location f could be to some extent due to dia liu et al 2019 discussed that their st6 results using dia show higher sensitivity to fetch geometry compared to the generalized multiple dia tolman 2008 gmd and the webb resio tracy method webb 1978 tracy and resio 1982 wrt the use of different wind drag formulations in narrow fetch conditions revealed their importance the wind drag formulations that take into account the wave impact on u estimation using iterative methods i e fan and ecmwf provide more accurate results than the default formulation in st6 in narrow fetches even small changes in the vertical wind profile induced by waves can affect the spectral shape hence accounting for the wave atmosphere coupling can provide a more physical representation of u and consequently more accurate s in there are other types of forcing which are not considered in the present study but might affect the fjord wave modelling the rain river run off surface currents and tides may play an important role in the fjord wave evolution rain affects the wind input and dissipation of surface waves more details in cavaleri et al 2015 during heavy rainfall or melting of snow or ice river run off creates freshwater plumes that can also influence the wave growth and direction surface currents and tides can affect the waves through several processes such as a change of the relative wind speed the doppler shift the concertina effect e g ardhuin 2019 wave refraction and energy bunching stretching future studies using a coupled ocean wave atmosphere system is needed to quantify and evaluate the importance of these effects in a fjord system 6 summary and conclusions accurate modelling of wave conditions in complex coastal areas is a challenging issue in addition to the uncertainties due to the quality of the boundary wave conditions and the wind forcing the choice of physics is found to be very important we have investigated the performance of three different source term packages available in swan the packages were evaluated by comparing their results against buoy measurements at five different locations using both long term statistics and detailed case studies all applied packages perform well for the most exposed locations d and a for the more sheltered locations the packages show pronounced differences the westh package provides the best overall performance in terms of h s in most measurement locations with mixed swell wind sea conditions d a b and c the komen package performs the best in terms of h s in the location with no exposure to the open sea f st6 package shows a strong positive h s bias in sheltered areas no swell for high frequencies the different source term packages perform quite similarly at the outermost location while significant deviations between the packages are detected at locations a and b where st6 and westh are the most accurate in exposed areas a weak dependency between fetch geometry and model accuracy is found as expected because of the dominant role of swell in narrow fjord areas with no swell the fetch geometry has a distinct effect on model performance in such areas the narrow fetch combined with wind channelling induced by the steep mountains surrounding the fjord significantly affects the model results these conditions give rise to large differences in the performance of the applied source packages the effect that the fetch geometry has on the accuracy of h s is best explained by the dimensionless width of the basin x w as opposed to the dimensionless effective fetch values of x w that were found problematic for the wave model are possible even in larger scales during sufficiently strong wind in the fjord system the deep water source terms s in and s ds contribute the most to the total energy the st6 white capping is too weak to balance the strong s in resulting in overestimation of density spectra and thus of h s both cases show that st6 is more sensitive to narrow fetch geometry and variations in the local wind speed than the other packages credit authorship contribution statement konstantinos christakos conceptualization methodology software formal analysis investigation data curation writing original draft writing review editing visualization jan victor björkqvist conceptualization methodology investigation writing review editing laura tuomi methodology supervision writing review editing birgitte r furevik methodology supervision writing review editing project administration øyvind breivik methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the four reviewers for their thoughtful and insightful comments that helped in improving the study furthermore we are thankful to erick w rogers oceanography division naval research laboratory stennis space center mississippi usa who provided the swan code revision 358 of swancom2 ftn for the estimation of narrowness in the white capping of st6 we are grateful to lasse lønseth fugro oceanor as norway and øyvind byrkjedal kjeller vindteknikk as norway who provided the wave spectral data and the wind forcing data respectively the study was funded by the norwegian public roads administration under the coastal highway route e39 project the bathymetry data is derived by emodnet bathymetry consortium 2018 
23934,this paper investigates the performance of three different wave model source term packages in narrow fetch geometries the packages are used to model the sea state in a complex coastal system with narrow fjords on the west coast of norway the modelling system is based on the simulating waves nearshore swan wave model that is forced with winds from a nested atmospheric model and wave spectra from a regional wave model at the boundaries the performances of the recent st6 and two older swan white capping and wind input packages are evaluated by comparing modelled spectra and integrated wave parameters against five wave buoys the comparison covers long term statistics and two case studies of narrow fetch geometries i without swell and ii with swell wind sea conditions swan s original saturation based approach performs best in the fjord system in narrow fetch geometry without swell all packages overestimate the wave energy st6 shows the highest sensitivity to fetch geometry and local wind changes the results indicate that the st6 white capping is too weak to balance its strong wind input keywords waves white capping wind swell fjord st6 swan 1 introduction the development of infrastructure in coastal areas demands accurate information of environmental conditions such as winds and waves knowledge of the local wave climate is essential for a number of marine activities e g aquaculture and maritime and energy applications however the need for long term wave statistics with high spatial and temporal resolution cannot be fulfilled with measurements alone thus numerical simulations are essential to fill these gaps the accuracy of wave model predictions has been significantly improved in recent years e g cavaleri et al 2018 2020 several hindcast and reanalysis datasets have shown good quality in offshore conditions e g for the north atlantic reistad et al 2011 haakenstad et al 2020 and the north sea lavidas and polinder 2019 these advances are mainly due to improved source term formulations and more accurate wind fields from atmospheric models cavaleri et al 2018 the wave field estimates in coastal and semi enclosed areas are less accurate than offshore because of islands shallow waters tides tidal currents and complex orography that affects the quality of the wind forcing as discussed in several studies e g cavaleri and bertotti 2004 ardhuin et al 2007 pallares et al 2014 the orography affects the quality of local wind field estimates and in turn also the wave field estimates in complex coastal areas such as in fjord systems a high resolution atmospheric model can capture orographically steered wind that determines local wave growth christakos et al 2020a the quality of the lateral boundary wave conditions has a major impact on wave predictions in exposed shores christakos et al 2020a performed wave model simulations with and without wind forcing in a fjord system exposed to the open ocean the simulations excluding the extreme cases showed quite similar results in the outermost fjord locations illustrating the dominant role of boundary wave conditions over the locally generated wind sea for coastal applications there is also a need for a high resolution bathymetry inaccuracies in bathymetric data can affect processes such as dissipation due to bottom friction and depth induced wave breaking both of which are often a central part of the performance of nearshore wave models roland et al 2014 suggested a list of factors that affect the quality of modelled significant wave height they found that the second most important factor right after the accuracy of forcing fields is the source term formulations the source terms are empirical approximations of the processes that contribute to wind wave growth decay and spectral evolution in the case of wind generated waves in deep water the source terms are wind input wave dissipation and resonant nonlinear wave wave interaction what we will refer to as the komen approach to parameterize white capping dissipation is widely applied and well established in wave modelling it is based on the pressure pulse model of hasselmann 1974 which was parameterized for wave models by komen et al 1984 it is the default method in swan booij et al 1999 wam the wamdi group 1988 and mike21 sw dhi 2017 and it is an option in wavewatch iii the wavewatch iii development group 2016 and tomawac benoit et al 1997 tomawac 2020 in this approach the white capping dissipation is a function of the mean wavenumber and steepness in mixed wind sea swell conditions the komen approach dissipates more swell energy than in cases with no wind while also overestimating the wind sea height in the presence of swell because of its dependency on the mean wavenumber and steepness see van der westhuysen et al 2007 and references therein an alternative saturation based approach was introduced by alves and banner 2003 and developed further by van der westhuysen et al 2007 this approach removes the dependency on mean spectral steepness by instead employing the local spectral saturation van der westhuysen et al 2007 showed that modelling wave dissipation using a local saturation gave better results in mixed wind sea swell conditions than komen s approach this saturation based approach has also been incorporated in spectral wave models such as swan and tomawac in recent years new developments in white capping and wind input formulations known as st4 ardhuin et al 2010 and st6 babanin et al 2010 have been implemented mainly in wavewatch iii but also in swan for st6 compared to older approaches these formulations are more sophisticated and include newer features such as negative wind input and swell dissipation they also have a high number of tuning options thus allowing more advanced calibration the performance of st6 for open sea conditions have been reported in several works van vledder et al 2016 studied the wave conditions during a severe storm in the southern north sea they concluded that the st6 package gave the best model performance in terms of the spectral shape and several integrated wave parameters including the significant wave height and the spectral period t m 1 0 rogers et al 2012 zieger et al 2015 stopa et al 2015 liu et al 2019 and lavidas and polinder 2019 have tested the st6 source terms across a large number of idealized and real world applications however the new parameterization has not been extensively tested in coastal areas amarouche et al 2019 evaluated st6 and a combination of white capping formula by janssen 1991 and exponential wind growth by komen et al 1984 in the western mediterranean sea they advised the use of a calibrated version of the latter combination due to its better performance and shorter simulation period however in norwegian fjord areas stefanakos et al 2020 found that the wind input and white capping of janssen 1991 systematically overestimates the wave heights our overall objective is to find appropriate source term formulations in swan for white capping and wind input under narrow fetch conditions in semi sheltered seas the location of our investigation is a fjord system fig 1 on the west coast of norway which serves as an excellent example of narrow fetch geometry in the presence of strong wind forcing the wave climate on the west coast of norway is characterized by strong swell from the north atlantic ocean semedo et al 2014 christakos et al 2020b and frequent passages of extratropical systems in addition coastal phenomena such as low level jets christakos et al 2014 and wind channelling christakos et al 2020a induced by topography also affect the local wind sea creating a mixed sea state of wind sea and swell the narrow fetch in itself also affects the growth of the waves pettersson 2004 we base our assessment of the source terms on both long term statistics and two cases of narrow fetch geometries with i no swell and ii mixed wind sea swell three different formulations for white capping and wind input are evaluated against in situ measurements special attention is given to analysis of the different source terms related to the fetch geometry this is to our knowledge the first paper that studies the effect of the narrow fetch geometry on the performance of source term packages in different sea states the paper is organized as follows section 2 describes the modelling system followed by section 3 which describes the data and the methods employed in section 4 we present the overall model performance and selected case studies section 5 discusses our results in section 6 we end by summarizing and concluding our findings 2 description of the modelling system the study area fig 1 is described in christakos et al 2020a in sulafjorden buoys a b c and d breidsundet are deployed and buoy f in the fjord cross section of vartdalsfjorden voldsfjorden and rovdefjorden as shown in fig 1 sulafjorden is approximately 10 km long with an average width of 4 6 km because of its exposure to the norwegian sea the wave climate in sulafjorden is usually characterized by mixed wind sea and swell conditions while the inner parts of the fjord system such as location f are unaffected by swell the fjords are 200 700 m deep much deeper than the shelf area which is less than 100 m over most areas in storm conditions wave dissipation due to bottom friction and depth induced wave breaking occurs off the coast in shallow transitional waters before reaching the fjord system 2 1 the wave model swan the wave model swan is a third generation spectral model mainly developed for nearshore applications the swan wave model is also capable of reproducing fjord wave conditions christakos et al 2020a herman et al 2019 in this study the swan cycle iii version 41 20 is used as a spectral model it estimates the evolution of wave action density n e σ by applying the action balance equation 1 n t c x n x c y n y c σ n σ c θ n θ s σ here e is the wave spectral energy σ the intrinsic circular frequency in absence of a surface current σ ω 2 π f rad s 1 where f is the linear frequency hz and c x and c y are the group velocity vector components in geographical x y space the c σ and c θ represent the propagation in frequency direction σ θ space the term s represents the total source term consisting of in all six source terms in swan 2 s s in s ds s nl4 s nl3 s fric s brk here s in is the energy input by wind s ds is the dissipation induced by white capping s nl4 is the nonlinear wave energy transfer between quadruplets s nl3 is the triad nonlinear interaction s fric is the bottom friction and s brk is the depth induced wave breaking e g holthuijsen 2007 since our study is focused on relatively deep water areas the term for triads is switched off the wind input term contains a linear and an exponential growth term a sensitivity study not shown found that the linear term had only a minor effect on wave growth and is therefore neglected for our fjord applications we therefore focused on s in s ds and s nl4 2 1 1 the komen package in swan the current default white capping dissipation is the pressure pulse model of hasselmann 1974 formulated by komen et al 1984 and defined as e g swan team 2017 3 s ds komen σ θ c ds komen 1 δ δ k k s s pm p σ k k e σ θ here c ds komen 0 24 1 0 4 δ 1 and p 4 are tuning parameters k is the wavenumber and s k e tot is the mean spectral steepness e tot is the total energy of the wave spectrum i e the integral over all frequencies and directions the k and σ are the mean wavenumber and the mean circular frequency the s pm corresponds to the mean spectral steepness of a pierson moskowitz spectrum a study by rogers et al 2003 showed that δ 1 the default value in swan 41 20 improves the wave energy estimates over δ 0 5 proposed by komen et al 1994 the wind input term is estimated according to komen et al 1984 which in turn is based on experimental results by snyder et al 1981 4 s in snyder σ θ max 0 0 25 ρ a ρ w 28 u c cos θ θ w 1 σ e σ θ here u τ ρ a where τ is the wind stress is the friction velocity the estimation of u is made according to zijlema et al 2012 c is the phase speed of the wave component and ρ a and ρ w are the air and water densities respectively the direction of the spectral wave component is θ and θ w is the direction of the wind this white capping wind input package will hereafter be denoted komen eq 4 is based on field observations of weakly forced waves where u 5 the wind speed at 5 m height had values up to 8 m s 1 snyder et al 1981 for wind speed ranges of 2 12 m s 1 hasselmann and bösenberg 1991 came up with similar results to snyder et al 1981 thus we consider eq 4 appropriate for weak to moderate wind conditions but its validity is not proven for strong wind events 2 1 2 the westh package as an alternative to the komen approach van der westhuysen et al 2007 modified the saturation based method of alves and banner 2003 and implemented it in swan in contrast to the approach taken by komen et al 1984 this method expresses white capping without the s and k dependencies which are problematic in mixed wind sea and swell conditions this method is based on experimental results showing that white capping is associated with the nonlinear hydrodynamics within wave groups the formulation reads 5 s break westh σ θ c ds westh b k b r p 2 tanh k d 2 p 0 4 g k e σ θ here c ds westh 0 50 1 0 4 is the white capping parameter d is the water depth g is the acceleration due to gravity and b k e σ k 3 c g c g is the wave group velocity is the azimuthally integrated spectral saturation the latter is well correlated with the breaking probability banner et al 2002 when b k is below the threshold saturation level b r 1 75 1 0 3 there is no breaking but a background dissipation of wave component is present with p 0 when b k exceeds b r there is wave breaking and p equals a calibration exponent p 0 to give a smooth transition between these two conditions p is expressed as function of b k alves and banner 2003 the dissipation is separated into a breaking and a non breaking part swan team 2017 6 s ds westh σ θ f br σ s break westh 1 f br σ s ds non break the s ds non break term is expressed by eq 3 similar to the parameter p f br is a smooth transition function swan team 2017 the wind input applied in the saturation based parameterization is according to yan 1987 which combines the expressions by komen et al 1984 and plant 1982 7 s in yan σ θ c 1 u c 2 c 2 u c c 3 cos θ θ w c 4 σ e σ θ where c 1 4 1 0 2 c 2 5 52 1 0 3 c 3 5 2 1 0 5 c 4 3 02 1 0 4 are coefficients given by swan team 2017 for strong wind conditions i e young wind sea u c 0 1 the wave growth rate has a quadratic relation to the inverse wave age u c for weaker winds i e older sea u c 0 1 the relation becomes linear similar to komen the estimation of u is according to zijlema et al 2012 this package is activated in the swan model with the command gen3 westh and is hereafter denoted westh 2 1 3 the st6 package st6 is a recent formulation included in swan version 41 20 the package is also implemented in wavewatch iii as documented by zieger et al 2015 the st6 implementation in swan has only minor differences to that of wavewatch iii rogers et al 2012 swan team 2017 st6 is an observation based scheme that contains wave turbulence interaction swell decay positive and negative wind input and two phase white capping dissipation the wind input formulation is given as 8 s in st6 σ θ ρ a ρ w σ g b n w e σ θ where 9 g 2 8 1 tanh 10 b n w 11 here b n a σ e σ k 3 c g is the spectral saturation a measure of steepness and a is the narrowness of the directional distribution the narrowness is defined as a 1 0 2 π e σ θ e max σ d θ where e max σ is the maximum density over all directions but a is set to unity for dissipation calculations in swan in addition to the positive wind input st6 also allows a negative wind input component that reduces wave growth in the part of the spectrum that experiences adverse wind stress this is formulated as 10 w σ θ w 1 σ θ a 0 w 2 σ θ where w is expressed as the sum of the positive wind input 11 w 1 σ θ max 2 0 s ws u c cos θ θ w 1 and the adverse negative wind input 12 w 2 σ θ min 2 0 s ws u c cos θ θ w 1 here a 0 is a tuning parameter and s ws is a scaling parameter which is set to 32 in swan 41 20 there are three available formulations in st6 for the estimation of u c d u 10 where c d is the drag coefficient in the wave model following the swan notation the formulations are hwang default rogers et al 2012 fan fan et al 2012 and ecmwf guenther et al 1992 in the hwang formulation the drag coefficient is only a function of wind speed on the other hand fan and ecmwf use an iterative procedure for estimating u based on the actual seas state in fan formula u is a function of both wave age and wind speed whereas in ecwmf it is a function of air flow and wave induced stress the white capping term s ds st6 is the sum of two dissipation components t 1 and t 2 e g rogers et al 2012 the component t 1 is the inherent breaking related to instabilities of waves and t 2 is a cumulative term that describes the dissipation of shorter waves triggered by longer breaking waves 13 s ds st6 σ θ t 1 σ t 2 σ e σ θ here 14 t 1 σ a 1 a σ σ 2 π e σ e t σ e t σ p 1 and 15 t 2 σ a 2 σ 1 σ a σ 2 π e σ e t σ e t σ p 2 d σ the threshold spectral density is e t b nt a σ c g k 3 where b nt a 1 and a 2 are constants p 1 4 and p 2 4 are power coefficients and σ 1 is the first prognostic frequency a key feature of the st6 formulation is that there is no breaking unless the spectral energy density at that particular frequency σ exceeds the threshold e t σ 2 1 4 wave wave interactions bottom friction and depth limited breaking the four wave interactions quadruplet are modelled by the discrete interaction approximation dia by hasselmann et al 1985 nonlinear triad interaction is turned off since their effect is minor in our deep water area of interest the bottom friction is represented by the jonswap bottom friction hasselmann et al 1973 where c fric 0 067 m 2 s 3 is the bottom friction coefficient according to bouws and komen 1983 finally the depth limited wave breaking is represented by the formulation of battjes and janssen 1978 with default settings of α 1 and γ 0 73 3 data and methods the model was run in non stationary mode with spherical coordinates and a time step of 10 min with 4 iterations of the implicit scheme the spectrum is resolved by 36 directional bins 10 directional resolution and 32 logarithmically spaced frequencies from 0 04 to 1 hz the inner domain d2 with a grid resolution of 250 m 250 m red rectangle in the left panel of fig 1 is nested into the outer grid d1 of 1 km 1 km the simulation period is from october 1 2016 until april 30 2018 3 1 wind forcing because of the complex fjord topography a high resolution wind forcing is essential to faithfully reproduce local wind conditions such local features may have a considerable effect on the wave growth in a fjord as discussed by christakos et al 2020a and herman et al 2019 in our study the advanced research wrf skamarock et al 2008 state of the art numerical weather prediction model version 3 5 0 is applied to downscale the reanalysis era interim dee et al 2011 to a grid resolution of 0 5 km for the fjord system christakos et al 2020a this downscaled wind product is hereafter called wrf0 5 christakos et al 2020a showed that wrf0 5 slightly overestimated high wind speeds in the innermost locations of our study area but nevertheless performed better than other available wind products the era5 reanalysis hersbach et al 2020 the hindcast nora10 reistad et al 2011 and the operational numerical weather prediction model arome2 5 wind input to the wave model is linearly interpolated to the swan grid from the 10 m height wind of wrf0 5 3 2 boundary wave conditions the wave conditions at the grid boundaries of the outer model domain are obtained from the nora10 hindcast with 3 hourly temporal resolution information on the spectral nesting and interpolation in breivik et al 2009 the wave component of nora10 is a 10 km wam model forced with winds from the high resolution limited area model hirlam nested inside a 50 km north atlantic wam model forced by era 40 winds reistad et al 2011 the wave component is a modified version of the wam cycle 4 model guenther et al 1992 set up on a rotated latitude longitude grid similar to the rotated spherical grid used for hirlam the outer domain covers the north atlantic with a 50 km grid resolution thus allowing realistic swell propagation from the north atlantic to the norwegian coast twenty four directional bins and twenty five frequencies 0 0420 to 0 4137 hz are used for the nora10 model setup no offshore measurements are available to verify the spectralboundary conditions from nora10 but several studies have investigated the quality of the nora10 wave hindcast according to aarnes et al 2012 a low bias of significant wave height between nora10 and observations located in the north sea and the norwegian sea is observed bruserud et al 2016 found good agreement between nora10 and wave observations in the northern part of north sea 3 3 measurements measurements from seawatch wavescan buoys fugro 2012 available via met norway s thredds service furevik et al 2020 are used to evaluate the performance of the different source term packages the measurement data contains integrated wave parameters such as significant wave height peak wave period mean wave period mean wave direction as well as wind speed and wind direction in addition wave spectra are provided for specific storm cases by fugro oceanor as norway the buoy wind sensors are placed at 4 1 m above the sea level buoys d at 345 m water depth a at 375 m b at 325 m c at 450 m and f at 217 m are deployed in the fjord system as illustrated in fig 1 we used available measurement data from the following periods october 14 2016 april 30 2018 location d october 13 2016 april 30 2018 locations a b april 27 2017 april 30 2018 location c and november 29 2017 april 30 2018 location f 3 4 wave and fetch parameters we analyse the spectral wave parameters of significant wave height h s the mean period t m 01 the peak period t p and mean wave direction θ the model t m 01 is calculated by integrating up to maximum observed frequency we use the logarithmic wind profile to adjust the observed wind speed from 4 1 m to 10 m u 10 with a roughness length of 0 0002 m e g wang et al 2018 christakos et al 2020a to investigate how the complex fetch geometry of the fjord system affects the performance of the source term packages the dimensionless effective fetch x is calculated using the following equations 16 x g x eff u 10 2 where u 10 is the model 10 m wind speed at the buoy location and x eff is the effective fetch estimated in a 30 degree sector with 5 degree increments 17 x eff i 0 6 x i cos 2 ϕ i i 0 6 cos ϕ i here x i is the fetch in a straight line to the coast and ϕ i is the angle from the wind direction in sectors i 0 1 6 the dimensionless width is defined as 18 x w g x w u 10 2 here x w is the width distance across the fetch the x w is quantified because the narrowness of a basin restricts the growth of the wave height even if the fetch is long pettersson 2004 the right hand panel of fig 1 shows estimated x i and x w at location f similar estimation is performed for locations d a b and c not shown where unlimited fetches are excluded in our study finally the normalized bias of h s is defined as 19 nbi h s mod h s obs h s obs where h s mod and h s obs are the modelled and observed significant wave height the use of nbi allows comparisons between areas with different wave climate e g exposed versus sheltered fjord locations for the estimation of nbi only h s mod and h s obs values greater than 0 2 m are considered 4 overall model performance and fetch geometry taylor diagram of error metrics taylor 2001 for h s is illustrated in fig 2 the applied error metrics same definitions as in christakos et al 2020a are the correlation coefficient r normalized standard deviation nstd and normalized centred root mean square error crmse the different source term packages show similar performance at the most exposed locations d and a with good scores for error metrics with nstd close to 1 and r approximately 0 9 further into the fjords the model performance degrades 0 8 r 0 9 and nstd 1 1 with the worst performance at locations c and f westh yields the best results in terms of h s for most of the measurement locations d a b and c while st6 performs worst in location f we plot the nbi as a function of dimensionless fetch to investigate potential over under estimation related to the fetch geometry fig 3 in all the measurement locations the highest overestimation of h s is observed at short medium x and decreases as x increases as a power function for large x the different source term packages show near identical results for most of the domain in exposed locations a and b the performance of the different packages has a weak dependency on x since these areas are affected mainly by strong swell only for low x which are linked to high wind speeds we observe some dependency if judged by the fits to the data all three packages perform similarly for long fetches for short dimensionless fetches the westh package has the lowest nbi while st6 and komen coincide in the slightly more sheltered location c the fits of the westh and st6 packages still agree for the longest fetches slightly outperforming the komen package nonetheless for short fetches the behaviour at c is similar to that at a and b in the most sheltered location f nbi depends more strongly on x and we observe the highest nbi difference between the source packages the wave climate in this location is characterized by no swell and strong local wind sea which is affected as expected by the wind structure and the complex fetch geometry we identify three x ranges i short x 1 0 2 ii medium 1 0 2 x 1 0 4 and iii large x 1 0 4 the short range represents mainly very short fetches x 5 km the medium range 5 km x 21 km with moderate to strong winds contains the values with the highest overestimation by the different source term packages for all parameterizations the nbi tends to zero for the largest range low wind conditions although all packages overestimate h s at f st6 shows the highest overestimation in both short and medium ranges by up to approx 50 compared to komen this suggests that st6 feeds too much energy to the dominant frequency within these ranges a clear relation between nbi and x w is also evident in fig 4 the x w is an indication of how the width restricts the growth within the fjord similar to x the nbi is high for short medium x w while it tends to zero for large x w this indicates a degrading model performance when the fetch geometry becomes more narrow which is especially evident for st6 the majority of the high nbi at f cases are linked to southeast wave direction yellow fetches width in fig 1 which is characterized by strong wind channelling christakos et al 2020a all in all at f the dimensionless width is a better explanation for the model performance than the dimensionless effective fetch even though the effective fetch contains some information about the narrowness of the fetch geometry in the following we investigate two cases i narrow fetch geometry without swell and ii narrow fetch geometry with mixed wind sea swell case i focuses on the most problematic area location f where the highest differences between the packages are observed and a clear link between fjord geometry and nbi exists location f which is located at the junction between three narrow fjords can be considered a natural laboratory for very narrow fetch conditions the case ii presents a case of mixed sea state locations d a and b under strong wind forcing at semi closed and narrow fetch geometry 4 1 case i narrow fetch geometry with no swell on january 15 2018 offshore winds greater than 15 m s 1 from southeast generated a strong local wind sea in location f fig 5 during most of the time the dimensionless fetch is between 1 0 2 and 1 0 3 and the dimensionless width varies roughly from 70 and 350 at location f where high nbi is observed figs 3 and 4 although the complex orography caused wind channelling in the fjord the high resolution wrf model has been shown to reproduce such local effects well christakos et al 2020a the observed h s in location f reached 1 m with θ about 130 150 fig 5 the t p and t m 01 ranged from 2 5 to 4 s and 2 5 to 3 s respectively modelled and observed wind directions were in good agreement varying from 120 160 a slight overestimation of the modelled wind speed at buoy location f of about 2 3 m s 1 was observed however considering the complex fjord orography the quality of the wind forcing can be characterized as good regarding h s we see large differences between the different source term packages st6 exhibits the highest values of h s with up to 1 m difference compared to observations the default package komen shows the best performance with differences of at most 0 3 m compared to the observations similar results are observed for t p and t m 01 st6 shows the largest over estimation compared to the observed values the spatial variation of s in ds u 10 and h s is presented in fig 6 the spatial variation of s in ds reflects the u 10 variation channelling within the fjord as expected similarities in spatial variation between s in ds h s and t p not shown are observed up to 40 of the fjord area has h s 1 5 m and t p 4 5 s in the st6 simulations the respective area for komen and westh is much smaller and concentrated around buoy f to further analyse the model performance the source terms s in s ds s nl4 and their sum s in ds nl4 are plotted as a function of f for four selected times from january 14 2018 at 00 utc calm conditions to january 15 2018 at 09 utc peak of wind speed fig 7 st6 shows much higher s in peak levels than the other packages more specifically for the dominant waves the absolute values of s in and s ds are roughly an order of magnitude higher in st6 than in komen on january 15 2018 at 09 utc source terms of komen and westh show similar performance with the latter giving slightly higher values as expected s nl4 reflects the magnitude of s in and s ds consequently the sum s in ds nl4 in st6 shows the highest values about 3 times as high as in komen westh and komen shows similar values with the former being slightly higher the energy of the dominant waves is about 3 4 times as high in st6 as the observed values fig 8 top panel komen and westh overestimate the energy of the dominant waves by about 50 in addition st6 underestimates the peak frequency by about 0 1 hz while komen and westh underestimate it by about 0 05 hz the best performance is found with komen both in terms of peak energy density and the location of the peak frequency for the high frequency tail f 0 3 hz st6 matches the observations while komen and westh show too high energy densities the high energy overestimation of the dominant waves in st6 for such narrow fetch geometries merits further analysis for this reason we investigate the sensitivity of st6 on i wind drag formulations and ii the narrowness a i the wind drag formulations are used to scale the input wind forcing u 10 to u which is applied to s in applying ecmwf and fan wind drag formulas the density level at the peak has reduced by 15 and 23 respectively while there is no negative impact on the good performance of the spectral tail fig 8 top panel ii as mentioned in section 2 1 3 the narrowness a in s ds st6 is omitted by setting it to unity default using the actual a a 1 with the wind drag formulations by hwang fan we observe a reduction of the density level peak by about 33 50 fig 8 bottom panel thus almost matching the performance of the other packages however the use of the actual a yields an overestimation in the spectral tail the use of fan with a constant narrowness a 1 2 in s ds st6 shows similar results to when using a 1 for the dominant waves with only a small negative bias for the spectral tail 4 2 case ii narrow fetch geometry with mixed wind sea swell on december 26 2016 a severe winter storm known as urd passed the norwegian sea and reached the west coast of norway significant wave heights up to 6 m were recorded in location d fig 9 shows the time variation of the model and observed wind speed and wind direction for the storm urd at location d a and b the wind speed exceeded 15 m s 1 at location d and reached 20 m s 1 at locations a and b the model wind speed and direction agrees with observations at locations a and b but the wind speed is slightly overestimated at d h s reached 3 6 m at a and 2 2 m at b the peak wave period t p and the mean wave period t m 01 varied from 8 to 16 s and 4 to 10 s respectively the mean wave direction θ was westerly and northwesterly differences between the source term packages are observed mainly in h s which is over predicted by all packages but westh and komen perform best they show similar performance for θ being in good accord with observed values the packages behave nearly identically for t p following the observations the high variation in the observations is likely caused by statistical variability which is not expected to be reproduced by the model in sheltered locations swell energy is less dominant compared to wind sea thus the peak period is shifting between values of 8 s old wind sea and 16 s swell the model shows good performance for t m 01 with some deviations observed between the source term packages at location b westh and st6 agree on the mean period t m 01 showing slightly higher values than those of komen there are strong similarities in the spatial variation of s in ds magnitude fig 10 top komen and westh show similar s in ds values while the values of st6 are considerably higher especially in sulafjorden where strong wind channelling is observed fig 10 middle the s fric and s brk are significant only in the small shallow areas around islands off the fjord system not shown st6 shows the highest h s values offshore up to 10 7 m it also shows the deepest penetration of high waves into the sulafjorden followed by westh and then komen fig 10 bottom the lowest wave heights both offshore and within the fjord system are shown by komen differences are mainly seen within the fjord system where st6 shows higher h s because of larger s in ds values compared to komen and westh the spatial variation of t p shows insignificant differences between the packages along the coast since it is mainly affected by the boundary conditions not shown along the coast t p is 17 5 s while being below 5 s within the fjord system all the packages predict similarly the reduction of t p outside sulafjorden that are due to changes in the bathymetry differences in t p are mainly observed in sulafjorden where st6 shows a deeper penetration of longer waves within the fjord to compare the ability of the packages to model the observed shape of spectra fig 11 presents the average frequency spectra in the linear and the logarithmic scale in location d most exposed to the open sea the different packages show quite similar spectral shapes and magnitudes some differences are detected in the inlet of sulafjorden location a for frequencies f 0 1 hz and the differences are even more pronounced within sulafjorden location b for the high frequency tail f 0 3 hz the different source term packages perform quite similarly at location d deviations between the packages are detected at locations a and b where st6 and westh show the best performance when evaluated against observations 5 discussion the saturation based white capping approach westh provides the best model performance in terms of h s in locations where mixed wind sea swell conditions are observed this is in accordance with findings of van der westhuysen et al 2007 who showed that the saturation based formulation outperformed the pressure pulse approach of komen in such mixed conditions the results show a strong wind input in st6 which is particularly problematic in case i with the extremely narrow fetch geometry in narrow fetch geometry with no swell st6 captures the energy of the high frequency tail well but overestimates strongly the energy of the dominant waves yielding too high h s in these areas the fetch geometry plays a crucial role in wave dynamics within the medium fetch range fetches between 5 and 21 km under moderate to strong wind conditions all the applied packages perform quite poorly location f this overestimation is especially strong for st6 because of a strong s in which is unbalanced due to a weak s ds the highest nbi is found within the medium range about x 1 0 3 at narrow fetch geometry location f e g fetches at 20 km with a wind speed of about 14 m s 1 for much larger scales these dimensionless fetch values can be equivalent to a fetch of 100 km with wind speeds at 30 m s 1 large values of nbi are also detected at approx x w 300 in location f for fjord areas this represents widths of about 3 km with a wind speed of about 10 m s 1 if we scale it again to larger regions it is approximately equivalent to a width of 20 km with wind speeds of 25 m s 1 therefore the inaccuracies detected in this study might be relevant also for significantly larger water bodies during high winds several factors can cause the high energy observed in narrow fetches by st6 they can be grouped into two categories i direct factors which are related to the formulation of wind input and white capping and ii indirect factors that are connected to effects triggered by e g non linear interactions wind drag and forcing 5 1 i direct factors rogers et al 2012 found a problematic energy growth in st6 at the young wave age stage due to i the quadratic relationship between s in and inverse wave age and ii the dependency of s in on the spectral saturation b n eq 8 in komen s in has a linear dependency on the inverse wave age for all wind conditions in westh the relationship is linear for low winds and quadratic for stronger winds the linear relationship in komen potentially explains the relatively low s in values the source term formulations of westh and st6 use an isotropic spectral saturation according to ardhuin et al 2010 using adirection dependent saturation can allow for a control of directional spread and improve the overall results according to pettersson 2004 a narrow fetch geometry influences the directional distribution of the dominant waves hence an isotropic white capping might therefore not be fully appropriate for fjord wave modelling accounting for the directional spread in s ds st6 by using the actual narrowness a shows an improvement for the dominant waves but as discussed by rogers et al 2012 it leads to lower dissipation in the high frequencies in narrow fetch geometries selecting a constant not unity narrowness e g a 1 2 in case i can improve the performance for both the larger dominant and shorter waves babanin et al 2010 suggested that dependence between t 1 2 and the exceedance level e e t should be linear however rogers et al 2003 found that a nonlinear relationship obtained by setting p 1 p 2 4 the default in swan is essential to balance the strong s in in our case these default values seem to provide still too weak s ds and a further increase of nonlinearity by setting p 1 p 2 6 improves considerably the wave height estimates not shown however this increases the dissipation in high frequencies with a negative impact on spectral tail even if the model performance in exposed locations is generally good for st6 there are inaccuracies regarding the density peak level which describes the energy of the dominant waves rogers et al 2012 presents a third dissipation term t 3 in their study see also the cumulative steepness method csm by van vledder and hurdle 2002 and hurdle and van vledder 2004 which provides a formulation for the straining mechanism in contrast to t 2 this term accounts for the change of the short wave steepness by the underlying longer waves the effect can be considered important in the exposed fjord locations where short waves local wind sea coexist with non breaking larger waves swell or old wind sea its implementation in s ds may provide a better balance to strong s in under mixed swell wind sea conditions we expect that this term should have a minor effect on sheltered locations with weak or no swell however more observational studies and numerical simulations are required to investigate this effect the wind input in the applied packages assume a stable air sea boundary layer since changes in the air and sea temperatures or densities are not considered in their formulation ρ a ρ w is constant in swan this assumption might not be appropriate in our study area norwegian fjord climate is associated with i rapid changes in weather conditions e g sharp changes in air density by atmospheric front passages and ii proximity to land with fresh water discharges that influence the density ratio and consequently the wind input 5 2 ii indirect factors christakos et al 2020a found that wrf0 5 has an overall good performance in the fjord system however the evaluation is based on the 5 measurement locations and did not draw firm conclusions about the wind quality over the whole fjord system considering the complexity of the orography possible inaccuracies in wind forcing along the fjords are transferred to s in affecting the wave growth the energy growth in st6 is much stronger than in the other packages in contrast to older wind input formulations which add the bulk around the spectral peak the s in in st6 adds more energy to higher frequencies rogers et al 2012 this possibly affects the dia which in turn will redistribute energy to lower frequencies more vigorously growing the wave field faster compared to other formulations therefore the resulting high density level at location f could be to some extent due to dia liu et al 2019 discussed that their st6 results using dia show higher sensitivity to fetch geometry compared to the generalized multiple dia tolman 2008 gmd and the webb resio tracy method webb 1978 tracy and resio 1982 wrt the use of different wind drag formulations in narrow fetch conditions revealed their importance the wind drag formulations that take into account the wave impact on u estimation using iterative methods i e fan and ecmwf provide more accurate results than the default formulation in st6 in narrow fetches even small changes in the vertical wind profile induced by waves can affect the spectral shape hence accounting for the wave atmosphere coupling can provide a more physical representation of u and consequently more accurate s in there are other types of forcing which are not considered in the present study but might affect the fjord wave modelling the rain river run off surface currents and tides may play an important role in the fjord wave evolution rain affects the wind input and dissipation of surface waves more details in cavaleri et al 2015 during heavy rainfall or melting of snow or ice river run off creates freshwater plumes that can also influence the wave growth and direction surface currents and tides can affect the waves through several processes such as a change of the relative wind speed the doppler shift the concertina effect e g ardhuin 2019 wave refraction and energy bunching stretching future studies using a coupled ocean wave atmosphere system is needed to quantify and evaluate the importance of these effects in a fjord system 6 summary and conclusions accurate modelling of wave conditions in complex coastal areas is a challenging issue in addition to the uncertainties due to the quality of the boundary wave conditions and the wind forcing the choice of physics is found to be very important we have investigated the performance of three different source term packages available in swan the packages were evaluated by comparing their results against buoy measurements at five different locations using both long term statistics and detailed case studies all applied packages perform well for the most exposed locations d and a for the more sheltered locations the packages show pronounced differences the westh package provides the best overall performance in terms of h s in most measurement locations with mixed swell wind sea conditions d a b and c the komen package performs the best in terms of h s in the location with no exposure to the open sea f st6 package shows a strong positive h s bias in sheltered areas no swell for high frequencies the different source term packages perform quite similarly at the outermost location while significant deviations between the packages are detected at locations a and b where st6 and westh are the most accurate in exposed areas a weak dependency between fetch geometry and model accuracy is found as expected because of the dominant role of swell in narrow fjord areas with no swell the fetch geometry has a distinct effect on model performance in such areas the narrow fetch combined with wind channelling induced by the steep mountains surrounding the fjord significantly affects the model results these conditions give rise to large differences in the performance of the applied source packages the effect that the fetch geometry has on the accuracy of h s is best explained by the dimensionless width of the basin x w as opposed to the dimensionless effective fetch values of x w that were found problematic for the wave model are possible even in larger scales during sufficiently strong wind in the fjord system the deep water source terms s in and s ds contribute the most to the total energy the st6 white capping is too weak to balance the strong s in resulting in overestimation of density spectra and thus of h s both cases show that st6 is more sensitive to narrow fetch geometry and variations in the local wind speed than the other packages credit authorship contribution statement konstantinos christakos conceptualization methodology software formal analysis investigation data curation writing original draft writing review editing visualization jan victor björkqvist conceptualization methodology investigation writing review editing laura tuomi methodology supervision writing review editing birgitte r furevik methodology supervision writing review editing project administration øyvind breivik methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the four reviewers for their thoughtful and insightful comments that helped in improving the study furthermore we are thankful to erick w rogers oceanography division naval research laboratory stennis space center mississippi usa who provided the swan code revision 358 of swancom2 ftn for the estimation of narrowness in the white capping of st6 we are grateful to lasse lønseth fugro oceanor as norway and øyvind byrkjedal kjeller vindteknikk as norway who provided the wave spectral data and the wind forcing data respectively the study was funded by the norwegian public roads administration under the coastal highway route e39 project the bathymetry data is derived by emodnet bathymetry consortium 2018 
