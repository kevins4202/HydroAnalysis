index,text
720,modeling the entire range of precipitation datasets using some parametric distribution is of great importance in many applications traditionally single component models such as an exponential or gamma distribution have been used but recently more flexible multi component models have also been investigated by combining known distributions in the form of mixture or hybrid models in this paper we introduce the phase type ph distribution a rich class of distributions previously used in other disciplines as a parametric alternative to model the full spectrum of precipitation datasets in different areas worldwide after discussing its distributional properties we compare the performance of the ph model to other existing models using 49 precipitation records in texas the results show that the ph model performs well compared to other alternative multi component models in terms of likelihood based model selection criteria and the fit in the tail part of the data we also consider precipitation datasets of different shapes and reaffirm the ability of the ph model to capture the full spectrum of the precipitation amount the computational complexity however remains as a possible caveat of the ph model keywords precipitation phase type distribution hybrid distribution 1 introduction measuring and predicting the precipitation are considered to be of great importance in many applications including agriculture forest management and hydrology common models of the precipitation are stochastic in that they describe the phenomenon of rainfalls through some static or dynamic statistical models with specific distributions with a suitable time interval as a base period of modelling the choice of the time interval can be arbitrary in theory but taking a daily basis is most natural and popular in the literature see for example richardson 1981 many previous studies tried to model daily rainfall data through parametric approaches for example ison et al 1971 mielke and johnson 1973 richardson 1981 and stern and coe 1984 non parameteric approaches have also been proposed by e g sharma and lall 1999 and harrold et al 2003 though each approach has its pros and cons parametric models are generally advantageous in that they can model rainfall datasets with only a few parameters and can be easily extrapolated towards extreme area where rainfall observations are relatively rare in frequency simple parametric models found in the literature include exponential gamma and some transformed normal distributions however these simple models often fail to capture important characteristics of the rainfall datasets which are typically skewed over dispersed relatively heavy tailed and sometimes bell shaped as an alternative approach to improve the calibration mixtures and hybrid distributions models have been suggested in the literature see e g wilks 1999 and li et al 2012 being natural extensions of simple stochastic models the class of mixture distributions is more flexible with more parameters and thus can address unique shape characteristics of the rainfall datasets for example woolhiser and roldan 1982 adopted mixed exponential distribution and yoo et al 2005 exploited mixed gamma distribution in recent studies of vrac and naveau 2007 and hundecha et al 2009 a dynamic mixture of gamma and generailzed pareto distribution was considered to emphasize the tail calibration of precipitation datasets related to this in some studies in the hydrology community the evidence of heavy tailed phenomenon on the distribution of high precipitation amount has recently gained strong support from researchers see e g koutsoyiannis 2004 the underlying idea of the heavy tail essentially says that the extreme precipitation amounts over some high threshold value tend to have different distributional behaviours and accordingly can be modelled using a separate statistical distribution in particular the distribution for the tail is modelled by the generalized pareto distiribution gpd justified by the standard result of extreme value theory evt to this extent various methods were investigated and explored in the literature focusing on the tail behavior of daily precipitation described by some power or polynomial survival function see for instance furrer and katz 2008 li et al 2012 papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 in particular in their recent paper li et al 2012 examined various hybrid distributions to model the full spectrum of daily precipitation under the evt framework and showed that the body and tail parts of the dataset can be adequately modelled by an exponential and gpd with a positive shape parameter respectively the idea that the tails of rainfall datasets follow some power function however is not universally accepted for example booij 2002 modeled extreme daily precipitations with gumbel distribution and exponential distribution which have lighter exponential tails also park et al 2011 compared several gev distribution based model and concluded both power tailed models and exponential tailed models could be adopted to explain extreme rainfalls thus whether the precipitation extremes in general follow a power or exponential tail remains an open question and it is reasonable to say that depending on the dataset under consideration a convolution or mixture of exponential distributions may serve as a good candidate to describe the entire range of the rainfall datasets by adding several layers of light tailed distributions in this paper we are interested in modelling the entire range of typical precipitation datasets for this we propose the phase type ph distribution as an alternative mixture distribution to model the precipitation the ph distributions are a class of mixture distributions that contains many well known distributions as members such as an exponential erlang and its mixtures being a mixture distribution of exponential tailed distributions the ph distribution class is not only flexible but also can adapt the heavy tail if needed by providing a fatter survival function with more components for the tail of the given dataset though this distribution class has widely been used in reliability and insurance contexts its applications towards the precipitation seems rare for the purpose of comparison in this paper we closely follow the work of li et al 2012 where texas rainfall datasets are analyzed using various single and hybrid models both with and without the evt framework in particular we use the identical datasets and model them with the ph distribution to compare with other existing parametric models later we also consider the global precipitation datasets used in e g papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 for further analyses as there are datasets with different shapes outside texas for these datasets we carry out extensive fitting exercises and standard model validations and show that the ph distribution class is a flexible competitive and well rounded alternative stochastic model in describing the whole range of precipitation datasets of various shapes the present article is organized as follows in section 2 we describe the datasets to be used in the paper section 3 surveys existing parametric models to describe precipitation datasets and introduces the ph distribution class along with its distributional properties in section 4 we analyze texas rainfall datasets using the ph distribution as well as other multi component models to show how the ph model performs compared to other alternatives in modeling the entire range of the precipitation datasets we extend our sample coverage to other places of the world in section 5 in this section we consider precipitation datasets of different shapes found in other locations and show that the ph distribution again successfully model the datasets under consideration we conclude our paper in section 6 2 datasets the first dataset analysed is united states historical climatology network ushcn daily data set raw data set contains daily records of precipitation snowfall snow depth maximum temperature minimum temperature and information about flag among 48 files of contiguous states we selected texas which has 49 stations which was used in li et al 2012 to model precipitation datasets we included all non zero precipitation values during 1940 and 2009 without taking care of missings following the criteria used in li et al 2012 table 1 presents some basic statistics for each station along with the location note that if we had included dry days i e zero values the mean would have been smaller the second set of data we will consider later in section 5 is a global precipitation dataset from daily global historical climatology network ghcn daily which has also been used in precipitation analyses in the literature this dataset includes about 100 000 stations and contains ushcn as its subset we filtered stations according to papalexiou et al 2013 2 2 we only included stations that have a record length of over 50 years b percentage of missing values less than 20 data assigned with suspicious quality flags less than 0 1 the screen values of quality flags are two one with g failed gap check and another with x failed bound check for more information about this dataset see menne et al 2012 after data cleansing a total record of 19 328 stations has been obtained from ghcn which are almost identical to those used in papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 this dataset is still prohibitively big and we are unable to analyse them all instead we will select two specific stations residing in extreme positions in the l moments ratio diagram which exhibit qualitatively distinct shape characteristics compared to texas datasets we investigate how alternative models perform for these different datasets 3 models 3 1 single component models fundamental characteristics of daily precipitation data are described as non negative continuous except at the spike on zero and right skewed assuming we only focus on the continuous part of the data common candidate statistical models include exponential distribution by e g todorovic and woolhiser 1975 gamma distribution by ison et al 1971 wilks 1999 and schoof et al 2010 and kappa distribution by mielke and johnson 1973 to name a few let x denote the non zero daily precipitation amount then each model s probability density function is given as follows 1 exponential distribuiton 1 f e x p x λ 1 λ e x λ x 0 λ 0 where λ is the scale parameter 2 gamma distribuiton 2 f g a m x α β 1 β α γ α x α 1 e x β x 0 α β 0 where α is the shape parameter and β is the scale parameter 3 kappa distribuiton 3 f k a p x α β θ α θ β x β θ 1 α x β α θ α 1 α x 0 α β θ 0 where θ and β are the shape and scale parameters respectively and α is the remaining third parameter these models are ordered in that they become increasingly more flexible with more parameters other distributions can also be found such as skewed normal wan et al 2005 truncated power of normal distribution bardossy and plate 1992 and generalized pareto distribution gpd provided that only the tail of dataset is modelled the list of possible single component models can surely be much longer but we restrict ourselves to these three models to avoid crowded model comparison however as evidenced in previous studies it is now much agreed that single component models are generally inadequate to describe the whole range of daily precipitation datasets to illustrate this let us consider the texas station id2 data as an example of which the histogram is given in fig 1 the shape of the histogram indicates that a simple model such as an exponential distribution may produce a reasonably good fit to our eyes but it turns out to be not true after fitting the dataset with these three models based on the maximum likelihood estimation mle we present the qq plots in fig 2 from the figure we see that all these single models yield substantially poor fits to describe the dataset overall with under or overestimating both the body and tail considerably with other stations we observe similar inadequacies and the fits are generally poor the inadequacy of single component models in fitting precipitation datasets is well documented in e g li et al 2012 3 2 multi component models further improvement in fitting can be achieved by introducing additional distributions or components to single component models in this regard mixture type distributions were suggested in the literature including a mixed exponential distribution wilks 1999 and dynamic mixture of gamma and gpd vrac and naveau 2007 alternatively hybrid models or composite distributions were also considered of which the density is created by stitching two densities at a particular threshold in recent studies furrer and katz 2008 suggested a hybrid distribution of gamma and gpd ggp in short and li et al 2012 proposed a hybrid of exponential and gpd egp which was reported to perform better than some mixture models both of these models take gpd as the upper tail distribution to reflect heavy tail behavior of precipitation extremes koutsoyiannis 2004 inspired from the peaks over threshold pot framework of evt just like single component models one can create many different mixture or hybrid models and it is not feasible to consider all possible candidates to this end we consider for our study two hybrid models that are reported to be superior in the literature the first model is the ggp of furrer and katz 2008 with density as 4 f g g p x α β ξ σ θ f g a m x α β i x θ 1 f g a m θ α β f g p x ξ σ θ i x θ where i is the indicator function and fgam and fgam are the probability density function and cumulative distribution function of a gamma distribution respectively the gpd density acts as the tail specific model starting from the threshold θ 5 f g p x ξ σ θ 1 σ 1 ξ x θ σ 1 ξ 1 x θ as this gpd is not defined below θ we need 1 f g a m θ α β in 4 as the normalising factor to ensure the integral of the ggp density over its support is unity to make the density 4 continuous at θ a constraint f g g p θ f g g p θ is imposed which in turn yields the scale parameter σ of gpd expressed as the reciprocal of the gamma hazard function 6 σ 1 f g a m θ α β f g a m θ α β as a result its parameter set reduces to α β ξ θ even though the model complexity have been decreased due to the continuity constraint the tail threshold selection issue remains which does not have any guaranteed solution and requires cumbersome trial and error methods the second model is the egp of li et al 2012 of which the density is given by 7 f e g p x λ ξ σ θ 1 1 f e x p θ λ f e x p x λ i x θ f g p x ξ σ θ i x θ where fexp and fexp are the density and cumulative distribution function of an exponential distribution respectively exponential distribution here the denominator 1 f e x p θ λ is the normalising constant because the integration of the numerator of fegp x is 0 f e x p x λ i x θ f g p x ξ σ θ i x θ d x f e x p θ λ 1 this model has an advantage in that it can avoid the threshold selection via the continuity constraint at the threshold θ that is requiring f e g p θ f e g p θ produces 8 θ λ ln λ σ so that the threshold θ is automatically selected from the data and the number of parameters reduce to λ ξ σ by sacrificing model flexibility with taking exponential rather than gamma on its body part it obtains a primary advantage of circumventing the threshold selection problem 3 3 phase type distribution class the phase type ph distribution was introduced by neuts 1975 1981 and is created by a convolution or mixture of exponential distributions mathematically it is defined as the continuous distribution of the time until absorption in a continuous time markov chain with an absorbing state to formally introduce this model consider a continuous time markov chain with p 1 states 1 2 p p 1 where the states 1 p are transient states and state p 1 is the absorbing state also we let the process have an initial probability of starting in any of the p 1 states given by the probability row vector α 1 α p α p 1 with α 1 α p 1 1 for notational convenience we denote α α 1 α p so that the initial probability vector can be written as α α p 1 note that α p 1 0 is the probability attached to the absorbing state whether α p 1 is zero or strictly positive depends on the existence of probability mass at zero in the distribution which will be further explained later based on the above description this continuous markov process can be written in the form of the following transition rate matrix or infinitesimal generator of size p 1 p 1 9 g t t 0 0 t t 1 where 0 is a 1 p row vector consisting of zeros and 1 is a p 1 column vector consisting of ones here t is a p p matrix where p is commonly called the phase size it is assumed that t is an infinitesimal generator such that the off diagonal elements of t are non negative and the diagonal elements of t are strictly negative we also assume that the real part of each eigenvalue of t is strictly negative and define η t 0 to be the eigenvalue of t closest to 0 these assumptions ensure that the first p states are transient and that absorption occurs almost surely if we let x be the time until absorption in the markov chain then the distribution of x is called the ph distribution with parameters α and t or simply ph α t though this distribution is motivated via a notion of time it can be used to fit any non negative continuous dataset the ph distribution class has received much attention in the applied literature related to queues dams insurance risk reliability etc due to its flexibility and useful distributional properties for more details we refer to latouche and ramaswami 1999 if x is ph distributed with parameters α t then fx x and fx x which are the density function and distribution function of x respectively are given by 10 f x x α e t x t x 0 and 11 f x x 1 α e t x 1 x 0 where e t x exp t x is the matrix exponential of matrix tx where t is the matrix defined in 9 the matrix exponential of a square matrix a is defined in the usual way by series expansion e a exp a k 0 1 k a k since α is a row vector of size 1 p etx is a square matrix of size p p and because both t t 1 and 1 are column vectors of size p 1 we see that the density and distribution functions in 10 and 11 are actually scalar functions also from its laplace stieltjes transform the moments of ph α t are given by 12 e x k k α t 1 k 1 for k 1 some well known members of the ph class include the exponential distribution when p 1 the mixture of exponential distributions a k a hyper exponential distribution erlang distributions i e gamma distributions with integer shape parameter and its mixture the following examples show how these distributions can be expressed as ph models example 1 exponential distribution let us take p 1 with t λ and α α 1 1 then the infinitesimal generator g in 9 with t t 1 λ becomes 13 g t t 0 0 λ λ 0 0 the distribution function of this ph model is given by 14 f x x 1 α e t x 1 1 e λ x corresponding to an exponential distribution example 2 hyper exponential distribution a hyper exponential distribution is a finite mixture of n exponential distributions with the distribution function expressed as f x x 1 i 1 n w i e λ i x with w 1 w k 1 here let us consider n 3 case as an example to express this distribution in a ph representation we take p 3 and α w 1 w 2 w 3 with 15 t λ 1 0 0 0 λ 2 0 0 0 λ 3 t t 1 λ 1 λ 2 λ 3 note that because t is a diagonal matrix we have 16 e t e λ 1 0 0 0 e λ 2 0 0 0 e λ 3 thus the distribution function of this ph model is given by 17 f x x 1 α e t x 1 1 w 1 w 2 w 3 e λ 1 x 0 0 0 e λ 2 x 0 0 0 e λ 3 x 1 1 1 1 i 1 3 w i e λ i x corresponding to a hyper exponential distribution with three components more components can be included by simply increasing the phase size p example 3 erlang distribution an erlang distribution is a gamma distribution with an integer shape parameter its distribution function is from reparametrizing 2 18 f x x λ n γ n x n 1 e λ x λ n n 1 x n 1 e λ x k 1 2 by having an integer shape parameter an erlang model s distribution function allows an explicit form unlike a gamma case given by 19 f x x 1 i 0 n 1 λ x i i e λ x for this distribution a ph representation is possible we consider n 3 in this example then by setting p 3 and α 1 0 0 with 20 t λ λ 0 0 λ λ 0 0 λ t t 1 0 0 λ to get et from series expansion we use the fact that the i i j t h element of tk is given by t i i j k 1 k j k j λ k for all k 0 1 i i j n from matrix theory then after some algebra we can obtain the density as 21 f x x α e t x t α k 0 1 k t x k t k 0 x k k α t k t k 0 x k k λ t 1 3 k λ 3 2 x 2 e λ x which agrees to the erlang density with the shape parameter 3 in general for an erlang distribution with the shape parameter n we set p n and t to be a bidiagonal square matrix of size n with diagonal elements being equal to λ and the remaining non zero elements being λ there are other interesting properties that the ph distribution class enjoys for example the sum of independent ph variables is again a ph variable and the finite mixture of independent ph distributions is also a ph distribution these two are collectively called the closure property of the ph distribution class it also posseses the denseness property which means that the class of ph distributions can approximate any continuous probability distributions defined on 0 at any given desired accuracy formally stated the ph class is dense in the prohorov metric of weak convergence in the set of all continuous non negative distributions though the required number of phases may be large although all t s in the examples above are upper triangular matrices one can actually allow all elements in the given t to be non zero with different values for general use of the ph models in this case the distribution becomes more flexible with additional parameters but the resulting models are not the standard distributions we are familiar with in this regard it is noted that while the ph model class has various useful distributional properties encompassing many non negative continuous distributions in a unified framework the number of parameters in the ph model can grow quickly as one increases the phase size p leading to an impractical model with excessively many parameters and a heavy computational burden in the estimating process so in many applications it is common to set p at a reasonable size and consider a subclass of the ph distribution by restricting t to a triangle or bidiagonal matrix where the latter is called the coxian specification of the ph distribution class in the literature the estimation of the parameters once the structure of t and the phase size p has been decided can be carried out using for example the mle based on the iterative expectation maximization em algorithm as shown in asmussen et al 1996 see appendix a for details on this empht procedure 3 3 the codes for the empht algorithm is available in http home imf au dk asmus pspapers html the choice of an optimal p can be made using different criteria such as user s professional judgement or likelihood based statistical criteria however no universally accepted method is available for selecting an optimal number of phases p and or specifying non zero elements in α and t for a given p it is also worth mentioning that from the form of 1 f x x in 11 ph distributions asymptotically have an exponentially decaying tail that is 1 f x x o e η t x as x which essentially means that the tail of the ph distribution eventually becomes that of an exponential distribution with rate ηt this exponential tail may be considered to be too light to accurately model heavy tailed precipitation datasets but for practical purposes the mixture structure inside the ph distribution can often capture heavy tails by adding many layers of exponential tailed distributions as will be further elaborated in the following section 4 analysis of texas datasets in this section we use the texas rainfall data considered in li et al 2012 to compare the performances of the three models we discussed above the ggp egp and ph models for the ggp model the estimation procedure of furrer and katz 2008 was applied as for the choice of threshold we follow the suggestion of li et al 2012 θ 3 99 corresponding to the 55 quantile at which the ggp is reported to perform best for the texas dataset thus we set the threshold for ggp model at the 55 sample quantile and avoid the cumbersome optimal threshold selection issue for the egp model the threshold selection is internally taken care of from the continuity constraint at the threshold as shown in 8 for the ph distribution we restricted the model to the coxian specification with phase size p 3 to keep the number of parameters at a manageable size the number of parameters in t is thus 5 for the initial probability vector we specified it to be α α 1 α 2 0 with α 1 α 2 1 so that only one parameter needs to be estimated in α for parsimony this specification leads to 6 parameters in total slightly more parameters compared to the other two models of course one can improve the fit by increasing the phase size and or relaxing the form of α and t though we did not explore this direction in the current research in order for all candidate models to have comparable complexities in terms of the number of parameters the fitting for the ph model is carried out using the empht algorithm of asmussen et al 1996 we excluded single component models from our analysis as they are generally inadequate in modelling the precipitation datasets li et al 2012 4 1 model comparison fig 3 presents the qq plots from the three fitted models on three selected stations of ushcn texas data set id2 id11 and id44 all the models show good performances in general in the body part of the data differences stand out at the tail part the qq plots indicate that the egp model over estimates the tail in particular for station id44 the egp fit yields a poor result by producing an excessively heavy tail whereas the ggp and ph models exhibit reasonably good fits for the tail side of the data in order to supplement the qq plots we present the fitted density for the same datasets in fig 4 note that the egp model has a kink in the middle of the density due to the continuity junction point for each dataset in addition to visual inspections for the selected stations we also carry out formal model section procedures for all 49 stations in texas listed in table 1 the results are in table 2 where we present the maximized log likelihood values the results of akaike information criterion aic of akaike 1974 which is given by a i c 2 log l 2 k where l is the maximized value of the likelihood function of the model and k is the number of parameters and the bayesian information criterion bic b i c 2 log l k log n where n is the length of the records or the sample size the best model is underlined for each station in the table for an easy comparison these criteria are widely used model selection methods and have an advantage of reflecting the model complexity by giving penalty on the number of parameters which is relevant to our case because the three models we consider have different numbers of parameters which are 4 of ggp 3 of egp and 6 of ph distributions overall from table 2 we see that the ph model is chosen as the best model for 39 stations among 49 according to the aic based on the bic the egp performs best for 31 stations and the ph is best for 18 stations this is because compared to the aic the bic by definition places larger penalties for the number of parameters used whenever log n 2 or n 8 in contrast the ggp model is never selected as the model of choice under both criteria while these model selection procedures lead to the model that describes the given dataset best we may also investigate the prediction performance of each model for new observations the idea is that if a model is calibrated to the given dataset too tight with overly many parameters the resulting model while producing an excellent fit for the given dataset could actually perform poorly in prediction this is because new observations often posses different characteristics than the existing dataset used for the calibration this is a common theme known as the bias variance tradeoff in the statistical model selection problem as new observations are not possible to obtain directly in most applications a practical solution is to adopt the cross validation cv framework where the original dataset is randomly split into two disjoint subsets the training set and the test set with a suitably chosen proportion such as m 1 1 according to this m fold cv framework one first fits the model solely based on the training set the fitted model then is examined through the test set which plays the role of new observations if the fitted model works better than alternative models for the test set it is deemed to generally perform better for new observations thus in the precipitation modelling context the cv can show how the model would perform in predicting the amount of rainfall in the future the classical m fold cv however has been criticized for its instability arising from a single split result if we repeat the m fold cv many times this instability can be significantly reduced in order to compare the prediction performance of the three models we consider we use the following steps 1 for each station randomly split the sample into two subsets with the ratio m 1 1 in their rough sizes and they are called training set and test set respectively typically m is set at 5 or 10 2 fit each model ggp egp ph to the training dataset from step 1 using the mle 3 compute the log likelihood of the fitted model density for the test dataset the model with a larger the likelihood value indicates a better performance in prediction 4 repeat the above steps r times then the average of the log likelihoods shows the prediction performance of each model we will call this procedure the random split cross validation rscv the last three columns of table 2 are the results of the rscv applied to the texas dataset with m 5 and r 50 repetitions for each station each number in these three columns is the average of the 50 log likelihood values for the given model from the table it is seen that the ph is selected as the best model for 40 stations out of 49 confirming its good performance in prediction 4 2 tail evaluation in modelling the entire range of precipitation datasets we are concerned with not just fitting of the body part but also with the tail part of the data because the tail area has invaluable information for unusually large records of precipitation the standard likelihood based model selection criteria such as the aic and bic however are not suitable for evaluating the tail fit because they are mainly affected by non extreme values which take up the most data count this is because the tail observations are relatively rare and their likelihood contributions are hardly substantial other standard methods of measuring the goodness of fit include the tests of kolmogorov smirnov cramer von mises and anderson darling all these criteria compute some distance between the empirical distribution fn and the fitted one f and decide whether the postulated model is acceptable but these procedures are like the likelihood based procedures designed to evaluate the fit over the entire data range not the tail region specifically as we simply wish to compare the performance of the tail fit among different candidate models we propose to use the sum of the squared distances between high quantiles of the sample and of the fitted model in financial applications high quantiles are often referred to as the value at risk var a risk measure widely used in various risk management exercises so this can be a reasonable way to assess the adequacy of the tail calibration this exercise also offers an opportunity to investigate the tail thickness of the rainfall datasets let q i n be the 100 i n quantile of the fitted model and q i n be the corresponding sample quantile then our tail fit index is defined as 22 q η n 1 i n η n q i n q i n 2 η 0 1 by selecting the value of η close to 1 q η measures the tail fit quality of the dataset where the tail part is defined as all observations above the 100 η quantile thus the smaller the value of q η the better the tail fit is scaling by n in 22 is merely a simple adjustment to keep the resulting values at a manageable magnitude for our comparison we computed q η for η 0 9 0 95 and 0 98 respectively for all three models and the results are presented in table 3 with the minimum values underlined for each station at all η levels we see that the ph model fits the tail data better than the other two models for a majority of the stations this is interesting because even though the egp and ggp are equipped with separate models to accommodate heavy pareto type power tails their tail fits are not as good as expected there are several comments in place from the results of the table first the tails of the texas rainfall datasets may not be that heavy and exponential tails are adequate to describe the tail behavior second even if the tails are indeed heavy for texas datasets the tail fit quality crucially depends on the choice of the gpd threshold of which the task is never trivial for the egp and ggp models the threshold is chosen either internally based on a constraint or with a prescribed value as neither of these approaches is ideal the resulting tail fit might have proved relatively poor third even though the ph model has an exponential tail it can model the tail part of the dataset quite well because it stacks up many layers of exponential type distributions via internal finite mixing process the last point has a further implication in the discussion of the heavy tailness of precipitation datasets when one creates a new distribution from mixing individual component distributions one may choose a discrete or continuous mixing variable if a discrete mixing variable is used the resulting mixture model s density is given as f x i 1 k w i f i x a weighted average of the component densities fi x with the weights wi playing the role of the discrete mixing distribution i 1 k this type of distributions is called the finite mixture model as the number of component distributions is finite the ph distribution belongs to the finite mixture model in contrast for a continuous mixing case which can be thought of as a limiting case of a finite mixture with uncountably many weights the resulting mixture model is obtained by replacing the sum with an integration that is f x f x λ π λ d λ where π λ is the density of the mixing variable λ it is known that the mixture model of both types tend to be heavier tailed than the component distributions see e g klugman et al 2008 however the ultimate tail behaviours may differ theoretically depending on whether the mixing variable is discrete or continuous for example consider a mixture model arising from exponential type component distributions if we opt a finite mixture the resulting model is a weighted average of k different exponentially decaying distributions and it preserves an exponential tail asymptotically for instance the ph distribution s tail decays to zero at an exponential rate of o e η t x as mentioned previously however if we choose a continuous mixture the resulting model can yield a substantially heavier tail a prominent example is the pareto distribution which is a mixture of exponential distributions with gamma mixing weights which suggests that the pareto tail can be created by a weighted average of uncountably many light tailed exponential distributions heuristically this observation implies that a finite mixture model consisting of light tailed component distributions may yield a heavy tailed distribution by increasing the number of components though one may need an infinitely many components in theory thus finite mixture models constructed by stacking up several exponential type distributions may not have the same tail thickness as the pareto type models in a strictly asymptotic sense but we expect them to be able to produce a reasonably heavy tail the ph distribution class in this regard can be a compromising but practical solution to handle heavy tailed datasets in addition unlike the egp and ggp models the ph model does not require the selection of the threshold where the heavy tail starts and thus needs no manual input which could potentially lead to a suboptimal calibration 4 3 including dry days so far we have excluded dry days in fitting the datasets implying that only strictly positive part of the dataset has been used in the ph distribution the proportion of dry days which stands for the probability mass at zero can be incorporated in a convenient and unified fashion recall from section 3 3 that for the ph distribution the domain of the density 10 is different from that of the distribution function 11 in that the density excludes the zero value this is due to the possibility of probability mass at zero which is interpreted as a situation where the underlying markov chain process has a strictly positive initial probability of being in the absorbing state in the first place or equivalently α p 1 0 to explain how to incorporate the dry days in the ph model let us suppose that a ph distribution with p phases excluding the absorption state has been calibrated using the rainy days observations only and the estimates α α 1 α p and t have been obtained here we have α 1 α p 1 and α p 1 0 indicating no probability mass at zero yet now assume that these rainy days take up 100 r of the entire day counts historically so that the probability of having rain for any given day is r and the probability of having a dry day 1 r in light of this information the estimates α i i 1 p 1 should be revised as follows we denote the revised estimates as α i i 1 p p 1 then first for the absorption state the revised estimate becomes α p 1 1 r 0 the probability of having no rain second the remaining initial probabilities are reduced proportionally that is α i r α i i 1 p so that the sum of all revised probabilities becomes α 1 α p α p 1 r 1 r 1 consequently p h α t is the mixed in the sense that it has both discrete and continuous parts model that describes both dry and wet days where the probability of dry days are expressed as a discrete spike at x 0 and the precipitation amount in wet days are modelled as a continuous part on x 0 note that no change is needed for t in the revision we may verify the size of the discrete mass at zero by plugging in x 0 to the distribution function 11 to obtain f x 0 1 α e t 0 1 1 α 1 1 i 1 p α i 1 1 α p 1 α p 1 1 r 4 4 an illustration for an illustration purpose let us consider the data of fort stockton station represented by id24 in ushcn texas dataset in this data there are 3021 wet days and 20 422 dry days in a total of 23 443 days recorded from 1940 to 2009 when we use the wet days only the estimated parameters of the ph distribution with p 3 under our specification are given by using the em algorithm 23 α 0 4795 0 5205 0 and t 0 1197 0 0100 0 0 0 5589 0 1074 0 0 0 0505 these parameters give the fitted ph distribution used previously to compute table 2 note that there are six parameter estimates in 23 because of the unit constraint in α this α implies that α 4 0 the initial probability associated with the absorbing state because we are only using positive observations thus the estimated ph distribution is a conditional distribution defined on x 0 all other stations dataset have been fitted in the same manner now suppose that we like to incorporate the dry days in the model noting that the probability of having no rain in fort stockton for any given day is 20 422 23 443 0 8712 1 r we obtain α 4 0 8712 the remaining initial probabilities after a proportional reduction becomes α r α 0 0618 0 0670 0 so that α 1 α 4 1 thus p h α t yields a full range stochastic precipitation model for fort stockton including both dry and wet days 4 5 efficiency of the ml estimator we consider in this subsection the asymptotic efficiency of the maximum likelihood ml estimator of the ph model in general studying the asymptotic behaviour of an ml estimator requires the corresponding fisher information matrix which can be obtained from the second derivatives of the log likelihood function functions of the ml estimator such as the quantiles can be further investigated by using the delta method however such a task is quite demanding for the ph model due to its matrix representation in addition the representation of the ph model is known to be not unique meaning that different sets of α and t may arrive at the same distribution because the distribution is determined by the product of these matrices rather than the matrices themselves as indicated from the distribution function f x x 1 α e t x 1 see e g latouche and ramaswami 1999 in the statistical inference viewpoint this implies that the estimated parameters may be different even though the resulting distribution is identical thus we investigate the asymptotic efficiency of the ml estimator using a simulation approach in particular we empirically examine the variations of the estimated quantiles rather than the parameters produced by a fitted ph model over various sample sizes n this method does not pose the non unique representation problem as the quantiles are computed from the distribution function the asymptotic efficiency of other distributional quantities as long as expressed as functions of the parameters can be studied in a similar fashion in our simulation based experiment we choose the fitted ph model for the id24 of the texas dataset as the true model and carry out the following steps to see how the variabilities of the ml quantiles behave as the sample size increases 1 generate a random sample of size n from the true model 2 fit the ph model to the sample generated in step 1 using the ml estimation and compute the ml quantiles at levels p 50 90 and 95 respectively 3 repeat steps 1 2 for b times to assess the variability of the estimated quantiles against the quantiles from the true model we take b 50 in our simulation 4 repeat steps 1 3 over various n values fig 5 presents the results of this simulation exercise from the box plot in the figure we see that the variations of all the estimated quantiles decreases over the sample size gradually converging to the true quantile values the corresponding mean squared errors mse which is the sum of the bias squared and the variance are also presented on the right side of the figure from the mse behaviour we again see that the ml based quantile estimates becomes more accurate as the sample size increases with smaller variations indicating that these are asymptotically efficient though the theoretical speed at which the estimates decay to zero is not precisely determined 5 datasets of other shapes in papalexiou and koutsoyiannis 2012 the worldwide ghcn dataset was analyzed to investigate the shapes of empirical precipitation distributions and their tail behaviors in this work the l moment ratios were used to capture the shape characteristics of each sample from a given geographical area s station following their work the diagram of the l varaiation versus l skewness for the ghcn dataset is presented in fig 6 which marks 19 328 different stations worldwide as mentioned in section 2 the shaded area stands for the texas dataset studied in the previous section from this figure papalexiou and koutsoyiannis 2012 showed that the world precipitation data roughly form a linear relationship between l variation and l skewness with a positive slope as superimposed in the figure they also found that depending on the position in the figure the precipitation datasets take different shapes because of different local conditions in particular the stations located in the top right area of the diagram have j shaped distributions meaning that the their densities have a mode at zero or minimum amount of precipitation followed by a monotone downward decrease for the entire range of the data the downward slope becomes steeper as the location of the station moves to further top right corner in the diagram another distinct shape occurs at the bottom left area of the diagram where the stations take bell shaped distributions with the mode or peak of the data located at a strictly positive value from their positions we see that the datasets of texas stations we analysed previously are moderately j shaped but some are more so than others by lying on the top right side in the diagram the number of datasets in ghcn being close to 20 000 is indeed huge and it is prohibitive to study them all with the computing power at our hands as we have analysed the texas dataset a subset of ghcn dataset we would like to extend our analyses to some other datasets which exhibit different distributional characteristics than those of texas given that the texas datasets are positioned in middle area the l moments ratio diagram in fig 6 our goal in this section is thus to study some stations located at extreme positions in the diagram for this we select two stations from the top right and bottom left areas of the diagram respectively and investigate how the alternative three models perform for these datasets the dataset selected from the top right area is from asn00004032 port hedland international airport australia its precipitation data is depicted in the right panel of fig 7 which clearly shows its j shape the dataset selected from the bottom left area is from in sf001943230 gannapan south africa its dataset shown in the left panel of fig 7 is bell shaped comparing the histograms in the figure reveals that the precipitation datasets in other parts of the world could take markedly different shapes as we have successfully modelled the rainfall datasets in texas with the ph distribution class we now investigate how the three candidate models perform for these two precipitation datasets the ph model used in the section has the identical parameter structure as in the previous section with p 3 we start with the bell shaped gannapan dataset of which the fitting result is given in figs 8 and 9 from these two figures the ph model is clearly favored over the other two models we note especially from fig 9 that the egp model is unable to capture the mode in the middle of the data because it uses an exponential distribution for the body part of the dataset furthermore its ml estimate results in a negative value of ξ after expanding the original parameter space defined in eq 7 which implies that the maximum precipitation amount is bounded from above the ggp model does capture the bell shape of the data but its overall fit is not as good as that of the ph model a numerical summary of the fits from these three models are given on the left side of table 4 which confirms our visual conclusion overall the ph model is best in all criteria considered for the gannapan dataset except for a single case next the j shaped port hedland international airport data from the right panel of fig 7 is analyzed in figs 10 and 11 in the qq plot we see that the fits from the ggp and egp over estimate the tail implying that the actual tail of this dataset may not be as heavy as the gpd the qq plot for the calibrated ph model shows a more satisfactory fit overall with a slight under estimation for only a few last observations in the tail the tail fit could be further improved by increasing the phase size p but larger p values also require more parameters to be estimated due to higher model complexity the numbers on the left side of table 4 summarize the numerical result for this dataset the ph model performs well for most criteria except for the bic where the additional number of parameters is more severely penalized for the large sample size n 2501 in summary our numerical analyses for these two precipitation datasets indicate that the ph model is a generally versatile well performing statistical tool to model the entire range of daily precipitation amounts 6 conclusion modeling precipitation datasets is of great importance in many applications including agriculture forest management and hydrology traditional models such as the exponential gamma and kappa distributions are known to be inadequate in modelling these datasets due to their shape restriction few parameters more sophisticated models have also been proposed in the literature by combining several individual component distributions in the form of mixture or hybrid distributions the hybrid distribution also known as the composite distribution is particularly appealing as it can separately model the tail data which is known to be heavy in many precipitation datasets however estimating hybrid models involves a cumbersome threshold selection or shape restrictions to make the density continuous or smooth at the tail threshold in this paper we introduced the phase type ph model a rich class of distributions previously used in reliability and insurance applications to model the entire range of daily precipitation datasets the ph distribution class can be very flexible in its density shape with mathematically tractable distributional properties it also contains commonly used distributions as its members however the general parameter estimation for the ph distribution is a delicate matter as the number of parameters can grow quickly as one increases the phase size leading to an impractical model with excessively many parameters to this extent we have selected a six parameter ph distribution with three phases for modelling precipitation datasets these parameters were estimated by the maximum likelihood estimation procedure based on the expectation maximization algorithm in asmussen et al 1996 we compared the ph model against other existing multi component models that have been reported to perform better in the literature both competing models are hybrid models and use the generalized pareto distribution gpd to separately handle the tail part of the data in order to compare the fitting performance the daily precipitation datasets collected from 49 stations in texas was considered following li et al 2012 based on the aic and bic criteria as well as the random split cross validation rscv to assess the prediction performance furthermore recognizing that the likelihood based procedures are mainly affected by the body part of the dataset we evaluated the tail fit separately to see if these models can adequately capture the tail characteristics of the datasets these extensive numerical studies overall show that the ph model yields satisfactory results in fitting the precipitation datasets as the texas dataset represents a small subset of the existing precipitation datasets in the world we also examined two additional datasets with qualitatively different shapes than the texas dataset selected from the l moments ratio diagram of ghcn papalexiou and koutsoyiannis 2012 analysing these two datasets again confirms that the ph distribution can be a competitive choice in modelling the precipitation datasets with various shapes perhaps the main weakness of the ph model despite its attractive theoretical properties is its computational difficulty in estimating parameters the maximum likelihood estimation requires a specialized and complicated numerical algorithm such as the one shown in appendix a but its actual execution is manageable given the code of the algorithm is available publicly appendix a empht algorithm consider n observations x 1 x n generated by ph α t distribution with phase p or equivalently a p 1 dimensional state space here the observed values are considered incomplete because xi s represent only the absorption times and the exact paths are unknown if we assume that we have observed the entire path of the underlying markov chain the complete observation corresponding to a given xi of the ph distribution can be written as y i j 0 i j m i 1 i s 0 i s m i 1 i where mi is the number of jumps until the markov chain hits the absorbing state 0 j k i is the k th state visited by the markov chain with j m i i 0 and s k i is the corresponding sojourn time at the k th state with s m i indicating that the last jump leads to the absorbing state then the sojourn times should satisfy x i s 0 i s m i 1 i and the density of the i th complete observation can be represented by 24 f y i α t α j 0 i exp t j 0 i j 0 i s 0 i t j 0 i j 1 i exp t j m i 1 i j m i 1 i s m i 1 i t j m i 1 i where we use the notations b i j and b i to denote i j th element and i th element of a given matrix b and a vector b respectively now if we denote the complete sample of all of n observations by 25 y j 0 1 j m 1 1 1 s 0 1 s m 1 1 1 j 0 n j m n 1 n s 0 n s m n 1 n then the density of the complete sample can be written in the form 26 f y α t i 1 p α i b i i 1 p exp t i i z i i 1 p j 1 j i p t i j n i j t i n i 0 where b i i 1 p denote the number of markov chains starting in state i z i i 1 p the total time spent by markov chains in state i and n i j the total number of jumps from state i to state j for i j i 1 p and j 0 1 p we see that the density in 26 is a member of the multi parameter exponential family with sufficient statistics bi s zi s and n i j s this leads the mle based on the complete sample y by 27 α i b i n t i j n i j z i i j t i n i 0 z i t i i t i j 1 j i t i j the em algorithm then calculates mle of α and t based on the incomplete data the em algorithm is an iterative procedure that maximizes in each step the conditional expectation of the log likelihood given the observed sample x 1 x n that is in each iteration two separate steps called the e and m steps are carried out in the e step one calculates the conditional expectation of the log likelihood given the observations which are absorption times and it is maximized in the m step from the density function in 26 the log likelihood of the complete sample y is in the form of 28 log f y α t i 1 p b i log α i i 1 p t i i z i i 1 p j 1 j i p n i j log t i j i 1 p n i 0 log t i which we observe to be linear in the sufficient statistics hence in the e step calculating the conditional expectation of the log likelihood given the observations reduces to calculating the conditional expectations of the sufficient statistics the exact expressions of these quantities as well as the detailed em procedure can be found in asmussen et al 1996 the em algorithm for the ph calibration can be summarized as follows given an initial parameters α 0 t 0 in e step the conditional expectations of the sufficient statistics given the observed sample x 1 x n are calculated and are plugged in the log likelihood function in 28 as the parameters for complete sample y then in m step the mles are obtained using the equations in 27 these two steps are iterated until convergence appendix b random number generation from ph distribution one can use the following steps to generate a random number from a ph distribution ph x α t 1 generate a random number from unif 0 1 and call it u 2 solve the following equation with respect to x u 1 α e t x 1 this step can be done in any standard mathematical software using a suitably chosen optimization procedure provided that the software has the matrix exponential function the solution x is a random number generated from ph x α t note that the solution is always uniquely obtained as the cdf of any ph distribution is strictly increasing supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 11 014 appendix c supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
720,modeling the entire range of precipitation datasets using some parametric distribution is of great importance in many applications traditionally single component models such as an exponential or gamma distribution have been used but recently more flexible multi component models have also been investigated by combining known distributions in the form of mixture or hybrid models in this paper we introduce the phase type ph distribution a rich class of distributions previously used in other disciplines as a parametric alternative to model the full spectrum of precipitation datasets in different areas worldwide after discussing its distributional properties we compare the performance of the ph model to other existing models using 49 precipitation records in texas the results show that the ph model performs well compared to other alternative multi component models in terms of likelihood based model selection criteria and the fit in the tail part of the data we also consider precipitation datasets of different shapes and reaffirm the ability of the ph model to capture the full spectrum of the precipitation amount the computational complexity however remains as a possible caveat of the ph model keywords precipitation phase type distribution hybrid distribution 1 introduction measuring and predicting the precipitation are considered to be of great importance in many applications including agriculture forest management and hydrology common models of the precipitation are stochastic in that they describe the phenomenon of rainfalls through some static or dynamic statistical models with specific distributions with a suitable time interval as a base period of modelling the choice of the time interval can be arbitrary in theory but taking a daily basis is most natural and popular in the literature see for example richardson 1981 many previous studies tried to model daily rainfall data through parametric approaches for example ison et al 1971 mielke and johnson 1973 richardson 1981 and stern and coe 1984 non parameteric approaches have also been proposed by e g sharma and lall 1999 and harrold et al 2003 though each approach has its pros and cons parametric models are generally advantageous in that they can model rainfall datasets with only a few parameters and can be easily extrapolated towards extreme area where rainfall observations are relatively rare in frequency simple parametric models found in the literature include exponential gamma and some transformed normal distributions however these simple models often fail to capture important characteristics of the rainfall datasets which are typically skewed over dispersed relatively heavy tailed and sometimes bell shaped as an alternative approach to improve the calibration mixtures and hybrid distributions models have been suggested in the literature see e g wilks 1999 and li et al 2012 being natural extensions of simple stochastic models the class of mixture distributions is more flexible with more parameters and thus can address unique shape characteristics of the rainfall datasets for example woolhiser and roldan 1982 adopted mixed exponential distribution and yoo et al 2005 exploited mixed gamma distribution in recent studies of vrac and naveau 2007 and hundecha et al 2009 a dynamic mixture of gamma and generailzed pareto distribution was considered to emphasize the tail calibration of precipitation datasets related to this in some studies in the hydrology community the evidence of heavy tailed phenomenon on the distribution of high precipitation amount has recently gained strong support from researchers see e g koutsoyiannis 2004 the underlying idea of the heavy tail essentially says that the extreme precipitation amounts over some high threshold value tend to have different distributional behaviours and accordingly can be modelled using a separate statistical distribution in particular the distribution for the tail is modelled by the generalized pareto distiribution gpd justified by the standard result of extreme value theory evt to this extent various methods were investigated and explored in the literature focusing on the tail behavior of daily precipitation described by some power or polynomial survival function see for instance furrer and katz 2008 li et al 2012 papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 in particular in their recent paper li et al 2012 examined various hybrid distributions to model the full spectrum of daily precipitation under the evt framework and showed that the body and tail parts of the dataset can be adequately modelled by an exponential and gpd with a positive shape parameter respectively the idea that the tails of rainfall datasets follow some power function however is not universally accepted for example booij 2002 modeled extreme daily precipitations with gumbel distribution and exponential distribution which have lighter exponential tails also park et al 2011 compared several gev distribution based model and concluded both power tailed models and exponential tailed models could be adopted to explain extreme rainfalls thus whether the precipitation extremes in general follow a power or exponential tail remains an open question and it is reasonable to say that depending on the dataset under consideration a convolution or mixture of exponential distributions may serve as a good candidate to describe the entire range of the rainfall datasets by adding several layers of light tailed distributions in this paper we are interested in modelling the entire range of typical precipitation datasets for this we propose the phase type ph distribution as an alternative mixture distribution to model the precipitation the ph distributions are a class of mixture distributions that contains many well known distributions as members such as an exponential erlang and its mixtures being a mixture distribution of exponential tailed distributions the ph distribution class is not only flexible but also can adapt the heavy tail if needed by providing a fatter survival function with more components for the tail of the given dataset though this distribution class has widely been used in reliability and insurance contexts its applications towards the precipitation seems rare for the purpose of comparison in this paper we closely follow the work of li et al 2012 where texas rainfall datasets are analyzed using various single and hybrid models both with and without the evt framework in particular we use the identical datasets and model them with the ph distribution to compare with other existing parametric models later we also consider the global precipitation datasets used in e g papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 for further analyses as there are datasets with different shapes outside texas for these datasets we carry out extensive fitting exercises and standard model validations and show that the ph distribution class is a flexible competitive and well rounded alternative stochastic model in describing the whole range of precipitation datasets of various shapes the present article is organized as follows in section 2 we describe the datasets to be used in the paper section 3 surveys existing parametric models to describe precipitation datasets and introduces the ph distribution class along with its distributional properties in section 4 we analyze texas rainfall datasets using the ph distribution as well as other multi component models to show how the ph model performs compared to other alternatives in modeling the entire range of the precipitation datasets we extend our sample coverage to other places of the world in section 5 in this section we consider precipitation datasets of different shapes found in other locations and show that the ph distribution again successfully model the datasets under consideration we conclude our paper in section 6 2 datasets the first dataset analysed is united states historical climatology network ushcn daily data set raw data set contains daily records of precipitation snowfall snow depth maximum temperature minimum temperature and information about flag among 48 files of contiguous states we selected texas which has 49 stations which was used in li et al 2012 to model precipitation datasets we included all non zero precipitation values during 1940 and 2009 without taking care of missings following the criteria used in li et al 2012 table 1 presents some basic statistics for each station along with the location note that if we had included dry days i e zero values the mean would have been smaller the second set of data we will consider later in section 5 is a global precipitation dataset from daily global historical climatology network ghcn daily which has also been used in precipitation analyses in the literature this dataset includes about 100 000 stations and contains ushcn as its subset we filtered stations according to papalexiou et al 2013 2 2 we only included stations that have a record length of over 50 years b percentage of missing values less than 20 data assigned with suspicious quality flags less than 0 1 the screen values of quality flags are two one with g failed gap check and another with x failed bound check for more information about this dataset see menne et al 2012 after data cleansing a total record of 19 328 stations has been obtained from ghcn which are almost identical to those used in papalexiou and koutsoyiannis 2012 and papalexiou et al 2013 this dataset is still prohibitively big and we are unable to analyse them all instead we will select two specific stations residing in extreme positions in the l moments ratio diagram which exhibit qualitatively distinct shape characteristics compared to texas datasets we investigate how alternative models perform for these different datasets 3 models 3 1 single component models fundamental characteristics of daily precipitation data are described as non negative continuous except at the spike on zero and right skewed assuming we only focus on the continuous part of the data common candidate statistical models include exponential distribution by e g todorovic and woolhiser 1975 gamma distribution by ison et al 1971 wilks 1999 and schoof et al 2010 and kappa distribution by mielke and johnson 1973 to name a few let x denote the non zero daily precipitation amount then each model s probability density function is given as follows 1 exponential distribuiton 1 f e x p x λ 1 λ e x λ x 0 λ 0 where λ is the scale parameter 2 gamma distribuiton 2 f g a m x α β 1 β α γ α x α 1 e x β x 0 α β 0 where α is the shape parameter and β is the scale parameter 3 kappa distribuiton 3 f k a p x α β θ α θ β x β θ 1 α x β α θ α 1 α x 0 α β θ 0 where θ and β are the shape and scale parameters respectively and α is the remaining third parameter these models are ordered in that they become increasingly more flexible with more parameters other distributions can also be found such as skewed normal wan et al 2005 truncated power of normal distribution bardossy and plate 1992 and generalized pareto distribution gpd provided that only the tail of dataset is modelled the list of possible single component models can surely be much longer but we restrict ourselves to these three models to avoid crowded model comparison however as evidenced in previous studies it is now much agreed that single component models are generally inadequate to describe the whole range of daily precipitation datasets to illustrate this let us consider the texas station id2 data as an example of which the histogram is given in fig 1 the shape of the histogram indicates that a simple model such as an exponential distribution may produce a reasonably good fit to our eyes but it turns out to be not true after fitting the dataset with these three models based on the maximum likelihood estimation mle we present the qq plots in fig 2 from the figure we see that all these single models yield substantially poor fits to describe the dataset overall with under or overestimating both the body and tail considerably with other stations we observe similar inadequacies and the fits are generally poor the inadequacy of single component models in fitting precipitation datasets is well documented in e g li et al 2012 3 2 multi component models further improvement in fitting can be achieved by introducing additional distributions or components to single component models in this regard mixture type distributions were suggested in the literature including a mixed exponential distribution wilks 1999 and dynamic mixture of gamma and gpd vrac and naveau 2007 alternatively hybrid models or composite distributions were also considered of which the density is created by stitching two densities at a particular threshold in recent studies furrer and katz 2008 suggested a hybrid distribution of gamma and gpd ggp in short and li et al 2012 proposed a hybrid of exponential and gpd egp which was reported to perform better than some mixture models both of these models take gpd as the upper tail distribution to reflect heavy tail behavior of precipitation extremes koutsoyiannis 2004 inspired from the peaks over threshold pot framework of evt just like single component models one can create many different mixture or hybrid models and it is not feasible to consider all possible candidates to this end we consider for our study two hybrid models that are reported to be superior in the literature the first model is the ggp of furrer and katz 2008 with density as 4 f g g p x α β ξ σ θ f g a m x α β i x θ 1 f g a m θ α β f g p x ξ σ θ i x θ where i is the indicator function and fgam and fgam are the probability density function and cumulative distribution function of a gamma distribution respectively the gpd density acts as the tail specific model starting from the threshold θ 5 f g p x ξ σ θ 1 σ 1 ξ x θ σ 1 ξ 1 x θ as this gpd is not defined below θ we need 1 f g a m θ α β in 4 as the normalising factor to ensure the integral of the ggp density over its support is unity to make the density 4 continuous at θ a constraint f g g p θ f g g p θ is imposed which in turn yields the scale parameter σ of gpd expressed as the reciprocal of the gamma hazard function 6 σ 1 f g a m θ α β f g a m θ α β as a result its parameter set reduces to α β ξ θ even though the model complexity have been decreased due to the continuity constraint the tail threshold selection issue remains which does not have any guaranteed solution and requires cumbersome trial and error methods the second model is the egp of li et al 2012 of which the density is given by 7 f e g p x λ ξ σ θ 1 1 f e x p θ λ f e x p x λ i x θ f g p x ξ σ θ i x θ where fexp and fexp are the density and cumulative distribution function of an exponential distribution respectively exponential distribution here the denominator 1 f e x p θ λ is the normalising constant because the integration of the numerator of fegp x is 0 f e x p x λ i x θ f g p x ξ σ θ i x θ d x f e x p θ λ 1 this model has an advantage in that it can avoid the threshold selection via the continuity constraint at the threshold θ that is requiring f e g p θ f e g p θ produces 8 θ λ ln λ σ so that the threshold θ is automatically selected from the data and the number of parameters reduce to λ ξ σ by sacrificing model flexibility with taking exponential rather than gamma on its body part it obtains a primary advantage of circumventing the threshold selection problem 3 3 phase type distribution class the phase type ph distribution was introduced by neuts 1975 1981 and is created by a convolution or mixture of exponential distributions mathematically it is defined as the continuous distribution of the time until absorption in a continuous time markov chain with an absorbing state to formally introduce this model consider a continuous time markov chain with p 1 states 1 2 p p 1 where the states 1 p are transient states and state p 1 is the absorbing state also we let the process have an initial probability of starting in any of the p 1 states given by the probability row vector α 1 α p α p 1 with α 1 α p 1 1 for notational convenience we denote α α 1 α p so that the initial probability vector can be written as α α p 1 note that α p 1 0 is the probability attached to the absorbing state whether α p 1 is zero or strictly positive depends on the existence of probability mass at zero in the distribution which will be further explained later based on the above description this continuous markov process can be written in the form of the following transition rate matrix or infinitesimal generator of size p 1 p 1 9 g t t 0 0 t t 1 where 0 is a 1 p row vector consisting of zeros and 1 is a p 1 column vector consisting of ones here t is a p p matrix where p is commonly called the phase size it is assumed that t is an infinitesimal generator such that the off diagonal elements of t are non negative and the diagonal elements of t are strictly negative we also assume that the real part of each eigenvalue of t is strictly negative and define η t 0 to be the eigenvalue of t closest to 0 these assumptions ensure that the first p states are transient and that absorption occurs almost surely if we let x be the time until absorption in the markov chain then the distribution of x is called the ph distribution with parameters α and t or simply ph α t though this distribution is motivated via a notion of time it can be used to fit any non negative continuous dataset the ph distribution class has received much attention in the applied literature related to queues dams insurance risk reliability etc due to its flexibility and useful distributional properties for more details we refer to latouche and ramaswami 1999 if x is ph distributed with parameters α t then fx x and fx x which are the density function and distribution function of x respectively are given by 10 f x x α e t x t x 0 and 11 f x x 1 α e t x 1 x 0 where e t x exp t x is the matrix exponential of matrix tx where t is the matrix defined in 9 the matrix exponential of a square matrix a is defined in the usual way by series expansion e a exp a k 0 1 k a k since α is a row vector of size 1 p etx is a square matrix of size p p and because both t t 1 and 1 are column vectors of size p 1 we see that the density and distribution functions in 10 and 11 are actually scalar functions also from its laplace stieltjes transform the moments of ph α t are given by 12 e x k k α t 1 k 1 for k 1 some well known members of the ph class include the exponential distribution when p 1 the mixture of exponential distributions a k a hyper exponential distribution erlang distributions i e gamma distributions with integer shape parameter and its mixture the following examples show how these distributions can be expressed as ph models example 1 exponential distribution let us take p 1 with t λ and α α 1 1 then the infinitesimal generator g in 9 with t t 1 λ becomes 13 g t t 0 0 λ λ 0 0 the distribution function of this ph model is given by 14 f x x 1 α e t x 1 1 e λ x corresponding to an exponential distribution example 2 hyper exponential distribution a hyper exponential distribution is a finite mixture of n exponential distributions with the distribution function expressed as f x x 1 i 1 n w i e λ i x with w 1 w k 1 here let us consider n 3 case as an example to express this distribution in a ph representation we take p 3 and α w 1 w 2 w 3 with 15 t λ 1 0 0 0 λ 2 0 0 0 λ 3 t t 1 λ 1 λ 2 λ 3 note that because t is a diagonal matrix we have 16 e t e λ 1 0 0 0 e λ 2 0 0 0 e λ 3 thus the distribution function of this ph model is given by 17 f x x 1 α e t x 1 1 w 1 w 2 w 3 e λ 1 x 0 0 0 e λ 2 x 0 0 0 e λ 3 x 1 1 1 1 i 1 3 w i e λ i x corresponding to a hyper exponential distribution with three components more components can be included by simply increasing the phase size p example 3 erlang distribution an erlang distribution is a gamma distribution with an integer shape parameter its distribution function is from reparametrizing 2 18 f x x λ n γ n x n 1 e λ x λ n n 1 x n 1 e λ x k 1 2 by having an integer shape parameter an erlang model s distribution function allows an explicit form unlike a gamma case given by 19 f x x 1 i 0 n 1 λ x i i e λ x for this distribution a ph representation is possible we consider n 3 in this example then by setting p 3 and α 1 0 0 with 20 t λ λ 0 0 λ λ 0 0 λ t t 1 0 0 λ to get et from series expansion we use the fact that the i i j t h element of tk is given by t i i j k 1 k j k j λ k for all k 0 1 i i j n from matrix theory then after some algebra we can obtain the density as 21 f x x α e t x t α k 0 1 k t x k t k 0 x k k α t k t k 0 x k k λ t 1 3 k λ 3 2 x 2 e λ x which agrees to the erlang density with the shape parameter 3 in general for an erlang distribution with the shape parameter n we set p n and t to be a bidiagonal square matrix of size n with diagonal elements being equal to λ and the remaining non zero elements being λ there are other interesting properties that the ph distribution class enjoys for example the sum of independent ph variables is again a ph variable and the finite mixture of independent ph distributions is also a ph distribution these two are collectively called the closure property of the ph distribution class it also posseses the denseness property which means that the class of ph distributions can approximate any continuous probability distributions defined on 0 at any given desired accuracy formally stated the ph class is dense in the prohorov metric of weak convergence in the set of all continuous non negative distributions though the required number of phases may be large although all t s in the examples above are upper triangular matrices one can actually allow all elements in the given t to be non zero with different values for general use of the ph models in this case the distribution becomes more flexible with additional parameters but the resulting models are not the standard distributions we are familiar with in this regard it is noted that while the ph model class has various useful distributional properties encompassing many non negative continuous distributions in a unified framework the number of parameters in the ph model can grow quickly as one increases the phase size p leading to an impractical model with excessively many parameters and a heavy computational burden in the estimating process so in many applications it is common to set p at a reasonable size and consider a subclass of the ph distribution by restricting t to a triangle or bidiagonal matrix where the latter is called the coxian specification of the ph distribution class in the literature the estimation of the parameters once the structure of t and the phase size p has been decided can be carried out using for example the mle based on the iterative expectation maximization em algorithm as shown in asmussen et al 1996 see appendix a for details on this empht procedure 3 3 the codes for the empht algorithm is available in http home imf au dk asmus pspapers html the choice of an optimal p can be made using different criteria such as user s professional judgement or likelihood based statistical criteria however no universally accepted method is available for selecting an optimal number of phases p and or specifying non zero elements in α and t for a given p it is also worth mentioning that from the form of 1 f x x in 11 ph distributions asymptotically have an exponentially decaying tail that is 1 f x x o e η t x as x which essentially means that the tail of the ph distribution eventually becomes that of an exponential distribution with rate ηt this exponential tail may be considered to be too light to accurately model heavy tailed precipitation datasets but for practical purposes the mixture structure inside the ph distribution can often capture heavy tails by adding many layers of exponential tailed distributions as will be further elaborated in the following section 4 analysis of texas datasets in this section we use the texas rainfall data considered in li et al 2012 to compare the performances of the three models we discussed above the ggp egp and ph models for the ggp model the estimation procedure of furrer and katz 2008 was applied as for the choice of threshold we follow the suggestion of li et al 2012 θ 3 99 corresponding to the 55 quantile at which the ggp is reported to perform best for the texas dataset thus we set the threshold for ggp model at the 55 sample quantile and avoid the cumbersome optimal threshold selection issue for the egp model the threshold selection is internally taken care of from the continuity constraint at the threshold as shown in 8 for the ph distribution we restricted the model to the coxian specification with phase size p 3 to keep the number of parameters at a manageable size the number of parameters in t is thus 5 for the initial probability vector we specified it to be α α 1 α 2 0 with α 1 α 2 1 so that only one parameter needs to be estimated in α for parsimony this specification leads to 6 parameters in total slightly more parameters compared to the other two models of course one can improve the fit by increasing the phase size and or relaxing the form of α and t though we did not explore this direction in the current research in order for all candidate models to have comparable complexities in terms of the number of parameters the fitting for the ph model is carried out using the empht algorithm of asmussen et al 1996 we excluded single component models from our analysis as they are generally inadequate in modelling the precipitation datasets li et al 2012 4 1 model comparison fig 3 presents the qq plots from the three fitted models on three selected stations of ushcn texas data set id2 id11 and id44 all the models show good performances in general in the body part of the data differences stand out at the tail part the qq plots indicate that the egp model over estimates the tail in particular for station id44 the egp fit yields a poor result by producing an excessively heavy tail whereas the ggp and ph models exhibit reasonably good fits for the tail side of the data in order to supplement the qq plots we present the fitted density for the same datasets in fig 4 note that the egp model has a kink in the middle of the density due to the continuity junction point for each dataset in addition to visual inspections for the selected stations we also carry out formal model section procedures for all 49 stations in texas listed in table 1 the results are in table 2 where we present the maximized log likelihood values the results of akaike information criterion aic of akaike 1974 which is given by a i c 2 log l 2 k where l is the maximized value of the likelihood function of the model and k is the number of parameters and the bayesian information criterion bic b i c 2 log l k log n where n is the length of the records or the sample size the best model is underlined for each station in the table for an easy comparison these criteria are widely used model selection methods and have an advantage of reflecting the model complexity by giving penalty on the number of parameters which is relevant to our case because the three models we consider have different numbers of parameters which are 4 of ggp 3 of egp and 6 of ph distributions overall from table 2 we see that the ph model is chosen as the best model for 39 stations among 49 according to the aic based on the bic the egp performs best for 31 stations and the ph is best for 18 stations this is because compared to the aic the bic by definition places larger penalties for the number of parameters used whenever log n 2 or n 8 in contrast the ggp model is never selected as the model of choice under both criteria while these model selection procedures lead to the model that describes the given dataset best we may also investigate the prediction performance of each model for new observations the idea is that if a model is calibrated to the given dataset too tight with overly many parameters the resulting model while producing an excellent fit for the given dataset could actually perform poorly in prediction this is because new observations often posses different characteristics than the existing dataset used for the calibration this is a common theme known as the bias variance tradeoff in the statistical model selection problem as new observations are not possible to obtain directly in most applications a practical solution is to adopt the cross validation cv framework where the original dataset is randomly split into two disjoint subsets the training set and the test set with a suitably chosen proportion such as m 1 1 according to this m fold cv framework one first fits the model solely based on the training set the fitted model then is examined through the test set which plays the role of new observations if the fitted model works better than alternative models for the test set it is deemed to generally perform better for new observations thus in the precipitation modelling context the cv can show how the model would perform in predicting the amount of rainfall in the future the classical m fold cv however has been criticized for its instability arising from a single split result if we repeat the m fold cv many times this instability can be significantly reduced in order to compare the prediction performance of the three models we consider we use the following steps 1 for each station randomly split the sample into two subsets with the ratio m 1 1 in their rough sizes and they are called training set and test set respectively typically m is set at 5 or 10 2 fit each model ggp egp ph to the training dataset from step 1 using the mle 3 compute the log likelihood of the fitted model density for the test dataset the model with a larger the likelihood value indicates a better performance in prediction 4 repeat the above steps r times then the average of the log likelihoods shows the prediction performance of each model we will call this procedure the random split cross validation rscv the last three columns of table 2 are the results of the rscv applied to the texas dataset with m 5 and r 50 repetitions for each station each number in these three columns is the average of the 50 log likelihood values for the given model from the table it is seen that the ph is selected as the best model for 40 stations out of 49 confirming its good performance in prediction 4 2 tail evaluation in modelling the entire range of precipitation datasets we are concerned with not just fitting of the body part but also with the tail part of the data because the tail area has invaluable information for unusually large records of precipitation the standard likelihood based model selection criteria such as the aic and bic however are not suitable for evaluating the tail fit because they are mainly affected by non extreme values which take up the most data count this is because the tail observations are relatively rare and their likelihood contributions are hardly substantial other standard methods of measuring the goodness of fit include the tests of kolmogorov smirnov cramer von mises and anderson darling all these criteria compute some distance between the empirical distribution fn and the fitted one f and decide whether the postulated model is acceptable but these procedures are like the likelihood based procedures designed to evaluate the fit over the entire data range not the tail region specifically as we simply wish to compare the performance of the tail fit among different candidate models we propose to use the sum of the squared distances between high quantiles of the sample and of the fitted model in financial applications high quantiles are often referred to as the value at risk var a risk measure widely used in various risk management exercises so this can be a reasonable way to assess the adequacy of the tail calibration this exercise also offers an opportunity to investigate the tail thickness of the rainfall datasets let q i n be the 100 i n quantile of the fitted model and q i n be the corresponding sample quantile then our tail fit index is defined as 22 q η n 1 i n η n q i n q i n 2 η 0 1 by selecting the value of η close to 1 q η measures the tail fit quality of the dataset where the tail part is defined as all observations above the 100 η quantile thus the smaller the value of q η the better the tail fit is scaling by n in 22 is merely a simple adjustment to keep the resulting values at a manageable magnitude for our comparison we computed q η for η 0 9 0 95 and 0 98 respectively for all three models and the results are presented in table 3 with the minimum values underlined for each station at all η levels we see that the ph model fits the tail data better than the other two models for a majority of the stations this is interesting because even though the egp and ggp are equipped with separate models to accommodate heavy pareto type power tails their tail fits are not as good as expected there are several comments in place from the results of the table first the tails of the texas rainfall datasets may not be that heavy and exponential tails are adequate to describe the tail behavior second even if the tails are indeed heavy for texas datasets the tail fit quality crucially depends on the choice of the gpd threshold of which the task is never trivial for the egp and ggp models the threshold is chosen either internally based on a constraint or with a prescribed value as neither of these approaches is ideal the resulting tail fit might have proved relatively poor third even though the ph model has an exponential tail it can model the tail part of the dataset quite well because it stacks up many layers of exponential type distributions via internal finite mixing process the last point has a further implication in the discussion of the heavy tailness of precipitation datasets when one creates a new distribution from mixing individual component distributions one may choose a discrete or continuous mixing variable if a discrete mixing variable is used the resulting mixture model s density is given as f x i 1 k w i f i x a weighted average of the component densities fi x with the weights wi playing the role of the discrete mixing distribution i 1 k this type of distributions is called the finite mixture model as the number of component distributions is finite the ph distribution belongs to the finite mixture model in contrast for a continuous mixing case which can be thought of as a limiting case of a finite mixture with uncountably many weights the resulting mixture model is obtained by replacing the sum with an integration that is f x f x λ π λ d λ where π λ is the density of the mixing variable λ it is known that the mixture model of both types tend to be heavier tailed than the component distributions see e g klugman et al 2008 however the ultimate tail behaviours may differ theoretically depending on whether the mixing variable is discrete or continuous for example consider a mixture model arising from exponential type component distributions if we opt a finite mixture the resulting model is a weighted average of k different exponentially decaying distributions and it preserves an exponential tail asymptotically for instance the ph distribution s tail decays to zero at an exponential rate of o e η t x as mentioned previously however if we choose a continuous mixture the resulting model can yield a substantially heavier tail a prominent example is the pareto distribution which is a mixture of exponential distributions with gamma mixing weights which suggests that the pareto tail can be created by a weighted average of uncountably many light tailed exponential distributions heuristically this observation implies that a finite mixture model consisting of light tailed component distributions may yield a heavy tailed distribution by increasing the number of components though one may need an infinitely many components in theory thus finite mixture models constructed by stacking up several exponential type distributions may not have the same tail thickness as the pareto type models in a strictly asymptotic sense but we expect them to be able to produce a reasonably heavy tail the ph distribution class in this regard can be a compromising but practical solution to handle heavy tailed datasets in addition unlike the egp and ggp models the ph model does not require the selection of the threshold where the heavy tail starts and thus needs no manual input which could potentially lead to a suboptimal calibration 4 3 including dry days so far we have excluded dry days in fitting the datasets implying that only strictly positive part of the dataset has been used in the ph distribution the proportion of dry days which stands for the probability mass at zero can be incorporated in a convenient and unified fashion recall from section 3 3 that for the ph distribution the domain of the density 10 is different from that of the distribution function 11 in that the density excludes the zero value this is due to the possibility of probability mass at zero which is interpreted as a situation where the underlying markov chain process has a strictly positive initial probability of being in the absorbing state in the first place or equivalently α p 1 0 to explain how to incorporate the dry days in the ph model let us suppose that a ph distribution with p phases excluding the absorption state has been calibrated using the rainy days observations only and the estimates α α 1 α p and t have been obtained here we have α 1 α p 1 and α p 1 0 indicating no probability mass at zero yet now assume that these rainy days take up 100 r of the entire day counts historically so that the probability of having rain for any given day is r and the probability of having a dry day 1 r in light of this information the estimates α i i 1 p 1 should be revised as follows we denote the revised estimates as α i i 1 p p 1 then first for the absorption state the revised estimate becomes α p 1 1 r 0 the probability of having no rain second the remaining initial probabilities are reduced proportionally that is α i r α i i 1 p so that the sum of all revised probabilities becomes α 1 α p α p 1 r 1 r 1 consequently p h α t is the mixed in the sense that it has both discrete and continuous parts model that describes both dry and wet days where the probability of dry days are expressed as a discrete spike at x 0 and the precipitation amount in wet days are modelled as a continuous part on x 0 note that no change is needed for t in the revision we may verify the size of the discrete mass at zero by plugging in x 0 to the distribution function 11 to obtain f x 0 1 α e t 0 1 1 α 1 1 i 1 p α i 1 1 α p 1 α p 1 1 r 4 4 an illustration for an illustration purpose let us consider the data of fort stockton station represented by id24 in ushcn texas dataset in this data there are 3021 wet days and 20 422 dry days in a total of 23 443 days recorded from 1940 to 2009 when we use the wet days only the estimated parameters of the ph distribution with p 3 under our specification are given by using the em algorithm 23 α 0 4795 0 5205 0 and t 0 1197 0 0100 0 0 0 5589 0 1074 0 0 0 0505 these parameters give the fitted ph distribution used previously to compute table 2 note that there are six parameter estimates in 23 because of the unit constraint in α this α implies that α 4 0 the initial probability associated with the absorbing state because we are only using positive observations thus the estimated ph distribution is a conditional distribution defined on x 0 all other stations dataset have been fitted in the same manner now suppose that we like to incorporate the dry days in the model noting that the probability of having no rain in fort stockton for any given day is 20 422 23 443 0 8712 1 r we obtain α 4 0 8712 the remaining initial probabilities after a proportional reduction becomes α r α 0 0618 0 0670 0 so that α 1 α 4 1 thus p h α t yields a full range stochastic precipitation model for fort stockton including both dry and wet days 4 5 efficiency of the ml estimator we consider in this subsection the asymptotic efficiency of the maximum likelihood ml estimator of the ph model in general studying the asymptotic behaviour of an ml estimator requires the corresponding fisher information matrix which can be obtained from the second derivatives of the log likelihood function functions of the ml estimator such as the quantiles can be further investigated by using the delta method however such a task is quite demanding for the ph model due to its matrix representation in addition the representation of the ph model is known to be not unique meaning that different sets of α and t may arrive at the same distribution because the distribution is determined by the product of these matrices rather than the matrices themselves as indicated from the distribution function f x x 1 α e t x 1 see e g latouche and ramaswami 1999 in the statistical inference viewpoint this implies that the estimated parameters may be different even though the resulting distribution is identical thus we investigate the asymptotic efficiency of the ml estimator using a simulation approach in particular we empirically examine the variations of the estimated quantiles rather than the parameters produced by a fitted ph model over various sample sizes n this method does not pose the non unique representation problem as the quantiles are computed from the distribution function the asymptotic efficiency of other distributional quantities as long as expressed as functions of the parameters can be studied in a similar fashion in our simulation based experiment we choose the fitted ph model for the id24 of the texas dataset as the true model and carry out the following steps to see how the variabilities of the ml quantiles behave as the sample size increases 1 generate a random sample of size n from the true model 2 fit the ph model to the sample generated in step 1 using the ml estimation and compute the ml quantiles at levels p 50 90 and 95 respectively 3 repeat steps 1 2 for b times to assess the variability of the estimated quantiles against the quantiles from the true model we take b 50 in our simulation 4 repeat steps 1 3 over various n values fig 5 presents the results of this simulation exercise from the box plot in the figure we see that the variations of all the estimated quantiles decreases over the sample size gradually converging to the true quantile values the corresponding mean squared errors mse which is the sum of the bias squared and the variance are also presented on the right side of the figure from the mse behaviour we again see that the ml based quantile estimates becomes more accurate as the sample size increases with smaller variations indicating that these are asymptotically efficient though the theoretical speed at which the estimates decay to zero is not precisely determined 5 datasets of other shapes in papalexiou and koutsoyiannis 2012 the worldwide ghcn dataset was analyzed to investigate the shapes of empirical precipitation distributions and their tail behaviors in this work the l moment ratios were used to capture the shape characteristics of each sample from a given geographical area s station following their work the diagram of the l varaiation versus l skewness for the ghcn dataset is presented in fig 6 which marks 19 328 different stations worldwide as mentioned in section 2 the shaded area stands for the texas dataset studied in the previous section from this figure papalexiou and koutsoyiannis 2012 showed that the world precipitation data roughly form a linear relationship between l variation and l skewness with a positive slope as superimposed in the figure they also found that depending on the position in the figure the precipitation datasets take different shapes because of different local conditions in particular the stations located in the top right area of the diagram have j shaped distributions meaning that the their densities have a mode at zero or minimum amount of precipitation followed by a monotone downward decrease for the entire range of the data the downward slope becomes steeper as the location of the station moves to further top right corner in the diagram another distinct shape occurs at the bottom left area of the diagram where the stations take bell shaped distributions with the mode or peak of the data located at a strictly positive value from their positions we see that the datasets of texas stations we analysed previously are moderately j shaped but some are more so than others by lying on the top right side in the diagram the number of datasets in ghcn being close to 20 000 is indeed huge and it is prohibitive to study them all with the computing power at our hands as we have analysed the texas dataset a subset of ghcn dataset we would like to extend our analyses to some other datasets which exhibit different distributional characteristics than those of texas given that the texas datasets are positioned in middle area the l moments ratio diagram in fig 6 our goal in this section is thus to study some stations located at extreme positions in the diagram for this we select two stations from the top right and bottom left areas of the diagram respectively and investigate how the alternative three models perform for these datasets the dataset selected from the top right area is from asn00004032 port hedland international airport australia its precipitation data is depicted in the right panel of fig 7 which clearly shows its j shape the dataset selected from the bottom left area is from in sf001943230 gannapan south africa its dataset shown in the left panel of fig 7 is bell shaped comparing the histograms in the figure reveals that the precipitation datasets in other parts of the world could take markedly different shapes as we have successfully modelled the rainfall datasets in texas with the ph distribution class we now investigate how the three candidate models perform for these two precipitation datasets the ph model used in the section has the identical parameter structure as in the previous section with p 3 we start with the bell shaped gannapan dataset of which the fitting result is given in figs 8 and 9 from these two figures the ph model is clearly favored over the other two models we note especially from fig 9 that the egp model is unable to capture the mode in the middle of the data because it uses an exponential distribution for the body part of the dataset furthermore its ml estimate results in a negative value of ξ after expanding the original parameter space defined in eq 7 which implies that the maximum precipitation amount is bounded from above the ggp model does capture the bell shape of the data but its overall fit is not as good as that of the ph model a numerical summary of the fits from these three models are given on the left side of table 4 which confirms our visual conclusion overall the ph model is best in all criteria considered for the gannapan dataset except for a single case next the j shaped port hedland international airport data from the right panel of fig 7 is analyzed in figs 10 and 11 in the qq plot we see that the fits from the ggp and egp over estimate the tail implying that the actual tail of this dataset may not be as heavy as the gpd the qq plot for the calibrated ph model shows a more satisfactory fit overall with a slight under estimation for only a few last observations in the tail the tail fit could be further improved by increasing the phase size p but larger p values also require more parameters to be estimated due to higher model complexity the numbers on the left side of table 4 summarize the numerical result for this dataset the ph model performs well for most criteria except for the bic where the additional number of parameters is more severely penalized for the large sample size n 2501 in summary our numerical analyses for these two precipitation datasets indicate that the ph model is a generally versatile well performing statistical tool to model the entire range of daily precipitation amounts 6 conclusion modeling precipitation datasets is of great importance in many applications including agriculture forest management and hydrology traditional models such as the exponential gamma and kappa distributions are known to be inadequate in modelling these datasets due to their shape restriction few parameters more sophisticated models have also been proposed in the literature by combining several individual component distributions in the form of mixture or hybrid distributions the hybrid distribution also known as the composite distribution is particularly appealing as it can separately model the tail data which is known to be heavy in many precipitation datasets however estimating hybrid models involves a cumbersome threshold selection or shape restrictions to make the density continuous or smooth at the tail threshold in this paper we introduced the phase type ph model a rich class of distributions previously used in reliability and insurance applications to model the entire range of daily precipitation datasets the ph distribution class can be very flexible in its density shape with mathematically tractable distributional properties it also contains commonly used distributions as its members however the general parameter estimation for the ph distribution is a delicate matter as the number of parameters can grow quickly as one increases the phase size leading to an impractical model with excessively many parameters to this extent we have selected a six parameter ph distribution with three phases for modelling precipitation datasets these parameters were estimated by the maximum likelihood estimation procedure based on the expectation maximization algorithm in asmussen et al 1996 we compared the ph model against other existing multi component models that have been reported to perform better in the literature both competing models are hybrid models and use the generalized pareto distribution gpd to separately handle the tail part of the data in order to compare the fitting performance the daily precipitation datasets collected from 49 stations in texas was considered following li et al 2012 based on the aic and bic criteria as well as the random split cross validation rscv to assess the prediction performance furthermore recognizing that the likelihood based procedures are mainly affected by the body part of the dataset we evaluated the tail fit separately to see if these models can adequately capture the tail characteristics of the datasets these extensive numerical studies overall show that the ph model yields satisfactory results in fitting the precipitation datasets as the texas dataset represents a small subset of the existing precipitation datasets in the world we also examined two additional datasets with qualitatively different shapes than the texas dataset selected from the l moments ratio diagram of ghcn papalexiou and koutsoyiannis 2012 analysing these two datasets again confirms that the ph distribution can be a competitive choice in modelling the precipitation datasets with various shapes perhaps the main weakness of the ph model despite its attractive theoretical properties is its computational difficulty in estimating parameters the maximum likelihood estimation requires a specialized and complicated numerical algorithm such as the one shown in appendix a but its actual execution is manageable given the code of the algorithm is available publicly appendix a empht algorithm consider n observations x 1 x n generated by ph α t distribution with phase p or equivalently a p 1 dimensional state space here the observed values are considered incomplete because xi s represent only the absorption times and the exact paths are unknown if we assume that we have observed the entire path of the underlying markov chain the complete observation corresponding to a given xi of the ph distribution can be written as y i j 0 i j m i 1 i s 0 i s m i 1 i where mi is the number of jumps until the markov chain hits the absorbing state 0 j k i is the k th state visited by the markov chain with j m i i 0 and s k i is the corresponding sojourn time at the k th state with s m i indicating that the last jump leads to the absorbing state then the sojourn times should satisfy x i s 0 i s m i 1 i and the density of the i th complete observation can be represented by 24 f y i α t α j 0 i exp t j 0 i j 0 i s 0 i t j 0 i j 1 i exp t j m i 1 i j m i 1 i s m i 1 i t j m i 1 i where we use the notations b i j and b i to denote i j th element and i th element of a given matrix b and a vector b respectively now if we denote the complete sample of all of n observations by 25 y j 0 1 j m 1 1 1 s 0 1 s m 1 1 1 j 0 n j m n 1 n s 0 n s m n 1 n then the density of the complete sample can be written in the form 26 f y α t i 1 p α i b i i 1 p exp t i i z i i 1 p j 1 j i p t i j n i j t i n i 0 where b i i 1 p denote the number of markov chains starting in state i z i i 1 p the total time spent by markov chains in state i and n i j the total number of jumps from state i to state j for i j i 1 p and j 0 1 p we see that the density in 26 is a member of the multi parameter exponential family with sufficient statistics bi s zi s and n i j s this leads the mle based on the complete sample y by 27 α i b i n t i j n i j z i i j t i n i 0 z i t i i t i j 1 j i t i j the em algorithm then calculates mle of α and t based on the incomplete data the em algorithm is an iterative procedure that maximizes in each step the conditional expectation of the log likelihood given the observed sample x 1 x n that is in each iteration two separate steps called the e and m steps are carried out in the e step one calculates the conditional expectation of the log likelihood given the observations which are absorption times and it is maximized in the m step from the density function in 26 the log likelihood of the complete sample y is in the form of 28 log f y α t i 1 p b i log α i i 1 p t i i z i i 1 p j 1 j i p n i j log t i j i 1 p n i 0 log t i which we observe to be linear in the sufficient statistics hence in the e step calculating the conditional expectation of the log likelihood given the observations reduces to calculating the conditional expectations of the sufficient statistics the exact expressions of these quantities as well as the detailed em procedure can be found in asmussen et al 1996 the em algorithm for the ph calibration can be summarized as follows given an initial parameters α 0 t 0 in e step the conditional expectations of the sufficient statistics given the observed sample x 1 x n are calculated and are plugged in the log likelihood function in 28 as the parameters for complete sample y then in m step the mles are obtained using the equations in 27 these two steps are iterated until convergence appendix b random number generation from ph distribution one can use the following steps to generate a random number from a ph distribution ph x α t 1 generate a random number from unif 0 1 and call it u 2 solve the following equation with respect to x u 1 α e t x 1 this step can be done in any standard mathematical software using a suitably chosen optimization procedure provided that the software has the matrix exponential function the solution x is a random number generated from ph x α t note that the solution is always uniquely obtained as the cdf of any ph distribution is strictly increasing supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 11 014 appendix c supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
721,a data space inversion dsi method is developed and applied to quantify uncertainty in the location of co2 plumes in the top layer of a storage aquifer in the dsi procedure posterior predictions of the co2 saturation distribution are generated using simulation results for prior geostatistical model realizations along with observed data which in this case derive from observations at monitoring wells posterior history matched geological models are not constructed in the dsi method so many of the complications that arise in traditional data assimilation methods are avoided the dsi method treats quantities of interest qoi such as the co2 saturation distribution in the top layer as random variables the posterior distribution for these qoi conditioned to observed data is formulated in the data space within a bayesian framework samples from this posterior distribution are generated using the randomized maximum likelihood method we also introduce a procedure to optimize the locations of monitoring wells using only prior model simulation results this approach is based on analytical dsi results and determines monitoring well locations such that the reduction in expected posterior variance of a relevant quantity is maximized the new dsi procedure is applied to three dimensional heterogeneous aquifer models involving uncertainties in a wide range of geological parameters including variogram orientation porosity and permeability fields and regional pressure gradient multiple monitoring scenarios involving four to eight monitoring wells are considered in the evaluation of our data space methodology application of dsi with optimal monitoring wells is shown to consistently reduce the posterior variance of average co2 saturation in the top layer and to provide detailed saturation fields in reasonable correspondence with the true saturation distribution finally we demonstrate consistent improvement in dsi predictions as data are collected from an increasing number of optimized monitoring wells keywords carbon storage sequestration data assimilation uncertainty quantification data space inversion optimal monitoring 1 introduction the geological storage of co2 in deep saline aquifers represents a potential strategy for large scale carbon mitigation it is essential that the movement of the injected fluid be well understood as such knowledge can be used to mitigate the risk of co2 leakage which could otherwise lead to the contamination of fresh water resources because the flow models used for prediction include many highly uncertain parameters such as porosity and permeability defined on simulation grid blocks there will typically be large uncertainty associated with prior flow predictions the incorporation of various types of monitoring data enables some amount of parameter calibration leading to reduced uncertainty in predictions there are however still challenges both conceptual and computational associated with conventional model based inversion procedures our goal in this work is to present an alternative approach that circumvents many of the issues with model based approaches in recent work we developed data space inversion dsi procedures to enable efficient predictions of well based quantities such as time varying phase production and injection rates in oil field problems sun and durlofsky 2017 sun et al 2017b dsi differs considerably from traditional model based inversion in that it directly samples the posterior distribution of quantities of interest qoi given measurements within a bayesian framework dsi uses only prior model simulation results and observed data to provide statistical predictions it does not provide posterior history matched models which is a limitation in some contexts in this work we generalize the dsi methodology to enable effective co2 plume prediction under uncertainty we also present an efficient procedure within the dsi framework to determine the optimal locations of monitoring wells such that expected uncertainty reduction in a relevant quantity is maximized traditional model based history matching has been actively studied in both oil field and groundwater applications general discussion of various history matching algorithms can be found in tarantola 2005 oliver et al 2008 zhou et al 2014 oliver and chen 2011 yeh 1986 and mclaughlin and townley 1996 ensemble based history matching algorithms such as ensemble kalman filter and ensemble smoothers are described in evensen 2003 aanonsen et al 2009 emerick and reynolds 2013 chen and zhang 2006 and gonzález nicolás et al 2015 within the context of geological carbon sequestration sun and nicot 2012 and sun et al 2013 used a probabilistic collocation method to assess the detectability of leakage using pressure data measured from monitoring wells for an uncertain heterogeneous aquifer gonzález nicolás et al 2015 compared the use of ensemble smoother and restart ensemble kalman filter algorithms for the detection of potential co2 leakage pathways using pressure data espinet et al 2013 investigated the use of a global optimization algorithm for model calibration specifically the determination of facies permeability values by matching a limited amount of pressure and gas monitoring data cameron et al 2016 investigated the assimilation of pressure data in the zone above the storage aquifer with the goal of locating and quantifying potential leaks during co2 storage operations they used a particle swarm optimization algorithm together with a karhunen loève representation of porosity for model reduction to find history matched aquifer models however in both espinet et al 2013 and cameron et al 2016 the optimization procedures were very time consuming and only a single history matched model was constructed which does not allow for uncertainty quantification in field application settings several studies have applied history matching to improve geological models for prediction of co2 migration or leakage detection daley et al 2008 doughty et al 2008 ennis king et al 2011 oladyshkin et al 2011 however many of these studies only considered simplified layered geological models with relatively few uncertain parameters the observations were generally matched manually in these studies for example daley et al 2008 and doughty et al 2008 calibrated numerical models through a trial and error approach with the target of matching the field pilot data including seismic data from the frio formation in dayton texas usa ennis king et al 2011 manually matched downhole pressure measurements and the gas arrival time at observation wells through multiple stages several approaches have been proposed recently to provide posterior forecasts without model updating scheidt et al 2015 and satija and caers 2015 developed prediction focused analysis pfa for predicting tracer flow at a few downstream locations pfa aims to build a direct statistical relationship between the observations and qoi using the simulated data from an ensemble of prior models this statistical relationship is then used to provide predictions when actual observations are made in the context of weather forecasting krishnamurti et al 2000 and mallet et al 2009 linearly combined predictions from a set of prior models with weights determined such that the predictions matched the historical data the pfa approach and ensemble approaches described in krishnamurti et al 2000 and mallet et al 2009 may have some limitations including linear assumptions and the treatment of measurement error detailed discussion of these issues and other related data space approaches can be found in sun and durlofsky 2017 sun et al 2017b and sun 2014 our dsi procedure has been previously applied within the context of oil field problems to bimodal channelized systems sun and durlofsky 2017 and naturally fractured reservoirs sun et al 2017b in both studies we observed reasonable agreement in forecasts between dsi and reference results obtained from a strict rejection sampling algorithm oliver et al 2008 for well based qoi this demonstrates that dsi can provide appropriate posterior uncertainty quantification for the qoi considered in this study we extend the dsi procedure to enable the prediction of the co2 saturation distribution in the top layer of a storage aquifer the co2 distribution which represents essential information for risk mitigation is a spatial quantity in contrast to the local time varying well production quantities considered in sun and durlofsky 2017 and sun et al 2017b the dsi methodology entails first generating and simulating a large ensemble of prior models 1000 models are used for the examples in this paper these are independent and can be run in parallel this is the only time consuming step in dsi and it provides a set of simulated measurement and field co2 saturation data we also present a data space approach for the optimization of monitoring well placement this procedure involves a multivariate gaussian assumption on the statistics in data space and the resulting expressions are consistent with the ensemble variance analysis algorithms applied in he et al 2018 given monitoring well data posterior samples distribution of co2 saturation in the top layer are then constructed using a bayesian formulation these samples are generated using the randomized maximum likelihood method kitanidis 1986 oliver 1996 reynolds et al 1999 which entails an inexpensive minimization involving a relatively small number of data space variables this paper proceeds as follows in section 2 the dsi methodology for predicting the posterior distribution of co2 in the top layer is described we then present the data space procedure to optimize monitoring well locations in section 3 we give a detailed description of the three dimensional uncertain heterogeneous aquifer model present results for the optimal placement of monitoring wells and apply our dsi procedure to provide posterior predictions several cases involving different numbers of monitoring wells are considered the performance of dsi for true models outside of the prior distribution and the impact of grid refinement on co2 saturation fields and dsi results are considered in section 4 concluding remarks and suggestions for future work are provided in section 5 2 methodology in this section we introduce a data space inversion dsi procedure for assimilation of measurement data the dsi procedure is based on a bayesian formulation in the data space with the target of sampling the conditional posterior distribution of quantities of interest which in our case is the distribution of co2 in the top layer at a future time given measurement data in addition based upon analytical dsi results we then develop a data space approach for a surveillance problem in which the locations of monitoring wells are optimized to maximize the expected effectiveness of measurement data 2 1 data space inversion formulation we let m denote the vector containing all unknown model parameters including discrete cell by cell geological properties such as porosity and permeability we express the forward model which maps the input parameters m to the output response as 1 d f g m where d f r n f 1 is a column vector that contains data variables corresponding to actual measurement data denoted as d obs r n obs 1 and to other quantities of interest qoi in this paper the qoi are specified to be the co2 saturation in the top layer of a three dimensional aquifer model in our system cap rock is not explicitly represented but it would lie directly above the top layer of the model see section 3 1 for the detailed aquifer description thus by quantifying the amount and distribution of co2 in the top layer of the model we can assess the risk of leakage which could occur through undetected fractures in the cap rock for example related quantities based on the top layer mass or mobility of co2 could also be used we note that quantities of this type were used as measures of risk to be minimized in the optimizations performed in cameron and durlofsky 2012 2014 we write d f as d f d h t d p t t where d h r n h 1 contains elements corresponding to d obs and d p r n p 1 contains the data variables we wish to predict the subscripts h and p refer to the historical and prediction portions of the data vector respectively in this study d h corresponds to pressure and co2 saturation data measured at monitoring wells over the 20 year co2 injection period while d p represents the co2 saturation field in the top layer of the storage aquifer at 200 years elements in d f referred to as data variables are uncertain due to the uncertainties associated with the parameters in m the forward model eq 1 is solved via numerical flow simulation the eclipse simulator schlumberger 2013 with the co2store option is used in this study since it has many specialized features useful for co2 storage problems because d h which is part of d f represents the simulated data corresponding to d obs we have n h n obs and can write 2 d obs d h ϵ h d f ϵ where ϵ contains the measurement error associated with d obs and h r n h n f is an extraction matrix containing zeros and ones which extracts the part of d f corresponding to d h measurement errors in ϵ are assumed to be normally distributed with mean 0 and covariance c d r n h n h eq 2 provides the relationship between d f and d obs therefore the posterior distribution of d f given d obs can be formulated using bayes rule if the prior probability density function pdf of d f is constructed in the following we first discuss the case where the prior pdf of d f is multivariate gaussian for which analytical solutions exist then we introduce approximate treatments for the case with a general distribution of d f when the model response d f is multivariate gaussian the posterior distribution of d f conditioned to d obs is given by see the derivations by tarantola 2005 and oliver et al 2008 for linear problems in traditional inverse modeling and discussion in sun and durlofsky 2017 within the context of dsi 3 p d f d obs k 1 exp 1 2 h d f d obs t c d 1 h d f d obs 1 2 d f μ d f t c d f d f 1 d f μ d f where k 1 is a normalization constant and μ d f r n f 1 and c d f d f r n f n f are the prior mean and covariance matrix for d f respectively the prior mean and covariance matrix can be estimated numerically from the simulation results eq 1 for an ensemble of prior realizations of m on the right hand side of eq 3 the function in the exponent is quadratic with respect to the variables in d f therefore p d f d obs is again multivariate gaussian with analytical expressions for the corresponding posterior mean and covariance matrix as given in sun and durlofsky 2017 as mentioned earlier d p which is part of d f contains the qoi we seek to predict the corresponding posterior mean μ d p d obs and covariance c d p d obs are computed as 4 μ d p d obs μ d p c d p d h c d h d h c d 1 d obs μ d h 5 c d p d obs c d p d p c d p d h c d h d h c d 1 c d h d p where c d p d h r n p n h denotes the cross covariance between d p and d h c d h d p c d p d h t and c d p d p r n p n p and c d h d h r n h n h denote the covariance of d p and d h these covariance matrices can be easily computed once the simulation results from a set of prior models are obtained interestingly the right hand side of eq 5 is independent of the actual measurements d obs which means that under the multivariate gaussian condition the posterior uncertainty of d p is always the same regardless of the values of the actual measurements though it does depend on the amount of observed data since n h n obs this is also a well known property of ordinary kriging methods he et al 2018 showed that eq 5 can be a useful metric to evaluate the effectiveness of possible future measurements from a pilot program in section 2 3 we will use eq 5 with some rearrangement to determine the optimal placement of monitoring wells eq 3 is limited to systems where d f is multivariate gaussian or nearly so in our problem d f is in general non gaussian so the problem is more complicated in such cases it is useful to introduce an intermediate low dimensional gaussian variable ξ the mapping between ξ and d f which is referred to as a reparameterization is expressed as d f f ξ because the flow response is in general non gaussian the relationship between d f and ξ is nonlinear we emphasize that the flow response is non gaussian regardless of the structure of the permeability field this is the case even for homogeneous permeability descriptions as a result of the high degree of nonlinearity in the equations governing multiphase flow this issue was discussed in detail in sun and durlofsky 2017 and sun et al 2017b and will be illustrated again in section 3 4 with the reparameterization d f f ξ we can write the posterior distribution of d f in terms of ξ as 6 p ξ d obs k 2 exp 1 2 h f ξ d obs t c d 1 h f ξ d obs 1 2 ξ t ξ where k 2 is a normalization constant the detailed reparameterization which involves principal component analysis pca and histogram transform is described in the next section the pca representation enables the prior pdf of the data variables to be expressed in terms of ξ t ξ as discussed in sun and durlofsky 2017 importantly with the representation in eq 6 an analytical expression of the posterior statistics of ξ and thus d f as given in eqs 4 and 5 does not exist thus the posterior distribution p ξ d obs must be sampled using an appropriate sampling procedure to sample the distribution in eq 6 we use the randomized maximum likelihood rml method originally developed by kitanidis 1986 and oliver 1996 for traditional model inversion in our data space procedure the objective function for the rml algorithm is 7 s ξ h f ξ d obs t c d 1 h f ξ d obs ξ ξ t ξ ξ where d obs denotes perturbed measurements obtained by adding noise consistent with c d to true data and ξ r l 1 n 0 i is a random sample from the multivariate normal distribution with mean 0 and identity covariance matrix a set of posterior samples of ξ can be generated by minimizing s ξ multiple times each time with randomly sampled d obs and ξ posterior samples of d f are then obtained by evaluating f ξ on the generated samples of ξ these samples of d f should closely match the observations d obs during the historical period d h but they will deviate from one another in the prediction period d p which provides an assessment of prediction uncertainty we now introduce the low dimensional representation of data variables d f f ξ 2 2 reparameterization of data variables as noted earlier the reparameterization of data variables is accomplished by applying pca in conjunction with a histogram transformation we first generate the pca representation of the correlated variables in d f this is expressed as 8 d f d f pca φ ξ μ d f where ξ r l 1 contains the pca parameters and φ r n f l is the basis matrix whose columns correspond to the first l left singular vectors multiplied by associated singular values of the covariance matrix x x t n r 1 here n r denotes the number of prior realizations of m that are simulated and the matrix x d f 1 d f 2 d f n r x r n f n r assembles all simulated model responses see sun and durlofsky 2017 for more details on the construction of φ and on the use of an energy criterion to determine l which allows us to take l n f the pca parameterization eq 8 enables us to represent the data variables using ξ which contains parameters that are uncorrelated this along with the fact that l n f greatly simplifies the minimization of s ξ in eq 7 however ξ is still linearly related to d f this linear relationship indicates that eq 8 should not be used to generate new realizations of d f when d f is non gaussian this issue was discussed in detail in the context of oil field applications in sun and durlofsky 2017 and sun et al 2017b consistent with sun et al 2017b in this work a histogram transformation step is applied to provide an improved approximation of d f with respect to the histogram or marginal distribution this procedure is depicted in fig 1 this transform performed independently on each data variable is written as d f j f t 1 f i d f pca j j 1 n f where f i is the input or initial cdf dashed blue curve in fig 1 and f t is the target cdf red curve in fig 1 the input cdf for d f j is gaussian since it derives from d f pca with mean μ d f j and variance φφt jj the jth diagonal element and the target cdf is constructed from the histogram of the simulated data for d f j it is important to note that histogram transformation directly impacts only the marginal distribution of components in d f we cannot claim that the cross correlations in d f as defined in prior simulation results are strictly captured following the histogram transformation procedure nonetheless as we will see in section 3 this approach is effective for the qoi considered in this work mathematically the reparameterization step used in this study can be written as 9 d f f ξ h t φ ξ μ d f where h t denotes the histogram transformation operation combining eqs 7 and 9 we can now generate multiple posterior predictions through use of rml the overall dsi procedure applied in this study is presented in algorithm 1 in the appendix 2 3 optimization of monitoring well placement our intent in performing data assimilation is to reduce the prediction uncertainty for qoi the actual reduction in uncertainty however depends on the predictive ability of the measurement data since measurement data directly relate to the location of monitoring wells optimal placement of monitoring wells is clearly of interest in carbon storage applications magnant 2011 used the shannon entropy a measure from information theory to optimize the placement of downhole gauges for cross well seismic analysis cameron and durlofsky 2014 described a simplified bayesian experimental design procedure to find improved monitoring well locations jeong et al 2018 presented a binary integer programming technique for the cost optimal design of a pressure monitoring network for leakage detection under geological uncertainty chen et al 2018 described a filter based data assimilation procedure for designing monitoring systems for geologic co2 sequestration they used a machine learning algorithm to reduce the computational cost though their method is limited to cases where only a few uncertain parameters are involved in more general cases the training of the machine learning model may require very large numbers of simulations in this section we present our data space approach for determining the optimal placement of monitoring wells such that the resulting data are maximally effective in reducing the posterior uncertainty in a key qoi it is important to emphasize that the locations of monitoring wells are determined before any data are actually measured the values of the measured data d obs will depend on the true but unknown reservoir model m the monitoring well locations y and measurement noise ϵ in this work y z n y 1 contains the i and j locations integer values designating the x and y locations on a grid for all monitoring wells thus n y 2 n w where n w is the number of monitoring wells here the monitoring wells are taken to be vertical wells that extend through the top three layers of the formation and provide data in each layer note that d obs as a function of m y and ϵ now contains random variables instead of fixed historical observations as in section 2 1 we let j denote the qoi considered in the optimization of monitoring well locations the qoi used in this optimization must be a scalar quantity otherwise the optimization formulation described below must be modified the quantity used here should correspond closely to the main quantities of interest which in our case are the amount and distribution of co2 in the top layer we thus take j to be the average co2 saturation in the top layer of the model which is given by 10 j 1 n grid i top layer s i where si is the co2 saturation in grid block i n grid is the number of grid blocks in the top layer and the sum is over all blocks in the top layer in general smaller values of j correspond to less co2 in the top layer and thus less leakage risk and higher values to more leakage risk so the distribution of j is clearly of interest our goal is to find monitoring well locations y such that the expected variance of j conditioned to measurement data over all possible realizations of the model and measurement error is minimized this optimization problem can be stated as 11 y opt argmin y σ j d obs m y ϵ 2 p m p ϵ d m d ϵ where σ j d obs m y ϵ 2 denotes the posterior variance of j given measurements d obs m y ϵ other statistics such as the difference between the 90th and 10th percentile p 90 p 10 in the distribution of j values could also be used to represent the posterior uncertainty of j the reason for choosing variance is that the resulting minimization problem eq 11 can be solved very efficiently as discussed below for now we consider the case where multivariate gaussian statistics are preserved in the data space discussed in section 2 1 then by setting d f j in eq 5 we have 12 σ j d obs m y ϵ 2 σ j j 2 c j d h c d h d h c d 1 c d h j as noted earlier the expression on the right hand side of eq 12 is independent of the actual measurement values more specifically this expression is independent of the true model and the actual measurement errors therefore we must have 13 σ j d obs m y ϵ 2 p m p ϵ d m d ϵ σ j j 2 c j d h c d h d h c d 1 c d h j where the covariance matrices are estimated using the simulated data from an ensemble of prior models m 1 m 2 m n r specifically 14 σ j j 2 1 n r 1 i 1 n r j i μ j 2 15 c j d h c d h j t 1 n r 1 i 1 n r j i μ j d h i μ d h 16 c d h d h 1 n r 1 i 1 n r d h i μ d h d h i μ d h t where ji and d h i denote the simulated value corresponding to prior model m i and μj and μ d h denote the mean over all prior models of j and d h we emphasize that d h i in eqs 15 and 16 is a function of y since it corresponds to data measurements at monitoring wells combining eqs 11 and 13 the optimization problem becomes 17 y opt argmin y σ j j 2 c j d h c d h d h c d 1 c d h j where σ j j 2 c d h d h c j d h and c d h j are computed using eqs 14 16 for each different y though these quantities must be evaluated at different monitoring well locations the simulated data at all required locations for all models are stored so there is no need to re run any flow simulations because the prior variance σ j j 2 does not vary with y eq 17 can be written as 18 y opt argmin y u r y where u r y c j d h c d h d h c d 1 c d h j σ j j 2 the term c j d h c d h d h c d 1 c d h j essentially represents the correlation between j and d h and u r y can be interpreted as the expected uncertainty reduction in j given measurements collected at monitoring well locations y therefore eq 18 can be interpreted as finding the y opt that provides measurements enabling the maximum variance reduction in the specified qoi j for arbitrary distributions of j and d obs m y ϵ it can be proven harville 2003 he et al 2018 that for any y 19 σ j d obs m y ϵ 2 p m p ϵ d m d ϵ σ j j 2 c j d h c d h d h c d 1 c d h j with the equality holding when j and d obs m y ϵ are jointly multivariate gaussian for any y thus the right hand side of eq 19 always provides an upper bound estimate of the expected posterior variance left hand side of eq 19 this observation indicates that monitoring wells placed at the optimized locations are able to provide prediction variance uncertainty less than or at least equal to the associated minimum value in the right hand side of eq 17 we reiterate that the monitoring well location optimization is based on all prior samples of d h which in general display non gaussian statistics and not on the permeability field itself because this optimization is performed before any data are collected it involves flow based quantities computed over all prior model simulation results note that the integration in eq 11 can also be estimated using monte carlo methods robert 2004 with the variance σ j d obs m y ϵ 2 estimated using the posterior samples generated by performing the dsi procedure described in section 2 1 though this approach is able to incorporate non multivariate gaussian statistics it is more time consuming and complex to apply than using eq 17 therefore in this paper eq 17 is used to optimize monitoring well placement as will be shown in section 3 the optimal well placement found through eq 17 is able to achieve significant uncertainty reduction in the qoi the workflow to optimize the monitoring well locations using the data space approach is summarized in algorithm 2 in the appendix for the optimization we apply a genetic algorithm called using the command ga in matlab this appears to be adequate for current purposes though it might be useful to test other optimizers 3 results for a three dimensional heterogeneous aquifer model in this section we present detailed dsi results for co2 storage in a three dimensional heterogeneous aquifer the basic model setup is modified from that used in cameron and durlofsky 2012 and jin and durlofsky 2018 we consider uncertainties in the porosity and permeability fields and in the direction of a regional pressure gradient multiple model scenarios represented by different variograms are considered when generating prior geological models note that model structural uncertainty e g uncertainty in the conceptual model which is not included in this study can be readily incorporated by considering an ensemble of prior realizations drawn from different geological concepts or training images this was in fact done in sun et al 2017b for a discrete fracture matrix model in which dsi was applied for production forecasting multi gaussian log permeability fields as are considered here have been widely used in previous studies related to forward modeling and data assimilation in co2 storage and related problems for example farajzadeh et al 2011 described flow regimes in geologic storage operations using two dimensional multi gaussian models characterized by exponential variograms with different correlation lengths and dykstra parsons coefficients similar models were used in the upscaling studies of rabinovich et al 2015 sun et al 2017a considered the identification of leaks with source term attributes treated as uncertain the true fields used in that work were in all cases multi gaussian cameron et al 2016 also used multi gaussian permeability models for a leak detection study in the context of co2 storage yoon et al 2017 studied data assimilation for a problem involving similar physics to that in co2 storage they considered the injection of freshwater into a saline aquifer for purposes of freshwater storage two dimensional multi gaussian models were considered and an ensemble kalman filtering procedure was used for data assimilation finally chen et al 2018 used multi gaussian models with a spherical variogram in their monitoring well optimization study we note that in the great majority of previous investigations involving data assimilation with multi gaussian models prior models were all characterized by a single variogram our treatment here is much more general as our prior includes models generated using a wide range of variogram and other parameters as described below in this work pressure and co2 saturation data within the storage aquifer are considered to be available in practice pressure data can be obtained through embedded pressure transducers and co2 saturation can be measured in situ using time lapse sonic logs caspari et al 2011 as well as by seismic and other monitoring technologies as described in zhang et al 2018 in this study synthetic pressure and co2 saturation data are collected at monitoring wells during the 20 year injection period with monitoring well locations optimized using the data space approach described in section 2 3 other data types could be readily incorporated if available given the monitoring data the conditional predictions for the co2 plume at the top layer after 180 years of post injection equilibration i e at the end of the 200 year time frame are generated using the dsi algorithm presented in section 2 1 we emphasize that no additional data are collected after the 20 year injection period note that this data assimilation could be performed more frequently e g every year during the injection period and this would be very inexpensive with dsi since no additional simulation runs are required 3 1 aquifer model the storage aquifer covers an area of 8 5 km 8 5 km and is of a vertical thickness of 151 m the aquifer initially contains only brine at a pressure of 15 5 mpa and a temperature of 55 c a total of 8 mt year of co2 is injected into the storage aquifer for 20 years this co2 volume corresponds to approximately 2 5 of the aquifer pore volume the aquifer is of an average porosity of about 0 2 the storage aquifer is modeled on a uniform grid of 35 35 11 blocks each of size 243 m 243 m 13 7 m the basic aquifer model is presented in fig 2 one realization of the heterogeneous porosity field for the storage aquifer is shown in fig 2a around the storage aquifer a larger scale regional aquifer is introduced which essentially acts to dissipate pressure cameron et al 2016 fig 2b shows the simulation grid for the full system with the white central region representing the storage aquifer shown in fig 2a to save computational effort the grid block size increases by a factor of three as we move out from the storage aquifer the full system is modeled on a 43 43 11 grid and is of overall dimension 67 km 67 km 151 m in the region outside the storage aquifer porosity and permeability values are specified to be constant at 0 2 and 29 md which correspond to the mean values in the storage aquifer no flow boundary conditions are applied at the boundaries of the full model four horizontal injectors are located in layer 9 third from the bottom of the storage aquifer each injector is controlled with a constant co2 injection rate of 2 mt year the four injectors shown as red lines in fig 2c are arranged in a square pattern in addition vertical monitoring wells depicted as green lines in fig 2c provide co2 saturation and pressure data at all of the grid blocks they contact recall that monitoring wells penetrate the top three layers of the model because these wells penetrate the cap rock in practice it will be important that proper well completion isolation and cementing procedures are applied the simulation model includes two fluid phases referred to as water and gas and three components water supercritical co2 and salt brine salinity is specified to be 10 000 mg kg the gas water relative permeability curves which include hysteresis important for residual trapping are taken from cameron and durlofsky 2012 and are shown in fig 3 a capillary pressure curves are generated using the brooks corey model saadatpoor et al 2010 with specific model coefficients of p e 0 36 entry pressure and λ 0 67 pore size distribution index capillary pressure curves which vary from block to block and depend on porosity and permeability are modeled using the leverett j function see eqs 2 3 and 2 4 in saadatpoor et al 2010 fig 3b shows the capillary pressure at reference porosity 0 2 and permeability 29 md given the large size of the grid blocks the absolute permeability and the relative permeability and capillary pressure curves should be regarded as appropriately upscaled functions this upscaling can be accomplished using e g the methods described in rabinovich et al 2015 chemical reactions and mineralization are not included in our model as these effects are not expected to be significant over the simulation time frame considered in this study all flow simulations are performed using the eclipse simulator schlumberger 2013 with the co2store option in this study the porosity and log permeability fields in the storage aquifer are represented using two point geostatistical models sequential gaussian simulation available within the sgems toolbox remy et al 2009 is used to generate multiple geological realizations of the porosity field these realizations are not conditioned to any well hard data the histogram of the porosity distribution is specified to be normal with mean ϕ 0 2 and standard deviation σ ϕ 0 04 the correlation structure of the porosity field is characterized using an ellipsoid shaped exponential variogram model with the three correlation lengths of the principal axes specified in terms of the number of grid blocks set to be l 1 40 l 2 5 and l 3 5 we consider different variogram models and thus different geological scenarios by varying the orientations of the principal axes of the ellipsoid the ranges of these parameters are shown in table 1 azimuth and dip refer to the two ellipsoid orientation angles see remy et al 2009 for more details the other parameters appearing in the table are described below the permeability value in the x direction kx is related to porosity via 20 ln k x a b ϕ ϕ σ ϕ e where a 3 5 b 1 and e represents random noise sampled from a normal distribution with mean e 0 and standard deviation σ e 0 4 therefore kx is log normally distributed with mean ln k x 3 5 and standard deviation σ ln k x 1 08 we specify k y k x and k z c k x where c is randomly sampled from a uniform distribution within 0 05 0 2 for each prior permeability realization i e kz kx is constant for a given model fig 4 shows two random realizations of the porosity field and the corresponding ln kx fields clear differences in the correlation structure of the two porosity or permeability fields due to the use of different variogram models are evident in addition to uncertainties in the distribution of porosity and permeability we also include an uncertain large scale regional pressure gradient which acts to move the co2 plume horizontally in the west to east direction the pressure gradient component is specified to be constant at 280 pa m while in the south to north direction the pressure gradient component is uncertain and ranges from 0 pa m to 280 pa m the effect of this regional pressure gradient is captured in the simulations by specifying water rates for an array of 12 wells penetrating all layers distributed around the storage aquifer shown as blue lines in fig 2c wells on the west and south sides are specified to be injectors and producers are on the opposite sides the injectors and producers on the west and east sides are assigned constant water rates of 55 m3 day which results in a pressure gradient of 280 pa m the water rate qw however is sampled uniformly from 0 m3 day to 55 m3 day for wells on the north and south sides each well in a particular realization is assigned the same qw therefore the uncertainty related to the regional pressure gradient is represented using the single random variable qw ranges for this parameter are given in table 1 in the results presented below four different test cases will be considered in detail for the evaluation of our data space approaches parameters for all test cases are provided in table 1 3 2 simulation results from prior models in this paper a total of n r 1000 prior models are generated over the parameter ranges given in table 1 as described in section 3 1 the duration of the injection period is 20 years during which data are collected and this is followed by 180 years of equilibration we are interested in assessing the co2 saturation distribution at the top layer at the end of the equilibration period fig 5 shows the co2 plume evolution in a cross section containing an injection well for one randomly selected prior model during the injection period co2 accumulates in the system while moving toward the top of the formation due to buoyancy from 140 years to 200 years we see that the co2 distribution changes relatively little indicating that much of the co2 is essentially trapped this is caused both by residual trapping and trapping due to heterogeneous capillary pressure the slight changes in the co2 distribution in the top layer at a late time fig 5g and h are due to spreading in the direction orthogonal to the image in the y direction fig 6 displays the co2 saturation distribution in the top layer these are x y plots in contrast to the x z plots in fig 5 corresponding to six different prior models the results presented in this figure are selected based on the total amount of co2 in the top layer at 200 years computed as j in eq 10 in fig 6 j p prior indicates the pth percentile of j among all prior simulation runs there are large variations in the distribution and total amount of co2 in the top layer which is evident by comparing fig 6a f more specifically the p 90 result in fig 6e j 90 prior 0 056 shows about twice the co2 compared with the p 10 result in fig 6a j 10 prior 0 027 in addition although there are essentially four co2 lobes corresponding to the four injectors the co2 plumes form into different shapes and move to different locations this phenomenon can be caused by differences in the regional pressure gradient and or by differences in the porosity and permeability fields as will be demonstrated below data at the monitoring wells enable us to narrow our estimates for the location and shape of the co2 plume 3 3 optimization of monitoring well locations we now present results for the optimization of a specified number of monitoring wells the number of monitoring wells is denoted by n w recall that this optimization is performed after simulating the n r prior models but before any data are measured as discussed earlier the qoi j is specified to be the average co2 saturation in the top layer at 200 years eq 10 and we are interested in maximizing the expected uncertainty reduction for j after assimilating 20 years of measurement data for each monitoring well pressure and co2 saturation data are measured annually for 20 years in each of the top three layers the standard deviation of the measurement error for pressure and co2 saturation data are specified to be 0 1 mpa and 0 02 respectively in this section we will consider two different cases n w 4 and n w 8 therefore the dimension of d h is n h n w 3 2 20 480 when n w 4 and n h 960 when n w 8 the number of parameters to determine in the optimization is 8 n w 4 or 16 n w 8 as mentioned in section 2 3 the matlab genetic algorithm ga optimizer with default options is used in this study the initial monitoring well locations determined heuristically are shown as blue squares in fig 7 a for the case with n w 4 the computed expected uncertainty reduction for this configuration is u r y init 4 0 34 where y init 4 denotes the initial locations for the four monitoring wells and the function u r y is defined in eq 18 this result means that the prediction uncertainty represented as variance of j is expected to be reduced by 34 compared with the prior variance σ j j 2 after assimilating all possible outcomes of measurement data collected at these well locations fig 7b shows the progression of the best ga solution the objective function is u r y over the 91 generations of the optimization procedure the best ga solution at generation 0 is 0 54 rather than 0 34 because at least one of the solutions in the initial population leads to more uncertainty reduction than the initial guess y init 4 the elapsed time for this optimization is about five minutes with our matlab implementation the optimal locations y opt 4 are shown as red diamonds in fig 7a this result corresponds to u r y opt 4 0 77 which is a clear improvement over the initial guess it is noteworthy that the optimal solution tends to place the monitoring wells above the injectors shown as black cross hatched lines in fig 7a as would generally be expected though there are two monitoring wells above the left injector and none above the lower injector we note that the optimized well locations will be different with different initial guesses based on limited experimentation however it does appear that monitoring wells tend to be placed above injectors fig 8 displays analogous results for the case of n w 8 a total of 312 ga generations are required in this case and the total elapsed time is around 30 minutes the initial and optimal expected uncertainty reduction are u r y init 8 0 61 and u r y opt 8 0 87 interestingly the optimal solution in this case corresponds to two monitoring wells placed above each injector see fig 8a 3 4 dsi predictions of co2 plume test case 1 we now apply the dsi methodology to a series of synthetic test cases to demonstrate the reduction in uncertainty that can be achieved using this procedure in all cases a true model which is not included in the set of n r prior models is generated the geological parameters for the three true models considered in this section test cases 1 2 and 3 are given in table 1 flow simulation is then performed on the true model to provide the true data measurement error with mean and standard deviation as given in section 2 3 is added to the true data to provide the observed data d obs note that this measurement error could be used to account for the fact that monitoring wells are much smaller than the grid blocks they penetrate i e because monitoring well diameter is much less than the horizontal grid block dimension measured data correspond to the grid block value plus some error a grid refinement assessment such as that presented in section 4 3 could be used to quantify this error in practice the porosity field for test case 1 is shown in fig 9 a and the top layer co2 at 200 years is displayed in fig 9b j true 0 029 for this case fig 10 shows the time series for the observed data red circles for a single grid block where data are measured annually note that the synthetic observed data are forced to be nonnegative in fig 10b when negative measurement error is added to zero co2 saturation data the simulated data from n r 1000 prior models for the selected grid block are shown as the gray curves in fig 10 fig 10c presents the histogram of the co2 saturation data at 10 years from the prior model simulations these results display strong non gaussian character which illustrates the fact noted in section 2 1 and discussed in detail in sun and durlofsky 2017 and sun et al 2017b that multiphase flow simulation results are non gaussian even when the underlying log permeability field is multi gaussian we first consider the case with four optimized monitoring wells which results in a total of n obs 480 observations consistent with n h in the previous section our intent is to predict the co2 saturation distribution in the top layer at 200 years recall that data are collected only during the 20 year injection period thus the number of variables to predict in d p is equal to the number of grid blocks in the top layer i e n p n grid 35 35 1225 the dimension for the full data vector d f in the dsi procedure is then n f n h n p 1705 because d f contains both pressure and saturation data variables which are of very different scales we normalize the pressure data variables to be of mean 0 and standard deviation 1 before applying pca fig 11 shows the cumulative energy loss in other words the variability that is not explained in the subspace for different numbers of retained principal components which is the dimension of ξ denoted as l in eq 8 we determine the number of principal components l by specifying the energy loss to be less than 0 005 which results in l 42 in this case though the dimension of the data space n f is fairly large the reduced space with pca parameterization is reasonably small this observation indicates that the simulated data have strong cross correlations applying the dsi procedure algorithm 1 with l 42 we generate a total of n post 100 posterior predictions the dsi predictions for the historical period d h are shown in fig 10 as the blue curves it is evident that the dsi predictions are able to essentially match the observed data red circles for both quantities though our interest is not to predict the observed data these results serve as a quality check of the application of the dsi method if the dsi predictions are not able to match observed data more prior runs might be required it is also possible that additional geological scenarios e g different variogram parameters in the current setting should be considered for more discussion of this issue please see our earlier work sun and durlofsky 2017 fig 12 shows three posterior realizations of the co2 saturation distribution obtained with the dsi method these three realizations are selected based on the average top layer co2 saturation at 200 years j in eq 10 we compute j for all 100 posterior dsi top layer saturation fields and then rank them from lowest to highest figs 12a c correspond to the results of rank 10 50 and 90 i e the p 10 p 50 p 90 results the p 10 and p 90 results can be viewed as optimistic and pessimistic predictions respectively of the top layer co2 saturation at 200 years it is evident that the amount of co2 in the dsi predictions is reasonably close to that from the true model fig 9b even though the amount of predicted co2 in the prior models varies substantially as seen in fig 6 more specifically j true 0 029 is encompassed within the range of dsi predictions 0 026 0 038 for j 10 to j 90 and this range is significantly smaller than the range of prior predictions 0 027 0 056 for j 10 prior to j 90 prior in addition the overall pattern of the true co2 plume fig 9b is captured better in the dsi predictions fig 12 than in the prior predictions shown in fig 6 especially for the plume at the left side of the model 3 5 dsi predictions for different monitoring scenarios we next consider three other monitoring scenarios to investigate the effects of the number and placement optimal versus heuristic of monitoring wells parameters for all monitoring scenarios are shown in table 2 with monitoring scenario 2 the location of monitoring wells is not optimized though all other parameters are the same as in monitoring scenario 1 considered in the previous section monitoring scenarios 3 and 4 differ from monitoring scenario 1 in terms of the number of monitoring wells and the associated number of observations fig 13 shows the dsi predictions for co2 saturation distribution when monitoring well locations are not optimized as in fig 12 the three saturation fields again correspond to p 10 p 50 p 90 results the predictions show clear improvement in terms of matching the true plume relative to the prior predictions shown in fig 6 however the variability of the average co2 among the three realizations in fig 13 is larger than in the results corresponding to optimal monitoring well placement fig 12 this observation is also evident in fig 14 where we plot the empirical cumulative density function cdf for the top layer average co2 saturation over the 100 posterior dsi predictions the dashed blue and the solid black lines represent results for n w 4 without and with optimization of monitoring well locations we see that the uncertainty range is much narrower when using data measured at optimized monitoring well locations the dashed green and solid blue lines display results for six and eight optimal monitoring wells we observe a consistent decrease in uncertainty as n w is increased consistent with expectations fig 15 displays co2 saturation predictions for monitoring scenario 4 which entails the use of eight optimally placed monitoring wells these results match the true plume better than those for monitoring scenario 1 where n w 4 in particular predictions of the lower plume in fig 15 are clearly more accurate than those in fig 12 this observation can be explained by the placement of monitoring wells shown in figs 7a and 8a in the case with n w 4 there are no monitoring wells above the lower injector while in the case with n w 8 two monitoring wells are placed above this injector as a result there are more observations corresponding to this co2 plume in addition with more monitoring wells the connection between the lower plume and the plume on the right is also captured more accurately to better quantify the accuracy of dsi predictions for the co2 saturation distribution in the top layer we compute the average saturation error for each posterior prediction δk as follows 21 δ k 1 n grid i top layer s i pred k s i true here δk denotes the average pixel wise prediction error in posterior prediction k n grid is the total number of top layer grid blocks s i pred k is the predicted co2 saturation at 200 years in grid block i from dsi posterior prediction k e g fig 15a and s i true is the true co2 saturation at 200 years in grid block i shown in fig 9b given δk for all n post 100 dsi predictions we can construct a cdf of the δk for each monitoring scenario fig 16 displays the resulting empirical cdfs the prediction error from the prior models is the largest as no additional measurement information is assimilated we also see that optimizing monitoring well locations improves prediction accuracy from the dashed blue line to the black line in fig 16 and that the use of more monitoring wells is also beneficial from the solid black line to the solid blue line another interesting observation is that comparing the solid blue optimized n w 8 and pink prior curves the worst prediction from the blue curve has an average prediction error of 0 066 which is better than 98 of the predictions from the prior models these results demonstrate that the dsi procedure is indeed able to provide improved predictions by assimilating measured data 3 6 dsi predictions with different true models in the previous section the dsi procedure was evaluated on a single true model test case 1 from which the synthetic measurements were generated we now evaluate the methodology on two additional true models referred to as test cases 2 and 3 we reiterate that neither true model was included in the set of n r 1000 prior models in each of the test cases optimal monitoring scenarios 1 and 4 defined in table 2 and corresponding to n w 4 and n w 8 are considered since the prior models and thus the prior simulation results do not change between test cases the locations of the monitoring wells are the same for all three cases table 3 shows the prior results which are the same as for test case 1 and dsi results in terms of p 10 p 50 and p 90 statistics for the top layer average co2 saturation at 200 years note that j true varies considerably between test cases for all three cases the dsi predictions consistently encompass the true data within the p 10 to p 90 range and show a narrower range of uncertainty represented as p 90 p 10 when more monitoring wells are used prediction results for the top layer co2 saturation distribution for n w 4 are shown in fig 17 for test cases 2 and 3 for test case 2 the true co2 distribution is displayed in fig 17d there we see a very different pattern from the true plume for test case 1 fig 9a there is relatively little co2 at the left and bottom of the model while the two co2 plumes toward the upper right display high co2 saturation and actually connect with each other these phenomena are essentially captured in the dsi results figs 17e g even though this behavior is not directly evident in the prior results the true plume for test case 3 is shown in fig 17h here we see four isolated co2 plumes and overall high co2 saturation j true 0 051 these features are largely captured in the corresponding dsi results figs 17i k taken in total the results for the three different test cases suggest that the dsi procedure is indeed able to provide improved forecasts for top layer co2 distribution at 200 years by assimilating 20 years of measurements from monitoring wells 4 additional considerations in the previous section we presented dsi results for test cases in which all of the true models were within the prior distribution this means that the prior realizations used in dsi were consistent with the underlying true model in this section we evaluate dsi performance for cases involving prior realizations that are inconsistent with the true model more specifically we first consider a true model characterized by parameters that fall outside the ranges defined in table 1 we then describe a means for quantifying the consistency of observed data with the prior model simulation results finally we consider a true model defined on a finer grid than that used for the prior simulations which allows us to assess for a particular example the impact of model error on dsi results 4 1 dsi predictions for true model parameters outside prior distributions table 1 displays the geological parameters for test case 4 we see that the true model parameters for this example all lie outside the range of the prior distributions test case 4 thus represents a potentially challenging case for dsi due to this inconsistency between true model parameters and prior distributions monitoring scenario 1 four wells optimized is considered in this case fig 18 presents the synthetic observed data shown as red circles from a monitoring well at a single grid block these data are for the same grid block as in fig 10 the gray curves represent the simulated results corresponding to the same n r 1000 prior models described in section 3 it is clear that the observed data are near the edge of the prior distributions of simulated data for both pressure and co2 saturation fig 19 displays the distribution of top layer average co2 saturation at 200 years from prior realizations pink curve along with the prediction corresponding to the true model vertical red line we see that the true model result in this case is at the edge of the prior distribution specifically j true 0 064 is above the 99th percentile of the prior cdf j 99 prior 0 063 this is likely due to the high vertical permeability for test case 4 k z k x 0 3 for this case as shown in table 1 although the test case 4 parameters are all outside the prior ranges the observed data are still somewhat consistent with the prior simulation results as is evident in fig 18 if this were not the case i e if the observed data fell well outside the prior simulation results it would indicate that the prior was too narrow and that a broader prior should be considered the degree of consistency between the observed data and prior simulation results can be quantified using the mahalanobis distance he et al 2017 which will be described and applied below within a dsi setting a lack of consistency here means that additional prior simulation runs must be performed it is however straightforward to include simulation results from a wide range of priors in dsi as illustrated in sun et al 2017b we now apply the dsi methodology with the original set of n r 1000 prior models we reiterate that these prior models are not consistent with the underlying true model dsi predictions of the grid block data are shown as blue curves in fig 18 it is evident that the dsi results display a reasonable match to the observed data though the predictions for co2 saturation at around 12 years somewhat underestimate the observations the distribution of dsi predictions for top layer average co2 saturation is shown in fig 19 dashed blue line we see that the range of uncertainty is reduced significantly after assimilating the measured data and that the true result red line is encompassed within the posterior cdf fig 20 a presents co2 saturation predictions from the true model along with p 10 p 50 and p 90 dsi results some features in the true co2 plumes are not fully captured in the dsi predictions for example the plume at the left side of the model has a more circular shape compared with the dsi posterior results and the plume at the right has a wedge shape that is not captured by the three dsi predictions these discrepancies likely result because the prior distributions of model parameters were specified too narrowly for this case it is noteworthy however that the general pattern and location of the true co2 plumes are still captured in the dsi predictions in addition the average co2 saturation obtained from the true model j true 0 064 is encompassed within the p 10 p 90 range of dsi results j 10 j 90 0 056 0 068 these results thus suggest that our dsi procedure displays a degree of robustness in terms of the prior parameter ranges we reiterate that it is essential that the prior simulation results encompass the observations if this is not the case we would not expect dsi to provide reasonable posterior predictions in the following section we describe the use of mahalanobis distance to quantify the consistency between observations and prior simulated data 4 2 use of mahalanobis distance to assess consistency with the prior inversion algorithms based on bayesian statistics rely on appropriately validated prior models oliver and alfonzo 2018 these algorithms cannot be expected to work when the true model is outside of the prior distribution thus in practice it may be important to evaluate the consistency between the true model and the prior before performing data assimilation within a dsi setting the consistency between observations and simulated data can be assessed by for example visually comparing results in a low dimensional space satija et al 2017 or by using a hypothesis test based on mahalanobis distance he et al 2017 in this study we consider the use of mahalanobis distance to quantitatively gauge the consistency of the prior model simulation results with the observed data mahalanobis distance is computed based on the first and second moments of the prior distribution though it is nonetheless widely used in consistency assessments for general problems de maesschalck et al 2000 in accordance with he et al 2017 we define the mahalanobis distance as 22 d d d μ d h t c d h d h 1 d μ d h 1 2 where d r n h 1 denotes a high dimensional data point vector and other quantities are as defined in section 2 eq 22 measures the distance between a point d and the mean of a multivariate distribution n μ d h c d h d p in this paper the mean and covariance matrix are computed using the simulated data from all n r 1000 prior models there are however some limitations associated with computing mahalanobis distance directly using eq 22 these include the fact that c d h d h is often not invertible it is not invertible in our case and that random noise may dominate the computation if a high number of singular vectors are retained in the approximation of c d h d h 1 these two issues can be addressed by using a variation of eq 22 in which the mahalanobis distance is recast as the euclidean distance of the sum of the squares of the scores of principal components brereton 2015 de maesschalck et al 2000 specifically we express d as d u σ ω μ d h where u r n h k corresponds to the left singular vectors of c d h d h σ r k k is a diagonal matrix containing the singular values and ω r k 1 contains the scores now writing ω as ω σ 1 u t d μ d h and c d h d h as c d h d h u σ 2 u t we can express eq 22 as 23 d k d ω t ω 1 2 note that this expression aligns directly with the pca representation of d f which is used in an intermediate step in our formulation in section 2 we will now assess the use of eq 23 in identifying the degree of consistency between observed data and prior simulated data observed data for test cases 1 4 will be assessed as will data for two additional cases that are purposely set up to be inconsistent with the prior these two new cases correspond to homogeneous models with high and low permeability values specifically in test case h100 we set permeabilities to be k x k y 100 md and k z 15 md these values are higher than the average permeability values in the prior models defined in table 1 and in test case l10 we set k x k y 10 md and k z 0 1 md which are lower than the average values in the prior models for test cases h100 and l10 the porosity values are constant at ϕ 0 2 and no large scale regional pressure gradient is applied other properties are the same as described in section 3 1 we again consider monitoring scenario 1 the settings for measurement error and the dsi treatments are as in sections 3 and 4 1 results for mahalanobis distance eq 23 are shown in fig 21 the plot in fig 21a k 11 corresponds to retaining 90 of the energy in the nonzero singular vectors associated with c d h d h and the plot in fig 21b k 38 corresponds to retaining 99 of this energy as noted earlier if we retain very high fractions of energy e g 99 99 over fitting to random measurement noise can occur which complicates the interpretation of the computed distances in fig 21 the pink curves represent dk computed from the prior model simulation results to generate these curves we take each prior model simulation result in turn as d and then apply eq 23 to compute dk the cdf is then constructed from the full set of 1000 prior simulation results the values for dk for test cases 1 4 and test cases h100 and l10 are shown in fig 21 it is apparent from the plots that results for test cases 1 3 fall well within the prior distribution results for test case 4 fall toward the tail and results for test cases h100 and l10 fall either outside the prior distribution entirely fig 21b or at the extreme edge fig 21a for test case l10 these results are very encouraging and in line with our expectations since test cases 1 3 are indeed from within the prior test case 4 is similar to the prior models but lies outside of the prior distribution and test cases h100 and l10 are quite inconsistent with the prior models thus we see that the mahalanobis distance dk computed using eq 23 is very useful for identifying inconsistencies between observed data and prior model simulation data for this problem if the observed data fall at the extreme edge or outside the prior distribution dsi should not be immediately applied rather the set of prior models should first be expanded such that the observed data fall within the prior distribution of simulated data unless the prior is extended in this manner we would not expect dsi to work for the case in question and it would not make sense to apply it the lack of applicability of dsi in such settings is illustrated in fig 22 for test cases l10 and h100 where we display dsi results for the cdf of top layer average co2 for these cases using the original set of 1000 simulation results as the prior all curves are as defined previously the fact that the true data vertical red lines do not intersect the dsi results indicates that the method fails in these cases this failure is expected however as it is clearly predicted by the mahalanobis distance plots in fig 21 thus a practitioner would know not to apply dsi for either of these cases without first extending the set of prior model simulation results such that the observed data fall well within the prior distribution 4 3 impact of grid resolution because our dsi procedure requires performing flow simulations for a large set of prior models efficiency considerations motivate the use of relatively coarse models in the results presented up to this point the grid block size was 243 m 243 m 13 7 m in the storage region with grid blocks of this size relative permeability and capillary pressure curves should in practice be upscaled from a finer scale description in addition the observed data were generated from simulation results for a true model with these large grid blocks we now quantify the impact of grid refinement which acts to better capture detailed flow behavior in the simulations first co2 saturation distributions for coarse and fine models are compared then dsi is applied for a case in which the true data are generated using a fine scale simulation the higher resolution fine models are generated by introducing 3 3 3 refinement in each original block in the storage region this results in a fine grid containing 105 105 33 cells in the storage region additional heterogeneity in the porosity and permeability fields is not incorporated this means that these properties are constant within 3 3 3 regions in the fine model although finer scale heterogeneity could also be introduced this approach enables us to isolate and assess the impact of numerical error only rather than the combined effect of numerical error and heterogeneity resolution level we first present saturation results for test cases 1 2 and 3 simulated at the fine and coarse scales the simulation setup is as described in section 3 the co2 saturation distributions for the three cases are shown in fig 23 original coarse model results are displayed in the left column and fine scale results appear in the right column to enable direct comparison the fine model results are obtained by averaging the saturation data over the 3 3 3 fine blocks corresponding to each coarse block we see that the location and shape of the co2 plumes in the fine models are very similar to those in the corresponding coarse models the average co2 saturations listed in the figure captions as j coarse and j fine are however somewhat higher in the fine models suggesting that co2 vertical migration is somehow limited by the coarse discretization we next consider the correspondence in fine to coarse model results for a range of test cases fig 24 displays a scatter plot of average co2 saturation from coarse models and the corresponding fine models for 20 different cases again the coarse model results are for the top layer average co2 saturation and the fine model results are for co2 saturation averaged over the top three layers in this way the results correspond to the same physical regions we observe that the average co2 saturation is consistently higher for the fine models with a shift of around 0 008 at the lower saturation values and around 0 02 at the highest saturation values nonetheless a clear trend is evident indicating that the error is systematic rather than random we note that these observations are consistent with the results of cameron and durlofsky 2012 where coarse models were used for the optimization of co2 storage problems we now apply dsi for a case in which the observed data correspond to simulation results for a true model that contains grid refinement i e the storage region in the true model is now simulated using 105 105 33 blocks in this assessment the same n r 1000 coarse scale prior realizations as were used in all previous examples will again be applied the true model in this case is the refined version of test case 1 which we refer to as refined test case 1 the average co2 saturation for refined test case 1 at 200 years is about 0 037 in contrast to 0 029 for the original coarse test case 1 this difference is consistent with the shifts noted above four monitoring wells at optimized locations monitoring scenario 1 in table 2 are considered note that the monitoring wells now penetrate the top nine layers in the fine model corresponding to the top three layers in the coarse model the data used for dsi now correspond to pressure and co2 saturation averaged over the 3 3 3 grid blocks around monitoring wells this treatment maintains consistency with the coarse models used for dsi and with test case 1 in section 3 noise is added as described earlier the observed data not shown fall within the prior simulation results so we expect dsi to provide sensible results for refined test case 1 dsi results in terms of the empirical cdf for average co2 over the top three layers of the fine model are shown in fig 25 the prior cdf shown as the pink curve is based on coarse model original simulations so it is identical to that for test case 1 in fig 14 the posterior dsi cdf shown as the dashed blue curve is however different from the posterior for monitoring well scenario 1 in fig 14 black curve in that figure since the data in the current case are different i e they now derive from a refined model simulation more specifically for the original test case 1 j true 0 029 we had j 10 0 026 j 50 0 031 j 90 0 038 while for refined test case 1 j true 0 037 indicated by the vertical red line in fig 25 we have j 10 0 029 j 50 0 035 j 90 0 042 thus we see that the dsi predictions shift towards higher saturation values consistent with the data from the refined test case 1 simulation this is an encouraging result since it demonstrates that dsi is able to provide reasonable predictions using coarse scale prior simulations even when the true data potentially contain finer scale information this suggests that dsi may be reasonably robust with respect to this type of model error dsi performance will however need to be assessed for a range of cases to quantify its behavior in this regard 5 concluding remarks in this work we devised and applied a data space inversion dsi procedure for the prediction of co2 saturation distribution in the top layer of a storage aquifer the method provides posterior estimates based on prior model simulation results and measurements at some number of monitoring wells in contrast to traditional history matching approaches the dsi procedure does not entail calibration of model parameters and thus does not provide posterior models in the dsi procedure a set of realizations 1000 in the cases considered here honoring prior geological information is first generated and simulated to provide prior samples for variables corresponding to measurement data and prediction quantities of interest qoi a reparameterization based on principal component analysis and histogram transformation is applied to facilitate the sampling of posterior data variables this sampling is accomplished using the randomized maximum likelihood rml method in the data space we also applied analytical results from the dsi formulation to quantify the effectiveness of measurements over all prior models for given monitoring well locations the analytical expressions used for this determination are consistent with the ensemble variance analysis formulations studied by he et al 2018 measurement effectiveness is defined here in terms of the expected reduction of posterior variance for a specified qoi in this work this qoi was taken to be the average co2 saturation in the top layer of the storage aquifer at 200 years given this analytical and thus fast to compute measure of effectiveness we successfully optimized the monitoring well locations using a genetic algorithm the overall dsi procedure was then applied to synthetic three dimensional heterogeneous aquifer systems uncertainties in the underlying variogram model in the porosity and permeability distributions and in the regional scale pressure gradient were incorporated into the prior models detailed physics including relative permeability hysteresis and capillary pressure heterogeneity were included in the flow simulations we evaluated dsi for three different true models with varying numbers of monitoring wells dsi predictions were compared with true model simulation results for the top layer co2 saturation distribution in all cases involving optimal monitoring wells we observed that the dsi posterior predictions for the amount and general distribution of co2 in the top layer displayed considerably less uncertainty than estimates from the prior models we further showed that dsi prediction accuracy was consistently enhanced as more monitoring wells were used and that a higher degree of uncertainty reduction was achieved using optimally located instead of heuristically placed monitoring wells dsi was also shown to provide reasonable results for a true model characterized by parameters that lie outside the prior distributions and for a case in which the observed data were generated from a fine grid simulation we also considered two homogeneous test cases that led to observed data that were very inconsistent with the prior simulation data we showed that an appropriately computed mahalanobis distance is able to clearly identify this inconsistency and that dsi will fail if directly applied for such cases there are several directions in which this work could be extended it will be useful to apply our dsi procedures to more complex geological models such as bimodal channelized systems which can be challenging for traditional model based history matching methods although the prediction of posterior well based quantities for such systems has been accomplished in a dsi setting in sun and durlofsky 2017 it will be interesting to assess the predictive ability of dsi for qoi of the type considered here such as top layer co2 saturation the use of dsi for different problem setups such as co2 leakage detection under uncertainty as described by cameron et al 2016 and jeong et al 2018 should also be considered in these applications leakage may have already occurred which will change the formulation objective of the optimization problem it may be possible to provide better uncertainty quantification for this problem using dsi than with model based methods finally some of the detailed treatments in our dsi procedure could be further studied with the goal of reducing the number of prior runs required or improving dsi predictions for a given number of prior runs for example it may be beneficial to apply functional pca as used by satija and caers 2015 for dimension reduction of tracer data in place of the pca parameterization used in this work acknowledgments we thank david cameron and zhaoyang larry jin for providing aquifer models and simulation files and for useful discussions we are grateful to chevron etc and the stanford smart fields consortium for financial support appendix 
721,a data space inversion dsi method is developed and applied to quantify uncertainty in the location of co2 plumes in the top layer of a storage aquifer in the dsi procedure posterior predictions of the co2 saturation distribution are generated using simulation results for prior geostatistical model realizations along with observed data which in this case derive from observations at monitoring wells posterior history matched geological models are not constructed in the dsi method so many of the complications that arise in traditional data assimilation methods are avoided the dsi method treats quantities of interest qoi such as the co2 saturation distribution in the top layer as random variables the posterior distribution for these qoi conditioned to observed data is formulated in the data space within a bayesian framework samples from this posterior distribution are generated using the randomized maximum likelihood method we also introduce a procedure to optimize the locations of monitoring wells using only prior model simulation results this approach is based on analytical dsi results and determines monitoring well locations such that the reduction in expected posterior variance of a relevant quantity is maximized the new dsi procedure is applied to three dimensional heterogeneous aquifer models involving uncertainties in a wide range of geological parameters including variogram orientation porosity and permeability fields and regional pressure gradient multiple monitoring scenarios involving four to eight monitoring wells are considered in the evaluation of our data space methodology application of dsi with optimal monitoring wells is shown to consistently reduce the posterior variance of average co2 saturation in the top layer and to provide detailed saturation fields in reasonable correspondence with the true saturation distribution finally we demonstrate consistent improvement in dsi predictions as data are collected from an increasing number of optimized monitoring wells keywords carbon storage sequestration data assimilation uncertainty quantification data space inversion optimal monitoring 1 introduction the geological storage of co2 in deep saline aquifers represents a potential strategy for large scale carbon mitigation it is essential that the movement of the injected fluid be well understood as such knowledge can be used to mitigate the risk of co2 leakage which could otherwise lead to the contamination of fresh water resources because the flow models used for prediction include many highly uncertain parameters such as porosity and permeability defined on simulation grid blocks there will typically be large uncertainty associated with prior flow predictions the incorporation of various types of monitoring data enables some amount of parameter calibration leading to reduced uncertainty in predictions there are however still challenges both conceptual and computational associated with conventional model based inversion procedures our goal in this work is to present an alternative approach that circumvents many of the issues with model based approaches in recent work we developed data space inversion dsi procedures to enable efficient predictions of well based quantities such as time varying phase production and injection rates in oil field problems sun and durlofsky 2017 sun et al 2017b dsi differs considerably from traditional model based inversion in that it directly samples the posterior distribution of quantities of interest qoi given measurements within a bayesian framework dsi uses only prior model simulation results and observed data to provide statistical predictions it does not provide posterior history matched models which is a limitation in some contexts in this work we generalize the dsi methodology to enable effective co2 plume prediction under uncertainty we also present an efficient procedure within the dsi framework to determine the optimal locations of monitoring wells such that expected uncertainty reduction in a relevant quantity is maximized traditional model based history matching has been actively studied in both oil field and groundwater applications general discussion of various history matching algorithms can be found in tarantola 2005 oliver et al 2008 zhou et al 2014 oliver and chen 2011 yeh 1986 and mclaughlin and townley 1996 ensemble based history matching algorithms such as ensemble kalman filter and ensemble smoothers are described in evensen 2003 aanonsen et al 2009 emerick and reynolds 2013 chen and zhang 2006 and gonzález nicolás et al 2015 within the context of geological carbon sequestration sun and nicot 2012 and sun et al 2013 used a probabilistic collocation method to assess the detectability of leakage using pressure data measured from monitoring wells for an uncertain heterogeneous aquifer gonzález nicolás et al 2015 compared the use of ensemble smoother and restart ensemble kalman filter algorithms for the detection of potential co2 leakage pathways using pressure data espinet et al 2013 investigated the use of a global optimization algorithm for model calibration specifically the determination of facies permeability values by matching a limited amount of pressure and gas monitoring data cameron et al 2016 investigated the assimilation of pressure data in the zone above the storage aquifer with the goal of locating and quantifying potential leaks during co2 storage operations they used a particle swarm optimization algorithm together with a karhunen loève representation of porosity for model reduction to find history matched aquifer models however in both espinet et al 2013 and cameron et al 2016 the optimization procedures were very time consuming and only a single history matched model was constructed which does not allow for uncertainty quantification in field application settings several studies have applied history matching to improve geological models for prediction of co2 migration or leakage detection daley et al 2008 doughty et al 2008 ennis king et al 2011 oladyshkin et al 2011 however many of these studies only considered simplified layered geological models with relatively few uncertain parameters the observations were generally matched manually in these studies for example daley et al 2008 and doughty et al 2008 calibrated numerical models through a trial and error approach with the target of matching the field pilot data including seismic data from the frio formation in dayton texas usa ennis king et al 2011 manually matched downhole pressure measurements and the gas arrival time at observation wells through multiple stages several approaches have been proposed recently to provide posterior forecasts without model updating scheidt et al 2015 and satija and caers 2015 developed prediction focused analysis pfa for predicting tracer flow at a few downstream locations pfa aims to build a direct statistical relationship between the observations and qoi using the simulated data from an ensemble of prior models this statistical relationship is then used to provide predictions when actual observations are made in the context of weather forecasting krishnamurti et al 2000 and mallet et al 2009 linearly combined predictions from a set of prior models with weights determined such that the predictions matched the historical data the pfa approach and ensemble approaches described in krishnamurti et al 2000 and mallet et al 2009 may have some limitations including linear assumptions and the treatment of measurement error detailed discussion of these issues and other related data space approaches can be found in sun and durlofsky 2017 sun et al 2017b and sun 2014 our dsi procedure has been previously applied within the context of oil field problems to bimodal channelized systems sun and durlofsky 2017 and naturally fractured reservoirs sun et al 2017b in both studies we observed reasonable agreement in forecasts between dsi and reference results obtained from a strict rejection sampling algorithm oliver et al 2008 for well based qoi this demonstrates that dsi can provide appropriate posterior uncertainty quantification for the qoi considered in this study we extend the dsi procedure to enable the prediction of the co2 saturation distribution in the top layer of a storage aquifer the co2 distribution which represents essential information for risk mitigation is a spatial quantity in contrast to the local time varying well production quantities considered in sun and durlofsky 2017 and sun et al 2017b the dsi methodology entails first generating and simulating a large ensemble of prior models 1000 models are used for the examples in this paper these are independent and can be run in parallel this is the only time consuming step in dsi and it provides a set of simulated measurement and field co2 saturation data we also present a data space approach for the optimization of monitoring well placement this procedure involves a multivariate gaussian assumption on the statistics in data space and the resulting expressions are consistent with the ensemble variance analysis algorithms applied in he et al 2018 given monitoring well data posterior samples distribution of co2 saturation in the top layer are then constructed using a bayesian formulation these samples are generated using the randomized maximum likelihood method kitanidis 1986 oliver 1996 reynolds et al 1999 which entails an inexpensive minimization involving a relatively small number of data space variables this paper proceeds as follows in section 2 the dsi methodology for predicting the posterior distribution of co2 in the top layer is described we then present the data space procedure to optimize monitoring well locations in section 3 we give a detailed description of the three dimensional uncertain heterogeneous aquifer model present results for the optimal placement of monitoring wells and apply our dsi procedure to provide posterior predictions several cases involving different numbers of monitoring wells are considered the performance of dsi for true models outside of the prior distribution and the impact of grid refinement on co2 saturation fields and dsi results are considered in section 4 concluding remarks and suggestions for future work are provided in section 5 2 methodology in this section we introduce a data space inversion dsi procedure for assimilation of measurement data the dsi procedure is based on a bayesian formulation in the data space with the target of sampling the conditional posterior distribution of quantities of interest which in our case is the distribution of co2 in the top layer at a future time given measurement data in addition based upon analytical dsi results we then develop a data space approach for a surveillance problem in which the locations of monitoring wells are optimized to maximize the expected effectiveness of measurement data 2 1 data space inversion formulation we let m denote the vector containing all unknown model parameters including discrete cell by cell geological properties such as porosity and permeability we express the forward model which maps the input parameters m to the output response as 1 d f g m where d f r n f 1 is a column vector that contains data variables corresponding to actual measurement data denoted as d obs r n obs 1 and to other quantities of interest qoi in this paper the qoi are specified to be the co2 saturation in the top layer of a three dimensional aquifer model in our system cap rock is not explicitly represented but it would lie directly above the top layer of the model see section 3 1 for the detailed aquifer description thus by quantifying the amount and distribution of co2 in the top layer of the model we can assess the risk of leakage which could occur through undetected fractures in the cap rock for example related quantities based on the top layer mass or mobility of co2 could also be used we note that quantities of this type were used as measures of risk to be minimized in the optimizations performed in cameron and durlofsky 2012 2014 we write d f as d f d h t d p t t where d h r n h 1 contains elements corresponding to d obs and d p r n p 1 contains the data variables we wish to predict the subscripts h and p refer to the historical and prediction portions of the data vector respectively in this study d h corresponds to pressure and co2 saturation data measured at monitoring wells over the 20 year co2 injection period while d p represents the co2 saturation field in the top layer of the storage aquifer at 200 years elements in d f referred to as data variables are uncertain due to the uncertainties associated with the parameters in m the forward model eq 1 is solved via numerical flow simulation the eclipse simulator schlumberger 2013 with the co2store option is used in this study since it has many specialized features useful for co2 storage problems because d h which is part of d f represents the simulated data corresponding to d obs we have n h n obs and can write 2 d obs d h ϵ h d f ϵ where ϵ contains the measurement error associated with d obs and h r n h n f is an extraction matrix containing zeros and ones which extracts the part of d f corresponding to d h measurement errors in ϵ are assumed to be normally distributed with mean 0 and covariance c d r n h n h eq 2 provides the relationship between d f and d obs therefore the posterior distribution of d f given d obs can be formulated using bayes rule if the prior probability density function pdf of d f is constructed in the following we first discuss the case where the prior pdf of d f is multivariate gaussian for which analytical solutions exist then we introduce approximate treatments for the case with a general distribution of d f when the model response d f is multivariate gaussian the posterior distribution of d f conditioned to d obs is given by see the derivations by tarantola 2005 and oliver et al 2008 for linear problems in traditional inverse modeling and discussion in sun and durlofsky 2017 within the context of dsi 3 p d f d obs k 1 exp 1 2 h d f d obs t c d 1 h d f d obs 1 2 d f μ d f t c d f d f 1 d f μ d f where k 1 is a normalization constant and μ d f r n f 1 and c d f d f r n f n f are the prior mean and covariance matrix for d f respectively the prior mean and covariance matrix can be estimated numerically from the simulation results eq 1 for an ensemble of prior realizations of m on the right hand side of eq 3 the function in the exponent is quadratic with respect to the variables in d f therefore p d f d obs is again multivariate gaussian with analytical expressions for the corresponding posterior mean and covariance matrix as given in sun and durlofsky 2017 as mentioned earlier d p which is part of d f contains the qoi we seek to predict the corresponding posterior mean μ d p d obs and covariance c d p d obs are computed as 4 μ d p d obs μ d p c d p d h c d h d h c d 1 d obs μ d h 5 c d p d obs c d p d p c d p d h c d h d h c d 1 c d h d p where c d p d h r n p n h denotes the cross covariance between d p and d h c d h d p c d p d h t and c d p d p r n p n p and c d h d h r n h n h denote the covariance of d p and d h these covariance matrices can be easily computed once the simulation results from a set of prior models are obtained interestingly the right hand side of eq 5 is independent of the actual measurements d obs which means that under the multivariate gaussian condition the posterior uncertainty of d p is always the same regardless of the values of the actual measurements though it does depend on the amount of observed data since n h n obs this is also a well known property of ordinary kriging methods he et al 2018 showed that eq 5 can be a useful metric to evaluate the effectiveness of possible future measurements from a pilot program in section 2 3 we will use eq 5 with some rearrangement to determine the optimal placement of monitoring wells eq 3 is limited to systems where d f is multivariate gaussian or nearly so in our problem d f is in general non gaussian so the problem is more complicated in such cases it is useful to introduce an intermediate low dimensional gaussian variable ξ the mapping between ξ and d f which is referred to as a reparameterization is expressed as d f f ξ because the flow response is in general non gaussian the relationship between d f and ξ is nonlinear we emphasize that the flow response is non gaussian regardless of the structure of the permeability field this is the case even for homogeneous permeability descriptions as a result of the high degree of nonlinearity in the equations governing multiphase flow this issue was discussed in detail in sun and durlofsky 2017 and sun et al 2017b and will be illustrated again in section 3 4 with the reparameterization d f f ξ we can write the posterior distribution of d f in terms of ξ as 6 p ξ d obs k 2 exp 1 2 h f ξ d obs t c d 1 h f ξ d obs 1 2 ξ t ξ where k 2 is a normalization constant the detailed reparameterization which involves principal component analysis pca and histogram transform is described in the next section the pca representation enables the prior pdf of the data variables to be expressed in terms of ξ t ξ as discussed in sun and durlofsky 2017 importantly with the representation in eq 6 an analytical expression of the posterior statistics of ξ and thus d f as given in eqs 4 and 5 does not exist thus the posterior distribution p ξ d obs must be sampled using an appropriate sampling procedure to sample the distribution in eq 6 we use the randomized maximum likelihood rml method originally developed by kitanidis 1986 and oliver 1996 for traditional model inversion in our data space procedure the objective function for the rml algorithm is 7 s ξ h f ξ d obs t c d 1 h f ξ d obs ξ ξ t ξ ξ where d obs denotes perturbed measurements obtained by adding noise consistent with c d to true data and ξ r l 1 n 0 i is a random sample from the multivariate normal distribution with mean 0 and identity covariance matrix a set of posterior samples of ξ can be generated by minimizing s ξ multiple times each time with randomly sampled d obs and ξ posterior samples of d f are then obtained by evaluating f ξ on the generated samples of ξ these samples of d f should closely match the observations d obs during the historical period d h but they will deviate from one another in the prediction period d p which provides an assessment of prediction uncertainty we now introduce the low dimensional representation of data variables d f f ξ 2 2 reparameterization of data variables as noted earlier the reparameterization of data variables is accomplished by applying pca in conjunction with a histogram transformation we first generate the pca representation of the correlated variables in d f this is expressed as 8 d f d f pca φ ξ μ d f where ξ r l 1 contains the pca parameters and φ r n f l is the basis matrix whose columns correspond to the first l left singular vectors multiplied by associated singular values of the covariance matrix x x t n r 1 here n r denotes the number of prior realizations of m that are simulated and the matrix x d f 1 d f 2 d f n r x r n f n r assembles all simulated model responses see sun and durlofsky 2017 for more details on the construction of φ and on the use of an energy criterion to determine l which allows us to take l n f the pca parameterization eq 8 enables us to represent the data variables using ξ which contains parameters that are uncorrelated this along with the fact that l n f greatly simplifies the minimization of s ξ in eq 7 however ξ is still linearly related to d f this linear relationship indicates that eq 8 should not be used to generate new realizations of d f when d f is non gaussian this issue was discussed in detail in the context of oil field applications in sun and durlofsky 2017 and sun et al 2017b consistent with sun et al 2017b in this work a histogram transformation step is applied to provide an improved approximation of d f with respect to the histogram or marginal distribution this procedure is depicted in fig 1 this transform performed independently on each data variable is written as d f j f t 1 f i d f pca j j 1 n f where f i is the input or initial cdf dashed blue curve in fig 1 and f t is the target cdf red curve in fig 1 the input cdf for d f j is gaussian since it derives from d f pca with mean μ d f j and variance φφt jj the jth diagonal element and the target cdf is constructed from the histogram of the simulated data for d f j it is important to note that histogram transformation directly impacts only the marginal distribution of components in d f we cannot claim that the cross correlations in d f as defined in prior simulation results are strictly captured following the histogram transformation procedure nonetheless as we will see in section 3 this approach is effective for the qoi considered in this work mathematically the reparameterization step used in this study can be written as 9 d f f ξ h t φ ξ μ d f where h t denotes the histogram transformation operation combining eqs 7 and 9 we can now generate multiple posterior predictions through use of rml the overall dsi procedure applied in this study is presented in algorithm 1 in the appendix 2 3 optimization of monitoring well placement our intent in performing data assimilation is to reduce the prediction uncertainty for qoi the actual reduction in uncertainty however depends on the predictive ability of the measurement data since measurement data directly relate to the location of monitoring wells optimal placement of monitoring wells is clearly of interest in carbon storage applications magnant 2011 used the shannon entropy a measure from information theory to optimize the placement of downhole gauges for cross well seismic analysis cameron and durlofsky 2014 described a simplified bayesian experimental design procedure to find improved monitoring well locations jeong et al 2018 presented a binary integer programming technique for the cost optimal design of a pressure monitoring network for leakage detection under geological uncertainty chen et al 2018 described a filter based data assimilation procedure for designing monitoring systems for geologic co2 sequestration they used a machine learning algorithm to reduce the computational cost though their method is limited to cases where only a few uncertain parameters are involved in more general cases the training of the machine learning model may require very large numbers of simulations in this section we present our data space approach for determining the optimal placement of monitoring wells such that the resulting data are maximally effective in reducing the posterior uncertainty in a key qoi it is important to emphasize that the locations of monitoring wells are determined before any data are actually measured the values of the measured data d obs will depend on the true but unknown reservoir model m the monitoring well locations y and measurement noise ϵ in this work y z n y 1 contains the i and j locations integer values designating the x and y locations on a grid for all monitoring wells thus n y 2 n w where n w is the number of monitoring wells here the monitoring wells are taken to be vertical wells that extend through the top three layers of the formation and provide data in each layer note that d obs as a function of m y and ϵ now contains random variables instead of fixed historical observations as in section 2 1 we let j denote the qoi considered in the optimization of monitoring well locations the qoi used in this optimization must be a scalar quantity otherwise the optimization formulation described below must be modified the quantity used here should correspond closely to the main quantities of interest which in our case are the amount and distribution of co2 in the top layer we thus take j to be the average co2 saturation in the top layer of the model which is given by 10 j 1 n grid i top layer s i where si is the co2 saturation in grid block i n grid is the number of grid blocks in the top layer and the sum is over all blocks in the top layer in general smaller values of j correspond to less co2 in the top layer and thus less leakage risk and higher values to more leakage risk so the distribution of j is clearly of interest our goal is to find monitoring well locations y such that the expected variance of j conditioned to measurement data over all possible realizations of the model and measurement error is minimized this optimization problem can be stated as 11 y opt argmin y σ j d obs m y ϵ 2 p m p ϵ d m d ϵ where σ j d obs m y ϵ 2 denotes the posterior variance of j given measurements d obs m y ϵ other statistics such as the difference between the 90th and 10th percentile p 90 p 10 in the distribution of j values could also be used to represent the posterior uncertainty of j the reason for choosing variance is that the resulting minimization problem eq 11 can be solved very efficiently as discussed below for now we consider the case where multivariate gaussian statistics are preserved in the data space discussed in section 2 1 then by setting d f j in eq 5 we have 12 σ j d obs m y ϵ 2 σ j j 2 c j d h c d h d h c d 1 c d h j as noted earlier the expression on the right hand side of eq 12 is independent of the actual measurement values more specifically this expression is independent of the true model and the actual measurement errors therefore we must have 13 σ j d obs m y ϵ 2 p m p ϵ d m d ϵ σ j j 2 c j d h c d h d h c d 1 c d h j where the covariance matrices are estimated using the simulated data from an ensemble of prior models m 1 m 2 m n r specifically 14 σ j j 2 1 n r 1 i 1 n r j i μ j 2 15 c j d h c d h j t 1 n r 1 i 1 n r j i μ j d h i μ d h 16 c d h d h 1 n r 1 i 1 n r d h i μ d h d h i μ d h t where ji and d h i denote the simulated value corresponding to prior model m i and μj and μ d h denote the mean over all prior models of j and d h we emphasize that d h i in eqs 15 and 16 is a function of y since it corresponds to data measurements at monitoring wells combining eqs 11 and 13 the optimization problem becomes 17 y opt argmin y σ j j 2 c j d h c d h d h c d 1 c d h j where σ j j 2 c d h d h c j d h and c d h j are computed using eqs 14 16 for each different y though these quantities must be evaluated at different monitoring well locations the simulated data at all required locations for all models are stored so there is no need to re run any flow simulations because the prior variance σ j j 2 does not vary with y eq 17 can be written as 18 y opt argmin y u r y where u r y c j d h c d h d h c d 1 c d h j σ j j 2 the term c j d h c d h d h c d 1 c d h j essentially represents the correlation between j and d h and u r y can be interpreted as the expected uncertainty reduction in j given measurements collected at monitoring well locations y therefore eq 18 can be interpreted as finding the y opt that provides measurements enabling the maximum variance reduction in the specified qoi j for arbitrary distributions of j and d obs m y ϵ it can be proven harville 2003 he et al 2018 that for any y 19 σ j d obs m y ϵ 2 p m p ϵ d m d ϵ σ j j 2 c j d h c d h d h c d 1 c d h j with the equality holding when j and d obs m y ϵ are jointly multivariate gaussian for any y thus the right hand side of eq 19 always provides an upper bound estimate of the expected posterior variance left hand side of eq 19 this observation indicates that monitoring wells placed at the optimized locations are able to provide prediction variance uncertainty less than or at least equal to the associated minimum value in the right hand side of eq 17 we reiterate that the monitoring well location optimization is based on all prior samples of d h which in general display non gaussian statistics and not on the permeability field itself because this optimization is performed before any data are collected it involves flow based quantities computed over all prior model simulation results note that the integration in eq 11 can also be estimated using monte carlo methods robert 2004 with the variance σ j d obs m y ϵ 2 estimated using the posterior samples generated by performing the dsi procedure described in section 2 1 though this approach is able to incorporate non multivariate gaussian statistics it is more time consuming and complex to apply than using eq 17 therefore in this paper eq 17 is used to optimize monitoring well placement as will be shown in section 3 the optimal well placement found through eq 17 is able to achieve significant uncertainty reduction in the qoi the workflow to optimize the monitoring well locations using the data space approach is summarized in algorithm 2 in the appendix for the optimization we apply a genetic algorithm called using the command ga in matlab this appears to be adequate for current purposes though it might be useful to test other optimizers 3 results for a three dimensional heterogeneous aquifer model in this section we present detailed dsi results for co2 storage in a three dimensional heterogeneous aquifer the basic model setup is modified from that used in cameron and durlofsky 2012 and jin and durlofsky 2018 we consider uncertainties in the porosity and permeability fields and in the direction of a regional pressure gradient multiple model scenarios represented by different variograms are considered when generating prior geological models note that model structural uncertainty e g uncertainty in the conceptual model which is not included in this study can be readily incorporated by considering an ensemble of prior realizations drawn from different geological concepts or training images this was in fact done in sun et al 2017b for a discrete fracture matrix model in which dsi was applied for production forecasting multi gaussian log permeability fields as are considered here have been widely used in previous studies related to forward modeling and data assimilation in co2 storage and related problems for example farajzadeh et al 2011 described flow regimes in geologic storage operations using two dimensional multi gaussian models characterized by exponential variograms with different correlation lengths and dykstra parsons coefficients similar models were used in the upscaling studies of rabinovich et al 2015 sun et al 2017a considered the identification of leaks with source term attributes treated as uncertain the true fields used in that work were in all cases multi gaussian cameron et al 2016 also used multi gaussian permeability models for a leak detection study in the context of co2 storage yoon et al 2017 studied data assimilation for a problem involving similar physics to that in co2 storage they considered the injection of freshwater into a saline aquifer for purposes of freshwater storage two dimensional multi gaussian models were considered and an ensemble kalman filtering procedure was used for data assimilation finally chen et al 2018 used multi gaussian models with a spherical variogram in their monitoring well optimization study we note that in the great majority of previous investigations involving data assimilation with multi gaussian models prior models were all characterized by a single variogram our treatment here is much more general as our prior includes models generated using a wide range of variogram and other parameters as described below in this work pressure and co2 saturation data within the storage aquifer are considered to be available in practice pressure data can be obtained through embedded pressure transducers and co2 saturation can be measured in situ using time lapse sonic logs caspari et al 2011 as well as by seismic and other monitoring technologies as described in zhang et al 2018 in this study synthetic pressure and co2 saturation data are collected at monitoring wells during the 20 year injection period with monitoring well locations optimized using the data space approach described in section 2 3 other data types could be readily incorporated if available given the monitoring data the conditional predictions for the co2 plume at the top layer after 180 years of post injection equilibration i e at the end of the 200 year time frame are generated using the dsi algorithm presented in section 2 1 we emphasize that no additional data are collected after the 20 year injection period note that this data assimilation could be performed more frequently e g every year during the injection period and this would be very inexpensive with dsi since no additional simulation runs are required 3 1 aquifer model the storage aquifer covers an area of 8 5 km 8 5 km and is of a vertical thickness of 151 m the aquifer initially contains only brine at a pressure of 15 5 mpa and a temperature of 55 c a total of 8 mt year of co2 is injected into the storage aquifer for 20 years this co2 volume corresponds to approximately 2 5 of the aquifer pore volume the aquifer is of an average porosity of about 0 2 the storage aquifer is modeled on a uniform grid of 35 35 11 blocks each of size 243 m 243 m 13 7 m the basic aquifer model is presented in fig 2 one realization of the heterogeneous porosity field for the storage aquifer is shown in fig 2a around the storage aquifer a larger scale regional aquifer is introduced which essentially acts to dissipate pressure cameron et al 2016 fig 2b shows the simulation grid for the full system with the white central region representing the storage aquifer shown in fig 2a to save computational effort the grid block size increases by a factor of three as we move out from the storage aquifer the full system is modeled on a 43 43 11 grid and is of overall dimension 67 km 67 km 151 m in the region outside the storage aquifer porosity and permeability values are specified to be constant at 0 2 and 29 md which correspond to the mean values in the storage aquifer no flow boundary conditions are applied at the boundaries of the full model four horizontal injectors are located in layer 9 third from the bottom of the storage aquifer each injector is controlled with a constant co2 injection rate of 2 mt year the four injectors shown as red lines in fig 2c are arranged in a square pattern in addition vertical monitoring wells depicted as green lines in fig 2c provide co2 saturation and pressure data at all of the grid blocks they contact recall that monitoring wells penetrate the top three layers of the model because these wells penetrate the cap rock in practice it will be important that proper well completion isolation and cementing procedures are applied the simulation model includes two fluid phases referred to as water and gas and three components water supercritical co2 and salt brine salinity is specified to be 10 000 mg kg the gas water relative permeability curves which include hysteresis important for residual trapping are taken from cameron and durlofsky 2012 and are shown in fig 3 a capillary pressure curves are generated using the brooks corey model saadatpoor et al 2010 with specific model coefficients of p e 0 36 entry pressure and λ 0 67 pore size distribution index capillary pressure curves which vary from block to block and depend on porosity and permeability are modeled using the leverett j function see eqs 2 3 and 2 4 in saadatpoor et al 2010 fig 3b shows the capillary pressure at reference porosity 0 2 and permeability 29 md given the large size of the grid blocks the absolute permeability and the relative permeability and capillary pressure curves should be regarded as appropriately upscaled functions this upscaling can be accomplished using e g the methods described in rabinovich et al 2015 chemical reactions and mineralization are not included in our model as these effects are not expected to be significant over the simulation time frame considered in this study all flow simulations are performed using the eclipse simulator schlumberger 2013 with the co2store option in this study the porosity and log permeability fields in the storage aquifer are represented using two point geostatistical models sequential gaussian simulation available within the sgems toolbox remy et al 2009 is used to generate multiple geological realizations of the porosity field these realizations are not conditioned to any well hard data the histogram of the porosity distribution is specified to be normal with mean ϕ 0 2 and standard deviation σ ϕ 0 04 the correlation structure of the porosity field is characterized using an ellipsoid shaped exponential variogram model with the three correlation lengths of the principal axes specified in terms of the number of grid blocks set to be l 1 40 l 2 5 and l 3 5 we consider different variogram models and thus different geological scenarios by varying the orientations of the principal axes of the ellipsoid the ranges of these parameters are shown in table 1 azimuth and dip refer to the two ellipsoid orientation angles see remy et al 2009 for more details the other parameters appearing in the table are described below the permeability value in the x direction kx is related to porosity via 20 ln k x a b ϕ ϕ σ ϕ e where a 3 5 b 1 and e represents random noise sampled from a normal distribution with mean e 0 and standard deviation σ e 0 4 therefore kx is log normally distributed with mean ln k x 3 5 and standard deviation σ ln k x 1 08 we specify k y k x and k z c k x where c is randomly sampled from a uniform distribution within 0 05 0 2 for each prior permeability realization i e kz kx is constant for a given model fig 4 shows two random realizations of the porosity field and the corresponding ln kx fields clear differences in the correlation structure of the two porosity or permeability fields due to the use of different variogram models are evident in addition to uncertainties in the distribution of porosity and permeability we also include an uncertain large scale regional pressure gradient which acts to move the co2 plume horizontally in the west to east direction the pressure gradient component is specified to be constant at 280 pa m while in the south to north direction the pressure gradient component is uncertain and ranges from 0 pa m to 280 pa m the effect of this regional pressure gradient is captured in the simulations by specifying water rates for an array of 12 wells penetrating all layers distributed around the storage aquifer shown as blue lines in fig 2c wells on the west and south sides are specified to be injectors and producers are on the opposite sides the injectors and producers on the west and east sides are assigned constant water rates of 55 m3 day which results in a pressure gradient of 280 pa m the water rate qw however is sampled uniformly from 0 m3 day to 55 m3 day for wells on the north and south sides each well in a particular realization is assigned the same qw therefore the uncertainty related to the regional pressure gradient is represented using the single random variable qw ranges for this parameter are given in table 1 in the results presented below four different test cases will be considered in detail for the evaluation of our data space approaches parameters for all test cases are provided in table 1 3 2 simulation results from prior models in this paper a total of n r 1000 prior models are generated over the parameter ranges given in table 1 as described in section 3 1 the duration of the injection period is 20 years during which data are collected and this is followed by 180 years of equilibration we are interested in assessing the co2 saturation distribution at the top layer at the end of the equilibration period fig 5 shows the co2 plume evolution in a cross section containing an injection well for one randomly selected prior model during the injection period co2 accumulates in the system while moving toward the top of the formation due to buoyancy from 140 years to 200 years we see that the co2 distribution changes relatively little indicating that much of the co2 is essentially trapped this is caused both by residual trapping and trapping due to heterogeneous capillary pressure the slight changes in the co2 distribution in the top layer at a late time fig 5g and h are due to spreading in the direction orthogonal to the image in the y direction fig 6 displays the co2 saturation distribution in the top layer these are x y plots in contrast to the x z plots in fig 5 corresponding to six different prior models the results presented in this figure are selected based on the total amount of co2 in the top layer at 200 years computed as j in eq 10 in fig 6 j p prior indicates the pth percentile of j among all prior simulation runs there are large variations in the distribution and total amount of co2 in the top layer which is evident by comparing fig 6a f more specifically the p 90 result in fig 6e j 90 prior 0 056 shows about twice the co2 compared with the p 10 result in fig 6a j 10 prior 0 027 in addition although there are essentially four co2 lobes corresponding to the four injectors the co2 plumes form into different shapes and move to different locations this phenomenon can be caused by differences in the regional pressure gradient and or by differences in the porosity and permeability fields as will be demonstrated below data at the monitoring wells enable us to narrow our estimates for the location and shape of the co2 plume 3 3 optimization of monitoring well locations we now present results for the optimization of a specified number of monitoring wells the number of monitoring wells is denoted by n w recall that this optimization is performed after simulating the n r prior models but before any data are measured as discussed earlier the qoi j is specified to be the average co2 saturation in the top layer at 200 years eq 10 and we are interested in maximizing the expected uncertainty reduction for j after assimilating 20 years of measurement data for each monitoring well pressure and co2 saturation data are measured annually for 20 years in each of the top three layers the standard deviation of the measurement error for pressure and co2 saturation data are specified to be 0 1 mpa and 0 02 respectively in this section we will consider two different cases n w 4 and n w 8 therefore the dimension of d h is n h n w 3 2 20 480 when n w 4 and n h 960 when n w 8 the number of parameters to determine in the optimization is 8 n w 4 or 16 n w 8 as mentioned in section 2 3 the matlab genetic algorithm ga optimizer with default options is used in this study the initial monitoring well locations determined heuristically are shown as blue squares in fig 7 a for the case with n w 4 the computed expected uncertainty reduction for this configuration is u r y init 4 0 34 where y init 4 denotes the initial locations for the four monitoring wells and the function u r y is defined in eq 18 this result means that the prediction uncertainty represented as variance of j is expected to be reduced by 34 compared with the prior variance σ j j 2 after assimilating all possible outcomes of measurement data collected at these well locations fig 7b shows the progression of the best ga solution the objective function is u r y over the 91 generations of the optimization procedure the best ga solution at generation 0 is 0 54 rather than 0 34 because at least one of the solutions in the initial population leads to more uncertainty reduction than the initial guess y init 4 the elapsed time for this optimization is about five minutes with our matlab implementation the optimal locations y opt 4 are shown as red diamonds in fig 7a this result corresponds to u r y opt 4 0 77 which is a clear improvement over the initial guess it is noteworthy that the optimal solution tends to place the monitoring wells above the injectors shown as black cross hatched lines in fig 7a as would generally be expected though there are two monitoring wells above the left injector and none above the lower injector we note that the optimized well locations will be different with different initial guesses based on limited experimentation however it does appear that monitoring wells tend to be placed above injectors fig 8 displays analogous results for the case of n w 8 a total of 312 ga generations are required in this case and the total elapsed time is around 30 minutes the initial and optimal expected uncertainty reduction are u r y init 8 0 61 and u r y opt 8 0 87 interestingly the optimal solution in this case corresponds to two monitoring wells placed above each injector see fig 8a 3 4 dsi predictions of co2 plume test case 1 we now apply the dsi methodology to a series of synthetic test cases to demonstrate the reduction in uncertainty that can be achieved using this procedure in all cases a true model which is not included in the set of n r prior models is generated the geological parameters for the three true models considered in this section test cases 1 2 and 3 are given in table 1 flow simulation is then performed on the true model to provide the true data measurement error with mean and standard deviation as given in section 2 3 is added to the true data to provide the observed data d obs note that this measurement error could be used to account for the fact that monitoring wells are much smaller than the grid blocks they penetrate i e because monitoring well diameter is much less than the horizontal grid block dimension measured data correspond to the grid block value plus some error a grid refinement assessment such as that presented in section 4 3 could be used to quantify this error in practice the porosity field for test case 1 is shown in fig 9 a and the top layer co2 at 200 years is displayed in fig 9b j true 0 029 for this case fig 10 shows the time series for the observed data red circles for a single grid block where data are measured annually note that the synthetic observed data are forced to be nonnegative in fig 10b when negative measurement error is added to zero co2 saturation data the simulated data from n r 1000 prior models for the selected grid block are shown as the gray curves in fig 10 fig 10c presents the histogram of the co2 saturation data at 10 years from the prior model simulations these results display strong non gaussian character which illustrates the fact noted in section 2 1 and discussed in detail in sun and durlofsky 2017 and sun et al 2017b that multiphase flow simulation results are non gaussian even when the underlying log permeability field is multi gaussian we first consider the case with four optimized monitoring wells which results in a total of n obs 480 observations consistent with n h in the previous section our intent is to predict the co2 saturation distribution in the top layer at 200 years recall that data are collected only during the 20 year injection period thus the number of variables to predict in d p is equal to the number of grid blocks in the top layer i e n p n grid 35 35 1225 the dimension for the full data vector d f in the dsi procedure is then n f n h n p 1705 because d f contains both pressure and saturation data variables which are of very different scales we normalize the pressure data variables to be of mean 0 and standard deviation 1 before applying pca fig 11 shows the cumulative energy loss in other words the variability that is not explained in the subspace for different numbers of retained principal components which is the dimension of ξ denoted as l in eq 8 we determine the number of principal components l by specifying the energy loss to be less than 0 005 which results in l 42 in this case though the dimension of the data space n f is fairly large the reduced space with pca parameterization is reasonably small this observation indicates that the simulated data have strong cross correlations applying the dsi procedure algorithm 1 with l 42 we generate a total of n post 100 posterior predictions the dsi predictions for the historical period d h are shown in fig 10 as the blue curves it is evident that the dsi predictions are able to essentially match the observed data red circles for both quantities though our interest is not to predict the observed data these results serve as a quality check of the application of the dsi method if the dsi predictions are not able to match observed data more prior runs might be required it is also possible that additional geological scenarios e g different variogram parameters in the current setting should be considered for more discussion of this issue please see our earlier work sun and durlofsky 2017 fig 12 shows three posterior realizations of the co2 saturation distribution obtained with the dsi method these three realizations are selected based on the average top layer co2 saturation at 200 years j in eq 10 we compute j for all 100 posterior dsi top layer saturation fields and then rank them from lowest to highest figs 12a c correspond to the results of rank 10 50 and 90 i e the p 10 p 50 p 90 results the p 10 and p 90 results can be viewed as optimistic and pessimistic predictions respectively of the top layer co2 saturation at 200 years it is evident that the amount of co2 in the dsi predictions is reasonably close to that from the true model fig 9b even though the amount of predicted co2 in the prior models varies substantially as seen in fig 6 more specifically j true 0 029 is encompassed within the range of dsi predictions 0 026 0 038 for j 10 to j 90 and this range is significantly smaller than the range of prior predictions 0 027 0 056 for j 10 prior to j 90 prior in addition the overall pattern of the true co2 plume fig 9b is captured better in the dsi predictions fig 12 than in the prior predictions shown in fig 6 especially for the plume at the left side of the model 3 5 dsi predictions for different monitoring scenarios we next consider three other monitoring scenarios to investigate the effects of the number and placement optimal versus heuristic of monitoring wells parameters for all monitoring scenarios are shown in table 2 with monitoring scenario 2 the location of monitoring wells is not optimized though all other parameters are the same as in monitoring scenario 1 considered in the previous section monitoring scenarios 3 and 4 differ from monitoring scenario 1 in terms of the number of monitoring wells and the associated number of observations fig 13 shows the dsi predictions for co2 saturation distribution when monitoring well locations are not optimized as in fig 12 the three saturation fields again correspond to p 10 p 50 p 90 results the predictions show clear improvement in terms of matching the true plume relative to the prior predictions shown in fig 6 however the variability of the average co2 among the three realizations in fig 13 is larger than in the results corresponding to optimal monitoring well placement fig 12 this observation is also evident in fig 14 where we plot the empirical cumulative density function cdf for the top layer average co2 saturation over the 100 posterior dsi predictions the dashed blue and the solid black lines represent results for n w 4 without and with optimization of monitoring well locations we see that the uncertainty range is much narrower when using data measured at optimized monitoring well locations the dashed green and solid blue lines display results for six and eight optimal monitoring wells we observe a consistent decrease in uncertainty as n w is increased consistent with expectations fig 15 displays co2 saturation predictions for monitoring scenario 4 which entails the use of eight optimally placed monitoring wells these results match the true plume better than those for monitoring scenario 1 where n w 4 in particular predictions of the lower plume in fig 15 are clearly more accurate than those in fig 12 this observation can be explained by the placement of monitoring wells shown in figs 7a and 8a in the case with n w 4 there are no monitoring wells above the lower injector while in the case with n w 8 two monitoring wells are placed above this injector as a result there are more observations corresponding to this co2 plume in addition with more monitoring wells the connection between the lower plume and the plume on the right is also captured more accurately to better quantify the accuracy of dsi predictions for the co2 saturation distribution in the top layer we compute the average saturation error for each posterior prediction δk as follows 21 δ k 1 n grid i top layer s i pred k s i true here δk denotes the average pixel wise prediction error in posterior prediction k n grid is the total number of top layer grid blocks s i pred k is the predicted co2 saturation at 200 years in grid block i from dsi posterior prediction k e g fig 15a and s i true is the true co2 saturation at 200 years in grid block i shown in fig 9b given δk for all n post 100 dsi predictions we can construct a cdf of the δk for each monitoring scenario fig 16 displays the resulting empirical cdfs the prediction error from the prior models is the largest as no additional measurement information is assimilated we also see that optimizing monitoring well locations improves prediction accuracy from the dashed blue line to the black line in fig 16 and that the use of more monitoring wells is also beneficial from the solid black line to the solid blue line another interesting observation is that comparing the solid blue optimized n w 8 and pink prior curves the worst prediction from the blue curve has an average prediction error of 0 066 which is better than 98 of the predictions from the prior models these results demonstrate that the dsi procedure is indeed able to provide improved predictions by assimilating measured data 3 6 dsi predictions with different true models in the previous section the dsi procedure was evaluated on a single true model test case 1 from which the synthetic measurements were generated we now evaluate the methodology on two additional true models referred to as test cases 2 and 3 we reiterate that neither true model was included in the set of n r 1000 prior models in each of the test cases optimal monitoring scenarios 1 and 4 defined in table 2 and corresponding to n w 4 and n w 8 are considered since the prior models and thus the prior simulation results do not change between test cases the locations of the monitoring wells are the same for all three cases table 3 shows the prior results which are the same as for test case 1 and dsi results in terms of p 10 p 50 and p 90 statistics for the top layer average co2 saturation at 200 years note that j true varies considerably between test cases for all three cases the dsi predictions consistently encompass the true data within the p 10 to p 90 range and show a narrower range of uncertainty represented as p 90 p 10 when more monitoring wells are used prediction results for the top layer co2 saturation distribution for n w 4 are shown in fig 17 for test cases 2 and 3 for test case 2 the true co2 distribution is displayed in fig 17d there we see a very different pattern from the true plume for test case 1 fig 9a there is relatively little co2 at the left and bottom of the model while the two co2 plumes toward the upper right display high co2 saturation and actually connect with each other these phenomena are essentially captured in the dsi results figs 17e g even though this behavior is not directly evident in the prior results the true plume for test case 3 is shown in fig 17h here we see four isolated co2 plumes and overall high co2 saturation j true 0 051 these features are largely captured in the corresponding dsi results figs 17i k taken in total the results for the three different test cases suggest that the dsi procedure is indeed able to provide improved forecasts for top layer co2 distribution at 200 years by assimilating 20 years of measurements from monitoring wells 4 additional considerations in the previous section we presented dsi results for test cases in which all of the true models were within the prior distribution this means that the prior realizations used in dsi were consistent with the underlying true model in this section we evaluate dsi performance for cases involving prior realizations that are inconsistent with the true model more specifically we first consider a true model characterized by parameters that fall outside the ranges defined in table 1 we then describe a means for quantifying the consistency of observed data with the prior model simulation results finally we consider a true model defined on a finer grid than that used for the prior simulations which allows us to assess for a particular example the impact of model error on dsi results 4 1 dsi predictions for true model parameters outside prior distributions table 1 displays the geological parameters for test case 4 we see that the true model parameters for this example all lie outside the range of the prior distributions test case 4 thus represents a potentially challenging case for dsi due to this inconsistency between true model parameters and prior distributions monitoring scenario 1 four wells optimized is considered in this case fig 18 presents the synthetic observed data shown as red circles from a monitoring well at a single grid block these data are for the same grid block as in fig 10 the gray curves represent the simulated results corresponding to the same n r 1000 prior models described in section 3 it is clear that the observed data are near the edge of the prior distributions of simulated data for both pressure and co2 saturation fig 19 displays the distribution of top layer average co2 saturation at 200 years from prior realizations pink curve along with the prediction corresponding to the true model vertical red line we see that the true model result in this case is at the edge of the prior distribution specifically j true 0 064 is above the 99th percentile of the prior cdf j 99 prior 0 063 this is likely due to the high vertical permeability for test case 4 k z k x 0 3 for this case as shown in table 1 although the test case 4 parameters are all outside the prior ranges the observed data are still somewhat consistent with the prior simulation results as is evident in fig 18 if this were not the case i e if the observed data fell well outside the prior simulation results it would indicate that the prior was too narrow and that a broader prior should be considered the degree of consistency between the observed data and prior simulation results can be quantified using the mahalanobis distance he et al 2017 which will be described and applied below within a dsi setting a lack of consistency here means that additional prior simulation runs must be performed it is however straightforward to include simulation results from a wide range of priors in dsi as illustrated in sun et al 2017b we now apply the dsi methodology with the original set of n r 1000 prior models we reiterate that these prior models are not consistent with the underlying true model dsi predictions of the grid block data are shown as blue curves in fig 18 it is evident that the dsi results display a reasonable match to the observed data though the predictions for co2 saturation at around 12 years somewhat underestimate the observations the distribution of dsi predictions for top layer average co2 saturation is shown in fig 19 dashed blue line we see that the range of uncertainty is reduced significantly after assimilating the measured data and that the true result red line is encompassed within the posterior cdf fig 20 a presents co2 saturation predictions from the true model along with p 10 p 50 and p 90 dsi results some features in the true co2 plumes are not fully captured in the dsi predictions for example the plume at the left side of the model has a more circular shape compared with the dsi posterior results and the plume at the right has a wedge shape that is not captured by the three dsi predictions these discrepancies likely result because the prior distributions of model parameters were specified too narrowly for this case it is noteworthy however that the general pattern and location of the true co2 plumes are still captured in the dsi predictions in addition the average co2 saturation obtained from the true model j true 0 064 is encompassed within the p 10 p 90 range of dsi results j 10 j 90 0 056 0 068 these results thus suggest that our dsi procedure displays a degree of robustness in terms of the prior parameter ranges we reiterate that it is essential that the prior simulation results encompass the observations if this is not the case we would not expect dsi to provide reasonable posterior predictions in the following section we describe the use of mahalanobis distance to quantify the consistency between observations and prior simulated data 4 2 use of mahalanobis distance to assess consistency with the prior inversion algorithms based on bayesian statistics rely on appropriately validated prior models oliver and alfonzo 2018 these algorithms cannot be expected to work when the true model is outside of the prior distribution thus in practice it may be important to evaluate the consistency between the true model and the prior before performing data assimilation within a dsi setting the consistency between observations and simulated data can be assessed by for example visually comparing results in a low dimensional space satija et al 2017 or by using a hypothesis test based on mahalanobis distance he et al 2017 in this study we consider the use of mahalanobis distance to quantitatively gauge the consistency of the prior model simulation results with the observed data mahalanobis distance is computed based on the first and second moments of the prior distribution though it is nonetheless widely used in consistency assessments for general problems de maesschalck et al 2000 in accordance with he et al 2017 we define the mahalanobis distance as 22 d d d μ d h t c d h d h 1 d μ d h 1 2 where d r n h 1 denotes a high dimensional data point vector and other quantities are as defined in section 2 eq 22 measures the distance between a point d and the mean of a multivariate distribution n μ d h c d h d p in this paper the mean and covariance matrix are computed using the simulated data from all n r 1000 prior models there are however some limitations associated with computing mahalanobis distance directly using eq 22 these include the fact that c d h d h is often not invertible it is not invertible in our case and that random noise may dominate the computation if a high number of singular vectors are retained in the approximation of c d h d h 1 these two issues can be addressed by using a variation of eq 22 in which the mahalanobis distance is recast as the euclidean distance of the sum of the squares of the scores of principal components brereton 2015 de maesschalck et al 2000 specifically we express d as d u σ ω μ d h where u r n h k corresponds to the left singular vectors of c d h d h σ r k k is a diagonal matrix containing the singular values and ω r k 1 contains the scores now writing ω as ω σ 1 u t d μ d h and c d h d h as c d h d h u σ 2 u t we can express eq 22 as 23 d k d ω t ω 1 2 note that this expression aligns directly with the pca representation of d f which is used in an intermediate step in our formulation in section 2 we will now assess the use of eq 23 in identifying the degree of consistency between observed data and prior simulated data observed data for test cases 1 4 will be assessed as will data for two additional cases that are purposely set up to be inconsistent with the prior these two new cases correspond to homogeneous models with high and low permeability values specifically in test case h100 we set permeabilities to be k x k y 100 md and k z 15 md these values are higher than the average permeability values in the prior models defined in table 1 and in test case l10 we set k x k y 10 md and k z 0 1 md which are lower than the average values in the prior models for test cases h100 and l10 the porosity values are constant at ϕ 0 2 and no large scale regional pressure gradient is applied other properties are the same as described in section 3 1 we again consider monitoring scenario 1 the settings for measurement error and the dsi treatments are as in sections 3 and 4 1 results for mahalanobis distance eq 23 are shown in fig 21 the plot in fig 21a k 11 corresponds to retaining 90 of the energy in the nonzero singular vectors associated with c d h d h and the plot in fig 21b k 38 corresponds to retaining 99 of this energy as noted earlier if we retain very high fractions of energy e g 99 99 over fitting to random measurement noise can occur which complicates the interpretation of the computed distances in fig 21 the pink curves represent dk computed from the prior model simulation results to generate these curves we take each prior model simulation result in turn as d and then apply eq 23 to compute dk the cdf is then constructed from the full set of 1000 prior simulation results the values for dk for test cases 1 4 and test cases h100 and l10 are shown in fig 21 it is apparent from the plots that results for test cases 1 3 fall well within the prior distribution results for test case 4 fall toward the tail and results for test cases h100 and l10 fall either outside the prior distribution entirely fig 21b or at the extreme edge fig 21a for test case l10 these results are very encouraging and in line with our expectations since test cases 1 3 are indeed from within the prior test case 4 is similar to the prior models but lies outside of the prior distribution and test cases h100 and l10 are quite inconsistent with the prior models thus we see that the mahalanobis distance dk computed using eq 23 is very useful for identifying inconsistencies between observed data and prior model simulation data for this problem if the observed data fall at the extreme edge or outside the prior distribution dsi should not be immediately applied rather the set of prior models should first be expanded such that the observed data fall within the prior distribution of simulated data unless the prior is extended in this manner we would not expect dsi to work for the case in question and it would not make sense to apply it the lack of applicability of dsi in such settings is illustrated in fig 22 for test cases l10 and h100 where we display dsi results for the cdf of top layer average co2 for these cases using the original set of 1000 simulation results as the prior all curves are as defined previously the fact that the true data vertical red lines do not intersect the dsi results indicates that the method fails in these cases this failure is expected however as it is clearly predicted by the mahalanobis distance plots in fig 21 thus a practitioner would know not to apply dsi for either of these cases without first extending the set of prior model simulation results such that the observed data fall well within the prior distribution 4 3 impact of grid resolution because our dsi procedure requires performing flow simulations for a large set of prior models efficiency considerations motivate the use of relatively coarse models in the results presented up to this point the grid block size was 243 m 243 m 13 7 m in the storage region with grid blocks of this size relative permeability and capillary pressure curves should in practice be upscaled from a finer scale description in addition the observed data were generated from simulation results for a true model with these large grid blocks we now quantify the impact of grid refinement which acts to better capture detailed flow behavior in the simulations first co2 saturation distributions for coarse and fine models are compared then dsi is applied for a case in which the true data are generated using a fine scale simulation the higher resolution fine models are generated by introducing 3 3 3 refinement in each original block in the storage region this results in a fine grid containing 105 105 33 cells in the storage region additional heterogeneity in the porosity and permeability fields is not incorporated this means that these properties are constant within 3 3 3 regions in the fine model although finer scale heterogeneity could also be introduced this approach enables us to isolate and assess the impact of numerical error only rather than the combined effect of numerical error and heterogeneity resolution level we first present saturation results for test cases 1 2 and 3 simulated at the fine and coarse scales the simulation setup is as described in section 3 the co2 saturation distributions for the three cases are shown in fig 23 original coarse model results are displayed in the left column and fine scale results appear in the right column to enable direct comparison the fine model results are obtained by averaging the saturation data over the 3 3 3 fine blocks corresponding to each coarse block we see that the location and shape of the co2 plumes in the fine models are very similar to those in the corresponding coarse models the average co2 saturations listed in the figure captions as j coarse and j fine are however somewhat higher in the fine models suggesting that co2 vertical migration is somehow limited by the coarse discretization we next consider the correspondence in fine to coarse model results for a range of test cases fig 24 displays a scatter plot of average co2 saturation from coarse models and the corresponding fine models for 20 different cases again the coarse model results are for the top layer average co2 saturation and the fine model results are for co2 saturation averaged over the top three layers in this way the results correspond to the same physical regions we observe that the average co2 saturation is consistently higher for the fine models with a shift of around 0 008 at the lower saturation values and around 0 02 at the highest saturation values nonetheless a clear trend is evident indicating that the error is systematic rather than random we note that these observations are consistent with the results of cameron and durlofsky 2012 where coarse models were used for the optimization of co2 storage problems we now apply dsi for a case in which the observed data correspond to simulation results for a true model that contains grid refinement i e the storage region in the true model is now simulated using 105 105 33 blocks in this assessment the same n r 1000 coarse scale prior realizations as were used in all previous examples will again be applied the true model in this case is the refined version of test case 1 which we refer to as refined test case 1 the average co2 saturation for refined test case 1 at 200 years is about 0 037 in contrast to 0 029 for the original coarse test case 1 this difference is consistent with the shifts noted above four monitoring wells at optimized locations monitoring scenario 1 in table 2 are considered note that the monitoring wells now penetrate the top nine layers in the fine model corresponding to the top three layers in the coarse model the data used for dsi now correspond to pressure and co2 saturation averaged over the 3 3 3 grid blocks around monitoring wells this treatment maintains consistency with the coarse models used for dsi and with test case 1 in section 3 noise is added as described earlier the observed data not shown fall within the prior simulation results so we expect dsi to provide sensible results for refined test case 1 dsi results in terms of the empirical cdf for average co2 over the top three layers of the fine model are shown in fig 25 the prior cdf shown as the pink curve is based on coarse model original simulations so it is identical to that for test case 1 in fig 14 the posterior dsi cdf shown as the dashed blue curve is however different from the posterior for monitoring well scenario 1 in fig 14 black curve in that figure since the data in the current case are different i e they now derive from a refined model simulation more specifically for the original test case 1 j true 0 029 we had j 10 0 026 j 50 0 031 j 90 0 038 while for refined test case 1 j true 0 037 indicated by the vertical red line in fig 25 we have j 10 0 029 j 50 0 035 j 90 0 042 thus we see that the dsi predictions shift towards higher saturation values consistent with the data from the refined test case 1 simulation this is an encouraging result since it demonstrates that dsi is able to provide reasonable predictions using coarse scale prior simulations even when the true data potentially contain finer scale information this suggests that dsi may be reasonably robust with respect to this type of model error dsi performance will however need to be assessed for a range of cases to quantify its behavior in this regard 5 concluding remarks in this work we devised and applied a data space inversion dsi procedure for the prediction of co2 saturation distribution in the top layer of a storage aquifer the method provides posterior estimates based on prior model simulation results and measurements at some number of monitoring wells in contrast to traditional history matching approaches the dsi procedure does not entail calibration of model parameters and thus does not provide posterior models in the dsi procedure a set of realizations 1000 in the cases considered here honoring prior geological information is first generated and simulated to provide prior samples for variables corresponding to measurement data and prediction quantities of interest qoi a reparameterization based on principal component analysis and histogram transformation is applied to facilitate the sampling of posterior data variables this sampling is accomplished using the randomized maximum likelihood rml method in the data space we also applied analytical results from the dsi formulation to quantify the effectiveness of measurements over all prior models for given monitoring well locations the analytical expressions used for this determination are consistent with the ensemble variance analysis formulations studied by he et al 2018 measurement effectiveness is defined here in terms of the expected reduction of posterior variance for a specified qoi in this work this qoi was taken to be the average co2 saturation in the top layer of the storage aquifer at 200 years given this analytical and thus fast to compute measure of effectiveness we successfully optimized the monitoring well locations using a genetic algorithm the overall dsi procedure was then applied to synthetic three dimensional heterogeneous aquifer systems uncertainties in the underlying variogram model in the porosity and permeability distributions and in the regional scale pressure gradient were incorporated into the prior models detailed physics including relative permeability hysteresis and capillary pressure heterogeneity were included in the flow simulations we evaluated dsi for three different true models with varying numbers of monitoring wells dsi predictions were compared with true model simulation results for the top layer co2 saturation distribution in all cases involving optimal monitoring wells we observed that the dsi posterior predictions for the amount and general distribution of co2 in the top layer displayed considerably less uncertainty than estimates from the prior models we further showed that dsi prediction accuracy was consistently enhanced as more monitoring wells were used and that a higher degree of uncertainty reduction was achieved using optimally located instead of heuristically placed monitoring wells dsi was also shown to provide reasonable results for a true model characterized by parameters that lie outside the prior distributions and for a case in which the observed data were generated from a fine grid simulation we also considered two homogeneous test cases that led to observed data that were very inconsistent with the prior simulation data we showed that an appropriately computed mahalanobis distance is able to clearly identify this inconsistency and that dsi will fail if directly applied for such cases there are several directions in which this work could be extended it will be useful to apply our dsi procedures to more complex geological models such as bimodal channelized systems which can be challenging for traditional model based history matching methods although the prediction of posterior well based quantities for such systems has been accomplished in a dsi setting in sun and durlofsky 2017 it will be interesting to assess the predictive ability of dsi for qoi of the type considered here such as top layer co2 saturation the use of dsi for different problem setups such as co2 leakage detection under uncertainty as described by cameron et al 2016 and jeong et al 2018 should also be considered in these applications leakage may have already occurred which will change the formulation objective of the optimization problem it may be possible to provide better uncertainty quantification for this problem using dsi than with model based methods finally some of the detailed treatments in our dsi procedure could be further studied with the goal of reducing the number of prior runs required or improving dsi predictions for a given number of prior runs for example it may be beneficial to apply functional pca as used by satija and caers 2015 for dimension reduction of tracer data in place of the pca parameterization used in this work acknowledgments we thank david cameron and zhaoyang larry jin for providing aquifer models and simulation files and for useful discussions we are grateful to chevron etc and the stanford smart fields consortium for financial support appendix 
722,one of the major concerns of carbon capture and storage ccs projects is the prediction of the long term storage security of injected co2 when injected underground in saline aquifers or depleted oil and gas fields co2 mixes with the resident brine to form carbonic acid the carbonic acid can react with the host carbonate rock and alter the rock structure and flow properties in this study we have used x ray micro tomography and focused ion beam scanning electron microscopy fib sem techniques to investigate the dissolution behavior in wettability altered carbonate rocks at the nm to µm scale to investigate co2 storage in depleted oil fields that have oil wet or mixed wet conditions our novel procedure of injecting oil after reactive transport has revealed previously unidentified ghost regions of partially dissolved rock grains that were difficult to identify in x ray tomographic images after dissolution from single fluid phase experiments we show that these ghost regions have a significantly higher porosity and pore sizes that are an order of magnitude larger than that of unreacted grains the average thickness of the ghost regions as well as the overall rock dissolution decreases with increasing distance from the injection point during dissolution micro porous rock retains much of its original fabric this suggests that considering the solid part of these ghost regions as macro bulk pore space can result in the overestimation of porosity and permeability predicted from segmented x ray tomographic images or indeed from reactive transport models that assume a uniform sharp reaction front at the grain surface keywords reactive transport ghost features carbonate rocks carbon capture and storage ccs x ray micro tomography fib sem 1 introduction carbon capture and storage ccs is one of the proposed methods to mitigate climate change for ccs carbon dioxide co2 can be captured from various industrial units such as power plants cement factories and iron and steel making industries boot handford et al 2014 the captured co2 is pressurized and transported to a storage site and then injected underground for its geological storage in saline aquifers depleted oil and gas reservoirs or deep coal seams there are four mechanisms by which the co2 can be stored underground physical trapping under an impermeable cap rock trapping of co2 due to its dissolution in the brine phase where co2 rich brine sinks due to its higher density capillary trapping where the co2 is stored as isolated trapped clusters and mineral trapping in which the co2 can react with the host rock to form secondary carbonates xu et al 2003 krevor et al 2015 bachu et al 1994 a major challenge of ccs is the long term security of stored co2 herzog et al 2003 during co2 injection when the supercritical co2 mixes with the resident brine it forms carbonic acid the carbonic acid can react with the host rock and consequently can alter the rock structure pore geometry and related flow properties such as absolute and relative permeability qajar and arns 2017 menke et al 2015 luquot and gouze 2009 luquot et al 2014 ott and oedai 2015 this is particularly the case for carbonate rocks the extent and pattern of rock dissolution depend on many factors including ph temperature pressure conditions injection rates pore structure and chemical and physical heterogeneity el maghraby et al 2012 menke et al 2017 al khulaifi et al 2018 daccord et al 1993 recently it has been shown that the dissolution pattern is also different for single phase and two phase reactive transport ott and oedai 2015 the latter involves the simultaneous injection of co2 and reactive brine these studies demonstrate the complexity of reactive transport and dissolution processes understanding the mechanisms of these processes is therefore important to estimate the fluid flow pore occupancy and the effectiveness of ccs projects recent advances in three dimensional imaging using x ray tomography have enabled the visualization and characterization of porous media at different length scales krevor et al 2015 ott and oedai 2015 singh et al 2017a b singh et al 2016 pak et al 2015 berg et al 2013 blunt et al 2013 blunt 2017 medical x ray tomography has been applied to investigate mm to dm scale features of reactive transport and dissolution regimes in rocks with varying degrees of heterogeneity ott and oedai 2015 menke et al 2018 to investigate reactive transport at the pore scale x ray micro tomography has been used in recent experimental studies qajar and arns 2017 menke et al 2015 2017 al khulaifi et al 2018 ott et al 2012 qajar and arns 2016 however the finer features of rock dissolution from the nm to µm scale have not been studied in detail the visualization of these features and their effect on flow properties are important to understand the overall behavior of carbonate rock dissolution in this study we have used x ray micro tomography and fib sem techniques to investigate the dissolution features of wettability altered carbonate rocks at different length scales after supercritical co2 saturated reactive brine injection the wettability of these rocks was altered by the adsorption of organic acids hamouda and rezaei gomari 2006 to represent the surface properties of rocks expected in hydrocarbon reservoirs injecting oil after reactive transport has revealed previously unidentified ghost features of partially dissolved rock grains we characterize these ghost features at the nano scale using fib sem the detection of the ghost features has important implications for predicting single and two phase flow behavior especially for carbonate rocks that almost ubiquitously have intra grain micro porosity cantrell et al 2004 2 experimental methods 2 1 materials the experiments were conducted on a 3 8 mm diameter and 13 3 mm long ketton limestone rock sample from the ketton quarry rutland uk which contains 99 calcite andrew et al 2014 the ketton rock contains both inter grain macro porosity and intra grain micro porosity tanino and blunt 2012 the cored sample was first cleaned with methanol using a soxhlet extraction apparatus for 24 h followed by drying in a vacuum oven at 100 c for 24 h a solution of 5 wt sodium chloride nacl salt sigma aldrich uk in deionized water was used as the aqueous phase the reactive fluid used in this study was a pre equilibrated solution of supercritical co2 and 5 wt nacl brine which was equilibrated in a hastelloy parr reactor equipped with a stirrer at a pressure of 10 mpa and temperature of 50 c for at least 24 h a 50 wt mixture of decane sigma aldrich uk and iododecane sigma aldrich uk was selected as the oil the decane was doped with iododecane to obtain an effective x ray micro tomography contrast with brine and rock 2 2 pre treatment of the rock sample the wettability of macro pores in the cleaned ketton sample initially strongly water wet was altered to oil wet whereas the micro intra grain pores remained water wet as they did not contact oil directly this wettability state represents the surface properties of carbonate rocks expected in hydrocarbon reservoirs or depleted oil fields to achieve this the sample was placed in a cylindrical viton sleeve that was attached to metal end pieces on both sides allowing fluid to be pumped through the rock a water wet nylon membrane whatman uk with a pore diameter of 0 2 µm was placed at the base of the sample the water wet membrane was used to restrict the passage of oil non wetting phase during oil injection from the top of the sample therefore establishing a maximum oil saturation in the macro pore space while the intra grain micro pores remained water saturated the metal end pieces were fitted to peek tubing the sample assembly was loaded in a hassler type flow cell made of carbon fiber which is nearly transparent to x rays a confining pressure of 2 mpa was applied to confine the viton sleeve to avoid fluid bypassing along the walls of the sample the sample was flushed with co2 at a flow rate of 0 5 ml min for approximately 30 min to displace air this was followed by injecting deionized di water at 0 2 ml min for 30 min to remove both gaseous and dissolved co2 in water ensuring 100 water saturation a 0 01 m solution of stearic acid in decane hereafter refer to as doped oil was injected from the top of the sample at a flow rate of 0 01 ml min until the oil phase invaded the pores of the nylon filter the breakthrough of the doped oil was determined by pressure monitoring the flow rate was then increased to 0 1 ml min the use of a water wet nylon membrane and high flow rate ensured that the water was displaced completely from the macro pore space by doped oil the system was left for 24 h at ambient conditions for ageing to alter the wettability of the oil filled pore space the change in the wettability occurs due to the attraction of the negatively charged tail of stearic acid in doped oil to the positively charged calcium ions forming a layer of calcium stearate that offers strongly oil wet conditions hamouda and rezaei gomari 2006 hansen et al 2000 note that the wettability alteration occurred only in the macro pore space of the sample and the smaller intra grain micro pores that have much smaller diameter tanino and blunt 2012 than that of pores of the nylon filter remained water wet this was also confirmed by conducting an additional experiment in which the water was doped with potassium iodide 7 wt to obtain an effective x ray absorption contrast with oil decane in the pore space see fig s1 supplementary information for details the sample was then flushed with di water from the base of the sample at a flow rate 0 1 ml min for more than 200 pore volumes to ensure maximum removal of the doped oil phase the sample was then unloaded from the core holder and the sleeve and left in the vacuum oven at 100 c for 24 h for drying 2 3 experimental and x ray micro tomographic imaging protocol the wettability altered dry rock sample was loaded in the core holder using the same procedure as explained in the previous section the rock sample was imaged before fluid injection dry scans with a voxel size of 2 µm and 5 µm using a zeiss xradia 500 versa x ray micro tomography scanner with 80 kv and 7 w settings the sample was first scanned at a lower resolution with a voxel size of 5 µm at multiple locations along the height of the sample these scans were then stitched together to obtain a total height of 10 3 mm the center of which was at 6 54 mm from the base of the 13 3 mm long rock sample the total size of the complete image was 1020 1079 2055 voxels for each tomographic image we acquired a total number of 2200 2800 projections two high resolution images with a voxel size of 2 µm were acquired near the top and the base of the sample at a distance of 9 5 mm and 3 5 mm from the base of the sample respectively a total of 4000 projections were acquired for each high resolution tomographic image 2 3 1 brine saturation and pressurizing the system the sample was saturated with brine using the same procedure as used during the pre treatment of the rock sample the pressure in the brine and the confining fluid di water was then raised to 10 mpa and 12 mpa respectively a higher pressure was used to confine the viton sleeve in which the sample was mounted to avoid any fluid bypassing along the walls of the sample the temperature of the system was raised to 50 c 2 3 2 reactive flow the reactive fluid pre equilibrated supercritical co2 saturated brine was then injected from the base inlet of the sample at a flow rate of 0 1 ml min for 168 min 10 s the reactive brine was then completely replaced with a non reactive brine at a flow rate of 0 1 ml min for 24 min we acquired two images near inlet and outlet at a voxel size of 2 µm however the scan near the inlet was discarded because of the image artefacts created by sample shift during stage rotation and scanning 2 3 3 oil and brine injection after reaction oil 50 wt mixture of decane and iododecane was injected from the top outlet of the brine saturated sample at a flow rate 0 015 ml min to 0 1 ml min followed by brine injection from the base inlet of the sample at a flow rate of 0 015 ml min the sample was scanned at a voxel size of 5 µm at multiple locations along the height of the sample these scans were then stitched together to obtain a complete image of the sample two high resolution images with a voxel size of 2 µm were acquired near the top and the base of the sample at same locations as for the dry scans 2 3 4 image processing and analysis the tomograms were reconstructed using proprietary software provided by zeiss and processed using avizo 9 software unless otherwise specified the tomograms were pre processed to remove distorted outer regions the stitched image 5 µm voxel size of the dry rock sample was filtered using a non local means edge preserving filter fig s2a supplementary information this was then segmented into two phases solid and pore space using a seeded watershed algorithm based on the gray scale gradient and gray scale intensity of each voxel the images 5 µm voxel size after dissolution followed by sequential oil and brine flooding were used for the evaluation of dissolution at the larger cm scale as the brine filled pore space was not clearly distinguishable due to the presence of partially dissolved regions that have similar gray scale to that of brine we used three intensity thresholds for segmenting the brine filled pore space in seg a fig s2b the brine filled pore space represented by the darkest color in fig s2a was assigned as brine while in seg b fig s2c a part of the partially dissolved regions intermediate gray in fig s2a was also assigned as brine in seg c fig s2d all the dark and intermediate gray regions were considered as brine in a subsequent step the oil white was segmented and merged with the segmented brine to obtain the complete pore space the pore space from the segmented dry scan was also merged to assure that the pore space is completely captured the segmentation thresholds were used to investigate the effect of selecting different segmentation thresholds on the overall porosity profiles and permeability due to intermediate gradient and intensity values some of the voxels adjacent to oil were segmented as rock phase fig s3 supplementary information to correct for this artefact we used a sequential erosion and dilation of the grain phase by 2 voxels with 26 neighborhood this procedure removed the unwanted oil layer while keeping the rest of the image unchanged fig s3 the corrected image was used for post processing the porosity of a given slice j of the segmented images was obtained as 1 ϕ j c l a s s 0 c l a s s 0 c l a s s 1 where class 0 and class 1 represent the number of pixels attributed to the pore and solid phase in a given slice respectively 2 3 5 simulations for permeability and flow fields for the flow simulations we used an open source cfd software openfoam muljadi et al 2016 first the pore space was isolated from the segmented images the flow through the isolated pores was computed by solving the incompressible navier stokes equation as 2 ρ u t u u p μ 2 u 3 u 0 u 0 at grain boundaries where u is the velocity vector and p is the pressure here a boundary condition of constant pressure drop between the inlet and the outlet of the image was used and a no slip boundary condition was used on the solid walls the simulations were run until a steady state solution of the equation u t 0 was achieved these computations resulted in pressure and velocity fields as well as the permeability of the samples bijeljic et al 2013 the values of the velocity fields were corrected for the darcy velocity used in the experiments 2 3 6 estimation of thickness width of partially dissolved regions the thickness width of partially dissolved regions of rock grains after reactive flow was estimated from high resolution tomographic images voxel size of 2 µm acquired after sequential oil and brine injection fig s4 supplementary information shows an example image containing rock brine oil and partially dissolved regions here the dark intermediate gray scale represents the partially dissolved regions of rock grains indicated by the red arrow as the interface boundary between brine in the pore space and the partially dissolved regions is diffused it was difficult to measure the exact thickness of partially dissolved regions from segmented images obtained after dissolution however the injected oil white allowed the identification of the boundary of the bulk pore space occupied by oil and the partially dissolved regions unambiguously we then visually identified the boundary between partially dissolved regions and the unreacted part of the grain this boundary is marked by the dashed yellow line in fig s4 the thickness of partially dissolved regions was then measured manually between these two boundaries this is shown as t between two blue arrows indicating two boundaries using the same procedure we measured thickness at more than 400 locations for each high resolution image one near the inlet and the other near the outlet of the sample 2 4 sem and fib sem 2 4 1 sample preparation the sample after sequential oil and brine flooding was flushed with di water from the base at a flow rate of 0 3 ml min for 10 min it was then cleaned by sequential injection of toluene for 11 min methanol for 11 min and di water for 15 min at a flow rate of 0 3 ml min the sample was then dried in a vacuum oven at 100 c for 24 h the dried sample was embedded in a fluorescent epoxy resin at a pressure of 4 mpa following the procedure of shah et al 2014 at this pressure the epoxy occupied the complete pore space in the rock sample including the micro porous regions the sample was then cut and polished using a polycrystalline diamond abrasive suspension to expose an internal plane for subsequent sem and fib sem analysis the polished sample was scanned in three dimensions using a heliscan microct scanner thermo fisher scientific at a voxel size of 4 65 µm 2 4 2 scanning the fib sem was conducted using an fei quanta 3d dualbeam fib sem scanner in the electron microscopy suite of the cavendish laboratory at the university of cambridge uk a 1 µm thick platinum layer was deposited on a 15 15 µm area around the region of interest which helped to enhance the image contrast trenches were excavated around the selected location from three sides which helped to reduce shadowing effects two locations were selected for fib sem one where the rock was undissolved after reactive brine injection control location a1 and the other where the rock was partially dissolved a2 the location a2 was selected at a distance of 20 27 µm from the bulk pore space we acquired a series of 8 bit two dimensional sem images after sequential cutting using a focused ion beam that were stacked together to obtain a complete three dimensional image for the locations a1 and a2 a voxel size of 14 1 17 7 25 4 nm and 13 7 17 1 25 2 nm in x y and z directions was obtained respectively for these images we used the backscattered imaging mode of the fib sem to negate charging effects as the field of view for fib sem is limited approximately 10 18 µm we also excavated two long trenches at different locations to visualize the entire partially dissolved region near grain boundaries using sem the location a3 was selected near location a2 approximately 43 µm away the location a4 was selected at a distance of approximately 1 9 mm from a3 toward the inlet of the sample the sem scans were acquired with a pixel size of 53 9 nm and 111 5 nm at locations a3 and a4 respectively the details of these locations are provided in section 3 2 4 3 image processing for the sem and fib sem images we applied a machine learning weka segmentation approach arganda carreras et al 2017 using imagej software this segmentation approach is extremely useful for segmenting images with low signal to noise ratio for this work we applied this technique on 8 bit filtered fib sem images and unfiltered sem images the pore space of the segmented fib sem images was isolated which was then separated into individual pores and throats using a maximal ball algorithm dong and blunt 2009 raeini et al 2017 the radius of each pore was obtained by calculating the radius of the maximum inscribed sphere in that pore 2 4 4 energy dispersive x ray spectroscopy edx analysis we also performed edx analysis to identify different phases in the fib sem images fig s5a supplementary information shows two locations s1 and s2 where the edx maps were generated fig s5b shows the energy spectra at these two locations a clear peak of calcium ca at location s1 confirms the light gray regions in the sem image as the rock phase 2 5 dimensionless numbers the péclet number pe the ratio of advective to diffusive transport flux is defined as 4 p e u a v l d where uav m s is the average pore interstitial velocity ratio of the darcy velocity to the scanned porosity measured from the segmented dry scan l m is the characteristic length and d is the molecular diffusion coefficient of ca 2 in water at 25 c 7 5 10 10 m2 s menke et al 2015 2017 the scanned porosity ϕ s 0 1457 of the rock sample is considered in these calculations as the bulk flow is focused in large macro pores that are captured in the segmented dry scan the characteristic length was estimated from l π s menke et al 2015 where s is the specific surface area s as vb here as is the surface area m2 that was computed from the segmented image and vb is the bulk total volume of the scanned sample the damköhler number da the ratio of reaction rate to advective transport rate is defined as 5 d a π r u a v n where the number of moles of calcite per unit volume of rock n ρ calcite 1 ϕ total mcalcite ρ calcite is the density of pure calcite 2 71 103 kg m3 ϕ total is the total porosity measured using helium pycnometry ϕ total 0 2337 andrew et al 2014 and mcalcite is the molecular mass of calcite 0 1 kg mol the surface reaction rate of pure calcite r 8 1 10 4 mol m2 s at 50 c and 10 mpa peng et al 2015 is based on the combination of two parallel reactions 6 cac o 3 h k 1 c a 2 hc o 3 7 cac o 3 h 2 c o 3 k 2 c a 2 2 hc o 3 the calculated péclet number and damköhler number are 789 and 1 21 10 4 respectively for these calculations we used uav 1 01 10 3 m s and s 5 352 103 m 1 a high value of pe indicates that the advective transport dominates over diffusion the value of da 1 indicates that the reaction rate is slower compared to the advective transport rate 3 results and discussion 3 1 ghost features of dissolution fig 1 a shows a three dimensional image of the original dry scan 5 µm voxel size of the rock sample before dissolution fig 1b and e show two dimensional high resolution images 2 µm voxel size of the original dry scans acquired at a distance of 9 5 mm and 3 5 mm from the base inlet of the sample respectively fig 1c shows the image after dissolution at the same location as in fig 1b this image shows that the reactive brine dissolved the rock grains at many locations near grain pore boundaries this is indicated by newly formed pore space darker regions with a gray scale similar to that of brine in pores in fig 1c that was gray representing grains before dissolution fig 1b after oil injection into the sample strikingly the oil white does not invade all the newly formed pore space fig 1d it rather stays at the initial grain boundaries as in fig 1b the grain marked by a in fig 1d appears almost completely dissolved in fig 1c however the oil did not invade this location fig 1f and g show the presence of similar features near the inlet of the sample scanned at two voxel sizes 2 µm and 5 µm these observations indicate that grains that appear to be dissolved are not really completely dissolved and a skeleton of grains ghost features or ghost regions remains in place after dissolution the possible reason that these ghost features were not identified in x ray images after dissolution before oil injection is the low x ray attenuation of the remaining skeleton this can be linked to the formation of high porosity in the ghost regions resulting in a gray scale or x ray attenuation similar to that of brine in the pore space at many other locations we also observe partially dissolved grain boundaries with intermediate gray scale darker rings around grains in fig 1c and d which are expected to have intermediate porosity values larger than the porosity of the original grains we hypothesize that the pore size in the ghost regions that are water wet remain too small for oil as a non wetting fluid to invade them under the flow conditions used in this study the formation of ghost regions is expected to be controlled by diffusive flow though the overall flow in the sample is dominated by advection ketton grains have interconnected nanometer scale pore space the small size of the intra granular pores implies an initial permeability many orders of magnitude smaller than that of the macro pores precluding significant advection however they can allow the reactive fluid to diffuse and dissolve the intra grain regions the effect of diffusion controlled dissolution is expected to reduce with increasing distance from the surface of the grains to explain this further we use the diffusive damköhler number gervais and jensen 2006 8 d a d i f f k l d where k is the reaction rate constant l is the characteristic length which is approximately taken as the radius of a micro pore 10 7 m and d is the molecular diffusion coefficient for h k 1 2 5 10 4 m s using the h and cl ion pair diffusion coefficient d 5 6 10 9 m2 s the calculated value of dadiff is 4 5 indicating that the protons are likely to be consumed within a few micro pore radii however for the dissolved co2 k 2 5 5 10 7 m s and the molecular diffusion coefficient of co2 in water d 3 6 10 9 m2 s at 50 c cadogan et al 2014 the calculated value of dadiff is 1 5 10 5 if we consider the average width of the ghost region as l 6 5 10 5 m this is discussed in the forthcoming sections the value of da diff is 9 9 10 3 this value is still small indicating that the reaction rates are slow compared to the rate of diffusion and that reaction with the dissolved co2 can take place over the width of the ghost regions we expect to observe a similar behavior of dissolution and formation of partially dissolved regions after reactive flow in a water wet rock sample previous studies on wettability altered carbonate minerals treated similarly to that in the current study show that the effects of wettability alteration on reaction rates are negligible at the experimental conditions investigated anabaraonye 2017 the partially dissolved features in a water wet sample can partly be seen in images from previous studies e g qajar and arns 2016 however they were not commented on at the time further we expect that the injection of an oil phase after reactive flow similar to the procedure used in the present study can make the identification of these partially dissolved regions unambiguous it should be noted that at many grain boundaries we do not observe ghost regions or any other indication of alteration which suggests that the reactive fluid did not dissolve the rock surface e g in fig 1d marked by b to confirm that the absence of ghost features occurs at unreacted grain surfaces we conducted a drainage imbibition oil and brine injection experiment on a separate rock sample without dissolution fig s6 supplementary information shows that the oil stays in the vicinity of the unreacted grain surfaces without having ghost regions which is similar to that observed in fig 1d e g marked by b overall the identification of the ghost features after dissolution provides new insights into the dissolution behavior of a carbonate rock that has intra granular micro porosity without considering these ghost features there will be a large uncertainty in the estimation of rock and pore properties over segmentation of the pore space by considering these ghost features as the bulk pore space e g in fig 1c could result in the incorrect estimation of porosity and flow properties such as absolute and relative permeability predicted from direct simulations performed on the segmented x ray micro tomographic images qajar and arns 2017 liu and mostaghimi 2018 pereira nunes et al 2016 the uncertainty in segmentation and computed properties can further increase for lower resolution images e g fig 1g that was acquired at a voxel size of 5 µm for a comparison of the quality of segmentation for different resolution images readers are referred to singh et al 2016 3 2 nano scale imaging of ghost features to investigate the ghost features we conducted nano scale imaging using fib sem fig 2 a shows a three dimensional image of the resin filled cut and polished rock sample that was used for fib sem analysis we selected two locations in this study a1 was selected as a control location where the rock grain did not go through dissolution during reactive fluid injection this was also confirmed from the tomographic images acquired at the end of sequential oil and brine injection figure s7 supplementary information the second location a2 was selected where there were clearly visible ghost regions dark gray also see fig s7 supplementary information fig 2b c e and f show the zoomed in sections at these selected locations fig 2d and g show the images of trenches at these locations fig 2h and i show two dimensional fib sem images acquired at the control location a1 and the partially dissolved location a2 respectively fig 2j and k show the same images after segmentation we observe a significant increase in the pore space after dissolution the segmented three dimensional images of rock and pore spaces are shown in fig 3 fig 3a and b show the segmented rock and pore space at the location a1 respectively the different colors in fig 3b indicate disconnected clusters of the pore space the pores that appear disconnected are either due to their presence at the border of the image or due to low image resolution voxel size of 14 1 17 7 25 4 nm that did not capture the connectivity of the pore space at the sub nano scale the overall porosity of the sample at location a1 is 6 2 mean sd fig 3c shows the porosity profiles in each direction orientation is indicated in fig 2 we do not observe major variations in porosity in the y and z directions which indicates that the porosity along the grain periphery is similar fig 2c the porosity changes significantly along the x direction going toward the bulk pore space the variation in porosity across a grain along the x direction in fig 2c is expected for the ketton rock the ketton rock is an oolite and is composed of nearly spherical grains with concentric layers of different densities and porosities this observation is consistent with the gray scale variations across the grain observed in x ray tomographic images fig 1 the darker concentric layers are more porous these layers absorb less x rays due to lower rock density fig 3 also shows the rock structure fig 3d the pore space fig 3e and the porosity profiles in each direction fig 3f after dissolution at location a2 the porosity is almost constant only along the y direction along the z direction toward the bulk pore space fig 2f the porosity increases from approximately 45 to 65 80 this is expected as the diffusion controlled dissolution effects are more predominant near the bulk pore space where the reactive fluid flows adjacent to grain boundaries the overall porosity of partially dissolved regions at location a2 is 64 5 which is an order of magnitude larger than that at the control location a1 this substantial difference in porosity indicates that the reactive fluid has accessed the nano scale pore space and dissolved the rock significantly the pore size distribution also shows significant differences at the control and partially dissolved locations fig 3 at the control location the pore size ranges from 34 nm to 307 nm with a clear peak at 77 nm fig 3g on the other hand we observe up to an order of magnitude increase in the pore sizes of the ghost regions the ghost regions show a wide spread in the distribution fig 3h with pore sizes in the range 54 nm to 1 1 µm with a peak at 390 nm fig 3h 3 3 characterization of the thickness of ghost regions after dissolution due to limited resources the three dimensional fib sem could only cover a region of 10 to 18 µm in size for investigating the overall view of partially dissolved regions across a grain we excavated two longer trenches of 44 to 66 µm length two dimensional sem images were then acquired at these locations the location a3 was selected at approximately 43 µm from the partially dissolved location a2 along the x direction refer to fig 2f the scanned image along with its segmented image and porosity profile is shown in fig 4 a b and e the calculated porosity varies from 100 in the bulk pore space to approximately 0 8 in the grain which is unreacted the value of 0 8 porosity in the undissolved grain is in agreement with the values obtained from the fib sem volume of the control location a1 6 the partially dissolved location a2 fig 3d f was imaged at an approximate distance of 25 µm from the bulk pore space refer to fig 2f the porosity profile at a2 along the z axis fig 3f is in close agreement to the plot blue in fig 4e between 25 µm and 35 µm small variations are expected as we have observed in fig 3f in which the porosity along the x direction varies significantly over a short distance fig 4c and d show the sem image of the second longer trench at the location a4 marked in fig 2a which was selected at a distance of 1 9 mm from the location a3 toward the inlet of the sample the porosity values of the partially dissolved regions at location a4 are in the same range as that of a3 compare black and blue in fig 4e the only difference we observe is that the width of the partially dissolved region is significantly larger than at location a3 to investigate the difference in the width of partially dissolved regions with a wider field of view we also measured the thickness of these regions from two high resolution tomographic images fig 1d and f obtained after sequential oil and brine flooding near the outlet and the inlet of the sample the thickness between oil representing the bulk pore space without any partially dissolved grains and the undissolved grain surfaces refer to the inset picture of fig 5 and fig s4 in supplementary information was measured manually at more than 400 locations for each tomographic image fig 5 shows the histograms of the thickness measured near the inlet and the outlet of the sample the average thickness of partially dissolved regions near the inlet and the outlet of the sample is 75 33 µm mean sd and 55 22 µm respectively this is consistent with the width of partially dissolved regions at location a3 and a4 shown in fig 4 location a3 is closer to the outlet of the sample where dissolution effects are less compared to a4 toward the inlet near the inlet we also observe completely dissolved grain surfaces that did not have ghost features this is shown in fig s8 supplementary information in which a indicates the location where the rock did not form ghost regions after dissolution we speculate that at these locations a complete dissolution of grains occurs due to unconnected intra grain micro porosity which does not allow diffusion of the reactive fluid into the grains therefore limiting the formation of ghost regions or represent areas where all the rock had dissolved completely 3 4 overall dissolution behavior along the height of the sample fig 6 shows the porosity profile of the rock dry scan before dissolution black the porosity is uniform along the height of the sample the overall porosity of the sample before dissolution is 15 2 mean sd the porosity increased by approximately a factor of two after dissolution the overall porosity after dissolution ranges from 27 6 to 31 6 for different segmentation thresholds see figure s2 supplementary information although we observe a variation in the porosity distributions for different segmentation thresholds the overall trend of all three plots is the same red green and blue in fig 6 we observe a uniform dissolution up to 4 mm from the inlet of the sample thereafter the amount of dissolution decreases with distance from the injection point as the system potentially approaches equilibrium near the outlet top of the sample this observation is also consistent with the thickness profiles of partially dissolved ghost regions near the inlet and outlet the thickness decreases with increasing distance from the injection point indicating a decreasing amount of diffusion controlled dissolution in micro pores fig 4 and fig 5 3 5 permeability and flow fields evaluation of the effect of segmentation thresholds the permeability of the rock sample was calculated directly from the segmented pore space using the procedure described in section 2 3 5 the permeability of the dry scan before dissolution is found to be 3 2 10 12 m2 which increased significantly after dissolution however the extent of this increase is dependent on the segmentation threshold the values of permeability for seg a seg b and seg c are found to be 6 10 11 m2 8 8 10 11 m2 and 1 10 10 10 m2 respectively the permeability values vary approximately by a factor of two depending of which portion of the partially dissolved rock is segmented as pore space in seg a seg b and seg c fig 7 a shows a three dimensional image of the velocity fields in the pore space of the segmented dry scan and fig 7b d show the velocity fields in the pore space after dissolution for various segmentation thresholds seg a seg b and seg c fig 7e h show the corresponding two dimensional horizontal cross sections through the middle of the sample as the pore space increases with different segmented thresholds from seg a to seg c the pore scale velocity reduces at many locations e g location x in fig 7g and h we also observe the formation of a focused flow field with high pore scale velocities as the segmented pore space expands from seg a to seg b location y in fig 7g these observations demonstrate that the flow fields and permeability are sensitive to how the pore space is segmented we suspect that the changes in segmented pore space can significantly affect the relative permeability in the case of two phase flow simulations however these simulations are out of the scope of the current study we also note that the ketton limestone used in this study has a very well connected and open macro pore space and much larger differences may be obtained in lower permeability samples future studies can also focus on the evaluation of the experimental permeability of rock samples after dissolution which can be achieved by adopting a flow injection strategy of oil injection after dissolution similar to that presented in the current study additionally a water wet membrane can be placed at the base of the sample which can restrict the passage of oil non wetting phase during pressure controlled oil injection therefore providing a complete oil saturation in the macro pores of the rock after oil injection in this way the effective segmentation of the bulk pore space can be achieved which can result in the isolation of partially dissolved regions these partially dissolved regions can then be assigned their own permeability while calculating the overall permeability through the dissolved sample 4 conclusions in this study we have used x ray micro tomography and fib sem to investigate the dissolution behavior of an oil wet carbonate rock sample after the injection of reactive supercritical co2 saturated brine the sample was first saturated with a non reactive brine followed by injection of a reactive supercritical co2 saturated brine the reactive brine was replaced with a non reactive brine followed by sequential injection of oil and brine the sample was imaged after each injection step furthermore to characterize the dissolution features at the nano scale the sample was imaged using a fib sem our findings provide new insights into the dissolution behavior of carbonate rock grains that have intra grain micro porosity the injection of oil after dissolution revealed the presence of partially dissolved ghost regions that were difficult to visualize from the x ray micro tomographic images obtained after dissolution without the presence of a second non wetting fluid phase these ghost features are expected to occur in a diffusion limited regime although the macro pores experience an advection dominated flow regime with high péclet number and low damköhler number we expect to observe a similar behavior of rock dissolution and formation of ghost regions in water wet rock samples we computed various parameters to characterize these ghost regions the overall porosity obtained from fib sem of these ghost regions is 64 5 which is significantly larger than that of a control location without dissolution 6 2 the pore size increased approximately by an order of magnitude after dissolution the average thickness of the ghost regions decreased from 75 µm near the inlet to 55 µm near the outlet of the sample this finding is consistent with the overall dissolution behavior of the complete sample in which we observe a decreasing trend of dissolution toward the outlet in addition near the inlet we also observe that the ghost regions did not form in a few grains rather a complete dissolution of the rock occurred we show that these ghost regions have a significant impact on the porosity and permeability without considering these ghost features there will be large uncertainties in predicting the correct values of permeability and relative permeability calculated from simulations on segmented x ray micro tomographic images if it is assumed that the grains dissolve with a sharp reaction front it is likely that the change in permeability is significantly over estimated although we have examined these features in a quarry rock sample a similar behavior is expected in any carbonate rock grains containing intra granular micro porosity conflicts of interest there are no conflicts to declare data availability the sem fib sem and x ray tomographic datasets used in the current study are available in the british geological survey repository http www bgs ac uk services ngdc citeddata catalogue 31a77ab1 8f21 4a10 8540 034da0dece1e html ref singh et al 2018 any additional data that support the findings and analysis are available from the corresponding author upon request acknowledgments we gratefully acknowledge funding from the qatar carbonates and carbon storage research centre qccsrc provided jointly by qatar petroleum shell and qatar science technology park k s gratefully acknowledges tom bultreys and takashi akai for help in imaging and image processing richard langford for fib sem image acquisition and ali raeini for help in performing the flow simulations supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 09 005 appendix supplementary materials image application 1 
722,one of the major concerns of carbon capture and storage ccs projects is the prediction of the long term storage security of injected co2 when injected underground in saline aquifers or depleted oil and gas fields co2 mixes with the resident brine to form carbonic acid the carbonic acid can react with the host carbonate rock and alter the rock structure and flow properties in this study we have used x ray micro tomography and focused ion beam scanning electron microscopy fib sem techniques to investigate the dissolution behavior in wettability altered carbonate rocks at the nm to µm scale to investigate co2 storage in depleted oil fields that have oil wet or mixed wet conditions our novel procedure of injecting oil after reactive transport has revealed previously unidentified ghost regions of partially dissolved rock grains that were difficult to identify in x ray tomographic images after dissolution from single fluid phase experiments we show that these ghost regions have a significantly higher porosity and pore sizes that are an order of magnitude larger than that of unreacted grains the average thickness of the ghost regions as well as the overall rock dissolution decreases with increasing distance from the injection point during dissolution micro porous rock retains much of its original fabric this suggests that considering the solid part of these ghost regions as macro bulk pore space can result in the overestimation of porosity and permeability predicted from segmented x ray tomographic images or indeed from reactive transport models that assume a uniform sharp reaction front at the grain surface keywords reactive transport ghost features carbonate rocks carbon capture and storage ccs x ray micro tomography fib sem 1 introduction carbon capture and storage ccs is one of the proposed methods to mitigate climate change for ccs carbon dioxide co2 can be captured from various industrial units such as power plants cement factories and iron and steel making industries boot handford et al 2014 the captured co2 is pressurized and transported to a storage site and then injected underground for its geological storage in saline aquifers depleted oil and gas reservoirs or deep coal seams there are four mechanisms by which the co2 can be stored underground physical trapping under an impermeable cap rock trapping of co2 due to its dissolution in the brine phase where co2 rich brine sinks due to its higher density capillary trapping where the co2 is stored as isolated trapped clusters and mineral trapping in which the co2 can react with the host rock to form secondary carbonates xu et al 2003 krevor et al 2015 bachu et al 1994 a major challenge of ccs is the long term security of stored co2 herzog et al 2003 during co2 injection when the supercritical co2 mixes with the resident brine it forms carbonic acid the carbonic acid can react with the host rock and consequently can alter the rock structure pore geometry and related flow properties such as absolute and relative permeability qajar and arns 2017 menke et al 2015 luquot and gouze 2009 luquot et al 2014 ott and oedai 2015 this is particularly the case for carbonate rocks the extent and pattern of rock dissolution depend on many factors including ph temperature pressure conditions injection rates pore structure and chemical and physical heterogeneity el maghraby et al 2012 menke et al 2017 al khulaifi et al 2018 daccord et al 1993 recently it has been shown that the dissolution pattern is also different for single phase and two phase reactive transport ott and oedai 2015 the latter involves the simultaneous injection of co2 and reactive brine these studies demonstrate the complexity of reactive transport and dissolution processes understanding the mechanisms of these processes is therefore important to estimate the fluid flow pore occupancy and the effectiveness of ccs projects recent advances in three dimensional imaging using x ray tomography have enabled the visualization and characterization of porous media at different length scales krevor et al 2015 ott and oedai 2015 singh et al 2017a b singh et al 2016 pak et al 2015 berg et al 2013 blunt et al 2013 blunt 2017 medical x ray tomography has been applied to investigate mm to dm scale features of reactive transport and dissolution regimes in rocks with varying degrees of heterogeneity ott and oedai 2015 menke et al 2018 to investigate reactive transport at the pore scale x ray micro tomography has been used in recent experimental studies qajar and arns 2017 menke et al 2015 2017 al khulaifi et al 2018 ott et al 2012 qajar and arns 2016 however the finer features of rock dissolution from the nm to µm scale have not been studied in detail the visualization of these features and their effect on flow properties are important to understand the overall behavior of carbonate rock dissolution in this study we have used x ray micro tomography and fib sem techniques to investigate the dissolution features of wettability altered carbonate rocks at different length scales after supercritical co2 saturated reactive brine injection the wettability of these rocks was altered by the adsorption of organic acids hamouda and rezaei gomari 2006 to represent the surface properties of rocks expected in hydrocarbon reservoirs injecting oil after reactive transport has revealed previously unidentified ghost features of partially dissolved rock grains we characterize these ghost features at the nano scale using fib sem the detection of the ghost features has important implications for predicting single and two phase flow behavior especially for carbonate rocks that almost ubiquitously have intra grain micro porosity cantrell et al 2004 2 experimental methods 2 1 materials the experiments were conducted on a 3 8 mm diameter and 13 3 mm long ketton limestone rock sample from the ketton quarry rutland uk which contains 99 calcite andrew et al 2014 the ketton rock contains both inter grain macro porosity and intra grain micro porosity tanino and blunt 2012 the cored sample was first cleaned with methanol using a soxhlet extraction apparatus for 24 h followed by drying in a vacuum oven at 100 c for 24 h a solution of 5 wt sodium chloride nacl salt sigma aldrich uk in deionized water was used as the aqueous phase the reactive fluid used in this study was a pre equilibrated solution of supercritical co2 and 5 wt nacl brine which was equilibrated in a hastelloy parr reactor equipped with a stirrer at a pressure of 10 mpa and temperature of 50 c for at least 24 h a 50 wt mixture of decane sigma aldrich uk and iododecane sigma aldrich uk was selected as the oil the decane was doped with iododecane to obtain an effective x ray micro tomography contrast with brine and rock 2 2 pre treatment of the rock sample the wettability of macro pores in the cleaned ketton sample initially strongly water wet was altered to oil wet whereas the micro intra grain pores remained water wet as they did not contact oil directly this wettability state represents the surface properties of carbonate rocks expected in hydrocarbon reservoirs or depleted oil fields to achieve this the sample was placed in a cylindrical viton sleeve that was attached to metal end pieces on both sides allowing fluid to be pumped through the rock a water wet nylon membrane whatman uk with a pore diameter of 0 2 µm was placed at the base of the sample the water wet membrane was used to restrict the passage of oil non wetting phase during oil injection from the top of the sample therefore establishing a maximum oil saturation in the macro pore space while the intra grain micro pores remained water saturated the metal end pieces were fitted to peek tubing the sample assembly was loaded in a hassler type flow cell made of carbon fiber which is nearly transparent to x rays a confining pressure of 2 mpa was applied to confine the viton sleeve to avoid fluid bypassing along the walls of the sample the sample was flushed with co2 at a flow rate of 0 5 ml min for approximately 30 min to displace air this was followed by injecting deionized di water at 0 2 ml min for 30 min to remove both gaseous and dissolved co2 in water ensuring 100 water saturation a 0 01 m solution of stearic acid in decane hereafter refer to as doped oil was injected from the top of the sample at a flow rate of 0 01 ml min until the oil phase invaded the pores of the nylon filter the breakthrough of the doped oil was determined by pressure monitoring the flow rate was then increased to 0 1 ml min the use of a water wet nylon membrane and high flow rate ensured that the water was displaced completely from the macro pore space by doped oil the system was left for 24 h at ambient conditions for ageing to alter the wettability of the oil filled pore space the change in the wettability occurs due to the attraction of the negatively charged tail of stearic acid in doped oil to the positively charged calcium ions forming a layer of calcium stearate that offers strongly oil wet conditions hamouda and rezaei gomari 2006 hansen et al 2000 note that the wettability alteration occurred only in the macro pore space of the sample and the smaller intra grain micro pores that have much smaller diameter tanino and blunt 2012 than that of pores of the nylon filter remained water wet this was also confirmed by conducting an additional experiment in which the water was doped with potassium iodide 7 wt to obtain an effective x ray absorption contrast with oil decane in the pore space see fig s1 supplementary information for details the sample was then flushed with di water from the base of the sample at a flow rate 0 1 ml min for more than 200 pore volumes to ensure maximum removal of the doped oil phase the sample was then unloaded from the core holder and the sleeve and left in the vacuum oven at 100 c for 24 h for drying 2 3 experimental and x ray micro tomographic imaging protocol the wettability altered dry rock sample was loaded in the core holder using the same procedure as explained in the previous section the rock sample was imaged before fluid injection dry scans with a voxel size of 2 µm and 5 µm using a zeiss xradia 500 versa x ray micro tomography scanner with 80 kv and 7 w settings the sample was first scanned at a lower resolution with a voxel size of 5 µm at multiple locations along the height of the sample these scans were then stitched together to obtain a total height of 10 3 mm the center of which was at 6 54 mm from the base of the 13 3 mm long rock sample the total size of the complete image was 1020 1079 2055 voxels for each tomographic image we acquired a total number of 2200 2800 projections two high resolution images with a voxel size of 2 µm were acquired near the top and the base of the sample at a distance of 9 5 mm and 3 5 mm from the base of the sample respectively a total of 4000 projections were acquired for each high resolution tomographic image 2 3 1 brine saturation and pressurizing the system the sample was saturated with brine using the same procedure as used during the pre treatment of the rock sample the pressure in the brine and the confining fluid di water was then raised to 10 mpa and 12 mpa respectively a higher pressure was used to confine the viton sleeve in which the sample was mounted to avoid any fluid bypassing along the walls of the sample the temperature of the system was raised to 50 c 2 3 2 reactive flow the reactive fluid pre equilibrated supercritical co2 saturated brine was then injected from the base inlet of the sample at a flow rate of 0 1 ml min for 168 min 10 s the reactive brine was then completely replaced with a non reactive brine at a flow rate of 0 1 ml min for 24 min we acquired two images near inlet and outlet at a voxel size of 2 µm however the scan near the inlet was discarded because of the image artefacts created by sample shift during stage rotation and scanning 2 3 3 oil and brine injection after reaction oil 50 wt mixture of decane and iododecane was injected from the top outlet of the brine saturated sample at a flow rate 0 015 ml min to 0 1 ml min followed by brine injection from the base inlet of the sample at a flow rate of 0 015 ml min the sample was scanned at a voxel size of 5 µm at multiple locations along the height of the sample these scans were then stitched together to obtain a complete image of the sample two high resolution images with a voxel size of 2 µm were acquired near the top and the base of the sample at same locations as for the dry scans 2 3 4 image processing and analysis the tomograms were reconstructed using proprietary software provided by zeiss and processed using avizo 9 software unless otherwise specified the tomograms were pre processed to remove distorted outer regions the stitched image 5 µm voxel size of the dry rock sample was filtered using a non local means edge preserving filter fig s2a supplementary information this was then segmented into two phases solid and pore space using a seeded watershed algorithm based on the gray scale gradient and gray scale intensity of each voxel the images 5 µm voxel size after dissolution followed by sequential oil and brine flooding were used for the evaluation of dissolution at the larger cm scale as the brine filled pore space was not clearly distinguishable due to the presence of partially dissolved regions that have similar gray scale to that of brine we used three intensity thresholds for segmenting the brine filled pore space in seg a fig s2b the brine filled pore space represented by the darkest color in fig s2a was assigned as brine while in seg b fig s2c a part of the partially dissolved regions intermediate gray in fig s2a was also assigned as brine in seg c fig s2d all the dark and intermediate gray regions were considered as brine in a subsequent step the oil white was segmented and merged with the segmented brine to obtain the complete pore space the pore space from the segmented dry scan was also merged to assure that the pore space is completely captured the segmentation thresholds were used to investigate the effect of selecting different segmentation thresholds on the overall porosity profiles and permeability due to intermediate gradient and intensity values some of the voxels adjacent to oil were segmented as rock phase fig s3 supplementary information to correct for this artefact we used a sequential erosion and dilation of the grain phase by 2 voxels with 26 neighborhood this procedure removed the unwanted oil layer while keeping the rest of the image unchanged fig s3 the corrected image was used for post processing the porosity of a given slice j of the segmented images was obtained as 1 ϕ j c l a s s 0 c l a s s 0 c l a s s 1 where class 0 and class 1 represent the number of pixels attributed to the pore and solid phase in a given slice respectively 2 3 5 simulations for permeability and flow fields for the flow simulations we used an open source cfd software openfoam muljadi et al 2016 first the pore space was isolated from the segmented images the flow through the isolated pores was computed by solving the incompressible navier stokes equation as 2 ρ u t u u p μ 2 u 3 u 0 u 0 at grain boundaries where u is the velocity vector and p is the pressure here a boundary condition of constant pressure drop between the inlet and the outlet of the image was used and a no slip boundary condition was used on the solid walls the simulations were run until a steady state solution of the equation u t 0 was achieved these computations resulted in pressure and velocity fields as well as the permeability of the samples bijeljic et al 2013 the values of the velocity fields were corrected for the darcy velocity used in the experiments 2 3 6 estimation of thickness width of partially dissolved regions the thickness width of partially dissolved regions of rock grains after reactive flow was estimated from high resolution tomographic images voxel size of 2 µm acquired after sequential oil and brine injection fig s4 supplementary information shows an example image containing rock brine oil and partially dissolved regions here the dark intermediate gray scale represents the partially dissolved regions of rock grains indicated by the red arrow as the interface boundary between brine in the pore space and the partially dissolved regions is diffused it was difficult to measure the exact thickness of partially dissolved regions from segmented images obtained after dissolution however the injected oil white allowed the identification of the boundary of the bulk pore space occupied by oil and the partially dissolved regions unambiguously we then visually identified the boundary between partially dissolved regions and the unreacted part of the grain this boundary is marked by the dashed yellow line in fig s4 the thickness of partially dissolved regions was then measured manually between these two boundaries this is shown as t between two blue arrows indicating two boundaries using the same procedure we measured thickness at more than 400 locations for each high resolution image one near the inlet and the other near the outlet of the sample 2 4 sem and fib sem 2 4 1 sample preparation the sample after sequential oil and brine flooding was flushed with di water from the base at a flow rate of 0 3 ml min for 10 min it was then cleaned by sequential injection of toluene for 11 min methanol for 11 min and di water for 15 min at a flow rate of 0 3 ml min the sample was then dried in a vacuum oven at 100 c for 24 h the dried sample was embedded in a fluorescent epoxy resin at a pressure of 4 mpa following the procedure of shah et al 2014 at this pressure the epoxy occupied the complete pore space in the rock sample including the micro porous regions the sample was then cut and polished using a polycrystalline diamond abrasive suspension to expose an internal plane for subsequent sem and fib sem analysis the polished sample was scanned in three dimensions using a heliscan microct scanner thermo fisher scientific at a voxel size of 4 65 µm 2 4 2 scanning the fib sem was conducted using an fei quanta 3d dualbeam fib sem scanner in the electron microscopy suite of the cavendish laboratory at the university of cambridge uk a 1 µm thick platinum layer was deposited on a 15 15 µm area around the region of interest which helped to enhance the image contrast trenches were excavated around the selected location from three sides which helped to reduce shadowing effects two locations were selected for fib sem one where the rock was undissolved after reactive brine injection control location a1 and the other where the rock was partially dissolved a2 the location a2 was selected at a distance of 20 27 µm from the bulk pore space we acquired a series of 8 bit two dimensional sem images after sequential cutting using a focused ion beam that were stacked together to obtain a complete three dimensional image for the locations a1 and a2 a voxel size of 14 1 17 7 25 4 nm and 13 7 17 1 25 2 nm in x y and z directions was obtained respectively for these images we used the backscattered imaging mode of the fib sem to negate charging effects as the field of view for fib sem is limited approximately 10 18 µm we also excavated two long trenches at different locations to visualize the entire partially dissolved region near grain boundaries using sem the location a3 was selected near location a2 approximately 43 µm away the location a4 was selected at a distance of approximately 1 9 mm from a3 toward the inlet of the sample the sem scans were acquired with a pixel size of 53 9 nm and 111 5 nm at locations a3 and a4 respectively the details of these locations are provided in section 3 2 4 3 image processing for the sem and fib sem images we applied a machine learning weka segmentation approach arganda carreras et al 2017 using imagej software this segmentation approach is extremely useful for segmenting images with low signal to noise ratio for this work we applied this technique on 8 bit filtered fib sem images and unfiltered sem images the pore space of the segmented fib sem images was isolated which was then separated into individual pores and throats using a maximal ball algorithm dong and blunt 2009 raeini et al 2017 the radius of each pore was obtained by calculating the radius of the maximum inscribed sphere in that pore 2 4 4 energy dispersive x ray spectroscopy edx analysis we also performed edx analysis to identify different phases in the fib sem images fig s5a supplementary information shows two locations s1 and s2 where the edx maps were generated fig s5b shows the energy spectra at these two locations a clear peak of calcium ca at location s1 confirms the light gray regions in the sem image as the rock phase 2 5 dimensionless numbers the péclet number pe the ratio of advective to diffusive transport flux is defined as 4 p e u a v l d where uav m s is the average pore interstitial velocity ratio of the darcy velocity to the scanned porosity measured from the segmented dry scan l m is the characteristic length and d is the molecular diffusion coefficient of ca 2 in water at 25 c 7 5 10 10 m2 s menke et al 2015 2017 the scanned porosity ϕ s 0 1457 of the rock sample is considered in these calculations as the bulk flow is focused in large macro pores that are captured in the segmented dry scan the characteristic length was estimated from l π s menke et al 2015 where s is the specific surface area s as vb here as is the surface area m2 that was computed from the segmented image and vb is the bulk total volume of the scanned sample the damköhler number da the ratio of reaction rate to advective transport rate is defined as 5 d a π r u a v n where the number of moles of calcite per unit volume of rock n ρ calcite 1 ϕ total mcalcite ρ calcite is the density of pure calcite 2 71 103 kg m3 ϕ total is the total porosity measured using helium pycnometry ϕ total 0 2337 andrew et al 2014 and mcalcite is the molecular mass of calcite 0 1 kg mol the surface reaction rate of pure calcite r 8 1 10 4 mol m2 s at 50 c and 10 mpa peng et al 2015 is based on the combination of two parallel reactions 6 cac o 3 h k 1 c a 2 hc o 3 7 cac o 3 h 2 c o 3 k 2 c a 2 2 hc o 3 the calculated péclet number and damköhler number are 789 and 1 21 10 4 respectively for these calculations we used uav 1 01 10 3 m s and s 5 352 103 m 1 a high value of pe indicates that the advective transport dominates over diffusion the value of da 1 indicates that the reaction rate is slower compared to the advective transport rate 3 results and discussion 3 1 ghost features of dissolution fig 1 a shows a three dimensional image of the original dry scan 5 µm voxel size of the rock sample before dissolution fig 1b and e show two dimensional high resolution images 2 µm voxel size of the original dry scans acquired at a distance of 9 5 mm and 3 5 mm from the base inlet of the sample respectively fig 1c shows the image after dissolution at the same location as in fig 1b this image shows that the reactive brine dissolved the rock grains at many locations near grain pore boundaries this is indicated by newly formed pore space darker regions with a gray scale similar to that of brine in pores in fig 1c that was gray representing grains before dissolution fig 1b after oil injection into the sample strikingly the oil white does not invade all the newly formed pore space fig 1d it rather stays at the initial grain boundaries as in fig 1b the grain marked by a in fig 1d appears almost completely dissolved in fig 1c however the oil did not invade this location fig 1f and g show the presence of similar features near the inlet of the sample scanned at two voxel sizes 2 µm and 5 µm these observations indicate that grains that appear to be dissolved are not really completely dissolved and a skeleton of grains ghost features or ghost regions remains in place after dissolution the possible reason that these ghost features were not identified in x ray images after dissolution before oil injection is the low x ray attenuation of the remaining skeleton this can be linked to the formation of high porosity in the ghost regions resulting in a gray scale or x ray attenuation similar to that of brine in the pore space at many other locations we also observe partially dissolved grain boundaries with intermediate gray scale darker rings around grains in fig 1c and d which are expected to have intermediate porosity values larger than the porosity of the original grains we hypothesize that the pore size in the ghost regions that are water wet remain too small for oil as a non wetting fluid to invade them under the flow conditions used in this study the formation of ghost regions is expected to be controlled by diffusive flow though the overall flow in the sample is dominated by advection ketton grains have interconnected nanometer scale pore space the small size of the intra granular pores implies an initial permeability many orders of magnitude smaller than that of the macro pores precluding significant advection however they can allow the reactive fluid to diffuse and dissolve the intra grain regions the effect of diffusion controlled dissolution is expected to reduce with increasing distance from the surface of the grains to explain this further we use the diffusive damköhler number gervais and jensen 2006 8 d a d i f f k l d where k is the reaction rate constant l is the characteristic length which is approximately taken as the radius of a micro pore 10 7 m and d is the molecular diffusion coefficient for h k 1 2 5 10 4 m s using the h and cl ion pair diffusion coefficient d 5 6 10 9 m2 s the calculated value of dadiff is 4 5 indicating that the protons are likely to be consumed within a few micro pore radii however for the dissolved co2 k 2 5 5 10 7 m s and the molecular diffusion coefficient of co2 in water d 3 6 10 9 m2 s at 50 c cadogan et al 2014 the calculated value of dadiff is 1 5 10 5 if we consider the average width of the ghost region as l 6 5 10 5 m this is discussed in the forthcoming sections the value of da diff is 9 9 10 3 this value is still small indicating that the reaction rates are slow compared to the rate of diffusion and that reaction with the dissolved co2 can take place over the width of the ghost regions we expect to observe a similar behavior of dissolution and formation of partially dissolved regions after reactive flow in a water wet rock sample previous studies on wettability altered carbonate minerals treated similarly to that in the current study show that the effects of wettability alteration on reaction rates are negligible at the experimental conditions investigated anabaraonye 2017 the partially dissolved features in a water wet sample can partly be seen in images from previous studies e g qajar and arns 2016 however they were not commented on at the time further we expect that the injection of an oil phase after reactive flow similar to the procedure used in the present study can make the identification of these partially dissolved regions unambiguous it should be noted that at many grain boundaries we do not observe ghost regions or any other indication of alteration which suggests that the reactive fluid did not dissolve the rock surface e g in fig 1d marked by b to confirm that the absence of ghost features occurs at unreacted grain surfaces we conducted a drainage imbibition oil and brine injection experiment on a separate rock sample without dissolution fig s6 supplementary information shows that the oil stays in the vicinity of the unreacted grain surfaces without having ghost regions which is similar to that observed in fig 1d e g marked by b overall the identification of the ghost features after dissolution provides new insights into the dissolution behavior of a carbonate rock that has intra granular micro porosity without considering these ghost features there will be a large uncertainty in the estimation of rock and pore properties over segmentation of the pore space by considering these ghost features as the bulk pore space e g in fig 1c could result in the incorrect estimation of porosity and flow properties such as absolute and relative permeability predicted from direct simulations performed on the segmented x ray micro tomographic images qajar and arns 2017 liu and mostaghimi 2018 pereira nunes et al 2016 the uncertainty in segmentation and computed properties can further increase for lower resolution images e g fig 1g that was acquired at a voxel size of 5 µm for a comparison of the quality of segmentation for different resolution images readers are referred to singh et al 2016 3 2 nano scale imaging of ghost features to investigate the ghost features we conducted nano scale imaging using fib sem fig 2 a shows a three dimensional image of the resin filled cut and polished rock sample that was used for fib sem analysis we selected two locations in this study a1 was selected as a control location where the rock grain did not go through dissolution during reactive fluid injection this was also confirmed from the tomographic images acquired at the end of sequential oil and brine injection figure s7 supplementary information the second location a2 was selected where there were clearly visible ghost regions dark gray also see fig s7 supplementary information fig 2b c e and f show the zoomed in sections at these selected locations fig 2d and g show the images of trenches at these locations fig 2h and i show two dimensional fib sem images acquired at the control location a1 and the partially dissolved location a2 respectively fig 2j and k show the same images after segmentation we observe a significant increase in the pore space after dissolution the segmented three dimensional images of rock and pore spaces are shown in fig 3 fig 3a and b show the segmented rock and pore space at the location a1 respectively the different colors in fig 3b indicate disconnected clusters of the pore space the pores that appear disconnected are either due to their presence at the border of the image or due to low image resolution voxel size of 14 1 17 7 25 4 nm that did not capture the connectivity of the pore space at the sub nano scale the overall porosity of the sample at location a1 is 6 2 mean sd fig 3c shows the porosity profiles in each direction orientation is indicated in fig 2 we do not observe major variations in porosity in the y and z directions which indicates that the porosity along the grain periphery is similar fig 2c the porosity changes significantly along the x direction going toward the bulk pore space the variation in porosity across a grain along the x direction in fig 2c is expected for the ketton rock the ketton rock is an oolite and is composed of nearly spherical grains with concentric layers of different densities and porosities this observation is consistent with the gray scale variations across the grain observed in x ray tomographic images fig 1 the darker concentric layers are more porous these layers absorb less x rays due to lower rock density fig 3 also shows the rock structure fig 3d the pore space fig 3e and the porosity profiles in each direction fig 3f after dissolution at location a2 the porosity is almost constant only along the y direction along the z direction toward the bulk pore space fig 2f the porosity increases from approximately 45 to 65 80 this is expected as the diffusion controlled dissolution effects are more predominant near the bulk pore space where the reactive fluid flows adjacent to grain boundaries the overall porosity of partially dissolved regions at location a2 is 64 5 which is an order of magnitude larger than that at the control location a1 this substantial difference in porosity indicates that the reactive fluid has accessed the nano scale pore space and dissolved the rock significantly the pore size distribution also shows significant differences at the control and partially dissolved locations fig 3 at the control location the pore size ranges from 34 nm to 307 nm with a clear peak at 77 nm fig 3g on the other hand we observe up to an order of magnitude increase in the pore sizes of the ghost regions the ghost regions show a wide spread in the distribution fig 3h with pore sizes in the range 54 nm to 1 1 µm with a peak at 390 nm fig 3h 3 3 characterization of the thickness of ghost regions after dissolution due to limited resources the three dimensional fib sem could only cover a region of 10 to 18 µm in size for investigating the overall view of partially dissolved regions across a grain we excavated two longer trenches of 44 to 66 µm length two dimensional sem images were then acquired at these locations the location a3 was selected at approximately 43 µm from the partially dissolved location a2 along the x direction refer to fig 2f the scanned image along with its segmented image and porosity profile is shown in fig 4 a b and e the calculated porosity varies from 100 in the bulk pore space to approximately 0 8 in the grain which is unreacted the value of 0 8 porosity in the undissolved grain is in agreement with the values obtained from the fib sem volume of the control location a1 6 the partially dissolved location a2 fig 3d f was imaged at an approximate distance of 25 µm from the bulk pore space refer to fig 2f the porosity profile at a2 along the z axis fig 3f is in close agreement to the plot blue in fig 4e between 25 µm and 35 µm small variations are expected as we have observed in fig 3f in which the porosity along the x direction varies significantly over a short distance fig 4c and d show the sem image of the second longer trench at the location a4 marked in fig 2a which was selected at a distance of 1 9 mm from the location a3 toward the inlet of the sample the porosity values of the partially dissolved regions at location a4 are in the same range as that of a3 compare black and blue in fig 4e the only difference we observe is that the width of the partially dissolved region is significantly larger than at location a3 to investigate the difference in the width of partially dissolved regions with a wider field of view we also measured the thickness of these regions from two high resolution tomographic images fig 1d and f obtained after sequential oil and brine flooding near the outlet and the inlet of the sample the thickness between oil representing the bulk pore space without any partially dissolved grains and the undissolved grain surfaces refer to the inset picture of fig 5 and fig s4 in supplementary information was measured manually at more than 400 locations for each tomographic image fig 5 shows the histograms of the thickness measured near the inlet and the outlet of the sample the average thickness of partially dissolved regions near the inlet and the outlet of the sample is 75 33 µm mean sd and 55 22 µm respectively this is consistent with the width of partially dissolved regions at location a3 and a4 shown in fig 4 location a3 is closer to the outlet of the sample where dissolution effects are less compared to a4 toward the inlet near the inlet we also observe completely dissolved grain surfaces that did not have ghost features this is shown in fig s8 supplementary information in which a indicates the location where the rock did not form ghost regions after dissolution we speculate that at these locations a complete dissolution of grains occurs due to unconnected intra grain micro porosity which does not allow diffusion of the reactive fluid into the grains therefore limiting the formation of ghost regions or represent areas where all the rock had dissolved completely 3 4 overall dissolution behavior along the height of the sample fig 6 shows the porosity profile of the rock dry scan before dissolution black the porosity is uniform along the height of the sample the overall porosity of the sample before dissolution is 15 2 mean sd the porosity increased by approximately a factor of two after dissolution the overall porosity after dissolution ranges from 27 6 to 31 6 for different segmentation thresholds see figure s2 supplementary information although we observe a variation in the porosity distributions for different segmentation thresholds the overall trend of all three plots is the same red green and blue in fig 6 we observe a uniform dissolution up to 4 mm from the inlet of the sample thereafter the amount of dissolution decreases with distance from the injection point as the system potentially approaches equilibrium near the outlet top of the sample this observation is also consistent with the thickness profiles of partially dissolved ghost regions near the inlet and outlet the thickness decreases with increasing distance from the injection point indicating a decreasing amount of diffusion controlled dissolution in micro pores fig 4 and fig 5 3 5 permeability and flow fields evaluation of the effect of segmentation thresholds the permeability of the rock sample was calculated directly from the segmented pore space using the procedure described in section 2 3 5 the permeability of the dry scan before dissolution is found to be 3 2 10 12 m2 which increased significantly after dissolution however the extent of this increase is dependent on the segmentation threshold the values of permeability for seg a seg b and seg c are found to be 6 10 11 m2 8 8 10 11 m2 and 1 10 10 10 m2 respectively the permeability values vary approximately by a factor of two depending of which portion of the partially dissolved rock is segmented as pore space in seg a seg b and seg c fig 7 a shows a three dimensional image of the velocity fields in the pore space of the segmented dry scan and fig 7b d show the velocity fields in the pore space after dissolution for various segmentation thresholds seg a seg b and seg c fig 7e h show the corresponding two dimensional horizontal cross sections through the middle of the sample as the pore space increases with different segmented thresholds from seg a to seg c the pore scale velocity reduces at many locations e g location x in fig 7g and h we also observe the formation of a focused flow field with high pore scale velocities as the segmented pore space expands from seg a to seg b location y in fig 7g these observations demonstrate that the flow fields and permeability are sensitive to how the pore space is segmented we suspect that the changes in segmented pore space can significantly affect the relative permeability in the case of two phase flow simulations however these simulations are out of the scope of the current study we also note that the ketton limestone used in this study has a very well connected and open macro pore space and much larger differences may be obtained in lower permeability samples future studies can also focus on the evaluation of the experimental permeability of rock samples after dissolution which can be achieved by adopting a flow injection strategy of oil injection after dissolution similar to that presented in the current study additionally a water wet membrane can be placed at the base of the sample which can restrict the passage of oil non wetting phase during pressure controlled oil injection therefore providing a complete oil saturation in the macro pores of the rock after oil injection in this way the effective segmentation of the bulk pore space can be achieved which can result in the isolation of partially dissolved regions these partially dissolved regions can then be assigned their own permeability while calculating the overall permeability through the dissolved sample 4 conclusions in this study we have used x ray micro tomography and fib sem to investigate the dissolution behavior of an oil wet carbonate rock sample after the injection of reactive supercritical co2 saturated brine the sample was first saturated with a non reactive brine followed by injection of a reactive supercritical co2 saturated brine the reactive brine was replaced with a non reactive brine followed by sequential injection of oil and brine the sample was imaged after each injection step furthermore to characterize the dissolution features at the nano scale the sample was imaged using a fib sem our findings provide new insights into the dissolution behavior of carbonate rock grains that have intra grain micro porosity the injection of oil after dissolution revealed the presence of partially dissolved ghost regions that were difficult to visualize from the x ray micro tomographic images obtained after dissolution without the presence of a second non wetting fluid phase these ghost features are expected to occur in a diffusion limited regime although the macro pores experience an advection dominated flow regime with high péclet number and low damköhler number we expect to observe a similar behavior of rock dissolution and formation of ghost regions in water wet rock samples we computed various parameters to characterize these ghost regions the overall porosity obtained from fib sem of these ghost regions is 64 5 which is significantly larger than that of a control location without dissolution 6 2 the pore size increased approximately by an order of magnitude after dissolution the average thickness of the ghost regions decreased from 75 µm near the inlet to 55 µm near the outlet of the sample this finding is consistent with the overall dissolution behavior of the complete sample in which we observe a decreasing trend of dissolution toward the outlet in addition near the inlet we also observe that the ghost regions did not form in a few grains rather a complete dissolution of the rock occurred we show that these ghost regions have a significant impact on the porosity and permeability without considering these ghost features there will be large uncertainties in predicting the correct values of permeability and relative permeability calculated from simulations on segmented x ray micro tomographic images if it is assumed that the grains dissolve with a sharp reaction front it is likely that the change in permeability is significantly over estimated although we have examined these features in a quarry rock sample a similar behavior is expected in any carbonate rock grains containing intra granular micro porosity conflicts of interest there are no conflicts to declare data availability the sem fib sem and x ray tomographic datasets used in the current study are available in the british geological survey repository http www bgs ac uk services ngdc citeddata catalogue 31a77ab1 8f21 4a10 8540 034da0dece1e html ref singh et al 2018 any additional data that support the findings and analysis are available from the corresponding author upon request acknowledgments we gratefully acknowledge funding from the qatar carbonates and carbon storage research centre qccsrc provided jointly by qatar petroleum shell and qatar science technology park k s gratefully acknowledges tom bultreys and takashi akai for help in imaging and image processing richard langford for fib sem image acquisition and ali raeini for help in performing the flow simulations supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 09 005 appendix supplementary materials image application 1 
723,early ionic pulse during spring snowmelt can account for a significant portion of the total annual nutrient load in seasonally snow covered areas ionic pulses are a consequence of snow grain core to surface ion segregation during metamorphism a process commonly referred to as ion exclusion while numerous studies have provided quantitative measurements of this phenomenon very few process based mathematical models have been proposed for diagnostic and prognostic investigations a few early modelling attempts have been successful in capturing this process assuming transport through porous media with variable porosity however this process is represented in models in ways that misalign with the mechanistic view of the process described in the literature in this research a process based model is proposed that can simulated ionic pulses in runoff by emulating solute leaching from snow grains during melt and the subsequent vertical solute transport by meltwater through the snowpack to facilitate its use without the need for snow physics models simplified alternative methods are proposed to estimate some of the variables required by the model the model was applied to two regions and a total of 4 study sites that are subject to significantly different winter climatic and hydrological conditions comparison between observations and simulation results suggest that the model can capture well the overall snow melt runoff concentration pattern including both the timing and magnitude of the early melt ionic pulse the model enables the prediction of concentration profiles of the dry snow and liquid wet fractions within the snow matrix for the first time although there is a computational cost associated with the proposed modelling framework this study demonstrates that it can provide more detailed information about the reallocation and transport of ions through snowpacks which can ultimately be used to improve nutrient transport predictions during snowmelt keywords nutrient exports cryosphere meltwater nutrient dynamics preferential elution numerical modelling 1 introduction chemicals accumulate in snow through winter and are rapidly released to runoff during snowmelt during this accumulation process changes in temperature pressure humidity and temperature gradient cause the snow crystals to undergo metamorphosis and change their form this phenomenon causes snow fractionation pomeroy et al 2005 and densification e g bormann et al 2013 and promotes snow ion exclusion a process where solutes are segregated from the ice crystal lattice and concentrate on the exterior of snow grains colbeck 1976 davis 1991 lilbaek 2007 pomeroy et al 2005 the redistribution of ion within the snowpack cause preferential elution of some ions johannessen and henriksen 1978a which are mobilized and transported through the snowpack with the percolating meltwater the result is an early melt ionic pulse e g davis 1991 lilbæk and pomeroy 2008 which has been observed to release 50 80 of the snow ions during the first 1 3 of the melt maulé and stein 1990 this chemical load can lead to temporary acidification of streams and cause stress conditions for the aquatic biota marsh and pomeroy 1999 including fish mortality e g driscoll et al 1980 gunn and keller 1984 particularly in cases where the soil has low buffering capacity tranter et al 1988 wigington et al 1990 or the contact between meltwater and the soil matrix is limited by frost ferrier et al 1989 the timing and magnitude of the ionic pulse has been attributed to a number of different factors which harrington and bales 1998 summarized as melt rate colbeck 1981 marsh and pomeroy 1993 melt freeze cycles bales et al 1993 tsiouris et al 1985 heterogeneous flow paths bales et al 1990 harrington et al 1996 jones 1985 marsh and pomeroy 1993 metamorphic history davis 1991 hewitt et al 1991 snowpack energy fluxes suzuki 1991 williams et al 1996 solute concentration brimblecombe et al 1987 domine and thibert 1995 variable concentration of ions in the snow profile bales et al 1989 colbeck 1981 and scale effects on sampling marsh and pomeroy 1993 the ratio between solute concentrations in the eluted meltwater and in the snowcover commonly referred to as concentration factor cf johannessen and henriksen 1978a stein et al 1986 has been used to indirectly measure ion exclusion laboratory and field studies have identified values of cf ranging between 2 hodson 2006 and 39 tranter 1991 typical values vary between 2 and 6 tranter 1991 but they can reach 23 to 39 fold in cases where meltwater runs over a basal ice layer hodson 2006 numerous studies have provided quantitative evidence of these processes but fewer research has concentrated on the development of mathematical models for diagnostic and predictive purposes stein et al 1986 developed an empirical model for the estimation of cf values based on pre melt average snow concentrations and swe dynamics which has been successfully used in several studies e g costa et al 2017 lilbaek 2007 more physically based approaches have also been proposed e g bales 1991 harrington and bales 1998 hibberd 1984 harrington and bales 1998 for instance proposed to model meltwater ion pulses by simulating solute transport along with percolating water using porous medium flow theory however the model does not explicitly represent solute mass exchanges between the core and the surface of snow grains as proposed in the literature instead it uses the concept of mobile and immobile pore water to describe the movement and trapping of solutes through the snowpack another important limitation of this model for practical applications is that it requires the use of detailed models of snow physics such as snowpack bartelt and lehning 2002 lehning et al 2002a 2002b sntherm jordan 1991 or crocus brun et al 1992 and therefore it may be difficult to apply with reliable input data e g pre melt snow density hourly ground temperature and snow temperatures are various depths and more importantly these hinder its readily integration in catchment scale hydrological models in this research a modified version of the model introduced by harrington and bales 1998 is proposed with new components that provide a more explicit and physically based approach to simulate the evolution of solid and liquid in pack solute concentrations during melt to capture snowmelt runoff ionic concentrations special attention was given to limit the model inputs to the snow related variables typically provided by cold regions hydrological models i e snow water equivalent and melt rate 2 materials and methods 2 1 review of critical processes the presence of supercooled water droplets in the atmosphere leads to conditions of vapor supersaturation and the growth of snow crystals through water vapor diffusion such conditions no longer exist when snow accumulates on the ground causing metamorphic changes in ice crystals that form the snowpack harrington and bales 1998 crystal metamophosis depends on temperature and pressure gradients across the snowpack faceted grains develop in the presence of high growth rates kinetic metamorphism and rounded grains form when slow growth rates occur equilibrium metamorphism colbeck 1986 in both cases the mechanisms of crystal metamorphism impacts the redistribution of chemicals within the snow matrix during snow metamorphism where some snow grains lose mass while others gain volatile ionic solutes from the grains losing mass accumulate on the surface of the surrounding snow grains harrington and bales 1998 ions are not readily incorporated in the growing crystal lattice when refreezing occurs and impurities tend to be excluded and accumulate on the surface of snow grains hewitt et al 1991 the ice air interface within the snowpack has properties similar to liquid fletcher 1968 and it is where solutes accumulate undergo reactions and are mobilized brimblecombe and shooter 1991 chatterjee and jellinek 1971 ion exclusion rates depend on the chemical species e g davis 1991 pomeroy et al 2005 and lead to preferential elution this is caused by differences in diffusion rates and on the solubility of ions in ice harrington and bales 1998 processes that are affected by the hydrated radii of ions and by their ability to form hydrogen bonds lilbæk and pomeroy 2008 freeze thaw cycles accelerate metamorphism and ice crystals undergo successive readjustments that change their orientation harrington and bales 1998 this also promoting the segregation of ions during this process capillary pressure causes the formation of grain clusters colbeck 1979 containing liquid water in both inter cluster veins and on films around snow grains harrington and bales 1998 thus increasing the mobility of ions as meltwater begins to percolate the snowpack during snowmelt preferential flow pf in melting snowpack can occur due to flow instabilities at the leading edge of the wetting front e g parlange 1974 pf forms when the vertically percolating meltwater is subject to a ponding process on a less impermeable snowpack layer boundary katsushima et al 2013 wakahama 1963 the ponding process ceases when the water entry value of capillary pressure threshold value is reached and water is allowed to enter the underlying snow layer dry pores the effect of pf on melt rates has been examined in experiments using dye traces gerdel 1954 marsh and woo 1984 and in numerical models leroux and pomeroy 2017 but its influence on the release on snow ions is less understood marsh and pomeroy 1999 observed that solute concentrations were largest in the snowpack low flow areas due to dilution effects however the snowpack highest flow areas carried the largest mass load 2 1 1 mathematical framework brimblecombe et al 1987 examined ice and meltwater in laboratory experiments and concluded that snow can be modelled as a two compartment mixture of concentrated snow surface and diluted snow grain interior other researchers followed and extended this approach e g bales 1991 harrington and bales 1998 the model proposed in this paper named as pulse was developed based on the harrington and bales 1998 paradigm which was modified herein fig 1 shows the conceptual model used to simulate the snowpack solid phase which is divided in the snow grain core and snow grain surface and the mobile phase although a liquid film is generally present around snow grains throughout seasons before snowmelt the liquid phase in snow can be considered negligible for the purposes of this model the mass balance for the solid phase includes the snow grain core csc eq 1 and the snow grain surface css eq 2 1 θ s c c s c t c s c θ s c q ρ s ρ l where ρs and ρl are snow and liquid water densities θsc is the volume fraction occupied by the snowpack solid phase and q is the melt rate 2 θ s s c s s t c s c θ s c q ρ s ρ l e θ s s where θss is the volume fraction occupied by the snowpack liquid phase and e is the solute mass exchange between the surface of the snow grain and the mobile liquid phase it is assumed that the snow grain core mass eq 1 decreases via a first order exponential decay process that is also controlled by the meltrate q this considers that the concentrations in the snow grains decrease as they melt which means also that the snow concentration radial gradient decreases exponentially towards the center of the snow grain the total mass in the snow grain surface eq 2 depends on the snow grain core mass that has melted and on exchanges with the mobile liquid phase the exchange of mass between the snow grains surface and the moving liquid mobile water e is described as 3 e α c s s c m where css and cm are the concentrations at the surface of the snow grains ss and in meltwater m and α is a parameter to account for ion exclusion although the ion exclusion process is known to depend on the ionic species variations in field observations suggest additional controls that are not entirely understood e g johannessen et al 1977 johannessen and henriksen 1978b according to brimblecombe et al 1985 some of these controls can be the inhomogeneity of the snowpack the pre met ion concentration in the snowpack and the history of the melting and refreezing fresh vs weathered snow surfaces anion also show more variation than cations as a result presently the parameter α is obtained through calibration but its characterization should be revised in the future as research sheds more light into the ion exclusion mechanism the simulation of the vertical movement of the mobile solute phase through the snowpack during melt is adapted from the approach used by harrington and bales 1998 which extends from the work by bear and bachmat 1990 on the modelling of transport through porous media in our model the porosity of the snowpack is set to change linearly as a function of the hourly or daily depending on the data availability snowmelt rate to avoid the need for complex snow physics models in other words the solid phase fraction decreases as it is converted into the liquid fraction at a speed that is controlled by the melt rate this ensures mass conservation between the liquid and solid phases throughout the snowmelt process and that the effect of daily variabilities in the melt rate often occurring at the onset of melt and potentially causing melting and refreezing could be translated into the temporal distribution of the liquid snow fractions as snow melts the vertical movement of liquid water through the snowpack is modelled as 4 θ m c m t θ m v c m θ m d c m e θ s s where v c m describes advection v is the interstitial flow velocity used as a proxy for the wetting front d is the diffusion coefficient d cm describes diffusion and e represents the mass exchange between the percolating meltwater liquid phase and the snow grain surface as it melts eq 3 in the horizontal averaged domain the advection and diffusion terms can be written as 5 θ m v c m θ m v c m z 6 θ m d c m 2 θ m d c m z 2 the interstitial velocity is described as 7 v q θ m where q is the snowmelt rate to calculate the dispersion coefficient d a simple approach often adopted in subsurface hydrology is used dispersivity d is taken as a calibrated coefficient parameter to relate interstitial velocity v to d charbeneau et al 1992 8 d d v the effect of pf is not simulated explicitly but it is indirectly accounted for by using interstitial flow velocity in the computation of the wetting front eq 7 in spite of this the model aims primarily at providing numerical laterally integrated 1d vertical snowpack response simulations and is not purposed to examine the effect of pf on the release on snow ions to meltwater the model requires pre melt snow depth and solute concentration values along with the time series of melt rate the outputs of the model are the evolution of the concentration vertical profiles for the dry core and surface of snow grains and wet snowpack portions the meltwater runoff concentrations correspond to the concentrations of the percolating meltwater wet snowpack portion at the bottom of the snowpack fig 2 shows the typical dynamics generated by the proposed model framework which agrees with concentrations profiles measured by davis et al 1995 in a series of controlled experiments on in flux through snowpack and aligns with the literature on snow chemistry during melt reported in section 2 1 2 1 2 numerical integration an implicit numerical solution based on the crank nicolson scheme second order method in time was adopted to integrate the solution of the advection dispersion equation eq 4 for the mobile phase the regions occupied by the solid and liquid phases are different and change as melt progresses to account for the effect of snowmelt on the snow depth and on the movement of the wetting front as depicted in fig 2 in other words the active wet layers of the snowpack see fig 1 are constrained by the upper snow layer which moves downwards as snow melts at the surface of the snowpack and the position of the wetting front which progressively moves downwards as meltwater percolates through the snow matrix see fig 2 the wetting front separates two regions an upper wet region and a lower dry region the transport of solutes by the snowpack liquid phase is thus limited by these two moving boundaries and is affected by varying upper and lower boundary conditions bc and by changes occurring within the wetting front is a no flow and no solute transport boundary lower boundary as melt occurs the upper boundary moves downwards and the mass remaining in the solid phase is transferred into the mobile liquid phase see eq 3 to ensure mass conservation only advection is allowed at the moving wetting front layer for this purpose an upwind scheme forward euler is used to guarantee no exchange fluxes advective or dispersive between the wetting front and the contiguous downstream layer which remains dry and immobile i e the snow is assumed completely dry downward of the wetting front thus the advection dispersion equation is only solved for the wet active region which is limited by the upper and lower boundaries layers see fig 2 the no flux condition results in the development of an ion load front as ions accumulate at the wetting front the intensity of this magnification mechanism depends on the balance between mixing and dilution processes which is affected by the intestinal flow velocity and ultimately controlled by the melt rate it is assumed that water and solutes in the solid phase are gradually converted into the mobile phase when water melts at each layer at a speed that is likewise controlled by the melt rate during this process it is considered that snow grain core solutes are excluded to the surface of the snow grains parameter e in eq 3 and subsequently gradually mixed with the percolating liquid mobile water eq 4 to maximize computational efficiency without compromising numerical stability and accuracy the model allows for different space grid sizes see fig 1 and performs dynamic time steps that comply with a pre defined maximum courant number c 1 obeying the courant condition is critical to guarantee both numerical stability and accuracy for the solution of the advection term note that unsteady interstitial velocities which control the advection term in eq 4 arise from both variable melt rates and mobile phase fractions i e porosity a maximum time step of one hour is also enforced to ensure sufficient temporal resolution during the development and dissipation phases of both the wetting and ion load fronts 2 1 3 model characteristics and assumptions in the model proposed by harrington and bales 1998 the initial ratio between snow grain core and snow grain surface concentrations is prescribed contrariwise in the proposed model only the initial average concentration of the snow grain core is defined which is set equal to the average pre melt snowpack concentrations as melt starts solute mass is transferred from the ice grain core to the ice grain surface and finally to the mobile phase as a result the proposed model framework does not require considerations or input data for snow grain surface solute concentrations that effect is encapsulated in the parameters defining the exchange rate e although in reality ion exclusion processes occur throughout the winter as snow metamorphism progresses and not necessarily only during the melt period such simplification avoids the need for pre melt snow grain core and surface solute concentrations ratios which would be difficult to measure and would most likely require additional model parameterizations extending the model to annual or inter annual simulations in the future could enable representing ion exclusion mechanisms for the entire winter period therefore arguably representing the process more realistically in the proposed framework the solute in the solid phase is thus assumed as initially being entirely in the snow grain core and as it melts being first segregated into the surface of the wet snow grain it is only after progressively transferred into the mobile phase thus the model results lead to concentrations in the solid phase decreasing behind the wetting front due to mass being gradually mixed and transported vertically with the liquid mobile phase the liquid and solid fractions θl and θs vary between 0 and 1 and are calculated through a simple linear function that is controlled by the meltrate and swe θ l 0 and θ s 1 at swe0 and θ l 1 and θ s 0 at swe f i n a l 0 the model simulates three wave fronts namely two fast and one slow the fast moving ones are the snowpack wetting and ion load fronts which are largely controlled by the interstitial velocity the slow moving wave is the melt front which determines the position of the upper boundary of the snowpack and is controlled by the melt of snow at the surface of the snowpack see fig 2 2 1 4 model applications the model was tested using four independent datasets from two distinct study areas fig 3 one dataset was collected from the emerald lake watershed in sierra nevada california usa harrington and bales 1998 tonnessen 1991 and the other three were measured at different sites in the trail valley creek basin north of inuvik northwest territories canada marsh and pomeroy 1996 1999 pomeroy et al 1993 emerald lake is located in sequoia national park and has a catchment area of 1 2 km2 this watershed has little human disturbance but is exposed to air pollution from upwind major urban and agricultural areas tonnessen 1991 the site was subject to an experiment involving the release and monitoring of chloride from a melting snowpack the average chloride cl concentration in the snowpack was measured at 1 5 μeq l at the onset of melt the trail valley creek basin is located 40 km north west of inuvik the three study sites monitored in this basin were located along a transect perpendicular to the creek channel the first site is defined as open tundra representing 70 of the total basin the second site is defined as shrub transition representing 22 of the total basin and the third site is characterised as drift valley representing 8 of the total area the reader is referred to the suggested literature for more information about the sites and respective field monitoring programs these two independent case studies comprising a total of 4 monitored sites provide a fairly wide range of hydrological and geochemical conditions i e snow depth concentrations and melt rates to test the proposed model fig 4 shows the cumulative melt rate measured in the two case study areas these are snowpack discharge volumes calculated from daily lysimeter flow data in the case of the emerald lake watershed and from hourly snow water equivalent swe data in the case of the trail valley creek basin unfortunately these are lumped snowpack discharge volumes and therefore the effect of pf on the temporal and spatial dynamics of the discharge and melt process cannot be accessed these observations point to very different snowmelt conditions between the two study areas on the one hand while the pre melt snow depth is just over 60 cm at the emerald lake watershed site the values recorded at the different sites at trail valley creek basin vary between 45 cm open tundra site and almost 200 cm drift valley site the one shown in fig 4 corresponds to the remaining site the shrub transition site which has an intermediate snow depth on the other hand the melt period varies between 13 4 and 36 days at trail valley creek but it takes more than 4 months at emerald lake for the snow to completely disintegrate and disappear table 1 shows the main characteristics of the numerical model setup including information about the initial conditions and the calibration and validation procedures as expected the initial conditions are very different depending on the site this is important to test the performance of the model over a broad range of conditions pre melt snow depth and no3 concentrations and duration of the melt period the thickness of the vertical layers used to discretize the model is also different depending on the site as a compromise between spatial resolution and computational demand the model was calibrated for two case sites through a monte carlo mc simulation framework based on 500 model realizations in order to examine both parameter spaces and parameter correlations the mc sampling procedure was deployed for the two model parameters together through parameter combinations the remaining two sites were used for validation purposes the performance of the model was evaluated at hourly time steps using the nash sutcliffe efficiency nse root mean square error rmse and model bias mb statistical metrics monte carlo simulations were performed for one site at each case study area to ensure that the parameter sets reflect local climate hydrological and geochemical conditions in the case of the emerald lake watershed case study the model is compared with observations and the empirical and process based model results presented by harrington and bales 1998 in the trail valley creek case study the model results were compared with observations for the different sites for this study region the best parameter sets were determined for the site with an intermediate snow cover depth shrub transition the model was subsequently tested for the remaining two sites using the same calibrated parameter combination 3 results 3 1 emerald lake watershed fig 5 shows the performance of the model using different parameter sets obtained from the monte carlo simulations results show that the numerical problem is moderately stiff in the sense that the solution generally varies slowly but has nearby solutions that vary rapidly for different parameter combinations it is somewhat sensitive and stiff to α i e solid phase snow grain surface to liquid phase exchange but nearly insensitive to d dispersivity the best model fit is obtained for different parameters depending on the statistics measure used which is not surprising given the nature of the different metrics while the best nse 0 596 and rmse 0 325 μ e q l 2 values are obtained using the parameter set α 10 3 and a d 5 96 10 2 mm 2 the best mb value 0 01 is obtained using α 1 02 10 2 and a d 4 50 10 1 mm 2 which are both one order of magnitude higher using the best parameter set obtained using both the nse and rmse based calibrations fig 6 shows the model results computed for the snowpack solid and mobile phases and compares the simulated meltwater cf values against observations the results obtained by harrington and bales 1998 and using empirical formulae are also included for comparison purposes unlike the trail valley creek basin model in section 3 1 1 no additional data was available for model validation in addition to calibration with the main objective this model application being the comparison of the performance of the model proposed to existing ones results suggest that the model can capture fairly well the timing middle and lower panel and magnitude lower panel of the ionic pulse nse 0 596 it shows some improvements in relation to the empirical and harrington and bales 1998 model results particularly during the initial melt period however the model seems to perform slightly worse at the end of the snowmelt season an issue that is discussed in section 4 discussion 3 1 1 trail valley creek basin as discussed previously in section 2 1 4 the calibration of the model was performed using the shrub transition site which is the intermediate site in terms of pre melt snow depth for the remaining sites the model was run using the best parameter combination identified for the calibrated site validation of the model fig 7 shows the model performance for different parameter combinations obtained by the monte carlo simulation approach as in the previous model application different best parameter sets were obtained depending on the statistical measure of fit used while the best model performance was obtained using α 1 26 10 2 and a d 4 95 10 1 mm 2 for both the nse 0 600 and rmse 0 325 μ eq l 2 metrics the best fit using mb 1 was obtained using α 1 36 10 1 and a d 2 70 10 1 mm 2 the best parameter set obtained for nse and rmse is also one order of magnitude higher for both parameters than that obtained for the emerald lake site while the reason for this difference is not entirely understood previous research has observed that ion exclusion rates decrease with increasing snowmelt rates e g stein et al 1986 which is in alignment with the ion exclusion parameter α being smaller for emerald lake watershed higher snowmelt rates see fig 4 when compared to the trail valley creek basin smaller snowmelt rates as in the emerald lake watershed case the model was also here run for all sites within the trail valley creek open tundra shrub transition and drift valley using the best parameter fit obtained using nse and rmse fig 8 results show a good agreement between observed and modelled meltwater concentrations for all sites the model can capture well both the timing and magnitude of the peak i e ionic pulse as well as the subsequent concentration evolution rse 0 6 it should be noted that the timing of the observed and modelled peak concentrations is different between sites and the model can capture these differences compare the concentration peaks in the lower panels of figs 6 and 8 a b and c this is related to the time required for the mobile phase and wetting front to move through the snow and reach the bottom of the snowpack e g the thickness of the snowcover is higher for the drift valley site and therefore the ion pulse arrives latter 4 discussion 4 1 is the model behaviour in agreement with the literature research suggests that snowpack ion exclusion processes occurs due to solutes being subject to segregation from the ice crystal lattice to the surface of the snow grain e g colbeck 1976 davis 1991 harrington and bales 1998 advanced that such phenomenon occurs during snow metamorphism as volatile ionic solutes from the grains losing mass accumulate on the surface of the surrounding gaining grains in the proposed model this process is represented through solute exchange estimates between the core and surface of ice grains eq 3 this leads to the development of an ion load front during the initial phase of melt a process that is caused by the mixing of the percolating meltwater vertically moving through the snow during snowmelt with ions located and readily available at the surface of the snow grains within the snow matrix see fig 2 the model can simulate such behaviour with concentration of the solid phase snow grain core and surface gradually decreasing as melt progresses upper panels of figs 6 and 8 and the concentrations in the mobile phase gradually increasing as the load front moves through the snowpack which causes the ion pulse commonly observed in snowmelt runoff the concentrations gradually decrease in the solid phases as it melts and the ions are incorporated into the mobile liquid phase 4 2 vertical concentration profiles solid and liquid phases fig 9 shows two snapshots of the vertical profiles of the simulated ionic concentrations of the solid and mobile phases before upper panel and after lower panel the ion load front has reached the bottom of the snowpack these simulated concentration profiles agree with the profiles measured by davis et al 1995 in a series of experiments on in flux through shallow snowpacks performed under controlled conditions results show the concentration of the solid immobile phase decreases as snow melt progresses and solute mass is carried by the liquid mobile phase upper panel as liquid water percolates through the snowpack it accumulates ions after removing them from the surface of snow grains this is noticeable in the upper panel by the significantly higher concentrations at the ion load front 8 5 μ meq l 1 when compared to the solid phase 1 7 μ meq l 1 after the ion load front has reached the snowpack bottom which means that snowmelt runoff has also initiated it can be noticed that the snow depth and concentration of the solid phase have significantly decreased likewise the concentration of the liquid phase is much smaller because a significant portion of the solute in the snow has already been carried out by initial flush i e ion load front 4 3 ion exclusion mechanisms and parameter α in the emerald lake watershed site the harrington and bales model shows a slightly better performance at the very end of the snowmelt season fig 6 the difference shows that meltwater concentrations do not tend to zero as predicted by our model this suggests an incomplete depletion of ions from the solid snow phase which points at a residual ionic concentration at the snow grain cores or a dynamic ion exclusion mechanism that cannot be entirely characterized via a calibrated fixed ion exclusion coefficient α this reinforces the need for a better characterization of this parameter as highlighted in section 2 1 1 research suggests that the rate at which ions are excluded from the ice lattice depends on the chemical species e g pomeroy et al 2005 1993 for they may have different diffusion rates and solubility in ice harrington and bales 1998 this is accounted in the model through an exchange rate e between the snow grain surface and the mobile phase that is controlled by concentration differences between the two phases and a calibrated parameter α although this is a simplification of the physical and chemical migration mechanisms involved it allows capturing the overall snow grain surface to mobile phase ion release phenomenon future development efforts should include the improvement of such simplification 4 4 concentration pulses in meltwater patterns and controls results suggest also that the timing and magnitude of the ionic pulse depend mainly on the depth of the snowpack on the melting rate and on the pre melt snow concentration these findings concur with field evidence such as reported in colbeck 1981 and marsh and pomeroy 1993 which highlight the importance of the melt rate and in brimblecombe et al 1987 and domine and thibert 1995 which emphasize the effect of pre melt snow solute concentrations the melt rate affects the porosity of the snowpack and therefore controls the interstitial flow velocity field this in turn determining the speed of the ion load front the melt rates and overall snowmelt dynamics can be significantly affected by pf e g hirashima et al 2017 leroux and pomeroy 2017 which can also potentially influence the ion transport process this modelling framework does not account explicitly for this transport pathway being only included through a rather simplistic approach based on the interstitial flow velocity eq 7 therefore the model is purposed primarily for simulation of laterally integrated 1d vertical snowpack responses and its extension to the 2d or 3d domain and to include pf should be addressed in future fig 10 shows the simulated liquid mobile and solid immobile fractions as calculated from a linear function controlled by the melt rate these results point at nonlinearities in melt and porosity dynamics caused by varying atmospheric conditions during melt the snow cover depth and melt rate play a critical role in the speed of the ion load front and thus on the timing of ionic pulse in runoff to further investigate the importance of such effect fig 11 shows the results obtained for the emerald lake watershed case when forcing the model with different snowmelt temporal distributions namely a actual recorded melt rate time series b constant averaged melt rate and c normal and d beta probability distribution functions fitted to the melt rate time series the normal probability distribution function was fitted to the melt rate data with a mean and standard deviation of 1 2 and 1 5 and the beta distribution function with shape parameters of 3 and 2 results confirm the importance of accurate melt rate evolutions for adequately prediction of the magnitude and even more notably of the timing of the ionic pulse i e compare the timing and magnitude of peaks for run 1 and run 2 complementary runs using different approximated normal and beta curves showed that the model predictions improved significantly as these approximations became closer to the real observed pattern improvements were observed for the overall meltwater concentration temporal evolution including the timing and magnitude of the peaks 4 5 advantages and limitations and integration into hydrological models some of the advantages of the proposed model when compared to previous modelling efforts are that 1 the ion exclusion processes is represented in a more physically based manner and is better aligned with field lab evidences e g the simulated concentration profiles in fig 9 compared with observations by davis et al 1995 2 it shows to capture the timing and peak of meltwater concentrations more accurately e g fig 6 and 3 it does not require a snow physics model to generate forcing data since that can be obtained directly from both observations pre melt concentrations and hydrological models that are suitable for cold regions swe and melt rate temporal dynamics the model is currently being integrated in the cold regions hydrological model crhm pomeroy et al 2007 as part of a series of water quality modules currently under developed some of the limitations of the proposed model are that it does not include the effect of pf on solute transport which may be potentially relevant in some cases particularly at small sales see section 2 1 and that despite showing better performances see fig 6 it is more computationally expensive than the analytical model proposed by stein et al 1986 the computational time increases in conditions of deep snowpacks fast melt rates and detailed model vertical resolutions high number of vertical layers see fig 1 5 conclusions the release of chemicals from the snowpack is complex it is influenced by several processes including snow metamorphism ion exclusion preferential elution and advection diffusion of ions along with the percolating meltwater one important combined effect of these processes is the segregation of ions from the core of snow grains to their surface and their rapid mixing with the first meltwater flush several field studies have shown indirect evidence for this phenomenon however research efforts for providing physically based simulations of these processes has been more limited in this research a numerical model was developed to simulate solute dynamics within the wet and dry phases of the snow matrix alongside with the temporal dynamics of meltwater concentrations the mathematical model developed was formulated based on the current understanding of the different release migration and transport mechanisms involved although some processes were simplified to compromise between computational demand and practical use the model was tested for 2 independent study areas a total of 4 sites comprising a wide range of pre melt snowpack depths and concentrations and of melt rate dynamics results showed that the model can accurately simulate meltwater concentration dynamics at the bottom of the snowpack runoff including the timing and magnitude of ionic pulses for various landscape and climatic conditions simulations suggest that snow melt rates at high temporal resolution e g hourly are particularly important for the adequate prediction of the timing and magnitude of concentration peaks concentration profiles of the dry snow and liquid wet fractions have been simulated for the first time with the results matching well with previous laboratory measurements although there is a computational cost associated with the proposed model particularly in conditions of deep snowpacks fast melt rates and detailed model vertical resolution i e snow layers these results show a good predictive capacity for different landscape and climate scenarios future research work includes 1 the modular coupling with long term catchment scale nutrient models for inter annual nutrient export simulations e g crhm 2 the development of model algorithms to estimate the ion exclusion coefficient α from the chemical properties of the ions e g ability to establish hydrogen bonds and solubility in ice and 3 the modification of the model to include the effect of preferential flow a process that affects the ability of meltwater to remove and mix with snow ions during snowmelt acknowledgments the authors would like to thank the global water futures programme the canada excellence research chair in water security the canada research chair in water resources and climate change the canadian water network and the natural sciences and engineering research council nserc through its create in water security and discovery grants 463960 2015 for financial support 
723,early ionic pulse during spring snowmelt can account for a significant portion of the total annual nutrient load in seasonally snow covered areas ionic pulses are a consequence of snow grain core to surface ion segregation during metamorphism a process commonly referred to as ion exclusion while numerous studies have provided quantitative measurements of this phenomenon very few process based mathematical models have been proposed for diagnostic and prognostic investigations a few early modelling attempts have been successful in capturing this process assuming transport through porous media with variable porosity however this process is represented in models in ways that misalign with the mechanistic view of the process described in the literature in this research a process based model is proposed that can simulated ionic pulses in runoff by emulating solute leaching from snow grains during melt and the subsequent vertical solute transport by meltwater through the snowpack to facilitate its use without the need for snow physics models simplified alternative methods are proposed to estimate some of the variables required by the model the model was applied to two regions and a total of 4 study sites that are subject to significantly different winter climatic and hydrological conditions comparison between observations and simulation results suggest that the model can capture well the overall snow melt runoff concentration pattern including both the timing and magnitude of the early melt ionic pulse the model enables the prediction of concentration profiles of the dry snow and liquid wet fractions within the snow matrix for the first time although there is a computational cost associated with the proposed modelling framework this study demonstrates that it can provide more detailed information about the reallocation and transport of ions through snowpacks which can ultimately be used to improve nutrient transport predictions during snowmelt keywords nutrient exports cryosphere meltwater nutrient dynamics preferential elution numerical modelling 1 introduction chemicals accumulate in snow through winter and are rapidly released to runoff during snowmelt during this accumulation process changes in temperature pressure humidity and temperature gradient cause the snow crystals to undergo metamorphosis and change their form this phenomenon causes snow fractionation pomeroy et al 2005 and densification e g bormann et al 2013 and promotes snow ion exclusion a process where solutes are segregated from the ice crystal lattice and concentrate on the exterior of snow grains colbeck 1976 davis 1991 lilbaek 2007 pomeroy et al 2005 the redistribution of ion within the snowpack cause preferential elution of some ions johannessen and henriksen 1978a which are mobilized and transported through the snowpack with the percolating meltwater the result is an early melt ionic pulse e g davis 1991 lilbæk and pomeroy 2008 which has been observed to release 50 80 of the snow ions during the first 1 3 of the melt maulé and stein 1990 this chemical load can lead to temporary acidification of streams and cause stress conditions for the aquatic biota marsh and pomeroy 1999 including fish mortality e g driscoll et al 1980 gunn and keller 1984 particularly in cases where the soil has low buffering capacity tranter et al 1988 wigington et al 1990 or the contact between meltwater and the soil matrix is limited by frost ferrier et al 1989 the timing and magnitude of the ionic pulse has been attributed to a number of different factors which harrington and bales 1998 summarized as melt rate colbeck 1981 marsh and pomeroy 1993 melt freeze cycles bales et al 1993 tsiouris et al 1985 heterogeneous flow paths bales et al 1990 harrington et al 1996 jones 1985 marsh and pomeroy 1993 metamorphic history davis 1991 hewitt et al 1991 snowpack energy fluxes suzuki 1991 williams et al 1996 solute concentration brimblecombe et al 1987 domine and thibert 1995 variable concentration of ions in the snow profile bales et al 1989 colbeck 1981 and scale effects on sampling marsh and pomeroy 1993 the ratio between solute concentrations in the eluted meltwater and in the snowcover commonly referred to as concentration factor cf johannessen and henriksen 1978a stein et al 1986 has been used to indirectly measure ion exclusion laboratory and field studies have identified values of cf ranging between 2 hodson 2006 and 39 tranter 1991 typical values vary between 2 and 6 tranter 1991 but they can reach 23 to 39 fold in cases where meltwater runs over a basal ice layer hodson 2006 numerous studies have provided quantitative evidence of these processes but fewer research has concentrated on the development of mathematical models for diagnostic and predictive purposes stein et al 1986 developed an empirical model for the estimation of cf values based on pre melt average snow concentrations and swe dynamics which has been successfully used in several studies e g costa et al 2017 lilbaek 2007 more physically based approaches have also been proposed e g bales 1991 harrington and bales 1998 hibberd 1984 harrington and bales 1998 for instance proposed to model meltwater ion pulses by simulating solute transport along with percolating water using porous medium flow theory however the model does not explicitly represent solute mass exchanges between the core and the surface of snow grains as proposed in the literature instead it uses the concept of mobile and immobile pore water to describe the movement and trapping of solutes through the snowpack another important limitation of this model for practical applications is that it requires the use of detailed models of snow physics such as snowpack bartelt and lehning 2002 lehning et al 2002a 2002b sntherm jordan 1991 or crocus brun et al 1992 and therefore it may be difficult to apply with reliable input data e g pre melt snow density hourly ground temperature and snow temperatures are various depths and more importantly these hinder its readily integration in catchment scale hydrological models in this research a modified version of the model introduced by harrington and bales 1998 is proposed with new components that provide a more explicit and physically based approach to simulate the evolution of solid and liquid in pack solute concentrations during melt to capture snowmelt runoff ionic concentrations special attention was given to limit the model inputs to the snow related variables typically provided by cold regions hydrological models i e snow water equivalent and melt rate 2 materials and methods 2 1 review of critical processes the presence of supercooled water droplets in the atmosphere leads to conditions of vapor supersaturation and the growth of snow crystals through water vapor diffusion such conditions no longer exist when snow accumulates on the ground causing metamorphic changes in ice crystals that form the snowpack harrington and bales 1998 crystal metamophosis depends on temperature and pressure gradients across the snowpack faceted grains develop in the presence of high growth rates kinetic metamorphism and rounded grains form when slow growth rates occur equilibrium metamorphism colbeck 1986 in both cases the mechanisms of crystal metamorphism impacts the redistribution of chemicals within the snow matrix during snow metamorphism where some snow grains lose mass while others gain volatile ionic solutes from the grains losing mass accumulate on the surface of the surrounding snow grains harrington and bales 1998 ions are not readily incorporated in the growing crystal lattice when refreezing occurs and impurities tend to be excluded and accumulate on the surface of snow grains hewitt et al 1991 the ice air interface within the snowpack has properties similar to liquid fletcher 1968 and it is where solutes accumulate undergo reactions and are mobilized brimblecombe and shooter 1991 chatterjee and jellinek 1971 ion exclusion rates depend on the chemical species e g davis 1991 pomeroy et al 2005 and lead to preferential elution this is caused by differences in diffusion rates and on the solubility of ions in ice harrington and bales 1998 processes that are affected by the hydrated radii of ions and by their ability to form hydrogen bonds lilbæk and pomeroy 2008 freeze thaw cycles accelerate metamorphism and ice crystals undergo successive readjustments that change their orientation harrington and bales 1998 this also promoting the segregation of ions during this process capillary pressure causes the formation of grain clusters colbeck 1979 containing liquid water in both inter cluster veins and on films around snow grains harrington and bales 1998 thus increasing the mobility of ions as meltwater begins to percolate the snowpack during snowmelt preferential flow pf in melting snowpack can occur due to flow instabilities at the leading edge of the wetting front e g parlange 1974 pf forms when the vertically percolating meltwater is subject to a ponding process on a less impermeable snowpack layer boundary katsushima et al 2013 wakahama 1963 the ponding process ceases when the water entry value of capillary pressure threshold value is reached and water is allowed to enter the underlying snow layer dry pores the effect of pf on melt rates has been examined in experiments using dye traces gerdel 1954 marsh and woo 1984 and in numerical models leroux and pomeroy 2017 but its influence on the release on snow ions is less understood marsh and pomeroy 1999 observed that solute concentrations were largest in the snowpack low flow areas due to dilution effects however the snowpack highest flow areas carried the largest mass load 2 1 1 mathematical framework brimblecombe et al 1987 examined ice and meltwater in laboratory experiments and concluded that snow can be modelled as a two compartment mixture of concentrated snow surface and diluted snow grain interior other researchers followed and extended this approach e g bales 1991 harrington and bales 1998 the model proposed in this paper named as pulse was developed based on the harrington and bales 1998 paradigm which was modified herein fig 1 shows the conceptual model used to simulate the snowpack solid phase which is divided in the snow grain core and snow grain surface and the mobile phase although a liquid film is generally present around snow grains throughout seasons before snowmelt the liquid phase in snow can be considered negligible for the purposes of this model the mass balance for the solid phase includes the snow grain core csc eq 1 and the snow grain surface css eq 2 1 θ s c c s c t c s c θ s c q ρ s ρ l where ρs and ρl are snow and liquid water densities θsc is the volume fraction occupied by the snowpack solid phase and q is the melt rate 2 θ s s c s s t c s c θ s c q ρ s ρ l e θ s s where θss is the volume fraction occupied by the snowpack liquid phase and e is the solute mass exchange between the surface of the snow grain and the mobile liquid phase it is assumed that the snow grain core mass eq 1 decreases via a first order exponential decay process that is also controlled by the meltrate q this considers that the concentrations in the snow grains decrease as they melt which means also that the snow concentration radial gradient decreases exponentially towards the center of the snow grain the total mass in the snow grain surface eq 2 depends on the snow grain core mass that has melted and on exchanges with the mobile liquid phase the exchange of mass between the snow grains surface and the moving liquid mobile water e is described as 3 e α c s s c m where css and cm are the concentrations at the surface of the snow grains ss and in meltwater m and α is a parameter to account for ion exclusion although the ion exclusion process is known to depend on the ionic species variations in field observations suggest additional controls that are not entirely understood e g johannessen et al 1977 johannessen and henriksen 1978b according to brimblecombe et al 1985 some of these controls can be the inhomogeneity of the snowpack the pre met ion concentration in the snowpack and the history of the melting and refreezing fresh vs weathered snow surfaces anion also show more variation than cations as a result presently the parameter α is obtained through calibration but its characterization should be revised in the future as research sheds more light into the ion exclusion mechanism the simulation of the vertical movement of the mobile solute phase through the snowpack during melt is adapted from the approach used by harrington and bales 1998 which extends from the work by bear and bachmat 1990 on the modelling of transport through porous media in our model the porosity of the snowpack is set to change linearly as a function of the hourly or daily depending on the data availability snowmelt rate to avoid the need for complex snow physics models in other words the solid phase fraction decreases as it is converted into the liquid fraction at a speed that is controlled by the melt rate this ensures mass conservation between the liquid and solid phases throughout the snowmelt process and that the effect of daily variabilities in the melt rate often occurring at the onset of melt and potentially causing melting and refreezing could be translated into the temporal distribution of the liquid snow fractions as snow melts the vertical movement of liquid water through the snowpack is modelled as 4 θ m c m t θ m v c m θ m d c m e θ s s where v c m describes advection v is the interstitial flow velocity used as a proxy for the wetting front d is the diffusion coefficient d cm describes diffusion and e represents the mass exchange between the percolating meltwater liquid phase and the snow grain surface as it melts eq 3 in the horizontal averaged domain the advection and diffusion terms can be written as 5 θ m v c m θ m v c m z 6 θ m d c m 2 θ m d c m z 2 the interstitial velocity is described as 7 v q θ m where q is the snowmelt rate to calculate the dispersion coefficient d a simple approach often adopted in subsurface hydrology is used dispersivity d is taken as a calibrated coefficient parameter to relate interstitial velocity v to d charbeneau et al 1992 8 d d v the effect of pf is not simulated explicitly but it is indirectly accounted for by using interstitial flow velocity in the computation of the wetting front eq 7 in spite of this the model aims primarily at providing numerical laterally integrated 1d vertical snowpack response simulations and is not purposed to examine the effect of pf on the release on snow ions to meltwater the model requires pre melt snow depth and solute concentration values along with the time series of melt rate the outputs of the model are the evolution of the concentration vertical profiles for the dry core and surface of snow grains and wet snowpack portions the meltwater runoff concentrations correspond to the concentrations of the percolating meltwater wet snowpack portion at the bottom of the snowpack fig 2 shows the typical dynamics generated by the proposed model framework which agrees with concentrations profiles measured by davis et al 1995 in a series of controlled experiments on in flux through snowpack and aligns with the literature on snow chemistry during melt reported in section 2 1 2 1 2 numerical integration an implicit numerical solution based on the crank nicolson scheme second order method in time was adopted to integrate the solution of the advection dispersion equation eq 4 for the mobile phase the regions occupied by the solid and liquid phases are different and change as melt progresses to account for the effect of snowmelt on the snow depth and on the movement of the wetting front as depicted in fig 2 in other words the active wet layers of the snowpack see fig 1 are constrained by the upper snow layer which moves downwards as snow melts at the surface of the snowpack and the position of the wetting front which progressively moves downwards as meltwater percolates through the snow matrix see fig 2 the wetting front separates two regions an upper wet region and a lower dry region the transport of solutes by the snowpack liquid phase is thus limited by these two moving boundaries and is affected by varying upper and lower boundary conditions bc and by changes occurring within the wetting front is a no flow and no solute transport boundary lower boundary as melt occurs the upper boundary moves downwards and the mass remaining in the solid phase is transferred into the mobile liquid phase see eq 3 to ensure mass conservation only advection is allowed at the moving wetting front layer for this purpose an upwind scheme forward euler is used to guarantee no exchange fluxes advective or dispersive between the wetting front and the contiguous downstream layer which remains dry and immobile i e the snow is assumed completely dry downward of the wetting front thus the advection dispersion equation is only solved for the wet active region which is limited by the upper and lower boundaries layers see fig 2 the no flux condition results in the development of an ion load front as ions accumulate at the wetting front the intensity of this magnification mechanism depends on the balance between mixing and dilution processes which is affected by the intestinal flow velocity and ultimately controlled by the melt rate it is assumed that water and solutes in the solid phase are gradually converted into the mobile phase when water melts at each layer at a speed that is likewise controlled by the melt rate during this process it is considered that snow grain core solutes are excluded to the surface of the snow grains parameter e in eq 3 and subsequently gradually mixed with the percolating liquid mobile water eq 4 to maximize computational efficiency without compromising numerical stability and accuracy the model allows for different space grid sizes see fig 1 and performs dynamic time steps that comply with a pre defined maximum courant number c 1 obeying the courant condition is critical to guarantee both numerical stability and accuracy for the solution of the advection term note that unsteady interstitial velocities which control the advection term in eq 4 arise from both variable melt rates and mobile phase fractions i e porosity a maximum time step of one hour is also enforced to ensure sufficient temporal resolution during the development and dissipation phases of both the wetting and ion load fronts 2 1 3 model characteristics and assumptions in the model proposed by harrington and bales 1998 the initial ratio between snow grain core and snow grain surface concentrations is prescribed contrariwise in the proposed model only the initial average concentration of the snow grain core is defined which is set equal to the average pre melt snowpack concentrations as melt starts solute mass is transferred from the ice grain core to the ice grain surface and finally to the mobile phase as a result the proposed model framework does not require considerations or input data for snow grain surface solute concentrations that effect is encapsulated in the parameters defining the exchange rate e although in reality ion exclusion processes occur throughout the winter as snow metamorphism progresses and not necessarily only during the melt period such simplification avoids the need for pre melt snow grain core and surface solute concentrations ratios which would be difficult to measure and would most likely require additional model parameterizations extending the model to annual or inter annual simulations in the future could enable representing ion exclusion mechanisms for the entire winter period therefore arguably representing the process more realistically in the proposed framework the solute in the solid phase is thus assumed as initially being entirely in the snow grain core and as it melts being first segregated into the surface of the wet snow grain it is only after progressively transferred into the mobile phase thus the model results lead to concentrations in the solid phase decreasing behind the wetting front due to mass being gradually mixed and transported vertically with the liquid mobile phase the liquid and solid fractions θl and θs vary between 0 and 1 and are calculated through a simple linear function that is controlled by the meltrate and swe θ l 0 and θ s 1 at swe0 and θ l 1 and θ s 0 at swe f i n a l 0 the model simulates three wave fronts namely two fast and one slow the fast moving ones are the snowpack wetting and ion load fronts which are largely controlled by the interstitial velocity the slow moving wave is the melt front which determines the position of the upper boundary of the snowpack and is controlled by the melt of snow at the surface of the snowpack see fig 2 2 1 4 model applications the model was tested using four independent datasets from two distinct study areas fig 3 one dataset was collected from the emerald lake watershed in sierra nevada california usa harrington and bales 1998 tonnessen 1991 and the other three were measured at different sites in the trail valley creek basin north of inuvik northwest territories canada marsh and pomeroy 1996 1999 pomeroy et al 1993 emerald lake is located in sequoia national park and has a catchment area of 1 2 km2 this watershed has little human disturbance but is exposed to air pollution from upwind major urban and agricultural areas tonnessen 1991 the site was subject to an experiment involving the release and monitoring of chloride from a melting snowpack the average chloride cl concentration in the snowpack was measured at 1 5 μeq l at the onset of melt the trail valley creek basin is located 40 km north west of inuvik the three study sites monitored in this basin were located along a transect perpendicular to the creek channel the first site is defined as open tundra representing 70 of the total basin the second site is defined as shrub transition representing 22 of the total basin and the third site is characterised as drift valley representing 8 of the total area the reader is referred to the suggested literature for more information about the sites and respective field monitoring programs these two independent case studies comprising a total of 4 monitored sites provide a fairly wide range of hydrological and geochemical conditions i e snow depth concentrations and melt rates to test the proposed model fig 4 shows the cumulative melt rate measured in the two case study areas these are snowpack discharge volumes calculated from daily lysimeter flow data in the case of the emerald lake watershed and from hourly snow water equivalent swe data in the case of the trail valley creek basin unfortunately these are lumped snowpack discharge volumes and therefore the effect of pf on the temporal and spatial dynamics of the discharge and melt process cannot be accessed these observations point to very different snowmelt conditions between the two study areas on the one hand while the pre melt snow depth is just over 60 cm at the emerald lake watershed site the values recorded at the different sites at trail valley creek basin vary between 45 cm open tundra site and almost 200 cm drift valley site the one shown in fig 4 corresponds to the remaining site the shrub transition site which has an intermediate snow depth on the other hand the melt period varies between 13 4 and 36 days at trail valley creek but it takes more than 4 months at emerald lake for the snow to completely disintegrate and disappear table 1 shows the main characteristics of the numerical model setup including information about the initial conditions and the calibration and validation procedures as expected the initial conditions are very different depending on the site this is important to test the performance of the model over a broad range of conditions pre melt snow depth and no3 concentrations and duration of the melt period the thickness of the vertical layers used to discretize the model is also different depending on the site as a compromise between spatial resolution and computational demand the model was calibrated for two case sites through a monte carlo mc simulation framework based on 500 model realizations in order to examine both parameter spaces and parameter correlations the mc sampling procedure was deployed for the two model parameters together through parameter combinations the remaining two sites were used for validation purposes the performance of the model was evaluated at hourly time steps using the nash sutcliffe efficiency nse root mean square error rmse and model bias mb statistical metrics monte carlo simulations were performed for one site at each case study area to ensure that the parameter sets reflect local climate hydrological and geochemical conditions in the case of the emerald lake watershed case study the model is compared with observations and the empirical and process based model results presented by harrington and bales 1998 in the trail valley creek case study the model results were compared with observations for the different sites for this study region the best parameter sets were determined for the site with an intermediate snow cover depth shrub transition the model was subsequently tested for the remaining two sites using the same calibrated parameter combination 3 results 3 1 emerald lake watershed fig 5 shows the performance of the model using different parameter sets obtained from the monte carlo simulations results show that the numerical problem is moderately stiff in the sense that the solution generally varies slowly but has nearby solutions that vary rapidly for different parameter combinations it is somewhat sensitive and stiff to α i e solid phase snow grain surface to liquid phase exchange but nearly insensitive to d dispersivity the best model fit is obtained for different parameters depending on the statistics measure used which is not surprising given the nature of the different metrics while the best nse 0 596 and rmse 0 325 μ e q l 2 values are obtained using the parameter set α 10 3 and a d 5 96 10 2 mm 2 the best mb value 0 01 is obtained using α 1 02 10 2 and a d 4 50 10 1 mm 2 which are both one order of magnitude higher using the best parameter set obtained using both the nse and rmse based calibrations fig 6 shows the model results computed for the snowpack solid and mobile phases and compares the simulated meltwater cf values against observations the results obtained by harrington and bales 1998 and using empirical formulae are also included for comparison purposes unlike the trail valley creek basin model in section 3 1 1 no additional data was available for model validation in addition to calibration with the main objective this model application being the comparison of the performance of the model proposed to existing ones results suggest that the model can capture fairly well the timing middle and lower panel and magnitude lower panel of the ionic pulse nse 0 596 it shows some improvements in relation to the empirical and harrington and bales 1998 model results particularly during the initial melt period however the model seems to perform slightly worse at the end of the snowmelt season an issue that is discussed in section 4 discussion 3 1 1 trail valley creek basin as discussed previously in section 2 1 4 the calibration of the model was performed using the shrub transition site which is the intermediate site in terms of pre melt snow depth for the remaining sites the model was run using the best parameter combination identified for the calibrated site validation of the model fig 7 shows the model performance for different parameter combinations obtained by the monte carlo simulation approach as in the previous model application different best parameter sets were obtained depending on the statistical measure of fit used while the best model performance was obtained using α 1 26 10 2 and a d 4 95 10 1 mm 2 for both the nse 0 600 and rmse 0 325 μ eq l 2 metrics the best fit using mb 1 was obtained using α 1 36 10 1 and a d 2 70 10 1 mm 2 the best parameter set obtained for nse and rmse is also one order of magnitude higher for both parameters than that obtained for the emerald lake site while the reason for this difference is not entirely understood previous research has observed that ion exclusion rates decrease with increasing snowmelt rates e g stein et al 1986 which is in alignment with the ion exclusion parameter α being smaller for emerald lake watershed higher snowmelt rates see fig 4 when compared to the trail valley creek basin smaller snowmelt rates as in the emerald lake watershed case the model was also here run for all sites within the trail valley creek open tundra shrub transition and drift valley using the best parameter fit obtained using nse and rmse fig 8 results show a good agreement between observed and modelled meltwater concentrations for all sites the model can capture well both the timing and magnitude of the peak i e ionic pulse as well as the subsequent concentration evolution rse 0 6 it should be noted that the timing of the observed and modelled peak concentrations is different between sites and the model can capture these differences compare the concentration peaks in the lower panels of figs 6 and 8 a b and c this is related to the time required for the mobile phase and wetting front to move through the snow and reach the bottom of the snowpack e g the thickness of the snowcover is higher for the drift valley site and therefore the ion pulse arrives latter 4 discussion 4 1 is the model behaviour in agreement with the literature research suggests that snowpack ion exclusion processes occurs due to solutes being subject to segregation from the ice crystal lattice to the surface of the snow grain e g colbeck 1976 davis 1991 harrington and bales 1998 advanced that such phenomenon occurs during snow metamorphism as volatile ionic solutes from the grains losing mass accumulate on the surface of the surrounding gaining grains in the proposed model this process is represented through solute exchange estimates between the core and surface of ice grains eq 3 this leads to the development of an ion load front during the initial phase of melt a process that is caused by the mixing of the percolating meltwater vertically moving through the snow during snowmelt with ions located and readily available at the surface of the snow grains within the snow matrix see fig 2 the model can simulate such behaviour with concentration of the solid phase snow grain core and surface gradually decreasing as melt progresses upper panels of figs 6 and 8 and the concentrations in the mobile phase gradually increasing as the load front moves through the snowpack which causes the ion pulse commonly observed in snowmelt runoff the concentrations gradually decrease in the solid phases as it melts and the ions are incorporated into the mobile liquid phase 4 2 vertical concentration profiles solid and liquid phases fig 9 shows two snapshots of the vertical profiles of the simulated ionic concentrations of the solid and mobile phases before upper panel and after lower panel the ion load front has reached the bottom of the snowpack these simulated concentration profiles agree with the profiles measured by davis et al 1995 in a series of experiments on in flux through shallow snowpacks performed under controlled conditions results show the concentration of the solid immobile phase decreases as snow melt progresses and solute mass is carried by the liquid mobile phase upper panel as liquid water percolates through the snowpack it accumulates ions after removing them from the surface of snow grains this is noticeable in the upper panel by the significantly higher concentrations at the ion load front 8 5 μ meq l 1 when compared to the solid phase 1 7 μ meq l 1 after the ion load front has reached the snowpack bottom which means that snowmelt runoff has also initiated it can be noticed that the snow depth and concentration of the solid phase have significantly decreased likewise the concentration of the liquid phase is much smaller because a significant portion of the solute in the snow has already been carried out by initial flush i e ion load front 4 3 ion exclusion mechanisms and parameter α in the emerald lake watershed site the harrington and bales model shows a slightly better performance at the very end of the snowmelt season fig 6 the difference shows that meltwater concentrations do not tend to zero as predicted by our model this suggests an incomplete depletion of ions from the solid snow phase which points at a residual ionic concentration at the snow grain cores or a dynamic ion exclusion mechanism that cannot be entirely characterized via a calibrated fixed ion exclusion coefficient α this reinforces the need for a better characterization of this parameter as highlighted in section 2 1 1 research suggests that the rate at which ions are excluded from the ice lattice depends on the chemical species e g pomeroy et al 2005 1993 for they may have different diffusion rates and solubility in ice harrington and bales 1998 this is accounted in the model through an exchange rate e between the snow grain surface and the mobile phase that is controlled by concentration differences between the two phases and a calibrated parameter α although this is a simplification of the physical and chemical migration mechanisms involved it allows capturing the overall snow grain surface to mobile phase ion release phenomenon future development efforts should include the improvement of such simplification 4 4 concentration pulses in meltwater patterns and controls results suggest also that the timing and magnitude of the ionic pulse depend mainly on the depth of the snowpack on the melting rate and on the pre melt snow concentration these findings concur with field evidence such as reported in colbeck 1981 and marsh and pomeroy 1993 which highlight the importance of the melt rate and in brimblecombe et al 1987 and domine and thibert 1995 which emphasize the effect of pre melt snow solute concentrations the melt rate affects the porosity of the snowpack and therefore controls the interstitial flow velocity field this in turn determining the speed of the ion load front the melt rates and overall snowmelt dynamics can be significantly affected by pf e g hirashima et al 2017 leroux and pomeroy 2017 which can also potentially influence the ion transport process this modelling framework does not account explicitly for this transport pathway being only included through a rather simplistic approach based on the interstitial flow velocity eq 7 therefore the model is purposed primarily for simulation of laterally integrated 1d vertical snowpack responses and its extension to the 2d or 3d domain and to include pf should be addressed in future fig 10 shows the simulated liquid mobile and solid immobile fractions as calculated from a linear function controlled by the melt rate these results point at nonlinearities in melt and porosity dynamics caused by varying atmospheric conditions during melt the snow cover depth and melt rate play a critical role in the speed of the ion load front and thus on the timing of ionic pulse in runoff to further investigate the importance of such effect fig 11 shows the results obtained for the emerald lake watershed case when forcing the model with different snowmelt temporal distributions namely a actual recorded melt rate time series b constant averaged melt rate and c normal and d beta probability distribution functions fitted to the melt rate time series the normal probability distribution function was fitted to the melt rate data with a mean and standard deviation of 1 2 and 1 5 and the beta distribution function with shape parameters of 3 and 2 results confirm the importance of accurate melt rate evolutions for adequately prediction of the magnitude and even more notably of the timing of the ionic pulse i e compare the timing and magnitude of peaks for run 1 and run 2 complementary runs using different approximated normal and beta curves showed that the model predictions improved significantly as these approximations became closer to the real observed pattern improvements were observed for the overall meltwater concentration temporal evolution including the timing and magnitude of the peaks 4 5 advantages and limitations and integration into hydrological models some of the advantages of the proposed model when compared to previous modelling efforts are that 1 the ion exclusion processes is represented in a more physically based manner and is better aligned with field lab evidences e g the simulated concentration profiles in fig 9 compared with observations by davis et al 1995 2 it shows to capture the timing and peak of meltwater concentrations more accurately e g fig 6 and 3 it does not require a snow physics model to generate forcing data since that can be obtained directly from both observations pre melt concentrations and hydrological models that are suitable for cold regions swe and melt rate temporal dynamics the model is currently being integrated in the cold regions hydrological model crhm pomeroy et al 2007 as part of a series of water quality modules currently under developed some of the limitations of the proposed model are that it does not include the effect of pf on solute transport which may be potentially relevant in some cases particularly at small sales see section 2 1 and that despite showing better performances see fig 6 it is more computationally expensive than the analytical model proposed by stein et al 1986 the computational time increases in conditions of deep snowpacks fast melt rates and detailed model vertical resolutions high number of vertical layers see fig 1 5 conclusions the release of chemicals from the snowpack is complex it is influenced by several processes including snow metamorphism ion exclusion preferential elution and advection diffusion of ions along with the percolating meltwater one important combined effect of these processes is the segregation of ions from the core of snow grains to their surface and their rapid mixing with the first meltwater flush several field studies have shown indirect evidence for this phenomenon however research efforts for providing physically based simulations of these processes has been more limited in this research a numerical model was developed to simulate solute dynamics within the wet and dry phases of the snow matrix alongside with the temporal dynamics of meltwater concentrations the mathematical model developed was formulated based on the current understanding of the different release migration and transport mechanisms involved although some processes were simplified to compromise between computational demand and practical use the model was tested for 2 independent study areas a total of 4 sites comprising a wide range of pre melt snowpack depths and concentrations and of melt rate dynamics results showed that the model can accurately simulate meltwater concentration dynamics at the bottom of the snowpack runoff including the timing and magnitude of ionic pulses for various landscape and climatic conditions simulations suggest that snow melt rates at high temporal resolution e g hourly are particularly important for the adequate prediction of the timing and magnitude of concentration peaks concentration profiles of the dry snow and liquid wet fractions have been simulated for the first time with the results matching well with previous laboratory measurements although there is a computational cost associated with the proposed model particularly in conditions of deep snowpacks fast melt rates and detailed model vertical resolution i e snow layers these results show a good predictive capacity for different landscape and climate scenarios future research work includes 1 the modular coupling with long term catchment scale nutrient models for inter annual nutrient export simulations e g crhm 2 the development of model algorithms to estimate the ion exclusion coefficient α from the chemical properties of the ions e g ability to establish hydrogen bonds and solubility in ice and 3 the modification of the model to include the effect of preferential flow a process that affects the ability of meltwater to remove and mix with snow ions during snowmelt acknowledgments the authors would like to thank the global water futures programme the canada excellence research chair in water security the canada research chair in water resources and climate change the canadian water network and the natural sciences and engineering research council nserc through its create in water security and discovery grants 463960 2015 for financial support 
724,pore to darcy scale upscaling of multiphase flow is one of the major unresolved problems in many fields of porous media research while this problem involves very fundamental aspects there are many practical and application driven challenges as well such as the accurate prediction of darcy scale multiphase effective properties e g relative permeability by pore scale flow simulation on the basis of the imaged pore geometry e g via x ray computed micro tomography validation of pore scale modeling methods against experimental data by comparison of measured against simulated relative permeability curves has proven to be insufficient comparison of the fluid topology in particular the non wetting phase topology is a much more reliable criteria as relative permeability shows a very strong correlation with connectivity while percolation based quasi static modeling approaches operating in the capillary limit have proven moderately successful in drainage they largely fail to predict fluid connectivity in imbibition we show that a fully coupled visco capillary simulation using a free energy based lattice boltzmann approach correctly predicts fluid connectivity in imbibition which was not predicted correctly by a quasi static approach in a previous study on the same dataset the respective relative permeability data shows a close match with results from darcy scale core flooding experiments while there is a major mismatch from quasi static approach the results once more highlight the close connection between relative permeability and fluid topology and suggest that topological measures are much more meaningful validation criteria for pore scale simulation the results also show that the direct simulation approach described in this paper using appropriate initial and boundary conditions correctly predicts darcy scale effective properties keywords fluid topology imbibition relative permeability direct numerical simulation free energy based lattice boltzmann method digital rock 1 introduction upscaling multiphase flow from pore to darcy scale is one of the large unresolved problems in many fields of porous media research that has captivated many researchers for the past decades das and hassanizadeh 2005 while darcy s law darcy 1856 which is a continuum mechanics description for single phase flow in porous media can be derived by upscaling stokes flow at the micro or pore scale through homogenization bear and bachmat 1990 in a relatively straightforward way this is tremendously more challenging for multiphase flow and until today remains unsolved conceptual upscaling approaches for multiphase flow from pore to darcy scale include models and theories such as percolation larson et al 1981 theory of mixtures bowen 1982 thermodynamically consistent approaches hassanizadeh and gray 1993 and thermodynamically constrained averaging theory gray and miller 2005 one of the key challenges is to address connected and disconnected fractions of fluid phase this is captured successfully on a conceptual level only in phenomenological models hilfer 1998 for that reason for most practical applications phenomenological extensions to darcy s single phase flow law are employed muskat meres 1936 wyckoff botset 1936 in these phenomenological descriptions the relative permeability saturation function is introduced which cannot be predicted within the framework of the description however it has to be measured experimentally johnson et al 1959 kokkedee et al 1996 dake 1978 honarpour et al 2000 this very pragmatic approach has many downsides from a conceptual perspective the relative permeability saturation function as such is problematic for various reasons niessner et al 2011 hysteresis is neglected viscous coupling effects between liquid phases ayub and bentsen 2005 and at the solid interface berg et al 2008 are also ignored from a more practical perspective measuring relative permeability in the laboratory requires very specialized equipment berg et al 2008 is expensive and very time consuming obtaining the drilled core in the laboratory takes half a year to a year a full special core analysis program takes typically another year to the extent that for instance for applications in oil recovery measurement results often become not available in time before investment decisions are taken both the conceptual issues arising within the context of multiphase flow upscaling but also the practical applications e g obtaining relative permeability largely benefits from having accurate numerical simulations of multiphase flow at the pore scale level the main requirement is simulations need to be performed for domain sizes that can be interpreted at the darcy scale in the form of relative permeability attempts have been made to establish a link between pore and darcy scale pressure drops since the last two decades e g nordbotten et al 2008 korteland et al 2010 and gray et al 2013 recent developments which use direct numerical simulation to represent pore scale flow physics within the context of pore to darcy scale numerical upscaling include raeini et al 2014 koroteev et al 2014 and boek et al 2017 the basis of numerical modeling approaches are digital images of rock at pore scale resolution i e resolving the pore space explicitly and in detail one of the big questions is which pore scale simulation approach gives accurate and reliable results there are various approaches which have their specific pros and cons numerical modeling of two phase flow group into two main categories pore network modeling blunt et al 2002 and direct numerical simulation ferrari and lunati 2013 ferrari et al 2015 alpak et al 2016 evseev et al 2016 rabbani et al 2017 alpak et al 2018b c frank et al 2018 network models are based on an equivalent network of capillary tubes abstracted from the digital image of the pore space multiphase displacement and flow simulations can be conducted on network models at low to moderate computational cost owing to many simplifications and abstractions the most significant abstraction is the assumption of quasi static displacement blunt et al 2002 in combination with uncertainties in the extraction of the equivalent network quasi static displacement assumption is one of the key reasons for difficulties to correctly model imbibition processes berg et al 2016a it is increasingly well understood that pore scale displacement processes are non local and involve visco capillary coupling flow experiments imaged at pore scale resolution under flowing conditions by fast x ray computed micro tomography micro ct and micromodel experiments imaged with high speed cameras have been instrumental for developing this knowledge armstrong and berg 2013 armstrong et al 2014 while in drainage these effects have less impact on the fluid topology because drainage is relatively more a percolation driven process resulting in overall connected phases in imbibition the quasi static assumption generally breaks down due to snap off processes schlüter et al 2016 that is one of the reasons why quasi static approaches often deliver reasonable results in drainage but fail more often in imbibition berg et al 2016a bultreys et al 2018 performed a detailed analysis of pore filling event sequences during drainage and imbibition they report that essential topology characteristics matched well for drainage simulations but not for imbibition this suggests that the pore filling rules in the pore network model need to be improved to make reliable predictions of imbibition moreover the presented analysis illustrates the potential of their methodology to systematically and robustly test two phase flow models to aid in model development and calibration it is important to mention that there are also dynamic pore network models joekar niasar 2009 2010 hammond and unsal 2012 which do not suffer from the shortcomings of more conventional pore network models but are computationally much more expensive direct numerical simulations are performed directly on the digital image of the pore space which is in many cases directly on the voxel grid obtained from the micro ct scans direct numerical simulations can be regarded more similar to computer experiments where all the dominant physical principles are accounted for in a natural way direct numerical simulation approach uses navier stokes equations to honor momentum balance and all relevant forces i e capillary viscous gravity and inertial forces act simultaneously ferrari and lunati 2013 there are still some important choices to be made which can be grouped into two classes i the formulation solver to be used for the momentum balance ii the approach to be employed for the treatment of the liquid liquid interfaces evseev et al 2016 and the liquid solid interface ding et al 2007 alpak et al 2016 2018b c compared with quasi static pore network modeling direct numerical simulation approaches are in particular in the low capillary number regime computationally significantly costlier which is one of the main reason why they have not been explored to the same extent as pore network modeling however increasing availability of computational power in particular through general purpose graphics processing units gpgpus have made direct simulation approaches more accessible zacharoudiou and boek 2016 alpak et al 2018a c increasing diversity of pore scale simulation approaches and availability of better direct simulation approaches raise the question about validation in terms of performance but also correctness while for single phase flow the validation is more straightforward saxena et al 2017 for multiphase flow simulation approaches so far validation has been made mainly on the basis of comparison with experimentally measured relative permeability data masalmeh et al 2015 in particular for pore network modeling approaches this validation method has been used extensively however because of the large number of degrees of freedom in pore network models and respective possibility for tuning relative permeability saturation relationships may not be sufficiently unique thus they do not constrain pore scale simulation sufficiently to discriminate between uncertainty in the representation of the pore space and issues with the pore scale modeling approach validation of correct pore scale displacement physics on small model problems evseev et al 2016 armstrong et al 2016a large realistic problems alpak et al 2018b c and comparison of the fluid topology with experimental data in particular the non wetting phase topology provide a much more meaningful validation berg et al 2016a this is because relative permeability shows a very strong correlation with connectivity liu et al 2017 experimental data on fluid phase topology and connectivity has more recently become available berg et al 2016a through the advances in pore scale imaging berg et al 2013 they have already been used in a previous study to establish the validity of a direct pore scale simulation approach armstrong et al 2016b in the current work we close the argument that the quasi static treatment of multiphase flow operating in the capillary limit may be applicable for drainage but not in imbibition the benchmark dataset is an experiment where pore scale fluid distributions were imaged with fast x ray computed tomography during an imbibition experiment in a sandstone rock rücker et al 2015 the relative permeability computed from these fluid distributions at each saturation step was consistent with steady state special core analysis relative permeability measurements on a twin sample berg et al 2016a a quasi static morphological approach operating directly on the voxel grid obtained by micro ct which was chosen for a more equivalent comparison with pore level image based validation data showed major discrepancies with the pore scale fluid distribution specifically in terms of fluid topology and percolation threshold berg et al 2016a here we show that for the same dataset a fully coupled visco capillary simulation using a free energy based lattice boltzmann approach correctly predicts in imbibition fluid connectivity i e that was not predicted correctly by a quasi static approach the respective relative permeability data shows a close match with results from darcy scale core flooding experiments while there was a major mismatch from quasi static approach the results once more highlight the close connection between relative permeability and fluid topology and suggest that topological measures are much more meaningful validation criteria for pore scale simulation the results also show that the direct simulation approach described in this paper using appropriate initial and boundary conditions correctly predicts darcy scale effective properties 2 mathematical models 2 1 direct numerical simulation using free energy lattice boltzmann method we utilize the free energy lattice boltzmann method lbm motivated by the findings of yang 2013 where a quantitative comparison of the shan chen pseudo potential model the r k color gradient model and an implementation of the free energy model was performed it has been found that the shan chen model allows the simulation of high density ratio fluids e g liquid gas systems but gives rise to low numerical stability and wide interfaces for multi phase immiscible systems e g oil water systems on the other hand the r k color gradient model and the free energy model readily permit the simulation of two phase flow for fluids with significant viscosity contrast and recover the analytical solutions of poiseuille flow and fingering simulations yang 2013 concluded that the free energy and r k color gradient models are most appropriate to simulate immiscible two phase pore scale flow of fluids exhibiting high viscosity contrast with high numerical stability while the free energy lbm is a thermodynamically based model where there is a direct link between interfacial curvatures and interfacial tension as an upscaled quantity stemming from the actual nano scale characteristics of the interface the r k color gradient model lacks such a direct link to the thermodynamics which renders it unsuitable for subsurface applications in hydrocarbon recovery we refer the reader to alpak et al 2018c for a more detailed literature review on the subject the equilibrium properties of a binary two phase fluid can be described by a helmholtz free energy functional swift et al 1995 1996 briant and yeomans 2004 1 f v f b κ ϕ 2 α ϕ 2 d v s f s d s the first term in the integrand is the bulk free energy density given by 2 f b a 2 ϕ 2 b 4 ϕ 4 c 2 3 ρ l n ρ where ϕ is the order parameter ρ is the fluid mass density and c is a lattice velocity parameter the order parameter is defined as m 1 m 2 m 1 m 2 where m 1 and m 2 are mass densities of fluid phase 1 and phase 2 respectively this choice of fb allows binary phase separation into two phases if a 0 and b 0 as the bulk free energy density takes the form of a double well potential with bulk equilibrium solutions ϕ e q a b here we make the choice a b which leads to ϕ eq 1 for the two phases the position of the interface is chosen to be at ϕ 0 the final term in the bulk free energy density c 2 3 ρ l n ρ does not affect the phase behavior and is added to enforce incompressibility kendon et al 2001 the gradient term κ ϕ 2 α ϕ 2 in eq 1 penalizes the spatial variations of the order parameter ϕ for example across an interface and ensures a smooth transition from one phase to the other hence this term is related to the interfacial tension γ 8 κ ϕ a 3 9 b 2 and to the interface width ξ κ ϕ a briant and yeomans 2004 the final term in the free energy functional eq 1 describes the interactions between the fluid and the solid surface following cahn 1977 the surface energy density is taken to be of the form fs hϕ s where ϕ s is the value of the order parameter at the surface minimization of the free energy gives an equilibrium wetting boundary condition briant and yeomans 2004 3 κ ϕ ϕ d f s d ϕ s h the value of the parameter h surface excess chemical potential is related to the equilibrium contact angle θ eq via briant and yeomans 2004 4 h 2 κ ϕ b s i g n π 2 θ e q c o s α 3 1 c o s α 3 where α arccos sin 2θ eq and the function sign returns the sign of its argument this choice of the free energy leads to the exchange chemical potential 5 μ δ f δ ϕ a ϕ b ϕ 3 κ ϕ γ γ ϕ which describes the change in f for a small change in the order parameter and is constant at equilibrium the pressure tensor which determines how the system approaches equilibrium is given by anderson et al 1998 and kendon et al 2001 6 p α β ϕ δ f δ ϕ ρ δ f δ ρ f δ α β α ϕ δ f δ β ϕ p b κ ϕ ϕ γ γ ϕ κ ϕ 2 γ ϕ 2 δ α β κ ϕ α ϕ β ϕ p i s o δ α β p α β c h e m where p b c 2 3 ρ 1 2 a ϕ 2 3 4 b ϕ 4 is the bulk pressure the pressure tensor comprises of two terms a chemical pressure tensor contribution p α β c h e m and an isotropic contribution p i s o c 2 3 ρ to ensure constant density kendon et al 2001 p α β c h e m originates from the fact that in the presence of concentration represented by the order parameter gradients there is a thermodynamic force density ϕ αμ acting at each point of the fluid which can be expressed as the divergence of a chemical pressure tensor ϕ α μ β p α β c h e m effectively this thermodynamic force density pulls the two fluids in opposite directions due to the chemical potential gradient with the net force being zero at the interface ϕ 0 for a free energy based multicomponent lbm we refer the reader to li and wagner 2007 and zhang and kwok 2009 the hydrodynamic equations for the system are the continuity eq 7 and the navier stokes eq 8 equations for a non ideal fluid 7 t ρ α ρ u α 0 8 t ρ u α β ρ u α u β β p α β β η β u α α u β f α where u p η and f ρ g denote the fluid velocity pressure tensor dynamic viscosity and body force respectively for a binary fluid the equations of motion are coupled with the advective cahn hilliard equation 9 t ϕ α ϕ u α m 2 μ which describes the dynamics of the order parameter ϕ m is a mobility coefficient the equilibrium thermodynamic properties of the fluid enter the equations of motion through the pressure tensor eq 6 and the chemical potential eq 5 the above equations are solved using an mrt implementation of lbm d humières et al 2002 details about the implementation of this technique are given in the references briant and yeomans 2004 yeomans 2006 and pooley et al 2008 and thus are not repeated in this document it is important to note that the continuity and navier stokes equations are coupled to the advective cahn hilliard equation and are not solved independently this ensures that the equations are solved with an algorithm which is consistent with the thermodynamics of the fluids thermodynamic concepts enter into the equations of motion through the chemical potential and pressure tensor in this formulation the coupling occurs at the level of the distribution functions for the density and in the pressure tensor details of this can be found in briant and yeomans 2004 yeomans 2006 and pooley et al 2008 the evolution of the order parameter is obtained from solving the advective cahn hilliard equation the order parameter responds to the flow as it can be advected by the flow while velocity field is obtained from solving the navier stokes and continuity equations but it also responds to chemical potential gradients the evolution of the order parameter field results in a change of the pressure field which in turn affects the flow field the fluid flow is driven by applying a constant injection flow rate more specifically we apply velocity boundary conditions at the inlet and outlet of the simulation domain for forced drainage and forced imbibition simulations it is possible to impose velocity velocity boundary conditions because we make the incompressible flow approximation the inlet and outlet of the simulation domain are modeled by use of discretized fully porous buffers of variable user choice length the buffer size depends on the physics of the problem we use a periodic like loop boundary condition at the domain boundaries that are perpendicular to the main flow direction alpak et al 2018a we use this periodic like loop boundary condition on all domain boundaries together with mirror imaging of the domain in the main flow direction for steady state relative permeability computations the flow is then driven by a body force and fully porous buffers are not used for relative permeability computations due to the continuity equation eq 7 we are free to specify only three of the four variables density and the three components of the velocity on the boundary the fourth variable will be the outcome of solving the equations of motion using the lb algorithm hecht harting 2010 the code implementation of the above described energy based lb method has been successfully utilized previously in zacharoudiou and boek 2016 for developing an in depth understanding of dynamics of capillary filling and haines jumps an accelerated variant of the energy based lb method is later developed and coined as elbm for simplicity in referral and has been extensively validated in alpak et al 2018c we use elbm in the studies described in this paper 2 2 quasi static morphological method the quasi static morphological method hilpert and miller 2001 ahrenholz et al 2008 becker et al 2008 silin et al 2010 relies on two major approximations i the morphological approach approximating drainage or imbibition as a sequence of young laplace equilibrium states in contrast to dynamic methods involving moving liquid liquid interfaces such as the phase field method on which elbm is based and ii the young laplace equilibrium states found by a series of morphological erosion and dilation operations using a spherical structuring element the quasi static drainage algorithm starts with a completely water saturated porous medium and begins with a maximal pore radius r which is then decreased step by step in each step a pore is drained if 1 the pore radius is larger than r 2 the entering non wetting phase is connected by pores larger than r to the non wetting phase reservoir and 3 the replaced wetting phase is connected to the wetting phase reservoir conditions 1 and 2 describe the original algorithm as defined by hilpert and miller 2001 and used in becker et al 2008 condition 3 introduces a residual wetting phase and was added by ahrenholz et al 2008 the imbibition algorithm starts with a completely oil saturated porous medium and minimal pore radius r which is then increased step by step in each step a pore is imbibed if 1 the pore radius is smaller than r 2 the entering wetting phase is connected to the wetting phase reservoir and 3 the re placed non wetting phase is connected to the non wetting phase reservoir ahrenholz et al 2008 this approach is computationally less costly than the capillary dominated quasi static level set method jettestuen et al 2013 and more efficient than directly solving the navier stokes equations for two phase flow with mobile liquid liquid interfaces as in the case of the elbm technique described above the morphological approach was initially developed to compute a simulated mercury air hg air intrusion capillary pressure for comparison with experimentally obtained hg air intrusion data often also referred to as mercury intrusion capillary porosimetry micp in a second step the morphological method was employed to simulate drainage and imbibition processes from the resulting pore scale saturation distribution snapshots connected pathway flow relative permeabilities are computed by applying a single phase pore scale flow simulator on the one phase at a time basis to compute effective phase permeabilities for each saturation snapshot a quasi static morphologically based relative permeability curve is computed by normalizing the phase effective permeabilities with the absolute permeability of the image which is also computed with the single phase flow simulator 2 3 discussion while direct simulation techniques such as elbm capture the full visco capillary force coupling during flow and transport the morphological method relies on a purely capillary force driven representation of the displacement physics and does not account for the viscous effects moreover the construction destruction and movement of the fluid interfaces are treated in a simplistic analytical fashion independent of the developments in the globally coupled pressure field recent work has demonstrated that while this approach leads to a somewhat acceptable first order approximation of the displacement physics for the drainage process it is very inaccurate for capturing the physics of imbibition berg et al 2016a b on the other hand direct simulation techniques particularly the ones that not only incorporate the visco capillary coupling into the model but also account for the physics of interfacial phenomena in a thermodynamically consistent fashion have the capability of capturing the imbibition physics and thereby the associated fluid distributions quite well the study described in the following section provides a quantitative evidence for this claim 3 fluid topology study on the gildehauser dataset while close agreement of relative permeability saturation functions between the experiment and numerical model is a good indication that the elbm simulations are predictive it is not an ultimate proof as relative permeability saturation functions are non unique in particular in pore network modeling it has been shown that a good match can be achieved by sufficient tuning using a network of a different rock raeesi et al 2013 while in most direct simulation approaches including the method used here no such tuning is performed we will demonstrate that not only that the relative permeability matches the experiment but also the pore scale fluid configuration in a series of publications schlüter et al 2016 liu et al 2017 and mcclure et al 2018 showed that the pore scale fluid configuration can be uniquely characterized using a set of geometric state variables mcclure et al 2018 in particular the euler characteristic provides a very relevant fingerprint of the fluid topology and relative permeability of the non wetting phase can be directly related to the euler characteristic of the non wetting phase liu et al 2017 hence in order to establish a fully convincing validation and predictive capability of the direct simulation approach validation of both the fluid topology and the relative permeability is required berg et al 2014 2016a b performed detailed investigations of fluid configurations and connected pathway relative permeability on a dataset obtained via a synchrotron based x ray computed micro ct imbibition experiment using a sandstone rock sample the gildehauser sandstone used in these papers has an average porosity of 20 and a permeability of 1500 400 md it has low clay content and a narrow pore size distribution 35 µm pore throat diameter which renders the rock well suitable for micro ct imaging berg et al 2016a we use the same gildehauser sandstone dataset to carry out investigations of the imaged vs simulated two phase flow fields the maximum inscribed rectangular prism of size 566 550 552 x y and z directions fig 1 is extracted from the original image of size 566 893 897 which contains an embedded image of a cylindrically shaped porous rock sample the voxel resolutions of both the original and the cut out image are 4 µm use of the maximum inscribed rectangular prism allows us to eliminate potential edge effects and impose a variant of the periodic boundary condition at the domain boundaries perpendicular to the main flow x direction the porosity of the extracted model is 0 19 and its permeability is 1 161 5 md the latter is computed by an efficient and accurate mrt lbm code for single phase pore scale flow simulation alpak et al 2018a for two phase pore scale flow simulation with elbm a small reservoir 16 lu is added at the inlet outlet of the simulation domain a constant velocity boundary condition is imposed at the inlet only the x component of the velocity vector u x i n l e t is non zero at the inlet in the experiment the rock sample was first saturated with brine hereafter referred to as water and then n decane also referred to as oil was injected at a high rate to reach a non wetting phase saturation around 0 78 the viscosities were 9 2 10 4 pa s and 1 0 10 3 pa s for n decane and water respectively giving rise to a viscosity ratio m η nw η w of 0 92 first the forced drainage process is simulated by imposing a relatively high velocity as the inlet boundary condition u x i n l e t 5 0 10 5 l u and the corresponding capillary number canw η nw unw γ in the simulation was 1 9 10 3 n decane is injected from one end of the domain until irreducible water saturation is established an interesting finding is that the simulated irreducible water saturation is 0 7947 fig 2 which is very close to the experimentally obtained value then the forced imbibition process simulated where water is injected to displace n decane for imbibition simulations locations of the inlet and outlet are swapped in other words the main flow direction is reversed for these simulations the inlet boundary condition imposed for the forced imbibition simulation was u x i n l e t 1 0 10 5 l u and the corresponding capillary numbers caw η w uw γ canw η nw unw γ in the simulation were 3 6 10 4 and 1 3 10 4 respectively further details of the fluid and rock properties of the gildehauser dataset and the experimental setup and procedures can be found in berg et al 2014 2016a b we quantify to which degree the pore scale fluid distributions predicted by use of elbm differ from the experimental data reported by berg et al 2016b for the imbibition process we perform a similar study for drainage but the comparison is carried out with respect to the quasi static morphological approach utilized in the same reference and briefly described above because no experimental fluid distribution data were reported for the primary drainage process that preceded the imaged imbibition experiment we compute the euler characteristic χ as a measure for the topology of the non wetting phase directly from the pore scale fluid configuration using the image processing software avizo fei the euler characteristic is a topological invariant that can be expressed as the difference between the number of objects zeroth betti number β0 and the number of redundant loops herring et al 2013 schlüter et al 2014 via 10 χ β 0 β 1 in fig 3 χ values computed for experimental and elbm simulated fluid configurations are plotted as a function of wetting phase saturation sw note that the calculation of χ can be very sensitive to small disconnected clusters that could be noise or segmentation errors in the experimental data and artifacts of the morphological approach therefore in fig 3 all clusters smaller than 100 voxels where a cluster with 100 voxels approximately corresponds to a spherical cluster size of about 25 µm diameter which is about the noise level in the data see berg et al 2014 are eliminated in the experimental elbm simulated and morphologically computed data for consistency in analysis fig 4 illustrates example non wetting phase oil configuration snapshots from imaged and simulated forced imbibition experiment for the same injected pore volume details of the configuration are different however overall pore occupancies are quite similar the trend in fig 4 is consistent with the euler characteristic analysis documented in fig 3 for the saturation range of the imbibition experiment 0 22 sw 0 70 we observe that χ 0 which indicates that the non wetting phase is percolating i e consists of more redundant loops mainly around the grains than individual clusters we show example fluid configurations during imbibition as predicted by elbm in fig 5 typically χ 0 is considered as an indication for the percolation threshold which for the experimental data is expected to be around sw 0 70 an excellent agreement is obtained between the experimentally determined and elbm simulated χ profiles for the imbibition process on the other hand the quasi static morphological approach and elbm predictions for χ exhibit significant disagreement for both drainage and imbibition processes the morphological approach exhibits notable violations of the water saturation range observed in the experiment 0 22 sw 0 70 while elbm simulations accurately capture it based on χ as one of the key measures for fluid topology we quantitatively demonstrate that the morphological approach produces very different and inconsistent pore scale fluid configurations compared to experimental observations unlike elbm the origin of the differences in the pore scale fluid configurations predicted by the morphological approach and elbm relates to neglecting viscous and inertial forces ferrari and lunati 2013 in modeling pore scale displacement processes by the morphological approach which operates in the capillary limit due to the absence of viscous forces relaxation phenomena and internal fluid re distribution caused by local capillary pressure gradients are not captured in any quasi static approach the associated time scales for relaxation range from seconds armstrong et al 2014 to many hours schlüter et al 2016 consequently during two phase flow at field relevant flow rates 1 3 ft day the fluid fluid interfaces and associated menisci do not reach capillary equilibrium instantly in most cases and the fluid dynamics is non local the quasi static method however always assumes an equilibrium curvature capillary re distribution phenomena are not captured and the interface dynamics is local on the other hand including viscous forces in addition to capillary forces and capturing global fluid dynamics are necessary for accurately predicting pore scale fluid configurations as demonstrated by elbm simulations fig 3 it is important to note that elbm is based on a thermodynamically based visco capillary model formulation 4 relative permeability study on the gildehauser dataset the number of studies in the open literature on the direct calculation of relative permeability for reservoir rocks is sparse martys and chen 1996 ramstad et al 2012 koroteev et al 2014 boek et al 2017 the effects of capillary number wettability and viscosity ratio on the relative permeability saturation functions were studied by li et al 2005 using the shan chen model shan and chen 1993 the challenges for the relative permeability computation from direct pore scale simulations are significant the direct simulator needs to be very accurate efficient robust and most importantly sufficiently flexible to reproduce the experimental conditions in the simulation with the exception of boek et al 2017 the above mentioned publications document relative permeability calculations on the basis of the random distribution of the non wetting phase according to the desired saturation such fluid configurations are straightforward to set up however they come with a number of drawbacks because they are not consistent with the experimental procedures for example there is no mechanism to prevent the small pores to be saturated by the non wetting phase while high capillary pressure typically prevents this in real life experiments absence of the notion of the drainage imbibition hysteresis makes it difficult to compute the imbibition relative permeability function we use a process based approach originally developed by yang 2013 and later used by boek et al 2017 to address the above challenges this approach accounts for the drainage imbibition hysteresis by use of direct simulations this method represents a steady state type of displacement approach to relative permeability computation a forced drainage process is simulated first here the in situ wetting phase fully saturating the pore space is displaced by an injected non wetting phase the rock model is fully saturated by the wetting phase a buffer layer saturated with oil is placed to the inlet and one saturated with water is placed to the outlet oil is injected from the inlet buffer layer into the pore space with a constant prescribed velocity until the average water saturation in the pore space does not exhibit an appreciable change saturation convergence at which time the drainage calculations are terminated note that the water saturation achieved in this way may not necessarily correspond to the irreducible or connate water saturation of a representative elementary volume as the viscous pressure drop achieved in such a small computational domain size much smaller than a core plug is significantly less than capillary pressure established in the porous plate or centrifuge method corresponding to the saturation height in an oil reservoir snapshots of the fluid configuration at different average water saturation values are used for the drainage relative permeability calculations the post drainage fluid configuration is then used as the initial state for the forced imbibition simulation where the non wetting phase is displaced by the wetting phase the fluids in the inlet and outlet buffers are interchanged prior to the forced imbibition calculations the forced imbibition calculations are continued again until average water saturation in the porous domain converges it is important to note that the visco capillary model formulation does not entirely capture the physics of spontaneous imbibition which is a solely capillary dominated process for stability reasons there is a problem dependent minimum limit to the inlet velocity that can be imposed to a forced imbibition simulation therefore the spontaneous imbibition is approximated by using a small constant velocity boundary condition that can be stably simulated by use of elbm depending on the accuracy of this approximation the oil saturation remaining at the end of the forced imbibition process may or may not necessarily correspond to the ground truth residual oil saturation due to a potentially limited viscous pressure drop fig 6 again the fluid configuration snapshots at different average water saturation values acquired during forced imbibition simulations are then used for relative permeability computations in order to ensure steady state conditions avraam and payatakes 1995 in the relative permeability computation for a given saturation snapshot calculations are performed using the loop type periodic boundary conditions imposed on all faces of the domain the full mirroring of the porous domain in the main flow direction is applied such that the periodic boundary condition is fully honored on the outlet face of the domain the system is then driven to steady state which closely mimics the steady state relative permeability experiment upon convergence of the system to steady state effective wetting and non wetting phase permeabilities computed by elbm are normalized by the absolute permeability computed with an accurate and efficient mrt lbm code alpak et al 2018a prior to the relative permeability simulation the fluxes used for computing effective wetting and non wetting phase permeabilities are derived by monitoring the average velocities of wetting and non wetting phases respectively over the part of the domain that corresponds to the porous rock in other words buffers are excluded from the flux calculations relatively longer buffers are used for forced drainage and especially forced imbibition process simulations when the intent is to use the resulting fluid configurations for subsequent relative permeability calculations to minimize the boundary effects moreover an additional ring of the internal rock domain neighboring the buffers can be excluded from the effective property calculations to further minimize the boundary effects this approach is typically used for the forced imbibition simulations the process is then repeated for all saturation snapshots that cover the saturation range observed during the forced drainage or forced imbibition process the relative permeability computation process is accurate physically robust and computationally quite demanding the computational demand directly scales with the saturation resolution i e the number of saturation snapshots required to accurately capture the relative permeability functions we compute the relative permeability curves for the gildehauser sandstone sample using the above described process based methodology for the imbibition process we use the saturation snapshots stemming from the imbibition simulation the gildehauser dataset also includes the steady state relative permeability data measured on a twin sample of very different much larger size moreover we also include in the comparison the relative permeability curves predicted by a quasi static morphological approach berg et al 2016a b we purposefully keep the connected pathway relative permeabilities reported in berg et al 2016a b outside the scope because they require beamline imaging which is very impractical for digital rock applications one would need to measure the pore scale fluid distribution in a synchrotron beamline experiment which requires even more effort than conducting a steady state relative permeability experiment berg et al 2016b panels of fig 7 show the comparison of experimental elbm simulated process based and morphologically predicted becker et al 2008 steady state relative permeability curves on linear and logarithmic scales we observe that the overall agreement of the elbm simulated relative permeability curves with experimental data is reasonably good the agreement of the elbm predicted non wetting phase oil n decane relative permeability with experimental data is very good however the wetting phase water relative permeability is slightly overpredicted by the direct simulation approach but the trend is quite similar to the experimental data here it is important to note that experimental relative permeabilities are derived from flow measurements on a much larger sample volume than the image used for the numerical relative permeability computations therefore it is reasonable to expect that there will be some effects of larger scale heterogeneities on the measured relative permeability data which cannot be captured through numerical simulation this may be true despite the image volume used may contain a sufficient number of grains and pore throats typical for a representative elementary volume approximation for absolute permeability estimation in all cases elbm predicted relative permeability curves honor the experimentally observed saturation range on the other hand the relative permeability curves predicted by the morphological approach grossly violate the experimentally observed saturation range the relative permeability curve for the non wetting phase exhibits a major divergence from experimental observations the relative permeability curve for the wetting phase does not show a consistent trend with the experimentally observed data overall the process based direct simulation driven prediction of the underlying fluid configuration field for relative permeability computations is a more reliable and accurate technique than the quasi static morphological approach 5 relative permeability study on a reservoir rock image having built in confidence on the underlying methodology of computing relative permeability through direct numerical simulation in the previous sections we have performed a relative permeability computation study for a sandstone rock from a producing reservoir a core plug of 1 in diameter and 2 5 in length is taken from the core and flow properties were measured the core plug is of 29 md permeability and its porosity is approximately 0 09 a steady state experimental relative permeability curve for the primary drainage of brine via decane injection was also available first we have performed absolute permeability and porosity computations using our in house mrt lbm permeability estimation code alpak et al 2018a on a representative x ray computed micro tomography image volume fig 8 the simulation domain size is 512 512 512 lattice units l u with a resolution of 2 03 µm per l u which corresponds to a physical domain size of 1 039 mm 1 039 mm 1 039 mm and a porosity of 0 11 the computed permeability in the x y and z directions are 31 8 34 3 and 36 6 md respectively subsequently we have simulated the forced drainage two phase displacement process until apparent connate water saturation is reached a small reservoir 16 lu is added at the inlet outlet of the domain for the forced drainage simulation we imposed a contact angle boundary condition with θ eq 40 on the solid surfaces for two phase flow simulations on the reservoir rock image volume using the computed saturation snapshots that are nearest on average to the experimentally observed saturation points we have computed the relative permeability values fig 9 documents the experimentally measured and computed relative permeability curves for the wetting and non wetting phase the agreement between the measured and computed relative permeability curves is reasonably well 6 conclusions a detailed analysis of fluid topology is performed for a gildehauser sandstone dataset including a favorable comparison between imaging determined and numerically simulated euler characteristic profiles for the imbibition cycle finally we use the same gildehauser sandstone dataset to compute process based steady state relative permeability curves through the full visco capillary simulation via elbm and compare them to the ones computed by a morphological approach and steady state relative permeability measurements performed on a core plug which is much larger than the image used for numerical computations we observe that the overall agreement of the elbm simulated relative permeability curves with experimental data is very good for the non wetting phase and satisfactory while being still better than quasi static method predictions for the wetting phase elbm predicted relative permeability curves honor the experimentally observed saturation range on the other hand the relative permeability curves predicted by the quasi static morphological approach grossly violate the experimentally observed saturation range the relative permeability curve for the non wetting phase exhibits a major divergence from experimental observations the relative permeability curve for the wetting phase does not show a consistent trend with the experimentally observed data overall the process based direct simulation driven prediction of the underlying fluid configuration field is a more reliable and accurate technique than the quasi static morphological approach a separate study is conducted for a real reservoir rock where simulated and experimentally measured steady state relative permeability curves are compared for a forced drainage process it has been observed that the agreement between the measured and computed relative permeability curves is reasonably well supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 09 001 appendix supplementary materials image application 1 ahrenholz et al 2008 b ahrenholz j tölke p lehmann a peters a kaestner m krafczyk w durner prediction of capillary hysteresis in a porous material using lattice boltzmann methods and comparison to experimental data and a morphological pore network model adv water res 31 2008 1151 1173 alpak et al 2018a f o alpak f gray n saxena j dietderich r hofmann s berg a distributed parallel multiple relaxation time lattice boltzmann method on general purpose graphics processing units for the rapid and scalable computation of absolute permeability from high resolution 3d micro ct images comput geosci 22 2018 815 832 alpak et al 2016 f o alpak b riviere f frank a phase field method for the direct simulation of two phase flows in pore scale media using a non equilibrium wetting boundary condition comput geosci 20 2016 881 908 alpak et al 2018b f o alpak a samardžić f frank a distributed parallel direct simulator for pore scale two phase flow on digital rock images using a finite difference implementation of the phase field method j petroleum sci eng 166 2018 806 824 alpak et al 2018c f o alpak i zacharoudiou s berg j dietderich n saxena direct simulation of pore scale two phase visco capillary flow on large digital rock images using a phase field lattice boltzmann method on general purpose graphics processing units comput geosci 2018 submitted anderson et al 1998 d m anderson g b mcfadden a a wheeler diffuse interface methods in fluid mechanics annu rev fluid mech 30 1 1998 139 165 armstrong and berg 2013 r t armstrong s berg interfacial velocities and capillary pressure gradients during haines jumps phy rev e 88 4 2013 043010 armstrong et al 2016a r t armstrong s berg o dinariev n evseev d klemin d koroteev s safonov modeling of pore scale two phase phenomena using density functional hydrodynamics transp porous media 112 3 2016 577 607 armstrong et al 2016b r t armstrong j e mcclure m a berill m rücker s schlüter s berg beyond darcy s law the role of phase topology and ganglion dynamics for two fluid flow phys rev e 94 2016 043113 armstrong et al 2014 r t armstrong h ott a georgiadis m ruecker a schwing s berg sub second pore scale displacement processes and relaxation dynamics in multiphase flow water resour res 50 12 2014 9162 9176 avraam and payatakes 1995 d avraam a payatakes flow regimes and relative permeabilities during steady state two phase flow in porous media j fluid mech 293 1995 207 236 ayub and bentsen 2005 m ayub r g bentsen experimental testing of interfacial coupling in two phase flow in porous media pet sci technol 23 2005 863 897 bear and bachmat 1990 j bear y bachmat introduction to modeling of transport phenomena in porous media 1990 kluwer academic publishers the netherlands becker et al 2008 j becker v schulz a wiegmann numerical determination of two phase material parameters of a gas diffusion layer using tomography images j fuel cell sci technol 5 2 2008 021006 9 berg et al 2014 s berg r armstrong h ott a georgiadis s a klapp a schwing r neiteler n brussee a makurat l leu f enzmann j o schwarz m wolf f khan m kersten s irvine m stampanoni multiphase flow in porous rock imaged under dynamic flow conditions with fast x ray computed microtomography petrophysics 55 4 2014 304 312 berg et al 2008 s berg a w cense j p hofmann r m m smits two phase flow in porous media with slip boundary condition transp porous media 74 2008 275 292 berg et al 2013 s berg h ott s a klapp a schwing r neiteler n brussee a makurat l leu f enzmann j o schwarz m kersten s irvine m stampanoni real time 3d imaging of haines jumps in porous media flow proc natl acad sci 110 10 2013 3755 3759 berg et al 2016a s berg m rücker h ott a georgiadis h van der linde f enzmann m kersten r t armstrong s de with j becker a wiegmann connected pathway relative permeability from pore scale imaging of imbibition adv water res 90 2016 24 35 berg et al 2016b s berg m rücker h ott a georgiadis h van der linde f enzmann m kersten r t armstrong s de with j becker a wiegmann modelling of imbibition relative permeability by direct quasi static approach paper sca2016 007 presented at the international symposium of the society of core analysts held in snowmass 21 26 august colorado usa 2016 blunt et al 2002 m j blunt m d jackson m piri p h valvatne detailed physics predictive capabilities and macroscopic consequences for pore network models of multiphase flow adv water res 25 2002 1069 1089 boek et al 2017 e s boek i zacharoudiou f gray s m shah j p crawshaw j yang multiphase flow and reactive transport validation studies at the pore scale by use of lattice boltzmann computer simulations spe j 22 3 2017 940 949 bowen 1982 r bowen compressible porous media models by use of the theory of mixtures int j eng sci 20 6 1982 697 735 briant and yeomans 2004 a j briant j m yeomans lattice boltzmann simulations of contact line motion ii binary fluids phys rev e 69 3 2004 031603 bultreys et al 2018 t bultreys q lin y gao a q raeini a alratrout b bijeljic m j blunt validation of model predictions of pore scale fluid distributions during two phase flow phys rev e 2018 053104 cahn 1977 j cahn critical point wetting j chem phys 66 8 1977 3367 dake 1978 l p dake fundamentals of reservoir engineering 1978 elsevier b v the netherlands darcy 1856 h darcy détermination des lois d écoulement de l eau à travers le sable p victor dalmont les fontaines publiques de la ville de dijon 1856 v dalmont paris france 590 594 das and hassanizadeh 2005 d b das s m hassanizadeh upscaling multiphase flow in porous media 2005 springer d humières et al 2002 d d humières i ginzburg m krafczyk p lallemand l s luo multiple relaxation time lattice boltzmann models in three dimensions philosophical transactions of the royal society a mathematical phys eng sci 360 1792 2002 72 ding and spelt 2007 h ding p d m spelt wetting condition in diffuse interface simulations of contact line motion phys rev e 75 2007 046708 1 8 evseev et al 2016 n evseev r t armstrong s berg o dinariev d klemin d koroteev s safonov modeling of pore scale two phase flow phenomena using density functional hydrodynamics transp porous media 112 3 2016 577 607 ferrari et al 2015 a ferrari j jimenez martinez t le borgne y méheust i lunati challenges in modeling unstable two phase flow experiments in porous micromodels water resour res 51 3 2015 1381 1400 ferrari and lunati 2013 a ferrari i lunati direct numerical simulations of interface dynamics to link capillary pressure and total surface energy adv water res 57 2013 19 31 frank et al 2018 f frank c liu f o alpak s berg b riviere direct numerical simulation of flow on pore scale images using the phase field method spe j 2018 published online gray and miller 2005 w g gray c t miller thermodynamically constrained averaging theory approach for modeling of flow in porous media 1 motivation and overview adv water resour 28 2 2005 161 180 gray et al 2013 w g gray c t miller b a schrefler averaging theory for description of environmental problems what have we learned adv water res 51 2013 123 138 hammond and unsal 2012 p s hammond e unsal a dynamic pore network model for oil displacement by wettability altering surfactant solution transp porous media 92 3 2012 789 817 hassanizadeh and gray 1993 s m hassanizadeh w g gray toward an improved description of the physics of two phase flow adv water res 16 1 1993 53 67 hecht 2010 m hecht j harting implementation of on site velocity boundary conditions for d3q19 lattice boltzmann simulations j stat mech 2010 p01018 herring et al 2013 a l herring e j harper l andersson a sheppard b k bay d wildenschild effect of fluid topology on residual nonwetting phase trapping implications for geologic co2 sequestration adv water res 62 2013 47 58 hilfer 1998 r hilfer macroscopic equations of motion for two phase flow in porous media phys rev e 58 2 1998 2090 2096 hilpert and miller 2001 m hilpert t c miller pore morphology based simulation of drainage in totally wetting porous media adv water res 24 2001 243 255 honarpour et al 2000 m honarpour l koederitz a h harvey relative permeability of petroleum reservoirs 2000 crc press boca raton fl u s a jettestuen et al 2013 e jettestuen j o helland m prodanović a level set method for simulating capillary controlled displacements at the pore scale with nonzero contact angles water resour res 49 2013 1 17 joekar niasar et al 2009 v joekar niasar s m hassanizadeh l j pyrak nolte c berentsen simulating drainage and imbibition experiments in a high porosity micromodel using an unstructured pore network model water resour res 45 2 2009 w02430 15 joekar niasar et al 2010 v joekar niasar m prodanović d wildenschild s m hassanizadeh network model investigation of interfacial area capillary pressure and saturation relationships in granular porous media water resour res 46 6 2010 w06526 18 johnson et al 1959 e f johnson d p bossler v o naumann calculation of relative permeability from displacement experiments trans aime 216 1959 370 372 kendon et al 2001 v kendon m cates i pagonabarraga j c desplat p bladon inertial effects in three dimensional spinodal decomposition of a symmetric binary fluid mixture a lattice boltzmann study j fluid mech 440 2001 147 203 kokkedee et al 1996 j a kokkedee w boom a m frens j g maas improved special core analysis scope for a reduced residual oil saturation proceedings of society of core analysis conference aper 9601 1996 1 13 koroteev et al 2014 d koroteev o dinariev n evseev d klemin a nadeev s safonov o gurpinar s berg c van kruijsdijk r armstrong m t myers l hathon h de jong direct hydrodynamic simulation of multiphase flow in porous rock petrophysics 55 4 2014 294 303 korteland et al 2010 s korteland s bottero s m hassanizadeh c w j berentsen what is the correct definition of average pressure transp porous media 84 1 2010 153 175 larson et al 1981 r g larson l e scriven h t davis percolation theory of two phase flow in porous media chem eng sci 36 1 1981 57 73 li et al 2005 h li c pan c t miller pore scale investigation of viscous coupling effects for two phase flow in porous media phys rev e 72 2 2005 026705 li and wagner 2007 q li a j wagner symmetric free energy based multicomponent lattice boltzmann method phys rev e 76 2007 036701 liu et al 2017 z liu a herring c arns s berg r t armstrong pore scale characterization of two phase flow using integral geometry transp porous media 118 1 2017 99 117 martys and chen 1996 n s martys h d chen simulation of multicomponent fluids in complex three dimensional geometries by the lattice boltzmann method phys rev e 53 1 1996 743 750 masalmeh et al 2015 s k masalmeh x jing s roth c wang h dong towards predicting multi phase flow in porous media using digital rock physics workflow to test the predictive capability of pore scale modelling abu dhabi international petroleum exhibition and conference held in abu dhabi u a e 9 12 november paper spe 177572 2015 mcclure et al 2018 j e mcclure r t armstrong m a berrill s schlüter s berg w g gray c t miller a geometric state function for two fluid flow in porous media phys rev fluids 3 2018 084306 muskat 1936 m muskat m w meres the flow of heterogeneous fluids through porous media j appl phys 7 1936 346 363 niessner et al 2011 j niessner s berg s m hassanizadeh comparison of two phase darcy s law with a thermodynamically consistent approach transp porous media 88 2011 133 148 nordbotten et al 2008 j m nordbotten m a celia h k dahle s m hassanizadeh on the definition of macroscale pressure for multiphase flow in porous media water resour res 44 6 2008 w06s02 pooley and furtado 2008 c m pooley k furtado eliminating spurious velocities in the free energy lattice boltzmann method phys rev e 77 4 2008 046702 rabbani et al 2017 h s rabbani v joekar niasar t pak n shokri new insights on the complex dynamics of two phase flow in porous media under intermediate wet conditions sci rep 7 1 2017 4584 raeesi et al 2013 b raeesi n r morrow g mason pore network modelling of experimental capillary pressure hysteresis relationships paper sca2013 015 international symposium of the society of core analysts held in napa valley california usa 16 19 september 2013 raeini et al 2014 a q raeini m j blunt b bijeljic direct simulations of two phase flow on micro ct images of porous media and upscaling of pore scale forces adv water res 74 2014 116 126 ramstad et al 2012 t ramstad n idowu c nardi p e øren relative permeability calculations from two phase flow simulations directly on digital images of porous rocks transp porous media 94 2 2012 487 504 rücker et al 2015 rücker m berg s armstrong r t georgiadis a ott h schwing a neiteler r brussee n makurat a leu l wolf m khan f enzmann f kersten m from connected pathway flow to ganglion dynamics geophys res lett 42 10 2015 3888 3894 saxena et al 2017 n saxena r hofmann f o alpak s berg j dietderich u agarwal k tandon s hunter j freeman o b wilson 
724,pore to darcy scale upscaling of multiphase flow is one of the major unresolved problems in many fields of porous media research while this problem involves very fundamental aspects there are many practical and application driven challenges as well such as the accurate prediction of darcy scale multiphase effective properties e g relative permeability by pore scale flow simulation on the basis of the imaged pore geometry e g via x ray computed micro tomography validation of pore scale modeling methods against experimental data by comparison of measured against simulated relative permeability curves has proven to be insufficient comparison of the fluid topology in particular the non wetting phase topology is a much more reliable criteria as relative permeability shows a very strong correlation with connectivity while percolation based quasi static modeling approaches operating in the capillary limit have proven moderately successful in drainage they largely fail to predict fluid connectivity in imbibition we show that a fully coupled visco capillary simulation using a free energy based lattice boltzmann approach correctly predicts fluid connectivity in imbibition which was not predicted correctly by a quasi static approach in a previous study on the same dataset the respective relative permeability data shows a close match with results from darcy scale core flooding experiments while there is a major mismatch from quasi static approach the results once more highlight the close connection between relative permeability and fluid topology and suggest that topological measures are much more meaningful validation criteria for pore scale simulation the results also show that the direct simulation approach described in this paper using appropriate initial and boundary conditions correctly predicts darcy scale effective properties keywords fluid topology imbibition relative permeability direct numerical simulation free energy based lattice boltzmann method digital rock 1 introduction upscaling multiphase flow from pore to darcy scale is one of the large unresolved problems in many fields of porous media research that has captivated many researchers for the past decades das and hassanizadeh 2005 while darcy s law darcy 1856 which is a continuum mechanics description for single phase flow in porous media can be derived by upscaling stokes flow at the micro or pore scale through homogenization bear and bachmat 1990 in a relatively straightforward way this is tremendously more challenging for multiphase flow and until today remains unsolved conceptual upscaling approaches for multiphase flow from pore to darcy scale include models and theories such as percolation larson et al 1981 theory of mixtures bowen 1982 thermodynamically consistent approaches hassanizadeh and gray 1993 and thermodynamically constrained averaging theory gray and miller 2005 one of the key challenges is to address connected and disconnected fractions of fluid phase this is captured successfully on a conceptual level only in phenomenological models hilfer 1998 for that reason for most practical applications phenomenological extensions to darcy s single phase flow law are employed muskat meres 1936 wyckoff botset 1936 in these phenomenological descriptions the relative permeability saturation function is introduced which cannot be predicted within the framework of the description however it has to be measured experimentally johnson et al 1959 kokkedee et al 1996 dake 1978 honarpour et al 2000 this very pragmatic approach has many downsides from a conceptual perspective the relative permeability saturation function as such is problematic for various reasons niessner et al 2011 hysteresis is neglected viscous coupling effects between liquid phases ayub and bentsen 2005 and at the solid interface berg et al 2008 are also ignored from a more practical perspective measuring relative permeability in the laboratory requires very specialized equipment berg et al 2008 is expensive and very time consuming obtaining the drilled core in the laboratory takes half a year to a year a full special core analysis program takes typically another year to the extent that for instance for applications in oil recovery measurement results often become not available in time before investment decisions are taken both the conceptual issues arising within the context of multiphase flow upscaling but also the practical applications e g obtaining relative permeability largely benefits from having accurate numerical simulations of multiphase flow at the pore scale level the main requirement is simulations need to be performed for domain sizes that can be interpreted at the darcy scale in the form of relative permeability attempts have been made to establish a link between pore and darcy scale pressure drops since the last two decades e g nordbotten et al 2008 korteland et al 2010 and gray et al 2013 recent developments which use direct numerical simulation to represent pore scale flow physics within the context of pore to darcy scale numerical upscaling include raeini et al 2014 koroteev et al 2014 and boek et al 2017 the basis of numerical modeling approaches are digital images of rock at pore scale resolution i e resolving the pore space explicitly and in detail one of the big questions is which pore scale simulation approach gives accurate and reliable results there are various approaches which have their specific pros and cons numerical modeling of two phase flow group into two main categories pore network modeling blunt et al 2002 and direct numerical simulation ferrari and lunati 2013 ferrari et al 2015 alpak et al 2016 evseev et al 2016 rabbani et al 2017 alpak et al 2018b c frank et al 2018 network models are based on an equivalent network of capillary tubes abstracted from the digital image of the pore space multiphase displacement and flow simulations can be conducted on network models at low to moderate computational cost owing to many simplifications and abstractions the most significant abstraction is the assumption of quasi static displacement blunt et al 2002 in combination with uncertainties in the extraction of the equivalent network quasi static displacement assumption is one of the key reasons for difficulties to correctly model imbibition processes berg et al 2016a it is increasingly well understood that pore scale displacement processes are non local and involve visco capillary coupling flow experiments imaged at pore scale resolution under flowing conditions by fast x ray computed micro tomography micro ct and micromodel experiments imaged with high speed cameras have been instrumental for developing this knowledge armstrong and berg 2013 armstrong et al 2014 while in drainage these effects have less impact on the fluid topology because drainage is relatively more a percolation driven process resulting in overall connected phases in imbibition the quasi static assumption generally breaks down due to snap off processes schlüter et al 2016 that is one of the reasons why quasi static approaches often deliver reasonable results in drainage but fail more often in imbibition berg et al 2016a bultreys et al 2018 performed a detailed analysis of pore filling event sequences during drainage and imbibition they report that essential topology characteristics matched well for drainage simulations but not for imbibition this suggests that the pore filling rules in the pore network model need to be improved to make reliable predictions of imbibition moreover the presented analysis illustrates the potential of their methodology to systematically and robustly test two phase flow models to aid in model development and calibration it is important to mention that there are also dynamic pore network models joekar niasar 2009 2010 hammond and unsal 2012 which do not suffer from the shortcomings of more conventional pore network models but are computationally much more expensive direct numerical simulations are performed directly on the digital image of the pore space which is in many cases directly on the voxel grid obtained from the micro ct scans direct numerical simulations can be regarded more similar to computer experiments where all the dominant physical principles are accounted for in a natural way direct numerical simulation approach uses navier stokes equations to honor momentum balance and all relevant forces i e capillary viscous gravity and inertial forces act simultaneously ferrari and lunati 2013 there are still some important choices to be made which can be grouped into two classes i the formulation solver to be used for the momentum balance ii the approach to be employed for the treatment of the liquid liquid interfaces evseev et al 2016 and the liquid solid interface ding et al 2007 alpak et al 2016 2018b c compared with quasi static pore network modeling direct numerical simulation approaches are in particular in the low capillary number regime computationally significantly costlier which is one of the main reason why they have not been explored to the same extent as pore network modeling however increasing availability of computational power in particular through general purpose graphics processing units gpgpus have made direct simulation approaches more accessible zacharoudiou and boek 2016 alpak et al 2018a c increasing diversity of pore scale simulation approaches and availability of better direct simulation approaches raise the question about validation in terms of performance but also correctness while for single phase flow the validation is more straightforward saxena et al 2017 for multiphase flow simulation approaches so far validation has been made mainly on the basis of comparison with experimentally measured relative permeability data masalmeh et al 2015 in particular for pore network modeling approaches this validation method has been used extensively however because of the large number of degrees of freedom in pore network models and respective possibility for tuning relative permeability saturation relationships may not be sufficiently unique thus they do not constrain pore scale simulation sufficiently to discriminate between uncertainty in the representation of the pore space and issues with the pore scale modeling approach validation of correct pore scale displacement physics on small model problems evseev et al 2016 armstrong et al 2016a large realistic problems alpak et al 2018b c and comparison of the fluid topology with experimental data in particular the non wetting phase topology provide a much more meaningful validation berg et al 2016a this is because relative permeability shows a very strong correlation with connectivity liu et al 2017 experimental data on fluid phase topology and connectivity has more recently become available berg et al 2016a through the advances in pore scale imaging berg et al 2013 they have already been used in a previous study to establish the validity of a direct pore scale simulation approach armstrong et al 2016b in the current work we close the argument that the quasi static treatment of multiphase flow operating in the capillary limit may be applicable for drainage but not in imbibition the benchmark dataset is an experiment where pore scale fluid distributions were imaged with fast x ray computed tomography during an imbibition experiment in a sandstone rock rücker et al 2015 the relative permeability computed from these fluid distributions at each saturation step was consistent with steady state special core analysis relative permeability measurements on a twin sample berg et al 2016a a quasi static morphological approach operating directly on the voxel grid obtained by micro ct which was chosen for a more equivalent comparison with pore level image based validation data showed major discrepancies with the pore scale fluid distribution specifically in terms of fluid topology and percolation threshold berg et al 2016a here we show that for the same dataset a fully coupled visco capillary simulation using a free energy based lattice boltzmann approach correctly predicts in imbibition fluid connectivity i e that was not predicted correctly by a quasi static approach the respective relative permeability data shows a close match with results from darcy scale core flooding experiments while there was a major mismatch from quasi static approach the results once more highlight the close connection between relative permeability and fluid topology and suggest that topological measures are much more meaningful validation criteria for pore scale simulation the results also show that the direct simulation approach described in this paper using appropriate initial and boundary conditions correctly predicts darcy scale effective properties 2 mathematical models 2 1 direct numerical simulation using free energy lattice boltzmann method we utilize the free energy lattice boltzmann method lbm motivated by the findings of yang 2013 where a quantitative comparison of the shan chen pseudo potential model the r k color gradient model and an implementation of the free energy model was performed it has been found that the shan chen model allows the simulation of high density ratio fluids e g liquid gas systems but gives rise to low numerical stability and wide interfaces for multi phase immiscible systems e g oil water systems on the other hand the r k color gradient model and the free energy model readily permit the simulation of two phase flow for fluids with significant viscosity contrast and recover the analytical solutions of poiseuille flow and fingering simulations yang 2013 concluded that the free energy and r k color gradient models are most appropriate to simulate immiscible two phase pore scale flow of fluids exhibiting high viscosity contrast with high numerical stability while the free energy lbm is a thermodynamically based model where there is a direct link between interfacial curvatures and interfacial tension as an upscaled quantity stemming from the actual nano scale characteristics of the interface the r k color gradient model lacks such a direct link to the thermodynamics which renders it unsuitable for subsurface applications in hydrocarbon recovery we refer the reader to alpak et al 2018c for a more detailed literature review on the subject the equilibrium properties of a binary two phase fluid can be described by a helmholtz free energy functional swift et al 1995 1996 briant and yeomans 2004 1 f v f b κ ϕ 2 α ϕ 2 d v s f s d s the first term in the integrand is the bulk free energy density given by 2 f b a 2 ϕ 2 b 4 ϕ 4 c 2 3 ρ l n ρ where ϕ is the order parameter ρ is the fluid mass density and c is a lattice velocity parameter the order parameter is defined as m 1 m 2 m 1 m 2 where m 1 and m 2 are mass densities of fluid phase 1 and phase 2 respectively this choice of fb allows binary phase separation into two phases if a 0 and b 0 as the bulk free energy density takes the form of a double well potential with bulk equilibrium solutions ϕ e q a b here we make the choice a b which leads to ϕ eq 1 for the two phases the position of the interface is chosen to be at ϕ 0 the final term in the bulk free energy density c 2 3 ρ l n ρ does not affect the phase behavior and is added to enforce incompressibility kendon et al 2001 the gradient term κ ϕ 2 α ϕ 2 in eq 1 penalizes the spatial variations of the order parameter ϕ for example across an interface and ensures a smooth transition from one phase to the other hence this term is related to the interfacial tension γ 8 κ ϕ a 3 9 b 2 and to the interface width ξ κ ϕ a briant and yeomans 2004 the final term in the free energy functional eq 1 describes the interactions between the fluid and the solid surface following cahn 1977 the surface energy density is taken to be of the form fs hϕ s where ϕ s is the value of the order parameter at the surface minimization of the free energy gives an equilibrium wetting boundary condition briant and yeomans 2004 3 κ ϕ ϕ d f s d ϕ s h the value of the parameter h surface excess chemical potential is related to the equilibrium contact angle θ eq via briant and yeomans 2004 4 h 2 κ ϕ b s i g n π 2 θ e q c o s α 3 1 c o s α 3 where α arccos sin 2θ eq and the function sign returns the sign of its argument this choice of the free energy leads to the exchange chemical potential 5 μ δ f δ ϕ a ϕ b ϕ 3 κ ϕ γ γ ϕ which describes the change in f for a small change in the order parameter and is constant at equilibrium the pressure tensor which determines how the system approaches equilibrium is given by anderson et al 1998 and kendon et al 2001 6 p α β ϕ δ f δ ϕ ρ δ f δ ρ f δ α β α ϕ δ f δ β ϕ p b κ ϕ ϕ γ γ ϕ κ ϕ 2 γ ϕ 2 δ α β κ ϕ α ϕ β ϕ p i s o δ α β p α β c h e m where p b c 2 3 ρ 1 2 a ϕ 2 3 4 b ϕ 4 is the bulk pressure the pressure tensor comprises of two terms a chemical pressure tensor contribution p α β c h e m and an isotropic contribution p i s o c 2 3 ρ to ensure constant density kendon et al 2001 p α β c h e m originates from the fact that in the presence of concentration represented by the order parameter gradients there is a thermodynamic force density ϕ αμ acting at each point of the fluid which can be expressed as the divergence of a chemical pressure tensor ϕ α μ β p α β c h e m effectively this thermodynamic force density pulls the two fluids in opposite directions due to the chemical potential gradient with the net force being zero at the interface ϕ 0 for a free energy based multicomponent lbm we refer the reader to li and wagner 2007 and zhang and kwok 2009 the hydrodynamic equations for the system are the continuity eq 7 and the navier stokes eq 8 equations for a non ideal fluid 7 t ρ α ρ u α 0 8 t ρ u α β ρ u α u β β p α β β η β u α α u β f α where u p η and f ρ g denote the fluid velocity pressure tensor dynamic viscosity and body force respectively for a binary fluid the equations of motion are coupled with the advective cahn hilliard equation 9 t ϕ α ϕ u α m 2 μ which describes the dynamics of the order parameter ϕ m is a mobility coefficient the equilibrium thermodynamic properties of the fluid enter the equations of motion through the pressure tensor eq 6 and the chemical potential eq 5 the above equations are solved using an mrt implementation of lbm d humières et al 2002 details about the implementation of this technique are given in the references briant and yeomans 2004 yeomans 2006 and pooley et al 2008 and thus are not repeated in this document it is important to note that the continuity and navier stokes equations are coupled to the advective cahn hilliard equation and are not solved independently this ensures that the equations are solved with an algorithm which is consistent with the thermodynamics of the fluids thermodynamic concepts enter into the equations of motion through the chemical potential and pressure tensor in this formulation the coupling occurs at the level of the distribution functions for the density and in the pressure tensor details of this can be found in briant and yeomans 2004 yeomans 2006 and pooley et al 2008 the evolution of the order parameter is obtained from solving the advective cahn hilliard equation the order parameter responds to the flow as it can be advected by the flow while velocity field is obtained from solving the navier stokes and continuity equations but it also responds to chemical potential gradients the evolution of the order parameter field results in a change of the pressure field which in turn affects the flow field the fluid flow is driven by applying a constant injection flow rate more specifically we apply velocity boundary conditions at the inlet and outlet of the simulation domain for forced drainage and forced imbibition simulations it is possible to impose velocity velocity boundary conditions because we make the incompressible flow approximation the inlet and outlet of the simulation domain are modeled by use of discretized fully porous buffers of variable user choice length the buffer size depends on the physics of the problem we use a periodic like loop boundary condition at the domain boundaries that are perpendicular to the main flow direction alpak et al 2018a we use this periodic like loop boundary condition on all domain boundaries together with mirror imaging of the domain in the main flow direction for steady state relative permeability computations the flow is then driven by a body force and fully porous buffers are not used for relative permeability computations due to the continuity equation eq 7 we are free to specify only three of the four variables density and the three components of the velocity on the boundary the fourth variable will be the outcome of solving the equations of motion using the lb algorithm hecht harting 2010 the code implementation of the above described energy based lb method has been successfully utilized previously in zacharoudiou and boek 2016 for developing an in depth understanding of dynamics of capillary filling and haines jumps an accelerated variant of the energy based lb method is later developed and coined as elbm for simplicity in referral and has been extensively validated in alpak et al 2018c we use elbm in the studies described in this paper 2 2 quasi static morphological method the quasi static morphological method hilpert and miller 2001 ahrenholz et al 2008 becker et al 2008 silin et al 2010 relies on two major approximations i the morphological approach approximating drainage or imbibition as a sequence of young laplace equilibrium states in contrast to dynamic methods involving moving liquid liquid interfaces such as the phase field method on which elbm is based and ii the young laplace equilibrium states found by a series of morphological erosion and dilation operations using a spherical structuring element the quasi static drainage algorithm starts with a completely water saturated porous medium and begins with a maximal pore radius r which is then decreased step by step in each step a pore is drained if 1 the pore radius is larger than r 2 the entering non wetting phase is connected by pores larger than r to the non wetting phase reservoir and 3 the replaced wetting phase is connected to the wetting phase reservoir conditions 1 and 2 describe the original algorithm as defined by hilpert and miller 2001 and used in becker et al 2008 condition 3 introduces a residual wetting phase and was added by ahrenholz et al 2008 the imbibition algorithm starts with a completely oil saturated porous medium and minimal pore radius r which is then increased step by step in each step a pore is imbibed if 1 the pore radius is smaller than r 2 the entering wetting phase is connected to the wetting phase reservoir and 3 the re placed non wetting phase is connected to the non wetting phase reservoir ahrenholz et al 2008 this approach is computationally less costly than the capillary dominated quasi static level set method jettestuen et al 2013 and more efficient than directly solving the navier stokes equations for two phase flow with mobile liquid liquid interfaces as in the case of the elbm technique described above the morphological approach was initially developed to compute a simulated mercury air hg air intrusion capillary pressure for comparison with experimentally obtained hg air intrusion data often also referred to as mercury intrusion capillary porosimetry micp in a second step the morphological method was employed to simulate drainage and imbibition processes from the resulting pore scale saturation distribution snapshots connected pathway flow relative permeabilities are computed by applying a single phase pore scale flow simulator on the one phase at a time basis to compute effective phase permeabilities for each saturation snapshot a quasi static morphologically based relative permeability curve is computed by normalizing the phase effective permeabilities with the absolute permeability of the image which is also computed with the single phase flow simulator 2 3 discussion while direct simulation techniques such as elbm capture the full visco capillary force coupling during flow and transport the morphological method relies on a purely capillary force driven representation of the displacement physics and does not account for the viscous effects moreover the construction destruction and movement of the fluid interfaces are treated in a simplistic analytical fashion independent of the developments in the globally coupled pressure field recent work has demonstrated that while this approach leads to a somewhat acceptable first order approximation of the displacement physics for the drainage process it is very inaccurate for capturing the physics of imbibition berg et al 2016a b on the other hand direct simulation techniques particularly the ones that not only incorporate the visco capillary coupling into the model but also account for the physics of interfacial phenomena in a thermodynamically consistent fashion have the capability of capturing the imbibition physics and thereby the associated fluid distributions quite well the study described in the following section provides a quantitative evidence for this claim 3 fluid topology study on the gildehauser dataset while close agreement of relative permeability saturation functions between the experiment and numerical model is a good indication that the elbm simulations are predictive it is not an ultimate proof as relative permeability saturation functions are non unique in particular in pore network modeling it has been shown that a good match can be achieved by sufficient tuning using a network of a different rock raeesi et al 2013 while in most direct simulation approaches including the method used here no such tuning is performed we will demonstrate that not only that the relative permeability matches the experiment but also the pore scale fluid configuration in a series of publications schlüter et al 2016 liu et al 2017 and mcclure et al 2018 showed that the pore scale fluid configuration can be uniquely characterized using a set of geometric state variables mcclure et al 2018 in particular the euler characteristic provides a very relevant fingerprint of the fluid topology and relative permeability of the non wetting phase can be directly related to the euler characteristic of the non wetting phase liu et al 2017 hence in order to establish a fully convincing validation and predictive capability of the direct simulation approach validation of both the fluid topology and the relative permeability is required berg et al 2014 2016a b performed detailed investigations of fluid configurations and connected pathway relative permeability on a dataset obtained via a synchrotron based x ray computed micro ct imbibition experiment using a sandstone rock sample the gildehauser sandstone used in these papers has an average porosity of 20 and a permeability of 1500 400 md it has low clay content and a narrow pore size distribution 35 µm pore throat diameter which renders the rock well suitable for micro ct imaging berg et al 2016a we use the same gildehauser sandstone dataset to carry out investigations of the imaged vs simulated two phase flow fields the maximum inscribed rectangular prism of size 566 550 552 x y and z directions fig 1 is extracted from the original image of size 566 893 897 which contains an embedded image of a cylindrically shaped porous rock sample the voxel resolutions of both the original and the cut out image are 4 µm use of the maximum inscribed rectangular prism allows us to eliminate potential edge effects and impose a variant of the periodic boundary condition at the domain boundaries perpendicular to the main flow x direction the porosity of the extracted model is 0 19 and its permeability is 1 161 5 md the latter is computed by an efficient and accurate mrt lbm code for single phase pore scale flow simulation alpak et al 2018a for two phase pore scale flow simulation with elbm a small reservoir 16 lu is added at the inlet outlet of the simulation domain a constant velocity boundary condition is imposed at the inlet only the x component of the velocity vector u x i n l e t is non zero at the inlet in the experiment the rock sample was first saturated with brine hereafter referred to as water and then n decane also referred to as oil was injected at a high rate to reach a non wetting phase saturation around 0 78 the viscosities were 9 2 10 4 pa s and 1 0 10 3 pa s for n decane and water respectively giving rise to a viscosity ratio m η nw η w of 0 92 first the forced drainage process is simulated by imposing a relatively high velocity as the inlet boundary condition u x i n l e t 5 0 10 5 l u and the corresponding capillary number canw η nw unw γ in the simulation was 1 9 10 3 n decane is injected from one end of the domain until irreducible water saturation is established an interesting finding is that the simulated irreducible water saturation is 0 7947 fig 2 which is very close to the experimentally obtained value then the forced imbibition process simulated where water is injected to displace n decane for imbibition simulations locations of the inlet and outlet are swapped in other words the main flow direction is reversed for these simulations the inlet boundary condition imposed for the forced imbibition simulation was u x i n l e t 1 0 10 5 l u and the corresponding capillary numbers caw η w uw γ canw η nw unw γ in the simulation were 3 6 10 4 and 1 3 10 4 respectively further details of the fluid and rock properties of the gildehauser dataset and the experimental setup and procedures can be found in berg et al 2014 2016a b we quantify to which degree the pore scale fluid distributions predicted by use of elbm differ from the experimental data reported by berg et al 2016b for the imbibition process we perform a similar study for drainage but the comparison is carried out with respect to the quasi static morphological approach utilized in the same reference and briefly described above because no experimental fluid distribution data were reported for the primary drainage process that preceded the imaged imbibition experiment we compute the euler characteristic χ as a measure for the topology of the non wetting phase directly from the pore scale fluid configuration using the image processing software avizo fei the euler characteristic is a topological invariant that can be expressed as the difference between the number of objects zeroth betti number β0 and the number of redundant loops herring et al 2013 schlüter et al 2014 via 10 χ β 0 β 1 in fig 3 χ values computed for experimental and elbm simulated fluid configurations are plotted as a function of wetting phase saturation sw note that the calculation of χ can be very sensitive to small disconnected clusters that could be noise or segmentation errors in the experimental data and artifacts of the morphological approach therefore in fig 3 all clusters smaller than 100 voxels where a cluster with 100 voxels approximately corresponds to a spherical cluster size of about 25 µm diameter which is about the noise level in the data see berg et al 2014 are eliminated in the experimental elbm simulated and morphologically computed data for consistency in analysis fig 4 illustrates example non wetting phase oil configuration snapshots from imaged and simulated forced imbibition experiment for the same injected pore volume details of the configuration are different however overall pore occupancies are quite similar the trend in fig 4 is consistent with the euler characteristic analysis documented in fig 3 for the saturation range of the imbibition experiment 0 22 sw 0 70 we observe that χ 0 which indicates that the non wetting phase is percolating i e consists of more redundant loops mainly around the grains than individual clusters we show example fluid configurations during imbibition as predicted by elbm in fig 5 typically χ 0 is considered as an indication for the percolation threshold which for the experimental data is expected to be around sw 0 70 an excellent agreement is obtained between the experimentally determined and elbm simulated χ profiles for the imbibition process on the other hand the quasi static morphological approach and elbm predictions for χ exhibit significant disagreement for both drainage and imbibition processes the morphological approach exhibits notable violations of the water saturation range observed in the experiment 0 22 sw 0 70 while elbm simulations accurately capture it based on χ as one of the key measures for fluid topology we quantitatively demonstrate that the morphological approach produces very different and inconsistent pore scale fluid configurations compared to experimental observations unlike elbm the origin of the differences in the pore scale fluid configurations predicted by the morphological approach and elbm relates to neglecting viscous and inertial forces ferrari and lunati 2013 in modeling pore scale displacement processes by the morphological approach which operates in the capillary limit due to the absence of viscous forces relaxation phenomena and internal fluid re distribution caused by local capillary pressure gradients are not captured in any quasi static approach the associated time scales for relaxation range from seconds armstrong et al 2014 to many hours schlüter et al 2016 consequently during two phase flow at field relevant flow rates 1 3 ft day the fluid fluid interfaces and associated menisci do not reach capillary equilibrium instantly in most cases and the fluid dynamics is non local the quasi static method however always assumes an equilibrium curvature capillary re distribution phenomena are not captured and the interface dynamics is local on the other hand including viscous forces in addition to capillary forces and capturing global fluid dynamics are necessary for accurately predicting pore scale fluid configurations as demonstrated by elbm simulations fig 3 it is important to note that elbm is based on a thermodynamically based visco capillary model formulation 4 relative permeability study on the gildehauser dataset the number of studies in the open literature on the direct calculation of relative permeability for reservoir rocks is sparse martys and chen 1996 ramstad et al 2012 koroteev et al 2014 boek et al 2017 the effects of capillary number wettability and viscosity ratio on the relative permeability saturation functions were studied by li et al 2005 using the shan chen model shan and chen 1993 the challenges for the relative permeability computation from direct pore scale simulations are significant the direct simulator needs to be very accurate efficient robust and most importantly sufficiently flexible to reproduce the experimental conditions in the simulation with the exception of boek et al 2017 the above mentioned publications document relative permeability calculations on the basis of the random distribution of the non wetting phase according to the desired saturation such fluid configurations are straightforward to set up however they come with a number of drawbacks because they are not consistent with the experimental procedures for example there is no mechanism to prevent the small pores to be saturated by the non wetting phase while high capillary pressure typically prevents this in real life experiments absence of the notion of the drainage imbibition hysteresis makes it difficult to compute the imbibition relative permeability function we use a process based approach originally developed by yang 2013 and later used by boek et al 2017 to address the above challenges this approach accounts for the drainage imbibition hysteresis by use of direct simulations this method represents a steady state type of displacement approach to relative permeability computation a forced drainage process is simulated first here the in situ wetting phase fully saturating the pore space is displaced by an injected non wetting phase the rock model is fully saturated by the wetting phase a buffer layer saturated with oil is placed to the inlet and one saturated with water is placed to the outlet oil is injected from the inlet buffer layer into the pore space with a constant prescribed velocity until the average water saturation in the pore space does not exhibit an appreciable change saturation convergence at which time the drainage calculations are terminated note that the water saturation achieved in this way may not necessarily correspond to the irreducible or connate water saturation of a representative elementary volume as the viscous pressure drop achieved in such a small computational domain size much smaller than a core plug is significantly less than capillary pressure established in the porous plate or centrifuge method corresponding to the saturation height in an oil reservoir snapshots of the fluid configuration at different average water saturation values are used for the drainage relative permeability calculations the post drainage fluid configuration is then used as the initial state for the forced imbibition simulation where the non wetting phase is displaced by the wetting phase the fluids in the inlet and outlet buffers are interchanged prior to the forced imbibition calculations the forced imbibition calculations are continued again until average water saturation in the porous domain converges it is important to note that the visco capillary model formulation does not entirely capture the physics of spontaneous imbibition which is a solely capillary dominated process for stability reasons there is a problem dependent minimum limit to the inlet velocity that can be imposed to a forced imbibition simulation therefore the spontaneous imbibition is approximated by using a small constant velocity boundary condition that can be stably simulated by use of elbm depending on the accuracy of this approximation the oil saturation remaining at the end of the forced imbibition process may or may not necessarily correspond to the ground truth residual oil saturation due to a potentially limited viscous pressure drop fig 6 again the fluid configuration snapshots at different average water saturation values acquired during forced imbibition simulations are then used for relative permeability computations in order to ensure steady state conditions avraam and payatakes 1995 in the relative permeability computation for a given saturation snapshot calculations are performed using the loop type periodic boundary conditions imposed on all faces of the domain the full mirroring of the porous domain in the main flow direction is applied such that the periodic boundary condition is fully honored on the outlet face of the domain the system is then driven to steady state which closely mimics the steady state relative permeability experiment upon convergence of the system to steady state effective wetting and non wetting phase permeabilities computed by elbm are normalized by the absolute permeability computed with an accurate and efficient mrt lbm code alpak et al 2018a prior to the relative permeability simulation the fluxes used for computing effective wetting and non wetting phase permeabilities are derived by monitoring the average velocities of wetting and non wetting phases respectively over the part of the domain that corresponds to the porous rock in other words buffers are excluded from the flux calculations relatively longer buffers are used for forced drainage and especially forced imbibition process simulations when the intent is to use the resulting fluid configurations for subsequent relative permeability calculations to minimize the boundary effects moreover an additional ring of the internal rock domain neighboring the buffers can be excluded from the effective property calculations to further minimize the boundary effects this approach is typically used for the forced imbibition simulations the process is then repeated for all saturation snapshots that cover the saturation range observed during the forced drainage or forced imbibition process the relative permeability computation process is accurate physically robust and computationally quite demanding the computational demand directly scales with the saturation resolution i e the number of saturation snapshots required to accurately capture the relative permeability functions we compute the relative permeability curves for the gildehauser sandstone sample using the above described process based methodology for the imbibition process we use the saturation snapshots stemming from the imbibition simulation the gildehauser dataset also includes the steady state relative permeability data measured on a twin sample of very different much larger size moreover we also include in the comparison the relative permeability curves predicted by a quasi static morphological approach berg et al 2016a b we purposefully keep the connected pathway relative permeabilities reported in berg et al 2016a b outside the scope because they require beamline imaging which is very impractical for digital rock applications one would need to measure the pore scale fluid distribution in a synchrotron beamline experiment which requires even more effort than conducting a steady state relative permeability experiment berg et al 2016b panels of fig 7 show the comparison of experimental elbm simulated process based and morphologically predicted becker et al 2008 steady state relative permeability curves on linear and logarithmic scales we observe that the overall agreement of the elbm simulated relative permeability curves with experimental data is reasonably good the agreement of the elbm predicted non wetting phase oil n decane relative permeability with experimental data is very good however the wetting phase water relative permeability is slightly overpredicted by the direct simulation approach but the trend is quite similar to the experimental data here it is important to note that experimental relative permeabilities are derived from flow measurements on a much larger sample volume than the image used for the numerical relative permeability computations therefore it is reasonable to expect that there will be some effects of larger scale heterogeneities on the measured relative permeability data which cannot be captured through numerical simulation this may be true despite the image volume used may contain a sufficient number of grains and pore throats typical for a representative elementary volume approximation for absolute permeability estimation in all cases elbm predicted relative permeability curves honor the experimentally observed saturation range on the other hand the relative permeability curves predicted by the morphological approach grossly violate the experimentally observed saturation range the relative permeability curve for the non wetting phase exhibits a major divergence from experimental observations the relative permeability curve for the wetting phase does not show a consistent trend with the experimentally observed data overall the process based direct simulation driven prediction of the underlying fluid configuration field for relative permeability computations is a more reliable and accurate technique than the quasi static morphological approach 5 relative permeability study on a reservoir rock image having built in confidence on the underlying methodology of computing relative permeability through direct numerical simulation in the previous sections we have performed a relative permeability computation study for a sandstone rock from a producing reservoir a core plug of 1 in diameter and 2 5 in length is taken from the core and flow properties were measured the core plug is of 29 md permeability and its porosity is approximately 0 09 a steady state experimental relative permeability curve for the primary drainage of brine via decane injection was also available first we have performed absolute permeability and porosity computations using our in house mrt lbm permeability estimation code alpak et al 2018a on a representative x ray computed micro tomography image volume fig 8 the simulation domain size is 512 512 512 lattice units l u with a resolution of 2 03 µm per l u which corresponds to a physical domain size of 1 039 mm 1 039 mm 1 039 mm and a porosity of 0 11 the computed permeability in the x y and z directions are 31 8 34 3 and 36 6 md respectively subsequently we have simulated the forced drainage two phase displacement process until apparent connate water saturation is reached a small reservoir 16 lu is added at the inlet outlet of the domain for the forced drainage simulation we imposed a contact angle boundary condition with θ eq 40 on the solid surfaces for two phase flow simulations on the reservoir rock image volume using the computed saturation snapshots that are nearest on average to the experimentally observed saturation points we have computed the relative permeability values fig 9 documents the experimentally measured and computed relative permeability curves for the wetting and non wetting phase the agreement between the measured and computed relative permeability curves is reasonably well 6 conclusions a detailed analysis of fluid topology is performed for a gildehauser sandstone dataset including a favorable comparison between imaging determined and numerically simulated euler characteristic profiles for the imbibition cycle finally we use the same gildehauser sandstone dataset to compute process based steady state relative permeability curves through the full visco capillary simulation via elbm and compare them to the ones computed by a morphological approach and steady state relative permeability measurements performed on a core plug which is much larger than the image used for numerical computations we observe that the overall agreement of the elbm simulated relative permeability curves with experimental data is very good for the non wetting phase and satisfactory while being still better than quasi static method predictions for the wetting phase elbm predicted relative permeability curves honor the experimentally observed saturation range on the other hand the relative permeability curves predicted by the quasi static morphological approach grossly violate the experimentally observed saturation range the relative permeability curve for the non wetting phase exhibits a major divergence from experimental observations the relative permeability curve for the wetting phase does not show a consistent trend with the experimentally observed data overall the process based direct simulation driven prediction of the underlying fluid configuration field is a more reliable and accurate technique than the quasi static morphological approach a separate study is conducted for a real reservoir rock where simulated and experimentally measured steady state relative permeability curves are compared for a forced drainage process it has been observed that the agreement between the measured and computed relative permeability curves is reasonably well supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2018 09 001 appendix supplementary materials image application 1 ahrenholz et al 2008 b ahrenholz j tölke p lehmann a peters a kaestner m krafczyk w durner prediction of capillary hysteresis in a porous material using lattice boltzmann methods and comparison to experimental data and a morphological pore network model adv water res 31 2008 1151 1173 alpak et al 2018a f o alpak f gray n saxena j dietderich r hofmann s berg a distributed parallel multiple relaxation time lattice boltzmann method on general purpose graphics processing units for the rapid and scalable computation of absolute permeability from high resolution 3d micro ct images comput geosci 22 2018 815 832 alpak et al 2016 f o alpak b riviere f frank a phase field method for the direct simulation of two phase flows in pore scale media using a non equilibrium wetting boundary condition comput geosci 20 2016 881 908 alpak et al 2018b f o alpak a samardžić f frank a distributed parallel direct simulator for pore scale two phase flow on digital rock images using a finite difference implementation of the phase field method j petroleum sci eng 166 2018 806 824 alpak et al 2018c f o alpak i zacharoudiou s berg j dietderich n saxena direct simulation of pore scale two phase visco capillary flow on large digital rock images using a phase field lattice boltzmann method on general purpose graphics processing units comput geosci 2018 submitted anderson et al 1998 d m anderson g b mcfadden a a wheeler diffuse interface methods in fluid mechanics annu rev fluid mech 30 1 1998 139 165 armstrong and berg 2013 r t armstrong s berg interfacial velocities and capillary pressure gradients during haines jumps phy rev e 88 4 2013 043010 armstrong et al 2016a r t armstrong s berg o dinariev n evseev d klemin d koroteev s safonov modeling of pore scale two phase phenomena using density functional hydrodynamics transp porous media 112 3 2016 577 607 armstrong et al 2016b r t armstrong j e mcclure m a berill m rücker s schlüter s berg beyond darcy s law the role of phase topology and ganglion dynamics for two fluid flow phys rev e 94 2016 043113 armstrong et al 2014 r t armstrong h ott a georgiadis m ruecker a schwing s berg sub second pore scale displacement processes and relaxation dynamics in multiphase flow water resour res 50 12 2014 9162 9176 avraam and payatakes 1995 d avraam a payatakes flow regimes and relative permeabilities during steady state two phase flow in porous media j fluid mech 293 1995 207 236 ayub and bentsen 2005 m ayub r g bentsen experimental testing of interfacial coupling in two phase flow in porous media pet sci technol 23 2005 863 897 bear and bachmat 1990 j bear y bachmat introduction to modeling of transport phenomena in porous media 1990 kluwer academic publishers the netherlands becker et al 2008 j becker v schulz a wiegmann numerical determination of two phase material parameters of a gas diffusion layer using tomography images j fuel cell sci technol 5 2 2008 021006 9 berg et al 2014 s berg r armstrong h ott a georgiadis s a klapp a schwing r neiteler n brussee a makurat l leu f enzmann j o schwarz m wolf f khan m kersten s irvine m stampanoni multiphase flow in porous rock imaged under dynamic flow conditions with fast x ray computed microtomography petrophysics 55 4 2014 304 312 berg et al 2008 s berg a w cense j p hofmann r m m smits two phase flow in porous media with slip boundary condition transp porous media 74 2008 275 292 berg et al 2013 s berg h ott s a klapp a schwing r neiteler n brussee a makurat l leu f enzmann j o schwarz m kersten s irvine m stampanoni real time 3d imaging of haines jumps in porous media flow proc natl acad sci 110 10 2013 3755 3759 berg et al 2016a s berg m rücker h ott a georgiadis h van der linde f enzmann m kersten r t armstrong s de with j becker a wiegmann connected pathway relative permeability from pore scale imaging of imbibition adv water res 90 2016 24 35 berg et al 2016b s berg m rücker h ott a georgiadis h van der linde f enzmann m kersten r t armstrong s de with j becker a wiegmann modelling of imbibition relative permeability by direct quasi static approach paper sca2016 007 presented at the international symposium of the society of core analysts held in snowmass 21 26 august colorado usa 2016 blunt et al 2002 m j blunt m d jackson m piri p h valvatne detailed physics predictive capabilities and macroscopic consequences for pore network models of multiphase flow adv water res 25 2002 1069 1089 boek et al 2017 e s boek i zacharoudiou f gray s m shah j p crawshaw j yang multiphase flow and reactive transport validation studies at the pore scale by use of lattice boltzmann computer simulations spe j 22 3 2017 940 949 bowen 1982 r bowen compressible porous media models by use of the theory of mixtures int j eng sci 20 6 1982 697 735 briant and yeomans 2004 a j briant j m yeomans lattice boltzmann simulations of contact line motion ii binary fluids phys rev e 69 3 2004 031603 bultreys et al 2018 t bultreys q lin y gao a q raeini a alratrout b bijeljic m j blunt validation of model predictions of pore scale fluid distributions during two phase flow phys rev e 2018 053104 cahn 1977 j cahn critical point wetting j chem phys 66 8 1977 3367 dake 1978 l p dake fundamentals of reservoir engineering 1978 elsevier b v the netherlands darcy 1856 h darcy détermination des lois d écoulement de l eau à travers le sable p victor dalmont les fontaines publiques de la ville de dijon 1856 v dalmont paris france 590 594 das and hassanizadeh 2005 d b das s m hassanizadeh upscaling multiphase flow in porous media 2005 springer d humières et al 2002 d d humières i ginzburg m krafczyk p lallemand l s luo multiple relaxation time lattice boltzmann models in three dimensions philosophical transactions of the royal society a mathematical phys eng sci 360 1792 2002 72 ding and spelt 2007 h ding p d m spelt wetting condition in diffuse interface simulations of contact line motion phys rev e 75 2007 046708 1 8 evseev et al 2016 n evseev r t armstrong s berg o dinariev d klemin d koroteev s safonov modeling of pore scale two phase flow phenomena using density functional hydrodynamics transp porous media 112 3 2016 577 607 ferrari et al 2015 a ferrari j jimenez martinez t le borgne y méheust i lunati challenges in modeling unstable two phase flow experiments in porous micromodels water resour res 51 3 2015 1381 1400 ferrari and lunati 2013 a ferrari i lunati direct numerical simulations of interface dynamics to link capillary pressure and total surface energy adv water res 57 2013 19 31 frank et al 2018 f frank c liu f o alpak s berg b riviere direct numerical simulation of flow on pore scale images using the phase field method spe j 2018 published online gray and miller 2005 w g gray c t miller thermodynamically constrained averaging theory approach for modeling of flow in porous media 1 motivation and overview adv water resour 28 2 2005 161 180 gray et al 2013 w g gray c t miller b a schrefler averaging theory for description of environmental problems what have we learned adv water res 51 2013 123 138 hammond and unsal 2012 p s hammond e unsal a dynamic pore network model for oil displacement by wettability altering surfactant solution transp porous media 92 3 2012 789 817 hassanizadeh and gray 1993 s m hassanizadeh w g gray toward an improved description of the physics of two phase flow adv water res 16 1 1993 53 67 hecht 2010 m hecht j harting implementation of on site velocity boundary conditions for d3q19 lattice boltzmann simulations j stat mech 2010 p01018 herring et al 2013 a l herring e j harper l andersson a sheppard b k bay d wildenschild effect of fluid topology on residual nonwetting phase trapping implications for geologic co2 sequestration adv water res 62 2013 47 58 hilfer 1998 r hilfer macroscopic equations of motion for two phase flow in porous media phys rev e 58 2 1998 2090 2096 hilpert and miller 2001 m hilpert t c miller pore morphology based simulation of drainage in totally wetting porous media adv water res 24 2001 243 255 honarpour et al 2000 m honarpour l koederitz a h harvey relative permeability of petroleum reservoirs 2000 crc press boca raton fl u s a jettestuen et al 2013 e jettestuen j o helland m prodanović a level set method for simulating capillary controlled displacements at the pore scale with nonzero contact angles water resour res 49 2013 1 17 joekar niasar et al 2009 v joekar niasar s m hassanizadeh l j pyrak nolte c berentsen simulating drainage and imbibition experiments in a high porosity micromodel using an unstructured pore network model water resour res 45 2 2009 w02430 15 joekar niasar et al 2010 v joekar niasar m prodanović d wildenschild s m hassanizadeh network model investigation of interfacial area capillary pressure and saturation relationships in granular porous media water resour res 46 6 2010 w06526 18 johnson et al 1959 e f johnson d p bossler v o naumann calculation of relative permeability from displacement experiments trans aime 216 1959 370 372 kendon et al 2001 v kendon m cates i pagonabarraga j c desplat p bladon inertial effects in three dimensional spinodal decomposition of a symmetric binary fluid mixture a lattice boltzmann study j fluid mech 440 2001 147 203 kokkedee et al 1996 j a kokkedee w boom a m frens j g maas improved special core analysis scope for a reduced residual oil saturation proceedings of society of core analysis conference aper 9601 1996 1 13 koroteev et al 2014 d koroteev o dinariev n evseev d klemin a nadeev s safonov o gurpinar s berg c van kruijsdijk r armstrong m t myers l hathon h de jong direct hydrodynamic simulation of multiphase flow in porous rock petrophysics 55 4 2014 294 303 korteland et al 2010 s korteland s bottero s m hassanizadeh c w j berentsen what is the correct definition of average pressure transp porous media 84 1 2010 153 175 larson et al 1981 r g larson l e scriven h t davis percolation theory of two phase flow in porous media chem eng sci 36 1 1981 57 73 li et al 2005 h li c pan c t miller pore scale investigation of viscous coupling effects for two phase flow in porous media phys rev e 72 2 2005 026705 li and wagner 2007 q li a j wagner symmetric free energy based multicomponent lattice boltzmann method phys rev e 76 2007 036701 liu et al 2017 z liu a herring c arns s berg r t armstrong pore scale characterization of two phase flow using integral geometry transp porous media 118 1 2017 99 117 martys and chen 1996 n s martys h d chen simulation of multicomponent fluids in complex three dimensional geometries by the lattice boltzmann method phys rev e 53 1 1996 743 750 masalmeh et al 2015 s k masalmeh x jing s roth c wang h dong towards predicting multi phase flow in porous media using digital rock physics workflow to test the predictive capability of pore scale modelling abu dhabi international petroleum exhibition and conference held in abu dhabi u a e 9 12 november paper spe 177572 2015 mcclure et al 2018 j e mcclure r t armstrong m a berrill s schlüter s berg w g gray c t miller a geometric state function for two fluid flow in porous media phys rev fluids 3 2018 084306 muskat 1936 m muskat m w meres the flow of heterogeneous fluids through porous media j appl phys 7 1936 346 363 niessner et al 2011 j niessner s berg s m hassanizadeh comparison of two phase darcy s law with a thermodynamically consistent approach transp porous media 88 2011 133 148 nordbotten et al 2008 j m nordbotten m a celia h k dahle s m hassanizadeh on the definition of macroscale pressure for multiphase flow in porous media water resour res 44 6 2008 w06s02 pooley and furtado 2008 c m pooley k furtado eliminating spurious velocities in the free energy lattice boltzmann method phys rev e 77 4 2008 046702 rabbani et al 2017 h s rabbani v joekar niasar t pak n shokri new insights on the complex dynamics of two phase flow in porous media under intermediate wet conditions sci rep 7 1 2017 4584 raeesi et al 2013 b raeesi n r morrow g mason pore network modelling of experimental capillary pressure hysteresis relationships paper sca2013 015 international symposium of the society of core analysts held in napa valley california usa 16 19 september 2013 raeini et al 2014 a q raeini m j blunt b bijeljic direct simulations of two phase flow on micro ct images of porous media and upscaling of pore scale forces adv water res 74 2014 116 126 ramstad et al 2012 t ramstad n idowu c nardi p e øren relative permeability calculations from two phase flow simulations directly on digital images of porous rocks transp porous media 94 2 2012 487 504 rücker et al 2015 rücker m berg s armstrong r t georgiadis a ott h schwing a neiteler r brussee n makurat a leu l wolf m khan f enzmann f kersten m from connected pathway flow to ganglion dynamics geophys res lett 42 10 2015 3888 3894 saxena et al 2017 n saxena r hofmann f o alpak s berg j dietderich u agarwal k tandon s hunter j freeman o b wilson 
