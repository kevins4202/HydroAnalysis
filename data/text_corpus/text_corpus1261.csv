index,text
6305,the description of the floods which have occurred in the past and an assessment of the adverse impacts they have entailed are among the duties required by the european flood directive indeed to understand the consequences of a future flood on a city that in the past has already been affected by other flood events it is very useful to reconstruct the hydraulic effects produced by those events such a task is particularly difficult for cases which occurred many years ago for past events it is often easier to have conventional hydrological data for example the hyetographs of the event than conventional hydraulic data recordings of flow rates water depths etc it is also difficult to obtain the topography valid for the period in which the event occurred the greater the distance in time the greater the difficulty in gathering these data in this paper we present a criterion for making a flow of information using various non conventional sources of information such as amateur videos photographs traditional topographic surveys news reports etc in particular it is shown how the data thus obtained can be used together in order to reconstruct numerically the hydraulic dynamics of a flood event in an urban area with a complete hydrodynamic model which requires a particularly accurate computational domain all these issues will be presented and discussed with reference to the numerical reconstruction of the flood event that occurred 23 years ago 1996 in the city of crotone calabria italy keywords flood reconstruction hydraulics effects post flood surveys urban flooding non conventional data 1 introduction in the last few years the numerical modelling aimed at the simulation of flood events in urban areas has been significantly improved thanks to the progress achieved in several fields such as the physical mathematical description of flood behaviour the increase of computing power and the ever more accurate techniques of topographic surveys the advances in these fields are documented by many studies dealing with purely modelling issues i e mark et al 2004 hunter et al 2008 neal et al 2012 costabile and macchione 2012 néelz and pender 2013 ozdemir et al 2013 costabile et al 2015 hou et al 2015 papaioannou et al 2016 fernández pato et al 2016 vacondio et al 2016 fleischmann et al 2018 martins et al 2018 or focused on the relations between modelling and topographic surveys aspects including the techniques for the representation of buildings i e yu and lane 2006 fewtrell et al 2011 tsubaky and kawahara 2013 vojinovic et al 2013 kvočka et al 2015 shen et al 2015 abily et al 2016 chen et al 2017 other papers have been more oriented to the representation of buildings as a sub grid process also known as the porosity based approach defina et al 1994 among these the works proposed by the following authors are relevant guinot and soares frazão 2006 sanders et al 2008 soares frazão et al 2008 cea and vázquez cendón 2010 schubert and sanders 2012 kim et al 2015 costabile et al 2017 özgen et al 2016 guinot et al 2017 velickovic et al 2017 bruwier et al 2017 viero and valipour 2017 bruwier et al 2018 viero 2019 despite the plethora of studies available in the literature on this topic it should be observed that the number of highly detailed real world cases that can be effectively used for the calibration validation and assessment of the numerical models is not so high for example neal et al 2009 noted that due to the lack of detailed validation data the urban flood events for which the accuracy of the numerical simulation has been assessed against data relative to the inundation extent or water surface elevations are very few an extensive list of recent papers in which real world cases of urban flooding have been studied is shown in table 1 table 1 highlights that there are not many cases for which observed hydrographs in some sections or maximum water levels reached by the flood flow are available in particular only the observed data relative to the flood events reported in mignot et al 2006 neal et al 2009 abdullah et al 2012 vojinovic et al 2013 kvočka et al 2015 portugués mollá et al 2016 segura beltrán et al 2016 include also the maximum water levels research activities aimed at data collection especially referred to flash floods events can be found in the literature gaume et al 2009 marchi et al 2010 gaume and borga 2008 in general performing post events surveys is a tedious and difficult task gaume and borga 2008 kjeldsen et al 2014 this activity is undoubtedly more complex and arduous when data collection refers to an urban flooding a relevant example of this has been presented by portugués mollá et al 2016 who analysed the flood event which occurred in the city of valencia spain in 1957 in that case the temporal distance of the event induced the authors to analyse it through a gis database obtained by using an enormous amount of documents and photos it is evident that whenever possible the data collections are very useful also in order to perform hydraulic simulations aimed at the numerical reconstruction of the event reliable numerical reconstructions of past flood events can be essential not only for the validation of simulation models but also to application of them to predict future scenarios in order to give an effective support in several aspects related to flood risk assessment and management in this regard the european directive 2007 60 ce states there is a need of a description of the significant floods which have occurred in the past where significant adverse consequences of similar future events might be envisaged in those cases for which no conventional measures of the main hydrodynamic and hydrological variables water depths in the main river channel or in the adjacent flood prone areas velocities discharge hydrographs topographic data etc are available the reconstruction of past flood events becomes an extremely complicated task a very detailed example of this kind of work has been presented by segura beltrán et al 2016 who have analysed flash floods of the girona river spain in 2007 using post flood surveys and geomorphologic mapping to evaluate hydrological and hydraulic models another example can be found in the work of neal et al 2009 for the severe flooding event which occurred in and around the city of carlisle england on the 8th january 2005 a third example is the work presented by kvočka et al 2015 related to the flood event which occurred in the city of boscastle on the 16th august 2004 for each of the three cases mentioned above lidar data were available the greater the distance in time the greater the difficulty in studying a flood event of the past mainly because it is quite hard to have a detailed topographic description of the flooded areas suitable for two dimensional numerical simulations for example in order to numerically reproduce the flood event which occurred in the october of 1988 in the city of nîmes france mignot et al 2006 used about 200 cross sectional profiles describing the 60 streets located in the studied area martín vide and llasat 2018 accurately revisited the very disastrous 1962 rubí flood spain from a meteorological pluviometric hydraulic hydrological and sediment transport point of view in general for past flood events the hydrologic data are very often more abundant than the hydraulic ones indeed it is much more difficult to obtain conventional hydraulic data in particular time trend of levels and velocities at different points of the flooded area however the importance of these data for the reasons given above requires that efforts be made to extract them from unconventional documents although this work requires a lot of patience and a lot of time the novel methodological contribution of this article is the reconstruction of the hydraulic effects of the flood events including the numerical simulation of the flood evolution in urbanized areas based only on the sources of available information represented by non conventional data such as amateur videos photographs traditional topographic surveys news reports etc this approach requires a patient work aimed at the identification of flooded areas velocities maximum water levels and temporal flood evolution sometimes comparing the images extracted from the videos to those available in street view mode using google earth software the second relevant activity of this research has been focused on a reliable reconstruction of the computational domain representative of the situation of the territory at that time in particular a specific procedure aimed at the integration of traditional digital topographic maps and cross sections surveyed post event and more recent lidar data has been developed and discussed the third aspect of this research is checking the coherence of the hydrological input estimations with the observed hydraulic effects of the flood all these open issues have been analysed and discussed in the reconstruction of a flood event that occurred 23 years ago 1996 in the city of crotone calabria italy the following sections present the methods used the information obtained the hydraulic simulations and the conclusions 2 methodological approach in those cases for which no hydraulic and topographic conventional data are available attention can be focused on the sources of information non conventional data listed below which could be related to each other generating the flow of information reported in fig 1 and explained in the following subsections 2 1 damage estimations damage estimation is information related to flooding effects in terms of direct economic loss due to damaged goods it is quite difficult to relate them to the flood dynamics however they could be useful for an indirect estimation of the flooded areas on the basis of the location of damaged goods 2 2 post event reports related to indirect evaluations of flood watermarks these are the closest data to the hydraulic aspects of the event often these data are derived from the marks left by the water on the walls of the buildings or from the position of the floating objects that remained entangled at the maximum altitude reached by the water it must be said that these data do not always correspond to the maximum levels reached by the current it may happen that they correspond rather to the levels at which the water stayed for the longest time for example if the signs left by the water are perfectly horizontal it means that the speed there was almost nil so it is mostly water that remained stagnant even after the passage of the flood peak 2 3 photos photographs represent a specific instant of the event or its consequences in a certain place from them information about the levels or the extent of the flooded area can be derived if they are taken during the event or if signs left by the water are visible they are also useful as it is possible to have a qualitative evaluation of the forces exerted by the current if they document displaced objects vehicles rubbish bins vegetable debris sediments mud or garage doors and broken down walls however they are only useful if you can recognize the site and if possible if the shooting time is known 2 4 videos videos are commonly taken by professional reporters or by amateurs in the first case the quality is very high but they are usually quite limited in time on the contrary the amateurs videos generally have a longer duration but their quality could be significantly lower than that of the professionals usually the video reporter does not have a hydraulic sensibility leading to the filming of details not particularly useful for the hydraulic reconstruction of the situation nevertheless the careful and patient analysis of each frame can lead to the extraction of useful information related to the temporal evolution of the phenomenon specifically the evolution of the water levels moreover it is possible to build a patchwork of frames in order to obtain a panoramic shot of the flooding during its evolution finally filming small floating bodies could be useful in providing estimations of the flood velocity 2 5 google earth and street view almost all the surface of the world is currently viewable with google earth with this tool it is possible to obtain information on the ground coverage for the extra urban areas and on the urban fabric of the cities it is not always possible to have the chronology of images that date back to the date of the event however these tools are useful for interactively and dynamically viewing the areas that have remained unchanged over time the possibility to change the point of view of the image as you want allows you to identify with relative ease the locations represented in the photographs and videos photographs and videos whose location could not be identified can easily be located by looking in google earth and in street view for the same point of view from which the photographs were taken provided they contain an easily recognizable reference point 2 6 information taken from local mass media the reports in the newspapers or the radio television reports most often focus on the consequences of the flood from the point of view first of the loss of human life and economic damage and interruptions to normal activities schools offices traffic etc unfortunately this information is not very detailed on the hydrodynamic aspects of the event but they can be helpful to obtain early indications of a hydraulic nature that need to be fleshed out with other sources of information listed here 2 7 interviews with eyewitnesses the people involved in the flood are usually interviewed by local mass media and judicial authorities these are people who have personally experienced the event and can therefore provide information from which we can indirectly have elements of knowledge on the dynamics and the timing of the event 2 8 topographic maps generally for the topography of the area to be studied official topographic maps issued by the government technical offices are available unfortunately they often have too low a resolution to be used alone as a basis for the construction of the computational domain especially for urban areas therefore they must be integrated with other data sources such as the topographic surveys after the event or more recent surveys that can be used to represent the topography of the areas that have remained unchanged over time 2 9 lidar surveys lidar surveys are not available for past flood events that happened long ago since this technique is relatively recent however recent lidar surveys can be used to adequately represent those areas that have not undergone major topographic changes over time the sewing up of the lidar survey with the information extracted from the topographic maps contemporary to the event and with those extracted from the post event topographical surveys can allow the computational domain to be realized with sufficient accuracy 2 10 post event topographic surveys usually after a flood event that has produced considerable damages defence structures are built on the riverbed for the protection against future floods therefore after some years the topography will be different from the topography of the area at the time of the event in these cases topographic surveys are usually performed immediately after the event if similar surveys carried out immediately before the event are not available it becomes very difficult to quantify the plano altimetric variations of the riverbed caused by the flood although the final bed level may not be the bed level at the flow peak nor the bed level before the flood post event surveys are very useful because they allow us to reconstruct a topographic representation of the riverbed as close as possible to the one at the time of the event 2 11 orthophotos the orthophotos give useful information on the state of the places at the time of the event in particular they give information on the degree of urbanization of the area and on the presence of vegetation and artefacts that interfere with the current flowing within the channel and with the water outflowing in the flooded areas 2 12 hydrological inputs generally the hydrological analysis of the event is the first study performed on significant flood events especially those that have produced damage and it is aimed at the reconstruction of the flood hydrograph this is generally done by using hydrological rainfall runoff models whose input data when available are the recorded hyetographs for the area under examination based on these inputs the numerical reconstruction of the spatial and temporal evolution of the flood flow is then performed symmetrically the reliability of numerical reconstruction can be used to verify the correctness of the hydrological input for the sake of completeness it should be observed that for more recent and future flood events other sources of information can be used to extract quantitative data related to flow one option is represented by the use of large scale particle image velocimetry lpsiv whose accuracy for discharge measurements and velocity fields derived from imagery of the water surface has been recently analyzed i e lewis et al 2018 another possible choice is the analysis of satellite derived flood extent maps that can be used for the calibration and validation of the hydraulic models in this context satellite borne synthetic aperture radar sar sensors have been extensively used to support the knowledge of many flooding events based on an image processing technique see for example garcía pintado et al 2015 finally it should be recalled the important role played by social media e g facebook and twitter in disaster management for receiving disaster information and warnings and for linking community members following a disaster starkey et al 2017 barker and macleod 2019 in this field the increasing importance of the so called volunteered geographic data should be underlined since they include any geo located information on a disaster and can comprise a diverse range of data including personal accounts photographs and videos and crowd sourced measurements see for example rollason et al 2018 the use of these data is fostering the development of procedures able to extrapolate quantitative information from footages an example of this can be found in the work of milanesi et al 2016 who proposed a set of procedures to quantify the individual s stability condition during a flood event from videos and in zheng et al 2018 who discussed recent techniques for using crowdsourced images and videos 3 description of the case study and available data 3 1 general features of the case study the case study analysed in this work is one of the most important events which has occurred in the calabria region south of italy in the last few decades specifically in the city of crotone on 14th october 1996 the flood wave of the esaro river provoked the inundation of a wide area of the city of crotone see fig 2 for a general overview the pluviometric station located in crotone recorded an hourly precipitation of 72 8 mm between 10 00 and 11 00 a m and a precipitation equal to 112 4 mm in the six hours between 7 00 a m and 13 00 p m the flood event caused six fatalities and several injuries induced the collapse of bridges and the northern overpass near the gesù neighbourhood hereafter called neighbourhood 1 and the disruption of the main access roads including the railway several buildings commercial activities and small factories registered enormous damages the values of the water depths and velocities were such that significant hazard conditions occurred in the urbanized areas the meteorological and hydrological details and the consequences on the flooded areas are reported in gabriele 1998 3 2 available conventional data 3 2 1 topographic data the available cartographic data are represented by pre event digital maps obtained from an aero photogrammetric survey dated 1994 scale 1 1000 in the gauss boaga reference system this map that can be reasonably assumed to be representative of the geometric peculiarities of the river and the neighbouring areas at the time of the event is shown in fig 3 the latter figure shows the level of detail that characterizes structural infrastructural and morphologic elements and two details near two bridges san francesco and ex fcl called bridge 1 and bridge 2 hereafter that will be analysed later on in this work moreover several cross sections were surveyed seven months after the event whose location is represented by red lines in fig 3 finally the 1 m digital elevation model obtained from the airborne lidar survey dated 2015 has been also considered to represent those neighbouring areas flooded in 1996 that have not been significantly changed over time 3 2 2 hydrometric and hydrological data no water level measurements in the river are available during the flooding event instead some post event estimates of the maximum water levels were surveyed as pre fixed ranges and reported in a map drawn up by working group for the data collection of the crotone flood of 14 10 1996 unpublished no hydrological observed data are available d asaro and niccoli 1998 proposed two different discharge hydrographs hereafter called hydrograph 1 and hydrograph 2 estimated by rainfall runoff models applied to the whole basin upstream of the bridge 1 see fig 4 3 3 available non conventional data visual documentation of the crotone inundation the information on the hydraulic effects of the flood inundation has been extracted from an accurate analysis of the available visual documentation in particular it consists of amateur videos stored in vhs formats the quality of which is relatively poor being analog videotapes unfortunately there are few images that document the flood in progress much more visual documentation regarding the situations around the city just after the flood evolution is available the videos have been analysed carefully in order to document the hydraulic impacts not only to quantify them but also to assess the correctness of the results of the simulations unfortunately several times the authors of the videos even though showing interesting particulars did not show high view angles of the flooded areas but limited their footage to some details that do not allow the topographic localization of the viewpoints 4 extracting hydraulic effects induced by the flood flow from video analysis quantitative issues for all the situations for which the videos show parts of roads buildings or other recognizable objects a systematic identification of them within the city has been carried out in order to localize exactly the observed viewpoints to that purpose when possible the images of the city as shown in the videos were compared with those that can be seen from the google earth and street view software using practically the same viewpoints in those cases for which the author of the videos moved the camera gradually in order to film a wide area the single frames have been gathered together so that wide overviews of the flooded areas could be represented using this method original images of crotone city during or just after the inundation have been obtained even though their quality is low due to the poor video resolution then the specific viewpoints extracted from the videos have been localized in the cartographic map 4 1 analysis of the temporal evolution of the water levels in the areas close to the upstream boundary condition no verifications have been performed on the reliability of those hydrographs depicted in fig 4 in terms of coherence with the hydraulic effects observed on the flooded areas since they have been computed considering the whole basin upstream to the bridge 1 the attention has been focused on the areas close to this section 4 1 1 analysis of the flood hydraulic behaviour near a trapped car a very interesting aspect that has been found in one of the available videos is what happened to a car an amaranth red colour five door fiat uno caught in the middle of the flow along the road near the high school for surveyors hereafter referred to as school see fig 2 and filmed for half an hour the local newspapers of that time reported several pieces of information which have proved useful in reconstructing the accident three people were on board after crossing bridge 1 the car was hit by the flow and carried off the road the driver jumped onto the top of the car and stayed there for two hours the analysis of the video allowed us to generate a never before seen image depicted in fig 5 a obtained through a patchwork of several frames moving from left to right this figure shows the school the car and the driver on the top of the car and the bridge railings emerging from the water see also fig 6 for other details of the bridge the water levels reached by the flow can be deduced by the frames extracted from the video highlighted in fig 5b in which the last picture represents the car after the flood event since the car is 1 42 m in height the frames analysis leads to the estimates of the water depths shown in table 2 despite the uncertainties that might affect those estimations it is important to observe that their values can be assumed accurate enough for this situation also because what is really important here is not so much the numerical value but their temporal evolution 4 1 2 analysis of the flood hydraulic behaviour close to the electricity column located near the road external to the bridge 1 left abutment another useful piece of information that can be extracted from videos is the water levels evolution close to an electricity column located to the left of bridge 1 the electricity column has been highlighted with a green rectangle in fig 5b by comparing it to the height of the people it can be assumed that the electricity column is 1 2 m tall the water levels estimated in the instants of time relative to some frames shown in fig 5b are reported in table 2 4 1 3 analysis of the flood hydraulic behaviour close to bridge 1 the analysis of the videos allowed us to evaluate the temporal evolution of the water levels just above the road surface of bridge 1 see fig 6 these estimations are reported in table 2 despite the low quality of the images the analysis of the flow motion in both upstream and downstream directions highlighted that the bridge though overtopped by the flow was not fully obstructed moreover from 13 15 p m on a sudden lowering of the water depths upstream of the bridge is observed that could be explained by a significant unclogging of the bridge itself 4 2 analysis of the water levels and velocities in the middle of the computational domain areas close to bridge 2 in this section the peculiarities of the flood flow behaviour in areas located in the middle of the computational domain are discussed in particular attention is focused in a specific area close to a steel bridge bridge 2 see figs 2 3 and 7 a one of the available videos captured for a long time the river flow situation in both the upstream and downstream directions and in addition the buildings located on the right side of the bridge no information about the time of the videotape is available but it occurred when the flood flow interacted with the bridge deck see fig 7e fig 7d highlights that pieces of wooden floating debris were trapped in the bridge trusses this situation has not been observed during the rising phase of the flow see fig 7c therefore it can be deduced that the water levels overtopped the top of the bridge the hydraulic situation of this part of the river in these instants of time can be analysed in the patchwork of images extracted from the video and shown in fig 7b the point of view of the video operator has been highlighted in fig 7a the yellow lines delimit the view angle of the scene represented in the patchwork for these areas three river cross sections are available see sections s10 s11 and s12 in fig 8 efforts have been made in order to extract from the videos the maximum water levels close to these sections in particular attention has been focused on the cross section s12 see fig 8c because the viewpoint of the video operator was located close to the extreme part of the section on the right identified by the number 122 section 12 extreme 2 in fig 8a a patchwork of frames obtained from the video shows the hydraulic situation near the cross section s12 that can be further appreciated in fig 8b which is a zoom of the previous image considering together the map shown in fig 8c and the cross section of fig 8e it can be observed that that extreme point is located near a courtyard boundary wall see fig 8d for a detail the point 122 has been highlighted with a red circle in the fig 8a 8b and 8e to make comprehension of the area easier the analysis of the image close to the courtyard shows that the water reached the ground level of that courtyard which according to the profile of the section is about 7 83 m for this reason this value can be assumed as the maximum water level reached by the flow in the right part of the section s12 finally other investigations have been carried out in order to extract some watermarks in the extreme part of the section on the left identified by the number 121 on fig 8c to this purpose the google earth map shown in fig 9 a in which the red line represents the section s12 is useful for the localization of some elements of the areas in particular fig 8c and 9a show that the extreme point of the left is located close to the edge of the railway station square but unfortunately no images are available for this area though not shown here some video frames document a residual inundation of the areas behind the railway station using google earth it is possible to travel along the road highlighted by the yellow dotted line reported in fig 9a and 9b reaching the views shown in fig 9c and 9d and further detected by the circles 1 and 2 the yellow arrows highlighted in fig 9a and 9b help to realize the point of view of the images depicted in fig 9c and 9d the viewpoint shown in fig 9b can be detected in the videos as shown by the frame reported in fig 9e in which the yellow lines highlight the water level reached by the flood flow the point shown in fig 9e as highlighted in a google earth image represented in fig 9b is located very close to the extreme left part of the section s12 since this point falls in a quite protected area the kinetic energy term may be assumed not to be particularly significant so that the water levels observed there can be reasonably assumed as representative of the maximum water levels reached by the flow in the section s12 considering that according to the available lidar data the road level is 6 8 m a s l and from the frames the water depth value can be estimated approximately equal to about 1 2 1 3 m by a comparison with the cars and the door that can be seen in fig 9e the maximum water level in this point can be considered approximately 8 8 1 m a s l 4 2 1 rough estimation of the flow velocity using video images the available videotapes have been also analysed carefully in order to provide some rough estimation of the flow velocity attention has been focused on a floating wooden pallet transported by the flow that can be seen for five seconds in the videos see fig 10 this object seems to be representative of a common pallet of standard dimension 80 cm wide and 120 cm long shown in fig 10a three frames have been considered see fig 10b 10c and 10d that cover an interval of 2 s then a superimposition of the three frames has been carried out using the open source software gimp considering some specific reference points see fig 10f the length covered by the object has been estimated using as unit of measure the lenght of the pallet itself 1 2 m the estimated velocity is 2 3 m s in order to verify this value the velocity has been computed again using the frames shown in the fig 10b and e that cover five seconds performing again a superimposition of the images see fig 10g and repeating the above described method for the computation of the length covered by the object we found again an estimated velocity of 2 3 m s the google earth software has been used again in order to locate the plan position of the pallet setting the google earth street view mode in such a way as to obtain a similar viewpoint of the author of the video see fig 11 a b though the current image available in that software shows different river banks due to the post event hydraulic works carried out in those areas it was possible to locate other elements whose position has remained unchanged over time therefore the gimp software has been used to compare the two images setting a suitable value of the transparency in order to superimpose the common objects and elements visible in the pictures finally the object position has been located in the google earth image see fig 11c the position has been located also using the orthophoto relative to the years 88 89 and the present one as shown by the white arrows and green point in fig 11d and 11e 5 numerical simulation of the event 5 1 dem generation obtained by integration of different source of topographic data the currently available high resolution lidar data cannot be used for the representation of the river channel and the relative banks at the time of the inundation therefore attention has been oriented to the pre event digital map described in section 3 in particular the contour levels and spot elevations have been extracted from the map together with the breaklines and buildings footprints using the arcgis software the digital elevation model was obtained according to a standard procedure based on the generation of the tin triangular irregular network that has been considered more suitable for the management of the breaklines and the river banks the result obtained following this procedure is shown in fig 12 in which an overview of a large part of the domain is shown together with the buildings located in the area represented in red 5 1 1 verification and integration of the tin model even though particular care has been devoted to the construction of the tin using all the topographic elements reported in the available map it is evident that the generation of the tin in such a case is intrinsically affected by not negligible uncertainties therefore in order to check the validity of the work done a comparison between the section surveyed after the event and the same data extracted by the tin has been carried out as an example fig 13 shows that comparison limited to six cross sections four of which see also fig 3 are representative of the upstream part s17 s18 and final part s4 s6 of the domain and the other two that cross both the esaro river and lamps stream s11 s12 fig 13 allows a couple of considerations 1 the tin model provides satisfactory results for out of bank areas and 2 the river channel resulted reasonably reproduced except for the bathymetric levels especially for the section close to the mouth the second observation is expected due to the very limited number of spot elevations related to the channel and in general to the lack of bathymetric data therefore a specific procedure was developed in order to reconstruct the river channel topography of the esaro river by integrating data extracted from the post event survey in particular the problem faced here concerns the generation of fictitious cross sections starting from two consecutive surveyed cross sections this issue is not trivial and as a matter of fact has recently been debated in the scientific literature merwade et al 2008 caviedes voullième et al 2014 podhoranyi and fedorcak 2015 falcão et al 2016 andes and cox 2017 considering the unavoidable arbitrariness associated to the geometrical and interpolative techniques that characterizes whatever methods have been found in the literature this aspect has been faced here using for the sake of simplicity a procedure based on graphic and numerical considerations once two consecutive surveyed cross sections sj and sk are known the procedure is based on the following steps see also fig 14 for the notations 1 location of the thalweg of the two sections together with the right and left bank levels 2 determination of the lines joining the thalweg lt the left bank level llb and the right bank level lrb this operation has been carried out by a graphical construction imposing an orthogonal condition with the surveyed cross section and following the plan development of the breaklines banks and cliffs the use of the plan development of these elements already known from the pre event topographic map see fig 3 allowed us to draw a river axis curvature that even though subjective closely follows the actual plan development of the river at the time of the event 3 computation of the slope for each of the lines previously identified lt llb and lrb assuming a linear variation of the ground level 4 identification of the two parts of the cross sections si l si r i j k respectively on the left and on the right of the thalweg location counting of the surveyed points ni l and ni r falling on the two subsections and their numbering pi l1 l n pi r1 r n 5 determination of tl and tr that are those subsections which have the minimum surveyed points respectively between sj l sk l and sj r sk r in particular if the number of points in homologous subsections are different then more points are added to the subsections having fewer points in order to have the same numerousness furthermore a final renumbering is applied 6 generation of the interpolated sections using a pre determined spatial step which have to be transversal to the trajectories identified in point 2 7 for each of the interpolated sections generation of points through a linear interpolation along the curvilinear axis delimited by the points having the same numbering in two consecutive cross sections 5 2 mathematical model and outline of the numerical scheme the mathematical model used for the simulation of the flood event is based on the 2 d swe that can be expressed in the following form 1 u t f x g y s where 2 u h h u h v 3 f hu h u 2 g h 2 2 h u v 4 g hv h u v h v 2 g h 2 2 5 s q g h s 0 x s fx g h s 0 y s fy in which t is time x y are the horizontal coordinates h is the water depth u v are the depth averaged flow velocities in x and y directions g is the gravitational acceleration s0x s0y are the bed slopes in x and y directions sfx sfy are the friction slopes in x and y directions q is a lateral inflow for the numerical integration of system 1 the finite volume method fvm approach has been considered in particular the roe scheme first order accurate in time and space has been used for the computation of the numerical fluxes moreover particular care has been devoted to the numerical treatment of the source terms the details of the numerical scheme used are presented in the appendix 5 3 details on the computational grid insertion of buildings and upstream internal and downstream boundary conditions an unstructured grid based on irregular triangular elements tin has been used to obtain the computational domain it covers an area equal to about 3 78 km2 and it is delimited by the red line shown in fig 15 the upstream boundary conditions set for the simulation refer to the esaro river and the lamps papaniciaro stream whose inflow sections have been highlighted by the green and black arrows respectively in fig 15 as already recalled in the previous sections two different boundary conditions have been considered for the esaro river see fig 4 for the lamps stream a triangular hydrograph symmetrical to the peak value has been considered for the lamps papaniciaro stream characterized by a peak discharge value equal to 363 m3 s and a time to peak equal to 1 h and 15 min frega et al 1999 the buildings have been modelled as solid wall boundary conditions therefore cells falling in the buildings footprints act as not submergible elements as an example fig 15a shows a grid detail just downstream from the bridge 2 near the neighbourhood 1 great attention has been devoted to model the flow process around the two bridges described in section 4 to that purpose the blocking phenomena of the bridges span have been simulated using again a solid wall internal boundary condition more precisely as regards the bridge 1 starting from the hydraulic situation deduced by the analysis of the video discussed in section 4 the following sequence has been assumed 1 until 11 00 a m the bridge has not been interested by any occlusion and 2 sudden almost full occlusion at 11 00 a m this is the time for which the car presumably was hit by the flow in particular the grey cells inside the red circle shown in fig 15c highlight the reduction of the area under the bridge and thus the occlusion assumed in the computations as already underlined the analysis of the available video highlighted a rapid decrease of the water levels upstream of the bridge that suggests a rapid unblocking of the bridge span therefore the simulation has been performed assuming for the unblocking phenomenon the following progressive sequence of the span bridge opening 1 13 05p m unblocking of cells related to the area number 3 see fig 15d 2 13 30p m unblocking of cells belonging to the area number 4 3 13 50p m unblocking of the cells falling within the area number 2 4 13 55p m unblocking of the cells falling within the areas numbers 1 and 5 finally the downstream boundary condition has been set according to the simulated flow regime specifically transmissive boundary conditions are considered in the case of supercritical flow while for subcritical or critical flow critical conditions have been set due to the presence of sand dunes and other different ridges 6 numerical reconstruction of the event results 6 1 numerical results near bridge 1 in order to check the coherence between estimated hydrographs and the hydraulics effects downstream attention has been focused on the water levels evolution in a reference cell see the red cell in fig 15c and d that can be considered as representative of simulated hydraulic phenomenon just upstream of the bridge in particular fig 16 a shows the comparison between the water levels simulated using the two different hydrographs shown in fig 4 and the estimated ones in particular it can be observed that the maximum water levels reached by the flow for both the simulations is about 15 m a s l that is 0 3 m above the bridge deck the two simulated hydrographs are quite similar and are characterized by a decreasing behaviour close to the observed one 6 2 numerical results close to the car and the electricity column first of all the position of both the car and the electricity column have been localized on the grid as highlighted by the green and cyan cells shown in fig 15c for these cells the simulated water depths hydrographs have been plotted and compared to the estimated ones as shown in fig 16b and c the computed water depths are in a reasonably good agreement with the observed ones in particular it is important to highlight that both the upstream boundary conditions used for the esaro river seem to be coherent with the observed and computed hydraulic effects moreover the sequence adopted to model the unblocking of the bridge span allowed us to obtain water depth values close to the observed ones in the surrounding areas of the bridge itself 6 3 numerical results upstream to bridge 2 the computed maximum water levels in the cross section above bridge 2 see section s12 in fig 17 a are shown in fig 17b in which z is the bed level h the water depth and y is the abscissa oriented according to the section itself the simulated levels are very close together resulting as about 8 5 m a s l and 8 0 m a s l using hydrographs 1 and 2 respectively the observed one was approximately equal to 8 8 1 m a s l as shown in the previous section it should be observed that the flood watermarks do not necessarily highlight the maximum water levels but more realistically the flood levels having the greater duration over time as water storages that remain after the peak of the water levels therefore the computed values can be considered as very close to the observed one since the discrepancies with the estimated level can be assumed as belonging to an uncertainty range that has to be considered in the evaluations and computation discussed here fig 17c shows the velocity profile v computed across the pallet section highlighted in fig 17a in which y is the abscissa oriented according to the section itself the maximum velocity close to the pallet location is about 1 9 m s for both the simulations the ratio between the estimated value 2 3 m s and the calculated one is 1 2 considering that not only does the numerical model provide a depth averaged velocity but also that the velocity on the free water surface is greater than the mean velocity itself the simulated velocity can be considered in good agreement with the observed one 6 4 comparison between observed and computed water levels a wider assessment of the numerical reconstruction has been carried out comparing the water depth ranges observed during a post event survey with the computed values in particular attention has been focused on the four relevant flooded areas shown in the figs 18 and 19 and identified as follows zone 1 road 2 and railway areas zone 2 neighbourhood 1 zone 3 street 1 zone 4 port considering the uncertainties necessarily associated with post event watermarks surveys the numerical reconstruction of the event is satisfying this confirms that 1 the boundary conditions are coherent with the observed hydraulic effects and 2 the topography assumed in the computation for the generation of the computational domain has been carried out with a suitable degree of accuracy the map of the simulated maximum water depths is shown in fig 20 for both hydrograph 1 fig 20a and hydrograph 2 fig 20b finally the froude number map computed in an instant of time just after the time to peak is shown in fig 20c 7 conclusions the careful analysis of the state of the art discussed in the introduction has highlighted that the number of highly detailed real world cases that can be effectively used for the calibration validation and assessment of numerical models is not so high see table 1 furthermore the numerical reconstruction of historical events is useful for the prediction of future scenarios in areas which have already experienced flood inundation in the past for these two reasons there is the need to increase the number of numerical reconstruction of historical cases the greater the distance in time of the flood event the greater the difficulty in performing these analyses due to couple of reasons a lack of conventional data related to hydrological and hydraulic variables b lack of suitable topographical data accurate enough to perform 2 d numerical reconstructions this paper has been focused mainly on these two aspects proposing a methodological approach summarized by the flow chart depicted in fig 1 the findings achieved using this method can be grouped into two blocks according to the two issues mentioned above as regards the first issue see point a this study has provided four major results using photos and frames extracted from video it is possible to obtain information on the evolution of water levels and velocities provided that the zones displayed in them are definitely recognized reports in the newspapers can be useful for localizing the areas in which the events took place once the inundated areas are detected the viewpoints of the places represented in the photographs and videos can be recognized through the use of visualization software such as google earth and street view patchworking of frames extracted from videos allows scientists and technicians to generate unpublished panoramic images representing the flow evolution during the event as regards the second issue see point b the three following conclusions can be highlighted the reconstruction of the topography can be achieved starting from the pre event official maps which can be supplemented by traditional post event surveys of river cross sections the refinement of the topographical details required for the application of accurate 2 d numerical models can be achieved using recent lidar data to provide detailed representations of those areas remained unchanged over time the orthophotos give useful information on land use and urban set up at the time of the event this method has been applied to the numerical reconstruction of the flood event in the city of crotone which occurred on october 14 1996 the quantitative data extracted using the non conventional information according to the method presented here and the numerical reconstruction of the event has allowed us to evaluate the validity of estimated discharge hydrographs used as upstream boundary condition of the flood propagation model in conclusion the application of the flow chart depicted in fig 1 has proved to be a reliable approach to achieve the numerical reconstruction of a flood event occurred in the past the complexity of which is testified not only by the presence of urbanized areas and the impulsiveness of the event but also by the effects of obstructing and unblocking of a bridge it is essential to underline that the added value provided by the careful analysis of the non conventional sources of information related to a past flood event is not limited to the numerical reconstruction of the event but also should be extended to the increase of people s awareness the behaviour of the population at risk can be effectively oriented once the flood dynamic in the urban areas is completely clear using the methods presented here it is possible to provide an unedited visual and quantitative documentation that can be disseminated among the population eventually supported by virtual visualization scenarios realized on the basis of the collected data leskens et al 2017 macchione et al 2019 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to rosa de santis and fabiola gangi for their help in dealing with the frames taken from the films and in the reconstructing the topographic data his work was supported in part by the funding project pon sila pona3 00341a appendix outline of the numerical model according to finite volume method approach denoting by u i the average value of the flow variables over the control volume ω i at a given time eq 1 may be discretized as 6 u i n 1 u i n δ t ω i j 1 3 e n ij δ γ i j δ t s i in which i and j refer respectively to the ith cell and the jth edge of the cell n ij and δγij are the unit outward normal vector and the length of the jth edge respectively e is the numerical flux through the edge which may be computed by an appropriate riemann solver the numerical model used in this work has been already tested in previous works costabile and macchione 2015 macchione et al 2016 costabile et al 2017 specifically it uses the roe 1981 scheme for the computation of the numerical flux as reported in relation 7 7 e n 1 2 e l n e r n i 1 3 α i λ i e i in which 8 α 1 3 h r h l 2 1 2 c hu r hu l n x hv r hv l n y u n x v n y h r h l 9 α 2 1 c hv r hv l v h r h l n x hv r hv l u h r h l n y λ and ẽ are the eigenvalues and the eingevectors of the approximated jacobian matrix defined 10 λ 1 3 u n x v n y c 11 λ 2 u n x v n y 12 e 1 3 1 u c n x v c n y 13 e 2 0 c n y c n x they depend on the following averaged variables 14 u h r u r h l u l h r h l 15 v h r v r h l v l h r h l 16 c g 2 h r h l the harten hyman 1983 modification of the modulus of eingenvalues λ is applied in order to avoid non physical discontinuities the treatment of source terms of the shallow water equations is a key topic for the numerical models murillo et al 2007 valiani and begnudelli 2006 murillo and garcía navarro 2010 costabile et al 2012 2013 chertock et al 2015 liang et al 2015 vacondio et al 2016 xia et al 2017 in our scheme the source term vector s is decomposed in two different parts that are treated separately the bottom variation s 0 and the friction term s f s s 0 s f an upwind approach has been adopted to model the bottom variations for every edge r of the control volume the inward contribution of the bottom term is brufau et al 2004 17 s 0 r m 1 3 β m e m where the coefficients βm are calculated as 18 β 1 3 1 4 c 1 λ 1 3 λ 1 3 s 0 2 n x s 0 3 n y d rl 19 β 2 1 2 c 1 λ 2 λ 2 s 0 2 n y s 0 3 n x d rl where s 0 2 and s 0 3 are the second and third components of the vector of source terms s 0 20 s 0 0 g h δ z x g h δ z y in which h 1 2 h r h l δ z x zr z l d rl n x δ z y zr z l d rl n y and drl is the distance between the centroids of the right r and left l cells moreover a semi implicit treatment of the friction source term brufau et al 2004 costabile et al 2013 cea and bladé 2015 is applied here leading to the following relation 21 u i n 1 u i δ t θ s fi n 1 1 θ δ t s fi n u i n in which u i u i n δ t ω i r 1 3 f g r n n r s 0 r n i n δ l r θ is the implicitness degree of the friction term discretization θ 1 corresponds to a totally explicit treatment and θ 0 to a totally implicit one finally a robust wet dry procedure was implemented according to the approach presented in costabile et al 2013 
6305,the description of the floods which have occurred in the past and an assessment of the adverse impacts they have entailed are among the duties required by the european flood directive indeed to understand the consequences of a future flood on a city that in the past has already been affected by other flood events it is very useful to reconstruct the hydraulic effects produced by those events such a task is particularly difficult for cases which occurred many years ago for past events it is often easier to have conventional hydrological data for example the hyetographs of the event than conventional hydraulic data recordings of flow rates water depths etc it is also difficult to obtain the topography valid for the period in which the event occurred the greater the distance in time the greater the difficulty in gathering these data in this paper we present a criterion for making a flow of information using various non conventional sources of information such as amateur videos photographs traditional topographic surveys news reports etc in particular it is shown how the data thus obtained can be used together in order to reconstruct numerically the hydraulic dynamics of a flood event in an urban area with a complete hydrodynamic model which requires a particularly accurate computational domain all these issues will be presented and discussed with reference to the numerical reconstruction of the flood event that occurred 23 years ago 1996 in the city of crotone calabria italy keywords flood reconstruction hydraulics effects post flood surveys urban flooding non conventional data 1 introduction in the last few years the numerical modelling aimed at the simulation of flood events in urban areas has been significantly improved thanks to the progress achieved in several fields such as the physical mathematical description of flood behaviour the increase of computing power and the ever more accurate techniques of topographic surveys the advances in these fields are documented by many studies dealing with purely modelling issues i e mark et al 2004 hunter et al 2008 neal et al 2012 costabile and macchione 2012 néelz and pender 2013 ozdemir et al 2013 costabile et al 2015 hou et al 2015 papaioannou et al 2016 fernández pato et al 2016 vacondio et al 2016 fleischmann et al 2018 martins et al 2018 or focused on the relations between modelling and topographic surveys aspects including the techniques for the representation of buildings i e yu and lane 2006 fewtrell et al 2011 tsubaky and kawahara 2013 vojinovic et al 2013 kvočka et al 2015 shen et al 2015 abily et al 2016 chen et al 2017 other papers have been more oriented to the representation of buildings as a sub grid process also known as the porosity based approach defina et al 1994 among these the works proposed by the following authors are relevant guinot and soares frazão 2006 sanders et al 2008 soares frazão et al 2008 cea and vázquez cendón 2010 schubert and sanders 2012 kim et al 2015 costabile et al 2017 özgen et al 2016 guinot et al 2017 velickovic et al 2017 bruwier et al 2017 viero and valipour 2017 bruwier et al 2018 viero 2019 despite the plethora of studies available in the literature on this topic it should be observed that the number of highly detailed real world cases that can be effectively used for the calibration validation and assessment of the numerical models is not so high for example neal et al 2009 noted that due to the lack of detailed validation data the urban flood events for which the accuracy of the numerical simulation has been assessed against data relative to the inundation extent or water surface elevations are very few an extensive list of recent papers in which real world cases of urban flooding have been studied is shown in table 1 table 1 highlights that there are not many cases for which observed hydrographs in some sections or maximum water levels reached by the flood flow are available in particular only the observed data relative to the flood events reported in mignot et al 2006 neal et al 2009 abdullah et al 2012 vojinovic et al 2013 kvočka et al 2015 portugués mollá et al 2016 segura beltrán et al 2016 include also the maximum water levels research activities aimed at data collection especially referred to flash floods events can be found in the literature gaume et al 2009 marchi et al 2010 gaume and borga 2008 in general performing post events surveys is a tedious and difficult task gaume and borga 2008 kjeldsen et al 2014 this activity is undoubtedly more complex and arduous when data collection refers to an urban flooding a relevant example of this has been presented by portugués mollá et al 2016 who analysed the flood event which occurred in the city of valencia spain in 1957 in that case the temporal distance of the event induced the authors to analyse it through a gis database obtained by using an enormous amount of documents and photos it is evident that whenever possible the data collections are very useful also in order to perform hydraulic simulations aimed at the numerical reconstruction of the event reliable numerical reconstructions of past flood events can be essential not only for the validation of simulation models but also to application of them to predict future scenarios in order to give an effective support in several aspects related to flood risk assessment and management in this regard the european directive 2007 60 ce states there is a need of a description of the significant floods which have occurred in the past where significant adverse consequences of similar future events might be envisaged in those cases for which no conventional measures of the main hydrodynamic and hydrological variables water depths in the main river channel or in the adjacent flood prone areas velocities discharge hydrographs topographic data etc are available the reconstruction of past flood events becomes an extremely complicated task a very detailed example of this kind of work has been presented by segura beltrán et al 2016 who have analysed flash floods of the girona river spain in 2007 using post flood surveys and geomorphologic mapping to evaluate hydrological and hydraulic models another example can be found in the work of neal et al 2009 for the severe flooding event which occurred in and around the city of carlisle england on the 8th january 2005 a third example is the work presented by kvočka et al 2015 related to the flood event which occurred in the city of boscastle on the 16th august 2004 for each of the three cases mentioned above lidar data were available the greater the distance in time the greater the difficulty in studying a flood event of the past mainly because it is quite hard to have a detailed topographic description of the flooded areas suitable for two dimensional numerical simulations for example in order to numerically reproduce the flood event which occurred in the october of 1988 in the city of nîmes france mignot et al 2006 used about 200 cross sectional profiles describing the 60 streets located in the studied area martín vide and llasat 2018 accurately revisited the very disastrous 1962 rubí flood spain from a meteorological pluviometric hydraulic hydrological and sediment transport point of view in general for past flood events the hydrologic data are very often more abundant than the hydraulic ones indeed it is much more difficult to obtain conventional hydraulic data in particular time trend of levels and velocities at different points of the flooded area however the importance of these data for the reasons given above requires that efforts be made to extract them from unconventional documents although this work requires a lot of patience and a lot of time the novel methodological contribution of this article is the reconstruction of the hydraulic effects of the flood events including the numerical simulation of the flood evolution in urbanized areas based only on the sources of available information represented by non conventional data such as amateur videos photographs traditional topographic surveys news reports etc this approach requires a patient work aimed at the identification of flooded areas velocities maximum water levels and temporal flood evolution sometimes comparing the images extracted from the videos to those available in street view mode using google earth software the second relevant activity of this research has been focused on a reliable reconstruction of the computational domain representative of the situation of the territory at that time in particular a specific procedure aimed at the integration of traditional digital topographic maps and cross sections surveyed post event and more recent lidar data has been developed and discussed the third aspect of this research is checking the coherence of the hydrological input estimations with the observed hydraulic effects of the flood all these open issues have been analysed and discussed in the reconstruction of a flood event that occurred 23 years ago 1996 in the city of crotone calabria italy the following sections present the methods used the information obtained the hydraulic simulations and the conclusions 2 methodological approach in those cases for which no hydraulic and topographic conventional data are available attention can be focused on the sources of information non conventional data listed below which could be related to each other generating the flow of information reported in fig 1 and explained in the following subsections 2 1 damage estimations damage estimation is information related to flooding effects in terms of direct economic loss due to damaged goods it is quite difficult to relate them to the flood dynamics however they could be useful for an indirect estimation of the flooded areas on the basis of the location of damaged goods 2 2 post event reports related to indirect evaluations of flood watermarks these are the closest data to the hydraulic aspects of the event often these data are derived from the marks left by the water on the walls of the buildings or from the position of the floating objects that remained entangled at the maximum altitude reached by the water it must be said that these data do not always correspond to the maximum levels reached by the current it may happen that they correspond rather to the levels at which the water stayed for the longest time for example if the signs left by the water are perfectly horizontal it means that the speed there was almost nil so it is mostly water that remained stagnant even after the passage of the flood peak 2 3 photos photographs represent a specific instant of the event or its consequences in a certain place from them information about the levels or the extent of the flooded area can be derived if they are taken during the event or if signs left by the water are visible they are also useful as it is possible to have a qualitative evaluation of the forces exerted by the current if they document displaced objects vehicles rubbish bins vegetable debris sediments mud or garage doors and broken down walls however they are only useful if you can recognize the site and if possible if the shooting time is known 2 4 videos videos are commonly taken by professional reporters or by amateurs in the first case the quality is very high but they are usually quite limited in time on the contrary the amateurs videos generally have a longer duration but their quality could be significantly lower than that of the professionals usually the video reporter does not have a hydraulic sensibility leading to the filming of details not particularly useful for the hydraulic reconstruction of the situation nevertheless the careful and patient analysis of each frame can lead to the extraction of useful information related to the temporal evolution of the phenomenon specifically the evolution of the water levels moreover it is possible to build a patchwork of frames in order to obtain a panoramic shot of the flooding during its evolution finally filming small floating bodies could be useful in providing estimations of the flood velocity 2 5 google earth and street view almost all the surface of the world is currently viewable with google earth with this tool it is possible to obtain information on the ground coverage for the extra urban areas and on the urban fabric of the cities it is not always possible to have the chronology of images that date back to the date of the event however these tools are useful for interactively and dynamically viewing the areas that have remained unchanged over time the possibility to change the point of view of the image as you want allows you to identify with relative ease the locations represented in the photographs and videos photographs and videos whose location could not be identified can easily be located by looking in google earth and in street view for the same point of view from which the photographs were taken provided they contain an easily recognizable reference point 2 6 information taken from local mass media the reports in the newspapers or the radio television reports most often focus on the consequences of the flood from the point of view first of the loss of human life and economic damage and interruptions to normal activities schools offices traffic etc unfortunately this information is not very detailed on the hydrodynamic aspects of the event but they can be helpful to obtain early indications of a hydraulic nature that need to be fleshed out with other sources of information listed here 2 7 interviews with eyewitnesses the people involved in the flood are usually interviewed by local mass media and judicial authorities these are people who have personally experienced the event and can therefore provide information from which we can indirectly have elements of knowledge on the dynamics and the timing of the event 2 8 topographic maps generally for the topography of the area to be studied official topographic maps issued by the government technical offices are available unfortunately they often have too low a resolution to be used alone as a basis for the construction of the computational domain especially for urban areas therefore they must be integrated with other data sources such as the topographic surveys after the event or more recent surveys that can be used to represent the topography of the areas that have remained unchanged over time 2 9 lidar surveys lidar surveys are not available for past flood events that happened long ago since this technique is relatively recent however recent lidar surveys can be used to adequately represent those areas that have not undergone major topographic changes over time the sewing up of the lidar survey with the information extracted from the topographic maps contemporary to the event and with those extracted from the post event topographical surveys can allow the computational domain to be realized with sufficient accuracy 2 10 post event topographic surveys usually after a flood event that has produced considerable damages defence structures are built on the riverbed for the protection against future floods therefore after some years the topography will be different from the topography of the area at the time of the event in these cases topographic surveys are usually performed immediately after the event if similar surveys carried out immediately before the event are not available it becomes very difficult to quantify the plano altimetric variations of the riverbed caused by the flood although the final bed level may not be the bed level at the flow peak nor the bed level before the flood post event surveys are very useful because they allow us to reconstruct a topographic representation of the riverbed as close as possible to the one at the time of the event 2 11 orthophotos the orthophotos give useful information on the state of the places at the time of the event in particular they give information on the degree of urbanization of the area and on the presence of vegetation and artefacts that interfere with the current flowing within the channel and with the water outflowing in the flooded areas 2 12 hydrological inputs generally the hydrological analysis of the event is the first study performed on significant flood events especially those that have produced damage and it is aimed at the reconstruction of the flood hydrograph this is generally done by using hydrological rainfall runoff models whose input data when available are the recorded hyetographs for the area under examination based on these inputs the numerical reconstruction of the spatial and temporal evolution of the flood flow is then performed symmetrically the reliability of numerical reconstruction can be used to verify the correctness of the hydrological input for the sake of completeness it should be observed that for more recent and future flood events other sources of information can be used to extract quantitative data related to flow one option is represented by the use of large scale particle image velocimetry lpsiv whose accuracy for discharge measurements and velocity fields derived from imagery of the water surface has been recently analyzed i e lewis et al 2018 another possible choice is the analysis of satellite derived flood extent maps that can be used for the calibration and validation of the hydraulic models in this context satellite borne synthetic aperture radar sar sensors have been extensively used to support the knowledge of many flooding events based on an image processing technique see for example garcía pintado et al 2015 finally it should be recalled the important role played by social media e g facebook and twitter in disaster management for receiving disaster information and warnings and for linking community members following a disaster starkey et al 2017 barker and macleod 2019 in this field the increasing importance of the so called volunteered geographic data should be underlined since they include any geo located information on a disaster and can comprise a diverse range of data including personal accounts photographs and videos and crowd sourced measurements see for example rollason et al 2018 the use of these data is fostering the development of procedures able to extrapolate quantitative information from footages an example of this can be found in the work of milanesi et al 2016 who proposed a set of procedures to quantify the individual s stability condition during a flood event from videos and in zheng et al 2018 who discussed recent techniques for using crowdsourced images and videos 3 description of the case study and available data 3 1 general features of the case study the case study analysed in this work is one of the most important events which has occurred in the calabria region south of italy in the last few decades specifically in the city of crotone on 14th october 1996 the flood wave of the esaro river provoked the inundation of a wide area of the city of crotone see fig 2 for a general overview the pluviometric station located in crotone recorded an hourly precipitation of 72 8 mm between 10 00 and 11 00 a m and a precipitation equal to 112 4 mm in the six hours between 7 00 a m and 13 00 p m the flood event caused six fatalities and several injuries induced the collapse of bridges and the northern overpass near the gesù neighbourhood hereafter called neighbourhood 1 and the disruption of the main access roads including the railway several buildings commercial activities and small factories registered enormous damages the values of the water depths and velocities were such that significant hazard conditions occurred in the urbanized areas the meteorological and hydrological details and the consequences on the flooded areas are reported in gabriele 1998 3 2 available conventional data 3 2 1 topographic data the available cartographic data are represented by pre event digital maps obtained from an aero photogrammetric survey dated 1994 scale 1 1000 in the gauss boaga reference system this map that can be reasonably assumed to be representative of the geometric peculiarities of the river and the neighbouring areas at the time of the event is shown in fig 3 the latter figure shows the level of detail that characterizes structural infrastructural and morphologic elements and two details near two bridges san francesco and ex fcl called bridge 1 and bridge 2 hereafter that will be analysed later on in this work moreover several cross sections were surveyed seven months after the event whose location is represented by red lines in fig 3 finally the 1 m digital elevation model obtained from the airborne lidar survey dated 2015 has been also considered to represent those neighbouring areas flooded in 1996 that have not been significantly changed over time 3 2 2 hydrometric and hydrological data no water level measurements in the river are available during the flooding event instead some post event estimates of the maximum water levels were surveyed as pre fixed ranges and reported in a map drawn up by working group for the data collection of the crotone flood of 14 10 1996 unpublished no hydrological observed data are available d asaro and niccoli 1998 proposed two different discharge hydrographs hereafter called hydrograph 1 and hydrograph 2 estimated by rainfall runoff models applied to the whole basin upstream of the bridge 1 see fig 4 3 3 available non conventional data visual documentation of the crotone inundation the information on the hydraulic effects of the flood inundation has been extracted from an accurate analysis of the available visual documentation in particular it consists of amateur videos stored in vhs formats the quality of which is relatively poor being analog videotapes unfortunately there are few images that document the flood in progress much more visual documentation regarding the situations around the city just after the flood evolution is available the videos have been analysed carefully in order to document the hydraulic impacts not only to quantify them but also to assess the correctness of the results of the simulations unfortunately several times the authors of the videos even though showing interesting particulars did not show high view angles of the flooded areas but limited their footage to some details that do not allow the topographic localization of the viewpoints 4 extracting hydraulic effects induced by the flood flow from video analysis quantitative issues for all the situations for which the videos show parts of roads buildings or other recognizable objects a systematic identification of them within the city has been carried out in order to localize exactly the observed viewpoints to that purpose when possible the images of the city as shown in the videos were compared with those that can be seen from the google earth and street view software using practically the same viewpoints in those cases for which the author of the videos moved the camera gradually in order to film a wide area the single frames have been gathered together so that wide overviews of the flooded areas could be represented using this method original images of crotone city during or just after the inundation have been obtained even though their quality is low due to the poor video resolution then the specific viewpoints extracted from the videos have been localized in the cartographic map 4 1 analysis of the temporal evolution of the water levels in the areas close to the upstream boundary condition no verifications have been performed on the reliability of those hydrographs depicted in fig 4 in terms of coherence with the hydraulic effects observed on the flooded areas since they have been computed considering the whole basin upstream to the bridge 1 the attention has been focused on the areas close to this section 4 1 1 analysis of the flood hydraulic behaviour near a trapped car a very interesting aspect that has been found in one of the available videos is what happened to a car an amaranth red colour five door fiat uno caught in the middle of the flow along the road near the high school for surveyors hereafter referred to as school see fig 2 and filmed for half an hour the local newspapers of that time reported several pieces of information which have proved useful in reconstructing the accident three people were on board after crossing bridge 1 the car was hit by the flow and carried off the road the driver jumped onto the top of the car and stayed there for two hours the analysis of the video allowed us to generate a never before seen image depicted in fig 5 a obtained through a patchwork of several frames moving from left to right this figure shows the school the car and the driver on the top of the car and the bridge railings emerging from the water see also fig 6 for other details of the bridge the water levels reached by the flow can be deduced by the frames extracted from the video highlighted in fig 5b in which the last picture represents the car after the flood event since the car is 1 42 m in height the frames analysis leads to the estimates of the water depths shown in table 2 despite the uncertainties that might affect those estimations it is important to observe that their values can be assumed accurate enough for this situation also because what is really important here is not so much the numerical value but their temporal evolution 4 1 2 analysis of the flood hydraulic behaviour close to the electricity column located near the road external to the bridge 1 left abutment another useful piece of information that can be extracted from videos is the water levels evolution close to an electricity column located to the left of bridge 1 the electricity column has been highlighted with a green rectangle in fig 5b by comparing it to the height of the people it can be assumed that the electricity column is 1 2 m tall the water levels estimated in the instants of time relative to some frames shown in fig 5b are reported in table 2 4 1 3 analysis of the flood hydraulic behaviour close to bridge 1 the analysis of the videos allowed us to evaluate the temporal evolution of the water levels just above the road surface of bridge 1 see fig 6 these estimations are reported in table 2 despite the low quality of the images the analysis of the flow motion in both upstream and downstream directions highlighted that the bridge though overtopped by the flow was not fully obstructed moreover from 13 15 p m on a sudden lowering of the water depths upstream of the bridge is observed that could be explained by a significant unclogging of the bridge itself 4 2 analysis of the water levels and velocities in the middle of the computational domain areas close to bridge 2 in this section the peculiarities of the flood flow behaviour in areas located in the middle of the computational domain are discussed in particular attention is focused in a specific area close to a steel bridge bridge 2 see figs 2 3 and 7 a one of the available videos captured for a long time the river flow situation in both the upstream and downstream directions and in addition the buildings located on the right side of the bridge no information about the time of the videotape is available but it occurred when the flood flow interacted with the bridge deck see fig 7e fig 7d highlights that pieces of wooden floating debris were trapped in the bridge trusses this situation has not been observed during the rising phase of the flow see fig 7c therefore it can be deduced that the water levels overtopped the top of the bridge the hydraulic situation of this part of the river in these instants of time can be analysed in the patchwork of images extracted from the video and shown in fig 7b the point of view of the video operator has been highlighted in fig 7a the yellow lines delimit the view angle of the scene represented in the patchwork for these areas three river cross sections are available see sections s10 s11 and s12 in fig 8 efforts have been made in order to extract from the videos the maximum water levels close to these sections in particular attention has been focused on the cross section s12 see fig 8c because the viewpoint of the video operator was located close to the extreme part of the section on the right identified by the number 122 section 12 extreme 2 in fig 8a a patchwork of frames obtained from the video shows the hydraulic situation near the cross section s12 that can be further appreciated in fig 8b which is a zoom of the previous image considering together the map shown in fig 8c and the cross section of fig 8e it can be observed that that extreme point is located near a courtyard boundary wall see fig 8d for a detail the point 122 has been highlighted with a red circle in the fig 8a 8b and 8e to make comprehension of the area easier the analysis of the image close to the courtyard shows that the water reached the ground level of that courtyard which according to the profile of the section is about 7 83 m for this reason this value can be assumed as the maximum water level reached by the flow in the right part of the section s12 finally other investigations have been carried out in order to extract some watermarks in the extreme part of the section on the left identified by the number 121 on fig 8c to this purpose the google earth map shown in fig 9 a in which the red line represents the section s12 is useful for the localization of some elements of the areas in particular fig 8c and 9a show that the extreme point of the left is located close to the edge of the railway station square but unfortunately no images are available for this area though not shown here some video frames document a residual inundation of the areas behind the railway station using google earth it is possible to travel along the road highlighted by the yellow dotted line reported in fig 9a and 9b reaching the views shown in fig 9c and 9d and further detected by the circles 1 and 2 the yellow arrows highlighted in fig 9a and 9b help to realize the point of view of the images depicted in fig 9c and 9d the viewpoint shown in fig 9b can be detected in the videos as shown by the frame reported in fig 9e in which the yellow lines highlight the water level reached by the flood flow the point shown in fig 9e as highlighted in a google earth image represented in fig 9b is located very close to the extreme left part of the section s12 since this point falls in a quite protected area the kinetic energy term may be assumed not to be particularly significant so that the water levels observed there can be reasonably assumed as representative of the maximum water levels reached by the flow in the section s12 considering that according to the available lidar data the road level is 6 8 m a s l and from the frames the water depth value can be estimated approximately equal to about 1 2 1 3 m by a comparison with the cars and the door that can be seen in fig 9e the maximum water level in this point can be considered approximately 8 8 1 m a s l 4 2 1 rough estimation of the flow velocity using video images the available videotapes have been also analysed carefully in order to provide some rough estimation of the flow velocity attention has been focused on a floating wooden pallet transported by the flow that can be seen for five seconds in the videos see fig 10 this object seems to be representative of a common pallet of standard dimension 80 cm wide and 120 cm long shown in fig 10a three frames have been considered see fig 10b 10c and 10d that cover an interval of 2 s then a superimposition of the three frames has been carried out using the open source software gimp considering some specific reference points see fig 10f the length covered by the object has been estimated using as unit of measure the lenght of the pallet itself 1 2 m the estimated velocity is 2 3 m s in order to verify this value the velocity has been computed again using the frames shown in the fig 10b and e that cover five seconds performing again a superimposition of the images see fig 10g and repeating the above described method for the computation of the length covered by the object we found again an estimated velocity of 2 3 m s the google earth software has been used again in order to locate the plan position of the pallet setting the google earth street view mode in such a way as to obtain a similar viewpoint of the author of the video see fig 11 a b though the current image available in that software shows different river banks due to the post event hydraulic works carried out in those areas it was possible to locate other elements whose position has remained unchanged over time therefore the gimp software has been used to compare the two images setting a suitable value of the transparency in order to superimpose the common objects and elements visible in the pictures finally the object position has been located in the google earth image see fig 11c the position has been located also using the orthophoto relative to the years 88 89 and the present one as shown by the white arrows and green point in fig 11d and 11e 5 numerical simulation of the event 5 1 dem generation obtained by integration of different source of topographic data the currently available high resolution lidar data cannot be used for the representation of the river channel and the relative banks at the time of the inundation therefore attention has been oriented to the pre event digital map described in section 3 in particular the contour levels and spot elevations have been extracted from the map together with the breaklines and buildings footprints using the arcgis software the digital elevation model was obtained according to a standard procedure based on the generation of the tin triangular irregular network that has been considered more suitable for the management of the breaklines and the river banks the result obtained following this procedure is shown in fig 12 in which an overview of a large part of the domain is shown together with the buildings located in the area represented in red 5 1 1 verification and integration of the tin model even though particular care has been devoted to the construction of the tin using all the topographic elements reported in the available map it is evident that the generation of the tin in such a case is intrinsically affected by not negligible uncertainties therefore in order to check the validity of the work done a comparison between the section surveyed after the event and the same data extracted by the tin has been carried out as an example fig 13 shows that comparison limited to six cross sections four of which see also fig 3 are representative of the upstream part s17 s18 and final part s4 s6 of the domain and the other two that cross both the esaro river and lamps stream s11 s12 fig 13 allows a couple of considerations 1 the tin model provides satisfactory results for out of bank areas and 2 the river channel resulted reasonably reproduced except for the bathymetric levels especially for the section close to the mouth the second observation is expected due to the very limited number of spot elevations related to the channel and in general to the lack of bathymetric data therefore a specific procedure was developed in order to reconstruct the river channel topography of the esaro river by integrating data extracted from the post event survey in particular the problem faced here concerns the generation of fictitious cross sections starting from two consecutive surveyed cross sections this issue is not trivial and as a matter of fact has recently been debated in the scientific literature merwade et al 2008 caviedes voullième et al 2014 podhoranyi and fedorcak 2015 falcão et al 2016 andes and cox 2017 considering the unavoidable arbitrariness associated to the geometrical and interpolative techniques that characterizes whatever methods have been found in the literature this aspect has been faced here using for the sake of simplicity a procedure based on graphic and numerical considerations once two consecutive surveyed cross sections sj and sk are known the procedure is based on the following steps see also fig 14 for the notations 1 location of the thalweg of the two sections together with the right and left bank levels 2 determination of the lines joining the thalweg lt the left bank level llb and the right bank level lrb this operation has been carried out by a graphical construction imposing an orthogonal condition with the surveyed cross section and following the plan development of the breaklines banks and cliffs the use of the plan development of these elements already known from the pre event topographic map see fig 3 allowed us to draw a river axis curvature that even though subjective closely follows the actual plan development of the river at the time of the event 3 computation of the slope for each of the lines previously identified lt llb and lrb assuming a linear variation of the ground level 4 identification of the two parts of the cross sections si l si r i j k respectively on the left and on the right of the thalweg location counting of the surveyed points ni l and ni r falling on the two subsections and their numbering pi l1 l n pi r1 r n 5 determination of tl and tr that are those subsections which have the minimum surveyed points respectively between sj l sk l and sj r sk r in particular if the number of points in homologous subsections are different then more points are added to the subsections having fewer points in order to have the same numerousness furthermore a final renumbering is applied 6 generation of the interpolated sections using a pre determined spatial step which have to be transversal to the trajectories identified in point 2 7 for each of the interpolated sections generation of points through a linear interpolation along the curvilinear axis delimited by the points having the same numbering in two consecutive cross sections 5 2 mathematical model and outline of the numerical scheme the mathematical model used for the simulation of the flood event is based on the 2 d swe that can be expressed in the following form 1 u t f x g y s where 2 u h h u h v 3 f hu h u 2 g h 2 2 h u v 4 g hv h u v h v 2 g h 2 2 5 s q g h s 0 x s fx g h s 0 y s fy in which t is time x y are the horizontal coordinates h is the water depth u v are the depth averaged flow velocities in x and y directions g is the gravitational acceleration s0x s0y are the bed slopes in x and y directions sfx sfy are the friction slopes in x and y directions q is a lateral inflow for the numerical integration of system 1 the finite volume method fvm approach has been considered in particular the roe scheme first order accurate in time and space has been used for the computation of the numerical fluxes moreover particular care has been devoted to the numerical treatment of the source terms the details of the numerical scheme used are presented in the appendix 5 3 details on the computational grid insertion of buildings and upstream internal and downstream boundary conditions an unstructured grid based on irregular triangular elements tin has been used to obtain the computational domain it covers an area equal to about 3 78 km2 and it is delimited by the red line shown in fig 15 the upstream boundary conditions set for the simulation refer to the esaro river and the lamps papaniciaro stream whose inflow sections have been highlighted by the green and black arrows respectively in fig 15 as already recalled in the previous sections two different boundary conditions have been considered for the esaro river see fig 4 for the lamps stream a triangular hydrograph symmetrical to the peak value has been considered for the lamps papaniciaro stream characterized by a peak discharge value equal to 363 m3 s and a time to peak equal to 1 h and 15 min frega et al 1999 the buildings have been modelled as solid wall boundary conditions therefore cells falling in the buildings footprints act as not submergible elements as an example fig 15a shows a grid detail just downstream from the bridge 2 near the neighbourhood 1 great attention has been devoted to model the flow process around the two bridges described in section 4 to that purpose the blocking phenomena of the bridges span have been simulated using again a solid wall internal boundary condition more precisely as regards the bridge 1 starting from the hydraulic situation deduced by the analysis of the video discussed in section 4 the following sequence has been assumed 1 until 11 00 a m the bridge has not been interested by any occlusion and 2 sudden almost full occlusion at 11 00 a m this is the time for which the car presumably was hit by the flow in particular the grey cells inside the red circle shown in fig 15c highlight the reduction of the area under the bridge and thus the occlusion assumed in the computations as already underlined the analysis of the available video highlighted a rapid decrease of the water levels upstream of the bridge that suggests a rapid unblocking of the bridge span therefore the simulation has been performed assuming for the unblocking phenomenon the following progressive sequence of the span bridge opening 1 13 05p m unblocking of cells related to the area number 3 see fig 15d 2 13 30p m unblocking of cells belonging to the area number 4 3 13 50p m unblocking of the cells falling within the area number 2 4 13 55p m unblocking of the cells falling within the areas numbers 1 and 5 finally the downstream boundary condition has been set according to the simulated flow regime specifically transmissive boundary conditions are considered in the case of supercritical flow while for subcritical or critical flow critical conditions have been set due to the presence of sand dunes and other different ridges 6 numerical reconstruction of the event results 6 1 numerical results near bridge 1 in order to check the coherence between estimated hydrographs and the hydraulics effects downstream attention has been focused on the water levels evolution in a reference cell see the red cell in fig 15c and d that can be considered as representative of simulated hydraulic phenomenon just upstream of the bridge in particular fig 16 a shows the comparison between the water levels simulated using the two different hydrographs shown in fig 4 and the estimated ones in particular it can be observed that the maximum water levels reached by the flow for both the simulations is about 15 m a s l that is 0 3 m above the bridge deck the two simulated hydrographs are quite similar and are characterized by a decreasing behaviour close to the observed one 6 2 numerical results close to the car and the electricity column first of all the position of both the car and the electricity column have been localized on the grid as highlighted by the green and cyan cells shown in fig 15c for these cells the simulated water depths hydrographs have been plotted and compared to the estimated ones as shown in fig 16b and c the computed water depths are in a reasonably good agreement with the observed ones in particular it is important to highlight that both the upstream boundary conditions used for the esaro river seem to be coherent with the observed and computed hydraulic effects moreover the sequence adopted to model the unblocking of the bridge span allowed us to obtain water depth values close to the observed ones in the surrounding areas of the bridge itself 6 3 numerical results upstream to bridge 2 the computed maximum water levels in the cross section above bridge 2 see section s12 in fig 17 a are shown in fig 17b in which z is the bed level h the water depth and y is the abscissa oriented according to the section itself the simulated levels are very close together resulting as about 8 5 m a s l and 8 0 m a s l using hydrographs 1 and 2 respectively the observed one was approximately equal to 8 8 1 m a s l as shown in the previous section it should be observed that the flood watermarks do not necessarily highlight the maximum water levels but more realistically the flood levels having the greater duration over time as water storages that remain after the peak of the water levels therefore the computed values can be considered as very close to the observed one since the discrepancies with the estimated level can be assumed as belonging to an uncertainty range that has to be considered in the evaluations and computation discussed here fig 17c shows the velocity profile v computed across the pallet section highlighted in fig 17a in which y is the abscissa oriented according to the section itself the maximum velocity close to the pallet location is about 1 9 m s for both the simulations the ratio between the estimated value 2 3 m s and the calculated one is 1 2 considering that not only does the numerical model provide a depth averaged velocity but also that the velocity on the free water surface is greater than the mean velocity itself the simulated velocity can be considered in good agreement with the observed one 6 4 comparison between observed and computed water levels a wider assessment of the numerical reconstruction has been carried out comparing the water depth ranges observed during a post event survey with the computed values in particular attention has been focused on the four relevant flooded areas shown in the figs 18 and 19 and identified as follows zone 1 road 2 and railway areas zone 2 neighbourhood 1 zone 3 street 1 zone 4 port considering the uncertainties necessarily associated with post event watermarks surveys the numerical reconstruction of the event is satisfying this confirms that 1 the boundary conditions are coherent with the observed hydraulic effects and 2 the topography assumed in the computation for the generation of the computational domain has been carried out with a suitable degree of accuracy the map of the simulated maximum water depths is shown in fig 20 for both hydrograph 1 fig 20a and hydrograph 2 fig 20b finally the froude number map computed in an instant of time just after the time to peak is shown in fig 20c 7 conclusions the careful analysis of the state of the art discussed in the introduction has highlighted that the number of highly detailed real world cases that can be effectively used for the calibration validation and assessment of numerical models is not so high see table 1 furthermore the numerical reconstruction of historical events is useful for the prediction of future scenarios in areas which have already experienced flood inundation in the past for these two reasons there is the need to increase the number of numerical reconstruction of historical cases the greater the distance in time of the flood event the greater the difficulty in performing these analyses due to couple of reasons a lack of conventional data related to hydrological and hydraulic variables b lack of suitable topographical data accurate enough to perform 2 d numerical reconstructions this paper has been focused mainly on these two aspects proposing a methodological approach summarized by the flow chart depicted in fig 1 the findings achieved using this method can be grouped into two blocks according to the two issues mentioned above as regards the first issue see point a this study has provided four major results using photos and frames extracted from video it is possible to obtain information on the evolution of water levels and velocities provided that the zones displayed in them are definitely recognized reports in the newspapers can be useful for localizing the areas in which the events took place once the inundated areas are detected the viewpoints of the places represented in the photographs and videos can be recognized through the use of visualization software such as google earth and street view patchworking of frames extracted from videos allows scientists and technicians to generate unpublished panoramic images representing the flow evolution during the event as regards the second issue see point b the three following conclusions can be highlighted the reconstruction of the topography can be achieved starting from the pre event official maps which can be supplemented by traditional post event surveys of river cross sections the refinement of the topographical details required for the application of accurate 2 d numerical models can be achieved using recent lidar data to provide detailed representations of those areas remained unchanged over time the orthophotos give useful information on land use and urban set up at the time of the event this method has been applied to the numerical reconstruction of the flood event in the city of crotone which occurred on october 14 1996 the quantitative data extracted using the non conventional information according to the method presented here and the numerical reconstruction of the event has allowed us to evaluate the validity of estimated discharge hydrographs used as upstream boundary condition of the flood propagation model in conclusion the application of the flow chart depicted in fig 1 has proved to be a reliable approach to achieve the numerical reconstruction of a flood event occurred in the past the complexity of which is testified not only by the presence of urbanized areas and the impulsiveness of the event but also by the effects of obstructing and unblocking of a bridge it is essential to underline that the added value provided by the careful analysis of the non conventional sources of information related to a past flood event is not limited to the numerical reconstruction of the event but also should be extended to the increase of people s awareness the behaviour of the population at risk can be effectively oriented once the flood dynamic in the urban areas is completely clear using the methods presented here it is possible to provide an unedited visual and quantitative documentation that can be disseminated among the population eventually supported by virtual visualization scenarios realized on the basis of the collected data leskens et al 2017 macchione et al 2019 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors are grateful to rosa de santis and fabiola gangi for their help in dealing with the frames taken from the films and in the reconstructing the topographic data his work was supported in part by the funding project pon sila pona3 00341a appendix outline of the numerical model according to finite volume method approach denoting by u i the average value of the flow variables over the control volume ω i at a given time eq 1 may be discretized as 6 u i n 1 u i n δ t ω i j 1 3 e n ij δ γ i j δ t s i in which i and j refer respectively to the ith cell and the jth edge of the cell n ij and δγij are the unit outward normal vector and the length of the jth edge respectively e is the numerical flux through the edge which may be computed by an appropriate riemann solver the numerical model used in this work has been already tested in previous works costabile and macchione 2015 macchione et al 2016 costabile et al 2017 specifically it uses the roe 1981 scheme for the computation of the numerical flux as reported in relation 7 7 e n 1 2 e l n e r n i 1 3 α i λ i e i in which 8 α 1 3 h r h l 2 1 2 c hu r hu l n x hv r hv l n y u n x v n y h r h l 9 α 2 1 c hv r hv l v h r h l n x hv r hv l u h r h l n y λ and ẽ are the eigenvalues and the eingevectors of the approximated jacobian matrix defined 10 λ 1 3 u n x v n y c 11 λ 2 u n x v n y 12 e 1 3 1 u c n x v c n y 13 e 2 0 c n y c n x they depend on the following averaged variables 14 u h r u r h l u l h r h l 15 v h r v r h l v l h r h l 16 c g 2 h r h l the harten hyman 1983 modification of the modulus of eingenvalues λ is applied in order to avoid non physical discontinuities the treatment of source terms of the shallow water equations is a key topic for the numerical models murillo et al 2007 valiani and begnudelli 2006 murillo and garcía navarro 2010 costabile et al 2012 2013 chertock et al 2015 liang et al 2015 vacondio et al 2016 xia et al 2017 in our scheme the source term vector s is decomposed in two different parts that are treated separately the bottom variation s 0 and the friction term s f s s 0 s f an upwind approach has been adopted to model the bottom variations for every edge r of the control volume the inward contribution of the bottom term is brufau et al 2004 17 s 0 r m 1 3 β m e m where the coefficients βm are calculated as 18 β 1 3 1 4 c 1 λ 1 3 λ 1 3 s 0 2 n x s 0 3 n y d rl 19 β 2 1 2 c 1 λ 2 λ 2 s 0 2 n y s 0 3 n x d rl where s 0 2 and s 0 3 are the second and third components of the vector of source terms s 0 20 s 0 0 g h δ z x g h δ z y in which h 1 2 h r h l δ z x zr z l d rl n x δ z y zr z l d rl n y and drl is the distance between the centroids of the right r and left l cells moreover a semi implicit treatment of the friction source term brufau et al 2004 costabile et al 2013 cea and bladé 2015 is applied here leading to the following relation 21 u i n 1 u i δ t θ s fi n 1 1 θ δ t s fi n u i n in which u i u i n δ t ω i r 1 3 f g r n n r s 0 r n i n δ l r θ is the implicitness degree of the friction term discretization θ 1 corresponds to a totally explicit treatment and θ 0 to a totally implicit one finally a robust wet dry procedure was implemented according to the approach presented in costabile et al 2013 
6306,urban flooding is still frequently treated as a direct consequence of excess rainfall without considering the watershed as an interdependent system connected with the development of its territory the traditional flood control approach implies in continuous corrective interventions usually of local character and resulting from post events responses this process requires increasingly large investments to implement or retrofit structures capable to accommodate the runoff generated by new urbanized areas these efforts have not prevented floods from continuing to cause high damages worldwide thus there is a need to change stormwater management strategies shifting to a risk management approach not only considering cost benefit analysis but also internalizing the residual risk accounting for inherent uncertainties such as climate change and fast and uncontrolled urban growth this paper proposes a multi criteria index the urban flood resilience index ufri to measure quantitatively urban resilience to floods supported by a hydrodynamic mathematical model and socio economic indicators resulting in spatialized maps as a communicating tool a case study of an urban watershed in rio de janeiro brazil is used to demonstrate ufri potential keywords sustainable storm water management distributed flood control measures flood risk management urban flood resilience 1 introduction despite the growing concern about what should be an adequate urban water management intending to face the changes caused by the urban development process flood events continue to cause great damages worldwide even in the core countries where there is already a considerable progress in conducting cities towards sustainability aroca jiménez et al 2018 summarized that the main causes that have been increasing the losses due to natural disasters are the inadequate land use planning population growth environmental degradation and the effects of global climate change as a response to this situation pender and néelz 2007 observed that throughout the world the way decision makers are dealing with urban flood is changing shifting from the strategy of defence against flooding to a flood risk management approach this background indicates the need for a change in flood management strategy leaving the simple cost benefit analysis of structural flood control measures and their results to assume a flood risk management approach in order to internalize residual risk escudero bueno et al 2011 faber 2006 handmer 2001 plate 2002 samuels et al 2009 plate 2002 describes the residual risk as the risk of failure of the structural system or occurrence of a flood greater than that used to design the defence system in addition to possible structural failures and occurrence of events of greater magnitude than the project event changes in patterns of hydrological variability may still occur with flood control infrastructure being no more reliable to mitigate flood uncertainties of the climate change process koutsoyiannis 2007 the step to be taken towards creating and maintaining cities that are less susceptible to potential damages from flood events is the recognition and internalization of the residual risk in the decision making strategies to be adopted in the management of stormwater within urban management to make it possible the various uncertainties inherent in the process of flooding should be considered such as climate change and different urban development possibilities including uncontrolled urban growth such as slums commonly flood management cope with risk trying to eliminate it and when urban planning does not consider the uncertainties a false perception of risk can be created on society leading to an increasing exposure of people and properties usually elimination of risk is impossible and impractical therefore the objective of risk management is not its elimination but the search for adequate and justifiable degrees of residual risk ciria 2010 to maintain an acceptable flood risk pattern cities must incorporate adaptation measures to allow the urban infrastructure to cope with flooding damages considering possible future changes in hydrological events likelihood arnbjerg nielsen and fleischer 2009 one way to internalize uncertainties into flood planning can be driven by a resilience approach in a way that the solutions should be designed not just to face a reference event but also to adequately behave over time even when facing challenges different from that of the design event over the last 15 years the technical literature about urban water management often discusses the concept of flood resilience see for example andoh and iwugo 2002 aroca jiménez et al 2018 brown et al 2009 gallopín 2006 johannessen and wamsler 2017 liao 2012 meerow et al 2016 roy et al 2008 unesco 2013 proag 2014 in general resilience may be defined as the ability of an individual community city or nation to resist absorb or recover from a shock such as an extreme flood and or successfully adapt to adversity or a change in conditions such as climate change or an economic downturn in a timely and efficient manner unesco 2013 this concept may have different interpretations depending on the discipline that uses it holling 1996 discussed different resilience interpretations in engineering and ecology the engineering resilience usually concentrates on a static equilibrium where resistance to disturbance and speed of recovery are the key features and recovery refer to going back to the pre defined standards the ecological resilience on the other hand relies on persistence changing and unpredictability in a dynamic equilibrium this ecological concept approaches resilience as the capacity to absorb a certain disturbance before changing and adapting its structure and it is related with the survival of the system similar to the definition of soft resilience proag 2014 in this case the adaptive system can evolve and will not return to the original condition liao 2012 highlighted that the concept of ecological resilience could be more appropriate to deal with flood risks and to seek adaptation measures because of the urban diversity the socioeconomic factors the riverine processes and the natural environment complexity rezende 2018 poses that the process of building resilience for the urban systems suggests a continuous process and a feedback approach this continuous process can help to bring together the engineering and ecological resilience approaches since even the engineering approach will move from a reference state to another new reference learning from past floods within the feedback process changing the original status to an improved one miguez et al 2018 a city can be considered as a socio ecological system where there are elements of both approaches that should be jointly considered in fact when a city alters the watershed consequently aggravating flow generation and increasing floods it is expected that measures to control floods and recover hydrological functions are introduced to reverse the negative effects and not only helping to live with them the ecological resilience approach however should complement this action by adapting the city to respond to residual risks and future challenges ibid urban planning guidelines should reflect the idea of building the city together with water dynamics shannon 2013 however in order to make resilience useful in the decision making process it is important to be able to measure and evaluate it since resilience brings several components together from the hazard assessment itself passing through the drainage system behaviour resistance and functional recovery and finishing in the analysis of the urban systems material recovery capacity it captures a general picture of the problem and has a great potential in composing the management tools of tomorrow bertilsson et al 2018 ahsan and warner 2014 observed the use of indexes in several research studies aiming the vulnerability assessment and adaptive capacity of communities the challenge of building a flood resilience assessment tool is addressed in this paper we aim to offer a practical analysis alternative which can be used as a supporting tool for territorial planning based on a multicriteria index that measures flood resilience spatialized over the watershed this tool is designed intending to guide the storm water management as a driver for the urban space structuring offering solutions to urban growth and flood control that are more resilient thus the paper proposes a methodological process that uses the urban flood resilience index ufri to assess resilience in a distributed way over the space of the watershed considering the residual risk over a project horizon allowing comparing the behaviour of different possible project alternatives in this work and using the proposed methodology we also intend to demonstrate the advantages of joining integrated flood risk management ifrm and the city territorial planning in this way two different concepts of interventions acting in a concentrated and distributed way in the space in the drainage system of an urban catchment with a consolidated occupation are opposed and assessed to support the main discussion 2 materials and methods this paper presents a framework of methodological procedures that allows a systemic evaluation of flood resilience in an urban catchment considering that the design of flood control measures should be guided by a reasoning of risk management and not just by a flood or even a damage reduction evaluation this is considered possible by internalizing residual risk and evaluating the resulting resilience of the system the consideration of hydrological scenarios with return periods greater than that of the reference design event in a given horizon of planning is taken into account therefore allowing to seek for better adaptive solutions when facing these scenarios the framework considers the use of a computational modelling system which is able to simulate the hydrodynamic behaviour of an urban drainage system in response to the several hydrologic events and a multicriteria index which is built to assess different urban characteristics and its relations with flood hazards 2 1 computational modelling system in order to obtain information on flood patterns in different scenarios hydrological and hydrodynamic modelling tools were used to support the analyses of different rainfall design events for a set of varied return periods rp the rp of storm events were chosen to cover the entire probabilistic curve flooding characteristics were obtained by using the urban flow cell model modcel mascarenhas and miguez 2002 miguez et al 2017 this model was based on the original work of zanobetti and lorgeré 1968 and assumes that the watershed can be subdivided into various types of flow cells which interact with each other through 1d flow equations representing the watershed surface and its flow pattern including a set of different hydraulic structures therefore modcel can be described as a quasi 2d cell model which integrates the hydrological processes observed in each cell into a looped hydrodynamic model creating a spatial representation that interconnects surface flow channel flows and storm drains therefore a dual drainage approach supports this model so the flow can occur simultaneously on both layers surface and underground silva et al 2017 this feature allows the assessment of both phenomena the river flooding and the drainage network failures during a storm event urban landscape as seen in fig 1 a can flood in response to two different types of failure channel overflows or storm drain overflows the first occurs when river and channels cannot support the total flow resulting from storm waters drained from the watershed as can be seen in case b of fig 1 the second occurs when urban drainage system mainly composed by storm drains are not able to conduct runoff resulting from a storm event drained by street lots squares etc as shown in case c of fig 1 when both systems fail there is a generalised urban flooding represented in fig 1 by case d 2 2 urban flood resilience index ufri to support the discussion on residual risk and compose the methodology proposed here an index is developed to aid the planning and design of urban drainage solutions adopting a methodology that departs from the basic concepts of risk management and evolves to consolidate a resilience index this index allow to build resilience maps and consequently allows to work to reduce risk consequences over time especially regarding avoided losses unesco 2013 the urban flood resilience index ufri which is based on the index presented as s fresi in tebaldi et al 2015 and bertilsson et al 2018 was expanded in this work to consider more variabilities of flooding and urban areas interactions fig 2 shows a flowchart highlighting the evolution of the s fresi to the ufri which considers more indicators in its formulation this increase aims to incorporate other aspects of urban flood resilience therefore the general revision in the formulation of s fresi accompanied by detailing and complementation of indicators justify the adoption of the new name ufri the ufri combines three sub indexes representing the three properties of resilience cited by proag 2014 i absorptive capacity the ability of the system to absorb the disruptive event represented by the sub index of risk to resistance capacity si r ii adaptive capacity the ability to adapt to the event represented by the sub index of risk to system functional capacity si f iii restorative capacity the ability of the system to recover represented by the sub index of risk to material recovery capacity si c each sub index considers hazard related indicators covering maximum flood depths water flow velocities and flood duration combined with vulnerability indicators the hierarchical arrangement of the indicators and sub indexes that compose the ufri is shown in the fig 3 the calculation of ufri uses eq 1 described in the table 1 the indicators are shortly presented below 1 ufri a 1 si r b 1 si c c 1 si f with si r risk to resistance capacity sub index si c risk to material recovery capacity sub index si f risk to system functional capacity sub index a b e c weights of each term the weighting method were not explored and the application did not define any preference therefore the weights have received equal values we consider that this is essentially a decision maker task and it can vary from case to case depending on the local characteristics of the flood and the social system it also can vary accordingly with the main objectives of the application 2 2 1 sub index of risk to resistance capacity si r the s i r represents the resistance to damage according to the degree of exposure of the population and the existing assets in the basin relating the exposure of buildings and urban infrastructure to the potential damages of a given flood three indicators are used in its formulation the building exposure indicator the urban infrastructure exposure and the flood depth indicator this sub index is calculated according to eq 2 2 si r a i eb n 1 b i ei n 2 i h n 3 2 2 1 1 i eb building exposure indicator the building exposure indirectly indicates exposure of people it is represented by built up density area in m2 ha the higher the density the more vertical the buildings are indicating a greater occupation either residential or commercial the values are normalized in a range between 0 and 1 with the higher value of exposure taken as the third quartile of built density distribution in the basin this method was applied to the canal do mangue catchment used as a case study resulting in the eq 3 fig 4 shows the i eb normalization applied to the canal do mangue catchment 3 i eb 4 43 10 5 b d 0 b d 22 596 i eb 1 0 b d 22 596 2 2 1 2 i ei urban infrastructure exposure indicator this indicator represents an indirectly measure of urban infrastructure exposure by road density in m ha the greater the density of roads in a region the greater is the coverage of infrastructure services such as water supply sanitation public lighting cable services etc the normalization of the indicator was done similarly to i e with the higher value of exposure given by the third quartile of the sample values varies between 0 and 1 the construction of the i ei to the canal do mangue catchment resulted in equation 4 fig 5 shows the i ei normalization applied to the canal do mangue catchment 4 i ei 3 25 10 3 r d 0 r d 284 i ei 1 0 r d 284 2 2 1 3 i h flood depth indicator this indicator computes the portion related to the potential damage of the evaluated flood event representing the hazard the maximum flood depth gives the value of the indicator thus the greater the depth of flooding the greater is the potential damage to the goods and people exposed it is normalized between 0 and 1 with higher value represented by a depth of 1 30 m which was chosen to represent very high potential damage the normalized formulation can be seen in eq 5 fig 6 shows the i h normalization 5 i h 0 0 h 0 15 i h 0 465 ln h 0 878 0 15 h 1 30 i h 1 0 h 1 30 2 2 2 sub index of risk to material recovery capacity si c it represents the socioeconomic part of the floods risk through a relative value indicator relating the flood depth to the potential damage according to the income range of the population directly exposed to flood its formulation is presented in the form of eq 6 6 si c i rv a i sv b 2 2 2 1 i rv relative value indicator it represents the economic recovery capacity of a region against the damages of a given flood event the indicator is calculated by the relation between the potential economic losses and the capacity to replace these damages represented by the difference between the total income and the average expenditure of a family in this way the i rv intends to represent a socioeconomic variable equalized according to the relation between the potential loss caused by the flooding event and the economic class of the exposed population assessing not an absolute loss but the ability to recover the suffered damage the i rv is given by eq 7 7 i rv c d b c d c a b i s 12 t i r c with cdb cost of damage to a building cdc cost of damage to building contents a b total area built in the analysis unit i s building susceptibility indicator ti total income of the population in the analysed region rc average replacement capacity of the population in the analysed region the whole formulation of this indicator can be found in rezende 2018 and is based in salgado 1995 2 2 2 2 i s building susceptibility indicator the indicator of susceptibility of the buildings is represented by the average height of the buildings in the analysed region since the flood damage is computed through the percentage of potential injury of a given flood depth the potential damage of a flooding event can injury the whole single story housing with a certain severity while it can only proportionally affect half of a double floor building since only the first floor is exposed the same logic is applied to multi floor buildings with three or more storeys therefore buildings with one floor are more susceptible to flooding damages than multi floors buildings this indicator is used as a correction factor to the i rv which is based on flood depth damage curves 2 2 2 3 i sv social vulnerability indicator this indicator represents a portion of the region s social vulnerability related to the percentage of people potentially most vulnerable to flood events from a physical point of view it considers the indicator of vulnerable people and an indicator related to the hazard represented by the velocity factor indicator the product of flow velocity and water depth and how its value can drag a person with the flow escudero bueno et al 2011 the i sv is given by eq 8 8 i sv a i vp n 1 i vfv n 2 b i np n 3 i vfn n 4 with i vp indicator of vulnerable persons i np indicator of non vulnerable persons i vfv velocity factor indicator for vulnerable people i vfn velocity factor indicator for non vulnerable people the whole formulation of this indicator can be found in rezende et al 2018 2 2 2 4 i vp and i np vulnerability of people indicator this indicator takes the direct proportion of the population that is less than 15 and over 60 years old in relation to the total population it represents people who are more prone to flooding consequences the i np is the complement of the i vp 2 2 2 5 i vf velocity factor indicator the velocity factor vf directly indicates the potential for affecting human stability during a flood event the normalization of i vf considers previous studies on the stability of people exposed to water rescdam 2000 based on this study two risk classifications of loss of stability were developed for vulnerable and non vulnerable groups of people as shown in table 2 the normalized formulations of i vfv and i vfn are given by eqs 9 and 10 the normalization curves are shown in fig 7 9 i vfv 0 9743 ln v f 2 3308 10 i vfn 1 0554 ln v f 1 3596 2 2 3 sub index of risk to system functional capacity si f it represents the system s ability to continue providing part of its services during the occurrence of a flood event this subscript considers the mobility risk indicator represented by the relationship between road hierarchy and non attendance by rail transport with the flooding event this sub index indicates the impact of the flood in the traffic of cars and people it also assesses the impact on the rescue access through the analysis of flooding in the squares of fire departments and their surroundings indicating potential difficulties in the organization of emergency actions the general formulation is given by eq 11 11 si c i mr a i da b 2 2 3 1 i da aid access difficulty indicator it indirectly represents the difficulty of a given region to receive help from a specialized aid team in the present study due to the ease of data access it was used the facilities of the fire department of rio de janeiro existing in the interior of the canal do mangue basin each department received an influence area which can be penalized when the flood reaches the local where the fire department is installed the penalization considers the flood depth representing the difficulty or even the impossibility of exit of aid cars the normalization of the indicator considers a nullified impact for flood depth up to 15 cm and maximum impact for floods of over 50 cm in depth indicating the interruption of the aid vehicles traffic as can be seen in fig 8 2 2 3 2 i mr mobility risk indicator the mobility risk indicator represents how much the transport system is affected by a flood event assessing the potential impact on the traffic of cars and people mobility for this it uses a road hierarchy indicator and a non attendance indicator for rail transport relating them to a permanence factor of flooding as a hazard indicator the i mr is given by 12 12 i mr i rh a i nrt b n 1 i pf n 2 2 2 3 3 i rh road hierarchy indicator this indicator is given by the highest route hierarchy within the analysis area according to the values presented in table 3 the information of hierarchy comes from cet rio an organ of the municipal transport department of rio de janeiro city 2 2 3 4 i nrt non rail transport service indicator it evaluates the offer of subway or train stations in radius of 1000 m and 500 m indicating the places with the highest coverage of this transport service which would indirectly present better possibilities for the continuity of traffic during flooding events the i nrt is given by the complement of the rail system offer indicator i rt ranked accordingly to the classification presented in table 4 2 2 3 5 i pf permanence factor indicator the i pf is the hazard indicator relative to duration of flooding considering three thresholds associated with different consequences regarding different water depths this indicator indirectly assesses the stormwater network s ability to drain floods evaluating the time that urban areas stay flooded it considers three depth classes between 10 cm and 25 cm t1 between 25 cm and 50 cm t2 and above 50 cm t3 the periods of each class are normalized according to a maximum time for which the maximum impact of flooding could be reached the definition of the maximum hazard time for each class considers the relative impact for the urban system thus for class t1 three hour flooded areas would have a high impact on the mobility of people restricting passage and increasing the possibility of transmission of waterborne diseases for class t2 with floods of up to 50 cm sidewalks are reached and traffic can be partially affected pregnolato et al 2017 assuming that a 60 minute period of flooding is sufficient to result in a high negative impact for the class t3 a period of 30 min could damage buildings structure and contents and could result in significant impacts on traffic with total disruption pregnolato et al 2017 in case of floods exceeding 50 cm in depth commonly in the canal do mangue basin the urbanization pattern shows sidewalks 25 cm above roads and first floors buildings have one step of 25 cm therefore only flooding depths with 50 cm or more can reach the basement of buildings the i pf is calculated by eq 13 13 i pf t 1 a t 2 b t 3 c eqs 14 15 and 16 show the normalization of each term of the i pf the weights considered in this study aimed to prioritize the impact of higher water levels considering the following values a 0 10 b 0 22 and c 0 68 these weights were originally proposed in the work of zonensein zonensein et al 2008 as mentioned before the periods of each class are normalized according to a maximum time for which the maximum impact of flooding is considered as shown in fig 9 14 t 1 0 0056 t 1 15 t 2 0 0167 t 2 16 t 1 0 0333 t 3 with t 1 total duration of floods with water depths between 10 cm and 25 cm t 2 total duration of floods with water depths between 25 cm and 50 cm t 3 total duration of floods with water depths greater than 50 cm 2 3 proposed methodological framework to measure urban flood resilience the proposed framework aims to internalize residual risk in the urban resilience evaluation from the analysis of system response to several hydrological events thus it is proposed the use of the multi events criterion which offers the possibility to create a spatialized resilience map a resilience value is estimated by the integration of the function ufri versus probability of occurrence of the events in a given planning horizon this integration is done for each basic evaluation unit of the model which are the flow cells allowing the spatialized resilience mapping of the urban catchment partial ufri values are plotted against the probability of occurrence of a given event or higher over a 25 year horizon taken as a planning reference horizon for each cell the ufri function ufri vs probability is integrated in order to estimate the final ufri which considers the probability of occurrence of several hydrological events over a period of 25 years in the end the resilience map of the watershed is elaborated with ufri values integrated for each cell considering all simulated events since the impacts of events with more severity than that of the design event are considered in this ufri integration process one can conclude that the residual risk related with these events is internalized in the estimation of the urban basin resilience the steps required to evaluate urban flood resilience with urban flood resilience index ufri through multi events criterion rezende 2018 are shown in fig 10 starting from the urban catchment evaluation physical and socioeconomic data need to be collected the first step is to define the catchment limits which interferes on hydrological modelling the physical data mainly topography hydrography pluviometry land use and urban patterns are used to build the mathematical modelling basis after deciding which area will be mapped the interest domain can be defined this domain must be more detailed to allow more accurate evaluations results of the flooding process are shown inside the interest domain such as flood depths flow velocities and flood duration this information is achieved through mathematical modelling after the construction of the mathematical model basis simulations are performed considering several hydrological events with different return periods the return periods rp adopted were 1 5 10 25 50 100 500 and 1000 years this choice aims to cover the entire range of the probabilistic curve considering events from ordinary probabilities once per 01 year to highly rare events once in 1000 years the results of the hydrodynamics modelling are used to fulfil the demands for representing the hazard indicators that are used to compose the higher orders indicators that is the hydrodynamic model provides flooding data which will compose the indicators i h i vf and i pf these indicators are inserted in the formulation of the ufri index for each flooding simulation result considering the several hydrological events additionally to these indicators i rv i sv i rm and i da depends on flooding data compounding the group of dependent indicators the second set of data referring to socio economic information is used to build the indicators i e i ei i s i sv i vp i rh and i nrt these indicators compose the group of independent indicators which means that they have no variability with flooding characteristics for each cell the results of mathematical modelling represented by flooding depths flow velocities and flood durations are used to feed a spreadsheet designed to calculate the indicators the sub indexes and finally the ufri this activity is performed for each hydrological scenario resulting in partial ufri maps which represents each individual flooding event for all recurrence times adopted finally the values of ufri are plotted against their probability of occurrence in a planning horizon defined as 25 years in this paper the final function ufri probability of each cell is integrated giving the urban resilience map as shown in fig 11 the detailed composition of indicators and indexes can be found in rezende 2018 it is important to highlight that modcel is able to represent different watershed scales since it performs the rainfall runoff transformation simulates the superficial flows before entering into the drainage network then joins storm drains and open channels ending up to include river simulation in fact these scales may be too different depending on the interest and the basis of simulation can be diverse from one aim to another however we are considering here as the main study object urban watersheds where small rivers are included in the major drainage system as its main channels 2 4 case study and simulation scenarios the canal do mangue catchment was chosen as a case study to exemplify the discussion carried out in this work this catchment is located in the northern part of the city of rio de janeiro covering parts of downtown and the traditional neighbourhoods of tijuca vila isabel maracanã rio comprido andaraí and grajaú important landmarks are located at canal do mangue catchment as the maracanã stadium the imperium museum and the old railway station leopoldina it drains a total area of around 45 km2 presenting very steep headwaters hills and a large lowland limited by the guanabara bay part of the lowlands is the result of landfills over wetlands and seashore areas in the guanabara bay which were done during the portuguese imperial period for sanitation purposes and urban growth this geomorphological pattern favours flooding at downstream plains where the major part of population is settled the catchment covers a highly urbanized area with a consolidated occupation and is one of the most symbolic areas in terms of flooding in rio de janeiro part of the urban occupation however refers to informal substandard occupations in this kind of situation dense occupation high runoff generation and uncontrolled flows structural measures based on sustainable urban drainage techniques are required within the compensatory measures approach consolidated by baptista et al 2011 in the last decades we have been noticing a considerable evolution in the urban storm water management concepts covering aspects from low impact development until water sensitive urban design see fletcher et al 2015 all approaches converge to a urban storm water management that favour source control distributed over the watershed minimizing hydrologic changes in the urban water cycle composing integrated solutions within urban landscape hoang and fenner 2016 considering this evolution on storm water management two sets of interventions were designed one with large and concentrated reservoirs and other with minor and distributed reservoirs thereby scenarios considering three conditions of the drainage infrastructure system were simulated c0 without interventions reflecting the actual state of flooding in the urban catchment c1 with concentrated large interventions based on a set of solutions proposed by the drainage master plan of rio de janeiro city published in 2010 c2 with distributed interventions over the watershed based on the canal do mangue flood control project presented in 2000 but not implemented for each drainage system condition the hydrodynamic modelling was performed for the selected hydrological events resulting in a spatial assessment of flooding hazard on the urban area three main aspects of flooding were mapped flood depth surface flow velocity and duration of flooding over certain thresholds as discussed in the permanence factor indicator description the model simulated the whole watershed including the upstream hills the urban plains the channel network and the main storm drains network thus the mapped flooding referred both to river flooding and storm water network surcharges and consequent overflows therefore using the main features of modcel the modelling base was built to simulate all the watershed functioning as an integrated system in this way the canal do mangue catchment was divided into 1036 cells with 100 cells representing rivers and channels 204 cells for storm drains 681 cells to simulate urban plains and 51 cells representing the upstream hills fig 12 shows the localization and discretization of the canal do mangue catchment in flow cells the model was calibrated for a storm event occurred on february 16th and validated for an event occurred on march 19th both in 2000 these dates refer to the only period of fluviometric measurements available in the watershed between 1998 and 2001 the results of water levels were compared to measured data in six fluvial gauges implemented during the elaboration of the canal do mangue flood master plan after calibration and validation process the different storm events with the chosen return periods were simulated for each event simulated flood maps were elaborated considering results of water levels this package of results comprehends a diagnosis of the current situation of drainage system which can be used as a base line as represented by scenario c0 to perform the simulations of the first designed solution represented in scenario c1 four large reservoirs were introduced into the modelling base summing 278 000 m3 of storage capacity and a river deviation to create a new outfall to the watershed decentralizing flooding flows this last intervention recovers a natural condition since joana river was originally separated from maracanã river the channelization that took place in this watershed artificially joined the low reaches of these rivers in just one channel these interventions are shown in fig 13 the second designed solution represented in scenario c2 considered a set of interventions based on detention measures with smaller dimensions compared to c1 there were inserted into the base modelling 18 hillside reservoirs 31 watersquares associated with small reservoirs depths between 1 0 m and 1 5 m pervious pavement in parking lots and sidewalks and the same river deviation considered on scenario c1 these proposed interventions can be seen in fig 14 the storage capacity of proposed reservoirs in this solution reaches 324 556 m3 63 allocated in hillside reservoirs and 37 in watersquares in addition to the permeable pavement systems 3 results and discussion the results of modelling process are compound by values of flooding characteristics and indicators values provided by socioeconomic data the indicators can be dependent on flooding results or independent composed only by socioeconomic data the situation of high propensity for the occurrence of floods in the canal do mangue catchment is confirmed by the results of the simulations of scenario c0 which show the extent of flooding problems for a storm with 10 years of recurrence time compatible with the design capacity of urban drainage systems the mapped area presents more than two thirds 68 1 of the cells with flooding depths greater than 15 cm situation in which problems of traffic and pedestrian circulation already begin flooding depths above 50 cm when possible damages to buildings and urban facilities can be observed cover almost a third of the cells 27 8 of interested area for this same storm event flooding depths over 100 cm which already cause damages to the contents of the buildings and increases the potential damages of the flood event cover about 5 of the cells considering the same storm of 10 years of recurrence time the implementation of the detention measures proposed in scenarios c1 and c2 considerably reduces floods above 50 cm which are observed in 10 9 and 6 8 of the cells of the area of interest respectively for each scenario the number of cells with depths greater than 100 cm that presents a high potential of damages and losses were reduced by about 90 representing less than 1 of the cells of the area of interest for both scenarios with interventions the intervention scenarios c1 and c2 also obtained an excellent result in the reduction of flood duration it has a direct impact on the flooding resilience since the capacity to return to normal functioning as soon as possible is one of the main characteristics of a resilient system concentrated interventions c1 reduced cells that had floods of more than 50 cm by over 60 for more than 30 min while the scenario with distributed measures c2 achieved a 74 reduction in the number of these cells floods with these characteristics are the most critical capable of generating great disturbances for the mobility disrupting the traffic in roads and causing damages to the infrastructure the flood risk sub indexes can be seen in fig 15 the observation of the results shows a better positive impact in the dimension of recovery capacity given by the sub index to material recovery capacity si c followed by the dimension of the ability to absorb and continue to offer minimum services given by the risk to system functional capacity si f these positive results are a consequence of maximum depth and duration of flooding reductions the effect of flood water levels lowering has a more significant impact on the si c because its formulation considers damage flood depth curves since the si r formulation computes built up and infrastructure density even if reductions in flood depths can reduce the number of affected buildings shallow water levels may still affect urban infrastructures the assessment of results was carried out by each sub index of risk showing that the risks decreases as interventions are more distributed the most significant reductions occur in the sub indexes of risk to material recovery and to system maintenance capacities as shown in fig 16 which summaries the flood risk in average values weighted by areas for the whole catchment the performance of each designed scenario can indicate that improvements in flood conditions resulted from drainage interventions reach the potential reduction of damages on urban infrastructure socioeconomic impacts and mobility during flooding events after the calculation of all sub indexes in ufri formulation and the application of multi event criteria urban flood resilience could be assessed in canal do mangue catchment in scenario c0 the less resilient areas are concentrated along the rivers courses and in the region known as praça da bandeira and maracanã where there is a strong tendency of concentrating floodwaters the results of scenario c1 show an improvement in flood conditions of praça da bandeira region due to the attenuation of volumes caused by the large reservoirs implantation and mainly by the diversion of one important river of watershed as interventions focus more on the lower part of the basin there is no significant positive impacts on upstream areas much of this flooding occurs due to the hydraulic insufficiency of drainage storm drains located upstream of the interventions which do not receive any benefits from reservoirs operation part of these problems is reduced by interventions proposed on scenario c2 based on small decentralized reservoirs and the use of permeable pavements fig 17 presents the distributed integral ufri result spatialized in the canal do mangue catchment resulting from the simulations with the three drainage network conditions scenarios c1 c2 and c3 the integralization of flood resilience values for each cell considered flooding results of all hydrological events simulated with return periods of 1 5 10 25 50 100 500 and 1000 years a comparative evaluation of the results of ufri in the basin can be carried out by analysing the potential of reducing areas with low resilience and increasing areas with high resilience in order to illustrate the analysis the accounting of areas in different resilience ranges was performed in the ires scale considering five bands as shown in table 5 with this evaluation it is possible to observe a sensitive impact of the interventions in the reduction of the area with very low resilience 8 in c0 to 1 in c2 and in the increase of the areas with high and very high resilience 41 in c0 to 60 in c2 as seen in fig 18 the present study did not aim to assess possible changes in urban construction patterns focusing on interventions in drainage system to reduce potential damages from flooding events therefore increasing resilience can be achieved by attenuation of flood behaviour represented by its three main characteristics depths flow velocities and flood duration 4 conclusions the paper presents an alternative path for the evaluation of flood risk management plans creating an approach focused on increasing resilience to floods in the urban system instead of maintaining the direct logic of damage reduction the resilience based approach prioritizes adaptive measures that aim to harmonize the relationship between the city and the water cycle since the concept of resilience relies not only on the responsive capacity of the system but also on its ability to absorb and coexist with the negative impacts of floods allowing an adaptive strategy arnbjerg nielsen and fleischer 2009 highlighted the urgency of the incorporation of adaptive measures in urban planning since urban infrastructure presents long technical lifetimes and climate changes are already occurring the authors suggest that we need simple forms to internalize potential impacts of climate change by urban planners as simple graphics and rules of thumb urban flood resilience mapping can be post as a simple illustrated way to demonstrate vantages and disadvantages of different set of solutions the application of urban flood resilience index ufri makes it possible to demonstrate spatially distributed results obtained by different approaches facilitating the assessment of multiple intervention scenarios and providing a comparative basis for easy presentation and understanding essential to a clear and efficient decision making process the results showed an improvement in the response of the basin as more distributed the flood control interventions are resilience mapping can be used as a supporting tool for hierarchizing interventions defining the locations that produce the greatest positive impacts on the system as a whole and thus addressing a systemic assessment even not demonstrated by chosen simulations scenarios to flood resilience assessment the proposed criterion also allows an ecosystemic evaluation since it allows one to perform several simulations of scenarios of land use patterns and drainage system strategies giving the results of impacts to each simulation at last it is important to highlight that we worked here with scenarios containing different hydraulic approaches opposing concentrated and distributed flood control measures however it would be also possible to work with city features reducing exposure defining safe routes individually protecting important buildings changing construction standards among others the combination of hydraulic adjustments in the drainage design procedures and the possibility of acting in the city systems adaptation would allow a broad range of actions to support a resilient urban planning process 5 formatting of funding sources the coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 financed this study in part some authors received financial support from the conselho nacional de desenvolvimento científico e tecnológico brazil cnpq osvaldo moura rezende financial code 141065 2012 5 antonio krishnamurti beleño de oliveira financial code 142284 2018 1 marcelo gomes miguez financial code 303240 2017 2 6 authors contributions osvaldo moura rezende led the ufri development and conducted the flood simulations as the final discus of resilience results proposing the new framework to assess urban flood resilience named as multi event criteria marcelo gomes miguez is the author of modcel and help with modelling process antonio krishnamurti beleño de oliveira anna beatriz ribeiro da cruz de franco and ana caroline pitzer jacob supported the modelling simulations and the evaluation of socioeconomic data used to fulfil the composition of the indicators declaration of competing interest none acknowledgements we acknowledge the coordenação de aperfeiçoamento de pessoal de nível superior brasil capes and the conselho nacional de desenvolvimento científico e tecnológico brasil cnpq for supporting this research we are also grateful for the support of the company aquafluxus consultoria ambiental em recursos hídricos 
6306,urban flooding is still frequently treated as a direct consequence of excess rainfall without considering the watershed as an interdependent system connected with the development of its territory the traditional flood control approach implies in continuous corrective interventions usually of local character and resulting from post events responses this process requires increasingly large investments to implement or retrofit structures capable to accommodate the runoff generated by new urbanized areas these efforts have not prevented floods from continuing to cause high damages worldwide thus there is a need to change stormwater management strategies shifting to a risk management approach not only considering cost benefit analysis but also internalizing the residual risk accounting for inherent uncertainties such as climate change and fast and uncontrolled urban growth this paper proposes a multi criteria index the urban flood resilience index ufri to measure quantitatively urban resilience to floods supported by a hydrodynamic mathematical model and socio economic indicators resulting in spatialized maps as a communicating tool a case study of an urban watershed in rio de janeiro brazil is used to demonstrate ufri potential keywords sustainable storm water management distributed flood control measures flood risk management urban flood resilience 1 introduction despite the growing concern about what should be an adequate urban water management intending to face the changes caused by the urban development process flood events continue to cause great damages worldwide even in the core countries where there is already a considerable progress in conducting cities towards sustainability aroca jiménez et al 2018 summarized that the main causes that have been increasing the losses due to natural disasters are the inadequate land use planning population growth environmental degradation and the effects of global climate change as a response to this situation pender and néelz 2007 observed that throughout the world the way decision makers are dealing with urban flood is changing shifting from the strategy of defence against flooding to a flood risk management approach this background indicates the need for a change in flood management strategy leaving the simple cost benefit analysis of structural flood control measures and their results to assume a flood risk management approach in order to internalize residual risk escudero bueno et al 2011 faber 2006 handmer 2001 plate 2002 samuels et al 2009 plate 2002 describes the residual risk as the risk of failure of the structural system or occurrence of a flood greater than that used to design the defence system in addition to possible structural failures and occurrence of events of greater magnitude than the project event changes in patterns of hydrological variability may still occur with flood control infrastructure being no more reliable to mitigate flood uncertainties of the climate change process koutsoyiannis 2007 the step to be taken towards creating and maintaining cities that are less susceptible to potential damages from flood events is the recognition and internalization of the residual risk in the decision making strategies to be adopted in the management of stormwater within urban management to make it possible the various uncertainties inherent in the process of flooding should be considered such as climate change and different urban development possibilities including uncontrolled urban growth such as slums commonly flood management cope with risk trying to eliminate it and when urban planning does not consider the uncertainties a false perception of risk can be created on society leading to an increasing exposure of people and properties usually elimination of risk is impossible and impractical therefore the objective of risk management is not its elimination but the search for adequate and justifiable degrees of residual risk ciria 2010 to maintain an acceptable flood risk pattern cities must incorporate adaptation measures to allow the urban infrastructure to cope with flooding damages considering possible future changes in hydrological events likelihood arnbjerg nielsen and fleischer 2009 one way to internalize uncertainties into flood planning can be driven by a resilience approach in a way that the solutions should be designed not just to face a reference event but also to adequately behave over time even when facing challenges different from that of the design event over the last 15 years the technical literature about urban water management often discusses the concept of flood resilience see for example andoh and iwugo 2002 aroca jiménez et al 2018 brown et al 2009 gallopín 2006 johannessen and wamsler 2017 liao 2012 meerow et al 2016 roy et al 2008 unesco 2013 proag 2014 in general resilience may be defined as the ability of an individual community city or nation to resist absorb or recover from a shock such as an extreme flood and or successfully adapt to adversity or a change in conditions such as climate change or an economic downturn in a timely and efficient manner unesco 2013 this concept may have different interpretations depending on the discipline that uses it holling 1996 discussed different resilience interpretations in engineering and ecology the engineering resilience usually concentrates on a static equilibrium where resistance to disturbance and speed of recovery are the key features and recovery refer to going back to the pre defined standards the ecological resilience on the other hand relies on persistence changing and unpredictability in a dynamic equilibrium this ecological concept approaches resilience as the capacity to absorb a certain disturbance before changing and adapting its structure and it is related with the survival of the system similar to the definition of soft resilience proag 2014 in this case the adaptive system can evolve and will not return to the original condition liao 2012 highlighted that the concept of ecological resilience could be more appropriate to deal with flood risks and to seek adaptation measures because of the urban diversity the socioeconomic factors the riverine processes and the natural environment complexity rezende 2018 poses that the process of building resilience for the urban systems suggests a continuous process and a feedback approach this continuous process can help to bring together the engineering and ecological resilience approaches since even the engineering approach will move from a reference state to another new reference learning from past floods within the feedback process changing the original status to an improved one miguez et al 2018 a city can be considered as a socio ecological system where there are elements of both approaches that should be jointly considered in fact when a city alters the watershed consequently aggravating flow generation and increasing floods it is expected that measures to control floods and recover hydrological functions are introduced to reverse the negative effects and not only helping to live with them the ecological resilience approach however should complement this action by adapting the city to respond to residual risks and future challenges ibid urban planning guidelines should reflect the idea of building the city together with water dynamics shannon 2013 however in order to make resilience useful in the decision making process it is important to be able to measure and evaluate it since resilience brings several components together from the hazard assessment itself passing through the drainage system behaviour resistance and functional recovery and finishing in the analysis of the urban systems material recovery capacity it captures a general picture of the problem and has a great potential in composing the management tools of tomorrow bertilsson et al 2018 ahsan and warner 2014 observed the use of indexes in several research studies aiming the vulnerability assessment and adaptive capacity of communities the challenge of building a flood resilience assessment tool is addressed in this paper we aim to offer a practical analysis alternative which can be used as a supporting tool for territorial planning based on a multicriteria index that measures flood resilience spatialized over the watershed this tool is designed intending to guide the storm water management as a driver for the urban space structuring offering solutions to urban growth and flood control that are more resilient thus the paper proposes a methodological process that uses the urban flood resilience index ufri to assess resilience in a distributed way over the space of the watershed considering the residual risk over a project horizon allowing comparing the behaviour of different possible project alternatives in this work and using the proposed methodology we also intend to demonstrate the advantages of joining integrated flood risk management ifrm and the city territorial planning in this way two different concepts of interventions acting in a concentrated and distributed way in the space in the drainage system of an urban catchment with a consolidated occupation are opposed and assessed to support the main discussion 2 materials and methods this paper presents a framework of methodological procedures that allows a systemic evaluation of flood resilience in an urban catchment considering that the design of flood control measures should be guided by a reasoning of risk management and not just by a flood or even a damage reduction evaluation this is considered possible by internalizing residual risk and evaluating the resulting resilience of the system the consideration of hydrological scenarios with return periods greater than that of the reference design event in a given horizon of planning is taken into account therefore allowing to seek for better adaptive solutions when facing these scenarios the framework considers the use of a computational modelling system which is able to simulate the hydrodynamic behaviour of an urban drainage system in response to the several hydrologic events and a multicriteria index which is built to assess different urban characteristics and its relations with flood hazards 2 1 computational modelling system in order to obtain information on flood patterns in different scenarios hydrological and hydrodynamic modelling tools were used to support the analyses of different rainfall design events for a set of varied return periods rp the rp of storm events were chosen to cover the entire probabilistic curve flooding characteristics were obtained by using the urban flow cell model modcel mascarenhas and miguez 2002 miguez et al 2017 this model was based on the original work of zanobetti and lorgeré 1968 and assumes that the watershed can be subdivided into various types of flow cells which interact with each other through 1d flow equations representing the watershed surface and its flow pattern including a set of different hydraulic structures therefore modcel can be described as a quasi 2d cell model which integrates the hydrological processes observed in each cell into a looped hydrodynamic model creating a spatial representation that interconnects surface flow channel flows and storm drains therefore a dual drainage approach supports this model so the flow can occur simultaneously on both layers surface and underground silva et al 2017 this feature allows the assessment of both phenomena the river flooding and the drainage network failures during a storm event urban landscape as seen in fig 1 a can flood in response to two different types of failure channel overflows or storm drain overflows the first occurs when river and channels cannot support the total flow resulting from storm waters drained from the watershed as can be seen in case b of fig 1 the second occurs when urban drainage system mainly composed by storm drains are not able to conduct runoff resulting from a storm event drained by street lots squares etc as shown in case c of fig 1 when both systems fail there is a generalised urban flooding represented in fig 1 by case d 2 2 urban flood resilience index ufri to support the discussion on residual risk and compose the methodology proposed here an index is developed to aid the planning and design of urban drainage solutions adopting a methodology that departs from the basic concepts of risk management and evolves to consolidate a resilience index this index allow to build resilience maps and consequently allows to work to reduce risk consequences over time especially regarding avoided losses unesco 2013 the urban flood resilience index ufri which is based on the index presented as s fresi in tebaldi et al 2015 and bertilsson et al 2018 was expanded in this work to consider more variabilities of flooding and urban areas interactions fig 2 shows a flowchart highlighting the evolution of the s fresi to the ufri which considers more indicators in its formulation this increase aims to incorporate other aspects of urban flood resilience therefore the general revision in the formulation of s fresi accompanied by detailing and complementation of indicators justify the adoption of the new name ufri the ufri combines three sub indexes representing the three properties of resilience cited by proag 2014 i absorptive capacity the ability of the system to absorb the disruptive event represented by the sub index of risk to resistance capacity si r ii adaptive capacity the ability to adapt to the event represented by the sub index of risk to system functional capacity si f iii restorative capacity the ability of the system to recover represented by the sub index of risk to material recovery capacity si c each sub index considers hazard related indicators covering maximum flood depths water flow velocities and flood duration combined with vulnerability indicators the hierarchical arrangement of the indicators and sub indexes that compose the ufri is shown in the fig 3 the calculation of ufri uses eq 1 described in the table 1 the indicators are shortly presented below 1 ufri a 1 si r b 1 si c c 1 si f with si r risk to resistance capacity sub index si c risk to material recovery capacity sub index si f risk to system functional capacity sub index a b e c weights of each term the weighting method were not explored and the application did not define any preference therefore the weights have received equal values we consider that this is essentially a decision maker task and it can vary from case to case depending on the local characteristics of the flood and the social system it also can vary accordingly with the main objectives of the application 2 2 1 sub index of risk to resistance capacity si r the s i r represents the resistance to damage according to the degree of exposure of the population and the existing assets in the basin relating the exposure of buildings and urban infrastructure to the potential damages of a given flood three indicators are used in its formulation the building exposure indicator the urban infrastructure exposure and the flood depth indicator this sub index is calculated according to eq 2 2 si r a i eb n 1 b i ei n 2 i h n 3 2 2 1 1 i eb building exposure indicator the building exposure indirectly indicates exposure of people it is represented by built up density area in m2 ha the higher the density the more vertical the buildings are indicating a greater occupation either residential or commercial the values are normalized in a range between 0 and 1 with the higher value of exposure taken as the third quartile of built density distribution in the basin this method was applied to the canal do mangue catchment used as a case study resulting in the eq 3 fig 4 shows the i eb normalization applied to the canal do mangue catchment 3 i eb 4 43 10 5 b d 0 b d 22 596 i eb 1 0 b d 22 596 2 2 1 2 i ei urban infrastructure exposure indicator this indicator represents an indirectly measure of urban infrastructure exposure by road density in m ha the greater the density of roads in a region the greater is the coverage of infrastructure services such as water supply sanitation public lighting cable services etc the normalization of the indicator was done similarly to i e with the higher value of exposure given by the third quartile of the sample values varies between 0 and 1 the construction of the i ei to the canal do mangue catchment resulted in equation 4 fig 5 shows the i ei normalization applied to the canal do mangue catchment 4 i ei 3 25 10 3 r d 0 r d 284 i ei 1 0 r d 284 2 2 1 3 i h flood depth indicator this indicator computes the portion related to the potential damage of the evaluated flood event representing the hazard the maximum flood depth gives the value of the indicator thus the greater the depth of flooding the greater is the potential damage to the goods and people exposed it is normalized between 0 and 1 with higher value represented by a depth of 1 30 m which was chosen to represent very high potential damage the normalized formulation can be seen in eq 5 fig 6 shows the i h normalization 5 i h 0 0 h 0 15 i h 0 465 ln h 0 878 0 15 h 1 30 i h 1 0 h 1 30 2 2 2 sub index of risk to material recovery capacity si c it represents the socioeconomic part of the floods risk through a relative value indicator relating the flood depth to the potential damage according to the income range of the population directly exposed to flood its formulation is presented in the form of eq 6 6 si c i rv a i sv b 2 2 2 1 i rv relative value indicator it represents the economic recovery capacity of a region against the damages of a given flood event the indicator is calculated by the relation between the potential economic losses and the capacity to replace these damages represented by the difference between the total income and the average expenditure of a family in this way the i rv intends to represent a socioeconomic variable equalized according to the relation between the potential loss caused by the flooding event and the economic class of the exposed population assessing not an absolute loss but the ability to recover the suffered damage the i rv is given by eq 7 7 i rv c d b c d c a b i s 12 t i r c with cdb cost of damage to a building cdc cost of damage to building contents a b total area built in the analysis unit i s building susceptibility indicator ti total income of the population in the analysed region rc average replacement capacity of the population in the analysed region the whole formulation of this indicator can be found in rezende 2018 and is based in salgado 1995 2 2 2 2 i s building susceptibility indicator the indicator of susceptibility of the buildings is represented by the average height of the buildings in the analysed region since the flood damage is computed through the percentage of potential injury of a given flood depth the potential damage of a flooding event can injury the whole single story housing with a certain severity while it can only proportionally affect half of a double floor building since only the first floor is exposed the same logic is applied to multi floor buildings with three or more storeys therefore buildings with one floor are more susceptible to flooding damages than multi floors buildings this indicator is used as a correction factor to the i rv which is based on flood depth damage curves 2 2 2 3 i sv social vulnerability indicator this indicator represents a portion of the region s social vulnerability related to the percentage of people potentially most vulnerable to flood events from a physical point of view it considers the indicator of vulnerable people and an indicator related to the hazard represented by the velocity factor indicator the product of flow velocity and water depth and how its value can drag a person with the flow escudero bueno et al 2011 the i sv is given by eq 8 8 i sv a i vp n 1 i vfv n 2 b i np n 3 i vfn n 4 with i vp indicator of vulnerable persons i np indicator of non vulnerable persons i vfv velocity factor indicator for vulnerable people i vfn velocity factor indicator for non vulnerable people the whole formulation of this indicator can be found in rezende et al 2018 2 2 2 4 i vp and i np vulnerability of people indicator this indicator takes the direct proportion of the population that is less than 15 and over 60 years old in relation to the total population it represents people who are more prone to flooding consequences the i np is the complement of the i vp 2 2 2 5 i vf velocity factor indicator the velocity factor vf directly indicates the potential for affecting human stability during a flood event the normalization of i vf considers previous studies on the stability of people exposed to water rescdam 2000 based on this study two risk classifications of loss of stability were developed for vulnerable and non vulnerable groups of people as shown in table 2 the normalized formulations of i vfv and i vfn are given by eqs 9 and 10 the normalization curves are shown in fig 7 9 i vfv 0 9743 ln v f 2 3308 10 i vfn 1 0554 ln v f 1 3596 2 2 3 sub index of risk to system functional capacity si f it represents the system s ability to continue providing part of its services during the occurrence of a flood event this subscript considers the mobility risk indicator represented by the relationship between road hierarchy and non attendance by rail transport with the flooding event this sub index indicates the impact of the flood in the traffic of cars and people it also assesses the impact on the rescue access through the analysis of flooding in the squares of fire departments and their surroundings indicating potential difficulties in the organization of emergency actions the general formulation is given by eq 11 11 si c i mr a i da b 2 2 3 1 i da aid access difficulty indicator it indirectly represents the difficulty of a given region to receive help from a specialized aid team in the present study due to the ease of data access it was used the facilities of the fire department of rio de janeiro existing in the interior of the canal do mangue basin each department received an influence area which can be penalized when the flood reaches the local where the fire department is installed the penalization considers the flood depth representing the difficulty or even the impossibility of exit of aid cars the normalization of the indicator considers a nullified impact for flood depth up to 15 cm and maximum impact for floods of over 50 cm in depth indicating the interruption of the aid vehicles traffic as can be seen in fig 8 2 2 3 2 i mr mobility risk indicator the mobility risk indicator represents how much the transport system is affected by a flood event assessing the potential impact on the traffic of cars and people mobility for this it uses a road hierarchy indicator and a non attendance indicator for rail transport relating them to a permanence factor of flooding as a hazard indicator the i mr is given by 12 12 i mr i rh a i nrt b n 1 i pf n 2 2 2 3 3 i rh road hierarchy indicator this indicator is given by the highest route hierarchy within the analysis area according to the values presented in table 3 the information of hierarchy comes from cet rio an organ of the municipal transport department of rio de janeiro city 2 2 3 4 i nrt non rail transport service indicator it evaluates the offer of subway or train stations in radius of 1000 m and 500 m indicating the places with the highest coverage of this transport service which would indirectly present better possibilities for the continuity of traffic during flooding events the i nrt is given by the complement of the rail system offer indicator i rt ranked accordingly to the classification presented in table 4 2 2 3 5 i pf permanence factor indicator the i pf is the hazard indicator relative to duration of flooding considering three thresholds associated with different consequences regarding different water depths this indicator indirectly assesses the stormwater network s ability to drain floods evaluating the time that urban areas stay flooded it considers three depth classes between 10 cm and 25 cm t1 between 25 cm and 50 cm t2 and above 50 cm t3 the periods of each class are normalized according to a maximum time for which the maximum impact of flooding could be reached the definition of the maximum hazard time for each class considers the relative impact for the urban system thus for class t1 three hour flooded areas would have a high impact on the mobility of people restricting passage and increasing the possibility of transmission of waterborne diseases for class t2 with floods of up to 50 cm sidewalks are reached and traffic can be partially affected pregnolato et al 2017 assuming that a 60 minute period of flooding is sufficient to result in a high negative impact for the class t3 a period of 30 min could damage buildings structure and contents and could result in significant impacts on traffic with total disruption pregnolato et al 2017 in case of floods exceeding 50 cm in depth commonly in the canal do mangue basin the urbanization pattern shows sidewalks 25 cm above roads and first floors buildings have one step of 25 cm therefore only flooding depths with 50 cm or more can reach the basement of buildings the i pf is calculated by eq 13 13 i pf t 1 a t 2 b t 3 c eqs 14 15 and 16 show the normalization of each term of the i pf the weights considered in this study aimed to prioritize the impact of higher water levels considering the following values a 0 10 b 0 22 and c 0 68 these weights were originally proposed in the work of zonensein zonensein et al 2008 as mentioned before the periods of each class are normalized according to a maximum time for which the maximum impact of flooding is considered as shown in fig 9 14 t 1 0 0056 t 1 15 t 2 0 0167 t 2 16 t 1 0 0333 t 3 with t 1 total duration of floods with water depths between 10 cm and 25 cm t 2 total duration of floods with water depths between 25 cm and 50 cm t 3 total duration of floods with water depths greater than 50 cm 2 3 proposed methodological framework to measure urban flood resilience the proposed framework aims to internalize residual risk in the urban resilience evaluation from the analysis of system response to several hydrological events thus it is proposed the use of the multi events criterion which offers the possibility to create a spatialized resilience map a resilience value is estimated by the integration of the function ufri versus probability of occurrence of the events in a given planning horizon this integration is done for each basic evaluation unit of the model which are the flow cells allowing the spatialized resilience mapping of the urban catchment partial ufri values are plotted against the probability of occurrence of a given event or higher over a 25 year horizon taken as a planning reference horizon for each cell the ufri function ufri vs probability is integrated in order to estimate the final ufri which considers the probability of occurrence of several hydrological events over a period of 25 years in the end the resilience map of the watershed is elaborated with ufri values integrated for each cell considering all simulated events since the impacts of events with more severity than that of the design event are considered in this ufri integration process one can conclude that the residual risk related with these events is internalized in the estimation of the urban basin resilience the steps required to evaluate urban flood resilience with urban flood resilience index ufri through multi events criterion rezende 2018 are shown in fig 10 starting from the urban catchment evaluation physical and socioeconomic data need to be collected the first step is to define the catchment limits which interferes on hydrological modelling the physical data mainly topography hydrography pluviometry land use and urban patterns are used to build the mathematical modelling basis after deciding which area will be mapped the interest domain can be defined this domain must be more detailed to allow more accurate evaluations results of the flooding process are shown inside the interest domain such as flood depths flow velocities and flood duration this information is achieved through mathematical modelling after the construction of the mathematical model basis simulations are performed considering several hydrological events with different return periods the return periods rp adopted were 1 5 10 25 50 100 500 and 1000 years this choice aims to cover the entire range of the probabilistic curve considering events from ordinary probabilities once per 01 year to highly rare events once in 1000 years the results of the hydrodynamics modelling are used to fulfil the demands for representing the hazard indicators that are used to compose the higher orders indicators that is the hydrodynamic model provides flooding data which will compose the indicators i h i vf and i pf these indicators are inserted in the formulation of the ufri index for each flooding simulation result considering the several hydrological events additionally to these indicators i rv i sv i rm and i da depends on flooding data compounding the group of dependent indicators the second set of data referring to socio economic information is used to build the indicators i e i ei i s i sv i vp i rh and i nrt these indicators compose the group of independent indicators which means that they have no variability with flooding characteristics for each cell the results of mathematical modelling represented by flooding depths flow velocities and flood durations are used to feed a spreadsheet designed to calculate the indicators the sub indexes and finally the ufri this activity is performed for each hydrological scenario resulting in partial ufri maps which represents each individual flooding event for all recurrence times adopted finally the values of ufri are plotted against their probability of occurrence in a planning horizon defined as 25 years in this paper the final function ufri probability of each cell is integrated giving the urban resilience map as shown in fig 11 the detailed composition of indicators and indexes can be found in rezende 2018 it is important to highlight that modcel is able to represent different watershed scales since it performs the rainfall runoff transformation simulates the superficial flows before entering into the drainage network then joins storm drains and open channels ending up to include river simulation in fact these scales may be too different depending on the interest and the basis of simulation can be diverse from one aim to another however we are considering here as the main study object urban watersheds where small rivers are included in the major drainage system as its main channels 2 4 case study and simulation scenarios the canal do mangue catchment was chosen as a case study to exemplify the discussion carried out in this work this catchment is located in the northern part of the city of rio de janeiro covering parts of downtown and the traditional neighbourhoods of tijuca vila isabel maracanã rio comprido andaraí and grajaú important landmarks are located at canal do mangue catchment as the maracanã stadium the imperium museum and the old railway station leopoldina it drains a total area of around 45 km2 presenting very steep headwaters hills and a large lowland limited by the guanabara bay part of the lowlands is the result of landfills over wetlands and seashore areas in the guanabara bay which were done during the portuguese imperial period for sanitation purposes and urban growth this geomorphological pattern favours flooding at downstream plains where the major part of population is settled the catchment covers a highly urbanized area with a consolidated occupation and is one of the most symbolic areas in terms of flooding in rio de janeiro part of the urban occupation however refers to informal substandard occupations in this kind of situation dense occupation high runoff generation and uncontrolled flows structural measures based on sustainable urban drainage techniques are required within the compensatory measures approach consolidated by baptista et al 2011 in the last decades we have been noticing a considerable evolution in the urban storm water management concepts covering aspects from low impact development until water sensitive urban design see fletcher et al 2015 all approaches converge to a urban storm water management that favour source control distributed over the watershed minimizing hydrologic changes in the urban water cycle composing integrated solutions within urban landscape hoang and fenner 2016 considering this evolution on storm water management two sets of interventions were designed one with large and concentrated reservoirs and other with minor and distributed reservoirs thereby scenarios considering three conditions of the drainage infrastructure system were simulated c0 without interventions reflecting the actual state of flooding in the urban catchment c1 with concentrated large interventions based on a set of solutions proposed by the drainage master plan of rio de janeiro city published in 2010 c2 with distributed interventions over the watershed based on the canal do mangue flood control project presented in 2000 but not implemented for each drainage system condition the hydrodynamic modelling was performed for the selected hydrological events resulting in a spatial assessment of flooding hazard on the urban area three main aspects of flooding were mapped flood depth surface flow velocity and duration of flooding over certain thresholds as discussed in the permanence factor indicator description the model simulated the whole watershed including the upstream hills the urban plains the channel network and the main storm drains network thus the mapped flooding referred both to river flooding and storm water network surcharges and consequent overflows therefore using the main features of modcel the modelling base was built to simulate all the watershed functioning as an integrated system in this way the canal do mangue catchment was divided into 1036 cells with 100 cells representing rivers and channels 204 cells for storm drains 681 cells to simulate urban plains and 51 cells representing the upstream hills fig 12 shows the localization and discretization of the canal do mangue catchment in flow cells the model was calibrated for a storm event occurred on february 16th and validated for an event occurred on march 19th both in 2000 these dates refer to the only period of fluviometric measurements available in the watershed between 1998 and 2001 the results of water levels were compared to measured data in six fluvial gauges implemented during the elaboration of the canal do mangue flood master plan after calibration and validation process the different storm events with the chosen return periods were simulated for each event simulated flood maps were elaborated considering results of water levels this package of results comprehends a diagnosis of the current situation of drainage system which can be used as a base line as represented by scenario c0 to perform the simulations of the first designed solution represented in scenario c1 four large reservoirs were introduced into the modelling base summing 278 000 m3 of storage capacity and a river deviation to create a new outfall to the watershed decentralizing flooding flows this last intervention recovers a natural condition since joana river was originally separated from maracanã river the channelization that took place in this watershed artificially joined the low reaches of these rivers in just one channel these interventions are shown in fig 13 the second designed solution represented in scenario c2 considered a set of interventions based on detention measures with smaller dimensions compared to c1 there were inserted into the base modelling 18 hillside reservoirs 31 watersquares associated with small reservoirs depths between 1 0 m and 1 5 m pervious pavement in parking lots and sidewalks and the same river deviation considered on scenario c1 these proposed interventions can be seen in fig 14 the storage capacity of proposed reservoirs in this solution reaches 324 556 m3 63 allocated in hillside reservoirs and 37 in watersquares in addition to the permeable pavement systems 3 results and discussion the results of modelling process are compound by values of flooding characteristics and indicators values provided by socioeconomic data the indicators can be dependent on flooding results or independent composed only by socioeconomic data the situation of high propensity for the occurrence of floods in the canal do mangue catchment is confirmed by the results of the simulations of scenario c0 which show the extent of flooding problems for a storm with 10 years of recurrence time compatible with the design capacity of urban drainage systems the mapped area presents more than two thirds 68 1 of the cells with flooding depths greater than 15 cm situation in which problems of traffic and pedestrian circulation already begin flooding depths above 50 cm when possible damages to buildings and urban facilities can be observed cover almost a third of the cells 27 8 of interested area for this same storm event flooding depths over 100 cm which already cause damages to the contents of the buildings and increases the potential damages of the flood event cover about 5 of the cells considering the same storm of 10 years of recurrence time the implementation of the detention measures proposed in scenarios c1 and c2 considerably reduces floods above 50 cm which are observed in 10 9 and 6 8 of the cells of the area of interest respectively for each scenario the number of cells with depths greater than 100 cm that presents a high potential of damages and losses were reduced by about 90 representing less than 1 of the cells of the area of interest for both scenarios with interventions the intervention scenarios c1 and c2 also obtained an excellent result in the reduction of flood duration it has a direct impact on the flooding resilience since the capacity to return to normal functioning as soon as possible is one of the main characteristics of a resilient system concentrated interventions c1 reduced cells that had floods of more than 50 cm by over 60 for more than 30 min while the scenario with distributed measures c2 achieved a 74 reduction in the number of these cells floods with these characteristics are the most critical capable of generating great disturbances for the mobility disrupting the traffic in roads and causing damages to the infrastructure the flood risk sub indexes can be seen in fig 15 the observation of the results shows a better positive impact in the dimension of recovery capacity given by the sub index to material recovery capacity si c followed by the dimension of the ability to absorb and continue to offer minimum services given by the risk to system functional capacity si f these positive results are a consequence of maximum depth and duration of flooding reductions the effect of flood water levels lowering has a more significant impact on the si c because its formulation considers damage flood depth curves since the si r formulation computes built up and infrastructure density even if reductions in flood depths can reduce the number of affected buildings shallow water levels may still affect urban infrastructures the assessment of results was carried out by each sub index of risk showing that the risks decreases as interventions are more distributed the most significant reductions occur in the sub indexes of risk to material recovery and to system maintenance capacities as shown in fig 16 which summaries the flood risk in average values weighted by areas for the whole catchment the performance of each designed scenario can indicate that improvements in flood conditions resulted from drainage interventions reach the potential reduction of damages on urban infrastructure socioeconomic impacts and mobility during flooding events after the calculation of all sub indexes in ufri formulation and the application of multi event criteria urban flood resilience could be assessed in canal do mangue catchment in scenario c0 the less resilient areas are concentrated along the rivers courses and in the region known as praça da bandeira and maracanã where there is a strong tendency of concentrating floodwaters the results of scenario c1 show an improvement in flood conditions of praça da bandeira region due to the attenuation of volumes caused by the large reservoirs implantation and mainly by the diversion of one important river of watershed as interventions focus more on the lower part of the basin there is no significant positive impacts on upstream areas much of this flooding occurs due to the hydraulic insufficiency of drainage storm drains located upstream of the interventions which do not receive any benefits from reservoirs operation part of these problems is reduced by interventions proposed on scenario c2 based on small decentralized reservoirs and the use of permeable pavements fig 17 presents the distributed integral ufri result spatialized in the canal do mangue catchment resulting from the simulations with the three drainage network conditions scenarios c1 c2 and c3 the integralization of flood resilience values for each cell considered flooding results of all hydrological events simulated with return periods of 1 5 10 25 50 100 500 and 1000 years a comparative evaluation of the results of ufri in the basin can be carried out by analysing the potential of reducing areas with low resilience and increasing areas with high resilience in order to illustrate the analysis the accounting of areas in different resilience ranges was performed in the ires scale considering five bands as shown in table 5 with this evaluation it is possible to observe a sensitive impact of the interventions in the reduction of the area with very low resilience 8 in c0 to 1 in c2 and in the increase of the areas with high and very high resilience 41 in c0 to 60 in c2 as seen in fig 18 the present study did not aim to assess possible changes in urban construction patterns focusing on interventions in drainage system to reduce potential damages from flooding events therefore increasing resilience can be achieved by attenuation of flood behaviour represented by its three main characteristics depths flow velocities and flood duration 4 conclusions the paper presents an alternative path for the evaluation of flood risk management plans creating an approach focused on increasing resilience to floods in the urban system instead of maintaining the direct logic of damage reduction the resilience based approach prioritizes adaptive measures that aim to harmonize the relationship between the city and the water cycle since the concept of resilience relies not only on the responsive capacity of the system but also on its ability to absorb and coexist with the negative impacts of floods allowing an adaptive strategy arnbjerg nielsen and fleischer 2009 highlighted the urgency of the incorporation of adaptive measures in urban planning since urban infrastructure presents long technical lifetimes and climate changes are already occurring the authors suggest that we need simple forms to internalize potential impacts of climate change by urban planners as simple graphics and rules of thumb urban flood resilience mapping can be post as a simple illustrated way to demonstrate vantages and disadvantages of different set of solutions the application of urban flood resilience index ufri makes it possible to demonstrate spatially distributed results obtained by different approaches facilitating the assessment of multiple intervention scenarios and providing a comparative basis for easy presentation and understanding essential to a clear and efficient decision making process the results showed an improvement in the response of the basin as more distributed the flood control interventions are resilience mapping can be used as a supporting tool for hierarchizing interventions defining the locations that produce the greatest positive impacts on the system as a whole and thus addressing a systemic assessment even not demonstrated by chosen simulations scenarios to flood resilience assessment the proposed criterion also allows an ecosystemic evaluation since it allows one to perform several simulations of scenarios of land use patterns and drainage system strategies giving the results of impacts to each simulation at last it is important to highlight that we worked here with scenarios containing different hydraulic approaches opposing concentrated and distributed flood control measures however it would be also possible to work with city features reducing exposure defining safe routes individually protecting important buildings changing construction standards among others the combination of hydraulic adjustments in the drainage design procedures and the possibility of acting in the city systems adaptation would allow a broad range of actions to support a resilient urban planning process 5 formatting of funding sources the coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 financed this study in part some authors received financial support from the conselho nacional de desenvolvimento científico e tecnológico brazil cnpq osvaldo moura rezende financial code 141065 2012 5 antonio krishnamurti beleño de oliveira financial code 142284 2018 1 marcelo gomes miguez financial code 303240 2017 2 6 authors contributions osvaldo moura rezende led the ufri development and conducted the flood simulations as the final discus of resilience results proposing the new framework to assess urban flood resilience named as multi event criteria marcelo gomes miguez is the author of modcel and help with modelling process antonio krishnamurti beleño de oliveira anna beatriz ribeiro da cruz de franco and ana caroline pitzer jacob supported the modelling simulations and the evaluation of socioeconomic data used to fulfil the composition of the indicators declaration of competing interest none acknowledgements we acknowledge the coordenação de aperfeiçoamento de pessoal de nível superior brasil capes and the conselho nacional de desenvolvimento científico e tecnológico brasil cnpq for supporting this research we are also grateful for the support of the company aquafluxus consultoria ambiental em recursos hídricos 
6307,subsurface dams are widely used to prevent saltwater intrusion around the world a subsurface dam blocks the groundwater movement both from and towards the sea this blockage often leads to an accumulation of pollutants and salt on the inland and sea side of the dam respectively while the latter is intended the former effect is not desired and poses a huge problem in groundwater management herein we propose the use of dams of minimum effective height to prevent saltwater intrusion and the use of the fresh groundwater discharge to assess the environmental performance of the subsurface dam laboratory tests and numerical simulations were used to study the effects of dam height distance from the saltwater boundary and head difference on the subsurface dam s saltwater intrusion prevention efficiency and fresh groundwater discharge we found that i the fresh groundwater discharge reaches its peak at the minimum dam effective height and ii the minimum effective dam height is shorter than the height of swi without the dam this means under the premise of effectively preventing swi we can reduce both construction costs and increase fresh groundwater discharge through constructing the dam with the minimum effective dam height when the dam height was less than the minimum effective dam height the subsurface dam had little effect in preventing saltwater intrusion as the dam distance to the shoreline increased the minimum effective dam height and the peak fresh groundwater discharge decreased simultaneously a reduction of the dam height is conducive to saving engineering cost while a reduction of the peak fresh groundwater discharge favors the accumulation of land based pollutants and salt although an increased distance of the dam to the coast seems more economic during construction this also implies a larger inland soil salinization and accumulation of pollutants the site selection of subsurface dams is therefore an optimization task that should consider both the engineering cost and ecological environmental effects keywords saltwater intrusion subsurface dams dam location minimum effective dam height fresh groundwater discharge 1 introduction saltwater intrusion swi is the primary adverse factor affecting groundwater exploitation in coastal regions bear 1999 kayode 2017 under the action of a regional groundwater flow field fresh groundwater discharges to the ocean and exchanges with the high density saltwater body near the coast fig 1 a excessive pumping of groundwater in coastal aquifers leads to a decreased water table height and the saltwater wedge keeps invading inland goswami and clement 2007 walther et al 2017 zhang 2019 swi directly leads to soil salinization and to the substantial decline of agricultural output yu 2019 swi has become an important factor restricting the social and economic development in coastal regions werner et al 2013 at present the main methods to prevent swi are hydraulic barriers and physical barriers abarca et al 2006 botero acosta and donado 2015 in addition the compressed air injection method was proposed to prevent swi but it has not been widely used due to its low efficiency for preventing swi sun et al 2013 hydraulic barriers require the continuous pumping of the saltwater or recharge of the fresh water into the aquifers and the wells used face the problem of clogging in the long run luyun et al 2011 allow 2012 physical barriers use the soil mixing wall method or trench cutting remixing deep wall method to construct impervious soil cement bentonite walls that can effectively prevent swi once and for all onder et al 2005 luiz et al 2018 since the 1980s japan china india the middle east and african countries have built many underground physical barriers to prevent and control swi raju et al 2013 stevanović 2015 at present physical barriers can be divided into cut off walls subsurface dams and semi pervious subsurface barriers spsb fig 1b d hasan basri 2001 kaleris and ziogas 2013 subsurface dams are the most widely used wall type in the international field of preventing swi nawa et al 2009 abdoulhalik et al 2017c jamali et al 2013 used a gis model coupled to a groundwater balance model to study the siting solution of subsurface dams kang et al 2017 used isotope analysis to investigate the effect of subsurface dams on the groundwater nutrient dynamics in the wang river watershed in china they found that due to the blocking effect of subsurface dams on the groundwater the nitrogen and phosphorus concentrations upstream of the subsurface dams were higher than those downstream cantalice et al 2016 built an underground dam in the brazilian jacu watershed and monitored the soil moisture groundwater quality and electrical conductivity for more than three years according to the monitoring results the underground dam resulted in the retention of more soil moisture in the rainy season however the interception effect of the underground dam led to gradual increase of groundwater salinity upstream which eventually lead to soil salinization senthilkumar and elango 2011 used modflow to study the influence of subsurface dams on groundwater flow fields in the palar river basin in india the model predicted that after the establishment of subsurface dams the upstream groundwater levels would rise by 0 1 0 3 m and the range of influence would be about 1 5 2 km upstream while the downstream groundwater level would decrease by 0 1 0 2 m abdoulhalik and ahmed 2017a used laboratory tests and seawat numerical simulation to study the cut off wall efficiency for swi control in stratified aquifers they combined for the first time the use of cut off walls and subsurface dams to enhance the efficiency of swi prevention abdoulhalik et al 2017b luyun et al 2009 studied the relationship between the height of subsurface dams and the thickness of the saltwater wedge using laboratory tests and seawat they found that when the subsurface dams were higher than the thickness of the saltwater wedge seawater intrusion could be prevented and the saltwater trapped upstream could be flushed out however the effects of the construction location of subsurface dams and head difference were neglected the efficiency of subsurface dams for preventing swi is determined by a wall s depth hydraulic conductivity distance from the coast groundwater velocity and aquifer anisotropy kaleris and ziogas 2013 the top of a subsurface dam is generally at sea level fig 1 c in some regions the subsurface dams intersect the full cross section of the aquifer to store water underground for irrigation fig 1 d silva et al 1998 ishida et al 2011 yasumoto et al 2011 however the excessive dam height will not only increase the engineering cost but will also cut off the route of fresh groundwater discharge to the sea the interception of fresh groundwater leads to inland soil salinization and accumulation of pollutants see references above in order to avoid such disadvantages sugio et al 1987 proposed to change impermeable subsurface dams to semi permeable ones then the salt and pollutants in the fresh groundwater could discharge to the sea through the semi permeable subsurface dam however the saltwater could also invade the aquifer through the semi permeable subsurface dam which reduced the efficiency of the subsurface dam for preventing swi in conclusion it is a significant problem to prevent the inland soil salinization and accumulation of pollutants by maximizing the fresh groundwater discharge while ensuring the efficiency of subsurface dams for preventing swi in contrast to previous work we propose using dams of minimum effective height to prevent swi moreover we used the fresh groundwater discharge to assess the environmental performance of the subsurface dam as an increased fresh groundwater discharge is beneficial for carrying land based pollutants and salt to the sea which accumulate in traditional high subsurface barriers qu et al 2017 sathe and mahanta 2019 tavakoli kivi et al 2019 sun et al 2019 we used laboratory tests and numerical simulation to investigate the optimization of subsurface dams the laboratory tests were completed in a flow tank to represent swi in an unconfined aquifer under the influence of a subsurface dam seawat was used to interpret the laboratory test results the subsurface dam height dam distance to the saltwater boundary and head difference were investigated to maximize the efficiency of swi prevention and the discharge of fresh groundwater to the sea we have found that the fresh groundwater discharge reaches its peak with the minimum effective dam height and the minimum effective dam height is slightly shorter than the height of swi without the dam thus we can reduce both construction costs and increase fresh groundwater discharge through constructing the dam with the optimized dam height 2 material and methods 2 1 scenario definition we defined two scenarios to investigate the efficiency of the subsurface dam a baseline case was used to compare the experimental and numerical setups and acquire a parametrization in the baseline case the head differences of freshwater and saltwater were set as 8 mm 9 mm and 10 mm in the lab experiments length of saltwater wedge dynamics were used to compare the lab results and numerical simulations a subsurface dam case was used to assess the sensitivity of the dam height location and head difference with respect to steady state swi length and fresh groundwater discharge the subsurface dam case was defined as the base dam case was set as dam height 7 cm distance 20 cm and head difference 9 mm we changed one factor of dam height location and head difference at a time in the lab experiments to compare with the base dam case pictures of steady state swi were taken to observe the shape of saltwater wedge at different dam cases seawat was used to assess the sensitivity of the dam height location and head difference 2 2 laboratory material the experiment was carried out in a flow tank with internal dimensions of 90 cm length 45 cm height 5 cm width fig 2 in order to simulate an unconfined aquifer the water tank was divided into three zones by porous plates freshwater reservoir saltwater reservoir and porous media chamber glass beads with uniform diameter of 0 7 mm were used to fill in the middle zone of the tank as porous media the fresh and saltwater reservoirs were positioned on the left and right sides of the flow tank respectively and the fresh and saltwater flow was pumped at a constant rate into the reservoirs from the bottom inlets the constant heads of the fresh groundwater and saltwater were controlled by adjustable drainage overflow pipes nacl solution with a concentration of 36 g l was prepared to represent seawater a densitometer alfamirage sd 200l was used to measure the seawater density ρs 1025 kg m3 the freshwater density ρf 1000kg m3 see table 1 cochineal dyes red food color sinopharm chemical reagent co ltd were added to trace the saltwater the dyes could be migrated synchronously with the saltwater in the flow tank goswami and clement 2007 therefore the red area in the flow tank could be used to determine the range of the saltwater wedge the average hydraulic conductivity k of the porous media as calculated by darcy s law was 5 8 e 3 m s and the porosity measured by the volume method was 0 4 the longitudinal dispersivity αl is 0 13 cm which was determined by fitting the breakthrough curves with an one dimensional column test the transverse dispersivity αt was set to be 1 10 of the longitudinal dispersion shoemaker et al 2004 lu et al 2013 the subsurface dam was made of plasticine which is impermeable 2 3 experimental setup the saltwater head was fixed at 26 cm the fresh groundwater head was adjustable and was adjusted to 26 8 cm 26 9 cm and 27 0 cm respectively during different scenarios we filled the glass beads into the porous media chamber layer by layer under saturated conditions to avoid air bubbles to reside in the pores the fresh water was pumped into the freshwater reservoir which was then filled with porous media and the overflow discharged through the overflow outlet of the saltwater reservoir then the saltwater entered the saltwater reservoir from the inlet pipe and gradually filled the saltwater reservoir from the bottom up the saltwater wedge gradually formed and began a continuous invasion of the aquifer the position of the saltwater wedge was recorded every 10 min by a digital camera canon ixus 285 hs as soon as the saltwater wedge reached the subsurface dam it stopped advancing and rose against the subsurface dam if the saltwater wedge could be captured at the position of the subsurface dam the dam was effective to prevent swi if the saltwater extended downward behind the dam after flowing over the top of the subsurface dam the subsurface dam failed to prevent swi when the saltwater reached the impervious base behind the dam a new saltwater wedge formed and continued to invade the aquifer we considered the setup equilibrated when swi was not advancing more than 1 mm per 10 min 2 4 numerical setup seawat was used to simulate swi and to calculate the fresh groundwater discharge to the sea guo and langevin 2002 langevin 2003 during the setup of the numerical model we followed the laboratory settings and parameters as close as possible the numerical simulation area was a homogeneous unconfined two dimensional vertical cross section with the size of 90 27 cm2 a no flow boundary condition was defined on the upper part and lower part of the numerical model the left side freshwater boundary was set as a variable constant head boundary 26 5 to 27 1 cm the concentration was set to cf 0 g l the right side saltwater boundary was set to a constant head of 26 cm and the concentration was set to cs 36 g l the simulation area was discretized by a uniform grid with quadratic elements with an edge length of 0 5 cm the grid spacing and dispersivity satisfied the péclet number criterion to ensure numerical stability voss et al 1987 1 p e v δ l d l v δ l l 3 8 4 where δl is the grid spacing d is molecular diffusion the time step was set to 60 s the aquifer medium hydraulic conductivity k was set to 5 8e 3 m s as the used plasticine is practically impermeable the hydraulic conductivity of the subsurface dam was set to 1e 9 m s and the width of the subsurface dam was 1 cm a stress period was set for both the baseline case and the subsurface dam case lasting for 6 h which was adequate for the saltwater wedge to reach a state of dynamic equilibrium 3 results and discussion 3 1 baseline case in the baseline case we firstly studied the influence of the variation of the head difference fig 4 a b and c shows the results for head differences of 8 9 and 10 mm which resulted in intrusion lengths of the saltwater wedge of 56 4 44 7 and 37 1 cm respectively fig 4 d shows the comparison of the 50 isoline under the different head conditions 50 isoline is wildly used for saltwater wedge in the aquifer with low dispersivity goswami and clement 2007 luyun et al 2009 stoeckl et al 2016 the comparison between the experimental data and the numerical simulation results of the length of the saltwater wedge is shown in fig 5 the numerical simulation results and the experimental data have a good degree of fit under the different head conditions for the head differences of 8 9 and 10 mm swi reaches dynamic equilibrium at 300 230 and 180 min respectively the water flowing out of the right boundary of the flow tank is the brackish water mixed with the fresh groundwater and saltwater therefore the study on the fresh groundwater discharge should be based on the water balance of the fresh groundwater flowing into and flowing out of the flow tank seawat was used to calculate the fresh groundwater rate flowing into the flow tank which is equal to the discharge of the fresh groundwater fig 6 plots the variation of fresh groundwater discharge versus head difference when swi reaches dynamic equilibrium it can be seen that the fresh groundwater discharge increased gradually with increase of the head difference this is because the velocity of the fresh groundwater flowing into the flow tank increases with increase of the head difference according to darcy s law the increased fresh groundwater flow velocity results in an increase of the fresh groundwater discharge 3 2 dam height the head difference of freshwater boundary and saltwater boundary was kept at 9 mm the location of the subsurface dam was set at a distance of 20 cm from the saltwater boundary the subsurface dam heights were set at 6 cm 7 cm and 8 cm respectively fig 7 shows the results for the variations of the dam height with the laboratory experiments in the case of no subsurface dam the length of the saltwater wedge was 44 7 cm fig 3 b when the dam height was 6 cm the saltwater wedge flowed over the top of the subsurface dam and advanced to a distance of 43 3 cm in this case the subsurface dam lost its function of preventing swi when the dam height was increased to 7 cm the saltwater wedge was intercepted at the position of the subsurface dam and the thickness of the saltwater wedge at the dam was approximately equal to the height of the subsurface dam when the dam height was increased to 8 cm the saltwater wedge was also effectively intercepted and the thickness of the saltwater wedge toe was lower than the height of the subsurface dam the numerical simulation results and the laboratory tests have a good degree of fit in figs 7 and 8 which shows the numerical simulations are reliable for the dam heights of 6 7 and 8 cm the saltwater wedge reaches dynamic equilibrium at 463 54 and 64 min respectively comparing with the swi dynamic equilibrium time of 230 min without the dam the equilibrium time decreases three quarters when the subsurface dam is effective even if the subsurface dam is too low to prevent swi it can still slow down the speed of swi in the following we use the dimensionless ratio of the dam height hdam and the aquifer thickness haqu haqu 26 cm fig 9 shows the influence of the dam height on the swi length until the ratio hdam haqu reaches 0 27 i e hdam 7 cm the swi length decreases only slightly and is similar to the baseline case indicating that the dam loses the function of preventing swi when hdam haqu is larger than 0 27 the swi length decreases sharply to 20 cm and the saltwater wedge is intercepted by the dam thus hdam haqu 0 27 is the minimum effective dam height to prevent swi in the case of a head difference of 9 mm fig 10 shows the fresh groundwater discharge for different dam heights with increase of the dam height the fresh groundwater discharge increases slightly and then decreases sharply the fresh groundwater discharge reaches the maximum value at hdam haqu 0 27 from fig 9 we know that hdam haqu 0 27 is the minimum effective dam height to prevent swi in this case it is worth noting that the fresh groundwater discharge at the minimum effective dam height is larger than that of the baseline case without subsurface dam the flow velocity in the saltwater wedge is far smaller than that of fresh groundwater abdoulhalik and ahmed 2017a therefore the stagnant saltwater wedge decreases the discharge section area just like the subsurface dam does as we can see in fig 7d the thickness of the saltwater wedge in the baseline case without subsurface dam is higher than the minimum effective dam height at the dam location this means that the fresh groundwater discharge section area in the baseline case is smaller than that of the minimum effective dam case at the same height as sea level the fresh groundwater discharge of the subsurface dam decreases to 37 2 of the maximum value this is because the fresh groundwater discharge section area is too small 3 3 dam location under the condition that the head difference was 9 mm and the dam height was set at 7 cm i e the minimum height at which the dam was effective the distance from the saltwater boundary was changed to 15 cm and 25 cm according to the laboratory results when the distance from saltwater boundary was 15 cm the saltwater wedge crossed the top of the subsurface dam and advanced to a length of 42 8 cm fig 11 a when the distance was increased to 25 cm the subsurface dam could still prevent swi fig 11b fig 12 shows the influence of the dam location on the saltwater wedge length the dam location is expressed by the ratio of the distance from saltwater boundary ldam to the thickness of the aquifer haqu when ldam haqu is less than 0 77 ldam 20 cm the saltwater wedge length decreases slightly with increase of ldam haqu when ldam haqu is equal to 0 77 the saltwater wedge length sharply decreases to 20 cm indicating that the saltwater wedge is intercepted by the subsurface dam when ldam haqu is greater than 0 77 the saltwater wedge is still intercepted at the dam position the saltwater wedge length increases with the dam distance from the saltwater boundary therefore the minimum effective dam height is related to the distance from the saltwater boundary therefore hdam haqu 0 27 hdam 7 cm is the minimum effective dam height just at the dam position of ldam haqu 0 77 ldam 20 cm fig 13 shows the fresh groundwater discharge in cases with different dam distance when ldam haqu is less than 0 77 the fresh groundwater discharge increases slightly with increase of the dam distance when ldam haqu 0 77 ldam 20 cm the discharge reaches its peak when ldam haqu is greater than 0 77 the fresh groundwater discharge gradually decreases with increase of the dam distance as we know from the previous analysis hdam haqu 0 27 hdam 7 cm is the minimum effective dam height only at the dam position of ldam haqu 0 77 therefore when hdam haqu 0 27 hd 7 cm the discharge reaches the peak at the dam position of ldam haqu 0 77 ldam 20 cm 3 4 head difference the hydraulic gradient is expressed by the head difference between the fresh groundwater boundary and the saltwater boundary the dam height was set at 7 cm and the distance from the saltwater boundary was set at 20 cm the head differences were changed to 8 mm and 10 mm respectively when the head difference was 8 mm the saltwater wedge flowed over the top of the subsurface dam and advanced to a length of 53 cm the subsurface dam could not prevent swi fig 14 a when the head difference was increased to 10 mm the dam height was greater than the thickness of the saltwater wedge toe and the saltwater wedge stopped at the dam location fig 14b sensitivity analysis was used to investigate the influence of the head difference on the length of the saltwater wedge fig 15 when the head difference is less than 9 mm the length of the saltwater wedge gradually decreases with the head difference when the head difference is equal to 9 mm the saltwater wedge sharply decreases to the same distance that the dam is from the shoreline when the head difference is greater than 9 mm swi is still intercepted at the dam position fig 16 shows the fresh groundwater discharge in the cases with different head differences the fresh groundwater discharge gradually increases with the head difference as we know the fresh groundwater flow velocity gradually increases with the head difference according to darcy s law therefore the increase of fresh groundwater flow velocity leads to gradual increase of the fresh groundwater discharge 3 5 discharge at the minimum effective dam height according to the above analysis the fresh groundwater discharge is related to the dam height location and head difference fig 17 shows the effect of the dam height and location on the fresh groundwater discharge under the head difference of 9 mm as can be seen from fig 17 the boundary between the effective region red region and the failed region blue region is the minimum effective dam height needed to prevent swi the discharge reaches its peak value at the minimum effective dam height hmin at a defined dam position when the dam distance from the saltwater boundary is zero the peak discharge is the largest as the dam distance from the saltwater boundary increases the peak discharge becomes smaller and smaller the fresh groundwater discharge reaches its peak at the minimum effective dam height which is beneficial to control the accumulation of land based pollutants and salt it is of great significance to investigate the minimum effective height of the subsurface dams at different positions and with different head differences fig 18 shows the minimum effective dam height and corresponding fresh groundwater discharge at the different dam distances and head differences it can be seen that with the same head difference and with increase of the dam distance away from the shoreline the minimum effective dam height and fresh groundwater discharge decrease gradually this is consistent with fig 17 with increase of the head difference the minimum effective dam height decreases and the fresh groundwater discharge increases at the same dam location this indicates that a large head differences is conducive to saving engineering costs and reducing the accumulation of land based pollutants and salt 4 summary and conclusions in this study we proposed the use of dams of minimum effective height to prevent saltwater intrusion and used the fresh groundwater discharge to assess the environmental performance of the subsurface dam laboratory tests and numerical simulations were used to investigate the effects of the dam height the dam location and the head difference on the saltwater intrusion prevention ability of the subsurface dam and on the fresh groundwater discharge for the baseline case without subsurface dam with increase of the head difference the time for swi to reach dynamic equilibrium as well as the length of the saltwater wedge shorten and the fresh groundwater discharge increases a minimum effective dam height at a defined distance from the shoreline that will prevent saltwater intrusion could be identified until a minimum effective dam height increasing dam height has no significant effect on decreasing of the saltwater wedge length when the dam height is equal to or higher than the minimum effective dam height the saltwater wedge can be intercepted at the subsurface dam position the fresh groundwater discharge reaches its peak at the minimum effective dam height a larger freshwater recharge will push back more saltwater therefore the minimum effective dam height is shorter than the height of swi without the dam the minimum effective dam height strongly depends on the distance to the shoreline as the dam distance from saltwater boundary increases the minimum effective height and the peak fresh groundwater discharge decreases simultaneously with increase of the head difference the minimum effective height decreases and the fresh groundwater discharge increases at the same dam location therefore a steep head difference is beneficial to reducing engineering costs and reducing the accumulation of land based pollutants and salt the reduction of the minimum effective dam height is conducive for saving engineering cost additionally avoiding the reduction of the fresh groundwater discharge as it is the case for a dam which is constructed over the whole aquifer thickness decreases the accumulation of land based pollutants and salt therefore the site selection of the subsurface dams should consider both the engineering cost and ecological environmental effects tidal effects on the minimum effective dam height by changing the head difference luyun et al 2009 designers should carefully consider the minimum effective dam height on the lowest head difference the head difference between the lowest underground water level and maximum tidal heights in local history an adequate safety margin should be reserved based on the minimum effective height as this study firstly focussed on laboratory scale setups further studies will have to investigate field scale implications to delineate minimum effective dam heights acknowledgements this work was supported by the national key research and development program of china no 2016yfc0402810 and the national natural science foundation of china shandong joint fund no u1806210 for funding this project declaration of competing interest none 
6307,subsurface dams are widely used to prevent saltwater intrusion around the world a subsurface dam blocks the groundwater movement both from and towards the sea this blockage often leads to an accumulation of pollutants and salt on the inland and sea side of the dam respectively while the latter is intended the former effect is not desired and poses a huge problem in groundwater management herein we propose the use of dams of minimum effective height to prevent saltwater intrusion and the use of the fresh groundwater discharge to assess the environmental performance of the subsurface dam laboratory tests and numerical simulations were used to study the effects of dam height distance from the saltwater boundary and head difference on the subsurface dam s saltwater intrusion prevention efficiency and fresh groundwater discharge we found that i the fresh groundwater discharge reaches its peak at the minimum dam effective height and ii the minimum effective dam height is shorter than the height of swi without the dam this means under the premise of effectively preventing swi we can reduce both construction costs and increase fresh groundwater discharge through constructing the dam with the minimum effective dam height when the dam height was less than the minimum effective dam height the subsurface dam had little effect in preventing saltwater intrusion as the dam distance to the shoreline increased the minimum effective dam height and the peak fresh groundwater discharge decreased simultaneously a reduction of the dam height is conducive to saving engineering cost while a reduction of the peak fresh groundwater discharge favors the accumulation of land based pollutants and salt although an increased distance of the dam to the coast seems more economic during construction this also implies a larger inland soil salinization and accumulation of pollutants the site selection of subsurface dams is therefore an optimization task that should consider both the engineering cost and ecological environmental effects keywords saltwater intrusion subsurface dams dam location minimum effective dam height fresh groundwater discharge 1 introduction saltwater intrusion swi is the primary adverse factor affecting groundwater exploitation in coastal regions bear 1999 kayode 2017 under the action of a regional groundwater flow field fresh groundwater discharges to the ocean and exchanges with the high density saltwater body near the coast fig 1 a excessive pumping of groundwater in coastal aquifers leads to a decreased water table height and the saltwater wedge keeps invading inland goswami and clement 2007 walther et al 2017 zhang 2019 swi directly leads to soil salinization and to the substantial decline of agricultural output yu 2019 swi has become an important factor restricting the social and economic development in coastal regions werner et al 2013 at present the main methods to prevent swi are hydraulic barriers and physical barriers abarca et al 2006 botero acosta and donado 2015 in addition the compressed air injection method was proposed to prevent swi but it has not been widely used due to its low efficiency for preventing swi sun et al 2013 hydraulic barriers require the continuous pumping of the saltwater or recharge of the fresh water into the aquifers and the wells used face the problem of clogging in the long run luyun et al 2011 allow 2012 physical barriers use the soil mixing wall method or trench cutting remixing deep wall method to construct impervious soil cement bentonite walls that can effectively prevent swi once and for all onder et al 2005 luiz et al 2018 since the 1980s japan china india the middle east and african countries have built many underground physical barriers to prevent and control swi raju et al 2013 stevanović 2015 at present physical barriers can be divided into cut off walls subsurface dams and semi pervious subsurface barriers spsb fig 1b d hasan basri 2001 kaleris and ziogas 2013 subsurface dams are the most widely used wall type in the international field of preventing swi nawa et al 2009 abdoulhalik et al 2017c jamali et al 2013 used a gis model coupled to a groundwater balance model to study the siting solution of subsurface dams kang et al 2017 used isotope analysis to investigate the effect of subsurface dams on the groundwater nutrient dynamics in the wang river watershed in china they found that due to the blocking effect of subsurface dams on the groundwater the nitrogen and phosphorus concentrations upstream of the subsurface dams were higher than those downstream cantalice et al 2016 built an underground dam in the brazilian jacu watershed and monitored the soil moisture groundwater quality and electrical conductivity for more than three years according to the monitoring results the underground dam resulted in the retention of more soil moisture in the rainy season however the interception effect of the underground dam led to gradual increase of groundwater salinity upstream which eventually lead to soil salinization senthilkumar and elango 2011 used modflow to study the influence of subsurface dams on groundwater flow fields in the palar river basin in india the model predicted that after the establishment of subsurface dams the upstream groundwater levels would rise by 0 1 0 3 m and the range of influence would be about 1 5 2 km upstream while the downstream groundwater level would decrease by 0 1 0 2 m abdoulhalik and ahmed 2017a used laboratory tests and seawat numerical simulation to study the cut off wall efficiency for swi control in stratified aquifers they combined for the first time the use of cut off walls and subsurface dams to enhance the efficiency of swi prevention abdoulhalik et al 2017b luyun et al 2009 studied the relationship between the height of subsurface dams and the thickness of the saltwater wedge using laboratory tests and seawat they found that when the subsurface dams were higher than the thickness of the saltwater wedge seawater intrusion could be prevented and the saltwater trapped upstream could be flushed out however the effects of the construction location of subsurface dams and head difference were neglected the efficiency of subsurface dams for preventing swi is determined by a wall s depth hydraulic conductivity distance from the coast groundwater velocity and aquifer anisotropy kaleris and ziogas 2013 the top of a subsurface dam is generally at sea level fig 1 c in some regions the subsurface dams intersect the full cross section of the aquifer to store water underground for irrigation fig 1 d silva et al 1998 ishida et al 2011 yasumoto et al 2011 however the excessive dam height will not only increase the engineering cost but will also cut off the route of fresh groundwater discharge to the sea the interception of fresh groundwater leads to inland soil salinization and accumulation of pollutants see references above in order to avoid such disadvantages sugio et al 1987 proposed to change impermeable subsurface dams to semi permeable ones then the salt and pollutants in the fresh groundwater could discharge to the sea through the semi permeable subsurface dam however the saltwater could also invade the aquifer through the semi permeable subsurface dam which reduced the efficiency of the subsurface dam for preventing swi in conclusion it is a significant problem to prevent the inland soil salinization and accumulation of pollutants by maximizing the fresh groundwater discharge while ensuring the efficiency of subsurface dams for preventing swi in contrast to previous work we propose using dams of minimum effective height to prevent swi moreover we used the fresh groundwater discharge to assess the environmental performance of the subsurface dam as an increased fresh groundwater discharge is beneficial for carrying land based pollutants and salt to the sea which accumulate in traditional high subsurface barriers qu et al 2017 sathe and mahanta 2019 tavakoli kivi et al 2019 sun et al 2019 we used laboratory tests and numerical simulation to investigate the optimization of subsurface dams the laboratory tests were completed in a flow tank to represent swi in an unconfined aquifer under the influence of a subsurface dam seawat was used to interpret the laboratory test results the subsurface dam height dam distance to the saltwater boundary and head difference were investigated to maximize the efficiency of swi prevention and the discharge of fresh groundwater to the sea we have found that the fresh groundwater discharge reaches its peak with the minimum effective dam height and the minimum effective dam height is slightly shorter than the height of swi without the dam thus we can reduce both construction costs and increase fresh groundwater discharge through constructing the dam with the optimized dam height 2 material and methods 2 1 scenario definition we defined two scenarios to investigate the efficiency of the subsurface dam a baseline case was used to compare the experimental and numerical setups and acquire a parametrization in the baseline case the head differences of freshwater and saltwater were set as 8 mm 9 mm and 10 mm in the lab experiments length of saltwater wedge dynamics were used to compare the lab results and numerical simulations a subsurface dam case was used to assess the sensitivity of the dam height location and head difference with respect to steady state swi length and fresh groundwater discharge the subsurface dam case was defined as the base dam case was set as dam height 7 cm distance 20 cm and head difference 9 mm we changed one factor of dam height location and head difference at a time in the lab experiments to compare with the base dam case pictures of steady state swi were taken to observe the shape of saltwater wedge at different dam cases seawat was used to assess the sensitivity of the dam height location and head difference 2 2 laboratory material the experiment was carried out in a flow tank with internal dimensions of 90 cm length 45 cm height 5 cm width fig 2 in order to simulate an unconfined aquifer the water tank was divided into three zones by porous plates freshwater reservoir saltwater reservoir and porous media chamber glass beads with uniform diameter of 0 7 mm were used to fill in the middle zone of the tank as porous media the fresh and saltwater reservoirs were positioned on the left and right sides of the flow tank respectively and the fresh and saltwater flow was pumped at a constant rate into the reservoirs from the bottom inlets the constant heads of the fresh groundwater and saltwater were controlled by adjustable drainage overflow pipes nacl solution with a concentration of 36 g l was prepared to represent seawater a densitometer alfamirage sd 200l was used to measure the seawater density ρs 1025 kg m3 the freshwater density ρf 1000kg m3 see table 1 cochineal dyes red food color sinopharm chemical reagent co ltd were added to trace the saltwater the dyes could be migrated synchronously with the saltwater in the flow tank goswami and clement 2007 therefore the red area in the flow tank could be used to determine the range of the saltwater wedge the average hydraulic conductivity k of the porous media as calculated by darcy s law was 5 8 e 3 m s and the porosity measured by the volume method was 0 4 the longitudinal dispersivity αl is 0 13 cm which was determined by fitting the breakthrough curves with an one dimensional column test the transverse dispersivity αt was set to be 1 10 of the longitudinal dispersion shoemaker et al 2004 lu et al 2013 the subsurface dam was made of plasticine which is impermeable 2 3 experimental setup the saltwater head was fixed at 26 cm the fresh groundwater head was adjustable and was adjusted to 26 8 cm 26 9 cm and 27 0 cm respectively during different scenarios we filled the glass beads into the porous media chamber layer by layer under saturated conditions to avoid air bubbles to reside in the pores the fresh water was pumped into the freshwater reservoir which was then filled with porous media and the overflow discharged through the overflow outlet of the saltwater reservoir then the saltwater entered the saltwater reservoir from the inlet pipe and gradually filled the saltwater reservoir from the bottom up the saltwater wedge gradually formed and began a continuous invasion of the aquifer the position of the saltwater wedge was recorded every 10 min by a digital camera canon ixus 285 hs as soon as the saltwater wedge reached the subsurface dam it stopped advancing and rose against the subsurface dam if the saltwater wedge could be captured at the position of the subsurface dam the dam was effective to prevent swi if the saltwater extended downward behind the dam after flowing over the top of the subsurface dam the subsurface dam failed to prevent swi when the saltwater reached the impervious base behind the dam a new saltwater wedge formed and continued to invade the aquifer we considered the setup equilibrated when swi was not advancing more than 1 mm per 10 min 2 4 numerical setup seawat was used to simulate swi and to calculate the fresh groundwater discharge to the sea guo and langevin 2002 langevin 2003 during the setup of the numerical model we followed the laboratory settings and parameters as close as possible the numerical simulation area was a homogeneous unconfined two dimensional vertical cross section with the size of 90 27 cm2 a no flow boundary condition was defined on the upper part and lower part of the numerical model the left side freshwater boundary was set as a variable constant head boundary 26 5 to 27 1 cm the concentration was set to cf 0 g l the right side saltwater boundary was set to a constant head of 26 cm and the concentration was set to cs 36 g l the simulation area was discretized by a uniform grid with quadratic elements with an edge length of 0 5 cm the grid spacing and dispersivity satisfied the péclet number criterion to ensure numerical stability voss et al 1987 1 p e v δ l d l v δ l l 3 8 4 where δl is the grid spacing d is molecular diffusion the time step was set to 60 s the aquifer medium hydraulic conductivity k was set to 5 8e 3 m s as the used plasticine is practically impermeable the hydraulic conductivity of the subsurface dam was set to 1e 9 m s and the width of the subsurface dam was 1 cm a stress period was set for both the baseline case and the subsurface dam case lasting for 6 h which was adequate for the saltwater wedge to reach a state of dynamic equilibrium 3 results and discussion 3 1 baseline case in the baseline case we firstly studied the influence of the variation of the head difference fig 4 a b and c shows the results for head differences of 8 9 and 10 mm which resulted in intrusion lengths of the saltwater wedge of 56 4 44 7 and 37 1 cm respectively fig 4 d shows the comparison of the 50 isoline under the different head conditions 50 isoline is wildly used for saltwater wedge in the aquifer with low dispersivity goswami and clement 2007 luyun et al 2009 stoeckl et al 2016 the comparison between the experimental data and the numerical simulation results of the length of the saltwater wedge is shown in fig 5 the numerical simulation results and the experimental data have a good degree of fit under the different head conditions for the head differences of 8 9 and 10 mm swi reaches dynamic equilibrium at 300 230 and 180 min respectively the water flowing out of the right boundary of the flow tank is the brackish water mixed with the fresh groundwater and saltwater therefore the study on the fresh groundwater discharge should be based on the water balance of the fresh groundwater flowing into and flowing out of the flow tank seawat was used to calculate the fresh groundwater rate flowing into the flow tank which is equal to the discharge of the fresh groundwater fig 6 plots the variation of fresh groundwater discharge versus head difference when swi reaches dynamic equilibrium it can be seen that the fresh groundwater discharge increased gradually with increase of the head difference this is because the velocity of the fresh groundwater flowing into the flow tank increases with increase of the head difference according to darcy s law the increased fresh groundwater flow velocity results in an increase of the fresh groundwater discharge 3 2 dam height the head difference of freshwater boundary and saltwater boundary was kept at 9 mm the location of the subsurface dam was set at a distance of 20 cm from the saltwater boundary the subsurface dam heights were set at 6 cm 7 cm and 8 cm respectively fig 7 shows the results for the variations of the dam height with the laboratory experiments in the case of no subsurface dam the length of the saltwater wedge was 44 7 cm fig 3 b when the dam height was 6 cm the saltwater wedge flowed over the top of the subsurface dam and advanced to a distance of 43 3 cm in this case the subsurface dam lost its function of preventing swi when the dam height was increased to 7 cm the saltwater wedge was intercepted at the position of the subsurface dam and the thickness of the saltwater wedge at the dam was approximately equal to the height of the subsurface dam when the dam height was increased to 8 cm the saltwater wedge was also effectively intercepted and the thickness of the saltwater wedge toe was lower than the height of the subsurface dam the numerical simulation results and the laboratory tests have a good degree of fit in figs 7 and 8 which shows the numerical simulations are reliable for the dam heights of 6 7 and 8 cm the saltwater wedge reaches dynamic equilibrium at 463 54 and 64 min respectively comparing with the swi dynamic equilibrium time of 230 min without the dam the equilibrium time decreases three quarters when the subsurface dam is effective even if the subsurface dam is too low to prevent swi it can still slow down the speed of swi in the following we use the dimensionless ratio of the dam height hdam and the aquifer thickness haqu haqu 26 cm fig 9 shows the influence of the dam height on the swi length until the ratio hdam haqu reaches 0 27 i e hdam 7 cm the swi length decreases only slightly and is similar to the baseline case indicating that the dam loses the function of preventing swi when hdam haqu is larger than 0 27 the swi length decreases sharply to 20 cm and the saltwater wedge is intercepted by the dam thus hdam haqu 0 27 is the minimum effective dam height to prevent swi in the case of a head difference of 9 mm fig 10 shows the fresh groundwater discharge for different dam heights with increase of the dam height the fresh groundwater discharge increases slightly and then decreases sharply the fresh groundwater discharge reaches the maximum value at hdam haqu 0 27 from fig 9 we know that hdam haqu 0 27 is the minimum effective dam height to prevent swi in this case it is worth noting that the fresh groundwater discharge at the minimum effective dam height is larger than that of the baseline case without subsurface dam the flow velocity in the saltwater wedge is far smaller than that of fresh groundwater abdoulhalik and ahmed 2017a therefore the stagnant saltwater wedge decreases the discharge section area just like the subsurface dam does as we can see in fig 7d the thickness of the saltwater wedge in the baseline case without subsurface dam is higher than the minimum effective dam height at the dam location this means that the fresh groundwater discharge section area in the baseline case is smaller than that of the minimum effective dam case at the same height as sea level the fresh groundwater discharge of the subsurface dam decreases to 37 2 of the maximum value this is because the fresh groundwater discharge section area is too small 3 3 dam location under the condition that the head difference was 9 mm and the dam height was set at 7 cm i e the minimum height at which the dam was effective the distance from the saltwater boundary was changed to 15 cm and 25 cm according to the laboratory results when the distance from saltwater boundary was 15 cm the saltwater wedge crossed the top of the subsurface dam and advanced to a length of 42 8 cm fig 11 a when the distance was increased to 25 cm the subsurface dam could still prevent swi fig 11b fig 12 shows the influence of the dam location on the saltwater wedge length the dam location is expressed by the ratio of the distance from saltwater boundary ldam to the thickness of the aquifer haqu when ldam haqu is less than 0 77 ldam 20 cm the saltwater wedge length decreases slightly with increase of ldam haqu when ldam haqu is equal to 0 77 the saltwater wedge length sharply decreases to 20 cm indicating that the saltwater wedge is intercepted by the subsurface dam when ldam haqu is greater than 0 77 the saltwater wedge is still intercepted at the dam position the saltwater wedge length increases with the dam distance from the saltwater boundary therefore the minimum effective dam height is related to the distance from the saltwater boundary therefore hdam haqu 0 27 hdam 7 cm is the minimum effective dam height just at the dam position of ldam haqu 0 77 ldam 20 cm fig 13 shows the fresh groundwater discharge in cases with different dam distance when ldam haqu is less than 0 77 the fresh groundwater discharge increases slightly with increase of the dam distance when ldam haqu 0 77 ldam 20 cm the discharge reaches its peak when ldam haqu is greater than 0 77 the fresh groundwater discharge gradually decreases with increase of the dam distance as we know from the previous analysis hdam haqu 0 27 hdam 7 cm is the minimum effective dam height only at the dam position of ldam haqu 0 77 therefore when hdam haqu 0 27 hd 7 cm the discharge reaches the peak at the dam position of ldam haqu 0 77 ldam 20 cm 3 4 head difference the hydraulic gradient is expressed by the head difference between the fresh groundwater boundary and the saltwater boundary the dam height was set at 7 cm and the distance from the saltwater boundary was set at 20 cm the head differences were changed to 8 mm and 10 mm respectively when the head difference was 8 mm the saltwater wedge flowed over the top of the subsurface dam and advanced to a length of 53 cm the subsurface dam could not prevent swi fig 14 a when the head difference was increased to 10 mm the dam height was greater than the thickness of the saltwater wedge toe and the saltwater wedge stopped at the dam location fig 14b sensitivity analysis was used to investigate the influence of the head difference on the length of the saltwater wedge fig 15 when the head difference is less than 9 mm the length of the saltwater wedge gradually decreases with the head difference when the head difference is equal to 9 mm the saltwater wedge sharply decreases to the same distance that the dam is from the shoreline when the head difference is greater than 9 mm swi is still intercepted at the dam position fig 16 shows the fresh groundwater discharge in the cases with different head differences the fresh groundwater discharge gradually increases with the head difference as we know the fresh groundwater flow velocity gradually increases with the head difference according to darcy s law therefore the increase of fresh groundwater flow velocity leads to gradual increase of the fresh groundwater discharge 3 5 discharge at the minimum effective dam height according to the above analysis the fresh groundwater discharge is related to the dam height location and head difference fig 17 shows the effect of the dam height and location on the fresh groundwater discharge under the head difference of 9 mm as can be seen from fig 17 the boundary between the effective region red region and the failed region blue region is the minimum effective dam height needed to prevent swi the discharge reaches its peak value at the minimum effective dam height hmin at a defined dam position when the dam distance from the saltwater boundary is zero the peak discharge is the largest as the dam distance from the saltwater boundary increases the peak discharge becomes smaller and smaller the fresh groundwater discharge reaches its peak at the minimum effective dam height which is beneficial to control the accumulation of land based pollutants and salt it is of great significance to investigate the minimum effective height of the subsurface dams at different positions and with different head differences fig 18 shows the minimum effective dam height and corresponding fresh groundwater discharge at the different dam distances and head differences it can be seen that with the same head difference and with increase of the dam distance away from the shoreline the minimum effective dam height and fresh groundwater discharge decrease gradually this is consistent with fig 17 with increase of the head difference the minimum effective dam height decreases and the fresh groundwater discharge increases at the same dam location this indicates that a large head differences is conducive to saving engineering costs and reducing the accumulation of land based pollutants and salt 4 summary and conclusions in this study we proposed the use of dams of minimum effective height to prevent saltwater intrusion and used the fresh groundwater discharge to assess the environmental performance of the subsurface dam laboratory tests and numerical simulations were used to investigate the effects of the dam height the dam location and the head difference on the saltwater intrusion prevention ability of the subsurface dam and on the fresh groundwater discharge for the baseline case without subsurface dam with increase of the head difference the time for swi to reach dynamic equilibrium as well as the length of the saltwater wedge shorten and the fresh groundwater discharge increases a minimum effective dam height at a defined distance from the shoreline that will prevent saltwater intrusion could be identified until a minimum effective dam height increasing dam height has no significant effect on decreasing of the saltwater wedge length when the dam height is equal to or higher than the minimum effective dam height the saltwater wedge can be intercepted at the subsurface dam position the fresh groundwater discharge reaches its peak at the minimum effective dam height a larger freshwater recharge will push back more saltwater therefore the minimum effective dam height is shorter than the height of swi without the dam the minimum effective dam height strongly depends on the distance to the shoreline as the dam distance from saltwater boundary increases the minimum effective height and the peak fresh groundwater discharge decreases simultaneously with increase of the head difference the minimum effective height decreases and the fresh groundwater discharge increases at the same dam location therefore a steep head difference is beneficial to reducing engineering costs and reducing the accumulation of land based pollutants and salt the reduction of the minimum effective dam height is conducive for saving engineering cost additionally avoiding the reduction of the fresh groundwater discharge as it is the case for a dam which is constructed over the whole aquifer thickness decreases the accumulation of land based pollutants and salt therefore the site selection of the subsurface dams should consider both the engineering cost and ecological environmental effects tidal effects on the minimum effective dam height by changing the head difference luyun et al 2009 designers should carefully consider the minimum effective dam height on the lowest head difference the head difference between the lowest underground water level and maximum tidal heights in local history an adequate safety margin should be reserved based on the minimum effective height as this study firstly focussed on laboratory scale setups further studies will have to investigate field scale implications to delineate minimum effective dam heights acknowledgements this work was supported by the national key research and development program of china no 2016yfc0402810 and the national natural science foundation of china shandong joint fund no u1806210 for funding this project declaration of competing interest none 
6308,the simulation and optimization of low impact development lid practices has been a key research topic in stormwater management in this study a fast and robust framework was proposed for providing the optimal design of lid practices by coupling a physically based model the markov chain with the multi objective shuffled frog leaping algorithm mosfla the proposed framework was then tested for chemical oxygen demand cod reduction in a typical urban catchment in china the storm water management model swmm was used to provide the flow cod data during the baseline scenario and the markov chain method was then incorporated as a subset of the physically based model based on the results the computational efficiency was improved by 500 times when the new framework was used and the robustness of the optimal results increased over 50 compared to commonly used algorithms the relative error between the swmm and the markov chain method was less than 5 indicating that a satisfactory performance could be obtained using the proposed framework this new method provides a useful tool for optimizing lid practices and green infrastructure especially for complex urban catchments keywords low impact development lid storm water management model swmm multi objective shuffled frog leaping algorithm mosfla markov chain 1 introduction the extent of urban areas has been increasing globally which has resulted in dramatic environmental change such as increased temperatures altered hydrology and elevated water pollution newcomer et al 2014 yang et al 2016 hamed et al 2018 specifically urbanization seals native soils with impervious roofs roads and pavement resulting in an altered hydrological cycle londo et al 2013 and serious nonpoint source nps pollution chen et al 2018 dai et al 2019 hou et al 2018 the mitigation of stormwater impacts on flow and water quality requires a range of low impact development lid practices dietz 2007 such as rainfall gardens ponds infiltration systems vegetated roofs and other control measures currently lids have been suggested to be an efficient measure for restoring flow regimes zhu and chen 2017 and mitigating nps pollution hong et al 2018 as well as for green infrastructure or sponge city construction li et al 2019 urban lids vary greatly in their efficiency cost and design parameters therefore the most important question is how to reach the optimal design of lid practices at the catchment scale booth et al 2002 alfredo et al 2010 the philosophy behind this question is to replicate the natural hydrological process by using a comprehensive analysis of the type number location and combination of many lids particularly at a large scale two tools can be utilized for the implementation of lid design one powerful tool is the physically based urban hydrological model such as the storm water management model swmm the hydrological simulation program fortan hspf model the source loading and management model slamm and the storm water drainage system design and analysis program drains these models can simulate the entire rainfall runoff and nps processes from land surfaces through a channel or pipe network and can quantify their impacts on the receiving water bodies as one of the most commonly used models the swmm has incorporated the lid module for quantifying the detailed hydrological and hydraulic response to the lid design haris et al 2016 qin et al 2013 furthermore evolutionary algorithms have also been used for the optimal design of lid in recent years due to the large number complex configuration and distributed location of lids especially for complex catchments for this purpose famous algorithms such as the non dominated sorting genetic algorithm ii nsga ii deb et al 2002 the annealing based multi objective optimization algorithm bandyopadhyay et al 2008 and the multi objective particle swarm optimization abido 2009 have been commonly used to date the nsga ii represents one of the most commonly used algorithms for the optimal design of lid practices due to its iterative and parallel subpopulation features based on the above development coupling a multi objective optimization algorithm with an urban model has been explored more recently for the optimal design of lids to date a few decision support systems dsss have been developed for example the best management practice decision support system bmpdss has been developed for stormwater management at both the plot scale and the catchment scale cheng et al 2009 this tool is based on the integration of the swmm and an evolutionary algorithm for a detailed understanding of lids jia et al 2012 the benefit cost b c analysis has also been considered for the mitigation of megacity floods huang et al 2018 however it should be noted that although the advances in urban models have benefited stakeholders with the possibility for comparing the efficiency of different lids these comprehensive models are often physically based and have many distributed parameters thus the execution of models such as the swmm is computationally expensive and technically complex if not impossible especially for urban catchments during the optimization process chen et al 2015 if an effective simulator can be proposed which decreases the computational complexity while maintaining the full use of the watershed model s strengths a satisfactory performance could be obtained at large scale simulation to solve this problem the markov chain has been used as a substitute for traditional models for improving the computational efficiency of lid practices grimvall and stalnacke 1996 however there are also several problems in these commonly used algorithms such as poor robustness or low computational efficiency instead the multi objective shuffled frog leaping algorithm mosfla as a state of the art method in multiple objective optimization has been developed mosfla is a novel multi objective optimization algorithm which is easy and convenient to code with less control parameters and it has been testified compatible with handling comprehensive optimization problems including the non linear and high dimensional discrete systems it is mostly used in reservoir operation and water resources system optimization in the field of hydrology and environment however as far as we know few scientists have used the advanced mosfla for optimizing lid practices especially from the perspective of nps reduction the objectives of this study were as follows 1 to develop a simulation optimization framework to generate cost benefit information for the optimal design of lid practices 2 to improve the computation efficiency by introducing the markov simulator and 3 to solve the robustness problem by incorporating the mosfla the new framework was then tested in a typical urban catchment in china and the reliability of results was validated by comparing them to the most commonly used swmm and nsga ii 2 methodology 2 1 study area description and data collection in this study the beijing normal university located in the haidian district of beijing china was selected as the study area fig 1 the mean annual precipitation and temperature are 570 mm and 14 0 c respectively the study area has a total drainage area of 58 ha and five outfalls were found based on drainage pipe network information the detailed land use data sewer network map and digital elevation model were obtained from a local administrative agency while buildings and green areas were identified as the two major land uses types 30 29 for buildings and 25 22 of green areas an automatic weather station hobo onset computer corporation bourne ma usa was installed for collecting meteorological data several rainfall events were monitored for the construction of this new simulation optimization framework specifically a monitoring device fl900 hach us was used for recording flow data at outfall3 which occupies 73 19 of the total drainage area water samples were also collected for the analysis of nps pollutants based on our previous study the chemical oxygen demand cod was identified as one of the major pollutants from this catchment therefore cod was selected as the target pollutant for lid practices these measured flow and cod data were then used for calibrating the swmm model 2 2 the general framework for the proposed framework in this study an integrated framework was proposed for the simulation and optimization of urban lid practices this framework in terms of the markov mosfla lid m m lid method was based on the integration of the swmm the markov chain method and the mosfla algorithm fig 2 illustrates the detailed process of the m m lid method for the optimal design of lid practices in terms of the type number location and configuration of lids at the urban catchment scale the following four procedures were considered 1 the simulation of the urban hydrology and nps processes during the baseline scenario was performed by using a physically based urban model then the benefits or efficiency of the typical lid practices during the lids scenario were quantified by considering the popularity and data availability the swmm was chosen for this study 2 the establishment of a substitute simulator for the previous urban model was achieved from the perspective of computational efficiency in this study the markov chain method was used as a substitute for the swmm during the following optimization process 3 the markov chain method and the cost function were then integrated with the advanced mosfla in order to provide the cost benefit curves for each design of lid practices the efficiency and the related cost of each lid scheme were used as the targeted objectives 4 finally the type number location and configuration of the selected optimal lid design was further optimized and translated using gis software in this study the optimal results of lid design were then validated by running the swmm within the lid scenario 2 3 the simulator from the swmm to the markov chain in this study the swmm was used for providing detailed information of runoff and nps processes during the baseline scenario and the markov chain method was then used as the substitute simulator for the following optimal design of lids 2 3 1 the setup of swmm the pcswmm developed by computational hydraulics international chi was used in this study the infiltration loss on the previous area was estimated by the horton equation and dynamic wave routing which models pressurized flow and entrance exit energy losses of the pipe network was selected for the routing process in this study the cod load was generally stated as follows 1 l 0 t c t q t d t where l is the pollution load for rainfall event g c t is the instantaneous cod concentration at time t mg l q t is the runoff at time t m3 s and t represents the rainfall duration s for the swmm lid practices are divided into several vertical layers surface soil and storage and different design parameters should be defined for each layer for the surface layer the water balance follows the equation 2 d 1 t q 0 e 1 f 1 q 1 where q 0 is the inflow and q 1 is the outflow e 1 is evaporation flux and f 1 is the permeation flux in the surface layer for the soil layer 3 d 2 θ t f 1 e 2 f p where d 2 is the soil layer thickness e 2 is evaporation flux and f p is permeation flux in the soil layer for the storage layer 4 ϕ d 3 t f p e 3 f 3 q 3 where ϕ is porosity e 3 is evaporation flux f 3 is permeation flux and q 3 is the outflow in the storage layer the measured flow and cod data were used to calibrate and validate the swmm using an iterative process of trial and error and two good of fit indicators the nse and the correlation index r2 were used to evaluate the model performance for more detailed information about model construction and calibration please refer to our previous study hou et al 2019 for the hydrological model the range of nse was from 0 507 to 0 669 and the r2 ranged from 0 514 to 0 763 the cod model also performed well producing an nse of 0 669 and an r2 of 0 765 these results indicate that the calibrated swmm could provide reliable flow and nps cod simulations furthermore based on our local investigations two lid practices in terms of permeable pavement and green roofs were considered for the following optimization the detailed flow and cod data at outfall3 during the baseline and lid scenario were obtained by running the swmm 2 3 2 the markov chain method to alleviate the computational burden the markov chain method was used as a substitute for the swmm the markov chain represents a stochastic model describing a sequence of possible events in which the probability of each current event depends only on the state of its previous event in this study this algorithm was used for describing the upstream downstream hydrological relationship of each pipe as well as the transportation processes of the nps pollutants within the pipe network during the rainfall process flow and nps pollutants were attenuated after passing through the lid facilities and the pipe network one assumption is that the direction of sewage flow in the pipe network is similar to that within the natural catchment and could therefore be expressed by the upstream downstream relationship of the markov matrix chen et al 2014 the second assumption is that the transportation of nps pollutants in the current process in each pipe section is only related to its former state liu and weller 2008 miller et al 2013 the details of this markov method are described below step 1 construct the hydrology relation matrix of the pipe network one unique fact about urban hydrology is that an artificial subsurface routing system significantly affects runoff and nps pollution processes and runoff routing from land surfaces to the pipe network is usually achieved via downspouts instead of elevation gradients based on geographic theory the urban catchment can be broken down into several subwatersheds and a distinct pipe network with many downspouts unlike a nature catchment that could be extracted from a dem such geographic information of the urban catchment should only be described by the surface elevation data the downspout location and the pipe network map therefore the upstream and downstream relation matrix of urban hydrology can be constructed according to this information the number of subwatersheds and junction nodes downspout is defined as n and the relation matrix can be simplified as a matrix h n n to represent the pipe network 5 h i j 1 j i s t h e n e a r e s t s i t e d o w n s t r e a m f r o m i 0 otherwise step 2 quantifying the attenuation of pollutants within the pipe network the generation transformation and attenuation of nps pollutants in urban catchments represents a very complicated process in this study the swmm was used to describe the detailed transformation and attenuation processes within the pipe network the flow and pollutant input data from each subwatershed as well as the data series for each pipe section were first calculated using the swmm then data from the baseline scenario were described by using a flow pollutant input matrix and the retention coefficient matrix of the pipe within this step a n 1 matrix e e 1 e 2 e n t was developed to represent the flow or pollutant input matrix during each lid scenario from each subwatershed s 1 s 2 s n where e i represents the simulated flow or nps pollutant input from the ith subwatershed the complex processes of the pipe network were then simplified into the retention coefficient for representing the removal capacity of the network the retention coefficient was calculated as an index of transport efficiency which can be expressed as follows 6 r loa d in l o a d out loa d in where the ith input of the load is load i in s u b i l o a d i 1 out the ith input of the load is equal to the sum of the upstream pipe load and the total load generated in the subwatershed finally the retention coefficient matrix r is expressed as follows 7 r r 1 0 0 0 r 2 0 0 0 r n step 3 calculation of the efficiency of lid practices considering the retention in the pipe network we define the transfer matrix of nps pollutants as h h i r where i is unit matrix the assessment point for the evaluation of lid efficiency in terms of cod reduction in this study was set at outfall3 which is within the drainage pipe network a n 1 matrix k k 1 k 2 k n t was then developed to represent the lid efficiency for each subwatershed grimvall and stalnacke 2015 8 h k i j h k i j if i k 1 if i j k 0 if i k a n d j k 9 v k i 1 if i k 0 otherwise then the following equation was used to calculate the contribution of lid practices constructed at each subwatershed to the final cod reduction at the assessment point 10 l h k n v k e finally the efficiency of lid configuration was obtained for each lid scenario 2 4 the shuffled frog leaping algorithm based optimization method in this study the mosfla which is based on the shuffled frog leaping algorithm sfla was applied for solving multi objective optimization problems 2 4 1 the description of the shuffled frog leaping algorithm the sfla was developed as a heuristic algorithm by integrating the characteristics of the particle swarm optimization pso algorithm and the meme algorithm ma this algorithm consists of a set of interacting populations of virtual scenarios that are partitioned into different groups eusuff and lansey 2003 eusuff et al 2006 within each scenario set the individual solution can be influenced by other individuals and each individual can evolve through a process of memetic evolution in memetic evolution the poor individuals should be weeded out through the fitness function after some iterations of memetic evolution information is integrated among memplexes formed through a shuffling process the local search and the shuffling processes continue until defined convergence criteria are satisfied in this sense both global and local search strategies are considered for the sfla the most distinguishing difference between the mosfla and the original sfla is the change of fitness function both the dominance and distribution of solutions are considered for the mosfla li et al 2010 to judge the merits of solutions instead of only the fitness values as used in the original sfla 2 4 1 1 sorting strategy first all scenarios were stratified according to the dominated relation by fast nondominated sorting which is derived from nsga ii deb et al 2002 second crowding distances were calculated for each front as 11 p i dis tan c e k 1 r p i 1 f k p i 1 f k where p i dis tan c e indicates the crowding distance of ith nondominant solution and p i 1 f k and p i 1 f k indicate the kth objective function values of two adjacent solutions finally all scenarios of each generation were ranked in ascending order and the scenarios of each front were sorted in descending order based on crowding distance 2 4 1 2 memetic evolution within each local memplex improvements have been made for the memetic evolution process to enhance the search efficiency in the solution space in this study memetic evolution was mainly achieved by the evolution of nondominant solutions the main evolutionary mechanisms include the following 1 the original evolution was computed based on a local optimal solution 12 d r a n d xb x w where xb is the local optimal solution and xw is the local worst solution 2 the original evolution was computed based on a global optimal solution 13 d r a n d xg x w where xg is the global optimal solution 3 the mutation mechanism based on a genetic algorithm is shown as 14 a 1 a 2 a 3 a 4 a 5 a 1 a 2 a 3 a 1 a 2 a 1 a 2 a 3 a 4 a 5 a 4 a 5 a 3 a 4 a 5 4 the random solutions were generated near the global optimal solution as shown by 15 new x w 0 95 x g 0 05 r a n d x x where x and x are the neighbors of xg 2 4 2 the mosfla based optimization of lid practices in this study the multi objective design of lid practices was established by considering the reduction of the nps pollution and the related cost objective function minimize the cost of lid practices 16 min cos t min min cos t x based on our investigation the corresponding cost of permeable pavement and green roofs was set as 200 yuan m2 and 310 yuan m2 maximize the retention efficiency of cod 17 max r e max max r e x constraints several constraints were set for the construction of lid practices at the catchment scale based on local law the permeable pavement and green roofs were set as 50 100 and 80 100 of the lid installable area for each subwatershed algorithm adaptation the type location and installation area of lid practices for each subwatershed were treated as the decision variables and the combination of lid configuration at the catchment scale was represented by decision vectors whose length was determined by the number of subwatersheds 515 for the study area in this study twenty solutions were set as a memeplex each memeplex will be memetically evolved twice internally and then shuffled into a population while ten memeplexes were set as a population to improve the evolution efficiency all dominated solutions were evolved at the same time after the above steps the optimal design pareto front of the lid practices was achieved then gis was used to realize the visualization of optimization strategy and swmm was used to validate the feasibility of the selected optimal lid scenario 3 results and discussions 3 1 the results of the new framework in this study the new framework was evolved for 50 100 and 200 generations in the study area to test its efficiency and robustness fig 3 shows the result of cod removal and the related cost of each lid configuration the cost benefit curves are shown in fig 3a once the pareto optimal front was generated it was indicated that the optimal design of the lid practices could reduce nps cod by 0 33 80 kg and could reduce cost by 0 2 04 million yuan by observing the front curve we found that cod removal would first increase with increasing expenditure however after the turning point when cod removal was 32 kg the cod reduction tended to be gentle even if the cost increased there was no obvious improvement of cod removal in previous studies it was believed that more lid practices would result in a greater nps reduction however fig 3a indicates that the efficiency of lids remains stable inside a relevant domain of cost and that any cost outside this domain would not result in a better lid efficiency the evolutionary processes are also shown in fig 3 as illustrated in fig 3a the front curve was far from the pareto front and the solutions did not show significant change in the first 10 generations due to the limitation of the algorithm s searching ability as the algorithm processed from 10 to 20 generations the front curve quickly approached the pareto front however nondominance was not exhibited by the solutions of the front curve during the following evolutionary processes to 50 generations the shape of the pareto trade off front obtained by the proposed method shifted from relatively scattered points to a smooth curve and the solutions were close to the pareto front the maximum cod removal was found and the optimal cod reduction was 22 32 kg this result indicated that local optimal solutions were found but the global optimal solutions had not been reached as this algorithm did not converge at that time structural lids were observed on the higher edge of the front curve which is where expensive solutions were located as the generation gradually reached 100 the front curve became basically stable with only a few points located outside the pareto curve finally when the generation reached 200 the optimal front was found and this current curve was completely stable with good distribution and convergence the final pareto optimality front indicated the optimal design of lid practices had reduced the nps cod from 862 42 kg to 828 61 kg in outfall3 from the study area the removal of cod caused a reduction of 33 80 kg and the corresponding cost was 2 04 106 fig 3b further shows the spatial distribution of lid practices for the study area thirteen permeable pavements and two green roofs were finally set around several taller buildings which were found to be hotspots of nps cod for the study area these results indicated that effective nps reduction could first be achieved through the optimal design of permeable pavement and green roofs to reach further reductions a combination of other lids is suggested for the entire catchment 3 2 the comparison between the m m lid and swmm methods in this study the optimal results of the new algorithm were compared with those obtained by the commonly used physically based model once the pareto optimal front was generated the pareto optimal lid design was imported into the swmm and the swmm model was used again to obtain the real efficiency of the optimal lid practices in this sense the markov chain and the swmm were compared to describe the main features of the new algorithm in a better way first the performances of the new and traditional algorithms were compared by using the computational burden utilized in the optimization run compared with swmm method the biggest advantage of the m m lid method was the improvement of computational efficiency by evaluating a total of 200 generations the entire process of the swmm required approximately 72 h of computational time on a computer with 2 10 ghz e5 2620 cpu and 64 g ram conversely the markov based optimization was terminated in fewer than 10 min which was a drastic improvement of approximately 500 times that of the original process in practice by reducing the complexity of the simulation the new algorithm ran much more quickly 500 times faster for the case study than the swmm based method at present the large computation time has become the bottleneck of the lid optimization especially for large catchments moreover as a mathematics based method the markov based method could be applicable to all kinds of current urban models and has provided a new idea for the optimal design of lids for large urban catchments however the markov based method uses a simple index to describe the complex migration and transformation process of nps pollutants within the pipe network thus the goodness of fit of the new and traditional algorithms were evaluated by comparing the simulated nps cod data during specific lid configuration the results obtained by the markov and the swmm are shown in fig 3 only two solutions with the highest cost scenario and least cost scenario are shown because the largest error was observed for these two solutions it is shown that the nps cod was estimated as 828 61 kg by the m m lid and 814 17 kg by the swmm the relative error between these two methods was 1 77 indicating there was no significant difference between the results of the m m lid method and the swmm model for the least cost scenario the simulated nps cod was 862 42 kg and 846 40 kg when by using the m m lid method and the swmm method respectively the relative error between the two calculation methods was 4 89 therefore it could be considered that the m m lid method is a good substitute for the physically based models 3 3 the comparison between mosfla and nsga ii the optimal design of lid practices by the new algorithm and the nsga ii were further compared by using matlab r2018b the results during the evolutionary processes are shown in fig 4 it is obvious that the solutions of the nsga ii and the mosfla were both far from the final pareto curve but were located within 50 generations the computational time was 203 34 s for the of nsga ii in comparison the computational time of the mosfla was 167 52 s which was 82 38 faster than the nsga ii furthermore the optimal solutions of the nsga ii did not show a good distribution as most solutions were gathered in high cost regions the range of cod removal was from 0 to 33 80 kg using the mosfla and from 31 69 to 33 80 kg using the nsga ii this difference could be due to the local and global search abilities as well as the high robustness of the mosfla as the evolution was processed to 100 generations the nsga ii and the mosfla took 337 21 s and 256 22 s respectively the convergence and distribution of the mosfla were significantly improved compared with that of 50 generations and the ranges of cost and cod had reached the optimal level in comparison the range of cod removal was improved a range from 12 83 to 33 80 kg was obtained using nsga ii when the optimization continued to 200 generations the mosfla and the nsga ii both showed good convergence and distribution and the computational time was 734 78 s for the nsga ii and 412 05 s for the mosfla zheng et al 2014 on one hand the computation time for the mosfla was faster than that of the nsga ii by 82 38 31 61 and 78 32 for the 50 100 and 200 generations evaluated for the study area on the other hand the mosfla also showed better convergence and distribution than the nsga ii as shown in fig 4 the optimal design of the lid practices using the mosfla were more dominant than using the nsga ii especially for low cost solutions this result could be due to the crossover operator of the nsga de vos and rientjes 2008 rodriguez et al 2011 the computational efficiency advantage of mosfla was more applicable to the m m lid method especially for complex urban catchments the advantage of robustness guaranteed the distribution of solutions and the diversity of lid practices yang et al 2019 4 conclusion the increasing urbanization has resulted in dramatic environmental change causing a big impact on stromwater quality management and lid practices were required for the mitigation of stormwater impacts in this study a fast and robust multi objective framework was proposed for the simulation and optimization of lid practices at the catchment scale the markov chain method and the mosfla were integrated and the framework was validated for a typical urban catchment in china the new m m lid method generated desirable scenarios more quickly based on markov chain and the solutions are robust in different generations rather than nsga ⅱ method this method can provide a series of optimal scenarios and the cost benefit curves as well as insights on optimal lid combinations sizing and placement indicated that a cost of 0 2 04 million would provide reductions of 0 33 80 kg for cod in the urban watershed the results indicated the following 1 the relative error between the swmm and the markov chain method was less than 5 indicating that a satisfactory performance could be obtained using the proposed framework 2 the computational efficiency was improved by 500 times when the new framework was used for the case study 3 the robustness of the optimal results increased over 50 compared to commonly used algorithms this new method provides a useful tool for optimizing lid practices and green infrastructure especially for complex urban catchments declaration of competing interest the authors declare that there are no conflicts of interest regarding this manuscript acknowledgements this research was funded by the state key program of national natural science of china no 417 41530635 the national natural science foundation of china nos 51779010 and 51579011 and the interdiscipline research funds of beijing normal university data used in this study are available from the publications and local administrative agency cited therein 
6308,the simulation and optimization of low impact development lid practices has been a key research topic in stormwater management in this study a fast and robust framework was proposed for providing the optimal design of lid practices by coupling a physically based model the markov chain with the multi objective shuffled frog leaping algorithm mosfla the proposed framework was then tested for chemical oxygen demand cod reduction in a typical urban catchment in china the storm water management model swmm was used to provide the flow cod data during the baseline scenario and the markov chain method was then incorporated as a subset of the physically based model based on the results the computational efficiency was improved by 500 times when the new framework was used and the robustness of the optimal results increased over 50 compared to commonly used algorithms the relative error between the swmm and the markov chain method was less than 5 indicating that a satisfactory performance could be obtained using the proposed framework this new method provides a useful tool for optimizing lid practices and green infrastructure especially for complex urban catchments keywords low impact development lid storm water management model swmm multi objective shuffled frog leaping algorithm mosfla markov chain 1 introduction the extent of urban areas has been increasing globally which has resulted in dramatic environmental change such as increased temperatures altered hydrology and elevated water pollution newcomer et al 2014 yang et al 2016 hamed et al 2018 specifically urbanization seals native soils with impervious roofs roads and pavement resulting in an altered hydrological cycle londo et al 2013 and serious nonpoint source nps pollution chen et al 2018 dai et al 2019 hou et al 2018 the mitigation of stormwater impacts on flow and water quality requires a range of low impact development lid practices dietz 2007 such as rainfall gardens ponds infiltration systems vegetated roofs and other control measures currently lids have been suggested to be an efficient measure for restoring flow regimes zhu and chen 2017 and mitigating nps pollution hong et al 2018 as well as for green infrastructure or sponge city construction li et al 2019 urban lids vary greatly in their efficiency cost and design parameters therefore the most important question is how to reach the optimal design of lid practices at the catchment scale booth et al 2002 alfredo et al 2010 the philosophy behind this question is to replicate the natural hydrological process by using a comprehensive analysis of the type number location and combination of many lids particularly at a large scale two tools can be utilized for the implementation of lid design one powerful tool is the physically based urban hydrological model such as the storm water management model swmm the hydrological simulation program fortan hspf model the source loading and management model slamm and the storm water drainage system design and analysis program drains these models can simulate the entire rainfall runoff and nps processes from land surfaces through a channel or pipe network and can quantify their impacts on the receiving water bodies as one of the most commonly used models the swmm has incorporated the lid module for quantifying the detailed hydrological and hydraulic response to the lid design haris et al 2016 qin et al 2013 furthermore evolutionary algorithms have also been used for the optimal design of lid in recent years due to the large number complex configuration and distributed location of lids especially for complex catchments for this purpose famous algorithms such as the non dominated sorting genetic algorithm ii nsga ii deb et al 2002 the annealing based multi objective optimization algorithm bandyopadhyay et al 2008 and the multi objective particle swarm optimization abido 2009 have been commonly used to date the nsga ii represents one of the most commonly used algorithms for the optimal design of lid practices due to its iterative and parallel subpopulation features based on the above development coupling a multi objective optimization algorithm with an urban model has been explored more recently for the optimal design of lids to date a few decision support systems dsss have been developed for example the best management practice decision support system bmpdss has been developed for stormwater management at both the plot scale and the catchment scale cheng et al 2009 this tool is based on the integration of the swmm and an evolutionary algorithm for a detailed understanding of lids jia et al 2012 the benefit cost b c analysis has also been considered for the mitigation of megacity floods huang et al 2018 however it should be noted that although the advances in urban models have benefited stakeholders with the possibility for comparing the efficiency of different lids these comprehensive models are often physically based and have many distributed parameters thus the execution of models such as the swmm is computationally expensive and technically complex if not impossible especially for urban catchments during the optimization process chen et al 2015 if an effective simulator can be proposed which decreases the computational complexity while maintaining the full use of the watershed model s strengths a satisfactory performance could be obtained at large scale simulation to solve this problem the markov chain has been used as a substitute for traditional models for improving the computational efficiency of lid practices grimvall and stalnacke 1996 however there are also several problems in these commonly used algorithms such as poor robustness or low computational efficiency instead the multi objective shuffled frog leaping algorithm mosfla as a state of the art method in multiple objective optimization has been developed mosfla is a novel multi objective optimization algorithm which is easy and convenient to code with less control parameters and it has been testified compatible with handling comprehensive optimization problems including the non linear and high dimensional discrete systems it is mostly used in reservoir operation and water resources system optimization in the field of hydrology and environment however as far as we know few scientists have used the advanced mosfla for optimizing lid practices especially from the perspective of nps reduction the objectives of this study were as follows 1 to develop a simulation optimization framework to generate cost benefit information for the optimal design of lid practices 2 to improve the computation efficiency by introducing the markov simulator and 3 to solve the robustness problem by incorporating the mosfla the new framework was then tested in a typical urban catchment in china and the reliability of results was validated by comparing them to the most commonly used swmm and nsga ii 2 methodology 2 1 study area description and data collection in this study the beijing normal university located in the haidian district of beijing china was selected as the study area fig 1 the mean annual precipitation and temperature are 570 mm and 14 0 c respectively the study area has a total drainage area of 58 ha and five outfalls were found based on drainage pipe network information the detailed land use data sewer network map and digital elevation model were obtained from a local administrative agency while buildings and green areas were identified as the two major land uses types 30 29 for buildings and 25 22 of green areas an automatic weather station hobo onset computer corporation bourne ma usa was installed for collecting meteorological data several rainfall events were monitored for the construction of this new simulation optimization framework specifically a monitoring device fl900 hach us was used for recording flow data at outfall3 which occupies 73 19 of the total drainage area water samples were also collected for the analysis of nps pollutants based on our previous study the chemical oxygen demand cod was identified as one of the major pollutants from this catchment therefore cod was selected as the target pollutant for lid practices these measured flow and cod data were then used for calibrating the swmm model 2 2 the general framework for the proposed framework in this study an integrated framework was proposed for the simulation and optimization of urban lid practices this framework in terms of the markov mosfla lid m m lid method was based on the integration of the swmm the markov chain method and the mosfla algorithm fig 2 illustrates the detailed process of the m m lid method for the optimal design of lid practices in terms of the type number location and configuration of lids at the urban catchment scale the following four procedures were considered 1 the simulation of the urban hydrology and nps processes during the baseline scenario was performed by using a physically based urban model then the benefits or efficiency of the typical lid practices during the lids scenario were quantified by considering the popularity and data availability the swmm was chosen for this study 2 the establishment of a substitute simulator for the previous urban model was achieved from the perspective of computational efficiency in this study the markov chain method was used as a substitute for the swmm during the following optimization process 3 the markov chain method and the cost function were then integrated with the advanced mosfla in order to provide the cost benefit curves for each design of lid practices the efficiency and the related cost of each lid scheme were used as the targeted objectives 4 finally the type number location and configuration of the selected optimal lid design was further optimized and translated using gis software in this study the optimal results of lid design were then validated by running the swmm within the lid scenario 2 3 the simulator from the swmm to the markov chain in this study the swmm was used for providing detailed information of runoff and nps processes during the baseline scenario and the markov chain method was then used as the substitute simulator for the following optimal design of lids 2 3 1 the setup of swmm the pcswmm developed by computational hydraulics international chi was used in this study the infiltration loss on the previous area was estimated by the horton equation and dynamic wave routing which models pressurized flow and entrance exit energy losses of the pipe network was selected for the routing process in this study the cod load was generally stated as follows 1 l 0 t c t q t d t where l is the pollution load for rainfall event g c t is the instantaneous cod concentration at time t mg l q t is the runoff at time t m3 s and t represents the rainfall duration s for the swmm lid practices are divided into several vertical layers surface soil and storage and different design parameters should be defined for each layer for the surface layer the water balance follows the equation 2 d 1 t q 0 e 1 f 1 q 1 where q 0 is the inflow and q 1 is the outflow e 1 is evaporation flux and f 1 is the permeation flux in the surface layer for the soil layer 3 d 2 θ t f 1 e 2 f p where d 2 is the soil layer thickness e 2 is evaporation flux and f p is permeation flux in the soil layer for the storage layer 4 ϕ d 3 t f p e 3 f 3 q 3 where ϕ is porosity e 3 is evaporation flux f 3 is permeation flux and q 3 is the outflow in the storage layer the measured flow and cod data were used to calibrate and validate the swmm using an iterative process of trial and error and two good of fit indicators the nse and the correlation index r2 were used to evaluate the model performance for more detailed information about model construction and calibration please refer to our previous study hou et al 2019 for the hydrological model the range of nse was from 0 507 to 0 669 and the r2 ranged from 0 514 to 0 763 the cod model also performed well producing an nse of 0 669 and an r2 of 0 765 these results indicate that the calibrated swmm could provide reliable flow and nps cod simulations furthermore based on our local investigations two lid practices in terms of permeable pavement and green roofs were considered for the following optimization the detailed flow and cod data at outfall3 during the baseline and lid scenario were obtained by running the swmm 2 3 2 the markov chain method to alleviate the computational burden the markov chain method was used as a substitute for the swmm the markov chain represents a stochastic model describing a sequence of possible events in which the probability of each current event depends only on the state of its previous event in this study this algorithm was used for describing the upstream downstream hydrological relationship of each pipe as well as the transportation processes of the nps pollutants within the pipe network during the rainfall process flow and nps pollutants were attenuated after passing through the lid facilities and the pipe network one assumption is that the direction of sewage flow in the pipe network is similar to that within the natural catchment and could therefore be expressed by the upstream downstream relationship of the markov matrix chen et al 2014 the second assumption is that the transportation of nps pollutants in the current process in each pipe section is only related to its former state liu and weller 2008 miller et al 2013 the details of this markov method are described below step 1 construct the hydrology relation matrix of the pipe network one unique fact about urban hydrology is that an artificial subsurface routing system significantly affects runoff and nps pollution processes and runoff routing from land surfaces to the pipe network is usually achieved via downspouts instead of elevation gradients based on geographic theory the urban catchment can be broken down into several subwatersheds and a distinct pipe network with many downspouts unlike a nature catchment that could be extracted from a dem such geographic information of the urban catchment should only be described by the surface elevation data the downspout location and the pipe network map therefore the upstream and downstream relation matrix of urban hydrology can be constructed according to this information the number of subwatersheds and junction nodes downspout is defined as n and the relation matrix can be simplified as a matrix h n n to represent the pipe network 5 h i j 1 j i s t h e n e a r e s t s i t e d o w n s t r e a m f r o m i 0 otherwise step 2 quantifying the attenuation of pollutants within the pipe network the generation transformation and attenuation of nps pollutants in urban catchments represents a very complicated process in this study the swmm was used to describe the detailed transformation and attenuation processes within the pipe network the flow and pollutant input data from each subwatershed as well as the data series for each pipe section were first calculated using the swmm then data from the baseline scenario were described by using a flow pollutant input matrix and the retention coefficient matrix of the pipe within this step a n 1 matrix e e 1 e 2 e n t was developed to represent the flow or pollutant input matrix during each lid scenario from each subwatershed s 1 s 2 s n where e i represents the simulated flow or nps pollutant input from the ith subwatershed the complex processes of the pipe network were then simplified into the retention coefficient for representing the removal capacity of the network the retention coefficient was calculated as an index of transport efficiency which can be expressed as follows 6 r loa d in l o a d out loa d in where the ith input of the load is load i in s u b i l o a d i 1 out the ith input of the load is equal to the sum of the upstream pipe load and the total load generated in the subwatershed finally the retention coefficient matrix r is expressed as follows 7 r r 1 0 0 0 r 2 0 0 0 r n step 3 calculation of the efficiency of lid practices considering the retention in the pipe network we define the transfer matrix of nps pollutants as h h i r where i is unit matrix the assessment point for the evaluation of lid efficiency in terms of cod reduction in this study was set at outfall3 which is within the drainage pipe network a n 1 matrix k k 1 k 2 k n t was then developed to represent the lid efficiency for each subwatershed grimvall and stalnacke 2015 8 h k i j h k i j if i k 1 if i j k 0 if i k a n d j k 9 v k i 1 if i k 0 otherwise then the following equation was used to calculate the contribution of lid practices constructed at each subwatershed to the final cod reduction at the assessment point 10 l h k n v k e finally the efficiency of lid configuration was obtained for each lid scenario 2 4 the shuffled frog leaping algorithm based optimization method in this study the mosfla which is based on the shuffled frog leaping algorithm sfla was applied for solving multi objective optimization problems 2 4 1 the description of the shuffled frog leaping algorithm the sfla was developed as a heuristic algorithm by integrating the characteristics of the particle swarm optimization pso algorithm and the meme algorithm ma this algorithm consists of a set of interacting populations of virtual scenarios that are partitioned into different groups eusuff and lansey 2003 eusuff et al 2006 within each scenario set the individual solution can be influenced by other individuals and each individual can evolve through a process of memetic evolution in memetic evolution the poor individuals should be weeded out through the fitness function after some iterations of memetic evolution information is integrated among memplexes formed through a shuffling process the local search and the shuffling processes continue until defined convergence criteria are satisfied in this sense both global and local search strategies are considered for the sfla the most distinguishing difference between the mosfla and the original sfla is the change of fitness function both the dominance and distribution of solutions are considered for the mosfla li et al 2010 to judge the merits of solutions instead of only the fitness values as used in the original sfla 2 4 1 1 sorting strategy first all scenarios were stratified according to the dominated relation by fast nondominated sorting which is derived from nsga ii deb et al 2002 second crowding distances were calculated for each front as 11 p i dis tan c e k 1 r p i 1 f k p i 1 f k where p i dis tan c e indicates the crowding distance of ith nondominant solution and p i 1 f k and p i 1 f k indicate the kth objective function values of two adjacent solutions finally all scenarios of each generation were ranked in ascending order and the scenarios of each front were sorted in descending order based on crowding distance 2 4 1 2 memetic evolution within each local memplex improvements have been made for the memetic evolution process to enhance the search efficiency in the solution space in this study memetic evolution was mainly achieved by the evolution of nondominant solutions the main evolutionary mechanisms include the following 1 the original evolution was computed based on a local optimal solution 12 d r a n d xb x w where xb is the local optimal solution and xw is the local worst solution 2 the original evolution was computed based on a global optimal solution 13 d r a n d xg x w where xg is the global optimal solution 3 the mutation mechanism based on a genetic algorithm is shown as 14 a 1 a 2 a 3 a 4 a 5 a 1 a 2 a 3 a 1 a 2 a 1 a 2 a 3 a 4 a 5 a 4 a 5 a 3 a 4 a 5 4 the random solutions were generated near the global optimal solution as shown by 15 new x w 0 95 x g 0 05 r a n d x x where x and x are the neighbors of xg 2 4 2 the mosfla based optimization of lid practices in this study the multi objective design of lid practices was established by considering the reduction of the nps pollution and the related cost objective function minimize the cost of lid practices 16 min cos t min min cos t x based on our investigation the corresponding cost of permeable pavement and green roofs was set as 200 yuan m2 and 310 yuan m2 maximize the retention efficiency of cod 17 max r e max max r e x constraints several constraints were set for the construction of lid practices at the catchment scale based on local law the permeable pavement and green roofs were set as 50 100 and 80 100 of the lid installable area for each subwatershed algorithm adaptation the type location and installation area of lid practices for each subwatershed were treated as the decision variables and the combination of lid configuration at the catchment scale was represented by decision vectors whose length was determined by the number of subwatersheds 515 for the study area in this study twenty solutions were set as a memeplex each memeplex will be memetically evolved twice internally and then shuffled into a population while ten memeplexes were set as a population to improve the evolution efficiency all dominated solutions were evolved at the same time after the above steps the optimal design pareto front of the lid practices was achieved then gis was used to realize the visualization of optimization strategy and swmm was used to validate the feasibility of the selected optimal lid scenario 3 results and discussions 3 1 the results of the new framework in this study the new framework was evolved for 50 100 and 200 generations in the study area to test its efficiency and robustness fig 3 shows the result of cod removal and the related cost of each lid configuration the cost benefit curves are shown in fig 3a once the pareto optimal front was generated it was indicated that the optimal design of the lid practices could reduce nps cod by 0 33 80 kg and could reduce cost by 0 2 04 million yuan by observing the front curve we found that cod removal would first increase with increasing expenditure however after the turning point when cod removal was 32 kg the cod reduction tended to be gentle even if the cost increased there was no obvious improvement of cod removal in previous studies it was believed that more lid practices would result in a greater nps reduction however fig 3a indicates that the efficiency of lids remains stable inside a relevant domain of cost and that any cost outside this domain would not result in a better lid efficiency the evolutionary processes are also shown in fig 3 as illustrated in fig 3a the front curve was far from the pareto front and the solutions did not show significant change in the first 10 generations due to the limitation of the algorithm s searching ability as the algorithm processed from 10 to 20 generations the front curve quickly approached the pareto front however nondominance was not exhibited by the solutions of the front curve during the following evolutionary processes to 50 generations the shape of the pareto trade off front obtained by the proposed method shifted from relatively scattered points to a smooth curve and the solutions were close to the pareto front the maximum cod removal was found and the optimal cod reduction was 22 32 kg this result indicated that local optimal solutions were found but the global optimal solutions had not been reached as this algorithm did not converge at that time structural lids were observed on the higher edge of the front curve which is where expensive solutions were located as the generation gradually reached 100 the front curve became basically stable with only a few points located outside the pareto curve finally when the generation reached 200 the optimal front was found and this current curve was completely stable with good distribution and convergence the final pareto optimality front indicated the optimal design of lid practices had reduced the nps cod from 862 42 kg to 828 61 kg in outfall3 from the study area the removal of cod caused a reduction of 33 80 kg and the corresponding cost was 2 04 106 fig 3b further shows the spatial distribution of lid practices for the study area thirteen permeable pavements and two green roofs were finally set around several taller buildings which were found to be hotspots of nps cod for the study area these results indicated that effective nps reduction could first be achieved through the optimal design of permeable pavement and green roofs to reach further reductions a combination of other lids is suggested for the entire catchment 3 2 the comparison between the m m lid and swmm methods in this study the optimal results of the new algorithm were compared with those obtained by the commonly used physically based model once the pareto optimal front was generated the pareto optimal lid design was imported into the swmm and the swmm model was used again to obtain the real efficiency of the optimal lid practices in this sense the markov chain and the swmm were compared to describe the main features of the new algorithm in a better way first the performances of the new and traditional algorithms were compared by using the computational burden utilized in the optimization run compared with swmm method the biggest advantage of the m m lid method was the improvement of computational efficiency by evaluating a total of 200 generations the entire process of the swmm required approximately 72 h of computational time on a computer with 2 10 ghz e5 2620 cpu and 64 g ram conversely the markov based optimization was terminated in fewer than 10 min which was a drastic improvement of approximately 500 times that of the original process in practice by reducing the complexity of the simulation the new algorithm ran much more quickly 500 times faster for the case study than the swmm based method at present the large computation time has become the bottleneck of the lid optimization especially for large catchments moreover as a mathematics based method the markov based method could be applicable to all kinds of current urban models and has provided a new idea for the optimal design of lids for large urban catchments however the markov based method uses a simple index to describe the complex migration and transformation process of nps pollutants within the pipe network thus the goodness of fit of the new and traditional algorithms were evaluated by comparing the simulated nps cod data during specific lid configuration the results obtained by the markov and the swmm are shown in fig 3 only two solutions with the highest cost scenario and least cost scenario are shown because the largest error was observed for these two solutions it is shown that the nps cod was estimated as 828 61 kg by the m m lid and 814 17 kg by the swmm the relative error between these two methods was 1 77 indicating there was no significant difference between the results of the m m lid method and the swmm model for the least cost scenario the simulated nps cod was 862 42 kg and 846 40 kg when by using the m m lid method and the swmm method respectively the relative error between the two calculation methods was 4 89 therefore it could be considered that the m m lid method is a good substitute for the physically based models 3 3 the comparison between mosfla and nsga ii the optimal design of lid practices by the new algorithm and the nsga ii were further compared by using matlab r2018b the results during the evolutionary processes are shown in fig 4 it is obvious that the solutions of the nsga ii and the mosfla were both far from the final pareto curve but were located within 50 generations the computational time was 203 34 s for the of nsga ii in comparison the computational time of the mosfla was 167 52 s which was 82 38 faster than the nsga ii furthermore the optimal solutions of the nsga ii did not show a good distribution as most solutions were gathered in high cost regions the range of cod removal was from 0 to 33 80 kg using the mosfla and from 31 69 to 33 80 kg using the nsga ii this difference could be due to the local and global search abilities as well as the high robustness of the mosfla as the evolution was processed to 100 generations the nsga ii and the mosfla took 337 21 s and 256 22 s respectively the convergence and distribution of the mosfla were significantly improved compared with that of 50 generations and the ranges of cost and cod had reached the optimal level in comparison the range of cod removal was improved a range from 12 83 to 33 80 kg was obtained using nsga ii when the optimization continued to 200 generations the mosfla and the nsga ii both showed good convergence and distribution and the computational time was 734 78 s for the nsga ii and 412 05 s for the mosfla zheng et al 2014 on one hand the computation time for the mosfla was faster than that of the nsga ii by 82 38 31 61 and 78 32 for the 50 100 and 200 generations evaluated for the study area on the other hand the mosfla also showed better convergence and distribution than the nsga ii as shown in fig 4 the optimal design of the lid practices using the mosfla were more dominant than using the nsga ii especially for low cost solutions this result could be due to the crossover operator of the nsga de vos and rientjes 2008 rodriguez et al 2011 the computational efficiency advantage of mosfla was more applicable to the m m lid method especially for complex urban catchments the advantage of robustness guaranteed the distribution of solutions and the diversity of lid practices yang et al 2019 4 conclusion the increasing urbanization has resulted in dramatic environmental change causing a big impact on stromwater quality management and lid practices were required for the mitigation of stormwater impacts in this study a fast and robust multi objective framework was proposed for the simulation and optimization of lid practices at the catchment scale the markov chain method and the mosfla were integrated and the framework was validated for a typical urban catchment in china the new m m lid method generated desirable scenarios more quickly based on markov chain and the solutions are robust in different generations rather than nsga ⅱ method this method can provide a series of optimal scenarios and the cost benefit curves as well as insights on optimal lid combinations sizing and placement indicated that a cost of 0 2 04 million would provide reductions of 0 33 80 kg for cod in the urban watershed the results indicated the following 1 the relative error between the swmm and the markov chain method was less than 5 indicating that a satisfactory performance could be obtained using the proposed framework 2 the computational efficiency was improved by 500 times when the new framework was used for the case study 3 the robustness of the optimal results increased over 50 compared to commonly used algorithms this new method provides a useful tool for optimizing lid practices and green infrastructure especially for complex urban catchments declaration of competing interest the authors declare that there are no conflicts of interest regarding this manuscript acknowledgements this research was funded by the state key program of national natural science of china no 417 41530635 the national natural science foundation of china nos 51779010 and 51579011 and the interdiscipline research funds of beijing normal university data used in this study are available from the publications and local administrative agency cited therein 
6309,offshore fresh groundwater is increasingly suggested as a potential water resource for onshore human demands in many cases onshore pumping already draws significant fresh groundwater from offshore however offshore aquifers and the extent of offshore freshwater are usually poorly characterised due to data scarcity this study combines geophysical data hydraulic information and a first order mathematical analysis to investigate offshore freshwater extent in the gambier embayment australia a large seismic data set combined with onshore and offshore bore log geological profiles are used to explore the regional offshore hydro stratigraphy aquifer hydraulic parameters and onshore heads are obtained from onshore investigations a novel application of archie s law geophysical data and onshore hydrochemical data provide useful insights into the salinity profiles within four offshore wells these are compared to steady state sharp interface estimates of the freshwater extent obtained from a recently developed analytical solution albeit using simplified conceptual models salinities derived from resistivity measurements indicate that in the south of the study area pore water with total dissolved solids tds of 2 2 g l 1 is found up to 13 2 km offshore offshore pore water salinities are more saline in the northern areas most likely due to thinning of the offshore confining unit the analytical solution produced freshwater saltwater interface locations that were approximately consistent with the freshwater saltwater stratification in two of the offshore wells although analytical uncertainty is high this investigation provides a leading example of offshore freshwater evaluation applying multiple techniques demonstrating both the benefit and uncertainty of geophysical interpretation and analytical solutions of freshwater extent keywords offshore fresh groundwater seawater intrusion geophysics seismic data analytical solution 1 introduction increasing coastal populations and the impacts of a changing climate are predicted to threaten the freshwater resources of many coastal communities post et al 2013 michael et al 2017 several studies have suggested the use of fresh and brackish water contained within confined and semi confined submarine aquifers to assist in meeting the freshwater demands of coastal communities cohen et al 2010 bakken et al 2012 post et al 2013 jiao et al 2015 here we consider freshwater salinities as total dissolved solids tds 1 g l 1 while brackish water salinities are 1 g l 1 tds 10 g l 1 the landward movement of fresh and or brackish groundwater stored in subsea aquifers likely delays onshore seawater intrusion swi in several regions globally knight et al 2018 however as coastal groundwater investigations frequently focus on the onshore resources and coastal fringe processes more generally the behaviour of fresh groundwater within submarine aquifers remains understudied bratton 2010 post et al 2013 werner et al 2013 the occurrence of subsea freshwater and brackish water referred to collectively as offshore fresh groundwater ofg in what follows is thought to form through two main mechanisms firstly ofg can form where fresh groundwater discharges from an onshore confined or semi confined aquifer hereafter termed semi confined into the offshore continuation of the aquifer kooi and groen 2001 bakker 2006 secondly increased continental shelf exposure due to vastly different hydraulic conditions during glacial maxima in some cases leading to increased groundwater hydraulic gradients are thought to have facilitated the emplacement of freshwater in present day submarine aquifers cohen et al 2010 post et al 2013 morgan et al 2018 both mechanisms require an overlying aquitard to inhibit the rapid vertical mixing of fresh and saline waters that would otherwise occur due to the buoyancy forces induced from seawater overlying freshwater various methods have been applied to assess ofg reserves although there are few studies that adopt multiple techniques to characterise offshore aquifers for the purposes of freshwater exploration i e to estimate ofg extents direct observations of ofg include the sampling of pore water salinities from offshore core samples e g jiao et al 2015 and the sampling of pumped fluids from short screened intervals offshore e g krantz et al 2004 geophysical methods for characterising ofg include downhole deep induction resistivity logs and resistivity transect surveys e g oteri 1988 groen et al 2000 krantz et al 2004 hennig and otto 2005 the inverse relationship between resistivity and fluid salinity contained in archie s law archie 1942 can allow for freshwater to be inferred from both transect and downhole resistivity data however the method requires knowledge of porous medium resistivities leading to seldom reported uncertainties in the pore water resistivities calculated using archie s law there are limited documented studies investigating how regional variations in the hydro stratigraphy impact offshore salinities krantz et al 2004 used a combination of seismic resistivity and drill hole data from aquifers below indian river bay delaware usa to conclude that ofg can preferentially form within sand filled incised valleys that are silt capped with ofg within such channels able to reach several kilometres offshore mulligan et al 2007 identified that when the overlying confining unit is incised by paleo channels enhanced vertical flows resulting in increased freshwater saltwater mixing are likely pauw et al 2017 used onshore data and analytical modelling to demonstrate how shore parallel variability in the onshore hydro stratigraphy can alter the ofg extent michael et al 2016 used cross sectional numerical modelling to show that in comparison to a homogeneous aquifer freshwater can extend further offshore in aquifers that have strong vertical heterogeneity but well connected horizontal flow paths to date there is no study supported by offshore data that investigates the potential alongshore variability of ofg extent on a regional scale despite the fact that ofg is considered to be widespread post et al 2013 only three ofg bodies are evidenced by offshore data from the australian continental shelf i e perth basin hennig and otto 2005 morgan et al 2018 adelaide plains sub basin knight et al 2018 and gippsland basin varma and michael 2012 in all cases ofg has been found adjacent to significant onshore pumping which is thought to be mining offshore freshwater to supplement onshore demands knight et al 2018 in the gambier embayment ge located in the southeast of south australia fig 1 groundwater supports extensive irrigation schemes and provides water supplies for three coastal towns previous studies of the ge suggest that local head conditions in the regional semi confined aquifer may be conducive to the formation of an extensive ofg body e g pollock 2003 bush 2009 morgan et al 2015 although the occurrence and magnitude of this resource are currently unsubstantiated previous studies of the ge by pollock 2003 and bush 2009 include offshore interpretations of the main regional semi confined aquifer i e the lower tertiary confined aquifer ltca however digital copies of the lithological surfaces presented by pollock 2003 are no longer available and do not separate the ltca from the overlying confining unit the hydro stratigraphic surfaces presented by bush 2009 terminate at the offshore petroleum exploration well herein referred to as offshore wells locations despite the system extending tens of kilometres past the well locations neither of these previous seismic studies have generated the hydro stratigraphic surfaces required to assess the extent of ofg in the ge this study aims to provide a best estimate of offshore pore water salinities in the regional semi confined aquifer of the ge using available data and through application of the analytical solution of werner and robinson 2018 the study also aims to identify the offshore distribution of the upper semi confined aquifer in the ge at least at a resolution reasonable for the large scale of the study area using seismic line survey data knowledge of the offshore hydro stratigraphy is vital for understanding potential offshore groundwater fluxes for the interpretation of calculated offshore salinities and to inform the application of analytical approaches we aim to establish offshore salinities in the regional semi confined aquifer of the ge using legacy downhole geophysical data from both onshore and offshore petroleum exploration wells this study represents the first attempt at using onshore salinity resistivity relationships to inform the offshore application and uncertainties of archie s law with the aim of inferring groundwater salinities and the extent of ofg we compare the salinities calculated from geophysical data against those predicted by analytical modelling to explore the potential influence of present day hydrological forcing the werner and robinson 2018 analytical solution is applied to a range of conceptual models each representing simplified versions of the offshore conditions of the ge as determined from available field data 2 study area the ge is the western sub basin of the otway basin an extensive passive rift sag rift basin boult and hibburt 2002 that reaches the city of melbourne some 500 km east of the south australian victorian border fig 1 the ge is bounded in the northwest by the tartwaup hinge zone and in the southeast by the portland trough freeman et al 2010 the offshore regions of the basin are heavily faulted offshore fault lines are generally steeply dipping towards the southwest and have a northwest southeast strike freeman et al 2010 holford et al 2014 clarke et al 2015 previous studies of the ge have identified three hydro stratigraphic units of importance to anthropogenic activities love et al 1993 smith et al 2012 morgan et al 2015 clarke et al 2015 these are 1 an upper unconfined aquifer uua comprised primarily of the gambier limestone 2 an upper tertiary aquitard uta consisting of marl intervals and the upper clay layer of the dilwyn formation and 3 a lower tertiary confined aquifer ltca which encompasses several interbedded and generally unconsolidated sand and carbonaceous clay layers of the dilwyn formation clarke et al 2015 the uua uta and ltca are primarily offshore dipping these units reach a maximum combined thickness of 1 km in the south of the study area and thin towards the north love et al 1993 previous onshore investigations of the ge assume a lower hydro stratigraphic boundary consisting of the lower clay unit of the dilwyn formation in the south and the sherbrook formation comprising interbedded sands and clays in the north morgan et al 2015 this lower boundary is based on the assumption that current anthropogenic activities are unlikely to interact with water contained in the sherbrook formation morgan et al 2015 we adopt the same assumption in our study 3 methods 3 1 offshore stratigraphy from seismic line surveys in the offshore region of the ge 32 shore perpendicular seismic lines and 19 shore parallel seismic lines were selected for the interpretation of the offshore stratigraphy seismic and geophysical well data were obtained from the south australian government department of the premier and cabinet energy resources division j davies 2017 pers comm 14 december 2017 to generate a regional scale model of the offshore distributions of the uua uta and ltca seismic line surveys were selected at 3 km spacings in both the shore parallel and shore perpendicular directions where possible seismic lines that include multiple well ties i e passing through one or more wells from which downhole lithology has been recorded were chosen seismic data are of varying quality and were acquired at different times consequently it was not possible to determine a minimum resolvable vertical resolution that could be applied to the entire data set however previous work using the same data found that seismic reflectors are clearly imaged for units with a two way travel time twt under 2000 ms freeman et al 2010 the seismic line survey data contain no information within 5 km of the shoreline due to a regulatory exclusion zone we adopt the methodology used by pollock 2003 for the interpretation of the hydro stratigraphic horizons the top of the uua uta ltca and the sherbrook formation were selected to characterise the regional hydro stratigraphy as seismic line surveys have a vertical axis measured in the time domain a conversion between the measured twt and depth is required to identify the target horizons on downhole lithology logs a regional depth to twt relationship of z 1132 twt1 2678 r2 of 0 99 was obtained from regression of the available synthetic seismogram data i e measured twt values at set depths from the breaksea reef chama and copa wells see fig 1 for well locations we use the elevation datum m ahd metres australian height datum where 0 m ahd is approximately mean sea level the interpreted seismic horizons for the ltca were compared against the available hard copy data presented by pollock 2003 to ensure that the interpreted seismic sections were equivalent natural neighbour interpolation was used to generate continuous surfaces for each hydro stratigraphic unit natural neighbour interpolation was selected due to the linear and clustered characteristics of the seismic line survey data the input data consisted of both offshore data points obtained from the tracing of the seismic line surveys and onshore data points acquired from morgan et al 2015 a cell size of 500 m was selected due to the large scale of the study area the surfaces representing the top of the uta and ltca were clipped to honour the extents of these units interpreted from the seismic line surveys as this study focuses on the ltca the extents of the uua and pseudo basement surfaces were restricted to an arbitrarily chosen 10 km from the spatial limits of the available data as beyond this distance the surfaces are unlikely to be realistic 3 2 calculating offshore groundwater salinities from geophysical borehole logs 3 2 1 obtaining regional parameters for application of archie s law archie s law archie 1942 is an empirically derived relationship that allows for the calculation of fluid resistivity r f ω m from a measured bulk resistivity r o ω m in formations with a relatively non conductive matrix e g sand free from clay minerals archie 1942 proposed that r f r o porosity i e total porosity φ and a cementation exponent m can be related using 1 r o r f φ m in archie s law m is related to the degree of connectedness of the pore network glover 2009 a value of m 1 represents a bundle of capillary tubes with all pore spaces connected while higher values e g 2 5 to 5 represent carbonates with poorly connected pore spaces glover 2009 typical values of m for sandstone range from 1 3 to 2 6 archie 1942 values of m are usually established by taking the best fit slope through a plot of log r o r f versus log φ or through re arranging eq 1 to solve for m directly glover 2016 despite extensive petroleum exploration within the ge no pre existing values of m have been reported within the available literature values of m were obtained by applying eq 1 to five onshore petroleum exploration wells fig 1 where r o and lithological data were available however values of r f in the ltca were unavailable in all the petroleum exploration wells both onshore and offshore in addition no onshore monitoring wells had both φ and r o data recorded in the ltca to apply eq 1 to the onshore petroleum exploration wells values of r f corrected to 25 c were adopted from the nearest short screened onshore monitoring well in the ltca with hydrochemical data available dew 2019 groundwater salinity measurements elsewhere within the onshore region of the ltca have low variability over distances similar to the distances between the groundwater monitoring wells where r f values were obtained and the onshore petroleum exploration wells for example the recorded tds changed by 25 mg l 1 between two onshore monitoring wells well 7022 7871 and well 7021 3339 that were 10 km apart the distances between the petroleum exploration wells and the onshore monitoring wells were under 10 km as r f data were only available for the upper sand interval of the ltca r o data were also restricted to this interval the upper sand intervals of the onshore petroleum wells were at similar depths to the screened interval depths in the onshore monitoring wells from which r f data were obtained upper clean sand horizons in each well were identified from downhole lithological descriptions with gamma ray logs used to discern clean sands from those with significant clay using this approach the ge was found to have clean sand horizons with a gamma ray signature of 25 api lithological descriptions for ltca sand horizons and the data available for each of the wells used in this study are presented in the supplementary material table s1 as a variable number of geophysical data points were available within the upper sand horizon in each well the mean m value for each onshore petroleum exploration well m w was obtained the regional value for the ltca of m m r was obtained by taking the mean of the m w values the standard deviation of m r σ m was also obtained porosity can be estimated from both bulk density and sonic logs of the wells included in this study only argonaut and chama have both bulk density and sonic logs in the targeted hydro stratigraphic units except for the copa well all wells both onshore and offshore have sonic log data a regional value of porosity was used in the application of eq 1 to the copa data because both sonic and bulk density logs were absent at the depths of interest to this study in the argonaut and chama wells where both sonic and density data were available porosity was preferentially determined for each data point from bulk density logs according to 2 φ b ρ m ρ b ρ m ρ w where φ b is the bulk density derived porosity ρ m is the density of the solid matrix 2650 kg m 3 e g groen et al 2000 ρ b is the measured bulk density of the saturated porous media kg m 3 and ρ w is the density of water 1000 kg m 3 excluding the argonaut chama and copa wells porosity was determined for each ltca data point representing clean sand from sonic log data using the wyllie time average equation wyllie et al 1958 3 φ s δ t z δ t m a δ t f δ t m a where φ s is the sonic derived porosity δt z is the measured acoustic transit time i e the time taken for the seismic wave to travel a unit distance μs m 1 δt ma is the acoustic transit time of the rock matrix 192 9 μs m 1 taken from well completion reports and δt f is the acoustic transit time of interstitial fluids a value of 616 μs m 1 was adopted from the well completion reports as sonic porosities in unconsolidated sediments tend to overestimate the total porosity the sonic porosity was divided by a correction factor c p calculated using raymer et al 1980 4 c p φ s φ the regional value of c p for the ge was taken as the mean c p from the argonaut and chama wells for which φ s were available and φ could be approximated as φ b values in copa neither sonic nor bulk density logs were available in the ltca to enable the application of eq 1 to the copa well data a single regional ltca φ value was established by taking the mean of the calculated φ values of all data points in the ltca sand layers using data from the other eight wells both onshore and offshore included in this study as electrical resistivity is dependent on temperature r o was converted to equivalent values at a standard temperature of 25 c using jorgensen 1996 5 r 25 z 1 8 t z 39 84 r o z where r 25 z is the bulk resistivity ω m adjusted to 25 c at depth z r o z is the bulk resistivity ω m measured at depth z and t z is the temperature c at depth z m t z is calculated from the local geothermal profile obtained from drilling completion reports of 6 t z 0 2759 z 19 3 2 2 calculating offshore salinity profiles the downhole r f profiles of four offshore wells in the ge were calculated by applying a re arranged form of eq 1 to temperature corrected resistivity data from each well temperature corrections were undertaken using eq 5 to identify the possible r f values due to uncertainty surrounding the estimation of m r pore water resistivities were calculated from eq 1 using m values of m r m r 1σ m and m r 2σ m the calculated fluid resistivities were converted to an approximate tds mg l 1 at depth z using an empirically derived relationship of 7 tds z 10 000 0 55 r f a mean tds value for each sand interval tds was established by averaging the calculated pore water salinities of all the data points contained within each respective sand interval this was repeated to obtain tds values for all sand intervals and using alternative values of m i e m r m r 1σ m and m r 2σ m 3 3 sharp interface analytical modelling of present day steady state conditions to explore the possible ofg extent attributable to present day ofg inflows in the ltca the analytical solution of werner and robinson 2018 was applied to three simplified shore normal transects the werner and robinson 2018 solution assumes that the aquifer is flat lying isotropic homogeneous of constant thickness and is confined onshore and semi confined offshore the solution also assumes that 1 the system is at steady state with respect to onshore heads 2 the freshwater saltwater interface can be represented by a line of pressure equilibrium i e a sharp interface 3 shore parallel flow is negligible and 4 vertical freshwater flow in the aquifer can be neglected while horizontal flow in the semi confining unit is ignored the modelled transects pass through the breaksea reef argonaut and copa wells fig 1 as the interpreted seismic line survey data indicated that the ltca and uta are not continuous between the onshore environment and chama the analytical solution of werner and robinson 2018 cannot be applied to investigate the potential salinity at chama from current onshore conditions also the top of the ltca has an offshore slope of around 1 on average whereas the analytical solution assumes that the aquifer is horizontal to account for this two different sets of geometric conditions aquifer depth and thickness were used in applying the analytical solution to each transect namely 1 reflecting the conditions at the shoreline and 2 reflecting the conditions at the offshore wells the werner and robinson 2018 solution requires the hydraulic conductivity k of the aquifer k a m d 1 the thickness of the aquifer h the thickness of the semi confining unit d a specified head h b at a distance onshore x b the vertical k of the semi confining unit k l m d 1 the length of the offshore semi confining unit l s the depth to the base of the semi confined aquifer below sea level z 0 and the densities of fresh ρ f kg m 3 and saline water ρ s kg m 3 the werner and robinson 2018 solution allows for the designation of the pore water salinity of the semi confining unit which in this case was set to freshwater following the recommendation of solórzano rivas and werner 2017 the parameter sets applied to the werner and robinson 2018 solution are listed in table 1 parameters obtained from the offshore wells are denoted by an asterisk otherwise parameters reflect onshore data the analytical solution was applied to both present day and pre development heads h b and h b p respectively in the onshore aquifer values for h b p are approximate only and were estimated by extrapolation based on temporal head slopes from earliest recordings typically in the 1970s the tip and the toe where the freshwater saltwater interface coincides with the aquifer top and bottom respectively were obtained by applying the parameters in table 1 to the analytical solution resistivity derived salinities of tds 17 5 g l 1 50 of seawater were used to compare to the tip and toe positions calculated using the sharp interface analytical solution in the same manner as previous publications e g werner 2017 4 results 4 1 offshore hydro stratigraphy the horizons traced in the seismic line surveys show evidence of extensive shore parallel faulting within the offshore hydro stratigraphic units fault induced displacement appears to have led to localised thinning of the uta in several survey lines the interpreted seismic horizons corresponding to the hydro stratigraphic units for the uta and the ltca indicate that the respective units either pinch out underneath the uua at the continental slope or remain covered by the uua rather than terminating at the seafloor an example of this is visible in fig 2 a the northern offshore extent of the uta and ltca was determined by considering that these two units appear to onlap i e pinch out against a local high in the underlying sherbrook formation fig 2b causing the interpreted units to become discontinuous an example of this onlap is highlighted in fig 2b other seismic line surveys that pass through chama appear to show similar onlap against the sherbrook formation in other directions outwards from the chama well see fig 3 a this suggests that the uta and ltca recorded in the downhole lithological log at chama are disconnected from their onshore counterparts fig 2a also provides an interpreted cross section of the aquifers of interest to this investigation two additional interpreted cross sections are provided in the supplementary material fig s1 the isopach distribution for the uta and ltca are shown in fig 3 while both the interpolation process and the large cell size chosen acted to dampen high frequency features e g sharp fault driven elevation changes in the interpolated offshore hydro stratigraphic surfaces there is still noticeable variability regionally in the offshore thickness of the uta and ltca south of argonaut the calculated thickness of the uta fig 3a varies predominantly between 50 m and 150 m north of argonaut the uta is mainly 25 m to 100 m thick the ltca also displays increased thickness south of argonaut fig 3b with thicknesses predominantly between 450 m and 1145 m thick north of argonaut the ltca thins to between 100 m and 550 m this northward thinning is also visible in the three interpreted cross sections presented in the supplementary materials fig s1 three paleo channel features described by pollock 2003 were interpreted to incise through the uta and into the ltca close to the continental slope fig 3a with the largest of these paleo channels occurring midway between copa and argonaut as these paleo channels incise through the uta they may reduce the semi confined offshore extent of the ltca and lead to saltwater entering the aquifer preferentially from above two maps that display the top of the uta and ltca are presented in the supplementary material figs s2 and s3 4 2 establishing regional parameters for archie s law using the onshore petroleum exploration well data an m r value of 1 40 and a σ m of 0 14 were obtained the regional value of c p established from paired sonic and density logs was 1 74 the available density and corrected sonic data produced an average φ of 0 37 along with σ φ standard deviation of the calculated porosities for ltca clean sand intervals extracted from the other eight wells included in this study of 0 068 there was no clear relationship between φ and depth or between m and depth these data are presented in the supplementary material figs s4 and s5 4 3 offshore salinity profiles from geophysical data fig 4 a shows the tds values for each r o measurement limited to sand intervals in the argonaut well despite substantial tds variability the two shallower sand intervals show distinctly lower tds values than the two deeper sand intervals there is significant scattering of tds values within each sand layer this scattering is greater in the two lower sand intervals where calculated tds values are higher the observed scattering of the calculated tds values in an individual sand layer was due to fluctuations in both φ and r o with depth this suggests that a single calculated tds value is unlikely to be representative of the pore water salinities that would be encountered across the entire sand interval the mean values of tds tds for each sand layer in the four offshore wells of interest argonaut breaksea reef chama and copa are presented in fig 5 tds calculated using m r m r σ m and m r 2 σ m are shown for each sand interval the wells ranked in order of the lowest salinity groundwater encountered in each well are argonaut breaksea reef chama and copa the salinities within the copa well are the highest with tds in the ltca ranging between 22 2 g l 1 and 30 9 g l 1 the distinctive increase in tds with depth that is apparent at argonaut fig 4a can also be found in the breaksea reef chama and copa wells although without the same well defined salinity stratification of the argonaut data for example the breaksea reef data reveal elevated salinities in the uppermost sand interval for which tds is 11 2 g l 1 while the two underlying sand intervals have a tds of 3 8 g l 1 and 4 2 g l 1 respectively salinities appear to increase with depth thereafter with the deepest sand interval in the breaksea reef well having a tds of 14 7 g l 1 in argonaut salinities increase with depth within the ltca with a tds of 2 2 g l 1 calculated for the shallowest sand interval while the deepest sand interval in the ltca has a tds of 22 9 g l 1 in the chama well salinity in the ltca also increases with depth ranging from 13 1 g l 1 in the shallowest sand interval to 45 9 g l 1 in the deepest sand interval there were no sand intervals in copa that had a tds under 22 2 g l 1 4 4 analytical modelling the interface tip and toe positions calculated using analytical methods for three transects passing through the breaksea reef argonaut and copa wells are listed in table 2 four sets of tip and toe positions were produced for each transect using the werner and robinson 2018 solution in accordance with present day and pre development conditions and using cross sections based on onshore and offshore hydro stratigraphic data according to table 2 calculated toe positions are shoreward of respective well locations for all simulated cases and therefore the analytical solution suggests that seawater is at least partly expected to occur in all wells there is an underlying presumption here that offshore freshwater seawater conditions are in equilibrium with present day or pre development conditions in onshore aquifers this is discussed further in later subsections in the breaksea reef transect the application of the analytical solution to present day conditions produces interface tips that are 33 9 km and 10 6 km offshore for the onshore and offshore data sets respectively the calculated present day steady state tip positions for the argonaut and copa transects follow a similar pattern with the interface tip calculated using the offshore data shoreward of those calculated using the onshore data that is tip positions from offshore based aquifer geometries were shoreward of those obtained from onshore geometries by 2 7 km and 8 3 km for argonaut and copa respectively the tip positions calculated from the present day onshore data sets for breaksea reef and argonaut both reach the offshore boundary of the semi confined aquifer when the werner and robinson 2018 analytical solution was applied to the pre development data sets for breaksea reef and argonaut the calculated tip reached the offshore boundary for both the onshore and offshore data sets the analytical solution suggests that under steady state conditions present day onshore heads are capable of driving freshwater past the argonaut well for both the onshore and offshore parameter sets for the transect passing through breaksea reef the onshore parameter set indicates that modern heads are sufficient to drive freshwater seaward of the well location while the offshore parameter set places the tip 2 km shoreward of the well in the copa transect the calculated pre development tip positions are seaward of their present day counterparts as expected given the higher pre development head however pre development tip locations are shoreward of the copa well location indicating only seawater in the aquifer at the copa well location for both the onshore and offshore data sets modern heads were also insufficient to drive freshwater to copa for either parameter set 5 discussion 5 1 offshore salinities of the ge while potable tds 1 g l 1 water was not identified in the offshore wells included in this study the low calculated salinities tds 2 2 g l 1 up to 13 5 km offshore suggest that in the south of the ge potable water may extend a significant distance offshore these results support the inferences of earlier work pollock 2003 bush 2009 morgan et al 2015 that there is a potential for ofg in the ge the downhole salinity profiles within the ltca in breaksea reef and argonaut are typical of those observed in other ofg bodies e g groen et al 2000 cohen et al 2010 post et al 2013 in which the salinity generally increases with depth albeit the transition is not necessarily smooth the sand intervals in copa return lower resistivity values than the surrounding clay intervals data not shown under constant pore water salinities clays typically return lower resistivity values than sands waxman and smits 1968 and therefore the clay pore water is potentially fresher than that in the adjacent sand intervals this may indicate that clays contained entrapped fresher pore water as might occur when more permeable sands salinise due to the landward movement of saline groundwater e g due to falling onshore heads the observation that clays likely contained fresher water than overlying underlying sand units may provide useful information on transient interface movements in future investigations of the ge offshore domain using the value of m r obtained from the ltca sand layers preliminary investigations of the possible pore water salinities in the underlying sherbrook formation were also undertaken however as m r was established for the ltca these values have higher uncertainty an expanded version of fig 5 that includes approximate pore water salinities of the upper sherbrook formation is presented in the supplementary material fig s6 except for a single sand layer in chama that has a tds of 11 1 g l 1 the sand layers in the underlying sherbrook formation have approximate calculated tds values in the saline range i e tds between 16 7 g l 1 and 46 9 g l 1 no clear relationships between salinity and depth are apparent in the tds values for the sand layers of the sherbrook formation the two separate zones of near brackish water tds values of 11 1 g l 1 and 13 1 g l 1 in the downhole salinity profile for chama fig s6d do not conform to the salinity profile expected if these two zones are hydraulically connected and or maintained through freshwater flow driven by present day onshore heads if the two units were hydraulically connected then buoyancy forces due to density contrasts between fresh and saltwater would cause the brackish water in the lower zone to migrate upwards therefore it appears that some separation between units of differing hydraulic conductivity is apparent around chama the two southern wells breaksea reef and argonaut that contain fresher pore water are both closer to the shoreline and further from any termination of the uta than the two northern wells for example the more saline copa well is 2 km from the interpreted northern offshore termination of the uta if the ltca is in contact with the uua along this zone due to the lack of uta aquitard between the two aquifers ltca and uua e g fig 2b increased groundwater mixing may occur similar enhanced mixing due to the incision of submarine paleo channels through overlying semi confining units is described by mulligan et al 2007 this presumes that the overlying uua is saline which is evident from consistently low resistivity values in the downhole resistivity logs the three paleo channel features identified in the seismic line surveys are situated at significant distance 19 km from the offshore wells and are therefore unlikely to have a significant impact on the calculated downhole salinities the steady state ofg extents calculated using the werner and robinson 2018 analytical solution indicate that present day heads may be sufficient to drive freshwater past argonaut for both the onshore and offshore data sets the calculated tip positions from the werner and robinson 2018 solution suggest that the low resistivity derived salinities observed in argonaut may be a result of relatively modern freshwater inputs from the onshore semi confined aquifer while the tip position predicted along the breaksea reef transect using onshore data indicates that freshwater driven by present day heads is capable of reaching the continental shelf the present day tip position calculated using offshore data is between breaksea reef and the coastline suggesting that present day onshore heads are unlikely to maintain the offshore freshwater evidenced by low pore water salinities observed in the resistivity data in its current location as the calculated pre development tip locations for both the onshore and offshore argonaut and breaksea reef data sets occur seaward of the respective well locations it is possible that pre development groundwater flows may have assisted in maintaining forming the brackish salinities identified from the downhole resistivity data as groundwater systems are slow to adapt to hydrological changes post et al 2013 it is questionable if the impact of modern changes to the onshore hydrology have reached these offshore well locations no data set for the copa transect generated an interface tip that reached the well location however this is in agreement with the resistivity derived salinity data as the calculated minimum tds for copa was 17 5 g l 1 50 of seawater concentration for comparison with the sharp interface analytical solution both the analytical modelling and the resistivity derived salinities support previous conceptual models of the offshore ge e g bush 2009 in that ofg in the ltca has both a paleo pre development component and an active flow component generated due to present day onshore conditions conceptual diagrams of the three transects modelled using the werner and robinson 2018 solution are presented in fig 6 in all three transects there is potential for submarine fresh groundwater discharge sfgd through the overlying confining unit for several kilometres offshore however as no faults were interpreted to extend through the entire overlying unconfined aquifer i e the uua this discharge is unlikely to form discrete discharge features on the seafloor the offshore extent of ofg emplaced under paleo and or pre development conditions is likely being reduced due to the landward movement of the saltwater freshwater interface caused by changes in the hydraulic conditions and through the diffusion of salt within the uta the variability between the tip and toe positions calculated using the onshore and offshore data sets are a result of the variations in z 0 h and d the depth of the overlying seawater is greater in the offshore data sets in the breaksea reef and copa transects 211 m and 97 m deeper respectively greater seawater depths result in milder offshore hydraulic gradients and therefore lower freshwater discharge rates because increased seawater depths impose greater equivalent freshwater heads on the subsea aquifer however in the argonaut transect a local offshore topographic high causes a shallower seawater depth i e 70 m shallower for the offshore dataset yet the calculated tip and toe positions for the transect using offshore data are landward of the tip and toe positions calculated from the transect using onshore data this suggests that variations in both h and d must also contribute to the landward shift in the tip and toe positions for the argonaut transect all transects generated from offshore data have smaller values of h and d than their onshore derived counterparts a thinning of the confining unit in the offshore data sets would increase the upwards freshwater leakage through the overlying aquitard in the analytical solution moving the interface shoreward the offshore data sets likely provide a better estimation of the tip position compared to that obtained using onshore data sets for the breaksea reef and copa transects as these data sets capture the thickness of the overlying water column offshore for the argonaut transect the thinner confining unit offshore results in a reduction in the calculated tip position and a reduced estimate of the steady state freshwater extent conversely when the toe is onshore or close to the shoreline in the ge it is likely that the onshore data sets provide better estimates of toe positions this is because the cross sections generated using offshore data may have z 0 values that differ significantly to that identified in the onshore data resulting in unrealistic calculated toe positions for some offshore transects e g the breaksea reef transect that uses offshore data has a toe 89 9 km onshore the different calculated interface tip positions for the onshore and offshore data sets show that variations in the hydro stratigraphy make a significant difference to the estimation of subsea interface locations and that the cross section used to calculate the interface ought to be chosen closest to the expected interface position e g onshore aquifer data for interfaces near the shoreline in offshore sloping semi confined aquifers failure to account for an increase in aquifer depth in the offshore extent has the potential to result in a significant over estimation of the tip and toe positions if only onshore data are considered in parameterising analytical solutions of the subsea interface 5 2 data limitations previous studies that have applied archie s law to obtain pore water salinities either assume a generic value of m for unconsolidated sediment e g pauw et al 2017 or adopt a single value from prior regional studies e g groen et al 2000 locally calibrated m values likely produce more reliable estimates of r f compared to those obtained from generic values of m additionally consideration of the uncertainty in m that accompanies calibrated values allows for an evaluation of the plausible range in offshore groundwater salinity values in the ltca m r was 1 40 with a σ m of 0 14 the difference between the calculated value of m r 1 40 and the standard value of 1 30 for unconsolidated sands archie 1942 is comparable to σ m this indicates that the local variability of m may be high and can have a significant impact on the uncertainty of the final salinity estimates additional uncertainty is introduced due to m r being calibrated from onshore petroleum exploration wells where drilling reports indicate that the drilling muds were freshwater based yet m r was applied to calculate salinities in offshore wells where drilling reports indicate that saltwater was used in the drilling mud while deep induction logs were used to minimise the influence of drilling induced freshening and or salinisation of both the invaded zone and borehole fluids the contrasting borehole drilling fluid salinities in the onshore and offshore wells may have resulted in the calculated offshore salinities being slightly more saline than the true values the assumption that the values of r f in the nearby onshore monitoring wells are the same as those in the onshore petroleum exploration wells where geophysical data are available generates additional uncertainty the adoption of r f values from nearby onshore monitoring wells was necessary as r f values were unavailable in the onshore petroleum exploration wells that contained the bulk resistivity and porosity data the estimates of offshore salinity also incorporate several other possible sources of uncertainty particularly surrounding the calculation of φ in the ge well completion reports note caving of the well walls in sandy zones of the ltca during drilling this caving may have caused the calculated porosities to be higher than those observed in the unperturbed ltca an overestimation of φ would cause the estimated salinities to be lower than the true values as both the uncorrected wyllie time average equation and the alternative raymer hunt gardner equation raymer et al 1980 return unrealistic porosities i e 0 55 the accuracy of the sonic log derived φ values is questionable this is despite the more recent raymer hunt gardner equation partially correcting for the impact of unconsolidated sediments on sonic velocity data as both methods originally returned unrealistic porosity estimates we adopted the wyllie time average approach because this method incorporates a mechanism to scale the sonic porosity values in unconsolidated sediments providing that other porosity data such as neutron density derived porosities are available to estimate correction factors however considerable uncertainty is likely to be present due this approach of estimating φ the tip and toe positions derived from the analytical model are associated with significant uncertainties these uncertainties arise primarily as a result of numerous simplifications made in the analytical solution that do not fully reflect the field conditions as discussed above the impact of the flat lying assumption is tested to some degree by the calculation of a tip and toe position for both onshore where the aquifer is generally shallower and offshore parameter sets the cross sections treat h and d as constant across the transect despite the hydro stratigraphic isopachs fig 3 showing that h and d vary spatially across the ge e g near argonaut the uta transitions from a thickness of 25 50 m to a thickness of 100 150 m over a distance of 5 km due to uncertainty surrounding the interpreted hydro stratigraphic unit thickness discussed below h and d in the offshore data sets were obtained from offshore geological well log data as a result the spatial variability in h and d was not captured and the effect of variability on tip and toe positions remains unclear in addition to regional variations in h and d the transects used to apply the analytical solution omit multiple shore parallel faults present in the ge the localised displacement of the hydro stratigraphic units associated with this faulting appears to generate several zones where the aquitard thins these zones of localised thinning generate the potential for increased freshwater saltwater mixing which if present may cause the analytical solution to over predict the ofg extent however to date the impact of a varying aquitard thickness on offshore salinities remains unstudied and the degree to which these fault based zones of aquitard thinning impact regional salinities is unknown the cross sectional models treat the ltca vertically as a single homogeneous unit as per previous regional studies e g love et al 1993 morgan et al 2015 this is contrary to the downhole geological well data indicating the ltca is comprised of several sandy layers interbedded with clay which may have significant thickness in places i e up to 85 m as the werner and robinson 2018 analytical solution is only applicable to the upper most semi confined aquifer it is unclear how this layering would affect the calculated interface position michael et al 2016 found that heterogeneity can result in freshwater driven by onshore heads occurring further offshore than expected in equivalent homogeneous aquifers however they did not include a semi confining unit overlying the homogeneous aquifer and as a result their findings apply to a different hydro stratigraphic arrangement to that adopted by werner and robinson 2018 the offshore stratigraphic interpretations also contain significant uncertainty the multiple sources of the seismic line survey data with variable information surrounding the acquisition parameters meant that obtaining a minimum vertical resolution was unachievable as a result it is likely that the interpreted truncations of the uta and ltca do not reflect their true locations as these units may extend beyond the interpreted end points albeit at thicknesses below those resolvable from the available seismic data confidence in the offshore stratigraphy interpretations is elevated in areas where well ties are possible particularly around seismic lines that contain multiple well ties uncertainty increases rapidly in the offshore direction as the shore parallel faulting results in vertical displacement of the seismic horizons increasing discontinuity in the traced surfaces lastly the seismic exclusion zone imposed between the shoreline and 5 km offshore creates additional uncertainty in the near shore region due to this zone onshore data were unable to be accurately connected to offshore interpretations 6 conclusions our analyses provide a rare demonstration of the significant uncertainty attached to pore water salinities calculated using archie s law archie 1942 due to variations of m we present a new adaptation of methods commonly used in the petroleum industry for establishing m and its variability to a coastal hydrogeological investigation in the ge σ m was comparable to the difference between m r and the m value commonly adopted for unconsolidated sands this highlights the importance of establishing the regional variability of m and not merely adopting the mean m we produced estimates of offshore salinity in the south australian portion of the gambier embayment ge though novel application of both onshore and offshore geophysical well data our analyses indicate that low salinity groundwater tds 2 2 g l 1 is likely to be present up to 13 5 km offshore in the south of the ge albeit there is large uncertainty surrounding this distance in the north of the ge calculated pore water salinities are higher this suggests that extensive ofg is likely restricted to the southern portion of the ge there appears to be a possible association between the offshore hydro stratigraphy and the calculated salinities with wells closer to terminations in the uta and ltca displaying higher salinities this may occur due to increased vertical freshwater saltwater mixing in areas where the ltca becomes connected to overlying seawater the seismic survey data suggests that the ltca around copa may be disconnected from the onshore system highlighting the need to view hydro stratigraphic and salinity data together to prevent unrealistic extrapolations of ofg bodies in areas where hydro stratigraphic variability precludes the seaward extent of ofg our analytical modelling indicates that while present day heads are predicted to drive freshwater significant distances offshore there is conceptual variability that when tested within the analytical modelling leads to significant differences in the estimates of ofg extent when onshore elevations and thicknesses of the aquifer and aquitard are used for present day conditions the calculated steady state tip position occurs seaward of the breaksea reef and argonaut wells when elevations and thicknesses that correspond to the offshore well information are used the calculated interface tip only extends past the well in the argonaut transect this indicates that present day onshore conditions have the potential to explain the occurrence of ofg at argonaut while a pre development ofg component is likely required to explain the calculated salinities at breaksea reef the large discrepancies between calculated tip positions depending on whether onshore or offshore data are used emphasises the need to account for the possible offshore slope of aquifer systems when estimating ofg extents through analytical methods our study presents evidence of a fourth australian site where ofg is encountered in offshore aquifers the approach adopted provides a unique example of applying multiple techniques to investigate the potential extent of ofg using onshore hydrochemical data legacy geophysical data and analytical modelling we were able to approximate offshore salinities including their uncertainty and offer hypotheses for ofg origins and influencing factors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank vincent post and leanne morgan for their initial feedback and suggestions simon holford for assistance with the seismic data and the south australian department for energy and mining for the provision of the seismic survey and petroleum well data we also gratefully acknowledge the suggestions of 3 anonymous reviewers andrew knight is supported by an australian government research training program scholarship adrian werner is the recipient of an australian research council future fellowship project number ft150100403 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 06 059 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6309,offshore fresh groundwater is increasingly suggested as a potential water resource for onshore human demands in many cases onshore pumping already draws significant fresh groundwater from offshore however offshore aquifers and the extent of offshore freshwater are usually poorly characterised due to data scarcity this study combines geophysical data hydraulic information and a first order mathematical analysis to investigate offshore freshwater extent in the gambier embayment australia a large seismic data set combined with onshore and offshore bore log geological profiles are used to explore the regional offshore hydro stratigraphy aquifer hydraulic parameters and onshore heads are obtained from onshore investigations a novel application of archie s law geophysical data and onshore hydrochemical data provide useful insights into the salinity profiles within four offshore wells these are compared to steady state sharp interface estimates of the freshwater extent obtained from a recently developed analytical solution albeit using simplified conceptual models salinities derived from resistivity measurements indicate that in the south of the study area pore water with total dissolved solids tds of 2 2 g l 1 is found up to 13 2 km offshore offshore pore water salinities are more saline in the northern areas most likely due to thinning of the offshore confining unit the analytical solution produced freshwater saltwater interface locations that were approximately consistent with the freshwater saltwater stratification in two of the offshore wells although analytical uncertainty is high this investigation provides a leading example of offshore freshwater evaluation applying multiple techniques demonstrating both the benefit and uncertainty of geophysical interpretation and analytical solutions of freshwater extent keywords offshore fresh groundwater seawater intrusion geophysics seismic data analytical solution 1 introduction increasing coastal populations and the impacts of a changing climate are predicted to threaten the freshwater resources of many coastal communities post et al 2013 michael et al 2017 several studies have suggested the use of fresh and brackish water contained within confined and semi confined submarine aquifers to assist in meeting the freshwater demands of coastal communities cohen et al 2010 bakken et al 2012 post et al 2013 jiao et al 2015 here we consider freshwater salinities as total dissolved solids tds 1 g l 1 while brackish water salinities are 1 g l 1 tds 10 g l 1 the landward movement of fresh and or brackish groundwater stored in subsea aquifers likely delays onshore seawater intrusion swi in several regions globally knight et al 2018 however as coastal groundwater investigations frequently focus on the onshore resources and coastal fringe processes more generally the behaviour of fresh groundwater within submarine aquifers remains understudied bratton 2010 post et al 2013 werner et al 2013 the occurrence of subsea freshwater and brackish water referred to collectively as offshore fresh groundwater ofg in what follows is thought to form through two main mechanisms firstly ofg can form where fresh groundwater discharges from an onshore confined or semi confined aquifer hereafter termed semi confined into the offshore continuation of the aquifer kooi and groen 2001 bakker 2006 secondly increased continental shelf exposure due to vastly different hydraulic conditions during glacial maxima in some cases leading to increased groundwater hydraulic gradients are thought to have facilitated the emplacement of freshwater in present day submarine aquifers cohen et al 2010 post et al 2013 morgan et al 2018 both mechanisms require an overlying aquitard to inhibit the rapid vertical mixing of fresh and saline waters that would otherwise occur due to the buoyancy forces induced from seawater overlying freshwater various methods have been applied to assess ofg reserves although there are few studies that adopt multiple techniques to characterise offshore aquifers for the purposes of freshwater exploration i e to estimate ofg extents direct observations of ofg include the sampling of pore water salinities from offshore core samples e g jiao et al 2015 and the sampling of pumped fluids from short screened intervals offshore e g krantz et al 2004 geophysical methods for characterising ofg include downhole deep induction resistivity logs and resistivity transect surveys e g oteri 1988 groen et al 2000 krantz et al 2004 hennig and otto 2005 the inverse relationship between resistivity and fluid salinity contained in archie s law archie 1942 can allow for freshwater to be inferred from both transect and downhole resistivity data however the method requires knowledge of porous medium resistivities leading to seldom reported uncertainties in the pore water resistivities calculated using archie s law there are limited documented studies investigating how regional variations in the hydro stratigraphy impact offshore salinities krantz et al 2004 used a combination of seismic resistivity and drill hole data from aquifers below indian river bay delaware usa to conclude that ofg can preferentially form within sand filled incised valleys that are silt capped with ofg within such channels able to reach several kilometres offshore mulligan et al 2007 identified that when the overlying confining unit is incised by paleo channels enhanced vertical flows resulting in increased freshwater saltwater mixing are likely pauw et al 2017 used onshore data and analytical modelling to demonstrate how shore parallel variability in the onshore hydro stratigraphy can alter the ofg extent michael et al 2016 used cross sectional numerical modelling to show that in comparison to a homogeneous aquifer freshwater can extend further offshore in aquifers that have strong vertical heterogeneity but well connected horizontal flow paths to date there is no study supported by offshore data that investigates the potential alongshore variability of ofg extent on a regional scale despite the fact that ofg is considered to be widespread post et al 2013 only three ofg bodies are evidenced by offshore data from the australian continental shelf i e perth basin hennig and otto 2005 morgan et al 2018 adelaide plains sub basin knight et al 2018 and gippsland basin varma and michael 2012 in all cases ofg has been found adjacent to significant onshore pumping which is thought to be mining offshore freshwater to supplement onshore demands knight et al 2018 in the gambier embayment ge located in the southeast of south australia fig 1 groundwater supports extensive irrigation schemes and provides water supplies for three coastal towns previous studies of the ge suggest that local head conditions in the regional semi confined aquifer may be conducive to the formation of an extensive ofg body e g pollock 2003 bush 2009 morgan et al 2015 although the occurrence and magnitude of this resource are currently unsubstantiated previous studies of the ge by pollock 2003 and bush 2009 include offshore interpretations of the main regional semi confined aquifer i e the lower tertiary confined aquifer ltca however digital copies of the lithological surfaces presented by pollock 2003 are no longer available and do not separate the ltca from the overlying confining unit the hydro stratigraphic surfaces presented by bush 2009 terminate at the offshore petroleum exploration well herein referred to as offshore wells locations despite the system extending tens of kilometres past the well locations neither of these previous seismic studies have generated the hydro stratigraphic surfaces required to assess the extent of ofg in the ge this study aims to provide a best estimate of offshore pore water salinities in the regional semi confined aquifer of the ge using available data and through application of the analytical solution of werner and robinson 2018 the study also aims to identify the offshore distribution of the upper semi confined aquifer in the ge at least at a resolution reasonable for the large scale of the study area using seismic line survey data knowledge of the offshore hydro stratigraphy is vital for understanding potential offshore groundwater fluxes for the interpretation of calculated offshore salinities and to inform the application of analytical approaches we aim to establish offshore salinities in the regional semi confined aquifer of the ge using legacy downhole geophysical data from both onshore and offshore petroleum exploration wells this study represents the first attempt at using onshore salinity resistivity relationships to inform the offshore application and uncertainties of archie s law with the aim of inferring groundwater salinities and the extent of ofg we compare the salinities calculated from geophysical data against those predicted by analytical modelling to explore the potential influence of present day hydrological forcing the werner and robinson 2018 analytical solution is applied to a range of conceptual models each representing simplified versions of the offshore conditions of the ge as determined from available field data 2 study area the ge is the western sub basin of the otway basin an extensive passive rift sag rift basin boult and hibburt 2002 that reaches the city of melbourne some 500 km east of the south australian victorian border fig 1 the ge is bounded in the northwest by the tartwaup hinge zone and in the southeast by the portland trough freeman et al 2010 the offshore regions of the basin are heavily faulted offshore fault lines are generally steeply dipping towards the southwest and have a northwest southeast strike freeman et al 2010 holford et al 2014 clarke et al 2015 previous studies of the ge have identified three hydro stratigraphic units of importance to anthropogenic activities love et al 1993 smith et al 2012 morgan et al 2015 clarke et al 2015 these are 1 an upper unconfined aquifer uua comprised primarily of the gambier limestone 2 an upper tertiary aquitard uta consisting of marl intervals and the upper clay layer of the dilwyn formation and 3 a lower tertiary confined aquifer ltca which encompasses several interbedded and generally unconsolidated sand and carbonaceous clay layers of the dilwyn formation clarke et al 2015 the uua uta and ltca are primarily offshore dipping these units reach a maximum combined thickness of 1 km in the south of the study area and thin towards the north love et al 1993 previous onshore investigations of the ge assume a lower hydro stratigraphic boundary consisting of the lower clay unit of the dilwyn formation in the south and the sherbrook formation comprising interbedded sands and clays in the north morgan et al 2015 this lower boundary is based on the assumption that current anthropogenic activities are unlikely to interact with water contained in the sherbrook formation morgan et al 2015 we adopt the same assumption in our study 3 methods 3 1 offshore stratigraphy from seismic line surveys in the offshore region of the ge 32 shore perpendicular seismic lines and 19 shore parallel seismic lines were selected for the interpretation of the offshore stratigraphy seismic and geophysical well data were obtained from the south australian government department of the premier and cabinet energy resources division j davies 2017 pers comm 14 december 2017 to generate a regional scale model of the offshore distributions of the uua uta and ltca seismic line surveys were selected at 3 km spacings in both the shore parallel and shore perpendicular directions where possible seismic lines that include multiple well ties i e passing through one or more wells from which downhole lithology has been recorded were chosen seismic data are of varying quality and were acquired at different times consequently it was not possible to determine a minimum resolvable vertical resolution that could be applied to the entire data set however previous work using the same data found that seismic reflectors are clearly imaged for units with a two way travel time twt under 2000 ms freeman et al 2010 the seismic line survey data contain no information within 5 km of the shoreline due to a regulatory exclusion zone we adopt the methodology used by pollock 2003 for the interpretation of the hydro stratigraphic horizons the top of the uua uta ltca and the sherbrook formation were selected to characterise the regional hydro stratigraphy as seismic line surveys have a vertical axis measured in the time domain a conversion between the measured twt and depth is required to identify the target horizons on downhole lithology logs a regional depth to twt relationship of z 1132 twt1 2678 r2 of 0 99 was obtained from regression of the available synthetic seismogram data i e measured twt values at set depths from the breaksea reef chama and copa wells see fig 1 for well locations we use the elevation datum m ahd metres australian height datum where 0 m ahd is approximately mean sea level the interpreted seismic horizons for the ltca were compared against the available hard copy data presented by pollock 2003 to ensure that the interpreted seismic sections were equivalent natural neighbour interpolation was used to generate continuous surfaces for each hydro stratigraphic unit natural neighbour interpolation was selected due to the linear and clustered characteristics of the seismic line survey data the input data consisted of both offshore data points obtained from the tracing of the seismic line surveys and onshore data points acquired from morgan et al 2015 a cell size of 500 m was selected due to the large scale of the study area the surfaces representing the top of the uta and ltca were clipped to honour the extents of these units interpreted from the seismic line surveys as this study focuses on the ltca the extents of the uua and pseudo basement surfaces were restricted to an arbitrarily chosen 10 km from the spatial limits of the available data as beyond this distance the surfaces are unlikely to be realistic 3 2 calculating offshore groundwater salinities from geophysical borehole logs 3 2 1 obtaining regional parameters for application of archie s law archie s law archie 1942 is an empirically derived relationship that allows for the calculation of fluid resistivity r f ω m from a measured bulk resistivity r o ω m in formations with a relatively non conductive matrix e g sand free from clay minerals archie 1942 proposed that r f r o porosity i e total porosity φ and a cementation exponent m can be related using 1 r o r f φ m in archie s law m is related to the degree of connectedness of the pore network glover 2009 a value of m 1 represents a bundle of capillary tubes with all pore spaces connected while higher values e g 2 5 to 5 represent carbonates with poorly connected pore spaces glover 2009 typical values of m for sandstone range from 1 3 to 2 6 archie 1942 values of m are usually established by taking the best fit slope through a plot of log r o r f versus log φ or through re arranging eq 1 to solve for m directly glover 2016 despite extensive petroleum exploration within the ge no pre existing values of m have been reported within the available literature values of m were obtained by applying eq 1 to five onshore petroleum exploration wells fig 1 where r o and lithological data were available however values of r f in the ltca were unavailable in all the petroleum exploration wells both onshore and offshore in addition no onshore monitoring wells had both φ and r o data recorded in the ltca to apply eq 1 to the onshore petroleum exploration wells values of r f corrected to 25 c were adopted from the nearest short screened onshore monitoring well in the ltca with hydrochemical data available dew 2019 groundwater salinity measurements elsewhere within the onshore region of the ltca have low variability over distances similar to the distances between the groundwater monitoring wells where r f values were obtained and the onshore petroleum exploration wells for example the recorded tds changed by 25 mg l 1 between two onshore monitoring wells well 7022 7871 and well 7021 3339 that were 10 km apart the distances between the petroleum exploration wells and the onshore monitoring wells were under 10 km as r f data were only available for the upper sand interval of the ltca r o data were also restricted to this interval the upper sand intervals of the onshore petroleum wells were at similar depths to the screened interval depths in the onshore monitoring wells from which r f data were obtained upper clean sand horizons in each well were identified from downhole lithological descriptions with gamma ray logs used to discern clean sands from those with significant clay using this approach the ge was found to have clean sand horizons with a gamma ray signature of 25 api lithological descriptions for ltca sand horizons and the data available for each of the wells used in this study are presented in the supplementary material table s1 as a variable number of geophysical data points were available within the upper sand horizon in each well the mean m value for each onshore petroleum exploration well m w was obtained the regional value for the ltca of m m r was obtained by taking the mean of the m w values the standard deviation of m r σ m was also obtained porosity can be estimated from both bulk density and sonic logs of the wells included in this study only argonaut and chama have both bulk density and sonic logs in the targeted hydro stratigraphic units except for the copa well all wells both onshore and offshore have sonic log data a regional value of porosity was used in the application of eq 1 to the copa data because both sonic and bulk density logs were absent at the depths of interest to this study in the argonaut and chama wells where both sonic and density data were available porosity was preferentially determined for each data point from bulk density logs according to 2 φ b ρ m ρ b ρ m ρ w where φ b is the bulk density derived porosity ρ m is the density of the solid matrix 2650 kg m 3 e g groen et al 2000 ρ b is the measured bulk density of the saturated porous media kg m 3 and ρ w is the density of water 1000 kg m 3 excluding the argonaut chama and copa wells porosity was determined for each ltca data point representing clean sand from sonic log data using the wyllie time average equation wyllie et al 1958 3 φ s δ t z δ t m a δ t f δ t m a where φ s is the sonic derived porosity δt z is the measured acoustic transit time i e the time taken for the seismic wave to travel a unit distance μs m 1 δt ma is the acoustic transit time of the rock matrix 192 9 μs m 1 taken from well completion reports and δt f is the acoustic transit time of interstitial fluids a value of 616 μs m 1 was adopted from the well completion reports as sonic porosities in unconsolidated sediments tend to overestimate the total porosity the sonic porosity was divided by a correction factor c p calculated using raymer et al 1980 4 c p φ s φ the regional value of c p for the ge was taken as the mean c p from the argonaut and chama wells for which φ s were available and φ could be approximated as φ b values in copa neither sonic nor bulk density logs were available in the ltca to enable the application of eq 1 to the copa well data a single regional ltca φ value was established by taking the mean of the calculated φ values of all data points in the ltca sand layers using data from the other eight wells both onshore and offshore included in this study as electrical resistivity is dependent on temperature r o was converted to equivalent values at a standard temperature of 25 c using jorgensen 1996 5 r 25 z 1 8 t z 39 84 r o z where r 25 z is the bulk resistivity ω m adjusted to 25 c at depth z r o z is the bulk resistivity ω m measured at depth z and t z is the temperature c at depth z m t z is calculated from the local geothermal profile obtained from drilling completion reports of 6 t z 0 2759 z 19 3 2 2 calculating offshore salinity profiles the downhole r f profiles of four offshore wells in the ge were calculated by applying a re arranged form of eq 1 to temperature corrected resistivity data from each well temperature corrections were undertaken using eq 5 to identify the possible r f values due to uncertainty surrounding the estimation of m r pore water resistivities were calculated from eq 1 using m values of m r m r 1σ m and m r 2σ m the calculated fluid resistivities were converted to an approximate tds mg l 1 at depth z using an empirically derived relationship of 7 tds z 10 000 0 55 r f a mean tds value for each sand interval tds was established by averaging the calculated pore water salinities of all the data points contained within each respective sand interval this was repeated to obtain tds values for all sand intervals and using alternative values of m i e m r m r 1σ m and m r 2σ m 3 3 sharp interface analytical modelling of present day steady state conditions to explore the possible ofg extent attributable to present day ofg inflows in the ltca the analytical solution of werner and robinson 2018 was applied to three simplified shore normal transects the werner and robinson 2018 solution assumes that the aquifer is flat lying isotropic homogeneous of constant thickness and is confined onshore and semi confined offshore the solution also assumes that 1 the system is at steady state with respect to onshore heads 2 the freshwater saltwater interface can be represented by a line of pressure equilibrium i e a sharp interface 3 shore parallel flow is negligible and 4 vertical freshwater flow in the aquifer can be neglected while horizontal flow in the semi confining unit is ignored the modelled transects pass through the breaksea reef argonaut and copa wells fig 1 as the interpreted seismic line survey data indicated that the ltca and uta are not continuous between the onshore environment and chama the analytical solution of werner and robinson 2018 cannot be applied to investigate the potential salinity at chama from current onshore conditions also the top of the ltca has an offshore slope of around 1 on average whereas the analytical solution assumes that the aquifer is horizontal to account for this two different sets of geometric conditions aquifer depth and thickness were used in applying the analytical solution to each transect namely 1 reflecting the conditions at the shoreline and 2 reflecting the conditions at the offshore wells the werner and robinson 2018 solution requires the hydraulic conductivity k of the aquifer k a m d 1 the thickness of the aquifer h the thickness of the semi confining unit d a specified head h b at a distance onshore x b the vertical k of the semi confining unit k l m d 1 the length of the offshore semi confining unit l s the depth to the base of the semi confined aquifer below sea level z 0 and the densities of fresh ρ f kg m 3 and saline water ρ s kg m 3 the werner and robinson 2018 solution allows for the designation of the pore water salinity of the semi confining unit which in this case was set to freshwater following the recommendation of solórzano rivas and werner 2017 the parameter sets applied to the werner and robinson 2018 solution are listed in table 1 parameters obtained from the offshore wells are denoted by an asterisk otherwise parameters reflect onshore data the analytical solution was applied to both present day and pre development heads h b and h b p respectively in the onshore aquifer values for h b p are approximate only and were estimated by extrapolation based on temporal head slopes from earliest recordings typically in the 1970s the tip and the toe where the freshwater saltwater interface coincides with the aquifer top and bottom respectively were obtained by applying the parameters in table 1 to the analytical solution resistivity derived salinities of tds 17 5 g l 1 50 of seawater were used to compare to the tip and toe positions calculated using the sharp interface analytical solution in the same manner as previous publications e g werner 2017 4 results 4 1 offshore hydro stratigraphy the horizons traced in the seismic line surveys show evidence of extensive shore parallel faulting within the offshore hydro stratigraphic units fault induced displacement appears to have led to localised thinning of the uta in several survey lines the interpreted seismic horizons corresponding to the hydro stratigraphic units for the uta and the ltca indicate that the respective units either pinch out underneath the uua at the continental slope or remain covered by the uua rather than terminating at the seafloor an example of this is visible in fig 2 a the northern offshore extent of the uta and ltca was determined by considering that these two units appear to onlap i e pinch out against a local high in the underlying sherbrook formation fig 2b causing the interpreted units to become discontinuous an example of this onlap is highlighted in fig 2b other seismic line surveys that pass through chama appear to show similar onlap against the sherbrook formation in other directions outwards from the chama well see fig 3 a this suggests that the uta and ltca recorded in the downhole lithological log at chama are disconnected from their onshore counterparts fig 2a also provides an interpreted cross section of the aquifers of interest to this investigation two additional interpreted cross sections are provided in the supplementary material fig s1 the isopach distribution for the uta and ltca are shown in fig 3 while both the interpolation process and the large cell size chosen acted to dampen high frequency features e g sharp fault driven elevation changes in the interpolated offshore hydro stratigraphic surfaces there is still noticeable variability regionally in the offshore thickness of the uta and ltca south of argonaut the calculated thickness of the uta fig 3a varies predominantly between 50 m and 150 m north of argonaut the uta is mainly 25 m to 100 m thick the ltca also displays increased thickness south of argonaut fig 3b with thicknesses predominantly between 450 m and 1145 m thick north of argonaut the ltca thins to between 100 m and 550 m this northward thinning is also visible in the three interpreted cross sections presented in the supplementary materials fig s1 three paleo channel features described by pollock 2003 were interpreted to incise through the uta and into the ltca close to the continental slope fig 3a with the largest of these paleo channels occurring midway between copa and argonaut as these paleo channels incise through the uta they may reduce the semi confined offshore extent of the ltca and lead to saltwater entering the aquifer preferentially from above two maps that display the top of the uta and ltca are presented in the supplementary material figs s2 and s3 4 2 establishing regional parameters for archie s law using the onshore petroleum exploration well data an m r value of 1 40 and a σ m of 0 14 were obtained the regional value of c p established from paired sonic and density logs was 1 74 the available density and corrected sonic data produced an average φ of 0 37 along with σ φ standard deviation of the calculated porosities for ltca clean sand intervals extracted from the other eight wells included in this study of 0 068 there was no clear relationship between φ and depth or between m and depth these data are presented in the supplementary material figs s4 and s5 4 3 offshore salinity profiles from geophysical data fig 4 a shows the tds values for each r o measurement limited to sand intervals in the argonaut well despite substantial tds variability the two shallower sand intervals show distinctly lower tds values than the two deeper sand intervals there is significant scattering of tds values within each sand layer this scattering is greater in the two lower sand intervals where calculated tds values are higher the observed scattering of the calculated tds values in an individual sand layer was due to fluctuations in both φ and r o with depth this suggests that a single calculated tds value is unlikely to be representative of the pore water salinities that would be encountered across the entire sand interval the mean values of tds tds for each sand layer in the four offshore wells of interest argonaut breaksea reef chama and copa are presented in fig 5 tds calculated using m r m r σ m and m r 2 σ m are shown for each sand interval the wells ranked in order of the lowest salinity groundwater encountered in each well are argonaut breaksea reef chama and copa the salinities within the copa well are the highest with tds in the ltca ranging between 22 2 g l 1 and 30 9 g l 1 the distinctive increase in tds with depth that is apparent at argonaut fig 4a can also be found in the breaksea reef chama and copa wells although without the same well defined salinity stratification of the argonaut data for example the breaksea reef data reveal elevated salinities in the uppermost sand interval for which tds is 11 2 g l 1 while the two underlying sand intervals have a tds of 3 8 g l 1 and 4 2 g l 1 respectively salinities appear to increase with depth thereafter with the deepest sand interval in the breaksea reef well having a tds of 14 7 g l 1 in argonaut salinities increase with depth within the ltca with a tds of 2 2 g l 1 calculated for the shallowest sand interval while the deepest sand interval in the ltca has a tds of 22 9 g l 1 in the chama well salinity in the ltca also increases with depth ranging from 13 1 g l 1 in the shallowest sand interval to 45 9 g l 1 in the deepest sand interval there were no sand intervals in copa that had a tds under 22 2 g l 1 4 4 analytical modelling the interface tip and toe positions calculated using analytical methods for three transects passing through the breaksea reef argonaut and copa wells are listed in table 2 four sets of tip and toe positions were produced for each transect using the werner and robinson 2018 solution in accordance with present day and pre development conditions and using cross sections based on onshore and offshore hydro stratigraphic data according to table 2 calculated toe positions are shoreward of respective well locations for all simulated cases and therefore the analytical solution suggests that seawater is at least partly expected to occur in all wells there is an underlying presumption here that offshore freshwater seawater conditions are in equilibrium with present day or pre development conditions in onshore aquifers this is discussed further in later subsections in the breaksea reef transect the application of the analytical solution to present day conditions produces interface tips that are 33 9 km and 10 6 km offshore for the onshore and offshore data sets respectively the calculated present day steady state tip positions for the argonaut and copa transects follow a similar pattern with the interface tip calculated using the offshore data shoreward of those calculated using the onshore data that is tip positions from offshore based aquifer geometries were shoreward of those obtained from onshore geometries by 2 7 km and 8 3 km for argonaut and copa respectively the tip positions calculated from the present day onshore data sets for breaksea reef and argonaut both reach the offshore boundary of the semi confined aquifer when the werner and robinson 2018 analytical solution was applied to the pre development data sets for breaksea reef and argonaut the calculated tip reached the offshore boundary for both the onshore and offshore data sets the analytical solution suggests that under steady state conditions present day onshore heads are capable of driving freshwater past the argonaut well for both the onshore and offshore parameter sets for the transect passing through breaksea reef the onshore parameter set indicates that modern heads are sufficient to drive freshwater seaward of the well location while the offshore parameter set places the tip 2 km shoreward of the well in the copa transect the calculated pre development tip positions are seaward of their present day counterparts as expected given the higher pre development head however pre development tip locations are shoreward of the copa well location indicating only seawater in the aquifer at the copa well location for both the onshore and offshore data sets modern heads were also insufficient to drive freshwater to copa for either parameter set 5 discussion 5 1 offshore salinities of the ge while potable tds 1 g l 1 water was not identified in the offshore wells included in this study the low calculated salinities tds 2 2 g l 1 up to 13 5 km offshore suggest that in the south of the ge potable water may extend a significant distance offshore these results support the inferences of earlier work pollock 2003 bush 2009 morgan et al 2015 that there is a potential for ofg in the ge the downhole salinity profiles within the ltca in breaksea reef and argonaut are typical of those observed in other ofg bodies e g groen et al 2000 cohen et al 2010 post et al 2013 in which the salinity generally increases with depth albeit the transition is not necessarily smooth the sand intervals in copa return lower resistivity values than the surrounding clay intervals data not shown under constant pore water salinities clays typically return lower resistivity values than sands waxman and smits 1968 and therefore the clay pore water is potentially fresher than that in the adjacent sand intervals this may indicate that clays contained entrapped fresher pore water as might occur when more permeable sands salinise due to the landward movement of saline groundwater e g due to falling onshore heads the observation that clays likely contained fresher water than overlying underlying sand units may provide useful information on transient interface movements in future investigations of the ge offshore domain using the value of m r obtained from the ltca sand layers preliminary investigations of the possible pore water salinities in the underlying sherbrook formation were also undertaken however as m r was established for the ltca these values have higher uncertainty an expanded version of fig 5 that includes approximate pore water salinities of the upper sherbrook formation is presented in the supplementary material fig s6 except for a single sand layer in chama that has a tds of 11 1 g l 1 the sand layers in the underlying sherbrook formation have approximate calculated tds values in the saline range i e tds between 16 7 g l 1 and 46 9 g l 1 no clear relationships between salinity and depth are apparent in the tds values for the sand layers of the sherbrook formation the two separate zones of near brackish water tds values of 11 1 g l 1 and 13 1 g l 1 in the downhole salinity profile for chama fig s6d do not conform to the salinity profile expected if these two zones are hydraulically connected and or maintained through freshwater flow driven by present day onshore heads if the two units were hydraulically connected then buoyancy forces due to density contrasts between fresh and saltwater would cause the brackish water in the lower zone to migrate upwards therefore it appears that some separation between units of differing hydraulic conductivity is apparent around chama the two southern wells breaksea reef and argonaut that contain fresher pore water are both closer to the shoreline and further from any termination of the uta than the two northern wells for example the more saline copa well is 2 km from the interpreted northern offshore termination of the uta if the ltca is in contact with the uua along this zone due to the lack of uta aquitard between the two aquifers ltca and uua e g fig 2b increased groundwater mixing may occur similar enhanced mixing due to the incision of submarine paleo channels through overlying semi confining units is described by mulligan et al 2007 this presumes that the overlying uua is saline which is evident from consistently low resistivity values in the downhole resistivity logs the three paleo channel features identified in the seismic line surveys are situated at significant distance 19 km from the offshore wells and are therefore unlikely to have a significant impact on the calculated downhole salinities the steady state ofg extents calculated using the werner and robinson 2018 analytical solution indicate that present day heads may be sufficient to drive freshwater past argonaut for both the onshore and offshore data sets the calculated tip positions from the werner and robinson 2018 solution suggest that the low resistivity derived salinities observed in argonaut may be a result of relatively modern freshwater inputs from the onshore semi confined aquifer while the tip position predicted along the breaksea reef transect using onshore data indicates that freshwater driven by present day heads is capable of reaching the continental shelf the present day tip position calculated using offshore data is between breaksea reef and the coastline suggesting that present day onshore heads are unlikely to maintain the offshore freshwater evidenced by low pore water salinities observed in the resistivity data in its current location as the calculated pre development tip locations for both the onshore and offshore argonaut and breaksea reef data sets occur seaward of the respective well locations it is possible that pre development groundwater flows may have assisted in maintaining forming the brackish salinities identified from the downhole resistivity data as groundwater systems are slow to adapt to hydrological changes post et al 2013 it is questionable if the impact of modern changes to the onshore hydrology have reached these offshore well locations no data set for the copa transect generated an interface tip that reached the well location however this is in agreement with the resistivity derived salinity data as the calculated minimum tds for copa was 17 5 g l 1 50 of seawater concentration for comparison with the sharp interface analytical solution both the analytical modelling and the resistivity derived salinities support previous conceptual models of the offshore ge e g bush 2009 in that ofg in the ltca has both a paleo pre development component and an active flow component generated due to present day onshore conditions conceptual diagrams of the three transects modelled using the werner and robinson 2018 solution are presented in fig 6 in all three transects there is potential for submarine fresh groundwater discharge sfgd through the overlying confining unit for several kilometres offshore however as no faults were interpreted to extend through the entire overlying unconfined aquifer i e the uua this discharge is unlikely to form discrete discharge features on the seafloor the offshore extent of ofg emplaced under paleo and or pre development conditions is likely being reduced due to the landward movement of the saltwater freshwater interface caused by changes in the hydraulic conditions and through the diffusion of salt within the uta the variability between the tip and toe positions calculated using the onshore and offshore data sets are a result of the variations in z 0 h and d the depth of the overlying seawater is greater in the offshore data sets in the breaksea reef and copa transects 211 m and 97 m deeper respectively greater seawater depths result in milder offshore hydraulic gradients and therefore lower freshwater discharge rates because increased seawater depths impose greater equivalent freshwater heads on the subsea aquifer however in the argonaut transect a local offshore topographic high causes a shallower seawater depth i e 70 m shallower for the offshore dataset yet the calculated tip and toe positions for the transect using offshore data are landward of the tip and toe positions calculated from the transect using onshore data this suggests that variations in both h and d must also contribute to the landward shift in the tip and toe positions for the argonaut transect all transects generated from offshore data have smaller values of h and d than their onshore derived counterparts a thinning of the confining unit in the offshore data sets would increase the upwards freshwater leakage through the overlying aquitard in the analytical solution moving the interface shoreward the offshore data sets likely provide a better estimation of the tip position compared to that obtained using onshore data sets for the breaksea reef and copa transects as these data sets capture the thickness of the overlying water column offshore for the argonaut transect the thinner confining unit offshore results in a reduction in the calculated tip position and a reduced estimate of the steady state freshwater extent conversely when the toe is onshore or close to the shoreline in the ge it is likely that the onshore data sets provide better estimates of toe positions this is because the cross sections generated using offshore data may have z 0 values that differ significantly to that identified in the onshore data resulting in unrealistic calculated toe positions for some offshore transects e g the breaksea reef transect that uses offshore data has a toe 89 9 km onshore the different calculated interface tip positions for the onshore and offshore data sets show that variations in the hydro stratigraphy make a significant difference to the estimation of subsea interface locations and that the cross section used to calculate the interface ought to be chosen closest to the expected interface position e g onshore aquifer data for interfaces near the shoreline in offshore sloping semi confined aquifers failure to account for an increase in aquifer depth in the offshore extent has the potential to result in a significant over estimation of the tip and toe positions if only onshore data are considered in parameterising analytical solutions of the subsea interface 5 2 data limitations previous studies that have applied archie s law to obtain pore water salinities either assume a generic value of m for unconsolidated sediment e g pauw et al 2017 or adopt a single value from prior regional studies e g groen et al 2000 locally calibrated m values likely produce more reliable estimates of r f compared to those obtained from generic values of m additionally consideration of the uncertainty in m that accompanies calibrated values allows for an evaluation of the plausible range in offshore groundwater salinity values in the ltca m r was 1 40 with a σ m of 0 14 the difference between the calculated value of m r 1 40 and the standard value of 1 30 for unconsolidated sands archie 1942 is comparable to σ m this indicates that the local variability of m may be high and can have a significant impact on the uncertainty of the final salinity estimates additional uncertainty is introduced due to m r being calibrated from onshore petroleum exploration wells where drilling reports indicate that the drilling muds were freshwater based yet m r was applied to calculate salinities in offshore wells where drilling reports indicate that saltwater was used in the drilling mud while deep induction logs were used to minimise the influence of drilling induced freshening and or salinisation of both the invaded zone and borehole fluids the contrasting borehole drilling fluid salinities in the onshore and offshore wells may have resulted in the calculated offshore salinities being slightly more saline than the true values the assumption that the values of r f in the nearby onshore monitoring wells are the same as those in the onshore petroleum exploration wells where geophysical data are available generates additional uncertainty the adoption of r f values from nearby onshore monitoring wells was necessary as r f values were unavailable in the onshore petroleum exploration wells that contained the bulk resistivity and porosity data the estimates of offshore salinity also incorporate several other possible sources of uncertainty particularly surrounding the calculation of φ in the ge well completion reports note caving of the well walls in sandy zones of the ltca during drilling this caving may have caused the calculated porosities to be higher than those observed in the unperturbed ltca an overestimation of φ would cause the estimated salinities to be lower than the true values as both the uncorrected wyllie time average equation and the alternative raymer hunt gardner equation raymer et al 1980 return unrealistic porosities i e 0 55 the accuracy of the sonic log derived φ values is questionable this is despite the more recent raymer hunt gardner equation partially correcting for the impact of unconsolidated sediments on sonic velocity data as both methods originally returned unrealistic porosity estimates we adopted the wyllie time average approach because this method incorporates a mechanism to scale the sonic porosity values in unconsolidated sediments providing that other porosity data such as neutron density derived porosities are available to estimate correction factors however considerable uncertainty is likely to be present due this approach of estimating φ the tip and toe positions derived from the analytical model are associated with significant uncertainties these uncertainties arise primarily as a result of numerous simplifications made in the analytical solution that do not fully reflect the field conditions as discussed above the impact of the flat lying assumption is tested to some degree by the calculation of a tip and toe position for both onshore where the aquifer is generally shallower and offshore parameter sets the cross sections treat h and d as constant across the transect despite the hydro stratigraphic isopachs fig 3 showing that h and d vary spatially across the ge e g near argonaut the uta transitions from a thickness of 25 50 m to a thickness of 100 150 m over a distance of 5 km due to uncertainty surrounding the interpreted hydro stratigraphic unit thickness discussed below h and d in the offshore data sets were obtained from offshore geological well log data as a result the spatial variability in h and d was not captured and the effect of variability on tip and toe positions remains unclear in addition to regional variations in h and d the transects used to apply the analytical solution omit multiple shore parallel faults present in the ge the localised displacement of the hydro stratigraphic units associated with this faulting appears to generate several zones where the aquitard thins these zones of localised thinning generate the potential for increased freshwater saltwater mixing which if present may cause the analytical solution to over predict the ofg extent however to date the impact of a varying aquitard thickness on offshore salinities remains unstudied and the degree to which these fault based zones of aquitard thinning impact regional salinities is unknown the cross sectional models treat the ltca vertically as a single homogeneous unit as per previous regional studies e g love et al 1993 morgan et al 2015 this is contrary to the downhole geological well data indicating the ltca is comprised of several sandy layers interbedded with clay which may have significant thickness in places i e up to 85 m as the werner and robinson 2018 analytical solution is only applicable to the upper most semi confined aquifer it is unclear how this layering would affect the calculated interface position michael et al 2016 found that heterogeneity can result in freshwater driven by onshore heads occurring further offshore than expected in equivalent homogeneous aquifers however they did not include a semi confining unit overlying the homogeneous aquifer and as a result their findings apply to a different hydro stratigraphic arrangement to that adopted by werner and robinson 2018 the offshore stratigraphic interpretations also contain significant uncertainty the multiple sources of the seismic line survey data with variable information surrounding the acquisition parameters meant that obtaining a minimum vertical resolution was unachievable as a result it is likely that the interpreted truncations of the uta and ltca do not reflect their true locations as these units may extend beyond the interpreted end points albeit at thicknesses below those resolvable from the available seismic data confidence in the offshore stratigraphy interpretations is elevated in areas where well ties are possible particularly around seismic lines that contain multiple well ties uncertainty increases rapidly in the offshore direction as the shore parallel faulting results in vertical displacement of the seismic horizons increasing discontinuity in the traced surfaces lastly the seismic exclusion zone imposed between the shoreline and 5 km offshore creates additional uncertainty in the near shore region due to this zone onshore data were unable to be accurately connected to offshore interpretations 6 conclusions our analyses provide a rare demonstration of the significant uncertainty attached to pore water salinities calculated using archie s law archie 1942 due to variations of m we present a new adaptation of methods commonly used in the petroleum industry for establishing m and its variability to a coastal hydrogeological investigation in the ge σ m was comparable to the difference between m r and the m value commonly adopted for unconsolidated sands this highlights the importance of establishing the regional variability of m and not merely adopting the mean m we produced estimates of offshore salinity in the south australian portion of the gambier embayment ge though novel application of both onshore and offshore geophysical well data our analyses indicate that low salinity groundwater tds 2 2 g l 1 is likely to be present up to 13 5 km offshore in the south of the ge albeit there is large uncertainty surrounding this distance in the north of the ge calculated pore water salinities are higher this suggests that extensive ofg is likely restricted to the southern portion of the ge there appears to be a possible association between the offshore hydro stratigraphy and the calculated salinities with wells closer to terminations in the uta and ltca displaying higher salinities this may occur due to increased vertical freshwater saltwater mixing in areas where the ltca becomes connected to overlying seawater the seismic survey data suggests that the ltca around copa may be disconnected from the onshore system highlighting the need to view hydro stratigraphic and salinity data together to prevent unrealistic extrapolations of ofg bodies in areas where hydro stratigraphic variability precludes the seaward extent of ofg our analytical modelling indicates that while present day heads are predicted to drive freshwater significant distances offshore there is conceptual variability that when tested within the analytical modelling leads to significant differences in the estimates of ofg extent when onshore elevations and thicknesses of the aquifer and aquitard are used for present day conditions the calculated steady state tip position occurs seaward of the breaksea reef and argonaut wells when elevations and thicknesses that correspond to the offshore well information are used the calculated interface tip only extends past the well in the argonaut transect this indicates that present day onshore conditions have the potential to explain the occurrence of ofg at argonaut while a pre development ofg component is likely required to explain the calculated salinities at breaksea reef the large discrepancies between calculated tip positions depending on whether onshore or offshore data are used emphasises the need to account for the possible offshore slope of aquifer systems when estimating ofg extents through analytical methods our study presents evidence of a fourth australian site where ofg is encountered in offshore aquifers the approach adopted provides a unique example of applying multiple techniques to investigate the potential extent of ofg using onshore hydrochemical data legacy geophysical data and analytical modelling we were able to approximate offshore salinities including their uncertainty and offer hypotheses for ofg origins and influencing factors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors thank vincent post and leanne morgan for their initial feedback and suggestions simon holford for assistance with the seismic data and the south australian department for energy and mining for the provision of the seismic survey and petroleum well data we also gratefully acknowledge the suggestions of 3 anonymous reviewers andrew knight is supported by an australian government research training program scholarship adrian werner is the recipient of an australian research council future fellowship project number ft150100403 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 06 059 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
