index,text
1695,monitoring the water level and volume changes of lakes and reservoirs is essential for deepening our understanding of the temporal and spatial dynamics of water resources in the yellow river basin with a view to better utilizing and managing water resources in recent years there have been many studies on monitoring water level and volume changes in inland waters but they were mainly focused on radar altimetry and the full waveform lidar icesat which was retired in 2010 few studies based on the latest photon counting lidar icesat 2 have been reported compared with previous sensors icesat 2 has great advantages in footprint size transmitting frequency pulse number etc but its performance in monitoring water level and volume changes in inland waters has not been fully explored here we investigated the spatial distribution of water level and volume changes of 11 lakes and 8 reservoirs in the yellow river basin based on icesat 2 and google earth engine and analyzed the factors affecting the measurement uncertainties in situ validation of lake level in lake qinghai indicates that the root mean square error rmse of our result is only 7 cm after the reference coordinate system conversion we found that the water level trend of the natural lake shows significant seasonal variations while the water level trend of the reservoir shows a sharp rise and fall in addition precipitation plays a decisive role in the changes in natural lake levels and indirectly affects the artificial control of reservoirs water discharges the uncertainty of water volume change monitoring is mainly affected by water level measurement uncertainty for lakes while for reservoirs that is affected by the combination of water level and area measurement uncertainties the stability of lake level measurement increases with the increase in photon counts the introduction of icesat 2 atl13 significant wave height might lead larger standard deviation in water level measurement according to the law of propagation of uncertainty the uncertainty of the water volume change estimation by the combination of icesat 2 and gee is less than 9 keywords icesat 2 google earth engine yellow river basin water level water volume change 1 introduction the yellow river basin which is a key food production center of global importance has been facing the risk of water scarcity and environmental issues all the time barnett et al 2006 ringler et al 2010 with only 2 of the country s total water resources the yellow river basin undertakes the water supply task of 12 of the population 15 of the farmland and more than 50 large and medium sized cities in china moreover climate change and human activities are exacerbating the water scarcity in this basin wang et al 2013a wang et al 2013b which is a microcosm of the world s problem of water based on blue book on climate change in china 2018 the terrestrial water storage of the yellow river basin shows a descent rate of 590 m3 10 years 1 2 10 years due to climate change while the water demands in the yellow river basin is increasing rapidly which were estimated at 50 to 60 billion m3 for 2030 nearly 14 billion more than that of 2017 wang et al 2020 wu et al 2020 xu et al 2002 there is widespread recognition of the need for better observations and understanding of surface water dynamics in time and space ringler et al 2010 lakes and reservoirs are important carriers of freshwater resources and are considered sentinels integrators and regulators for climate change and environmental issues adrian et al 2009 williamson et al 2009 particularly lakes and reservoirs form a network of environmental sensors that can provide us with rich information about water resource dynamics and their response to climate alsdorf et al 2007 qiao et al 2019 monitoring the water level and volume changes of lakes and reservoirs is essential for deepening our understanding of the temporal and spatial dynamics of water resources in the yellow river basin with a view to better utilizing and managing water resources monitoring the water volume dynamics of lakes and reservoirs on a large scale has always been a challenge although this information is critical traditionally water level data may be collected in a hydrometric station by manual or by automated systems with a precision of one centimeter in general and to three millimeters at continuous record gauging stations vuglinskiy et al 2009 however the availability of such data is very limited due to the lack of hydrometric stations measurement consistency and continuity and data governance most lakes in the world lack effective in situ measurements although some of the largest natural lakes are monitored in relatively developed countries for reservoirs the issue is a lack of data sharing due to a conflict of interests gao 2015 in the past decade satellite remote sensing has shown its unique advantage in monitoring lakes and reservoirs over a large area due to its continuous global coverage capability and data consistency cretaux et al 2016 there are many remote sensing methods to estimate inland water volume change while the main idea is the same deriving area and level of water bodies separately and combining them fang et al 2019 optical remote sensing satellites such as landsat and sentinel 2 have high spatial resolutions 30 m for landsat 10 m for sentinel 2 and publicly available image data which have been widely applied to the extraction of lake surface area active remote sensing satellites such as radar and laser altimeter as well as digital elevation model dem have already been used to accurately extract lake surface levels gravity recovery and climate experiment grace satellite mission which measures earth s gravity is another alternative to retrieve water storage change in large areas however it represents the integrated water changes including not only inland water rivers lakes and reservoirs but also soil moisture and groundwater lv et al 2019 mo et al 2016 its low spatial resolution 0 5 and 1 about 55 and 111 km determines grace observes water storage change at the global and watershed scale rather than small water bodies such as lakes and reservoirs at present there are two major kinds of methods to estimate water volume change wvc using remote sensing techniques the first is based on the digital elevation model dem gao and zhang 2017 pan et al 2013 yang et al 2017 and the second is based on the radar altimeter and laser altimeter liu and yue 2017 phan et al 2012 wang et al 2013a each method has its advantage and limitation for studying water volume change the dem based method is performed by constructing a hierarchic function between lake level and area based on the topography above the lake surface at the moment of dem measurement bonnema and hossain 2017 yang et al 2017 when the lake area at a given time is obtained by satellite observation or products e g the global surface water datasets provided by the european commission s joint research centre jean francois pekel et al 2016 the corresponding lake level is calculated by the predetermined hierarchic function the dem based method can work without height measurement but the difference between the real topography and the assumption restricts the accuracy of the estimated lake level and hence reducing the accuracy of the estimated wvc the radar altimeter based method measures lake levels directly with a good root mean square error rmse from several to dozens of centimeters shum et al 2003 and has been widely used in lake level monitoring and climate impact analysis da silva et al 2010 duan and bastiaanssen 2013 frappart et al 2006 villadsen et al 2015 multi sensor radar altimeters are often used in combination to extract inland water levels with a high temporal and spatial resolution gao et al 2013 li et al 2020 however radar altimeter has relatively large footprints on the earth s surface and the size of the footprint depends on the characteristics of the surface from 1 65 to 20 km phan et al 2012 sichangi et al 2016 making the footprints on the water surface easy to be contaminated by lake shore topography thus reducing measurement accuracy for extracting levels of small water bodies the laser altimeter which has a small footprint size of fewer than 100 m provides the ability to measure accurate water levels with no contamination of the land surface the geoscience laser altimeter system glas instrument which was carried on nasa s ice cloud and land elevation icesat in operation from 2003 to 2009 is a full waveform laser altimetry it can transmit a single beam profiling that produced 70 m diameter footprints on the surface of earth in situ validations showed that icesat glas provided accurate inland water level information with a relative error of less than 10 cm swenson and wahr 2009 which is more suitable than radar altimeters for measuring small water bodies combined with water surface areas derived by traditional optical remote sensing satellite sensors e g landsat modis sentinel etc wvc can be exactly calculated however icesat glas had a long repeat cycle time for inland water bodies since there is only a single beam working even large lake such as lake qinghai which has an area of about 4543 km2 was measured only 47 times from 2003 to 2009 this means there was only an average of only 6 7 observations per year for lake qinghai let alone other small water bodies from 2003 to 2009 only 74 lakes on the qinghai tibet plateau had data coverage in four to seven years and 37 lakes in one to three years zhang et al 2011 although icesat glas is superior to radar altimeters in the accuracy and stability of water level measurement its low data coverage and revisiting frequency limit the assessment of inter annual and intra annual water volume changes in the inland water bodies this limitation has been overcome by its successor icesat 2 which is launched in late 2018 the icesat 2 carries a photon counting laser altimeter atlas which can measure the height of a changing earth with 6 laser beams simultaneously working its transmitting frequency is 10 khz 250 times faster than icesat glas http icesat 2 gsfc nasa gov each laser beam has a nominal 17 m diameter footprint with an along track sampling interval of 0 7 m the multiple beam pairs provide improved spatial coverage and revisit frequency according to our statistics icesat 2 atlas revisited lake qinghai 31 times in 2019 4 5 times that of icesat glas in temporal resolution performance assessment using gauge data indicates that icesat 2 has an advanced altimetric capability with a relative altimetric error of 0 06 m and measurement uncertainty of 0 07 m yuan et al 2020 zhang et al 2020 although there have been many studies on monitoring water level and volume changes of lakes and reservoirs few studies based on the latest photon counting lidar icesat 2 atlas have been reported recent studies have preliminarily validated the accuracy of icesat 2 atlas on water level monitoring yuan et al 2020 zhang et al 2020 however the factors affecting the monitoring uncertainties of water level and volume changes have not been systematically analyzed before besides in terms of application the spatial distribution of water level and volume changes of the major lakes and reservoirs in the yellow river basin has not been reported and the main drivers of their changes have also not been analyzed in this study the spatial distribution of water level and volume changes of the major lakes and reservoirs in the yellow river basin was monitored and the accuracy of icesat 2 atlas on water level monitoring was further analyzed in addition the main factors affecting the monitoring uncertainties of wvcs of lakes and reservoirs were analyzed for the first time and the drivers of lakes and reservoirs level changes were also discussed 2 study area and datasets 2 1 study area the yellow river basin is located between 96 119 e and 32 42 n in the continental monsoon climate zone of china covering an area of 795 000 km2 it originates from the qinghai tibet plateau crosses the inner mongolia plateau and the north china plain and finally flows into the bohai sea compared with other world class river basins the yellow river basin is mainly in the arid semi arid and semi humid regions and is very vulnerable to the environment and climate change wang et al 2013b the spatial distribution of the 11 lakes and 8 reservoirs studied in this paper is shown in fig 1 and their names are listed in fig 2 the elevation of the yellow river basin decreases rapidly from west to east resulting in a decent rate of 237 m e of surface water level statistics in this study of all the water bodies studied in the yellow river basin lake gyaring has the highest annual mean water level of 4294 246 m while dongping lake has the lowest annual mean water level of 41 072 m based on statistics for 2019 2 2 datasets 2 2 1 icesat 2 atlas inland water surface height dataset icesat 2 atlas inland water surface height dataset atl13 from october 2018 to may 2020 is used to provide elevation information of the lakes and reservoirs in the yellow river basin icesat 2 atlas can measure inland water level with a transmitting frequency of 10 khz 0 7 m sampling on the ground and 6 beams 3 pairs of lasers working simultaneously each pair of lasers is classified as a strong and a weak beam with a distance of 90 m between their ground tracks and 3 3 km between two adjacent pairs it is worth mentioning that the footprint of icesat 2 is about 14 m sufficient for measuring any size of the water body markus et al 2017 neumann et al 2019 atl13 was mainly developed by atl03 global geolocated photon data product the received photons which were classified as returning from inland water surface were segmented into short segments 100 photons then the mean height of each short segment was calculated jasinski et al 2019a more convenient than icesat glas gla14 icesat 2 atlas atl13 only displays elevations over inland water regions not the elevations of land so the water surface elevations extracted from atl13 will not be contaminated by the land surface available altimetry dates of icesat 2 for each studied water body are listed in fig 2 2 3 usgs landsat 8 surface reflectance tier 1 dataset from google earth engine usgs landsat 8 surface reflectance tier 1 dataset is the geometrically radiometrically and atmospherically corrected surface reflectance from landsat 8 oli tirs sensors these images contain 4 visible 1 near infrared 2 short wave infrared bands and 2 thermal infrared bands with a 30 m spatial resolution https developers google com earth engine datasets the dataset can be accessed instantly for further analysis on the google earth engine platform gee gee is the most advanced cloud based geospatial analysis platform in the world that enables users to visualize and analyze satellite imagery and vector data of our earth https www google com earth education tools google earth engine it has the advantages of cloud computing batch processing speed and efficiency moreover there is no need for researchers to carry out a lot of cumbersome data preprocessing such as scale conversion radiation atmospheric correction etc compared with traditional remote sensing image acquisition and processing gee is no longer limited by the huge amount of remote sensing images because users can directly access the preprocessed images or upload costume data to do geographic analysis in a highly efficient way without downloading any image kumar and mutanga 2018 for extracting lakes and reservoirs in the yellow river basin the 30 m spatial resolution dataset usgs landsat 8 surface reflectance tier 1 from gee is adopted all processes of extracting and calculating water region area directly took place in the gee platform 3 methods in this study we investigated the maximal and seasonal wvc of the major inland water bodies around the yellow river basin by combining icesat 2 laser altimeter observation and the gee cloud computing platform water level and volume changes of 18 water bodies including 7 natural lakes 8 reservoirs and 3 artificial lakes were investigated reservoirs and artificial lakes are generally built and managed by humans in which reservoirs are primarily used for flood control while artificial lakes are not icesat 2 laser altimeter observations were used to access the water level change while the gee computing platform was used to calculate the area of water bodies 3 1 water level extraction using icesat 2 atlas laser altimetry data icesat 2 atlas inland water surface height dataset atl13 provides along track mean water surface heights for short segment lengths 100 signal photons 30 to 100 m of 6 laser beams water levels are recorded in orthometric units based on the egm2008 geoid converted from the wgs84 ellipsoid reference jasinski et al 2019a the orthometric water level of each short segment contained in atl13 is used to compute the integral mean level of each studied water body and eliminate outliers there are three steps to extract water surface height in this study first the openaltimetry platform https openaltimetry org was used to screen out the available laser altimetry footprint tracks of each studied water body from all icesat 2 footprint tracks second the orthometric height h t ortho of each short segment was extracted according to the vector boundary of each studied water body each geographic coordinate corresponds to a specific h t ortho represents the average elevation of a short segment third the inter quartile range iqr method used in yuan et al 2020 was adopted to eliminate outliers from the extracted elevations finally the average of all elevations that meet the iqr requirement was computed to represent the integral mean level of an individual water body the iqr method is expressed by 1 iqr q 3 q 1 2 outliers q 1 1 5 i q r 3 outliers q 3 1 5 i q r where q 1 and q 3 are the first and third quartiles of the orthometric heights extracted in step 2 3 2 water area extraction using google earth engine for every studied water body the modified normalized difference water index mndwi proposed by xu 2006 was introduced to extract water area mndwi is a widely used water extraction index modified from ndwi proposed by mcfeeters 1996 compared with ndwi mndwi can reduce and even remove background noise caused by build up land effectively because some of the lakes studied in this paper are located in cities mndwi is more suitable than ndwi for water body extraction all area extraction processes were completed on gee with the dataset usgs landsat 8 surface reflectance tier 1 mndwi is expressed by 4 mndwi ρ green ρ swir ρ green ρ swir where ρ green and ρ swir are the surface reflectance of band 2 green and band 6 7 swir we also set a series of continuous and equally spaced thresholds with an interval of 0 001 to examine the stability of water area extraction 3 3 water volume change estimation wvcs were calculated based on the averaged lake level and area at two different times using the trapezoidal volume formula proposed by taube 2000 5 δ v 1 3 h 2 h 1 a 1 a 2 a 1 a 2 where h 1 h 2 are the averaged lake levels at two different times respectively and a 1 a 2 are the averaged lake surface areas at two different times respectively 3 4 uncertainty assessment of water volume change the standard deviation std of the wvc of a waterbody depends on the combination of both stds of water level change and area daily water level std computation is based on all screened atl13 cloud points and water area std computation is based on a series of continuous different reasonable mndwi thresholds then the std of the wvc can be combined using the first order taylor approximation of the law of propagation of uncertainty defined as eq 6 eq 6 has ignored the covariance term because the extractions of the water level and area are independent the stds of water level change std δ h area std a and wvc std δ v are calculated separately based on eq 7 to 11 respectively eq 9 10 and 11 are derived from eq 6 6 st d f x 2 i 1 n f x x i 2 s t d x i 2 7 δ h h 2 h 1 8 a a 1 a 2 a 1 a 2 9 st d δ h st d h 1 2 s t d h 2 2 10 st d a 1 2 a 2 a 1 s t d a 1 2 a 1 a 2 s t d a 2 2 11 st d δ v 1 3 a 2 s t d δ h 2 δ h 2 s t d a 2 where h 1 a 1 and h 2 a 2 are the water level and area at the beginning and end of a period respectively the workflow diagram for estimating wvc is shown in fig 3 on the left half of fig 3 the water level of an individual waterbody can be well extracted by cloud points screening cloud point heights extraction and outliers elimination sequentially using icesat 2 atlas altimetry data on the right half of fig 3 the water area of an individual waterbody can be well extracted by false color composite lake mask the mndwi method and a series of reasonable thresholds using the usgs landsat 8 surface reflectance tier 1 dataset after the water level and area extraction wvc can be estimated by eq 5 4 results 4 1 water level extraction and outliers elimination the water levels of 11 lakes and 8 reservoirs were extracted from october 2018 to november 2020 the water level outliers elimination of lake ngoring by the iqr method as an example is shown in fig 4 a and the comparison of stds before and after eliminating outliers is shown in fig 4 b the measurement stability on some days was significantly improved after removing outliers the mean stds of the two datasets were 5 796 cm and 4 932 cm respectively which proved that the elimination of outliers decreased the overall mean measurement std by 0 864 cm after removing outliers the remaining short segments of each available day were used to calculate the daily average water level of all the available altimetry data acquired by icesat 2 lake ngoring had the maximum water level of 4273 692 m on october 14 2018 and the minimum water level of 4272 406 m on april 11 2020 resulting in a maximum inter annual variation of 1 286 m the daily average water level of lake ngoring was 4272 949 m from october 2018 to april 2020 the water level of lake ngoring in november 2019 was 0 137 m lower than that of november 2018 showing an inter annual decline trend 4 2 water level dynamics in natural and artificial water bodies maximal level deviations mlds of all water bodies were calculated by subtracting the minimal daily level from the maximal daily level of the available altimetry dataset of icesat 2 fig 5 it is worth mentioning that the mlds in this paper had some limitations because no waterbody had complete altimetry data every month from october 2018 to may 2020 fig 2 while the relative difference of mlds could still reflect the magnitude water level variation of the studied water bodies we found that the mean mld of natural lakes artificial lakes and reservoirs were 1 024 m 1 210 m and 13 331 m respectively indicating that the mld of the reservoir was nearly 10 times larger than the natural lake and artificial lake and the mld of the reservoir was always over 3 m this is an efficient way to distinguish lakes and reservoirs if no prior knowledge has been acquired we also found that water levels of natural lake and reservoir both had obvious periodical changes throughout the year while artificial lake did not show that characteristic the periodical change forms of natural lakes and reservoirs were significantly different fig 6 the natural lake level had lots of small fluctuations over time there were several level ups and downs in the same season but the overall annual trend showed a regular gradual change with seasons reservoir water level changed monotonously over time and showed monotonically increasing or decreasing which was very different from the fluctuations of a natural lake moreover compared with the gradual change of natural lakes reservoirs showed sharp fall or rise in a short time due to artificial drainage or storage fig 6 shows that the water level of natural lakes in the yellow river basin would change with seasons but no significant change would happen in the same season therefore the averaged lake level within a season could represent the general characteristics of the season and seasonal wvcs were calculated for natural lakes water levels of reservoirs and artificial lakes might change significantly from month to month due to anthropogenic influence thus seasonal representativeness was inapplicable for them monthly averaged levels and areas were extracted to calculate their wvcs from month to month the natural lakes are mainly distributed at the source of the yellow river in order to estimate seasonal wvcs of natural lakes seasonal water level changes were also obtained by calculating the difference between the mean water levels in adjacent seasons fig 7 the data from september 2018 to november 2020 were acquired to analyze the changing trend of 9 seasons for natural lakes there were some data gaps in the seasonal change in five lakes longria co xingxing sea ayongwuerma co ayonggaima co and hongjiannao because they are relatively small and the icesat 2 altimetry data were not available in these lakes in some seasons xingxing sea was not displayed in the figure because icesat 2 altimetry data was not available for most of the 9 seasons similar seasonal level change trends of lake gyaring and lake ngoring could be observed because these two lakes are geographically adjacent 4 3 water area changes corresponding to water level observations for estimating the wvc of each waterbody landsat 8 surface reflectance images which were closest to the dates of the water level observations were used to extract the corresponding water areas they were both well extracted by the mndwi method using gee with the dataset named usgs landsat 8 surface reflectance tier 1 the time interval between water level and area observation was generally no more than 10 days in addition to the maximal wvc in the study period seasonal wvc was also an object of our interest for the natural lakes therefore the mean area of each season referred to in table 1 was also extracted as an example of the two kinds of water area extraction the mean water areas of lake qinghai in five seasons are shown in fig 8 a and maximal and minimal areas of longyangxia reservoir in the study period are shown in fig 8 b meanwhile in the aspect of mndwi threshold selection for each waterbody we set a series of thresholds that were continuous and very close to each other to evaluate the stability of our water area extraction we extracted different areas by using all the thresholds each threshold corresponds to an area and calculated the mean area and std we found the std was very small relative to the mean area indicating the extraction result was stable mndwi thresholds from 0 to 0 05 with a step length of 0 001 were used to extract the maximal and minimal water areas of longyangxia reservoir as an example the pleasant relative uncertainties were found at only 0 22 and 0 13 respectively proving that the method was insensitive to a small variation of threshold and stable enough to get accurate water areas 4 4 water volume changes in lakes and reservoirs in order to reflect the characteristics of different water types we analyzed the wvc from two perspectives one was the maximal wvc of each studied waterbody and the other was the seasonal wvcs of natural lakes absolute values of the maximal wvcs are shown in fig 9 although we couldn t obtain the whole monthly levels of reservoirs for their lack of atl13 data we found that reservoirs generally showed larger variations than lakes in wvc due to artificial regulations including water storage and flow control bai et al 2020 hou et al 2013 jin et al 2017 yin et al 2021 longyangxia reservoir and xiaolangdi reservoir no 8 and 18 in fig 9 the largest two reservoirs presented the greatest changes of all studied waterbodies lake qinghai no 1 in fig 9 presented the greatest change of all studied natural lakes but in the scope of the yellow river basin lake ngoring no 3 in fig 9 presented the greatest change we also found that from the perspective of distribution in the yellow river basin upstream wvcs were mainly affected by the combined actions of natural lakes artificial lakes and reservoirs midstream by reservoirs and downstream by the only one relatively large artificial lake no 19 in fig 9 lake dongping seasonal wvcs of 4 natural lakes are shown in fig 10 by calculating eq 5 with seasonal mean water levels and areas prepared in advance seasonal wvcs of natural lakes were very similar to that of level changes fig 7 which might explain that the wvc of the natural lake was much greater influenced by water level change than water area change the detailed analysis was described in the discussion section for lake gyaring and hongjiannao the whole seasonal wvcs could not be calculated and demonstrated the calculated numeric seasonal wvcs of the four natural lakes correspond to fig 10 are listed in table 2 5 discussion 5 1 performance of icesat 2 altimetry data for water level extraction in order to test the performance of icesat 2 altimetry data for water level extraction in situ lake level data of lake qinghai was used to make a comparison with that of the icesat 2 the in situ daily data of station xiashe was provided by the bureau of hydrology and water resources of qinghai province from october 2018 to december 2019 a strong correlation r2 0 88 was found between the in situ and icesat 2 data the in situ level is referred to the chinese yellow sea datum renewed in 1985 while the icesat 2 level is referred to the orthometric height egm2008 converted from wgs84 ellipsoid height a mean system error of 1 227 m was found between them in lake qinghai after subtracting 1 227 m from the icesat 2 lake level the rmse between the in situ and icesat 2 lake level was only 7 cm fig 11 the comparison proved that the icesat 2 altimetry data had high accuracy in estimating water level change which was also reported by zhang et al 2020 5 2 main factors affecting the uncertainty of water volume change measurement in order to identify the main factors affecting the uncertainty of wvc the std of water level change std δ h area std a and wvc std δ v were calculated separately based on eq 7 to 11 and then converted to the uncertainty percentage pe δ h p e a and pe δ v expressed by eq 12 12 p e vas st d vas vas 100 where vas represents δ h a or δ v the uncertainty percentages of water level area and wvc of several lakes and reservoirs are shown in table 3 the uncertainty of water level change estimation was much greater than that of area estimation in lakes while the differences between them were greatly reduced in reservoirs it can be concluded that for lakes especially natural lakes the uncertainty of wvc was mainly affected by the uncertainty of lake level estimation because the influence of lake level change δ h measurement uncertainty was much larger than that of lake area a measurement uncertainty on wvc estimation for reservoirs unlike lakes the uncertainty of wvc was affected by the combination of the uncertainty of δ h and a and wvc estimation in reservoirs showed much higher stability than that of lakes this is mainly because reservoirs generally have larger variations in water level than lakes resulting in a higher signal to noise ratio for monitoring water level changes 5 3 relationship between water level measurement stability and returned photon counts the short segments for specific lakes in each atl13 dataset were different ranging from 1 to 23478 there were about 100 returned photons in each short segment the number of atl13 samples used in this study was 244 in order to analyze the relationship between the water level measurement stability and the laser photon counts we sorted the 244 samples in ascending order of the number of short segments and divided them equally into two groups with 112 atl13 samples included in each one the number of short segments at the cut off point the 112th sample was 463 we also divided each group into 3 subgroups according to the stds which were very stable vs relative stable rs and unstable us respectively and vs and rs were both considered stable the detailed grouping scheme is 13 224 s a m p l e s group 1 112 s a m p l e s s h o r t s e g m e n t s 463 subgroup 1 v s s t d 0 05 s u b g r o u p 2 r s 0 05 s t d 0 1 s u b g r o u p 3 u s s t d 0 1 g r o u p 2 112 s a m p l e s s h o r t s e g m e n t s 463 subgroup 1 v s s t d 0 05 s u b g r o u p 2 r s 0 05 s t d 0 1 s u b g r o u p 3 u s s t d 0 1 the analysis result is shown in table 4 for group 1 the number of samples classified as vs subgroup 1 was much larger than that of rs subgroup 2 while for group 2 the number of samples classified as vs subgroup 1 was close to that of rs subgroup 2 this phenomenon indicated that samples with small photon counts had a higher stability level than those with large photon counts but in terms of overall stability std 0 1 group 2 showed a little bigger than group 1 generally speaking std less than 0 1 can meet the stability requirement of water level measurement thus the measurement stability will be better with the photon counts increases even though some very high stable samples will be lost 5 4 influence of significant wave height product on the stability of water level measurement atl13 dataset contains a product named significant wave height swh which was estimated as four times the std of the unit water surface jasinski et al 2019b we tried using the orthometric water level minus the swh to get the true water level but this greatly increased the std of the water level measurement and thus increased the uncertainty of the wvc calculation fig 12 takes the atl13 water levels on an individual day of lake qinghai as an example the std of the level estimated by subtracting swh from the orthometric level was 0 116 m obviously much greater than 0 041 m the std of the only orthometric level they both removed outliers in advance by the iqr method 5 5 the drivers of water level changes in natural lakes and reservoirs in order to analyze the drivers of water level changes in natural lakes and reservoirs two natural lakes lake qinghai and lake ngoring and two reservoirs longyangxia reservoir and xiaolangdi reservoir were selected as representatives of different water bodies monthly precipitation data was provided by weather stations named lake qinghai 151 for lake qinghai madoi for lake ngoring gonghe for longyangxia reservoir and mengjin for xiaolangdi reservoir respectively which are affiliated with the china meteorological administration the locations of the four weather stations are shown in fig 1 as shown in fig 13 a and b the changes in lake levels were in good agreement with precipitations and precipitation played a decisive role in the changes in lake levels the lake level raised as precipitation increased and fell as precipitation decreased thus forming periodic changes besides lake levels did not change immediately when precipitation changed and there was a lag of 1 3 months between the changes in precipitation and the changes in lake levels the lag between the changes of precipitation and the changes in lake level is also reported by mccoy and blanchard 2008 iwaki et al 2021 and li et al 2021 we think this is because a large part of the precipitation fell on the soil of the basin and it took time for the soil moisture to reach saturation then it took time for the saturated soil moisture to enter the surface runoff and the subsurface runoff to flow into the lake as shown in fig 13 c and d the precipitation did not have a direct effect on the changes in reservoir levels but indirectly affected the artificial control of reservoirs water discharges shang et al 2022 and bai et al 2020 studied the multi year average monthly discharges of longyangxia reservoir and xiaolangdi reservoir respectively and the results showed that the two reservoirs have similar periods of impounding and draining the most important function of the two reservoirs is flood control the water levels continued to fall from spring to the flood season and reached their lowest in july or august used for sediment regulation then they started to rise until the next spring and then started to fall again 6 conclusion in this study for a better evaluation of the performance of inland water level and volume changes monitoring by the icesat 2 we monitored the water level and volume changes of the major lakes and reservoirs in the yellow river basin based on the icesat 2 atlas laser altimetry and gee cloud computing platform in order to understand the distribution of water level and volume changes of lakes and reservoirs we selected relatively large 7 natural lakes 8 reservoirs and 3 artificial lakes and also applied the in situ lake level data of lake qinghai to examine the trends in our result finally we conducted some analysis including the measurement uncertainties of water level volume changes and the different drivers of water level changes in natural lakes and reservoirs based on the estimated result of the yellow river basin we found that upstream water volume changes were mainly affected by the combined actions of natural lakes artificial lakes and reservoirs midstream by reservoirs and downstream by only one relatively large artificial lake large water bodies showed large water volume changes benefit from improved spatial coverage of the icesat 2 observation seasonal water level and volume change analysis could be well performed in situ validation of lake level in lake qinghai indicated that the lake level change trend of our result was consistent with that of the in situ data and the rmse was only 7 cm after the reference coordinate system conversion comparative analysis showed that the variation water level trend of different waterbody types was much different from each other water levels of natural lake and reservoir both had obvious periodical changes throughout the year while artificial lake did not show that characteristic the natural lake level had lots of small fluctuations in one season and showed a regular gradual change with seasons but reservoir water level changed monotonously over time and showed abrupt changes in a short time the precipitation played a decisive role in the changes in natural lake levels and indirectly affected the artificial control of reservoirs water discharges the uncertainty of water volume change estimation was mainly affected by the measurement uncertainty of water level change for lakes but for reservoirs the estimated uncertainty of water volume change was affected by the combination of the measurement uncertainties of water level change and area in general the more photon counts of the icesat 2 altimetry dataset the higher measurement stability the introduction of atl13 significant wave height data may make the measurement more accurate however it might reduce the measurement stability of water level and volume change for both lakes and reservoirs the estimation uncertainty of water volume change was generally less than 9 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the yellow river major program of the national natural science foundation of china nsfc grant no 42041005 the second tibetan plateau scientific expedition and research step program grant no 2019qzkk0304 the nsfc grant no 41901288 beijing nova program of science and technology grant no z191100001119132 youth innovation promotion association cas and the fundamental research funds for the central universities we would like to acknowledge the nsidc for providing the icesat 2 altimetry dataset the usgs and google earth engine for processing landsat 8 image fusion and the bureau of hydrology and water resources of qinghai province for providing the in situ water level data 
1695,monitoring the water level and volume changes of lakes and reservoirs is essential for deepening our understanding of the temporal and spatial dynamics of water resources in the yellow river basin with a view to better utilizing and managing water resources in recent years there have been many studies on monitoring water level and volume changes in inland waters but they were mainly focused on radar altimetry and the full waveform lidar icesat which was retired in 2010 few studies based on the latest photon counting lidar icesat 2 have been reported compared with previous sensors icesat 2 has great advantages in footprint size transmitting frequency pulse number etc but its performance in monitoring water level and volume changes in inland waters has not been fully explored here we investigated the spatial distribution of water level and volume changes of 11 lakes and 8 reservoirs in the yellow river basin based on icesat 2 and google earth engine and analyzed the factors affecting the measurement uncertainties in situ validation of lake level in lake qinghai indicates that the root mean square error rmse of our result is only 7 cm after the reference coordinate system conversion we found that the water level trend of the natural lake shows significant seasonal variations while the water level trend of the reservoir shows a sharp rise and fall in addition precipitation plays a decisive role in the changes in natural lake levels and indirectly affects the artificial control of reservoirs water discharges the uncertainty of water volume change monitoring is mainly affected by water level measurement uncertainty for lakes while for reservoirs that is affected by the combination of water level and area measurement uncertainties the stability of lake level measurement increases with the increase in photon counts the introduction of icesat 2 atl13 significant wave height might lead larger standard deviation in water level measurement according to the law of propagation of uncertainty the uncertainty of the water volume change estimation by the combination of icesat 2 and gee is less than 9 keywords icesat 2 google earth engine yellow river basin water level water volume change 1 introduction the yellow river basin which is a key food production center of global importance has been facing the risk of water scarcity and environmental issues all the time barnett et al 2006 ringler et al 2010 with only 2 of the country s total water resources the yellow river basin undertakes the water supply task of 12 of the population 15 of the farmland and more than 50 large and medium sized cities in china moreover climate change and human activities are exacerbating the water scarcity in this basin wang et al 2013a wang et al 2013b which is a microcosm of the world s problem of water based on blue book on climate change in china 2018 the terrestrial water storage of the yellow river basin shows a descent rate of 590 m3 10 years 1 2 10 years due to climate change while the water demands in the yellow river basin is increasing rapidly which were estimated at 50 to 60 billion m3 for 2030 nearly 14 billion more than that of 2017 wang et al 2020 wu et al 2020 xu et al 2002 there is widespread recognition of the need for better observations and understanding of surface water dynamics in time and space ringler et al 2010 lakes and reservoirs are important carriers of freshwater resources and are considered sentinels integrators and regulators for climate change and environmental issues adrian et al 2009 williamson et al 2009 particularly lakes and reservoirs form a network of environmental sensors that can provide us with rich information about water resource dynamics and their response to climate alsdorf et al 2007 qiao et al 2019 monitoring the water level and volume changes of lakes and reservoirs is essential for deepening our understanding of the temporal and spatial dynamics of water resources in the yellow river basin with a view to better utilizing and managing water resources monitoring the water volume dynamics of lakes and reservoirs on a large scale has always been a challenge although this information is critical traditionally water level data may be collected in a hydrometric station by manual or by automated systems with a precision of one centimeter in general and to three millimeters at continuous record gauging stations vuglinskiy et al 2009 however the availability of such data is very limited due to the lack of hydrometric stations measurement consistency and continuity and data governance most lakes in the world lack effective in situ measurements although some of the largest natural lakes are monitored in relatively developed countries for reservoirs the issue is a lack of data sharing due to a conflict of interests gao 2015 in the past decade satellite remote sensing has shown its unique advantage in monitoring lakes and reservoirs over a large area due to its continuous global coverage capability and data consistency cretaux et al 2016 there are many remote sensing methods to estimate inland water volume change while the main idea is the same deriving area and level of water bodies separately and combining them fang et al 2019 optical remote sensing satellites such as landsat and sentinel 2 have high spatial resolutions 30 m for landsat 10 m for sentinel 2 and publicly available image data which have been widely applied to the extraction of lake surface area active remote sensing satellites such as radar and laser altimeter as well as digital elevation model dem have already been used to accurately extract lake surface levels gravity recovery and climate experiment grace satellite mission which measures earth s gravity is another alternative to retrieve water storage change in large areas however it represents the integrated water changes including not only inland water rivers lakes and reservoirs but also soil moisture and groundwater lv et al 2019 mo et al 2016 its low spatial resolution 0 5 and 1 about 55 and 111 km determines grace observes water storage change at the global and watershed scale rather than small water bodies such as lakes and reservoirs at present there are two major kinds of methods to estimate water volume change wvc using remote sensing techniques the first is based on the digital elevation model dem gao and zhang 2017 pan et al 2013 yang et al 2017 and the second is based on the radar altimeter and laser altimeter liu and yue 2017 phan et al 2012 wang et al 2013a each method has its advantage and limitation for studying water volume change the dem based method is performed by constructing a hierarchic function between lake level and area based on the topography above the lake surface at the moment of dem measurement bonnema and hossain 2017 yang et al 2017 when the lake area at a given time is obtained by satellite observation or products e g the global surface water datasets provided by the european commission s joint research centre jean francois pekel et al 2016 the corresponding lake level is calculated by the predetermined hierarchic function the dem based method can work without height measurement but the difference between the real topography and the assumption restricts the accuracy of the estimated lake level and hence reducing the accuracy of the estimated wvc the radar altimeter based method measures lake levels directly with a good root mean square error rmse from several to dozens of centimeters shum et al 2003 and has been widely used in lake level monitoring and climate impact analysis da silva et al 2010 duan and bastiaanssen 2013 frappart et al 2006 villadsen et al 2015 multi sensor radar altimeters are often used in combination to extract inland water levels with a high temporal and spatial resolution gao et al 2013 li et al 2020 however radar altimeter has relatively large footprints on the earth s surface and the size of the footprint depends on the characteristics of the surface from 1 65 to 20 km phan et al 2012 sichangi et al 2016 making the footprints on the water surface easy to be contaminated by lake shore topography thus reducing measurement accuracy for extracting levels of small water bodies the laser altimeter which has a small footprint size of fewer than 100 m provides the ability to measure accurate water levels with no contamination of the land surface the geoscience laser altimeter system glas instrument which was carried on nasa s ice cloud and land elevation icesat in operation from 2003 to 2009 is a full waveform laser altimetry it can transmit a single beam profiling that produced 70 m diameter footprints on the surface of earth in situ validations showed that icesat glas provided accurate inland water level information with a relative error of less than 10 cm swenson and wahr 2009 which is more suitable than radar altimeters for measuring small water bodies combined with water surface areas derived by traditional optical remote sensing satellite sensors e g landsat modis sentinel etc wvc can be exactly calculated however icesat glas had a long repeat cycle time for inland water bodies since there is only a single beam working even large lake such as lake qinghai which has an area of about 4543 km2 was measured only 47 times from 2003 to 2009 this means there was only an average of only 6 7 observations per year for lake qinghai let alone other small water bodies from 2003 to 2009 only 74 lakes on the qinghai tibet plateau had data coverage in four to seven years and 37 lakes in one to three years zhang et al 2011 although icesat glas is superior to radar altimeters in the accuracy and stability of water level measurement its low data coverage and revisiting frequency limit the assessment of inter annual and intra annual water volume changes in the inland water bodies this limitation has been overcome by its successor icesat 2 which is launched in late 2018 the icesat 2 carries a photon counting laser altimeter atlas which can measure the height of a changing earth with 6 laser beams simultaneously working its transmitting frequency is 10 khz 250 times faster than icesat glas http icesat 2 gsfc nasa gov each laser beam has a nominal 17 m diameter footprint with an along track sampling interval of 0 7 m the multiple beam pairs provide improved spatial coverage and revisit frequency according to our statistics icesat 2 atlas revisited lake qinghai 31 times in 2019 4 5 times that of icesat glas in temporal resolution performance assessment using gauge data indicates that icesat 2 has an advanced altimetric capability with a relative altimetric error of 0 06 m and measurement uncertainty of 0 07 m yuan et al 2020 zhang et al 2020 although there have been many studies on monitoring water level and volume changes of lakes and reservoirs few studies based on the latest photon counting lidar icesat 2 atlas have been reported recent studies have preliminarily validated the accuracy of icesat 2 atlas on water level monitoring yuan et al 2020 zhang et al 2020 however the factors affecting the monitoring uncertainties of water level and volume changes have not been systematically analyzed before besides in terms of application the spatial distribution of water level and volume changes of the major lakes and reservoirs in the yellow river basin has not been reported and the main drivers of their changes have also not been analyzed in this study the spatial distribution of water level and volume changes of the major lakes and reservoirs in the yellow river basin was monitored and the accuracy of icesat 2 atlas on water level monitoring was further analyzed in addition the main factors affecting the monitoring uncertainties of wvcs of lakes and reservoirs were analyzed for the first time and the drivers of lakes and reservoirs level changes were also discussed 2 study area and datasets 2 1 study area the yellow river basin is located between 96 119 e and 32 42 n in the continental monsoon climate zone of china covering an area of 795 000 km2 it originates from the qinghai tibet plateau crosses the inner mongolia plateau and the north china plain and finally flows into the bohai sea compared with other world class river basins the yellow river basin is mainly in the arid semi arid and semi humid regions and is very vulnerable to the environment and climate change wang et al 2013b the spatial distribution of the 11 lakes and 8 reservoirs studied in this paper is shown in fig 1 and their names are listed in fig 2 the elevation of the yellow river basin decreases rapidly from west to east resulting in a decent rate of 237 m e of surface water level statistics in this study of all the water bodies studied in the yellow river basin lake gyaring has the highest annual mean water level of 4294 246 m while dongping lake has the lowest annual mean water level of 41 072 m based on statistics for 2019 2 2 datasets 2 2 1 icesat 2 atlas inland water surface height dataset icesat 2 atlas inland water surface height dataset atl13 from october 2018 to may 2020 is used to provide elevation information of the lakes and reservoirs in the yellow river basin icesat 2 atlas can measure inland water level with a transmitting frequency of 10 khz 0 7 m sampling on the ground and 6 beams 3 pairs of lasers working simultaneously each pair of lasers is classified as a strong and a weak beam with a distance of 90 m between their ground tracks and 3 3 km between two adjacent pairs it is worth mentioning that the footprint of icesat 2 is about 14 m sufficient for measuring any size of the water body markus et al 2017 neumann et al 2019 atl13 was mainly developed by atl03 global geolocated photon data product the received photons which were classified as returning from inland water surface were segmented into short segments 100 photons then the mean height of each short segment was calculated jasinski et al 2019a more convenient than icesat glas gla14 icesat 2 atlas atl13 only displays elevations over inland water regions not the elevations of land so the water surface elevations extracted from atl13 will not be contaminated by the land surface available altimetry dates of icesat 2 for each studied water body are listed in fig 2 2 3 usgs landsat 8 surface reflectance tier 1 dataset from google earth engine usgs landsat 8 surface reflectance tier 1 dataset is the geometrically radiometrically and atmospherically corrected surface reflectance from landsat 8 oli tirs sensors these images contain 4 visible 1 near infrared 2 short wave infrared bands and 2 thermal infrared bands with a 30 m spatial resolution https developers google com earth engine datasets the dataset can be accessed instantly for further analysis on the google earth engine platform gee gee is the most advanced cloud based geospatial analysis platform in the world that enables users to visualize and analyze satellite imagery and vector data of our earth https www google com earth education tools google earth engine it has the advantages of cloud computing batch processing speed and efficiency moreover there is no need for researchers to carry out a lot of cumbersome data preprocessing such as scale conversion radiation atmospheric correction etc compared with traditional remote sensing image acquisition and processing gee is no longer limited by the huge amount of remote sensing images because users can directly access the preprocessed images or upload costume data to do geographic analysis in a highly efficient way without downloading any image kumar and mutanga 2018 for extracting lakes and reservoirs in the yellow river basin the 30 m spatial resolution dataset usgs landsat 8 surface reflectance tier 1 from gee is adopted all processes of extracting and calculating water region area directly took place in the gee platform 3 methods in this study we investigated the maximal and seasonal wvc of the major inland water bodies around the yellow river basin by combining icesat 2 laser altimeter observation and the gee cloud computing platform water level and volume changes of 18 water bodies including 7 natural lakes 8 reservoirs and 3 artificial lakes were investigated reservoirs and artificial lakes are generally built and managed by humans in which reservoirs are primarily used for flood control while artificial lakes are not icesat 2 laser altimeter observations were used to access the water level change while the gee computing platform was used to calculate the area of water bodies 3 1 water level extraction using icesat 2 atlas laser altimetry data icesat 2 atlas inland water surface height dataset atl13 provides along track mean water surface heights for short segment lengths 100 signal photons 30 to 100 m of 6 laser beams water levels are recorded in orthometric units based on the egm2008 geoid converted from the wgs84 ellipsoid reference jasinski et al 2019a the orthometric water level of each short segment contained in atl13 is used to compute the integral mean level of each studied water body and eliminate outliers there are three steps to extract water surface height in this study first the openaltimetry platform https openaltimetry org was used to screen out the available laser altimetry footprint tracks of each studied water body from all icesat 2 footprint tracks second the orthometric height h t ortho of each short segment was extracted according to the vector boundary of each studied water body each geographic coordinate corresponds to a specific h t ortho represents the average elevation of a short segment third the inter quartile range iqr method used in yuan et al 2020 was adopted to eliminate outliers from the extracted elevations finally the average of all elevations that meet the iqr requirement was computed to represent the integral mean level of an individual water body the iqr method is expressed by 1 iqr q 3 q 1 2 outliers q 1 1 5 i q r 3 outliers q 3 1 5 i q r where q 1 and q 3 are the first and third quartiles of the orthometric heights extracted in step 2 3 2 water area extraction using google earth engine for every studied water body the modified normalized difference water index mndwi proposed by xu 2006 was introduced to extract water area mndwi is a widely used water extraction index modified from ndwi proposed by mcfeeters 1996 compared with ndwi mndwi can reduce and even remove background noise caused by build up land effectively because some of the lakes studied in this paper are located in cities mndwi is more suitable than ndwi for water body extraction all area extraction processes were completed on gee with the dataset usgs landsat 8 surface reflectance tier 1 mndwi is expressed by 4 mndwi ρ green ρ swir ρ green ρ swir where ρ green and ρ swir are the surface reflectance of band 2 green and band 6 7 swir we also set a series of continuous and equally spaced thresholds with an interval of 0 001 to examine the stability of water area extraction 3 3 water volume change estimation wvcs were calculated based on the averaged lake level and area at two different times using the trapezoidal volume formula proposed by taube 2000 5 δ v 1 3 h 2 h 1 a 1 a 2 a 1 a 2 where h 1 h 2 are the averaged lake levels at two different times respectively and a 1 a 2 are the averaged lake surface areas at two different times respectively 3 4 uncertainty assessment of water volume change the standard deviation std of the wvc of a waterbody depends on the combination of both stds of water level change and area daily water level std computation is based on all screened atl13 cloud points and water area std computation is based on a series of continuous different reasonable mndwi thresholds then the std of the wvc can be combined using the first order taylor approximation of the law of propagation of uncertainty defined as eq 6 eq 6 has ignored the covariance term because the extractions of the water level and area are independent the stds of water level change std δ h area std a and wvc std δ v are calculated separately based on eq 7 to 11 respectively eq 9 10 and 11 are derived from eq 6 6 st d f x 2 i 1 n f x x i 2 s t d x i 2 7 δ h h 2 h 1 8 a a 1 a 2 a 1 a 2 9 st d δ h st d h 1 2 s t d h 2 2 10 st d a 1 2 a 2 a 1 s t d a 1 2 a 1 a 2 s t d a 2 2 11 st d δ v 1 3 a 2 s t d δ h 2 δ h 2 s t d a 2 where h 1 a 1 and h 2 a 2 are the water level and area at the beginning and end of a period respectively the workflow diagram for estimating wvc is shown in fig 3 on the left half of fig 3 the water level of an individual waterbody can be well extracted by cloud points screening cloud point heights extraction and outliers elimination sequentially using icesat 2 atlas altimetry data on the right half of fig 3 the water area of an individual waterbody can be well extracted by false color composite lake mask the mndwi method and a series of reasonable thresholds using the usgs landsat 8 surface reflectance tier 1 dataset after the water level and area extraction wvc can be estimated by eq 5 4 results 4 1 water level extraction and outliers elimination the water levels of 11 lakes and 8 reservoirs were extracted from october 2018 to november 2020 the water level outliers elimination of lake ngoring by the iqr method as an example is shown in fig 4 a and the comparison of stds before and after eliminating outliers is shown in fig 4 b the measurement stability on some days was significantly improved after removing outliers the mean stds of the two datasets were 5 796 cm and 4 932 cm respectively which proved that the elimination of outliers decreased the overall mean measurement std by 0 864 cm after removing outliers the remaining short segments of each available day were used to calculate the daily average water level of all the available altimetry data acquired by icesat 2 lake ngoring had the maximum water level of 4273 692 m on october 14 2018 and the minimum water level of 4272 406 m on april 11 2020 resulting in a maximum inter annual variation of 1 286 m the daily average water level of lake ngoring was 4272 949 m from october 2018 to april 2020 the water level of lake ngoring in november 2019 was 0 137 m lower than that of november 2018 showing an inter annual decline trend 4 2 water level dynamics in natural and artificial water bodies maximal level deviations mlds of all water bodies were calculated by subtracting the minimal daily level from the maximal daily level of the available altimetry dataset of icesat 2 fig 5 it is worth mentioning that the mlds in this paper had some limitations because no waterbody had complete altimetry data every month from october 2018 to may 2020 fig 2 while the relative difference of mlds could still reflect the magnitude water level variation of the studied water bodies we found that the mean mld of natural lakes artificial lakes and reservoirs were 1 024 m 1 210 m and 13 331 m respectively indicating that the mld of the reservoir was nearly 10 times larger than the natural lake and artificial lake and the mld of the reservoir was always over 3 m this is an efficient way to distinguish lakes and reservoirs if no prior knowledge has been acquired we also found that water levels of natural lake and reservoir both had obvious periodical changes throughout the year while artificial lake did not show that characteristic the periodical change forms of natural lakes and reservoirs were significantly different fig 6 the natural lake level had lots of small fluctuations over time there were several level ups and downs in the same season but the overall annual trend showed a regular gradual change with seasons reservoir water level changed monotonously over time and showed monotonically increasing or decreasing which was very different from the fluctuations of a natural lake moreover compared with the gradual change of natural lakes reservoirs showed sharp fall or rise in a short time due to artificial drainage or storage fig 6 shows that the water level of natural lakes in the yellow river basin would change with seasons but no significant change would happen in the same season therefore the averaged lake level within a season could represent the general characteristics of the season and seasonal wvcs were calculated for natural lakes water levels of reservoirs and artificial lakes might change significantly from month to month due to anthropogenic influence thus seasonal representativeness was inapplicable for them monthly averaged levels and areas were extracted to calculate their wvcs from month to month the natural lakes are mainly distributed at the source of the yellow river in order to estimate seasonal wvcs of natural lakes seasonal water level changes were also obtained by calculating the difference between the mean water levels in adjacent seasons fig 7 the data from september 2018 to november 2020 were acquired to analyze the changing trend of 9 seasons for natural lakes there were some data gaps in the seasonal change in five lakes longria co xingxing sea ayongwuerma co ayonggaima co and hongjiannao because they are relatively small and the icesat 2 altimetry data were not available in these lakes in some seasons xingxing sea was not displayed in the figure because icesat 2 altimetry data was not available for most of the 9 seasons similar seasonal level change trends of lake gyaring and lake ngoring could be observed because these two lakes are geographically adjacent 4 3 water area changes corresponding to water level observations for estimating the wvc of each waterbody landsat 8 surface reflectance images which were closest to the dates of the water level observations were used to extract the corresponding water areas they were both well extracted by the mndwi method using gee with the dataset named usgs landsat 8 surface reflectance tier 1 the time interval between water level and area observation was generally no more than 10 days in addition to the maximal wvc in the study period seasonal wvc was also an object of our interest for the natural lakes therefore the mean area of each season referred to in table 1 was also extracted as an example of the two kinds of water area extraction the mean water areas of lake qinghai in five seasons are shown in fig 8 a and maximal and minimal areas of longyangxia reservoir in the study period are shown in fig 8 b meanwhile in the aspect of mndwi threshold selection for each waterbody we set a series of thresholds that were continuous and very close to each other to evaluate the stability of our water area extraction we extracted different areas by using all the thresholds each threshold corresponds to an area and calculated the mean area and std we found the std was very small relative to the mean area indicating the extraction result was stable mndwi thresholds from 0 to 0 05 with a step length of 0 001 were used to extract the maximal and minimal water areas of longyangxia reservoir as an example the pleasant relative uncertainties were found at only 0 22 and 0 13 respectively proving that the method was insensitive to a small variation of threshold and stable enough to get accurate water areas 4 4 water volume changes in lakes and reservoirs in order to reflect the characteristics of different water types we analyzed the wvc from two perspectives one was the maximal wvc of each studied waterbody and the other was the seasonal wvcs of natural lakes absolute values of the maximal wvcs are shown in fig 9 although we couldn t obtain the whole monthly levels of reservoirs for their lack of atl13 data we found that reservoirs generally showed larger variations than lakes in wvc due to artificial regulations including water storage and flow control bai et al 2020 hou et al 2013 jin et al 2017 yin et al 2021 longyangxia reservoir and xiaolangdi reservoir no 8 and 18 in fig 9 the largest two reservoirs presented the greatest changes of all studied waterbodies lake qinghai no 1 in fig 9 presented the greatest change of all studied natural lakes but in the scope of the yellow river basin lake ngoring no 3 in fig 9 presented the greatest change we also found that from the perspective of distribution in the yellow river basin upstream wvcs were mainly affected by the combined actions of natural lakes artificial lakes and reservoirs midstream by reservoirs and downstream by the only one relatively large artificial lake no 19 in fig 9 lake dongping seasonal wvcs of 4 natural lakes are shown in fig 10 by calculating eq 5 with seasonal mean water levels and areas prepared in advance seasonal wvcs of natural lakes were very similar to that of level changes fig 7 which might explain that the wvc of the natural lake was much greater influenced by water level change than water area change the detailed analysis was described in the discussion section for lake gyaring and hongjiannao the whole seasonal wvcs could not be calculated and demonstrated the calculated numeric seasonal wvcs of the four natural lakes correspond to fig 10 are listed in table 2 5 discussion 5 1 performance of icesat 2 altimetry data for water level extraction in order to test the performance of icesat 2 altimetry data for water level extraction in situ lake level data of lake qinghai was used to make a comparison with that of the icesat 2 the in situ daily data of station xiashe was provided by the bureau of hydrology and water resources of qinghai province from october 2018 to december 2019 a strong correlation r2 0 88 was found between the in situ and icesat 2 data the in situ level is referred to the chinese yellow sea datum renewed in 1985 while the icesat 2 level is referred to the orthometric height egm2008 converted from wgs84 ellipsoid height a mean system error of 1 227 m was found between them in lake qinghai after subtracting 1 227 m from the icesat 2 lake level the rmse between the in situ and icesat 2 lake level was only 7 cm fig 11 the comparison proved that the icesat 2 altimetry data had high accuracy in estimating water level change which was also reported by zhang et al 2020 5 2 main factors affecting the uncertainty of water volume change measurement in order to identify the main factors affecting the uncertainty of wvc the std of water level change std δ h area std a and wvc std δ v were calculated separately based on eq 7 to 11 and then converted to the uncertainty percentage pe δ h p e a and pe δ v expressed by eq 12 12 p e vas st d vas vas 100 where vas represents δ h a or δ v the uncertainty percentages of water level area and wvc of several lakes and reservoirs are shown in table 3 the uncertainty of water level change estimation was much greater than that of area estimation in lakes while the differences between them were greatly reduced in reservoirs it can be concluded that for lakes especially natural lakes the uncertainty of wvc was mainly affected by the uncertainty of lake level estimation because the influence of lake level change δ h measurement uncertainty was much larger than that of lake area a measurement uncertainty on wvc estimation for reservoirs unlike lakes the uncertainty of wvc was affected by the combination of the uncertainty of δ h and a and wvc estimation in reservoirs showed much higher stability than that of lakes this is mainly because reservoirs generally have larger variations in water level than lakes resulting in a higher signal to noise ratio for monitoring water level changes 5 3 relationship between water level measurement stability and returned photon counts the short segments for specific lakes in each atl13 dataset were different ranging from 1 to 23478 there were about 100 returned photons in each short segment the number of atl13 samples used in this study was 244 in order to analyze the relationship between the water level measurement stability and the laser photon counts we sorted the 244 samples in ascending order of the number of short segments and divided them equally into two groups with 112 atl13 samples included in each one the number of short segments at the cut off point the 112th sample was 463 we also divided each group into 3 subgroups according to the stds which were very stable vs relative stable rs and unstable us respectively and vs and rs were both considered stable the detailed grouping scheme is 13 224 s a m p l e s group 1 112 s a m p l e s s h o r t s e g m e n t s 463 subgroup 1 v s s t d 0 05 s u b g r o u p 2 r s 0 05 s t d 0 1 s u b g r o u p 3 u s s t d 0 1 g r o u p 2 112 s a m p l e s s h o r t s e g m e n t s 463 subgroup 1 v s s t d 0 05 s u b g r o u p 2 r s 0 05 s t d 0 1 s u b g r o u p 3 u s s t d 0 1 the analysis result is shown in table 4 for group 1 the number of samples classified as vs subgroup 1 was much larger than that of rs subgroup 2 while for group 2 the number of samples classified as vs subgroup 1 was close to that of rs subgroup 2 this phenomenon indicated that samples with small photon counts had a higher stability level than those with large photon counts but in terms of overall stability std 0 1 group 2 showed a little bigger than group 1 generally speaking std less than 0 1 can meet the stability requirement of water level measurement thus the measurement stability will be better with the photon counts increases even though some very high stable samples will be lost 5 4 influence of significant wave height product on the stability of water level measurement atl13 dataset contains a product named significant wave height swh which was estimated as four times the std of the unit water surface jasinski et al 2019b we tried using the orthometric water level minus the swh to get the true water level but this greatly increased the std of the water level measurement and thus increased the uncertainty of the wvc calculation fig 12 takes the atl13 water levels on an individual day of lake qinghai as an example the std of the level estimated by subtracting swh from the orthometric level was 0 116 m obviously much greater than 0 041 m the std of the only orthometric level they both removed outliers in advance by the iqr method 5 5 the drivers of water level changes in natural lakes and reservoirs in order to analyze the drivers of water level changes in natural lakes and reservoirs two natural lakes lake qinghai and lake ngoring and two reservoirs longyangxia reservoir and xiaolangdi reservoir were selected as representatives of different water bodies monthly precipitation data was provided by weather stations named lake qinghai 151 for lake qinghai madoi for lake ngoring gonghe for longyangxia reservoir and mengjin for xiaolangdi reservoir respectively which are affiliated with the china meteorological administration the locations of the four weather stations are shown in fig 1 as shown in fig 13 a and b the changes in lake levels were in good agreement with precipitations and precipitation played a decisive role in the changes in lake levels the lake level raised as precipitation increased and fell as precipitation decreased thus forming periodic changes besides lake levels did not change immediately when precipitation changed and there was a lag of 1 3 months between the changes in precipitation and the changes in lake levels the lag between the changes of precipitation and the changes in lake level is also reported by mccoy and blanchard 2008 iwaki et al 2021 and li et al 2021 we think this is because a large part of the precipitation fell on the soil of the basin and it took time for the soil moisture to reach saturation then it took time for the saturated soil moisture to enter the surface runoff and the subsurface runoff to flow into the lake as shown in fig 13 c and d the precipitation did not have a direct effect on the changes in reservoir levels but indirectly affected the artificial control of reservoirs water discharges shang et al 2022 and bai et al 2020 studied the multi year average monthly discharges of longyangxia reservoir and xiaolangdi reservoir respectively and the results showed that the two reservoirs have similar periods of impounding and draining the most important function of the two reservoirs is flood control the water levels continued to fall from spring to the flood season and reached their lowest in july or august used for sediment regulation then they started to rise until the next spring and then started to fall again 6 conclusion in this study for a better evaluation of the performance of inland water level and volume changes monitoring by the icesat 2 we monitored the water level and volume changes of the major lakes and reservoirs in the yellow river basin based on the icesat 2 atlas laser altimetry and gee cloud computing platform in order to understand the distribution of water level and volume changes of lakes and reservoirs we selected relatively large 7 natural lakes 8 reservoirs and 3 artificial lakes and also applied the in situ lake level data of lake qinghai to examine the trends in our result finally we conducted some analysis including the measurement uncertainties of water level volume changes and the different drivers of water level changes in natural lakes and reservoirs based on the estimated result of the yellow river basin we found that upstream water volume changes were mainly affected by the combined actions of natural lakes artificial lakes and reservoirs midstream by reservoirs and downstream by only one relatively large artificial lake large water bodies showed large water volume changes benefit from improved spatial coverage of the icesat 2 observation seasonal water level and volume change analysis could be well performed in situ validation of lake level in lake qinghai indicated that the lake level change trend of our result was consistent with that of the in situ data and the rmse was only 7 cm after the reference coordinate system conversion comparative analysis showed that the variation water level trend of different waterbody types was much different from each other water levels of natural lake and reservoir both had obvious periodical changes throughout the year while artificial lake did not show that characteristic the natural lake level had lots of small fluctuations in one season and showed a regular gradual change with seasons but reservoir water level changed monotonously over time and showed abrupt changes in a short time the precipitation played a decisive role in the changes in natural lake levels and indirectly affected the artificial control of reservoirs water discharges the uncertainty of water volume change estimation was mainly affected by the measurement uncertainty of water level change for lakes but for reservoirs the estimated uncertainty of water volume change was affected by the combination of the measurement uncertainties of water level change and area in general the more photon counts of the icesat 2 altimetry dataset the higher measurement stability the introduction of atl13 significant wave height data may make the measurement more accurate however it might reduce the measurement stability of water level and volume change for both lakes and reservoirs the estimation uncertainty of water volume change was generally less than 9 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the yellow river major program of the national natural science foundation of china nsfc grant no 42041005 the second tibetan plateau scientific expedition and research step program grant no 2019qzkk0304 the nsfc grant no 41901288 beijing nova program of science and technology grant no z191100001119132 youth innovation promotion association cas and the fundamental research funds for the central universities we would like to acknowledge the nsidc for providing the icesat 2 altimetry dataset the usgs and google earth engine for processing landsat 8 image fusion and the bureau of hydrology and water resources of qinghai province for providing the in situ water level data 
1696,floods are among the devastating natural disasters that occurred very frequently in arid regions during the last decades accurate assessment of the flood susceptibility mapping is crucial in sustainable development it helps respective authorities to prevent as much as possible their irreversible consequences the digital elevation model dem spatial resolution is one of the most crucial base layer factors for modeling flood probability maps fpms therefore the main objective of this study was to assess the influence of the spatial resolution of the dems 12 5 m alos palsar and 30 m aster on the accuracy of flood probability prediction using three machine learning models mlms including random forest rf artificial neural network ann and generalized linear model glm this study selected 14 causative factors in the flood as independent variables and 220 flood locations were selected as dependent variables dependent variables were divided into training 70 and validation 30 for flood susceptibility modeling the receiver operating characteristic curve roc kappa index accuracy and other statistical criteria were used to evaluate the models accuracy the results showed that resolving the dem alone cannot significantly affect the accuracy of flood probability prediction regardless of the applied mlm and independently of the statistical model used to assess the performance accuracy in contrast the factors such as altitude precipitation and distance from the river have a considerable impact on floods in this region also the evaluation results of the models showed that the rf auc12 5 30m 0 983 0 975 model is more accurate in preparing the fpm than the ann auc12 5 30m 0 949 0 93 and glm auc12 5 30m 0 965 0 949 models this study s solution oriented findings might help water managers and decision makers to make the most effective adaptation and mitigation measures against potential flooding keywords heterogeneous data flood modelling random forest rf artificial neural network ann generalized linear model glm 1 introduction floods are the most devastating widespread and frequent natural disaster worldwide this global phenomenon causes property damages and puts in danger human life bell 2003 pirnazar et al 2017 floods are triggered by different factors both natural and human made some of the leading causes of floods are heavy rains frequent intense storms within a short duration and melting snow and ice gudiyangada nachappa et al 2020 wang et al 2019 moreover humans standard practice to build their settlements near rivers and other water bodies has also multiplied the casualties from flooding sharifi et al 2012 despite increasing efforts to develop and implement effective mitigation measures flood related mortality remains high doocy et al 2013 climate change and rapid landscape changes have intensified further flood occurrence and severity particularly in urban areas horritt and bates 2002 therefore flood modeling of floodplains and or inundation isolated areas is critical in taking effective adaptation and mitigation measures zhong et al 2018 for decades there has been a continuous effort to understand assess and predict flood events and their impact on the environment and human life physical based flood models are therefore being developed to serve this purpose costache et al 2020a in this regard the most typically used models use 1d geometry of the main channel connected with floodplain through some simple representation of grid cells where flow magnitude among them in response to water level fluctuations is commonly computed from manning s law and mass conservation equations ardıçlıoğlu and kuriqi 2019 papaioannou et al 2015 last decade in addition to 1d models 2d models were also frequently applied in flood modeling compared with 1d models the 2d models offer a more accurate estimation of flood propagation in the main channel and floodplain horritt and bates 2002 pradhan and youssef 2011 many conventional and non conventional 2d models are used for flood modeling bulti and abebe 2020 teng et al 2017 the hydrologic engineering center s river analysis system hec ras and mike teng et al 2017 the fundamental part of flood modeling is the hydraulic model calibration which requires accurate boundary conditions setting and a representative bathymetry of the floodplain or the expected inundated area hardy et al 1999 however that information is not always available or financially and or technically not possible to obtain for instance some of the main challenges in arid areas associated with flood records analysis include gauging problems and measurements and extreme events records el haddad et al 2021 in addition to the hydraulic models for floods modeling gis techniques several statistical and data driven techniques have been proposed and applied for identifying the flood susceptible areas domakinis et al 2020 mohammadi et al 2020a pradhan et al 2017 nevertheless these techniques are subjected to several mainly when applied in arid regions dodangeh et al 2020 horritt and bates 2002 arid and semi arid regions such as iran are frequently hit by flash floods that suddenly occurred due to the intense precipitation generated during rainstorms in such circumstances to cope with these issues the application of the remote sensing techniques combined with machine learning models has demonstrated to be a robust approach for mapping the susceptibility flooding areas khosravi et al 2019 pham et al 2020a towfiqul islam et al 2020 some of the most common machine learning models applied for flood susceptibility mapping include support vector machines svm choubin et al 2019 adaptive neuro fuzzy inference systems anfis sahoo et al 2020 artificial neural networks anns kia et al 2012 tehrany et al 2014 genetic algorithm ga hong et al 2018 boosted regression tree brt bui et al 2019 random forest rf band et al 2020 lee et al 2017 and parallel random forest prf ngo et al 2020 among others flood susceptibility mapping based remote sensing techniques combined with machine learning models relying on standalone models with one time train test data splitting for model calibration and validation in general it yields high accuracy results flood susceptibility mapping techniques allow us to predict future flood occurrences at high accuracy therefore assist in taking suitable measures to mitigate their potential casualties bulti and abebe 2020 islam et al 2020 in flood susceptibility mapping an essential issue that remains almost no or scarcely investigated and discussed in the literature particularly in arid regions is the spatial resolution effect of the digital elevation model dem in potential flooding areas spatial characterization several studies regarding the impact of the spatial resolution on the landslide susceptibility mapping have shown that dem resolution is an essential factor for effective future planning development of infrastructure and new urban areas and also providing adequate protection and mitigation measures by the respective authorities chang et al 2019 deng et al 2017 meena and gudiyangada nachappa 2019 mohammadi et al 2020b meena and gudiyangada nachappa 2019 compared three dem resolutions they found that 30 m dem showed higher accuracy than 12 5 m and 90 m dem landslide susceptibility in kullu valley himalayas chen et al 2020 applied seven different spatial resolutions of dems i e 30 40 50 60 70 80 and 90 m respectively they found that the best performances were produced at 70 m dem resolution concluding that more acceptable resolutions do not necessarily provide higher accuracy in landslide susceptibility mapping lee et al 2004 assessed the accuracy of dems five different spatial resolutions i e at 5 10 30 100 and 200 m spatial resolution for landslide susceptibility mapping they concluded the difference between more satisfactory resolutions was not significant but with a very coarse resolution i e 100 and 200 m the accuracy was considerably reduced similar conclusions were also obtained by other authors such as brock et al 2020 pradhan and sameen 2017 van westen et al 2008 inspired by the studies mentioned above valuable findings this study s main objective is to compare and estimate the dem spatial resolution s effect on the accuracy of flood susceptibility mapping based on novel machine learning models namely in this study three machine learning models were employed to generate flood susceptibility maps using remote sensing and gis tools considering two different spatial resolutions the machine learning models applied in this study are rf ann and generalized linear model glm these models were selected for many reasons including being newly involved in the field of flood susceptibility in arid regions similar to the one analyzed in this study adequate for regional and semi regional scale applications relying mainly on remote sensing datasets rather than intensive field investigations the specific objectives of this study are i to evaluate the performance of three rarely applied machine learning models for each spatial resolution of dems ii to explore the effects of dem spatial resolution on the accuracy of flood susceptibility mapping iii to investigate whether there is any potential relation between resolution degree the accuracy of flood susceptibility maps and the applied machine learning model iv finally provide practical recommendations regarding the effective ways of estimating the potential flooding areas we believe that this study s solution oriented findings provide valuable information to policymakers to take precautions and effective measures to avoid casualties moreover flood susceptibility maps can identify and delineate the most flood vulnerable areas by informing planners and decision makers to choose favorable locations for future development such as new urban areas or infrastructure related projects the rest of the manuscript is organized as follows section 2 provides brief information about the study site section 3 describes the methodological approach applied in this study section 4 shows the main results section 5 discuss the main findings resulted from this study and also limitations finally the main conclusions are summarized in section 6 2 description of the study area yasouj dena watershed is located in the northeast of kohgiluyeh boyer ahmad provinces iran this region is between 51 10 to 51 52 east longitude and 30 13 to 30 55 north latitude fig 1 the basin is limited to the zagros mountains from the north and the beshar river from the south the study area is 2185 km2 an enormous part of this mountainous area covered with oak forests the average altitude of this watershed is 2534 m and its average slope is 28 4 the climate of the study area is semi humid and cold according to amberje classification and its average temperature is 15 2 c also the average rainfall of the study area is approximately 752 mm most of the rain in the study area occurs in december and january the summer rainfall is less than 2 mm the average annual discharge of the beshar river which is one of the most important rivers in the study area is 55 8 m3 s the most crucial population areas in the study area include yasouj sisakht dena and margon counties biodiversity conservation plan in the central zagros landscape 3 material and methods 3 1 dataset flood is one of the most complex natural phenomena that can cause different hydrological responses depending on the region s hydrogeomorphological features therefore to understand this phenomenon s effects it is necessary to know the factors influencing it most ngo et al 2020 towfiqul islam et al 2020 considering the yasouj dena watershed hydrogeomorphological characteristics and recommendations from previous studies al abadi 2018 costache et al 2020c 14 factors that significantly influence the flood magnitude was selected these factors include slope altitude curvature distance from the river drainage density land use lithology aspect precipitation slope length topography wetness index twi topography position index tpi soil and normalized difference water index ndwi the baseline map for extracting some of these factors i e slope aspect altitude curvature river slope length twi and tpi is the dem two types of dems were used to investigate the effect of a spatial resolution of the dem on flood probability the dems with 12 5 and 30 m spatial resolution were obtained from alos palsar https vertex daac asf alaska edu and aster global digital elevation map https asterweb jpl nasa gov gdem asp respectively fig 2 it is important to emphasize that selecting the dataset used in flood modeling should be carefully chosen based on the lu and lc characteristics in this context in areas covered by dense forest vertical accuracy may be significantly affected therefore in such conditions aw3d30 and merit hydro may provide higher accuracy vertical accuracy of freely available global digital elevation models aster aw3d30 merit tandem x srtm and nasadem uuemaa et al 2020 nevertheless the study site analyzed in this paper is located in a semi arid region with very little vegetation coverage the forest s presence is very scarce over the entire region therefore the chosen raster dataset does not compromise the overall quality of the results also in this study to predict the potential future flood risk areas in the study area the locations of historical floods that occurred in this area were used the use of historical floods to predict future floods has been used by various researchers in recent years hosseini et al 2020 yariyan et al 2020b finally the last 220 flood locations were selected using available data maps and field surveys these flood locations were randomly divided into validation 30 and training 70 one hundred fifty four flood sites were randomly selected for model training the flood layer which is considered a dependent factor was created the flood layer is made with values 0 and 1 because value 1 indicates flood and value 0 indicate the absence of flood in the area accordingly 154 points were selected as non flood areas to create a value of 0 since floods cannot occur in high areas such as high hills non flood areas were randomly selected from these locations the remaining flood points 66 points were used for testing 3 2 flood influencing factors the main factor influencing the flood susceptibility are extracted for the respective dems and generated in the arcgis environment 3 2 1 altitude the topography is an essential factor that significantly influences the direction and speed of surface runoff previous studies have emphasized that elevation is among the most critical factors in flood susceptibility mapping avand et al 2020 azareh et al 2019 nevertheless it is inversely related to flooding the higher the elevation the lower the flood probability occurrence differences in elevations are associated with differences in climate conditions which significantly impact vegetation and soil properties thus the study area s altitude map was prepared of topography maps and pixels were measured from a dem of the watershed in the arcgis environment 3 2 2 topographic wetness index twi twi is a secondary topographical dimensionless index that characterizes topography s influence on the spatial distribution of wetness conditions and the landscape s saturation levels to generate runoff sørensen et al 2005 twi indicates the relationship between surface gradient and topsoil moisture content it is computed using the following equation twi a s t a n σ a s a l where a s is the draining at a given point t a n σ represents the slope a is areas of land upstream and l is the adequate slope i e measured to the point in the flow direction higher values indicate areas under consideration have high moister and are more productive in terms of runoff generation to prepare the twi the dem with ascii format was used in the sagagis software environment 3 2 3 slope the slope angle controls physiographic trends and soil moisture patterns ghorbanzadeh et al 2019a therefore it is an essential factor in hydrologic conditions that influence surface infiltration runoff rates and underground drainage avand et al 2021 the slope aspect strongly affects several hydrologic processes via evapotranspiration the direction of frontal precipitation involving weathering processes and vegetation development especially in drier environmental conditions lee et al 2017 a slope map was created from the dem using the spatial analysis tool in the arcgis environment fig 3 3 2 4 topography position index tpi the tpi is dimensionless increasingly used to characterize the topographic slope positions and automate landform classifications de reu et al 2013 tpimeasures the difference between elevation at the central point z o and the average elevation z within a predetermined radius r and is computed using the following equation 2 tpi z 0 z 3 z 1 n r i r z i positivetpivalues indicate that the central point is located higher than its average surroundings in contrast negative values indicate a position lower than the average the range oftpidepends on elevation differences andrlarger values mainly reveal central landscape units smaller values highlight smaller features such as minor valleys and ridges tpi was calculated using saga gis software 3 2 5 aspect aspect characterizes the exposure of the land surface towards sunlight it was also measured from the dem in the arcgis environment gudiyangada nachappa et al 2020 sunlight intensity varies for the various slope aspects aspects receiving being less exposed to the sunlight have more soil moisture rainfall on moist slopes will more likely generate higher runoff contributing to the flood risk downhill aspect measures were divided into nine classes n ne e se s sw w nw and flat fig 3 in the northern hemisphere the north facing and east facing directions are more likely to have water resources than south facing and west facing slopes avand et al 2021 bui et al 2019 solar radiation is lower on northern and eastern slopes than on southern and western slopes so evaporation is low and soil moisture is high on north facing and east facing inclines for this reason vegetation has developed more on northern and eastern faces dense vegetation in these areas increases the percolation of surface runoff 3 2 6 lithology infiltration capacity and sediment transport ratios are essential variables of a region s lithology diakakis et al 2012 yariyan et al 2020b the type of geological formations significantly influences the permeability of soils the finer is the upper topsoil layer the lower is the porosity and subsequently the generated runoff flow will increase the geological formations for this study are presented in table 1 the geological map of the study area was obtained from the geological survey mineral explorations agency of iran gsi https gsi ir fa 3 2 7 precipitation precipitation including rainfall and snowfall is the most crucial climate parameter affecting several hydrological processes rahman et al 2019 it must be measured as it is the only input of water into the catchment precipitation amounts and rates significantly affect the flood risk bui et al 2019 notably the intensity and frequency of rainfall events are the essential variables average annual precipitation was calculated from long term 1990 2017 precipitation data gathered at five rain gauges yasouj sisakht pataveh kakan gachsaran region maps of precipitation were generated using kriging in arcgis software precipitation in the watershed ranged from 870 mm at higher elevations to 380 in lower elevations 3 2 8 distance to the river river flows are the main alleyways for flood discharge amplification consequently the areas near rivers are highly susceptible to flooding several studies emphasize that proximity to a river influences the likelihood of flooding thus floods are most likely to occur near the watercourse hong et al 2018 papaioannou et al 2015 generally speaking as the distance from a river increases flood risk diminishes in this regard the river s distance is one of the leading conditioning factors due to its significant impact on the flood spread and magnitude in this study the river s distance was calculated using the arcgis environment buffer tool costache 2019 the locations of the historic floods in the study area tended to be close to the river 3 2 9 normalized difference water index ndwi ndwi is a practical method developed to delineate open water bodies and enhance their presence in remotely sensed digital imagery processing gao 1996 the ndwi uses reflected near infrared radiation and visible green light to improve open water body features while removing soil and terrestrial vegetation structures an appropriate threshold of the index is then established to separate water bodies from other land cover features based on the spectral characteristics the ndwi has been successfully used to delineate surface water features in several studies ji et al 2009 liuzzo et al 2020 mcfeeters 1996 the ndwi was obtained using landsat 8 satellite oli sensor and using the following formula in arcgis software 4 ndwi nir s w i r nir s w i r nir is the same near infrared with a wavelength between 0 841 and 0 876 and swir is part of the amplitude with a wavelength between 1 628 and 1 652 3 2 10 land use land use and land cover changes have a significant influence on several hydrological responses in this regard many studies have been focused on assessing the impacts of future trends of lulc at different scales on flood risk management and highlight that lulc plays an essential role in the runoff volume and rate costache et al 2020b islam et al 2020 lulc changes such as shifts from pasture to arable land forestry to agriculture rain and or groundwater fed to irrigated agriculture or forest use to urbanized areas are primary drivers for many landscape changes akter et al 2018 the lulc layers were prepared using operational land imager oli sensor landsat 8 satellite image after atmospheric and geometric corrections in the google earth engine web environment talukdar et al 2020 yariyan et al 2020b lulc were classified as either water residential garden farmland baren forest rock garden and rangeland 3 2 11 drainage density the drainage density dd represents the spacing between the channels dd is computed as the total length of channels of all orders per unit area divided by the area of a drainage basin therefore dd has an essential role in flood susceptibility occurrence alam et al 2020 high drainage density indicates high runoff volumes and rapid flood peaks therefore a drainage network s conditions considerably influence the runoff accumulates and the flood hydrograph curve steepens avand et al 2021 notably regional floods are often related to peak discharge volume and drainage area the drainage density factor was prepared using the streaming factor extracted from the dems to do this the density tool is used in arcgis software 3 2 12 stream power index spi the spi characterizes the flow power in terms of erosion it describes the erosive potential and surface runoff rate malik et al 2020 higher spi indicates higher surface runoff capacity and rate in contrast lower spi signifies the lower surface runoff capacity consequently heavy rainfall in the low spi region leads to a higher risk of flooding several studies have incorporated the spi to predict flood susceptibility in different areas bui et al 2019 hosseini et al 2020 yariyan et al 2020b the spi is computed using the following equation 5 spi a s t a n β where a s represent the specific catchment area in m2 and β represent the slope in degree spi was prepared using a dem map with ascii format and different spatial resolutions in the sagagis software environment spi map was generated in five different classes using quantile classification malik et al 2020 naghibi et al 2017 3 2 13 soil soil plays an essential role in the generation of surface runoff and inundation process losses of soil have altered the water retention and surface runoff generation influencing the flooding susceptibility hong et al 2018 consequently runoff generation is higher in areas characterized by porous soils and with low depth especially in the catchment upstream and vice versa papaioannou et al 2015 the soil layer was prepared using a soil map of iran with a scale of 1 100 000 in arcgis software fig 3 3 2 14 curvature the curvatures influence the water flow velocity and erosion and deposition processes along the watercourse malik et al 2020 profile curvature represents the slope change along the flow line also it indicates the flow acceleration areas plan curvature shows the aspect change along a contour and indicates the flow convergence and diversion the curvature comprises three categories convex concave and flat surface convex curvatures are characterized by increasing slope downhills and negative values in contrast the concave curvatures indicate the slope decreasing downhills and having positive values avand et al 2020 azareh et al 2019 dodangeh et al 2020 the curvature is a practical factor in runoff flow to detect flood susceptibility curvature was created using the respective dems of the study area in arcgis software fig 3 3 3 description of machine learning models 3 3 1 random forest rf the rf model is one of the most widespread algorithms applied to address the different nature of multi classification and prediction problems rf combines bagging ensemble learning and the random subspace method initially introduced breiman 2001 one of the main problems of regression models is that they are prone to overfitting the training data and perform poorly when given hidden data nachappa et al 2020 the rf model differently from other models has a low sensitivity to multi collinearity its results are relatively stable in missing and unfitted data tavakkoli piralilou et al 2019 the rf model consists of two main parameters the number of trees per forest and the number of random predictor variables each tree uses a sensitivity study of these parameters was performed to determine their effect on model performance the model was trained with the number of trees varying between 2 and 2000 with the default number of variables per tree to determine its sensitivity to the number of trees per forest sadler et al 2018 in addition to the actual predictive abilities of the rf model it can also be used to understand variable importance since many regression trees are produced with different sets of input variables the rf algorithm learns and records the input variables relative importance in predicting the output schoppa et al 2020 this capability is desirable as one of this study s objectives is to understand the relative importance of explanatory variables in predicting flood susceptibility in an arid region such understanding could be used to direct future investments in improving observational networks and building more resilient infrastructure to conduct this research biomod 2 package was used in r statistical software essential parameters in a random forest rf include the number of variables selected per tree node mtry the number of trees ntree and the minimum size or minimum observations in terminal nodes or leaves node size before performing the analyzes the fair values of these parameters must be determined optimal values were chosen based on the existing defaults for performing a rf model for a m try equal to the number of variables divided by 3 a n tree equal to 500 and a node size equal to 5 3 3 2 artificial neural network ann the ann model is a mathematical model of human perception based that can be trained for performing a particular task considering a set of empirical data anns are well known as so called and also considered as black box models they can make a robust prediction and are an essential tool for modeling when the relationships between data are unknown sahoo et al 2009 shahabi et al 2019 the processing units of an artificial neural network are called neurons which are arranged in layers links of variable weights connect neurons between layers the most commonly used ann architecture is the feed forward neural network ghorbanzadeh et al 2019b the network has one input layer with neurons or nodes where data are introduced hidden layers with several nodes or neurons the data are processed and the output layer where the given inputs are produced nikoo et al 2016 the number of neurons in a hidden layer is decided after training and testing procedures training of anns consists of inserting samples of inputs and target outputs to the network and then iteratively adjusting internal parameters based on the desired performance ali and shahbaz 2020 to conduct this research biomod 2 package was used in r statistical software the most critical parameters in the artificial neural network ann model include the number of cross validations to find the best size nbcv the maximum number of iterations maxit and the number of hidden layers size in this study default values were used for nbcv equal to 5 maxit equal to 200 and 3 hidden layers 3 3 3 generalized linear model glm the glm based on a logistic link function introduced initially by nelder and wedderburn 1972 has been widely used to solve different hydrological problems this algorithm consists of a linear relationship between a logistic regression of the dependent and independent variables recent applications of the glm have confirmed a satisfactory performance in reproducing the persistence characteristics of rainfall modeling rashid and beecham 2019 and flood modeling avand et al 2020 and landslide susceptibility pourghasemi and rossi 2017 a glm can model binary data sets according to presence absence data using a logistic model hosseini et al 2020 lee and pradhan 2007 to conduct this research biomod 2 package was used in r statistical software in the generalized linear model glm aic statistic is used to evaluate the model glm control is used to control the parameters 3 4 variance inflation factor and tolerance inflation variance factor vif is used to determine the multi collinearity between independent variables primarily related to tolerance when there are more than two independent variables it is equal to the inverse of the tolerance the amount of vif is related to the amount of variable standard error that increased due to multi collinearity the increase in standard error is equal to the second root of the vif khosravi et al 2016 tolerance could mostly be called a broad form of multiple correlation coefficient the desired variable is used as a dependent variable in regression analysis and other variables are used as independent variables the tolerance value varies between 0 and 1 zero tolerance indicates that this variable is entirely predictable through other independent variables and therefore there is perfect multi collinearity a tolerance equal to one means that the variable is uncorrelated with different independent variables arabameri et al 2018 6 tolerance 1 r 2 7 vif 1 1 r 2 3 5 evaluation of machine learning models 3 5 1 roc curve evaluating the results of modeling is one of the essential steps in this study the performance of flood probability prediction models was evaluated using two quantitative measures called the receiver operating characteristic roc curve and the area under the curve auc the roc curve was prepared using 30 of the test data in this curve the sensitivity is a function of the false positive rate a model s sensitivity is the ratio of true positives to the sum of true positives and the number of false negatives simultaneously specificity is the ratio of true negatives to the sum of true and false positives yariyan et al 2020c yousefi et al 2020 this curve can be generated by plotting the sensitivity on the y axis against the cumulative distribution function of the false positive rate on the x axis the amount of auc can be classified into 5 classes including excellent 1 0 9 very good 0 9 0 8 good 0 8 0 7 average 0 7 0 6 and poor 0 6 0 5 pham et al 2019 yariyan et al 2020a 8 auc t p tn p n 9 sensitivity tn tn f p 10 specificity tn tp f n tp and tn are considered the rate of pixels classified correctly as flood and non flood fp is the number of expected floods that are non flood fn is the number of non floods p and n are the total numbers of floods and non floods in addition to the mentioned criteria accuracy cohen s kappa and surface ratio sr statistical indices evaluated the models performance 11 accuracy tp t n tp t n f p f n kappa coefficient and statistical analysis based on it are numerical values between 1 to 1 the closer to 1 indicates the existence of the proportional and direct agreement measures close to 1 indicate the existence of an inverse agreement and vice versa and measures close to zero indicate disagreement 12 kappa o e 1 e where o represents the observational value and e represents the estimated value 4 results 4 1 multi collinearity analysis between independent variables a high correlation between independent input variables causes incorrect prediction results to evaluate the correlation between the independent variables the vif and tolerance tol were used the threshold value for determining the amount of multi collinearity was five the results showed that according to the vif method the amount of vif for the factors used in this study is less than the threshold value so these factors are independent of each other there is no multi collinearity between the factors the results of the tol factor also showed that because the value of this index for most factors is close to one so according to this method there is no correlation between factors table 2 identifying the most critical factors influencing floods is one of the ways to understand floods better the importance of each factor used in this study based on all three rf ann and glm models is shown in fig 4 the results show that in the rf model altitude 0 162 ndwi 0 084 and distance from river 0 13 factors in the ann model altitude 0 27 precipitation 0 319 and distance from river 0 114 factors and the glm model altitude 0 362 precipitation 0 186 and slope 0 135 factors respectively had the most significant impact on floods in the study area therefore the altitude precipitation and distance from the river factors in all three models have the most significant impact on floods 4 2 flood probability maps the study area s flood probability map fpm was generated using rf ann and glm models for a spatial resolution of 12 5 m and 30 m data and was classified in arcgis software to create the ability to compare and produce maps with the same conditions the classification of maps related to both data sets was performed using the natural break algorithm one of the classification algorithms of raster maps finally based on previous studies costache et al 2020c arabameri et al 2020 and the type of maps available these maps were divided into five classes very low low moderate high and very high to better understand the flood locations in the study area part of the map has been magnified throughout the maps the results of this division are shown in fig 5 the area of flood probability classes related to resolution accuracy data of 12 5 m and 30 m is shown in fig 6 as shown in fig 6 the very low flood probability class has the largest area in both data types the very low class area in modeling with 12 5 m data in rf ann and glm models is 937 808 and 1047 km2 respectively the class area is also tiny in the map produced using 30 m resolution of dem in rf ann and glm models respectively 1061 660 and 832 km2 the area of the very high flood probability class in the study area using 12 5 m data based on the rf ann and glm models is 304 325 and 259 km2 respectively while the area of the very high flood probability class in the study area using 30 m data based on the rf ann and glm models is 253 404 and 326 km2 respectively 4 3 model evaluation and comparison the evaluation of all models used in this study was performed using a roc curve the auc results for all three models in the validation stage show an acceptable accuracy level table 3 and 4 so that the value of auc for the rf ann and glm models using 12 5 m data is 0 983 0 949 and 0 965 respectively while this value is for rf ann and glm models are 0 975 0 93 and 0 949 using 30 meter data respectively fig 7 therefore based on the results the rf model agrees with the data available in the validation stage in both spatial resolutions of 12 5 and 30 m the value of the kappa coefficient and accuracy for the rf model in the validation stage using 12 5 m data is 0 841 and 0 92 this value is 0 841 and 0 92 respectively using data with a spatial resolution of 30 m table 3 and 4 fig 8 tables 5 and 6 fig 5 shows the correlation between the models results using two data sets with a spatial resolution of 12 5 and 30 m in this figure each model s outputs were compared using two data sets the results showed that the outputs of the rf model with a correlation value of 0 96 have the highest correlation fig 9 5 discussion and conclusion fast easy and accurate preparation of potential flood zones is essential to predict better model manage and understand floods in any region literature reviews have shown that mlms are suitable for modeling flood probability in different watershed types costache and tien 2019 nachappa et al 2020 yariyan et al 2020b many models have been evaluated to flood susceptibility mapping chen et al 2020a b hosseini et al 2020 however the performance of these models depends mainly on the input data therefore it is essential to check the data s quality before presenting it as input to mlms typically many input factors in flood modeling are generated from the dem as a result the quality of the dem factors used in the modeling is critical in producing accurate outputs of the flood probability map in this study to prepare a flood probability map in the yasouj dena watershed three mlms including rf ann and glm have been used the inventories of 220 flood locations were used as dependent variables besides 14 independent and influential variables on the flood with two pixels of different sizes of 12 5 and 30 m were used to investigate the effect of dem spatial resolution on the spatial distribution of flood finally the flood probability map was divided into five classes using the natural failure algorithm very low low medium high and very high the multi collinearity analysis results between independent variables showed that none of the factors have a high correlation all factors can be used in modeling therefore similar to previous studies hong et al 2018 papaioannou et al 2015 wang et al 2019 the factors used in this study included slope altitude curvature distance from the river drainage density land use lithology aspect precipitation slope length twi tpi soil and ndwi the results of evaluating the practical importance of those factors in flood susceptibility mapping using three models showed that altitude precipitation and distance from the river factors significantly impact flood occurrence in the study area the findings of this study are compatible with the findings of el haddad et al 2021 in the wadi qena watershed shahabi et al 2020 in the haraz watershed and avand et al 2021 avand et al 2020 in the tajan watershed given that over 75 of the yasouj dena watershed is mountainous with an average elevation of 2534 m and an average slope of 28 4 so the topographic factor could have a significant impact on shallow runoff amount and type of rainfall flow velocity and runoff volume in the study area because of abundant springs and snow cover in winter the heights upstream of the studied watershed provide a large discharge volume from the beshar river also because residential and agricultural areas are often next to the beshar river and downstream and low slope increasing the runoff volume at some times of the year causes flooding in residential areas and also causes damage in agricultural areas therefore the watershed s altitude factor significantly impacts rainfall and runoff making it more critical in floods than the river factor s distance because of the region s mountainous nature these results are consistent with the findings avand et al 2021b and el haddad et al 2021 this study evaluated the effect of the scale of influential flood factors produced using dems with a spatial resolution of 12 5 m and 30 m since most of the factors used in this study altitude slope aspect river slope length tpi twi are derived from the dems this factor s quality could significantly impact the flood susceptibility mapping the used models evaluation results showed that spatial resolution alone does not significantly affect the model prediction other factors such as the type of model used and local condition are also remarkably effective in modeling accuracy talukdar et al 2020 as the evaluation results of the used models showed the accuracy of mlms using data with a spatial resolution of 12 5 m is higher than the accuracy of data with a 30 m spatial resolution each pixel in the dems of 30 and 12 5 m represents 900 and 156 25 m of each factor independent variable respectively therefore the location of flood points a dependent variable in this study is different in various dems dems different pixel sizes cause dependent variables to be placed in different independent variable classes resulting in different modeling output these results are consistent with the findings chang et al 2019 and meena and gudiyangada nachappa 2019 therefore the evaluation results of mlms using 12 5 m spatial resolution data are more consistent with the flood points in the study area the accuracy of these models is higher than the accuracy of models with 30 m spatial resolution data the results vary from region to region and even with different dems chen et al 2017 even the results differ from other mlms or statistical models pham et al 2020b therefore it is suggested to replicate a similar approach by comparing different models in different regions and different data the results showed that increasing the spatial resolution cannot increase the accuracy of modeling the flood probability and may even decrease at higher resolutions e g 5 m consistent with some researchers findings chang et al 2019 however in each case the different scales of the dems have different results therefore testing dems with different scales is necessary to select an optimal dem for flood probability mapping also in this study we found that the dem change affects only the dem factors the dem scale did not influence other factors such as lithology and precipitation therefore perhaps one reason for the reduction in model results is the lack of change in factors not affected by the dem also to increase the accuracy of mlms the input flood points to mlms must be continuously updated pham et al 2021 thus based on performance and prediction accuracy the random forest model is suggested to be used in other regions worldwide characterized by similar hydrogeomorphological conditions as a final recommendation since studies on flood occurrence aim to develop a susceptibility map with high prediction accuracy the obtained results can help decision making and policy planning in areas prone to floods funding we acknowledge open access funding by the university of salzburg declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors appreciate the iranian soil conservation and watershed management research center for supporting this research 
1696,floods are among the devastating natural disasters that occurred very frequently in arid regions during the last decades accurate assessment of the flood susceptibility mapping is crucial in sustainable development it helps respective authorities to prevent as much as possible their irreversible consequences the digital elevation model dem spatial resolution is one of the most crucial base layer factors for modeling flood probability maps fpms therefore the main objective of this study was to assess the influence of the spatial resolution of the dems 12 5 m alos palsar and 30 m aster on the accuracy of flood probability prediction using three machine learning models mlms including random forest rf artificial neural network ann and generalized linear model glm this study selected 14 causative factors in the flood as independent variables and 220 flood locations were selected as dependent variables dependent variables were divided into training 70 and validation 30 for flood susceptibility modeling the receiver operating characteristic curve roc kappa index accuracy and other statistical criteria were used to evaluate the models accuracy the results showed that resolving the dem alone cannot significantly affect the accuracy of flood probability prediction regardless of the applied mlm and independently of the statistical model used to assess the performance accuracy in contrast the factors such as altitude precipitation and distance from the river have a considerable impact on floods in this region also the evaluation results of the models showed that the rf auc12 5 30m 0 983 0 975 model is more accurate in preparing the fpm than the ann auc12 5 30m 0 949 0 93 and glm auc12 5 30m 0 965 0 949 models this study s solution oriented findings might help water managers and decision makers to make the most effective adaptation and mitigation measures against potential flooding keywords heterogeneous data flood modelling random forest rf artificial neural network ann generalized linear model glm 1 introduction floods are the most devastating widespread and frequent natural disaster worldwide this global phenomenon causes property damages and puts in danger human life bell 2003 pirnazar et al 2017 floods are triggered by different factors both natural and human made some of the leading causes of floods are heavy rains frequent intense storms within a short duration and melting snow and ice gudiyangada nachappa et al 2020 wang et al 2019 moreover humans standard practice to build their settlements near rivers and other water bodies has also multiplied the casualties from flooding sharifi et al 2012 despite increasing efforts to develop and implement effective mitigation measures flood related mortality remains high doocy et al 2013 climate change and rapid landscape changes have intensified further flood occurrence and severity particularly in urban areas horritt and bates 2002 therefore flood modeling of floodplains and or inundation isolated areas is critical in taking effective adaptation and mitigation measures zhong et al 2018 for decades there has been a continuous effort to understand assess and predict flood events and their impact on the environment and human life physical based flood models are therefore being developed to serve this purpose costache et al 2020a in this regard the most typically used models use 1d geometry of the main channel connected with floodplain through some simple representation of grid cells where flow magnitude among them in response to water level fluctuations is commonly computed from manning s law and mass conservation equations ardıçlıoğlu and kuriqi 2019 papaioannou et al 2015 last decade in addition to 1d models 2d models were also frequently applied in flood modeling compared with 1d models the 2d models offer a more accurate estimation of flood propagation in the main channel and floodplain horritt and bates 2002 pradhan and youssef 2011 many conventional and non conventional 2d models are used for flood modeling bulti and abebe 2020 teng et al 2017 the hydrologic engineering center s river analysis system hec ras and mike teng et al 2017 the fundamental part of flood modeling is the hydraulic model calibration which requires accurate boundary conditions setting and a representative bathymetry of the floodplain or the expected inundated area hardy et al 1999 however that information is not always available or financially and or technically not possible to obtain for instance some of the main challenges in arid areas associated with flood records analysis include gauging problems and measurements and extreme events records el haddad et al 2021 in addition to the hydraulic models for floods modeling gis techniques several statistical and data driven techniques have been proposed and applied for identifying the flood susceptible areas domakinis et al 2020 mohammadi et al 2020a pradhan et al 2017 nevertheless these techniques are subjected to several mainly when applied in arid regions dodangeh et al 2020 horritt and bates 2002 arid and semi arid regions such as iran are frequently hit by flash floods that suddenly occurred due to the intense precipitation generated during rainstorms in such circumstances to cope with these issues the application of the remote sensing techniques combined with machine learning models has demonstrated to be a robust approach for mapping the susceptibility flooding areas khosravi et al 2019 pham et al 2020a towfiqul islam et al 2020 some of the most common machine learning models applied for flood susceptibility mapping include support vector machines svm choubin et al 2019 adaptive neuro fuzzy inference systems anfis sahoo et al 2020 artificial neural networks anns kia et al 2012 tehrany et al 2014 genetic algorithm ga hong et al 2018 boosted regression tree brt bui et al 2019 random forest rf band et al 2020 lee et al 2017 and parallel random forest prf ngo et al 2020 among others flood susceptibility mapping based remote sensing techniques combined with machine learning models relying on standalone models with one time train test data splitting for model calibration and validation in general it yields high accuracy results flood susceptibility mapping techniques allow us to predict future flood occurrences at high accuracy therefore assist in taking suitable measures to mitigate their potential casualties bulti and abebe 2020 islam et al 2020 in flood susceptibility mapping an essential issue that remains almost no or scarcely investigated and discussed in the literature particularly in arid regions is the spatial resolution effect of the digital elevation model dem in potential flooding areas spatial characterization several studies regarding the impact of the spatial resolution on the landslide susceptibility mapping have shown that dem resolution is an essential factor for effective future planning development of infrastructure and new urban areas and also providing adequate protection and mitigation measures by the respective authorities chang et al 2019 deng et al 2017 meena and gudiyangada nachappa 2019 mohammadi et al 2020b meena and gudiyangada nachappa 2019 compared three dem resolutions they found that 30 m dem showed higher accuracy than 12 5 m and 90 m dem landslide susceptibility in kullu valley himalayas chen et al 2020 applied seven different spatial resolutions of dems i e 30 40 50 60 70 80 and 90 m respectively they found that the best performances were produced at 70 m dem resolution concluding that more acceptable resolutions do not necessarily provide higher accuracy in landslide susceptibility mapping lee et al 2004 assessed the accuracy of dems five different spatial resolutions i e at 5 10 30 100 and 200 m spatial resolution for landslide susceptibility mapping they concluded the difference between more satisfactory resolutions was not significant but with a very coarse resolution i e 100 and 200 m the accuracy was considerably reduced similar conclusions were also obtained by other authors such as brock et al 2020 pradhan and sameen 2017 van westen et al 2008 inspired by the studies mentioned above valuable findings this study s main objective is to compare and estimate the dem spatial resolution s effect on the accuracy of flood susceptibility mapping based on novel machine learning models namely in this study three machine learning models were employed to generate flood susceptibility maps using remote sensing and gis tools considering two different spatial resolutions the machine learning models applied in this study are rf ann and generalized linear model glm these models were selected for many reasons including being newly involved in the field of flood susceptibility in arid regions similar to the one analyzed in this study adequate for regional and semi regional scale applications relying mainly on remote sensing datasets rather than intensive field investigations the specific objectives of this study are i to evaluate the performance of three rarely applied machine learning models for each spatial resolution of dems ii to explore the effects of dem spatial resolution on the accuracy of flood susceptibility mapping iii to investigate whether there is any potential relation between resolution degree the accuracy of flood susceptibility maps and the applied machine learning model iv finally provide practical recommendations regarding the effective ways of estimating the potential flooding areas we believe that this study s solution oriented findings provide valuable information to policymakers to take precautions and effective measures to avoid casualties moreover flood susceptibility maps can identify and delineate the most flood vulnerable areas by informing planners and decision makers to choose favorable locations for future development such as new urban areas or infrastructure related projects the rest of the manuscript is organized as follows section 2 provides brief information about the study site section 3 describes the methodological approach applied in this study section 4 shows the main results section 5 discuss the main findings resulted from this study and also limitations finally the main conclusions are summarized in section 6 2 description of the study area yasouj dena watershed is located in the northeast of kohgiluyeh boyer ahmad provinces iran this region is between 51 10 to 51 52 east longitude and 30 13 to 30 55 north latitude fig 1 the basin is limited to the zagros mountains from the north and the beshar river from the south the study area is 2185 km2 an enormous part of this mountainous area covered with oak forests the average altitude of this watershed is 2534 m and its average slope is 28 4 the climate of the study area is semi humid and cold according to amberje classification and its average temperature is 15 2 c also the average rainfall of the study area is approximately 752 mm most of the rain in the study area occurs in december and january the summer rainfall is less than 2 mm the average annual discharge of the beshar river which is one of the most important rivers in the study area is 55 8 m3 s the most crucial population areas in the study area include yasouj sisakht dena and margon counties biodiversity conservation plan in the central zagros landscape 3 material and methods 3 1 dataset flood is one of the most complex natural phenomena that can cause different hydrological responses depending on the region s hydrogeomorphological features therefore to understand this phenomenon s effects it is necessary to know the factors influencing it most ngo et al 2020 towfiqul islam et al 2020 considering the yasouj dena watershed hydrogeomorphological characteristics and recommendations from previous studies al abadi 2018 costache et al 2020c 14 factors that significantly influence the flood magnitude was selected these factors include slope altitude curvature distance from the river drainage density land use lithology aspect precipitation slope length topography wetness index twi topography position index tpi soil and normalized difference water index ndwi the baseline map for extracting some of these factors i e slope aspect altitude curvature river slope length twi and tpi is the dem two types of dems were used to investigate the effect of a spatial resolution of the dem on flood probability the dems with 12 5 and 30 m spatial resolution were obtained from alos palsar https vertex daac asf alaska edu and aster global digital elevation map https asterweb jpl nasa gov gdem asp respectively fig 2 it is important to emphasize that selecting the dataset used in flood modeling should be carefully chosen based on the lu and lc characteristics in this context in areas covered by dense forest vertical accuracy may be significantly affected therefore in such conditions aw3d30 and merit hydro may provide higher accuracy vertical accuracy of freely available global digital elevation models aster aw3d30 merit tandem x srtm and nasadem uuemaa et al 2020 nevertheless the study site analyzed in this paper is located in a semi arid region with very little vegetation coverage the forest s presence is very scarce over the entire region therefore the chosen raster dataset does not compromise the overall quality of the results also in this study to predict the potential future flood risk areas in the study area the locations of historical floods that occurred in this area were used the use of historical floods to predict future floods has been used by various researchers in recent years hosseini et al 2020 yariyan et al 2020b finally the last 220 flood locations were selected using available data maps and field surveys these flood locations were randomly divided into validation 30 and training 70 one hundred fifty four flood sites were randomly selected for model training the flood layer which is considered a dependent factor was created the flood layer is made with values 0 and 1 because value 1 indicates flood and value 0 indicate the absence of flood in the area accordingly 154 points were selected as non flood areas to create a value of 0 since floods cannot occur in high areas such as high hills non flood areas were randomly selected from these locations the remaining flood points 66 points were used for testing 3 2 flood influencing factors the main factor influencing the flood susceptibility are extracted for the respective dems and generated in the arcgis environment 3 2 1 altitude the topography is an essential factor that significantly influences the direction and speed of surface runoff previous studies have emphasized that elevation is among the most critical factors in flood susceptibility mapping avand et al 2020 azareh et al 2019 nevertheless it is inversely related to flooding the higher the elevation the lower the flood probability occurrence differences in elevations are associated with differences in climate conditions which significantly impact vegetation and soil properties thus the study area s altitude map was prepared of topography maps and pixels were measured from a dem of the watershed in the arcgis environment 3 2 2 topographic wetness index twi twi is a secondary topographical dimensionless index that characterizes topography s influence on the spatial distribution of wetness conditions and the landscape s saturation levels to generate runoff sørensen et al 2005 twi indicates the relationship between surface gradient and topsoil moisture content it is computed using the following equation twi a s t a n σ a s a l where a s is the draining at a given point t a n σ represents the slope a is areas of land upstream and l is the adequate slope i e measured to the point in the flow direction higher values indicate areas under consideration have high moister and are more productive in terms of runoff generation to prepare the twi the dem with ascii format was used in the sagagis software environment 3 2 3 slope the slope angle controls physiographic trends and soil moisture patterns ghorbanzadeh et al 2019a therefore it is an essential factor in hydrologic conditions that influence surface infiltration runoff rates and underground drainage avand et al 2021 the slope aspect strongly affects several hydrologic processes via evapotranspiration the direction of frontal precipitation involving weathering processes and vegetation development especially in drier environmental conditions lee et al 2017 a slope map was created from the dem using the spatial analysis tool in the arcgis environment fig 3 3 2 4 topography position index tpi the tpi is dimensionless increasingly used to characterize the topographic slope positions and automate landform classifications de reu et al 2013 tpimeasures the difference between elevation at the central point z o and the average elevation z within a predetermined radius r and is computed using the following equation 2 tpi z 0 z 3 z 1 n r i r z i positivetpivalues indicate that the central point is located higher than its average surroundings in contrast negative values indicate a position lower than the average the range oftpidepends on elevation differences andrlarger values mainly reveal central landscape units smaller values highlight smaller features such as minor valleys and ridges tpi was calculated using saga gis software 3 2 5 aspect aspect characterizes the exposure of the land surface towards sunlight it was also measured from the dem in the arcgis environment gudiyangada nachappa et al 2020 sunlight intensity varies for the various slope aspects aspects receiving being less exposed to the sunlight have more soil moisture rainfall on moist slopes will more likely generate higher runoff contributing to the flood risk downhill aspect measures were divided into nine classes n ne e se s sw w nw and flat fig 3 in the northern hemisphere the north facing and east facing directions are more likely to have water resources than south facing and west facing slopes avand et al 2021 bui et al 2019 solar radiation is lower on northern and eastern slopes than on southern and western slopes so evaporation is low and soil moisture is high on north facing and east facing inclines for this reason vegetation has developed more on northern and eastern faces dense vegetation in these areas increases the percolation of surface runoff 3 2 6 lithology infiltration capacity and sediment transport ratios are essential variables of a region s lithology diakakis et al 2012 yariyan et al 2020b the type of geological formations significantly influences the permeability of soils the finer is the upper topsoil layer the lower is the porosity and subsequently the generated runoff flow will increase the geological formations for this study are presented in table 1 the geological map of the study area was obtained from the geological survey mineral explorations agency of iran gsi https gsi ir fa 3 2 7 precipitation precipitation including rainfall and snowfall is the most crucial climate parameter affecting several hydrological processes rahman et al 2019 it must be measured as it is the only input of water into the catchment precipitation amounts and rates significantly affect the flood risk bui et al 2019 notably the intensity and frequency of rainfall events are the essential variables average annual precipitation was calculated from long term 1990 2017 precipitation data gathered at five rain gauges yasouj sisakht pataveh kakan gachsaran region maps of precipitation were generated using kriging in arcgis software precipitation in the watershed ranged from 870 mm at higher elevations to 380 in lower elevations 3 2 8 distance to the river river flows are the main alleyways for flood discharge amplification consequently the areas near rivers are highly susceptible to flooding several studies emphasize that proximity to a river influences the likelihood of flooding thus floods are most likely to occur near the watercourse hong et al 2018 papaioannou et al 2015 generally speaking as the distance from a river increases flood risk diminishes in this regard the river s distance is one of the leading conditioning factors due to its significant impact on the flood spread and magnitude in this study the river s distance was calculated using the arcgis environment buffer tool costache 2019 the locations of the historic floods in the study area tended to be close to the river 3 2 9 normalized difference water index ndwi ndwi is a practical method developed to delineate open water bodies and enhance their presence in remotely sensed digital imagery processing gao 1996 the ndwi uses reflected near infrared radiation and visible green light to improve open water body features while removing soil and terrestrial vegetation structures an appropriate threshold of the index is then established to separate water bodies from other land cover features based on the spectral characteristics the ndwi has been successfully used to delineate surface water features in several studies ji et al 2009 liuzzo et al 2020 mcfeeters 1996 the ndwi was obtained using landsat 8 satellite oli sensor and using the following formula in arcgis software 4 ndwi nir s w i r nir s w i r nir is the same near infrared with a wavelength between 0 841 and 0 876 and swir is part of the amplitude with a wavelength between 1 628 and 1 652 3 2 10 land use land use and land cover changes have a significant influence on several hydrological responses in this regard many studies have been focused on assessing the impacts of future trends of lulc at different scales on flood risk management and highlight that lulc plays an essential role in the runoff volume and rate costache et al 2020b islam et al 2020 lulc changes such as shifts from pasture to arable land forestry to agriculture rain and or groundwater fed to irrigated agriculture or forest use to urbanized areas are primary drivers for many landscape changes akter et al 2018 the lulc layers were prepared using operational land imager oli sensor landsat 8 satellite image after atmospheric and geometric corrections in the google earth engine web environment talukdar et al 2020 yariyan et al 2020b lulc were classified as either water residential garden farmland baren forest rock garden and rangeland 3 2 11 drainage density the drainage density dd represents the spacing between the channels dd is computed as the total length of channels of all orders per unit area divided by the area of a drainage basin therefore dd has an essential role in flood susceptibility occurrence alam et al 2020 high drainage density indicates high runoff volumes and rapid flood peaks therefore a drainage network s conditions considerably influence the runoff accumulates and the flood hydrograph curve steepens avand et al 2021 notably regional floods are often related to peak discharge volume and drainage area the drainage density factor was prepared using the streaming factor extracted from the dems to do this the density tool is used in arcgis software 3 2 12 stream power index spi the spi characterizes the flow power in terms of erosion it describes the erosive potential and surface runoff rate malik et al 2020 higher spi indicates higher surface runoff capacity and rate in contrast lower spi signifies the lower surface runoff capacity consequently heavy rainfall in the low spi region leads to a higher risk of flooding several studies have incorporated the spi to predict flood susceptibility in different areas bui et al 2019 hosseini et al 2020 yariyan et al 2020b the spi is computed using the following equation 5 spi a s t a n β where a s represent the specific catchment area in m2 and β represent the slope in degree spi was prepared using a dem map with ascii format and different spatial resolutions in the sagagis software environment spi map was generated in five different classes using quantile classification malik et al 2020 naghibi et al 2017 3 2 13 soil soil plays an essential role in the generation of surface runoff and inundation process losses of soil have altered the water retention and surface runoff generation influencing the flooding susceptibility hong et al 2018 consequently runoff generation is higher in areas characterized by porous soils and with low depth especially in the catchment upstream and vice versa papaioannou et al 2015 the soil layer was prepared using a soil map of iran with a scale of 1 100 000 in arcgis software fig 3 3 2 14 curvature the curvatures influence the water flow velocity and erosion and deposition processes along the watercourse malik et al 2020 profile curvature represents the slope change along the flow line also it indicates the flow acceleration areas plan curvature shows the aspect change along a contour and indicates the flow convergence and diversion the curvature comprises three categories convex concave and flat surface convex curvatures are characterized by increasing slope downhills and negative values in contrast the concave curvatures indicate the slope decreasing downhills and having positive values avand et al 2020 azareh et al 2019 dodangeh et al 2020 the curvature is a practical factor in runoff flow to detect flood susceptibility curvature was created using the respective dems of the study area in arcgis software fig 3 3 3 description of machine learning models 3 3 1 random forest rf the rf model is one of the most widespread algorithms applied to address the different nature of multi classification and prediction problems rf combines bagging ensemble learning and the random subspace method initially introduced breiman 2001 one of the main problems of regression models is that they are prone to overfitting the training data and perform poorly when given hidden data nachappa et al 2020 the rf model differently from other models has a low sensitivity to multi collinearity its results are relatively stable in missing and unfitted data tavakkoli piralilou et al 2019 the rf model consists of two main parameters the number of trees per forest and the number of random predictor variables each tree uses a sensitivity study of these parameters was performed to determine their effect on model performance the model was trained with the number of trees varying between 2 and 2000 with the default number of variables per tree to determine its sensitivity to the number of trees per forest sadler et al 2018 in addition to the actual predictive abilities of the rf model it can also be used to understand variable importance since many regression trees are produced with different sets of input variables the rf algorithm learns and records the input variables relative importance in predicting the output schoppa et al 2020 this capability is desirable as one of this study s objectives is to understand the relative importance of explanatory variables in predicting flood susceptibility in an arid region such understanding could be used to direct future investments in improving observational networks and building more resilient infrastructure to conduct this research biomod 2 package was used in r statistical software essential parameters in a random forest rf include the number of variables selected per tree node mtry the number of trees ntree and the minimum size or minimum observations in terminal nodes or leaves node size before performing the analyzes the fair values of these parameters must be determined optimal values were chosen based on the existing defaults for performing a rf model for a m try equal to the number of variables divided by 3 a n tree equal to 500 and a node size equal to 5 3 3 2 artificial neural network ann the ann model is a mathematical model of human perception based that can be trained for performing a particular task considering a set of empirical data anns are well known as so called and also considered as black box models they can make a robust prediction and are an essential tool for modeling when the relationships between data are unknown sahoo et al 2009 shahabi et al 2019 the processing units of an artificial neural network are called neurons which are arranged in layers links of variable weights connect neurons between layers the most commonly used ann architecture is the feed forward neural network ghorbanzadeh et al 2019b the network has one input layer with neurons or nodes where data are introduced hidden layers with several nodes or neurons the data are processed and the output layer where the given inputs are produced nikoo et al 2016 the number of neurons in a hidden layer is decided after training and testing procedures training of anns consists of inserting samples of inputs and target outputs to the network and then iteratively adjusting internal parameters based on the desired performance ali and shahbaz 2020 to conduct this research biomod 2 package was used in r statistical software the most critical parameters in the artificial neural network ann model include the number of cross validations to find the best size nbcv the maximum number of iterations maxit and the number of hidden layers size in this study default values were used for nbcv equal to 5 maxit equal to 200 and 3 hidden layers 3 3 3 generalized linear model glm the glm based on a logistic link function introduced initially by nelder and wedderburn 1972 has been widely used to solve different hydrological problems this algorithm consists of a linear relationship between a logistic regression of the dependent and independent variables recent applications of the glm have confirmed a satisfactory performance in reproducing the persistence characteristics of rainfall modeling rashid and beecham 2019 and flood modeling avand et al 2020 and landslide susceptibility pourghasemi and rossi 2017 a glm can model binary data sets according to presence absence data using a logistic model hosseini et al 2020 lee and pradhan 2007 to conduct this research biomod 2 package was used in r statistical software in the generalized linear model glm aic statistic is used to evaluate the model glm control is used to control the parameters 3 4 variance inflation factor and tolerance inflation variance factor vif is used to determine the multi collinearity between independent variables primarily related to tolerance when there are more than two independent variables it is equal to the inverse of the tolerance the amount of vif is related to the amount of variable standard error that increased due to multi collinearity the increase in standard error is equal to the second root of the vif khosravi et al 2016 tolerance could mostly be called a broad form of multiple correlation coefficient the desired variable is used as a dependent variable in regression analysis and other variables are used as independent variables the tolerance value varies between 0 and 1 zero tolerance indicates that this variable is entirely predictable through other independent variables and therefore there is perfect multi collinearity a tolerance equal to one means that the variable is uncorrelated with different independent variables arabameri et al 2018 6 tolerance 1 r 2 7 vif 1 1 r 2 3 5 evaluation of machine learning models 3 5 1 roc curve evaluating the results of modeling is one of the essential steps in this study the performance of flood probability prediction models was evaluated using two quantitative measures called the receiver operating characteristic roc curve and the area under the curve auc the roc curve was prepared using 30 of the test data in this curve the sensitivity is a function of the false positive rate a model s sensitivity is the ratio of true positives to the sum of true positives and the number of false negatives simultaneously specificity is the ratio of true negatives to the sum of true and false positives yariyan et al 2020c yousefi et al 2020 this curve can be generated by plotting the sensitivity on the y axis against the cumulative distribution function of the false positive rate on the x axis the amount of auc can be classified into 5 classes including excellent 1 0 9 very good 0 9 0 8 good 0 8 0 7 average 0 7 0 6 and poor 0 6 0 5 pham et al 2019 yariyan et al 2020a 8 auc t p tn p n 9 sensitivity tn tn f p 10 specificity tn tp f n tp and tn are considered the rate of pixels classified correctly as flood and non flood fp is the number of expected floods that are non flood fn is the number of non floods p and n are the total numbers of floods and non floods in addition to the mentioned criteria accuracy cohen s kappa and surface ratio sr statistical indices evaluated the models performance 11 accuracy tp t n tp t n f p f n kappa coefficient and statistical analysis based on it are numerical values between 1 to 1 the closer to 1 indicates the existence of the proportional and direct agreement measures close to 1 indicate the existence of an inverse agreement and vice versa and measures close to zero indicate disagreement 12 kappa o e 1 e where o represents the observational value and e represents the estimated value 4 results 4 1 multi collinearity analysis between independent variables a high correlation between independent input variables causes incorrect prediction results to evaluate the correlation between the independent variables the vif and tolerance tol were used the threshold value for determining the amount of multi collinearity was five the results showed that according to the vif method the amount of vif for the factors used in this study is less than the threshold value so these factors are independent of each other there is no multi collinearity between the factors the results of the tol factor also showed that because the value of this index for most factors is close to one so according to this method there is no correlation between factors table 2 identifying the most critical factors influencing floods is one of the ways to understand floods better the importance of each factor used in this study based on all three rf ann and glm models is shown in fig 4 the results show that in the rf model altitude 0 162 ndwi 0 084 and distance from river 0 13 factors in the ann model altitude 0 27 precipitation 0 319 and distance from river 0 114 factors and the glm model altitude 0 362 precipitation 0 186 and slope 0 135 factors respectively had the most significant impact on floods in the study area therefore the altitude precipitation and distance from the river factors in all three models have the most significant impact on floods 4 2 flood probability maps the study area s flood probability map fpm was generated using rf ann and glm models for a spatial resolution of 12 5 m and 30 m data and was classified in arcgis software to create the ability to compare and produce maps with the same conditions the classification of maps related to both data sets was performed using the natural break algorithm one of the classification algorithms of raster maps finally based on previous studies costache et al 2020c arabameri et al 2020 and the type of maps available these maps were divided into five classes very low low moderate high and very high to better understand the flood locations in the study area part of the map has been magnified throughout the maps the results of this division are shown in fig 5 the area of flood probability classes related to resolution accuracy data of 12 5 m and 30 m is shown in fig 6 as shown in fig 6 the very low flood probability class has the largest area in both data types the very low class area in modeling with 12 5 m data in rf ann and glm models is 937 808 and 1047 km2 respectively the class area is also tiny in the map produced using 30 m resolution of dem in rf ann and glm models respectively 1061 660 and 832 km2 the area of the very high flood probability class in the study area using 12 5 m data based on the rf ann and glm models is 304 325 and 259 km2 respectively while the area of the very high flood probability class in the study area using 30 m data based on the rf ann and glm models is 253 404 and 326 km2 respectively 4 3 model evaluation and comparison the evaluation of all models used in this study was performed using a roc curve the auc results for all three models in the validation stage show an acceptable accuracy level table 3 and 4 so that the value of auc for the rf ann and glm models using 12 5 m data is 0 983 0 949 and 0 965 respectively while this value is for rf ann and glm models are 0 975 0 93 and 0 949 using 30 meter data respectively fig 7 therefore based on the results the rf model agrees with the data available in the validation stage in both spatial resolutions of 12 5 and 30 m the value of the kappa coefficient and accuracy for the rf model in the validation stage using 12 5 m data is 0 841 and 0 92 this value is 0 841 and 0 92 respectively using data with a spatial resolution of 30 m table 3 and 4 fig 8 tables 5 and 6 fig 5 shows the correlation between the models results using two data sets with a spatial resolution of 12 5 and 30 m in this figure each model s outputs were compared using two data sets the results showed that the outputs of the rf model with a correlation value of 0 96 have the highest correlation fig 9 5 discussion and conclusion fast easy and accurate preparation of potential flood zones is essential to predict better model manage and understand floods in any region literature reviews have shown that mlms are suitable for modeling flood probability in different watershed types costache and tien 2019 nachappa et al 2020 yariyan et al 2020b many models have been evaluated to flood susceptibility mapping chen et al 2020a b hosseini et al 2020 however the performance of these models depends mainly on the input data therefore it is essential to check the data s quality before presenting it as input to mlms typically many input factors in flood modeling are generated from the dem as a result the quality of the dem factors used in the modeling is critical in producing accurate outputs of the flood probability map in this study to prepare a flood probability map in the yasouj dena watershed three mlms including rf ann and glm have been used the inventories of 220 flood locations were used as dependent variables besides 14 independent and influential variables on the flood with two pixels of different sizes of 12 5 and 30 m were used to investigate the effect of dem spatial resolution on the spatial distribution of flood finally the flood probability map was divided into five classes using the natural failure algorithm very low low medium high and very high the multi collinearity analysis results between independent variables showed that none of the factors have a high correlation all factors can be used in modeling therefore similar to previous studies hong et al 2018 papaioannou et al 2015 wang et al 2019 the factors used in this study included slope altitude curvature distance from the river drainage density land use lithology aspect precipitation slope length twi tpi soil and ndwi the results of evaluating the practical importance of those factors in flood susceptibility mapping using three models showed that altitude precipitation and distance from the river factors significantly impact flood occurrence in the study area the findings of this study are compatible with the findings of el haddad et al 2021 in the wadi qena watershed shahabi et al 2020 in the haraz watershed and avand et al 2021 avand et al 2020 in the tajan watershed given that over 75 of the yasouj dena watershed is mountainous with an average elevation of 2534 m and an average slope of 28 4 so the topographic factor could have a significant impact on shallow runoff amount and type of rainfall flow velocity and runoff volume in the study area because of abundant springs and snow cover in winter the heights upstream of the studied watershed provide a large discharge volume from the beshar river also because residential and agricultural areas are often next to the beshar river and downstream and low slope increasing the runoff volume at some times of the year causes flooding in residential areas and also causes damage in agricultural areas therefore the watershed s altitude factor significantly impacts rainfall and runoff making it more critical in floods than the river factor s distance because of the region s mountainous nature these results are consistent with the findings avand et al 2021b and el haddad et al 2021 this study evaluated the effect of the scale of influential flood factors produced using dems with a spatial resolution of 12 5 m and 30 m since most of the factors used in this study altitude slope aspect river slope length tpi twi are derived from the dems this factor s quality could significantly impact the flood susceptibility mapping the used models evaluation results showed that spatial resolution alone does not significantly affect the model prediction other factors such as the type of model used and local condition are also remarkably effective in modeling accuracy talukdar et al 2020 as the evaluation results of the used models showed the accuracy of mlms using data with a spatial resolution of 12 5 m is higher than the accuracy of data with a 30 m spatial resolution each pixel in the dems of 30 and 12 5 m represents 900 and 156 25 m of each factor independent variable respectively therefore the location of flood points a dependent variable in this study is different in various dems dems different pixel sizes cause dependent variables to be placed in different independent variable classes resulting in different modeling output these results are consistent with the findings chang et al 2019 and meena and gudiyangada nachappa 2019 therefore the evaluation results of mlms using 12 5 m spatial resolution data are more consistent with the flood points in the study area the accuracy of these models is higher than the accuracy of models with 30 m spatial resolution data the results vary from region to region and even with different dems chen et al 2017 even the results differ from other mlms or statistical models pham et al 2020b therefore it is suggested to replicate a similar approach by comparing different models in different regions and different data the results showed that increasing the spatial resolution cannot increase the accuracy of modeling the flood probability and may even decrease at higher resolutions e g 5 m consistent with some researchers findings chang et al 2019 however in each case the different scales of the dems have different results therefore testing dems with different scales is necessary to select an optimal dem for flood probability mapping also in this study we found that the dem change affects only the dem factors the dem scale did not influence other factors such as lithology and precipitation therefore perhaps one reason for the reduction in model results is the lack of change in factors not affected by the dem also to increase the accuracy of mlms the input flood points to mlms must be continuously updated pham et al 2021 thus based on performance and prediction accuracy the random forest model is suggested to be used in other regions worldwide characterized by similar hydrogeomorphological conditions as a final recommendation since studies on flood occurrence aim to develop a susceptibility map with high prediction accuracy the obtained results can help decision making and policy planning in areas prone to floods funding we acknowledge open access funding by the university of salzburg declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors appreciate the iranian soil conservation and watershed management research center for supporting this research 
1697,harmful algal blooms hab pose significant challenges to fisheries management and food and water security the onset of a hab is notoriously difficult to predict traditional methods of algal species identification under a microscope are also laborious and time consuming a real time system for identification and concentration measurement of algal bloom species has been developed at a marine fish culture zone fcz in the subtropical coastal waters of hong kong the system is based on analysis of high frequency algal cell images obtained from an underwater imaging flowcytobot ifcb deployed on the fish farm an explainable supervised machine learning technique has been successfuly developed the algal species classifier is trained by presenting a wide range of extracted image features to a random forest algorithm an optimized set of 25 features is identified by a recursive feature elimination technique the random forest rf classifier can identify 15 target hab classes with an overall out of bag accuracy of 94 2 with individual f 1 score ranging from 0 8 to 1 0 the classifier performs equally well as a convolution neural network cnn developed using transfer learning techniques based on the classifier an automated real time species identification and cell counting protocol has been developed with a response time of 10 min after data collection this work represents the first successful attempt of continuous algal species monitoring by ifcb and artificial intelligence ai based detection of hab in subtropical coastal waters keywords eutrophication harmful algal blooms fisheries management red tide ifcb real time system random forest feature selection machine learning water quality monitoring 1 introduction in hong kong marine fish culture mariculture is carried out in cages suspended by floating fish rafts in designated coastal waters fish culture zones which are typically weakly flushed tidal inlets there are currently 26 marine fish culture zones fcz which form a major supplier of high value fish including groupers snappers and sea breams algal blooms the explosive growth of phytoplankton are often observed in the subtropical eutrophic coastal waters around hong kong these blooms may cause water discoloration e g red tides severe dissolved oxygen depletion and shellfish poisoning resulting in beach closures massive fish kills and public health threats a total of 956 red tide incidents have been reported during 1975 2019 in hong kong afcd 2020 some of which are caused by harmful or toxic species for example a devastating red tide caused by the toxic karenia digitata in april 1998 wiped out over 80 3400 t of fish stocks in hong kong with an estimated loss of over hk 312 m us 40 m more recently in december 2015 a severe algal bloom event caused by toxic karenia mikimotoi started in tolo harbour and lasted for two months causing fish kills and threats of spreading to other hong kong waters over the past two decades despite significant upgrades in water pollution control infrastructures massive harmful algal blooms hab still recur and present formidable challenges to environmental and fisheries management traditional approaches of algal bloom monitoring rely on field sampling and laboratory analysis of chlorophyll a concentration chl a and manual species identification and cell counting which are laborious and time consuming with the increasing availability of real time water quality sensors and high frequency data such as temperature salinity dissolved oxygen do and chlorophyll fluorescence the development of hab early warning systems with a lead time of 1 2 days has become a practical possibility the use of data driven methods such as artificial neural networks ann to predict coastal algal blooms have been explored e g lee et al 2003 blauw et al 2006 data assimilation techniques which integrate monitoring data with 1d or 3d models have been reported e g mao et al 2009 wang et al 2019 research on hab early warning systems have correspondingly increased e g lee et al 2012 coad et al 2014 dabrowski et al 2016 recently we have developed a daily algal bloom risk forecast system based on i a vertical stability theory and ii a data driven artificial neural network ann model that assimilates high frequency data to predict sea surface temperature sst vertical density stratification on a daily basis guo et al 2020 nevertheless the bloom risk forecast system gives only the prognostic likelihood of an algal bloom occurrence the identification of causative species and cell counting are still conducted manually by human experts taxonomists under conventional microscopes while the manual method is the most reliable the time consuming monitoring sparse sampling followed by laboratory measurement cannot cater for the rapid management actions often needed during hab events e g massive fish kills the emergence of imaging flow cytometry ifc and computer vision has opened up new approaches to species identification and cell counting in an ifc system hydrodynamic focusing enables algal cells to pass one by one through a flow cell where laser induced fluorescence of chlorophyll bearing cells trigger a high speed camera to take photos among several commercially available ifc models e g flowcam cytosense cpics 4deep and others the imaging flowcytobot ifcb manufactured by mclane research laboratories falmouth massachusetts is an equipment that can acquire in situ high frequency microalgae image data it is an automated submersible device that can be continuously deployed underwater for months and can capture up to 40 000 high resolution images 3 4 pixels μ m in an hour olson and sosik 2007 analysis of image data at such a high sample rate requires automated taxonomic classification using machine learning techniques sosik and olson 2007 a number of research studies on habs have made use of ifcb to acquire image data with high temporal resolution the study areas ranged from the near temperate zone to the arctic circle in the northern hemisphere 27 8 n to 74 n hydrographic conditions varied from well mixed waters in strong tidal currents in the port aransas ship channel in texas 27 8 n campbell et al 2010 campbell et al 2013 santa cruz municipal wharf in monterey bay california 37 n fischer et al 2020 to summer stratified waters in nauset marsh estuary in massachusetts 41 8 n brosnahan et al 2017 and chukchi sea in the arctic ocean laney and sosik 2014 while some studies deployed ifcb underwater near the surface 1 to 5 m depth as originally designed for others relied on pumping water through the ifcb placed out of water as far as we are aware ifcb has hitherto not been tested in subtropical eutrophic coastal waters where field deployment faces new challenges such as intense bio fouling associated with the warm and nutrient rich water the use of ifcb is often accompanied by a classifier for automated species identification classifiers trained with supervised machine learning algorithms using hand crafted features extracted from the algal images have been successfully developed sosik and olson 2007 sosik et al 2016 the image processing involved edge detection using the phase congruency method kovesi 1999 the classification was based on a comprehensive feature set of 237 parameters that include simple geometry descriptors shape based symmetry measures huttenlocher et al 1993 texture statistics orientation invariant moments hu 1962 diffraction patterns berfanger and george 1999 and histograms of oriented gradients dalal and triggs 2005 feature subsets can be selected to optimize the classifier performance in recent years the use of support vector machine has been overtaken by the more robust random forests approach used with classification trees breiman 2001 moreover the use of deep learning methods such as convolutional neural networks cnn for classifying and enumeration of ifcb images have also been reported orenstein and beijbom 2017 gonzález et al 2019 despite the previous studies on using ifcb for automated hab warning campbell et al 2013 the development of an ifcb based classifier in subtropical waters has hitherto not been reported in previous studies typically the machine learning involved only one single or several target species and focused on issues of bloom formation and development mechanisms as many causative hab species up to 59 can be found in hong kong waters law 2018 the ability to distinguish multiple target classes is necessary for an early warning system to assist with fisheries management furthermore we note that a comprehensive interpretation of the decision tree approach from the viewpoint of explainable ai for algal species detection has not been attempted for example the selection of optimized feature subset for target species has not been elucidated hence the development of a classifier remains a black box which presents a barrier to the trust of users especially taxonomists that traditionally rely on their expertise for species identification the objective of this work is to i evaluate the performance of ifcb employed for the first time for fisheries management in eutrophic subtropical waters and ii develop using state of the art machine learning methods a classifier for multiple target hab species in hong kong waters first the essential details of the field deployment of the ifcb at the yim tin tsai ytt fish culture zone fcz in tolo harbour are described second the basic principles of the machine learning algorithms are presented in particular feature extraction and the ensemble random forest rf approach for developing an algal species classifier is illustrated using an example of 4 target classes and 4 image features third the use of a recursive feature elimination technique to arrive at an optimized feature subset with only 25 features out of entire set of 216 features listed by sosik et al 2016 is outlined the performance of the rf classifier for automatic identification of 15 target hab species is then evaluated and compared with a convolutional neural network cnn developed using transfer learning technique finally the field performance of a real time automated species identification and cell counts measurement protocol is demonstrated 2 materials and methods 2 1 study site the yim tin tsai fish culture zone ytt fcz 22 4 o n 114 2 o e is located in the inner part of tolo harbour in the northeastern waters of hong kong fig 1 the fcz has a mean depth of around 6 m 3d model computations and field observations have shown that the tidal inlet is weakly flushed with mean tidal velocities in the order of 1 cm s the average flushing time can be estimated to be 14 and 38 days in the wet and dry seasons respectively choi and lee 2004 fish farming is practised on a number of family operated fish raft platforms located 100 200 m from the shoreline starting from march 2019 we deployed our ifcb on a fish raft equipped with onshore 220 v line electric power supplied via underwater cables the ifcb is mounted securely to the raft platform and positioned to around 1 m depth a telemetry water quality monitoring system with two xylem ysi 6820 v2 multi parameter sensors deployed at 1 m and 4 m depth is also housed in a small shed on the raft close to the ifcb the system is part of the water quality monitoring network of the hong kong agriculture fisheries and conservation department afcd and has been operating since 2012 collecting high frequency data at 10 min interval including salinity temperature dissolved oxygen do and chlorophyll fluorescence chl f u the supplementary water quality data is invaluable for the interpretation of algal bloom events 2 2 imaging flowcytobot ifcb 2 2 1 design and working mechanism the basic design principles of the imaging flowcytobot ifcb manufactured by mclane have been reported olson and sosik 2007 a concise description of the ifcb deployment is described herein for completeness the ifcb has a compact size of 102 cm h 25 cm d and weighs 32 kg in air which makes it relatively convenient for transportation and handling fig 2 shows the design configuration and working mechanism of ifcb the core apparatus includes a ccd camera flash lamp syringe pumps photomultiplier tube pmt detectors a 4 5 mw red diode laser 635 nm flow pumps and filters computer stacks and other accessories all securely positioned inside a pressure housing fig 2a during operation a sheath flow circulation is maintained in the fluidic system via a sheath pump with filters fig 2b a 5 ml sea water sample is pumped into the ifcb through an intake port at the top fitted with a 150 μ m nitex nylon mesh preventing the inner flow system from being clogged by large particles the sample is injected into the circulating sheath fluid through the flow cell where cell particles intersect with the path of the laser light the particles induce laser light scattering and the chlorophyll containing cells emit red fluorescence which would trigger the activation of camera and flash lamp for image acquisition fig 2b the total number of samples for imaging can be controlled the ifcb can draw and analyze individual 5 ml samples every 25 min continuously 10 to 15 ml per hour without stopping except when maintenance service is required the trigger rate can reach up to 14 images per second and up to 40 000 gray scale images can be taken in an hour image data are stored in a set of raw data files for each sample together with other information such as sampling time in the once through flow system after passing through the flow cell the analyzed samples are returned back to the environment through an outlet port also at the top the intake and outlet ports are both protected by copper tubes from bio fouling 2 2 2 self cleaning in the fluidic system the fluidic system in the ifcb consists of tubing of 0 8 mm diameter and is highly sensitive to clogging and bio fouling the instrument is therefore designed to have an on board self cleaning protocol two plastic bags containing biocide and detergent solution are connected to the fluidic system during deployment the solution are periodically injected into the system with a preset schedule to prevent or remove bio fouling additionally a 120 ml solution with standard beads 6 0 μ m alighflowtm thermal fisher scientific biocide and detergent are stored in a syringe reservoir which allows regular bead particle analysis for monitoring of instrument performance e g camera focus with the preset schedule namely beads interval in previous studies the cleaning interval is usually set to 50 to 60 normal samples before a beads run with self cleaning is conducted 1 run per day in our ifcb operation in warm subtropical waters we have however found that beads interval has to be restricted to 30 2 runs per day otherwise the fluidic system will be contaminated within several weeks which affects the sheath flow and therefore image quality once contaminated the instrument has to be retrieved from the field and brought back to the laboratory for a deep manual cleaning 2 2 3 submersible deployment on the fish raft as shown in fig 3 the ifcb is deployed underwater at about 1 m depth from a raft platform using a system of nylon ropes with pulley blocks the pulley system allows easy lowering and pulling up the instrument since the ifcb is neutrally buoyant in water additional weights are installed at the bottom to anchor the instrument stably fig 4 shows some pictures of the deployment details of ifcb depending on the water quality significant bio fouling may cover the outside of the ifcb housing within two to four weeks the bio growth will become firmly attached to the surface and very hard to remove if left untreated regular cleaning of the outside of ifcb was performed normally biweekly in summer and monthly in winter to facilitate equipment maintenance plastic films are wrapped around the ifcb after cleaning before lowering it back into the water the ifcb requires a power source of 35 kw connected to the 220 v line supply on the raft to minimize data loss during power interruption e g bad weather an uninterrupted power supply apc smart ups 1500 schneider electric is also installed between the power source and the ifcb the ups can provide up to 5 h backup power and is also equipped with a network management card which allows remote monitoring of power status through the internet 2 2 4 remote control and data transfer we installed a 4g cellular network modem on the raft to facilitate remote control and data transfer the computer in ifcb has an ethernet network card which is connected to the 4g modem via a rj45 cable the network cable together with the power cable is equipped with an underwater pluggable connector during the deployment we logged into the ifcb remotely from the hkust laboratory on a daily basis to check the instrument performance such as image focus temperature and humidity inside the housing etc the data transfer from the ifcb computer to the user computer in the laboratory was enabled by an open source continuous file synchronization program syncthing net when a sample has been analyzed by ifcb and raw data has been created the program synchronizes the files with the user computer in real time once the user computer has received the data automated image classification will be triggered 3 automatic species identification the development of the ytt specific algal species classifier builds on the pioneering work of sosik and olson 2007 and the use of a set of publicly available matlab based tools https github com hsosik ifcb analysis wiki for each ifcb image a number of features dimension shape texture etc can be extracted full list of up to 237 each image is then characterized by a feature vector details of the feature extraction are given in appendix a the machine learning algorithm classifier involves the use of decision trees based on classification rules that make use of the selected features an ensemble random forest rf of decision trees is developed using a set of annotated algal images the development of an algal species classifier generally proceeds as follows first manual annotation of ifcb images spanning over a representative sampling period into different taxonomic groups is performed under the supervision of experts from the hong kong agriculture fisheries and conservation department afcd training data for each target class is then selected from labeled images and presented for classifier training the performance of a classifier is evaluated by comparison of automated identification and enumeration of target species and manually annotated results in the following the manual annotation of ifcb images and the development of the decision tree used with the random forest approach are outlined details of the use of classification trees and ensemble random forest method are elucidated by illustrative examples in appendix c 3 1 manual annotation of ifcb images the development of the classifier hinges on the manual annotation or labeling of the ifcb images to provide representative training images for classifier development we performed manual annotation of ifcb images by closely working with the taxonomy experts in afcd law 2018 to continuously review the collected images we first present a set of unlabeled ifcb images to the taxonomists who can make identification of classes based on expertise a number of well documented images in the corresponding classes taken under a light microscope in the laboratory would then be provided by the taxonomists as benchmarks for identification of ifcb images these benchmark images usually have high resolution and reveal various taxonomy features from different view angles which served as a basis for efficient and continual training on the labeling of ifcb images the above routine was performed iteratively on an extensive amount of ifcb images we were able to define a total of 45 explicit classes for the ifcb images collected from march 2019 to june 2020 in ytt many of which correspond to phytoplankton taxa at the genus or species level or groupings of a few morphological similar genera among them 19 classes are diatoms and 15 classes are dinoflagellates in addition there is one class of detritus for non algae material of various shapes and sizes a total of around 350 000 images have been annotated into these 45 classes see appendix a for a description of the manual annotation process each class contains a few to over 60 000 images depending on the instances the species has been imaged by ifcb during deployment as a quality assurance check to ensure correct classification for each class we also randomly selected and presented a number of images to taxonomist experts for review with consistently repeatable good results 3 2 description of target and non target classes the objective of classifier development is to achieve accurate real time identification and enumeration of target species from ifcb samples among the 45 identified classes we have selected 15 target classes table 1 these are common algal bloom causative species in hong kong waters considered to be important for an hab early warning system and include key diatom and dinoflagellate species the diatoms include 1 chaetoceros spp 2 leptocylindrius spp and similar chain forming diatoms cerataulina spp dactyliosolen spp and guinardia striata 3 skeletonema spp and 4 pseudo nitzschia spp the dinoflagellates include 5 tripos furca 6 akashiwo sanguinea 7 gonyaulax spp 8 scrippsiella spp 9 prorocentrum gracile and 10 prorocentrum triestinum other non diatoms and non dinoflagellates include 11 vicicitus globosus 2 mesodinium rubrum 13 heterosigma akashiwo 14 cyptophycea including teleculax acuta and 15 pseudochattonella veruculosa besides these 15 target classes we also selected 10 additional classes as training classes in classifier development non target classes which are considered as unimportant for hab earning warning but still commonly observed by ifcb the inclusion of these non target classes helps to improve the generalizing ability of the classifier and the accuracy of target species identification a total of 25 training classes are included in our final classifier 3 3 selection of training and testing images for the 25 training classes 15 as targets and 10 as non targets we compiled a set of 11 250 manual annotated images with even distribution across all classes i e 450 images per class for subsequent classifier developments as will be described below in training a random forest rf classifier all images are presented for training and the algorithm automatically creates out of bag examples for evaluation of model performance on the other hand in training a convolution neural network cnn classifier see later discussion we randomly split the compiled image set into training 70 and validation sets 30 independent of the above compiled image set for classifier development we also collected 12 ifcb sea water samples from ytt with time of acquisition spanning the entire deployment period and manually annotated every image in each sample this covers around 67 000 images number of images in each sample ranged from 1387 to 13 027 images this independent image set provides a basis for benchmarking the performance of rf and cnn classifiers 3 4 machine learning algorithms description of feature set in this study we used hand crafted features designed by phytoplankton experts to characterize each algal cell image with the aim of automatic species detection for ifcb images a comprehensive list of features in various classes has been proposed by sosik et al 2016 during feature extraction using matlab codes detection of cell boundaries is first performed to locate the region of interest blob using the phase congruency approach then various pertinent features are computed from the identified blob together with the original image we adopted a total of 216 features in six categories from sosik s list these include descriptors of simple geometry and shape based symmetry that can be linked to the knowledge of taxonomists as well as high level features texture statistics moment invariants diffraction patterns and histograms of oriented gradients which cannot be intuitively interpreted a detailed discussion of the image processing and feature extraction can be found in appendix b decision tree classification a decision tree based classifier is developed using a decision tree induction algorithm e g cart breiman et al 1984 to learn and reason from features extracted from labeled examples the tree after growing can be translated into a set of decision rules which resemble the way human experts identify species manually it is therefore possible to examine the decision made from trees by inspecting these rules the basic principles of the decision tree induction algorithm is elucidated with an instructive algal classification example in appendix c section c1 a single decision tree is used to classify 4 target classes using 2 geometry descriptors the 4 classes include two dinoflagellates akashiwo sanguinea prorocentrum gracile 1 diatom pseudonitzschia spp and a toxic species heterosigma akashiwo each class has 450 nos of training images for better illustration the decision tree is trained using only 2 features extracted from the training images we computed eccentricity and summedarea which indicate the geometry and size of cells which are both interpretable by taxonomists the tree is trained using the fitctree function in matlab r2019b mathworks fig c 3 in appendix c shows a simple decision tree and the decision rules translated from the tree it can be seen that the tree successfully splits the 1800 training images into 4 pure leaf nodes it can be seen that the tree can be visually inspected and a set of readable rules can be obtained however a single decision tree is prone to overfitting in this study we adopted an ensemble approach by constructing a random forest of multiple trees and output the majority of the classification results random forest classification random forests rf as described by breiman 2001 is a widely used ensemble learning technique that builds a collection of de correlated trees the training of a random forest classifier involves three major steps bootstrap sampling feature bagging and forming ensemble of trees first for a forest of nt trees nt data sets are obtained from the original training data set by bootstrap sampling with replacement for each bootstrapped data set a decision tree can be obtained by feature bagging essentially using a random selection of a subset of the original number of features at each interior node to decide on the correct classification split an ensemble of nt decision trees then constitute the ensemble rf classifier normally the minimum number of trees required for accurate identification is obtained by a sensitivity analysis an example on rf classification of the above 4 target species using a random forest with nt 6 trees based on 4 simple geometric descriptors is given in appendix c section c 2 the classifier is trained using the treebagger function in matlab it can be seen that using ensemble of trees the classification accuracy for out of bag examples can be significantly improved in the selected random forest algorithm for developing our final classifier with 15 target classes the number of trees is set to nt 100 and an optimized feature set is developed see later discussion 3 5 evaluation of classifier performance the performance of an algal species classifier can be evaluated by constructing a confusion matrix for classifying out of bag examples rf classifier and validation sets cnn classifier see later discussion in a confusion matrix each row represents the instances in a true class while each column represent the instances in a predicted class or vice versa each diagonal element represents the number of correctly predicted examples in each class true positives and true negatives while each off diagonal element represents the number of misclassified examples false positives and false negatives the following metrics can be defined 1 overall accuracy acc i tp i tn i tp i tn i fp i fn i precision p r i tp i tp i fp i recall re i tp i tp i fn i f 1 score f 1 i 2 pr i 1 re i 1 where tp i fp i tn i and fn i are the numbers of true positives false positives true negatives and false negatives in each class the f1 score is the harmonic mean of the precision and recall with its best value at 1 perfect precision and recall and worst at 0 3 6 optimized feature set by recursive feature elimination feature selection is important in machine learning when high dimensional feature set is used as it helps to identify redundant and uninformative features that may contribute noise and compromise the classifier performance it also helps to reduce the complexity of models and hence improve the interpretability in this study we aim to select an optimized set of features from the original 216 numbers the final random forest classifier makes use of this optimized set as input features we adopted a backward elimination strategy based on the built in permutation importance measure of features in the random forest algorithm namely recursive feature elimination rfe as originally described by guyon et al 2002 the rf rfe algorithm eliminates the least important feature in each step based on the computed feature importance firstly a random forest classifier with 100 trees is trained using the full feature set 216 nos permutation importance of each feature defined as the increased prediction error due to shuffling the values of that feature in the out of bag examples is then computed and the features are ranked the last 5 in the rank list i e least important are eliminated and a new feature set is obtained a new random forest classifier is then trained based on the new feature set and the whole process is repeated until all features have been eliminated for each classifier trained we recorded the f1 scores for the 15 target classes after all features being eliminated we plotted the f1 scores against the number of remaining classes a minimum number of features required to maintain the model performance can be determined and an optimized feature set can thus be obtained 3 7 convolutional neural network convolutional neural network cnn is a popular deep learning model which allows computers to be fed with raw data and to automatically discover the representations needed for recognition or classification lecun et al 2015 it typically consists of multiple layers in three types convolution pooling and fully connected layers the first two types perform feature extraction while the last type map the extracted features into final output for classification for purposes of image classification cnn uses pixel values of digital images scaled to a fixed input size as input and no hand crafted feature extraction is involved due to the complexity of training a cnn from scratch it is common to adopt a pre trained network already trained over millions of images in many object categories and use it as starting point to learn task i e transfer learning this allows acquiring a cnn model for a specific task using relatively small amount of training images the transfer learning technique has been successfully applied in several studies on classifying ifcb image data e g orenstein and beijbom 2017 lumini and nanni 2019 to assess the performance of our rf classifier we also developed a convolution neural network cnn classifier as a base line for comparison the cnn is fine tuned using transfer learning technique from googlenet szegedy et al 2015 imagenet version http www image net org which is 22 layer deep and originally classifies images into 1000 classes such as keyboard mouse pencil and many animals this pre trained network has learned different feature representations for a wide range of images before retraining the network we first replace the last fully connected layer with a new layer with the number of outputs equal to the number of training classes in our study i e 25 we also froze the weights of the 10 initial layers by setting the learning rates in those layers to zero which help to speed up network training and prevent overfitting to new data set since the network requires input images of size 224 224 3 but ifcb images are in gray scale and have various sizes we perform image re sizing before presenting them to the network for training parameters we set the learning rate to 0 005 min batch size to 64 and maximum number of training epochs to 10 the network is trained on a pc equipped with an i5 8600 cpu and a nvidia quadro p1000 gpu using the deep learning toolbox in matlab 4 results and discussion 4 1 feature selection for the rf classifier fig 5 shows the variation of model performance i e f1 score for out of bag examples in each target class as less important features are being eliminated using the recursive feature elimination rfe approach it can be seen that when feature size is reduced from 216 to 25 the f1 score for each target class remains nearly unchanged the overall performance is excellent with individual f1 scores above 0 9 for 12 classes and above 0 8 for 3 classes f1 scores for some of the classes begin to fall when feature size is reduced from 25 to 10 but still remain above 0 8 significant deterioration of performance is observed when feature size nf is reduced to below 10 it is interesting to see that the degree of performance deterioration varies depending on the target class for example for some dinoflagellates such as a sanguinea p gracile and tripos furca f1 score above 0 9 can still be achieved even using only 2 features on the other hand for some chain forming diatoms including chaetoceros spp and leptocylindrus spp noticeable decrease of f1 score can be observed when feature size is below 25 with unacceptable deterioration when nf is below 10 this indicates that the automatic detection of the chain forming diatoms requires more features than other classes overall extensive tests have demonstrated that a classifier using the optimum feature subset of 25 nos can be adopted with no performance deterioration as compared to that trained using all 216 features we further examine the details by looking into the features selected in each type as shown in table 2 it can be seen that all the six types of features are selected in the optimized 25 feature set with varying proportions it is noteworthy that the optimized set includes all the 6 texture features indicating the importance of this feature type for high level feature types such as diffraction patterns 100 features and histogram of oriented gradients 81 features the rfe algorithm identified only a few important features for inclusion in the final classifier 4 2 performance evaluation by confusion matrix fig 6 shows the confusion matrices for classifying a out of bag examples using the rf classifier and b validation examples using the cnn classifier each row indicates the instances of a true class the observations while each column indicates the instances of a predicted class the predictions the recall or specificity the percentage that the observed class is correctly predicted and precision or sensitivity the accuracy of the prediction values are computed using eq 1 generally both classifiers achieve excellent results for most of the target classes and overall classification accuracy across all 15 target classes i e percentage of all correctly identified target class images are 94 2 rf and 96 2 cnn for the rf classifier it can be seen that 12 target classes have both recall and precision above 90 and the other 3 classes i e chaetoceros spp leptocylindrus spp and m rubrum have both of them above 80 the precision and recall are generally balanced it is noted that 24 out of 450 images for chaetoceros spp are misclassified as leptocylindrius spp and 28 out of 450 images for leptocylindrius spp are misclassified as chaetoceros spp this indicates the difficulty in distinguishing these two classes which are both chain forming diatoms similar observation is also found for skeletonema spp and leptocylindrus spp nevertheless considering that only 25 features are used by the classifier such result is quite satisfactory for the cnn classifier the performance in terms of recall and precision is similar as the rf classifier for most classes except that the recall for leptocylindrus spp is as low as 68 9 much lower than 82 7 for the rf classifier it can be seen that 21 out of 135 images of chaetoceros spp are misclassified as leptocylindrus spp indicating the network is relatively easy to misidentify the former as the latter species during application the reason for the low performance of cnn for these two specific classes may be attributed to the image preprocessing technique adopted which is the simplest approach by shrinking or stretching the original image to fit to the input size of cnn images especially those with aspect ratio significantly larger or smaller than one can be distorted causing loss of information and therefore increasing the risk of misclassification 4 3 performance test on analyzing ifcb samples we developed a protocol to achieve real time automated species identification and cell count to quantify the performance of this real time system we analyzed 12 nos of fully manual annotated ifcb samples we recorded the processing time for analyzing each sample and compare the estimated cell abundance of target classes by manual rf and cnn approaches table 3 shows the results of this performance test for the processing time it can be seen that our rf classifier performs equally fast as using the cnn classifier in terms of cpu computing time even for analyzing a sample with over 13 000 images which is nearly the upper limit for ifcb sampling the rf approach only took less than 10 min for cell counts table 3 lists the estimated prevalence of the top 3 most abundant target classes in each sample and fig 7 shows comparison of prediction and true proportions for selected classes the predicted proportions by rf and cnn models were adjusted based on corresponding recall of each target class i re i using the approach as described by sosik and olson 2007 it can be seen that the rf model performs equally well as the cnn model the cnn model tends to over predict the proportion of chain forming diatoms such as leptocylindrus spp due to the high misclassification rate 4 4 interpretation by partial dependence plots when the number of trees and features in a random forest increase and the structure of each tree becomes deeper the interpretation of final decision becomes difficult through direct inspection of decision rules as an alternative we used the partial dependence plot pdp to evaluate the marginal effect of each feature on the output of the model friedman 2001 for the m th feature among the optimized feature set i e m 1 2 25 let x m be the value of this feature and x c represent the values of all other 24 features the partial dependence of the model output on predicting class j is then defined as 2 pd m j α 1 n i 1 n rf j x m i α x c i where rf j x i the probability score of the rf model i e the percentage of trees in the model with correct predictions to predict the i th example as class j n total number of out of bag examples the partial dependence calculates the average value of predicted probabilities of the n nos of examples by varying the value of x m α but keeping x c fixed we use the partial dependence plots pdp to see how a change in a feature variable affects the change in an output variable this helps us to verify that the classifier is making decisions based on correct reasoning we have performed this analysis for all 15 target classes and all 25 selected features as an illustrative example fig 8 shows the relationship between two geometric features selected in the optimized 25 feature set and the output of the rf classifier using pdp analysis for the feature of summedarea which can be an indicator of cell size we compared the pd values of cryptophycea gonyaulax spp and tripos furca as a function of α the box plot below shows the distribution of actual feature values of these three classes fig 8a it can be seen that pd values for a class significantly increases meaning that the probability score is higher when the feature value is within the range for that class and drops when the feature value is out of the range for example the pd value for gonyaulax spp is over 0 9 when the summedarea is around 4000 to 6000 but drops as low as 0 5 when feature value is below 800 this clearly shows that the feature summedarea is important in discriminating these three target classes similar observation can be made for the feature of eccentricity using another three classes h akashiwo p gracile and pseudo nitzschia spp fig 8b for example pd value of pseudo nitzschia is only high nearly 1 0 when the eccentricity is approaching 1 0 which is exactly the case for pseudo nitzschia it can be seen that pdp provides an intuitive way to understand the relationship between the input features and output classification and hence helps to build up confidence for users in applying the classifiers 4 5 realtime in situ automated species identification at ytt fcz with the developed classifier a fully automated routine for real time identification and cell count of target species has been established for ifcb fig 9 this contains the following major steps step 1 automated data transfer using file synchronization to achieve real time automated image analysis it is important to transfer raw data from ifcb computer to the remote user computer in real time this is achieved by the use of an open source software synctrazor www syncthing net that allows continuous file synchronization between two computers over the internet in real time we specified the data folder on ifcb computer as a shared folder once ifcb has finished analysis of one sample and corresponding raw data files have been created the software will automatically scan the data folder to search for the newly created files and synchronizes them to the destination folder on user computer in the lab step 2 automated image processing and auto classifier we automated the image analysis process using the timer function in matlab we first compiled the image processing functions for feature extraction and the trained auto classifer into a single matlab script the compiled script was then packed as a user defined custom matlab function for analysis of each ifcb sample data file i e identification and cell counts of target species using the timer function matlab automatically calls the custom function every 25 min search for new data and performing analysis the time for analysis usually takes around 0 5 to 10 min depending on the image quantity in each sample using the above steps a continuous real time data series of cell count for target species can be obtained with a response time of around 30 min after data collection 4 5 1 example h akashiwo bloom in march 2019 fig 10 shows the variation of abundance of target classes during an observed bloom from 22 27 march 2019 together with the real time data of dissolved oxygen d o and chlorophyll fluorescence chl f u measured by water quality sensors the data shows that d o near the surface 1 m depth exceeded 10 mg l for most of the time and several peaks of chl f u can be observed indicating there is a bloom happening during this period it should be noted that the saturated dissolved oxygen concentration in sea water is around 8 mg l and normally a distinct super saturation level of say over 10 mg l is indicative of algal blooms as confirmed by field observations of algal and d o dynamics in tolo harbour lee et al 1991 lee and lee 1995 guo et al 2020 the ifcb measurements suggest that the dominant species of the bloom is the motile heterosigma akashiwo it is also noted that ifcb measurements successfully captures the diurnal patterns of the abundance of motile species 5 concluding remarks the contribution of the present work is twofold i an ifcb has been successfully deployed underwater in a fish culture zone for the first time the research equipment has yielded large quantities of almost continuous algal image data over the 18 month operation in the order of 30 000 images per hour ii over 350 000 images have been manually annotated into 45 explicit classes an auto classifier for 15 target classes of hab species has been successfully developed using a classification tree method combined with an ensemble random forest rf approach using a robust recursive feature elimination technique the rf classifier uses only 25 key selected features and performs equally well as a fine tuned convolutional neural network cnn developed using transfer learning technique many of the commonly observed hab species in hong kong have been classified based on the developed classifier a protocol for automated real time species identification and cell counting has been successfully developed as far as we are aware this work represents the first successful attempt of continuous hab monitoring and automatic species identification at a fixed station in subtropical coastal waters compared to other algal bloom observation approaches such as the remote sensing method see e g cheng et al 2020 on using unmanned aerial vehicles for remote sensing of coastal algal blooms the use of ifcb has a unique advantage of being able to identify bloom species and count cells in real time through automated image classification the robust ifcb and computer vision based system can be integrated with an early warning hab prognostic forecast system guo et al 2020 to significantly enhance our ability to observe hab events in coastal waters it should be pointed out the experience so far has been limited to the ytt fish culture zone nevertheless it is conceivable the use of ifcb can usefully supplement traditional fisheries management by providing early alerts to prompt onsite monitoring and data on the time history of hab events in recent years a new wave of ai applications in water resources management has emerged in particular new modeling paradigms of using computer vision to incorporate spatial information e g temperature rainfall leaf index at catchment scale into integrated hydrological models to enhance streamflow forecasting have been proposed jiang et al 2018 jiang et al 2019 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by a r d project on pilot study of red tide early warning system from the agriculture fisheries and conservation department afcd of the hong kong special administrative region sar government afcd fis 01 18 the support of afcd in providing the real time and regular water quality data and discussion on the choice of the target hab species is gratefully acknowledged the guidance and assistance of mr stanley p c law on manual identification of algae species in hong kong is well appreciated appendix a manual annotation of ifcb images the manual annotation work is the key to the success of the present work as it provides the labeled training images for classifier development the annotation work is labor intensive and requires domain knowledge on taxonomy of algae species to optimize the efficiency of annotation as much as possible we used the startmc function in the ifcb analysis software package as developed by sosik et al 2016 the software provides a graphical user interface which displays a series of ifcb images on the computer screen by simple operations such as mouse clicking and pressing enter on keyboard each image can be annotated into the corresponding class depending on the availability of classifier there are two approaches to annotate the images using the software as described in the following a 1 approach 1 start from default unknown class without classifier we first defined our class list and set the default class as unknown at the beginning all images will be assigned into this default class automatically by the software fig a 1 shows an example of software display during the annotation the class list is displayed on the left and images on the right the images are displayed on the screen by size i e images with largest vertical dimension are shown first the number of images shown each time on the screen can be adjusted by setting the image scale factor and the number of images to load at one time during annotation we first highlighted a destination class i e the class to which we are annotating image in blue by clicking on the class name in the list then we selected images which we wished to annotate to the destination classes by single mouse clicking on each of them after selection results can be stored by pressing enter key and red numbers corresponding to the destination class will be shown on the location of each click the above process can be repeated for a new destination class after all images on the screen were annotated we could proceed to the next patch of images by clicking enter key one more time there are additional functions such as select all page which allows us to select all images on the screen using only one click which helps to save time spent on clicking a 2 approach 2 start from classifier to further improve the efficiency we also trained rf and cnn classifiers using the approach as described in the main test after we have collected a certain number of annotated images these classifiers were imperfect as compared to those adopted in the final automated system due to insufficient training images but the software enables us to start from displaying the images according to the classifier predicted classes and just use manual annotation to identify the incorrectly classified images and assign them to the correct class this helps to save a great amount of time and efforts fig a 2 shows two examples of screen display of the software that automatically assigns images into predicted classes appendix b extraction of image features for classifier development automatic hab species classification rests on supervised learning techniques based on extraction of image features the feature set and analysis method adopted for the ifcb images is based on the pioneering work of sosik and olson 2007 to facilitate the understanding of the workings of the machine learning and the optimization of the feature set the key steps of the algal image feature extraction are detailed below for completeness table 1 shows a list of 216 features widely adopted for algal image analysis as well as a sub set of 25 key features finally adopted for identification of 15 targeted hab species in hong kong b 1 step 1 edge detection b 1 1 blob images computed by phase congruency approach as the first step of image processing the boundary of the target of interest which is referred to as blob needs to be determined using edge detection techniques most of the images features are calculated based on the blob images and hence a robust and accurate edge detection is of the essence many methods are available for edge detection for ifcb images that reflects the morphological features of planktons such as spline flagella and many distinctive local areas sosik and olson 2007 recommended the use of a computationally intensive but effective approach computing the phase congruency in an image and apply a simple threshold based edge detection phase congruency is calculated following the method proposed by kovesi 1999 and using publicly available matlab based tools https github com hsosik ifcb analysis wiki after edge detection the blob image indicating the boundary of the target of interest is obtained the blob image is a black and white image that represents the blob area with white color pixel value 1 and other areas as black color pixel value 0 fig b 1 shows the typical computed blob images for selected target classes b 1 2 number of blobs in each images in each blob image one closed boundary represents one blob the total number of blobs in each image may vary depending on the characteristics of cell boundary and connection between cells for many image features the image processing tools compute the values based on a single blob but the sum of feature values of all blobs in one image may sometimes be more representative than the feature value of a single blob hence it is necessary to inspect the typical number of blobs in one image for each target species some examples are illustrated in fig b 1 for species that usually present as a single cell with a distinctive boundary such as prorocentrum gracile and akashiwo sanguinea there is usually only one blob in each image fig b 1a image features are therefore computed based on that blob for species usually presenting with multiple cells such as chain forming diatoms the number of blobs in each image depends on the type of connection between cells for leptocylindrus spp or pseudo nitzschia spp the cells are closely connected with a distinctive interface and the blob images usually contain only one blob for skeletonema spp the aperture between adjacent cells is large and cells are connected by numerous external tubes which can hardly be identified within the resolution of ifcb images in this case multiple blobs will be detected in one image similar situation is also observed for some of the chaetoceros spp fig b 1b in these cases it is more useful to compute the sum of features for all blobs b 2 step 2 image processing and feature extraction to achieve satisfactory performance in auto classification of target species it is important to extract representative features from the training images that are presented to the machine learning algorithm for classifier development it is also noted that a wide range of features are needed to describe different characteristics of the algae cells of different species these features which are usually referred to as hand crafted features are designed by domain experts who have knowledge on how to extract useful information from original images with pixel numbers for ifcb images we examined and adopted several groups of hand crafted features proposed by sosik et al 2016 as described in the following b 2 1 geometry descriptors as the normal practice of taxonomists in manual identification geometries size and shape of cells are usually used to identify certain species for example prorocentrum gracile is featured by its lanceolate shape with a pointed posterior end and a round anterior end for computer vision the geometric features need to be represented by a group of numerical values through some computation to show distinctive information let f x y represent a digital image with m rows and n columns of pixel points where x y are discrete coordinates x 0 1 2 m 1 y 0 1 2 n 1 and f x y is the pixel value at point x y the coordinate system is set with its origin at the top left corner of the image positive x axis extending downwards and positive y axis extending to the right a number of geometric features for each blob in the binary blob images are calculated as follows area a the area of each blob i e total number of pixel points in the blob region indicating the 2 d size of the blob area unit pixel2 perimeter p number of white pixel points along the boundary of each blob indicating the real perimeter of the blob in terms of pixel unit pixel majoraxislength l major length of the major axis of the ellipse that has the same normalized second central moments as the blob area see fig b 2 for an illustration computed as b 1 l major x 2 x 1 2 y 2 y 1 2 where x 1 y 1 and x 2 y 2 are two end points that define the major axis unit pixel minoraxislength l minor length of the minor axis of the ellipse that has the same normalized second central moments as the blob area computed as b 2 l minor x 4 x 3 2 y 4 y 3 2 where x 3 y 3 and x 4 y 4 are two end points that define the minor axis unit pixel eccentricity ratio of the distance between the foci and the major axis length of the ellipse that has the same normalized second central moments as the blob area computed as b 3 eccentricity l major 2 l minor 2 l major convexarea a c area of the smallest convex polygon or convex hull that can contain the blob unit pixel2 convexperimeter p c perimeter in pixel of the convex hull unit pixel solidity proportion of the white pixels pixel value 1 in the convex hull computed as b 4 solidity a a c the above features contain useful information to characterize the size and shape of a single blob to cater for some of the target species with multiple blobs in each image the sum of those features with units over all blobs are adopted including summedarea a summedperimeter p summedmajoraxislength l major summedminoraxislength l minor summedconvexarea a c and summedconvexperimeter p c for the dimensionless features of eccentricity and solidity the value corresponding to the largest blob in each image is used some dimensionless features derived from the above basic ones are added including area over perimeter computed as the ratio of a over p area over perimetersquared or compactness computed as the ratio of a over p 2 summedconvexperimeter over perimeter ratio of p c over p besides the basic geometric features we further define a bounding box which is the smallest rectangle that can contain a single blob it is noticed that the posture of an algae cell in each image may vary and the size of the bounding box may fluctuate in the same class due to different cell posture and hence affect the representativeness we therefore performed a rotation for the largest blob in each image to align its major axis along the x axis and a bounding box is defined based on the rotated blob fig b 2 the following features can therefore be computed rotatedboundingbox xwidth length of the side along x axis of the bounding box for largest blob after rotation in each image rotatedboundingbox ywidth length of the side along x axis of the bounding box for largest blob after rotation in each image rotated boundingbox solidity solidity of the bounding box for largest blob after rotation in each image a summary of the list of geometry descriptors can be found in table 4 b 2 2 shape based symmetry symmetry based on shape is also an important characteristic used by human experts to identify algae species for example taxonomists divide diatoms into two groups namely centric diatoms and pennate diatoms based on valve symmetry law 2018 a number of methods are available to detect the degree of symmetry through image processing considering the relative complex shape of some of the target species we adopted an effective and advanced approach by computing the hausdorff distance to measure the asymmetry of a shape the hausdorff distance measures the degree of similarity or overlap between two image objects that are superimposed on one another huttenlocher et al 1993 it is defined as longest distance that a point a in set a must travel in order to reach the closest point b in set b such that b 5 h a b max a a min b b a b where represents the l 2 or euclidean norm for the points of a and b the form of symmetry of the shape of a blob can therefore be evaluated by measuring the hausdorff distances between the pixel points in the original blob and the ones after some manipulation we computed the following features using the binary blob image h90 hausdorff distance between original blob and the one after rotating 90 with respect to its centroid i e intersection between major and minor axis h180 hausdorff distance between original blob and the one after rotating 180 with respect to its centroid hf lip hausdorff distance between original blob and the one after flipping along the major axis the hausdorff distances help to identify the different types of asymmetry and provide a quantitative characterization of different shapes some derived features can be further obtained as h90 over hflip ratio of h90 over hflip h90 over h180 ratio of h90 over h180 hflip over h180 ratio of hflip over h180 b 2 3 texture statistics besides geometry and shape the ornamentation over the cell also provides important information on identification of different species the pattern of ornamentation can be described numerically using texture measures either globally over the entire cell or locally at a specific area in this study we adopted a list of global texture descriptors derived from the gray level histogram fig b 3 shows how the gray level histogram is computed we first increase the contrast of the original gray scale image by saturating the bottom 1 and the top 1 of all pixel values then we filter out the pixels within the blob area region of interest the pixel values within the blob area are accumulated to form the histogram where the x axis corresponds to different pixel values or gray levels and y axis represents the number of instances the characteristics of this histogram can be described numerically by the statistical moments such that b 6 μ n i 0 n 1 i m n h i where μ n is the nth moment about the mean intensity m h i is the height percentage distribution of histogram bin at pixel value i n is the total number of possible pixel values and the mean intensity m is given by b 7 m i 0 n 1 ih i based on these the following descriptors are derived and adopted texture average gray level equals to the mean m and measures the average pixel values texture average contrast measures the average contrast and is given by b 8 σ σ 2 μ 2 texture smoothness measures the relative smoothness in terms of the variation of pixel values equals to 0 for constant gray level and 1 for large variations and is give by b 9 r 1 1 1 σ 2 n 1 2 texture third moment measures the skewness of the gray level histogram positive when skewed to the right and negative to the left and is given by b 10 μ 3 1 n 1 2 i 0 n 1 i m 3 h i texture uniformity measures the uniformity of pixel values and has its maximum when all pixel values are equal such that b 11 u i 0 n 1 h i 2 texture entropy measures the randomness of the histogram and is given by b 12 e i 0 n 1 h i log 2 h i b 2 4 moment invariants the shape of an image object can be described by its moments which are the weighted averages of its pixel intensities the moment of order a b for a continuous 2d function f x y is defined as b 13 m ab x a y b f x y dxdy where a b 0 1 2 for gray scale images with discrete pixel intensities g x y we replace the integrals with summations b 14 m ij x y x i y j g x y the moments can be used to derive invariants with respect to translation scale and rotation first central moments of any order that are invariant to translations are given by b 15 m ab x y x x a y y b g x y for a digital image g x y x m 10 m 00 and y m 01 m 00 represent the centroid of the object then invariants to both translation and scale can be derived from central moments as b 16 η μ ij μ 00 1 i j 2 where i j 2 using the above scale invariants hu 1962 showed that the following moments are invariant to translation scale and rotation b 17 i 1 η 20 η 02 i 2 η 20 η 02 2 4 η 11 2 i 3 η 30 3 η 12 2 3 η 21 η 03 2 i 4 η 30 η 12 2 η 21 η 03 2 i 5 η 30 3 η 12 η 30 η 12 η 30 η 12 2 3 η 21 η 03 2 3 η 21 η 03 η 21 η 03 3 η 30 η 12 2 η 21 η 03 2 i 6 η 20 η 02 η 30 η 12 2 η 21 η 03 2 4 η 11 η 30 η 12 η 21 η 03 i 7 3 η 21 η 03 η 30 η 12 η 30 η 12 2 3 η 21 η 03 2 η 30 3 η 12 η 21 η 03 3 η 30 η 21 2 η 21 η 03 2 the hu s moment invariants have been applied successfully in many pattern recognition tasks including identification of algae species e g sosik and olson 2007 we computed the 7 nos of moment invariants for the largest blob in each binary blob image namely moment invariant1 to moment invariant7 eq b 17 as an illustration fig b 4 shows comparison of blob images of different types it can be seen that moment invariants help to characterize different species with different shapes the moment invariants for a given observed cell species are approximately the same and not affected by different cell postures b 2 5 diffraction pattern sampling the diffraction pattern sampling is a widely applied technique for pattern recognition as described by berfanger and george 1999 it samples the fourier spectral density of an input image using a ring wedge geometry this geometry consists of a semi annular area rings on one half of the transformation plan and a wedge shaped area wedges on the other the radial sampling over the rings provides orientation independent information on the spatial frequency distribution in the image whereas the angular sampling of the wedges provides scale independent information about the spatial frequency orientation fig b 5 shows the 2d power spectrum of a blob image with size m n which can be calculated from the 2d fourier transform of the pixel value gray level distribution x j k defined by b 18 y p 1 q 1 j 0 m 1 k 0 n 1 e 2 π i m jp e 2 π i n kq x j 1 k 1 where i 1 p and j are indices ranging from 0 to m 1 and q and k are indices ranging from 0 to n 1 then a ring wedge filter with 50 nos of rings and 48 nos of wedges is used to sample the spectrum the portion of each wedge near the origin 15 pixel radius is removed the sampled energy in each ring or wedge is normalized by the total energy in the image to specify 98 nos of features i e ring01 to ring50 and wedge01 to wedge48 two additional features total energy rfhalfpowerintegral and the ratio of energy near the center to the total energy rwcenter2total powerratio are also included to form 100 nos of features in this type b 2 6 histogram of oriented gradients the histogram of oriented gradients hog descriptors have been widely applied in object detection since its successful application on human detection see dalal and triggs 2005 the technique counts occurrences of gradient orientation of pixel intensities in localized portions of a digital image the idea is to describe the local object appearance or shape using the distribution of local intensity gradients to compute hog descriptors the magnitudes of gradients at each pixel along x and y axis are computed to evaluate the total magnitude and direction of gradient vector at that pixel see fig b 6 for an illustration the computed gradient vector plot is divided into a number of windows a histogram of gradient directions in terms of cumulative magnitudes over all pixels in each window can be constructed the histogram bins are evenly spaced over 0 180 unsigned gradient or 0 360 signed gradient the heights of the bins indicating the gradient strength along different orientations form the elements of a feature vector in addition to eliminate the effect of local variations in illumination and shadowing the histogram is normalized over each window in the present work we followed the approach of ludwig et al 2009 and computed the hog descriptors of the original gray scale ifcb images over rectangular windows i e r hog using signed gradients fig b 7 each two adjacent windows overlap half of their area allowing each window to contribute more than once to the final feature vector each image is divided into 9 windows in each window a 9 bin histogram was computed the histogram were locally normalized over each cell using a l 2 norm scheme b 19 v v v 2 2 2 where v is the unnormalized descriptor vector v 2 is its l2 norm and is an arbitrary small constant take it as 0 01 with the resulting 9 histograms in 9 windows an 81 element feature vector was obtained namely hog01 to hog81 in summary each ifcb image is characterized by a feature vector of nf 216 elements table 4 shows the full list of features in our work through the random forest recursive feature elimination rf rfe process it is found that the inclusion of nf 25 features is sufficient for training the classifier for the target species identification appendix c species identification using decision tree based approach for learning and reasoning from feature based examples decision trees are among the most popular choices of various machine learning approaches decision trees resemble the way that human taxonomists identify a species manually by deduction from a set of decision rules learned from the extracted features of labeled training images a decision tree based classifier is developed using a decision tree induction algorithm the classification and regression trees cart method as described by breiman et al 1984 the detailed implementation of cart using a random forest approach for automatic algal species classification is outlined below for completeness c 1 decision trees c 1 1 basic principles to develop a decision tree classifier the induction algorithm splits a set of training samples into subsets so that the data in each of the child subsets are purer than the data in the parent set the objective is to reach final subsets that consist only samples belonging to single classes as illustrated in fig c 1 the result of the learning procedure is a tree in which each leaf node is labeled by a class name and each interior node specifies a test condition on a particular feature the growing of a tree is a recursive process in which the best split at each interior node is determined by trying all possible values of all input features the best split at each interior node can be evaluated by a measure of impurity the gini impurity index i e best split smallest gini index as defined by c 1 g i 1 n p i 1 p i where n number of classes and p i the percentage of samples with label i at that node g 0 implies a pure node with all samples in a single class while g 1 means all different classes are equally present in the samples c 1 2 an example for species identification we demonstrate the interpretability of a decision tree on species identification using 4 target classes as shown in fig c 2 each class has 450 nos of training images for better illustration the decision tree is trained using only 2 features extracted from the training images i e two input variables we computed eccentricity and summedarea which indicate the geometry and size of cells and are both interpretable by taxonomists the tree was trained using the fitctree function in matlab r2019b mathworks fig c 3 shows a simple decision tree after growing and the decision rules translated from the tree it can be seen that the tree successfully splits the 1800 training images into 4 pure leaf nodes the best split at each interior node indicates a decision boundary fig c 4 shows a visualization of decision boundaries on a 2d plot of the feature distribution of different classes c 1 3 issue of decision tree overfitting although decision trees are relatively easy to explain and interpret its classification power is limited trees that are grown to a very deep level tend to learn highly irregular patterns they overfit their training sets i e have low bias but very high variance to overcome this issue a common practice is to construct multiple trees and output the majority votes of the classification results which is referred to as ensemble learning among various ensemble methods random forests is the most popular one c 2 random forests c 2 1 basic principles random forests as described by breiman 2001 use the idea of bootstrap sampling and feature bagging to build a collection of decorrelated trees random forest of nt trees and average the tree results to make a final decision as shown in fig c 5 bootstrap sampling is achieved by sampling with replacement n examples from the original training data set of size n examples not picked up are left out as out of bag examples for each bootstrapped data set a decision tree can be grown using the classification tree method and a subset of the features the following steps are repeated at each interior node i select m p features at random from the original p features ii determine the best split among the m features and iii split the node into two child nodes the purpose of feature bagging is to remove correlation among trees the default value of m is p tunable by the user for example if p 216 features are used as input then at each interior node in each tree m 216 15 features will be selected at random to determine the best split similarly if p 25 is selected m 5 see fig c 6 using both bootstrap sampling and feature bagging an ensemble of nt trees can be developed as the final random forest classifier fig c 7 to make a classification of an unlabeled input the final decision is the majority vote of the predictions made by each of the nt individual trees fig c 8 c 2 2 an example for species identification we illustrate how a random forest classifier perform species identification using 4 target species as shown in fig c 2 450 nos of training images in each class or training set of 1800 images for illustration purpose 4 simple features are extracted including eccentricity summedarea summedmajoraxislength and summedminoraxislength for simplicity nt 6 trees are grown using bootstrap sampling and feature bagging the output of the random forest classifier will therefore be the majority vote of these 6 trees fig c 9 shows the variation of out of bag classification error with respect to the number of grown trees it can be seen that performance improves significantly by using multiple trees as compared to a single tree fig c 10 shows an application example of the rf classifier it can be seen that although a single tree may give a wrong prediction the rf classifier uses 5 out of 6 trees to correctly predict the test image as p gracile c 3 concluding remarks decision trees can learn to identify algal bloom species by deriving a set of decision rules based on extracted image features the rules are human readable and can be interpreted by taxonomists since a single tree may be prone to overfitting and thus is poor in generalization an ensemble of trees i e the random forest approach is used to improve the classification accuracy the cost of growing multiple trees is the increased model complexity and less interpretability especially when the number of trees and extracted features are large therefore feature selection will be necessary to reduce model complexity for better interpretation of the machine learning results and to enhance computational efficiency to pave the way for integration with internet of things e g ai chips 
1697,harmful algal blooms hab pose significant challenges to fisheries management and food and water security the onset of a hab is notoriously difficult to predict traditional methods of algal species identification under a microscope are also laborious and time consuming a real time system for identification and concentration measurement of algal bloom species has been developed at a marine fish culture zone fcz in the subtropical coastal waters of hong kong the system is based on analysis of high frequency algal cell images obtained from an underwater imaging flowcytobot ifcb deployed on the fish farm an explainable supervised machine learning technique has been successfuly developed the algal species classifier is trained by presenting a wide range of extracted image features to a random forest algorithm an optimized set of 25 features is identified by a recursive feature elimination technique the random forest rf classifier can identify 15 target hab classes with an overall out of bag accuracy of 94 2 with individual f 1 score ranging from 0 8 to 1 0 the classifier performs equally well as a convolution neural network cnn developed using transfer learning techniques based on the classifier an automated real time species identification and cell counting protocol has been developed with a response time of 10 min after data collection this work represents the first successful attempt of continuous algal species monitoring by ifcb and artificial intelligence ai based detection of hab in subtropical coastal waters keywords eutrophication harmful algal blooms fisheries management red tide ifcb real time system random forest feature selection machine learning water quality monitoring 1 introduction in hong kong marine fish culture mariculture is carried out in cages suspended by floating fish rafts in designated coastal waters fish culture zones which are typically weakly flushed tidal inlets there are currently 26 marine fish culture zones fcz which form a major supplier of high value fish including groupers snappers and sea breams algal blooms the explosive growth of phytoplankton are often observed in the subtropical eutrophic coastal waters around hong kong these blooms may cause water discoloration e g red tides severe dissolved oxygen depletion and shellfish poisoning resulting in beach closures massive fish kills and public health threats a total of 956 red tide incidents have been reported during 1975 2019 in hong kong afcd 2020 some of which are caused by harmful or toxic species for example a devastating red tide caused by the toxic karenia digitata in april 1998 wiped out over 80 3400 t of fish stocks in hong kong with an estimated loss of over hk 312 m us 40 m more recently in december 2015 a severe algal bloom event caused by toxic karenia mikimotoi started in tolo harbour and lasted for two months causing fish kills and threats of spreading to other hong kong waters over the past two decades despite significant upgrades in water pollution control infrastructures massive harmful algal blooms hab still recur and present formidable challenges to environmental and fisheries management traditional approaches of algal bloom monitoring rely on field sampling and laboratory analysis of chlorophyll a concentration chl a and manual species identification and cell counting which are laborious and time consuming with the increasing availability of real time water quality sensors and high frequency data such as temperature salinity dissolved oxygen do and chlorophyll fluorescence the development of hab early warning systems with a lead time of 1 2 days has become a practical possibility the use of data driven methods such as artificial neural networks ann to predict coastal algal blooms have been explored e g lee et al 2003 blauw et al 2006 data assimilation techniques which integrate monitoring data with 1d or 3d models have been reported e g mao et al 2009 wang et al 2019 research on hab early warning systems have correspondingly increased e g lee et al 2012 coad et al 2014 dabrowski et al 2016 recently we have developed a daily algal bloom risk forecast system based on i a vertical stability theory and ii a data driven artificial neural network ann model that assimilates high frequency data to predict sea surface temperature sst vertical density stratification on a daily basis guo et al 2020 nevertheless the bloom risk forecast system gives only the prognostic likelihood of an algal bloom occurrence the identification of causative species and cell counting are still conducted manually by human experts taxonomists under conventional microscopes while the manual method is the most reliable the time consuming monitoring sparse sampling followed by laboratory measurement cannot cater for the rapid management actions often needed during hab events e g massive fish kills the emergence of imaging flow cytometry ifc and computer vision has opened up new approaches to species identification and cell counting in an ifc system hydrodynamic focusing enables algal cells to pass one by one through a flow cell where laser induced fluorescence of chlorophyll bearing cells trigger a high speed camera to take photos among several commercially available ifc models e g flowcam cytosense cpics 4deep and others the imaging flowcytobot ifcb manufactured by mclane research laboratories falmouth massachusetts is an equipment that can acquire in situ high frequency microalgae image data it is an automated submersible device that can be continuously deployed underwater for months and can capture up to 40 000 high resolution images 3 4 pixels μ m in an hour olson and sosik 2007 analysis of image data at such a high sample rate requires automated taxonomic classification using machine learning techniques sosik and olson 2007 a number of research studies on habs have made use of ifcb to acquire image data with high temporal resolution the study areas ranged from the near temperate zone to the arctic circle in the northern hemisphere 27 8 n to 74 n hydrographic conditions varied from well mixed waters in strong tidal currents in the port aransas ship channel in texas 27 8 n campbell et al 2010 campbell et al 2013 santa cruz municipal wharf in monterey bay california 37 n fischer et al 2020 to summer stratified waters in nauset marsh estuary in massachusetts 41 8 n brosnahan et al 2017 and chukchi sea in the arctic ocean laney and sosik 2014 while some studies deployed ifcb underwater near the surface 1 to 5 m depth as originally designed for others relied on pumping water through the ifcb placed out of water as far as we are aware ifcb has hitherto not been tested in subtropical eutrophic coastal waters where field deployment faces new challenges such as intense bio fouling associated with the warm and nutrient rich water the use of ifcb is often accompanied by a classifier for automated species identification classifiers trained with supervised machine learning algorithms using hand crafted features extracted from the algal images have been successfully developed sosik and olson 2007 sosik et al 2016 the image processing involved edge detection using the phase congruency method kovesi 1999 the classification was based on a comprehensive feature set of 237 parameters that include simple geometry descriptors shape based symmetry measures huttenlocher et al 1993 texture statistics orientation invariant moments hu 1962 diffraction patterns berfanger and george 1999 and histograms of oriented gradients dalal and triggs 2005 feature subsets can be selected to optimize the classifier performance in recent years the use of support vector machine has been overtaken by the more robust random forests approach used with classification trees breiman 2001 moreover the use of deep learning methods such as convolutional neural networks cnn for classifying and enumeration of ifcb images have also been reported orenstein and beijbom 2017 gonzález et al 2019 despite the previous studies on using ifcb for automated hab warning campbell et al 2013 the development of an ifcb based classifier in subtropical waters has hitherto not been reported in previous studies typically the machine learning involved only one single or several target species and focused on issues of bloom formation and development mechanisms as many causative hab species up to 59 can be found in hong kong waters law 2018 the ability to distinguish multiple target classes is necessary for an early warning system to assist with fisheries management furthermore we note that a comprehensive interpretation of the decision tree approach from the viewpoint of explainable ai for algal species detection has not been attempted for example the selection of optimized feature subset for target species has not been elucidated hence the development of a classifier remains a black box which presents a barrier to the trust of users especially taxonomists that traditionally rely on their expertise for species identification the objective of this work is to i evaluate the performance of ifcb employed for the first time for fisheries management in eutrophic subtropical waters and ii develop using state of the art machine learning methods a classifier for multiple target hab species in hong kong waters first the essential details of the field deployment of the ifcb at the yim tin tsai ytt fish culture zone fcz in tolo harbour are described second the basic principles of the machine learning algorithms are presented in particular feature extraction and the ensemble random forest rf approach for developing an algal species classifier is illustrated using an example of 4 target classes and 4 image features third the use of a recursive feature elimination technique to arrive at an optimized feature subset with only 25 features out of entire set of 216 features listed by sosik et al 2016 is outlined the performance of the rf classifier for automatic identification of 15 target hab species is then evaluated and compared with a convolutional neural network cnn developed using transfer learning technique finally the field performance of a real time automated species identification and cell counts measurement protocol is demonstrated 2 materials and methods 2 1 study site the yim tin tsai fish culture zone ytt fcz 22 4 o n 114 2 o e is located in the inner part of tolo harbour in the northeastern waters of hong kong fig 1 the fcz has a mean depth of around 6 m 3d model computations and field observations have shown that the tidal inlet is weakly flushed with mean tidal velocities in the order of 1 cm s the average flushing time can be estimated to be 14 and 38 days in the wet and dry seasons respectively choi and lee 2004 fish farming is practised on a number of family operated fish raft platforms located 100 200 m from the shoreline starting from march 2019 we deployed our ifcb on a fish raft equipped with onshore 220 v line electric power supplied via underwater cables the ifcb is mounted securely to the raft platform and positioned to around 1 m depth a telemetry water quality monitoring system with two xylem ysi 6820 v2 multi parameter sensors deployed at 1 m and 4 m depth is also housed in a small shed on the raft close to the ifcb the system is part of the water quality monitoring network of the hong kong agriculture fisheries and conservation department afcd and has been operating since 2012 collecting high frequency data at 10 min interval including salinity temperature dissolved oxygen do and chlorophyll fluorescence chl f u the supplementary water quality data is invaluable for the interpretation of algal bloom events 2 2 imaging flowcytobot ifcb 2 2 1 design and working mechanism the basic design principles of the imaging flowcytobot ifcb manufactured by mclane have been reported olson and sosik 2007 a concise description of the ifcb deployment is described herein for completeness the ifcb has a compact size of 102 cm h 25 cm d and weighs 32 kg in air which makes it relatively convenient for transportation and handling fig 2 shows the design configuration and working mechanism of ifcb the core apparatus includes a ccd camera flash lamp syringe pumps photomultiplier tube pmt detectors a 4 5 mw red diode laser 635 nm flow pumps and filters computer stacks and other accessories all securely positioned inside a pressure housing fig 2a during operation a sheath flow circulation is maintained in the fluidic system via a sheath pump with filters fig 2b a 5 ml sea water sample is pumped into the ifcb through an intake port at the top fitted with a 150 μ m nitex nylon mesh preventing the inner flow system from being clogged by large particles the sample is injected into the circulating sheath fluid through the flow cell where cell particles intersect with the path of the laser light the particles induce laser light scattering and the chlorophyll containing cells emit red fluorescence which would trigger the activation of camera and flash lamp for image acquisition fig 2b the total number of samples for imaging can be controlled the ifcb can draw and analyze individual 5 ml samples every 25 min continuously 10 to 15 ml per hour without stopping except when maintenance service is required the trigger rate can reach up to 14 images per second and up to 40 000 gray scale images can be taken in an hour image data are stored in a set of raw data files for each sample together with other information such as sampling time in the once through flow system after passing through the flow cell the analyzed samples are returned back to the environment through an outlet port also at the top the intake and outlet ports are both protected by copper tubes from bio fouling 2 2 2 self cleaning in the fluidic system the fluidic system in the ifcb consists of tubing of 0 8 mm diameter and is highly sensitive to clogging and bio fouling the instrument is therefore designed to have an on board self cleaning protocol two plastic bags containing biocide and detergent solution are connected to the fluidic system during deployment the solution are periodically injected into the system with a preset schedule to prevent or remove bio fouling additionally a 120 ml solution with standard beads 6 0 μ m alighflowtm thermal fisher scientific biocide and detergent are stored in a syringe reservoir which allows regular bead particle analysis for monitoring of instrument performance e g camera focus with the preset schedule namely beads interval in previous studies the cleaning interval is usually set to 50 to 60 normal samples before a beads run with self cleaning is conducted 1 run per day in our ifcb operation in warm subtropical waters we have however found that beads interval has to be restricted to 30 2 runs per day otherwise the fluidic system will be contaminated within several weeks which affects the sheath flow and therefore image quality once contaminated the instrument has to be retrieved from the field and brought back to the laboratory for a deep manual cleaning 2 2 3 submersible deployment on the fish raft as shown in fig 3 the ifcb is deployed underwater at about 1 m depth from a raft platform using a system of nylon ropes with pulley blocks the pulley system allows easy lowering and pulling up the instrument since the ifcb is neutrally buoyant in water additional weights are installed at the bottom to anchor the instrument stably fig 4 shows some pictures of the deployment details of ifcb depending on the water quality significant bio fouling may cover the outside of the ifcb housing within two to four weeks the bio growth will become firmly attached to the surface and very hard to remove if left untreated regular cleaning of the outside of ifcb was performed normally biweekly in summer and monthly in winter to facilitate equipment maintenance plastic films are wrapped around the ifcb after cleaning before lowering it back into the water the ifcb requires a power source of 35 kw connected to the 220 v line supply on the raft to minimize data loss during power interruption e g bad weather an uninterrupted power supply apc smart ups 1500 schneider electric is also installed between the power source and the ifcb the ups can provide up to 5 h backup power and is also equipped with a network management card which allows remote monitoring of power status through the internet 2 2 4 remote control and data transfer we installed a 4g cellular network modem on the raft to facilitate remote control and data transfer the computer in ifcb has an ethernet network card which is connected to the 4g modem via a rj45 cable the network cable together with the power cable is equipped with an underwater pluggable connector during the deployment we logged into the ifcb remotely from the hkust laboratory on a daily basis to check the instrument performance such as image focus temperature and humidity inside the housing etc the data transfer from the ifcb computer to the user computer in the laboratory was enabled by an open source continuous file synchronization program syncthing net when a sample has been analyzed by ifcb and raw data has been created the program synchronizes the files with the user computer in real time once the user computer has received the data automated image classification will be triggered 3 automatic species identification the development of the ytt specific algal species classifier builds on the pioneering work of sosik and olson 2007 and the use of a set of publicly available matlab based tools https github com hsosik ifcb analysis wiki for each ifcb image a number of features dimension shape texture etc can be extracted full list of up to 237 each image is then characterized by a feature vector details of the feature extraction are given in appendix a the machine learning algorithm classifier involves the use of decision trees based on classification rules that make use of the selected features an ensemble random forest rf of decision trees is developed using a set of annotated algal images the development of an algal species classifier generally proceeds as follows first manual annotation of ifcb images spanning over a representative sampling period into different taxonomic groups is performed under the supervision of experts from the hong kong agriculture fisheries and conservation department afcd training data for each target class is then selected from labeled images and presented for classifier training the performance of a classifier is evaluated by comparison of automated identification and enumeration of target species and manually annotated results in the following the manual annotation of ifcb images and the development of the decision tree used with the random forest approach are outlined details of the use of classification trees and ensemble random forest method are elucidated by illustrative examples in appendix c 3 1 manual annotation of ifcb images the development of the classifier hinges on the manual annotation or labeling of the ifcb images to provide representative training images for classifier development we performed manual annotation of ifcb images by closely working with the taxonomy experts in afcd law 2018 to continuously review the collected images we first present a set of unlabeled ifcb images to the taxonomists who can make identification of classes based on expertise a number of well documented images in the corresponding classes taken under a light microscope in the laboratory would then be provided by the taxonomists as benchmarks for identification of ifcb images these benchmark images usually have high resolution and reveal various taxonomy features from different view angles which served as a basis for efficient and continual training on the labeling of ifcb images the above routine was performed iteratively on an extensive amount of ifcb images we were able to define a total of 45 explicit classes for the ifcb images collected from march 2019 to june 2020 in ytt many of which correspond to phytoplankton taxa at the genus or species level or groupings of a few morphological similar genera among them 19 classes are diatoms and 15 classes are dinoflagellates in addition there is one class of detritus for non algae material of various shapes and sizes a total of around 350 000 images have been annotated into these 45 classes see appendix a for a description of the manual annotation process each class contains a few to over 60 000 images depending on the instances the species has been imaged by ifcb during deployment as a quality assurance check to ensure correct classification for each class we also randomly selected and presented a number of images to taxonomist experts for review with consistently repeatable good results 3 2 description of target and non target classes the objective of classifier development is to achieve accurate real time identification and enumeration of target species from ifcb samples among the 45 identified classes we have selected 15 target classes table 1 these are common algal bloom causative species in hong kong waters considered to be important for an hab early warning system and include key diatom and dinoflagellate species the diatoms include 1 chaetoceros spp 2 leptocylindrius spp and similar chain forming diatoms cerataulina spp dactyliosolen spp and guinardia striata 3 skeletonema spp and 4 pseudo nitzschia spp the dinoflagellates include 5 tripos furca 6 akashiwo sanguinea 7 gonyaulax spp 8 scrippsiella spp 9 prorocentrum gracile and 10 prorocentrum triestinum other non diatoms and non dinoflagellates include 11 vicicitus globosus 2 mesodinium rubrum 13 heterosigma akashiwo 14 cyptophycea including teleculax acuta and 15 pseudochattonella veruculosa besides these 15 target classes we also selected 10 additional classes as training classes in classifier development non target classes which are considered as unimportant for hab earning warning but still commonly observed by ifcb the inclusion of these non target classes helps to improve the generalizing ability of the classifier and the accuracy of target species identification a total of 25 training classes are included in our final classifier 3 3 selection of training and testing images for the 25 training classes 15 as targets and 10 as non targets we compiled a set of 11 250 manual annotated images with even distribution across all classes i e 450 images per class for subsequent classifier developments as will be described below in training a random forest rf classifier all images are presented for training and the algorithm automatically creates out of bag examples for evaluation of model performance on the other hand in training a convolution neural network cnn classifier see later discussion we randomly split the compiled image set into training 70 and validation sets 30 independent of the above compiled image set for classifier development we also collected 12 ifcb sea water samples from ytt with time of acquisition spanning the entire deployment period and manually annotated every image in each sample this covers around 67 000 images number of images in each sample ranged from 1387 to 13 027 images this independent image set provides a basis for benchmarking the performance of rf and cnn classifiers 3 4 machine learning algorithms description of feature set in this study we used hand crafted features designed by phytoplankton experts to characterize each algal cell image with the aim of automatic species detection for ifcb images a comprehensive list of features in various classes has been proposed by sosik et al 2016 during feature extraction using matlab codes detection of cell boundaries is first performed to locate the region of interest blob using the phase congruency approach then various pertinent features are computed from the identified blob together with the original image we adopted a total of 216 features in six categories from sosik s list these include descriptors of simple geometry and shape based symmetry that can be linked to the knowledge of taxonomists as well as high level features texture statistics moment invariants diffraction patterns and histograms of oriented gradients which cannot be intuitively interpreted a detailed discussion of the image processing and feature extraction can be found in appendix b decision tree classification a decision tree based classifier is developed using a decision tree induction algorithm e g cart breiman et al 1984 to learn and reason from features extracted from labeled examples the tree after growing can be translated into a set of decision rules which resemble the way human experts identify species manually it is therefore possible to examine the decision made from trees by inspecting these rules the basic principles of the decision tree induction algorithm is elucidated with an instructive algal classification example in appendix c section c1 a single decision tree is used to classify 4 target classes using 2 geometry descriptors the 4 classes include two dinoflagellates akashiwo sanguinea prorocentrum gracile 1 diatom pseudonitzschia spp and a toxic species heterosigma akashiwo each class has 450 nos of training images for better illustration the decision tree is trained using only 2 features extracted from the training images we computed eccentricity and summedarea which indicate the geometry and size of cells which are both interpretable by taxonomists the tree is trained using the fitctree function in matlab r2019b mathworks fig c 3 in appendix c shows a simple decision tree and the decision rules translated from the tree it can be seen that the tree successfully splits the 1800 training images into 4 pure leaf nodes it can be seen that the tree can be visually inspected and a set of readable rules can be obtained however a single decision tree is prone to overfitting in this study we adopted an ensemble approach by constructing a random forest of multiple trees and output the majority of the classification results random forest classification random forests rf as described by breiman 2001 is a widely used ensemble learning technique that builds a collection of de correlated trees the training of a random forest classifier involves three major steps bootstrap sampling feature bagging and forming ensemble of trees first for a forest of nt trees nt data sets are obtained from the original training data set by bootstrap sampling with replacement for each bootstrapped data set a decision tree can be obtained by feature bagging essentially using a random selection of a subset of the original number of features at each interior node to decide on the correct classification split an ensemble of nt decision trees then constitute the ensemble rf classifier normally the minimum number of trees required for accurate identification is obtained by a sensitivity analysis an example on rf classification of the above 4 target species using a random forest with nt 6 trees based on 4 simple geometric descriptors is given in appendix c section c 2 the classifier is trained using the treebagger function in matlab it can be seen that using ensemble of trees the classification accuracy for out of bag examples can be significantly improved in the selected random forest algorithm for developing our final classifier with 15 target classes the number of trees is set to nt 100 and an optimized feature set is developed see later discussion 3 5 evaluation of classifier performance the performance of an algal species classifier can be evaluated by constructing a confusion matrix for classifying out of bag examples rf classifier and validation sets cnn classifier see later discussion in a confusion matrix each row represents the instances in a true class while each column represent the instances in a predicted class or vice versa each diagonal element represents the number of correctly predicted examples in each class true positives and true negatives while each off diagonal element represents the number of misclassified examples false positives and false negatives the following metrics can be defined 1 overall accuracy acc i tp i tn i tp i tn i fp i fn i precision p r i tp i tp i fp i recall re i tp i tp i fn i f 1 score f 1 i 2 pr i 1 re i 1 where tp i fp i tn i and fn i are the numbers of true positives false positives true negatives and false negatives in each class the f1 score is the harmonic mean of the precision and recall with its best value at 1 perfect precision and recall and worst at 0 3 6 optimized feature set by recursive feature elimination feature selection is important in machine learning when high dimensional feature set is used as it helps to identify redundant and uninformative features that may contribute noise and compromise the classifier performance it also helps to reduce the complexity of models and hence improve the interpretability in this study we aim to select an optimized set of features from the original 216 numbers the final random forest classifier makes use of this optimized set as input features we adopted a backward elimination strategy based on the built in permutation importance measure of features in the random forest algorithm namely recursive feature elimination rfe as originally described by guyon et al 2002 the rf rfe algorithm eliminates the least important feature in each step based on the computed feature importance firstly a random forest classifier with 100 trees is trained using the full feature set 216 nos permutation importance of each feature defined as the increased prediction error due to shuffling the values of that feature in the out of bag examples is then computed and the features are ranked the last 5 in the rank list i e least important are eliminated and a new feature set is obtained a new random forest classifier is then trained based on the new feature set and the whole process is repeated until all features have been eliminated for each classifier trained we recorded the f1 scores for the 15 target classes after all features being eliminated we plotted the f1 scores against the number of remaining classes a minimum number of features required to maintain the model performance can be determined and an optimized feature set can thus be obtained 3 7 convolutional neural network convolutional neural network cnn is a popular deep learning model which allows computers to be fed with raw data and to automatically discover the representations needed for recognition or classification lecun et al 2015 it typically consists of multiple layers in three types convolution pooling and fully connected layers the first two types perform feature extraction while the last type map the extracted features into final output for classification for purposes of image classification cnn uses pixel values of digital images scaled to a fixed input size as input and no hand crafted feature extraction is involved due to the complexity of training a cnn from scratch it is common to adopt a pre trained network already trained over millions of images in many object categories and use it as starting point to learn task i e transfer learning this allows acquiring a cnn model for a specific task using relatively small amount of training images the transfer learning technique has been successfully applied in several studies on classifying ifcb image data e g orenstein and beijbom 2017 lumini and nanni 2019 to assess the performance of our rf classifier we also developed a convolution neural network cnn classifier as a base line for comparison the cnn is fine tuned using transfer learning technique from googlenet szegedy et al 2015 imagenet version http www image net org which is 22 layer deep and originally classifies images into 1000 classes such as keyboard mouse pencil and many animals this pre trained network has learned different feature representations for a wide range of images before retraining the network we first replace the last fully connected layer with a new layer with the number of outputs equal to the number of training classes in our study i e 25 we also froze the weights of the 10 initial layers by setting the learning rates in those layers to zero which help to speed up network training and prevent overfitting to new data set since the network requires input images of size 224 224 3 but ifcb images are in gray scale and have various sizes we perform image re sizing before presenting them to the network for training parameters we set the learning rate to 0 005 min batch size to 64 and maximum number of training epochs to 10 the network is trained on a pc equipped with an i5 8600 cpu and a nvidia quadro p1000 gpu using the deep learning toolbox in matlab 4 results and discussion 4 1 feature selection for the rf classifier fig 5 shows the variation of model performance i e f1 score for out of bag examples in each target class as less important features are being eliminated using the recursive feature elimination rfe approach it can be seen that when feature size is reduced from 216 to 25 the f1 score for each target class remains nearly unchanged the overall performance is excellent with individual f1 scores above 0 9 for 12 classes and above 0 8 for 3 classes f1 scores for some of the classes begin to fall when feature size is reduced from 25 to 10 but still remain above 0 8 significant deterioration of performance is observed when feature size nf is reduced to below 10 it is interesting to see that the degree of performance deterioration varies depending on the target class for example for some dinoflagellates such as a sanguinea p gracile and tripos furca f1 score above 0 9 can still be achieved even using only 2 features on the other hand for some chain forming diatoms including chaetoceros spp and leptocylindrus spp noticeable decrease of f1 score can be observed when feature size is below 25 with unacceptable deterioration when nf is below 10 this indicates that the automatic detection of the chain forming diatoms requires more features than other classes overall extensive tests have demonstrated that a classifier using the optimum feature subset of 25 nos can be adopted with no performance deterioration as compared to that trained using all 216 features we further examine the details by looking into the features selected in each type as shown in table 2 it can be seen that all the six types of features are selected in the optimized 25 feature set with varying proportions it is noteworthy that the optimized set includes all the 6 texture features indicating the importance of this feature type for high level feature types such as diffraction patterns 100 features and histogram of oriented gradients 81 features the rfe algorithm identified only a few important features for inclusion in the final classifier 4 2 performance evaluation by confusion matrix fig 6 shows the confusion matrices for classifying a out of bag examples using the rf classifier and b validation examples using the cnn classifier each row indicates the instances of a true class the observations while each column indicates the instances of a predicted class the predictions the recall or specificity the percentage that the observed class is correctly predicted and precision or sensitivity the accuracy of the prediction values are computed using eq 1 generally both classifiers achieve excellent results for most of the target classes and overall classification accuracy across all 15 target classes i e percentage of all correctly identified target class images are 94 2 rf and 96 2 cnn for the rf classifier it can be seen that 12 target classes have both recall and precision above 90 and the other 3 classes i e chaetoceros spp leptocylindrus spp and m rubrum have both of them above 80 the precision and recall are generally balanced it is noted that 24 out of 450 images for chaetoceros spp are misclassified as leptocylindrius spp and 28 out of 450 images for leptocylindrius spp are misclassified as chaetoceros spp this indicates the difficulty in distinguishing these two classes which are both chain forming diatoms similar observation is also found for skeletonema spp and leptocylindrus spp nevertheless considering that only 25 features are used by the classifier such result is quite satisfactory for the cnn classifier the performance in terms of recall and precision is similar as the rf classifier for most classes except that the recall for leptocylindrus spp is as low as 68 9 much lower than 82 7 for the rf classifier it can be seen that 21 out of 135 images of chaetoceros spp are misclassified as leptocylindrus spp indicating the network is relatively easy to misidentify the former as the latter species during application the reason for the low performance of cnn for these two specific classes may be attributed to the image preprocessing technique adopted which is the simplest approach by shrinking or stretching the original image to fit to the input size of cnn images especially those with aspect ratio significantly larger or smaller than one can be distorted causing loss of information and therefore increasing the risk of misclassification 4 3 performance test on analyzing ifcb samples we developed a protocol to achieve real time automated species identification and cell count to quantify the performance of this real time system we analyzed 12 nos of fully manual annotated ifcb samples we recorded the processing time for analyzing each sample and compare the estimated cell abundance of target classes by manual rf and cnn approaches table 3 shows the results of this performance test for the processing time it can be seen that our rf classifier performs equally fast as using the cnn classifier in terms of cpu computing time even for analyzing a sample with over 13 000 images which is nearly the upper limit for ifcb sampling the rf approach only took less than 10 min for cell counts table 3 lists the estimated prevalence of the top 3 most abundant target classes in each sample and fig 7 shows comparison of prediction and true proportions for selected classes the predicted proportions by rf and cnn models were adjusted based on corresponding recall of each target class i re i using the approach as described by sosik and olson 2007 it can be seen that the rf model performs equally well as the cnn model the cnn model tends to over predict the proportion of chain forming diatoms such as leptocylindrus spp due to the high misclassification rate 4 4 interpretation by partial dependence plots when the number of trees and features in a random forest increase and the structure of each tree becomes deeper the interpretation of final decision becomes difficult through direct inspection of decision rules as an alternative we used the partial dependence plot pdp to evaluate the marginal effect of each feature on the output of the model friedman 2001 for the m th feature among the optimized feature set i e m 1 2 25 let x m be the value of this feature and x c represent the values of all other 24 features the partial dependence of the model output on predicting class j is then defined as 2 pd m j α 1 n i 1 n rf j x m i α x c i where rf j x i the probability score of the rf model i e the percentage of trees in the model with correct predictions to predict the i th example as class j n total number of out of bag examples the partial dependence calculates the average value of predicted probabilities of the n nos of examples by varying the value of x m α but keeping x c fixed we use the partial dependence plots pdp to see how a change in a feature variable affects the change in an output variable this helps us to verify that the classifier is making decisions based on correct reasoning we have performed this analysis for all 15 target classes and all 25 selected features as an illustrative example fig 8 shows the relationship between two geometric features selected in the optimized 25 feature set and the output of the rf classifier using pdp analysis for the feature of summedarea which can be an indicator of cell size we compared the pd values of cryptophycea gonyaulax spp and tripos furca as a function of α the box plot below shows the distribution of actual feature values of these three classes fig 8a it can be seen that pd values for a class significantly increases meaning that the probability score is higher when the feature value is within the range for that class and drops when the feature value is out of the range for example the pd value for gonyaulax spp is over 0 9 when the summedarea is around 4000 to 6000 but drops as low as 0 5 when feature value is below 800 this clearly shows that the feature summedarea is important in discriminating these three target classes similar observation can be made for the feature of eccentricity using another three classes h akashiwo p gracile and pseudo nitzschia spp fig 8b for example pd value of pseudo nitzschia is only high nearly 1 0 when the eccentricity is approaching 1 0 which is exactly the case for pseudo nitzschia it can be seen that pdp provides an intuitive way to understand the relationship between the input features and output classification and hence helps to build up confidence for users in applying the classifiers 4 5 realtime in situ automated species identification at ytt fcz with the developed classifier a fully automated routine for real time identification and cell count of target species has been established for ifcb fig 9 this contains the following major steps step 1 automated data transfer using file synchronization to achieve real time automated image analysis it is important to transfer raw data from ifcb computer to the remote user computer in real time this is achieved by the use of an open source software synctrazor www syncthing net that allows continuous file synchronization between two computers over the internet in real time we specified the data folder on ifcb computer as a shared folder once ifcb has finished analysis of one sample and corresponding raw data files have been created the software will automatically scan the data folder to search for the newly created files and synchronizes them to the destination folder on user computer in the lab step 2 automated image processing and auto classifier we automated the image analysis process using the timer function in matlab we first compiled the image processing functions for feature extraction and the trained auto classifer into a single matlab script the compiled script was then packed as a user defined custom matlab function for analysis of each ifcb sample data file i e identification and cell counts of target species using the timer function matlab automatically calls the custom function every 25 min search for new data and performing analysis the time for analysis usually takes around 0 5 to 10 min depending on the image quantity in each sample using the above steps a continuous real time data series of cell count for target species can be obtained with a response time of around 30 min after data collection 4 5 1 example h akashiwo bloom in march 2019 fig 10 shows the variation of abundance of target classes during an observed bloom from 22 27 march 2019 together with the real time data of dissolved oxygen d o and chlorophyll fluorescence chl f u measured by water quality sensors the data shows that d o near the surface 1 m depth exceeded 10 mg l for most of the time and several peaks of chl f u can be observed indicating there is a bloom happening during this period it should be noted that the saturated dissolved oxygen concentration in sea water is around 8 mg l and normally a distinct super saturation level of say over 10 mg l is indicative of algal blooms as confirmed by field observations of algal and d o dynamics in tolo harbour lee et al 1991 lee and lee 1995 guo et al 2020 the ifcb measurements suggest that the dominant species of the bloom is the motile heterosigma akashiwo it is also noted that ifcb measurements successfully captures the diurnal patterns of the abundance of motile species 5 concluding remarks the contribution of the present work is twofold i an ifcb has been successfully deployed underwater in a fish culture zone for the first time the research equipment has yielded large quantities of almost continuous algal image data over the 18 month operation in the order of 30 000 images per hour ii over 350 000 images have been manually annotated into 45 explicit classes an auto classifier for 15 target classes of hab species has been successfully developed using a classification tree method combined with an ensemble random forest rf approach using a robust recursive feature elimination technique the rf classifier uses only 25 key selected features and performs equally well as a fine tuned convolutional neural network cnn developed using transfer learning technique many of the commonly observed hab species in hong kong have been classified based on the developed classifier a protocol for automated real time species identification and cell counting has been successfully developed as far as we are aware this work represents the first successful attempt of continuous hab monitoring and automatic species identification at a fixed station in subtropical coastal waters compared to other algal bloom observation approaches such as the remote sensing method see e g cheng et al 2020 on using unmanned aerial vehicles for remote sensing of coastal algal blooms the use of ifcb has a unique advantage of being able to identify bloom species and count cells in real time through automated image classification the robust ifcb and computer vision based system can be integrated with an early warning hab prognostic forecast system guo et al 2020 to significantly enhance our ability to observe hab events in coastal waters it should be pointed out the experience so far has been limited to the ytt fish culture zone nevertheless it is conceivable the use of ifcb can usefully supplement traditional fisheries management by providing early alerts to prompt onsite monitoring and data on the time history of hab events in recent years a new wave of ai applications in water resources management has emerged in particular new modeling paradigms of using computer vision to incorporate spatial information e g temperature rainfall leaf index at catchment scale into integrated hydrological models to enhance streamflow forecasting have been proposed jiang et al 2018 jiang et al 2019 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by a r d project on pilot study of red tide early warning system from the agriculture fisheries and conservation department afcd of the hong kong special administrative region sar government afcd fis 01 18 the support of afcd in providing the real time and regular water quality data and discussion on the choice of the target hab species is gratefully acknowledged the guidance and assistance of mr stanley p c law on manual identification of algae species in hong kong is well appreciated appendix a manual annotation of ifcb images the manual annotation work is the key to the success of the present work as it provides the labeled training images for classifier development the annotation work is labor intensive and requires domain knowledge on taxonomy of algae species to optimize the efficiency of annotation as much as possible we used the startmc function in the ifcb analysis software package as developed by sosik et al 2016 the software provides a graphical user interface which displays a series of ifcb images on the computer screen by simple operations such as mouse clicking and pressing enter on keyboard each image can be annotated into the corresponding class depending on the availability of classifier there are two approaches to annotate the images using the software as described in the following a 1 approach 1 start from default unknown class without classifier we first defined our class list and set the default class as unknown at the beginning all images will be assigned into this default class automatically by the software fig a 1 shows an example of software display during the annotation the class list is displayed on the left and images on the right the images are displayed on the screen by size i e images with largest vertical dimension are shown first the number of images shown each time on the screen can be adjusted by setting the image scale factor and the number of images to load at one time during annotation we first highlighted a destination class i e the class to which we are annotating image in blue by clicking on the class name in the list then we selected images which we wished to annotate to the destination classes by single mouse clicking on each of them after selection results can be stored by pressing enter key and red numbers corresponding to the destination class will be shown on the location of each click the above process can be repeated for a new destination class after all images on the screen were annotated we could proceed to the next patch of images by clicking enter key one more time there are additional functions such as select all page which allows us to select all images on the screen using only one click which helps to save time spent on clicking a 2 approach 2 start from classifier to further improve the efficiency we also trained rf and cnn classifiers using the approach as described in the main test after we have collected a certain number of annotated images these classifiers were imperfect as compared to those adopted in the final automated system due to insufficient training images but the software enables us to start from displaying the images according to the classifier predicted classes and just use manual annotation to identify the incorrectly classified images and assign them to the correct class this helps to save a great amount of time and efforts fig a 2 shows two examples of screen display of the software that automatically assigns images into predicted classes appendix b extraction of image features for classifier development automatic hab species classification rests on supervised learning techniques based on extraction of image features the feature set and analysis method adopted for the ifcb images is based on the pioneering work of sosik and olson 2007 to facilitate the understanding of the workings of the machine learning and the optimization of the feature set the key steps of the algal image feature extraction are detailed below for completeness table 1 shows a list of 216 features widely adopted for algal image analysis as well as a sub set of 25 key features finally adopted for identification of 15 targeted hab species in hong kong b 1 step 1 edge detection b 1 1 blob images computed by phase congruency approach as the first step of image processing the boundary of the target of interest which is referred to as blob needs to be determined using edge detection techniques most of the images features are calculated based on the blob images and hence a robust and accurate edge detection is of the essence many methods are available for edge detection for ifcb images that reflects the morphological features of planktons such as spline flagella and many distinctive local areas sosik and olson 2007 recommended the use of a computationally intensive but effective approach computing the phase congruency in an image and apply a simple threshold based edge detection phase congruency is calculated following the method proposed by kovesi 1999 and using publicly available matlab based tools https github com hsosik ifcb analysis wiki after edge detection the blob image indicating the boundary of the target of interest is obtained the blob image is a black and white image that represents the blob area with white color pixel value 1 and other areas as black color pixel value 0 fig b 1 shows the typical computed blob images for selected target classes b 1 2 number of blobs in each images in each blob image one closed boundary represents one blob the total number of blobs in each image may vary depending on the characteristics of cell boundary and connection between cells for many image features the image processing tools compute the values based on a single blob but the sum of feature values of all blobs in one image may sometimes be more representative than the feature value of a single blob hence it is necessary to inspect the typical number of blobs in one image for each target species some examples are illustrated in fig b 1 for species that usually present as a single cell with a distinctive boundary such as prorocentrum gracile and akashiwo sanguinea there is usually only one blob in each image fig b 1a image features are therefore computed based on that blob for species usually presenting with multiple cells such as chain forming diatoms the number of blobs in each image depends on the type of connection between cells for leptocylindrus spp or pseudo nitzschia spp the cells are closely connected with a distinctive interface and the blob images usually contain only one blob for skeletonema spp the aperture between adjacent cells is large and cells are connected by numerous external tubes which can hardly be identified within the resolution of ifcb images in this case multiple blobs will be detected in one image similar situation is also observed for some of the chaetoceros spp fig b 1b in these cases it is more useful to compute the sum of features for all blobs b 2 step 2 image processing and feature extraction to achieve satisfactory performance in auto classification of target species it is important to extract representative features from the training images that are presented to the machine learning algorithm for classifier development it is also noted that a wide range of features are needed to describe different characteristics of the algae cells of different species these features which are usually referred to as hand crafted features are designed by domain experts who have knowledge on how to extract useful information from original images with pixel numbers for ifcb images we examined and adopted several groups of hand crafted features proposed by sosik et al 2016 as described in the following b 2 1 geometry descriptors as the normal practice of taxonomists in manual identification geometries size and shape of cells are usually used to identify certain species for example prorocentrum gracile is featured by its lanceolate shape with a pointed posterior end and a round anterior end for computer vision the geometric features need to be represented by a group of numerical values through some computation to show distinctive information let f x y represent a digital image with m rows and n columns of pixel points where x y are discrete coordinates x 0 1 2 m 1 y 0 1 2 n 1 and f x y is the pixel value at point x y the coordinate system is set with its origin at the top left corner of the image positive x axis extending downwards and positive y axis extending to the right a number of geometric features for each blob in the binary blob images are calculated as follows area a the area of each blob i e total number of pixel points in the blob region indicating the 2 d size of the blob area unit pixel2 perimeter p number of white pixel points along the boundary of each blob indicating the real perimeter of the blob in terms of pixel unit pixel majoraxislength l major length of the major axis of the ellipse that has the same normalized second central moments as the blob area see fig b 2 for an illustration computed as b 1 l major x 2 x 1 2 y 2 y 1 2 where x 1 y 1 and x 2 y 2 are two end points that define the major axis unit pixel minoraxislength l minor length of the minor axis of the ellipse that has the same normalized second central moments as the blob area computed as b 2 l minor x 4 x 3 2 y 4 y 3 2 where x 3 y 3 and x 4 y 4 are two end points that define the minor axis unit pixel eccentricity ratio of the distance between the foci and the major axis length of the ellipse that has the same normalized second central moments as the blob area computed as b 3 eccentricity l major 2 l minor 2 l major convexarea a c area of the smallest convex polygon or convex hull that can contain the blob unit pixel2 convexperimeter p c perimeter in pixel of the convex hull unit pixel solidity proportion of the white pixels pixel value 1 in the convex hull computed as b 4 solidity a a c the above features contain useful information to characterize the size and shape of a single blob to cater for some of the target species with multiple blobs in each image the sum of those features with units over all blobs are adopted including summedarea a summedperimeter p summedmajoraxislength l major summedminoraxislength l minor summedconvexarea a c and summedconvexperimeter p c for the dimensionless features of eccentricity and solidity the value corresponding to the largest blob in each image is used some dimensionless features derived from the above basic ones are added including area over perimeter computed as the ratio of a over p area over perimetersquared or compactness computed as the ratio of a over p 2 summedconvexperimeter over perimeter ratio of p c over p besides the basic geometric features we further define a bounding box which is the smallest rectangle that can contain a single blob it is noticed that the posture of an algae cell in each image may vary and the size of the bounding box may fluctuate in the same class due to different cell posture and hence affect the representativeness we therefore performed a rotation for the largest blob in each image to align its major axis along the x axis and a bounding box is defined based on the rotated blob fig b 2 the following features can therefore be computed rotatedboundingbox xwidth length of the side along x axis of the bounding box for largest blob after rotation in each image rotatedboundingbox ywidth length of the side along x axis of the bounding box for largest blob after rotation in each image rotated boundingbox solidity solidity of the bounding box for largest blob after rotation in each image a summary of the list of geometry descriptors can be found in table 4 b 2 2 shape based symmetry symmetry based on shape is also an important characteristic used by human experts to identify algae species for example taxonomists divide diatoms into two groups namely centric diatoms and pennate diatoms based on valve symmetry law 2018 a number of methods are available to detect the degree of symmetry through image processing considering the relative complex shape of some of the target species we adopted an effective and advanced approach by computing the hausdorff distance to measure the asymmetry of a shape the hausdorff distance measures the degree of similarity or overlap between two image objects that are superimposed on one another huttenlocher et al 1993 it is defined as longest distance that a point a in set a must travel in order to reach the closest point b in set b such that b 5 h a b max a a min b b a b where represents the l 2 or euclidean norm for the points of a and b the form of symmetry of the shape of a blob can therefore be evaluated by measuring the hausdorff distances between the pixel points in the original blob and the ones after some manipulation we computed the following features using the binary blob image h90 hausdorff distance between original blob and the one after rotating 90 with respect to its centroid i e intersection between major and minor axis h180 hausdorff distance between original blob and the one after rotating 180 with respect to its centroid hf lip hausdorff distance between original blob and the one after flipping along the major axis the hausdorff distances help to identify the different types of asymmetry and provide a quantitative characterization of different shapes some derived features can be further obtained as h90 over hflip ratio of h90 over hflip h90 over h180 ratio of h90 over h180 hflip over h180 ratio of hflip over h180 b 2 3 texture statistics besides geometry and shape the ornamentation over the cell also provides important information on identification of different species the pattern of ornamentation can be described numerically using texture measures either globally over the entire cell or locally at a specific area in this study we adopted a list of global texture descriptors derived from the gray level histogram fig b 3 shows how the gray level histogram is computed we first increase the contrast of the original gray scale image by saturating the bottom 1 and the top 1 of all pixel values then we filter out the pixels within the blob area region of interest the pixel values within the blob area are accumulated to form the histogram where the x axis corresponds to different pixel values or gray levels and y axis represents the number of instances the characteristics of this histogram can be described numerically by the statistical moments such that b 6 μ n i 0 n 1 i m n h i where μ n is the nth moment about the mean intensity m h i is the height percentage distribution of histogram bin at pixel value i n is the total number of possible pixel values and the mean intensity m is given by b 7 m i 0 n 1 ih i based on these the following descriptors are derived and adopted texture average gray level equals to the mean m and measures the average pixel values texture average contrast measures the average contrast and is given by b 8 σ σ 2 μ 2 texture smoothness measures the relative smoothness in terms of the variation of pixel values equals to 0 for constant gray level and 1 for large variations and is give by b 9 r 1 1 1 σ 2 n 1 2 texture third moment measures the skewness of the gray level histogram positive when skewed to the right and negative to the left and is given by b 10 μ 3 1 n 1 2 i 0 n 1 i m 3 h i texture uniformity measures the uniformity of pixel values and has its maximum when all pixel values are equal such that b 11 u i 0 n 1 h i 2 texture entropy measures the randomness of the histogram and is given by b 12 e i 0 n 1 h i log 2 h i b 2 4 moment invariants the shape of an image object can be described by its moments which are the weighted averages of its pixel intensities the moment of order a b for a continuous 2d function f x y is defined as b 13 m ab x a y b f x y dxdy where a b 0 1 2 for gray scale images with discrete pixel intensities g x y we replace the integrals with summations b 14 m ij x y x i y j g x y the moments can be used to derive invariants with respect to translation scale and rotation first central moments of any order that are invariant to translations are given by b 15 m ab x y x x a y y b g x y for a digital image g x y x m 10 m 00 and y m 01 m 00 represent the centroid of the object then invariants to both translation and scale can be derived from central moments as b 16 η μ ij μ 00 1 i j 2 where i j 2 using the above scale invariants hu 1962 showed that the following moments are invariant to translation scale and rotation b 17 i 1 η 20 η 02 i 2 η 20 η 02 2 4 η 11 2 i 3 η 30 3 η 12 2 3 η 21 η 03 2 i 4 η 30 η 12 2 η 21 η 03 2 i 5 η 30 3 η 12 η 30 η 12 η 30 η 12 2 3 η 21 η 03 2 3 η 21 η 03 η 21 η 03 3 η 30 η 12 2 η 21 η 03 2 i 6 η 20 η 02 η 30 η 12 2 η 21 η 03 2 4 η 11 η 30 η 12 η 21 η 03 i 7 3 η 21 η 03 η 30 η 12 η 30 η 12 2 3 η 21 η 03 2 η 30 3 η 12 η 21 η 03 3 η 30 η 21 2 η 21 η 03 2 the hu s moment invariants have been applied successfully in many pattern recognition tasks including identification of algae species e g sosik and olson 2007 we computed the 7 nos of moment invariants for the largest blob in each binary blob image namely moment invariant1 to moment invariant7 eq b 17 as an illustration fig b 4 shows comparison of blob images of different types it can be seen that moment invariants help to characterize different species with different shapes the moment invariants for a given observed cell species are approximately the same and not affected by different cell postures b 2 5 diffraction pattern sampling the diffraction pattern sampling is a widely applied technique for pattern recognition as described by berfanger and george 1999 it samples the fourier spectral density of an input image using a ring wedge geometry this geometry consists of a semi annular area rings on one half of the transformation plan and a wedge shaped area wedges on the other the radial sampling over the rings provides orientation independent information on the spatial frequency distribution in the image whereas the angular sampling of the wedges provides scale independent information about the spatial frequency orientation fig b 5 shows the 2d power spectrum of a blob image with size m n which can be calculated from the 2d fourier transform of the pixel value gray level distribution x j k defined by b 18 y p 1 q 1 j 0 m 1 k 0 n 1 e 2 π i m jp e 2 π i n kq x j 1 k 1 where i 1 p and j are indices ranging from 0 to m 1 and q and k are indices ranging from 0 to n 1 then a ring wedge filter with 50 nos of rings and 48 nos of wedges is used to sample the spectrum the portion of each wedge near the origin 15 pixel radius is removed the sampled energy in each ring or wedge is normalized by the total energy in the image to specify 98 nos of features i e ring01 to ring50 and wedge01 to wedge48 two additional features total energy rfhalfpowerintegral and the ratio of energy near the center to the total energy rwcenter2total powerratio are also included to form 100 nos of features in this type b 2 6 histogram of oriented gradients the histogram of oriented gradients hog descriptors have been widely applied in object detection since its successful application on human detection see dalal and triggs 2005 the technique counts occurrences of gradient orientation of pixel intensities in localized portions of a digital image the idea is to describe the local object appearance or shape using the distribution of local intensity gradients to compute hog descriptors the magnitudes of gradients at each pixel along x and y axis are computed to evaluate the total magnitude and direction of gradient vector at that pixel see fig b 6 for an illustration the computed gradient vector plot is divided into a number of windows a histogram of gradient directions in terms of cumulative magnitudes over all pixels in each window can be constructed the histogram bins are evenly spaced over 0 180 unsigned gradient or 0 360 signed gradient the heights of the bins indicating the gradient strength along different orientations form the elements of a feature vector in addition to eliminate the effect of local variations in illumination and shadowing the histogram is normalized over each window in the present work we followed the approach of ludwig et al 2009 and computed the hog descriptors of the original gray scale ifcb images over rectangular windows i e r hog using signed gradients fig b 7 each two adjacent windows overlap half of their area allowing each window to contribute more than once to the final feature vector each image is divided into 9 windows in each window a 9 bin histogram was computed the histogram were locally normalized over each cell using a l 2 norm scheme b 19 v v v 2 2 2 where v is the unnormalized descriptor vector v 2 is its l2 norm and is an arbitrary small constant take it as 0 01 with the resulting 9 histograms in 9 windows an 81 element feature vector was obtained namely hog01 to hog81 in summary each ifcb image is characterized by a feature vector of nf 216 elements table 4 shows the full list of features in our work through the random forest recursive feature elimination rf rfe process it is found that the inclusion of nf 25 features is sufficient for training the classifier for the target species identification appendix c species identification using decision tree based approach for learning and reasoning from feature based examples decision trees are among the most popular choices of various machine learning approaches decision trees resemble the way that human taxonomists identify a species manually by deduction from a set of decision rules learned from the extracted features of labeled training images a decision tree based classifier is developed using a decision tree induction algorithm the classification and regression trees cart method as described by breiman et al 1984 the detailed implementation of cart using a random forest approach for automatic algal species classification is outlined below for completeness c 1 decision trees c 1 1 basic principles to develop a decision tree classifier the induction algorithm splits a set of training samples into subsets so that the data in each of the child subsets are purer than the data in the parent set the objective is to reach final subsets that consist only samples belonging to single classes as illustrated in fig c 1 the result of the learning procedure is a tree in which each leaf node is labeled by a class name and each interior node specifies a test condition on a particular feature the growing of a tree is a recursive process in which the best split at each interior node is determined by trying all possible values of all input features the best split at each interior node can be evaluated by a measure of impurity the gini impurity index i e best split smallest gini index as defined by c 1 g i 1 n p i 1 p i where n number of classes and p i the percentage of samples with label i at that node g 0 implies a pure node with all samples in a single class while g 1 means all different classes are equally present in the samples c 1 2 an example for species identification we demonstrate the interpretability of a decision tree on species identification using 4 target classes as shown in fig c 2 each class has 450 nos of training images for better illustration the decision tree is trained using only 2 features extracted from the training images i e two input variables we computed eccentricity and summedarea which indicate the geometry and size of cells and are both interpretable by taxonomists the tree was trained using the fitctree function in matlab r2019b mathworks fig c 3 shows a simple decision tree after growing and the decision rules translated from the tree it can be seen that the tree successfully splits the 1800 training images into 4 pure leaf nodes the best split at each interior node indicates a decision boundary fig c 4 shows a visualization of decision boundaries on a 2d plot of the feature distribution of different classes c 1 3 issue of decision tree overfitting although decision trees are relatively easy to explain and interpret its classification power is limited trees that are grown to a very deep level tend to learn highly irregular patterns they overfit their training sets i e have low bias but very high variance to overcome this issue a common practice is to construct multiple trees and output the majority votes of the classification results which is referred to as ensemble learning among various ensemble methods random forests is the most popular one c 2 random forests c 2 1 basic principles random forests as described by breiman 2001 use the idea of bootstrap sampling and feature bagging to build a collection of decorrelated trees random forest of nt trees and average the tree results to make a final decision as shown in fig c 5 bootstrap sampling is achieved by sampling with replacement n examples from the original training data set of size n examples not picked up are left out as out of bag examples for each bootstrapped data set a decision tree can be grown using the classification tree method and a subset of the features the following steps are repeated at each interior node i select m p features at random from the original p features ii determine the best split among the m features and iii split the node into two child nodes the purpose of feature bagging is to remove correlation among trees the default value of m is p tunable by the user for example if p 216 features are used as input then at each interior node in each tree m 216 15 features will be selected at random to determine the best split similarly if p 25 is selected m 5 see fig c 6 using both bootstrap sampling and feature bagging an ensemble of nt trees can be developed as the final random forest classifier fig c 7 to make a classification of an unlabeled input the final decision is the majority vote of the predictions made by each of the nt individual trees fig c 8 c 2 2 an example for species identification we illustrate how a random forest classifier perform species identification using 4 target species as shown in fig c 2 450 nos of training images in each class or training set of 1800 images for illustration purpose 4 simple features are extracted including eccentricity summedarea summedmajoraxislength and summedminoraxislength for simplicity nt 6 trees are grown using bootstrap sampling and feature bagging the output of the random forest classifier will therefore be the majority vote of these 6 trees fig c 9 shows the variation of out of bag classification error with respect to the number of grown trees it can be seen that performance improves significantly by using multiple trees as compared to a single tree fig c 10 shows an application example of the rf classifier it can be seen that although a single tree may give a wrong prediction the rf classifier uses 5 out of 6 trees to correctly predict the test image as p gracile c 3 concluding remarks decision trees can learn to identify algal bloom species by deriving a set of decision rules based on extracted image features the rules are human readable and can be interpreted by taxonomists since a single tree may be prone to overfitting and thus is poor in generalization an ensemble of trees i e the random forest approach is used to improve the classification accuracy the cost of growing multiple trees is the increased model complexity and less interpretability especially when the number of trees and extracted features are large therefore feature selection will be necessary to reduce model complexity for better interpretation of the machine learning results and to enhance computational efficiency to pave the way for integration with internet of things e g ai chips 
1698,the otofuke river is a tributary of the tokachi river hokkaido japan consisting of a channelized reach with a steep slope and a relatively large designed width in august 2016 the river witnessed four major flooding events with a record breaking discharge within a time span of 15 days the otofuke river originally had a straight channelized reach however because of a series of flooding events the river promptly followed a sinusoidal path damaging the riverbank embankments the straight channelized reach of otofuke river faced active erosion of both banks leading to the formation of a meandering channel planform this also led to levee breaches at the seven locations in order to understand the mechanism of such a quick shift in river channel planform we collected various field survey data and conducted computational analysis we investigated the underlying processes by capturing the complex interactions between the rapid channel migration unsteady discharge and sediment transport field surveys including aerial photographs and images showed rapid formation of a meandering planform in the otofuke river as a result of the typhoon on 31 august 2016 according to the maximum water level traces bank erosion developed after the peak discharge numerical investigation revealed that alternate sandbars continuously developed and propagated downstream until the moment of peak discharge and a significant accumulation of sediment subsequently started on the bars at the mid channel during the flood falling stage such morphological processes led to strong flow deflections transversely toward the embankment that resulted in lateral channel shifting and levee breaches at a location where vegetation along the embankments had already disappeared keywords rapid meander shift levee breaches bank erosion unsteady discharge otofuke river 1 introduction lateral channel migration with bank erosion and growth of point bars leads to meander channel formation followed by increased meander amplitude neck cutoff and chute cutoff in a broad range of channel widths e g brice 1974 hickin 1969 ikeda et al 1981 parker 1976 meandering channels are quantitatively classified into several types from the perspectives of channel deformation rate related to channel slope and bed load materials brice 1983 schumm 1985 1977 among several types of meandering channels the most common river pattern in large lowland alluvial floodplains is a meandering braided transition channel in this type of meandering thalweg and morphological changes are relatively active in the channel characterized by a high width depth ratio zolezzi et al 2012 in the recent years rivers located in relatively high gradient reaches globally have been affected by river works such as channelization and flow regulation such river works have changed the forms of those channels from their original multi thread braided forms to single thread meandering forms e g camporeale et al 2013 friedman and lee 2002 winterbottom 2000 in those single thread meandering channels because of the significantly large amount of sediment load composed of gravel and cobble the growth and shift in channel meander often dramatically change the flow alignment e g kleinhans and van den berg 2011 nichols and viers 2017 tal and paola 2010 rapid channel migration is a risky factor because it may lead to bank erosion or levee breaches considering the recent increase in localized torrential rain accompanied with climate change factors and triggers of rapid channel migration in such regulated rivers are required to make a countermeasure still the exact factors influencing a rapid meander shift within a short term i e a night at single thread meandering channels remain unclear here we studied a case with a quick meander shift including seven levee breaches in the otofuke river in the eastern part of hokkaido japan and discussed several factors unsteady discharge flow structures sediment transport and vegetation by means of computational analysis to understand their impact on the lateral channel migration at this single thread meandering channel it was originally braided channels the number of flow paths is reduced from a multi thread channel to a single thread channel with co developing bend sinuosity in such rivers developing bend sinuosity due to meander growth and shift is strongly influenced by bank strengthening earlier experiments have shown that adding stabilization to banks for multi thread channels using cohesive fine sediment or vegetation leads to a significant decrease in both namely the erosion rate at the outer bank and the incision rate at the inner areas of bends e g braudrick et al 2009 jang and shimizu 2007 tal and paola 2007 van dijk et al 2013a the channel becomes more stable than before and it prevents chute cutoff in the inner area of the bends as well as channel widening e g bertoldi et al 2014 brooks and brierley 2002 surian et al 2015 van oorschot et al 2016 however it results in the development of bend sinuosity while with weak bank stability overbank flow enhances the occurrence of chute cutoff as the bank incision causes broadening of the channel van dijk et al 2014 2013a more recently variable discharge during floods is also a key factor for channel migration in the lateral direction in single thread meandering channels nagta et al 2014 van dijk et al 2013b in an early experiment van dijk et al 2013b showed the importance of unsteady discharge in developing bend sinuosity in a meandering channel including cohesive sediments high flow levels of unsteady discharge work to fill the potential chutes traces of old channels on higher floodplains with fine cohesive materials and suppress chute cutoff resulting in the development of bend sinuosity other computational studies iwasaki et al 2016 nagata et al 2014 have also clarified the importance of unsteady discharge under cohesionless conditions in single thread meandering channels affected by vegetation in their reports at first meandering amplitude developed with the co development of point bars at bends later a significant meander development with bank erosion occurred during the discharge decreasing stage due to flow accumulation into a low flow channel alternate thalweg until chute cutoff occurred at the inner bends however the above progresses with and without cohesion differ in the following ways in the case of cohesion banks are gradually stabilized by overbank flows meanwhile at meandering rivers affected by flourished vegetation the spatially different bank stability resistance between locations gradually increases during extreme flood events because of the flushing of vegetation patches away from the floodplain spatiotemporally therefore in such rivers it is difficult to predict the time and location of the lateral channel migration this difficulty should be more apparent in straight rivers before meandering having a weak sinuosity and undeveloped point bars meandering rivers that were originally braided channels located in high gradient reaches usually consist of non cohesive materials with a vegetated floodplain hence they are strongly affected by extreme flooding events for instance the large flood events in 2011 2013 and 2016 on hokkaido island of japan e g iwasaki et al 2016 nagata et al 2014 in particular in august 2016 tokachi river basin in eastern hokkaido experienced record breaking precipitation by a series of four typhoons and a rain front within two weeks furuichi et al 2018 the maximum total amount of rainfall in august observed in this region was around 800 mm nearly equal to the annual average rainfall because of a series of flooding events a remarkable large scale channel migration with the meandering planform led to levee breaches in a number of tributaries in the tokachi river basin e g ishida et al 2017 according to several reports and a field survey most of the levee breaches were not caused by overtopping of the levees but by the amplifying of the channel sinuosity with lateral migration in many reaches of the river despite the river channel width and embankment height being sufficiently designed for the extreme rainfall and discharge conditions based on historical data levee breach disasters have occurred in a short duration of less than one night caused by bank erosion due to the rapid channel meander shift generally studies on channel meandering are often related to moderate or long term time scales e g asahi et al 2013 comporeale et al 2013 friedman and lee 2002 parker et al 2011 while in a meandering channel that was originally a braided channel the role of extreme floods on channel evolution is more dominant an extreme flood event can have a short term impact leading to rapid channel meander shift which causes a major problem in river management work consequently it is important to understand and predict the patterns locations and scales of bank erosion due to the meander shift under different scales of flood events the development of sandbars and mid channel bars occurs relatively quickly during a flood event in high gradient rivers that modify flow alignments in space and time higkin 1969 wickert et al 2013 the strong flow near banks causes bank erosion and flushes the vegetation regardless of many past studies the conditions under which rapid channel migration develops during extreme flood events in weakly sinuous or straight single thread rivers affected by vegetation are still ambiguous the aim of this work is to describe the impact of an extreme flood event on the rapid lateral migration of channelized channels that were originally braided rivers the research was conducted on a channelized reach of the otofuke river a tributary of the tokachi river in hokkaido having a steep slope and a relatively wide designed width the otofuke river was originally a braided river with multi thread channels under natural higher flow discharge however after a series of river management works such as constructions of embankments and a dam for power generation namely nukabira dam completed in 1956 the river planform changed to a single thread channel with the reduction in channel width and discharge regulated by the dam then vegetation was invaded in august 2016 because of a series of flood events the otofuke river promptly followed a sinusoidal planform damaging the riverbank and embankments in particular the straight channelization part in the upstream area depicted in fig 1 faced active erosion of both banks because of meander shift and led to levee breaches at the seven locations as shown in fig 2 this channel shift was incredibly fast as short as one night leading to the development of a meandering planform that flushed revetments away completely in order to understand the dominating factors of such a large scale rapid channel migration within a night caused by the record breaking flood discharge we collected field survey data such as precipitation discharge water level traces and aerial photographs by uav unmanned aerial vehicle additionally two dimensional morphological modelling of the affected reach was carried out to replicate rapid channel migration under the unsteady discharge condition the model replicated sediment transport sandbar propagation and the effect of colonized vegetation 2 site description the river basin has a drainage area of 740 km2 and total channel length of 94 km its source is from mt otofuke located at an altitude of 1 932 m above sea level at the beginning the river flows southward from a small mountain including several tributaries and confluences and flows into nukabira lake which is an artificial lake reservoir created by the nukabira dam for electric power generation after the dam the river continues to flow southward across the tokachi plain eventually merging with tokachi river the otofuke river used to have abundant water discharge however at present its discharge has been decreased considerably due to dam operation and flow diversion toward a different river basin because of the decreasing flooding magnitude and frequency the morphology of the otofuke river changed from the original multi thread braided channel without floodplain vegetation to a single thread meandering channel wandering channel with a colonized vegetation floodplain the river management work started in 1951 in the otofuke river basin the first work was to build embankments and channels were subsequently dredged and widened in the 1970s to provide sufficient space between the main channel and bank with levees large scale changes were not observed in the river until 2010 however a relatively large flood event in september 2011 affected the river morphology iwasaki et al 2016 nagata et al 2014 the present study reach is around 8 km long with a drainage area around 500 km2 the reach is located around 34 to 42 km upstream from the confluence of the tokachi river as illustrated in fig 1 the slope is about 1 120 the channel width between embankments is 200 m and the mean sediment diameter is around 55 mm the study reach is characterized by a weakly sinuous single thread channel with vegetated alternate sandbars between straight embankments this is the reach where levee breaches occurred at seven locations during the flood of august 2016 as shown in fig 2 3 channel migration during an extreme flood in august 2016 3 1 extreme precipitation and flood discharge the historical record of the annual maximum discharge m3 s at the shihoro and otofuke gauging stations is shown in fig 3 which is based on the data measured by hokkaido development bureau the shihoro gauging station is located a few kilometers downstream of our study area as shown in fig 3 the highest flood since 1975 occurred in 31 august 2016 fig 4 shows the cumulative rainfall depth during august 2016 in hokkaido it was observed by an automated meteorological data acquisition system amedas at the nukabira onsen gauging station provided by japan meteorological agency the nukabira onsen amedas station is 540 m above sea level the total rain in the obihiro area located in eastern hokkaido and in the tokachi river basin obihiro area exceeded 500 mm in addition the nukabira onsen amedas station the otofuke river basin reported a total amount of precipitation exceeding 700 mm the average annual rainfall in the obihiro area is around 887 mm which implies that the rainfall during this extreme event was almost equal to the average annual amount fig 5 shows detailed information of rainfall intensity and cumulative rainfall depth during the period from 16 august to 1 september 2016 which were collected at the nukabira onsen amedas station as can be seen from fig 5 the river basin experienced record breaking precipitation first three typhoons no 7 11 and 9 hit hokkaido on 17 20 21 and 23 august 2016 respectively subsequently a rain front and another typhoon no 10 hit on 26 and 30 31 august respectively the entire period of these events was about 15 days fig 6 shows time series of the flow discharge and the water level at the otofuke gauging station during the period from 1 august to 15 september 2016 the highest water level occurred at 13 00 on 31 august with a peak discharge of 763 83 m3 s and a peak water level of 207 15 m the figure shows that the maximum observed water level did not exceed the designed high water level i e no embankment level overflow this implies that levee breaches occurred at seven locations not because of the overflow but because of the lateral erosion consequently for management of high gradient rivers it is important to understand not only the flow discharge capacity but also the morphological process of channel migration with bank erosion 3 2 channel migration the otofuke river also experienced levee breaches several times in the past this fact was considered in the river management planning and design by maintaining a larger channel width however even though the water level had not reached the designed high water level in the area the extreme precipitation on 31 august led to a rapid change in river planform with a sinusoidal meandering pattern it damaged the river embankments especially in the study area where the river was channelized as a part of river management works fig 7 shows the plan view of the channel form before and after the flooding events before the series of flood events the channel planform in the area was a weakly sinuous single thread affected by floodplain vegetation as shown in fig 7 a the width of the low water channel was around 20 to 80 m fig 7 b shows the channel planform after the three typhoon events comparing the channel planforms between fig 7 a and b does not reveal any noticeable bank erosion the photographs taken by uav dji phantom 4 after the last typhoon induced flood as shown in fig 7 c show channel migration and bank erosion along both the left and right banks alternately the width of the flow path increased from around 90 to 240 m according to the field survey this meander shift developed regardless of revetment which used to protect the lower channel path fig 7 c most revetment flushed away during the last flood fig 8 shows the bank lines before and after the series of flooding events comparing the bank lines depicted in fig 8 it can be revealed that the mean flow width between the left and right banks increased by a factor of around 2 54 from 63 to around 160 m and the maximum width between the banks increased up to around 300 m which is more than the designed channel width around 200 m between the embankments the water level trace detected on the remaining embankment in the study area during the field survey after the flood confirmed that the flood level was lower than the crest level of the embankments this observation agrees well with the water level measurement data at the gauging station depicted in fig 6 therefore it is most likely that the bank erosion and levee breaches occurred after peak discharge this was also observed in the past in the otofuke river as reported in nagata et al 2014 and iwasaki et al 2016 these studies were focused on the 2011 flood event in the otofuke river the study area was located relatively downstream where the channel curvature developed their study described that the channel meandering amplification was strongly related to point bar development during the high discharge stage in their study area it caused significant bank erosion and river bed evolution and resulted in the co development of sandbars and the meandering channel planform in the middle reach of otofuke river in addition a falling stage of the flood is a key factor which appears to cause significant bank erosion because of the flow concentration around the sandbar creating main channel thalweg curvature flowing toward the banks in september 2011 no levee breach occurred in the middle reach of otofuke river a chute cutoff finally occurred at the bend resulting in a returned flow path from the location close to the banks to the center part of the channel unlike the flood event of 2011 the flood event of 2016 damaged the banks and the levees at the upper basin and it was considerably more severe than that of the middle reach the flood of 2016 is recorded as a flood with maximum historical discharge during this flood the channelized area in the upstream reach experienced significant meandering resulting in levee breaches at seven locations this implies that the increase in flood peaks in the future also due to climate change could change not only the risk scales but also the locations for the planning and design of a future disaster management system in steep rivers even with a sufficient designed width it is important to understand the rapid channel migration process under varying flow with large peak discharge the physics based morphological modelling approach and tools are effective for the rapid assessment of such complex processes the modelling tool can be applied to replicate and understand the relationship between flow sediment transport sandbar dynamics vegetation dynamics flash by scour and bank erosion this is described in the next section 4 numerical analysis 4 1 computational model in this study an unsteady two dimensional numerical analysis is conducted to simulate flow bed deformation and channel migration in order to replicate the flooding event of 2016 the analysis used nays2d solver jang and shimizu 2005 shimizu 1996 1989 which was recently incorporated into the iric software provided by the international river interface cooperative iric project nelson et al 2016 4 1 1 governing equations for flow the governing equations are an unsteady horizontal two dimensional continuity equation and momentum equations shallow water equations the equations are mapped onto a generalized curvilinear coordinate system this model is summarized in several documents e g iwasaki et al 2016 jang and shimizu 2007 2005 shimizu 1989 the equations in orthogonal coordinates x y are transformed into a generalized curvilinear coordinate system ξ η continuity equation 1 t h j ξ h u ξ j η h u η j 0 momentum equation u ξ t u ξ u ξ ξ u η u ξ η α 1 u ξ u ξ α 2 u ξ u η α 3 u η u η g ξ x 2 ξ y 2 h ξ ξ x η x ξ y η y h η 2 c f u ξ hj η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 d ξ f ξ ρ h j u η t u ξ u η ξ u η u η η α 4 u ξ u ξ α 5 u ξ u η α 6 u η u η g ξ x η x ξ y η y h ξ η x 2 η y 2 h η 3 c f u η hj η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 d η f η ρ h j 4 u ξ ξ x u ξ y v u η η x u η y v 5 j 1 x ξ y η x η y ξ 6 c f g n 2 h 1 3 where t is the time h is the depth and u ξ and u η are the contravariant depth averaged velocities in the generalized curvilinear coordinate system ξ η respectively h is the water level g is the gravitational acceleration and α 1 to α 6 are coefficients resulting from transformations of the velocity components from orthogonal coordinates to the generalized curvilinear coordinate system jang and shimizu 2005 shimizu 1996 1989 c f is the bed friction coefficient d ξ and d η are the diffusion terms in the generalized curvilinear coordinate system f ξ and f η are the contravariant drag forces due to vegetation along the ξ and η coordinates respectively ρ is the density of water u and v are the velocities in the x and y directions respectively and n is manning s roughness coefficient the effect of vegetation is estimated by vegetation density and expressed as an additional drag force incorporated in the momentum equations f ξ and f η as follows 7 f ξ 1 2 ρ c dv λ v h u ξ η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 8 f η 1 2 ρ c dv λ v h u η η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 where c dv is the drag coefficient of vegetation and λ v is vegetation density note it has dimensions the vegetation density is determined as a shielding rate of vegetation percentage of vegetation occupied area in a projected area to the sampling area as 9 λ v n v d v a v where av is the sampling area nv is the number of vegetations and dv is the average diameter of vegetation in the sampling area here the original program is modified to calculate the vegetation density as a function of the bed erosion at each cell when the difference between the calculated bed level and initial bed level consider when the former value is smaller than the latter exceeds a specified criterion determined by the root average lengths of willows in the study area that vegetation density λv is set to zero this means that colonized vegetation is flushed away in the model 4 1 2 bed load transport and bed deformation the bed and the embankments of the otofuke river are dominated by sand gravel bed material hence we calculate only the bed load sediment transport as the effect of suspended load is negligible the following equilibrium bed load transport formula proposed by ashida and michiue 1972 is applied 10 q bs sg d 3 17 τ e 3 2 1 τ c τ 1 τ c τ where qbs is the total bed transport rate in the stream direction of depth averaged flow τ is the non dimensional shear stress τ c is the non dimensional critical shear stress τ e is the non dimensional effective shear stress ashida and michiue 1972 s is the specific density of bed load material and d is the sediment diameter the non dimensional critical shear stress is determined by the iwagaki formula iwagaki 1956 the sediment transport in the transverse direction is estimated as a function of transverse bed slope e g hasegawa 1989 kovacs and parker 1994 luu et al 2004 shimizu et al 1996 watanabe et al 2001 the sediment transport rate along ξ and η coordinates is given by the following equations 11 q b ξ q bs u b ξ v b γ z b ξ cos θ z b η 12 q b η q bs u b η v b γ z b η cos θ z b ξ where v b is the composite velocity velocity magnitude near the bed u b ξ and u b η are the near bed velocity components in the generalized curvilinear coordinate system θ is the angle between the ξ and η axis in the generalized curvilinear coordinate system and zb is the bed level γ is a correction coefficient for sediment transport rate based on the local bed slope at each grid cell and is calculated by hasegawa 1989 1981 13 γ τ c μ s μ k τ where μ s 0 45 and μ k 1 0 are coefficients for the static and kinetic frictions respectively the near bed velocities in the streamlines and secondary flow are estimated as follows 14 u bs β v 15 u bn u bs n h r s where u bs is the near bed velocity in the streamline direction v u 2 v 2 is the velocity magnitude of depth averaged flow u bn is the estimated near bed velocity under the effect of secondary flow in the direction orthogonal to the streamline n is an empirical coefficient equal to 7 0 engelund 1974 and r s is the curvature radius of stream lines jang and shimizu 2005 β is estimated by the following equation engelund 1974 16 β 3 1 σ 3 σ v σ 3 φ 0 κ 1 v u 2 v 2 where φ 0 is a coefficient related to flow velocity v u and κ is the von kármán constant the near bed velocity components u b ξ and u b η in the generalized coordinate system are transformed as follows 17 u b ξ x s ξ x x s ξ y u bs x n ξ x x n ξ y u bn 18 u b η x s η x x s η y u bs x n η x x n η y u bn the curvature radius of stream lines in orthogonal coordinates is transformed in generalized coordinates as follows jang and shimizu 2005 19 1 r s 1 u 2 v 2 3 2 u 2 ξ x v ξ η x v η u v ξ y v ξ η y v η u v ξ x u ξ η x u η v 2 ξ y u ξ η y u η bed elevation is calculated by a balance between incoming and outgoing sediment rates the governing equation is as follows exner equation 20 t z b j 1 1 λ ξ q b ξ j η q b η j 0 where λ is the porosity 0 4 of river bed material the bank erosion and sediment failure at an excessive local score hole are the effects of the sediment avalanching process hence we applied a model for sediment avalanching based on the angle of repose for two adjacent cells if the bed slope exceeds the angle of repose a volume of sediment from the cell with a higher level is moved to the other cell in such a way that a slope equal to the angle of repose is achieved e g crosato and saleh 2011 michiue and hinokidani 1992 nagata et al 2000 4 2 numerical parameters here we simulated river reach with a length of 7 3 km the grid size in the streamwise and transverse directions are set to dx 7 0 m and dy 4 0 m respectively the time step is set to dt 0 2 s we applied grid sensitivity analysis and found that the employed grid resolution is optimum and refining the grid does not affect the result significantly the discharge hydrograph is estimated from the recorded water level at the shihoro water gauging station corresponding to the last flooding event fig 9 the mean diameter of uniform sediment material is set to 55 mm based on the field survey data conducted by the hokkaido regional development bureau the roughness is set by means of the manning roughness coefficient equal to 0 03 vegetated regions are set based on a series of aerial photographs shown in fig 7 a the density of vegetation is set to 0 03 based on the field observation to consider the vegetation mainly natural willows disappearance due to local erosion the criterion for erosion depth from the initial bed level is set based on the field observation to 20 cm this depth is sufficient to remove all soil around natural willows in the tokachi river basin nagata et al 2016 according to nagata et al 2016 the roots of dominant species of natural willows in the tokachi river basin are not deep and 80 of the volume of major roots are concentrated within the top layer of 20 cm on the floodplain initial topography data were determined using the digital elevation model measured in 2013 with a resolution 5 m as for the boundary conditions depth averaged flow velocity and normal flow depth related to flow discharge were given at the upstream and downstream boundaries respectively in addition the equilibrium sediment transport rate was given at the upstream boundary where the initial bed elevation does not change because of bed aggradation or degradation 5 computational results and discussion 5 1 accuracy of water level and morphodynamics fig 10 shows a longitudinal profile of the trace water level from the field observation and water level at the moment of peak discharge from the computational results comparing both results in fig 10 the computed water level at the peak discharge did not exceed the height of the embankments it agrees with the results of the field surveys the averaged differences between the field survey and the computation for the maximum water level was tens of centimeters indicating that the maximum water level reasonably matches the field survey data fig 11 shows an aerial photograph from a moment after the disaster and a contour map of the simulated bed elevation the results for channel planform match well with the situation during and after the flood the weakly sinuous single thread channel within the straight embankments changed their planform to a significant meander single thread channel with increasing bend sinuosity at locations of the levee breaches and then alternating left and right embankments were reproduced 5 2 process of rapid channel meander shift 5 2 1 depth velocity and morphological changes fig 12 shows a time series of the contour map for simulated depth overall significant lateral channel migration was confirmed even in the fall down stage of the discharge hydrograph a comparison between the hydrograph fig 9 and the simulated depth fig 12 shows that the depth increased and formed alternate thalweg at the increasing stage of the hydrograph fig 12 b until the peak flow discharge it was confirmed that the alternate thalweg constantly propagated to the downstream direction although not shown in the figure subsequently after the peak flow discharge the depth became gradually shallower with the maintaining of the alternate thalweg caused by the planform of the meandering channel fig 12 d this led to a situation where the flow significantly reflected toward the river embankments even when the discharge became low fig 13 shows a time series of simulated contour maps for depth averaged velocity according to fig 13 the plane formation of high speed flow areas enlarged with the channel meandering shift until the peak of flow discharge fig 13 a 13 b subsequently during the decreasing stage of discharge the high speed velocity area gradually meandered as an alternate thalweg fig 13 b 13 c 13 d finally the meandering planform of the main flow path was most apparent in fig 13 e where the magnitude of flow velocity decreased considerably it indicates that the bank erosion progressed in the latter half of the flooding event this is because the new channel planform described below caused flow reflection divergence toward the bank embankments fig 14 shows a time series of simulated bed elevation changes a comparison between the bed elevation changes at each time indicates that channel sinuosity shifted remarkably and a rapid formation of sine curves in the otofuke river was presented although the channel widening gradually developed the lateral channel migration including bank erosion was clearer after the peak flow discharge fig 14 e than that before the peak flow discharge fig 14 b according to our simulations the propagation of alternate sandbars toward the downstream direction was confirmed until the moment of peak flow discharge but it stopped after the peak flow discharge as illustrated in fig 14 lateral channel migration with the co development of bend sinuosity started considerably after the peak flow discharge furthermore the height of the river bed elevation at the center part of the channel gradually increased due to sedimentation at the same time it led to the formation of mid channel bars see the depth contour map in fig 12 e in the center part of the channel during the falling stage of flow discharge this suggests that this topographic change causes flow reflection toward the river embankments and develops the meandering planform in this flood event 5 2 2 sediment transport rate fig 15 shows a time series of sediment transport rate and cumulative flow discharge at the cross section c c location is illustrated in fig 11 the figure reveals that the amount of sediment transport rate rose relatively slow with the increase in flow rate and decreased rapidly after the moment of peak flow discharge it implies that because of the imbalance in the amount of sediment transport and sedimentation rate incoming and outgoing sediment accumulation becomes active at the inner bends of the newly formed single thread meandering channel where the depth becomes shallower unlike the flow mostly follows the hydraulic parameters sediment transport and sedimentation usually have a time lag in space and time as the velocity shear stress and capacity of sediment transport rate become smaller during the falling stage of flow discharge sedimentation in the low flow channel see the yellow areas in fig 14 e will very likely increase and make the flow direction further change toward the embankment directions therefore although the flow depth and velocity magnitude also shear stress was much larger at the moment of peak flow discharge the channel shift accompanied with bank erosion became active after the peak flow discharge in the otofuke river in this short term flood event 5 2 3 lateral migration and vertical erosion fig 16 shows the simulated bed elevation at cross sections a a b b and c c as illustrated by fig 11 this figure shows that the levee was breached in the latter half and the channel widened during the flood event by about 200 m identical to the field survey data a similar behavior was observed at each cross section in the simulated river until the moment of peak flow discharge the channel widened in the lateral direction and the scouring depth increased in the vertical direction though after the peak flow discharge the lateral movement of the flow path continued but the vertical erosion rate did not increase to confirm the vertical erosion rate related to the hydrograph fig 17 a shows a time series of the differences in the specific bed height between the lowest and highest points levee on cross section c c location fig 11 the specific bed height in the vertical direction gradually increased until the peak flow discharge and it subsequently slightly decreased this implies that the specific bed height related to the growth of wave height of alternate sandbars increases depending on the flow magnitude conversely after the falling stage of flow discharge the growth of the wave height of alternate sandbars stops as well as the propagation of sandbars to the downstream direction fig 17 b shows a time series of the maximum width of sedimentation areas of an alternate sandbar on the cross section c c the width indicated a rapid widening of sedimentation areas until the moment of peak flow discharge subsequently the width of sandbars in the cross section c c continuously expanded even in the latter half of the flood event therefore although vertical erosion depth related to the wave height of sandbars strongly depends on the flow magnitude fig 17 a the channel expansion in the lateral direction does not mainly depend on the flow magnitude fig 17 b to discuss the interaction between channel expansion in the lateral direction and the route of sediment transport fig 18 shows contour maps of the bed topography elevation changes and vegetation distribution and the vector map of bed load transport rate around the cross section c c the computational approach explained that the route of bed load material gradually meandered in the latter half of the flood event because of the emergence of mid channel bars at the center part of the channel this strongly reflects flow deflection transversely toward the embankments those phenomena should develop a rapid lateral channel shift and channel deformation to a sinuous single thread meandering channel in the otofuke river furthermore compared to the morphological changes and vegetation distribution in fig 18 increases in channel sinuosity were confirmed in the place where vegetation patches disappeared during the flood event it is also important to note that changes in vegetation distribution during floods can lead to a local weakness of bank strengthening due to a lack of resistance comparison with the previous disaster event at the middle reach of the otofuke river iwasaki et al 2016 nagata et al 2014 and this event at the upper reach indicated that the locations of channel meander and bank erosion are different in the previous event lateral channel migration had been locally developed at the bend because of flow reflection caused by point bar deposits subsequently chute cut off had been developed on the floodplain at the inner bend so that bank erosion levee breach did not occur because of the decrease in channel sinuosity however in the current event on august 2016 a weakly sinuous single thread channel was damaged by channel meandering the situation was as follows alternate sandbars continuously propagated toward the downstream until the moment of peak flow discharge during this term the channel expanded as the flow discharge rate increased however local lateral channel migration was not clearly observed meanwhile the planform of the entire flow path changed after the moment of peak discharge when the propagation of sandbars to the downstream direction stopped a new planform meandering channel had developed with the co development of sedimentation in the center part of the channel and the planform was almost uniformly bend sinuosity leading to the alternate right and left banks levee breaches this suggests that the hydrograph bank strengthening and propagation of alternate sandbars considerably influenced the channel planform in a weakly sinuous single thread channel moreover once bank erosion begins sediment is supplied not only from the upstream but also from banks so the ratio of sediment deposition on the sandbars center part of the channel should be accelerated leading to a development of channel meandering and new bank erosion the results from the field survey and the computations explained that the channel meander shift in the short term cannot always be determined by the magnitude of the peak flow discharge the flow reflection toward the embankments occurred during the latter half of the flood event this is because sediment accumulation on sandbars at the inner banks due to the imbalance of sediment transport rate as well as the vegetation distribution changes due to flashed away may have important roles in the morphological changes in steep rivers including non cohesive sediment therefore this study suggests that in river management works for steep rivers sediment transport and morphological aspects such as sandbars and bank migration should be taken into account 6 conclusions in august 2016 the otofuke river faced four major flooding events with a record breaking discharge within a short time span of 15 days in the study area otofuke river had a weakly sinuous single thread channel between the straight embankments which was made by long term flow regulation river channelization and flourished vegetation on the floodplain however because of a series of flooding events the river promptly followed a sinusoidal path damaging the riverbank embankments and leading to levee breaches at seven locations the main conclusions are listed below 1 according to the field survey after a series of flooding events the water level was lower than the height of the embankments this observation shows that the levee breaches occurred not by overtopping the water on levees but by bank erosion due to the channel meander shift after the moment of peak discharge 2 the computational approach explained that although alternate sandbars continually propagated downstream until the moment of peak discharge within the channel between straight embankments sediment accumulation became active in the falling stage of the flood and it strongly deflected the flow path in the transverse direction toward the embankments this phenomenon developed a lateral channel shift and changed the channel formation to a meandering form in the straightened channelization part of the otofuke river additionally this study implies that the channel meandering shift accelerated at locations where the vegetation resistance disappeared during the flood 3 when designing river improvement and management works for steep rivers not only design discharge based on the extreme flow condition but also sediment transport and morphological changes considering sandbar and bank migration should be taken into account declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we gratefully acknowledge the data support from hokkaido regional development bureau for this research this study was supported by the river foundation number 28 5112 001 2017 5211 002 representative yasuyuki shimizu and the research foundation of 2017 by river center of hokkaido sapporo japan representative tomoko kyuka we gratefully acknowledge mohamed nabi for insightful discussions and textual refinement we acknowledge reviewers and editors for comments that significantly improved the manuscript and editors and associate editor for their helpful guidance appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jher 2020 05 003 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1698,the otofuke river is a tributary of the tokachi river hokkaido japan consisting of a channelized reach with a steep slope and a relatively large designed width in august 2016 the river witnessed four major flooding events with a record breaking discharge within a time span of 15 days the otofuke river originally had a straight channelized reach however because of a series of flooding events the river promptly followed a sinusoidal path damaging the riverbank embankments the straight channelized reach of otofuke river faced active erosion of both banks leading to the formation of a meandering channel planform this also led to levee breaches at the seven locations in order to understand the mechanism of such a quick shift in river channel planform we collected various field survey data and conducted computational analysis we investigated the underlying processes by capturing the complex interactions between the rapid channel migration unsteady discharge and sediment transport field surveys including aerial photographs and images showed rapid formation of a meandering planform in the otofuke river as a result of the typhoon on 31 august 2016 according to the maximum water level traces bank erosion developed after the peak discharge numerical investigation revealed that alternate sandbars continuously developed and propagated downstream until the moment of peak discharge and a significant accumulation of sediment subsequently started on the bars at the mid channel during the flood falling stage such morphological processes led to strong flow deflections transversely toward the embankment that resulted in lateral channel shifting and levee breaches at a location where vegetation along the embankments had already disappeared keywords rapid meander shift levee breaches bank erosion unsteady discharge otofuke river 1 introduction lateral channel migration with bank erosion and growth of point bars leads to meander channel formation followed by increased meander amplitude neck cutoff and chute cutoff in a broad range of channel widths e g brice 1974 hickin 1969 ikeda et al 1981 parker 1976 meandering channels are quantitatively classified into several types from the perspectives of channel deformation rate related to channel slope and bed load materials brice 1983 schumm 1985 1977 among several types of meandering channels the most common river pattern in large lowland alluvial floodplains is a meandering braided transition channel in this type of meandering thalweg and morphological changes are relatively active in the channel characterized by a high width depth ratio zolezzi et al 2012 in the recent years rivers located in relatively high gradient reaches globally have been affected by river works such as channelization and flow regulation such river works have changed the forms of those channels from their original multi thread braided forms to single thread meandering forms e g camporeale et al 2013 friedman and lee 2002 winterbottom 2000 in those single thread meandering channels because of the significantly large amount of sediment load composed of gravel and cobble the growth and shift in channel meander often dramatically change the flow alignment e g kleinhans and van den berg 2011 nichols and viers 2017 tal and paola 2010 rapid channel migration is a risky factor because it may lead to bank erosion or levee breaches considering the recent increase in localized torrential rain accompanied with climate change factors and triggers of rapid channel migration in such regulated rivers are required to make a countermeasure still the exact factors influencing a rapid meander shift within a short term i e a night at single thread meandering channels remain unclear here we studied a case with a quick meander shift including seven levee breaches in the otofuke river in the eastern part of hokkaido japan and discussed several factors unsteady discharge flow structures sediment transport and vegetation by means of computational analysis to understand their impact on the lateral channel migration at this single thread meandering channel it was originally braided channels the number of flow paths is reduced from a multi thread channel to a single thread channel with co developing bend sinuosity in such rivers developing bend sinuosity due to meander growth and shift is strongly influenced by bank strengthening earlier experiments have shown that adding stabilization to banks for multi thread channels using cohesive fine sediment or vegetation leads to a significant decrease in both namely the erosion rate at the outer bank and the incision rate at the inner areas of bends e g braudrick et al 2009 jang and shimizu 2007 tal and paola 2007 van dijk et al 2013a the channel becomes more stable than before and it prevents chute cutoff in the inner area of the bends as well as channel widening e g bertoldi et al 2014 brooks and brierley 2002 surian et al 2015 van oorschot et al 2016 however it results in the development of bend sinuosity while with weak bank stability overbank flow enhances the occurrence of chute cutoff as the bank incision causes broadening of the channel van dijk et al 2014 2013a more recently variable discharge during floods is also a key factor for channel migration in the lateral direction in single thread meandering channels nagta et al 2014 van dijk et al 2013b in an early experiment van dijk et al 2013b showed the importance of unsteady discharge in developing bend sinuosity in a meandering channel including cohesive sediments high flow levels of unsteady discharge work to fill the potential chutes traces of old channels on higher floodplains with fine cohesive materials and suppress chute cutoff resulting in the development of bend sinuosity other computational studies iwasaki et al 2016 nagata et al 2014 have also clarified the importance of unsteady discharge under cohesionless conditions in single thread meandering channels affected by vegetation in their reports at first meandering amplitude developed with the co development of point bars at bends later a significant meander development with bank erosion occurred during the discharge decreasing stage due to flow accumulation into a low flow channel alternate thalweg until chute cutoff occurred at the inner bends however the above progresses with and without cohesion differ in the following ways in the case of cohesion banks are gradually stabilized by overbank flows meanwhile at meandering rivers affected by flourished vegetation the spatially different bank stability resistance between locations gradually increases during extreme flood events because of the flushing of vegetation patches away from the floodplain spatiotemporally therefore in such rivers it is difficult to predict the time and location of the lateral channel migration this difficulty should be more apparent in straight rivers before meandering having a weak sinuosity and undeveloped point bars meandering rivers that were originally braided channels located in high gradient reaches usually consist of non cohesive materials with a vegetated floodplain hence they are strongly affected by extreme flooding events for instance the large flood events in 2011 2013 and 2016 on hokkaido island of japan e g iwasaki et al 2016 nagata et al 2014 in particular in august 2016 tokachi river basin in eastern hokkaido experienced record breaking precipitation by a series of four typhoons and a rain front within two weeks furuichi et al 2018 the maximum total amount of rainfall in august observed in this region was around 800 mm nearly equal to the annual average rainfall because of a series of flooding events a remarkable large scale channel migration with the meandering planform led to levee breaches in a number of tributaries in the tokachi river basin e g ishida et al 2017 according to several reports and a field survey most of the levee breaches were not caused by overtopping of the levees but by the amplifying of the channel sinuosity with lateral migration in many reaches of the river despite the river channel width and embankment height being sufficiently designed for the extreme rainfall and discharge conditions based on historical data levee breach disasters have occurred in a short duration of less than one night caused by bank erosion due to the rapid channel meander shift generally studies on channel meandering are often related to moderate or long term time scales e g asahi et al 2013 comporeale et al 2013 friedman and lee 2002 parker et al 2011 while in a meandering channel that was originally a braided channel the role of extreme floods on channel evolution is more dominant an extreme flood event can have a short term impact leading to rapid channel meander shift which causes a major problem in river management work consequently it is important to understand and predict the patterns locations and scales of bank erosion due to the meander shift under different scales of flood events the development of sandbars and mid channel bars occurs relatively quickly during a flood event in high gradient rivers that modify flow alignments in space and time higkin 1969 wickert et al 2013 the strong flow near banks causes bank erosion and flushes the vegetation regardless of many past studies the conditions under which rapid channel migration develops during extreme flood events in weakly sinuous or straight single thread rivers affected by vegetation are still ambiguous the aim of this work is to describe the impact of an extreme flood event on the rapid lateral migration of channelized channels that were originally braided rivers the research was conducted on a channelized reach of the otofuke river a tributary of the tokachi river in hokkaido having a steep slope and a relatively wide designed width the otofuke river was originally a braided river with multi thread channels under natural higher flow discharge however after a series of river management works such as constructions of embankments and a dam for power generation namely nukabira dam completed in 1956 the river planform changed to a single thread channel with the reduction in channel width and discharge regulated by the dam then vegetation was invaded in august 2016 because of a series of flood events the otofuke river promptly followed a sinusoidal planform damaging the riverbank and embankments in particular the straight channelization part in the upstream area depicted in fig 1 faced active erosion of both banks because of meander shift and led to levee breaches at the seven locations as shown in fig 2 this channel shift was incredibly fast as short as one night leading to the development of a meandering planform that flushed revetments away completely in order to understand the dominating factors of such a large scale rapid channel migration within a night caused by the record breaking flood discharge we collected field survey data such as precipitation discharge water level traces and aerial photographs by uav unmanned aerial vehicle additionally two dimensional morphological modelling of the affected reach was carried out to replicate rapid channel migration under the unsteady discharge condition the model replicated sediment transport sandbar propagation and the effect of colonized vegetation 2 site description the river basin has a drainage area of 740 km2 and total channel length of 94 km its source is from mt otofuke located at an altitude of 1 932 m above sea level at the beginning the river flows southward from a small mountain including several tributaries and confluences and flows into nukabira lake which is an artificial lake reservoir created by the nukabira dam for electric power generation after the dam the river continues to flow southward across the tokachi plain eventually merging with tokachi river the otofuke river used to have abundant water discharge however at present its discharge has been decreased considerably due to dam operation and flow diversion toward a different river basin because of the decreasing flooding magnitude and frequency the morphology of the otofuke river changed from the original multi thread braided channel without floodplain vegetation to a single thread meandering channel wandering channel with a colonized vegetation floodplain the river management work started in 1951 in the otofuke river basin the first work was to build embankments and channels were subsequently dredged and widened in the 1970s to provide sufficient space between the main channel and bank with levees large scale changes were not observed in the river until 2010 however a relatively large flood event in september 2011 affected the river morphology iwasaki et al 2016 nagata et al 2014 the present study reach is around 8 km long with a drainage area around 500 km2 the reach is located around 34 to 42 km upstream from the confluence of the tokachi river as illustrated in fig 1 the slope is about 1 120 the channel width between embankments is 200 m and the mean sediment diameter is around 55 mm the study reach is characterized by a weakly sinuous single thread channel with vegetated alternate sandbars between straight embankments this is the reach where levee breaches occurred at seven locations during the flood of august 2016 as shown in fig 2 3 channel migration during an extreme flood in august 2016 3 1 extreme precipitation and flood discharge the historical record of the annual maximum discharge m3 s at the shihoro and otofuke gauging stations is shown in fig 3 which is based on the data measured by hokkaido development bureau the shihoro gauging station is located a few kilometers downstream of our study area as shown in fig 3 the highest flood since 1975 occurred in 31 august 2016 fig 4 shows the cumulative rainfall depth during august 2016 in hokkaido it was observed by an automated meteorological data acquisition system amedas at the nukabira onsen gauging station provided by japan meteorological agency the nukabira onsen amedas station is 540 m above sea level the total rain in the obihiro area located in eastern hokkaido and in the tokachi river basin obihiro area exceeded 500 mm in addition the nukabira onsen amedas station the otofuke river basin reported a total amount of precipitation exceeding 700 mm the average annual rainfall in the obihiro area is around 887 mm which implies that the rainfall during this extreme event was almost equal to the average annual amount fig 5 shows detailed information of rainfall intensity and cumulative rainfall depth during the period from 16 august to 1 september 2016 which were collected at the nukabira onsen amedas station as can be seen from fig 5 the river basin experienced record breaking precipitation first three typhoons no 7 11 and 9 hit hokkaido on 17 20 21 and 23 august 2016 respectively subsequently a rain front and another typhoon no 10 hit on 26 and 30 31 august respectively the entire period of these events was about 15 days fig 6 shows time series of the flow discharge and the water level at the otofuke gauging station during the period from 1 august to 15 september 2016 the highest water level occurred at 13 00 on 31 august with a peak discharge of 763 83 m3 s and a peak water level of 207 15 m the figure shows that the maximum observed water level did not exceed the designed high water level i e no embankment level overflow this implies that levee breaches occurred at seven locations not because of the overflow but because of the lateral erosion consequently for management of high gradient rivers it is important to understand not only the flow discharge capacity but also the morphological process of channel migration with bank erosion 3 2 channel migration the otofuke river also experienced levee breaches several times in the past this fact was considered in the river management planning and design by maintaining a larger channel width however even though the water level had not reached the designed high water level in the area the extreme precipitation on 31 august led to a rapid change in river planform with a sinusoidal meandering pattern it damaged the river embankments especially in the study area where the river was channelized as a part of river management works fig 7 shows the plan view of the channel form before and after the flooding events before the series of flood events the channel planform in the area was a weakly sinuous single thread affected by floodplain vegetation as shown in fig 7 a the width of the low water channel was around 20 to 80 m fig 7 b shows the channel planform after the three typhoon events comparing the channel planforms between fig 7 a and b does not reveal any noticeable bank erosion the photographs taken by uav dji phantom 4 after the last typhoon induced flood as shown in fig 7 c show channel migration and bank erosion along both the left and right banks alternately the width of the flow path increased from around 90 to 240 m according to the field survey this meander shift developed regardless of revetment which used to protect the lower channel path fig 7 c most revetment flushed away during the last flood fig 8 shows the bank lines before and after the series of flooding events comparing the bank lines depicted in fig 8 it can be revealed that the mean flow width between the left and right banks increased by a factor of around 2 54 from 63 to around 160 m and the maximum width between the banks increased up to around 300 m which is more than the designed channel width around 200 m between the embankments the water level trace detected on the remaining embankment in the study area during the field survey after the flood confirmed that the flood level was lower than the crest level of the embankments this observation agrees well with the water level measurement data at the gauging station depicted in fig 6 therefore it is most likely that the bank erosion and levee breaches occurred after peak discharge this was also observed in the past in the otofuke river as reported in nagata et al 2014 and iwasaki et al 2016 these studies were focused on the 2011 flood event in the otofuke river the study area was located relatively downstream where the channel curvature developed their study described that the channel meandering amplification was strongly related to point bar development during the high discharge stage in their study area it caused significant bank erosion and river bed evolution and resulted in the co development of sandbars and the meandering channel planform in the middle reach of otofuke river in addition a falling stage of the flood is a key factor which appears to cause significant bank erosion because of the flow concentration around the sandbar creating main channel thalweg curvature flowing toward the banks in september 2011 no levee breach occurred in the middle reach of otofuke river a chute cutoff finally occurred at the bend resulting in a returned flow path from the location close to the banks to the center part of the channel unlike the flood event of 2011 the flood event of 2016 damaged the banks and the levees at the upper basin and it was considerably more severe than that of the middle reach the flood of 2016 is recorded as a flood with maximum historical discharge during this flood the channelized area in the upstream reach experienced significant meandering resulting in levee breaches at seven locations this implies that the increase in flood peaks in the future also due to climate change could change not only the risk scales but also the locations for the planning and design of a future disaster management system in steep rivers even with a sufficient designed width it is important to understand the rapid channel migration process under varying flow with large peak discharge the physics based morphological modelling approach and tools are effective for the rapid assessment of such complex processes the modelling tool can be applied to replicate and understand the relationship between flow sediment transport sandbar dynamics vegetation dynamics flash by scour and bank erosion this is described in the next section 4 numerical analysis 4 1 computational model in this study an unsteady two dimensional numerical analysis is conducted to simulate flow bed deformation and channel migration in order to replicate the flooding event of 2016 the analysis used nays2d solver jang and shimizu 2005 shimizu 1996 1989 which was recently incorporated into the iric software provided by the international river interface cooperative iric project nelson et al 2016 4 1 1 governing equations for flow the governing equations are an unsteady horizontal two dimensional continuity equation and momentum equations shallow water equations the equations are mapped onto a generalized curvilinear coordinate system this model is summarized in several documents e g iwasaki et al 2016 jang and shimizu 2007 2005 shimizu 1989 the equations in orthogonal coordinates x y are transformed into a generalized curvilinear coordinate system ξ η continuity equation 1 t h j ξ h u ξ j η h u η j 0 momentum equation u ξ t u ξ u ξ ξ u η u ξ η α 1 u ξ u ξ α 2 u ξ u η α 3 u η u η g ξ x 2 ξ y 2 h ξ ξ x η x ξ y η y h η 2 c f u ξ hj η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 d ξ f ξ ρ h j u η t u ξ u η ξ u η u η η α 4 u ξ u ξ α 5 u ξ u η α 6 u η u η g ξ x η x ξ y η y h ξ η x 2 η y 2 h η 3 c f u η hj η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 d η f η ρ h j 4 u ξ ξ x u ξ y v u η η x u η y v 5 j 1 x ξ y η x η y ξ 6 c f g n 2 h 1 3 where t is the time h is the depth and u ξ and u η are the contravariant depth averaged velocities in the generalized curvilinear coordinate system ξ η respectively h is the water level g is the gravitational acceleration and α 1 to α 6 are coefficients resulting from transformations of the velocity components from orthogonal coordinates to the generalized curvilinear coordinate system jang and shimizu 2005 shimizu 1996 1989 c f is the bed friction coefficient d ξ and d η are the diffusion terms in the generalized curvilinear coordinate system f ξ and f η are the contravariant drag forces due to vegetation along the ξ and η coordinates respectively ρ is the density of water u and v are the velocities in the x and y directions respectively and n is manning s roughness coefficient the effect of vegetation is estimated by vegetation density and expressed as an additional drag force incorporated in the momentum equations f ξ and f η as follows 7 f ξ 1 2 ρ c dv λ v h u ξ η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 8 f η 1 2 ρ c dv λ v h u η η y u ξ ξ y u η 2 η x u ξ ξ x u η 2 where c dv is the drag coefficient of vegetation and λ v is vegetation density note it has dimensions the vegetation density is determined as a shielding rate of vegetation percentage of vegetation occupied area in a projected area to the sampling area as 9 λ v n v d v a v where av is the sampling area nv is the number of vegetations and dv is the average diameter of vegetation in the sampling area here the original program is modified to calculate the vegetation density as a function of the bed erosion at each cell when the difference between the calculated bed level and initial bed level consider when the former value is smaller than the latter exceeds a specified criterion determined by the root average lengths of willows in the study area that vegetation density λv is set to zero this means that colonized vegetation is flushed away in the model 4 1 2 bed load transport and bed deformation the bed and the embankments of the otofuke river are dominated by sand gravel bed material hence we calculate only the bed load sediment transport as the effect of suspended load is negligible the following equilibrium bed load transport formula proposed by ashida and michiue 1972 is applied 10 q bs sg d 3 17 τ e 3 2 1 τ c τ 1 τ c τ where qbs is the total bed transport rate in the stream direction of depth averaged flow τ is the non dimensional shear stress τ c is the non dimensional critical shear stress τ e is the non dimensional effective shear stress ashida and michiue 1972 s is the specific density of bed load material and d is the sediment diameter the non dimensional critical shear stress is determined by the iwagaki formula iwagaki 1956 the sediment transport in the transverse direction is estimated as a function of transverse bed slope e g hasegawa 1989 kovacs and parker 1994 luu et al 2004 shimizu et al 1996 watanabe et al 2001 the sediment transport rate along ξ and η coordinates is given by the following equations 11 q b ξ q bs u b ξ v b γ z b ξ cos θ z b η 12 q b η q bs u b η v b γ z b η cos θ z b ξ where v b is the composite velocity velocity magnitude near the bed u b ξ and u b η are the near bed velocity components in the generalized curvilinear coordinate system θ is the angle between the ξ and η axis in the generalized curvilinear coordinate system and zb is the bed level γ is a correction coefficient for sediment transport rate based on the local bed slope at each grid cell and is calculated by hasegawa 1989 1981 13 γ τ c μ s μ k τ where μ s 0 45 and μ k 1 0 are coefficients for the static and kinetic frictions respectively the near bed velocities in the streamlines and secondary flow are estimated as follows 14 u bs β v 15 u bn u bs n h r s where u bs is the near bed velocity in the streamline direction v u 2 v 2 is the velocity magnitude of depth averaged flow u bn is the estimated near bed velocity under the effect of secondary flow in the direction orthogonal to the streamline n is an empirical coefficient equal to 7 0 engelund 1974 and r s is the curvature radius of stream lines jang and shimizu 2005 β is estimated by the following equation engelund 1974 16 β 3 1 σ 3 σ v σ 3 φ 0 κ 1 v u 2 v 2 where φ 0 is a coefficient related to flow velocity v u and κ is the von kármán constant the near bed velocity components u b ξ and u b η in the generalized coordinate system are transformed as follows 17 u b ξ x s ξ x x s ξ y u bs x n ξ x x n ξ y u bn 18 u b η x s η x x s η y u bs x n η x x n η y u bn the curvature radius of stream lines in orthogonal coordinates is transformed in generalized coordinates as follows jang and shimizu 2005 19 1 r s 1 u 2 v 2 3 2 u 2 ξ x v ξ η x v η u v ξ y v ξ η y v η u v ξ x u ξ η x u η v 2 ξ y u ξ η y u η bed elevation is calculated by a balance between incoming and outgoing sediment rates the governing equation is as follows exner equation 20 t z b j 1 1 λ ξ q b ξ j η q b η j 0 where λ is the porosity 0 4 of river bed material the bank erosion and sediment failure at an excessive local score hole are the effects of the sediment avalanching process hence we applied a model for sediment avalanching based on the angle of repose for two adjacent cells if the bed slope exceeds the angle of repose a volume of sediment from the cell with a higher level is moved to the other cell in such a way that a slope equal to the angle of repose is achieved e g crosato and saleh 2011 michiue and hinokidani 1992 nagata et al 2000 4 2 numerical parameters here we simulated river reach with a length of 7 3 km the grid size in the streamwise and transverse directions are set to dx 7 0 m and dy 4 0 m respectively the time step is set to dt 0 2 s we applied grid sensitivity analysis and found that the employed grid resolution is optimum and refining the grid does not affect the result significantly the discharge hydrograph is estimated from the recorded water level at the shihoro water gauging station corresponding to the last flooding event fig 9 the mean diameter of uniform sediment material is set to 55 mm based on the field survey data conducted by the hokkaido regional development bureau the roughness is set by means of the manning roughness coefficient equal to 0 03 vegetated regions are set based on a series of aerial photographs shown in fig 7 a the density of vegetation is set to 0 03 based on the field observation to consider the vegetation mainly natural willows disappearance due to local erosion the criterion for erosion depth from the initial bed level is set based on the field observation to 20 cm this depth is sufficient to remove all soil around natural willows in the tokachi river basin nagata et al 2016 according to nagata et al 2016 the roots of dominant species of natural willows in the tokachi river basin are not deep and 80 of the volume of major roots are concentrated within the top layer of 20 cm on the floodplain initial topography data were determined using the digital elevation model measured in 2013 with a resolution 5 m as for the boundary conditions depth averaged flow velocity and normal flow depth related to flow discharge were given at the upstream and downstream boundaries respectively in addition the equilibrium sediment transport rate was given at the upstream boundary where the initial bed elevation does not change because of bed aggradation or degradation 5 computational results and discussion 5 1 accuracy of water level and morphodynamics fig 10 shows a longitudinal profile of the trace water level from the field observation and water level at the moment of peak discharge from the computational results comparing both results in fig 10 the computed water level at the peak discharge did not exceed the height of the embankments it agrees with the results of the field surveys the averaged differences between the field survey and the computation for the maximum water level was tens of centimeters indicating that the maximum water level reasonably matches the field survey data fig 11 shows an aerial photograph from a moment after the disaster and a contour map of the simulated bed elevation the results for channel planform match well with the situation during and after the flood the weakly sinuous single thread channel within the straight embankments changed their planform to a significant meander single thread channel with increasing bend sinuosity at locations of the levee breaches and then alternating left and right embankments were reproduced 5 2 process of rapid channel meander shift 5 2 1 depth velocity and morphological changes fig 12 shows a time series of the contour map for simulated depth overall significant lateral channel migration was confirmed even in the fall down stage of the discharge hydrograph a comparison between the hydrograph fig 9 and the simulated depth fig 12 shows that the depth increased and formed alternate thalweg at the increasing stage of the hydrograph fig 12 b until the peak flow discharge it was confirmed that the alternate thalweg constantly propagated to the downstream direction although not shown in the figure subsequently after the peak flow discharge the depth became gradually shallower with the maintaining of the alternate thalweg caused by the planform of the meandering channel fig 12 d this led to a situation where the flow significantly reflected toward the river embankments even when the discharge became low fig 13 shows a time series of simulated contour maps for depth averaged velocity according to fig 13 the plane formation of high speed flow areas enlarged with the channel meandering shift until the peak of flow discharge fig 13 a 13 b subsequently during the decreasing stage of discharge the high speed velocity area gradually meandered as an alternate thalweg fig 13 b 13 c 13 d finally the meandering planform of the main flow path was most apparent in fig 13 e where the magnitude of flow velocity decreased considerably it indicates that the bank erosion progressed in the latter half of the flooding event this is because the new channel planform described below caused flow reflection divergence toward the bank embankments fig 14 shows a time series of simulated bed elevation changes a comparison between the bed elevation changes at each time indicates that channel sinuosity shifted remarkably and a rapid formation of sine curves in the otofuke river was presented although the channel widening gradually developed the lateral channel migration including bank erosion was clearer after the peak flow discharge fig 14 e than that before the peak flow discharge fig 14 b according to our simulations the propagation of alternate sandbars toward the downstream direction was confirmed until the moment of peak flow discharge but it stopped after the peak flow discharge as illustrated in fig 14 lateral channel migration with the co development of bend sinuosity started considerably after the peak flow discharge furthermore the height of the river bed elevation at the center part of the channel gradually increased due to sedimentation at the same time it led to the formation of mid channel bars see the depth contour map in fig 12 e in the center part of the channel during the falling stage of flow discharge this suggests that this topographic change causes flow reflection toward the river embankments and develops the meandering planform in this flood event 5 2 2 sediment transport rate fig 15 shows a time series of sediment transport rate and cumulative flow discharge at the cross section c c location is illustrated in fig 11 the figure reveals that the amount of sediment transport rate rose relatively slow with the increase in flow rate and decreased rapidly after the moment of peak flow discharge it implies that because of the imbalance in the amount of sediment transport and sedimentation rate incoming and outgoing sediment accumulation becomes active at the inner bends of the newly formed single thread meandering channel where the depth becomes shallower unlike the flow mostly follows the hydraulic parameters sediment transport and sedimentation usually have a time lag in space and time as the velocity shear stress and capacity of sediment transport rate become smaller during the falling stage of flow discharge sedimentation in the low flow channel see the yellow areas in fig 14 e will very likely increase and make the flow direction further change toward the embankment directions therefore although the flow depth and velocity magnitude also shear stress was much larger at the moment of peak flow discharge the channel shift accompanied with bank erosion became active after the peak flow discharge in the otofuke river in this short term flood event 5 2 3 lateral migration and vertical erosion fig 16 shows the simulated bed elevation at cross sections a a b b and c c as illustrated by fig 11 this figure shows that the levee was breached in the latter half and the channel widened during the flood event by about 200 m identical to the field survey data a similar behavior was observed at each cross section in the simulated river until the moment of peak flow discharge the channel widened in the lateral direction and the scouring depth increased in the vertical direction though after the peak flow discharge the lateral movement of the flow path continued but the vertical erosion rate did not increase to confirm the vertical erosion rate related to the hydrograph fig 17 a shows a time series of the differences in the specific bed height between the lowest and highest points levee on cross section c c location fig 11 the specific bed height in the vertical direction gradually increased until the peak flow discharge and it subsequently slightly decreased this implies that the specific bed height related to the growth of wave height of alternate sandbars increases depending on the flow magnitude conversely after the falling stage of flow discharge the growth of the wave height of alternate sandbars stops as well as the propagation of sandbars to the downstream direction fig 17 b shows a time series of the maximum width of sedimentation areas of an alternate sandbar on the cross section c c the width indicated a rapid widening of sedimentation areas until the moment of peak flow discharge subsequently the width of sandbars in the cross section c c continuously expanded even in the latter half of the flood event therefore although vertical erosion depth related to the wave height of sandbars strongly depends on the flow magnitude fig 17 a the channel expansion in the lateral direction does not mainly depend on the flow magnitude fig 17 b to discuss the interaction between channel expansion in the lateral direction and the route of sediment transport fig 18 shows contour maps of the bed topography elevation changes and vegetation distribution and the vector map of bed load transport rate around the cross section c c the computational approach explained that the route of bed load material gradually meandered in the latter half of the flood event because of the emergence of mid channel bars at the center part of the channel this strongly reflects flow deflection transversely toward the embankments those phenomena should develop a rapid lateral channel shift and channel deformation to a sinuous single thread meandering channel in the otofuke river furthermore compared to the morphological changes and vegetation distribution in fig 18 increases in channel sinuosity were confirmed in the place where vegetation patches disappeared during the flood event it is also important to note that changes in vegetation distribution during floods can lead to a local weakness of bank strengthening due to a lack of resistance comparison with the previous disaster event at the middle reach of the otofuke river iwasaki et al 2016 nagata et al 2014 and this event at the upper reach indicated that the locations of channel meander and bank erosion are different in the previous event lateral channel migration had been locally developed at the bend because of flow reflection caused by point bar deposits subsequently chute cut off had been developed on the floodplain at the inner bend so that bank erosion levee breach did not occur because of the decrease in channel sinuosity however in the current event on august 2016 a weakly sinuous single thread channel was damaged by channel meandering the situation was as follows alternate sandbars continuously propagated toward the downstream until the moment of peak flow discharge during this term the channel expanded as the flow discharge rate increased however local lateral channel migration was not clearly observed meanwhile the planform of the entire flow path changed after the moment of peak discharge when the propagation of sandbars to the downstream direction stopped a new planform meandering channel had developed with the co development of sedimentation in the center part of the channel and the planform was almost uniformly bend sinuosity leading to the alternate right and left banks levee breaches this suggests that the hydrograph bank strengthening and propagation of alternate sandbars considerably influenced the channel planform in a weakly sinuous single thread channel moreover once bank erosion begins sediment is supplied not only from the upstream but also from banks so the ratio of sediment deposition on the sandbars center part of the channel should be accelerated leading to a development of channel meandering and new bank erosion the results from the field survey and the computations explained that the channel meander shift in the short term cannot always be determined by the magnitude of the peak flow discharge the flow reflection toward the embankments occurred during the latter half of the flood event this is because sediment accumulation on sandbars at the inner banks due to the imbalance of sediment transport rate as well as the vegetation distribution changes due to flashed away may have important roles in the morphological changes in steep rivers including non cohesive sediment therefore this study suggests that in river management works for steep rivers sediment transport and morphological aspects such as sandbars and bank migration should be taken into account 6 conclusions in august 2016 the otofuke river faced four major flooding events with a record breaking discharge within a short time span of 15 days in the study area otofuke river had a weakly sinuous single thread channel between the straight embankments which was made by long term flow regulation river channelization and flourished vegetation on the floodplain however because of a series of flooding events the river promptly followed a sinusoidal path damaging the riverbank embankments and leading to levee breaches at seven locations the main conclusions are listed below 1 according to the field survey after a series of flooding events the water level was lower than the height of the embankments this observation shows that the levee breaches occurred not by overtopping the water on levees but by bank erosion due to the channel meander shift after the moment of peak discharge 2 the computational approach explained that although alternate sandbars continually propagated downstream until the moment of peak discharge within the channel between straight embankments sediment accumulation became active in the falling stage of the flood and it strongly deflected the flow path in the transverse direction toward the embankments this phenomenon developed a lateral channel shift and changed the channel formation to a meandering form in the straightened channelization part of the otofuke river additionally this study implies that the channel meandering shift accelerated at locations where the vegetation resistance disappeared during the flood 3 when designing river improvement and management works for steep rivers not only design discharge based on the extreme flow condition but also sediment transport and morphological changes considering sandbar and bank migration should be taken into account declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we gratefully acknowledge the data support from hokkaido regional development bureau for this research this study was supported by the river foundation number 28 5112 001 2017 5211 002 representative yasuyuki shimizu and the research foundation of 2017 by river center of hokkaido sapporo japan representative tomoko kyuka we gratefully acknowledge mohamed nabi for insightful discussions and textual refinement we acknowledge reviewers and editors for comments that significantly improved the manuscript and editors and associate editor for their helpful guidance appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jher 2020 05 003 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1699,the potential natural vegetation of large river floodplains from dynamic to static equilibrium konstantin ochs a gregory egger b arnd weber c teresa ferreira a john ethan householder b matthias schneider d a forest research centre instituto superior de agronomia university of lisbon lisbon portugal forest research centre instituto superior de agronomia university of lisbon lisbon portugal forest research centre instituto superior de agronomia university of lisbon lisbon portugal b department of wetland ecology karlsruhe institute of technology karlsruhe germany department of wetland ecology karlsruhe institute of technology karlsruhe germany department of wetland ecology karlsruhe institute of technology karlsruhe germany c department of vegetation studies landscape management federal institute of hydrology koblenz germany department of vegetation studies landscape management federal institute of hydrology koblenz germany department of vegetation studies landscape management federal institute of hydrology koblenz germany d sje ecohydraulic engineering gmbh stuttgart germany sje ecohydraulic engineering gmbh stuttgart germany sje ecohydraulic engineering gmbh stuttgart germany corresponding author the potential natural vegetation pnv is a useful benchmark for the restoration of large river floodplains because very few natural reference reaches exist expert based approaches and different types of ecological models static and dynamic are commonly used for its estimation despite the conceptual differences they imply for natural floodplains a static concept of pnv is not reasonable as natural disturbances cause a constant resetting of succession however various forms of river regulation have disrupted the natural dynamics of most large european rivers for centuries therefore we asked whether the consideration of succession dynamics and time dependent habitat turnover are still relevant factors for the reconstruction of the pnv to answer this we compared the results of a simulation of the vegetation succession 1872 2016 of a segment of the upper rhine river after regulation damming straightening and bank protection to different statistic and expert based modelling approaches for pnv reconstruction the validation of the different pnv estimation methods against a set of independent reference plots and the direct comparison of their results revealed very similar performances we therefore conclude that due to a lack of large disturbances the vegetation of regulated large rivers has reached a near equilibrium state with the altered hydrologic regime and that a static perception of its pnv may be justified consequently statistical models seem to be the best option for its reconstruction since they need relatively few resources data time expert knowledge and are reproducible keywords potential natural vegetation pnv riparian vegetation floodplain modelling large rivers 1 introduction river floodplains are amongst the most species rich and productive ecosystems naiman and decamps 1997 at the same time these ecosystems are one of the most threatened and modified worldwide tockner and stanford 2002 highlighting the need for conservation and restoration efforts buijse et al 2002 myers et al 2000 such efforts however are challenged by a lack of natural reference sites for orientation whited et al 2007 indeed 90 of river floodplains in europe and north america are used for agriculture or forestry and no longer harbor natural vegetation communities tockner and stanford 2002 where no natural references exist a potential natural vegetation pnv is often reconstructed and used as benchmark carranza et al 2003 hickler et al 2012 justice et al 2017 klimas et al 2009 schleupner and schneider 2013 shi et al 2016 but the concept of pnv and the methods for its reconstruction are highly controversial chiarucci et al 2010 loidi and fernández gonzález 2012 mucina 2010 somodi et al 2012 pnv was first defined by tuxen 1956 as the vegetation that would develop under present site conditions if human influences were excluded completely and succession would reach its climax stage at once it has often been thought of as an historic pre human reference condition hall and mcglone 2006 willis and birks 2006 however this idea has provoked disagreement carrión and fernández 2009 mitchell 2005 because it ignores that environmental conditions have changed since pre human times dotterweich 2008 nilsson et al 2005 therefore it has been argued that an estimation of the natural vegetation based on the assessment of present day natural vegetation remnants is more reliable kowarik 1987 but in areas with historically high levels of land use transformation this assessment is also prone to uncertainties zerbe 1998 another much discussed issue is the consideration of ecosystem dynamics and stochasticity chiarucci et al 2010 härdtle 1995 which are especially relevant in naturally disturbed areas jackson 2013 leuschner 1997 zerbe 1998 the traditional pnv estimation method is expert based and follows a floristic sociological approach westhoff and van der maarel 1978 it relies on the fieldworker s assessment and understanding of ecology to extrapolate present day natural vegetation remnants to similar environments kowarik 1987 moravec 1998 this approach however lacks transparency and reproducibility furthermore its implied static perception of pnv makes predictions in dynamic systems questionable mucina 2010 more comprehensive and also widely used for pnv estimations are ecological models based on the relationship between vegetation and environmental variables somodi et al 2012 zerbe 1998 two types can be differentiated that imply fundamental conceptual differences static models and dynamic models hannon and ruth 1998 static models describe a phenomenon at a given point in time and assume equilibrium between the vegetation and its environment dynamic models e g process based models or mechanistic models are based on ecological processes and differ from static models by explicitly incorporating time dependent changes in the system state therefor they are able to capture the transient response of vegetation to a changing environment hannon and ruth 2014 little attention however has been given to issues surrounding pnv in fluvial contexts the first modelling approaches of pnv in floodplains were static and tried to explain the vegetation patterns along vertical height above channel and lateral distance away from channel gradients bowman and mcdonough 1991 ellenberg 1996 glavac et al 1992 hosner and minckler 1963 hughes 1988 nixon et al 1977 roberts and ludwig 2016 robertson et al 1978 ward and stanford 1995 later more advanced static models emerged that relate the vegetation distribution to a set of hydrologic variables based on expert rules aggenbach and pelsma 2003 baptist et al 2004 fuchs et al 2012 jungwirth et al 2002 lenders et al 2001 pieterse et al 1998 runhaar 2003 or statistical analyses auble et al 1994 franz and bazzaz 1977 menuz 2011 dynamic floodplain vegetation models combine a simulation of the hydro dynamics with the modelling of ecological processes e g growth and mortality recruitment succession retrogression competition and are used to describe the vegetation development over time benjankar et al 2011 camporeale and ridolfi 2006 garcía arias and francés 2016 pearlstine et al 1985 more recently the dynamic feedbacks between vegetation and hydro geomorphological processes have also been incorporated camporeale et al 2013 van oorschot et al 2016 we argue that for floodplains of unregulated rivers the original static concept of pnv based on a climax stage of vegetation is not reasonable because successional sequences are repeatedly rejuvenated and reset by hydro geomorphological disturbances pringle et al 1988 it has been theorized that at the appropriate scale the proportion of successional phases would remain constant when processes of regression are compensated by progression a dynamic equilibrium referred to as shifting steady state mosaic bormann and likens 1979 geerling et al 2006 stanford et al 2005 while methodological advances reflect the growing recognition in the importance of allowing dynamic change in pnv estimation various forms of river regulation have disrupted the natural dynamics in most large rivers buijse et al 2002 dynesius and nilsson 1994 river damming and bank stabilization are the main reason for the impediment of dynamic geomorphological processes e g avulsion meandering braiding and decrease of hydrodynamic variability and disturbance in the riparian zone church 1995 magilligan and nislow 2005 nilsson and berggren 2000 petts and gurnell 2005 in this context we investigated whether the consideration of succession dynamics and habitat turnover are still relevant factors for the model based reconstruction of the pnv of regulated large river floodplains our hypothesis is that they can be neglected because riparian vegetation of regulated large rivers has reached a stable equilibrium due to the loss of natural disturbance dynamics to test this idea we compared the results of a simulation of the succession dynamics 1872 2016 of the floodplain vegetation of a segment of the heavily regulated upper rhine river to different static approaches for the estimation of its pnv a a statistical model based on hydrologic predictors and the geomorphological age of site b a statistical model only based on hydrologic predictors and c a gradient approach only based on the distance to the mean water level 2 methodology 2 1 study area the rhine river is one of the largest rivers in central europe with a length of approximately 1230 km and a catchment area of approximately 185300 km2 our study area lies in the upper rhine region where the nival discharge regime is strongly influenced by snow melt in the alps belz and frauenfelber kääb 2007 until the beginning of the 19th century the upper rhine could still be considered in natural condition gallusser and schenker 1992 and was classified as an highly dynamic island dominated anabranching river system gurnell and petts 2002 herget et al 2005 during the course of the 19th century however the upper rhine river was transformed into a single thread channel by cutting off meander bends and building groins and bank revetments bernhardt 2000 in the 20th century river regulation intensified through the construction of 10 hydropower plants in the main channel or in artificial side channels dister et al 1990 during this time industry and settlements also expanded in the study area habersack and piégay 2007 the study area is the raststatter rheinaue a nature reserve on the eastern german side of the floodplain that includes a 9 km segment of the upper rhine river downstream from the iffezheim dam to the confluence of the river murg rhine km 335 8 345 114 110 m a s l it is only limited by flood dykes towards the east and is still regularly flooded the study area covers approximately 645 ha including water bodies 2 2 material and data 2 2 1 historic maps because the upper rhine has been the border between france and germany detailed maps were produced for the planning of the river straightening in the beginning of the 19th century these indicate the location of water bodies islands and gravel sand bars within the aquatic area as well as land uses in the floodplain grasslands forests croplands and settlements our work is based primarily on four historical maps from that time 1816 1838 1852 1872 that were georeferenced and classified in natural natural water body gravel sand bar grassland and forest or anthropic artificial water body cropland settlement and industry habitat categories for details see table c1 and diaz redondo et al 2017 2 2 2 discharge data and hydrodynamic model the analysis of the flow regime of the study area for the whole simulation period is based on the maxau gauging station rhine km 362 3 which has the longest continuous record of daily discharge 1921 today and also records of the annual low mean and high discharges for the period 1872 1921 diaz redondo et al 2017 a two dimensional hydrodynamic model srh 2d lai 2008 of the rhine river and its eastern floodplain was set up the model bathymetry is based on a high resolution 1 m dem wasserstrassen und schifffahrtsverwaltung des bundes wsv 2016 supplemented by longitudinal profiles and cross sections through the main waterbodies in the study area díaz redondo et al 2018 the model mesh consists of 149 900 nodes with an average distance of 20 m in the main channel 10 m in the floodplain and down to 2 m in the river bank and dam zones break lines were integrated manually water surface elevations wse for 6 flood events with return periods between 1 and 100 years provided by the german federal agency for hydrology bfg were used for model calibration and setting of the lower boundary condition manning roughness coefficients were first appointed to the model elements based on different land use and lie around 0 083 for the floodplain forest and around 0 026 for the side channels and 0 037 for the main river channel calibration was performed by adjusting manning s roughness coefficients to minimize the difference between modelled and measured wses mean wse errors were between 1 cm for flood events with short return periods and 20 cm for higher return periods 2 2 3 calibration and validation data we used an expert based pnv map ochs et al 2019 and analyzed the historical land use to delineate likely reference areas for four main vegetation types reeds softwood forest transition forest and hardwood within these areas a total of 130 random sampling plots radius 5 m were distributed with a minimum distance between them of 50 m the pnv type of the plots was verified during several field visits föll and egger 2017 the verification was guided by indicator species from the herb and shrub layers see table a1 reeds could be confirmed in 8 plots softwood forest in 36 plots transition forest in 40 plots and 37 plots could be clearly identified as hardwood forest to increase the independency of the assessment of the predictive performance and comparison between the different modelling approaches we split the study area geographically perpendicular to the river axis wenger and olden 2012 the downstream part that represents between 30 and 40 of the reference plots of each vegetation type was used for validation fig 1 2 3 dynamic succession model dm the dynamic floodplain vegetation model casimir benjankar et al 2011 egger et al 2013 was used to predict the pnv by simulating the succession of the floodplain vegetation from 1872 to 2016 the time period was chosen because by 1872 the study area had already suffered the main hydro morphological impacts through river straightening and channelization bernhardt 2000 in the model the riparian vegetation is represented in succession lines and their respective succession phases table c2 the dynamic modules are recruitment controlled by the spring mean water level as described by the recruitment box model mahoney and rood 1998 and succession progression retrogression controlled by the disturbance indicators flood duration and shear stress formann et al 2014 each year the recruitment module checks for bare soils in the bank and floodplain zone as well as the water levels that allow seedling survival table c3 and the disturbance module checks whether the critical values of the disturbance indicators are surpassed table c4 and table c5 the result of one simulated year will be used as input for the next year the parametrization of the model was based on analyses of historic maps and historic discharge data the model was calibrated against an expert based pnv estimation of the upstream part of the study area so that the reference plots for validation can also be considered independent for a detailed description of the model functioning and calibration validation see ochs et al 2019 as well as appendix b and c for comparability the succession phases of the final year were aggregated to match the main pnv types in the study area table c2 2 4 statistic models sm1 and sm2 the statistic modelling approach for the classification of the main pnv types was based on the random forest algorithm breiman 2001 random forest selects random bootstrap samples from a given dataset to build a set of decision trees the final prediction is based on the majority vote from the individually developed trees we chose three predictors representing the hydrological control factors of riparian vegetation flood duration water depth and shear stress for the flood duration raster the average flood duration of each grid cell during the growing periods between 1921 and 2016 was calculated see appendix b maps of water depth and shear stress were calculated for hq10 4100 m3 s so that the whole floodplain could be represented in addition we tested the influence of the habitat age the geomorphological age of different areas of the floodplain was derived through the analyses of the changes from water surfaces to sand and gravel bars on historic maps diaz redondo et al 2017 we built two different models sm1 was based on the hydrological predictors and geomorphological age sm2 considered only the hydrological predictors the models were set to grow 1000 trees based on bootstrap samples from the calibration plots the sample was balanced to compensate for the overrepresentation of softwood forest in the reference plots which according to an expert based pnv map of 2017 covered around 10 of the study area the statistical modelling was done in the r environment using the randomforest package liaw and wiener 2002 2 5 gradient model gm the german federal institute of hydrology bfg developed a gradient model for the large scale assessment of the main floodplain vegetation types for the free flowing parts of river rhine and elbe in germany it is based on the field observation that the occurrence of salix alba at a site correlates with the relative height to the mean water level and the mean annual flood duration schleuter 2014 the mean annual flood duration of a grid cell is calculated as follows schleuter 2016 f 70 599 l n x 0 50 88 711 f mean annual flood duration x relative height to mean water level m the pnv types are then assigned based on expert knowledge table 1 2 6 model validation and comparison for validation of the predictive performance all models were tested against the same set of geographically separated reference plots based on a confusion matrix we calculated the global metrics overall accuracy oa and kappa coefficient k cohen 1960 which corrects the oa for chance agreement in addition we calculated sensitivity and specificity for each pnv class for comparison between the models all area wide predictions were directly compared to each other by calculating the metrics kappa k kappa location kloc and kappa histogram khist kloc describes the similarity of spatial allocation of categories of the two compared maps and khist describes the quantitative similarity pontius 2000 the following rating system was applied values greater than 0 75 indicate very good to excellent agreement values between 0 40 and 0 75 indicate fair to good agreement and values of 0 40 or less indicate poor agreement landis and koch 1977 3 results the results of the different approaches to reconstruct the pnv of our study area are shown in fig 2 the overall agreement between the models was good all approaches predicted hardwood forests to be the dominant vegetation class followed by transition forests softwood forests and reeds table 2 along the same sequence the agreement of the predictions between the approaches diminished table 3 hardwood forests were predicted for about 50 of the study area by all models and the agreement spatial and quantitative was excellent to very good transition forests were estimated to cover around 35 by dm sm1 and sm2 but only 26 by gm the similarity of the predictions of dm and sm1 2 was very good but only fair when compared to gm softwood forest were predicted on only 7 of the area by the dm but nearly twice as much by the other models the agreement between the dm and sm1 2 still can be considered fair but showed high discrepancies to gm reeds presented poor agreement between all models especially spatially 3 1 validation overall the dm sm1 and sm2 showed good predictive performance and that of the gm was fair see table 4 notably sm1 and sm2 performed identically all models were unable to detect reeds sensitivity 0 softwood forest and hardwood forests were predicted with very good accuracy but sm1 sm2 and gm only identified about 50 of transition forest reference plots correctly the mean decrease accuracy and mean decrease gini measures of the random forest models both revealed flood duration to be the most important predictor habitat age and shear stress were the least important ones 4 discussion the equally good performances of the dynamic and static modelling approaches in predicting the pnv of our study area support the hypothesis that due to the loss of natural disturbance dynamics the riparian vegetation in our study area has reached a stable equilibrium with the hydrological control factors sensitivity analyses of the statistic model and the dm ochs et al 2019 revealed that the pnv is mainly determined by flood duration but we show that the resulting pattern of softwood transition and hardwood forest is explained equally well by a static average as a reconstruction of the temporal dynamics of the flood regime dm even more the fair results of the gradient approach show that the relative height to the mean water level also captures most of the influencing factor of riparian vegetation with the predictor habitat age we wanted to include a time dimension to the static modelling approach as indication of a possible successional progression however roughly 150 years after geomorphological changes have been impeded habitat age proved to have no influence on the present vegetation communities the transition of the large scale dynamic equilibrium of natural floodplain ecosystem to a more mature and stable state after river regulation has also been recognized by other studies diaz redondo et al 2017 hohensinner et al 2004 ollero 2010 tockner and stanford 2002 and has been mainly attributed to an impediment of morphologic dynamics through bank stabilization and flow regulation florsheim et al 2008 hohensinner et al 2014 to allow for the comparison of the model predictions we validated the results against a geographically separated holdout sample the spatial blocking strategy increases the independency of the sample and allow an effective test of a models transferability roberts et al 2017 wenger and olden 2012 it meant however a trade off with the sample size used for calibration of the statistical model which already had to be considered small wisz et al 2008 nevertheless random forests are recognized as one of the most accurate species distribution modelling techniques cutler et al 2007 elith et al 2006 also some confidence about our results can be drawn from the good agreement between the modelling approaches themselves the reference plots were identified based on indicator species from the herb and shrub layers see table a1 that usually develop without direct human manipulation gilliam 2007 metzger and schultz 1984 as opposed to area wide expert based assessments of pnv that are often used to validate ecological models in areas of high anthropogenic transformation hickler et al 2012 somodi et al 2017 the reference plots are not extrapolated and therefore more comprehensive and less prone to uncertainties all tested modelling approaches simplify the complex floodplain ecosystem and are based on several assumptions they assume that in our study area the hydrological control factors are most relevant and neglect other factors that are known to influence plant communities in floodplains regarding the occurrence of reeds this seems to be an oversimplification since no model was able to detect it the proliferation and dominance of phragmites australis can be linked to nutrient competition and allelopathy hazelton et al 2014 uddin and robinson 2018 the fixed topographic input and disregard of the complex hydro morphological processes normally occurring within the floodplain gurnell 2016 can be justified in part by river regulation measures and artificially stabilized banks a further in depth discussion of the uncertainties regarding the dynamic model casimir vegetation can be found here benjankar et al 2011 ochs et al 2019 another obvious source of prediction bias for both the statistic and dynamic model are possible errors in the hydrological model and the historic maps that were used for parameterization in addition to the predictive performance other important criteria when choosing a model are the required resources and deployment time the simulation of succession dynamics for nearly 150 years was only possible with access to data of high spatiotemporal resolution and a high level of expert knowledge as well as a laborious calibration process the static models on the other hand needed less data know how and time especially the very simple gradient model gm which still showed fair agreement with the other modelling approaches doesn t even need hydraulic simulations since it is only based on the relative distance to the mean water level 4 1 conclusion the high degree of transformation of large river floodplains through forestry and agriculture makes pnv a valuable concept particularly as a benchmark for conservation measures although the conceptual and methodological issues around pnv are much discussed chiarucci et al 2010 loidi and fernández gonzález 2012 somodi et al 2012 the specific challenges for its reconstruction in river flood plains have gained little attention because natural floodplains are a disturbance driven ecosystem the classical static pnv definition is not reasonable however through the direct comparison of process based and statistic modelling approaches for pnv we showed that after 150 years of river regulation and impediment of geomorphological dynamics the riparian vegetation has reached a stable equilibrium state with its hydrologic control factors a static perception of its pnv seems justified consequently statistical models are the best option for its reconstruction since they need relatively few resources data time expert knowledge and are reproducible acknowledgements the first author is part of the fluvio doctoral program supported by a grant from the fundação para a ciência e tecnologia pd bd 114354 2016 we acknowledge the collaboration of the karlsruhe institute of technology department of wetland ecology in rastatt germany appendix a appendix b calculation of flood duration map representations of flood duration were needed as input for the dm and static models for the dm five representative years dry medium wet wet very wet and extreme wet from the period 1921 2016 were selected based on their maximum mean and minimum discharge and the representativeness of the flow duration curve table b1 for the sm the average flood duration of the vegetation period 1921 2016 was considered to reduce the calculational efforts for the hydrodynamic modelling 14 discharges were selected to best represent the average flow duration curve of the vegetation period table b2 using the two dimensional hydrodynamic model the water surface elevations wse for these 14 discharges were calculated for the whole study area in a first step the results from the irregular hydrodynamic model mesh were transferred into raster regular grids for the calculation of the flood duration raster of each representative year we attributed to the wse of the 14 modeled discharges the number of days that they were exceeded during the growing period through analyzing the respective hydrographs table b2 the final raster was then composed through superimposing the wse of each modelled discharge and their number of days exceeded the flood duration of the grid cell located between the water edge lines of two neighboring wse was calculated according to the relative vertical position of the grid cell between the two calculated water surface elevation as shown in fig b1 and the following equation calculation of the flood duration of a grid cell located between the water edges of two modeled discharges b1 fd n fd q 1 δ f d z n wse q 1 wse q 2 wse q 1 with fd n flood duration of grid cell n located between the water edge of flow rate q1 and flow rate q2 days fd q 1 flooding duration for flow rate q1 days δ f d difference between flooding duration for flow rate q1 and q2 days z n terrain elevation of grid cell n meter above sea level wse q 1 water surface elevation for flow rate q1 extrapolated meter above sea level wse q 2 water surface elevation for flow rate q2 meter above sea level appendix c casimir model parameters a detailed description of the model functioning as well as a description of the parametrization calibration and validation of the model can be found in ochs et al 2019 appendix d supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jher 2020 01 005 appendix d supplementary data the following are the supplementary data to this article supplementary data 1 
1699,the potential natural vegetation of large river floodplains from dynamic to static equilibrium konstantin ochs a gregory egger b arnd weber c teresa ferreira a john ethan householder b matthias schneider d a forest research centre instituto superior de agronomia university of lisbon lisbon portugal forest research centre instituto superior de agronomia university of lisbon lisbon portugal forest research centre instituto superior de agronomia university of lisbon lisbon portugal b department of wetland ecology karlsruhe institute of technology karlsruhe germany department of wetland ecology karlsruhe institute of technology karlsruhe germany department of wetland ecology karlsruhe institute of technology karlsruhe germany c department of vegetation studies landscape management federal institute of hydrology koblenz germany department of vegetation studies landscape management federal institute of hydrology koblenz germany department of vegetation studies landscape management federal institute of hydrology koblenz germany d sje ecohydraulic engineering gmbh stuttgart germany sje ecohydraulic engineering gmbh stuttgart germany sje ecohydraulic engineering gmbh stuttgart germany corresponding author the potential natural vegetation pnv is a useful benchmark for the restoration of large river floodplains because very few natural reference reaches exist expert based approaches and different types of ecological models static and dynamic are commonly used for its estimation despite the conceptual differences they imply for natural floodplains a static concept of pnv is not reasonable as natural disturbances cause a constant resetting of succession however various forms of river regulation have disrupted the natural dynamics of most large european rivers for centuries therefore we asked whether the consideration of succession dynamics and time dependent habitat turnover are still relevant factors for the reconstruction of the pnv to answer this we compared the results of a simulation of the vegetation succession 1872 2016 of a segment of the upper rhine river after regulation damming straightening and bank protection to different statistic and expert based modelling approaches for pnv reconstruction the validation of the different pnv estimation methods against a set of independent reference plots and the direct comparison of their results revealed very similar performances we therefore conclude that due to a lack of large disturbances the vegetation of regulated large rivers has reached a near equilibrium state with the altered hydrologic regime and that a static perception of its pnv may be justified consequently statistical models seem to be the best option for its reconstruction since they need relatively few resources data time expert knowledge and are reproducible keywords potential natural vegetation pnv riparian vegetation floodplain modelling large rivers 1 introduction river floodplains are amongst the most species rich and productive ecosystems naiman and decamps 1997 at the same time these ecosystems are one of the most threatened and modified worldwide tockner and stanford 2002 highlighting the need for conservation and restoration efforts buijse et al 2002 myers et al 2000 such efforts however are challenged by a lack of natural reference sites for orientation whited et al 2007 indeed 90 of river floodplains in europe and north america are used for agriculture or forestry and no longer harbor natural vegetation communities tockner and stanford 2002 where no natural references exist a potential natural vegetation pnv is often reconstructed and used as benchmark carranza et al 2003 hickler et al 2012 justice et al 2017 klimas et al 2009 schleupner and schneider 2013 shi et al 2016 but the concept of pnv and the methods for its reconstruction are highly controversial chiarucci et al 2010 loidi and fernández gonzález 2012 mucina 2010 somodi et al 2012 pnv was first defined by tuxen 1956 as the vegetation that would develop under present site conditions if human influences were excluded completely and succession would reach its climax stage at once it has often been thought of as an historic pre human reference condition hall and mcglone 2006 willis and birks 2006 however this idea has provoked disagreement carrión and fernández 2009 mitchell 2005 because it ignores that environmental conditions have changed since pre human times dotterweich 2008 nilsson et al 2005 therefore it has been argued that an estimation of the natural vegetation based on the assessment of present day natural vegetation remnants is more reliable kowarik 1987 but in areas with historically high levels of land use transformation this assessment is also prone to uncertainties zerbe 1998 another much discussed issue is the consideration of ecosystem dynamics and stochasticity chiarucci et al 2010 härdtle 1995 which are especially relevant in naturally disturbed areas jackson 2013 leuschner 1997 zerbe 1998 the traditional pnv estimation method is expert based and follows a floristic sociological approach westhoff and van der maarel 1978 it relies on the fieldworker s assessment and understanding of ecology to extrapolate present day natural vegetation remnants to similar environments kowarik 1987 moravec 1998 this approach however lacks transparency and reproducibility furthermore its implied static perception of pnv makes predictions in dynamic systems questionable mucina 2010 more comprehensive and also widely used for pnv estimations are ecological models based on the relationship between vegetation and environmental variables somodi et al 2012 zerbe 1998 two types can be differentiated that imply fundamental conceptual differences static models and dynamic models hannon and ruth 1998 static models describe a phenomenon at a given point in time and assume equilibrium between the vegetation and its environment dynamic models e g process based models or mechanistic models are based on ecological processes and differ from static models by explicitly incorporating time dependent changes in the system state therefor they are able to capture the transient response of vegetation to a changing environment hannon and ruth 2014 little attention however has been given to issues surrounding pnv in fluvial contexts the first modelling approaches of pnv in floodplains were static and tried to explain the vegetation patterns along vertical height above channel and lateral distance away from channel gradients bowman and mcdonough 1991 ellenberg 1996 glavac et al 1992 hosner and minckler 1963 hughes 1988 nixon et al 1977 roberts and ludwig 2016 robertson et al 1978 ward and stanford 1995 later more advanced static models emerged that relate the vegetation distribution to a set of hydrologic variables based on expert rules aggenbach and pelsma 2003 baptist et al 2004 fuchs et al 2012 jungwirth et al 2002 lenders et al 2001 pieterse et al 1998 runhaar 2003 or statistical analyses auble et al 1994 franz and bazzaz 1977 menuz 2011 dynamic floodplain vegetation models combine a simulation of the hydro dynamics with the modelling of ecological processes e g growth and mortality recruitment succession retrogression competition and are used to describe the vegetation development over time benjankar et al 2011 camporeale and ridolfi 2006 garcía arias and francés 2016 pearlstine et al 1985 more recently the dynamic feedbacks between vegetation and hydro geomorphological processes have also been incorporated camporeale et al 2013 van oorschot et al 2016 we argue that for floodplains of unregulated rivers the original static concept of pnv based on a climax stage of vegetation is not reasonable because successional sequences are repeatedly rejuvenated and reset by hydro geomorphological disturbances pringle et al 1988 it has been theorized that at the appropriate scale the proportion of successional phases would remain constant when processes of regression are compensated by progression a dynamic equilibrium referred to as shifting steady state mosaic bormann and likens 1979 geerling et al 2006 stanford et al 2005 while methodological advances reflect the growing recognition in the importance of allowing dynamic change in pnv estimation various forms of river regulation have disrupted the natural dynamics in most large rivers buijse et al 2002 dynesius and nilsson 1994 river damming and bank stabilization are the main reason for the impediment of dynamic geomorphological processes e g avulsion meandering braiding and decrease of hydrodynamic variability and disturbance in the riparian zone church 1995 magilligan and nislow 2005 nilsson and berggren 2000 petts and gurnell 2005 in this context we investigated whether the consideration of succession dynamics and habitat turnover are still relevant factors for the model based reconstruction of the pnv of regulated large river floodplains our hypothesis is that they can be neglected because riparian vegetation of regulated large rivers has reached a stable equilibrium due to the loss of natural disturbance dynamics to test this idea we compared the results of a simulation of the succession dynamics 1872 2016 of the floodplain vegetation of a segment of the heavily regulated upper rhine river to different static approaches for the estimation of its pnv a a statistical model based on hydrologic predictors and the geomorphological age of site b a statistical model only based on hydrologic predictors and c a gradient approach only based on the distance to the mean water level 2 methodology 2 1 study area the rhine river is one of the largest rivers in central europe with a length of approximately 1230 km and a catchment area of approximately 185300 km2 our study area lies in the upper rhine region where the nival discharge regime is strongly influenced by snow melt in the alps belz and frauenfelber kääb 2007 until the beginning of the 19th century the upper rhine could still be considered in natural condition gallusser and schenker 1992 and was classified as an highly dynamic island dominated anabranching river system gurnell and petts 2002 herget et al 2005 during the course of the 19th century however the upper rhine river was transformed into a single thread channel by cutting off meander bends and building groins and bank revetments bernhardt 2000 in the 20th century river regulation intensified through the construction of 10 hydropower plants in the main channel or in artificial side channels dister et al 1990 during this time industry and settlements also expanded in the study area habersack and piégay 2007 the study area is the raststatter rheinaue a nature reserve on the eastern german side of the floodplain that includes a 9 km segment of the upper rhine river downstream from the iffezheim dam to the confluence of the river murg rhine km 335 8 345 114 110 m a s l it is only limited by flood dykes towards the east and is still regularly flooded the study area covers approximately 645 ha including water bodies 2 2 material and data 2 2 1 historic maps because the upper rhine has been the border between france and germany detailed maps were produced for the planning of the river straightening in the beginning of the 19th century these indicate the location of water bodies islands and gravel sand bars within the aquatic area as well as land uses in the floodplain grasslands forests croplands and settlements our work is based primarily on four historical maps from that time 1816 1838 1852 1872 that were georeferenced and classified in natural natural water body gravel sand bar grassland and forest or anthropic artificial water body cropland settlement and industry habitat categories for details see table c1 and diaz redondo et al 2017 2 2 2 discharge data and hydrodynamic model the analysis of the flow regime of the study area for the whole simulation period is based on the maxau gauging station rhine km 362 3 which has the longest continuous record of daily discharge 1921 today and also records of the annual low mean and high discharges for the period 1872 1921 diaz redondo et al 2017 a two dimensional hydrodynamic model srh 2d lai 2008 of the rhine river and its eastern floodplain was set up the model bathymetry is based on a high resolution 1 m dem wasserstrassen und schifffahrtsverwaltung des bundes wsv 2016 supplemented by longitudinal profiles and cross sections through the main waterbodies in the study area díaz redondo et al 2018 the model mesh consists of 149 900 nodes with an average distance of 20 m in the main channel 10 m in the floodplain and down to 2 m in the river bank and dam zones break lines were integrated manually water surface elevations wse for 6 flood events with return periods between 1 and 100 years provided by the german federal agency for hydrology bfg were used for model calibration and setting of the lower boundary condition manning roughness coefficients were first appointed to the model elements based on different land use and lie around 0 083 for the floodplain forest and around 0 026 for the side channels and 0 037 for the main river channel calibration was performed by adjusting manning s roughness coefficients to minimize the difference between modelled and measured wses mean wse errors were between 1 cm for flood events with short return periods and 20 cm for higher return periods 2 2 3 calibration and validation data we used an expert based pnv map ochs et al 2019 and analyzed the historical land use to delineate likely reference areas for four main vegetation types reeds softwood forest transition forest and hardwood within these areas a total of 130 random sampling plots radius 5 m were distributed with a minimum distance between them of 50 m the pnv type of the plots was verified during several field visits föll and egger 2017 the verification was guided by indicator species from the herb and shrub layers see table a1 reeds could be confirmed in 8 plots softwood forest in 36 plots transition forest in 40 plots and 37 plots could be clearly identified as hardwood forest to increase the independency of the assessment of the predictive performance and comparison between the different modelling approaches we split the study area geographically perpendicular to the river axis wenger and olden 2012 the downstream part that represents between 30 and 40 of the reference plots of each vegetation type was used for validation fig 1 2 3 dynamic succession model dm the dynamic floodplain vegetation model casimir benjankar et al 2011 egger et al 2013 was used to predict the pnv by simulating the succession of the floodplain vegetation from 1872 to 2016 the time period was chosen because by 1872 the study area had already suffered the main hydro morphological impacts through river straightening and channelization bernhardt 2000 in the model the riparian vegetation is represented in succession lines and their respective succession phases table c2 the dynamic modules are recruitment controlled by the spring mean water level as described by the recruitment box model mahoney and rood 1998 and succession progression retrogression controlled by the disturbance indicators flood duration and shear stress formann et al 2014 each year the recruitment module checks for bare soils in the bank and floodplain zone as well as the water levels that allow seedling survival table c3 and the disturbance module checks whether the critical values of the disturbance indicators are surpassed table c4 and table c5 the result of one simulated year will be used as input for the next year the parametrization of the model was based on analyses of historic maps and historic discharge data the model was calibrated against an expert based pnv estimation of the upstream part of the study area so that the reference plots for validation can also be considered independent for a detailed description of the model functioning and calibration validation see ochs et al 2019 as well as appendix b and c for comparability the succession phases of the final year were aggregated to match the main pnv types in the study area table c2 2 4 statistic models sm1 and sm2 the statistic modelling approach for the classification of the main pnv types was based on the random forest algorithm breiman 2001 random forest selects random bootstrap samples from a given dataset to build a set of decision trees the final prediction is based on the majority vote from the individually developed trees we chose three predictors representing the hydrological control factors of riparian vegetation flood duration water depth and shear stress for the flood duration raster the average flood duration of each grid cell during the growing periods between 1921 and 2016 was calculated see appendix b maps of water depth and shear stress were calculated for hq10 4100 m3 s so that the whole floodplain could be represented in addition we tested the influence of the habitat age the geomorphological age of different areas of the floodplain was derived through the analyses of the changes from water surfaces to sand and gravel bars on historic maps diaz redondo et al 2017 we built two different models sm1 was based on the hydrological predictors and geomorphological age sm2 considered only the hydrological predictors the models were set to grow 1000 trees based on bootstrap samples from the calibration plots the sample was balanced to compensate for the overrepresentation of softwood forest in the reference plots which according to an expert based pnv map of 2017 covered around 10 of the study area the statistical modelling was done in the r environment using the randomforest package liaw and wiener 2002 2 5 gradient model gm the german federal institute of hydrology bfg developed a gradient model for the large scale assessment of the main floodplain vegetation types for the free flowing parts of river rhine and elbe in germany it is based on the field observation that the occurrence of salix alba at a site correlates with the relative height to the mean water level and the mean annual flood duration schleuter 2014 the mean annual flood duration of a grid cell is calculated as follows schleuter 2016 f 70 599 l n x 0 50 88 711 f mean annual flood duration x relative height to mean water level m the pnv types are then assigned based on expert knowledge table 1 2 6 model validation and comparison for validation of the predictive performance all models were tested against the same set of geographically separated reference plots based on a confusion matrix we calculated the global metrics overall accuracy oa and kappa coefficient k cohen 1960 which corrects the oa for chance agreement in addition we calculated sensitivity and specificity for each pnv class for comparison between the models all area wide predictions were directly compared to each other by calculating the metrics kappa k kappa location kloc and kappa histogram khist kloc describes the similarity of spatial allocation of categories of the two compared maps and khist describes the quantitative similarity pontius 2000 the following rating system was applied values greater than 0 75 indicate very good to excellent agreement values between 0 40 and 0 75 indicate fair to good agreement and values of 0 40 or less indicate poor agreement landis and koch 1977 3 results the results of the different approaches to reconstruct the pnv of our study area are shown in fig 2 the overall agreement between the models was good all approaches predicted hardwood forests to be the dominant vegetation class followed by transition forests softwood forests and reeds table 2 along the same sequence the agreement of the predictions between the approaches diminished table 3 hardwood forests were predicted for about 50 of the study area by all models and the agreement spatial and quantitative was excellent to very good transition forests were estimated to cover around 35 by dm sm1 and sm2 but only 26 by gm the similarity of the predictions of dm and sm1 2 was very good but only fair when compared to gm softwood forest were predicted on only 7 of the area by the dm but nearly twice as much by the other models the agreement between the dm and sm1 2 still can be considered fair but showed high discrepancies to gm reeds presented poor agreement between all models especially spatially 3 1 validation overall the dm sm1 and sm2 showed good predictive performance and that of the gm was fair see table 4 notably sm1 and sm2 performed identically all models were unable to detect reeds sensitivity 0 softwood forest and hardwood forests were predicted with very good accuracy but sm1 sm2 and gm only identified about 50 of transition forest reference plots correctly the mean decrease accuracy and mean decrease gini measures of the random forest models both revealed flood duration to be the most important predictor habitat age and shear stress were the least important ones 4 discussion the equally good performances of the dynamic and static modelling approaches in predicting the pnv of our study area support the hypothesis that due to the loss of natural disturbance dynamics the riparian vegetation in our study area has reached a stable equilibrium with the hydrological control factors sensitivity analyses of the statistic model and the dm ochs et al 2019 revealed that the pnv is mainly determined by flood duration but we show that the resulting pattern of softwood transition and hardwood forest is explained equally well by a static average as a reconstruction of the temporal dynamics of the flood regime dm even more the fair results of the gradient approach show that the relative height to the mean water level also captures most of the influencing factor of riparian vegetation with the predictor habitat age we wanted to include a time dimension to the static modelling approach as indication of a possible successional progression however roughly 150 years after geomorphological changes have been impeded habitat age proved to have no influence on the present vegetation communities the transition of the large scale dynamic equilibrium of natural floodplain ecosystem to a more mature and stable state after river regulation has also been recognized by other studies diaz redondo et al 2017 hohensinner et al 2004 ollero 2010 tockner and stanford 2002 and has been mainly attributed to an impediment of morphologic dynamics through bank stabilization and flow regulation florsheim et al 2008 hohensinner et al 2014 to allow for the comparison of the model predictions we validated the results against a geographically separated holdout sample the spatial blocking strategy increases the independency of the sample and allow an effective test of a models transferability roberts et al 2017 wenger and olden 2012 it meant however a trade off with the sample size used for calibration of the statistical model which already had to be considered small wisz et al 2008 nevertheless random forests are recognized as one of the most accurate species distribution modelling techniques cutler et al 2007 elith et al 2006 also some confidence about our results can be drawn from the good agreement between the modelling approaches themselves the reference plots were identified based on indicator species from the herb and shrub layers see table a1 that usually develop without direct human manipulation gilliam 2007 metzger and schultz 1984 as opposed to area wide expert based assessments of pnv that are often used to validate ecological models in areas of high anthropogenic transformation hickler et al 2012 somodi et al 2017 the reference plots are not extrapolated and therefore more comprehensive and less prone to uncertainties all tested modelling approaches simplify the complex floodplain ecosystem and are based on several assumptions they assume that in our study area the hydrological control factors are most relevant and neglect other factors that are known to influence plant communities in floodplains regarding the occurrence of reeds this seems to be an oversimplification since no model was able to detect it the proliferation and dominance of phragmites australis can be linked to nutrient competition and allelopathy hazelton et al 2014 uddin and robinson 2018 the fixed topographic input and disregard of the complex hydro morphological processes normally occurring within the floodplain gurnell 2016 can be justified in part by river regulation measures and artificially stabilized banks a further in depth discussion of the uncertainties regarding the dynamic model casimir vegetation can be found here benjankar et al 2011 ochs et al 2019 another obvious source of prediction bias for both the statistic and dynamic model are possible errors in the hydrological model and the historic maps that were used for parameterization in addition to the predictive performance other important criteria when choosing a model are the required resources and deployment time the simulation of succession dynamics for nearly 150 years was only possible with access to data of high spatiotemporal resolution and a high level of expert knowledge as well as a laborious calibration process the static models on the other hand needed less data know how and time especially the very simple gradient model gm which still showed fair agreement with the other modelling approaches doesn t even need hydraulic simulations since it is only based on the relative distance to the mean water level 4 1 conclusion the high degree of transformation of large river floodplains through forestry and agriculture makes pnv a valuable concept particularly as a benchmark for conservation measures although the conceptual and methodological issues around pnv are much discussed chiarucci et al 2010 loidi and fernández gonzález 2012 somodi et al 2012 the specific challenges for its reconstruction in river flood plains have gained little attention because natural floodplains are a disturbance driven ecosystem the classical static pnv definition is not reasonable however through the direct comparison of process based and statistic modelling approaches for pnv we showed that after 150 years of river regulation and impediment of geomorphological dynamics the riparian vegetation has reached a stable equilibrium state with its hydrologic control factors a static perception of its pnv seems justified consequently statistical models are the best option for its reconstruction since they need relatively few resources data time expert knowledge and are reproducible acknowledgements the first author is part of the fluvio doctoral program supported by a grant from the fundação para a ciência e tecnologia pd bd 114354 2016 we acknowledge the collaboration of the karlsruhe institute of technology department of wetland ecology in rastatt germany appendix a appendix b calculation of flood duration map representations of flood duration were needed as input for the dm and static models for the dm five representative years dry medium wet wet very wet and extreme wet from the period 1921 2016 were selected based on their maximum mean and minimum discharge and the representativeness of the flow duration curve table b1 for the sm the average flood duration of the vegetation period 1921 2016 was considered to reduce the calculational efforts for the hydrodynamic modelling 14 discharges were selected to best represent the average flow duration curve of the vegetation period table b2 using the two dimensional hydrodynamic model the water surface elevations wse for these 14 discharges were calculated for the whole study area in a first step the results from the irregular hydrodynamic model mesh were transferred into raster regular grids for the calculation of the flood duration raster of each representative year we attributed to the wse of the 14 modeled discharges the number of days that they were exceeded during the growing period through analyzing the respective hydrographs table b2 the final raster was then composed through superimposing the wse of each modelled discharge and their number of days exceeded the flood duration of the grid cell located between the water edge lines of two neighboring wse was calculated according to the relative vertical position of the grid cell between the two calculated water surface elevation as shown in fig b1 and the following equation calculation of the flood duration of a grid cell located between the water edges of two modeled discharges b1 fd n fd q 1 δ f d z n wse q 1 wse q 2 wse q 1 with fd n flood duration of grid cell n located between the water edge of flow rate q1 and flow rate q2 days fd q 1 flooding duration for flow rate q1 days δ f d difference between flooding duration for flow rate q1 and q2 days z n terrain elevation of grid cell n meter above sea level wse q 1 water surface elevation for flow rate q1 extrapolated meter above sea level wse q 2 water surface elevation for flow rate q2 meter above sea level appendix c casimir model parameters a detailed description of the model functioning as well as a description of the parametrization calibration and validation of the model can be found in ochs et al 2019 appendix d supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jher 2020 01 005 appendix d supplementary data the following are the supplementary data to this article supplementary data 1 
