index,text
5030,a clear identification of the hydrochemical processes in groundwater systems is critical for the management and protection of alternative water resources the dagu river basin drb has become one of the most concerning areas due to the typical geographical conditions and intensive human disturbance in this study the spatio temporal variations of groundwater hydrochemical characteristics were discriminated based on the self organizing maps som clustering results from 2001 to 2017 simultaneously their main governing factors were also identified according to the composite properties of hydrogen and oxygen isotopic evidence hydrochemical facies evolution diagram hfe d chloro alkaline indices cai values and the enrichment of nitrogen analysis results indicated that the long term evolution of hydrochemical signatures basically conformed to the trends of rising in the dry season and falling in the rainy season total dissolved solids tds fluctuated from 187 90 mg l to 2294 81 mg l with an average of 881 77 mg l moreover the nitrate concentrations in the river basin varied significantly from 0 70 mg l to 605 32 mg l the unconfined aquifer beneath drb was experiencing freshening gradually while some other samples were still subjected to the interference of environmental pollution spatio temporal variations in the respective clusters demonstrated that natural factors including precipitation infiltration evaporation and water rock interactions played vital roles in the samples of clusters i iii v and viii while the samples of cluster vii were influenced by seawater intrusion and those of clusters iv and vi were mainly affected by nitrate and nitrite contamination this study suggests that the som connected with stable isotope analysis hfe diagram cai values and correlation analysis could be successfully used to interpret nonlinear and high dimensional multivariate systems and provide supplementary information about the dominant mechanisms controlling the regional groundwater evolution keywords groundwater hydrochemistry self organizing maps som long term variations governing factors 1 introduction as an essential part of water resources groundwater is crucial for drinking purposes agricultural irrigation and industrial uses choi et al 2014 lee et al 2019 long term evolution of groundwater quality plays a primordial role in understanding ongoing hydrochemical processes in watersheds and also provides essential hydrogeological background information for detailed evaluations into aquifer sustainability and the management of local groundwater resources ovalle et al 2013 gejl et al 2019 the scale and dimensionality of hydrochemical data increase dramatically owing to the long term groundwater monitoring which definitely pose challenges to the recognition and visualization of groundwater traits moreover it is necessary to find an effective dimension reduction technique that can evaluate a large number of groundwater quality data and provide legible visualization effects for decision making haselbeck et al 2019 both natural processes the mineralogy of aquifers topography rock weathering surface water recharge atmospheric precipitation and evaporation crystallization and anthropogenic pollution urban demands domestic uses agricultural and industrial activities can result in the diversification and complication of the hydrodynamic and hydrochemical fields of groundwater systems singh et al 2007 2014 swartjes and otte 2017 molinari et al 2019 it is still an important issue to investigate the main mechanisms governing the chemical compositions in complex shallow groundwater systems traditional multivariate statistical methods such as factor analysis fa jang 2010 busico et al 2020 cluster analysis ca abdullah et al 2015 zhang et al 2019 discriminant analysis da jang 2010 matiatos et al 2014 fuzzy c means fcm clustering algorithm güler and thyne 2004 and principal component analysis pca helena et al 2000 olsen et al 2012 zhang et al 2012 are available for the estimation of groundwater hydrochemistry evolution however the results acquired by these approaches are essentially mixtures of the dimensions they can only provide an initial direction to interpret the differences between the reference vectors sun et al 2009 li et al 2018 self organizing maps som is a powerful neural network model based on an unsupervised learning algorithm nakagawa et al 2020 som projects the input parameters from high dimensional space to low dimensional space where the data visualization of the output is implemented during the learning process wehrens and buydens 2007 ali hameed et al 2019 kim et al 2020 furthermore som can effectively capture the spatio temporal traits of nonlinear complex systems with less computational requirements nguyen et al 2015b 2015a chen et al 2018 in recent years som has been widely applied to achieve a better understanding of the hydrogeological processes in different regions such as heavily populated cities shi et al 2018 lee et al 2019 agricultural watersheds li et al 2019a jampani et al 2020 coastal areas löhr et al 2010 li et al 2018 and mining areas haselbeck et al 2019 based on short term groundwater quality monitoring data however how to identify the long term trends of regional groundwater hydrochemistry in complex systems especially for the hydrochemical components and their potential controlling factors has attracted relatively limited concerns so far the dagu river basin drb is located in the western area of jiaodong peninsula china which has become one of the most concerning areas due to the typical geographical conditions containing mining agricultural and coastal areas from north to south and intensive human activities with the rapid development of urbanization and the continuous improvement of people s living standards the quality and quantity of groundwater have become bottlenecks restricting the advance of drb previous investigations in this region were based on a limited volume of hydrochemical data which is quite inadequate for interpreting the long period evolution of groundwater quality and the potential controlling factors in the unconfined aquifers therefore the main purpose of this research is to identify the hydrochemical evolution and governing mechanisms of a groundwater system based on long term monitoring data through the following steps 1 to identify the groundwater quality data by som 2 to reveal the spatio temporal variations of groundwater hydrochemical features on a basin wide scale 3 to verify the natural and anthropogenic factors governing the hydrochemical compositions of groundwater and 4 to propose some suitable groundwater management plans for the policymakers the results obtained from the present study will be pragmatic in getting a deep insight into groundwater hydrochemistry issues ranging from geochemical variations on local or regional scales to the assessments and measurements of shallow groundwater system s vulnerability 2 data and methods 2 1 study area description the study area includes 2513 villages and has a population of 2 4 million lv et al 2013 the drb is located between longitudes 120 03 to 120 25 e and latitudes 36 10 to 37 12 n covering an area of 4781 km2 approximately 45 of the total area of qingdao city china fig 1 a xiong et al 2020 the mean temperature and annual average evaporation are 12 3 c and 983 86 mm respectively the mean annual precipitation mainly concentrated in the rainy season july to september is about 618 4 mm yin et al 2018 the land use data of drb are derived from the us landsat satellite remote sensing images with a resolution of 30 m in 2015 http www dsac cn landscapes are classified into seven types including farmland residential areas woodland grassland paddy fields waters and unused land of which 74 55 is cultivable land 2 2 geology and hydrogeology as shown in fig 1b quaternary sediments belonging to cenozoic are the primary geologic units in the river basin and the outcrops are mainly covered by mesozoic cretaceous and proterozoic metamorphic strata it is notable that northern hills are controlled by acid rock with some auriferous quartz veins consisting of some sulfide deposits and mining areas the hydrochemical facies in these regions are occupied by ca mg so4 and ca mg so4 hco3 types yin et al 2018 furthermore calcite dolomite kaolinite ca montmorillonite illite and feldspar are widely distributed in the saltwater freshwater transition zones of the drb chen and zheng 2015 precipitation is the main source of groundwater recharge in the drb and artificial abstraction is the main discharge the aquifer distributes along the dagu river 179 9 km in a strip shape with a thickness ranging from 10 m to 20 m lv et al 2013 and it presents a quaternary alluvial proluvial double layer structure the upper layer is comprised of weakly permeable clayey sand and sandy clay and clay is regionally scattered whereas the lower layer with a great capability of storing groundwater in the drb is composed of thick sand and gravel fig 1c xiong et al 2020 the depth to the water table in the unconfined aquifer is about 1 62 8 80 m with an average of 4 09 m the runoff is affected by topography lithology and other natural and anthropogenic factors of the study area followed by terrain downhill the shallow water moves from northwest to southeast and finally flows into jiaozhou bay liu et al 2019 2 3 hydrochemical data and pre processing ten major ions cl so4 2 hco3 no3 no2 f na k ca2 and mg2 ph and the total dissolved solids tds of 213 groundwater samples were collected from 17 monitoring bore wells by qingdao geo engineering exploration institute of china during 2001 to 2017 the samples were collected once per year spanning 2001 to 2017 except twice per year in 2013 and 2016 isotopic data δ2h and δ18o including 23 precipitation samples and 34 groundwater samples were also collected at 2 local domestic monitoring wells in a hydrological year from august 2016 to october 2017 fig 1a the samples were filtered with 0 45 μm membrane and then poured into 1 5 l high density polyethylene bottles which were flushed at least 3 times with the sample water all samples were stored in refrigerators with temperatures below 4 celsius c until the laboratory analysis major ions measurements were conducted in accordance with the chinese standard testing methods before 2011 na and k were determined using flame atomic absorption spectrometry while major ions ca2 mg2 and so4 2 were analyzed by edta 2na titration in addition cl and f were measured by silver nitrate titration and ion selective electrode respectively and ultraviolet spectrophotometry was used to analyze the contents of no3 and no2 after 2011 with the exception of hco3 major anions were analyzed by ion chromatography ics 2100 produced by thermo scientific dionex and major cations in groundwater samples were measured using ion chromatography 1 930 2360 produced by metrohm the detection limits of ion analyses reported during this monitoring period were 0 05 ppm hco3 concentrations were analyzed by phenolphthalein titration in the whole monitoring period then tds values were obtained based on the above analysis data as to stable isotope data both δ2h and δ18o were determined by liquid water isotope analyzer dlt 100 at the key laboratory of water cycle and related surface processes institute of geographic sciences and natural resources research china the analysis results were expressed by the vienna standard mean ocean water vsmow 0 with the analytical accuracy of 1 δ2h and 0 1 δ18o to evaluate the reliability of hydrochemical data percent charge balance errors cbe were calculated then 197 out of 213 samples with cbe 10 were used in our study during the long term monitoring process a small proportion of the monitoring datasets are discontinuous due to the disturbance induced by accidents such as dry damage borehole collapse and urban renewal in this study all units of groundwater quality data were measured in mg l except ph in order to prevent the heavier and higher charged ions from misleading the analysis result all data were converted into meq l haselbeck et al 2019 furthermore the som is strongly influenced by some variables with a larger scale and may result in significant distortion of the hydrochemical data therefore all parameters were normalized into dimensionless data between 0 and 1 to ensure that they have the same or similar importance in som analysis kiang 2001 nguyen et al 2015b 2015a lee et al 2019 2 4 self organizing maps som the som developed by kohonen 1982 is a powerful neural network model based on unsupervised learning algorithm which includes an input layer connected with an output layer by a weight kohonen 1982 ali hameed et al 2019 nakagawa et al 2020 the som methodology can project the d dimensional input data into a two dimensional hexagonal grid so that the topology preserving can be visualized intuitively kohonen 2013 chen et al 2018 note that d 11 in this study representing eleven types of input data cl so4 2 hco3 no3 no2 f na k ca2 mg2 ph and tds where na k is defined as the summation of the two cations na and k given the requirements of som for the pattern s accuracy and scale the map size or the number of output neurons is an important factor of its implementation li et al 2018 the optimal number m of output neurons can be determined by a heuristic rule e g m 5 n where n denotes the number of training samples n 197 in our study vesanto and alhoniemi 2000 vesanto et al 2000 based on this heuristic rule 70 cells were approximately the best map size in this study the self organizing maps toolbox 2 0 for matlab r2019a was applied to conduct and visualize the som http www cis hut fi projects somtoolbox there are four training steps of the sequential learning algorithm of som i e initialization competition adaption and iteration these steps can be briefly described as follows 1 to initialize the weight space with small random values meanwhile the map size starting winner neuron and initial learning rate are set in this preliminary step respectively 2 to find out the best matching unit bmu whose weight vector is most similar to the input vector 3 to update the weight vector of the bmu and its proximal neurons during the training progress the weight vector would approach the closest sample value lee et al 2019 and 4 to iterate the search procedure and converge to the best self organizing maps if a pre determined number of iterations reaches or the learning rate tends to be 0 this procedure will end otherwise it will return to step 2 according to vesanto et al 2000 the outputs of som are usually presented in the forms of unified distance matrix u matrix and component planes u matrix displays the euclidian distance between two neighborhood neurons and the subgroup boundaries which facilitates the interpretation of the determined clusters also component planes visualize the weight values of a hydrochemical variable in each neuron using a color gradient map units with higher values are highlighted in hot colors while units with lower values are in cool colors significantly cluster analysis is one that seeks to enhance the information of the map and the data based on classifying the similar neurons of som haselbeck et al 2019 here the k means clustering algorithm was applied to categorize the groundwater samples and the davies bouldin index dbi was implemented before the optimal number of clusters was obtained davies and bouldin 1979 the dbi can be expressed as 1 dbi 1 n i 1 i j n max σ i σ j d c i c j where n is the number of clusters σi σj are the mean distance of all patterns in cluster i j to the centroid ci and cj respectively d ci cj is the distance between ci and cj 3 results and analysis 3 1 hydrochemical and isotopic signatures the statistics of hydrochemical compositions of the drb are presented in table 1 the ph values varied from 5 5 to 8 5 with a mean of 7 5 implying that groundwater in the study area is generally to be neutral or weakly alkaline groundwater salinity expressed by tds fluctuated over a wide range 187 90 2294 81 mg l during the whole monitoring periods with an average of 881 77 mg l the order of mean cation contents was ca2 na k mg2 and the major anion dominance was hco3 so4 2 cl no3 no2 in the drb moreover significant variations of nitrate concentrations were observed in our results 0 70 mg l to 605 32 mg l the mean values of nitrate were 157 82 mg l and 125 99 mg l in the dry season and rainy season respectively furthermore the maximum values of nitrite were 15 00 mg l in the dry season and 1 80 mg l in the rainy season both of which exceeded the highest permissible limit 1 mg l according to the national standard for drinking water quality in china gb5749 2006 in terms of the isotopic indicators as shown in table 2 the stable isotope values in precipitation varied from 17 48 to 2 03 in δ18o mean value of 9 43 and from 135 65 to 1 70 in δ2h mean value of 67 97 the deuterium excess dexcess δ2h 8δ18o of precipitation ranged between 15 82 and 25 37 with a mean value of 7 47 by comparison the isotopic compositions of δ2h and δ18o of groundwater samples in the dry season ranged from 52 50 to 46 85 and from 7 73 to 6 75 with averages of 49 75 and 7 07 respectively while those in the rainy season were 52 72 to 49 87 and 7 71 to 6 56 with averages of 51 54 and 7 07 respectively moreover the dexcess of groundwater fluctuated between 0 63 and 10 53 of which the average is 6 08 3 2 som based results and hydrochemical characteristics of each cluster the variations of the dbi in the process of som clustering are illustrated in fig 2 and the front part between 0 and 20 clusters is magnified to display the minimum dbi value 8 clusters evidently to some extent it provides a better understanding of the subgroups information and the long term spatio temporal variations of groundwater hydrochemical features after som training the u matrix and component planes of 11 groundwater hydrochemical parameters are presented in fig 3 and the correlations between these parameters can be discerned apparently the neurons with high similarities i e short distances shown in blue can be regarded as a subgroup while the neurons with low similarities i e long distances shown in yellow can be regarded as another subgroup löhr et al 2010 lee et al 2019 kim et al 2020 it is shown that ca2 mg2 cl and so4 2 have common patterns of the color gradient of component planes in which the pronounced maximum values scatter at the bottom and decrease upward also tds is paralleled by this tendency the highest values of na k and hco3 distribute in the lower right areas and reduce towards the upper left direction nitrogen no3 and no2 show similar patterns with the highest values in the lower left corner of the som maps while the distribution of fluoride is the exactly opposite to characterize the clustered hydrogeochemistry data numerically the radar plots as shown in fig 4 depicts the minimum first quartile median third quartile and maximum of the 9 major ions respectively combined with fig 3 it is shown that all ion contents of cluster i 48 samples accounting for 24 of the total samples were relatively less than other clusters the order of mean cation concentrations in this cluster was ca2 90 58 mg l na k 67 51 mg l mg2 32 25 mg l while the major anion dominance was hco3 134 66 mg l so4 2 133 46 mg l no3 109 92 mg l cl 100 25 mg l cluster ii 39 samples belonging to fresh water the salinity expressed by tds is less than 1000 mg l owned relatively high values of ca2 and hco3 with the average values of 131 94 mg l and 272 34 mg l respectively in this study it was found that cluster iii 18 samples was defined by relatively high f concentrations and the contents of some samples even exceeded the maximum concentration level 1 mg l the dominant hydrochemical signature of cluster iv 29 samples was occupied by higher nitrate values while that of cluster vi 17 samples was characterized by higher contents of nitrate and nitrite in comparison with other clusters the possible reason is that anthropogenic interference results in the increasing risk of groundwater pollution and poses a great threat to the monitoring sites involved the enrichment of na k and hco3 in cluster v 18 samples and the dominance of na k hco3 and so4 2 in cluster viii 18 samples reflected that water rock interactions dissolution of silicate and evaporite play influential roles in the relevant clusters furthermore it was obvious that the highest concentrations of ca2 so4 2 cl no3 and tds distributed in cluster vii 10 samples and their maximum concentrations were 435 97 mg l 702 60 mg l 702 45 mg l 605 32 mg l and 2294 81 mg l respectively 3 3 temporal variations and spatial distributions in the respective clusters the spatio temporal variations of groundwater hydrochemistry based on the som clustering are shown in fig 5 over the past decade years the average annual precipitation in the basin was 607 30 mm almost 100 mm smaller than the average annual precipitation 716 64 mm between 2001 and 2008 to make a more reasonable analysis of the temporal variations of groundwater hydrochemical attributes the time series were classified into two stages 2001 2008 and 2009 2017 called stage i and stage ii respectively in this study based on the annual precipitation connected with the results obtained by fig 3 and fig 4 analyses revealed that the temporal evolution of clusters i ii and vii was inapparent while the relative higher fluoride values of cluster iii were generally from stage i there were respective 79 and 100 of samples belonging to clusters iv and vi from stage ii by comparison with the first time series stage i 2001 2008 implying that with the rapid promotion of intensified agriculture the contradiction between immense food demands and eco environment improvement has become a bottleneck restricting the development of drb in recent years simultaneously the effects of intensive water rock silicate and evaporite interactions which were possibly responsible for the dissolution of na k so4 2 and hco3 in amounts of samples belonging to clusters v and viii in stage ii as expected clusters with similar hydrochemical compositions were geographically nearby the common groundwater origins it can be seen in fig 5 that clusters i ii and v representing the freshwater type were observed not only in the upper and middle reaches but also in the lower reaches such as d 8 well location the presence of fresh water in the eastern lower reaches before 2012 suggested that seawater intrusion has no impact on groundwater far inland cluster iii with relative higher f values was primarily found at some middle and lower reaches in certain years therefore we should pay more attention to decrease the concentrations of f and avoid endemic fluorosis clusters iv and vi were mainly distributed in the middle reaches it may be attributed to groundwater runoff from cultivated fields that were treated with nitrogenous fertilizers and these regions are important grain production areas in qingdao city meanwhile the well u 1 was also predominated by no3 and no2 spanning 2013 to 2017 the samples belonging to clusters vii viii scattered at the saline water intrusion transitional zones influenced by jiaozhou bay partially the seawater intrusion on fresh water may be the reason for the presence of high concentrations of ca2 na k so4 2 and cl in the coastal areas 4 discussion based on the preliminary conclusions above as shown in fig 4 natural factors precipitation evaporation mechanism rock weathering functions and seawater intrusion played influential roles in the samples belonging to clusters i iii v and vii viii while anthropogenic pollution was crucial for the samples belonging to clusters iv and vi 4 1 precipitation infiltration and evaporation the dissolution of aerosols particulates and dust from the atmosphere is the primary origin of some meteoric water ions e g k ca2 mg2 so4 2 and hco3 which are the original inputs of the groundwater huang et al 2010 hydrogen and oxygen isotopic compositions of precipitation as the effective clues on the hydrological process are usually used to identify the potential recharge zones of groundwater and evaluate the sources sinks of contaminants presented in groundwater kumar et al 2018 in this study the slope and the intercept of the local meteoric water line lmwl δ2h 8 9δ18o 16 3 n 23 r 2 0 939 were both greater than that of the global meteoric water line gmwl δ2h 8δ18o 10 which are probably due to local climatic and hydrometeorological parameters such as the origin of the vapor mass li et al 2019b furthermore most of the groundwater samples locate below the gmwl and lmwl fig 6 indicating that the groundwater originates from precipitation infiltration δ2h and δ18o in groundwater distribute along the evaporation line with a slope of 2 9 δ2h 2 9δ18o 29 9 suggesting that they are affected by secondary evaporation to a certain degree before or during precipitation infiltration fu et al 2018 the deuterium excess has advantages in getting a deeper insight into the original source of water vapor and humidity at the vapor source areas hu et al 2018 globally the mean value of dexcess is 10 for precipitation when a water body undergoes evaporation it will decrease in different degrees huang and pang 2012 in comparison with the dispersed range of precipitation dexcess values from 15 82 to 25 37 groundwater is of a relatively concentrated range of dexcess values from 0 63 to 10 53 suggesting that the primary vapor source of groundwater is from low latitude ocean with high humidity besides the mean values of amounts of hydrochemical parameters except for na k and hco3 fluctuated with seasonal variations this result suggested that the infiltration of precipitation into phreatic aquifers in the rainy season could dilute the concentrations of major ions in the local groundwater systems and conduce to lower values of hydrochemical compositions shi et al 2018 hence precipitation infiltration and evaporation played crucial roles in the evolution of groundwater hydrochemistry based on the above findings 4 2 water rock interactions given the inherent uniqueness of geological conditions of different aquifers it is essential to know and identify the hydrochemical controlling factors under the influence of water rock interactions the water rock interactions contain ion exchange chemical weathering mineral adsorption and absorption shi et al 2018 these reaction processes are often significant at vastly different spatial and temporal scales although cumulative small scale factors can combine to primary effects on hydrochemical variations in this study the assessment of base ion exchange between the groundwater system and its host geo environment is illustrated by chloro alkaline indices cai values as formulated as follows 2 cai i cl na k cl 3 cai ii cl na k so 4 2 hco 3 no 3 if the cai values are positive it demonstrates the direct base ion exchange of na and k in the groundwater with the ca2 and mg2 in rocks otherwise it means that the exchange is inverse and indirect kumar et al 2018 jampani et al 2020 as shown in fig 7 the direct cation alternating adsorption was predominant in cluster vii the reason may be that the higher na and k concentrations in the groundwater system replace a part of ca2 and mg2 in the rock however the inverse ion exchange played a primary role in the other clusters accounting for 63 64 of the remaining samples which may be caused by precipitation infiltration and irrigation recharge originally the cations in the groundwater are dominated by ca2 and mg2 but after going through the silicate na and k feldspar the na and k in groundwater are increased correspondingly li et al 2019b as mentioned in section 3 2 either ca2 mg2 cl and so4 2 or na k and hco3 had common patterns of color gradient in the component planes which implied the correlations between the hydrochemical compositions furthermore correlation analysis is applied to identify similar origins of major ions and predict the dependency of one chemical constituent to another pant et al 2018 as shown in fig 8 a strong positive correlation was observed between na k and hco3 demonstrating that silicate na and k feldspar weathering is taking place in clusters v and viii monitoring regions winnick and maher 2018 however there were no significant correlations in the ca2 hco3 and mg2 hco3 pairs indicating that carbonate chemical weathering across the river basin is not very intense the ca2 so4 2 na k so4 2 and mg2 so4 2 pairs exhibited a significant correlation which suggested that these ions have similar origins and potentially relate to the dissolution of sulfide deposits or evaporite rocks deuerling et al 2018 additionally na k was obviously correlated with cl implying that the groundwater has an interaction with halite and the local lithological origins of na and k in recent years fluoride rich groundwater has drawn worldwide attention as the consumption of excessive fluoride in drinking water led to endemic fluorosis such as dental fluorosis and skeletal fluorosis chowdhury et al 2019 in the study area it also has been found that ca2 had significant negative relationships with f revealing that fluorite dissolution under high alkaline conditions possibly boosts up the leaching of f into groundwater especially in cluster iii kumar et al 2018 and the concentration of no3 showed a strong negative correlation with hco3 due to the occurrence of denitrification because the organic carbon is used as the electron donor accompanied with the production of co2 that increases the contents of hco3 in groundwater during the process of denitrification lee et al 2019 4 3 seawater intrusion si seawater intrusion si a great threat to fresh water stored in coastal aquifers contains many complicated physical and chemical processes such as hydrogeological characteristics dispersive mixing tidal effects density effects and human interference werner et al 2013 badaruddin et al 2015 the archetypal hydrochemical type of fresh water is ca hco3 while it of seawater is na cl kim et al 2017 na hco3 cl is the predominant hydrochemical facies in freshening aquifers in contrast ca na hco3 cl and na ca cl hco3 types are the most universal groundwater chemical types in the saline water intrusion transitional zones wang and jiao 2012 chandrajith et al 2016 si in the jiaohzhou bay is a focus of great concern and it is important to timely analyze the potential impacts on hydrogeochemistry and chemical weathering processes in the river basin hydrochemical facies evolution diagram hfe d established by giménez forcada 2010 is a new analysis tool that gives potential hydrochemical facies and evolution processes considering the percentage of the most important ions as well as their connections giménez forcada 2010 2014 giménez forcada and sánchez san román 2015 as shown in fig 9 rectangles filled in diverse colors refer to different hydrochemical types the sub stages from fre i to fre iv indicate the process of freshening while the sub stages from int i to int iv reveal the process of intrusion the results showed that more than half of the samples were projected on the upper right of the figure in which 12 18 of samples belonged to the mixca mixhco3 type furthermore almost all samples belonging to cluster v occupied by na k and hco3 and cluster viii occupied by na k hco3 and so4 2 were experiencing freshening gradually however cluster vii was scattered at the sub stages from int i to int iii suggesting the influence of si this result can also be confirmed by the higher na and k concentrations in the groundwater system which result in the direct cation alternating adsorption in cluster vii as mentioned in section 4 2 14 72 and 8 12 of groundwater samples were characterized by mixca mixcl and ca mixcl type respectively meanwhile 10 66 of samples were marked by ca mixhco3 these results implied that some fresh groundwater is susceptible to degradation due to its proximity to seawater and the intensive water demands that accompany with higher population densities however the trend of intrusion has been mitigating as a consequence of effective measures concerning the construction of cutoff walls and suitable management plans of groundwater resources in recent years 4 4 anthropogenic pollution nitrogen fertilizer in crop production vastly devotes to global food security as indispensable nutrients for the growth of plants however this can also lead to n losses to the environment which have adverse impacts on ecosystems and biodiversity such as eutrophication and harmful algae blooms in coastal areas wang et al 2018 according to the questionnaire survey conducted in 2009 it was found that nitrogen applications were various in different cropping systems in china the highest nitrogen is utilized to the fruits 550 381 kg hm2 followed by vegetables 383 263 kg hm2 maize 231 142 kg hm2 rice 209 140 kg hm2 and wheat 197 134 kg hm2 zhang et al 2013 because of the agricultural practices and the intensification of anthropogenic inputs the use of nitrogenous fertilizer has increased in the drb over recent years as mentioned in section 3 significant variations in nitrate values were observed in our results 0 70 to 605 32 mg l and higher contents of nitrogen were the predominant hydrochemical signatures in clusters iv and vi it is acknowledged that the major source of nitrate is a mixture of synthetic fertilizer and manure sewage in groundwater and hydrogeological conditions are the primary governing factors in the nitrogen species based on the δ15n and δ18o evidence in the river basin liu et al 2017 the summer maize winter wheat rotation system is the typical cropping system in the drb simultaneously some vegetables and fruits are cultivated generally the farmers spread amounts of manure and use flooded irrigation systems in vegetable fields which are attributed to its shallow roots and its sensibility to water and nutrient intake however the residual fertilizer would get mixed with irrigation water and transfer into the groundwater systems in the form of surface runoff or seepage khan et al 2019 therefore the improper management of nitrogen fertilizer flood irrigation system excrement and domestic sewage water had led to the increased risk of groundwater pollution and posed a significant threat to the ecological environment especially for the groundwater samples belonging to clusters iv and vi 4 5 potential environmental problems and sustainable policy recommendations the study area has complex geographical circumstances containing mining agricultural and coastal areas from north to south intensive anthropogenic interventions and a severe groundwater environment xiong et al 2020 as mentioned above the potential environmental problems influencing the evolution of aqueous chemistry are mainly concentrated on the following two aspects 1 groundwater quality in the coastal areas is susceptible to deterioration due to its proximity to saltwater in combination with pumping activity and climate change 2 the application of chemical fertilizers and manure has been regarded as the important sources of groundwater contamination in the river basin to achieve sustainable development in the drb suitable policy recommendations are required for different regions in the coastal areas the abstraction and discharge of saline water should be strengthened to make sure that the regional groundwater can be renewed to fresh water additionally the use of nitrogen fertilizers and manure should be properly controlled to mitigate nitrate and nitrite contamination in the cultivated areas of the drb in order to alleviate nitrate leaching to soil water saving irrigation schemes also seem to be a necessary measurement moreover it is essential to implement the integrated management of surface water and groundwater to mitigate the contradictions between intensive water demands and geo environment restrictions 5 conclusions this study assessed the variations of groundwater quality and their potential controlling factors in a shallow groundwater system by som hydrogen and oxygen isotopic analysis hfe diagram cai values and correlation analysis results showed that the general cation abundance was ca2 na k mg2 and the dominant order for anions was hco3 so4 2 cl no3 no2 eight subgroups could be conclusively clustered associated with the local hydrogeochemical information and the component planes of ca2 mg2 cl and so4 2 or that of na k and hco3 had common patterns of the color gradient which indicated the dominance of water rock interactions and cation exchange in clusters i iii v and viii the significant correlations observed between ca2 cl ca2 so4 2 mg2 so4 2 and na k hco3 pairs also demonstrated these analytical results our findings highlighted that the long term evolution of hydrochemical signatures basically conformed to the trends of rising in the dry season and falling in the rainy season which demonstrated the influence of precipitation infiltration and evaporation these findings can also be confirmed by the results of stable isotope analysis moreover concentrated dexcess values revealed the primary vapor source of groundwater is from a low latitude ocean with high humidity on the other hand clusters iv and vi mainly distributed in the agricultural areas while cluster vii mainly scattered at the saline water intrusion transitional zones indicating that clusters with similar hydrochemical compositions are geographically nearby the common groundwater origins in summary natural factors precipitation evaporation mechanism seawater intrusion and rock weathering functions played vital roles in the samples belonging to clusters i iii v and vii viii while the samples of clusters iv and vi were mainly affected by anthropogenic interference it means that 72 of the groundwater samples represented the freshwater type and the unconfined aquifer beneath drb was experiencing freshening gradually even so the rest of samples were still affected by seawater intrusion and anthropogenic pollution which resulted in the higher concentrations of na and cl as well as no3 and no2 the analysis results of our study will give a deeper insight into groundwater hydrochemistry issues including geochemical variations on local or regional scales assessments and measurements of the vulnerability of shallow groundwater systems further research should focus on combining the som with other clustering algorithms to improve the ability of identifying the hydrochemical patterns and processes of groundwater in addition future studies should also explore the outcome of som in combination with multi level samplers that take into account the aquifers vertical stratification to have a more in depth knowledge of seawater intrusion problems it will be meaningful for groundwater quality monitoring network design and optimization of the local groundwater management strategies credit authorship contribution statement ziyue yin methodology software formal analysis writing original draft writing review editing qiankun luo writing original draft writing review editing jianfeng wu writing original draft writing review editing validation supervision project administration shaohui xu conceptualization investigation resources data curation supervision jichun wu supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is financially supported by the national key research and development program of china 2016yfc0402800 and 2019yfc1805302 the national natural science foundation of china 41772254 and the fundamental research funds for the central universities 14380105 the authors are also indebted to qingdao geo engineering exploration institute china and the key laboratory of water cycle and related surface processes institute of geographic sciences and natural resources research china for their support in hydrochemical and isotopic data analysis especially the authors are profoundly grateful to the editor prof huaming guo and the anonymous associate editor and four reviewers whose constructive comments led to significant improvement of the manuscript 
5030,a clear identification of the hydrochemical processes in groundwater systems is critical for the management and protection of alternative water resources the dagu river basin drb has become one of the most concerning areas due to the typical geographical conditions and intensive human disturbance in this study the spatio temporal variations of groundwater hydrochemical characteristics were discriminated based on the self organizing maps som clustering results from 2001 to 2017 simultaneously their main governing factors were also identified according to the composite properties of hydrogen and oxygen isotopic evidence hydrochemical facies evolution diagram hfe d chloro alkaline indices cai values and the enrichment of nitrogen analysis results indicated that the long term evolution of hydrochemical signatures basically conformed to the trends of rising in the dry season and falling in the rainy season total dissolved solids tds fluctuated from 187 90 mg l to 2294 81 mg l with an average of 881 77 mg l moreover the nitrate concentrations in the river basin varied significantly from 0 70 mg l to 605 32 mg l the unconfined aquifer beneath drb was experiencing freshening gradually while some other samples were still subjected to the interference of environmental pollution spatio temporal variations in the respective clusters demonstrated that natural factors including precipitation infiltration evaporation and water rock interactions played vital roles in the samples of clusters i iii v and viii while the samples of cluster vii were influenced by seawater intrusion and those of clusters iv and vi were mainly affected by nitrate and nitrite contamination this study suggests that the som connected with stable isotope analysis hfe diagram cai values and correlation analysis could be successfully used to interpret nonlinear and high dimensional multivariate systems and provide supplementary information about the dominant mechanisms controlling the regional groundwater evolution keywords groundwater hydrochemistry self organizing maps som long term variations governing factors 1 introduction as an essential part of water resources groundwater is crucial for drinking purposes agricultural irrigation and industrial uses choi et al 2014 lee et al 2019 long term evolution of groundwater quality plays a primordial role in understanding ongoing hydrochemical processes in watersheds and also provides essential hydrogeological background information for detailed evaluations into aquifer sustainability and the management of local groundwater resources ovalle et al 2013 gejl et al 2019 the scale and dimensionality of hydrochemical data increase dramatically owing to the long term groundwater monitoring which definitely pose challenges to the recognition and visualization of groundwater traits moreover it is necessary to find an effective dimension reduction technique that can evaluate a large number of groundwater quality data and provide legible visualization effects for decision making haselbeck et al 2019 both natural processes the mineralogy of aquifers topography rock weathering surface water recharge atmospheric precipitation and evaporation crystallization and anthropogenic pollution urban demands domestic uses agricultural and industrial activities can result in the diversification and complication of the hydrodynamic and hydrochemical fields of groundwater systems singh et al 2007 2014 swartjes and otte 2017 molinari et al 2019 it is still an important issue to investigate the main mechanisms governing the chemical compositions in complex shallow groundwater systems traditional multivariate statistical methods such as factor analysis fa jang 2010 busico et al 2020 cluster analysis ca abdullah et al 2015 zhang et al 2019 discriminant analysis da jang 2010 matiatos et al 2014 fuzzy c means fcm clustering algorithm güler and thyne 2004 and principal component analysis pca helena et al 2000 olsen et al 2012 zhang et al 2012 are available for the estimation of groundwater hydrochemistry evolution however the results acquired by these approaches are essentially mixtures of the dimensions they can only provide an initial direction to interpret the differences between the reference vectors sun et al 2009 li et al 2018 self organizing maps som is a powerful neural network model based on an unsupervised learning algorithm nakagawa et al 2020 som projects the input parameters from high dimensional space to low dimensional space where the data visualization of the output is implemented during the learning process wehrens and buydens 2007 ali hameed et al 2019 kim et al 2020 furthermore som can effectively capture the spatio temporal traits of nonlinear complex systems with less computational requirements nguyen et al 2015b 2015a chen et al 2018 in recent years som has been widely applied to achieve a better understanding of the hydrogeological processes in different regions such as heavily populated cities shi et al 2018 lee et al 2019 agricultural watersheds li et al 2019a jampani et al 2020 coastal areas löhr et al 2010 li et al 2018 and mining areas haselbeck et al 2019 based on short term groundwater quality monitoring data however how to identify the long term trends of regional groundwater hydrochemistry in complex systems especially for the hydrochemical components and their potential controlling factors has attracted relatively limited concerns so far the dagu river basin drb is located in the western area of jiaodong peninsula china which has become one of the most concerning areas due to the typical geographical conditions containing mining agricultural and coastal areas from north to south and intensive human activities with the rapid development of urbanization and the continuous improvement of people s living standards the quality and quantity of groundwater have become bottlenecks restricting the advance of drb previous investigations in this region were based on a limited volume of hydrochemical data which is quite inadequate for interpreting the long period evolution of groundwater quality and the potential controlling factors in the unconfined aquifers therefore the main purpose of this research is to identify the hydrochemical evolution and governing mechanisms of a groundwater system based on long term monitoring data through the following steps 1 to identify the groundwater quality data by som 2 to reveal the spatio temporal variations of groundwater hydrochemical features on a basin wide scale 3 to verify the natural and anthropogenic factors governing the hydrochemical compositions of groundwater and 4 to propose some suitable groundwater management plans for the policymakers the results obtained from the present study will be pragmatic in getting a deep insight into groundwater hydrochemistry issues ranging from geochemical variations on local or regional scales to the assessments and measurements of shallow groundwater system s vulnerability 2 data and methods 2 1 study area description the study area includes 2513 villages and has a population of 2 4 million lv et al 2013 the drb is located between longitudes 120 03 to 120 25 e and latitudes 36 10 to 37 12 n covering an area of 4781 km2 approximately 45 of the total area of qingdao city china fig 1 a xiong et al 2020 the mean temperature and annual average evaporation are 12 3 c and 983 86 mm respectively the mean annual precipitation mainly concentrated in the rainy season july to september is about 618 4 mm yin et al 2018 the land use data of drb are derived from the us landsat satellite remote sensing images with a resolution of 30 m in 2015 http www dsac cn landscapes are classified into seven types including farmland residential areas woodland grassland paddy fields waters and unused land of which 74 55 is cultivable land 2 2 geology and hydrogeology as shown in fig 1b quaternary sediments belonging to cenozoic are the primary geologic units in the river basin and the outcrops are mainly covered by mesozoic cretaceous and proterozoic metamorphic strata it is notable that northern hills are controlled by acid rock with some auriferous quartz veins consisting of some sulfide deposits and mining areas the hydrochemical facies in these regions are occupied by ca mg so4 and ca mg so4 hco3 types yin et al 2018 furthermore calcite dolomite kaolinite ca montmorillonite illite and feldspar are widely distributed in the saltwater freshwater transition zones of the drb chen and zheng 2015 precipitation is the main source of groundwater recharge in the drb and artificial abstraction is the main discharge the aquifer distributes along the dagu river 179 9 km in a strip shape with a thickness ranging from 10 m to 20 m lv et al 2013 and it presents a quaternary alluvial proluvial double layer structure the upper layer is comprised of weakly permeable clayey sand and sandy clay and clay is regionally scattered whereas the lower layer with a great capability of storing groundwater in the drb is composed of thick sand and gravel fig 1c xiong et al 2020 the depth to the water table in the unconfined aquifer is about 1 62 8 80 m with an average of 4 09 m the runoff is affected by topography lithology and other natural and anthropogenic factors of the study area followed by terrain downhill the shallow water moves from northwest to southeast and finally flows into jiaozhou bay liu et al 2019 2 3 hydrochemical data and pre processing ten major ions cl so4 2 hco3 no3 no2 f na k ca2 and mg2 ph and the total dissolved solids tds of 213 groundwater samples were collected from 17 monitoring bore wells by qingdao geo engineering exploration institute of china during 2001 to 2017 the samples were collected once per year spanning 2001 to 2017 except twice per year in 2013 and 2016 isotopic data δ2h and δ18o including 23 precipitation samples and 34 groundwater samples were also collected at 2 local domestic monitoring wells in a hydrological year from august 2016 to october 2017 fig 1a the samples were filtered with 0 45 μm membrane and then poured into 1 5 l high density polyethylene bottles which were flushed at least 3 times with the sample water all samples were stored in refrigerators with temperatures below 4 celsius c until the laboratory analysis major ions measurements were conducted in accordance with the chinese standard testing methods before 2011 na and k were determined using flame atomic absorption spectrometry while major ions ca2 mg2 and so4 2 were analyzed by edta 2na titration in addition cl and f were measured by silver nitrate titration and ion selective electrode respectively and ultraviolet spectrophotometry was used to analyze the contents of no3 and no2 after 2011 with the exception of hco3 major anions were analyzed by ion chromatography ics 2100 produced by thermo scientific dionex and major cations in groundwater samples were measured using ion chromatography 1 930 2360 produced by metrohm the detection limits of ion analyses reported during this monitoring period were 0 05 ppm hco3 concentrations were analyzed by phenolphthalein titration in the whole monitoring period then tds values were obtained based on the above analysis data as to stable isotope data both δ2h and δ18o were determined by liquid water isotope analyzer dlt 100 at the key laboratory of water cycle and related surface processes institute of geographic sciences and natural resources research china the analysis results were expressed by the vienna standard mean ocean water vsmow 0 with the analytical accuracy of 1 δ2h and 0 1 δ18o to evaluate the reliability of hydrochemical data percent charge balance errors cbe were calculated then 197 out of 213 samples with cbe 10 were used in our study during the long term monitoring process a small proportion of the monitoring datasets are discontinuous due to the disturbance induced by accidents such as dry damage borehole collapse and urban renewal in this study all units of groundwater quality data were measured in mg l except ph in order to prevent the heavier and higher charged ions from misleading the analysis result all data were converted into meq l haselbeck et al 2019 furthermore the som is strongly influenced by some variables with a larger scale and may result in significant distortion of the hydrochemical data therefore all parameters were normalized into dimensionless data between 0 and 1 to ensure that they have the same or similar importance in som analysis kiang 2001 nguyen et al 2015b 2015a lee et al 2019 2 4 self organizing maps som the som developed by kohonen 1982 is a powerful neural network model based on unsupervised learning algorithm which includes an input layer connected with an output layer by a weight kohonen 1982 ali hameed et al 2019 nakagawa et al 2020 the som methodology can project the d dimensional input data into a two dimensional hexagonal grid so that the topology preserving can be visualized intuitively kohonen 2013 chen et al 2018 note that d 11 in this study representing eleven types of input data cl so4 2 hco3 no3 no2 f na k ca2 mg2 ph and tds where na k is defined as the summation of the two cations na and k given the requirements of som for the pattern s accuracy and scale the map size or the number of output neurons is an important factor of its implementation li et al 2018 the optimal number m of output neurons can be determined by a heuristic rule e g m 5 n where n denotes the number of training samples n 197 in our study vesanto and alhoniemi 2000 vesanto et al 2000 based on this heuristic rule 70 cells were approximately the best map size in this study the self organizing maps toolbox 2 0 for matlab r2019a was applied to conduct and visualize the som http www cis hut fi projects somtoolbox there are four training steps of the sequential learning algorithm of som i e initialization competition adaption and iteration these steps can be briefly described as follows 1 to initialize the weight space with small random values meanwhile the map size starting winner neuron and initial learning rate are set in this preliminary step respectively 2 to find out the best matching unit bmu whose weight vector is most similar to the input vector 3 to update the weight vector of the bmu and its proximal neurons during the training progress the weight vector would approach the closest sample value lee et al 2019 and 4 to iterate the search procedure and converge to the best self organizing maps if a pre determined number of iterations reaches or the learning rate tends to be 0 this procedure will end otherwise it will return to step 2 according to vesanto et al 2000 the outputs of som are usually presented in the forms of unified distance matrix u matrix and component planes u matrix displays the euclidian distance between two neighborhood neurons and the subgroup boundaries which facilitates the interpretation of the determined clusters also component planes visualize the weight values of a hydrochemical variable in each neuron using a color gradient map units with higher values are highlighted in hot colors while units with lower values are in cool colors significantly cluster analysis is one that seeks to enhance the information of the map and the data based on classifying the similar neurons of som haselbeck et al 2019 here the k means clustering algorithm was applied to categorize the groundwater samples and the davies bouldin index dbi was implemented before the optimal number of clusters was obtained davies and bouldin 1979 the dbi can be expressed as 1 dbi 1 n i 1 i j n max σ i σ j d c i c j where n is the number of clusters σi σj are the mean distance of all patterns in cluster i j to the centroid ci and cj respectively d ci cj is the distance between ci and cj 3 results and analysis 3 1 hydrochemical and isotopic signatures the statistics of hydrochemical compositions of the drb are presented in table 1 the ph values varied from 5 5 to 8 5 with a mean of 7 5 implying that groundwater in the study area is generally to be neutral or weakly alkaline groundwater salinity expressed by tds fluctuated over a wide range 187 90 2294 81 mg l during the whole monitoring periods with an average of 881 77 mg l the order of mean cation contents was ca2 na k mg2 and the major anion dominance was hco3 so4 2 cl no3 no2 in the drb moreover significant variations of nitrate concentrations were observed in our results 0 70 mg l to 605 32 mg l the mean values of nitrate were 157 82 mg l and 125 99 mg l in the dry season and rainy season respectively furthermore the maximum values of nitrite were 15 00 mg l in the dry season and 1 80 mg l in the rainy season both of which exceeded the highest permissible limit 1 mg l according to the national standard for drinking water quality in china gb5749 2006 in terms of the isotopic indicators as shown in table 2 the stable isotope values in precipitation varied from 17 48 to 2 03 in δ18o mean value of 9 43 and from 135 65 to 1 70 in δ2h mean value of 67 97 the deuterium excess dexcess δ2h 8δ18o of precipitation ranged between 15 82 and 25 37 with a mean value of 7 47 by comparison the isotopic compositions of δ2h and δ18o of groundwater samples in the dry season ranged from 52 50 to 46 85 and from 7 73 to 6 75 with averages of 49 75 and 7 07 respectively while those in the rainy season were 52 72 to 49 87 and 7 71 to 6 56 with averages of 51 54 and 7 07 respectively moreover the dexcess of groundwater fluctuated between 0 63 and 10 53 of which the average is 6 08 3 2 som based results and hydrochemical characteristics of each cluster the variations of the dbi in the process of som clustering are illustrated in fig 2 and the front part between 0 and 20 clusters is magnified to display the minimum dbi value 8 clusters evidently to some extent it provides a better understanding of the subgroups information and the long term spatio temporal variations of groundwater hydrochemical features after som training the u matrix and component planes of 11 groundwater hydrochemical parameters are presented in fig 3 and the correlations between these parameters can be discerned apparently the neurons with high similarities i e short distances shown in blue can be regarded as a subgroup while the neurons with low similarities i e long distances shown in yellow can be regarded as another subgroup löhr et al 2010 lee et al 2019 kim et al 2020 it is shown that ca2 mg2 cl and so4 2 have common patterns of the color gradient of component planes in which the pronounced maximum values scatter at the bottom and decrease upward also tds is paralleled by this tendency the highest values of na k and hco3 distribute in the lower right areas and reduce towards the upper left direction nitrogen no3 and no2 show similar patterns with the highest values in the lower left corner of the som maps while the distribution of fluoride is the exactly opposite to characterize the clustered hydrogeochemistry data numerically the radar plots as shown in fig 4 depicts the minimum first quartile median third quartile and maximum of the 9 major ions respectively combined with fig 3 it is shown that all ion contents of cluster i 48 samples accounting for 24 of the total samples were relatively less than other clusters the order of mean cation concentrations in this cluster was ca2 90 58 mg l na k 67 51 mg l mg2 32 25 mg l while the major anion dominance was hco3 134 66 mg l so4 2 133 46 mg l no3 109 92 mg l cl 100 25 mg l cluster ii 39 samples belonging to fresh water the salinity expressed by tds is less than 1000 mg l owned relatively high values of ca2 and hco3 with the average values of 131 94 mg l and 272 34 mg l respectively in this study it was found that cluster iii 18 samples was defined by relatively high f concentrations and the contents of some samples even exceeded the maximum concentration level 1 mg l the dominant hydrochemical signature of cluster iv 29 samples was occupied by higher nitrate values while that of cluster vi 17 samples was characterized by higher contents of nitrate and nitrite in comparison with other clusters the possible reason is that anthropogenic interference results in the increasing risk of groundwater pollution and poses a great threat to the monitoring sites involved the enrichment of na k and hco3 in cluster v 18 samples and the dominance of na k hco3 and so4 2 in cluster viii 18 samples reflected that water rock interactions dissolution of silicate and evaporite play influential roles in the relevant clusters furthermore it was obvious that the highest concentrations of ca2 so4 2 cl no3 and tds distributed in cluster vii 10 samples and their maximum concentrations were 435 97 mg l 702 60 mg l 702 45 mg l 605 32 mg l and 2294 81 mg l respectively 3 3 temporal variations and spatial distributions in the respective clusters the spatio temporal variations of groundwater hydrochemistry based on the som clustering are shown in fig 5 over the past decade years the average annual precipitation in the basin was 607 30 mm almost 100 mm smaller than the average annual precipitation 716 64 mm between 2001 and 2008 to make a more reasonable analysis of the temporal variations of groundwater hydrochemical attributes the time series were classified into two stages 2001 2008 and 2009 2017 called stage i and stage ii respectively in this study based on the annual precipitation connected with the results obtained by fig 3 and fig 4 analyses revealed that the temporal evolution of clusters i ii and vii was inapparent while the relative higher fluoride values of cluster iii were generally from stage i there were respective 79 and 100 of samples belonging to clusters iv and vi from stage ii by comparison with the first time series stage i 2001 2008 implying that with the rapid promotion of intensified agriculture the contradiction between immense food demands and eco environment improvement has become a bottleneck restricting the development of drb in recent years simultaneously the effects of intensive water rock silicate and evaporite interactions which were possibly responsible for the dissolution of na k so4 2 and hco3 in amounts of samples belonging to clusters v and viii in stage ii as expected clusters with similar hydrochemical compositions were geographically nearby the common groundwater origins it can be seen in fig 5 that clusters i ii and v representing the freshwater type were observed not only in the upper and middle reaches but also in the lower reaches such as d 8 well location the presence of fresh water in the eastern lower reaches before 2012 suggested that seawater intrusion has no impact on groundwater far inland cluster iii with relative higher f values was primarily found at some middle and lower reaches in certain years therefore we should pay more attention to decrease the concentrations of f and avoid endemic fluorosis clusters iv and vi were mainly distributed in the middle reaches it may be attributed to groundwater runoff from cultivated fields that were treated with nitrogenous fertilizers and these regions are important grain production areas in qingdao city meanwhile the well u 1 was also predominated by no3 and no2 spanning 2013 to 2017 the samples belonging to clusters vii viii scattered at the saline water intrusion transitional zones influenced by jiaozhou bay partially the seawater intrusion on fresh water may be the reason for the presence of high concentrations of ca2 na k so4 2 and cl in the coastal areas 4 discussion based on the preliminary conclusions above as shown in fig 4 natural factors precipitation evaporation mechanism rock weathering functions and seawater intrusion played influential roles in the samples belonging to clusters i iii v and vii viii while anthropogenic pollution was crucial for the samples belonging to clusters iv and vi 4 1 precipitation infiltration and evaporation the dissolution of aerosols particulates and dust from the atmosphere is the primary origin of some meteoric water ions e g k ca2 mg2 so4 2 and hco3 which are the original inputs of the groundwater huang et al 2010 hydrogen and oxygen isotopic compositions of precipitation as the effective clues on the hydrological process are usually used to identify the potential recharge zones of groundwater and evaluate the sources sinks of contaminants presented in groundwater kumar et al 2018 in this study the slope and the intercept of the local meteoric water line lmwl δ2h 8 9δ18o 16 3 n 23 r 2 0 939 were both greater than that of the global meteoric water line gmwl δ2h 8δ18o 10 which are probably due to local climatic and hydrometeorological parameters such as the origin of the vapor mass li et al 2019b furthermore most of the groundwater samples locate below the gmwl and lmwl fig 6 indicating that the groundwater originates from precipitation infiltration δ2h and δ18o in groundwater distribute along the evaporation line with a slope of 2 9 δ2h 2 9δ18o 29 9 suggesting that they are affected by secondary evaporation to a certain degree before or during precipitation infiltration fu et al 2018 the deuterium excess has advantages in getting a deeper insight into the original source of water vapor and humidity at the vapor source areas hu et al 2018 globally the mean value of dexcess is 10 for precipitation when a water body undergoes evaporation it will decrease in different degrees huang and pang 2012 in comparison with the dispersed range of precipitation dexcess values from 15 82 to 25 37 groundwater is of a relatively concentrated range of dexcess values from 0 63 to 10 53 suggesting that the primary vapor source of groundwater is from low latitude ocean with high humidity besides the mean values of amounts of hydrochemical parameters except for na k and hco3 fluctuated with seasonal variations this result suggested that the infiltration of precipitation into phreatic aquifers in the rainy season could dilute the concentrations of major ions in the local groundwater systems and conduce to lower values of hydrochemical compositions shi et al 2018 hence precipitation infiltration and evaporation played crucial roles in the evolution of groundwater hydrochemistry based on the above findings 4 2 water rock interactions given the inherent uniqueness of geological conditions of different aquifers it is essential to know and identify the hydrochemical controlling factors under the influence of water rock interactions the water rock interactions contain ion exchange chemical weathering mineral adsorption and absorption shi et al 2018 these reaction processes are often significant at vastly different spatial and temporal scales although cumulative small scale factors can combine to primary effects on hydrochemical variations in this study the assessment of base ion exchange between the groundwater system and its host geo environment is illustrated by chloro alkaline indices cai values as formulated as follows 2 cai i cl na k cl 3 cai ii cl na k so 4 2 hco 3 no 3 if the cai values are positive it demonstrates the direct base ion exchange of na and k in the groundwater with the ca2 and mg2 in rocks otherwise it means that the exchange is inverse and indirect kumar et al 2018 jampani et al 2020 as shown in fig 7 the direct cation alternating adsorption was predominant in cluster vii the reason may be that the higher na and k concentrations in the groundwater system replace a part of ca2 and mg2 in the rock however the inverse ion exchange played a primary role in the other clusters accounting for 63 64 of the remaining samples which may be caused by precipitation infiltration and irrigation recharge originally the cations in the groundwater are dominated by ca2 and mg2 but after going through the silicate na and k feldspar the na and k in groundwater are increased correspondingly li et al 2019b as mentioned in section 3 2 either ca2 mg2 cl and so4 2 or na k and hco3 had common patterns of color gradient in the component planes which implied the correlations between the hydrochemical compositions furthermore correlation analysis is applied to identify similar origins of major ions and predict the dependency of one chemical constituent to another pant et al 2018 as shown in fig 8 a strong positive correlation was observed between na k and hco3 demonstrating that silicate na and k feldspar weathering is taking place in clusters v and viii monitoring regions winnick and maher 2018 however there were no significant correlations in the ca2 hco3 and mg2 hco3 pairs indicating that carbonate chemical weathering across the river basin is not very intense the ca2 so4 2 na k so4 2 and mg2 so4 2 pairs exhibited a significant correlation which suggested that these ions have similar origins and potentially relate to the dissolution of sulfide deposits or evaporite rocks deuerling et al 2018 additionally na k was obviously correlated with cl implying that the groundwater has an interaction with halite and the local lithological origins of na and k in recent years fluoride rich groundwater has drawn worldwide attention as the consumption of excessive fluoride in drinking water led to endemic fluorosis such as dental fluorosis and skeletal fluorosis chowdhury et al 2019 in the study area it also has been found that ca2 had significant negative relationships with f revealing that fluorite dissolution under high alkaline conditions possibly boosts up the leaching of f into groundwater especially in cluster iii kumar et al 2018 and the concentration of no3 showed a strong negative correlation with hco3 due to the occurrence of denitrification because the organic carbon is used as the electron donor accompanied with the production of co2 that increases the contents of hco3 in groundwater during the process of denitrification lee et al 2019 4 3 seawater intrusion si seawater intrusion si a great threat to fresh water stored in coastal aquifers contains many complicated physical and chemical processes such as hydrogeological characteristics dispersive mixing tidal effects density effects and human interference werner et al 2013 badaruddin et al 2015 the archetypal hydrochemical type of fresh water is ca hco3 while it of seawater is na cl kim et al 2017 na hco3 cl is the predominant hydrochemical facies in freshening aquifers in contrast ca na hco3 cl and na ca cl hco3 types are the most universal groundwater chemical types in the saline water intrusion transitional zones wang and jiao 2012 chandrajith et al 2016 si in the jiaohzhou bay is a focus of great concern and it is important to timely analyze the potential impacts on hydrogeochemistry and chemical weathering processes in the river basin hydrochemical facies evolution diagram hfe d established by giménez forcada 2010 is a new analysis tool that gives potential hydrochemical facies and evolution processes considering the percentage of the most important ions as well as their connections giménez forcada 2010 2014 giménez forcada and sánchez san román 2015 as shown in fig 9 rectangles filled in diverse colors refer to different hydrochemical types the sub stages from fre i to fre iv indicate the process of freshening while the sub stages from int i to int iv reveal the process of intrusion the results showed that more than half of the samples were projected on the upper right of the figure in which 12 18 of samples belonged to the mixca mixhco3 type furthermore almost all samples belonging to cluster v occupied by na k and hco3 and cluster viii occupied by na k hco3 and so4 2 were experiencing freshening gradually however cluster vii was scattered at the sub stages from int i to int iii suggesting the influence of si this result can also be confirmed by the higher na and k concentrations in the groundwater system which result in the direct cation alternating adsorption in cluster vii as mentioned in section 4 2 14 72 and 8 12 of groundwater samples were characterized by mixca mixcl and ca mixcl type respectively meanwhile 10 66 of samples were marked by ca mixhco3 these results implied that some fresh groundwater is susceptible to degradation due to its proximity to seawater and the intensive water demands that accompany with higher population densities however the trend of intrusion has been mitigating as a consequence of effective measures concerning the construction of cutoff walls and suitable management plans of groundwater resources in recent years 4 4 anthropogenic pollution nitrogen fertilizer in crop production vastly devotes to global food security as indispensable nutrients for the growth of plants however this can also lead to n losses to the environment which have adverse impacts on ecosystems and biodiversity such as eutrophication and harmful algae blooms in coastal areas wang et al 2018 according to the questionnaire survey conducted in 2009 it was found that nitrogen applications were various in different cropping systems in china the highest nitrogen is utilized to the fruits 550 381 kg hm2 followed by vegetables 383 263 kg hm2 maize 231 142 kg hm2 rice 209 140 kg hm2 and wheat 197 134 kg hm2 zhang et al 2013 because of the agricultural practices and the intensification of anthropogenic inputs the use of nitrogenous fertilizer has increased in the drb over recent years as mentioned in section 3 significant variations in nitrate values were observed in our results 0 70 to 605 32 mg l and higher contents of nitrogen were the predominant hydrochemical signatures in clusters iv and vi it is acknowledged that the major source of nitrate is a mixture of synthetic fertilizer and manure sewage in groundwater and hydrogeological conditions are the primary governing factors in the nitrogen species based on the δ15n and δ18o evidence in the river basin liu et al 2017 the summer maize winter wheat rotation system is the typical cropping system in the drb simultaneously some vegetables and fruits are cultivated generally the farmers spread amounts of manure and use flooded irrigation systems in vegetable fields which are attributed to its shallow roots and its sensibility to water and nutrient intake however the residual fertilizer would get mixed with irrigation water and transfer into the groundwater systems in the form of surface runoff or seepage khan et al 2019 therefore the improper management of nitrogen fertilizer flood irrigation system excrement and domestic sewage water had led to the increased risk of groundwater pollution and posed a significant threat to the ecological environment especially for the groundwater samples belonging to clusters iv and vi 4 5 potential environmental problems and sustainable policy recommendations the study area has complex geographical circumstances containing mining agricultural and coastal areas from north to south intensive anthropogenic interventions and a severe groundwater environment xiong et al 2020 as mentioned above the potential environmental problems influencing the evolution of aqueous chemistry are mainly concentrated on the following two aspects 1 groundwater quality in the coastal areas is susceptible to deterioration due to its proximity to saltwater in combination with pumping activity and climate change 2 the application of chemical fertilizers and manure has been regarded as the important sources of groundwater contamination in the river basin to achieve sustainable development in the drb suitable policy recommendations are required for different regions in the coastal areas the abstraction and discharge of saline water should be strengthened to make sure that the regional groundwater can be renewed to fresh water additionally the use of nitrogen fertilizers and manure should be properly controlled to mitigate nitrate and nitrite contamination in the cultivated areas of the drb in order to alleviate nitrate leaching to soil water saving irrigation schemes also seem to be a necessary measurement moreover it is essential to implement the integrated management of surface water and groundwater to mitigate the contradictions between intensive water demands and geo environment restrictions 5 conclusions this study assessed the variations of groundwater quality and their potential controlling factors in a shallow groundwater system by som hydrogen and oxygen isotopic analysis hfe diagram cai values and correlation analysis results showed that the general cation abundance was ca2 na k mg2 and the dominant order for anions was hco3 so4 2 cl no3 no2 eight subgroups could be conclusively clustered associated with the local hydrogeochemical information and the component planes of ca2 mg2 cl and so4 2 or that of na k and hco3 had common patterns of the color gradient which indicated the dominance of water rock interactions and cation exchange in clusters i iii v and viii the significant correlations observed between ca2 cl ca2 so4 2 mg2 so4 2 and na k hco3 pairs also demonstrated these analytical results our findings highlighted that the long term evolution of hydrochemical signatures basically conformed to the trends of rising in the dry season and falling in the rainy season which demonstrated the influence of precipitation infiltration and evaporation these findings can also be confirmed by the results of stable isotope analysis moreover concentrated dexcess values revealed the primary vapor source of groundwater is from a low latitude ocean with high humidity on the other hand clusters iv and vi mainly distributed in the agricultural areas while cluster vii mainly scattered at the saline water intrusion transitional zones indicating that clusters with similar hydrochemical compositions are geographically nearby the common groundwater origins in summary natural factors precipitation evaporation mechanism seawater intrusion and rock weathering functions played vital roles in the samples belonging to clusters i iii v and vii viii while the samples of clusters iv and vi were mainly affected by anthropogenic interference it means that 72 of the groundwater samples represented the freshwater type and the unconfined aquifer beneath drb was experiencing freshening gradually even so the rest of samples were still affected by seawater intrusion and anthropogenic pollution which resulted in the higher concentrations of na and cl as well as no3 and no2 the analysis results of our study will give a deeper insight into groundwater hydrochemistry issues including geochemical variations on local or regional scales assessments and measurements of the vulnerability of shallow groundwater systems further research should focus on combining the som with other clustering algorithms to improve the ability of identifying the hydrochemical patterns and processes of groundwater in addition future studies should also explore the outcome of som in combination with multi level samplers that take into account the aquifers vertical stratification to have a more in depth knowledge of seawater intrusion problems it will be meaningful for groundwater quality monitoring network design and optimization of the local groundwater management strategies credit authorship contribution statement ziyue yin methodology software formal analysis writing original draft writing review editing qiankun luo writing original draft writing review editing jianfeng wu writing original draft writing review editing validation supervision project administration shaohui xu conceptualization investigation resources data curation supervision jichun wu supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research is financially supported by the national key research and development program of china 2016yfc0402800 and 2019yfc1805302 the national natural science foundation of china 41772254 and the fundamental research funds for the central universities 14380105 the authors are also indebted to qingdao geo engineering exploration institute china and the key laboratory of water cycle and related surface processes institute of geographic sciences and natural resources research china for their support in hydrochemical and isotopic data analysis especially the authors are profoundly grateful to the editor prof huaming guo and the anonymous associate editor and four reviewers whose constructive comments led to significant improvement of the manuscript 
5031,flood inundation models are important tools in flood management commonly used flood inundation models such as hydrodynamic or simplified conceptual models are either computationally intensive or cannot simulate the temporal behavior of floods therefore emulation models based on data driven methods such as artificial neural networks anns have been developed however the performance of ann models like any other data driven models is limited by available data and will not perform well in data sparse regions in this study we developed an ann based hybrid modeling approach to improve model performance in data sparse regions by leveraging better model performance in data rich regions we applied our proposed hybrid modeling approach with three ann models including the traditional point based ann and two newly proposed block based ann models the results demonstrate that all three ann models have better performance in data rich regions compared to data sparse regions as expected with the block based ann with the most complicated model structure performing better in data rich regions and the simplest point based ann performing better in data sparse regions the hybrid modeling approach can significantly improve model performance in data sparse regions with the hybrid model based on the most complex block based ann performing the best our results show the importance of considering the trade offs between data availability and model complexity in developing data driven models and demonstrate the potential for improving performance in data sparse regions by using a hybrid modeling approach that optimizes model complexity based on data availability keywords hybrid models flood inundation models emulation models 1 introduction flooding has been recognized as one of the most frequent and destructive natural hazards in the world freer et al 2013 razavi et al 2020 however flooding can also be beneficial as they support ecosystems especially in arid areas teng et al 2017 bond et al 2014 due to both the negative and positive impacts of floods it is of significant importance to understand simulate predict and assess floods and risks teng et al 2017 many tools have been developed to improve flood management including hydrological models and flood inundation models i e hydraulic models huang and hattermann 2018 unduche et al 2018 verwey et al 2017 zischg et al 2018 emerton et al 2016 yang et al 2004 among these models flood inundation models are often used for flood risk analysis bhuiyan and dutta 2012 dutta et al 2006 real time forecasting for emergency planning chang et al 2018 and flood impact evaluation within water resources management vaze et al 2013 due to their capability in simulating flood inundation extent and depth with time which are directly related to flood impact apel et al 2006 hammond et al 2015 commonly used flood inundation models can be broadly divided into three categories empirical models hydrodynamic models and simplified conceptual models teng et al 2017 empirical models are based on observed data such as historical records surveys remote sensing data or experiment data o connor and costa 2004 schumann et al 2009 smith 1997 these methods use the observations in the most direct way and have been widely used together with other models to assist decision making archer et al 2018 schumann et al 2009 teng et al 2017 however these methods are restricted by their coarse spatial and temporal resolutions due to the limited number of data collection locations e g stream gauge locations and the long intervals between successive satellite data acquisition schumann et al 2009 hydrodynamic models simulate water movement by solving the equations which govern the physical processes involved and they are therefore the most widely used models for estimating flood inundation hydrodynamic models can be divided into one dimensional 1d two dimensional 2d and three dimensional 3d models according to their spatial dimensions casulli and stelling 1998 teng et al 2017 in general 1d models are based on the assumption that the flow is one dimensional along the river channel and therefore they are computationally efficient but cannot easily simulate flood inundation across floodplains brunner 2016 sen and garg 2002 2d models on the other hand simulate the flow across a 2d surface and can represent lateral flood movement across the floodplain well archer et al 2018 neal et al 2012 therefore they are commonly used for flood inundation modeling despite their high computational burden 3d models which represent vertical as well as horizontal flow behavior are more computational demanding than 2d hydrodynamic models and are mainly used to simulate complicated flood situations prakash et al 2014 in addition 1d 2d coupled models have also been used in recent years to take advantages of their strength in modeling river channels and floodplains respectively leandro et al 2009 liu et al 2015 although both 2d and 1d 2d coupled models are commonly used for food inundation modeling they are computationally expensive which prevents their use in applications requiring rapid model response e g real time forecasting or a large number of model runs e g uncertainty analysis teng et al 2017 in order to improve the computational efficiency of flood inundation modeling simplified conceptual models have been developed as an alternative approach mcgrath et al 2018 teng et al 2017 commonly used simplified conceptual models include the rapid flood spreading method lhomme et al 2008 the vtd model teng et al 2015 2019 and the height above the nearest drainage model mcgrath et al 2018 nobre et al 2011 these models do not simulate the dynamic process of water movement and therefore are very fast however as they are not physically based they have limited capacity to simulate the dynamic process of water movement and are therefore often used to merely estimate the maximum flood inundation of specific flood events teng et al 2017 consequently there is a need to develop a fast and accurate flood inundation modeling approach that takes advantage of physically based simulations of flood depth and extent one promising approach for fast flood inundation modeling is to use data driven methods to develop emulation or surrogate models to directly simulate flood input output relationships without explicitly representing the underlining physical process artificial neural network ann models are one of the most widely used emulation models in environmental modelling bermúdez et al 2018 rogers et al 1995 shrestha et al 2009 sreekanth and datta 2011 more recently the use of ann models has been extended to simulating flood inundation chang et al 2018 chu et al 2020 where the authors have found that ann based emulation models can significantly improve modeling efficiency compared to 2d hydrodynamic models a number of challenges of using ann models to simulate flood inundation have also been identified including the poor performance in data sparse regions and the difficulty in handling time series information without introducing a large number of parameters e g using deep learning techniques like any data driven models the performance of anns is limited by the information contained in data used for model calibration and therefore will not perform well in data sparse regions in addition in traditional anns the time series information in inputs e g inflow for flood inundation modeling is often represented using lagged data with one data point representing the input output relationship between the lagged inputs selected during the input selection process and the output at a specific snapshot in time therefore the continuity of the original time series information is not fully represented in the training process in this study we 1 proposed a hybrid modeling approach to improve the performance of ann models in data sparse regions by leveraging valuable information in data rich regions 2 applied this hybrid modeling approach with three different ann models including two block based anns which have improved representation of time series information in ann models without significantly increasing model complexity and 3 demonstrated the application of the hybrid modeling approach with the three ann models to flood inundation modeling using a real world system and compared the performance to an ann only approach the remainder of this paper is organized as follows the proposed ann based hybrid modeling approach and the block based ann models are introduced in section 2 and 3 respectively in section 4 the case study is introduced and the detailed model development process is also described both the simulation and comparison results are presented and discussed in section 5 finally the conclusions are summarized in section 6 2 ann based hybrid modeling approach 2 1 ann based hybrid modeling framework hybrid models refer to a class group of models which integrate the advantages of different individual models and are regarded as useful tools to capture the complex nature of a real world system kelly et al 2013 maier et al 2010 mount et al 2016 they have been widely used in environmental modeling including synthetic streamflow generation ochoa rivera et al 2002 streamflow forecasting chetan and sudheer 2006 wang et al 2006 rainfall runoff modeling mekonnen et al 2015 nayak et al 2007 water quality assessment lin et al 2008 and salinity prediction hunter et al 2018 in most of these studies a model technique intensive approach maier et al 2010 was used where different models techniques were used to simulate different components processes of an environmental system to take the advantages of these different models techniques for example mekonnen et al 2015 employed a hybrid model for unconventional runoff generation in the prairie region where the different components of the runoff were modelled by the swat and ann models respectively humphrey et al 2016 integrated soil moisture simulated using the gr4j conceptual rainfall runoff model into a bayesian ann model for monthly streamflow forecasts more recently hunter et al 2018 presented a hybrid modeling framework for salinity modeling in river systems where the different sub processes of salt transport in a river system were modelled using different methods alternatively a data intensive approach maier et al 2010 can be used to develop hybrid models where data are first divided into different clusters based on their statistical properties and a model is developed for each cluster for example wang et al 2006 divided the daily streamflow data into different groups based on flow regimes and then built different ann models for different groups chang et al 2010 employed a clustering based hybrid model for flood inundation modeling where the data were classified using the k means clustering methods based on statistical properties and then different models were built for each clusters however in these data intensive hybrid models model performance in data sparse regions is still limited by data availability in these regions therefore in this study we proposed an ann based hybrid modeling approach to address this challenge by considering the inherent relationships between different regions with varying data availability in an environmental system based on the identified relationships between regions with different data availability model performance in data sparse regions can be improved by leveraging the information contained in the data in data rich regions the proposed hybrid modeling approach including three stages is given in fig 1 in stage ⅰ the environmental system under consideration is divided into different regions according to data availability in this case 1 data sparse regions with limited data and 2 data rich regions with sufficient data in stage ⅱ anns are directly employed to model the input output relationships in data rich regions as in these regions data are sufficient for establishing ann models with good performance hunter et al 2018 mosavi et al 2018 mount et al 2016 in stage iii the inherent relationship between the data sparse and data rich regions are first established then the predictions in the data sparse regions are made based on predictions obtained from the ann models developed for data rich regions thus a hybrid modeling approach is used to produce predictions in data sparse regions by leveraging sufficient information in data rich regions 2 2 ann based hybrid modeling approach applied to flood inundation modeling in this study the hybrid modeling approach presented in fig 1 is applied to simulate flood inundation with time for flood inundation modeling the river channel is considered to be data rich as it is always inundated and therefore there are large amount of data available on the other hand floodplains are considered to be data sparse regions as they are only inundated when floodwater overtops riverbanks i e in relatively large flood events the inherent relationships between flood levels in the data rich river channels and data sparse floodplains can easily be established by considering the overtopping threshold water levels above which the floodplains will be inundated these relationships can be represented using a rectified linear unit relu which is commonly used in deep learning for improving the computational efficiency and model performance dahl et al 2013 nair and hinton 2010 shang et al 2016 and can be expressed using the following equation 1 d ds r e l u d dr t h m a x d dr t h 0 where d dr and d ds are predicted inundation depth in the data rich and data sparse regions respectively and th is an inundation depth threshold value in the data rich region i e river channel above which the data sparse region i e floodplains will start to be inundated 3 block based artificial neural networks it has been recognized that traditional anns such as multilayer perceptrons mlps have difficulties in handling time series information chu et al 2020 coulibaly and baldwin 2005 kratzert et al 2018 some deep learning techniques such as recurrent neural networks rnns have been developed to address this challenge coulibaly and baldwin 2005 le et al 2019 ye et al 2019 however the deep learning techniques often have a large number of parameters e g hundreds or thousands greff et al 2016 which require a large amount of data to support their development reichstein et al 2019 wang et al 2018 and their performance can be reduced significantly if there are insufficient data for model calibration chauhan et al 2019 pasupa and sunhem 2016 environmental systems often have limited data neal et al 2012 samaniego et al 2011 tramblay et al 2014 which will limit the application of deep learning techniques therefore a simple method the block based ann is introduced in this study to improve the way time series information is handled in traditional mlps it should be noted that in the proposed block based anns the block structure refers to a combination of consecutive observations in a time series ebtehaj et al 2010 not a combination of different layers in neural networks that is often referred to in deep learning greff et al 2016 targ et al 2016 zhang et al 2017 the proposed block based anns referred to as mb models are an integration of the block structure described above and the traditional point based anns i e mlps referred to as mp models during model calibration as shown in fig 2 in the figure b t and b t 1 refer to two blocks with starting time steps t and t 1 respectively and p t and p t 1 refer to two data points at time steps t and t 1 respectively xa represents autoregressive input variables which are the values of the output variable at previous time steps such as previous water depth for a flood system xe represents exogenous input variables which are variables representing external driving mechanisms having a direct impact on the output variable such as inflows for a flood system in fig 2 x a t and x e t refer to all autoregressive inputs e g current and previous water depth and exogenous inputs e g current and previous inflow selected at time t respectively for the traditional point based anns the model is trained based on each data point e g p t and p t 1 included in the dashed boxes in fig 2a for block based anns however a point based ann is repeatedly applied h times across a block of data with a block length of h e g b t and b t 1 included in the solid boxes in fig 2b where h is often the forecasting horizon in other words model parameter values are updated based on errors estimated across the entire block of data during the model calibration process for block based anns as opposed to being estimated based on a single data point for point based anns thus p t for point based anns is equivalent to b t for block based anns in block based anns there are various ways to estimate modal errors across the block to update model parameter values in this study two different ways for estimating errors across the blocks are investigated the resulting block based ann models are referred to as mb1 and mb2 respectively for mb1 the ann model parameters are updated based on the errors estimated in the first time step in the block i e for predicting y t 1 then the same model parameters are applied to the remaining time steps within the block i e for predicting y t 2 to y t h this way the errors in the first time step of the block structure is always minimized during model calibration in the mb1 model for mb2 the errors propagate through the block of length h and the final error at time step t h is used to update the model parameters in the model calibration process this way the final error at the end of each block is always minimized during model calibration in the mb2 model in other words given the same number of model parameters the mb2 model has the most complicated model structure followed by the mb1 model and the mp model has the simplest model structure 4 case study data and model development process 4 1 case study and data the performance of the ann based hybrid modeling approach and the block based ann was examined using a real world system the burnett river in queensland australia the river system is shown in fig 3 the river generally flows from southwest to northeast and enters the coral sea at burnett heads there is a dam paradise dam on the main stream of the river which is located approximately 100 km by road west of bundaberg fig 3a the burnett river has a catchment area of roughly 30 500 km2 upstream the paradise dam and a catchment area of 2 500 km2 downstream the dam the land use downstream of the dam mainly includes agriculture native grazing vegetation and some native forests a 2d hydrodynamic model was developed for the downstream area of paradise dam using the tuflow modeling suite huxley and syme 2016 the boundary conditions for the model include outflows from the paradise dam and the tidal levels at burnett heads flood inundation data generated using tuflow is available for ten flood events including seven design events ranging from 1 300 annual exceedance probability aep to the probable maximum flood pmf and three historical events i e the 1971 2010 and 2013 data from the 2013 historical event has a relatively short simulation period which is not suitable for the development of the block based anns and are therefore not used in this study flood information is available in terms of exogenous variables xe i e flows q from paradise dam at 15 minutes intervals and autoregressive variables xa i e flood inundation depth d within the model domain at one or two hour intervals for the development of the ann models all data were converted into hourly data using either the maximum value within one hour for flow or linear interpolation for water depth to account for the temporal relationships between the input and output variables lagged input variables are generated a maximum time lag of 15 h was used in this study based on travel time identified for the system in a previous study chu et al 2020 therefore the potential exogenous inputs variables at time t are q t 15 q t 14 q t and the potential autoregressive inputs variables at time t consists of d t 15 d t 14 d t 4 2 experiment setup for the purpose of this study an area of 2720 m 2860 m downstream the paradise dam is selected this area is represented by 19 448 20 m 20 m grid cells in the tuflow model during all nine flood events used 5 170 out of the 19 448 cells i e 26 6 of cells in the model domain are never inundated therefore in total 14 278 models are developed with one model used to estimate flood depths in one grid cell a forecast horizon h of 8 h is used in this study as this represents the travel time of flows between paradise dam and the study area as determined by chu et al 2020 the elevation of the study area is shown in fig 3b as described in section 2 the study area is divided into the river channel i e data rich region and the floodplain i e data sparse region considering the differences among different floodplain cells with varying data availability the floodplain is further classified into two zones based on elevation data the three zones are shown in fig 3c zone z1 is the river channel zone z2 is the low lying floodplain with less data i e flooded approximately half of the time and zone z3 is the floodplain with relatively higher elevations and very limited data i e flooded less than 30 of the time in this study both the ann only modeling approach and the ann based hybrid modeling approach are employed evaluated and compared as shown in fig 4 for the ann only modeling approach anns are developed for both the river channel i e zone z1 and the floodplains i e zones z2 and z3 to differently map the relationship between inflow and flood inundation levels for the ann based hybrid modeling approach anns are firstly developed in the river channel to map the input output relationships and then the relu is used to predict flood inundation levels on floodplains based on flood inundation levels in the river channel simulated using anns it should be noted that three ann model are used including two block based anns i e mb1 and mb2 and one traditional point based ann i e mp as described previously for the ann based hybrid modeling approach the threshold value th is defined as the inundation depth difference between the data sparse grid cell and a corresponding data rich grid cell in the river channel at the commencement of inundation in the data sparse grid cell therefore the threshold value th is grid cell dependent for each grid cell in the data sparse region its corresponding data rich grid cell is identified as the river channel grid cell that has the lowest estimation error when used to simulate flood levels in the data sparse grid cell based on eq 1 over calibration data 4 3 ann model development process the development of the three ann models i e mb1 mb2 and mp models follows recommendations by wu et al 2014 there are five major steps including input selection data splitting architecture and structure selection model calibration and model validation the details of these steps are described below 4 3 1 input selection input selection plays an important role in data driven modeling as there are often many potential input variables and not all of them contain critical information for model development an appropriate input variable set will improve model accuracy and prevent unnecessary model complexity bowden et al 2005 hejazi and cai 2009 in many input selection methods may et al 2011 quilty et al 2016 partial mutual information pmi which can evaluate both nonlinear dependency and redundancy between input and output variables is one of the most widely used methods to evaluate candidate models darudi et al 2013 fernando et al 2009 2005 may et al 2006 2008a 2008b sharma 2000 therefore pmi was also used in this study in order to make sure the input selection process can be carried out within a desired time frame two efficient stopping criteria i e the tabulated critical value based and aic based criteria were selected among all of the stopping criteria introduced by may et al 2008b 4 3 2 data splitting data splitting is an important step in ann modeling process through which the available data are divided into training test and validation sets maier et al 2010 in general the training and test set are used to train the model and determine when to stop training respectively maier et al 2010 the validation set is used to assess if the model can be used for its intended purposes humphrey et al 2017 considering that there are overlapping sections among different blocks the leave one out cross validation method bennett et al 2013 where one entire flood event is withheld from the model calibration process was used in this study to evaluate the performance of developed models for this study the leave one out cross validation approach was applied three times with one flood event being left out of the model calibration process each time the three flood events used in the cross validation process are the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood then a data splitting method was only used to split the data from the other flood events into the training and test datasets among many data splitting methods may et al 2010 sahoo et al 2012 snee 1977 wu et al 2012 2013 the duplex method developed by snee 1977 has been recommended in previous studies may et al 2010 wu et al 2014 therefore the duplex method is selected in this study to split calibration data into 75 for training and 25 for test the details of the duplex method can be found in the study by may et al 2010 4 3 3 architecture and structure selection the architecture of ann determines the model structure and significantly affects function estimation of the input output relationships maier et al 2010 in all ann architectures the three layer mlp is the most widely used for environmental systems due to their simple structure and less data requirement maier et al 2010 razavi and tolson 2011 wu et al 2014 and therefore is used in this study as discussed previously for an mlp the number of input nodes and output nodes are determined by the number of inputs and outputs respectively the number of hidden nodes determines the structure of mlp and needs to be determined during model calibration there are many methods to determine the optimal number of hidden nodes and these methods can be broadly divided into three groups global stepwise and ad hoc maier et al 2010 trial and error is a commonly used method for selecting model structure and was also used in this study to optimize the number of hidden nodes between a minimum number of 2 and a maximum number of 11 which were determined based on data availability 4 3 4 model calibration model calibration is used to find the optimal model parameters so that a model can represent the relationships between inputs and outputs maier et al 2010 wu et al 2014 there are generally two types of methods for ann model calibration 1 local optimization algorithms such as commonly used back propagation methods and newton s methods maier and dandy 1999 2000 rumelhart et al 1988 and 2 global optimization methods such as genetic algorithms sahoo et al 2009 generally local optimization algorithms are more computationally efficient considering the large number of models that will be developed in this study see section 4 2 a local optimization algorithm the levenberg marquardt algorithm lma levenberg 1944 was used lma can be regarded as a combination of the steepest descent and the gauss newton methods lourakis 2005 the details of lma can be found in madsen et al 1999 in order to increase the chance of finding the optimal parameter values four different sets of randomly generated initial weights were used for each number of hidden nodes considered in the calibration process 4 3 5 model validation model validation is an important process in the modeling process and it is used to assess the performance of the developed model over an independent dataset and make sure the model can be used for intended purposes with confidence humphrey et al 2017 according to the recommendations given by humphrey et al 2017 and wu et al 2014 three aspects of model validity need to be considered when validating data driven models such as anns namely 1 replicative validity which is the ability of a model to capture the underlying input to output relationships included in calibration data gass 1983 power 1993 2 structural validity which refers to how well a model explains the underlying physical processes of the system being simulated biondi et al 2012 kingston et al 2006 and 3 predictive validity which is how well a model performances in terms of its predictive ability over an unseen dataset the predictive validity is considered the most important as ultimately the models are developed for applications to events not considered in model development for this reason we focus on the predictive validation in the discussion of this paper the methods and results for replicative validation and structural validation are presented in the appendix three commonly used metrics were used in this study to assess predictive validity 1 root mean square error rmse which measures the agreement between observed and predicted data in real units 2 relative root mean square error rrmse which measures the relative error and 3 nash sutcliffe model efficiency coefficient nse which compares the model with a simple model that make predictions by averaging observed data these three metrics can be calculated according to the following equations 2 rmse 1 n i 1 n y i y i 2 0 3 rrmse rmse 1 n i 1 n y i 0 4 nse 1 i 1 n y i y i 2 i 1 n y i 1 n i 1 n y i 2 1 where n is the number of data y is the observed data and y is the predicted data in addition flood inundation extent obtained using the ann models developed was compared to that simulated using the tuflow model cell by cell to further evaluate the consistency between ann models and the tuflow model the cells were categorized into three groups 1 hits which mean the cells were inundated for both ann and tuflow models 2 misses which mean the cells were inundated for the tuflow model but not inundated for the ann models and 3 false alarms which mean the cells are inundated for the ann models but not inundated for the tuflow model hunter 2005 mcgrath et al 2018 the probability of detection pod and false alarm ratio far were also calculated according to the following equations 5 pod n hits n hits n misses 6 far n falsealarms n hits n falsealarms where n hits n misses and n falsealarms represent the number of cells in three groups respectively 5 results and discussion the results of the ann only modeling approach and the ann based hybrid modeling approach are presented and compared in terms of their predictive performance in this section in addition the three anns i e the block based mb1 mb2 and the point based mp are also compared in this section the results from the ann only and the hybrid modelling approaches are presented in sections 5 1 and 5 2 respectively model comparison results are discussed in section 5 3 5 1 predictive performance of the ann only approach the cross validated predictive performance i e across the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events combined see section 4 3 2 above of the ann only models i e mb1 mb2 and mp were first examined using the root mean square error rmse relative root mean square error rrmse and nash sutcliffe model efficiency coefficient nse obtained over the validation data as shown in fig 5 it can be seen from fig 5a 5c that rmses in the river channel i e z1 are larger than those on the floodplains i e z2 and z3 however the rrmses on the floodplains are greater than those in the river channel see fig 5d 5f this is because the mean water depths in the river channel are significantly greater than those on the floodplains it is also evident that all three models performed worse on the floodplain with higher elevations i e z3 where rrmses are greater than or equal to 0 5 this is also supported by the nse results obtained in these regions where the nse values can be near or below 0 for the boundary regions between the dry and wet conditions fig 5g 5i this is mainly due to the sparse data in these regions which are not sufficient to support the complex structure of ann models however for the majority of the study area the nse values are above 0 8 or near 1 which indicates good performance of the models the maximum flood inundation extent the probability of detection pod and the false alarm ratio far for each of the three cross validation events are shown in fig 6 as can be seen from the figure all three anns i e mb1 mb2 and mp can detect most inundated cells with pods greater than 95 for the 1 500 aep flood event ann models approximate the flood extent well in the river channel but mb2 overestimates water depths of some cells on the floodplain see the regions in yellow in fig 6b for the 1 12 100 aep flood event it is evident that the two block based anns overestimate the flood extent in zone z3 where the elevations are relatively higher fig 6d and 6e for the most extreme 1 33 000 aep flood event considered in cross validation however all three ann models approximate the flood extent well with the pods being close to 100 and the fars being close to 0 fig 6g 6i the worse performance of the ann models in terms of the maximum flood inundation extent in zone z3 for the 1 12 100 aep event compared to the other two events is mainly due to the fact that zone z3 is a transitional zone between dry and wet conditions for the 1 12 100 event and anns tend to over estimate flood in these regions as found in previous studies chu et al 2020 in summary all three ann only models performed reasonably well in terms of predictive performance in the data rich river channel however the predictive performance of all three models deteriorated across floodplains with limited data especially in zone z3 where the elevations are relatively higher i e the transitional regions of dry and wet conditions and therefore there are even less data available for model development 5 2 predictive performance of the ann based hybrid approach in order to improve the model performance across the data sparse floodplains the ann based hybrid modeling approach described in section 2 was used in the hybrid modeling approach the three anns are used to predict water depth in the river channel based on which the relu is used to predict water depth on the floodplain the cross validation results i e rmse rrmse and nse with the hybrid modeling approach are shown in fig 7 as can be seen from this figure the hybrid modeling approach has mixed impact on the predictive performance of the emulation models across the floodplains compared to fig 5 above in zone z3 i e the transitional regions of the dry and wet conditions on the northern side of the river the ann based hybrid modeling approach has significantly improved predictive performance compared with the ann only approach this is most evident for the relative error rrmse fig 7d 7f where the yellow regions indicating higher relative errors in zone z3 are significantly reduced in area however the hybrid modeling approach makes the predictive performance worse on floodplains with relatively lower elevations i e zone z2 compared with the ann only modeling approach this result indicates that in these low lying floodplain regions i e z2 the data available still contain relatively sufficient information to support the development of ann models and therefore it is better to directly simulate flood inundation based on the inflow and flood level relationship contained in the data using ann models similar results are obtained for the maximum flood extent the probability of detection pod and the false alarm ratio far for each of the three cross validation events as shown in fig 8 as can be seen from this figure compared to fig 6 above for the 1 12 100 aep flood the hybrid modeling approach significantly improve the poor performance in the zone z3 with relatively higher elevations which can be seen from the disappearance of the yellow regions and the decreasing far values fig 8d and 8e it should also be noted that the deteriorated performance of the hybrid modeling approach on the low lying floodplains which can be seen in previous discussion cannot be observed in terms of the maximum flood extent shown in fig 8 for the ann based hybrid modeling approach the additional parameter th i e the threshold value in eq 1 may have an impact on the predictive performance of the models therefore a sensitivity analysis of the threshold value th was conducted by examining the changes in rmses when varying the threshold values by adding a noise term the details of the sensitivity analysis are included in the appendix and the results are included in the supplementary material fig s5 the results demonstrate that the value of the threshold has varying impacts on the performance of the hybrid modeling approach in different zones in general the threshold value has a higher impact on the predictive performance of the hybrid modeling approach on floodplains with relatively lower elevations zone z2 compared to on floodplains with relatively higher elevations zone z3 within zone z2 especially on the southern side of the river channel the increase in the threshold values can result in significant increase of the rmses this highlights the importance of identifying appropriate threshold values when applying the hybrid modeling approach especially on floodplains with relatively lower elevations 5 3 model comparison as can be seen in previous sections both the ann only models and the ann based hybrid models have significantly different predictive performance in different regions of the study area therefore further analysis was conducted to compare the performance of the models in three different zones presented in fig 3c the predictive performance of the three ann only models i e the block based anns mb1 and mb2 and the point based ann mp and three ann based hybrid models i e the mb1 based mb2 based and mp based hybrid models in terms of the rmse is illustrated in fig 9 in fig 9 the y axis in each plot shows the values of the rmse and the axis shows the number of cells with rmse below specific values it should be noted that the hybrid modeling approach was only applied to floodplains i e zones z2 and z3 and are shown in the figure using dashed lines fig 9b and 9c 5 3 1 the comparison among three ann only models it is evident from fig 9 that the performance of the two block based and the point based ann models vary significantly across different regions in the study area as can be seen from fig 9a the block based mb2 model performed the best in zone z1 i e the river channel followed by the point based mp model while the block based mb1 model where model parameters were updated based on error in the first time step of the block produced the highest cumulative rmses in the river channel in zone z2 which is the low lying floodplain the mb1 mb2 and mp models have very similar predictive performance in terms of cumulative rmses the solid lines in fig 9b in zone z3 on the floodplains with relatively higher elevations however the point based ann model mp had the best performance i e the solid black line in fig 9c although all three ann only models performed poorly in zone z3 compared to zones z1 and z2 the reason for the different predictive performance of the three ann only models in different zones is related to data availability and the different model structures used as described in sections 3 and 4 the block based anns include eight mlps applied consecutively over eight data points contained in a block structure which makes it more complex than the point based ann which only includes one mlp structure applied to one data point during training the complex block structure enables the block based anns to better extract time series information contained in the block during model training however this also means that the block based anns need more data for model calibration therefore in the data rich region i e zone z1 river channel the mb2 model can be calibrated well and outperformed the point based mp model in the data sparse region i e zone z3 high floodplains the data available are not sufficient for the calibration of anns and thus all three models performed poorly and the point based mp had relatively better performance due to its simpler model structure in the regions with intermediate data availability i e zone z2 low lying floodplains all three ann models had very similar performance although the block based anns can generally extract more time series information from the training data it can also be seen from fig 9a that there is a significant difference between the mb1 and mb2 models and the mb1 model performed worse in the river channel i e zone z1 compared to the mb2 model and even the point based mp model the reason is that the mb1 model is trained based on error estimated in the first time step in the block structure and the cumulative error across the block is therefore greater than that of the mb2 model which is trained according to the cumulative error at the final time step of the block 5 3 2 the comparison between the hybrid modeling approach and the ann only modeling approach the hybrid modeling approach performed differently across the floodplains with different elevations although the point based ann model mp performed better in zone z3 the hybrid model based on the block based ann model mb2 outperformed the other two models in zone z3 see the dashed red line in fig 9c this improved predictive performance of the mb2 based hybrid model in zone z3 is directly related to the model performance in the river channel based on which the hybrid model was established as discussed above the mb2 model has the best predictive validation performance in the river channel i e zone z1 see fig 9a which led to better predictive results in zone z3 with the hybrid model compared to the other two hybrid models it should be noted that the hybrid models only improved predictive performance of the models in zone z3 where the floodplains have relatively higher elevations see fig 9c and the predictive performance with hybrid models deteriorated in zone z2 i e the low lying floodplains with intermediate data availability see fig 9b these results can be explained by the trade offs between model complexity and data availability the ann based hybrid models used in this study is indeed a linear function relu based on the predicted water depths in the river channel and only the relu is calibrated according to the limited data in the data sparse regions i e floodplains therefore the ann based hybrid models have simpler structures than the nonlinear anns on the floodplain in zone z3 the available flood data are not sufficient to support ann model development however the data are sufficient to calibrate the relu and therefore the ann based hybrid models can improve the prediction by leveraging the good predictive performance of anns in the data rich regions i e the river channel however the advantages of the hybrid models are lost in regions with more data such as the low lying floodplains i e zone z2 where better predictive performance can be achieved by directly mapping the input output relationships using anns while in the data rich region i e river channel the block based ann model mb2 performed better compared to the traditional point based ann model mp due to the improved ability of the block structure to better represent the time series information in training data this finding highlights the importance of considering data availability in model selection when developing data driven models without sufficient supporting data there is no point of using a complex model as a simpler model may perform better in addition the results demonstrate the potential to improve performance in data sparse regions by using a hybrid modeling approach which provides a more flexible way to cater for different data quantity in data driven model development 6 conclusions in this study an ann based hybrid modeling approach is developed to improve the model performance in data sparse regions by leveraging valuable information in data rich regions this hybrid modeling approach was applied to three ann models including two newly proposed block based anns which have improved representation of time series information in model development without significantly increasing model complexity the performance of the ann based hybrid modeling approach was compared to that of the ann only modeling approach via a real world case study in australia in addition the two newly proposed block based anns i e mb1 and mb2 were also compared to the traditional point based ann model i e the mp model the results show that all three ann only models i e mb1 mb2 and mp can simulate flood inundation with time reasonably well in data rich regions such as the river channel the block based mb2 model had the best performance due to the improved ability of the block structure in capturing time series flood information in input data during model calibration in regions with intermediate data availability i e the low lying floodplain the three models had very similar performance however all three ann only models performed poorly on floodplains with relatively higher elevations where data are scarce the ann based hybrid modeling approach which was based on a simple linear function the rectified linear unit relu and anns in the river channel was used to improve the predictive performance across floodplains the results show that the hybrid modeling approach can significantly improve the model performance on floodplains with relatively higher elevations i e floodplains with very sparse data based on predictions in the data rich region in the river channel with the hybrid model based on the most complex block based ann performing the best however ann only models still performed better on the low lying floodplains with intermediate data availability our results show that the final performance of the flood inundation models developed using a data driven approach is directly related to the trade offs between data availability and model complexity and highlight the importance of selecting model architecture and structure in a manner that is commensurate with data availability the hybrid modeling approach is demonstrated to be an effective way to strike a balance between model complexity and data availability and make sure all available information including information in data rich regions is used to improve model performance in data sparse regions for future research in order to integrate the advantages of complex models in data rich regions and simple models in data sparse regions the quantitative assessment of the trade offs between data availability and model complexity is needed in addition a formal method to select suitable hybrid models e g combination of model architecture and structure based on data availability needs to be developed although a trial and error approach can be used it is important to develop an objective method which can be integrated in the model calibration process to determine which combination of models should be used development of such a method will not only improve the efficiency of model development but it will assist the derivation of robust estimates when applied to real world problems where the data driven models may need to be continually updated as new flood information becomes available credit authorship contribution statement shuai xie conceptualization methodology software validation investigation data curation writing original draft wenyan wu conceptualization methodology validation resources data curation writing review editing supervision project administration sebastian mooser methodology software validation investigation q j wang conceptualization methodology validation writing review editing rory nathan validation resources data curation writing review editing yuefei huang validation writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank hydrology and risk consulting harc for providing flood inundation data utilized in this study and sunwater for their permission to use the burnett river as a case study the data that support the findings of this study are available online at https doi org 10 26188 5dafc6eb7475f this sutdy was financially supported by the national natural science foundation of china no 91647212 shuai xie is supported by a program of china scholarship council no 201806210127 during his visit to the university of melbourne where the research is conducted appendix replicative validation one way to evaluate replicative validity is to assess the goodness of fit of a model in the calibration data the other way is to test if the model residuals in calibration data violates the model error assumption the model residuals should be white noise and normally distributed for well calibrated models humphrey et al 2017 graphical diagnostics can be used for assessing replicative validity bennett et al 2013 chang and hanna 2004 humphrey et al 2017 in this study the histogram of standardized residuals in the training set was used to assess replicative validity in order to examine replicative validity of developed models across all wet cells the standardized residuals of all cells were combined for each type of models developed i e mb1 mb2 and mp the percentage of data falling into the 95 confidence interval i e 1 96 for standard normal distribution which is denoted by per95 is also calculated the histograms of standardized residuals and per95s for all three ann only models are shown in fig s1 in the supplementary material the validation results are cross validated results i e across the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events combined see section 4 3 2 above it was found that the standardized residuals for all three models are centered around zero with most of the data falling within the 95 confidence interval i e 1 96 indicating models have captured the useful information contained in the calibration data structural validation the methods used for assessing structural validity of anns can be based on sensitivity analysis dawson et al 2014 or relatively importance of input variables kingston et al 2006 olden and jackson 2002 humphrey et al 2017 summarizes that there is not an agreement on which method is best for structural validation and the performance of a method is dependent on the available data and complexity of the problem in this study the method based on relative importance of input variables introduced by kingston et al 2006 is used for structural validation the relative importance ri of each input can be calculated using the following equation kingston et al 2006 a1 r i i oc w i j 1 inp o c w j 100 where inp is the number of inputs oc w i is the overall connection weight of input i which can be calculated using the following equation a2 oc w i k 1 hid w i k w k o where w i k is the weight between the ith input node and the kth hidden node w k o is the weight between the kth hidden node and the output node and hid is the number of hidden nodes in this study the inputs may be different for different cells after input selection but for each cell the inputs can be divided into two groups river flows i e the exogenous inputs xe and previous water depths i e the autoregressive inputs xa therefore the ri of the river flow denoted by ri q is calculated for each cell by summing the absolute ri values of river flow input variables with different time lags in order to evaluate structural validity across all wet cells structural validity was examined over individual events in the validation sets i e the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events individually the relative importance ri of the exogenous input variable river flow q was examined for all three ann only models see figs s2 s3 and s4 in the supplementary material it was found that the river flow generally plays a more important role than the previous water depth on the floodplains for all three ann only models except for the high lying floodplains which are not affected by the change of the streamflow in most flood events due to its relatively higher elevations in the river channel the flow also plays a more important role than the previous water depth for the point based ann model mp as found in a previous study chu et al 2020 however a reverse result is observed for the block based anns in the river channel this is because the previous water depth is the key variable for the block which links the predictions within the forecasting window of the block sensitivity analysis of the threshold value for the ann based hybrid modeling approach there is an additional parameter th i e the threshold value in eq 1 which plays an important role in the hybrid modeling approach the sensitivity analysis of the threshold value th was carried out to provide insights into the impact of this variable on model predictive performance in this study we added an additional noise term to the threshold values which varied between 0 2 m and 0 2 m at 0 1 m intervals we assessed the corresponding performance of the ann based hybrid modeling approach in terms of rmses the rmses obtained from different noise factors are denoted by rmse 20 rmse 20 rmse10 and rmse20 respectively the impact of the change in the threshold values is illustrated in fig s5 in the supplementary material appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125605 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5031,flood inundation models are important tools in flood management commonly used flood inundation models such as hydrodynamic or simplified conceptual models are either computationally intensive or cannot simulate the temporal behavior of floods therefore emulation models based on data driven methods such as artificial neural networks anns have been developed however the performance of ann models like any other data driven models is limited by available data and will not perform well in data sparse regions in this study we developed an ann based hybrid modeling approach to improve model performance in data sparse regions by leveraging better model performance in data rich regions we applied our proposed hybrid modeling approach with three ann models including the traditional point based ann and two newly proposed block based ann models the results demonstrate that all three ann models have better performance in data rich regions compared to data sparse regions as expected with the block based ann with the most complicated model structure performing better in data rich regions and the simplest point based ann performing better in data sparse regions the hybrid modeling approach can significantly improve model performance in data sparse regions with the hybrid model based on the most complex block based ann performing the best our results show the importance of considering the trade offs between data availability and model complexity in developing data driven models and demonstrate the potential for improving performance in data sparse regions by using a hybrid modeling approach that optimizes model complexity based on data availability keywords hybrid models flood inundation models emulation models 1 introduction flooding has been recognized as one of the most frequent and destructive natural hazards in the world freer et al 2013 razavi et al 2020 however flooding can also be beneficial as they support ecosystems especially in arid areas teng et al 2017 bond et al 2014 due to both the negative and positive impacts of floods it is of significant importance to understand simulate predict and assess floods and risks teng et al 2017 many tools have been developed to improve flood management including hydrological models and flood inundation models i e hydraulic models huang and hattermann 2018 unduche et al 2018 verwey et al 2017 zischg et al 2018 emerton et al 2016 yang et al 2004 among these models flood inundation models are often used for flood risk analysis bhuiyan and dutta 2012 dutta et al 2006 real time forecasting for emergency planning chang et al 2018 and flood impact evaluation within water resources management vaze et al 2013 due to their capability in simulating flood inundation extent and depth with time which are directly related to flood impact apel et al 2006 hammond et al 2015 commonly used flood inundation models can be broadly divided into three categories empirical models hydrodynamic models and simplified conceptual models teng et al 2017 empirical models are based on observed data such as historical records surveys remote sensing data or experiment data o connor and costa 2004 schumann et al 2009 smith 1997 these methods use the observations in the most direct way and have been widely used together with other models to assist decision making archer et al 2018 schumann et al 2009 teng et al 2017 however these methods are restricted by their coarse spatial and temporal resolutions due to the limited number of data collection locations e g stream gauge locations and the long intervals between successive satellite data acquisition schumann et al 2009 hydrodynamic models simulate water movement by solving the equations which govern the physical processes involved and they are therefore the most widely used models for estimating flood inundation hydrodynamic models can be divided into one dimensional 1d two dimensional 2d and three dimensional 3d models according to their spatial dimensions casulli and stelling 1998 teng et al 2017 in general 1d models are based on the assumption that the flow is one dimensional along the river channel and therefore they are computationally efficient but cannot easily simulate flood inundation across floodplains brunner 2016 sen and garg 2002 2d models on the other hand simulate the flow across a 2d surface and can represent lateral flood movement across the floodplain well archer et al 2018 neal et al 2012 therefore they are commonly used for flood inundation modeling despite their high computational burden 3d models which represent vertical as well as horizontal flow behavior are more computational demanding than 2d hydrodynamic models and are mainly used to simulate complicated flood situations prakash et al 2014 in addition 1d 2d coupled models have also been used in recent years to take advantages of their strength in modeling river channels and floodplains respectively leandro et al 2009 liu et al 2015 although both 2d and 1d 2d coupled models are commonly used for food inundation modeling they are computationally expensive which prevents their use in applications requiring rapid model response e g real time forecasting or a large number of model runs e g uncertainty analysis teng et al 2017 in order to improve the computational efficiency of flood inundation modeling simplified conceptual models have been developed as an alternative approach mcgrath et al 2018 teng et al 2017 commonly used simplified conceptual models include the rapid flood spreading method lhomme et al 2008 the vtd model teng et al 2015 2019 and the height above the nearest drainage model mcgrath et al 2018 nobre et al 2011 these models do not simulate the dynamic process of water movement and therefore are very fast however as they are not physically based they have limited capacity to simulate the dynamic process of water movement and are therefore often used to merely estimate the maximum flood inundation of specific flood events teng et al 2017 consequently there is a need to develop a fast and accurate flood inundation modeling approach that takes advantage of physically based simulations of flood depth and extent one promising approach for fast flood inundation modeling is to use data driven methods to develop emulation or surrogate models to directly simulate flood input output relationships without explicitly representing the underlining physical process artificial neural network ann models are one of the most widely used emulation models in environmental modelling bermúdez et al 2018 rogers et al 1995 shrestha et al 2009 sreekanth and datta 2011 more recently the use of ann models has been extended to simulating flood inundation chang et al 2018 chu et al 2020 where the authors have found that ann based emulation models can significantly improve modeling efficiency compared to 2d hydrodynamic models a number of challenges of using ann models to simulate flood inundation have also been identified including the poor performance in data sparse regions and the difficulty in handling time series information without introducing a large number of parameters e g using deep learning techniques like any data driven models the performance of anns is limited by the information contained in data used for model calibration and therefore will not perform well in data sparse regions in addition in traditional anns the time series information in inputs e g inflow for flood inundation modeling is often represented using lagged data with one data point representing the input output relationship between the lagged inputs selected during the input selection process and the output at a specific snapshot in time therefore the continuity of the original time series information is not fully represented in the training process in this study we 1 proposed a hybrid modeling approach to improve the performance of ann models in data sparse regions by leveraging valuable information in data rich regions 2 applied this hybrid modeling approach with three different ann models including two block based anns which have improved representation of time series information in ann models without significantly increasing model complexity and 3 demonstrated the application of the hybrid modeling approach with the three ann models to flood inundation modeling using a real world system and compared the performance to an ann only approach the remainder of this paper is organized as follows the proposed ann based hybrid modeling approach and the block based ann models are introduced in section 2 and 3 respectively in section 4 the case study is introduced and the detailed model development process is also described both the simulation and comparison results are presented and discussed in section 5 finally the conclusions are summarized in section 6 2 ann based hybrid modeling approach 2 1 ann based hybrid modeling framework hybrid models refer to a class group of models which integrate the advantages of different individual models and are regarded as useful tools to capture the complex nature of a real world system kelly et al 2013 maier et al 2010 mount et al 2016 they have been widely used in environmental modeling including synthetic streamflow generation ochoa rivera et al 2002 streamflow forecasting chetan and sudheer 2006 wang et al 2006 rainfall runoff modeling mekonnen et al 2015 nayak et al 2007 water quality assessment lin et al 2008 and salinity prediction hunter et al 2018 in most of these studies a model technique intensive approach maier et al 2010 was used where different models techniques were used to simulate different components processes of an environmental system to take the advantages of these different models techniques for example mekonnen et al 2015 employed a hybrid model for unconventional runoff generation in the prairie region where the different components of the runoff were modelled by the swat and ann models respectively humphrey et al 2016 integrated soil moisture simulated using the gr4j conceptual rainfall runoff model into a bayesian ann model for monthly streamflow forecasts more recently hunter et al 2018 presented a hybrid modeling framework for salinity modeling in river systems where the different sub processes of salt transport in a river system were modelled using different methods alternatively a data intensive approach maier et al 2010 can be used to develop hybrid models where data are first divided into different clusters based on their statistical properties and a model is developed for each cluster for example wang et al 2006 divided the daily streamflow data into different groups based on flow regimes and then built different ann models for different groups chang et al 2010 employed a clustering based hybrid model for flood inundation modeling where the data were classified using the k means clustering methods based on statistical properties and then different models were built for each clusters however in these data intensive hybrid models model performance in data sparse regions is still limited by data availability in these regions therefore in this study we proposed an ann based hybrid modeling approach to address this challenge by considering the inherent relationships between different regions with varying data availability in an environmental system based on the identified relationships between regions with different data availability model performance in data sparse regions can be improved by leveraging the information contained in the data in data rich regions the proposed hybrid modeling approach including three stages is given in fig 1 in stage ⅰ the environmental system under consideration is divided into different regions according to data availability in this case 1 data sparse regions with limited data and 2 data rich regions with sufficient data in stage ⅱ anns are directly employed to model the input output relationships in data rich regions as in these regions data are sufficient for establishing ann models with good performance hunter et al 2018 mosavi et al 2018 mount et al 2016 in stage iii the inherent relationship between the data sparse and data rich regions are first established then the predictions in the data sparse regions are made based on predictions obtained from the ann models developed for data rich regions thus a hybrid modeling approach is used to produce predictions in data sparse regions by leveraging sufficient information in data rich regions 2 2 ann based hybrid modeling approach applied to flood inundation modeling in this study the hybrid modeling approach presented in fig 1 is applied to simulate flood inundation with time for flood inundation modeling the river channel is considered to be data rich as it is always inundated and therefore there are large amount of data available on the other hand floodplains are considered to be data sparse regions as they are only inundated when floodwater overtops riverbanks i e in relatively large flood events the inherent relationships between flood levels in the data rich river channels and data sparse floodplains can easily be established by considering the overtopping threshold water levels above which the floodplains will be inundated these relationships can be represented using a rectified linear unit relu which is commonly used in deep learning for improving the computational efficiency and model performance dahl et al 2013 nair and hinton 2010 shang et al 2016 and can be expressed using the following equation 1 d ds r e l u d dr t h m a x d dr t h 0 where d dr and d ds are predicted inundation depth in the data rich and data sparse regions respectively and th is an inundation depth threshold value in the data rich region i e river channel above which the data sparse region i e floodplains will start to be inundated 3 block based artificial neural networks it has been recognized that traditional anns such as multilayer perceptrons mlps have difficulties in handling time series information chu et al 2020 coulibaly and baldwin 2005 kratzert et al 2018 some deep learning techniques such as recurrent neural networks rnns have been developed to address this challenge coulibaly and baldwin 2005 le et al 2019 ye et al 2019 however the deep learning techniques often have a large number of parameters e g hundreds or thousands greff et al 2016 which require a large amount of data to support their development reichstein et al 2019 wang et al 2018 and their performance can be reduced significantly if there are insufficient data for model calibration chauhan et al 2019 pasupa and sunhem 2016 environmental systems often have limited data neal et al 2012 samaniego et al 2011 tramblay et al 2014 which will limit the application of deep learning techniques therefore a simple method the block based ann is introduced in this study to improve the way time series information is handled in traditional mlps it should be noted that in the proposed block based anns the block structure refers to a combination of consecutive observations in a time series ebtehaj et al 2010 not a combination of different layers in neural networks that is often referred to in deep learning greff et al 2016 targ et al 2016 zhang et al 2017 the proposed block based anns referred to as mb models are an integration of the block structure described above and the traditional point based anns i e mlps referred to as mp models during model calibration as shown in fig 2 in the figure b t and b t 1 refer to two blocks with starting time steps t and t 1 respectively and p t and p t 1 refer to two data points at time steps t and t 1 respectively xa represents autoregressive input variables which are the values of the output variable at previous time steps such as previous water depth for a flood system xe represents exogenous input variables which are variables representing external driving mechanisms having a direct impact on the output variable such as inflows for a flood system in fig 2 x a t and x e t refer to all autoregressive inputs e g current and previous water depth and exogenous inputs e g current and previous inflow selected at time t respectively for the traditional point based anns the model is trained based on each data point e g p t and p t 1 included in the dashed boxes in fig 2a for block based anns however a point based ann is repeatedly applied h times across a block of data with a block length of h e g b t and b t 1 included in the solid boxes in fig 2b where h is often the forecasting horizon in other words model parameter values are updated based on errors estimated across the entire block of data during the model calibration process for block based anns as opposed to being estimated based on a single data point for point based anns thus p t for point based anns is equivalent to b t for block based anns in block based anns there are various ways to estimate modal errors across the block to update model parameter values in this study two different ways for estimating errors across the blocks are investigated the resulting block based ann models are referred to as mb1 and mb2 respectively for mb1 the ann model parameters are updated based on the errors estimated in the first time step in the block i e for predicting y t 1 then the same model parameters are applied to the remaining time steps within the block i e for predicting y t 2 to y t h this way the errors in the first time step of the block structure is always minimized during model calibration in the mb1 model for mb2 the errors propagate through the block of length h and the final error at time step t h is used to update the model parameters in the model calibration process this way the final error at the end of each block is always minimized during model calibration in the mb2 model in other words given the same number of model parameters the mb2 model has the most complicated model structure followed by the mb1 model and the mp model has the simplest model structure 4 case study data and model development process 4 1 case study and data the performance of the ann based hybrid modeling approach and the block based ann was examined using a real world system the burnett river in queensland australia the river system is shown in fig 3 the river generally flows from southwest to northeast and enters the coral sea at burnett heads there is a dam paradise dam on the main stream of the river which is located approximately 100 km by road west of bundaberg fig 3a the burnett river has a catchment area of roughly 30 500 km2 upstream the paradise dam and a catchment area of 2 500 km2 downstream the dam the land use downstream of the dam mainly includes agriculture native grazing vegetation and some native forests a 2d hydrodynamic model was developed for the downstream area of paradise dam using the tuflow modeling suite huxley and syme 2016 the boundary conditions for the model include outflows from the paradise dam and the tidal levels at burnett heads flood inundation data generated using tuflow is available for ten flood events including seven design events ranging from 1 300 annual exceedance probability aep to the probable maximum flood pmf and three historical events i e the 1971 2010 and 2013 data from the 2013 historical event has a relatively short simulation period which is not suitable for the development of the block based anns and are therefore not used in this study flood information is available in terms of exogenous variables xe i e flows q from paradise dam at 15 minutes intervals and autoregressive variables xa i e flood inundation depth d within the model domain at one or two hour intervals for the development of the ann models all data were converted into hourly data using either the maximum value within one hour for flow or linear interpolation for water depth to account for the temporal relationships between the input and output variables lagged input variables are generated a maximum time lag of 15 h was used in this study based on travel time identified for the system in a previous study chu et al 2020 therefore the potential exogenous inputs variables at time t are q t 15 q t 14 q t and the potential autoregressive inputs variables at time t consists of d t 15 d t 14 d t 4 2 experiment setup for the purpose of this study an area of 2720 m 2860 m downstream the paradise dam is selected this area is represented by 19 448 20 m 20 m grid cells in the tuflow model during all nine flood events used 5 170 out of the 19 448 cells i e 26 6 of cells in the model domain are never inundated therefore in total 14 278 models are developed with one model used to estimate flood depths in one grid cell a forecast horizon h of 8 h is used in this study as this represents the travel time of flows between paradise dam and the study area as determined by chu et al 2020 the elevation of the study area is shown in fig 3b as described in section 2 the study area is divided into the river channel i e data rich region and the floodplain i e data sparse region considering the differences among different floodplain cells with varying data availability the floodplain is further classified into two zones based on elevation data the three zones are shown in fig 3c zone z1 is the river channel zone z2 is the low lying floodplain with less data i e flooded approximately half of the time and zone z3 is the floodplain with relatively higher elevations and very limited data i e flooded less than 30 of the time in this study both the ann only modeling approach and the ann based hybrid modeling approach are employed evaluated and compared as shown in fig 4 for the ann only modeling approach anns are developed for both the river channel i e zone z1 and the floodplains i e zones z2 and z3 to differently map the relationship between inflow and flood inundation levels for the ann based hybrid modeling approach anns are firstly developed in the river channel to map the input output relationships and then the relu is used to predict flood inundation levels on floodplains based on flood inundation levels in the river channel simulated using anns it should be noted that three ann model are used including two block based anns i e mb1 and mb2 and one traditional point based ann i e mp as described previously for the ann based hybrid modeling approach the threshold value th is defined as the inundation depth difference between the data sparse grid cell and a corresponding data rich grid cell in the river channel at the commencement of inundation in the data sparse grid cell therefore the threshold value th is grid cell dependent for each grid cell in the data sparse region its corresponding data rich grid cell is identified as the river channel grid cell that has the lowest estimation error when used to simulate flood levels in the data sparse grid cell based on eq 1 over calibration data 4 3 ann model development process the development of the three ann models i e mb1 mb2 and mp models follows recommendations by wu et al 2014 there are five major steps including input selection data splitting architecture and structure selection model calibration and model validation the details of these steps are described below 4 3 1 input selection input selection plays an important role in data driven modeling as there are often many potential input variables and not all of them contain critical information for model development an appropriate input variable set will improve model accuracy and prevent unnecessary model complexity bowden et al 2005 hejazi and cai 2009 in many input selection methods may et al 2011 quilty et al 2016 partial mutual information pmi which can evaluate both nonlinear dependency and redundancy between input and output variables is one of the most widely used methods to evaluate candidate models darudi et al 2013 fernando et al 2009 2005 may et al 2006 2008a 2008b sharma 2000 therefore pmi was also used in this study in order to make sure the input selection process can be carried out within a desired time frame two efficient stopping criteria i e the tabulated critical value based and aic based criteria were selected among all of the stopping criteria introduced by may et al 2008b 4 3 2 data splitting data splitting is an important step in ann modeling process through which the available data are divided into training test and validation sets maier et al 2010 in general the training and test set are used to train the model and determine when to stop training respectively maier et al 2010 the validation set is used to assess if the model can be used for its intended purposes humphrey et al 2017 considering that there are overlapping sections among different blocks the leave one out cross validation method bennett et al 2013 where one entire flood event is withheld from the model calibration process was used in this study to evaluate the performance of developed models for this study the leave one out cross validation approach was applied three times with one flood event being left out of the model calibration process each time the three flood events used in the cross validation process are the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood then a data splitting method was only used to split the data from the other flood events into the training and test datasets among many data splitting methods may et al 2010 sahoo et al 2012 snee 1977 wu et al 2012 2013 the duplex method developed by snee 1977 has been recommended in previous studies may et al 2010 wu et al 2014 therefore the duplex method is selected in this study to split calibration data into 75 for training and 25 for test the details of the duplex method can be found in the study by may et al 2010 4 3 3 architecture and structure selection the architecture of ann determines the model structure and significantly affects function estimation of the input output relationships maier et al 2010 in all ann architectures the three layer mlp is the most widely used for environmental systems due to their simple structure and less data requirement maier et al 2010 razavi and tolson 2011 wu et al 2014 and therefore is used in this study as discussed previously for an mlp the number of input nodes and output nodes are determined by the number of inputs and outputs respectively the number of hidden nodes determines the structure of mlp and needs to be determined during model calibration there are many methods to determine the optimal number of hidden nodes and these methods can be broadly divided into three groups global stepwise and ad hoc maier et al 2010 trial and error is a commonly used method for selecting model structure and was also used in this study to optimize the number of hidden nodes between a minimum number of 2 and a maximum number of 11 which were determined based on data availability 4 3 4 model calibration model calibration is used to find the optimal model parameters so that a model can represent the relationships between inputs and outputs maier et al 2010 wu et al 2014 there are generally two types of methods for ann model calibration 1 local optimization algorithms such as commonly used back propagation methods and newton s methods maier and dandy 1999 2000 rumelhart et al 1988 and 2 global optimization methods such as genetic algorithms sahoo et al 2009 generally local optimization algorithms are more computationally efficient considering the large number of models that will be developed in this study see section 4 2 a local optimization algorithm the levenberg marquardt algorithm lma levenberg 1944 was used lma can be regarded as a combination of the steepest descent and the gauss newton methods lourakis 2005 the details of lma can be found in madsen et al 1999 in order to increase the chance of finding the optimal parameter values four different sets of randomly generated initial weights were used for each number of hidden nodes considered in the calibration process 4 3 5 model validation model validation is an important process in the modeling process and it is used to assess the performance of the developed model over an independent dataset and make sure the model can be used for intended purposes with confidence humphrey et al 2017 according to the recommendations given by humphrey et al 2017 and wu et al 2014 three aspects of model validity need to be considered when validating data driven models such as anns namely 1 replicative validity which is the ability of a model to capture the underlying input to output relationships included in calibration data gass 1983 power 1993 2 structural validity which refers to how well a model explains the underlying physical processes of the system being simulated biondi et al 2012 kingston et al 2006 and 3 predictive validity which is how well a model performances in terms of its predictive ability over an unseen dataset the predictive validity is considered the most important as ultimately the models are developed for applications to events not considered in model development for this reason we focus on the predictive validation in the discussion of this paper the methods and results for replicative validation and structural validation are presented in the appendix three commonly used metrics were used in this study to assess predictive validity 1 root mean square error rmse which measures the agreement between observed and predicted data in real units 2 relative root mean square error rrmse which measures the relative error and 3 nash sutcliffe model efficiency coefficient nse which compares the model with a simple model that make predictions by averaging observed data these three metrics can be calculated according to the following equations 2 rmse 1 n i 1 n y i y i 2 0 3 rrmse rmse 1 n i 1 n y i 0 4 nse 1 i 1 n y i y i 2 i 1 n y i 1 n i 1 n y i 2 1 where n is the number of data y is the observed data and y is the predicted data in addition flood inundation extent obtained using the ann models developed was compared to that simulated using the tuflow model cell by cell to further evaluate the consistency between ann models and the tuflow model the cells were categorized into three groups 1 hits which mean the cells were inundated for both ann and tuflow models 2 misses which mean the cells were inundated for the tuflow model but not inundated for the ann models and 3 false alarms which mean the cells are inundated for the ann models but not inundated for the tuflow model hunter 2005 mcgrath et al 2018 the probability of detection pod and false alarm ratio far were also calculated according to the following equations 5 pod n hits n hits n misses 6 far n falsealarms n hits n falsealarms where n hits n misses and n falsealarms represent the number of cells in three groups respectively 5 results and discussion the results of the ann only modeling approach and the ann based hybrid modeling approach are presented and compared in terms of their predictive performance in this section in addition the three anns i e the block based mb1 mb2 and the point based mp are also compared in this section the results from the ann only and the hybrid modelling approaches are presented in sections 5 1 and 5 2 respectively model comparison results are discussed in section 5 3 5 1 predictive performance of the ann only approach the cross validated predictive performance i e across the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events combined see section 4 3 2 above of the ann only models i e mb1 mb2 and mp were first examined using the root mean square error rmse relative root mean square error rrmse and nash sutcliffe model efficiency coefficient nse obtained over the validation data as shown in fig 5 it can be seen from fig 5a 5c that rmses in the river channel i e z1 are larger than those on the floodplains i e z2 and z3 however the rrmses on the floodplains are greater than those in the river channel see fig 5d 5f this is because the mean water depths in the river channel are significantly greater than those on the floodplains it is also evident that all three models performed worse on the floodplain with higher elevations i e z3 where rrmses are greater than or equal to 0 5 this is also supported by the nse results obtained in these regions where the nse values can be near or below 0 for the boundary regions between the dry and wet conditions fig 5g 5i this is mainly due to the sparse data in these regions which are not sufficient to support the complex structure of ann models however for the majority of the study area the nse values are above 0 8 or near 1 which indicates good performance of the models the maximum flood inundation extent the probability of detection pod and the false alarm ratio far for each of the three cross validation events are shown in fig 6 as can be seen from the figure all three anns i e mb1 mb2 and mp can detect most inundated cells with pods greater than 95 for the 1 500 aep flood event ann models approximate the flood extent well in the river channel but mb2 overestimates water depths of some cells on the floodplain see the regions in yellow in fig 6b for the 1 12 100 aep flood event it is evident that the two block based anns overestimate the flood extent in zone z3 where the elevations are relatively higher fig 6d and 6e for the most extreme 1 33 000 aep flood event considered in cross validation however all three ann models approximate the flood extent well with the pods being close to 100 and the fars being close to 0 fig 6g 6i the worse performance of the ann models in terms of the maximum flood inundation extent in zone z3 for the 1 12 100 aep event compared to the other two events is mainly due to the fact that zone z3 is a transitional zone between dry and wet conditions for the 1 12 100 event and anns tend to over estimate flood in these regions as found in previous studies chu et al 2020 in summary all three ann only models performed reasonably well in terms of predictive performance in the data rich river channel however the predictive performance of all three models deteriorated across floodplains with limited data especially in zone z3 where the elevations are relatively higher i e the transitional regions of dry and wet conditions and therefore there are even less data available for model development 5 2 predictive performance of the ann based hybrid approach in order to improve the model performance across the data sparse floodplains the ann based hybrid modeling approach described in section 2 was used in the hybrid modeling approach the three anns are used to predict water depth in the river channel based on which the relu is used to predict water depth on the floodplain the cross validation results i e rmse rrmse and nse with the hybrid modeling approach are shown in fig 7 as can be seen from this figure the hybrid modeling approach has mixed impact on the predictive performance of the emulation models across the floodplains compared to fig 5 above in zone z3 i e the transitional regions of the dry and wet conditions on the northern side of the river the ann based hybrid modeling approach has significantly improved predictive performance compared with the ann only approach this is most evident for the relative error rrmse fig 7d 7f where the yellow regions indicating higher relative errors in zone z3 are significantly reduced in area however the hybrid modeling approach makes the predictive performance worse on floodplains with relatively lower elevations i e zone z2 compared with the ann only modeling approach this result indicates that in these low lying floodplain regions i e z2 the data available still contain relatively sufficient information to support the development of ann models and therefore it is better to directly simulate flood inundation based on the inflow and flood level relationship contained in the data using ann models similar results are obtained for the maximum flood extent the probability of detection pod and the false alarm ratio far for each of the three cross validation events as shown in fig 8 as can be seen from this figure compared to fig 6 above for the 1 12 100 aep flood the hybrid modeling approach significantly improve the poor performance in the zone z3 with relatively higher elevations which can be seen from the disappearance of the yellow regions and the decreasing far values fig 8d and 8e it should also be noted that the deteriorated performance of the hybrid modeling approach on the low lying floodplains which can be seen in previous discussion cannot be observed in terms of the maximum flood extent shown in fig 8 for the ann based hybrid modeling approach the additional parameter th i e the threshold value in eq 1 may have an impact on the predictive performance of the models therefore a sensitivity analysis of the threshold value th was conducted by examining the changes in rmses when varying the threshold values by adding a noise term the details of the sensitivity analysis are included in the appendix and the results are included in the supplementary material fig s5 the results demonstrate that the value of the threshold has varying impacts on the performance of the hybrid modeling approach in different zones in general the threshold value has a higher impact on the predictive performance of the hybrid modeling approach on floodplains with relatively lower elevations zone z2 compared to on floodplains with relatively higher elevations zone z3 within zone z2 especially on the southern side of the river channel the increase in the threshold values can result in significant increase of the rmses this highlights the importance of identifying appropriate threshold values when applying the hybrid modeling approach especially on floodplains with relatively lower elevations 5 3 model comparison as can be seen in previous sections both the ann only models and the ann based hybrid models have significantly different predictive performance in different regions of the study area therefore further analysis was conducted to compare the performance of the models in three different zones presented in fig 3c the predictive performance of the three ann only models i e the block based anns mb1 and mb2 and the point based ann mp and three ann based hybrid models i e the mb1 based mb2 based and mp based hybrid models in terms of the rmse is illustrated in fig 9 in fig 9 the y axis in each plot shows the values of the rmse and the axis shows the number of cells with rmse below specific values it should be noted that the hybrid modeling approach was only applied to floodplains i e zones z2 and z3 and are shown in the figure using dashed lines fig 9b and 9c 5 3 1 the comparison among three ann only models it is evident from fig 9 that the performance of the two block based and the point based ann models vary significantly across different regions in the study area as can be seen from fig 9a the block based mb2 model performed the best in zone z1 i e the river channel followed by the point based mp model while the block based mb1 model where model parameters were updated based on error in the first time step of the block produced the highest cumulative rmses in the river channel in zone z2 which is the low lying floodplain the mb1 mb2 and mp models have very similar predictive performance in terms of cumulative rmses the solid lines in fig 9b in zone z3 on the floodplains with relatively higher elevations however the point based ann model mp had the best performance i e the solid black line in fig 9c although all three ann only models performed poorly in zone z3 compared to zones z1 and z2 the reason for the different predictive performance of the three ann only models in different zones is related to data availability and the different model structures used as described in sections 3 and 4 the block based anns include eight mlps applied consecutively over eight data points contained in a block structure which makes it more complex than the point based ann which only includes one mlp structure applied to one data point during training the complex block structure enables the block based anns to better extract time series information contained in the block during model training however this also means that the block based anns need more data for model calibration therefore in the data rich region i e zone z1 river channel the mb2 model can be calibrated well and outperformed the point based mp model in the data sparse region i e zone z3 high floodplains the data available are not sufficient for the calibration of anns and thus all three models performed poorly and the point based mp had relatively better performance due to its simpler model structure in the regions with intermediate data availability i e zone z2 low lying floodplains all three ann models had very similar performance although the block based anns can generally extract more time series information from the training data it can also be seen from fig 9a that there is a significant difference between the mb1 and mb2 models and the mb1 model performed worse in the river channel i e zone z1 compared to the mb2 model and even the point based mp model the reason is that the mb1 model is trained based on error estimated in the first time step in the block structure and the cumulative error across the block is therefore greater than that of the mb2 model which is trained according to the cumulative error at the final time step of the block 5 3 2 the comparison between the hybrid modeling approach and the ann only modeling approach the hybrid modeling approach performed differently across the floodplains with different elevations although the point based ann model mp performed better in zone z3 the hybrid model based on the block based ann model mb2 outperformed the other two models in zone z3 see the dashed red line in fig 9c this improved predictive performance of the mb2 based hybrid model in zone z3 is directly related to the model performance in the river channel based on which the hybrid model was established as discussed above the mb2 model has the best predictive validation performance in the river channel i e zone z1 see fig 9a which led to better predictive results in zone z3 with the hybrid model compared to the other two hybrid models it should be noted that the hybrid models only improved predictive performance of the models in zone z3 where the floodplains have relatively higher elevations see fig 9c and the predictive performance with hybrid models deteriorated in zone z2 i e the low lying floodplains with intermediate data availability see fig 9b these results can be explained by the trade offs between model complexity and data availability the ann based hybrid models used in this study is indeed a linear function relu based on the predicted water depths in the river channel and only the relu is calibrated according to the limited data in the data sparse regions i e floodplains therefore the ann based hybrid models have simpler structures than the nonlinear anns on the floodplain in zone z3 the available flood data are not sufficient to support ann model development however the data are sufficient to calibrate the relu and therefore the ann based hybrid models can improve the prediction by leveraging the good predictive performance of anns in the data rich regions i e the river channel however the advantages of the hybrid models are lost in regions with more data such as the low lying floodplains i e zone z2 where better predictive performance can be achieved by directly mapping the input output relationships using anns while in the data rich region i e river channel the block based ann model mb2 performed better compared to the traditional point based ann model mp due to the improved ability of the block structure to better represent the time series information in training data this finding highlights the importance of considering data availability in model selection when developing data driven models without sufficient supporting data there is no point of using a complex model as a simpler model may perform better in addition the results demonstrate the potential to improve performance in data sparse regions by using a hybrid modeling approach which provides a more flexible way to cater for different data quantity in data driven model development 6 conclusions in this study an ann based hybrid modeling approach is developed to improve the model performance in data sparse regions by leveraging valuable information in data rich regions this hybrid modeling approach was applied to three ann models including two newly proposed block based anns which have improved representation of time series information in model development without significantly increasing model complexity the performance of the ann based hybrid modeling approach was compared to that of the ann only modeling approach via a real world case study in australia in addition the two newly proposed block based anns i e mb1 and mb2 were also compared to the traditional point based ann model i e the mp model the results show that all three ann only models i e mb1 mb2 and mp can simulate flood inundation with time reasonably well in data rich regions such as the river channel the block based mb2 model had the best performance due to the improved ability of the block structure in capturing time series flood information in input data during model calibration in regions with intermediate data availability i e the low lying floodplain the three models had very similar performance however all three ann only models performed poorly on floodplains with relatively higher elevations where data are scarce the ann based hybrid modeling approach which was based on a simple linear function the rectified linear unit relu and anns in the river channel was used to improve the predictive performance across floodplains the results show that the hybrid modeling approach can significantly improve the model performance on floodplains with relatively higher elevations i e floodplains with very sparse data based on predictions in the data rich region in the river channel with the hybrid model based on the most complex block based ann performing the best however ann only models still performed better on the low lying floodplains with intermediate data availability our results show that the final performance of the flood inundation models developed using a data driven approach is directly related to the trade offs between data availability and model complexity and highlight the importance of selecting model architecture and structure in a manner that is commensurate with data availability the hybrid modeling approach is demonstrated to be an effective way to strike a balance between model complexity and data availability and make sure all available information including information in data rich regions is used to improve model performance in data sparse regions for future research in order to integrate the advantages of complex models in data rich regions and simple models in data sparse regions the quantitative assessment of the trade offs between data availability and model complexity is needed in addition a formal method to select suitable hybrid models e g combination of model architecture and structure based on data availability needs to be developed although a trial and error approach can be used it is important to develop an objective method which can be integrated in the model calibration process to determine which combination of models should be used development of such a method will not only improve the efficiency of model development but it will assist the derivation of robust estimates when applied to real world problems where the data driven models may need to be continually updated as new flood information becomes available credit authorship contribution statement shuai xie conceptualization methodology software validation investigation data curation writing original draft wenyan wu conceptualization methodology validation resources data curation writing review editing supervision project administration sebastian mooser methodology software validation investigation q j wang conceptualization methodology validation writing review editing rory nathan validation resources data curation writing review editing yuefei huang validation writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank hydrology and risk consulting harc for providing flood inundation data utilized in this study and sunwater for their permission to use the burnett river as a case study the data that support the findings of this study are available online at https doi org 10 26188 5dafc6eb7475f this sutdy was financially supported by the national natural science foundation of china no 91647212 shuai xie is supported by a program of china scholarship council no 201806210127 during his visit to the university of melbourne where the research is conducted appendix replicative validation one way to evaluate replicative validity is to assess the goodness of fit of a model in the calibration data the other way is to test if the model residuals in calibration data violates the model error assumption the model residuals should be white noise and normally distributed for well calibrated models humphrey et al 2017 graphical diagnostics can be used for assessing replicative validity bennett et al 2013 chang and hanna 2004 humphrey et al 2017 in this study the histogram of standardized residuals in the training set was used to assess replicative validity in order to examine replicative validity of developed models across all wet cells the standardized residuals of all cells were combined for each type of models developed i e mb1 mb2 and mp the percentage of data falling into the 95 confidence interval i e 1 96 for standard normal distribution which is denoted by per95 is also calculated the histograms of standardized residuals and per95s for all three ann only models are shown in fig s1 in the supplementary material the validation results are cross validated results i e across the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events combined see section 4 3 2 above it was found that the standardized residuals for all three models are centered around zero with most of the data falling within the 95 confidence interval i e 1 96 indicating models have captured the useful information contained in the calibration data structural validation the methods used for assessing structural validity of anns can be based on sensitivity analysis dawson et al 2014 or relatively importance of input variables kingston et al 2006 olden and jackson 2002 humphrey et al 2017 summarizes that there is not an agreement on which method is best for structural validation and the performance of a method is dependent on the available data and complexity of the problem in this study the method based on relative importance of input variables introduced by kingston et al 2006 is used for structural validation the relative importance ri of each input can be calculated using the following equation kingston et al 2006 a1 r i i oc w i j 1 inp o c w j 100 where inp is the number of inputs oc w i is the overall connection weight of input i which can be calculated using the following equation a2 oc w i k 1 hid w i k w k o where w i k is the weight between the ith input node and the kth hidden node w k o is the weight between the kth hidden node and the output node and hid is the number of hidden nodes in this study the inputs may be different for different cells after input selection but for each cell the inputs can be divided into two groups river flows i e the exogenous inputs xe and previous water depths i e the autoregressive inputs xa therefore the ri of the river flow denoted by ri q is calculated for each cell by summing the absolute ri values of river flow input variables with different time lags in order to evaluate structural validity across all wet cells structural validity was examined over individual events in the validation sets i e the 1 500 aep flood the 1 12 100 aep flood and the 1 33 000 aep flood events individually the relative importance ri of the exogenous input variable river flow q was examined for all three ann only models see figs s2 s3 and s4 in the supplementary material it was found that the river flow generally plays a more important role than the previous water depth on the floodplains for all three ann only models except for the high lying floodplains which are not affected by the change of the streamflow in most flood events due to its relatively higher elevations in the river channel the flow also plays a more important role than the previous water depth for the point based ann model mp as found in a previous study chu et al 2020 however a reverse result is observed for the block based anns in the river channel this is because the previous water depth is the key variable for the block which links the predictions within the forecasting window of the block sensitivity analysis of the threshold value for the ann based hybrid modeling approach there is an additional parameter th i e the threshold value in eq 1 which plays an important role in the hybrid modeling approach the sensitivity analysis of the threshold value th was carried out to provide insights into the impact of this variable on model predictive performance in this study we added an additional noise term to the threshold values which varied between 0 2 m and 0 2 m at 0 1 m intervals we assessed the corresponding performance of the ann based hybrid modeling approach in terms of rmses the rmses obtained from different noise factors are denoted by rmse 20 rmse 20 rmse10 and rmse20 respectively the impact of the change in the threshold values is illustrated in fig s5 in the supplementary material appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125605 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5032,this study first discusses the conditional mean realizations and effective hydraulic conductivity in a theoretical framework it then introduces monte carlo simulation mcs algorithms for constraining the outcome by either hydraulic conductivity k samples or hydraulic head h measurements from the hydraulic tomographic survey ht it demonstrates that kriging using k measurements leads to a conditional mean k field while inverse modeling using successive linear estimator sle with head measurements of ht yields the conditional effective k field the effects of conditioning using k measurements are different from those using heads besides the conditional effective k leads to the unbiased prediction of the head that honors the observed head at measurement locations more importantly the study reveals that the harmonic and geometric means of conditional realizations of k fields of mcs given head measurements are equivalent to the conditional effective k in one and two dimensional flows respectively the first order approximation in the sle results in a conditional covariance similar to that from mcs with smaller magnitudes despite the difference all approaches predict unbiased conditional mean head behaviors keywords successive linear estimator conditional effective hydraulic conductivity conditional hydraulic conductivity realizations karhunen loeve expansion conditional covariance matrix uncertainty 1 introduction interpreting and extrapolating spatial point data to other locations or estimating spatial distributions of hydraulic properties using sparsely observed system responses is a common problem in hydrology geophysics and other environmental sciences and engineering fields for solving these problems many methods have been developed over the past decades among all these methods kriging is generally a widely used method in the groundwater hydrology field similarly model calibration or inverse modeling is popular for extracting information contained in the responses of aquifers to estimate the spatial distribution of hydraulic parameters franssen et al 2009 while these methods have become routine the logic behind these approaches and characteristics of the estimates are unclear let alone ways to address the uncertainty of these estimates for these purposes we focus on the estimates using kriging and hydraulic tomography ht and explain conditional mean realizations and effective hydraulic conductivity field engrained in these methods ht is a new generation of data collection and inverse modeling strategy many e g tosaka et al 1993 gottlieb and dietrich 1995 proposed the concept of hydraulic tomography ht using pressure variations induced by aquifer pumping to characterize hydraulic property distribution in the aquifer yeh and liu 2000 subsequently developed the first fully 3 d steady state hydraulic tomography using a successive linear estimator sle an inverse algorithm based on the spatial stochastic concept yeh et al 1995 1996 the accuracy and utility of ht were then tested and verified in sandbox experiments by liu et al 2002 later zhu and yeh 2005 developed the transient hydraulic tomography and xiang et al 2009 expanded sle to simsle simultaneous sle which simultaneously includes all the pumping test data sets for tht analysis since then the development and testing of this new technology have thrived more than two hundred seventy related research activities and papers have burgeoned since then initially research on hydraulic tomography consisted largely of numerical studies e g bohling et al 2002 brauchler et al 2003 zhu and yeh 2005 2006 ni and yeh 2008 fienen et al 2008 castagna and bellin 2009 xiang et al 2009 liu and kitanidis 2011 cardiff and barrash 2011 these numerical studies are followed by laboratory sandbox and field studies e g illman et al 2007 2009 liu et al 2007 yin and illman 2009a 2009b cardiff et al 2013 hochstetler et al 2016 sanchez león et al 2016 over the past decades ht has been analyzed mainly using geostatistical inverse models such as sle developed by yeh et al 1996 or quasi linear geostatistical approach qlga developed by kitanidis 1995 other approaches have also been used the pilot point method e g castagna and bellin 2009 lavenue and marsily 2001 a low frequency asymptotic approach by vasco and karasaki 2006 and ray tracing methods e g brauchler et al 2007 these algorithms focus on estimating smooth fields except the recent application of ensemble kalman filters enkfs to ht by schöniger et al 2012 recognizing the stochastic nature of the inverse modeling nowak 2009 advocated the benefits of empirical cross covariances from monte carlo mc analyses in the enkfs in this paper we first use a stochastic formulation to articulate conditional mean effective and realizations of hydraulic conductivity k and head fields we then introduce kriging which estimates the conditional mean k field and the ksa kriging with a superposition approach and the karhunen loeve expansion method klm which derive conditional realizations of k fields conditioned on the k measurements afterward the successive linear estimator sle which derive the effective k field conditioned on some observed heads is discussed subsequently the monte carlo sle slemcs and sle with klm sleklm approaches for generating conditional realizations of k fields which honor the observed heads are proposed we then apply these techniques to one and two dimensional numerical experiments to corroborate the results of the stochastic theories 2 theories before discussing the stochastic theories we assume that the following equations describe the steady state flow field due to pumpings in a saturated heterogeneous porous media 1 k x h x q x 0 with boundary conditions 2 h γ 1 h 1 k x h x n γ 2 q in eq 1 h is the total head l x is the location vector l q is the pumping rate 1 t k is hydraulic conductivity l t in eq 2 h 1 is the prescribed total head on the dirichlet boundary γ 1 and specific discharge q l t is specified on the neumann boundary conditions γ 2 n is a unit vector normal to γ 2 2 1 unconditional realizations and effective k investigation of effects of imposing hydraulic conductivity k and head h on the analysis and simulation of groundwater flow in aquifers is most appropriate to formulate the problem in a stochastic framework and to consider a pumping test at a single well the discussion starts with the case where no point data can be used to condition the hydraulic conductivity or the resulting head fields since k x is spatially varying and challenging to determine it at every location of the aquifer the stochastic analysis conceptualizes k as a random field 3 k x ω k k x ω where k is the unconditional mean the arithmetic average of all possible k realizations which are invariant in the spatial and ensemble the overhead bar stands for the expected value the unconditional perturbations at each x are k x ω where ω is the ensemble realization index ω 1 which are characterized by their unconditional covariance function this covariance specifies the spatial variance the uncertainty of the perturbations and the spatial relationship between perturbations in the ensemble sense or the spatial sense if the spatial domain is sufficiently large i e ergodicity is met accordingly many possible steady head fields h x ω exist in this aquifer induced by a pumping test with a given q these fields are thus a random field 4 h x ω h x h x ω in which h x is the unconditional ensemble mean which varies with x and h x ω is the perturbation at x substituting eqs 3 and 4 into the governing flow equation eq 1 we have 5 k k x ω h x h x ω q monte carlo simulation is one way to derive the possible head fields corresponding to all possible k fields averages of these fields over the ensemble are their means and their variances represent deviations of the means from the true fields instead of all possible h x fields we can seek the unconditional mean of h x ω directly to do so we expand eq 5 and take the expected value of eq 5 to derive an unconditional mean flow equation 6 k h x k x ω h x ω q which can also be rewritten as 7 k eff 2 h x q 0 the term k eff k k x ω h x ω 2 h x 1 is the unconditional effective parameter k eff is often assumed to be invariant in ensemble and space while some analysis e g indelman 2003 showed that it varies with radial distance near the pumping well and then approaches some constant values at large radial distances nevertheless this k eff yields the ensemble mean of h x ω field under all possible heterogeneity given the pumping discharge then the unconditional variance of h x ω gelhar 1986 quantifies the deviation of h x ω from h x 2 2 conditional realizations and mean k with k samples suppose we know the k values at some sampling locations xs and we like to use them for mapping the k distribution of an aquifer to increase the prediction accuracy of the flow field a conditional approach is appropriate which requires a highly parameterized model and k fields that are consistent with the measured k values at the sampling locations for this purpose we formulate a condition flow equation 8 k c x k c x ω h c x h c x ω q where the subscript c denotes conditioned eq 8 is the governing equation for the flow in realizations of k fields conditioned on the k samples notice that the k samples implicitly condition the head eq 8 can serve as the equation in which flow is conditioned on the head measurements to be discussed in section 2 3 solving eq 8 using conditional realizations of k fields k c x k c x ω yields many realizations of heads h c x h c x ω which reflect the effects of conditioning by the k samples notice that k c x and k c x ω represent the conditional mean and perturbation of k respectively while h c x and h c x ω are the conditional mean and perturbations of heads respectively implementation of this solution requires one to generate all possible k field conditioned on the k samples using ksa or klm methods section 3 first and then solves the equation for all conditional head fields this procedure is called the conditional monte carlo simulations conditional mcs the average of all conditional k fields from mcs results in the conditional mean k field while the average of all the simulated head is the conditional mean head field given the k samples alternatively one can expand eq 8 and take its expected value to have 9 k c x h c x k c x ω h c x k c x h c x ω k c x ω h c x ω q recognizing the expected value of the product of a perturbation and a mean of a variable is zero the cross out terms we then normalize k c x ω h x ω with the mean flux k c x h c x and lump the normalized cross covariance with h c x one has k c x h c x 1 k c x ω h c x ω k c x h c x 1 q or 10 k c x h ceff x q which is the conditional mean equation in which k c x is the conditional mean k from kriging that is to say if we use the condition mean k field to solve the flow equation we directly obtain the conditional effective head field h ceff however this head field is not the conditional mean head field from the mcs approach to derive the conditional mean head one can group the normalized covariance with k c x that is k c x 1 k c x ω h c x ω k c x h c x 1 h c x q or 11 k ceff x h c x q solving eq 11 with k ceff x yields the conditioned mean head given the k samples which is identical to the conditioned mean head from mcs this approach however requires k c x ω h c x ω to be known beforehand 2 3 conditional realizations and effective k with head measurements similar to using k measurements to condition the simulated head field this conditional head approach also adopts a highly parameterized conceptual model the governing equation is identical to eq 8 but is for the flow in realizations of unknown k fields conditioned on the head samples that is the mean and perturbation of k and head in eq 8 are conditioned on the head measurements instead of the sampled k to determine these realizations of unknown k fields we need to solve an inverse problem using some algorithms section 3 which can select all possible realizations of k fields with which the groundwater flow model can reproduce the observed heads at the monitoring locations in other words a conditional mcs using slemcs or sleklm algorithm see section 3 is necessary once all possible realizations of k and h fields are obtained their average leads to the conditional mean k and h fields respectively instead of using the mcs most inverse modeling efforts have attempted to seek one possible of k field that can preserve the observed heads when the flow equation is solved to explain the theory we make the use of eq 11 as the conditional mean equation but recognize the equation is conditioned on the observed head rather than the k measurements in this mean equation k ceff x and h c x are the conditional effective hydraulic conductivity and conditional mean heads given the head observations solving the conditional mean equation to match the observed head in a least square sense using an algorithm such as sle section 3 one has the conditional mean head and the effective k field while the effective k is not necessarily the same as the arithmetic mean of all possible conditional realizations of k fields it produces the conditional mean head which is unbiased and preserves the observed heads 3 methods to substantiate the above theories we introduce several methods that derive the conditional mean and realizations of k fields given some k samples we also present methods for deriving conditional effective k and condition realizations of k given some observed heads 3 1 conditional mean k field with k samples kriging is a widely accepted method to derive the conditional mean k field given the sampled k values readers are referred to the description of kriging in textbooks such as kitanidis 1997 and many others 3 2 conditional k realizations with k samples kriging superposition approach ksa to create conditional realizations given some k measurements we use a monte carlo simulation algorithm based on superposition e g yeh 1992 it consists of four steps step 1 use the natural logarithm of k lnk or y to avoid negative estimated values and generate a conditional mean lnk field y c x f where f denotes the given field data using kriging and measured lnk at measurement locations step 2 generate k realizations of the unconditional random field y x ω where ω is the realization index ω 1 k via a random field generator e g gutjahr 1989 with a known mean variance and autocorrelation distances step 3 extract the lnk values from y x ω at the same sample locations as those at the field site then use these sample values and kriging in step 1 to calculate corresponding conditional mean fields y c x ω ω 1 k given these generated samples next we determine the difference between each generated random field and its associated conditional mean field this is 12 d x ω y x ω y c x ω step 4 add the differences in eq 12 to the conditional mean y of the field site from step 1 to derive the conditional realizations 13 y c x ω y c x f d x ω these conditional realizations thus preserve the sample values at the sample locations of the field site since d x ω 0 at these locations at other locations y c x ω s are random variables determined by deviations d x and kriging estimates based on the field observations karhunen loeve expansion method klm in this method y c x ω can be written as 14 y c x ω y c x ω ξ λ g where y c x ω is the conditional mean k derived from kriging or the effective k from sle the last term in the eq 14 ξ λ g is the perturbation term and ξ n y 1 are a set of uncorrelated random variables with zero mean and unit variance i e ξ i 0 ξ i ξ i 1 and ξ i ξ j 0 when i j furthermore g n y are orthogonal eigenvectors λ is a diagonal matrix filling with corresponding nonnegative eigenvalues based on the conditional covariance function the eigenvalues and eigenvectors are obtained by eigenvalue decomposition of the conditional covariance λ yy from kriging 15 λ yy g t λ g the decomposition is easily accomplished by the built in eig function in matlab in which the eig function will automatically selectthe cholesky factorization algorithm to compute the λ and g since the conditional covariance matrix is hermitian ma dong and zhang 2006 mathworks 2005 yaz and azemi 1995 afterward we sort the eigenvalues in the descending order then only the ny eigenvalues and the associated eigenvectors are retained to approximate the perturbation term in eq 14 that is the dimensions of matrix λ and g in the truncated kl expansion are reduced to n y n y at last with given different random variables vectors ξ n y 1 different random fields are generated note that lu and zhang 2004 derived a solution for eigenvalue decomposition in kl expansion which is different from our method 3 3 conditional effective k field with head data while many different inverse methods could be used for this purpose we focus on ht estimates using the successive linear estimator sle yeh et al 1996 which has widely used as we mentioned in the introduction suppose we collect n d observed heads in space denoted by the data vector d during a steady state ht survey the conditional effective y c e f f x with given observations is determined using the following sle 16 y c e f f x r 1 y c e f f x r ω t d d r where r is the iteration index the vector d r is the simulated heads at the observation locations obtained from the forward model i e eqs 1 and 2 using y c e f f x at iteration r when r 0 y c e f f x is the unconditional mean the coefficient matrix ω n d n y denotes the weights which assign the contribution of difference between the observed and simulated head at each observation location to the previously estimated y c e f f x field and the superscript t denotes the transpose this coefficient matrix ω is derived by solving the following equations 17 ε dd r θ r diag ε dd r ω r ε dy r where ε dd is the covariance of the head and ε dy is the cross covariance between lnk and head the parameter θ is a dynamic stability multiplier and diag ε dd is a stability factor which is a diagonal matrix with the same diagonal elements as ε dd the covariance ε dd and cross covariance ε dy can be derived from the first order numerical approximation e g yeh and liu 2000 18 ε dd r j d r ε yy r j d r t ε dy r j d r ε yy r where j d n d n y is the sensitivity jacobian matrix of head data with respect to lnk using the lnk estimated at the current iteration at iteration r 0 the ε yy n y n y is the unconditional covariance of lnk for r 1 the conditional or conditional covariance function are evaluated according to 19 ε yy r 1 ε yy r ω t ε dy the above steps eq 16 through eq 19 are repeated until the convergence of the solution is achieved one convergence criterion is the change in variances of the estimated lnk field between the current iteration and the previous iteration if this criterion is small sle cannot improve the estimates any further the other is the change of simulated heads between successive iterations if this quantity is small the estimates could not further fit the observed heads once one of the two criteria is met we consider the estimates to be optimal and we terminate the iteration the above algorithm can be applied to each pumping test in ht survey sequentially ssle sequential sle zhu and yeh 2005 or all the pumping tests simultaneously simultaneous sle xiang et al 2009 3 4 conditional k realization with head data mcs using sle slemcs besides the conditional effective hydraulic conductivity field sle can generate many possible realizations of y c x ω fields that preserve the observed head and satisfy their underlying statistical properties i e mean and covariance as well as the governing flow equation eqs 1 and 2 similar to the approach proposed by gutjahr et al 1994 hanna and yeh 1998 one way for this purpose is the monte carlo simulation slemcs as described below this approach uses an unconditional realization k field as the starting field and its unconditional covariance is employed as the prior covariance for sle then sle iteratively updates the estimates and conditional covariance until the simulated heads agree with the observed ones once the estimated field converges the estimated lnk field becomes the conditional realization given head measurements of ht survey if we repeat this procedure with other unconditional realizations we then have a conditional mc simulation for ht this approach is analogous to the iterative enkfs nowak 2009 schöniger et al 2012 but it uses sensitivity and the first order analysis to update the conditional covariances as opposed to calculating the conditional covariances using the approximated conditional realizations during each iteration mcs using klm sleklm as an alternative to slemcs sleklm takes advantage of the effective lnk field and the conditional covariance ε yy from sle and then directly uses klm to generate conditional realizations that is klm generates zero mean realizations based on the ε yy at the final iteration from sle which are then added to the effective lnk field from sle to produce the conditional realizations this approach thus avoids the time consuming conditioning mc simulation based on sle as in slemcs approach 4 one dimensional numerical experiments 4 1 case ⅰ conditioning using k measurements for the sake of easy visualization and understanding we use a one dimensional confined aquifer to demonstrate the algorithms above this aquifer is 128 m in length and is discretized into 128 elements each 1 m and 129 nodes each element is assigned a k value from a fast fourier transform fft random field generator gutjahr 1989 the generation assumes that the lnk has a jointly normal distribution with a mean of 1 0 a variance of 1 0 and an exponential correlation structure whose correlation scale equals to 10 m this k field is depicted in fig 1 as the solid black line and the unit of k is m s the k values at x 32 56 and 96 are taken as the hydraulic conductivity measurements red circles in the figure so that there are 125 unknowns of k using three k samples and the exact spatial statistics we derive the conditional mean k field via kriging and conditional realizations of k fields through ksa and klm given the three sample values kriging the conditional mean k field derived by kriging using three k samples is displayed as a green long dashed line in fig 2 this figure also shows the upper and lower bounds of the kriging estimates i e the conditional mean values plus or minus one standard deviation of the kriging respectively ksa the dotted color lines in fig 2 are three realizations from the 2 000 realizations generated from ksa means and standard deviations of the realizations at each location are used to determine the upper and the lower bounds we observe that these means and the upper and lower bounds agree with the conditional mean and the upper and lower bounds derived from kriging mean and variance from fig 2 we observe 1 the conditional means at the sample locations are identical to the values of the samples 2 the conditional mean k captures the general spatial trend of the true lnk field and 3 the closer the location to sampled locations say less than 10 m the smaller fluctuations of the lnk values of the realization we also observe that the smaller the distance to the sample location the narrower the gap between the upper and lower bounds this result indicates that the measurements have strong influences on the k at distances less than 10 m the correlation scale of the heterogeneity from the sampling locations beyond this distance the mean values remain the same as the unconditional mean value in other words the uncertainty of the true field around the conditional mean at these locations remains the same as the variability of lnk i e effects of conditioning are zero the unconditional covariance and the kriging or conditional covariance matrices for this problem are exhibited in fig 3 a and b respectively for the unconditional case the covariance decays rapidly from the diagonal terms according to the correlation scale the kriging i e conditional covariance forms four distinct zones according to the three sample locations and in other areas the covariance is zero due to zero variance at the sample locations klm in this approach the conditional covariance matrix from kriging is directly used in klm to generate 2 000 realizations of conditional lnk fields three of the 2 000 realizations and the true k field are illustrated in fig 4 notice that the realizations are different from those in fig 2 generated with ksa because a different random field generator is used nevertheless the conditional means and the upper and the lower bounds of the realizations from klm are comparable to those derived from ksa besides these realizations from klm honor the sample values at sample locations in summary kriging estimates are conditional means of all the possible realizations in the ensemble they are the means of all the equally likely realizations which agree with the sample values at the sample locations kriging estimates are smoother than the true field since they represent the most likely estimates at the locations where no samples are available and they are the sample values at the sampled locations kriging variance is the statistics that describe the likely deviation of the true field from the conditional means notice that if samples are taken at every location the conditioning means are identical to the true field and the kriging variance or conditional variance is zero everywhere ksa and klm generate conditional realizations which have the same spatial statistics spatial variability of the true field and honor the sample values at the sample locations they are as jagged as the true field but their ensemble averages are similar to the kriging means conditioned head fields to illustrate the effects of conditional mean k field from kriging and conditional realizations of ksa on the prediction of head distributions we create a new 1 d aquifer which has 1 024 elements each 0 125 m with random k values with the same length of the aquifer and spatial statistics as in fig 1 and bounded by constant heads of 1000 m on the both sides we increase the number of element of the aquifer to avoid the ergodicity issue fig 5 a is an illustration of the k field and those from kriging and the average of ksa realizations given the k values at three locations it shows that the kriging mean is identical to the conditional mean of ksa as they should be we then simulate the steady head fields due to pumping at a location with a rate of 0 1 m3 s in fig 5b the simulated head from the kriged field is consistently higher than the true head of the heterogeneous aquifer while the average of the simulated conditional head fields light blue lines in the figure from conditional 1 000 realizations of k fields based on ksa is close to the true field the scatter plots of the simulated head from the kriged k field and that from ksa vs the true field fig 5c also confirms that the kriged k field produces the conditional effective head field and that ksa can yield the conditional mean head field as we have remarked in section 2 2 the results of klm are identical to those of ksa and are not presented however we cautiously point out that the unbiased prediction could vary with the pumping location in particular in 1 d aquifers since flow process ergodicity should also be met yeh et al 2015 because the heterogeneity near the pumping well heavily controls the behavior that is the unbiased prediction will always be true in the average sense over a larger number of pumping tests at different locations 4 2 case ⅱ conditioning using head data in this case two aquifers are considered aq1 and aq2 with an unconditional variance of lnk 1 and 3 respectively which have the same mean correlation scale and random seed number as that in case i the true k fields of the two aquifers are given in fig 6 a and 6b which are bounded by the left hand and right hand prescribed head boundaries of 1000 m seven wells are located at x 16 32 48 64 80 96 and 112 m of the aquifers three pumping stresses are conducted at x 32 64 and 96 individually as the ht survey with a constant discharge q 0 02 m 3 s we then use vsaft2 yeh et al 1993 available at hptt tian hwr arizona edu download to simulate the steady state flow field induced by each test and take the heads at the other six wells for ht analysis the red the green and the orange dotted line in fig 1 are the simulated head field in aq1 for stresses 1 2 and 3 respectively the head in aq2 is not shown using head measurements from the six wells during each test we derive the most likely effective hydraulic conductivity using sle without any k measurements then with the same head measurement locations slemcs derives 2 000 equally likely hydraulic conductivity realizations that preserve the observed heads and so does sleklm the conditional mean and covariance of these k realizations are then calculated to compare with that directly from sle the results of this analysis are given below 4 2 1 slemcs conditional k fields as shown in fig 6a and 6b the conditional effective k field from sle captures the spatial trend of the true k field but is smoother than the true field on the other hand the conditional realizations from slemcs are as erratic as but different from the true field although with a similar trend we also see that the harmonic mean of the conditional k realizations agrees with the conditional effective k while the arithmetic and the geometric mean of the realizations are consistently higher comparison of fig 6a and 6b indicates that deviations of the arithmetic and geometric means from the effective k increase as the unconditional variance of lnk increases the histogram plots in fig 6c and 6d show that the distributions of the true field conditional effective k and k fields from different averages are log normal notice that the distributions of the effective k field and the harmonic mean of slemc are identical and they have similar means as the true field but smaller variances reflecting effects of conditioning i e the posterior distribution in bayesian theory these findings corroborate with the fact that 1 sle produces the conditional effective hydraulic conductivity field as stated in yeh et al 1996 and 2 the effective k in one dimensional flow scenarios is the harmonic average of all possible conditional realizations see yeh et al 2015 conditional head fields to check if the conditional head fields honor the observed heads we simulate head fields corresponding to the three pumping tests using the 2 000 conditional random k fields from slemcs and calculate the conditional means and variances note that the sle approach substitutes the final conditional covariance of lnk ε yy into eq 18 to determine the conditional head covariance ε dd in which the diagonal elements are its conditional variances according to fig 7 a c effective k conditional k realizations and harmonic mean k from slemcs yield head fields that honor the observed heads of each stress they are unbiased estimates of the true head field for each stress even if the unconditional variance of lnk is 3 0 fig 7d f notice that we present only one realization of heads corresponding to one conditional k realization dotted pink line in fig 7 since other realizations behave similarly on the contrary we observe that the arithmetic and geometric means of the conditional k realization form slemcs result in heads departing from the observed with increasing deviations with the variance of lnk these findings manifest that the effective k is not equal to the ensemble arithmetic average of the conditional realizations of k but is their harmonic average the conditional head variances from sle and slemcs are depicted in fig 8 a for the unconditional variance of lnk 1 those for the variance equal to 3 are in fig 8b these figures indicate that the conditional variance of the head at each observation location is zero while the other locations are not the conditional variances of the head from slemcs are larger than those from the first order analysis used in sle and the difference increases with the unconditional variance of lnk these results indicate that the head variances approximated by the first order analysis in sle underestimate the conditional variances of the head conditional covariance of lnk in the case of sle the first order approximation of the conditional covariance matrix of lnk eq 19 at the last iteration is used as the conditional covariance on the other hand the conditional covariance matrix for the slemcs approach is derived from a statistical covariance analysis of the 2 000 conditional realizations the covariance matrices for cases with the unconditional variance of lnk of 1 0 from sle and slemcs are displayed in fig 9 a and b respectively fig 9d and e show the corresponding covariances for the unconditional variance of lnk of 3 0 the patterns of these two conditional covariance matrices are similar although the values from slemcs are larger than those from sle the difference increases with the unconditional variance of lnk fig 9c and f the largest conditional variance of lnk diagonal elements of the matrices is at the location of head measurement while the minimum is at the location between the head observed locations that is the head data at the observation wells reduce the uncertainty of the lnk between the observation wells but not that at the observation well such behavior is distinctly different from the conditional variance resulted from conditioning with lnk measurements fig 3b where the conditional variance is zero at the measurement locations such findings are consistent with the explanation of the impacts of head measurements of ht by yeh et al 2014 notice that the variance is always positive but the covariance can be negative 4 2 2 sleklm slemcs evaluation is computationally intensive since it requires to run sle 2 000 times using 2 000 random realizations as initial fields a new approach i e sleklm is proposed specifically it first employs sle to derive the conditional effective lnk field and conditional covariance matrix of lnk using the conditional covariance of lnk resulting from sle sleklm then generates the zero mean conditional realizations afterward these zero mean realizations are added to the conditional effective lnk field to form the conditional realizations of lnk fields which are then converted to the conditional realizations of k fields a comparison of the efficiency of the two methods of slemcs and sleklm is shown in table 1 using sleklm method takes only a few tenths of the computational time of slemcs while the cpu time required by sle is much less than those of the slemcs and sleklm since sle directly derives the conditional effective k field and associated conditional covariance matrix next we investigate whether these conditional random fields derived from sleklm honor the observed heads at the observed locations during the ht survey for this purpose we use these conditional random fields 2 000 realizations to simulate the ht survey in fig 10 a and b we plot the simulated heads at the observation wells of each pumping test against those heads simulated using the true k field observed true heads these plots show that the simulated heads agree with the observed heads only in an average sense they scatter around the one to one line the conditional variances of the heads from sleklm for different pumping stresses of ht are illustrated in fig 10c and d the head variances at the observation locations are nonzero even though they are much smaller than those at other locations manifesting the effects of head conditioning in other words sleklm does not guarantee the preservation of the head measurements preservation of the observed heads can only be accomplished via solving the governing flow equation rather than generating them from the conditional covariance 5 two dimensional numerical experiments reference field here a two dimensional heterogeneous aquifer with a dimension of 128 m 128 m is discretized into 1024 4 m 4 m elements each element is assigned a k value using the fft random field generator the generated k field see fig 11 i e the true or reference field has the unconditional mean and variance of lnk of 1 0 and an exponential correlation structure with anisotropic correlation scales λ x 40 m and λ y 2 0 m in and y directions respectively the upper and lower sides of the aquifer are no flow boundaries and the left and right sides are constant head boundaries of 1000 m nine wells w1 to w9 are installed and three pumping stresses are conduct at w1 w5 and w8 for ht survey each stress is a constant discharge q 0 05 m 3 s at one of the wells and vsaft2 simulates the steady state flow the simulated heads at the other eight wells are collected for each stress subsequently a total of 24 head measurements for the three tests are simultaneously used for inversion using sle slemcs and sleklm approach without using any k measurement conditional k fields the effective hydraulic conductivity from sle is displayed in fig 12 a with the same head measurements we use slemcs to derive 2 000 conditional k realizations that honor the observed heads the geometric arithmetic and harmonic averages of these realizations are depicted in fig 12b d respectively the scatter plot comparing the true and effective k and the geometric average from slemcs is in fig 12e the scatter plot for the arithmetic and harmonic averages of slemcs vs the true field is in fig 12f from fig 12a and b we notice that the effective k from sle is similar to the geometric mean of the k fields from slemcs both are all unbiased with the true field fig 12e the field from the arithmetic mean of the slemcs generally is larger than the true field while that from the harmonic mean is smaller as shown in fig 12f the patterns of the conditional variance of lnk from sle and slemcs fig 12g and h respectively are similar but the values from slemcs are larger than those from sle both yield small uncertainty of the estimated lnk near the observation positions and significant uncertainty far away from the observation ports especially near the boundary consistent with those in one dimensional results conditional head fields we use the same procedure as in the 1 d case to derive the conditional head fields to check if the conditional head fields honor the observed heads we subtract the conditional head field obtained by the three approaches from the true head field and then take its absolute value to obtain the fig 13 a c only stress 1 is shown the simulated head based on the effective k the average head from slemcs and that from sleklm honor the head observations conditional head standard deviation from slemcs are generally larger than those from the sle and sleklm as shown in fig 13d f although the standard deviation of the head field from the sleklm at the observation wells is not zero the pattern is similar to those from the sle and slemcs approach 6 effect of ensemble size for mcs to ensure our mcs results from the limited domain size are conclusive we investigate the effect of the number of realizations on the ensemble harmonic and the geometric mean of k from slemcs in comparison with the effective k from sle using the mean square error as a criterion 20 mse 1 n i 1 n z i z i 2 this mse measures the difference between z i the effective conductivity from sle and z i the ensemble harmonic or geometric mean of hydraulic conductivity from slemcs n is the total number of elements if the mse value is small then the averages of the slemcs is equivalent to the effective k as shown in fig 14 for 1 d aquifers with the variance of lnk of 1 and 3 the mse value of the harmonic mean of slemcs k h drops rapidly to a minimal value and it stabilizes after about 500 realizations for 2 d aquifers the geometric mean of the slemcs k g also behaves similarly 7 demonstration of the usefulness of the approaches to demonstrate the utility of the sle slemcs and sleklm we used their estimated k fields to predict an independent pumping test using wells not used in the previous ht analysis the independent pumping test experiment uses the same grid size and boundary condition as the 2 d ht experiment but uses different the pumping and observation well locations i e the pumping well p5 with a constant discharge q 0 2 m 3 s and the observation wells p1 p2 p3 and p4 as shown in fig 11 the specific storage 0 02 m is known and uniform over the aquifer the initial head is 1000 m at all nodes and equal to the left and right boundary conditions we then simulate transient drawdown behaviors induced by this pumping based on the true and the estimated k fields from the previous ht analysis from the three different methods the drawdown distribution at the steady state of the true k field is displayed in fig 15 a while fig 15b presents the simulated drawdown distribution using the conditional effective k derived from sle meanwhile the average of 1 000 realizations of simulated drawdown fields using 1 000 conditional realizations of k fields derived from slemcs and sleklm are presented in fig 15c and d respectively the comparisons between the true and the simulated drawdowns using the conditional effective k over the entire aquifer is illustrated in fig 15e as the scatter plot the scatter plot of the averaged drawdowns from slemcs and sleklm vs the true is presented in fig 15f overall the effective k from sle yields unbiased predictions of the drawdown likewise the average of the simulated drawdowns from slemcs and sleklm also are unbiased notice large scatterings at small drawdown values in these scatter plots are attributed to the sparse well network used in the ht survey and log scale plot lastly the usefulness of the monte carlo simulations using slemcs and sleklm for showing the uncertainty of the drawdown at the observation well p1 and p3 are illustrated in fig 16 in all these drawdown time plots the solid black lines are the drawdown curves in the true field while the light blue lines are the 1 000 possible drawdown time curves simulated by the slemcs and sleklm as we have remarked before the sleklm likely underestimates the conditional variance of lnk as such it produces narrow bands of possible drawdown time behaviors besides the results in fig 16 also reveals that the unbiased predictions shown in fig 15 do not apply to observed heads at one or two locations 8 summary and conclusion to explain conditional mean effective and realizations of conductivity fields we develop conditional monte carlo simulation algorithms using hydraulic conductivity measurements namely ksa and klm or based on hydraulic head measurements from the hydraulic tomographic survey slemcs and sleklm results of the analysis of these algorithms can be summarized as follows 1 ksa and klm can generate conditional realizations which have the same spatial statistics as the unconditional k field also they yield conditional mean and covariance which are the same as the kriging mean and conditional covariance 2 interpretation of ht data using sle yields a conditional effective hydraulic conductivity field and the conditional covariance of the estimated field given the head discharge and boundary information during the ht survey on the other hand slemcs produce conditional realizations equally likely hydraulic conductivity fields that honor the observed heads during ht surveys and are as jagged as the true field the conditional effective hydraulic conductivity of sle is close to the harmonic average of all these realizations for one dimensional flow but agrees with the geometric average for two dimensional flow the covariance functions of these realizations from slemcs are similar in pattern with that of the conditional covariance function of sle although the values from slemcs are larger than those from sle and the deviation increases with the unconditional variance of lnk 3 sleklm can efficiently generate conditional realizations of hydraulic conductivity fields by taking advantage of sle s conditional effective hydraulic conductivity field and conditional covariance function however the simulated heads from the generated conditional realizations of k match the observed head data of ht survey only in the average sense 4 applications of sle slemcs and sleklm to an independent flow event demonstrate that all approaches yield unbiased prediction of the true head field and the uncertainty of drawdown around the observed locations from sleklm are small based on these results we come to the following conclusions 1 the effects of conditioning using k and head measurements are different 2 harmonic and geometric averages of conditional hydraulic conductivity realizations are equivalent to the effective hydraulic conductivity derived from sle for one and two dimensional flow problems respectively 3 the effective hydraulic conductivity from ht can predict head fields that are unbiased and preserve the observed heads during each ht pumping test it also yields an unbiased prediction of the head field under a different flow scenario 4 while sleklm is more computationally efficient than slemcs but its conditional variance is smaller than that of slemcs on the other hand sle and a first order analysis is a computationally efficient approach for the same purpose but derives only conditional variances without the generation of conditional realizations lastly as stated in yeh et al 2015 the uncertainty analysis is not to seek absolute uncertainty but to gauge the relative uncertainty between different operational strategies therefore we recommend the use of sle or sleklm for practical applications due to their computational efficiency moreover if we just estimate the head and its uncertainty we recommend the sle method since it can directly derive the best unbiased k estimates honoring the observations and the conditional covariance addressing the uncertainty of estimates and it also avoids the mc intensive computational efforts however if we need to estimate the uncertainty of flow and concentration fields and derive possible realizations we suggest the conditional realizations from slemcs and sleklm credit authorship contribution statement xu gao conceptualization formal analysis writing original draft tian chyi jim yeh methodology software writing review editing e chuan yan validation supervision yu li wang software visualization yonghong hao supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author gratefully acknowledges financial support by china scholarship council csc no 201606410033 and the fundamental research funds for the central universities china university of geosciences wuhan grant no cug200612 and the laboratory open project fund of engineering research center of rock soil drilling excavation and protection ministry of education grant no 202002 the third authors acknowledge the support by the national natural science foundation of china grant no 41172282 and no 41672313 the corresponding author acknowledges the partially supported by the u s nsf grant ear1931756 
5032,this study first discusses the conditional mean realizations and effective hydraulic conductivity in a theoretical framework it then introduces monte carlo simulation mcs algorithms for constraining the outcome by either hydraulic conductivity k samples or hydraulic head h measurements from the hydraulic tomographic survey ht it demonstrates that kriging using k measurements leads to a conditional mean k field while inverse modeling using successive linear estimator sle with head measurements of ht yields the conditional effective k field the effects of conditioning using k measurements are different from those using heads besides the conditional effective k leads to the unbiased prediction of the head that honors the observed head at measurement locations more importantly the study reveals that the harmonic and geometric means of conditional realizations of k fields of mcs given head measurements are equivalent to the conditional effective k in one and two dimensional flows respectively the first order approximation in the sle results in a conditional covariance similar to that from mcs with smaller magnitudes despite the difference all approaches predict unbiased conditional mean head behaviors keywords successive linear estimator conditional effective hydraulic conductivity conditional hydraulic conductivity realizations karhunen loeve expansion conditional covariance matrix uncertainty 1 introduction interpreting and extrapolating spatial point data to other locations or estimating spatial distributions of hydraulic properties using sparsely observed system responses is a common problem in hydrology geophysics and other environmental sciences and engineering fields for solving these problems many methods have been developed over the past decades among all these methods kriging is generally a widely used method in the groundwater hydrology field similarly model calibration or inverse modeling is popular for extracting information contained in the responses of aquifers to estimate the spatial distribution of hydraulic parameters franssen et al 2009 while these methods have become routine the logic behind these approaches and characteristics of the estimates are unclear let alone ways to address the uncertainty of these estimates for these purposes we focus on the estimates using kriging and hydraulic tomography ht and explain conditional mean realizations and effective hydraulic conductivity field engrained in these methods ht is a new generation of data collection and inverse modeling strategy many e g tosaka et al 1993 gottlieb and dietrich 1995 proposed the concept of hydraulic tomography ht using pressure variations induced by aquifer pumping to characterize hydraulic property distribution in the aquifer yeh and liu 2000 subsequently developed the first fully 3 d steady state hydraulic tomography using a successive linear estimator sle an inverse algorithm based on the spatial stochastic concept yeh et al 1995 1996 the accuracy and utility of ht were then tested and verified in sandbox experiments by liu et al 2002 later zhu and yeh 2005 developed the transient hydraulic tomography and xiang et al 2009 expanded sle to simsle simultaneous sle which simultaneously includes all the pumping test data sets for tht analysis since then the development and testing of this new technology have thrived more than two hundred seventy related research activities and papers have burgeoned since then initially research on hydraulic tomography consisted largely of numerical studies e g bohling et al 2002 brauchler et al 2003 zhu and yeh 2005 2006 ni and yeh 2008 fienen et al 2008 castagna and bellin 2009 xiang et al 2009 liu and kitanidis 2011 cardiff and barrash 2011 these numerical studies are followed by laboratory sandbox and field studies e g illman et al 2007 2009 liu et al 2007 yin and illman 2009a 2009b cardiff et al 2013 hochstetler et al 2016 sanchez león et al 2016 over the past decades ht has been analyzed mainly using geostatistical inverse models such as sle developed by yeh et al 1996 or quasi linear geostatistical approach qlga developed by kitanidis 1995 other approaches have also been used the pilot point method e g castagna and bellin 2009 lavenue and marsily 2001 a low frequency asymptotic approach by vasco and karasaki 2006 and ray tracing methods e g brauchler et al 2007 these algorithms focus on estimating smooth fields except the recent application of ensemble kalman filters enkfs to ht by schöniger et al 2012 recognizing the stochastic nature of the inverse modeling nowak 2009 advocated the benefits of empirical cross covariances from monte carlo mc analyses in the enkfs in this paper we first use a stochastic formulation to articulate conditional mean effective and realizations of hydraulic conductivity k and head fields we then introduce kriging which estimates the conditional mean k field and the ksa kriging with a superposition approach and the karhunen loeve expansion method klm which derive conditional realizations of k fields conditioned on the k measurements afterward the successive linear estimator sle which derive the effective k field conditioned on some observed heads is discussed subsequently the monte carlo sle slemcs and sle with klm sleklm approaches for generating conditional realizations of k fields which honor the observed heads are proposed we then apply these techniques to one and two dimensional numerical experiments to corroborate the results of the stochastic theories 2 theories before discussing the stochastic theories we assume that the following equations describe the steady state flow field due to pumpings in a saturated heterogeneous porous media 1 k x h x q x 0 with boundary conditions 2 h γ 1 h 1 k x h x n γ 2 q in eq 1 h is the total head l x is the location vector l q is the pumping rate 1 t k is hydraulic conductivity l t in eq 2 h 1 is the prescribed total head on the dirichlet boundary γ 1 and specific discharge q l t is specified on the neumann boundary conditions γ 2 n is a unit vector normal to γ 2 2 1 unconditional realizations and effective k investigation of effects of imposing hydraulic conductivity k and head h on the analysis and simulation of groundwater flow in aquifers is most appropriate to formulate the problem in a stochastic framework and to consider a pumping test at a single well the discussion starts with the case where no point data can be used to condition the hydraulic conductivity or the resulting head fields since k x is spatially varying and challenging to determine it at every location of the aquifer the stochastic analysis conceptualizes k as a random field 3 k x ω k k x ω where k is the unconditional mean the arithmetic average of all possible k realizations which are invariant in the spatial and ensemble the overhead bar stands for the expected value the unconditional perturbations at each x are k x ω where ω is the ensemble realization index ω 1 which are characterized by their unconditional covariance function this covariance specifies the spatial variance the uncertainty of the perturbations and the spatial relationship between perturbations in the ensemble sense or the spatial sense if the spatial domain is sufficiently large i e ergodicity is met accordingly many possible steady head fields h x ω exist in this aquifer induced by a pumping test with a given q these fields are thus a random field 4 h x ω h x h x ω in which h x is the unconditional ensemble mean which varies with x and h x ω is the perturbation at x substituting eqs 3 and 4 into the governing flow equation eq 1 we have 5 k k x ω h x h x ω q monte carlo simulation is one way to derive the possible head fields corresponding to all possible k fields averages of these fields over the ensemble are their means and their variances represent deviations of the means from the true fields instead of all possible h x fields we can seek the unconditional mean of h x ω directly to do so we expand eq 5 and take the expected value of eq 5 to derive an unconditional mean flow equation 6 k h x k x ω h x ω q which can also be rewritten as 7 k eff 2 h x q 0 the term k eff k k x ω h x ω 2 h x 1 is the unconditional effective parameter k eff is often assumed to be invariant in ensemble and space while some analysis e g indelman 2003 showed that it varies with radial distance near the pumping well and then approaches some constant values at large radial distances nevertheless this k eff yields the ensemble mean of h x ω field under all possible heterogeneity given the pumping discharge then the unconditional variance of h x ω gelhar 1986 quantifies the deviation of h x ω from h x 2 2 conditional realizations and mean k with k samples suppose we know the k values at some sampling locations xs and we like to use them for mapping the k distribution of an aquifer to increase the prediction accuracy of the flow field a conditional approach is appropriate which requires a highly parameterized model and k fields that are consistent with the measured k values at the sampling locations for this purpose we formulate a condition flow equation 8 k c x k c x ω h c x h c x ω q where the subscript c denotes conditioned eq 8 is the governing equation for the flow in realizations of k fields conditioned on the k samples notice that the k samples implicitly condition the head eq 8 can serve as the equation in which flow is conditioned on the head measurements to be discussed in section 2 3 solving eq 8 using conditional realizations of k fields k c x k c x ω yields many realizations of heads h c x h c x ω which reflect the effects of conditioning by the k samples notice that k c x and k c x ω represent the conditional mean and perturbation of k respectively while h c x and h c x ω are the conditional mean and perturbations of heads respectively implementation of this solution requires one to generate all possible k field conditioned on the k samples using ksa or klm methods section 3 first and then solves the equation for all conditional head fields this procedure is called the conditional monte carlo simulations conditional mcs the average of all conditional k fields from mcs results in the conditional mean k field while the average of all the simulated head is the conditional mean head field given the k samples alternatively one can expand eq 8 and take its expected value to have 9 k c x h c x k c x ω h c x k c x h c x ω k c x ω h c x ω q recognizing the expected value of the product of a perturbation and a mean of a variable is zero the cross out terms we then normalize k c x ω h x ω with the mean flux k c x h c x and lump the normalized cross covariance with h c x one has k c x h c x 1 k c x ω h c x ω k c x h c x 1 q or 10 k c x h ceff x q which is the conditional mean equation in which k c x is the conditional mean k from kriging that is to say if we use the condition mean k field to solve the flow equation we directly obtain the conditional effective head field h ceff however this head field is not the conditional mean head field from the mcs approach to derive the conditional mean head one can group the normalized covariance with k c x that is k c x 1 k c x ω h c x ω k c x h c x 1 h c x q or 11 k ceff x h c x q solving eq 11 with k ceff x yields the conditioned mean head given the k samples which is identical to the conditioned mean head from mcs this approach however requires k c x ω h c x ω to be known beforehand 2 3 conditional realizations and effective k with head measurements similar to using k measurements to condition the simulated head field this conditional head approach also adopts a highly parameterized conceptual model the governing equation is identical to eq 8 but is for the flow in realizations of unknown k fields conditioned on the head samples that is the mean and perturbation of k and head in eq 8 are conditioned on the head measurements instead of the sampled k to determine these realizations of unknown k fields we need to solve an inverse problem using some algorithms section 3 which can select all possible realizations of k fields with which the groundwater flow model can reproduce the observed heads at the monitoring locations in other words a conditional mcs using slemcs or sleklm algorithm see section 3 is necessary once all possible realizations of k and h fields are obtained their average leads to the conditional mean k and h fields respectively instead of using the mcs most inverse modeling efforts have attempted to seek one possible of k field that can preserve the observed heads when the flow equation is solved to explain the theory we make the use of eq 11 as the conditional mean equation but recognize the equation is conditioned on the observed head rather than the k measurements in this mean equation k ceff x and h c x are the conditional effective hydraulic conductivity and conditional mean heads given the head observations solving the conditional mean equation to match the observed head in a least square sense using an algorithm such as sle section 3 one has the conditional mean head and the effective k field while the effective k is not necessarily the same as the arithmetic mean of all possible conditional realizations of k fields it produces the conditional mean head which is unbiased and preserves the observed heads 3 methods to substantiate the above theories we introduce several methods that derive the conditional mean and realizations of k fields given some k samples we also present methods for deriving conditional effective k and condition realizations of k given some observed heads 3 1 conditional mean k field with k samples kriging is a widely accepted method to derive the conditional mean k field given the sampled k values readers are referred to the description of kriging in textbooks such as kitanidis 1997 and many others 3 2 conditional k realizations with k samples kriging superposition approach ksa to create conditional realizations given some k measurements we use a monte carlo simulation algorithm based on superposition e g yeh 1992 it consists of four steps step 1 use the natural logarithm of k lnk or y to avoid negative estimated values and generate a conditional mean lnk field y c x f where f denotes the given field data using kriging and measured lnk at measurement locations step 2 generate k realizations of the unconditional random field y x ω where ω is the realization index ω 1 k via a random field generator e g gutjahr 1989 with a known mean variance and autocorrelation distances step 3 extract the lnk values from y x ω at the same sample locations as those at the field site then use these sample values and kriging in step 1 to calculate corresponding conditional mean fields y c x ω ω 1 k given these generated samples next we determine the difference between each generated random field and its associated conditional mean field this is 12 d x ω y x ω y c x ω step 4 add the differences in eq 12 to the conditional mean y of the field site from step 1 to derive the conditional realizations 13 y c x ω y c x f d x ω these conditional realizations thus preserve the sample values at the sample locations of the field site since d x ω 0 at these locations at other locations y c x ω s are random variables determined by deviations d x and kriging estimates based on the field observations karhunen loeve expansion method klm in this method y c x ω can be written as 14 y c x ω y c x ω ξ λ g where y c x ω is the conditional mean k derived from kriging or the effective k from sle the last term in the eq 14 ξ λ g is the perturbation term and ξ n y 1 are a set of uncorrelated random variables with zero mean and unit variance i e ξ i 0 ξ i ξ i 1 and ξ i ξ j 0 when i j furthermore g n y are orthogonal eigenvectors λ is a diagonal matrix filling with corresponding nonnegative eigenvalues based on the conditional covariance function the eigenvalues and eigenvectors are obtained by eigenvalue decomposition of the conditional covariance λ yy from kriging 15 λ yy g t λ g the decomposition is easily accomplished by the built in eig function in matlab in which the eig function will automatically selectthe cholesky factorization algorithm to compute the λ and g since the conditional covariance matrix is hermitian ma dong and zhang 2006 mathworks 2005 yaz and azemi 1995 afterward we sort the eigenvalues in the descending order then only the ny eigenvalues and the associated eigenvectors are retained to approximate the perturbation term in eq 14 that is the dimensions of matrix λ and g in the truncated kl expansion are reduced to n y n y at last with given different random variables vectors ξ n y 1 different random fields are generated note that lu and zhang 2004 derived a solution for eigenvalue decomposition in kl expansion which is different from our method 3 3 conditional effective k field with head data while many different inverse methods could be used for this purpose we focus on ht estimates using the successive linear estimator sle yeh et al 1996 which has widely used as we mentioned in the introduction suppose we collect n d observed heads in space denoted by the data vector d during a steady state ht survey the conditional effective y c e f f x with given observations is determined using the following sle 16 y c e f f x r 1 y c e f f x r ω t d d r where r is the iteration index the vector d r is the simulated heads at the observation locations obtained from the forward model i e eqs 1 and 2 using y c e f f x at iteration r when r 0 y c e f f x is the unconditional mean the coefficient matrix ω n d n y denotes the weights which assign the contribution of difference between the observed and simulated head at each observation location to the previously estimated y c e f f x field and the superscript t denotes the transpose this coefficient matrix ω is derived by solving the following equations 17 ε dd r θ r diag ε dd r ω r ε dy r where ε dd is the covariance of the head and ε dy is the cross covariance between lnk and head the parameter θ is a dynamic stability multiplier and diag ε dd is a stability factor which is a diagonal matrix with the same diagonal elements as ε dd the covariance ε dd and cross covariance ε dy can be derived from the first order numerical approximation e g yeh and liu 2000 18 ε dd r j d r ε yy r j d r t ε dy r j d r ε yy r where j d n d n y is the sensitivity jacobian matrix of head data with respect to lnk using the lnk estimated at the current iteration at iteration r 0 the ε yy n y n y is the unconditional covariance of lnk for r 1 the conditional or conditional covariance function are evaluated according to 19 ε yy r 1 ε yy r ω t ε dy the above steps eq 16 through eq 19 are repeated until the convergence of the solution is achieved one convergence criterion is the change in variances of the estimated lnk field between the current iteration and the previous iteration if this criterion is small sle cannot improve the estimates any further the other is the change of simulated heads between successive iterations if this quantity is small the estimates could not further fit the observed heads once one of the two criteria is met we consider the estimates to be optimal and we terminate the iteration the above algorithm can be applied to each pumping test in ht survey sequentially ssle sequential sle zhu and yeh 2005 or all the pumping tests simultaneously simultaneous sle xiang et al 2009 3 4 conditional k realization with head data mcs using sle slemcs besides the conditional effective hydraulic conductivity field sle can generate many possible realizations of y c x ω fields that preserve the observed head and satisfy their underlying statistical properties i e mean and covariance as well as the governing flow equation eqs 1 and 2 similar to the approach proposed by gutjahr et al 1994 hanna and yeh 1998 one way for this purpose is the monte carlo simulation slemcs as described below this approach uses an unconditional realization k field as the starting field and its unconditional covariance is employed as the prior covariance for sle then sle iteratively updates the estimates and conditional covariance until the simulated heads agree with the observed ones once the estimated field converges the estimated lnk field becomes the conditional realization given head measurements of ht survey if we repeat this procedure with other unconditional realizations we then have a conditional mc simulation for ht this approach is analogous to the iterative enkfs nowak 2009 schöniger et al 2012 but it uses sensitivity and the first order analysis to update the conditional covariances as opposed to calculating the conditional covariances using the approximated conditional realizations during each iteration mcs using klm sleklm as an alternative to slemcs sleklm takes advantage of the effective lnk field and the conditional covariance ε yy from sle and then directly uses klm to generate conditional realizations that is klm generates zero mean realizations based on the ε yy at the final iteration from sle which are then added to the effective lnk field from sle to produce the conditional realizations this approach thus avoids the time consuming conditioning mc simulation based on sle as in slemcs approach 4 one dimensional numerical experiments 4 1 case ⅰ conditioning using k measurements for the sake of easy visualization and understanding we use a one dimensional confined aquifer to demonstrate the algorithms above this aquifer is 128 m in length and is discretized into 128 elements each 1 m and 129 nodes each element is assigned a k value from a fast fourier transform fft random field generator gutjahr 1989 the generation assumes that the lnk has a jointly normal distribution with a mean of 1 0 a variance of 1 0 and an exponential correlation structure whose correlation scale equals to 10 m this k field is depicted in fig 1 as the solid black line and the unit of k is m s the k values at x 32 56 and 96 are taken as the hydraulic conductivity measurements red circles in the figure so that there are 125 unknowns of k using three k samples and the exact spatial statistics we derive the conditional mean k field via kriging and conditional realizations of k fields through ksa and klm given the three sample values kriging the conditional mean k field derived by kriging using three k samples is displayed as a green long dashed line in fig 2 this figure also shows the upper and lower bounds of the kriging estimates i e the conditional mean values plus or minus one standard deviation of the kriging respectively ksa the dotted color lines in fig 2 are three realizations from the 2 000 realizations generated from ksa means and standard deviations of the realizations at each location are used to determine the upper and the lower bounds we observe that these means and the upper and lower bounds agree with the conditional mean and the upper and lower bounds derived from kriging mean and variance from fig 2 we observe 1 the conditional means at the sample locations are identical to the values of the samples 2 the conditional mean k captures the general spatial trend of the true lnk field and 3 the closer the location to sampled locations say less than 10 m the smaller fluctuations of the lnk values of the realization we also observe that the smaller the distance to the sample location the narrower the gap between the upper and lower bounds this result indicates that the measurements have strong influences on the k at distances less than 10 m the correlation scale of the heterogeneity from the sampling locations beyond this distance the mean values remain the same as the unconditional mean value in other words the uncertainty of the true field around the conditional mean at these locations remains the same as the variability of lnk i e effects of conditioning are zero the unconditional covariance and the kriging or conditional covariance matrices for this problem are exhibited in fig 3 a and b respectively for the unconditional case the covariance decays rapidly from the diagonal terms according to the correlation scale the kriging i e conditional covariance forms four distinct zones according to the three sample locations and in other areas the covariance is zero due to zero variance at the sample locations klm in this approach the conditional covariance matrix from kriging is directly used in klm to generate 2 000 realizations of conditional lnk fields three of the 2 000 realizations and the true k field are illustrated in fig 4 notice that the realizations are different from those in fig 2 generated with ksa because a different random field generator is used nevertheless the conditional means and the upper and the lower bounds of the realizations from klm are comparable to those derived from ksa besides these realizations from klm honor the sample values at sample locations in summary kriging estimates are conditional means of all the possible realizations in the ensemble they are the means of all the equally likely realizations which agree with the sample values at the sample locations kriging estimates are smoother than the true field since they represent the most likely estimates at the locations where no samples are available and they are the sample values at the sampled locations kriging variance is the statistics that describe the likely deviation of the true field from the conditional means notice that if samples are taken at every location the conditioning means are identical to the true field and the kriging variance or conditional variance is zero everywhere ksa and klm generate conditional realizations which have the same spatial statistics spatial variability of the true field and honor the sample values at the sample locations they are as jagged as the true field but their ensemble averages are similar to the kriging means conditioned head fields to illustrate the effects of conditional mean k field from kriging and conditional realizations of ksa on the prediction of head distributions we create a new 1 d aquifer which has 1 024 elements each 0 125 m with random k values with the same length of the aquifer and spatial statistics as in fig 1 and bounded by constant heads of 1000 m on the both sides we increase the number of element of the aquifer to avoid the ergodicity issue fig 5 a is an illustration of the k field and those from kriging and the average of ksa realizations given the k values at three locations it shows that the kriging mean is identical to the conditional mean of ksa as they should be we then simulate the steady head fields due to pumping at a location with a rate of 0 1 m3 s in fig 5b the simulated head from the kriged field is consistently higher than the true head of the heterogeneous aquifer while the average of the simulated conditional head fields light blue lines in the figure from conditional 1 000 realizations of k fields based on ksa is close to the true field the scatter plots of the simulated head from the kriged k field and that from ksa vs the true field fig 5c also confirms that the kriged k field produces the conditional effective head field and that ksa can yield the conditional mean head field as we have remarked in section 2 2 the results of klm are identical to those of ksa and are not presented however we cautiously point out that the unbiased prediction could vary with the pumping location in particular in 1 d aquifers since flow process ergodicity should also be met yeh et al 2015 because the heterogeneity near the pumping well heavily controls the behavior that is the unbiased prediction will always be true in the average sense over a larger number of pumping tests at different locations 4 2 case ⅱ conditioning using head data in this case two aquifers are considered aq1 and aq2 with an unconditional variance of lnk 1 and 3 respectively which have the same mean correlation scale and random seed number as that in case i the true k fields of the two aquifers are given in fig 6 a and 6b which are bounded by the left hand and right hand prescribed head boundaries of 1000 m seven wells are located at x 16 32 48 64 80 96 and 112 m of the aquifers three pumping stresses are conducted at x 32 64 and 96 individually as the ht survey with a constant discharge q 0 02 m 3 s we then use vsaft2 yeh et al 1993 available at hptt tian hwr arizona edu download to simulate the steady state flow field induced by each test and take the heads at the other six wells for ht analysis the red the green and the orange dotted line in fig 1 are the simulated head field in aq1 for stresses 1 2 and 3 respectively the head in aq2 is not shown using head measurements from the six wells during each test we derive the most likely effective hydraulic conductivity using sle without any k measurements then with the same head measurement locations slemcs derives 2 000 equally likely hydraulic conductivity realizations that preserve the observed heads and so does sleklm the conditional mean and covariance of these k realizations are then calculated to compare with that directly from sle the results of this analysis are given below 4 2 1 slemcs conditional k fields as shown in fig 6a and 6b the conditional effective k field from sle captures the spatial trend of the true k field but is smoother than the true field on the other hand the conditional realizations from slemcs are as erratic as but different from the true field although with a similar trend we also see that the harmonic mean of the conditional k realizations agrees with the conditional effective k while the arithmetic and the geometric mean of the realizations are consistently higher comparison of fig 6a and 6b indicates that deviations of the arithmetic and geometric means from the effective k increase as the unconditional variance of lnk increases the histogram plots in fig 6c and 6d show that the distributions of the true field conditional effective k and k fields from different averages are log normal notice that the distributions of the effective k field and the harmonic mean of slemc are identical and they have similar means as the true field but smaller variances reflecting effects of conditioning i e the posterior distribution in bayesian theory these findings corroborate with the fact that 1 sle produces the conditional effective hydraulic conductivity field as stated in yeh et al 1996 and 2 the effective k in one dimensional flow scenarios is the harmonic average of all possible conditional realizations see yeh et al 2015 conditional head fields to check if the conditional head fields honor the observed heads we simulate head fields corresponding to the three pumping tests using the 2 000 conditional random k fields from slemcs and calculate the conditional means and variances note that the sle approach substitutes the final conditional covariance of lnk ε yy into eq 18 to determine the conditional head covariance ε dd in which the diagonal elements are its conditional variances according to fig 7 a c effective k conditional k realizations and harmonic mean k from slemcs yield head fields that honor the observed heads of each stress they are unbiased estimates of the true head field for each stress even if the unconditional variance of lnk is 3 0 fig 7d f notice that we present only one realization of heads corresponding to one conditional k realization dotted pink line in fig 7 since other realizations behave similarly on the contrary we observe that the arithmetic and geometric means of the conditional k realization form slemcs result in heads departing from the observed with increasing deviations with the variance of lnk these findings manifest that the effective k is not equal to the ensemble arithmetic average of the conditional realizations of k but is their harmonic average the conditional head variances from sle and slemcs are depicted in fig 8 a for the unconditional variance of lnk 1 those for the variance equal to 3 are in fig 8b these figures indicate that the conditional variance of the head at each observation location is zero while the other locations are not the conditional variances of the head from slemcs are larger than those from the first order analysis used in sle and the difference increases with the unconditional variance of lnk these results indicate that the head variances approximated by the first order analysis in sle underestimate the conditional variances of the head conditional covariance of lnk in the case of sle the first order approximation of the conditional covariance matrix of lnk eq 19 at the last iteration is used as the conditional covariance on the other hand the conditional covariance matrix for the slemcs approach is derived from a statistical covariance analysis of the 2 000 conditional realizations the covariance matrices for cases with the unconditional variance of lnk of 1 0 from sle and slemcs are displayed in fig 9 a and b respectively fig 9d and e show the corresponding covariances for the unconditional variance of lnk of 3 0 the patterns of these two conditional covariance matrices are similar although the values from slemcs are larger than those from sle the difference increases with the unconditional variance of lnk fig 9c and f the largest conditional variance of lnk diagonal elements of the matrices is at the location of head measurement while the minimum is at the location between the head observed locations that is the head data at the observation wells reduce the uncertainty of the lnk between the observation wells but not that at the observation well such behavior is distinctly different from the conditional variance resulted from conditioning with lnk measurements fig 3b where the conditional variance is zero at the measurement locations such findings are consistent with the explanation of the impacts of head measurements of ht by yeh et al 2014 notice that the variance is always positive but the covariance can be negative 4 2 2 sleklm slemcs evaluation is computationally intensive since it requires to run sle 2 000 times using 2 000 random realizations as initial fields a new approach i e sleklm is proposed specifically it first employs sle to derive the conditional effective lnk field and conditional covariance matrix of lnk using the conditional covariance of lnk resulting from sle sleklm then generates the zero mean conditional realizations afterward these zero mean realizations are added to the conditional effective lnk field to form the conditional realizations of lnk fields which are then converted to the conditional realizations of k fields a comparison of the efficiency of the two methods of slemcs and sleklm is shown in table 1 using sleklm method takes only a few tenths of the computational time of slemcs while the cpu time required by sle is much less than those of the slemcs and sleklm since sle directly derives the conditional effective k field and associated conditional covariance matrix next we investigate whether these conditional random fields derived from sleklm honor the observed heads at the observed locations during the ht survey for this purpose we use these conditional random fields 2 000 realizations to simulate the ht survey in fig 10 a and b we plot the simulated heads at the observation wells of each pumping test against those heads simulated using the true k field observed true heads these plots show that the simulated heads agree with the observed heads only in an average sense they scatter around the one to one line the conditional variances of the heads from sleklm for different pumping stresses of ht are illustrated in fig 10c and d the head variances at the observation locations are nonzero even though they are much smaller than those at other locations manifesting the effects of head conditioning in other words sleklm does not guarantee the preservation of the head measurements preservation of the observed heads can only be accomplished via solving the governing flow equation rather than generating them from the conditional covariance 5 two dimensional numerical experiments reference field here a two dimensional heterogeneous aquifer with a dimension of 128 m 128 m is discretized into 1024 4 m 4 m elements each element is assigned a k value using the fft random field generator the generated k field see fig 11 i e the true or reference field has the unconditional mean and variance of lnk of 1 0 and an exponential correlation structure with anisotropic correlation scales λ x 40 m and λ y 2 0 m in and y directions respectively the upper and lower sides of the aquifer are no flow boundaries and the left and right sides are constant head boundaries of 1000 m nine wells w1 to w9 are installed and three pumping stresses are conduct at w1 w5 and w8 for ht survey each stress is a constant discharge q 0 05 m 3 s at one of the wells and vsaft2 simulates the steady state flow the simulated heads at the other eight wells are collected for each stress subsequently a total of 24 head measurements for the three tests are simultaneously used for inversion using sle slemcs and sleklm approach without using any k measurement conditional k fields the effective hydraulic conductivity from sle is displayed in fig 12 a with the same head measurements we use slemcs to derive 2 000 conditional k realizations that honor the observed heads the geometric arithmetic and harmonic averages of these realizations are depicted in fig 12b d respectively the scatter plot comparing the true and effective k and the geometric average from slemcs is in fig 12e the scatter plot for the arithmetic and harmonic averages of slemcs vs the true field is in fig 12f from fig 12a and b we notice that the effective k from sle is similar to the geometric mean of the k fields from slemcs both are all unbiased with the true field fig 12e the field from the arithmetic mean of the slemcs generally is larger than the true field while that from the harmonic mean is smaller as shown in fig 12f the patterns of the conditional variance of lnk from sle and slemcs fig 12g and h respectively are similar but the values from slemcs are larger than those from sle both yield small uncertainty of the estimated lnk near the observation positions and significant uncertainty far away from the observation ports especially near the boundary consistent with those in one dimensional results conditional head fields we use the same procedure as in the 1 d case to derive the conditional head fields to check if the conditional head fields honor the observed heads we subtract the conditional head field obtained by the three approaches from the true head field and then take its absolute value to obtain the fig 13 a c only stress 1 is shown the simulated head based on the effective k the average head from slemcs and that from sleklm honor the head observations conditional head standard deviation from slemcs are generally larger than those from the sle and sleklm as shown in fig 13d f although the standard deviation of the head field from the sleklm at the observation wells is not zero the pattern is similar to those from the sle and slemcs approach 6 effect of ensemble size for mcs to ensure our mcs results from the limited domain size are conclusive we investigate the effect of the number of realizations on the ensemble harmonic and the geometric mean of k from slemcs in comparison with the effective k from sle using the mean square error as a criterion 20 mse 1 n i 1 n z i z i 2 this mse measures the difference between z i the effective conductivity from sle and z i the ensemble harmonic or geometric mean of hydraulic conductivity from slemcs n is the total number of elements if the mse value is small then the averages of the slemcs is equivalent to the effective k as shown in fig 14 for 1 d aquifers with the variance of lnk of 1 and 3 the mse value of the harmonic mean of slemcs k h drops rapidly to a minimal value and it stabilizes after about 500 realizations for 2 d aquifers the geometric mean of the slemcs k g also behaves similarly 7 demonstration of the usefulness of the approaches to demonstrate the utility of the sle slemcs and sleklm we used their estimated k fields to predict an independent pumping test using wells not used in the previous ht analysis the independent pumping test experiment uses the same grid size and boundary condition as the 2 d ht experiment but uses different the pumping and observation well locations i e the pumping well p5 with a constant discharge q 0 2 m 3 s and the observation wells p1 p2 p3 and p4 as shown in fig 11 the specific storage 0 02 m is known and uniform over the aquifer the initial head is 1000 m at all nodes and equal to the left and right boundary conditions we then simulate transient drawdown behaviors induced by this pumping based on the true and the estimated k fields from the previous ht analysis from the three different methods the drawdown distribution at the steady state of the true k field is displayed in fig 15 a while fig 15b presents the simulated drawdown distribution using the conditional effective k derived from sle meanwhile the average of 1 000 realizations of simulated drawdown fields using 1 000 conditional realizations of k fields derived from slemcs and sleklm are presented in fig 15c and d respectively the comparisons between the true and the simulated drawdowns using the conditional effective k over the entire aquifer is illustrated in fig 15e as the scatter plot the scatter plot of the averaged drawdowns from slemcs and sleklm vs the true is presented in fig 15f overall the effective k from sle yields unbiased predictions of the drawdown likewise the average of the simulated drawdowns from slemcs and sleklm also are unbiased notice large scatterings at small drawdown values in these scatter plots are attributed to the sparse well network used in the ht survey and log scale plot lastly the usefulness of the monte carlo simulations using slemcs and sleklm for showing the uncertainty of the drawdown at the observation well p1 and p3 are illustrated in fig 16 in all these drawdown time plots the solid black lines are the drawdown curves in the true field while the light blue lines are the 1 000 possible drawdown time curves simulated by the slemcs and sleklm as we have remarked before the sleklm likely underestimates the conditional variance of lnk as such it produces narrow bands of possible drawdown time behaviors besides the results in fig 16 also reveals that the unbiased predictions shown in fig 15 do not apply to observed heads at one or two locations 8 summary and conclusion to explain conditional mean effective and realizations of conductivity fields we develop conditional monte carlo simulation algorithms using hydraulic conductivity measurements namely ksa and klm or based on hydraulic head measurements from the hydraulic tomographic survey slemcs and sleklm results of the analysis of these algorithms can be summarized as follows 1 ksa and klm can generate conditional realizations which have the same spatial statistics as the unconditional k field also they yield conditional mean and covariance which are the same as the kriging mean and conditional covariance 2 interpretation of ht data using sle yields a conditional effective hydraulic conductivity field and the conditional covariance of the estimated field given the head discharge and boundary information during the ht survey on the other hand slemcs produce conditional realizations equally likely hydraulic conductivity fields that honor the observed heads during ht surveys and are as jagged as the true field the conditional effective hydraulic conductivity of sle is close to the harmonic average of all these realizations for one dimensional flow but agrees with the geometric average for two dimensional flow the covariance functions of these realizations from slemcs are similar in pattern with that of the conditional covariance function of sle although the values from slemcs are larger than those from sle and the deviation increases with the unconditional variance of lnk 3 sleklm can efficiently generate conditional realizations of hydraulic conductivity fields by taking advantage of sle s conditional effective hydraulic conductivity field and conditional covariance function however the simulated heads from the generated conditional realizations of k match the observed head data of ht survey only in the average sense 4 applications of sle slemcs and sleklm to an independent flow event demonstrate that all approaches yield unbiased prediction of the true head field and the uncertainty of drawdown around the observed locations from sleklm are small based on these results we come to the following conclusions 1 the effects of conditioning using k and head measurements are different 2 harmonic and geometric averages of conditional hydraulic conductivity realizations are equivalent to the effective hydraulic conductivity derived from sle for one and two dimensional flow problems respectively 3 the effective hydraulic conductivity from ht can predict head fields that are unbiased and preserve the observed heads during each ht pumping test it also yields an unbiased prediction of the head field under a different flow scenario 4 while sleklm is more computationally efficient than slemcs but its conditional variance is smaller than that of slemcs on the other hand sle and a first order analysis is a computationally efficient approach for the same purpose but derives only conditional variances without the generation of conditional realizations lastly as stated in yeh et al 2015 the uncertainty analysis is not to seek absolute uncertainty but to gauge the relative uncertainty between different operational strategies therefore we recommend the use of sle or sleklm for practical applications due to their computational efficiency moreover if we just estimate the head and its uncertainty we recommend the sle method since it can directly derive the best unbiased k estimates honoring the observations and the conditional covariance addressing the uncertainty of estimates and it also avoids the mc intensive computational efforts however if we need to estimate the uncertainty of flow and concentration fields and derive possible realizations we suggest the conditional realizations from slemcs and sleklm credit authorship contribution statement xu gao conceptualization formal analysis writing original draft tian chyi jim yeh methodology software writing review editing e chuan yan validation supervision yu li wang software visualization yonghong hao supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the first author gratefully acknowledges financial support by china scholarship council csc no 201606410033 and the fundamental research funds for the central universities china university of geosciences wuhan grant no cug200612 and the laboratory open project fund of engineering research center of rock soil drilling excavation and protection ministry of education grant no 202002 the third authors acknowledge the support by the national natural science foundation of china grant no 41172282 and no 41672313 the corresponding author acknowledges the partially supported by the u s nsf grant ear1931756 
5033,hydrological conditions are a critical factor for phytoplankton ecology in hydroelectric reservoirs and how this factor contributes to the succession of phytoplankton functional groups is still unclear therefore we investigated the phytoplankton functional groups relative water column stability and related environmental factors in the wujiang cascade reservoirs to understand this process altogether five phyla and thirteen functional groups were identified and they showed evident variations across space and time the b d p and j groups were dominant and the lo and x1 groups existed only in the reservoirs relative water column stability rather than nutrient availability affects the succession and distribution of phytoplankton functional groups in the study area and high relative water column stability usually increases phytoplankton biomass this indicates that hydrologic conditions are an important factor controlling phytoplankton composition in hydroelectric reservoirs and this study enriches the understanding of reservoir phytoplankton ecology keywords relative water column stability phytoplankton functional groups hydroelectric reservoirs wujiang river 1 introduction dam construction is a growing anthropogenic disturbance in natural rivers globally meybeck 1981 milliman 1997 klaver et al 2007 dai and liu 2013 guo et al 2020 an estimated 70 of the world s rivers are interrupted by dams and the construction and operation of more than 50 000 large dams 15 m high worldwide have severely altered the global flux of water and sediments from continents to oceans vörösmarty et al 1997 poff et al 2007 syvitski et al 2005 dai et al 2011 ehsani et al 2017 ocko and hamburg 2019 although reservoirs provide many benefits to humankind they can cause potential ecological disturbances by interrupting the river continuum ittekkot 1988 chen et al 2015 maberly and wang 2018 it is well known that environmental variables such as water temperature light and nutrient availability have a significant effect on reservoir phytoplankton loza et al 2014 descy et al 2016 however few studies have examined the relationship between hydrological forces and phytoplankton which is sensitive to hydrological variation due to dam construction mitrovic et al 2003 zhu et al 2013 yang et al 2017 zhang et al 2019 recently phytoplankton functional groups have proven to be an efficient indicator for understanding seasonal changes in phytoplankton communities becker et al 2008 salmaso et al 2015 de souza et al 2016 cao et al 2018 qu et al 2019 long et al 2020 the classification of reynolds et al 2002 consists of a system comprising 31 functional groups codons according to their morphological and physiological adaptive strategies a subsequent review by padisák et al 2009 reported more than 40 codons although not all of them are sufficiently substantiated in the final classification water movement in cascade reservoirs can be indicated by relative water column stability rwcs which is calculated by comparing the density gradient of the whole water column to the density difference between pure water at 4 c and 5 c becker et al 2008 in this study we hypothesized that variation in the phytoplankton community is greatly due to water movement in cascade reservoirs to test this hypothesis we investigated phytoplankton functional groups the rwcs and related physicochemical variables including ph dissolved oxygen water temperature and nutrients in four cascade reservoirs on the wujiang river southwest china as it is an ideal river for cascade hydropower exploitation we try to use the functional group theory reynolds et al 2002 to explain the intrinsic mechanisms affecting phytoplankton growth and functional group succession in the impounded wujiang river the main objective of this study is to understand the importance of rwcs in regulating phytoplankton functional groups and biomass 2 sampling and methods 2 1 study area the wujiang river originates from the wumeng ranges and it is a southern tributary of the changjiang river with a length of 1037 km a drainage area of 8 8 104 km2 and an average runoff of 53 4 109 m3 han et al 2010 the elevation of the wujiang river ranges from 500 to 1500 m the annual precipitation ranges from 850 to 1600 mm and rainfall from may to october accounts for 80 of the total annual precipitation the wujiang river has a mean annual air temperature from 10 to 18 c wang et al 2010 in this study four reservoirs hongjiadu reservoir hjd dongfeng reservoir df suofengying reservoir sfy and wujiangdu reservoir wjd situated in the middle upper reaches of the wujiang river were investigated fig 1 a total of 17 sites were investigated including w1 w2 w6 w7 w11 w13 and w17 as the sites of the inflowing and released waters and w3 5 hjd w8 10 df w12 sfy and w14 16 wjd as the reservoir waters fig 1 by 2016 the hjd df sfy and wjd reservoirs had been operated for twelve years twenty two years thirty eight years and ten years respectively table 1 these reservoirs serve multiple uses such as drinking water irrigation electric energy generation and recreation wang et al 2010 2 2 sampling and analysis the sampling campaigns were conducted in october 2015 and january april and july 2016 which represent autumn winter spring and summer respectively water samples were taken from the depth profile at 0 5 15 30 and 60 m at sites w5 w10 and w16 and from the surface 0 m middle 30 m and bottom layers 60 m at sites w3 w4 w8 w9 w14 and w15 with the other water samples collected 0 5 m beneath the surface fig 1 water temperature ph and dissolved oxygen do were measured in situ with a calibrated automated multiparameter ysi 6600 profiler xylem inc usa the water samples were stored in a refrigerator at 4 c for analyses of total nitrogen tn total phosphorus tp and dissolved silicon dsi tn and tp were determined spectrophotometrically unico uv 2000 usa after alkaline potassium persulfate digestion epa 1988 dsi was analyzed by inductively coupled plasma optical emission spectrometry icp oes usa the detection limit was 0 05 mg l 1 for tn 0 01 mg l 1 for tp and 0 7 mg l 1 for dsi respectively the analytical precision for nutrients was estimated by repeated determinations of samples and was better than 3 chai et al 2009 chlorophyll a chl a content was determined using a calibrated walz phyto pam ed pulse amplitude modulated fluorescence system heinz walz gmbh germany with a detection limit of 0 01 mg m 3 parsons et al 1984 water samples 1 5 l were preserved with lugol s solution for the quantitative analysis of phytoplankton phytoplankton samples used in the qualitative analysis were collected with a 64 μm nylon mesh and preserved with a 2 formaldehyde solution taxon identification counting and cell dimensions were implemented according to the methods of zhang and huang 1991 the biovolume of algal species was geometrically calculated hillebrand et al 1999 and wet weight mg l 1 of the phytoplankton biomass was calculated with its biovolume and cell density zhang and huang 1991 species contributing more than 10 to the total biomass were classified into the dominant functional groups using the criteria of reynolds et al 2002 and padisák et al 2009 2 3 calculations shannon wiener diversity h was calculated with eq 1 shannon and weaver 1949 h i 1 s n i n log2 n i n 1 s indicates the total number of algal species n represents the total species number of phytoplankton and ni represents the number of ith species the relative water column stability rwcs a dimensionless parameter that can be used to reflect the degree of thermal stratification and water movement was expressed by eq 2 padisák et al 2003 becker et al 2008 zhu et al 2013 pu et al 2020 2 rwcs ρb ρw ρ4 ρ5 in the formula ρb and ρw represent the bottom water density g cm 3 and water density at a certain depth g cm 3 respectively for the studied reservoirs a depth of 60 m was artificially considered bottom water ρ4 and ρ5 represent the pure water density g cm 3 at 4 c and 5 c respectively the water density is a function of water temperature c and can be calculated from the empirical formula lawson and anderson 2007 3 ρ t 1000 1 t 288 9414 508929 2 t 68 1296 t 3 9863 2 2 4 statistical analysis the relationship between the phytoplankton community and physicochemical factors was analyzed using pearson s correlation coefficient in addition redundancy analysis rda was applied to analyze the factors affecting the phytoplankton community structure using ln transformed data the rda was based on the results of a detrended correspondence analysis dca of the aforementioned data in which the lengths of the gradients were shorter than 3 pełechata et al 2016 the ordination analyses were performed using canoco version 4 5 ter braak and šmilauer 2002 and other statistical analyses were carried out using spss 19 0 ibm usa software packages at a significance level p value of 0 05 3 results 3 1 basic physical and chemical properties the surface water temperatures ranged from 11 0 to 28 2 c with an average of 17 9 c no significant difference in the water temperature was noted between the reservoirs but the released water had a lower water temperature than the inflowing and reservoir waters fig 2 a for example the average water temperature of the released water in the hjd df sfy and wjd reservoirs decreased to 15 1 c 16 1 c 16 2 c and 16 3 c respectively in response the spatial variations in ph and do were similar to those in water temperature and the reservoir surface water showed higher ph and do than the river water fig 2b and c the reservoirs were strongly stratified from may to september and the stratification disappeared gradually from october to next april in the water profile do and ph decreased with water depth the average tp varied seasonally with the highest value in the summer 0 23 mg l 1 and the lowest value in the winter 0 17 mg l 1 in contrast the average tn and dsi contents in summer were lower than those in winter the released water usually had higher tn tp and dsi contents than the inflowing and reservoir waters for example the average dsi content of released water in the hjd df sfy and wjd reservoirs increased to 3 30 mg l 1 3 59 mg l 1 3 82 mg l 1 and 2 82 mg l 1 respectively fig 2d e and f in the water profile the tn tp and dsi contents usually increased with water depth fig 3 3 2 relative water column stability the reservoir rwcs showed no significant differences in the average values among the reservoirs and varied seasonally with the highest value in the summer 301 41 and the lowest value in the winter 10 11 reservoir surface water usually had significantly higher rwcs than the inflowing and released waters fig 2g there was apparent summer rwcs stratification in the reservoirs which covaried with the thermal stratification in the water profile fig 3 3 3 biomass and functional groups of phytoplankton the average phytoplankton biomass in the surface water varied seasonally with the highest value in the summer 0 44 mg l 1 and the lowest value in the winter 0 20 mg l 1 the reservoir water usually had higher biomass than the inflowing and released waters with the highest value at station w16 in the wjd reservoir 2 86 mg l 1 fig 2h in the water profile the biomass significantly decreased with water depth fig 3 a total of five taxonomic groups and thirteen functional groups were recorded in the study area the b cyclotella sp kützing brébisson d synedra sp ehrenberg and p aulacoseira granulata ehrenberg simonsen and fragilaria sp lyngbye groups were the dominant functional groups throughout the year accounting for 10 of the total biomass fig 4 a b and c additionally the j group hariotina reticulata p a dangeard coelastrum microporum nägeli scenedesmus obtusus meyen tetradesmus obliquus turpin m j wynne and tetraëdron minimum a braun hansgirg became a dominant functional group only in the reservoir area in summer and the lo chroococcus sp nägeli and peridinium sp ehrenberg and x1 chlorella vulgaris beyerinck beijerinck and ankistrodesmus falcatus corda ralfs groups only existed in the reservoir area fig 2a b and table 2 interestingly the x1 group mainly emerged in the winter while the lo group was present only in the summer fig 4a and b therefore regarding the dominant functional groups the succession of the b d and p groups to the b d p and j groups from the winter to the summer was observed moreover the reservoir water had a higher h than the inflowing and released waters which was consistent with the rwcs variations in the reservoirs fig 4c 3 4 redundancy analysis rda axis one and axis two of the rda explained 90 8 and 6 4 of variation in the phytoplankton functional groups respectively and variations in the phytoplankton functional groups were found to be related to water temperature ph nutrients and the rwcs fig 5 a among them the rwcs had a significantly positive correlation with axis 1 r 0 65 p 0 01 suggesting that the phytoplankton functional groups were strongly influenced by the rwcs fig 5b 4 discussion 4 1 environmental factors influencing phytoplankton biomass and community structure the factors influencing phytoplankton biomass and communities usually include water temperature light and nutrient availability kimmel and groeger 1984 water temperature showed significant positive correlations with phytoplankton biomass table 3 suggesting that it is a key factor controlling phytoplankton biomass in these cascade reservoirs an increase in water temperature can enhance photosynthetic rates neori and holm hansen 1982 and thus lead to an increase in phytoplankton biomass in addition phytoplankton biomass was significantly positively correlated with water temperature do and ph table 3 this is because phytoplankton uptake co2 and release o2 which can result in an increase in ph and do liu et al 2012 although n p molar ratios 50 indicate phosphorus limitation guildford and hecky 2000 phosphorus may not be a limiting factor for phytoplankton growth in these reservoirs because the tp concentrations were relatively high and there was not a significant positive correlation between tp and chl a in turn nutrient assimilation by phytoplankton resulted in a decrease in the dsi concentration therefore dsi concentrations showed a significant negative correlation with the chl a concentration and the biomass of the b group the b group is composed of diatoms and sensitive to dsi availability reynolds 1998 reynolds et al 2002 padisák et al 2009 codon j showed similar seasonal variation to group b and its biomass increased sharply in the summer fig 6 leading to a nominal negative relationship between the j group and dsi 4 2 rwcs drives the succession of phytoplankton functional groups hydrological conditions constitute a basic background for the variation in physical chemical and biological factors of hydroelectric reservoirs liang et al 2019 wang et al 2019 yang et al 2020 after dam interception the rwcs is enhanced with increasing water retention time in the hydroelectric reservoirs fig 2g and the succession of functional groups takes place during the change from river to reservoir fig 4 table 2 which is consistent with previous studies becker et al 2010 zhu et al 2013 de souza et al 2016 liu et al 2019 in addition thermal stratification results in rwcs differences in the water profile and a high rwcs appears in the upper layer of the reservoirs codon b which is often subject to the availability of dsi and depends on turbulence can be found at the seasonal onset of near surface thermal stratification reynolds et al 2002 padisák et al 2009 varol 2019 the d and p groups favor high light and an abundance of nutrients and usually appear in shallow nutrient enriched well ventilated waters as well as in the epilimnion of stratified lakes padisák et al 2009 therefore the high rwcs in the upper layer of the reservoirs facilitates their growth group j favors high water temperature and rwcs table 3 padisák et al 2009 de souza et al 2016 making it dominant in july fig 6c codon j has been reported as the dominant group in the thermal stratification period with high rwcs in a reservoir varol 2019 moreover during this time the phytoplankton biomass increases sharply and thus positively correlates with the rwcs figs 6 and 7 table 3 therefore they showed similar variations with time and space in the reservoirs fig 3 the reservoir had a higher phytoplankton diversity index i e h than the inflowing and released waters fig 4c and the lo and x1 groups were found only in the reservoir area codon lo was represented by the motile peridinium sp and by colonial species enveloped in mucilage such as chroococcus sp in the reservoirs and thus has better adaptability to the relative high rwcs caused by thermal stratification reynolds et al 2002 dantas et al 2012 žutinić et al 2014 group x1 includes small and slim single celled chlorophyta that are sensitive to nutrient deficiency and usually tend to be present in shallow mixed layers with low rwcs reynolds et al 2002 padisák et al 2009 kruk et al 2010 xiao et al 2011 in contrast codon mp represented by unicellular diatoms and characterized by high surface to volume ratios shows adaptability to low light and turbid habitats and usually lies in the lower layer in the water column fig 7 bovo scomparin and train 2008 as reported for a subtropical brazilian reservoir mp group prefers turbid habit and is associated with low water residence time de souza et al 2016 therefore the hydrological changes that occur during the filling of the reservoir act as a major force driving the succession of phytoplankton functional groups 5 conclusions a total of thirteen phytoplankton functional groups were recorded in the impounded wujiang river and they showed evident variations across space and time functional group succession usually takes place during changes from a river to a reservoir and seasonal alternation fig 7 the rwcs rather than nutrient availability affects the succession and distribution of phytoplankton functional groups suggesting that hydrologic conditions are an important factor controlling the phytoplankton community structure in hydroelectric reservoirs this study will be of great significance for insight into the hydraulic control mechanisms of phytoplankton ecology in karst hydroelectric reservoirs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the kind help of their team in the field work this work was financially supported by the national natural science foundation of china u1612441 and u1612442 and the national key r d program of china 2016yfa0601001 
5033,hydrological conditions are a critical factor for phytoplankton ecology in hydroelectric reservoirs and how this factor contributes to the succession of phytoplankton functional groups is still unclear therefore we investigated the phytoplankton functional groups relative water column stability and related environmental factors in the wujiang cascade reservoirs to understand this process altogether five phyla and thirteen functional groups were identified and they showed evident variations across space and time the b d p and j groups were dominant and the lo and x1 groups existed only in the reservoirs relative water column stability rather than nutrient availability affects the succession and distribution of phytoplankton functional groups in the study area and high relative water column stability usually increases phytoplankton biomass this indicates that hydrologic conditions are an important factor controlling phytoplankton composition in hydroelectric reservoirs and this study enriches the understanding of reservoir phytoplankton ecology keywords relative water column stability phytoplankton functional groups hydroelectric reservoirs wujiang river 1 introduction dam construction is a growing anthropogenic disturbance in natural rivers globally meybeck 1981 milliman 1997 klaver et al 2007 dai and liu 2013 guo et al 2020 an estimated 70 of the world s rivers are interrupted by dams and the construction and operation of more than 50 000 large dams 15 m high worldwide have severely altered the global flux of water and sediments from continents to oceans vörösmarty et al 1997 poff et al 2007 syvitski et al 2005 dai et al 2011 ehsani et al 2017 ocko and hamburg 2019 although reservoirs provide many benefits to humankind they can cause potential ecological disturbances by interrupting the river continuum ittekkot 1988 chen et al 2015 maberly and wang 2018 it is well known that environmental variables such as water temperature light and nutrient availability have a significant effect on reservoir phytoplankton loza et al 2014 descy et al 2016 however few studies have examined the relationship between hydrological forces and phytoplankton which is sensitive to hydrological variation due to dam construction mitrovic et al 2003 zhu et al 2013 yang et al 2017 zhang et al 2019 recently phytoplankton functional groups have proven to be an efficient indicator for understanding seasonal changes in phytoplankton communities becker et al 2008 salmaso et al 2015 de souza et al 2016 cao et al 2018 qu et al 2019 long et al 2020 the classification of reynolds et al 2002 consists of a system comprising 31 functional groups codons according to their morphological and physiological adaptive strategies a subsequent review by padisák et al 2009 reported more than 40 codons although not all of them are sufficiently substantiated in the final classification water movement in cascade reservoirs can be indicated by relative water column stability rwcs which is calculated by comparing the density gradient of the whole water column to the density difference between pure water at 4 c and 5 c becker et al 2008 in this study we hypothesized that variation in the phytoplankton community is greatly due to water movement in cascade reservoirs to test this hypothesis we investigated phytoplankton functional groups the rwcs and related physicochemical variables including ph dissolved oxygen water temperature and nutrients in four cascade reservoirs on the wujiang river southwest china as it is an ideal river for cascade hydropower exploitation we try to use the functional group theory reynolds et al 2002 to explain the intrinsic mechanisms affecting phytoplankton growth and functional group succession in the impounded wujiang river the main objective of this study is to understand the importance of rwcs in regulating phytoplankton functional groups and biomass 2 sampling and methods 2 1 study area the wujiang river originates from the wumeng ranges and it is a southern tributary of the changjiang river with a length of 1037 km a drainage area of 8 8 104 km2 and an average runoff of 53 4 109 m3 han et al 2010 the elevation of the wujiang river ranges from 500 to 1500 m the annual precipitation ranges from 850 to 1600 mm and rainfall from may to october accounts for 80 of the total annual precipitation the wujiang river has a mean annual air temperature from 10 to 18 c wang et al 2010 in this study four reservoirs hongjiadu reservoir hjd dongfeng reservoir df suofengying reservoir sfy and wujiangdu reservoir wjd situated in the middle upper reaches of the wujiang river were investigated fig 1 a total of 17 sites were investigated including w1 w2 w6 w7 w11 w13 and w17 as the sites of the inflowing and released waters and w3 5 hjd w8 10 df w12 sfy and w14 16 wjd as the reservoir waters fig 1 by 2016 the hjd df sfy and wjd reservoirs had been operated for twelve years twenty two years thirty eight years and ten years respectively table 1 these reservoirs serve multiple uses such as drinking water irrigation electric energy generation and recreation wang et al 2010 2 2 sampling and analysis the sampling campaigns were conducted in october 2015 and january april and july 2016 which represent autumn winter spring and summer respectively water samples were taken from the depth profile at 0 5 15 30 and 60 m at sites w5 w10 and w16 and from the surface 0 m middle 30 m and bottom layers 60 m at sites w3 w4 w8 w9 w14 and w15 with the other water samples collected 0 5 m beneath the surface fig 1 water temperature ph and dissolved oxygen do were measured in situ with a calibrated automated multiparameter ysi 6600 profiler xylem inc usa the water samples were stored in a refrigerator at 4 c for analyses of total nitrogen tn total phosphorus tp and dissolved silicon dsi tn and tp were determined spectrophotometrically unico uv 2000 usa after alkaline potassium persulfate digestion epa 1988 dsi was analyzed by inductively coupled plasma optical emission spectrometry icp oes usa the detection limit was 0 05 mg l 1 for tn 0 01 mg l 1 for tp and 0 7 mg l 1 for dsi respectively the analytical precision for nutrients was estimated by repeated determinations of samples and was better than 3 chai et al 2009 chlorophyll a chl a content was determined using a calibrated walz phyto pam ed pulse amplitude modulated fluorescence system heinz walz gmbh germany with a detection limit of 0 01 mg m 3 parsons et al 1984 water samples 1 5 l were preserved with lugol s solution for the quantitative analysis of phytoplankton phytoplankton samples used in the qualitative analysis were collected with a 64 μm nylon mesh and preserved with a 2 formaldehyde solution taxon identification counting and cell dimensions were implemented according to the methods of zhang and huang 1991 the biovolume of algal species was geometrically calculated hillebrand et al 1999 and wet weight mg l 1 of the phytoplankton biomass was calculated with its biovolume and cell density zhang and huang 1991 species contributing more than 10 to the total biomass were classified into the dominant functional groups using the criteria of reynolds et al 2002 and padisák et al 2009 2 3 calculations shannon wiener diversity h was calculated with eq 1 shannon and weaver 1949 h i 1 s n i n log2 n i n 1 s indicates the total number of algal species n represents the total species number of phytoplankton and ni represents the number of ith species the relative water column stability rwcs a dimensionless parameter that can be used to reflect the degree of thermal stratification and water movement was expressed by eq 2 padisák et al 2003 becker et al 2008 zhu et al 2013 pu et al 2020 2 rwcs ρb ρw ρ4 ρ5 in the formula ρb and ρw represent the bottom water density g cm 3 and water density at a certain depth g cm 3 respectively for the studied reservoirs a depth of 60 m was artificially considered bottom water ρ4 and ρ5 represent the pure water density g cm 3 at 4 c and 5 c respectively the water density is a function of water temperature c and can be calculated from the empirical formula lawson and anderson 2007 3 ρ t 1000 1 t 288 9414 508929 2 t 68 1296 t 3 9863 2 2 4 statistical analysis the relationship between the phytoplankton community and physicochemical factors was analyzed using pearson s correlation coefficient in addition redundancy analysis rda was applied to analyze the factors affecting the phytoplankton community structure using ln transformed data the rda was based on the results of a detrended correspondence analysis dca of the aforementioned data in which the lengths of the gradients were shorter than 3 pełechata et al 2016 the ordination analyses were performed using canoco version 4 5 ter braak and šmilauer 2002 and other statistical analyses were carried out using spss 19 0 ibm usa software packages at a significance level p value of 0 05 3 results 3 1 basic physical and chemical properties the surface water temperatures ranged from 11 0 to 28 2 c with an average of 17 9 c no significant difference in the water temperature was noted between the reservoirs but the released water had a lower water temperature than the inflowing and reservoir waters fig 2 a for example the average water temperature of the released water in the hjd df sfy and wjd reservoirs decreased to 15 1 c 16 1 c 16 2 c and 16 3 c respectively in response the spatial variations in ph and do were similar to those in water temperature and the reservoir surface water showed higher ph and do than the river water fig 2b and c the reservoirs were strongly stratified from may to september and the stratification disappeared gradually from october to next april in the water profile do and ph decreased with water depth the average tp varied seasonally with the highest value in the summer 0 23 mg l 1 and the lowest value in the winter 0 17 mg l 1 in contrast the average tn and dsi contents in summer were lower than those in winter the released water usually had higher tn tp and dsi contents than the inflowing and reservoir waters for example the average dsi content of released water in the hjd df sfy and wjd reservoirs increased to 3 30 mg l 1 3 59 mg l 1 3 82 mg l 1 and 2 82 mg l 1 respectively fig 2d e and f in the water profile the tn tp and dsi contents usually increased with water depth fig 3 3 2 relative water column stability the reservoir rwcs showed no significant differences in the average values among the reservoirs and varied seasonally with the highest value in the summer 301 41 and the lowest value in the winter 10 11 reservoir surface water usually had significantly higher rwcs than the inflowing and released waters fig 2g there was apparent summer rwcs stratification in the reservoirs which covaried with the thermal stratification in the water profile fig 3 3 3 biomass and functional groups of phytoplankton the average phytoplankton biomass in the surface water varied seasonally with the highest value in the summer 0 44 mg l 1 and the lowest value in the winter 0 20 mg l 1 the reservoir water usually had higher biomass than the inflowing and released waters with the highest value at station w16 in the wjd reservoir 2 86 mg l 1 fig 2h in the water profile the biomass significantly decreased with water depth fig 3 a total of five taxonomic groups and thirteen functional groups were recorded in the study area the b cyclotella sp kützing brébisson d synedra sp ehrenberg and p aulacoseira granulata ehrenberg simonsen and fragilaria sp lyngbye groups were the dominant functional groups throughout the year accounting for 10 of the total biomass fig 4 a b and c additionally the j group hariotina reticulata p a dangeard coelastrum microporum nägeli scenedesmus obtusus meyen tetradesmus obliquus turpin m j wynne and tetraëdron minimum a braun hansgirg became a dominant functional group only in the reservoir area in summer and the lo chroococcus sp nägeli and peridinium sp ehrenberg and x1 chlorella vulgaris beyerinck beijerinck and ankistrodesmus falcatus corda ralfs groups only existed in the reservoir area fig 2a b and table 2 interestingly the x1 group mainly emerged in the winter while the lo group was present only in the summer fig 4a and b therefore regarding the dominant functional groups the succession of the b d and p groups to the b d p and j groups from the winter to the summer was observed moreover the reservoir water had a higher h than the inflowing and released waters which was consistent with the rwcs variations in the reservoirs fig 4c 3 4 redundancy analysis rda axis one and axis two of the rda explained 90 8 and 6 4 of variation in the phytoplankton functional groups respectively and variations in the phytoplankton functional groups were found to be related to water temperature ph nutrients and the rwcs fig 5 a among them the rwcs had a significantly positive correlation with axis 1 r 0 65 p 0 01 suggesting that the phytoplankton functional groups were strongly influenced by the rwcs fig 5b 4 discussion 4 1 environmental factors influencing phytoplankton biomass and community structure the factors influencing phytoplankton biomass and communities usually include water temperature light and nutrient availability kimmel and groeger 1984 water temperature showed significant positive correlations with phytoplankton biomass table 3 suggesting that it is a key factor controlling phytoplankton biomass in these cascade reservoirs an increase in water temperature can enhance photosynthetic rates neori and holm hansen 1982 and thus lead to an increase in phytoplankton biomass in addition phytoplankton biomass was significantly positively correlated with water temperature do and ph table 3 this is because phytoplankton uptake co2 and release o2 which can result in an increase in ph and do liu et al 2012 although n p molar ratios 50 indicate phosphorus limitation guildford and hecky 2000 phosphorus may not be a limiting factor for phytoplankton growth in these reservoirs because the tp concentrations were relatively high and there was not a significant positive correlation between tp and chl a in turn nutrient assimilation by phytoplankton resulted in a decrease in the dsi concentration therefore dsi concentrations showed a significant negative correlation with the chl a concentration and the biomass of the b group the b group is composed of diatoms and sensitive to dsi availability reynolds 1998 reynolds et al 2002 padisák et al 2009 codon j showed similar seasonal variation to group b and its biomass increased sharply in the summer fig 6 leading to a nominal negative relationship between the j group and dsi 4 2 rwcs drives the succession of phytoplankton functional groups hydrological conditions constitute a basic background for the variation in physical chemical and biological factors of hydroelectric reservoirs liang et al 2019 wang et al 2019 yang et al 2020 after dam interception the rwcs is enhanced with increasing water retention time in the hydroelectric reservoirs fig 2g and the succession of functional groups takes place during the change from river to reservoir fig 4 table 2 which is consistent with previous studies becker et al 2010 zhu et al 2013 de souza et al 2016 liu et al 2019 in addition thermal stratification results in rwcs differences in the water profile and a high rwcs appears in the upper layer of the reservoirs codon b which is often subject to the availability of dsi and depends on turbulence can be found at the seasonal onset of near surface thermal stratification reynolds et al 2002 padisák et al 2009 varol 2019 the d and p groups favor high light and an abundance of nutrients and usually appear in shallow nutrient enriched well ventilated waters as well as in the epilimnion of stratified lakes padisák et al 2009 therefore the high rwcs in the upper layer of the reservoirs facilitates their growth group j favors high water temperature and rwcs table 3 padisák et al 2009 de souza et al 2016 making it dominant in july fig 6c codon j has been reported as the dominant group in the thermal stratification period with high rwcs in a reservoir varol 2019 moreover during this time the phytoplankton biomass increases sharply and thus positively correlates with the rwcs figs 6 and 7 table 3 therefore they showed similar variations with time and space in the reservoirs fig 3 the reservoir had a higher phytoplankton diversity index i e h than the inflowing and released waters fig 4c and the lo and x1 groups were found only in the reservoir area codon lo was represented by the motile peridinium sp and by colonial species enveloped in mucilage such as chroococcus sp in the reservoirs and thus has better adaptability to the relative high rwcs caused by thermal stratification reynolds et al 2002 dantas et al 2012 žutinić et al 2014 group x1 includes small and slim single celled chlorophyta that are sensitive to nutrient deficiency and usually tend to be present in shallow mixed layers with low rwcs reynolds et al 2002 padisák et al 2009 kruk et al 2010 xiao et al 2011 in contrast codon mp represented by unicellular diatoms and characterized by high surface to volume ratios shows adaptability to low light and turbid habitats and usually lies in the lower layer in the water column fig 7 bovo scomparin and train 2008 as reported for a subtropical brazilian reservoir mp group prefers turbid habit and is associated with low water residence time de souza et al 2016 therefore the hydrological changes that occur during the filling of the reservoir act as a major force driving the succession of phytoplankton functional groups 5 conclusions a total of thirteen phytoplankton functional groups were recorded in the impounded wujiang river and they showed evident variations across space and time functional group succession usually takes place during changes from a river to a reservoir and seasonal alternation fig 7 the rwcs rather than nutrient availability affects the succession and distribution of phytoplankton functional groups suggesting that hydrologic conditions are an important factor controlling the phytoplankton community structure in hydroelectric reservoirs this study will be of great significance for insight into the hydraulic control mechanisms of phytoplankton ecology in karst hydroelectric reservoirs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the kind help of their team in the field work this work was financially supported by the national natural science foundation of china u1612441 and u1612442 and the national key r d program of china 2016yfa0601001 
5034,it is commonly accepted in geospatial analysis that automated calculation of thalweg networks from a digital elevation model produces a theoretical flow system that overall represents the branching of in place hydrographic networks however in detail this theoretical network is too different from the natural river network to substitute for the systematic digitization of rivers numerous papers seek to optimize numeric calculations to reduce this discrepancy but none has proposed to use this difference as data specific to the context under study toward this end the principal idea behind the idpr network development and persistence index is to apply a particular metric to disparity measurements between the theoretical drainage system produced by the raw automatic analysis of a digital model and the field reality represented by branching rivers by measuring the difference between a simplified modeling of water pathways based on a hypothesis of homogeneous and isotropic terrain and the complexity of a natural network subject to the properties of the land surface it crosses this metric makes it possible to determine spatial distribution of infiltration and runoff keywords idpr dem hydrology network thalwegs groundwater infiltration runoff 1 introduction to better characterize the groundwater resources of an area their renewal capacity and their vulnerability to surface pollution it is useful to have regional maps that show the distribution of infiltration or runoff phenomena this capacity of the ground and subsurface to allow rainwater to infiltrate or on the contrary to run off depends on different parameters that may be correlated so called qualitative methods combine several parameters to estimate infiltration rates thus brito et al 2006 proposes an infiltration model that uses a geographic information system based on four parameters geology soil slope flood zones shaban et al 2006 and witkowski et al 2005 provide infiltration maps based on topographic geologic pedologic criteria and or land use with algorithms that use various combinations of them at the scale of large drainage basins valladares soares et al 2012 identify infiltration zones by overlapping geologic geomorphologic and pedologic units with a land use map and a grid of precipitation amounts more recently quiroz londoño et al 2016 used a fuzzy logic mathematical model based on five parameters drainage density geomorphological units soils land use and slope to infer an infiltration potential from them parameters linked to topography geologic structures and subsurface lithological composition are heavily weighted in the methods cited above their respective roles are in fact predominant in infiltration processes and in hydrographic network formation prud homme 1972 has experimented since 1972 with cartographic analysis of hydrographic networks he shows correlations between their forms and geological and lithological units kim 1978 and deffontaines 1990 continued this work deffontaines insists on the primacy of the hydrographic network for a morphostructural approach the hydrographic network is modified principally by lithology and fracturing riazanoff 1989 proposes automatic methods for extracting and analyzing hydrographic networks the work of these authors shows that the trace of the hydrographic network is a product of complex interactions and may indirectly reflect certain characteristics of the soil and subsurface in other words mathematical modeling which produces a hydrographic network uniquely from the dem will fail to reproduce perfectly the natural organization of observed watercourses a network development and persistence index idpr developed in france since the early 2000 uhan et al 2004 described here quantifies the offset between an observed natural network that results from complex factors and the theoretical network calculated solely by topography it is based on the hypothesis that this offset reflects the presence of these complex factors that affect natural flow emplacement this article provides for the first time a technical description of the calculation of the idpr proposing some hydrogeological application using this index since its creation the idpr has evolved over time and its most advance version is described here compared to the previously published article uhan et al 2004 this is a complete description of the method new input data dtm river network as well as a new approach to slopes and old basement areas 2 method the network development and persistence index idpr was created by brgm the french geological survey uhan et al 2004 to qualify an area in terms of pathways used by meteoric water rainfall that flows across the surface of natural terrain because it is not absorbed by plants or subject to direct evaporation leaves its drainage basin in two different ways it flows along the land surface and concentrates in streams and rivers it infiltrates into the subsurface is concentrated into an aquifer and leaves the aquifer through an outlet that is often different from that of the river network the idpr provides a qualitative approach to the relationship between these two pathways it provides an indication of ability of surface and subsurface formations to promote surface water infiltration or run off toward or away from the underground environment the idea behind idpr comes from the following hypothesis organization of the hydrographic network depends primarily on the hydrologic and hydrogeologic properties of underlying geologic formations using the hypothesis of a perfectly homogeneous and isotropic medium only slope and thus landscape morphology will control the emplacement of watercourses in the natural environment geologic structures the lithological composition of the subsurface the pedology and plant cover have a significant influence on the establishment of hydrographic networks these factors control the permeability and roughness of the soil surface which in turn affect runoff velocity and the ratio between runoff and infiltration drainage density in an area is thus a revealing indicator of the properties of the geologic formations of which it is composed a basin composed of highly permeable materials in general will have a low drainage density conversely a basin composed of impermeable but loose and erosive rocks such as marls and clays will often have a higher drainage density following this idea the idpr calculation is based on a comparison between a theoretical hydrographic network which considers the presence of a river in each thalweg development index and the natural hydrographic network persistence of networks the overall method is shown in illustration 1 2 1 definition of a theoretical hydrographic network thalwegs from dem there are several methods for generating thalweg networks from a dtm for the calculation of the idpr one method has been chosen and the resulting thalweg network is an input which is essential but not the only one each dtm is produced by a third party and has its own non modifiable characteristics acquisition accuracy and limits of use which must be taken into account in the proposed calculations for this paper the angle of view is to present first what the idpr characterizes i e the infiltration or runoff capacity of soils a digital elevation model dem is a representation of landforms of elevation in a form suitable for use by geo referenced data treatment software for the idpr calculation the dem used is a set of data in the form of grid of points on a square mesh each point is labeled with the elevation of the closest point assigned to the grid of which it is the center to model the bottoms of the valleys on the scale of the french territory the 25 m resolution bdalti v2 ign database was used bdalti v2 ign is an elevation database used to derive a range of dems and isohypses that describe the relief of the national territory at various resolutions illustration 2 for the 25 m dem the use of several data acquisition techniques made it possible to improve its precision lidar and radar technology and aerial photography correlation techniques to calculate the theoretical thalweg network from the dem the method used is based on the algorithms of tarboton 1997 and distributed by the environmental systems research institute esri the calculation processes are simple and can be summarized into a data treatment set largely described in the bibliography available in gis tools some prior treatment is necessary to extract thalwegs such as searching for depressions or endorheic zones and the overlaying of the natural hydrographic network on the dem the calculation tools used are available in the arcgis 10 2 2 software esri and his arcmap s application 2 1 1 pretreatment 2 1 1 1 search for and filling endorheic zones the usual preliminary correction to the calculation of a drainage basin consists of searching for cells surrounded by higher elevation cells the zones that form basins generally pose a difficulty due to the determination of flow directions because there is no solution for getting out of these areas a simple pretreatment of the dem is required for idpr this involves filling these basins until an adjacent cell is found that allows flow this cell will become the outlet cell during flow calculation the treated zone artificially becomes a flat zone endorheic zones can be treated differently if it is possible to assign them a fictitious outlet at their lowest point at a large scale this alternative makes it possible to reduce artifacts in the network calculation at a smaller scale and specifically at the national scale this alternative brings little precision to the final treatment 2 1 1 2 overlaying the hydrologic network on the dem calculation of the axis of valley bottoms can be based on the vector watercourse layer this correction can reduce the slope bias introduced by bank vegetation it also ensures that the calculated lowest point is located in the cell that corresponds to the natural watercourse the river network used for the idpr calculation was provided by bd topo of ign as described in paragraph 2 2 2 1 2 extraction of the drainage network the calculation establishes a flow direction grid then an accumulation grid from which a drainage grid will be extracted the threshold value used to determine if a surface is apt to produce significant flow is estimated by an overall analysis of the study area 2 1 2 1 flow direction each cell of the dem grid is ranked according to the dem value at the center of the grid cell the flow direction grid makes it possible to define the position of the immediately neighboring cell toward which the water layer will flow that is the one that has the greatest elevation difference the calculation method used by the flux direction tool is that of a flow model with eight directions d8 jenson and domingue 1988 which models the flow direction from each cell toward its neighbor in the direction of steepest descending slope the grid cell can thus have eight different values illustration 3 2 1 2 2 flux accumulation these flow directions then make it possible to calculate accumulation values for each cell of the initial grid the accumulation value represents the number of cells that flow into a given cell illustration 4 the calculation is done at the scale of the initial dem grid 2 1 2 3 definition of drainage network the following illustrations retain only those cells in which the number of accumulated cells is greater than or equal to four they make it possible to extract a first drainage network for which the value 4 represents the minimum number of cells necessary for accumulation of a quantity of water sufficient to define a thalweg in other terms they represent the sum of cells necessary and sufficient to initiate flow if these cells have a surface of 100 m2 then the elementary drainage basin has an area of 400 m2 the framework for the study proposed in this article is that of metropolitan france the choice of the accumulation threshold necessary and sufficient to establish the upper end of basins results from a simple statistical analysis of the assumed distribution of sources of the natural river network these supposed sources correspond to a unique upstream point forming the upstream of the stream trace with the objective of reproducing an equivalent reality as close as possible to a natural watercourse the search for a minimal basin surface capable of initiating a water course in an average climate environment like that of the french national territory is 62 5 ha the choice of the elementary basin plays an important role in the calculation of the theoretical network its value will thus have a direct implication on the upstream thalweg and on the distance ratio between the two networks the values of the idpr can therefore vary upstream of the watercourses according to the calculated thalweg network for a study at another scale with a dtm of a different precision it is necessary to make several tests with different elementary basins to have a certain coherence between the calculated thalweg and the hydrographic network used in this approach expertise hydrological hydrogeological and gis and experience are important other potential thalweg network definitions exist the robustness of the idpr calculation shows that variations obtained according to different methods do not significantly affect the final idpr calculation 2 2 river network the idpr method uses as first input the natural hydrologic network digitized according to a river representation deduced from observations of geographers and photo interpreters it results from observation of flows perennial and intermittent and from transferring the vectorized path of the major bed onto maps that are more of less precise the natural hydrographic network that was used is from bd topo ign data which is more precise than the bd carthage cf illustration 4 used for the calculation of the 2007 idpr uhan et al 2004 bd carthage has decametric 10 m precision and was conceived to be used at a base scale ranging from 1 50 000 to 1 100 000 the bd topo has metric precision this makes it possible to use data up to a scale of 1 10 000 or even 1 5000 the arcs described in the information layer and lakes or wide watercourse zones in this cartographic database describe the hydrographic axis geometry attributes of the hydrographic segments of the bdtopo table 1 used for idpr analysis are the rate regime whether permanent or intermittent the hydrographic position of the segment compared to the position of the ground pos sol 0 and the nature of the network with the choice of preserving only natural networks artif none by default idpr integrates permanent and intermittent networks in its calculation which makes it possible to account for an area s runoff capacity when flows occur during periods of high river water during flooding notably but also periods of high underground aquifer water when sources of the watercourses migrate upstream in the thalwegs 2 3 discrepancy measurement idpr measures the observed discrepancy between the thalweg network and the natural network this calculation is done for each cell in the original grid of the 25 m dem for bd topo and thus provides spatialized information for the index idpr dis tan c e o f e a c h c e l l t o t h e c l o s e s t r e a l w a t e r c o u r s e o n t h e s l o p e dis tan c e o f e a c h c e l l t o t h e c l o s e s t t h e r e t i c a l w a t e r c o u r s e o n t h e s l o p e 1000 this distance ratio makes it possible to highlight zones where the theoretical network is denser than the natural hydrographic network zones of high infiltration and those on the contrary where the natural network is denser than the numerical model produced by the dem and where runoff is therefore significant cf illustration 5 the databases essential to the idpr calculation are thus the pattern of the natural hydrographic network and the dem because the quality of these data determine the quality of the idpr calculation particular attention must be paid to the homogeneity of these input data and particularly to the choice of representation of the natural river network which may result from operators and different instructions depending on the study area 2 3 1 treatment of slopes the goal of introducing slope criteria into the idpr index calculation is to obtain a representation that conforms more closely to local variations of areal morphology the index calculation results initially from the ratio at any point in the study area between the distance to the closest real watercourse and the distance to the closest thalweg in terms of euclidian distance by weighting this ratio with a distance calculation constrained by slopes the hydrographic network is better accounted for in zones with high geomorphological contrast such as alluvial zones and their slopes flat laterally extensive zones artifacts can be introduced into the slope calculation which show up on the idpr result with terrace effects these effects are due to metric or multi metric precision of the digital elevation model in the idpr calculation presented these effects are corrected directly on the slope grid by a resizing based on a symmetrical linear mathematic transformation function this function as well as the calculation of slopes are directly calculated with processing tools available on the slope calculation tools are available on the arcgis 10 2 2 software esri the values of the bounds to smooth the slope calculation are determined from the statistics 2 3 2 treatment of watercourses and lakes at the scale of the metropolitan territory the distribution of idpr index values range from 0 to n with 99 of the values being less than or equal to 2 by convention the index calculation is multiplied by 1000 and limited to 2000 to simplify use and to decrease the volume of data in a synthetic way illustration 6 the value 0 corresponds to a thalweg for which no watercourse exists the value 1000 corresponds to a thalweg which has a watercourse the value 2000 corresponds to a water zone that is not described by a thalweg lake 2 4 particular case of basement aquifers idpr analysis of basement aquifers has shown that it does not distinguish in a satisfactory way local variations in lithologies that it encounters in fact its values are too homogeneous and centered on the value 1000 equal parts infiltration and or runoff this observation is consistent with the knowledge of basement aquifers which are generally described as low capacity water resources often more aquitard than aquifer however the role of regolith formation and fracturations is preponderant and to emphasize them in the idpr calculation a complementary approach was applied it is based primarily on the principal of continuity discontinuity of hydrographic networks as described by deffontaines 1990 and crave 1995 observation of the longitudinal profiles of rivers located in basement zones show zones of slope discontinuity where fracturing of the ground plays a role in flow distribution and orientation these zones which are often flat can be lumped with sectors where infiltration would potentially be favored because of the presence of fractures to detect these discontinuity zones geomorphological treatment tools such as the topographic position index tpi developed by tagil et al 2008 can be used for each dem cell the tool calculates an index corresponding to the difference between the elevation of the cell and the average elevation of neighboring cells included in the perimeter of a shape and extent determined by the user a negative index means that the cell is located lower than its neighbors depression a positive index indicates the opposite situation high and an index near 0 implies either that all cells have the same elevation or the cell is located on a slope as a function of the size of the calculation perimeter number of cells the tpi index is classified as a function of the landforms that it characterizes illustration 7 in the following case the raw results are distributed into two classes according to experts illustration 7 making it possible for valleys and the rest of the topography to stand out as a function of discontinuity zones the hydrographic network of the bd topo natural network is reapportioned and reinjected into the idpr calculation illustration 8 3 results idpr proposes new data that can substitute for data linked to soil permeability surface water or subsurface permeability groundwater this is a simplified approach to characterize these environments for which as we have seen idpr qualitatively describes permeability as areas of infiltration and runoff at the metropolitan scale the mapping of this index is consistent with the expected behavior of large geologic regions with a well defined distribution of sedimentary basins old basins and alpine domains illustration 9 the readers guide in table 2 provides a key for interpreting the calculated idpr considering the entire permanent and intermittent network as flowing the chalky aureole formed in upper cretaceous formations appears clearly by the contrast it makes at the contact with low permeability lower cretaceous formations the wet champagne this is also apparent at the contact of older and often karstified formations of the jurassic at its eastern boundary at larger scales idpr also reproduces lithology changes this is the case of the buttonhole of the pays de bray in northern france where jurassic age rocks crop out within the senonian chalk these lithological units are composed of clays or relatively impervious calcareous marls the block diagram and the extract of the geologic map harmonized at 1 50 000 together illustrate the morphology and geologic structure the idpr calculation grid provides a highly detailed response for this region where the presence of low permeability lower cretaceous formations highlights the anticlinal structure of the pays de bray illustration 10 there is a particular case where the watercourse density may be higher than that of thalwegs in the context of potentially permeable formations this involves territories where the proximity of shallow groundwater depth supports the presence of perennial network flow at the surface this is the case for example of littoral swamps or large swamps that are present in alluvial valleys illustration 11 these particular cases are systematically associated with areas of low or no slope unlike sedimentary zones bedrock formations favor runoff which is apparently related to the existence in the sectors concerned of relatively dense permanent surface water networks coinciding with the majority of thalwegs the limit of the idpr use is set by the data preparation method in general we can consider the maximum scale to be 1 50 000 this scale is directly related to the validity scales of the cartographic data used dem bd topo at the scale of the french metropolis to work at more precise scales it is necessary to modify the input data accordingly more precise dem and hydrographic network produced for example by field control and recalculation of idpr values the consequences of the change in precision of the dtm and its implications for the calculation of the idpr were studied in desprats et al 2010 and the main conclusions are as follows for indirect indicators such as the idpr and the twi potential soil moisture index the dtms tend to have a limit related to the production method type of interpolation in some cases the 1 m dtm seems to provide a non negligible precision for detecting thalwegs apart from the smoothing of the dem to produce the 1 m dtm also evacuated the channels the move of certain thalwegs will make the areas where the two networks cohabit surface network and thalwegs wider the results of the high resolution dtm must therefore be taken with caution the dtm produced from the dem has generated data smoothing which beyond the removal of multiple channels has induced a potential shift in the existing drainage axes when compared to existing networks such as geomorphological indices like idpr this lateral displacement 1 widens the areas where these two networks coexist and 2 artificially increases the so called runoff areas these large scale shifts produce fuzzy boundaries on a smaller scale these phenomena become blurred and produce a more consistent result 4 examples of idpr use 4 1 intrinsic vulnerability of groundwater the methods described by gogu and dassargues 2000 or more recently by kumar et al 2015 that make it possible to evaluate groundwater vulnerability to surface pollution are called index methods they combine different parameters that play a role in pollutant transfer thus the drastic aller et al 1987 method weights the criteria linked to the depth of the water bearing layer recharge the nature of the saturated and unsaturated zones the nature of the ground topography and aquifer permeability idpr being an integrating index it can be overlapped with the thickness of the unsaturated zone usz to hierarchize the intrinsic vulnerability of groundwater the formula for calculating intrinsic vulnerability of groundwater is thus the following vi weight idpr idpr criteria weight usz criteria usz with weight idpr weight usz 1 vi is between 0 and 100 the weighting can vary according to the hydrogeologic context thus for areas with the most infiltration chalk sand the weight given to idpr with respect to the thickness of the usz must overall be preponderant because the infiltration potential prevails in this case however it is highly probable that the relative weight of the usz thickness will take on more importance as its thickness diminishes and reaches very low values several meters on the contrary it is evident that the weight given to the usz thickness must be clearly higher in alluvial plains where the water bearing layer is quite shallow the results obtained by this method based on idpr and the usz have been compared to results obtained with the drastic method on the scale of the french nord pas de calais region gravier et al 2005 and on the scale of the bourgogne region seguin et al 2007 cf illustration 12 in these two studies the different scenarios were reviewed and the selected scenario is that of 50 zns and 50 idpr to qualify the simplified intrinsic vulnerability other studies have been carried out on the french territory with this method the scenario retained each time depends on the hydrogeological context mardhel and gravier 2005 the results obtained by these two methods are completely consistent with the hydrogeologic knowledge of these territories for the nord pas de calais region a qualitative analysis by regional experts was produced on the comparison of the two methods the simplified vulnerability map build using idpr is more accurate than the drastic map this is because the mesh size used to calculate the idpr and the zns is 250 250 m whereas that of the drastic method is 500 500 m the simplified vulnerability method idpr zns gives more details on the alluvial valleys and the captive fringe improving the distribution of the different degrees of vulnerability it also avoids the globalization as drastic does for rivers in particular this is also true for low vulnerabilities in interfluvial zones because the parameters necessary for the drastic method or for other multiparametric methods are difficult to obtain on a regional or national scale the method of vulnerability estimation based on the idpr approach seems well suited at these scales the results obtained by the latter are homogeneous the calculation is done in a uniform manner for the entire study area it does not require the density of point information usually necessary for this type of analysis and it is based on data whose reliability is known dem observed hydrographic network thickness of the unsaturated zone 4 2 recharge the geomorphologic work and calculations of brydsten 2006 show that topography has a significant influence on recharge distribution infiltration zones indicated on the idpr map seem to be zones of preferential recharge but idpr values between 0 and 2000 do not directly provide an infiltration rate and are thus not useful for estimating recharge from a spatialization of effective rainfall the work of seguin 2016 done to estimate the quantitative status of underground water masses within the framework of the european water directive made it possible to choose after analysis of different recharge evaluation methods three methods based on hydrograph decomposition bfi part and bfirora usgs rutledge 1998 et bfi w ceh of wallingford bullock et al 1992 and to apply them to 29 drainage basins distributed throughout france the results were compared to each other and when possible with global and spatialized models the results obtained made it possible to calculate on average over a long time period most often more than 10 years a base flow index bfi that is a ratio between base flow eb and the total discharge q of a watercourse and a ratio between base flow eb and effective rainfall peff when these two water fluxes had been calculated by a model spatialized or global in the studied drainage basins the study made it possible to show an approximately linear relationship between these two ratios bfi and eb peff and idpr illustration 13 to follow this work arnaud 2017 extended this work to 66 drainage basins 48 of which are in sedimentary environments for drainage basins in basement domain or with a karst component no linear relationship could be established however for the sedimentary environment a strong relationship exists between bfi here calculated according to wallingford s method of hydrograph decomposition and the average idpr value over the drainage basin from these regression curves illustrations 13 and 14 infiltration coefficient values as a function of idpr have been proposed they make it possible to propose the following table 3 classification established qualitatively from the bfi and eb peff ratios this classification is applied to sedimentary aquifers with unconfined water bearing layers and non karstic environments 4 3 karst infiltration distribution can also be highly influenced by the presence of karst type fissures in chalk and limestones in some sectors affecting both the unsaturated zone and the saturated zone karst has complex hydrogeological functioning and its interaction with surface water cause these zones to be able to contribute to infiltration and runoff at the same time in this domain idpr can be used to improve the delimitation of karst zones and to qualify them in terms of permeability if the data from the karst hazard study cartannaz et al 2013 in franche comté is superimposed on idpr values illustration 15 we observe that infiltration zones provide a good representation of zones qualified as naked karst based on an analysis of the 1 50 000 geologic map field data ground movement corroborate these delimitations and the idpr in this study is used as one of the criteria that make it possible to qualify the susceptibility to cavity collapse in 2017 brgm began working on behalf of the central hydrometeorology and flood forecasting support service schapi to construct a runoff map of karst basins combining spatial data from harmonized geologic maps at 1 50 000 and idpr in a study on runoff mapping in karstic areas pinson and charlier 2018 a degree of karstification was previously determined on existing geological contours before applying the idpr it turns out that there is a good match and that even karsts under marl cover stand out with a higher idpr than those with high infiltration 4 4 nitrate the transfer mode of soil nitrate across the unsaturated zone and toward groundwater is controlled by the quantity of effective rainfall and the infiltration capacity of the ground idpr makes it possible to evaluate infiltration qualitatively the groundwater quality chemical status for the nitrate parameter has been compared to values and to the distribution of this spatial indicator over the mainland france to construct the graph presented illustration 16 all of the quality data of the ades database have been projected on the national map and for each point the median idpr has been calculated radius of about 500 m around each point the concentrations used 90th percentile are those of may 2016 only measurements validated and labeled with the code remark 1 validity domain with a result higher than the quantification threshold and lower than the saturation threshold are taken into account for each idpr class between 0 and 2000 the median and quartiles of nitrate concentration have been calculated and reported on the graph below the graph highlights the close correlation between idpr and nitrate concentrations the data distribution shows that the higher the infiltration of a zone idpr 1000 zones that allow more infiltration the higher the nitrate concentration and conversely for runoff impermeable zones concentrations are low with nitrate values that are similar to contents that occur naturally in groundwater for an idpr 1000 nitrate concentration values are high and this is often characteristic of alluvial water bearing layers with variable permeability and water bearing layer river exchanges this correlation between idpr and nitrate concentrations does not take soil pressure into account which results in some uncertainty 5 conclusions the network development and persistence index idpr makes it possible to qualify indirectly the capacity of soils and the subsurface to allow infiltration or on the contrary to cause rainfall to run off because its calculation is based uniquely on two input data the dem and the observed hydrographic network this comparison method is robust and easy to implement the quality of the idpr produced depends on the accuracy of the elevation model used and the precision of the observed hydrographic network its interpretation limit is set by the method of data preparation that is used by construction a maximum scale of 1 50 000 for the idpr grid at a resolution of 25 m for the entire area of metropolitan france can be used idpr makes it possible to show at small scale highly infiltrating zones and zones where runoff predominates extreme values are easier to interpret than intermediate values for which it is necessary to proceed to data validation field work on the idpr map of france objects that are otherwise well identified whether geology or even hydrology with the example of wet areas are clearly demarcated idpr can be used as entry data for vulnerability studies to define preferential recharge zones and for hazard maps these application domains are varied and with improvement of imagery data it will be possible to work at more local scales first developed for the cesse basin in southern france pinson and charlier 2017 the idpr high resolution approach is now in development for the mediterranean region pinson and charlier 2018 the results obtained at the scale of small drainage basins in the mediterranean area are promising they make it possible to discriminate karst zones that may possibly contribute to flooding credit authorship contribution statement vincent mardhel writing original draft conceptualization methodology validation stéphanie pinson writing original draft conceptualization methodology validation delphine allier writing original draft conceptualization methodology validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments ign data for the quality of data provided which improves year to year idpr was created from an elevation model at scale of 50 m developed with bdalti at resolution of 25 m and continues with bdtopo ign at resolution of 5 meters laurence gourcy for her attentive reading of this article and the contribution of the brgm water service which has supported the development and perfection of this index for 15 years we would also like to thank patricia bobeck for her translation of the article and her proofreading finally this project was conceived with the support of a brilliant team that set up the water gis cell of the brgm 2004 2010 dedicated to groundwater and established within teams then directed by didier pennequin delphine allier stéphanie pinson eric putot and annabelle gravier actively participated in the first applications of this index 
5034,it is commonly accepted in geospatial analysis that automated calculation of thalweg networks from a digital elevation model produces a theoretical flow system that overall represents the branching of in place hydrographic networks however in detail this theoretical network is too different from the natural river network to substitute for the systematic digitization of rivers numerous papers seek to optimize numeric calculations to reduce this discrepancy but none has proposed to use this difference as data specific to the context under study toward this end the principal idea behind the idpr network development and persistence index is to apply a particular metric to disparity measurements between the theoretical drainage system produced by the raw automatic analysis of a digital model and the field reality represented by branching rivers by measuring the difference between a simplified modeling of water pathways based on a hypothesis of homogeneous and isotropic terrain and the complexity of a natural network subject to the properties of the land surface it crosses this metric makes it possible to determine spatial distribution of infiltration and runoff keywords idpr dem hydrology network thalwegs groundwater infiltration runoff 1 introduction to better characterize the groundwater resources of an area their renewal capacity and their vulnerability to surface pollution it is useful to have regional maps that show the distribution of infiltration or runoff phenomena this capacity of the ground and subsurface to allow rainwater to infiltrate or on the contrary to run off depends on different parameters that may be correlated so called qualitative methods combine several parameters to estimate infiltration rates thus brito et al 2006 proposes an infiltration model that uses a geographic information system based on four parameters geology soil slope flood zones shaban et al 2006 and witkowski et al 2005 provide infiltration maps based on topographic geologic pedologic criteria and or land use with algorithms that use various combinations of them at the scale of large drainage basins valladares soares et al 2012 identify infiltration zones by overlapping geologic geomorphologic and pedologic units with a land use map and a grid of precipitation amounts more recently quiroz londoño et al 2016 used a fuzzy logic mathematical model based on five parameters drainage density geomorphological units soils land use and slope to infer an infiltration potential from them parameters linked to topography geologic structures and subsurface lithological composition are heavily weighted in the methods cited above their respective roles are in fact predominant in infiltration processes and in hydrographic network formation prud homme 1972 has experimented since 1972 with cartographic analysis of hydrographic networks he shows correlations between their forms and geological and lithological units kim 1978 and deffontaines 1990 continued this work deffontaines insists on the primacy of the hydrographic network for a morphostructural approach the hydrographic network is modified principally by lithology and fracturing riazanoff 1989 proposes automatic methods for extracting and analyzing hydrographic networks the work of these authors shows that the trace of the hydrographic network is a product of complex interactions and may indirectly reflect certain characteristics of the soil and subsurface in other words mathematical modeling which produces a hydrographic network uniquely from the dem will fail to reproduce perfectly the natural organization of observed watercourses a network development and persistence index idpr developed in france since the early 2000 uhan et al 2004 described here quantifies the offset between an observed natural network that results from complex factors and the theoretical network calculated solely by topography it is based on the hypothesis that this offset reflects the presence of these complex factors that affect natural flow emplacement this article provides for the first time a technical description of the calculation of the idpr proposing some hydrogeological application using this index since its creation the idpr has evolved over time and its most advance version is described here compared to the previously published article uhan et al 2004 this is a complete description of the method new input data dtm river network as well as a new approach to slopes and old basement areas 2 method the network development and persistence index idpr was created by brgm the french geological survey uhan et al 2004 to qualify an area in terms of pathways used by meteoric water rainfall that flows across the surface of natural terrain because it is not absorbed by plants or subject to direct evaporation leaves its drainage basin in two different ways it flows along the land surface and concentrates in streams and rivers it infiltrates into the subsurface is concentrated into an aquifer and leaves the aquifer through an outlet that is often different from that of the river network the idpr provides a qualitative approach to the relationship between these two pathways it provides an indication of ability of surface and subsurface formations to promote surface water infiltration or run off toward or away from the underground environment the idea behind idpr comes from the following hypothesis organization of the hydrographic network depends primarily on the hydrologic and hydrogeologic properties of underlying geologic formations using the hypothesis of a perfectly homogeneous and isotropic medium only slope and thus landscape morphology will control the emplacement of watercourses in the natural environment geologic structures the lithological composition of the subsurface the pedology and plant cover have a significant influence on the establishment of hydrographic networks these factors control the permeability and roughness of the soil surface which in turn affect runoff velocity and the ratio between runoff and infiltration drainage density in an area is thus a revealing indicator of the properties of the geologic formations of which it is composed a basin composed of highly permeable materials in general will have a low drainage density conversely a basin composed of impermeable but loose and erosive rocks such as marls and clays will often have a higher drainage density following this idea the idpr calculation is based on a comparison between a theoretical hydrographic network which considers the presence of a river in each thalweg development index and the natural hydrographic network persistence of networks the overall method is shown in illustration 1 2 1 definition of a theoretical hydrographic network thalwegs from dem there are several methods for generating thalweg networks from a dtm for the calculation of the idpr one method has been chosen and the resulting thalweg network is an input which is essential but not the only one each dtm is produced by a third party and has its own non modifiable characteristics acquisition accuracy and limits of use which must be taken into account in the proposed calculations for this paper the angle of view is to present first what the idpr characterizes i e the infiltration or runoff capacity of soils a digital elevation model dem is a representation of landforms of elevation in a form suitable for use by geo referenced data treatment software for the idpr calculation the dem used is a set of data in the form of grid of points on a square mesh each point is labeled with the elevation of the closest point assigned to the grid of which it is the center to model the bottoms of the valleys on the scale of the french territory the 25 m resolution bdalti v2 ign database was used bdalti v2 ign is an elevation database used to derive a range of dems and isohypses that describe the relief of the national territory at various resolutions illustration 2 for the 25 m dem the use of several data acquisition techniques made it possible to improve its precision lidar and radar technology and aerial photography correlation techniques to calculate the theoretical thalweg network from the dem the method used is based on the algorithms of tarboton 1997 and distributed by the environmental systems research institute esri the calculation processes are simple and can be summarized into a data treatment set largely described in the bibliography available in gis tools some prior treatment is necessary to extract thalwegs such as searching for depressions or endorheic zones and the overlaying of the natural hydrographic network on the dem the calculation tools used are available in the arcgis 10 2 2 software esri and his arcmap s application 2 1 1 pretreatment 2 1 1 1 search for and filling endorheic zones the usual preliminary correction to the calculation of a drainage basin consists of searching for cells surrounded by higher elevation cells the zones that form basins generally pose a difficulty due to the determination of flow directions because there is no solution for getting out of these areas a simple pretreatment of the dem is required for idpr this involves filling these basins until an adjacent cell is found that allows flow this cell will become the outlet cell during flow calculation the treated zone artificially becomes a flat zone endorheic zones can be treated differently if it is possible to assign them a fictitious outlet at their lowest point at a large scale this alternative makes it possible to reduce artifacts in the network calculation at a smaller scale and specifically at the national scale this alternative brings little precision to the final treatment 2 1 1 2 overlaying the hydrologic network on the dem calculation of the axis of valley bottoms can be based on the vector watercourse layer this correction can reduce the slope bias introduced by bank vegetation it also ensures that the calculated lowest point is located in the cell that corresponds to the natural watercourse the river network used for the idpr calculation was provided by bd topo of ign as described in paragraph 2 2 2 1 2 extraction of the drainage network the calculation establishes a flow direction grid then an accumulation grid from which a drainage grid will be extracted the threshold value used to determine if a surface is apt to produce significant flow is estimated by an overall analysis of the study area 2 1 2 1 flow direction each cell of the dem grid is ranked according to the dem value at the center of the grid cell the flow direction grid makes it possible to define the position of the immediately neighboring cell toward which the water layer will flow that is the one that has the greatest elevation difference the calculation method used by the flux direction tool is that of a flow model with eight directions d8 jenson and domingue 1988 which models the flow direction from each cell toward its neighbor in the direction of steepest descending slope the grid cell can thus have eight different values illustration 3 2 1 2 2 flux accumulation these flow directions then make it possible to calculate accumulation values for each cell of the initial grid the accumulation value represents the number of cells that flow into a given cell illustration 4 the calculation is done at the scale of the initial dem grid 2 1 2 3 definition of drainage network the following illustrations retain only those cells in which the number of accumulated cells is greater than or equal to four they make it possible to extract a first drainage network for which the value 4 represents the minimum number of cells necessary for accumulation of a quantity of water sufficient to define a thalweg in other terms they represent the sum of cells necessary and sufficient to initiate flow if these cells have a surface of 100 m2 then the elementary drainage basin has an area of 400 m2 the framework for the study proposed in this article is that of metropolitan france the choice of the accumulation threshold necessary and sufficient to establish the upper end of basins results from a simple statistical analysis of the assumed distribution of sources of the natural river network these supposed sources correspond to a unique upstream point forming the upstream of the stream trace with the objective of reproducing an equivalent reality as close as possible to a natural watercourse the search for a minimal basin surface capable of initiating a water course in an average climate environment like that of the french national territory is 62 5 ha the choice of the elementary basin plays an important role in the calculation of the theoretical network its value will thus have a direct implication on the upstream thalweg and on the distance ratio between the two networks the values of the idpr can therefore vary upstream of the watercourses according to the calculated thalweg network for a study at another scale with a dtm of a different precision it is necessary to make several tests with different elementary basins to have a certain coherence between the calculated thalweg and the hydrographic network used in this approach expertise hydrological hydrogeological and gis and experience are important other potential thalweg network definitions exist the robustness of the idpr calculation shows that variations obtained according to different methods do not significantly affect the final idpr calculation 2 2 river network the idpr method uses as first input the natural hydrologic network digitized according to a river representation deduced from observations of geographers and photo interpreters it results from observation of flows perennial and intermittent and from transferring the vectorized path of the major bed onto maps that are more of less precise the natural hydrographic network that was used is from bd topo ign data which is more precise than the bd carthage cf illustration 4 used for the calculation of the 2007 idpr uhan et al 2004 bd carthage has decametric 10 m precision and was conceived to be used at a base scale ranging from 1 50 000 to 1 100 000 the bd topo has metric precision this makes it possible to use data up to a scale of 1 10 000 or even 1 5000 the arcs described in the information layer and lakes or wide watercourse zones in this cartographic database describe the hydrographic axis geometry attributes of the hydrographic segments of the bdtopo table 1 used for idpr analysis are the rate regime whether permanent or intermittent the hydrographic position of the segment compared to the position of the ground pos sol 0 and the nature of the network with the choice of preserving only natural networks artif none by default idpr integrates permanent and intermittent networks in its calculation which makes it possible to account for an area s runoff capacity when flows occur during periods of high river water during flooding notably but also periods of high underground aquifer water when sources of the watercourses migrate upstream in the thalwegs 2 3 discrepancy measurement idpr measures the observed discrepancy between the thalweg network and the natural network this calculation is done for each cell in the original grid of the 25 m dem for bd topo and thus provides spatialized information for the index idpr dis tan c e o f e a c h c e l l t o t h e c l o s e s t r e a l w a t e r c o u r s e o n t h e s l o p e dis tan c e o f e a c h c e l l t o t h e c l o s e s t t h e r e t i c a l w a t e r c o u r s e o n t h e s l o p e 1000 this distance ratio makes it possible to highlight zones where the theoretical network is denser than the natural hydrographic network zones of high infiltration and those on the contrary where the natural network is denser than the numerical model produced by the dem and where runoff is therefore significant cf illustration 5 the databases essential to the idpr calculation are thus the pattern of the natural hydrographic network and the dem because the quality of these data determine the quality of the idpr calculation particular attention must be paid to the homogeneity of these input data and particularly to the choice of representation of the natural river network which may result from operators and different instructions depending on the study area 2 3 1 treatment of slopes the goal of introducing slope criteria into the idpr index calculation is to obtain a representation that conforms more closely to local variations of areal morphology the index calculation results initially from the ratio at any point in the study area between the distance to the closest real watercourse and the distance to the closest thalweg in terms of euclidian distance by weighting this ratio with a distance calculation constrained by slopes the hydrographic network is better accounted for in zones with high geomorphological contrast such as alluvial zones and their slopes flat laterally extensive zones artifacts can be introduced into the slope calculation which show up on the idpr result with terrace effects these effects are due to metric or multi metric precision of the digital elevation model in the idpr calculation presented these effects are corrected directly on the slope grid by a resizing based on a symmetrical linear mathematic transformation function this function as well as the calculation of slopes are directly calculated with processing tools available on the slope calculation tools are available on the arcgis 10 2 2 software esri the values of the bounds to smooth the slope calculation are determined from the statistics 2 3 2 treatment of watercourses and lakes at the scale of the metropolitan territory the distribution of idpr index values range from 0 to n with 99 of the values being less than or equal to 2 by convention the index calculation is multiplied by 1000 and limited to 2000 to simplify use and to decrease the volume of data in a synthetic way illustration 6 the value 0 corresponds to a thalweg for which no watercourse exists the value 1000 corresponds to a thalweg which has a watercourse the value 2000 corresponds to a water zone that is not described by a thalweg lake 2 4 particular case of basement aquifers idpr analysis of basement aquifers has shown that it does not distinguish in a satisfactory way local variations in lithologies that it encounters in fact its values are too homogeneous and centered on the value 1000 equal parts infiltration and or runoff this observation is consistent with the knowledge of basement aquifers which are generally described as low capacity water resources often more aquitard than aquifer however the role of regolith formation and fracturations is preponderant and to emphasize them in the idpr calculation a complementary approach was applied it is based primarily on the principal of continuity discontinuity of hydrographic networks as described by deffontaines 1990 and crave 1995 observation of the longitudinal profiles of rivers located in basement zones show zones of slope discontinuity where fracturing of the ground plays a role in flow distribution and orientation these zones which are often flat can be lumped with sectors where infiltration would potentially be favored because of the presence of fractures to detect these discontinuity zones geomorphological treatment tools such as the topographic position index tpi developed by tagil et al 2008 can be used for each dem cell the tool calculates an index corresponding to the difference between the elevation of the cell and the average elevation of neighboring cells included in the perimeter of a shape and extent determined by the user a negative index means that the cell is located lower than its neighbors depression a positive index indicates the opposite situation high and an index near 0 implies either that all cells have the same elevation or the cell is located on a slope as a function of the size of the calculation perimeter number of cells the tpi index is classified as a function of the landforms that it characterizes illustration 7 in the following case the raw results are distributed into two classes according to experts illustration 7 making it possible for valleys and the rest of the topography to stand out as a function of discontinuity zones the hydrographic network of the bd topo natural network is reapportioned and reinjected into the idpr calculation illustration 8 3 results idpr proposes new data that can substitute for data linked to soil permeability surface water or subsurface permeability groundwater this is a simplified approach to characterize these environments for which as we have seen idpr qualitatively describes permeability as areas of infiltration and runoff at the metropolitan scale the mapping of this index is consistent with the expected behavior of large geologic regions with a well defined distribution of sedimentary basins old basins and alpine domains illustration 9 the readers guide in table 2 provides a key for interpreting the calculated idpr considering the entire permanent and intermittent network as flowing the chalky aureole formed in upper cretaceous formations appears clearly by the contrast it makes at the contact with low permeability lower cretaceous formations the wet champagne this is also apparent at the contact of older and often karstified formations of the jurassic at its eastern boundary at larger scales idpr also reproduces lithology changes this is the case of the buttonhole of the pays de bray in northern france where jurassic age rocks crop out within the senonian chalk these lithological units are composed of clays or relatively impervious calcareous marls the block diagram and the extract of the geologic map harmonized at 1 50 000 together illustrate the morphology and geologic structure the idpr calculation grid provides a highly detailed response for this region where the presence of low permeability lower cretaceous formations highlights the anticlinal structure of the pays de bray illustration 10 there is a particular case where the watercourse density may be higher than that of thalwegs in the context of potentially permeable formations this involves territories where the proximity of shallow groundwater depth supports the presence of perennial network flow at the surface this is the case for example of littoral swamps or large swamps that are present in alluvial valleys illustration 11 these particular cases are systematically associated with areas of low or no slope unlike sedimentary zones bedrock formations favor runoff which is apparently related to the existence in the sectors concerned of relatively dense permanent surface water networks coinciding with the majority of thalwegs the limit of the idpr use is set by the data preparation method in general we can consider the maximum scale to be 1 50 000 this scale is directly related to the validity scales of the cartographic data used dem bd topo at the scale of the french metropolis to work at more precise scales it is necessary to modify the input data accordingly more precise dem and hydrographic network produced for example by field control and recalculation of idpr values the consequences of the change in precision of the dtm and its implications for the calculation of the idpr were studied in desprats et al 2010 and the main conclusions are as follows for indirect indicators such as the idpr and the twi potential soil moisture index the dtms tend to have a limit related to the production method type of interpolation in some cases the 1 m dtm seems to provide a non negligible precision for detecting thalwegs apart from the smoothing of the dem to produce the 1 m dtm also evacuated the channels the move of certain thalwegs will make the areas where the two networks cohabit surface network and thalwegs wider the results of the high resolution dtm must therefore be taken with caution the dtm produced from the dem has generated data smoothing which beyond the removal of multiple channels has induced a potential shift in the existing drainage axes when compared to existing networks such as geomorphological indices like idpr this lateral displacement 1 widens the areas where these two networks coexist and 2 artificially increases the so called runoff areas these large scale shifts produce fuzzy boundaries on a smaller scale these phenomena become blurred and produce a more consistent result 4 examples of idpr use 4 1 intrinsic vulnerability of groundwater the methods described by gogu and dassargues 2000 or more recently by kumar et al 2015 that make it possible to evaluate groundwater vulnerability to surface pollution are called index methods they combine different parameters that play a role in pollutant transfer thus the drastic aller et al 1987 method weights the criteria linked to the depth of the water bearing layer recharge the nature of the saturated and unsaturated zones the nature of the ground topography and aquifer permeability idpr being an integrating index it can be overlapped with the thickness of the unsaturated zone usz to hierarchize the intrinsic vulnerability of groundwater the formula for calculating intrinsic vulnerability of groundwater is thus the following vi weight idpr idpr criteria weight usz criteria usz with weight idpr weight usz 1 vi is between 0 and 100 the weighting can vary according to the hydrogeologic context thus for areas with the most infiltration chalk sand the weight given to idpr with respect to the thickness of the usz must overall be preponderant because the infiltration potential prevails in this case however it is highly probable that the relative weight of the usz thickness will take on more importance as its thickness diminishes and reaches very low values several meters on the contrary it is evident that the weight given to the usz thickness must be clearly higher in alluvial plains where the water bearing layer is quite shallow the results obtained by this method based on idpr and the usz have been compared to results obtained with the drastic method on the scale of the french nord pas de calais region gravier et al 2005 and on the scale of the bourgogne region seguin et al 2007 cf illustration 12 in these two studies the different scenarios were reviewed and the selected scenario is that of 50 zns and 50 idpr to qualify the simplified intrinsic vulnerability other studies have been carried out on the french territory with this method the scenario retained each time depends on the hydrogeological context mardhel and gravier 2005 the results obtained by these two methods are completely consistent with the hydrogeologic knowledge of these territories for the nord pas de calais region a qualitative analysis by regional experts was produced on the comparison of the two methods the simplified vulnerability map build using idpr is more accurate than the drastic map this is because the mesh size used to calculate the idpr and the zns is 250 250 m whereas that of the drastic method is 500 500 m the simplified vulnerability method idpr zns gives more details on the alluvial valleys and the captive fringe improving the distribution of the different degrees of vulnerability it also avoids the globalization as drastic does for rivers in particular this is also true for low vulnerabilities in interfluvial zones because the parameters necessary for the drastic method or for other multiparametric methods are difficult to obtain on a regional or national scale the method of vulnerability estimation based on the idpr approach seems well suited at these scales the results obtained by the latter are homogeneous the calculation is done in a uniform manner for the entire study area it does not require the density of point information usually necessary for this type of analysis and it is based on data whose reliability is known dem observed hydrographic network thickness of the unsaturated zone 4 2 recharge the geomorphologic work and calculations of brydsten 2006 show that topography has a significant influence on recharge distribution infiltration zones indicated on the idpr map seem to be zones of preferential recharge but idpr values between 0 and 2000 do not directly provide an infiltration rate and are thus not useful for estimating recharge from a spatialization of effective rainfall the work of seguin 2016 done to estimate the quantitative status of underground water masses within the framework of the european water directive made it possible to choose after analysis of different recharge evaluation methods three methods based on hydrograph decomposition bfi part and bfirora usgs rutledge 1998 et bfi w ceh of wallingford bullock et al 1992 and to apply them to 29 drainage basins distributed throughout france the results were compared to each other and when possible with global and spatialized models the results obtained made it possible to calculate on average over a long time period most often more than 10 years a base flow index bfi that is a ratio between base flow eb and the total discharge q of a watercourse and a ratio between base flow eb and effective rainfall peff when these two water fluxes had been calculated by a model spatialized or global in the studied drainage basins the study made it possible to show an approximately linear relationship between these two ratios bfi and eb peff and idpr illustration 13 to follow this work arnaud 2017 extended this work to 66 drainage basins 48 of which are in sedimentary environments for drainage basins in basement domain or with a karst component no linear relationship could be established however for the sedimentary environment a strong relationship exists between bfi here calculated according to wallingford s method of hydrograph decomposition and the average idpr value over the drainage basin from these regression curves illustrations 13 and 14 infiltration coefficient values as a function of idpr have been proposed they make it possible to propose the following table 3 classification established qualitatively from the bfi and eb peff ratios this classification is applied to sedimentary aquifers with unconfined water bearing layers and non karstic environments 4 3 karst infiltration distribution can also be highly influenced by the presence of karst type fissures in chalk and limestones in some sectors affecting both the unsaturated zone and the saturated zone karst has complex hydrogeological functioning and its interaction with surface water cause these zones to be able to contribute to infiltration and runoff at the same time in this domain idpr can be used to improve the delimitation of karst zones and to qualify them in terms of permeability if the data from the karst hazard study cartannaz et al 2013 in franche comté is superimposed on idpr values illustration 15 we observe that infiltration zones provide a good representation of zones qualified as naked karst based on an analysis of the 1 50 000 geologic map field data ground movement corroborate these delimitations and the idpr in this study is used as one of the criteria that make it possible to qualify the susceptibility to cavity collapse in 2017 brgm began working on behalf of the central hydrometeorology and flood forecasting support service schapi to construct a runoff map of karst basins combining spatial data from harmonized geologic maps at 1 50 000 and idpr in a study on runoff mapping in karstic areas pinson and charlier 2018 a degree of karstification was previously determined on existing geological contours before applying the idpr it turns out that there is a good match and that even karsts under marl cover stand out with a higher idpr than those with high infiltration 4 4 nitrate the transfer mode of soil nitrate across the unsaturated zone and toward groundwater is controlled by the quantity of effective rainfall and the infiltration capacity of the ground idpr makes it possible to evaluate infiltration qualitatively the groundwater quality chemical status for the nitrate parameter has been compared to values and to the distribution of this spatial indicator over the mainland france to construct the graph presented illustration 16 all of the quality data of the ades database have been projected on the national map and for each point the median idpr has been calculated radius of about 500 m around each point the concentrations used 90th percentile are those of may 2016 only measurements validated and labeled with the code remark 1 validity domain with a result higher than the quantification threshold and lower than the saturation threshold are taken into account for each idpr class between 0 and 2000 the median and quartiles of nitrate concentration have been calculated and reported on the graph below the graph highlights the close correlation between idpr and nitrate concentrations the data distribution shows that the higher the infiltration of a zone idpr 1000 zones that allow more infiltration the higher the nitrate concentration and conversely for runoff impermeable zones concentrations are low with nitrate values that are similar to contents that occur naturally in groundwater for an idpr 1000 nitrate concentration values are high and this is often characteristic of alluvial water bearing layers with variable permeability and water bearing layer river exchanges this correlation between idpr and nitrate concentrations does not take soil pressure into account which results in some uncertainty 5 conclusions the network development and persistence index idpr makes it possible to qualify indirectly the capacity of soils and the subsurface to allow infiltration or on the contrary to cause rainfall to run off because its calculation is based uniquely on two input data the dem and the observed hydrographic network this comparison method is robust and easy to implement the quality of the idpr produced depends on the accuracy of the elevation model used and the precision of the observed hydrographic network its interpretation limit is set by the method of data preparation that is used by construction a maximum scale of 1 50 000 for the idpr grid at a resolution of 25 m for the entire area of metropolitan france can be used idpr makes it possible to show at small scale highly infiltrating zones and zones where runoff predominates extreme values are easier to interpret than intermediate values for which it is necessary to proceed to data validation field work on the idpr map of france objects that are otherwise well identified whether geology or even hydrology with the example of wet areas are clearly demarcated idpr can be used as entry data for vulnerability studies to define preferential recharge zones and for hazard maps these application domains are varied and with improvement of imagery data it will be possible to work at more local scales first developed for the cesse basin in southern france pinson and charlier 2017 the idpr high resolution approach is now in development for the mediterranean region pinson and charlier 2018 the results obtained at the scale of small drainage basins in the mediterranean area are promising they make it possible to discriminate karst zones that may possibly contribute to flooding credit authorship contribution statement vincent mardhel writing original draft conceptualization methodology validation stéphanie pinson writing original draft conceptualization methodology validation delphine allier writing original draft conceptualization methodology validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments ign data for the quality of data provided which improves year to year idpr was created from an elevation model at scale of 50 m developed with bdalti at resolution of 25 m and continues with bdtopo ign at resolution of 5 meters laurence gourcy for her attentive reading of this article and the contribution of the brgm water service which has supported the development and perfection of this index for 15 years we would also like to thank patricia bobeck for her translation of the article and her proofreading finally this project was conceived with the support of a brilliant team that set up the water gis cell of the brgm 2004 2010 dedicated to groundwater and established within teams then directed by didier pennequin delphine allier stéphanie pinson eric putot and annabelle gravier actively participated in the first applications of this index 
