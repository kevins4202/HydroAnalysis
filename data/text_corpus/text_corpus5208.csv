index,text
26040,since launching five years ago seasketch has been used in approximately 30 large scale projects and over 200 educational programs and research based initiatives distributed over 40 countries the study presented in this article engages seasketch developers project administrators and users through semi structured interviews and surveys meant to inform designers on how to better incorporate the participatory process within geodesign applications the results of this study suggest five ways in which designers can help increase public participation including 1 determining the eligibility of a project by mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 project management features within geodesign each one of these suggestions provides ample avenues of inquiry and can help practitioners and researchers conduct longitudinal studies across projects and or applications keywords marine spatial planning participatory mapping geodesign applications software seasketch 1 introduction seasketch is a collaborative web based geo design software application created by mcclintock labs at the university of california santa barbara s marine science institute seasketch is a geodesign tool provided as a software service that is used worldwide by governments marine planners and scientists to visualize and analyze spatial data for the purpose of building multi stakeholder consensus around natural resource decisions since launching in 2012 seasketch has been used in approximately 30 large scale projects and over 200 educational programs and research based initiatives distributed over 40 countries seasketch is primarily used to support marine spatial planning msp initiatives led by government agencies in countries such as montserrat barbuda new zealand canada and the cook islands seasketch 2019a seasketch has also been used by intergovernmental agencies such as the u s federal government s integrated working group on oceans and coastal mapping iwg ocm non governmental organizations such as the world wildlife fund the nature conservancy and conservation international and by educational institutions alike such as the hogeschool van hall larenstein university of applied sciences in the netherlands and by the erasmus mundus masters course in marine spatial planning based at the university of the azores an overview of these each of these projects and subsequent links to convening publications can be found at https www seasketch org projects these convening institutions use seasketch to coordinate national mapping and beach nourishment projects make engineering and repair decisions conduct habitat change and stock assessments determine nautical chart updates marine debris detection and removal areas inundation modeling and infrastructure strengthening for future storms and coastal resilience initiatives exploring how project managers embed seasketch within a participatory process is an important aspect in understanding the mechanisms of change brought about by public participatory geographic information systems ppgis in this article i use developer project administrator and user experience in the form of interviews and surveys to answer the question how can designers of geospatial applications best embed public participatory processes within the technology to answer this question i first review seasketch s main features and how these features relate and are often dependent on the participatory process second i discuss how other methods have been used to evaluate ppgis and how ballatore et al s participatory gis usability scale pgus has been used alongside seasketch in the past to make a contribution to this topic i asked developers project administrators and users of seasketch specific questions about the participatory process and which aspects were most important to them i use this feedback to develop a set of key aspects to consider when designing platforms for ppgis each one of these suggested aspects provides an avenue of inquiry for how designers might best help project administrators and gis users increase public participation 2 participatory planning with seasketch ppgis refers to a collaborative form of cartography that focuses on the local and traditional knowledge of communities and the value of its inclusion in planning and decision making processes sieber 2006 craig et al 2002 ppgis can be applied to assessing environmental impacts sidlar and rinner 2009 land use zoning brown et al 2004 warner 2006 urban planning elwood and ghose 2001 indigenous land rights brown and kyttä 2014 mccall and minang 2005 and marine spatial planning merrifield et al 2013 the process as it is idealized seeks to empower non technical individuals through the facilitation of greater input and access to geographic data and technology as they relate to decision making merrifield et al 2013 68 many scholars and practitioners use ppgis to enhance public participation in policymaking and advance democratic principles by giving greater voice to marginalized groups craig and elwood 1998 sieber 2006 marginalization is the process of pushing a particular group or groups of people to the edge of society and excluding their voices from the political process and policymaking harris and weiner 1998 drawing from critical theory practitioners of participatory processes set out to examine the intersections of identity such as class employment ethnicity religion language gender and age to assess mobility and access to key resources of historically marginalized groups sieber 2006 p 492 reviewing 17 cases in the united states australia and new zealand between 1998 and 2011 brown 2012 found that regardless of the idealized nature of ppgis participant engagement still contained a bias towards older males with high education levels this suggests a lack of proper engagement with underrepresented racial ethnic groups brown argues that despite methodological advances ppgis has not had a significant impact on regional and environmental planning outcomes in regard to enhancing public participation in environmental stewardship 2012 p 8 their analyses suggest that the use of spatial applications in participatory mapping are not strongly associated with an increase in public participation or normative changes in behavior around conserving the environment without adequate engagement scholars are beginning to ask themselves what actually constitutes the public and what are the best models for ppgis so far participants and practitioners disagree on what constitutes a good model for ppgis webler and tuler 2001 found that some participants placed greater value on legitimacy and data accuracy while others focused on the role that information has on the equity of the decision making process the assumption that public participation is a moral right even when greater participation leads to an increase in the complexity is one of the greatest problems facing ppgis administrators how can we balance the need for representational community participation and the increase in the diversity of opinions values and objectives this caveat in participatory planning highlights a significant obstacle to the development of geospatial applications for participatory mapping if the purpose of ppgis is to increase public participation scholars and practitioners must first agree on the change mechanisms and prospective outcomes goals of its ontology the use of gis tools had traditionally been limited to experts with advanced training in geospatial tools and analytics sieber 2006 as a result gis tools were often perceived by designers and administrators as counter intuitive or too complex for less sophisticated or less trained end users this argument is still used by some administrators and is the main driving factor in using chauffeurs or intermediaries who map on behalf of participants focused on breaking these barriers to ppgis seasketch was created to be an easy to use and accessible geo design application that allows users with limited technological skills to map and analyze spatial data that supports the creation of marine protected areas mpas users had difficulties using marinemap seasketch s predecessor as a result designers wanted to take lessons learned and build a more efficient geospatial software cravens 2016 to make seasketch s interface more accessible to non technical experts the lab purposefully employed a team of software engineers that had limited or no prior use of desktop gis applications seasketch comes with built in tools for designing and implementing crowd sourced and stakeholder targeted surveys that can provide valuable foundation data to ppgis initiatives seasketch 2019b seasketch helps project administrators design survey tools to gather information about resources and participant values including the added feature of a points scale to rank participant values seasketch s interactive interface allows project administrators to guide participants through the design process and encourages participants to communicate asynchronously during workshops forum groups and formal meetings project administrators can assign survey tasks to specific groups or individuals at any given time participants can choose which maps to share in the stakeholder process while still being able to remain ownership over the mapping content project administrators can then use this data to solve an array of policy relevant decision problems seasketch 2019b project administrators do not have to manage elaborate servers or multiple file formats which is a common challenge using other applications for example the new zealand department of conservation used seasketch by using data from an arcgis server based map services hosted on agency servers and map services hosted on cloud computing services amazon web services to create a comprehensive marine spatial plan in the hauraki gulf hauraki gulf marine park 2017 the analytical and reporting features of a seasketch project depend on the users needs goals and objectives mcclintock lab s team helps to guide convening institutions and their project administrators in planning and conducting the analysis this helps to ensure the quality of the data and the academic integrity of the analysis but can seem limiting for those looking for a tool that has built in analytical features analytics might include data on zoning for renewable energies fisheries transportation habitat conservation and or aquaculture reports help users understand whether zoning designs meet goals for ecosystem protection or economic growth seasketch evaluates user generated designs provides comparative analytics and helps the conveners with their intended project goals fig 1 the forum feature in seasketch allows stakeholders to ask questions share maps and plans and express opinions and collaborate fig 2 the fora provide another avenue of assessment for project administrators who want to document the participatory process and provide transparency project administrators can further assess user engagement with the planning process through a user analytics dashboard fig 3 the dashboard allows project administrators to see who has logged into seasketch participated in specific geodesign surveys and who has or has not opened email invitations the analytics dashboard could be expanded to include a number of different social and cultural indicators that are monitored and updated over time depending on the users needs for some decision problems experts and scientists are commissioned to collect data on ecological units often referred to as objective or hard data data gathered from the stakeholder surveys fig 4 are considered subjective or soft data malczewski 1999 12 this soft data can provide project administrators with valuable knowledge on the demographic social and economic make up of participants social interactions with the environment are initiated by motives as time passes the interactions alter these motives and generate new ones deutsch 1977 the developers of seasketch pers commun note that soft data is usually collected about a specific terrestrial feature and not about the planning process itself 3 evaluating the planning process there are many methods to evaluating human computer interaction the majority focus on software usability usability is not directly observable what s intuitive for a designer is not always intuitive to the general population in the case of geodesign applications the features must be able to be transferable across socio cultural variations technology literacy remains a significant barrier to socially marginalized groups and individuals stevens et al 2014 the cost of not using the appropriate application given the context is that the participants become disinterested in the participatory process or even becoming hostile to using the technology in the future weiner et al 2002 sieber 2006 zhao and coleman 2007 developed an analytical framework for measuring human computer interaction that can be applied to ppgis the model draws from f d davis s technological acceptance model tam the goal of tam is to predict information system acceptance and diagnose design problems before users have any specific experience with a system p 4 zhao and coleman s framework evaluates the system s technological acceptance of ppgis s usefulness ease of use cost of entry intended users and satisfaction by applying video and audiotapes of the testing sessions to measure how long each task takes for the user to complete and how many errors the participants make using observational and recorded data post hoc comments on fora and questionnaire surveys zhao and coleman conclude that when applied to their test case the framework measures the satisfaction and interaction with the system effectively however this model can be costly and is not always appropriate for participatory mapping projects in low income and developing countries who do not have the same access to technology as highlighted in zhao and coleman s analysis this is a problem for software developers and project administrators on a budget who are interested in understanding user preferences and perceptions an alternative to zhao and coleman s tam is ballatore et al 2019 participatory gis usability scale pgus ballatore et al 2019 debuted a 25 question survey method based incorporates relevant questions for geo design applications with enough feedback the results of the survey can be used to evaluate changes to the application over time and provides a method of comparative analysis that incorporates some elements of the participatory process alongside a usability assessment a version of the pgus current v1 questionnaire is available in postgresql on machine readable formats on github under an open data creative commons attribution share alike 4 0 cc by sa 4 0 in 2016 ballatore et al distributed the pgus survey via email to 3 200 seasketch users and received 175 responses the results of the survey were generally positive and helped the mcclintock lab s development team with identifying several areas of improvement including updating specific mapping design features in addition to providing feedback on technical uses the survey showed specific patterns among seasketch s users that made the team question how well project administrators were soliciting feedback according to the survey results seasketch users were predominantly male between the ages of 30 50 and were highly educated nearly 60 had a graduate level degree ballatore et al 2019 332 the researchers speculate that the amount of highly educated respondents was partially due to self selection bias caused by email surveying socioeconomic status often limits the user s access to computers and the internet reducing the access of underrepresented communities to the survey as a result project evaluation cannot rely on email surveying alone the pgus survey highlighted the need for an evaluation tool that could be used in real time and offer an opportunity for all respondents to provide feedback on the process and the technology while it s being used moreover there needs to be methods of evaluating the planning process and not just the usability of the software s design developers must design participatory mapping software that integrates tools for the planning process that will help researchers evaluate how user perceptions interact with project outcomes and the use of the technology the goal of the research outlined in this paper is to develop a framework for understanding the needs of administrators and users through in person semi structured interviews and surveys 4 interview and survey methods as mentioned previously the incorporation of the public has rested almost entirely on the conveners who design the participatory process and not the developers our goal was to create a research agenda that captures and compares the perspectives of developers project administrators and users of seasketch to find aspects of the participatory process that could enhance future designs i conducted four in depth interviews with two seasketch developers and two project administrators using seasketch at field sites i administered fifteen face to face surveys with seasketch users but only six completed the entire survey due to deviations in the interviews focus anonymity was essential to both project administrators and users as the projects being evaluated were still ongoing and intervention could have an impact on project outcomes the average interview time with developers and project administrators was 42 min the developers and administrators were asked six open ended questions including background information project specifics and other information that was either not relevant to this specific study or that the researchers were asked not to publish to limit the scope of this specific paper i focus on only two of the questions posed 1 what is the step by step process you took in planning and implementing the public participatory process 2 were there any issues that you didn t foresee in the planning process how were these issues managed and are there any suggestions for future planning initiatives the survey administered to user participants comprised of twenty questions including fifteen perception statements see appendix i the users were asked to rank the perception statements on a five point likert scale strongly agree agree neither agree or disagree disagree and strongly disagree nine of the surveys were left unfinished because many of the users were unable to answer the specific questions dedicated to the technology because a chauffeur was used instead of answering all the questions in the survey the structure was challenged as respondents wanted to provide more anecdotal evidence about the planning process rather than answer the questions posed in the survey directly to account for this i will focus on the following four statements that were completed by all fifteen users 1 i found value in the planning process 2 i would participate in a similar planning process 3 i contributed to the final planning decision 4 the participants reflect the diverse communities in the region the transcripts were coded using the following five specific descriptive codes technology planning process participation equality and sustainability the next section provides a comparison of the codes by cross examining them between the developer and project administrator interviews and the user responses the next section outlines the results of the analysis in an integrative way in the hopes of sparking interest in the research and design of geospatial applications that are accessible build consensus around specific plans and create normative shifts in behavior 5 issues in participatory mapping and geodesign applications the major concern of seasketch developers and most users was the participation of underrepresented individuals in the community which could not occur unless the conveners and project administrators use well formulated participatory models and collect relevant data on those that participate for years now there has been serious concern that representation was not being evaluated by administrators using seasketch through a critical interrogation of feedback provided by seasketch developers project administrators and users our research found five areas in which developers may be able to assist project administers increase public participation through built in data collection methods these include 1 determining the eligibility of a project by mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 project management features within geodesign these areas of focus deserve special attention and not just in the development of new geo design applications but also by donors and conveners who claim public participation and transparency several ways in which developers might solve these problems are provided below these suggestions require more input from both technical experts and ppgis participants themselves the results presented is an attempt at consolidating our research and ideas before seasketch 2 0 goes into development the goal of seasketch 2 0 is to expand the usability of the design features but also increase public participation more specifically the participation of underrepresented and marginalized groups and individuals in the process these results are meant to spark interest and challenge us to create new innovative tools 6 determining eligibility of project and mapping stakeholder engagement determining the eligibility of a seasketch project is difficult it s subjective to the needs of the convening client and the project administrators perceived ability to influence the outcome of the decision making process during the planning process participants should be engaged and help determine the general climate of the decision scenario itself the project administrator should gather enough information on the decision problem the intersectional identities and relations of stakeholders and the budget to make a judgment about the applicability of ppgis for any specific case sieber 2006 one project administrator described a scenario where the local community politics were not well enough understood to predict the shift in political power which occurred during the intervention the project administrator goes on to explain the budget only provides limited engagement with the public making research and outreach hard this is a remote area in the direct path of climate change it limits how much we can meet with our staff in the field anonymous project administrator a 2018 this is similar to the feedback that we received from the user survey responses although the majority of participants 11 out of 15 responded in agreement with the statement i found value in the participatory process many had concerns about how participants were selected nearly the same amount of survey participations 9 out of 15 disagreed with the statement the participants reflect the diverse communities in the region one user stated i was told about the project after data was collected anonymous user 5 2018 while another described issues with how knowledge was obtained saying we told them that the final spatial plan did not seem to represent us and even signed a petition against it it was still passed into law we were never asked about it anonymous user 9 2018 tracking and monitoring outreach becomes a necessity in public participatory processes who participates is everything to the political who gets what when and where to help project administrators with assessing the social economic and political contexts developers should be encouraged to create features that use analytics about the public generated from already existent national and local databases the scholarly literature provides a number of techniques that would serve project administrators in participatory processes such as conflict analysis risk assessment and cost benefit analysis cuppen 2012 these analytics could easily be built directly into the design of the application one framework that developers could use is wiedemann and femers 1993 citizen participation ladder that assesses the public s agency in the decision making process the authors theoretical framework is based on the assumption that the empowerment of the public requires access to information technical competence compensation for time and effort and the right to participate in decision making p 364 in many decision scenarios at the governmental or institutional level the public is only told about decisions made on their behalf after the fact with limited to no right to object this process is not only undemocratic but can lead to increased social tensions this can reduce the likelihood of the normative behavior changes necessary to implement and act on the new rules regulations or laws elwood 2002 sieber 2006 when the public is granted the ability to assist in defining interests actors and determining the agenda there s greater capacity for empowerment and social change yet as wiedemann and femers point out officials may offer citizens a token role in the decision making process to give the appearance of public participation p 361 in this instance stakeholders may be allowed to participate and even lead the process but the final decision comes from the top the ideal planning process allows all stakeholders to have equal power in the final decision kwaku kyem 2004 having a built in feature to assess the level of participation political power in the decision outcome and other data on variables related to the social economic and demographic makeup of participating groups would be helpful in ensuring the equitable distribution of political power 7 monitoring perceptions of fairness in the participatory process the concept of fairness was mentioned by all interviewees as being an integral part of the participatory process one interview participant described a scenario where including outsiders in the process made specific groups in the local community suspicious one survey respondent repeatedly referred to the project administrators as outsiders stating i don t even know who redacted are they are outsiders the new plans don t work here it s unfair to us when we have to live with the new plans not them anonymous user 1 2018 eventually the distrust of outsiders led some members of the community to believe that the entire process was unfair and that only certain individual or group priorities were being discussed and acted upon in this case government agencies lacked the experience in participatory planning so the government hired consultants to facilitate the participatory process from outside the region even though the project administrators worked with local nonprofits and leadership the outsiders seemed to be aligned with specific political affiliations which made certain communities perceive the new spatial plans as unfair the consultants were not always perceived as being inclusive or communicating effectively anonymous project administrator a 2018 it would be beneficial to integrate tools to measure perceptions of fairness directly in the geodesign application and provide administrators with a rubric of measurement founded in empirical study gaining feedback on the process is difficult and project administrators have a hard time assessing the perceptions of participants particularly from underrepresented groups because there are certain political dynamics at play one of the developers explains often times project administrators do not communicate effectively about how the data was translated into the final plans there needs to be some way of monitoring the interactions of project administrators and users one that gauges political affiliation anonymous developer a 2018 empirical findings suggest that public participation procedures do not always improve conflict resolution on the contrary in many cases public participation can create new conflicts wiedemann and femers 1993 reed 2008 stakeholders who are not engaged in the decision making process may harbor deep feelings of injustice which further contribute to tensions in fragile social systems weiner et al 2002 sieber 2006 perhaps the participant group is not understanding how to use the application and other methods or techniques needed to participate these types of feelings are likely to contribute to negative perceptions and unequal representation in the planning process estrella 2000 the concept of fairness is well researched in applied psychology and is understood as a protagonist of behavioral change in social change theory moorman 1991 conducted a survey analysis of the perceptions of fairness in relation to employee citizenship the study found that employees perceptions of fairness in the workplace correlated with higher levels of employee citizenship another study by syme et al 1999 found that local procedural justice issues pertaining to public involvement were significant determinants of judgments of fairness in the decision making and solution chosen perhaps geo design applications could survey participants perceptions of fairness and include it in a comparative visual dashboard a survey designed to measure fairness at various intervals of the process may help track and manage participant perceptions and potentially build greater consensus among decision makers even still the incorporation of all groups in the process does not necessarily facilitate perceptions of fairness or ensure success in project outcomes we find the endeavor meaningful in terms of transparency and social justice nevertheless 8 visualizing data for non technical experts the way in which data is collected analyzed and presented during the participatory mapping process can have serious implications for how participants view decision problems project administrators and even other users craig et al 2002 both project administrators and users mentioned that visualizing data especially the analysis played a critical role in the way participants viewed the overall process if stakeholders do not understand where the data came from or how the data was used they may choose not to accept the decision outcome wiedemann and fermer 1993 describes how data collection and visualization methods made participants frustrated and overwhelmed by technical jargon stating that citizens may react emotionally and withdraw from any collaboration in the task force 1992 p 362 the project administrators must grasp enough scientific knowledge and have the emotional intelligence to communicate with non technical individuals nearly half the users 6 out 15 disagreed with the statement i would participate in a similar planning process this was very concerning for project administrators and developers alike one user provided greater explanation saying i just don t understand how they collected the information i was asked to participate and give feedback but our plan doesn t look anything like that pointing to the final zoning map that the researcher had brought anonymous user 1 2018 p 4 the presentation of information and facilitation of the decision making process is instrumental to empowering stakeholders to engage with the technology and cooperate with other groups wiedemann and fermer s continues to describe two ways in which project administrators could increase power in decision making first participants i e the public require access to information technical competence compensation for time and effort and the right to participate in decision making p 364 second the project administrator must work to close the knowledge gap between the experts developers scientists politicians and official decision makers and the public developers must focus on ways of visualizing the data collection and analysis phases in ways that take the participants through the decision making process itself and at least attempt to explain how the analyses work this is particularly important in times where the project administrators themselves do not fully understand the technical jargon and mathematical methods used in external analysis and cannot relay it to stakeholders project administrators are often working on a limited budget and cannot afford to implement the community advocacy and education needed to ensure the understanding of the process this is why donors and conveners need to budget accordingly but in times where that s simply not an option it s up to the developers to design support tools that have built in analytic dashboards that users can watch as data comes taking this a step further developers can include tutorials and videos explaining the analytic processes even training built directly into the platform this may help to encourage participants to adopt the technology and participate more in the process 9 alternatives to usability models with chauffeurs ballatore et al s pgus is an effective measurement tool when users have direct contact with the technology but many times project administrators act as or hire others to represent a group of participants in the designing phase they might do this to reduce cost time or to assist groups perceived as not technologically literate haklay and tobón 2003 not only does this take away the stakeholders agency to learn how to use the application it can lead to misunderstandings and negative perceptions these representatives sometimes referred to as gis chauffeurs stop participants from using the technology directly rendering certain aspects of the pgus survey useless acting as mediators over the knowledge these representatives may disconnect participants from experiencing the transformational effects of the technology potentially leading to an increase in the perceptions of data inaccuracy and or tampering the bottom line is that participants who rely on chauffeurs do not participate in the project in the same way as those who use the geodesign platform directly project administrators using seasketch mentioned that the use of chauffeurs made it difficult to gauge the local community s understanding of the maps explaining that although we gathered feedback from many of the fishermen the final maps were often questioned we noticed that that participants who used seasketch directly seemed less shocked about the final maps project administrator b 2018 harris and weiner 1998 and others curry 2008 brown 2012 raise the issue of expert driven systems and how it relates to community empowerment data access public participation and the incorporation of local knowledge harris and weiner concludes that communities are becoming involved in gis projects but they are not in control of those projects and remain dependent on state agencies ngos external funding and technically oriented advocates p 71 geodesign applications could include mechanisms to support diversity local empowerment and direct engagement with all of the public those looking to develop a geo support tool must be able to incorporate the public at various levels by creating multiple pathways for gathering and sharing data including the ideas and opinions of those not able to participate in the mapping process in person collaborative geo design applications should allow project administrators to gather a wide variety of data from users with and without access to the internet cell phones or computers perhaps automated cellular messaging services could be used to contact the public and update them on upcoming events or the application could help project administrators manage contact information emails and advocacy all on the same platform to evaluate the impact of chauffeurs and enforce transparency in the participatory process geodesign tools should at least provide practitioners with a tool that evaluates whether or not the user is relying on someone else to represent their interests or are using the application on their behalf 10 project management features within geodesign there is no single participatory process model used alongside seasketch most geodesign applications are used across decision arenas where project administrators are constrained by many externalities such as funding politics and capacity some projects allow for many public forums presentations and meetings that engage the broader public while other projects may only be convened by representatives in private meeting spaces either way geodesign applications are used in combination with a wide array of process models that incorporate the public at various levels both seasketch developers and project administrators mentioned the need for more integrative planning and management tools in their one on one interviews many of our clients have to use other project management tools in combination with seasketch which limits what we know about the planning process one developer discussed in their interview the disconnect between the project management features such as calendars to do lists gantt charts instant messaging or email and geodesign makes managing content and user participation more difficult one project administrator reflected on the issue in a different way explaining it s hard to keep track of who comes to our public forums we don t have a way to track them project administrator a 2017 project administrators need to be able to import and export lists of users who participate on and off the application including the ability to collect telephone numbers addresses and make comments including project management features directly into geodesign applications could help increase user participation across different groups ensure transparency and provide direct feedback to conveners and donors there are a number of project management support tools such as workfront wrike and basecamp that offer these types of features to clients but the majority of such professional applications cost between 200 and 5000 annually project administrators are searching to consolidate software costs and time spent switching between applications many participatory mapping projects simply go without project management tools altogether making monitoring and evaluating over time more difficult geo design developers can provide these features within their application to not only reduce the cost of participatory mapping projects but also allow them to conduct a more in depth analysis of project processes and outcomes monitoring and evaluating objectives and deliverables over time allows project administrators to analyze process models and project outcomes which could help strengthen the empirical evidence of the theoretical benefits of ppgis and thus more representation in public policymaking the design aspects included in this analysis involved mapping political social and economic power of different stakeholder groups within the geodesign application and providing an interactive experience with the data when creating new features we may do better by asking ourselves how our applications answer the harder to reach questions within the scholarly research and visualize them for project administrators these questions include 1 how much political social and economic power does each stakeholder group have in the participatory process 2 how does the stakeholder groups utilize and value each resource and how much control does the stakeholder have over the resources being evaluated 3 how can we better create manage and record perception data within the planning process 4 how can the analysis be visualized differently for nontechnical participants of participatory mapping 5 how can public databases be incorporated into geodesign applications and readily visible to project managers 6 how can project managers better engage with and encourage dialogue and communication among diverse participants 11 conclusions this article has focused on the ways in which developers of geodesign applications can increase public participation in ppgis using the experience of developers project administrators and users of seasketch our research highlights five ways in which the participatory process could be incorporated into the development of geodesign applications 1 determining the eligibility of a project and mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 other project management features within geodesign each one provides ample avenues for further inquiry furthermore i highlight gaps within the field of ppgis and areas in which the developers of geospatial software could collect and manage relevant data on group dynamics perceptions of fairness and program evaluation in addition to standard environmental data i argue that the participatory process used alongside geo design tools is just as important as the usability of the technology because the majority of the participatory elements happens outside of the platform geodesign tools need to be dynamic and provide its users with multiple collection and analysis techniques that guide new users in learning project administrators draw from a multitude of interdisciplinary backgrounds such as social and political theory psychology and mediation and negotiation to assess projects or sometimes none at all as the process is being implemented project administrators try to adjust their models to account for the evolving dynamics among participants and the social and political environment the political and cultural context has a significant impact on participatory processes and projects success and should be incorporated in its design weiner et al 2002 sieber 2006 with considerable input from project administrators and researchers the creators of seasketch hope to design a seasketch 2 0 that incorporates the planning process hopefully this article inspires new ways of thinking about the development of geodesign support tools and helps to increase the participation of marginalized and at risk communities in our effort to build democratic consensus around resource based problems acknowlegement i thank will mcclintock university of california santa barbara for allowing me access to seasketch developers and the seasketch users for their detailed feedback and willingness to share their experiences initial funding and support for this research was provided by university of massachusetts boston and harvard university s program on negotiation appendix j supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix j supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104678 appendix i table 1 user survey questions table 1 planning process participant understands and values the planning process q1 i found value in the planning process q2 the planning process helped to build a better and stronger relationship between the participants q3 i understand the outcomes of the planning process and feel comfortable with the decision solution technology participant has used mapping software before and understands how to use it q4 the mapping technology gave me the tools i needed to reach my goals q5 i completed tasks that would have been impossible without the mapping technology q6 i would use this mapping technology again in the future q7 i would recommend this mapping technology to others sustainability participants are treated equally in the process and feel empowered to follow through with the plans q8 i contributed to the final planning decision q9 i was able to communicate my ideas and needs to others in the planning process q10 i agree with the final outcome of the planning process trust participants view the conveners and facilitators as being impartial and trustworthy q11 the facilitator helped to build consensus around our ideas q12 the stakeholders were treated equally throughout the planning process cooperation participants view the other participants as cooperative and wants to continue working on the project with them q13 the other participants were cooperative throughout the planning process q14 i would work with the other participants again q15 i will work together with the other participants to implement the project outcomes general questions participants demographic make up q16 do youtable 1 user survey questions consider yourself a part of a historically underrepresented group q17 what group do you most identify with environmental scientist activist government agency fisheries tourism or other q18 did you map your designs directly into seasketch or did you have someone map them for you chauffeur q19 what is your age q20 do you have any additional feedback 
26040,since launching five years ago seasketch has been used in approximately 30 large scale projects and over 200 educational programs and research based initiatives distributed over 40 countries the study presented in this article engages seasketch developers project administrators and users through semi structured interviews and surveys meant to inform designers on how to better incorporate the participatory process within geodesign applications the results of this study suggest five ways in which designers can help increase public participation including 1 determining the eligibility of a project by mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 project management features within geodesign each one of these suggestions provides ample avenues of inquiry and can help practitioners and researchers conduct longitudinal studies across projects and or applications keywords marine spatial planning participatory mapping geodesign applications software seasketch 1 introduction seasketch is a collaborative web based geo design software application created by mcclintock labs at the university of california santa barbara s marine science institute seasketch is a geodesign tool provided as a software service that is used worldwide by governments marine planners and scientists to visualize and analyze spatial data for the purpose of building multi stakeholder consensus around natural resource decisions since launching in 2012 seasketch has been used in approximately 30 large scale projects and over 200 educational programs and research based initiatives distributed over 40 countries seasketch is primarily used to support marine spatial planning msp initiatives led by government agencies in countries such as montserrat barbuda new zealand canada and the cook islands seasketch 2019a seasketch has also been used by intergovernmental agencies such as the u s federal government s integrated working group on oceans and coastal mapping iwg ocm non governmental organizations such as the world wildlife fund the nature conservancy and conservation international and by educational institutions alike such as the hogeschool van hall larenstein university of applied sciences in the netherlands and by the erasmus mundus masters course in marine spatial planning based at the university of the azores an overview of these each of these projects and subsequent links to convening publications can be found at https www seasketch org projects these convening institutions use seasketch to coordinate national mapping and beach nourishment projects make engineering and repair decisions conduct habitat change and stock assessments determine nautical chart updates marine debris detection and removal areas inundation modeling and infrastructure strengthening for future storms and coastal resilience initiatives exploring how project managers embed seasketch within a participatory process is an important aspect in understanding the mechanisms of change brought about by public participatory geographic information systems ppgis in this article i use developer project administrator and user experience in the form of interviews and surveys to answer the question how can designers of geospatial applications best embed public participatory processes within the technology to answer this question i first review seasketch s main features and how these features relate and are often dependent on the participatory process second i discuss how other methods have been used to evaluate ppgis and how ballatore et al s participatory gis usability scale pgus has been used alongside seasketch in the past to make a contribution to this topic i asked developers project administrators and users of seasketch specific questions about the participatory process and which aspects were most important to them i use this feedback to develop a set of key aspects to consider when designing platforms for ppgis each one of these suggested aspects provides an avenue of inquiry for how designers might best help project administrators and gis users increase public participation 2 participatory planning with seasketch ppgis refers to a collaborative form of cartography that focuses on the local and traditional knowledge of communities and the value of its inclusion in planning and decision making processes sieber 2006 craig et al 2002 ppgis can be applied to assessing environmental impacts sidlar and rinner 2009 land use zoning brown et al 2004 warner 2006 urban planning elwood and ghose 2001 indigenous land rights brown and kyttä 2014 mccall and minang 2005 and marine spatial planning merrifield et al 2013 the process as it is idealized seeks to empower non technical individuals through the facilitation of greater input and access to geographic data and technology as they relate to decision making merrifield et al 2013 68 many scholars and practitioners use ppgis to enhance public participation in policymaking and advance democratic principles by giving greater voice to marginalized groups craig and elwood 1998 sieber 2006 marginalization is the process of pushing a particular group or groups of people to the edge of society and excluding their voices from the political process and policymaking harris and weiner 1998 drawing from critical theory practitioners of participatory processes set out to examine the intersections of identity such as class employment ethnicity religion language gender and age to assess mobility and access to key resources of historically marginalized groups sieber 2006 p 492 reviewing 17 cases in the united states australia and new zealand between 1998 and 2011 brown 2012 found that regardless of the idealized nature of ppgis participant engagement still contained a bias towards older males with high education levels this suggests a lack of proper engagement with underrepresented racial ethnic groups brown argues that despite methodological advances ppgis has not had a significant impact on regional and environmental planning outcomes in regard to enhancing public participation in environmental stewardship 2012 p 8 their analyses suggest that the use of spatial applications in participatory mapping are not strongly associated with an increase in public participation or normative changes in behavior around conserving the environment without adequate engagement scholars are beginning to ask themselves what actually constitutes the public and what are the best models for ppgis so far participants and practitioners disagree on what constitutes a good model for ppgis webler and tuler 2001 found that some participants placed greater value on legitimacy and data accuracy while others focused on the role that information has on the equity of the decision making process the assumption that public participation is a moral right even when greater participation leads to an increase in the complexity is one of the greatest problems facing ppgis administrators how can we balance the need for representational community participation and the increase in the diversity of opinions values and objectives this caveat in participatory planning highlights a significant obstacle to the development of geospatial applications for participatory mapping if the purpose of ppgis is to increase public participation scholars and practitioners must first agree on the change mechanisms and prospective outcomes goals of its ontology the use of gis tools had traditionally been limited to experts with advanced training in geospatial tools and analytics sieber 2006 as a result gis tools were often perceived by designers and administrators as counter intuitive or too complex for less sophisticated or less trained end users this argument is still used by some administrators and is the main driving factor in using chauffeurs or intermediaries who map on behalf of participants focused on breaking these barriers to ppgis seasketch was created to be an easy to use and accessible geo design application that allows users with limited technological skills to map and analyze spatial data that supports the creation of marine protected areas mpas users had difficulties using marinemap seasketch s predecessor as a result designers wanted to take lessons learned and build a more efficient geospatial software cravens 2016 to make seasketch s interface more accessible to non technical experts the lab purposefully employed a team of software engineers that had limited or no prior use of desktop gis applications seasketch comes with built in tools for designing and implementing crowd sourced and stakeholder targeted surveys that can provide valuable foundation data to ppgis initiatives seasketch 2019b seasketch helps project administrators design survey tools to gather information about resources and participant values including the added feature of a points scale to rank participant values seasketch s interactive interface allows project administrators to guide participants through the design process and encourages participants to communicate asynchronously during workshops forum groups and formal meetings project administrators can assign survey tasks to specific groups or individuals at any given time participants can choose which maps to share in the stakeholder process while still being able to remain ownership over the mapping content project administrators can then use this data to solve an array of policy relevant decision problems seasketch 2019b project administrators do not have to manage elaborate servers or multiple file formats which is a common challenge using other applications for example the new zealand department of conservation used seasketch by using data from an arcgis server based map services hosted on agency servers and map services hosted on cloud computing services amazon web services to create a comprehensive marine spatial plan in the hauraki gulf hauraki gulf marine park 2017 the analytical and reporting features of a seasketch project depend on the users needs goals and objectives mcclintock lab s team helps to guide convening institutions and their project administrators in planning and conducting the analysis this helps to ensure the quality of the data and the academic integrity of the analysis but can seem limiting for those looking for a tool that has built in analytical features analytics might include data on zoning for renewable energies fisheries transportation habitat conservation and or aquaculture reports help users understand whether zoning designs meet goals for ecosystem protection or economic growth seasketch evaluates user generated designs provides comparative analytics and helps the conveners with their intended project goals fig 1 the forum feature in seasketch allows stakeholders to ask questions share maps and plans and express opinions and collaborate fig 2 the fora provide another avenue of assessment for project administrators who want to document the participatory process and provide transparency project administrators can further assess user engagement with the planning process through a user analytics dashboard fig 3 the dashboard allows project administrators to see who has logged into seasketch participated in specific geodesign surveys and who has or has not opened email invitations the analytics dashboard could be expanded to include a number of different social and cultural indicators that are monitored and updated over time depending on the users needs for some decision problems experts and scientists are commissioned to collect data on ecological units often referred to as objective or hard data data gathered from the stakeholder surveys fig 4 are considered subjective or soft data malczewski 1999 12 this soft data can provide project administrators with valuable knowledge on the demographic social and economic make up of participants social interactions with the environment are initiated by motives as time passes the interactions alter these motives and generate new ones deutsch 1977 the developers of seasketch pers commun note that soft data is usually collected about a specific terrestrial feature and not about the planning process itself 3 evaluating the planning process there are many methods to evaluating human computer interaction the majority focus on software usability usability is not directly observable what s intuitive for a designer is not always intuitive to the general population in the case of geodesign applications the features must be able to be transferable across socio cultural variations technology literacy remains a significant barrier to socially marginalized groups and individuals stevens et al 2014 the cost of not using the appropriate application given the context is that the participants become disinterested in the participatory process or even becoming hostile to using the technology in the future weiner et al 2002 sieber 2006 zhao and coleman 2007 developed an analytical framework for measuring human computer interaction that can be applied to ppgis the model draws from f d davis s technological acceptance model tam the goal of tam is to predict information system acceptance and diagnose design problems before users have any specific experience with a system p 4 zhao and coleman s framework evaluates the system s technological acceptance of ppgis s usefulness ease of use cost of entry intended users and satisfaction by applying video and audiotapes of the testing sessions to measure how long each task takes for the user to complete and how many errors the participants make using observational and recorded data post hoc comments on fora and questionnaire surveys zhao and coleman conclude that when applied to their test case the framework measures the satisfaction and interaction with the system effectively however this model can be costly and is not always appropriate for participatory mapping projects in low income and developing countries who do not have the same access to technology as highlighted in zhao and coleman s analysis this is a problem for software developers and project administrators on a budget who are interested in understanding user preferences and perceptions an alternative to zhao and coleman s tam is ballatore et al 2019 participatory gis usability scale pgus ballatore et al 2019 debuted a 25 question survey method based incorporates relevant questions for geo design applications with enough feedback the results of the survey can be used to evaluate changes to the application over time and provides a method of comparative analysis that incorporates some elements of the participatory process alongside a usability assessment a version of the pgus current v1 questionnaire is available in postgresql on machine readable formats on github under an open data creative commons attribution share alike 4 0 cc by sa 4 0 in 2016 ballatore et al distributed the pgus survey via email to 3 200 seasketch users and received 175 responses the results of the survey were generally positive and helped the mcclintock lab s development team with identifying several areas of improvement including updating specific mapping design features in addition to providing feedback on technical uses the survey showed specific patterns among seasketch s users that made the team question how well project administrators were soliciting feedback according to the survey results seasketch users were predominantly male between the ages of 30 50 and were highly educated nearly 60 had a graduate level degree ballatore et al 2019 332 the researchers speculate that the amount of highly educated respondents was partially due to self selection bias caused by email surveying socioeconomic status often limits the user s access to computers and the internet reducing the access of underrepresented communities to the survey as a result project evaluation cannot rely on email surveying alone the pgus survey highlighted the need for an evaluation tool that could be used in real time and offer an opportunity for all respondents to provide feedback on the process and the technology while it s being used moreover there needs to be methods of evaluating the planning process and not just the usability of the software s design developers must design participatory mapping software that integrates tools for the planning process that will help researchers evaluate how user perceptions interact with project outcomes and the use of the technology the goal of the research outlined in this paper is to develop a framework for understanding the needs of administrators and users through in person semi structured interviews and surveys 4 interview and survey methods as mentioned previously the incorporation of the public has rested almost entirely on the conveners who design the participatory process and not the developers our goal was to create a research agenda that captures and compares the perspectives of developers project administrators and users of seasketch to find aspects of the participatory process that could enhance future designs i conducted four in depth interviews with two seasketch developers and two project administrators using seasketch at field sites i administered fifteen face to face surveys with seasketch users but only six completed the entire survey due to deviations in the interviews focus anonymity was essential to both project administrators and users as the projects being evaluated were still ongoing and intervention could have an impact on project outcomes the average interview time with developers and project administrators was 42 min the developers and administrators were asked six open ended questions including background information project specifics and other information that was either not relevant to this specific study or that the researchers were asked not to publish to limit the scope of this specific paper i focus on only two of the questions posed 1 what is the step by step process you took in planning and implementing the public participatory process 2 were there any issues that you didn t foresee in the planning process how were these issues managed and are there any suggestions for future planning initiatives the survey administered to user participants comprised of twenty questions including fifteen perception statements see appendix i the users were asked to rank the perception statements on a five point likert scale strongly agree agree neither agree or disagree disagree and strongly disagree nine of the surveys were left unfinished because many of the users were unable to answer the specific questions dedicated to the technology because a chauffeur was used instead of answering all the questions in the survey the structure was challenged as respondents wanted to provide more anecdotal evidence about the planning process rather than answer the questions posed in the survey directly to account for this i will focus on the following four statements that were completed by all fifteen users 1 i found value in the planning process 2 i would participate in a similar planning process 3 i contributed to the final planning decision 4 the participants reflect the diverse communities in the region the transcripts were coded using the following five specific descriptive codes technology planning process participation equality and sustainability the next section provides a comparison of the codes by cross examining them between the developer and project administrator interviews and the user responses the next section outlines the results of the analysis in an integrative way in the hopes of sparking interest in the research and design of geospatial applications that are accessible build consensus around specific plans and create normative shifts in behavior 5 issues in participatory mapping and geodesign applications the major concern of seasketch developers and most users was the participation of underrepresented individuals in the community which could not occur unless the conveners and project administrators use well formulated participatory models and collect relevant data on those that participate for years now there has been serious concern that representation was not being evaluated by administrators using seasketch through a critical interrogation of feedback provided by seasketch developers project administrators and users our research found five areas in which developers may be able to assist project administers increase public participation through built in data collection methods these include 1 determining the eligibility of a project by mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 project management features within geodesign these areas of focus deserve special attention and not just in the development of new geo design applications but also by donors and conveners who claim public participation and transparency several ways in which developers might solve these problems are provided below these suggestions require more input from both technical experts and ppgis participants themselves the results presented is an attempt at consolidating our research and ideas before seasketch 2 0 goes into development the goal of seasketch 2 0 is to expand the usability of the design features but also increase public participation more specifically the participation of underrepresented and marginalized groups and individuals in the process these results are meant to spark interest and challenge us to create new innovative tools 6 determining eligibility of project and mapping stakeholder engagement determining the eligibility of a seasketch project is difficult it s subjective to the needs of the convening client and the project administrators perceived ability to influence the outcome of the decision making process during the planning process participants should be engaged and help determine the general climate of the decision scenario itself the project administrator should gather enough information on the decision problem the intersectional identities and relations of stakeholders and the budget to make a judgment about the applicability of ppgis for any specific case sieber 2006 one project administrator described a scenario where the local community politics were not well enough understood to predict the shift in political power which occurred during the intervention the project administrator goes on to explain the budget only provides limited engagement with the public making research and outreach hard this is a remote area in the direct path of climate change it limits how much we can meet with our staff in the field anonymous project administrator a 2018 this is similar to the feedback that we received from the user survey responses although the majority of participants 11 out of 15 responded in agreement with the statement i found value in the participatory process many had concerns about how participants were selected nearly the same amount of survey participations 9 out of 15 disagreed with the statement the participants reflect the diverse communities in the region one user stated i was told about the project after data was collected anonymous user 5 2018 while another described issues with how knowledge was obtained saying we told them that the final spatial plan did not seem to represent us and even signed a petition against it it was still passed into law we were never asked about it anonymous user 9 2018 tracking and monitoring outreach becomes a necessity in public participatory processes who participates is everything to the political who gets what when and where to help project administrators with assessing the social economic and political contexts developers should be encouraged to create features that use analytics about the public generated from already existent national and local databases the scholarly literature provides a number of techniques that would serve project administrators in participatory processes such as conflict analysis risk assessment and cost benefit analysis cuppen 2012 these analytics could easily be built directly into the design of the application one framework that developers could use is wiedemann and femers 1993 citizen participation ladder that assesses the public s agency in the decision making process the authors theoretical framework is based on the assumption that the empowerment of the public requires access to information technical competence compensation for time and effort and the right to participate in decision making p 364 in many decision scenarios at the governmental or institutional level the public is only told about decisions made on their behalf after the fact with limited to no right to object this process is not only undemocratic but can lead to increased social tensions this can reduce the likelihood of the normative behavior changes necessary to implement and act on the new rules regulations or laws elwood 2002 sieber 2006 when the public is granted the ability to assist in defining interests actors and determining the agenda there s greater capacity for empowerment and social change yet as wiedemann and femers point out officials may offer citizens a token role in the decision making process to give the appearance of public participation p 361 in this instance stakeholders may be allowed to participate and even lead the process but the final decision comes from the top the ideal planning process allows all stakeholders to have equal power in the final decision kwaku kyem 2004 having a built in feature to assess the level of participation political power in the decision outcome and other data on variables related to the social economic and demographic makeup of participating groups would be helpful in ensuring the equitable distribution of political power 7 monitoring perceptions of fairness in the participatory process the concept of fairness was mentioned by all interviewees as being an integral part of the participatory process one interview participant described a scenario where including outsiders in the process made specific groups in the local community suspicious one survey respondent repeatedly referred to the project administrators as outsiders stating i don t even know who redacted are they are outsiders the new plans don t work here it s unfair to us when we have to live with the new plans not them anonymous user 1 2018 eventually the distrust of outsiders led some members of the community to believe that the entire process was unfair and that only certain individual or group priorities were being discussed and acted upon in this case government agencies lacked the experience in participatory planning so the government hired consultants to facilitate the participatory process from outside the region even though the project administrators worked with local nonprofits and leadership the outsiders seemed to be aligned with specific political affiliations which made certain communities perceive the new spatial plans as unfair the consultants were not always perceived as being inclusive or communicating effectively anonymous project administrator a 2018 it would be beneficial to integrate tools to measure perceptions of fairness directly in the geodesign application and provide administrators with a rubric of measurement founded in empirical study gaining feedback on the process is difficult and project administrators have a hard time assessing the perceptions of participants particularly from underrepresented groups because there are certain political dynamics at play one of the developers explains often times project administrators do not communicate effectively about how the data was translated into the final plans there needs to be some way of monitoring the interactions of project administrators and users one that gauges political affiliation anonymous developer a 2018 empirical findings suggest that public participation procedures do not always improve conflict resolution on the contrary in many cases public participation can create new conflicts wiedemann and femers 1993 reed 2008 stakeholders who are not engaged in the decision making process may harbor deep feelings of injustice which further contribute to tensions in fragile social systems weiner et al 2002 sieber 2006 perhaps the participant group is not understanding how to use the application and other methods or techniques needed to participate these types of feelings are likely to contribute to negative perceptions and unequal representation in the planning process estrella 2000 the concept of fairness is well researched in applied psychology and is understood as a protagonist of behavioral change in social change theory moorman 1991 conducted a survey analysis of the perceptions of fairness in relation to employee citizenship the study found that employees perceptions of fairness in the workplace correlated with higher levels of employee citizenship another study by syme et al 1999 found that local procedural justice issues pertaining to public involvement were significant determinants of judgments of fairness in the decision making and solution chosen perhaps geo design applications could survey participants perceptions of fairness and include it in a comparative visual dashboard a survey designed to measure fairness at various intervals of the process may help track and manage participant perceptions and potentially build greater consensus among decision makers even still the incorporation of all groups in the process does not necessarily facilitate perceptions of fairness or ensure success in project outcomes we find the endeavor meaningful in terms of transparency and social justice nevertheless 8 visualizing data for non technical experts the way in which data is collected analyzed and presented during the participatory mapping process can have serious implications for how participants view decision problems project administrators and even other users craig et al 2002 both project administrators and users mentioned that visualizing data especially the analysis played a critical role in the way participants viewed the overall process if stakeholders do not understand where the data came from or how the data was used they may choose not to accept the decision outcome wiedemann and fermer 1993 describes how data collection and visualization methods made participants frustrated and overwhelmed by technical jargon stating that citizens may react emotionally and withdraw from any collaboration in the task force 1992 p 362 the project administrators must grasp enough scientific knowledge and have the emotional intelligence to communicate with non technical individuals nearly half the users 6 out 15 disagreed with the statement i would participate in a similar planning process this was very concerning for project administrators and developers alike one user provided greater explanation saying i just don t understand how they collected the information i was asked to participate and give feedback but our plan doesn t look anything like that pointing to the final zoning map that the researcher had brought anonymous user 1 2018 p 4 the presentation of information and facilitation of the decision making process is instrumental to empowering stakeholders to engage with the technology and cooperate with other groups wiedemann and fermer s continues to describe two ways in which project administrators could increase power in decision making first participants i e the public require access to information technical competence compensation for time and effort and the right to participate in decision making p 364 second the project administrator must work to close the knowledge gap between the experts developers scientists politicians and official decision makers and the public developers must focus on ways of visualizing the data collection and analysis phases in ways that take the participants through the decision making process itself and at least attempt to explain how the analyses work this is particularly important in times where the project administrators themselves do not fully understand the technical jargon and mathematical methods used in external analysis and cannot relay it to stakeholders project administrators are often working on a limited budget and cannot afford to implement the community advocacy and education needed to ensure the understanding of the process this is why donors and conveners need to budget accordingly but in times where that s simply not an option it s up to the developers to design support tools that have built in analytic dashboards that users can watch as data comes taking this a step further developers can include tutorials and videos explaining the analytic processes even training built directly into the platform this may help to encourage participants to adopt the technology and participate more in the process 9 alternatives to usability models with chauffeurs ballatore et al s pgus is an effective measurement tool when users have direct contact with the technology but many times project administrators act as or hire others to represent a group of participants in the designing phase they might do this to reduce cost time or to assist groups perceived as not technologically literate haklay and tobón 2003 not only does this take away the stakeholders agency to learn how to use the application it can lead to misunderstandings and negative perceptions these representatives sometimes referred to as gis chauffeurs stop participants from using the technology directly rendering certain aspects of the pgus survey useless acting as mediators over the knowledge these representatives may disconnect participants from experiencing the transformational effects of the technology potentially leading to an increase in the perceptions of data inaccuracy and or tampering the bottom line is that participants who rely on chauffeurs do not participate in the project in the same way as those who use the geodesign platform directly project administrators using seasketch mentioned that the use of chauffeurs made it difficult to gauge the local community s understanding of the maps explaining that although we gathered feedback from many of the fishermen the final maps were often questioned we noticed that that participants who used seasketch directly seemed less shocked about the final maps project administrator b 2018 harris and weiner 1998 and others curry 2008 brown 2012 raise the issue of expert driven systems and how it relates to community empowerment data access public participation and the incorporation of local knowledge harris and weiner concludes that communities are becoming involved in gis projects but they are not in control of those projects and remain dependent on state agencies ngos external funding and technically oriented advocates p 71 geodesign applications could include mechanisms to support diversity local empowerment and direct engagement with all of the public those looking to develop a geo support tool must be able to incorporate the public at various levels by creating multiple pathways for gathering and sharing data including the ideas and opinions of those not able to participate in the mapping process in person collaborative geo design applications should allow project administrators to gather a wide variety of data from users with and without access to the internet cell phones or computers perhaps automated cellular messaging services could be used to contact the public and update them on upcoming events or the application could help project administrators manage contact information emails and advocacy all on the same platform to evaluate the impact of chauffeurs and enforce transparency in the participatory process geodesign tools should at least provide practitioners with a tool that evaluates whether or not the user is relying on someone else to represent their interests or are using the application on their behalf 10 project management features within geodesign there is no single participatory process model used alongside seasketch most geodesign applications are used across decision arenas where project administrators are constrained by many externalities such as funding politics and capacity some projects allow for many public forums presentations and meetings that engage the broader public while other projects may only be convened by representatives in private meeting spaces either way geodesign applications are used in combination with a wide array of process models that incorporate the public at various levels both seasketch developers and project administrators mentioned the need for more integrative planning and management tools in their one on one interviews many of our clients have to use other project management tools in combination with seasketch which limits what we know about the planning process one developer discussed in their interview the disconnect between the project management features such as calendars to do lists gantt charts instant messaging or email and geodesign makes managing content and user participation more difficult one project administrator reflected on the issue in a different way explaining it s hard to keep track of who comes to our public forums we don t have a way to track them project administrator a 2017 project administrators need to be able to import and export lists of users who participate on and off the application including the ability to collect telephone numbers addresses and make comments including project management features directly into geodesign applications could help increase user participation across different groups ensure transparency and provide direct feedback to conveners and donors there are a number of project management support tools such as workfront wrike and basecamp that offer these types of features to clients but the majority of such professional applications cost between 200 and 5000 annually project administrators are searching to consolidate software costs and time spent switching between applications many participatory mapping projects simply go without project management tools altogether making monitoring and evaluating over time more difficult geo design developers can provide these features within their application to not only reduce the cost of participatory mapping projects but also allow them to conduct a more in depth analysis of project processes and outcomes monitoring and evaluating objectives and deliverables over time allows project administrators to analyze process models and project outcomes which could help strengthen the empirical evidence of the theoretical benefits of ppgis and thus more representation in public policymaking the design aspects included in this analysis involved mapping political social and economic power of different stakeholder groups within the geodesign application and providing an interactive experience with the data when creating new features we may do better by asking ourselves how our applications answer the harder to reach questions within the scholarly research and visualize them for project administrators these questions include 1 how much political social and economic power does each stakeholder group have in the participatory process 2 how does the stakeholder groups utilize and value each resource and how much control does the stakeholder have over the resources being evaluated 3 how can we better create manage and record perception data within the planning process 4 how can the analysis be visualized differently for nontechnical participants of participatory mapping 5 how can public databases be incorporated into geodesign applications and readily visible to project managers 6 how can project managers better engage with and encourage dialogue and communication among diverse participants 11 conclusions this article has focused on the ways in which developers of geodesign applications can increase public participation in ppgis using the experience of developers project administrators and users of seasketch our research highlights five ways in which the participatory process could be incorporated into the development of geodesign applications 1 determining the eligibility of a project and mapping stakeholder engagement 2 monitoring perceptions of fairness 3 visualizing data for non technical experts 4 alternatives to usability models with chauffeurs and 5 other project management features within geodesign each one provides ample avenues for further inquiry furthermore i highlight gaps within the field of ppgis and areas in which the developers of geospatial software could collect and manage relevant data on group dynamics perceptions of fairness and program evaluation in addition to standard environmental data i argue that the participatory process used alongside geo design tools is just as important as the usability of the technology because the majority of the participatory elements happens outside of the platform geodesign tools need to be dynamic and provide its users with multiple collection and analysis techniques that guide new users in learning project administrators draw from a multitude of interdisciplinary backgrounds such as social and political theory psychology and mediation and negotiation to assess projects or sometimes none at all as the process is being implemented project administrators try to adjust their models to account for the evolving dynamics among participants and the social and political environment the political and cultural context has a significant impact on participatory processes and projects success and should be incorporated in its design weiner et al 2002 sieber 2006 with considerable input from project administrators and researchers the creators of seasketch hope to design a seasketch 2 0 that incorporates the planning process hopefully this article inspires new ways of thinking about the development of geodesign support tools and helps to increase the participation of marginalized and at risk communities in our effort to build democratic consensus around resource based problems acknowlegement i thank will mcclintock university of california santa barbara for allowing me access to seasketch developers and the seasketch users for their detailed feedback and willingness to share their experiences initial funding and support for this research was provided by university of massachusetts boston and harvard university s program on negotiation appendix j supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix j supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104678 appendix i table 1 user survey questions table 1 planning process participant understands and values the planning process q1 i found value in the planning process q2 the planning process helped to build a better and stronger relationship between the participants q3 i understand the outcomes of the planning process and feel comfortable with the decision solution technology participant has used mapping software before and understands how to use it q4 the mapping technology gave me the tools i needed to reach my goals q5 i completed tasks that would have been impossible without the mapping technology q6 i would use this mapping technology again in the future q7 i would recommend this mapping technology to others sustainability participants are treated equally in the process and feel empowered to follow through with the plans q8 i contributed to the final planning decision q9 i was able to communicate my ideas and needs to others in the planning process q10 i agree with the final outcome of the planning process trust participants view the conveners and facilitators as being impartial and trustworthy q11 the facilitator helped to build consensus around our ideas q12 the stakeholders were treated equally throughout the planning process cooperation participants view the other participants as cooperative and wants to continue working on the project with them q13 the other participants were cooperative throughout the planning process q14 i would work with the other participants again q15 i will work together with the other participants to implement the project outcomes general questions participants demographic make up q16 do youtable 1 user survey questions consider yourself a part of a historically underrepresented group q17 what group do you most identify with environmental scientist activist government agency fisheries tourism or other q18 did you map your designs directly into seasketch or did you have someone map them for you chauffeur q19 what is your age q20 do you have any additional feedback 
26041,this paper presents a framework to systematically compare the contributions to uncertainty in hydro economic simulated outputs from the uncertainty surrounding input parameters employed by the hydrologic and economic models independently we consider an illustrative case study example an integrated modeling framework is adopted involving a surface water groundwater nitrate transport model and a multi regional computable general equilibrium model environmental uncertainty contributions are determined by optimizing nitrate loading under ecologically relevant constraint uncertainty at varying risk stances the results of which are mapped to economic outputs economic uncertainty contributions are quantified through monte carlo sampling of variables associated with social accounting matrices and substitution and transformation elasticities results indicate that at the study area scale the environmental contribution to gross regional product uncertainty is generally larger compared to that of economic uncertainty nevertheless the reliability of hydro economic outputs is shown to be highly dependent on environmental and economic sources of uncertainty on the basis of our case study findings we recommend that commensurate effort be focused toward enhanced assimilation of observation data in both types of models to reduce their respective uncertainties graphical abstract image 1 keywords hydro economic model uncertainty quantification decision making surface water groundwater model computable general equilibrium model optimization under uncertainty 1 introduction effective water resource management requires consideration of environmental ecological and economic objectives and constraints as well as a sound understanding of the complex interrelations between these interdisciplinary factors gorelick and zheng 2015 problems of water resource management are increasingly being addressed through application of integrated hydrologic and economic computer models of different types referred to herein as hydro economic models brouwer and hofkes 2008 harou et al 2009 reliable resource management decision making in this context is underpinned by risk based i e probabilistic assessments of the impact of future potential management strategies freeze et al 1990 faucheux and froger 1995 tartakovsky 2013 use of hydro economic models within a risk based decision support context therefore relies on robust quantification of uncertainty surrounding decision relevant simulated outputs referred to herein as outputs of interest or simply outputs e g sigel et al 2010 doherty and simmons 2013 this study explores the uncertainty surrounding hydro economic outputs arising from two distinct sources the uncertain parameters used by the hydrologic model and the uncertain parameters used by the economic model only a handful of previous studies have treated uncertainty in hydro economic modeling e g guillaume et al 2012 d agostino et al 2014 settre et al 2017 previous hydro economic modeling studies have dealt with uncertainties associated with parameters of either the hydrologic model e g peña haro et al 2011 llopis albert et al 2014 or the economic model e g abler et al 1999 belgodere and vellutini 2011 graveline et al 2012 mary et al 2018 however the uncertainties associated with both hydrologic and economic models have not been expressed in concert there are therefore currently no existing estimates of the relative contribution of hydrologic and economic model input uncertainty to hydro economic output uncertainty this paper serves to address the aforementioned knowledge gap by means of numerical experiments aimed at elucidating the relative hydrologic and economic contributions to the uncertainty surrounding hydro economic outputs of interest namely gross regional product grp in other words this study sets out to answer the question is the uncertainty surrounding economic outputs primarily attributable to underlying hydrologic or economic model input parameter uncertainty a hypothetical hydro economic model serves as a case study the case study reflects a new zealand environmental and economic context where a recent increase in the amount of agricultural land used for dairy farming has been linked to environmental impacts e g increased nitrate fluxes entering water ways mfe 2017 to the best of the authors knowledge this is the first study that explicitly compares sources of uncertainty arising from both hydrologic and economic system models it is hoped that this study through identification of these relative contributions and their variability for different outputs of interest will provide a useful platform for prioritizing the efforts of future interdisciplinary modeling endeavours for improved risk based decision support our hydro economic modeling approach involves a physically based and spatially distributed hydrologic and nitrate transport model and a multi regional general equilibrium economic model to explore the relationships between environmental and economic outcomes in response to changes in nitrate loading this approach provides a robust basis for quantifying the uncertainties associated with these relationships it allows for insights to be gained into environmental and economic trade offs across multiple scales for multiple stakeholders including critical enablers inhibiters that play out in the wider economy we consider this approach to be an essential feature in the context of model based land use management decision making support the remainder of this paper is organized as follows first a detailed description is given regarding the hypothetical case study that serves as an illustrative example this description includes an overview of the underlying hydrologic and economic models their integration and the methodologies used to quantify the uncertainty associated with parameters for each of these models in hydro economic model output terms the results of the analysis are then presented followed by a more general discussion of the implications of these results before drawing conclusions and recommendations 2 an illustrative example 2 1 overview of hydro economic modeling approach this study employs a hypothetical case study to investigate the relative hydrologic and economic model contributions to hydro economic output uncertainty our integrated hydro economic model like many other models of this type e g brouwer et al 2008 van heerden et al 2008 strzepek et al 2008 adopts a tight geospatial coupling of climatic analysis surface water groundwater hydrology and land use characteristics integrated with detailed farm system management and supporting financial information while also recognizing wider i e general equilibrium economic system impacts this approach facilitates reporting of the nitrate input concentration scenarios at different geospatial scales i e informing farmers catchment managers and regional national policy makers for decision making the hydrologic model is a physics based groundwater unsaturated surface water flow and nitrate transport simulator while the economic model is a comparative static and multi regional cge model a modular integration approach is adopted e g brouwer and hofkes 2008 i e whereby the system of equations solved by the hydrologic and economic models are independent both models their integration and the approaches used for uncertainty quantification are described below fig 1 provides a schematic representation of the integrated hydro economic modeling approach adopted to disentangle the relative contributions to output uncertainty 2 2 hydro economic outputs of interest the output of interest here is the net change in grp i e δgrp grp is a measure of the total market value of final goods and services produced by a nation region s economy in a given year net changes in value added va i e δva are also reported at an industry level including for dairy cattle farming sheep and beef farming horticulture forestry and so forth change in grp outputs are first considered under a management scenario aimed at decreasing nitrate loading this scenario represents a hypothetical ecological conservation agenda typical of water allocation and nutrient limit setting prerogatives being instigated worldwide oecd 2017 this scenario is referred to herein as the ecological conservation or simply the conservation scenario some of the data on which the economic model is constructed e g cost abatement curves relate to how an economy responds to cut backs in intensive dairy farming given environmental policy targets discussed in detail later the economic model is therefore considered to be well suited to simulating outputs of interest under ecological conservation i e nitrate loading reduction scenarios we also explore the outputs from a different land use management agenda representing a nitrate loading increase scenario a hypothetical dairy farming intensification agenda this scenario is referred to herein as the intensification scenario consideration of both management scenarios allows for insights to be gained surrounding the non linear nature of the resulting economic outputs and their uncertainty the representation of these nitrate loading management scenarios is different between the hydrologic model and economic model as described in the following sections 2 3 the hydrologic model the hydrologic model is used to simulate water quality responses to changes in hydrologic and environmental inputs it is also used to express how the uncertainty surrounding hydrologic and environmental input quantities represented by model input parameters propagates through to environmental outputs of interest namely surface water nitrate concentrations at locations of management interest the uncertainty of environmental outputs is subsequently mapped to the economic outputs of interest in a decision relevant manner i e related to ecological environmental risk aversion through use of a nitrate loading optimization under uncertainty approach the underlying hydrologic model and its use in expressing uncertainty is described in detail below 2 3 1 model description the hydrologic model simulates flow and advective dispersive transport of nitrate within groundwater surface water and the unsaturated zone of a large scale 1476 km2 hypothetical hillslope catchment exhibiting extensive surface water groundwater interaction fig 2 provides a schematic of the simulated hydrologic system modflow nwt niswonger et al 2011 was used to simulate steady state surface water unsaturated zone and groundwater flow conditions mt3d usgs bedekar et al 2016 was subsequently used to simulate transient nitrate transport in the simulated surface water unsaturated zone and groundwater hydrologic systems the hydrologic model is described in knowling et al 2019 and white et al 2020 we therefore provide only a brief summary of features that are relevant to the current study the model comprises a structured finite difference grid with 3 layers 200 rows and 144 columns with a uniform horizontal grid discretization of 250 m spatially distributed nitrate inputs are represented by specifying the nitrate concentration that accompanies groundwater recharge the pre optimized base case nitrate input concentration is given in fig 2 spatially distributed first order reaction i e denitrification rates are specified 2 3 2 quantification of environmental uncertainty contributions optimizing nitrate loading under ecological constraints 2 3 2 1 overview quantification of how the uncertainty associated with environmental outputs from the hydrologic model effects the hydro economic model outputs of interest is achieved by subjecting the hydrologic model to a series of optimization under uncertainty ouu analyses these analyses are necessary given that we need a way to be able to map the environmental output uncertainty to the economic model inputs i e we cannot pass the outputs of the hydrologic model to the economics model directly the ouu analyses involve optimizing the spatial pattern of nitrate input concentration to the hydrologic model while satisfying maximum acceptable surface water nitrate concentration constraints which are important from an ecological perspective for maintaining in stream water quality at varying levels of ecological environmental risk aversion this is achieved by adopting the technique of chance constraints e g wagner and gorelick 1987 white et al 2018 as described in detail below here risk aversion represents the probability that the concentration chance constraints are truly satisfied the true value of these constraints can never be known because it is derived from the hydrologic model and is therefore uncertain risk aversion values vary between 0 0 and 1 0 low values represent a risk tolerant stance whereas high values represent a risk averse stance the series of ouu analyses used to quantify environmental uncertainty is performed by systematically adjusting the level of environmental risk aversion at increments of 0 01 1 between 0 0 and 1 0 or until the ouu problem becomes infeasible with respect to the satisfaction of constraints this approach yields a series of optimal yet risk based solutions of spatial nitrate input concentration patterns each risk optimal nitrate input concentration pattern is subsequently aggregated to reflect changes in industry wide nitrate loading rates with respect to a base case such that it can be used as input to the economics model described in detail below these aggregated solutions collectively express the uncertainty associated with nitrate inputs to the environmental system this uncertainty arises due to the uncertainty in simulated surface water nitrate concentration constraints which reflects our incomplete knowledge of the physical hydrologic system properties and boundary conditions i e hydrologic parameter uncertainty the propagation of each of the aggregated ouu solutions through the economic model yields a collection of economic model outputs of interest the consequence of environmental uncertainty in terms of economic output uncertainty can then be measured by taking the difference between simulated changes in economic outputs at different risk aversion values this decision relevant mapping of environmental uncertainty through risk based optimality to simulated economic indicators allows for quantification of how hydrologic model uncertainty propagates to economic model outputs of interest and as will be demonstrated facilitates a comparison between the environmental and economic contributions to hydro economic output uncertainty in summary the ouu approach provides a basis for mapping the decision relevant uncertainty associated with hydrologic model outputs i e the uncertainty associated with ecological environmental risk aversion to economic model outputs we note that environmental uncertainty is therefore defined specifically here as the uncertainty associated with the satisfaction of ecologically motivated surface water nitrate concentration constraints 2 3 2 2 fosm based quantification of uncertainty in simulated nitrate concentration chance constraints uncertainty is propagated through the hydrologic model i e from uncertain model parameters representing hydrologic system properties such as hydraulic conductivity porosity denitrification rate etc to simulated outputs serving as concentration chance constraints surface water nitrate concentrations using first order second moment fosm techniques e g tarantola 2005 doherty 2015 fosm approaches are commonly adopted in environmental modeling given the large computational burden often associated with forward model evaluations and the high dimensional parameter spaces that are usually required to be represented in decision support hydrologic modeling e g hunt et al 2007 knowling et al 2019 despite the approximate nature of fosm analyses several studies have demonstrated their robustness especially in the context of simulating output changes or differences e g dausman et al 2010 herckenrath et al 2011 using fosm the uncertainty variance for a model simulated output or optimization constraint of interest s σ s 2 is given by 1 σ s 2 y t σ θ y where σ θ is a parameter covariance matrix encapsulating knowledge or lack thereof surrounding parameters y is a vector of partial first derivatives or sensitivities relating changes in a model output or constraint s with respect to changes in a parameter θ i e a row of j in equation 2 herein we adopt a prior in a bayesian sense uncertainty stance that is σ θ represents our expert knowledge of parameters before any parameter conditioning on the basis of state observations via history matching or calibration σ s 2 therefore represents the prior uncertainty variance of s hydrologic model input uncertainty expressed via the σ θ matrix of equation 1 is expressed using a total of 802 uncertain parameters including horizontal and vertical aquifer hydraulic conductivities effective porosities denitrification rates and boundary conductances the diagonal elements of σ θ comprising the squared parameter standard deviations assumed are given in table 1 we employ a highly parameterized approach e g hunt et al 2007 to facilitate a robust expression of model input uncertainty especially when considering a prior uncertainty stance e g knowling et al 2019 pilot points are used to parameterize spatially variable aquifer properties e g doherty 2003 prior parameter distributions were specified as multi variate gaussian i e ɲ μ θ σ θ where are the initial parameter values spatially distributed parameters are assumed to be geostatistically correlated in accordance with an exponential variogram with a range of 2500 m and a sill proportional to the expected prior variance the jacobian matrix j comprising rows pertaining to y vectors is populated via finite difference approximation to partial first derivatives 2 j c o n c e n t r a t i o n i p a r a m e t e r j c o n c e n t r a t i o n i p a r a m e t e r j δ c o n c e n t r a t i o n i δ p a r a m e t e r j where c o n c e n t r a t i o n i is the simulated nitrate concentration at the surface water chance constraint location i and p a r a m e t e r j is an uncertain hydrologic model parameter 2 3 2 3 nitrate loading optimization under uncertainty chance constrained linear programming as summarised above following estimation of the uncertainty associated with simulated surface water nitrate concentrations serving as environmental constraints via equation 1 the ouu approach is employed to yield a series of optimal nitrate input concentration patterns under varying levels of risk aversion i e varying probability that surface water nitrate concentration chance constraints will be truly satisfied this is achieved using the technique of chance constraints e g wagner and gorelick 1987 white et al 2018 which yields a deterministic value for each simulated concentration constraint by moving along the implied gaussian cumulative distribution function implied by the variance in equation 1 in accordance with the risk aversion value it is noted that the ouu approach adopted here is like those adopted by peña haro et al 2011 and alizadeh et al 2018 also in the context of hydro economic modeling the linear programming lp optimization problem is solved as follows e g nocedal and wright 2006 3 maximize c t x subject to a x b x 0 where x is a vector of decision variables herein spatially varying nitrate input concentrations applied to the hydrologic model c is vector of objective function coefficients or weights b is a vector of constraint values herein maximum allowable surface water nitrate concentrations and a is a matrix of constraint coefficients herein representing a response matrix constructed on the basis of hydrologic model evaluations following decision variable perturbations e g ahlfeld and mulligan 2000 see appendix a solution of the lp problem equation 3 using chance constraints i e where vector b comprises shifted constraint values in accordance with a risk aversion value see above constitutes ouu an overview of the ouu formulation considered herein is as follows decision variables the decision variables comprise 14 383 grid cell based groundwater input i e recharge nitrate concentrations one at every uppermost layer model cell within dairy land use areas taken together these 14 383 decision variables form the spatial pattern of nitrate input concentration for the hydrologic model the upper value bounds for these nitrate input concentration decision variables are used as a basis for representing the conservation and intensification nitrate loading management scenarios described in more detail below objective function coefficients nitrate input concentration decision variables kg n m3 recharge are converted to nitrate mass loading rate kg n yr using objective function coefficients comprising annual volumetric ground recharge rates m3 year c vector in equation 4 chance constraints ecologically relevant simulated surface water nitrate concentrations at four locations red triangles fig 2 constitute the chance constraints used in the ouu problem the chance constraint values are based on simulated surface water concentrations from the hydrologic model and are shifted using a specified value of risk aversion we employ pestpp opt white et al 2018 to solve the chance constrained lp ouu problem and to populate the a and j matrices in a parallelized fashion the python scripting packages flopy bakker et al 2016 and pyemu white et al 2016 are used to construct the modflow nwt mt3d usgs numerical models and the pest doherty 2015 interface for these models respectively 2 3 2 4 post processing following the above described process to identify risk optimal spatial patterns of nitrate input concentration for the hydrologic model each of these nitrate input concentration patterns is aggregated so that it can serve as input for the economic model described below this aggregation yields a single value representing the percentage change in total nitrate load across dairy sector areas relative to the pre optimized i e base case solution as given by 4 δ n i 1 m x i o p t w i i 1 m x i b a s e w i 100 where x i o p t is the risk optimized value of decision variable i of which there are 14 383 nitrate input concentration decision variables x i b a s e is the pre optimized value of decision variable i fig 2 and w is the objective function coefficient of decision variable i 2 4 the economic model the economic model simulates both direct on farm and indirect rest of economy economic consequences including value chain and pricing effects associated with changes in nitrate loading it provides a basis for propagating the uncertainty associated with our knowledge of 1 how different industries supply and use different commodities as represented using social accounting matrices sams described below and 2 how production and consumption takes place across different industries and factors represented using constant elasticities of substitution ces and transformation cet described below it also provides a basis for mapping the environmental ecological uncertainty expressed using the hydrologic model within an ouu framework to economic outcome terms 2 4 1 model description we adopt a multi regional computable general equilibrium cge model to assess the economic consequences associated with changes in nitrate loading cge models are commonly applied in assessing whole of economy consequences including in analysis of water related policy options e g berck et al 1991 seung et al 1999 brouwer et al 2008 luckmann et al 2014 banerjee et al 2016 beckchanov et al 2017 and kahsay et al 2019 cge models assume that the economy is as a starting point in equilibrium and converges to a new equilibrium in response to an exogenous shock which in our case is a given change in nitrate loading industries households and government known as agents instantaneously choose their production and consumption behaviours to maximize profit utility equilibrium is reached when it is impossible to make an agent better off without making other agents worse off production and consumption behaviours are dependent on commodity factor prices where for every equilibrium there exist a unique set of prices that satisfy 1 zero profit i e under perfect competition the production sector makes no economic profit 2 market clearing i e commodity factor supply and demand equilibrate and 3 income balance i e each agent s income equals its expenditure these conditions may be modified depending on context our multi regional economic model represents two primary regions the region within which the study area resides and the rest of nation the model is based on the new zealand economy refer to smith et al 2015 moreover it is a comparative static model comparing changes in two equilibrium solutions i e a business as usual baseline against a given nitrate loading agenda the model represents 21 industries each capable of producing up to 16 joint commodities with five agricultural industries that are represented separately at the study area and the region scale that is a total of three spatial scales are considered referred to herein as study area this is the scale at which environmental risk is assessed using the hydrologic model rest of region and rest of nation the separation of agricultural industries between the study area and the rest of region facilitates tight coupling of the hydrologic and economic models at a fine spatial scale i e land use hydrologic and climatic characteristics are linked directly with farm scale management practices and financial analysis the equilibrium solution satisfying these conditions is solved using an optimization formulation based on an arrow debreu general equilibrium framework arrow and debreu 1954 our model is specified as a mixed complementarity program mcp in the mathematical programming systems for general equilibrium mpsge package rutherford 1995 as a general algebraic system gams sub system brooke et al 1988 for an overview of the cge modeling approach adopted the reader is referred to appendix b 2 4 1 1 model closure solving the above system of functions under an mcp approach also requires choosing which variables will be exogenously specified these so called closure conditions are typically based on how agents are assumed to behave in response to a shock event or policy change in this paper we assume the following closure conditions a short term focus i e any economic changes associated with δn occur immediately the level of labour provided by households varies but is correlated at an aggregate level with changes in the consumer price index i e labour growth is relatively slow and total national capital and land use remain fixed i e there is no land use change 2 4 2 quantification of uncertainty in economic outputs of interest the uncertainty associated with input quantities underpinning our multi regional cge model arising from the following primary sources are now summarised table 2 we recognize that other sources of uncertainty exist but these have not been explored in this study see discussion social accounting matrices sams so called supply use tables e g united nations 2018 and institutional accounts are used to derive the sams that underpin our comparative static cge model a supply use table expresses information pertaining to 1 which industries including households supply which commodities within an economy the supply table and 2 which industries use which commodities within an economy the use table these tables are developed through official national accounting procedures and statistical surveys united nations 2018 commodity trade data based on the world customs organization s harmonised system world customs organization 2016 and taxation data a total of 297 sam related cge model input quantities are considered as uncertain using standard errors mapped to sam commodity industries definitions estimates of the statistical accuracy i e representing uncertainty of the above mentioned table values are made see table 2 for standard deviation values specified for the range of sam related parameters this approach follows the work of lenzen et al 2010 but instead of calculating uncertainty for a multi regional input output table a multi regional sam is utilised constant elasticities of substitution and transformation ces and cet these are functions with exogenous parameters typically referred to as scale and share parameters that describe how factors e g labour capital and land commodities and industries and households produce or consume within an economy most of these are derived using econometric analysis the parameters underpinning e g a cobb douglas production function which is a simplified ces function are derived using constrained regression analysis where the elasticities must equal one a total of 66 elasticity related model input quantities are considered as uncertain since the calculation of the ces and cet functions is normally undertaken using regression analysis standard errors are readily available see table 2 for standard deviation values specified for the range of elasticity related parameters a standard monte carlo analysis is used to propagate uncertainty from both the sams and the ces and cet inputs to simulated δgrp uncertain input quantities are stochastically sampled as independent gaussian random variables 10 000 samples are drawn and evaluated this is performed by interfacing the economics model within the non intrusive pest doherty 2015 model interface using pyemu white et al 2016 pyemu is also used to generate the 10 000 realization ensemble the ensemble is then evaluated in a parallel processing fashion using pestpp swp white et al 2017 monte carlo sampling inevitably results in an unbalanced sam rebalancing using a quadratic programming approach refer to geschke et al 2019 for alternative rebalancing methodologies is required to ensure key economic equilibrium identities are met i e corresponding row and column totals of the sam equate we then shock the cge in accordance with δn by farm industry type translated into changes in farm revenue and expenditure using the cost abatement curves the cge model in turn captures the general equilibrium impacts repercussionary effects in other industries price changes factor substitution transformation transfers and so on in the wider synthetic catchment area and rest of new zealand economies impacts are reported in grp terms by industry and in total for the synthetic catchment area and rest of new zealand economies grp is a monetary measure of the market value of goods and services produced with an economy for farming industries grp equates directly with the earnings before income tax less depreciation and rental ebit dr estimates generated through the cost abatement curves for all other industries it is the sum of the compensation of employees operating surplus consumption of fixed capital and other taxes on production variables as generated by the cge model 2 5 comparison between environmental and economic model uncertainty contributions to quantify environmental contributions to hydro economic model output uncertainty i e from the hydro economic output uncertainty associated with environmental ecological risk aversion each risk optimal δn value at risk aversion increments of 0 01 or 1 is used as input to the cge model while holding all uncertain economic input variables fixed running the cge model once for each risk optimal δn value produces δgrp outputs that collectively represent the environmental contribution to hydro economic output uncertainty these environmental contributions to hydro economic model output uncertainty are then compared to those of economic uncertainty sources as quantified by the above described monte carlo sampling approach described above 2 5 1 nitrate loading management scenarios to quantify the environmental contributions to hydro economic model output uncertainty under different nitrate loading management scenarios the hydrologic model is subjected to the above described ouu analysis to obtain risk optimal δn values twice once for each of the conservation and intensification scenarios the two ouu analyses employed different decision variable i e nitrate input concentration upper bounds as a means of representing these different management scenarios for the ecological conservation scenario the nitrate input concentrations are kept below the maximum base case level as calculated across the case study area fig 2 for the intensification scenario the nitrate input concentrations are allowed to increase above current base case levels specifically nitrate input concentration upper bounds for the conservation and intensification scenarios are specified respectively as 0 026 and 0 040 kg n m3 i e 26 and 40 mg n l which correspond to credible nitrate loading rates e g ledgard et al 1997 to quantify the economic contributions to hydro economic model output uncertainty under different nitrate loading management scenarios the above described monte carlo analysis is undertaken twice once for the ecological conservation scenario and once for the dairy farming intensification scenario the analysis for the conservation scenario is undertaken using a constant δn value of 80 whereas for the intensification scenario a constant δn value of 120 is used these δn values are comparable in magnitude to those obtained from the respective nitrate loading ouu analyses 2 5 2 a note on the integration of environmental and economic models the relationship between industry based nitrate loading rate and economic activity which essentially represents the mechanism by which the environmental and economic models are coupled is governed herein by cost abatement curves for each agricultural industry in the cge model i e sheep and beef farming dairy cattle farming and other livestock farming cost abatement curves serve to relate δn to associated changes in revenue and expenditure particular attention is paid to dairy cattle farmer responses to δn representing the dominant farming activity within the synthetic catchment area a sample of responses from representative dairy farms covering the key determinants of leaching e g including geophysical climatic and farm management practice factors was generated from a database of all dairy farms within the synthetic catchment area farmer responses were assessed using the overseer nutrient management tool and in turn translated into changes in revenue as ebit dr and expenditure by item where relevant for use in the cost abatement curves these responses are based on actual farm systems using best practice financial reporting we therefore believe the uncertainty will be of a similar magnitude to that reported for the farming industries within the nz system of national accounts i e as applied to generate the multi regional sam 3 results 3 1 environmental contribution to economic uncertainty fig 3 shows how δgrp varies with environmental risk aversion for the ecological conservation scenario fig 3a a declining δgrp trend is apparent at the study area scale as a more environmental risk averse stance is adopted i e with increasing risk aversion values this is expected given that increasing risk aversion must result in less nitrate being introduced into the hydrologic system less nitrate means that less value added e g operating surplus employee income can be made within the study area when seeking a higher probability or chance that the ecologically motivated nitrate concentration chance constraints are truly satisfied note that δgrp within the study area does not vary at low risk aversion values 0 10 this is because the nitrate loading ouu problem is bound by the specified allowable range of decision variables rather than concentration chance constraints declining δgrp trends exist to a certain point risk aversion 0 50 where the nitrate loading ouu problem becomes infeasible i e there is no region of decision variable space that simultaneously satisfies surface water nitrate concentration chance constraints at risk aversion values exceeding 50 ouu solution infeasibility is attributable to the large degree of environmental uncertainty uncertainty in simulated surface water concentrations arising from uncertainty hydrologic system properties as estimated by fosm analysis the total magnitude of the monotonic decline in study area δgrp with increasing risk aversion for the conservation scenario is approximately nz 2007 18 million us 2018 13 5 million for the study area this represents the economic cost or monetary value of the uncertainty in environmental risk aversion for the study area from a prior bayesian stance i e a prior uncertainty stance is adopted to counter possible variance under estimation it should be noted however that this measure does not account for the full range of surface water nitrate concentration constraint uncertainty as estimated by fosm techniques because of the infeasibility of the ouu problem at high risk aversion values e g 60 the resulting economic cost of uncertainty in environmental risk aversion may therefore be an underestimate of the total cost of environmental uncertainty in economic terms for the rest of nation scale the relationship between δgrp and environmental risk aversion displays a more complicated trend δgrp decreases when considering increasing risk aversion values less than 0 20 i e up to a constraint satisfaction confidence of 20 followed by δgrp stabilization and recovery increase at an increasing rate with further increasing risk aversion in fact the δgrp at a risk aversion value of 0 50 nz 2007 11 7 million or us 2018 8 8 million is marginally greater than that at a risk aversion value of 0 01 nz 2007 10 4 million or us 2018 7 8 million this result indicates the greater flexibility within the wider national economy to adapt due to the mobility of capital and labour as a factor of production in accordance with environmental management initiatives i e as environmental risk aversion increases the rest of nation economic cost of environmental risk aversion taken as largest difference in δgrp values occurring between risk aversion values of 0 22 and 0 50 is approximately nz 2007 12 million us 2018 9 million this is smaller than the economic cost of the uncertainty in environmental risk aversion within the study area which is not unexpected given the flexibility of the greater economy to adapt as described above for the additional intensification scenario fig 3b both the study area δgrp and rest of nation δgrp outputs display a monotonic declining trend as environmental risk aversion increases the relative magnitude of δgrp decline with increasing risk aversion is considerably larger for the rest of nation compared to the study area this is due to the inter dependencies that exist between the study area and rest of the nation particularly with regards to value added in the downstream primary processing plants and to a lesser degree associated service i e there are increasing returns to scale with dairying the overall economic cost of the uncertainty in environmental risk aversion is approximately equivalent to nz 2007 18 million us 2018 13 5 million for the study area and nz 2007 115 million us 2018 86 million for the rest of nation in terms of δgrp terms fig 4 shows the relationship between environmental risk aversion and industry based δva at both study area and rest of region scales for the ecological conservation scenario fig 4a industry δva trends with varying environmental risk aversion show complicated patterns as expected given δgrp trends apparent for this scenario fig 3a as risk aversion values increase the dairy cattle farming industry in the rest of region and the water supply industry in the study area display an overall increase in δva this occurs while δva for dairy cattle farming within the study area and associated industries such as dairy product manufacturing significantly decrease as expected both the construction and services e g business education health services industries show variable δva trends as risk aversion increases note that for some industries small increases in value added occur with increasing environmental risk aversion as a result of capital being freed up for investment however the overall trends show a reduction with increasing environmental risk aversion in contrast the intensification scenario fig 4b displays comparatively simple i e monotonic δva trends with increasing risk aversion among different industries namely significant changes in the dairy farming industry δva at both study area decreasing but positive δva and rest of region increasing but negative δva scales the services industry also shows a large δva decrease with increasing risk aversion due to economic interdependencies that exist between dairy cattle farming and services particularly banking financial and technical scientific services note that with increasing environmental risk aversion within the study area capital investment in dairy farming in the wider region increases 3 2 economic uncertainty contribution and comparison with environmental contribution fig 5 shows probability density functions pdfs of study area and rest of nation δgrp outputs of interest under conservation and intensification management scenarios that are attributable to the uncertainty associated with environmental risk aversion referred to as environmental contribution pdfs herein for simplicity notwithstanding the caveats described above and economic uncertainty economic contribution pdfs independently fig 5 provides a general basis for comparing the relative contributions of environmental and economic sources to δgrp output uncertainty note that the environmental contribution pdfs blue on fig 5 simply represent a different way of expressing the information presented in the δgrp versus risk aversion plots of fig 3 this provides an explanation as to the non gaussian nature of the environmental contribution pdfs particularly those for the conservation scenario fig 5a and c specifically the truncation of the upper portion of the pdf in fig 5a reflects the distinct maximum δgrp value allowed for the conservation scenario i e through the lowered decision variable upper bound fig 3a the approximately bi modal pdf in fig 5c reflects the non monotonic nature of the δgrp versus risk aversion relationship at the national scale under the conservation scenario fig 3b the following observations and interpretations can be made based on fig 5 the second moments i e variance of the environmental contribution pdfs blue are significantly larger than those of the economic contribution pdfs orange for the intensification management scenario at both a regional and national scale the δgrp ranges are approximately three and ten times larger respectively fig 5b d this reflects that the intensification scenario generally represents a situation whereby the environmental uncertainty contribution to hydro economic output uncertainty is not limited by other economic factors that is where the economy is able to re use capital freed up in dairy cattle farming elsewhere within the economy under normal constraints e g labour availability does not constrain investment the second moment of the environmental contribution pdf is also considerably larger than that of the economic contribution pdf for the ecological conservation scenario at a regional scale fig 5a the larger environmental uncertainty contribution for both conservation and intensification management scenarios at a regional scale fig 5a and b is an important finding it suggests that for the synthetic case study considered reflecting hydrologic catchments and economies present in new zealand the environmental uncertainty contributions exceed those of economic uncertainty at a regional scale as mediated by exploration of the full range of risk aversion values regardless of the non linearities surrounding economic uncertainties the second moments of the economic contribution pdfs are considerably larger for the conservation scenario compared to the intensification scenario at both spatial scales the δgrp ranges are approximately two and three times larger for regional and national scales respectively this demonstrates non linearity in the relationship between uncertain economic model outputs with respect to changes in nitrate loading i e δn it is hypothesized that the larger economic output uncertainty associated with the ecological conservation scenario is because of the simulated re distribution of capital within the economy resulting from the environmentally infeasible dairy practice and the associated activation of additional uncertain economic model inputs that are used in simulating the δgrp in contrast the sensitivity of δgrp outputs with respect to these input parameters would be less or zero for the intensification scenario the economic contribution pdfs display an approximately gaussian i e normal nature given that the economic parameter input uncertainty is gaussian this suggests that the cge model is approximately linear in terms of its mapping of input uncertainty to δgrp output uncertainty note that this implies applicability of fosm techniques as per equation 1 an increase in the second moment of both the environmental and economic contribution pdfs from the regional to the national scale is evident as discussed this is explained by the ability of the national economy to re use capital freed up in dairy cattle farming elsewhere within the economy under normal constraints 4 discussion the nitrate loading ouu approach adopted herein provides a basis for quantifying the decision relevant environmental uncertainty i e the uncertainty associated with ecological environmental risk aversion or constraint satisfaction probability this is the only uncertainty that matters in the context of the hypothetical decision making context of this work through decision relevant mapping of this uncertainty to economic model outputs the contribution of environmental uncertainty to hydro economic output uncertainty can be determined as described the environmental uncertainty contributions presented herein do not account for the full range of surface water nitrate concentration constraint uncertainty as estimated by fosm techniques because of the infeasibility of the ouu problem at high risk aversion values e g 60 it follows that the resulting environmental contribution to hydro economic model output uncertainty may therefore be an underestimate of the total environmental uncertainty however our consideration of a prior environmental uncertainty stance serves to counter possible variance under estimation notwithstanding the inevitable subjective definition of priors an important assumption underpinning the ouu approach is that of independence between the decision variable constraint relations and the uncertain parameter constraint relation the assumption of independence is also known as decoupling in the realm of reliability based design optimization e g royset et al 2001 the former of these relations has been shown to be linear e g gorelick and remson 1982 mclay et al 2001 and the latter of these has been shown as an appropriate approximation especially given its ability to reduce computational burden e g dausman et al 2010 herckenrath et al 2011 the computational efficiency and scalability of the nitrate loading ouu approach is the subject of the companion paper white et al 2020 while the extent to which the assumption of independence holds is presently unknown and is the subject of a concurrent study it is expected that this potential source of non linearity would only cause minor changes to the overall outcomes of the present analysis the approach adopted herein for quantifying economic uncertainty contributions was based on methods that capture uncertainty in the baseline sam building particularly on the work of lenzen et al 2010 and in the ces cet elasticities e g abler et al 1999 graveline et al 2012 mary et al 2018 it is important to note that very few applied economic studies have quantified uncertainty in multi regional cge models due to confidentiality constraints the complexity and laborious nature associated with compiling multi regional sams and the lack of statistical error reporting in the underlying economic datasets this study therefore provides an important contribution to advancing the state of uncertainty quantification in economic modeling towards enhancing risk based management decision support it should be noted that economic model outputs associated with the ecological conservation management scenario considered herein are expected to be more robust than those associated with the dairy farming intensification management scenario this is because the cost abatement curves are formulated with respect to nitrate loading reduction impacts on capital and labour whereas the intensification scenario involving nitrate loading increases extrapolates these abatement curves the form and availability of these abatement curves reflects the general environmental and ecological conservation agendas that are increasingly being adopted e g bay of plenty regional council 2017 while it is not known how well the cost abatement curves describe the relationship between capital and labour responses associated with increases in nitrate loading we hypothesize that the relationships will be weaker i e the curve will have a lower slope under an intensification management scenario nevertheless our assessment of a hypothetical dairy farming intensification scenario in addition to an ecological conservation scenario allows for insights into the degree of non linearity in the uncertainty surrounding economic outputs with respect to different land use management scenarios it also provides a basis for testing the robustness of the findings based on a single condition only the modular approach used herein to integrate environmental and economic models involves a one way transfer of information between the respective models only i e there is no dynamic feedback between the equations solved by the respective models brouwer and hofkes 2008 the alternative would be to use a holistic model integration approach involving much more detailed representation of complex model interactions and dynamic feedbacks e g cai et al 2008 the modular approach was deemed necessary in this study because it allows for more comprehensive simulation of each independent model domain given the need to simplify the individual underlying models to make the holistic approach viable from a computational efficiency standpoint e g brouwer and hofkes 2008 more specifically use of a modular approach in this study allows for a spatially explicit and physically motivated hydrologic model to be employed i e without encountering excessive computational times this is important given that environmental management questions invariably concern these discrete spatial distributions while this work focuses on the uncertainty associated with input parameters underpinning our hydro economic model we do not investigate the uncertainty inherent in the modeling process so called model error structural error or unknown unknowns e g doherty and welter 2010 for example our multi regional cge economic model is comparative static ignoring the passage of time and the uncertainty associated with transition to a new equilibrium while dynamic cge dcge models are increasingly being used in policy analysis particularly so called recursive dynamic institutional and or other fully dynamic implementations they are yet to be widely utilised in hydro economic modeling in the case of the nitrate reduction agenda it is for example likely that reduction technologies might be phased in over time or alternatively at the right price tipping point a dairy cattle farmer might simply cease operation and use their land for another economic activity to meet reduction targets additionally while labour and capital are relatively mobile in an economy this is less so when tied heavily to a particular land use plant machinery and equipment is not always easily re deployed to another economic activity our hydro economic activity does not account for this complex behaviour or for its inherent uncertainty this is an obvious next step in the research agenda for accounting for uncertainty in hydro economic modeling the dependence of the magnitude of both environmental and economic uncertainty contributions on the specific hydro economic model output of management interest e g study area versus national scale conservation versus intensification scenario is not a surprising outcome this finding has been documented extensively in the environmental modeling literature e g doherty and christensen 2011 white et al 2014 we acknowledge the unavoidable subjectivity accompanying the many decisions that underpin modeling endeavours especially those that adopt coupled or integrated models from distinct and separate disciplines and those that are framed within the decision support context both of which are the case here for example the findings presented herein are dependent on e g hydrologic model parameterization details such as the problem dimensionality i e number of uncertain parameters considered the geostatistical relationships assumed that govern correlation between parameters the definition of appropriate prior expected parameter variances among others a specific example includes our use of prior parameter uncertainty distributions for setting fosm derived chance constraints which would ultimately result in larger environmental uncertainty contributions providing that hydrologic model parameters are sensitive to observations for parameter conditioning despite the challenges associated with the transferability of findings between modeling investigations as a result of these subjective factors the hypothetical case study findings presented herein provide a useful benchmark for understanding the relative environmental and economic contributions to hydro economic output uncertainty 5 conclusions this paper presents a methodological framework for the systematic comparison of uncertainty contributions in hydro economic simulated outputs from hydrologic and economic models the framework involves mapping decision relevant environmental uncertainty arising from hydrologic model parameters to hydro economic simulated output space this is achieved by solving a series of management optimization under uncertainty problems economic uncertainty quantification is achieved through monte carlo sampling of parameters underpinning social accounting matrices and substitution and transformation elasticities it is hoped that this framework is adopted elsewhere as a basis for prioritizing the efforts of modeling practitioners across disciplines this paper also provides an important benchmark for understanding the relative environmental and economic contributions to hydro economic output uncertainty using a synthetic model case study example to the best of the authors knowledge the current study is the first to explicitly and comprehensively compare both environmental and economic sources of uncertainty in a multi scale hydro economic management scenario context it is shown that for our case study example the environmental contribution to the uncertainty in hydro economic model outputs i e change in grp at the regional scale is generally larger compared to that of economic uncertainty under both ecological conservation and dairy farming intensification management scenarios the relative economic uncertainty contributions are shown to be larger than those of environmental uncertainty only for change in grp outputs made at the national scale under a conservation management scenario in more general terms the results presented demonstrate that while the reliability of hydro economic outputs of interest is dependent on both environmental and economic sources of uncertainty the relative environmental versus economic uncertainty contributions are highly model output specific we therefore recommend that commensurate effort be focused toward enhanced uncertainty quantification and assimilation of observation data in both environmental and economic models to increase the reliability of coupled environmental economic e g hydro economic model outputs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors wish to acknowledge matthew newman dairynz for providing farmax data and katy kelly gns science for assistance in developing the graphical abstract the authors wish to thank the reviewers and associate editor joseph guillaume for their constructive comments this research was performed as part of the smart models for aquifer management programme funded by the ministry of business innovation and employment new zealand appendix a use of the stochastic impulse response emulator sire for nitrate input concentration optimization under uncertainty ouu a highly efficient nitrate input concentration ouu approach is adopted we term this approach stochastic impulse response emulator or sire the approach affords its computational efficiency through employing model emulation e g asher et al 2015 and fosm uncertainty estimation techniques the reader is referred to the companion paper white et al 2020 for a full description and demonstration of sire and its use in the present ouu context the emulation strategy relies on the concept of linearity between nitrate loading or nitrate input concentration as in the current study changes and surface water or groundwater nitrate concentration changes sire adopts a response matrix based emulation strategy e g ahlfeld and mulligan 2000 the response matrix a maps changes in decision variables i e nitrate loading rates to changes in model outputs constraints of interest i e surface water nitrate concentrations a is given by a 1 a c o n c e n t r a t i o n i l o a d i n g j c o n c e n t r a t i o n i l o a d i n g j δ c o n c e n t r a t i o n i δ l o a d i n g j where l o a d i n g j is the nitrate loading rate at model node j and c o n c e n t r a t i o n i is the nitrate concentration at a surface water reach of interest in this work a is independent of the decision variable values given the linear loading concentration relation see below the a matrix equation 3 is used as a basis for solving the linear programming lp problem e g nocedal and wright 2006 eq 3 the relationship between nitrate loading changes decision variables and resulting surface water concentration changes hydrologic model outputs has been discussed by many studies to take a linear form e g gorelick and remson 1982 spalding and exner 1993 mclay et al 2001 that is the concentration evaluated at any point in space or time is a linear function of the initial concentration herein the nitrate loading or nitrate input concentration this means that down gradient concentrations of interest can be calculated simply by linearly scaling the nitrate input concentration or the concentration resulting from loading this linear relation is also not affected by simulation of a first order reaction rate to represent denitrification the reader is referred to white et al 2020 for more details appendix b multi regional comparative static cge model brief mathematical overview commodity production is represented by hierarchically nested constant elasticity of substitution ces production functions where inputs are intermediate commodity consumption and labour capital and land factors of production inputs are grouped and nested depending on their degree of substitutability e g no substitution is assumed to exist within the intermediate consumption nest i e the proportion of commodities required to produce a unit of output remains constant between intermediate consumption and factors of production nests and between the factors of production nests for labour capital and land finally labour and capital are assumed to be fully substitutable mathematically the profit maximization production function takes the form max x i j r p x i j r u i 1 i p i r p x i j r p i 1 i p i r d x i j r u k 1 k p k r f j k r b 1 s t x i j r p min 1 a j r f r j r r j r ϕ j r k j r k j r δ j r 1 δ j r 1 ϕ j r l j r l j r δ j r 1 δ j r δ j r δ j r 1 x 1 j r u a 1 j r u x i j r u a i j r u where the revenue from sector j in region r selling commodity i is generated by x i j r p quantities of commodities at the producer s price i e less indirect taxes and subsidies p i r p while the cost to sector j in region r of selling commodity i uses x i j r u quantities of intermediate commodities at a composite i e as domestically produced and imported supply price p i r d and f j k r quantities of factor of production k at price p k r profit maximization is subject to a cost minimizing production function where the x i j r p quantities of commodities i sold and produced by sector j in region r is a nested ces function of intermediate consumption and factors of production where intermediate consumption is determined by technological coefficients for intermediate inputs a 1 j r u a i j r u and x i j r u quantities of intermediate commodities used and the factors of production by 1 technological coefficients for all factors a j r f 2 the relative factor shares between capital and labour ϕ j r 3 land capital and labour quantities used by sector j in region r respectively r j r k j r and l j r 4 the baseline land capital and labour quantities used respectively r j r k j r and l j r and 5 δ j r is the ces elasticities of substitution commodities are sold either domestically or exported regional or overseas we portray this using a nested constant elasticity of transformation cet function where 1 for each percentage change in economic output the proportion of commodities consumed domestically and exported remains the same 2 produced commodities are non homogenous and 3 market demand is not fully substitutable together these conditions ensure that no individual market demands all quantities produced of each commodity although world commodity prices are fixed i e our economy is a price taker they are affected by changes in exchange rate commodity consumption is subject to a ces utility maximization function where agents choose a combination of commodities to consume that is less than or equal to their total income available less of course any savings mathematically this takes the form b 2 max x i a r c u a r x i a r c w h e r e u a r x i a r c i 1 i a i a r 1 σ a r x i a r c σ a r 1 σ a r σ a r σ a r 1 s t i 1 i p i r d x i a r c y a r where u a r is a utility maximization function for an agent a in region r where x i a r c is the quantity of commodity i consumed by agent a in region r a i a r is a share of commodity i for an agent a in region r and σ a r is an elasticity of substitution between commodities for an agent a in region r this function is subject to a budget constraint where y a r is the total income of an agent a in region r and p i r d is price of each commodity i in region r each agent may have a different utility maximizing commodity substitutability households for example are assumed to have a ces elasticity of substitution greater than zero thus diminishing increasing utility returns to an increase decrease in commodity consumption which may be different to the baseline consumption mix furthermore commodity consumption by government is assumed to be non substitutable instead requiring a fixed proportion of each commodity for a given level of utility consumer agents e g households government generate income from returns on the factors of production in the form of wage payments returns to capital and land rent payments this income is used for savings transfer payments taxes and subsidies or consumed directly on commodities savings and transfer payments are assumed to be proportional to disposable income a note on the integration of catchment scale farm systems information into our hydro economic model farm systems and their nutrient budgets and associated financials specific to our study region are incorporated as sub industries with parent industries adjusted accordingly surveyed farms with key climatic geophysical land use and management practice characteristics considered to most greatly impact on nitrate loading e g rainfall soil type slope drainage stocking rates etc provide this information the farm scale overseer nutrient ledgard et al 1999 wheeler et al 2006 and farmax financial management software is applied to create abatement curves describing the relationship between on farm nitrate nutrient reduction and the coupled sub industry revenue expenditure streams 
26041,this paper presents a framework to systematically compare the contributions to uncertainty in hydro economic simulated outputs from the uncertainty surrounding input parameters employed by the hydrologic and economic models independently we consider an illustrative case study example an integrated modeling framework is adopted involving a surface water groundwater nitrate transport model and a multi regional computable general equilibrium model environmental uncertainty contributions are determined by optimizing nitrate loading under ecologically relevant constraint uncertainty at varying risk stances the results of which are mapped to economic outputs economic uncertainty contributions are quantified through monte carlo sampling of variables associated with social accounting matrices and substitution and transformation elasticities results indicate that at the study area scale the environmental contribution to gross regional product uncertainty is generally larger compared to that of economic uncertainty nevertheless the reliability of hydro economic outputs is shown to be highly dependent on environmental and economic sources of uncertainty on the basis of our case study findings we recommend that commensurate effort be focused toward enhanced assimilation of observation data in both types of models to reduce their respective uncertainties graphical abstract image 1 keywords hydro economic model uncertainty quantification decision making surface water groundwater model computable general equilibrium model optimization under uncertainty 1 introduction effective water resource management requires consideration of environmental ecological and economic objectives and constraints as well as a sound understanding of the complex interrelations between these interdisciplinary factors gorelick and zheng 2015 problems of water resource management are increasingly being addressed through application of integrated hydrologic and economic computer models of different types referred to herein as hydro economic models brouwer and hofkes 2008 harou et al 2009 reliable resource management decision making in this context is underpinned by risk based i e probabilistic assessments of the impact of future potential management strategies freeze et al 1990 faucheux and froger 1995 tartakovsky 2013 use of hydro economic models within a risk based decision support context therefore relies on robust quantification of uncertainty surrounding decision relevant simulated outputs referred to herein as outputs of interest or simply outputs e g sigel et al 2010 doherty and simmons 2013 this study explores the uncertainty surrounding hydro economic outputs arising from two distinct sources the uncertain parameters used by the hydrologic model and the uncertain parameters used by the economic model only a handful of previous studies have treated uncertainty in hydro economic modeling e g guillaume et al 2012 d agostino et al 2014 settre et al 2017 previous hydro economic modeling studies have dealt with uncertainties associated with parameters of either the hydrologic model e g peña haro et al 2011 llopis albert et al 2014 or the economic model e g abler et al 1999 belgodere and vellutini 2011 graveline et al 2012 mary et al 2018 however the uncertainties associated with both hydrologic and economic models have not been expressed in concert there are therefore currently no existing estimates of the relative contribution of hydrologic and economic model input uncertainty to hydro economic output uncertainty this paper serves to address the aforementioned knowledge gap by means of numerical experiments aimed at elucidating the relative hydrologic and economic contributions to the uncertainty surrounding hydro economic outputs of interest namely gross regional product grp in other words this study sets out to answer the question is the uncertainty surrounding economic outputs primarily attributable to underlying hydrologic or economic model input parameter uncertainty a hypothetical hydro economic model serves as a case study the case study reflects a new zealand environmental and economic context where a recent increase in the amount of agricultural land used for dairy farming has been linked to environmental impacts e g increased nitrate fluxes entering water ways mfe 2017 to the best of the authors knowledge this is the first study that explicitly compares sources of uncertainty arising from both hydrologic and economic system models it is hoped that this study through identification of these relative contributions and their variability for different outputs of interest will provide a useful platform for prioritizing the efforts of future interdisciplinary modeling endeavours for improved risk based decision support our hydro economic modeling approach involves a physically based and spatially distributed hydrologic and nitrate transport model and a multi regional general equilibrium economic model to explore the relationships between environmental and economic outcomes in response to changes in nitrate loading this approach provides a robust basis for quantifying the uncertainties associated with these relationships it allows for insights to be gained into environmental and economic trade offs across multiple scales for multiple stakeholders including critical enablers inhibiters that play out in the wider economy we consider this approach to be an essential feature in the context of model based land use management decision making support the remainder of this paper is organized as follows first a detailed description is given regarding the hypothetical case study that serves as an illustrative example this description includes an overview of the underlying hydrologic and economic models their integration and the methodologies used to quantify the uncertainty associated with parameters for each of these models in hydro economic model output terms the results of the analysis are then presented followed by a more general discussion of the implications of these results before drawing conclusions and recommendations 2 an illustrative example 2 1 overview of hydro economic modeling approach this study employs a hypothetical case study to investigate the relative hydrologic and economic model contributions to hydro economic output uncertainty our integrated hydro economic model like many other models of this type e g brouwer et al 2008 van heerden et al 2008 strzepek et al 2008 adopts a tight geospatial coupling of climatic analysis surface water groundwater hydrology and land use characteristics integrated with detailed farm system management and supporting financial information while also recognizing wider i e general equilibrium economic system impacts this approach facilitates reporting of the nitrate input concentration scenarios at different geospatial scales i e informing farmers catchment managers and regional national policy makers for decision making the hydrologic model is a physics based groundwater unsaturated surface water flow and nitrate transport simulator while the economic model is a comparative static and multi regional cge model a modular integration approach is adopted e g brouwer and hofkes 2008 i e whereby the system of equations solved by the hydrologic and economic models are independent both models their integration and the approaches used for uncertainty quantification are described below fig 1 provides a schematic representation of the integrated hydro economic modeling approach adopted to disentangle the relative contributions to output uncertainty 2 2 hydro economic outputs of interest the output of interest here is the net change in grp i e δgrp grp is a measure of the total market value of final goods and services produced by a nation region s economy in a given year net changes in value added va i e δva are also reported at an industry level including for dairy cattle farming sheep and beef farming horticulture forestry and so forth change in grp outputs are first considered under a management scenario aimed at decreasing nitrate loading this scenario represents a hypothetical ecological conservation agenda typical of water allocation and nutrient limit setting prerogatives being instigated worldwide oecd 2017 this scenario is referred to herein as the ecological conservation or simply the conservation scenario some of the data on which the economic model is constructed e g cost abatement curves relate to how an economy responds to cut backs in intensive dairy farming given environmental policy targets discussed in detail later the economic model is therefore considered to be well suited to simulating outputs of interest under ecological conservation i e nitrate loading reduction scenarios we also explore the outputs from a different land use management agenda representing a nitrate loading increase scenario a hypothetical dairy farming intensification agenda this scenario is referred to herein as the intensification scenario consideration of both management scenarios allows for insights to be gained surrounding the non linear nature of the resulting economic outputs and their uncertainty the representation of these nitrate loading management scenarios is different between the hydrologic model and economic model as described in the following sections 2 3 the hydrologic model the hydrologic model is used to simulate water quality responses to changes in hydrologic and environmental inputs it is also used to express how the uncertainty surrounding hydrologic and environmental input quantities represented by model input parameters propagates through to environmental outputs of interest namely surface water nitrate concentrations at locations of management interest the uncertainty of environmental outputs is subsequently mapped to the economic outputs of interest in a decision relevant manner i e related to ecological environmental risk aversion through use of a nitrate loading optimization under uncertainty approach the underlying hydrologic model and its use in expressing uncertainty is described in detail below 2 3 1 model description the hydrologic model simulates flow and advective dispersive transport of nitrate within groundwater surface water and the unsaturated zone of a large scale 1476 km2 hypothetical hillslope catchment exhibiting extensive surface water groundwater interaction fig 2 provides a schematic of the simulated hydrologic system modflow nwt niswonger et al 2011 was used to simulate steady state surface water unsaturated zone and groundwater flow conditions mt3d usgs bedekar et al 2016 was subsequently used to simulate transient nitrate transport in the simulated surface water unsaturated zone and groundwater hydrologic systems the hydrologic model is described in knowling et al 2019 and white et al 2020 we therefore provide only a brief summary of features that are relevant to the current study the model comprises a structured finite difference grid with 3 layers 200 rows and 144 columns with a uniform horizontal grid discretization of 250 m spatially distributed nitrate inputs are represented by specifying the nitrate concentration that accompanies groundwater recharge the pre optimized base case nitrate input concentration is given in fig 2 spatially distributed first order reaction i e denitrification rates are specified 2 3 2 quantification of environmental uncertainty contributions optimizing nitrate loading under ecological constraints 2 3 2 1 overview quantification of how the uncertainty associated with environmental outputs from the hydrologic model effects the hydro economic model outputs of interest is achieved by subjecting the hydrologic model to a series of optimization under uncertainty ouu analyses these analyses are necessary given that we need a way to be able to map the environmental output uncertainty to the economic model inputs i e we cannot pass the outputs of the hydrologic model to the economics model directly the ouu analyses involve optimizing the spatial pattern of nitrate input concentration to the hydrologic model while satisfying maximum acceptable surface water nitrate concentration constraints which are important from an ecological perspective for maintaining in stream water quality at varying levels of ecological environmental risk aversion this is achieved by adopting the technique of chance constraints e g wagner and gorelick 1987 white et al 2018 as described in detail below here risk aversion represents the probability that the concentration chance constraints are truly satisfied the true value of these constraints can never be known because it is derived from the hydrologic model and is therefore uncertain risk aversion values vary between 0 0 and 1 0 low values represent a risk tolerant stance whereas high values represent a risk averse stance the series of ouu analyses used to quantify environmental uncertainty is performed by systematically adjusting the level of environmental risk aversion at increments of 0 01 1 between 0 0 and 1 0 or until the ouu problem becomes infeasible with respect to the satisfaction of constraints this approach yields a series of optimal yet risk based solutions of spatial nitrate input concentration patterns each risk optimal nitrate input concentration pattern is subsequently aggregated to reflect changes in industry wide nitrate loading rates with respect to a base case such that it can be used as input to the economics model described in detail below these aggregated solutions collectively express the uncertainty associated with nitrate inputs to the environmental system this uncertainty arises due to the uncertainty in simulated surface water nitrate concentration constraints which reflects our incomplete knowledge of the physical hydrologic system properties and boundary conditions i e hydrologic parameter uncertainty the propagation of each of the aggregated ouu solutions through the economic model yields a collection of economic model outputs of interest the consequence of environmental uncertainty in terms of economic output uncertainty can then be measured by taking the difference between simulated changes in economic outputs at different risk aversion values this decision relevant mapping of environmental uncertainty through risk based optimality to simulated economic indicators allows for quantification of how hydrologic model uncertainty propagates to economic model outputs of interest and as will be demonstrated facilitates a comparison between the environmental and economic contributions to hydro economic output uncertainty in summary the ouu approach provides a basis for mapping the decision relevant uncertainty associated with hydrologic model outputs i e the uncertainty associated with ecological environmental risk aversion to economic model outputs we note that environmental uncertainty is therefore defined specifically here as the uncertainty associated with the satisfaction of ecologically motivated surface water nitrate concentration constraints 2 3 2 2 fosm based quantification of uncertainty in simulated nitrate concentration chance constraints uncertainty is propagated through the hydrologic model i e from uncertain model parameters representing hydrologic system properties such as hydraulic conductivity porosity denitrification rate etc to simulated outputs serving as concentration chance constraints surface water nitrate concentrations using first order second moment fosm techniques e g tarantola 2005 doherty 2015 fosm approaches are commonly adopted in environmental modeling given the large computational burden often associated with forward model evaluations and the high dimensional parameter spaces that are usually required to be represented in decision support hydrologic modeling e g hunt et al 2007 knowling et al 2019 despite the approximate nature of fosm analyses several studies have demonstrated their robustness especially in the context of simulating output changes or differences e g dausman et al 2010 herckenrath et al 2011 using fosm the uncertainty variance for a model simulated output or optimization constraint of interest s σ s 2 is given by 1 σ s 2 y t σ θ y where σ θ is a parameter covariance matrix encapsulating knowledge or lack thereof surrounding parameters y is a vector of partial first derivatives or sensitivities relating changes in a model output or constraint s with respect to changes in a parameter θ i e a row of j in equation 2 herein we adopt a prior in a bayesian sense uncertainty stance that is σ θ represents our expert knowledge of parameters before any parameter conditioning on the basis of state observations via history matching or calibration σ s 2 therefore represents the prior uncertainty variance of s hydrologic model input uncertainty expressed via the σ θ matrix of equation 1 is expressed using a total of 802 uncertain parameters including horizontal and vertical aquifer hydraulic conductivities effective porosities denitrification rates and boundary conductances the diagonal elements of σ θ comprising the squared parameter standard deviations assumed are given in table 1 we employ a highly parameterized approach e g hunt et al 2007 to facilitate a robust expression of model input uncertainty especially when considering a prior uncertainty stance e g knowling et al 2019 pilot points are used to parameterize spatially variable aquifer properties e g doherty 2003 prior parameter distributions were specified as multi variate gaussian i e ɲ μ θ σ θ where are the initial parameter values spatially distributed parameters are assumed to be geostatistically correlated in accordance with an exponential variogram with a range of 2500 m and a sill proportional to the expected prior variance the jacobian matrix j comprising rows pertaining to y vectors is populated via finite difference approximation to partial first derivatives 2 j c o n c e n t r a t i o n i p a r a m e t e r j c o n c e n t r a t i o n i p a r a m e t e r j δ c o n c e n t r a t i o n i δ p a r a m e t e r j where c o n c e n t r a t i o n i is the simulated nitrate concentration at the surface water chance constraint location i and p a r a m e t e r j is an uncertain hydrologic model parameter 2 3 2 3 nitrate loading optimization under uncertainty chance constrained linear programming as summarised above following estimation of the uncertainty associated with simulated surface water nitrate concentrations serving as environmental constraints via equation 1 the ouu approach is employed to yield a series of optimal nitrate input concentration patterns under varying levels of risk aversion i e varying probability that surface water nitrate concentration chance constraints will be truly satisfied this is achieved using the technique of chance constraints e g wagner and gorelick 1987 white et al 2018 which yields a deterministic value for each simulated concentration constraint by moving along the implied gaussian cumulative distribution function implied by the variance in equation 1 in accordance with the risk aversion value it is noted that the ouu approach adopted here is like those adopted by peña haro et al 2011 and alizadeh et al 2018 also in the context of hydro economic modeling the linear programming lp optimization problem is solved as follows e g nocedal and wright 2006 3 maximize c t x subject to a x b x 0 where x is a vector of decision variables herein spatially varying nitrate input concentrations applied to the hydrologic model c is vector of objective function coefficients or weights b is a vector of constraint values herein maximum allowable surface water nitrate concentrations and a is a matrix of constraint coefficients herein representing a response matrix constructed on the basis of hydrologic model evaluations following decision variable perturbations e g ahlfeld and mulligan 2000 see appendix a solution of the lp problem equation 3 using chance constraints i e where vector b comprises shifted constraint values in accordance with a risk aversion value see above constitutes ouu an overview of the ouu formulation considered herein is as follows decision variables the decision variables comprise 14 383 grid cell based groundwater input i e recharge nitrate concentrations one at every uppermost layer model cell within dairy land use areas taken together these 14 383 decision variables form the spatial pattern of nitrate input concentration for the hydrologic model the upper value bounds for these nitrate input concentration decision variables are used as a basis for representing the conservation and intensification nitrate loading management scenarios described in more detail below objective function coefficients nitrate input concentration decision variables kg n m3 recharge are converted to nitrate mass loading rate kg n yr using objective function coefficients comprising annual volumetric ground recharge rates m3 year c vector in equation 4 chance constraints ecologically relevant simulated surface water nitrate concentrations at four locations red triangles fig 2 constitute the chance constraints used in the ouu problem the chance constraint values are based on simulated surface water concentrations from the hydrologic model and are shifted using a specified value of risk aversion we employ pestpp opt white et al 2018 to solve the chance constrained lp ouu problem and to populate the a and j matrices in a parallelized fashion the python scripting packages flopy bakker et al 2016 and pyemu white et al 2016 are used to construct the modflow nwt mt3d usgs numerical models and the pest doherty 2015 interface for these models respectively 2 3 2 4 post processing following the above described process to identify risk optimal spatial patterns of nitrate input concentration for the hydrologic model each of these nitrate input concentration patterns is aggregated so that it can serve as input for the economic model described below this aggregation yields a single value representing the percentage change in total nitrate load across dairy sector areas relative to the pre optimized i e base case solution as given by 4 δ n i 1 m x i o p t w i i 1 m x i b a s e w i 100 where x i o p t is the risk optimized value of decision variable i of which there are 14 383 nitrate input concentration decision variables x i b a s e is the pre optimized value of decision variable i fig 2 and w is the objective function coefficient of decision variable i 2 4 the economic model the economic model simulates both direct on farm and indirect rest of economy economic consequences including value chain and pricing effects associated with changes in nitrate loading it provides a basis for propagating the uncertainty associated with our knowledge of 1 how different industries supply and use different commodities as represented using social accounting matrices sams described below and 2 how production and consumption takes place across different industries and factors represented using constant elasticities of substitution ces and transformation cet described below it also provides a basis for mapping the environmental ecological uncertainty expressed using the hydrologic model within an ouu framework to economic outcome terms 2 4 1 model description we adopt a multi regional computable general equilibrium cge model to assess the economic consequences associated with changes in nitrate loading cge models are commonly applied in assessing whole of economy consequences including in analysis of water related policy options e g berck et al 1991 seung et al 1999 brouwer et al 2008 luckmann et al 2014 banerjee et al 2016 beckchanov et al 2017 and kahsay et al 2019 cge models assume that the economy is as a starting point in equilibrium and converges to a new equilibrium in response to an exogenous shock which in our case is a given change in nitrate loading industries households and government known as agents instantaneously choose their production and consumption behaviours to maximize profit utility equilibrium is reached when it is impossible to make an agent better off without making other agents worse off production and consumption behaviours are dependent on commodity factor prices where for every equilibrium there exist a unique set of prices that satisfy 1 zero profit i e under perfect competition the production sector makes no economic profit 2 market clearing i e commodity factor supply and demand equilibrate and 3 income balance i e each agent s income equals its expenditure these conditions may be modified depending on context our multi regional economic model represents two primary regions the region within which the study area resides and the rest of nation the model is based on the new zealand economy refer to smith et al 2015 moreover it is a comparative static model comparing changes in two equilibrium solutions i e a business as usual baseline against a given nitrate loading agenda the model represents 21 industries each capable of producing up to 16 joint commodities with five agricultural industries that are represented separately at the study area and the region scale that is a total of three spatial scales are considered referred to herein as study area this is the scale at which environmental risk is assessed using the hydrologic model rest of region and rest of nation the separation of agricultural industries between the study area and the rest of region facilitates tight coupling of the hydrologic and economic models at a fine spatial scale i e land use hydrologic and climatic characteristics are linked directly with farm scale management practices and financial analysis the equilibrium solution satisfying these conditions is solved using an optimization formulation based on an arrow debreu general equilibrium framework arrow and debreu 1954 our model is specified as a mixed complementarity program mcp in the mathematical programming systems for general equilibrium mpsge package rutherford 1995 as a general algebraic system gams sub system brooke et al 1988 for an overview of the cge modeling approach adopted the reader is referred to appendix b 2 4 1 1 model closure solving the above system of functions under an mcp approach also requires choosing which variables will be exogenously specified these so called closure conditions are typically based on how agents are assumed to behave in response to a shock event or policy change in this paper we assume the following closure conditions a short term focus i e any economic changes associated with δn occur immediately the level of labour provided by households varies but is correlated at an aggregate level with changes in the consumer price index i e labour growth is relatively slow and total national capital and land use remain fixed i e there is no land use change 2 4 2 quantification of uncertainty in economic outputs of interest the uncertainty associated with input quantities underpinning our multi regional cge model arising from the following primary sources are now summarised table 2 we recognize that other sources of uncertainty exist but these have not been explored in this study see discussion social accounting matrices sams so called supply use tables e g united nations 2018 and institutional accounts are used to derive the sams that underpin our comparative static cge model a supply use table expresses information pertaining to 1 which industries including households supply which commodities within an economy the supply table and 2 which industries use which commodities within an economy the use table these tables are developed through official national accounting procedures and statistical surveys united nations 2018 commodity trade data based on the world customs organization s harmonised system world customs organization 2016 and taxation data a total of 297 sam related cge model input quantities are considered as uncertain using standard errors mapped to sam commodity industries definitions estimates of the statistical accuracy i e representing uncertainty of the above mentioned table values are made see table 2 for standard deviation values specified for the range of sam related parameters this approach follows the work of lenzen et al 2010 but instead of calculating uncertainty for a multi regional input output table a multi regional sam is utilised constant elasticities of substitution and transformation ces and cet these are functions with exogenous parameters typically referred to as scale and share parameters that describe how factors e g labour capital and land commodities and industries and households produce or consume within an economy most of these are derived using econometric analysis the parameters underpinning e g a cobb douglas production function which is a simplified ces function are derived using constrained regression analysis where the elasticities must equal one a total of 66 elasticity related model input quantities are considered as uncertain since the calculation of the ces and cet functions is normally undertaken using regression analysis standard errors are readily available see table 2 for standard deviation values specified for the range of elasticity related parameters a standard monte carlo analysis is used to propagate uncertainty from both the sams and the ces and cet inputs to simulated δgrp uncertain input quantities are stochastically sampled as independent gaussian random variables 10 000 samples are drawn and evaluated this is performed by interfacing the economics model within the non intrusive pest doherty 2015 model interface using pyemu white et al 2016 pyemu is also used to generate the 10 000 realization ensemble the ensemble is then evaluated in a parallel processing fashion using pestpp swp white et al 2017 monte carlo sampling inevitably results in an unbalanced sam rebalancing using a quadratic programming approach refer to geschke et al 2019 for alternative rebalancing methodologies is required to ensure key economic equilibrium identities are met i e corresponding row and column totals of the sam equate we then shock the cge in accordance with δn by farm industry type translated into changes in farm revenue and expenditure using the cost abatement curves the cge model in turn captures the general equilibrium impacts repercussionary effects in other industries price changes factor substitution transformation transfers and so on in the wider synthetic catchment area and rest of new zealand economies impacts are reported in grp terms by industry and in total for the synthetic catchment area and rest of new zealand economies grp is a monetary measure of the market value of goods and services produced with an economy for farming industries grp equates directly with the earnings before income tax less depreciation and rental ebit dr estimates generated through the cost abatement curves for all other industries it is the sum of the compensation of employees operating surplus consumption of fixed capital and other taxes on production variables as generated by the cge model 2 5 comparison between environmental and economic model uncertainty contributions to quantify environmental contributions to hydro economic model output uncertainty i e from the hydro economic output uncertainty associated with environmental ecological risk aversion each risk optimal δn value at risk aversion increments of 0 01 or 1 is used as input to the cge model while holding all uncertain economic input variables fixed running the cge model once for each risk optimal δn value produces δgrp outputs that collectively represent the environmental contribution to hydro economic output uncertainty these environmental contributions to hydro economic model output uncertainty are then compared to those of economic uncertainty sources as quantified by the above described monte carlo sampling approach described above 2 5 1 nitrate loading management scenarios to quantify the environmental contributions to hydro economic model output uncertainty under different nitrate loading management scenarios the hydrologic model is subjected to the above described ouu analysis to obtain risk optimal δn values twice once for each of the conservation and intensification scenarios the two ouu analyses employed different decision variable i e nitrate input concentration upper bounds as a means of representing these different management scenarios for the ecological conservation scenario the nitrate input concentrations are kept below the maximum base case level as calculated across the case study area fig 2 for the intensification scenario the nitrate input concentrations are allowed to increase above current base case levels specifically nitrate input concentration upper bounds for the conservation and intensification scenarios are specified respectively as 0 026 and 0 040 kg n m3 i e 26 and 40 mg n l which correspond to credible nitrate loading rates e g ledgard et al 1997 to quantify the economic contributions to hydro economic model output uncertainty under different nitrate loading management scenarios the above described monte carlo analysis is undertaken twice once for the ecological conservation scenario and once for the dairy farming intensification scenario the analysis for the conservation scenario is undertaken using a constant δn value of 80 whereas for the intensification scenario a constant δn value of 120 is used these δn values are comparable in magnitude to those obtained from the respective nitrate loading ouu analyses 2 5 2 a note on the integration of environmental and economic models the relationship between industry based nitrate loading rate and economic activity which essentially represents the mechanism by which the environmental and economic models are coupled is governed herein by cost abatement curves for each agricultural industry in the cge model i e sheep and beef farming dairy cattle farming and other livestock farming cost abatement curves serve to relate δn to associated changes in revenue and expenditure particular attention is paid to dairy cattle farmer responses to δn representing the dominant farming activity within the synthetic catchment area a sample of responses from representative dairy farms covering the key determinants of leaching e g including geophysical climatic and farm management practice factors was generated from a database of all dairy farms within the synthetic catchment area farmer responses were assessed using the overseer nutrient management tool and in turn translated into changes in revenue as ebit dr and expenditure by item where relevant for use in the cost abatement curves these responses are based on actual farm systems using best practice financial reporting we therefore believe the uncertainty will be of a similar magnitude to that reported for the farming industries within the nz system of national accounts i e as applied to generate the multi regional sam 3 results 3 1 environmental contribution to economic uncertainty fig 3 shows how δgrp varies with environmental risk aversion for the ecological conservation scenario fig 3a a declining δgrp trend is apparent at the study area scale as a more environmental risk averse stance is adopted i e with increasing risk aversion values this is expected given that increasing risk aversion must result in less nitrate being introduced into the hydrologic system less nitrate means that less value added e g operating surplus employee income can be made within the study area when seeking a higher probability or chance that the ecologically motivated nitrate concentration chance constraints are truly satisfied note that δgrp within the study area does not vary at low risk aversion values 0 10 this is because the nitrate loading ouu problem is bound by the specified allowable range of decision variables rather than concentration chance constraints declining δgrp trends exist to a certain point risk aversion 0 50 where the nitrate loading ouu problem becomes infeasible i e there is no region of decision variable space that simultaneously satisfies surface water nitrate concentration chance constraints at risk aversion values exceeding 50 ouu solution infeasibility is attributable to the large degree of environmental uncertainty uncertainty in simulated surface water concentrations arising from uncertainty hydrologic system properties as estimated by fosm analysis the total magnitude of the monotonic decline in study area δgrp with increasing risk aversion for the conservation scenario is approximately nz 2007 18 million us 2018 13 5 million for the study area this represents the economic cost or monetary value of the uncertainty in environmental risk aversion for the study area from a prior bayesian stance i e a prior uncertainty stance is adopted to counter possible variance under estimation it should be noted however that this measure does not account for the full range of surface water nitrate concentration constraint uncertainty as estimated by fosm techniques because of the infeasibility of the ouu problem at high risk aversion values e g 60 the resulting economic cost of uncertainty in environmental risk aversion may therefore be an underestimate of the total cost of environmental uncertainty in economic terms for the rest of nation scale the relationship between δgrp and environmental risk aversion displays a more complicated trend δgrp decreases when considering increasing risk aversion values less than 0 20 i e up to a constraint satisfaction confidence of 20 followed by δgrp stabilization and recovery increase at an increasing rate with further increasing risk aversion in fact the δgrp at a risk aversion value of 0 50 nz 2007 11 7 million or us 2018 8 8 million is marginally greater than that at a risk aversion value of 0 01 nz 2007 10 4 million or us 2018 7 8 million this result indicates the greater flexibility within the wider national economy to adapt due to the mobility of capital and labour as a factor of production in accordance with environmental management initiatives i e as environmental risk aversion increases the rest of nation economic cost of environmental risk aversion taken as largest difference in δgrp values occurring between risk aversion values of 0 22 and 0 50 is approximately nz 2007 12 million us 2018 9 million this is smaller than the economic cost of the uncertainty in environmental risk aversion within the study area which is not unexpected given the flexibility of the greater economy to adapt as described above for the additional intensification scenario fig 3b both the study area δgrp and rest of nation δgrp outputs display a monotonic declining trend as environmental risk aversion increases the relative magnitude of δgrp decline with increasing risk aversion is considerably larger for the rest of nation compared to the study area this is due to the inter dependencies that exist between the study area and rest of the nation particularly with regards to value added in the downstream primary processing plants and to a lesser degree associated service i e there are increasing returns to scale with dairying the overall economic cost of the uncertainty in environmental risk aversion is approximately equivalent to nz 2007 18 million us 2018 13 5 million for the study area and nz 2007 115 million us 2018 86 million for the rest of nation in terms of δgrp terms fig 4 shows the relationship between environmental risk aversion and industry based δva at both study area and rest of region scales for the ecological conservation scenario fig 4a industry δva trends with varying environmental risk aversion show complicated patterns as expected given δgrp trends apparent for this scenario fig 3a as risk aversion values increase the dairy cattle farming industry in the rest of region and the water supply industry in the study area display an overall increase in δva this occurs while δva for dairy cattle farming within the study area and associated industries such as dairy product manufacturing significantly decrease as expected both the construction and services e g business education health services industries show variable δva trends as risk aversion increases note that for some industries small increases in value added occur with increasing environmental risk aversion as a result of capital being freed up for investment however the overall trends show a reduction with increasing environmental risk aversion in contrast the intensification scenario fig 4b displays comparatively simple i e monotonic δva trends with increasing risk aversion among different industries namely significant changes in the dairy farming industry δva at both study area decreasing but positive δva and rest of region increasing but negative δva scales the services industry also shows a large δva decrease with increasing risk aversion due to economic interdependencies that exist between dairy cattle farming and services particularly banking financial and technical scientific services note that with increasing environmental risk aversion within the study area capital investment in dairy farming in the wider region increases 3 2 economic uncertainty contribution and comparison with environmental contribution fig 5 shows probability density functions pdfs of study area and rest of nation δgrp outputs of interest under conservation and intensification management scenarios that are attributable to the uncertainty associated with environmental risk aversion referred to as environmental contribution pdfs herein for simplicity notwithstanding the caveats described above and economic uncertainty economic contribution pdfs independently fig 5 provides a general basis for comparing the relative contributions of environmental and economic sources to δgrp output uncertainty note that the environmental contribution pdfs blue on fig 5 simply represent a different way of expressing the information presented in the δgrp versus risk aversion plots of fig 3 this provides an explanation as to the non gaussian nature of the environmental contribution pdfs particularly those for the conservation scenario fig 5a and c specifically the truncation of the upper portion of the pdf in fig 5a reflects the distinct maximum δgrp value allowed for the conservation scenario i e through the lowered decision variable upper bound fig 3a the approximately bi modal pdf in fig 5c reflects the non monotonic nature of the δgrp versus risk aversion relationship at the national scale under the conservation scenario fig 3b the following observations and interpretations can be made based on fig 5 the second moments i e variance of the environmental contribution pdfs blue are significantly larger than those of the economic contribution pdfs orange for the intensification management scenario at both a regional and national scale the δgrp ranges are approximately three and ten times larger respectively fig 5b d this reflects that the intensification scenario generally represents a situation whereby the environmental uncertainty contribution to hydro economic output uncertainty is not limited by other economic factors that is where the economy is able to re use capital freed up in dairy cattle farming elsewhere within the economy under normal constraints e g labour availability does not constrain investment the second moment of the environmental contribution pdf is also considerably larger than that of the economic contribution pdf for the ecological conservation scenario at a regional scale fig 5a the larger environmental uncertainty contribution for both conservation and intensification management scenarios at a regional scale fig 5a and b is an important finding it suggests that for the synthetic case study considered reflecting hydrologic catchments and economies present in new zealand the environmental uncertainty contributions exceed those of economic uncertainty at a regional scale as mediated by exploration of the full range of risk aversion values regardless of the non linearities surrounding economic uncertainties the second moments of the economic contribution pdfs are considerably larger for the conservation scenario compared to the intensification scenario at both spatial scales the δgrp ranges are approximately two and three times larger for regional and national scales respectively this demonstrates non linearity in the relationship between uncertain economic model outputs with respect to changes in nitrate loading i e δn it is hypothesized that the larger economic output uncertainty associated with the ecological conservation scenario is because of the simulated re distribution of capital within the economy resulting from the environmentally infeasible dairy practice and the associated activation of additional uncertain economic model inputs that are used in simulating the δgrp in contrast the sensitivity of δgrp outputs with respect to these input parameters would be less or zero for the intensification scenario the economic contribution pdfs display an approximately gaussian i e normal nature given that the economic parameter input uncertainty is gaussian this suggests that the cge model is approximately linear in terms of its mapping of input uncertainty to δgrp output uncertainty note that this implies applicability of fosm techniques as per equation 1 an increase in the second moment of both the environmental and economic contribution pdfs from the regional to the national scale is evident as discussed this is explained by the ability of the national economy to re use capital freed up in dairy cattle farming elsewhere within the economy under normal constraints 4 discussion the nitrate loading ouu approach adopted herein provides a basis for quantifying the decision relevant environmental uncertainty i e the uncertainty associated with ecological environmental risk aversion or constraint satisfaction probability this is the only uncertainty that matters in the context of the hypothetical decision making context of this work through decision relevant mapping of this uncertainty to economic model outputs the contribution of environmental uncertainty to hydro economic output uncertainty can be determined as described the environmental uncertainty contributions presented herein do not account for the full range of surface water nitrate concentration constraint uncertainty as estimated by fosm techniques because of the infeasibility of the ouu problem at high risk aversion values e g 60 it follows that the resulting environmental contribution to hydro economic model output uncertainty may therefore be an underestimate of the total environmental uncertainty however our consideration of a prior environmental uncertainty stance serves to counter possible variance under estimation notwithstanding the inevitable subjective definition of priors an important assumption underpinning the ouu approach is that of independence between the decision variable constraint relations and the uncertain parameter constraint relation the assumption of independence is also known as decoupling in the realm of reliability based design optimization e g royset et al 2001 the former of these relations has been shown to be linear e g gorelick and remson 1982 mclay et al 2001 and the latter of these has been shown as an appropriate approximation especially given its ability to reduce computational burden e g dausman et al 2010 herckenrath et al 2011 the computational efficiency and scalability of the nitrate loading ouu approach is the subject of the companion paper white et al 2020 while the extent to which the assumption of independence holds is presently unknown and is the subject of a concurrent study it is expected that this potential source of non linearity would only cause minor changes to the overall outcomes of the present analysis the approach adopted herein for quantifying economic uncertainty contributions was based on methods that capture uncertainty in the baseline sam building particularly on the work of lenzen et al 2010 and in the ces cet elasticities e g abler et al 1999 graveline et al 2012 mary et al 2018 it is important to note that very few applied economic studies have quantified uncertainty in multi regional cge models due to confidentiality constraints the complexity and laborious nature associated with compiling multi regional sams and the lack of statistical error reporting in the underlying economic datasets this study therefore provides an important contribution to advancing the state of uncertainty quantification in economic modeling towards enhancing risk based management decision support it should be noted that economic model outputs associated with the ecological conservation management scenario considered herein are expected to be more robust than those associated with the dairy farming intensification management scenario this is because the cost abatement curves are formulated with respect to nitrate loading reduction impacts on capital and labour whereas the intensification scenario involving nitrate loading increases extrapolates these abatement curves the form and availability of these abatement curves reflects the general environmental and ecological conservation agendas that are increasingly being adopted e g bay of plenty regional council 2017 while it is not known how well the cost abatement curves describe the relationship between capital and labour responses associated with increases in nitrate loading we hypothesize that the relationships will be weaker i e the curve will have a lower slope under an intensification management scenario nevertheless our assessment of a hypothetical dairy farming intensification scenario in addition to an ecological conservation scenario allows for insights into the degree of non linearity in the uncertainty surrounding economic outputs with respect to different land use management scenarios it also provides a basis for testing the robustness of the findings based on a single condition only the modular approach used herein to integrate environmental and economic models involves a one way transfer of information between the respective models only i e there is no dynamic feedback between the equations solved by the respective models brouwer and hofkes 2008 the alternative would be to use a holistic model integration approach involving much more detailed representation of complex model interactions and dynamic feedbacks e g cai et al 2008 the modular approach was deemed necessary in this study because it allows for more comprehensive simulation of each independent model domain given the need to simplify the individual underlying models to make the holistic approach viable from a computational efficiency standpoint e g brouwer and hofkes 2008 more specifically use of a modular approach in this study allows for a spatially explicit and physically motivated hydrologic model to be employed i e without encountering excessive computational times this is important given that environmental management questions invariably concern these discrete spatial distributions while this work focuses on the uncertainty associated with input parameters underpinning our hydro economic model we do not investigate the uncertainty inherent in the modeling process so called model error structural error or unknown unknowns e g doherty and welter 2010 for example our multi regional cge economic model is comparative static ignoring the passage of time and the uncertainty associated with transition to a new equilibrium while dynamic cge dcge models are increasingly being used in policy analysis particularly so called recursive dynamic institutional and or other fully dynamic implementations they are yet to be widely utilised in hydro economic modeling in the case of the nitrate reduction agenda it is for example likely that reduction technologies might be phased in over time or alternatively at the right price tipping point a dairy cattle farmer might simply cease operation and use their land for another economic activity to meet reduction targets additionally while labour and capital are relatively mobile in an economy this is less so when tied heavily to a particular land use plant machinery and equipment is not always easily re deployed to another economic activity our hydro economic activity does not account for this complex behaviour or for its inherent uncertainty this is an obvious next step in the research agenda for accounting for uncertainty in hydro economic modeling the dependence of the magnitude of both environmental and economic uncertainty contributions on the specific hydro economic model output of management interest e g study area versus national scale conservation versus intensification scenario is not a surprising outcome this finding has been documented extensively in the environmental modeling literature e g doherty and christensen 2011 white et al 2014 we acknowledge the unavoidable subjectivity accompanying the many decisions that underpin modeling endeavours especially those that adopt coupled or integrated models from distinct and separate disciplines and those that are framed within the decision support context both of which are the case here for example the findings presented herein are dependent on e g hydrologic model parameterization details such as the problem dimensionality i e number of uncertain parameters considered the geostatistical relationships assumed that govern correlation between parameters the definition of appropriate prior expected parameter variances among others a specific example includes our use of prior parameter uncertainty distributions for setting fosm derived chance constraints which would ultimately result in larger environmental uncertainty contributions providing that hydrologic model parameters are sensitive to observations for parameter conditioning despite the challenges associated with the transferability of findings between modeling investigations as a result of these subjective factors the hypothetical case study findings presented herein provide a useful benchmark for understanding the relative environmental and economic contributions to hydro economic output uncertainty 5 conclusions this paper presents a methodological framework for the systematic comparison of uncertainty contributions in hydro economic simulated outputs from hydrologic and economic models the framework involves mapping decision relevant environmental uncertainty arising from hydrologic model parameters to hydro economic simulated output space this is achieved by solving a series of management optimization under uncertainty problems economic uncertainty quantification is achieved through monte carlo sampling of parameters underpinning social accounting matrices and substitution and transformation elasticities it is hoped that this framework is adopted elsewhere as a basis for prioritizing the efforts of modeling practitioners across disciplines this paper also provides an important benchmark for understanding the relative environmental and economic contributions to hydro economic output uncertainty using a synthetic model case study example to the best of the authors knowledge the current study is the first to explicitly and comprehensively compare both environmental and economic sources of uncertainty in a multi scale hydro economic management scenario context it is shown that for our case study example the environmental contribution to the uncertainty in hydro economic model outputs i e change in grp at the regional scale is generally larger compared to that of economic uncertainty under both ecological conservation and dairy farming intensification management scenarios the relative economic uncertainty contributions are shown to be larger than those of environmental uncertainty only for change in grp outputs made at the national scale under a conservation management scenario in more general terms the results presented demonstrate that while the reliability of hydro economic outputs of interest is dependent on both environmental and economic sources of uncertainty the relative environmental versus economic uncertainty contributions are highly model output specific we therefore recommend that commensurate effort be focused toward enhanced uncertainty quantification and assimilation of observation data in both environmental and economic models to increase the reliability of coupled environmental economic e g hydro economic model outputs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors wish to acknowledge matthew newman dairynz for providing farmax data and katy kelly gns science for assistance in developing the graphical abstract the authors wish to thank the reviewers and associate editor joseph guillaume for their constructive comments this research was performed as part of the smart models for aquifer management programme funded by the ministry of business innovation and employment new zealand appendix a use of the stochastic impulse response emulator sire for nitrate input concentration optimization under uncertainty ouu a highly efficient nitrate input concentration ouu approach is adopted we term this approach stochastic impulse response emulator or sire the approach affords its computational efficiency through employing model emulation e g asher et al 2015 and fosm uncertainty estimation techniques the reader is referred to the companion paper white et al 2020 for a full description and demonstration of sire and its use in the present ouu context the emulation strategy relies on the concept of linearity between nitrate loading or nitrate input concentration as in the current study changes and surface water or groundwater nitrate concentration changes sire adopts a response matrix based emulation strategy e g ahlfeld and mulligan 2000 the response matrix a maps changes in decision variables i e nitrate loading rates to changes in model outputs constraints of interest i e surface water nitrate concentrations a is given by a 1 a c o n c e n t r a t i o n i l o a d i n g j c o n c e n t r a t i o n i l o a d i n g j δ c o n c e n t r a t i o n i δ l o a d i n g j where l o a d i n g j is the nitrate loading rate at model node j and c o n c e n t r a t i o n i is the nitrate concentration at a surface water reach of interest in this work a is independent of the decision variable values given the linear loading concentration relation see below the a matrix equation 3 is used as a basis for solving the linear programming lp problem e g nocedal and wright 2006 eq 3 the relationship between nitrate loading changes decision variables and resulting surface water concentration changes hydrologic model outputs has been discussed by many studies to take a linear form e g gorelick and remson 1982 spalding and exner 1993 mclay et al 2001 that is the concentration evaluated at any point in space or time is a linear function of the initial concentration herein the nitrate loading or nitrate input concentration this means that down gradient concentrations of interest can be calculated simply by linearly scaling the nitrate input concentration or the concentration resulting from loading this linear relation is also not affected by simulation of a first order reaction rate to represent denitrification the reader is referred to white et al 2020 for more details appendix b multi regional comparative static cge model brief mathematical overview commodity production is represented by hierarchically nested constant elasticity of substitution ces production functions where inputs are intermediate commodity consumption and labour capital and land factors of production inputs are grouped and nested depending on their degree of substitutability e g no substitution is assumed to exist within the intermediate consumption nest i e the proportion of commodities required to produce a unit of output remains constant between intermediate consumption and factors of production nests and between the factors of production nests for labour capital and land finally labour and capital are assumed to be fully substitutable mathematically the profit maximization production function takes the form max x i j r p x i j r u i 1 i p i r p x i j r p i 1 i p i r d x i j r u k 1 k p k r f j k r b 1 s t x i j r p min 1 a j r f r j r r j r ϕ j r k j r k j r δ j r 1 δ j r 1 ϕ j r l j r l j r δ j r 1 δ j r δ j r δ j r 1 x 1 j r u a 1 j r u x i j r u a i j r u where the revenue from sector j in region r selling commodity i is generated by x i j r p quantities of commodities at the producer s price i e less indirect taxes and subsidies p i r p while the cost to sector j in region r of selling commodity i uses x i j r u quantities of intermediate commodities at a composite i e as domestically produced and imported supply price p i r d and f j k r quantities of factor of production k at price p k r profit maximization is subject to a cost minimizing production function where the x i j r p quantities of commodities i sold and produced by sector j in region r is a nested ces function of intermediate consumption and factors of production where intermediate consumption is determined by technological coefficients for intermediate inputs a 1 j r u a i j r u and x i j r u quantities of intermediate commodities used and the factors of production by 1 technological coefficients for all factors a j r f 2 the relative factor shares between capital and labour ϕ j r 3 land capital and labour quantities used by sector j in region r respectively r j r k j r and l j r 4 the baseline land capital and labour quantities used respectively r j r k j r and l j r and 5 δ j r is the ces elasticities of substitution commodities are sold either domestically or exported regional or overseas we portray this using a nested constant elasticity of transformation cet function where 1 for each percentage change in economic output the proportion of commodities consumed domestically and exported remains the same 2 produced commodities are non homogenous and 3 market demand is not fully substitutable together these conditions ensure that no individual market demands all quantities produced of each commodity although world commodity prices are fixed i e our economy is a price taker they are affected by changes in exchange rate commodity consumption is subject to a ces utility maximization function where agents choose a combination of commodities to consume that is less than or equal to their total income available less of course any savings mathematically this takes the form b 2 max x i a r c u a r x i a r c w h e r e u a r x i a r c i 1 i a i a r 1 σ a r x i a r c σ a r 1 σ a r σ a r σ a r 1 s t i 1 i p i r d x i a r c y a r where u a r is a utility maximization function for an agent a in region r where x i a r c is the quantity of commodity i consumed by agent a in region r a i a r is a share of commodity i for an agent a in region r and σ a r is an elasticity of substitution between commodities for an agent a in region r this function is subject to a budget constraint where y a r is the total income of an agent a in region r and p i r d is price of each commodity i in region r each agent may have a different utility maximizing commodity substitutability households for example are assumed to have a ces elasticity of substitution greater than zero thus diminishing increasing utility returns to an increase decrease in commodity consumption which may be different to the baseline consumption mix furthermore commodity consumption by government is assumed to be non substitutable instead requiring a fixed proportion of each commodity for a given level of utility consumer agents e g households government generate income from returns on the factors of production in the form of wage payments returns to capital and land rent payments this income is used for savings transfer payments taxes and subsidies or consumed directly on commodities savings and transfer payments are assumed to be proportional to disposable income a note on the integration of catchment scale farm systems information into our hydro economic model farm systems and their nutrient budgets and associated financials specific to our study region are incorporated as sub industries with parent industries adjusted accordingly surveyed farms with key climatic geophysical land use and management practice characteristics considered to most greatly impact on nitrate loading e g rainfall soil type slope drainage stocking rates etc provide this information the farm scale overseer nutrient ledgard et al 1999 wheeler et al 2006 and farmax financial management software is applied to create abatement curves describing the relationship between on farm nitrate nutrient reduction and the coupled sub industry revenue expenditure streams 
26042,recent advances in cloud computing and social networking are influencing how we communicate professionally work collaboratively and approach data science tasks here we show how the groundwater modeling field is well positioned to benefit from these advances we present a case study detailing a vertically integrated collaborative modeling framework jointly developed by participants at the american samoa power authority and at the university of hawaii water resources research center the framework components include direct collection and analysis of climate and streamflow data development of a water budget model and initiation of a dynamic groundwater modeling process the framework is entirely open source and applies newly available data science infrastructure using python based tools compiled with jupyter notebooks and cloud computing services such as github these resources allow for seamless integration of multiple computational components into a dynamic cloud based workflow that is immediately accessible to stakeholders resource managers or anyone with an internet connection keywords groundwater modeling hydrologic monitoring network american samoa jupyter notebooks github python 1 introduction for the last half century computational modeling has become a principal tool in the water resource manager s toolbox groundwater models have become indispensable industry standard methods for estimating the availability and sustainability of groundwater resources e g young and bredehoeft 1972 cummings and mcfarland 1974 willis and yeh 1987 however because of the inherent complexity of numerical models and the significant time effort and expertise needed for their development it is often challenging for stakeholders and water resources managers to access models that are appropriate for their needs essawy et al 2018 within the traditional model development paradigm water management agencies usually take one of two approaches for obtaining hydrologic models to suit their needs 1 dedicate significant resources to building internal modeling capacity or 2 contract with outside experts to deliver models that typically cannot be interacted with once completed drawbacks to the former approach include the high cost of training software and salary required for agencies to retain personnel with sufficient skills to assess the validity conceptualization calibration and usefulness of existing models or to create and maintain effective modeling programs this level of resource dedication is often only possible for larger utility companies or management agencies leaving small remotely located agencies with few to no options for maintaining quality modeling expertise on the other hand the latter approach of hiring contractors generally results in production of static models that may lose relevance quickly and are often delivered in a format that do not allow end users to modify parameters or address new questions this approach also suffers from the inherent temporariness of typical funding mechanisms whereas the calibration and validation process lasts only as long as the project account is solvent after which a final report is delivered and the latest iteration of model files are archived for long term storage on a server in the back of someone s office compounding this issue is the fact that many groundwater models are developed with proprietary software or within specialized computational environments making it prohibitively challenging for end users to open and interact with the finished product to circumvent these problems yet retain the benefits from each of the aforementioned approaches we here propose a new approach to the hydrologic modeling process where model developers and end users enter into a long term collaborative working relationship facilitated by advances in open source cloud computing capabilities to demonstrate this approach we present as a case study the ongoing development of a collaborative modeling framework conceived as a joint effort between the university of hawaii water resources research center uhwrrc and the american samoa power authority aspa the intended outcomes for this modeling framework are commensurate with the motivations behind the participatory and collaborative modeling movement that has in recent decades become a highly utilized approach in environmental management e g argent and grayson 2003 liu et al 2008 these outcomes are centered around addressing the need for enhanced researcher stakeholder engagement and producing practical defendable models that sufficiently address stakeholder needs and promote model use in guiding important water management decisions this paradigm allows for incorporation of the views needs and knowledge of many stakeholders including scientists policy makers and resource managers in the modeling process moran 2016 describes the collaborative process as one where model developers decision makers stakeholders and others work together to develop a shared understanding of the region s management objectives and the model s role in supporting those objectives langsdale et al 2013 further refines collaborative modeling as a process where both the model and the process remain accessible and transparent to all participants collaborative modeling builds trust and respect among parties participatory and collaborative modeling methods are well tested and have been applied across many disciplines ranging from computer science e g bidarra et al 2001 to economics e g mendoza and prabhu 2006 and social sciences e g flint et al 2017 the approach is especially pertinent in water resource management as water s indispensable and ubiquitous nature inherently makes any issue a multi stakeholder concern in the water resources field collaborative or participatory approaches have been applied in numerous case studies across a range of technical foci including watershed modeling e g liu et al 2008 groundwater modeling e g barfield 2009 beall et al 2011 and water policy and planning e g tidwell et al 2004 however the technological boundaries for the implementation of this collaborative paradigm within the high level programming revolution of the present day have not yet been fully explored here we contend that recent developments in cloud computing technologies are now providing new opportunities for collaboration and communication between remotely located institutions and agencies application of these new technological tools within a collaborative paradigm allows participants to more efficiently share resources and facilitates direct application of models by the managers who are tasked with solving their region s water resource challenges the primary objective of this manuscript is to present an example of a collaborative hydrologic modeling framework that takes advantage of recent advances in cloud computing and open source modeling tools the framework is vertically integrated as it is intended to handle all components in the process that ultimately leads to the development of groundwater models used for drinking water management these components include 1 the direct collection and processing of basic hydrologic parameters through an island wide hydrologic monitoring network 2 development of automated data processing applications to integrate updated data into subsequent model components 3 creation of a dynamic water budget model to predict island wide groundwater recharge and 4 development and application of a set of open source groundwater modeling tools that can be directly modified by stakeholders to address local water resources management questions the framework is intended to be entirely open source and all raw data model code and processed outputs are made publicly available online so anyone with skills and interest can modify inputs test scenarios and continue model development this philosophy promotes transparency reproducibility and accessibility through both the development and implementation process thereby facilitating interaction with interested stakeholders or other modelers the framework is designed to adhere to the best practices of reproducibility for digital research objects fehr et al 2016 which include 1 being physically accessible by using open source codes 2 being conceptually accessible by facilitating sharing of required core skills for data management workflow efficiency and visualization and 3 being reusable by applying modularity and by providing opportunities to dynamically change inputs as needed the framework is also intended to be portable flexible use small file sizes and only include models with short run times which are attributes that have been shown to enhance model adoption rates amongst managers argent and grayson 2003 by presenting this framework we hope to demonstrate the ease of use and the applicability of modern code sharing and cloud computing tools in a scientific modeling setting involving participants at remotely located institutions these tools have allowed us to connect researchers and stakeholders through ready built data science infrastructure and to share advanced modeling capacity across our network of participants while the case study in its current form demonstrates these ideas we also view model development as a process not necessarily an end goal therefore the framework continues to evolve and change as we and our stakeholders continue to participate in discussion raise concerns and contribute new ideas 2 case study setting the island of tutuila is the main population center of the u s territory of american samoa it is located near 14 s and 170 w and at 142 km2 is the third largest island in the samoan hot spot chain geologically tutuila contains two distinct provinces the bulk of the island is composed of an older highly eroded basaltic shield edifice 1 5 1 0 ma and recent holocene age rejuvenation stage volcanism on the southwestern flank of the older shields has created the younger tafuna leone plain stearns 1944 mcdougall 1985 the young pahoehoe flows of the tafuna leone plain give it a higher hydraulic conductivity k than the older volcanic unit which is composed of a heterogeneous mixture of a a lava flows pyroclastic materials and trachyte domes stearns 1944 eyre and walker 1991 geological subdivisions within each of these units exist and may be used as the basis for further refinement into zones with different hydrogeologic properties izuka et al 2007 tutuila s climate is warm and humid with abundant year round rainfall due to its position within the south pacific convergence zone the island experiences a wetter season with increased precipitation amounts from october to may and a drier season with less though still significant precipitation from june to september rainfall varies considerably with location and elevation and ranges between 1800 mm yr near the tafuna airport up to more than 5000 mm yr along the crest of the highest mountains daly et al 2006 the region is also influenced by tropical storms and hurricanes and an average of 25 30 significant thunderstorms affect the island annually kennedy and chilton consulting engineers 1987 in american samoa groundwater resources supply over 90 of domestic and nearly 100 of industrial water use however these resources are afflicted by multiple threats to their long term sustainability since 2009 portions of the public water supply system have been unsafe to drink necessitating one of the longest standing boil water advisories in u s history this is partly caused by the vulnerability of tutuila s young and highly permeable aquifers to anthropogenic and surface water contamination shuler et al 2017 2018 other aquifers on tutuila produce high salinity water presumably caused by salt water intrusion izuka 1999 in some cases the island s wells produce water with cl concentrations exceeding the u s environmental protection agency drinking water standards by four to five times multiple local stakeholders see groundwater models as a tool that will greatly facilitate management of these issues aspa 2013 as of this writing there have been four known groundwater models developed for portions of tutuila izuka et al 2007 aspa 2013 shuler et al 2014 shuler et al 2017 while each of these models addressed a specific question ranging from defining well capture zones to modeling nutrient transport none have satisfied the requirements to fully address aspa s water management needs the static nature of these models also restricts their ability to be modified and aspa like most small scale water utilities does not have time or resources to support building and maintaining an active hydrologic modeling program on their own 2 1 collaborative groundwork and stakeholder needs in american samoa aspa is the only water utility and the agency is also responsible for all municipal power wastewater and solid waste services american samoa is a unique environment as it is small population of approximately 60 000 geographically isolated 4000 km to the nearest continent and a sovereign society still retaining much of its indigenous culture and tradition therefore aspa is particularly invested in not only meeting customer needs but also in conservation and responsible stewardship of the island s limited natural resources the water resources research center is a technical research unit at the university of hawaii and its stated mission is to promote understanding of critical state and regional including the u s affiliated pacific islands water resource management and policy issues through research community outreach and public education to fulfil this mission in american samoa uhwrrc has been working with aspa and other agencies since 2013 to develop an integrated water resources research program in the territory that strives to incorporate on island stakeholder concerns into research priorities in 2015 we a group of researchers and staff at aspa and uhwrrc formally initiated the collaborative modeling effort through a memorandum of understanding originally intended to 1 develop infrastructure for collection of hydrologic and climatic data and 2 apply this data in support of aspa s water resources management priorities at the time we also recruited a diverse group of representatives from local management agencies to form the american samoa water resources stakeholders committee the committee was tasked with documenting and communicating american samoa s water resource needs and since its formation hydrologic data collection and groundwater model development have been consistently identified as top priorities throughout the next four years our collaborative efforts have been directed towards hydrologic data collection development of water budget estimates development and use of groundwater and hydraulic system models and capacity building within both institutions during a training workshop conducted in american samoa for aspa and uhwrrc staff the following modeling focused management priorities were identified assessing resource sustainability through water budgets or sustainable yield estimates identifying new well drilling locations based on freshwater lens thickness simulating contaminant plumes from sources including piggeries and industry identifying low pressure zones and examining hypothetical stresses in the water distribution system these stakeholder driven objectives currently guide the focus of our conceptual and numerical groundwater modeling activities as well as the continued development of hydrological monitoring operations 3 framework development methods 3 1 cyber infrastructure framework to make hydrologic monitoring data publicly accessible and also to store projects and code in a way that allowed results to be automatically updated each time new data became available a set of open source cloud based applications were used as the cyberinfrastructure for our collaborative modeling framework these applications have been imperative for facilitating communication providing the ability to collaboratively code and for taking care of the basic data science needs that would be overwhelmingly resource intensive for either agency to develop independently we selected jupyter notebooks https jupyter org for python based coding and project development github https github com for project storage and version control skype and google hangouts http www skype com and https hangouts google com for communication and as of this writing we are currently exploring different applications for live cloud based code execution e g binder and google colab https mybinder org and https colab research google com a common thread between these services is that they are all are intuitive simple open source and integrable with each other and other widely used cloud computing services the diverse and rapidly developing array of existing python packages allows the language to be used reliably for every task across our collaborative modeling framework maintaining this methodological consistency streamlines execution of the modeling process by routing computational outputs from one module as inputs to others while computing languages such as python r and matlab are commonly used for scientific model development e g borah and bhattacharjya 2013 bakker et al 2016 yin et al 2017 code based tools have nonetheless been historically difficult for end users to access due to steep learning curves and sometimes costly licenses jupyter notebooks help to solve this issue by bridging the gap between coders and the uninitiated by integrating live code equations visualizations web links and explanatory documentation into notebooks to make them easier to understand and interact with perez and granger 2015 kluyver et al 2016 because of this accessibility jupyter notebooks are becoming increasingly popular amongst modelers and across many scientific disciplines e g subramanian et al 2015 white et al 2016 somers 2018 though these advances may seem unimportant to those more familiar with coding in a collaborative framework where team members with variable degrees of expertise wish to be involved in the modeling process simplicity and ease of access is paramount for everyone s engagement additionally inclusion of numerous participants and integration of multiple components into a single workflow necessitates a significant amount of data organization and project management work while this would be time consuming to do manually the open source project management tool github provides free cloud based server hosting version control and workflow organization to facilitate collaborative contributions from multiple participants github maintains organization in the modeling framework by storing all data and code within individual repositories that preserve the file folder structures that allow for consistent relative connectivity between model inputs and outputs open access repositories can be directly downloaded from the web by anyone and authorized team members can make changes and upload them back to github automated version control features track all changes and allow users to review and accept or reject them github is becoming increasingly popular as a collaborative coding and data driven project management tool dabbish et al 2012 and at present it is the computer science industry standard application for storing managing and tracking changes to code stack overflow 2018 a key feature for facilitating input from stakeholders is github s browser friendly graphical user interface gui which allows anyone to view and explore files datasets and results without needing any specialized software or computing resources while github provides online file storage and organization it does not provide computational resources for running models to avoid issues with local dependencies software and computational resource limitations on individual user s computers we are currently exploring the utility of a number of open source cloud computing resources dedicated to addressing this concern such services operate by opening a cloud based python environment on a remote server and installing all needed software at the time of use there are numerous existing resources including binder and google colab amongst others that provide this service through seamless integration with jupiter notebooks and github at present we have found these services to be most useful for conducting demonstrations of framework components during workshops or teleconferences finally although a seemingly simple task the importance of teleconferencing and specifically screen sharing services cannot be overlooked for projects of this nature for this project skype and google hangouts has been a significant boon for facilitating communication to and from american samoa which is still serviced by international telephone calling rates these internet based services allow participants to share screens and see visual output directly and this is especially helpful when working within a fairly complicated modeling framework 3 2 modeling framework the tutuila collaborative modeling framework includes tools that address the island s most pressing water management questions through three distinct yet integrated components these include 1 collection and automated processing of weather station stream gauge and monitoring well data from a hydrologic monitoring network 2 development and application of a dynamic water budget model that produces and automatically updates an island wide groundwater recharge coverage based on monitoring network data and 3 ongoing collaborative development of dynamic regional and local scale numerical groundwater models that automatically intake the most recent recharge coverage and monitoring well data tasks performed in the first framework component include collecting raw hydrologic data uploading data to the github repository shuler and mariner 2019 checking quality and processing data into the necessary format to be used as input to the subsequent modeling steps we developed python based data processing scrips as jupyter notebooks which are archived along with raw and processed hydrologic data on github processed hydrologic data from the monitoring component is output to the input data folder accessed by the water budget model script we developed the tutuila water budget model with the soil water balance 2 swb2 code developed by the usgs westenbroek et al 2018 the swb2 model calculates spatially distributed groundwater recharge rates at a monthly resolution and all inputs and outputs are processed in the same python development environment as the monitoring network data while linking these steps creates a complex network of interdependencies consistency and organization are easily maintained through github the final component in the collaborative modeling process is a modflow based groundwater model this component like those previously described is developed within the same python based environment thereby allowing for a cohesive workflow and seamless integration from raw data to model results for groundwater model development we used flopy a python based site package designed to simplify pre processing run time and post processing tasks for development of modflow based models as new data is collected and uploaded dynamic updates to the swb2 generated groundwater recharge coverage are translated through to the flopy models which then ideally become more accurate every time new monitoring data is processed fig 1 shows a schematic of the data processing and modeling workflow for the aspa uhwrrc cooperative modeling framework 3 3 hydrologic monitoring network beginning in the 1950 s the u s geological survey usgs monitored rainfall and streamflow at multiple sites throughout american samoa however in 2008 all usgs monitoring operations in the territory were halted leaving a 7 year long data gap until 2015 when we began installing weather stations since 2015 we at aspa and uhwrrc have worked to develop a monitoring network consisting of eight stream gauging stations six weather monitoring stations and three preliminary water level monitoring sites fig 2 hydrologic data from these instruments is imperative for estimating groundwater recharge which is an important spatially distributed input variable in groundwater models especially in island settings with very steep rainfall gradients both aspa and uhwrrc contributed to instrument installation and we continue to work together to maintain the network to ensure continuity with data downloads and maintenance of physical infrastructure aspa created a full time position for a hydrologic technician and uhwrrc continues to develop and maintain systems for data processing quality assurance quality control qa qc procedures and archiving and distribution of data all weather stations have the capability to record precipitation temperature relative humidity rh wind speed and direction and solar radiation sr the network was initially developed using low cost spectrum technologies inc watchdog 2900 et weather stations spectrum item number 3350wd2 but as funding allows these stations are incrementally being replaced with solar powered campbell scientific stations fig 3 consisting of an rm young wind sentry set 03002 l12 pt a csl temperature rh probe cs215 l7 pt an apogee sp 110 pyranometer cs300 l12 pt and a texas electronics rain gauge te525 l10 pt part numbers refer to campbell scientific catalog numbers all stations are mounted on 2 3 m poles and placed at sites with the best balance of station siting characteristics considering the available terrain wmo 1983 u s epa 1987 weather stations log at 15 min intervals and data is downloaded quarterly by the aspa technician once downloaded the technician simply uploads raw data files to the project repository on github for processing and for long term storage additional metadata and information about the aspa uhwrrc network can be found in shuler and el kadi 2018a stream gauge installation began in 2016 and at present our streamflow monitoring network consists of eight separate continuous record gauges located on different streams throughout tutuila barometers and in stream pressure transducers record data at 15 min intervals the stream gauges physically consist of stainless steel hobo water level loggers hobo model u20 001 01 i e pressure transducers pt installed in durable steel housings which are permanently mounted to immobile structures such as bridges or bedrock outcroppings housings are constructed of perforated square galvanized steel pipe with a locking mechanism at the top fig 3 site selection involved field scoping and soliciting input from multiple departments at aspa other on island stakeholders such as the american samoa epa and also with hydrologists at other universities to ensure maximization of data utility site selection criteria included considering site access proximity to historical gauges bank and channel control stability and representativeness of the variability in tutuila s different climatic and geological regions additional metadata and information about the stream gauge network is available in shuler and el kadi 2018a data is downloaded from loggers and uploaded to github by aspa on a quarterly basis in 2017 we initiated a pilot program to repurpose abandoned aspa production wells as monitoring wells in order to continuously observe water levels and aquifer electrical conductivity ec since this time only three open boreholes have been available for this purpose but as new wells are drilled and older wells are abandoned we anticipate the scope will expand at each monitoring well an instrument package consisting of a hobo water level logger and a hobo ec logger is contained within a perforated 1 25 inch pvc casing and suspended by a non elastic tape these loggers are retrieved downloaded and maintained on a quarterly basis by aspa and data is uploaded to github for processing 3 4 tutuila swb2 model development the usgs developed the swb2 water budget modeling code westenbroek et al 2018 to allow users to easily calculate water budget components and specifically groundwater recharge some functionality based on the hawaii water balance code engott et al 2017 was incorporated into swb2 making it one of the better suited options for modeling tropical basaltic islands in the hawaiian or samoan chains westenbroek et al 2018 for this study the swb2 code was applied to develop a tutuila island groundwater recharge coverage that then served as an input to the flopy groundwater model the swb2 code is based on a modified thornthwaite mather 1955 soil water balance approach which in a simplified form is represented by the following recharge rainfall runoff actual evapotranspiration for this study runoff to rainfall ratios and temporal rainfall distributions derived from our monitoring network data were used as key input variables to the tutuila swb2 water budget model all other input datasets used for the swb2 model were obtained from existing publications or databases with each being described in the respective documentation as cited below all swb2 inputs are either in the form of tabular lookup data or spatially distributed datasets in the esri ascii grid format input files for the tutuila swb2 model included gridded monthly precipitation data daly et al 2006 precipitation gauge data used to represent temporal rainfall distributions this study land use data meyer et al 2016 impervious surface ratios meyer et al 2016 canopy coverage ratios meyer et al 2016 soil type data consistent with the nrcs ssurgo database nakamura 1984 direct infiltration data from municipal water line leaks aspa personal communication direct infiltration data from osds effluent discharge as doc 2009 runoff to rainfall ratios this study perreault 2010 wong 1996 potential evapotranspiration data in monthly gridded format izuka et al 2005 canopy evaporation data engott et al 2015 aws truepower 2014 gridded monthly maximum and minimum temperature data daly et al 2006 mountain front recharge information izuka et al 2007 the swb2 code calculates all water balance components at a daily resolution and output files are produced in netcdf format the tutuila water budget model just like the other routines and models used in the framework was designed to be dynamic whereas once newly collected runoff and rainfall data are uploaded to github the seamlessly integrated workflow automatically incorporates it into all subsequent calculations although a dynamic version of the tutuila water budget model is integrated as a module of the integrated modeling framework a static version of the water budget model was published to stand alone for documentation in shuler and el kadi 2018b this report along with all of the input data code and output data for the static version of the tutuila water budget model is publicly available at https github com uh wrrc swb model swb2 tutuila 3 5 flopy groundwater model development in 1984 the usgs released the first version of modflow mcdonald and harbaugh 2003 over three decades later modflow remains one of the most widely used groundwater modeling applications the model s large user base results from its simplicity and continuing evolution and presently the python based module flopy lies at one of the forefronts of usgs model development efforts bakker et al 2016 flopy is an open source python package that provides functionality to simplify pre and post processing tasks for the modflow family of models such as modflow harbaugh et al 2000 mt3dms zheng and wang 1999 and seawat guo and langevin 2002 following the development philosophy of most python packages flopy is open source and constantly in development therefore new functionality continues to be added by the software s developers and users presently the flopy package is relatively new but it is rapidly gaining in popularity due to its modularity open source availability and support by usgs modelers e g rotzoll et al 2016 feo et al 2018 foglia et al 2018 benefits of using flopy for developing groundwater models include 1 model building and pre processing steps are quick to execute 2 specific inputs are easy to modify for example changing cell size and 3 the modeling process is transparent and simple to share with team members as well as with end users other researchers or reviewers providing the ability to modify model inputs quickly and easily makes flopy work with our process based paradigm quite well simplifying the model evolution process as new stakeholder needs development of new procedures and updated data become available at present we have initiated flopy groundwater model development for regional scale models covering the whole island and because this component of the framework continues to be driven by direct stakeholder needs sustained development is intended to continue into the foreseeable future pending continued support from both uhwrrc and aspa presently the scope of the groundwater modeling component of the framework is focused on 1 presenting examples of flopy python modeling functionality using data from tutuila and 2 providing opportunities for staff at aspa to work with a ready built model and to experiment with applying results for management needs while the model we have developed currently provides the foundation for models that will be applied by aspa in the future at present the model presented in this manuscript is not calibrated or validated to the point where it is intended to be used as a management tool at the time of writing we are collaboratively refining our existing modeling tools in order to lower uncertainties to the point where we can inform management questions with a higher degree of certainty while development of the groundwater modeling component remains ongoing throughout the process we have employed a common set of guiding principles to ensure that groundwater models integrate seamlessly into the greater collaborative framework these include 1 the groundwater models only depend on tools that operate within the python environment this ensures seamless integration of this component with the others 2 model steps are broken into manageable units in order to make the process easy to understand each step is annotated with text based explanations in markdown cells separating code blocks and input data and important parameters are clearly defined typically in a dedicated cell 3 whenever possible output from each step is automatically visualized using in line plots plots are also saved as images and as geographic data files using kml format which open directly in end user mapping platforms 4 all input datasets are simple cleanly organized and well annotated participants can directly modify inputs if needed or when other updated datasets become available 5 calibration routines automatically incorporate updated observation and input data e g updated water levels and revised recharge coverages from the swb2 model following collection from the hydrologic monitoring network 6 cell size resolution is simple to modify so experimentation can be performed at low resolution with short morel run times resolution can then be increased for sensitivity testing or creating finalized results 7 all model files are kept small enough to be hosted on github under 100 mb each 4 process implementation and results 4 1 monitoring network implementation weather stations and stream gauges are downloaded on a quarterly basis and the raw data require qa qc processing and integration with previous data to create long term station records we accomplish these tasks with python based processing routines designed to produce output data that are formatted for use as input to the water budget model with the primary weather station output accessed by the swb2 model being a daily rainfall time series from each station once downloaded the hydrologic technician at aspa uploads raw data files directly to the cloud based repository on github shuler and mariner 2019 and new datasets are automatically incorporated with previous datasets once the processing routine is run the weather station data processing routine includes consolidation and organization of raw data files into a single time series performing qa qc checks removing previously identified sequences of corrupted data from known station malfunctions graphing datasets to allow users to inspect data validity fig 4 summarizing data at different time resolutions and creating output files both for distribution and to be used as input in the tutuila swb2 water budget model the streamflow datasets are processed with a script similar to the weather station routine the streamflow routine processes updated stage i e water height data from each gage site as well as discrete streamflow measurements that are used for automated rating curve development stage measurements from pt s at each site are post processed by comparing with flow measurements to convert stage into discharge the stage discharge relationship is unique to each site and is dynamic alluvial processes are constantly reshaping channel morphology thereby necessitating continual updates to rating curves although rating curves can take many different mathematical forms we have achieved the lowest error by applying a 2d polynomial relationship between stage and discharge at the tutuila gauging sites data from land based barometers is also uploaded with stream stage data and used to automatically correct for transient changes in barometric pressure the data processing routine for stream gauge data includes automated barometric compensation removal of false readings corrections for physical changes at gauging sites automated rating curve development baseflow and surface runoff separation wahl and wahl 1995 summarizing data into daily time series monthly averages and annual averages fig 5 the routine also generates monthly volumetric surface runoff rates for each basin above each gauge which is the primary stream gauging output accessed by the swb2 model to calculate runoff to rainfall ratios an updated file is automatically generated each time new data is loaded and the routine is run and this file is saved to a location directly accessed by the swb2 model as it compiles input data monitoring well data is processed with a routine similar to the streamflow routine where data is consolidated barometrically compensated and qa qc procedures are implemented fig 6 at present the groundwater modeling component is set up as a steady state model therefore the transient water level data is averaged to obtain a single water level value for each site which is then consolidated with the other static water levels and used for calibrating the modflow model 4 2 swb2 model implementation the swb2 model component was designed to be run as a series of modular cells the first of which contain pre processing routines that format shapefile or raster datasets into ascii grids for use in the swb2 model it is simple for the user to modify or substitute different input datasets during any of these steps if desired to update the model or to assess different scenarios the open source swb executable https github com smwesten usgs swb2 is run as a sub process from the jupyter notebook once the swb2 code is executed the model output is post processed to produce annual resolution outputs for each water budget component with the most current set of input data the swb2 output indicates that tutuila receives approximately 402 mgal d as precipitation inputs and of these inputs approximately 33 mgal d or 8 are lost to canopy interception 61 mgal d or 15 are lost to evapotranspiration 84 mgal d or 21 are lost to island wide runoff leaving the remaining 54 of inputs totaling 221 mgal d as the total island wide groundwater recharge estimate fig 7 the annual groundwater recharge layer produced by swb2 is then directly integrated into the flopy pre processing routine to supply the modflow model with recharge rates at the desired spatial resolution because the framework is dynamic results adjust as updated streamflow and weather station data are produced thus it should be noted that the model outputs reported here only represent the latest model iteration and are subject to change as new data are gathered the primary management utility of the water budget model lies in assessing different scenarios to show how possible future conditions may affect groundwater recharge to develop recharge predictions in consideration of likely future climate scenarios we modified the rainfall and temperature variables in the swb2 model using output from gridded dynamically downscaled climate projections for american samoa wang and zhang 2016 the gridded climate model data covered three specific scenarios 1 present day climate for the years 1990 2009 2 future climate during the years 2080 2099 reflecting a lower carbon emissions scenario rcp4 5 and 3 2080 2099 climate reflecting on a higher emissions scenario rcp8 5 the wang and zang 2016 projections for both emissions scenarios predict significant increases in both precipitation and temperature and when integrated into the tutuila swb2 model this translated into overall increases in all water budget components as calculated by the modified swb2 runs most notably the 11 18 increase in precipitation predicted by the rcp8 5 and rcp4 5 scenarios respectively drove increases in groundwater recharge rates of 17 27 respectively 4 3 flopy model implementation one of the primary motivations behind developing the modeling framework within a cooperative paradigm was to build direct technical capacity at aspa the organization tasked with managing the island s water resources therefore instead of focusing the groundwater model component on creating a single extensively calibrated static model realization this component is designed to build modeling capacity and share knowledge between participants through the collaborative development of a set of modular flopy centric tools by developing this portion of the framework as a dynamic toolbox we can continually adapt the models and data collection efforts to target specific water management questions as they arise for example aspa is currently drilling a number of new production wells in the village of malaeimi in western tutuila as additional pump test and drawdown data are collected during well development these tools can be directly applied by aspa to help set sustainable pumping rates at the wells we developed the groundwater modeling toolbox as a series of jupyter notebooks that use the whole island of tutuila as the model active area when investigation of a more localized area is desired the active area can be changed by substituting different shapefiles and the scripts can be reused with only a small amount of modification the implementation presented here covers the whole island model which is intended to demonstrate the application of these tools however the validity of the regional scale realization is severely limited by the spatial distribution of available observation data which is a common issue when modeling steep and challenging terrains such as high volcanic islands where wells are only located in coastal areas therefore results and plots based on this realization should be considered to be for demonstration purposes only and should not be directly used for management purposes at this time in general the tutuila flopy model follows a workflow that includes the following steps 1 defining cell size and model geometry including active and inactive areas layer elevations and boundary conditions 2 importing input data such as observed water levels groundwater recharge from the swb2 model and starting values for hydraulic conductivity 3 setting starting conditions for model variables including water levels and the elevation of the salt water interface 4 compiling inputs into a flopy model object 5 running the modflow executable as a sub process in python 6 optimizing calibration parameters and 7 reading output files visualizing results and assessing model performance 4 3 1 model initialization the first cells of each notebook consolidate explanations variable definitions and settings grid size time steps etc to make it easy for users to understand and interact with the model all modules were written to automatically adjust for changes in grid resolution so users can reduce model run time when experimenting input datasets are clearly defined in a single cell so users know what data goes into each model the subsequent jupyter notebook cells each contain a separate module that handles a specific model development task these tasks generally correspond to specific modflow packages for example geolocation and model grid boundaries are defined in a single cell that creates the modflow dis package in this cell the grid is defined by importing a projected shapefile determining its extent and extending the grid edges beyond the shapefile edges by a defined percentage for this case study the grid covers an area 5 larger than the extent of the 50 m bathymetric contour around tutuila fig 8 a the bas package contains model active areas and boundary conditions such as specified head or general head boundaries we define these by overlaying shapefiles onto the model grid and creating grid indexed arrays to assign conditions to individual cells for the tutuila model the area inside of the 50 m bathymetric contour which geologically represents the former maximum areal extent of the island prior to erosion and subsidence stearns 1944 is defined as the model active area and the submarine area between this contour and the island s coastline is set as a general head boundary to simulate the freshwater head set to 0 01 m exerted on the ocean bottom by seawater fig 8b the model top and bottom elevations are defined with a digital elevation model fig 8c and a constant depth value of 1000 ft respectively model stress periods and time steps are also defined for the bas package spatially distributed groundwater recharge is obtained from the output of the swb2 water budget component and is spatially resampled to match the groundwater model grid size for implementation in the modflow rch package fig 8d to simulate the interaction between salt and freshwater we use the flopy swi2 package bakker et al 2013 to obtain a first order approximation of the position of the 50 freshwater seawater interface fig 9 the more computationally expensive density dependent package seawat or langevin et al 2008 can also be implemented with flopy and should provide more reliable salinity information in local scale adaptations of the regional model 4 3 2 model execution and calibration with the flopy package model inputs can be formatted and the modflow executable can be run directly from a single python interface this functionality allows the model to be wrapped into a loop function or class for model calibration and sensitivity testing calibration can be handled by a wide array of widely used python based optimization packages such as scipy https www scipy org pest http www pesthomepage org or other custom built optimization packages such as pypcga lee et al 2016 to optimize the tutuila model we have designed two different workflows to calibrate for spatially distributed k values using a zone based approach and a grid based method both of which minimize error between observed and simulated water levels the zone based approach divides the island into different hydrogeologic zones based on a geologic map stearns 1944 and a single k value for each zone is parameterized for optimization using the scipy optimize minimize package fig 10 a and c the grid based approach applies principal component geostatistical approach kitanidis and lee 2014 by applying the open source pypcga python package this package provides a ready built computationally inexpensive inversion method to solve for large parameter sets in this case each model cell with low numbers of observations each method has different benefits and costs and the same model can be run with both to provide managers with a sense of how initial assumptions and methods may affect the model output fig 10b and d the static water level observations used for calibration were collected from historical records and monitoring wells in the monitoring network historical observations are taken from all known driller s logs and production well pump test logs conducted at the time of drilling these pre development water levels represent the most reliable spatially distributed static water level information for tutuila since no dedicated monitoring wells have been drilled on the island historical water levels are lumped together with average water levels from the monitoring network and these water levels are automatically updated as monitoring well instruments are downloaded and data is uploaded to github as new wells are drilled by aspa or as production wells are taken offline and converted to monitoring wells these data will be included as well please note that the model results shown in the figures below are example visualizations and do not represent appropriately calibrated model outputs 5 discussion and conclusions the traditional approach to groundwater modeling has a number of significant drawbacks it is expensive it produces products with limited longevity and it is technologically dated recent advances in social networking are spilling over into how we communicate professionally how we work collaboratively and how we approach data science scientific endeavors and especially computational tasks such as groundwater modeling are well poised to take advantage of these new developments improvement in the sharability of information is revolutionizing how we work with each other and this allows for a new process based paradigm that promotes the maintenance of long standing project partnerships the collaborative process based approach is especially well suited to development of groundwater models on small islands such as tutuila where there is a critical management need for environmental models but limited resources to develop and maintain the scientific capacity to use them groundwater modeling is a complex process and within the traditional paradigm often takes multiple years of project development to obtain results during this period the original research questions may become outdated and newer more relevant questions may not be appropriate to answer with a model designed for older objectives to create a low cost and functional groundwater modeling solution in light of these challenges we developed a collaborative hydrologic modeling framework that integrates monitoring network data water budget modeling and groundwater modeling into a seamless data to model workflow the workflow is made entirely open source reproducible and dynamic by using tools such as jupyter notebooks and github these tools manage the data science infrastructure so the project team can focus on communication and development of models that are scientifically relevant and useful for water resources management the framework also leverages the adaptability of the open source high level python environment if a task cannot be performed with the groundwater modeling package flopy then thousands of other freely available python modules covering a wide range of functions are available to be imported and integrated using just a few lines of code this functionality is the primary benefit of using flopy for groundwater model development as it leverages the power of python s significant data analysis and computer science library of readymade open source packages alongside a wealth of online support tutorials and documentation for example in addition to automatically generating plots our model framework applies a kml writer to save all output figures in kml format which allows users with no gis experience to instantly open and interact with spatially distributed model data in end user mapping platforms such as google earth https www google com earth while we have applied this framework to develop hydrologic models in american samoa this paradigm could also be adapted to other localities or other data to model workflows 5 1 limitations of the framework the primary limitation of the collaborative modeling framework we propose here is the significant investment needed from the participants process based approaches by nature require more time and commitment then static product based approaches while the existing funding and resource allocation setting at both aspa and uhwrrc have been conducive to this model we recognize that elements are often not aligned in this way nonetheless we contend that new cloud based collaborative tools can simplify numerous aspects of this challenge and facilitate the maintenance of relationships between agencies in different locations another limitation of this paradigm is that it depends heavily on the abilities and interests of both modelers and the stakeholders whom the work is intended to benefit in a relationship where neither party is contractually obligated to maintain engagement the strength of collaboration relies on the cost to benefit ratio of maintaining the program for each organization therefore in our program we strive to ensure that the benefits of working together such as improved access to resources maintaining dynamic models and improved understanding of results and uncertainties outweigh the costs from a technical standpoint generalization of the code is another limitation of the framework since our backgrounds are in hydrology or water management and not programing the code used in this project is primarily focused on meeting our and our stakeholder s specific needs rather than producing a software product intended to be generalizable for other projects or different locations therefore to apply these workflows to other datasets will require a variable degree of modification depending on the similarity in formatting and scale to the input datasets used in this workflow nonetheless to account for the lack of robustness built into the code itself we have instead focused on making our workbooks and workflows well annotated and easy to understand so other potential users can learn from these methods and develop their own through variable degrees of modification 5 2 current and future management applications this case study demonstrates a long term process based groundwater modeling approach that as of this writing continues to evolve as stakeholders continue to develop uses for data and model results and as our experience using these tools grows we plan to continue developing the framework to meet the management needs in american samoa planned additions to the monitoring network include additional streamflow stations and continued upgrades to weather station infrastructure data will continue to be downloaded on a quarterly basis and streamflow measurements for to rating curve updates remains ongoing the water budget model will automatically incorporate new monitoring data as it is updated quarterly and we are currently working directly with numerous stakeholders at agencies throughout american samoa to develop future land use scenarios for the water budget model these scenarios will be incorporated with the future climate scenarios to provide multi faceted predictions of impacts to groundwater recharge under different possible futures the groundwater modeling component is as stated before ongoing with continued model calibration validation and running groundwater pumping scenarios to assess potential rise in the transition zone collection of high resolution salinity data is currently planned as part of aspa s system wide operational scada system upgrades and as this data becomes available we intend to improve the flopy model by applying our existing calibration and validation approaches e g the scipy optimize method and pypcga lee et al 2016 in addition we also intend to explore and apply other open source python based optimization modules such as salib herman j usher 2017 and spotpy houska et al 2015 to refine our existing methods of sensitivity testing and model calibration again the ability to plug in new tools to our analysis pipeline as they are developed and as we become aware of them is one of the great advantages to maintaining our workflow in the python ecosystem the groundwater model has already and will likely continue to expose data gaps which can be prioritized in the future these include developing additional monitoring well capacity and additional constraint on mountain front recharge behavior in the tafuna leone plain area ultimately addressing the issues of sustainable yield and salt water intrusion remains as the primary goal of the groundwater modeling component and we anticipate the tools developed here to be an important part of laying the foundations for these efforts to improve the water resources sustainability in american samoa software and data availability all raw data model code and processed model outputs are archived under an open source license in the project repository on github titled aspa uh integrated modeling framework developer contact information is christopher shuler water resources research center and department of geology and geophysics university of hawaii at manoa 1680 east west road hi 96822 usa cshuler hawaii edu 1 808 956 7847 we archived and released version 1 0 of the repository in september 2019 which can be accessed at http doi org 10 5281 zenodo 3460214 the most recent version of the repository can be accessed at https github com cshuler aspa uh integrated modeling framework models and data processing routines are developed as live code execution documents jupyter notebooks and are written in python all notebooks can be executed on a personal computer with the free anaconda python distribution https www anaconda com or executed directly in a cloud based live code execution environment e g https mybinder org raw data is stored in tabular vector and gridded formats and the total repository size at time of release is 808 4 mb declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to express our appreciation for the many individuals and agencies who made this work possible by generously providing their time expertise and assistance with data collection and field support these people and agencies include the american samoa power authority especially matt erickson will spitzenberg and utu abe malae the american samoa community college especially mark schmaedick jameson newtson and kelley anderson taggarino the american samoa epa especially tim bodell the usgs specifically kolja rotzoll alan mair scot izuka and steve westenbroek and the university of hawaii especially aly el kadi henrietta dulai craig glenn and celia smith we would also like to thank alex messina formerly at san diego state university author contributions c k s and m k e m developed the collaborative research design c k s performed all of the monitoring network and water budget components and both c k s and m k e m performed implementation of the groundwater modeling component c k s wrote the majority of the manuscript and m k e m reviewed revised and edited the manuscript this is contributed paper wrrc cp 20xx xx of the water resources research center university of hawaii at manoa honolulu hawaii soest publication funding for this project was provided by the usgs water resources research institute program wrrip grant numbers 2015as443b 2015as445b 2018as488b and noaa s pacific regional integrated sciences and assessments program pacific risa grant number na15oar4310146 
26042,recent advances in cloud computing and social networking are influencing how we communicate professionally work collaboratively and approach data science tasks here we show how the groundwater modeling field is well positioned to benefit from these advances we present a case study detailing a vertically integrated collaborative modeling framework jointly developed by participants at the american samoa power authority and at the university of hawaii water resources research center the framework components include direct collection and analysis of climate and streamflow data development of a water budget model and initiation of a dynamic groundwater modeling process the framework is entirely open source and applies newly available data science infrastructure using python based tools compiled with jupyter notebooks and cloud computing services such as github these resources allow for seamless integration of multiple computational components into a dynamic cloud based workflow that is immediately accessible to stakeholders resource managers or anyone with an internet connection keywords groundwater modeling hydrologic monitoring network american samoa jupyter notebooks github python 1 introduction for the last half century computational modeling has become a principal tool in the water resource manager s toolbox groundwater models have become indispensable industry standard methods for estimating the availability and sustainability of groundwater resources e g young and bredehoeft 1972 cummings and mcfarland 1974 willis and yeh 1987 however because of the inherent complexity of numerical models and the significant time effort and expertise needed for their development it is often challenging for stakeholders and water resources managers to access models that are appropriate for their needs essawy et al 2018 within the traditional model development paradigm water management agencies usually take one of two approaches for obtaining hydrologic models to suit their needs 1 dedicate significant resources to building internal modeling capacity or 2 contract with outside experts to deliver models that typically cannot be interacted with once completed drawbacks to the former approach include the high cost of training software and salary required for agencies to retain personnel with sufficient skills to assess the validity conceptualization calibration and usefulness of existing models or to create and maintain effective modeling programs this level of resource dedication is often only possible for larger utility companies or management agencies leaving small remotely located agencies with few to no options for maintaining quality modeling expertise on the other hand the latter approach of hiring contractors generally results in production of static models that may lose relevance quickly and are often delivered in a format that do not allow end users to modify parameters or address new questions this approach also suffers from the inherent temporariness of typical funding mechanisms whereas the calibration and validation process lasts only as long as the project account is solvent after which a final report is delivered and the latest iteration of model files are archived for long term storage on a server in the back of someone s office compounding this issue is the fact that many groundwater models are developed with proprietary software or within specialized computational environments making it prohibitively challenging for end users to open and interact with the finished product to circumvent these problems yet retain the benefits from each of the aforementioned approaches we here propose a new approach to the hydrologic modeling process where model developers and end users enter into a long term collaborative working relationship facilitated by advances in open source cloud computing capabilities to demonstrate this approach we present as a case study the ongoing development of a collaborative modeling framework conceived as a joint effort between the university of hawaii water resources research center uhwrrc and the american samoa power authority aspa the intended outcomes for this modeling framework are commensurate with the motivations behind the participatory and collaborative modeling movement that has in recent decades become a highly utilized approach in environmental management e g argent and grayson 2003 liu et al 2008 these outcomes are centered around addressing the need for enhanced researcher stakeholder engagement and producing practical defendable models that sufficiently address stakeholder needs and promote model use in guiding important water management decisions this paradigm allows for incorporation of the views needs and knowledge of many stakeholders including scientists policy makers and resource managers in the modeling process moran 2016 describes the collaborative process as one where model developers decision makers stakeholders and others work together to develop a shared understanding of the region s management objectives and the model s role in supporting those objectives langsdale et al 2013 further refines collaborative modeling as a process where both the model and the process remain accessible and transparent to all participants collaborative modeling builds trust and respect among parties participatory and collaborative modeling methods are well tested and have been applied across many disciplines ranging from computer science e g bidarra et al 2001 to economics e g mendoza and prabhu 2006 and social sciences e g flint et al 2017 the approach is especially pertinent in water resource management as water s indispensable and ubiquitous nature inherently makes any issue a multi stakeholder concern in the water resources field collaborative or participatory approaches have been applied in numerous case studies across a range of technical foci including watershed modeling e g liu et al 2008 groundwater modeling e g barfield 2009 beall et al 2011 and water policy and planning e g tidwell et al 2004 however the technological boundaries for the implementation of this collaborative paradigm within the high level programming revolution of the present day have not yet been fully explored here we contend that recent developments in cloud computing technologies are now providing new opportunities for collaboration and communication between remotely located institutions and agencies application of these new technological tools within a collaborative paradigm allows participants to more efficiently share resources and facilitates direct application of models by the managers who are tasked with solving their region s water resource challenges the primary objective of this manuscript is to present an example of a collaborative hydrologic modeling framework that takes advantage of recent advances in cloud computing and open source modeling tools the framework is vertically integrated as it is intended to handle all components in the process that ultimately leads to the development of groundwater models used for drinking water management these components include 1 the direct collection and processing of basic hydrologic parameters through an island wide hydrologic monitoring network 2 development of automated data processing applications to integrate updated data into subsequent model components 3 creation of a dynamic water budget model to predict island wide groundwater recharge and 4 development and application of a set of open source groundwater modeling tools that can be directly modified by stakeholders to address local water resources management questions the framework is intended to be entirely open source and all raw data model code and processed outputs are made publicly available online so anyone with skills and interest can modify inputs test scenarios and continue model development this philosophy promotes transparency reproducibility and accessibility through both the development and implementation process thereby facilitating interaction with interested stakeholders or other modelers the framework is designed to adhere to the best practices of reproducibility for digital research objects fehr et al 2016 which include 1 being physically accessible by using open source codes 2 being conceptually accessible by facilitating sharing of required core skills for data management workflow efficiency and visualization and 3 being reusable by applying modularity and by providing opportunities to dynamically change inputs as needed the framework is also intended to be portable flexible use small file sizes and only include models with short run times which are attributes that have been shown to enhance model adoption rates amongst managers argent and grayson 2003 by presenting this framework we hope to demonstrate the ease of use and the applicability of modern code sharing and cloud computing tools in a scientific modeling setting involving participants at remotely located institutions these tools have allowed us to connect researchers and stakeholders through ready built data science infrastructure and to share advanced modeling capacity across our network of participants while the case study in its current form demonstrates these ideas we also view model development as a process not necessarily an end goal therefore the framework continues to evolve and change as we and our stakeholders continue to participate in discussion raise concerns and contribute new ideas 2 case study setting the island of tutuila is the main population center of the u s territory of american samoa it is located near 14 s and 170 w and at 142 km2 is the third largest island in the samoan hot spot chain geologically tutuila contains two distinct provinces the bulk of the island is composed of an older highly eroded basaltic shield edifice 1 5 1 0 ma and recent holocene age rejuvenation stage volcanism on the southwestern flank of the older shields has created the younger tafuna leone plain stearns 1944 mcdougall 1985 the young pahoehoe flows of the tafuna leone plain give it a higher hydraulic conductivity k than the older volcanic unit which is composed of a heterogeneous mixture of a a lava flows pyroclastic materials and trachyte domes stearns 1944 eyre and walker 1991 geological subdivisions within each of these units exist and may be used as the basis for further refinement into zones with different hydrogeologic properties izuka et al 2007 tutuila s climate is warm and humid with abundant year round rainfall due to its position within the south pacific convergence zone the island experiences a wetter season with increased precipitation amounts from october to may and a drier season with less though still significant precipitation from june to september rainfall varies considerably with location and elevation and ranges between 1800 mm yr near the tafuna airport up to more than 5000 mm yr along the crest of the highest mountains daly et al 2006 the region is also influenced by tropical storms and hurricanes and an average of 25 30 significant thunderstorms affect the island annually kennedy and chilton consulting engineers 1987 in american samoa groundwater resources supply over 90 of domestic and nearly 100 of industrial water use however these resources are afflicted by multiple threats to their long term sustainability since 2009 portions of the public water supply system have been unsafe to drink necessitating one of the longest standing boil water advisories in u s history this is partly caused by the vulnerability of tutuila s young and highly permeable aquifers to anthropogenic and surface water contamination shuler et al 2017 2018 other aquifers on tutuila produce high salinity water presumably caused by salt water intrusion izuka 1999 in some cases the island s wells produce water with cl concentrations exceeding the u s environmental protection agency drinking water standards by four to five times multiple local stakeholders see groundwater models as a tool that will greatly facilitate management of these issues aspa 2013 as of this writing there have been four known groundwater models developed for portions of tutuila izuka et al 2007 aspa 2013 shuler et al 2014 shuler et al 2017 while each of these models addressed a specific question ranging from defining well capture zones to modeling nutrient transport none have satisfied the requirements to fully address aspa s water management needs the static nature of these models also restricts their ability to be modified and aspa like most small scale water utilities does not have time or resources to support building and maintaining an active hydrologic modeling program on their own 2 1 collaborative groundwork and stakeholder needs in american samoa aspa is the only water utility and the agency is also responsible for all municipal power wastewater and solid waste services american samoa is a unique environment as it is small population of approximately 60 000 geographically isolated 4000 km to the nearest continent and a sovereign society still retaining much of its indigenous culture and tradition therefore aspa is particularly invested in not only meeting customer needs but also in conservation and responsible stewardship of the island s limited natural resources the water resources research center is a technical research unit at the university of hawaii and its stated mission is to promote understanding of critical state and regional including the u s affiliated pacific islands water resource management and policy issues through research community outreach and public education to fulfil this mission in american samoa uhwrrc has been working with aspa and other agencies since 2013 to develop an integrated water resources research program in the territory that strives to incorporate on island stakeholder concerns into research priorities in 2015 we a group of researchers and staff at aspa and uhwrrc formally initiated the collaborative modeling effort through a memorandum of understanding originally intended to 1 develop infrastructure for collection of hydrologic and climatic data and 2 apply this data in support of aspa s water resources management priorities at the time we also recruited a diverse group of representatives from local management agencies to form the american samoa water resources stakeholders committee the committee was tasked with documenting and communicating american samoa s water resource needs and since its formation hydrologic data collection and groundwater model development have been consistently identified as top priorities throughout the next four years our collaborative efforts have been directed towards hydrologic data collection development of water budget estimates development and use of groundwater and hydraulic system models and capacity building within both institutions during a training workshop conducted in american samoa for aspa and uhwrrc staff the following modeling focused management priorities were identified assessing resource sustainability through water budgets or sustainable yield estimates identifying new well drilling locations based on freshwater lens thickness simulating contaminant plumes from sources including piggeries and industry identifying low pressure zones and examining hypothetical stresses in the water distribution system these stakeholder driven objectives currently guide the focus of our conceptual and numerical groundwater modeling activities as well as the continued development of hydrological monitoring operations 3 framework development methods 3 1 cyber infrastructure framework to make hydrologic monitoring data publicly accessible and also to store projects and code in a way that allowed results to be automatically updated each time new data became available a set of open source cloud based applications were used as the cyberinfrastructure for our collaborative modeling framework these applications have been imperative for facilitating communication providing the ability to collaboratively code and for taking care of the basic data science needs that would be overwhelmingly resource intensive for either agency to develop independently we selected jupyter notebooks https jupyter org for python based coding and project development github https github com for project storage and version control skype and google hangouts http www skype com and https hangouts google com for communication and as of this writing we are currently exploring different applications for live cloud based code execution e g binder and google colab https mybinder org and https colab research google com a common thread between these services is that they are all are intuitive simple open source and integrable with each other and other widely used cloud computing services the diverse and rapidly developing array of existing python packages allows the language to be used reliably for every task across our collaborative modeling framework maintaining this methodological consistency streamlines execution of the modeling process by routing computational outputs from one module as inputs to others while computing languages such as python r and matlab are commonly used for scientific model development e g borah and bhattacharjya 2013 bakker et al 2016 yin et al 2017 code based tools have nonetheless been historically difficult for end users to access due to steep learning curves and sometimes costly licenses jupyter notebooks help to solve this issue by bridging the gap between coders and the uninitiated by integrating live code equations visualizations web links and explanatory documentation into notebooks to make them easier to understand and interact with perez and granger 2015 kluyver et al 2016 because of this accessibility jupyter notebooks are becoming increasingly popular amongst modelers and across many scientific disciplines e g subramanian et al 2015 white et al 2016 somers 2018 though these advances may seem unimportant to those more familiar with coding in a collaborative framework where team members with variable degrees of expertise wish to be involved in the modeling process simplicity and ease of access is paramount for everyone s engagement additionally inclusion of numerous participants and integration of multiple components into a single workflow necessitates a significant amount of data organization and project management work while this would be time consuming to do manually the open source project management tool github provides free cloud based server hosting version control and workflow organization to facilitate collaborative contributions from multiple participants github maintains organization in the modeling framework by storing all data and code within individual repositories that preserve the file folder structures that allow for consistent relative connectivity between model inputs and outputs open access repositories can be directly downloaded from the web by anyone and authorized team members can make changes and upload them back to github automated version control features track all changes and allow users to review and accept or reject them github is becoming increasingly popular as a collaborative coding and data driven project management tool dabbish et al 2012 and at present it is the computer science industry standard application for storing managing and tracking changes to code stack overflow 2018 a key feature for facilitating input from stakeholders is github s browser friendly graphical user interface gui which allows anyone to view and explore files datasets and results without needing any specialized software or computing resources while github provides online file storage and organization it does not provide computational resources for running models to avoid issues with local dependencies software and computational resource limitations on individual user s computers we are currently exploring the utility of a number of open source cloud computing resources dedicated to addressing this concern such services operate by opening a cloud based python environment on a remote server and installing all needed software at the time of use there are numerous existing resources including binder and google colab amongst others that provide this service through seamless integration with jupiter notebooks and github at present we have found these services to be most useful for conducting demonstrations of framework components during workshops or teleconferences finally although a seemingly simple task the importance of teleconferencing and specifically screen sharing services cannot be overlooked for projects of this nature for this project skype and google hangouts has been a significant boon for facilitating communication to and from american samoa which is still serviced by international telephone calling rates these internet based services allow participants to share screens and see visual output directly and this is especially helpful when working within a fairly complicated modeling framework 3 2 modeling framework the tutuila collaborative modeling framework includes tools that address the island s most pressing water management questions through three distinct yet integrated components these include 1 collection and automated processing of weather station stream gauge and monitoring well data from a hydrologic monitoring network 2 development and application of a dynamic water budget model that produces and automatically updates an island wide groundwater recharge coverage based on monitoring network data and 3 ongoing collaborative development of dynamic regional and local scale numerical groundwater models that automatically intake the most recent recharge coverage and monitoring well data tasks performed in the first framework component include collecting raw hydrologic data uploading data to the github repository shuler and mariner 2019 checking quality and processing data into the necessary format to be used as input to the subsequent modeling steps we developed python based data processing scrips as jupyter notebooks which are archived along with raw and processed hydrologic data on github processed hydrologic data from the monitoring component is output to the input data folder accessed by the water budget model script we developed the tutuila water budget model with the soil water balance 2 swb2 code developed by the usgs westenbroek et al 2018 the swb2 model calculates spatially distributed groundwater recharge rates at a monthly resolution and all inputs and outputs are processed in the same python development environment as the monitoring network data while linking these steps creates a complex network of interdependencies consistency and organization are easily maintained through github the final component in the collaborative modeling process is a modflow based groundwater model this component like those previously described is developed within the same python based environment thereby allowing for a cohesive workflow and seamless integration from raw data to model results for groundwater model development we used flopy a python based site package designed to simplify pre processing run time and post processing tasks for development of modflow based models as new data is collected and uploaded dynamic updates to the swb2 generated groundwater recharge coverage are translated through to the flopy models which then ideally become more accurate every time new monitoring data is processed fig 1 shows a schematic of the data processing and modeling workflow for the aspa uhwrrc cooperative modeling framework 3 3 hydrologic monitoring network beginning in the 1950 s the u s geological survey usgs monitored rainfall and streamflow at multiple sites throughout american samoa however in 2008 all usgs monitoring operations in the territory were halted leaving a 7 year long data gap until 2015 when we began installing weather stations since 2015 we at aspa and uhwrrc have worked to develop a monitoring network consisting of eight stream gauging stations six weather monitoring stations and three preliminary water level monitoring sites fig 2 hydrologic data from these instruments is imperative for estimating groundwater recharge which is an important spatially distributed input variable in groundwater models especially in island settings with very steep rainfall gradients both aspa and uhwrrc contributed to instrument installation and we continue to work together to maintain the network to ensure continuity with data downloads and maintenance of physical infrastructure aspa created a full time position for a hydrologic technician and uhwrrc continues to develop and maintain systems for data processing quality assurance quality control qa qc procedures and archiving and distribution of data all weather stations have the capability to record precipitation temperature relative humidity rh wind speed and direction and solar radiation sr the network was initially developed using low cost spectrum technologies inc watchdog 2900 et weather stations spectrum item number 3350wd2 but as funding allows these stations are incrementally being replaced with solar powered campbell scientific stations fig 3 consisting of an rm young wind sentry set 03002 l12 pt a csl temperature rh probe cs215 l7 pt an apogee sp 110 pyranometer cs300 l12 pt and a texas electronics rain gauge te525 l10 pt part numbers refer to campbell scientific catalog numbers all stations are mounted on 2 3 m poles and placed at sites with the best balance of station siting characteristics considering the available terrain wmo 1983 u s epa 1987 weather stations log at 15 min intervals and data is downloaded quarterly by the aspa technician once downloaded the technician simply uploads raw data files to the project repository on github for processing and for long term storage additional metadata and information about the aspa uhwrrc network can be found in shuler and el kadi 2018a stream gauge installation began in 2016 and at present our streamflow monitoring network consists of eight separate continuous record gauges located on different streams throughout tutuila barometers and in stream pressure transducers record data at 15 min intervals the stream gauges physically consist of stainless steel hobo water level loggers hobo model u20 001 01 i e pressure transducers pt installed in durable steel housings which are permanently mounted to immobile structures such as bridges or bedrock outcroppings housings are constructed of perforated square galvanized steel pipe with a locking mechanism at the top fig 3 site selection involved field scoping and soliciting input from multiple departments at aspa other on island stakeholders such as the american samoa epa and also with hydrologists at other universities to ensure maximization of data utility site selection criteria included considering site access proximity to historical gauges bank and channel control stability and representativeness of the variability in tutuila s different climatic and geological regions additional metadata and information about the stream gauge network is available in shuler and el kadi 2018a data is downloaded from loggers and uploaded to github by aspa on a quarterly basis in 2017 we initiated a pilot program to repurpose abandoned aspa production wells as monitoring wells in order to continuously observe water levels and aquifer electrical conductivity ec since this time only three open boreholes have been available for this purpose but as new wells are drilled and older wells are abandoned we anticipate the scope will expand at each monitoring well an instrument package consisting of a hobo water level logger and a hobo ec logger is contained within a perforated 1 25 inch pvc casing and suspended by a non elastic tape these loggers are retrieved downloaded and maintained on a quarterly basis by aspa and data is uploaded to github for processing 3 4 tutuila swb2 model development the usgs developed the swb2 water budget modeling code westenbroek et al 2018 to allow users to easily calculate water budget components and specifically groundwater recharge some functionality based on the hawaii water balance code engott et al 2017 was incorporated into swb2 making it one of the better suited options for modeling tropical basaltic islands in the hawaiian or samoan chains westenbroek et al 2018 for this study the swb2 code was applied to develop a tutuila island groundwater recharge coverage that then served as an input to the flopy groundwater model the swb2 code is based on a modified thornthwaite mather 1955 soil water balance approach which in a simplified form is represented by the following recharge rainfall runoff actual evapotranspiration for this study runoff to rainfall ratios and temporal rainfall distributions derived from our monitoring network data were used as key input variables to the tutuila swb2 water budget model all other input datasets used for the swb2 model were obtained from existing publications or databases with each being described in the respective documentation as cited below all swb2 inputs are either in the form of tabular lookup data or spatially distributed datasets in the esri ascii grid format input files for the tutuila swb2 model included gridded monthly precipitation data daly et al 2006 precipitation gauge data used to represent temporal rainfall distributions this study land use data meyer et al 2016 impervious surface ratios meyer et al 2016 canopy coverage ratios meyer et al 2016 soil type data consistent with the nrcs ssurgo database nakamura 1984 direct infiltration data from municipal water line leaks aspa personal communication direct infiltration data from osds effluent discharge as doc 2009 runoff to rainfall ratios this study perreault 2010 wong 1996 potential evapotranspiration data in monthly gridded format izuka et al 2005 canopy evaporation data engott et al 2015 aws truepower 2014 gridded monthly maximum and minimum temperature data daly et al 2006 mountain front recharge information izuka et al 2007 the swb2 code calculates all water balance components at a daily resolution and output files are produced in netcdf format the tutuila water budget model just like the other routines and models used in the framework was designed to be dynamic whereas once newly collected runoff and rainfall data are uploaded to github the seamlessly integrated workflow automatically incorporates it into all subsequent calculations although a dynamic version of the tutuila water budget model is integrated as a module of the integrated modeling framework a static version of the water budget model was published to stand alone for documentation in shuler and el kadi 2018b this report along with all of the input data code and output data for the static version of the tutuila water budget model is publicly available at https github com uh wrrc swb model swb2 tutuila 3 5 flopy groundwater model development in 1984 the usgs released the first version of modflow mcdonald and harbaugh 2003 over three decades later modflow remains one of the most widely used groundwater modeling applications the model s large user base results from its simplicity and continuing evolution and presently the python based module flopy lies at one of the forefronts of usgs model development efforts bakker et al 2016 flopy is an open source python package that provides functionality to simplify pre and post processing tasks for the modflow family of models such as modflow harbaugh et al 2000 mt3dms zheng and wang 1999 and seawat guo and langevin 2002 following the development philosophy of most python packages flopy is open source and constantly in development therefore new functionality continues to be added by the software s developers and users presently the flopy package is relatively new but it is rapidly gaining in popularity due to its modularity open source availability and support by usgs modelers e g rotzoll et al 2016 feo et al 2018 foglia et al 2018 benefits of using flopy for developing groundwater models include 1 model building and pre processing steps are quick to execute 2 specific inputs are easy to modify for example changing cell size and 3 the modeling process is transparent and simple to share with team members as well as with end users other researchers or reviewers providing the ability to modify model inputs quickly and easily makes flopy work with our process based paradigm quite well simplifying the model evolution process as new stakeholder needs development of new procedures and updated data become available at present we have initiated flopy groundwater model development for regional scale models covering the whole island and because this component of the framework continues to be driven by direct stakeholder needs sustained development is intended to continue into the foreseeable future pending continued support from both uhwrrc and aspa presently the scope of the groundwater modeling component of the framework is focused on 1 presenting examples of flopy python modeling functionality using data from tutuila and 2 providing opportunities for staff at aspa to work with a ready built model and to experiment with applying results for management needs while the model we have developed currently provides the foundation for models that will be applied by aspa in the future at present the model presented in this manuscript is not calibrated or validated to the point where it is intended to be used as a management tool at the time of writing we are collaboratively refining our existing modeling tools in order to lower uncertainties to the point where we can inform management questions with a higher degree of certainty while development of the groundwater modeling component remains ongoing throughout the process we have employed a common set of guiding principles to ensure that groundwater models integrate seamlessly into the greater collaborative framework these include 1 the groundwater models only depend on tools that operate within the python environment this ensures seamless integration of this component with the others 2 model steps are broken into manageable units in order to make the process easy to understand each step is annotated with text based explanations in markdown cells separating code blocks and input data and important parameters are clearly defined typically in a dedicated cell 3 whenever possible output from each step is automatically visualized using in line plots plots are also saved as images and as geographic data files using kml format which open directly in end user mapping platforms 4 all input datasets are simple cleanly organized and well annotated participants can directly modify inputs if needed or when other updated datasets become available 5 calibration routines automatically incorporate updated observation and input data e g updated water levels and revised recharge coverages from the swb2 model following collection from the hydrologic monitoring network 6 cell size resolution is simple to modify so experimentation can be performed at low resolution with short morel run times resolution can then be increased for sensitivity testing or creating finalized results 7 all model files are kept small enough to be hosted on github under 100 mb each 4 process implementation and results 4 1 monitoring network implementation weather stations and stream gauges are downloaded on a quarterly basis and the raw data require qa qc processing and integration with previous data to create long term station records we accomplish these tasks with python based processing routines designed to produce output data that are formatted for use as input to the water budget model with the primary weather station output accessed by the swb2 model being a daily rainfall time series from each station once downloaded the hydrologic technician at aspa uploads raw data files directly to the cloud based repository on github shuler and mariner 2019 and new datasets are automatically incorporated with previous datasets once the processing routine is run the weather station data processing routine includes consolidation and organization of raw data files into a single time series performing qa qc checks removing previously identified sequences of corrupted data from known station malfunctions graphing datasets to allow users to inspect data validity fig 4 summarizing data at different time resolutions and creating output files both for distribution and to be used as input in the tutuila swb2 water budget model the streamflow datasets are processed with a script similar to the weather station routine the streamflow routine processes updated stage i e water height data from each gage site as well as discrete streamflow measurements that are used for automated rating curve development stage measurements from pt s at each site are post processed by comparing with flow measurements to convert stage into discharge the stage discharge relationship is unique to each site and is dynamic alluvial processes are constantly reshaping channel morphology thereby necessitating continual updates to rating curves although rating curves can take many different mathematical forms we have achieved the lowest error by applying a 2d polynomial relationship between stage and discharge at the tutuila gauging sites data from land based barometers is also uploaded with stream stage data and used to automatically correct for transient changes in barometric pressure the data processing routine for stream gauge data includes automated barometric compensation removal of false readings corrections for physical changes at gauging sites automated rating curve development baseflow and surface runoff separation wahl and wahl 1995 summarizing data into daily time series monthly averages and annual averages fig 5 the routine also generates monthly volumetric surface runoff rates for each basin above each gauge which is the primary stream gauging output accessed by the swb2 model to calculate runoff to rainfall ratios an updated file is automatically generated each time new data is loaded and the routine is run and this file is saved to a location directly accessed by the swb2 model as it compiles input data monitoring well data is processed with a routine similar to the streamflow routine where data is consolidated barometrically compensated and qa qc procedures are implemented fig 6 at present the groundwater modeling component is set up as a steady state model therefore the transient water level data is averaged to obtain a single water level value for each site which is then consolidated with the other static water levels and used for calibrating the modflow model 4 2 swb2 model implementation the swb2 model component was designed to be run as a series of modular cells the first of which contain pre processing routines that format shapefile or raster datasets into ascii grids for use in the swb2 model it is simple for the user to modify or substitute different input datasets during any of these steps if desired to update the model or to assess different scenarios the open source swb executable https github com smwesten usgs swb2 is run as a sub process from the jupyter notebook once the swb2 code is executed the model output is post processed to produce annual resolution outputs for each water budget component with the most current set of input data the swb2 output indicates that tutuila receives approximately 402 mgal d as precipitation inputs and of these inputs approximately 33 mgal d or 8 are lost to canopy interception 61 mgal d or 15 are lost to evapotranspiration 84 mgal d or 21 are lost to island wide runoff leaving the remaining 54 of inputs totaling 221 mgal d as the total island wide groundwater recharge estimate fig 7 the annual groundwater recharge layer produced by swb2 is then directly integrated into the flopy pre processing routine to supply the modflow model with recharge rates at the desired spatial resolution because the framework is dynamic results adjust as updated streamflow and weather station data are produced thus it should be noted that the model outputs reported here only represent the latest model iteration and are subject to change as new data are gathered the primary management utility of the water budget model lies in assessing different scenarios to show how possible future conditions may affect groundwater recharge to develop recharge predictions in consideration of likely future climate scenarios we modified the rainfall and temperature variables in the swb2 model using output from gridded dynamically downscaled climate projections for american samoa wang and zhang 2016 the gridded climate model data covered three specific scenarios 1 present day climate for the years 1990 2009 2 future climate during the years 2080 2099 reflecting a lower carbon emissions scenario rcp4 5 and 3 2080 2099 climate reflecting on a higher emissions scenario rcp8 5 the wang and zang 2016 projections for both emissions scenarios predict significant increases in both precipitation and temperature and when integrated into the tutuila swb2 model this translated into overall increases in all water budget components as calculated by the modified swb2 runs most notably the 11 18 increase in precipitation predicted by the rcp8 5 and rcp4 5 scenarios respectively drove increases in groundwater recharge rates of 17 27 respectively 4 3 flopy model implementation one of the primary motivations behind developing the modeling framework within a cooperative paradigm was to build direct technical capacity at aspa the organization tasked with managing the island s water resources therefore instead of focusing the groundwater model component on creating a single extensively calibrated static model realization this component is designed to build modeling capacity and share knowledge between participants through the collaborative development of a set of modular flopy centric tools by developing this portion of the framework as a dynamic toolbox we can continually adapt the models and data collection efforts to target specific water management questions as they arise for example aspa is currently drilling a number of new production wells in the village of malaeimi in western tutuila as additional pump test and drawdown data are collected during well development these tools can be directly applied by aspa to help set sustainable pumping rates at the wells we developed the groundwater modeling toolbox as a series of jupyter notebooks that use the whole island of tutuila as the model active area when investigation of a more localized area is desired the active area can be changed by substituting different shapefiles and the scripts can be reused with only a small amount of modification the implementation presented here covers the whole island model which is intended to demonstrate the application of these tools however the validity of the regional scale realization is severely limited by the spatial distribution of available observation data which is a common issue when modeling steep and challenging terrains such as high volcanic islands where wells are only located in coastal areas therefore results and plots based on this realization should be considered to be for demonstration purposes only and should not be directly used for management purposes at this time in general the tutuila flopy model follows a workflow that includes the following steps 1 defining cell size and model geometry including active and inactive areas layer elevations and boundary conditions 2 importing input data such as observed water levels groundwater recharge from the swb2 model and starting values for hydraulic conductivity 3 setting starting conditions for model variables including water levels and the elevation of the salt water interface 4 compiling inputs into a flopy model object 5 running the modflow executable as a sub process in python 6 optimizing calibration parameters and 7 reading output files visualizing results and assessing model performance 4 3 1 model initialization the first cells of each notebook consolidate explanations variable definitions and settings grid size time steps etc to make it easy for users to understand and interact with the model all modules were written to automatically adjust for changes in grid resolution so users can reduce model run time when experimenting input datasets are clearly defined in a single cell so users know what data goes into each model the subsequent jupyter notebook cells each contain a separate module that handles a specific model development task these tasks generally correspond to specific modflow packages for example geolocation and model grid boundaries are defined in a single cell that creates the modflow dis package in this cell the grid is defined by importing a projected shapefile determining its extent and extending the grid edges beyond the shapefile edges by a defined percentage for this case study the grid covers an area 5 larger than the extent of the 50 m bathymetric contour around tutuila fig 8 a the bas package contains model active areas and boundary conditions such as specified head or general head boundaries we define these by overlaying shapefiles onto the model grid and creating grid indexed arrays to assign conditions to individual cells for the tutuila model the area inside of the 50 m bathymetric contour which geologically represents the former maximum areal extent of the island prior to erosion and subsidence stearns 1944 is defined as the model active area and the submarine area between this contour and the island s coastline is set as a general head boundary to simulate the freshwater head set to 0 01 m exerted on the ocean bottom by seawater fig 8b the model top and bottom elevations are defined with a digital elevation model fig 8c and a constant depth value of 1000 ft respectively model stress periods and time steps are also defined for the bas package spatially distributed groundwater recharge is obtained from the output of the swb2 water budget component and is spatially resampled to match the groundwater model grid size for implementation in the modflow rch package fig 8d to simulate the interaction between salt and freshwater we use the flopy swi2 package bakker et al 2013 to obtain a first order approximation of the position of the 50 freshwater seawater interface fig 9 the more computationally expensive density dependent package seawat or langevin et al 2008 can also be implemented with flopy and should provide more reliable salinity information in local scale adaptations of the regional model 4 3 2 model execution and calibration with the flopy package model inputs can be formatted and the modflow executable can be run directly from a single python interface this functionality allows the model to be wrapped into a loop function or class for model calibration and sensitivity testing calibration can be handled by a wide array of widely used python based optimization packages such as scipy https www scipy org pest http www pesthomepage org or other custom built optimization packages such as pypcga lee et al 2016 to optimize the tutuila model we have designed two different workflows to calibrate for spatially distributed k values using a zone based approach and a grid based method both of which minimize error between observed and simulated water levels the zone based approach divides the island into different hydrogeologic zones based on a geologic map stearns 1944 and a single k value for each zone is parameterized for optimization using the scipy optimize minimize package fig 10 a and c the grid based approach applies principal component geostatistical approach kitanidis and lee 2014 by applying the open source pypcga python package this package provides a ready built computationally inexpensive inversion method to solve for large parameter sets in this case each model cell with low numbers of observations each method has different benefits and costs and the same model can be run with both to provide managers with a sense of how initial assumptions and methods may affect the model output fig 10b and d the static water level observations used for calibration were collected from historical records and monitoring wells in the monitoring network historical observations are taken from all known driller s logs and production well pump test logs conducted at the time of drilling these pre development water levels represent the most reliable spatially distributed static water level information for tutuila since no dedicated monitoring wells have been drilled on the island historical water levels are lumped together with average water levels from the monitoring network and these water levels are automatically updated as monitoring well instruments are downloaded and data is uploaded to github as new wells are drilled by aspa or as production wells are taken offline and converted to monitoring wells these data will be included as well please note that the model results shown in the figures below are example visualizations and do not represent appropriately calibrated model outputs 5 discussion and conclusions the traditional approach to groundwater modeling has a number of significant drawbacks it is expensive it produces products with limited longevity and it is technologically dated recent advances in social networking are spilling over into how we communicate professionally how we work collaboratively and how we approach data science scientific endeavors and especially computational tasks such as groundwater modeling are well poised to take advantage of these new developments improvement in the sharability of information is revolutionizing how we work with each other and this allows for a new process based paradigm that promotes the maintenance of long standing project partnerships the collaborative process based approach is especially well suited to development of groundwater models on small islands such as tutuila where there is a critical management need for environmental models but limited resources to develop and maintain the scientific capacity to use them groundwater modeling is a complex process and within the traditional paradigm often takes multiple years of project development to obtain results during this period the original research questions may become outdated and newer more relevant questions may not be appropriate to answer with a model designed for older objectives to create a low cost and functional groundwater modeling solution in light of these challenges we developed a collaborative hydrologic modeling framework that integrates monitoring network data water budget modeling and groundwater modeling into a seamless data to model workflow the workflow is made entirely open source reproducible and dynamic by using tools such as jupyter notebooks and github these tools manage the data science infrastructure so the project team can focus on communication and development of models that are scientifically relevant and useful for water resources management the framework also leverages the adaptability of the open source high level python environment if a task cannot be performed with the groundwater modeling package flopy then thousands of other freely available python modules covering a wide range of functions are available to be imported and integrated using just a few lines of code this functionality is the primary benefit of using flopy for groundwater model development as it leverages the power of python s significant data analysis and computer science library of readymade open source packages alongside a wealth of online support tutorials and documentation for example in addition to automatically generating plots our model framework applies a kml writer to save all output figures in kml format which allows users with no gis experience to instantly open and interact with spatially distributed model data in end user mapping platforms such as google earth https www google com earth while we have applied this framework to develop hydrologic models in american samoa this paradigm could also be adapted to other localities or other data to model workflows 5 1 limitations of the framework the primary limitation of the collaborative modeling framework we propose here is the significant investment needed from the participants process based approaches by nature require more time and commitment then static product based approaches while the existing funding and resource allocation setting at both aspa and uhwrrc have been conducive to this model we recognize that elements are often not aligned in this way nonetheless we contend that new cloud based collaborative tools can simplify numerous aspects of this challenge and facilitate the maintenance of relationships between agencies in different locations another limitation of this paradigm is that it depends heavily on the abilities and interests of both modelers and the stakeholders whom the work is intended to benefit in a relationship where neither party is contractually obligated to maintain engagement the strength of collaboration relies on the cost to benefit ratio of maintaining the program for each organization therefore in our program we strive to ensure that the benefits of working together such as improved access to resources maintaining dynamic models and improved understanding of results and uncertainties outweigh the costs from a technical standpoint generalization of the code is another limitation of the framework since our backgrounds are in hydrology or water management and not programing the code used in this project is primarily focused on meeting our and our stakeholder s specific needs rather than producing a software product intended to be generalizable for other projects or different locations therefore to apply these workflows to other datasets will require a variable degree of modification depending on the similarity in formatting and scale to the input datasets used in this workflow nonetheless to account for the lack of robustness built into the code itself we have instead focused on making our workbooks and workflows well annotated and easy to understand so other potential users can learn from these methods and develop their own through variable degrees of modification 5 2 current and future management applications this case study demonstrates a long term process based groundwater modeling approach that as of this writing continues to evolve as stakeholders continue to develop uses for data and model results and as our experience using these tools grows we plan to continue developing the framework to meet the management needs in american samoa planned additions to the monitoring network include additional streamflow stations and continued upgrades to weather station infrastructure data will continue to be downloaded on a quarterly basis and streamflow measurements for to rating curve updates remains ongoing the water budget model will automatically incorporate new monitoring data as it is updated quarterly and we are currently working directly with numerous stakeholders at agencies throughout american samoa to develop future land use scenarios for the water budget model these scenarios will be incorporated with the future climate scenarios to provide multi faceted predictions of impacts to groundwater recharge under different possible futures the groundwater modeling component is as stated before ongoing with continued model calibration validation and running groundwater pumping scenarios to assess potential rise in the transition zone collection of high resolution salinity data is currently planned as part of aspa s system wide operational scada system upgrades and as this data becomes available we intend to improve the flopy model by applying our existing calibration and validation approaches e g the scipy optimize method and pypcga lee et al 2016 in addition we also intend to explore and apply other open source python based optimization modules such as salib herman j usher 2017 and spotpy houska et al 2015 to refine our existing methods of sensitivity testing and model calibration again the ability to plug in new tools to our analysis pipeline as they are developed and as we become aware of them is one of the great advantages to maintaining our workflow in the python ecosystem the groundwater model has already and will likely continue to expose data gaps which can be prioritized in the future these include developing additional monitoring well capacity and additional constraint on mountain front recharge behavior in the tafuna leone plain area ultimately addressing the issues of sustainable yield and salt water intrusion remains as the primary goal of the groundwater modeling component and we anticipate the tools developed here to be an important part of laying the foundations for these efforts to improve the water resources sustainability in american samoa software and data availability all raw data model code and processed model outputs are archived under an open source license in the project repository on github titled aspa uh integrated modeling framework developer contact information is christopher shuler water resources research center and department of geology and geophysics university of hawaii at manoa 1680 east west road hi 96822 usa cshuler hawaii edu 1 808 956 7847 we archived and released version 1 0 of the repository in september 2019 which can be accessed at http doi org 10 5281 zenodo 3460214 the most recent version of the repository can be accessed at https github com cshuler aspa uh integrated modeling framework models and data processing routines are developed as live code execution documents jupyter notebooks and are written in python all notebooks can be executed on a personal computer with the free anaconda python distribution https www anaconda com or executed directly in a cloud based live code execution environment e g https mybinder org raw data is stored in tabular vector and gridded formats and the total repository size at time of release is 808 4 mb declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to express our appreciation for the many individuals and agencies who made this work possible by generously providing their time expertise and assistance with data collection and field support these people and agencies include the american samoa power authority especially matt erickson will spitzenberg and utu abe malae the american samoa community college especially mark schmaedick jameson newtson and kelley anderson taggarino the american samoa epa especially tim bodell the usgs specifically kolja rotzoll alan mair scot izuka and steve westenbroek and the university of hawaii especially aly el kadi henrietta dulai craig glenn and celia smith we would also like to thank alex messina formerly at san diego state university author contributions c k s and m k e m developed the collaborative research design c k s performed all of the monitoring network and water budget components and both c k s and m k e m performed implementation of the groundwater modeling component c k s wrote the majority of the manuscript and m k e m reviewed revised and edited the manuscript this is contributed paper wrrc cp 20xx xx of the water resources research center university of hawaii at manoa honolulu hawaii soest publication funding for this project was provided by the usgs water resources research institute program wrrip grant numbers 2015as443b 2015as445b 2018as488b and noaa s pacific regional integrated sciences and assessments program pacific risa grant number na15oar4310146 
26043,the hidropixel high resolution pixel to pixel distributed hydrological simulation approach was proposed based on digital elevation model dem and adaptations of the curve number and unit hydrograph methods this paper presents a reference evaluation of hidropixel showing how sensible the model is to spatial resolution and assessing the effect of different dem data sources a small peri urban brazilian catchment 6 km2 is studied using a 1 m lidar dem 6 million pixels and aggregated 2 m 10 m and 30 m and srtm 30 m resolutions peak flows were satisfactorily reproduced with model performance decreasing with the spatial resolution coarsening which tended to shorten the flow paths and underestimate the drainage area for short and concentrated rain events peak times were anticipated best results were obtained by adjusting the initial losses parameter this methodology could easily be applied to other catchments incorporating high resolution dem and simulating both land use changes and spatial rainfall variability keywords rainfall runoff lidar spatial resolution digital elevation model terrain modeling 1 introduction one of the ways to improve hydrological models is the incorporation of the spatial variability of the physical characteristics of the basin both for large basins tens of thousands of square kilometers and small basins urban or rural basins covering a few square kilometers in this sense distributed hydrological models have been proposed and applied and they take advantage of the greater availability of diverse spatial data e g topography soil types land use the ease of integration of these data into hydrological models using geoprocessing tools and geographic information systems giss and the increase in the available computational capacity white 1988 maidment et al 1996 bates 2012 sheffield et al 2018 kite and pietroniro 1996 pina et al 2016 moglen 2000 in particular distributed modeling is impacted by improvements in topographic representation obtained through digital elevation models dems and the development of procedures for the automated processing of dems for the extraction of different types of products such as flow paths river drainage network lengths and slopes of river reaches olivera 2001 pullar and springer 2000 paz and collischonn 2007 in the last years several authors explored dems obtained from high definition surveys such as lidar light detection and ranging and satellite products including aw3d tadono et al 2015 on the improvement of topographic representations e g zhang et al 2019 the drainage network e g roelens et al 2018 maderal et al 2016 moretti and orlandini 2018 and hydrological simulations e g meesuk et al 2015 lopez and maxwell 2016 noh et al 2018 advances in the representation of land surfaces and drainage networks are particularly important for urban drainage studies consequently several methods used for urban drainage have been developed or revised to make better use of remote sensing information and modern geoprocessing techniques gironás et al 2010 verma et al 2017 du et al 2009 jena et al 2012 gibbs et al 2010 sarangi et al 2006 grimaldi et al 2012 pina et al 2016 melesse and graham 2004 moglen 2000 bartlett et al 2016 rodriguez et al 2005 sanzana et al 2017 the diversity of the proposed models and approaches is vast and each methodology is suitable for a given situation according to the objectives of the study the characteristics of the area and the availability of data among other factors singh and frevert 2006 zoppou 2001 fread 1992 gironás et al 2010 for example in developing countries and especially in brazil upgrades of stormwater facilities are often designed with very limited data and engineers must be creative in developing approaches to improve stormwater management for instance the existing system plans may be non existent or miss key information the design rainfall criteria may not be specified watershed monitoring data is usually sparse and pre development conditions are poorly documented as funding for data collection is limited and must compete with other population needs e g goldenfum et al 2007 pmpa 2005 in this light several good approaches e g rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 to correctly simulate urban systems could not be applied to the region and methods must rely on the available information in this sense it is desirable to seek a compromise between the level of detail of the model representation the accuracy required by the study objectives and the computational efficiency dottori et al 2013 on the other hand several simplified rainfall runoff modeling approaches have been proposed for the estimation of small scale project hydrographs in basins lacking data however the curve number cn methodology proposed by the u s natural resources conservation service nrcs formerly scs scs 1972 usda 2007 combined with the triangular unit hydrograph tuh also known as tr55 usda 1986 2007 is still the most commonly used method in macrodrainage because of its simplicity ease of use and widespread acceptance verma et al 2017 rajib and merwade 2016 bartlett et al 2016 garen and moore 2005 ponce and hawkins 1996 babu and mishra n d several disadvantages and criticisms of the nrcs cn method have been presented in the literature such as that the method considers the basin as lumped was developed based on regional data from agricultural areas sets the initial abstractions at 20 of the maximum storage capacity of the basin and does not incorporate scale effects ponce and hawkins 1996 ogden et al 2017 garen and moore 2005 however the experience peer acceptance and familiarity with this hydrological model have strongly influenced the preference for its use often even when other approaches may be more suitable for an application addor and melsen 2019 garen and moore 2005 the existence of tables and graphs that enable its satisfactory use with a variety of soil type and land use conditions has also contributed to the wide use of the cn method nearing et al 1996 in addition to being widely used for hydraulic structure projects the cn method has also been used for hydrological simulations of the effect of urbanization zhang and pan 2014 shuster et al 2005 dozens of modifications have been proposed since the original development of the nrcs cn method and continue to be presented in the scientific literature with different focuses including a to propose changes in the formulation of the method with other relationships between the main variables e g ajmal and kim 2015 bartlett et al 2016 jain et al 2006 babu and mishra n d sahu et al 2010 mishra et al 2014 b to test and recommend calibrations of coefficients that were originally considered to be constants e g jain et al 2006 woodward et al 2003 d asaro et al 2014 c to present calibration approaches for the cn parameter ajmal and kim 2015 d asaro et al 2014 schneider and mccuen 2005 stewart et al 2012 ponce and hawkins 1996 cunha et al 2015 d to propose alternatives to the recommended cn values based on soil infiltration tests christianson et al 2016 e to obtain cn values for surfaces not covered by the method s recommendations such as green roofs fassman beck et al 2016 f to adapt the method for continuous hydrological simulations williams et al 2012 sahu et al 2010 g to incorporate the effects of variations in the intensity and duration of precipitation babu and mishra n d h to incorporate the antecedent soil moisture conditions in the formulation of the estimated excess rainfall durán barroso et al 2016 michel et al 2005 and i to adapt the methodology to consider the spatial variability of the physical characteristics of the basin to make the method applicable in a distributed way verma et al 2017 jena et al 2012 paudel et al 2006 melesse and graham 2004 grove et al 1998 white 1988 moglen 2000 bartlett et al 2016 in parallel studies of the unit hydrograph uh theory have been developed by proposing modifications to the formulation itself duband et al 1993 including a the adjustment of empirical coefficients for a synthetic uh tucci 2003 b the development of a geomorphological uh grimaldi et al 2012 moussa 2009 sarangi et al 2006 rodriguez et al 2005 and c the use of gis platforms or remote sensing data to apply to the uh gibbs et al 2010 grimaldi et al 2012 noto and la loggia 2007 sarangi et al 2006 maidment et al 1996 paudel et al 2006 sanzana et al 2017 in the scope of the uh theory the synthetic tuh proposed by the nrcs is the most widely used method which is usually combined with the runoff generation estimate of the cn method in the traditional nrcs cn tuh version which currently predominates the formulation for determining the excess rainfall and unit hydrograph is applied by considering the basin as a lumped entity however for hydrological simulations of land use changes the spatial variability is a key element due to the significant spatial heterogeneity elga et al 2015 moglen 2000 melesse and graham 2004 pina et al 2016 which also allows the identification of how each portion of the basin contributes to the flow at a certain site greene and cruise 1995 depending on the characteristics of the region the spatial variability of the rainfall may also be relevant for hydrological simulations e g cristiano et al 2019 lobligeois et al 2014 smith et al 2004 and in urban regions the anthropic effects over the connectivity of surface and subsurface flow paths rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 this research presents an approach to high spatial resolution pixel to pixel distributed hydrological simulations using dem processing tools and adaptations of the nrcs cn and nrcs tuh methods this hydrological model called hidropixel was initially presented by costa et al 2019 and allowed the distributed estimation of the flow rates without a significant increase in the required inputs or computational information compared to the traditional nrcs cn tuh methodology in this sense the model was targeted to aid urban design studies in small catchments focused on scarce data regions in developing countries where data is hard to acquire and if it openly exists it often has questionable quality e g williams et al 2014 this paper has three major objectives i to be a reference evaluation of hidropixel which is different from existing distributed approaches for the nrcs cn tuh methodology and thus enhancing the first analysis and proposition of this model presented in the earlier paper costa et al 2019 ii to show how sensible the model is to spatial resolution and the sources of sensitivity iii and to assess the effect of considering different data sources for the dem a small peri urban basin catchment called saint hilaire which is located in the arroio dilúvio river basin in porto alegre southern brazil is used as a case study due to the availability of data of observed rainfall and flow events and a high spatial resolution dem based on lidar data the effect of the spatial resolution is investigated by degrading this dem to resolutions of 2 m 10 m and 30 m and comparing these results with a dem from 30 m shuttle radar topography mission srtm data 2 methodology 2 1 characterization of the study area the saint hilaire catchment has a drainage area of approximately 6 km2 and is located on the border between the municipalities of porto alegre and viamão in the state of rio grande do sul southern brazil fig 1 this region includes the saint hilaire natural park and is part of the arroio dilúvio river basin in this light has been mostly preserved in natural conditions historically this region contained large areas of farming and livestock lands and rural characteristics predominate even after the region underwent an industrial expansion and rapid population growth in the 1960s and 1970s according to historical records and the analysis of land use and vegetation cover based on images from the landsat 5 tm sensor satellite from august 1987 the cover of this region was characterized as urban areas 12 exposed soil 15 and natural vegetation 73 2 2 observed rainfall and flow event data the available rainfall and flow data are part of a monitoring study carried out throughout the arroio dilúvio river basin which was supported by 11 linigraphs and 14 rain gauges from 1978 to 1982 silveira 2000 the linigraph and rain gauge networks operated automatically and recorded the observed rainfall and flow on paper every 30 min this temporal resolution was not ideal for all of the catchments involved in the project due to the speed of flood events in urbanized areas silveira 1996 2000 despite these limitations these data have been used for hydrological modeling studies in the region silveira and desbordes 1999 motta and tucci 1984 silveira et al 1998 diaz and tucci 1987 tucci 2003 for this study data were made available from the former water and sewer department of porto alegre dep in portuguese and the flow database of brazilian urban basins tucci et al 1998 eighteen rainfall and flow events were selected table 1 and the surface runoff was separated from groundwater using the graphical method 2 3 digital elevation model processing two data sources were used to obtain the dems i 30 m srtm data spatial resolution of 30 m which were available free of charge rabus et al 2003 and ii data collected by a lidar survey of the entire city of porto alegre in august 2010 and made available by the former porto alegre s department of rainwater engineering dep which had a spatial resolution of 1 m zanardi et al 2013 important to note that dems are from the 2010s and data from the early 1980s however as this region has been mostly a natural park drainage conditions have not changed significantly over the years in general the 30 m srtm dem and the 1 m lidar dtm had the same pattern of terrain elevation variation fig 2 but the lidar dtm clearly showed greater details of the topographic gradient and the srtm dem tends to overestimate the elevations due either to the grouping of information into 30 m pixels or to the influence of vegetation or buildings these artifacts over surface terrain were removed from 1 m lidar digital surface model dsm to obtain the corresponding dtm the difference between dsm and dtm highlights how vegetation and buildings were removed approximately 37 2 of the catchment showed a difference of fewer than 1 m between the dsm and the dtm 17 5 of the catchment had a difference between 1 and 5 m the dsm was 5 15 m higher than the dtm in 40 of the catchment area and for approximately 5 3 this difference was higher than 15 m several studies have indicated that the cell size of a dem may have a greater impact on hydrological modeling than the method by which the dem was produced e g murphy et al 2008 yang et al 2014 therefore the lidar data were resampled via bilinear interpolation to generate degraded dtms with spatial resolutions of 2 10 and 30 m table 2 the basin discretization ranged from nearly 6 million pixels hyper resolution with a spatial resolution of 1 m to less than 6500 pixels at the lower spatial resolution of 30 m for each dem and dtm the procedure for obtaining the flow directions for one of the eight neighbors was performed through a priority first search pfs algorithm as described in sedgewick 1992 and used by jones 2002 the pfs algorithm implemented in the terrset software clark labs 2019 was used and consisted of two stages for the removal of depressions i searching for a path that directs the flow out of the depression and ii adjusting the elevations of the pixels along the flow path to decrease monotonically based on the flow directions the accumulated drainage areas were obtained and the river basin was delimited a reference drainage network hasenack et al 2008 was considered to determine the starting points of the drainage 2 4 the hidropixel hydrologic modeling approach 2 4 1 overview hidropixel is a distributed hydrological modeling approach with pixel level discretization based on dem processing that was initially proposed by costa et al 2019 in this methodology the flow in each pixel is initially estimated based on the information about land use and type using the nrcs cn methodology then these flows are propagated by the tuh methodology to obtain the resulting pixel level hydrographs subsequently the surface flow is propagated though the basin by considering the flow paths and their characteristics e g slope extension roughness surface type hidropixel is currently fully designed in the form of computational routines in the fortran language and inputs of the model include rainfall cn and manning roughness coefficient at each pixel cn and manning roughness coefficient depends in turn of lulc and output are the basin hydrograph and travel times and hydrographs generated at each pixel 2 4 2 excess rainfall the nrcs cn method is used considering its conventional formulation for estimating excess rainfall equations 1 and 2 based on the estimation of the maximum water storage capacity s in equation 3 which is a function of the cn parameter cn is usually obtained from tables related to the land type and use assuming the antecedent moisture condition amc from the precipitation over the previous days 1 p e x c p λ s 2 p λ s s 2 p e x c 0 i f p λ s 3 s 25400 c n 254 where pexc is the excess rainfall mm s is the water storage capacity mm p is the precipitation mm λ is the initial abstraction rate and cn is a dimensionless parameter whose value ranges between 0 and 100 where 0 corresponds to a soil of infinite infiltration capacity and 100 corresponds to a completely waterproof soil the cn parameter varies as a function of three conditions soil type land use and amc in the tables of typical values from the literature whereas it is conventional to adopt the same value of λ for any basin and any rainy event in the original nrcs cn method λ 0 2 is recommended that is the initial losses in the transformation of precipitation into surface runoff are approximately 20 of the maximum storage s ponce and hawkins 1996 many studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 ogden et al 2017 have indicated that values of λ different from the original values are more representative in the application of the nrcs cn method for this reason hidropixel allows the definition of λ values different from 0 2 2 4 3 triangular unit hydrograph to obtain the hydrograph resulting from a rain event hidropixel uses the concept of the unit hydrograph using the equations proposed by the nrcs for the tuh and considering each pixel as if it has a watershed area microbasin equal to the surface of the pixel dx2 where dx is the pixel dimension the tuh generated by the pixel is triangular with the peak flow peak time and base time determined as functions of the area and concentration time of the microbasin equations 4 6 4 t p d 2 0 6 t c 5 t b 2 67 t p 6 q p 0 208 a t p where t p is the peak time h d is the duration of precipitation h t c is the time of concentration h of the microbasin following the concept described below t b is the base time h q p is the peak flow rate in m³ s 1 mm 1 and a is the basin area in this case the pixel or dx2 in km2 2 4 4 runoff travel time to apply the nrcs tuh approach it is also necessary to estimate t c of each pixel which in this study was adapted to calculate the travel time of the runoff originating in each pixel to the outlet of the basin fig 3 thus the resulting hydrograph of each pixel is already conceptually positioned at the basin outlet that is it already represents the response of that pixel in terms of its contribution to the outlet of the basin after repeating this process for each pixel the resulting hydrographs are added to obtain the final response of the basin q t o t o u t for the estimation of t c of each pixel the flow path is determined to reach the basin outlet based on the flow directions resulting from the dem processing along this flowing track we identify the path in which the surface runoff occurs ravines and grooves or is channeled into the drainage network the surface runoff stretch is subdivided according to land use into smaller homogeneous stretches with length ls and the travel time td is estimated by the tr55 method equation 7 for each small stretch the slope is taken as the elevation difference between the end and initial pixels of the stretch divided by the length ls in the example shown in fig 4 the water travels a stretch of exposed soil followed by a vegetated surface before finding the drainage network the stretch along the drainage network is also subdivided into smaller stretches that are considered homogeneous in terms of slope coefficient of roughness and cross sectional area for each stretch the manning equation is used to estimate the travel time equations 8 and 9 thus the travel time from a pixel to the outlet of the basin is given by the sum of the individual travel times of the surface stretches tds and the drainage network stretches tdd equation 10 7 t d s 5 74 n s l s 0 8 p 24 0 5 s s 0 4 8 v r h 2 3 s s 1 2 n s 9 t d d l s v 10 t d i 1 n s t d s i j 1 n d t d d j where rh is the hydraulic radius of the section m v is the runoff velocity m s ns is the manning roughness coefficient of the stretch surface or drainage network ls m and ss m m are the length and slope of the stretch respectively and p24 is the precipitation over 24 h mm for the return period of the event considered 2 4 5 application of hidropixel to the study area hidropixel was applied to the 30 m srtm dem and the lidar dtms with resolutions of 1 m 2 m 10 m and 30 m simulation time step was 1min for all resolutions and values were compared to observed hydrographs at 30min interval of the original observed data according to the soil map of the city of porto alegre hasenack et al 2008 the basin soils include red argisols and red yellow argisols with haplic cambisols according to sartori et al 2005 these soils are considered hydrological group b in the nrcs classification according to the soil types and land uses of the basin the cn values table 3 were defined for each amc based on usda 2007 for each rainfall event the amc was determined by taking the cumulative rainfall of the previous five days from the historical precipitation data of the porto alegre station code 03051011 which are available in the hidroweb system of the national water agency ana and the data of the also named porto alegre station same name but other location and code 83967 which are available from the national institute of meteorology inmet although some studies have suggested adjusting cn based on the observed rainfall and flow data this study proposes adjusting λ which we consider to be much more uncertain some authors e g schneiderman et al 2007 michel et al 2005 jain et al 2006 mishra and singh 2004 sahu et al 2010 have proposed to account for soil moisture variability to improve the accuracy of cn based models these studies showed that introducing soil moisture values in the model through the adjustment of cn or the initial abstraction improves the accuracy of the estimated runoff thus to estimate the excess rainfall the λ value of the nrcs cn method was considered variable for each event and dem dtm following previous studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 that indicated the inadequacy of the original value of 0 2 for each event spatial resolution and dtm the value of λ was selected by trial and error to identify the value that provided the lowest peak relative error other statistics used to verify the calibration were the relative error in time to peak and runoff volume as well as the best visual agreement between the observed and calculated hydrographs in contrast the cn value recommended from the literature was kept unchanged table 3 time discretization of 1 min was also adopted for the application of the distributed nrcs cn the same value was used for the duration of the unitary excess rainfall in the application of the nrcs tuh method based on the processing of the dem or dtm the distances and slopes for the surface stretches were determined in the calculation of the runoff travel time the p24 value was determined from the intensity duration frequency idf curve recommended for the basin region in the urban drainage master plan of porto alegre pmpa 2005 and considering the return period tr estimated for each event to define the manning roughness coefficient was identified the farthest point from the outlet and estimated its time of concentration using equations 7 to 10 as the flow path downstream to this point passes only through surface stretches with vegetation until reaching the drainage network and considering that this surface type represents 73 of the basin we chose to adjust manning roughness coefficient nveg by comparing the concentration times estimated from the observed rainfall and flow data tc obs and those calculated tc calc tc obs was estimated as the time elapsed from the end of the excess rainfall until the end of the surface runoff hydrograph for each event nveg was determined by trial and error and provided a better fit between tc obs and tc calc subsequently the nveg value that provided the best concordance between tc obs and tc calc for all events was determined this value was defined as nveg 0 29 for the other land use types exposed soil n 0 013 urban area n 0 024 and for the drainage channels which are considered to be of small scale and largely influenced by roughness effects caused by the vegetation or morphology n 0 08 manning roughness coefficient were chosen from the literature chow 1959 due to the lack of data trapezoidal cross sections were determined for the drainage network with four types of river stretches with homogeneous cross sectional characteristics fig 5 a and the distances of the stretches were obtained based on the reference drainage network and the slopes according to the dtm the scattering of the points between tc obs and tc calc is shown in fig 5 b 3 results and discussion 3 1 dtm dem processing and runoff travel time the length of the main river measured in the drainage network extracted from each dtm decreased with decreasing spatial resolution fig 6 from 5 10 km in the 1 m dtm to 3 98 km in the 30 m dtm decrease of 22 this decrease was about 18 8 in the 30 m srtm dem compared to the 1 m dtm this effect was identified and reported in several previous studies colombo et al 2007 heine et al 2004 and occurred because coarser resolutions have more difficulty in representing the complexities of the drainage consequently the river network becomes less sinuous and distance shortening occurs fekete et al 2001 yang et al 2014 the decrease in spatial resolution has a smaller impact on the catchment delimitation than on the length of the main river errors of commission and omission of less than 2 occur in the catchment delimitations from the resampled lidar dtm compared to the delimitation based on the lidar 1 m dtm fig 7 the difference is greater for the delimitation of the basin based on the 30 m srtm dem but it can still be considered relatively small with errors of commission and omission of less than 6 this contrasts with gironás et al 2010 results that showed much larger differences the travel times of the surface and channel runoff and the total times were obtained from the products derived from the dtms and dem and the application of the nrcs method equation fig 8 shows the results obtained from the 10 m lidar dtm and the 30 m srtm dem for the event on may 18 1979 longer surface travel times can be observed in the eastern and southeastern regions of the catchment due to the larger stretches with vegetated surfaces which are more than 16 h for the 1 m lidar dtm and 8 h for the 30 m srtm dem as expected the travel time in the channel network is much lower up to 80 min from the upstream points to the outlet the spatial variations in the total travel time are similar to the surface travel time map fig 9 shows the total travel times of the pixels for the events on may 18 1979 total rainfall of 33 mm and march 03 1980 total rainfall of 11 mm for both events it is clear that i coarsening the spatial resolution of the lidar dtm led to a decrease in the travel times as a result of the decrease in the lengths mentioned previously for example for may 18 event all basin drains with less than 700 min for 30 m resolution but takes more than 2000 min for 1 m resolution and ii for the same spatial resolution 30 m the travel times obtained from the srtm data are systematically lower than those obtained based on the lidar data we can also observe the effect of the larger size of the event on 05 18 1979 which resulted in shorter travel times than in the 03 03 1980 event this result highlights the positive characteristics of the travel time estimation method which allows rainfall events to be differentiated by considering the parameter p24 in the formulation the dependence of the basin time of concentration on the event intensity is a striking feature of the nonlinearity of the rainfall runoff transformation that hinders the reproduction of the flows observed by hydrological models michailidi et al 2018 3 2 initial losses scale effect and model calibration the fitted initial losses during almost all of the events are lower than the original value used in the method 20 or λ 0 2 fig 10 corroborating the results of other studies e g ajmal and kim 2015 shi et al 2009 that indicated that this value is too high and recommended λ values of approximately 0 05 a recent study by lautharte 2015 on catchments in the arroio dilúvio river basin also indicated a λ value of approximately 0 05 it should be noted that in this study we did not calibrate the cn parameter but rather used the recommended value from the literature and calibrate λ the results indicated that there was a general pattern in which the lower the amc was the lower the adjusted λ value was that is the drier the moisture conditions were the lower the value of λ required to reduce the losses to fit the simulation to the observed data better the inverse was also true the wetter the amc conditions were the greater the fitted value of λ was these results contradict the use of the same value of λ for any event or amc condition this is somewhat consistent with the actual rainfall runoff transformation process which does not occur with constant initial losses for every event and moisture condition moreover the flow generation is nonlinear and different parts of the catchment contribute differently to the flow in time and space due to the simplified formulation proposed in the nrcs cn which does not represent this spatiotemporal variation and does not explicitly consider the soil moisture conditions the variation in λ as a function of the antecedent soil moisture may be a reasonable counterbalance also there are alternative approaches to the original nrcs cn method that explicitly incorporate the total antecedent rainfall over the previous 5 day as a quantitative variable when calculating the excess rainfall e g jain et al 2006 babu and mishra n d sahu et al 2010 as well as approaches that propose to directly incorporate a state variable related to the soil moisture in the excess rainfall formulation e g durán barroso et al 2016 michel et al 2005 these efforts follow the growing line of research that incorporates soil moisture as an improvement to hydrological modeling for hydrological flood studies cea and fraga 2018 schoener and stone 2019 hettiarachchi et al 2019 the adjusted values of λ are very similar for simulations considering the dtms and dem and these values decrease slightly with the coarsening in the spatial resolution in the formulation of the cn method a smaller λ value entails fewer initial losses and a greater volume of water that turns into runoff the slight tendency for the basin area to decrease with spatial resolution coarsening as illustrated in fig 7 contributed to the slight increase in λ to compensate for the smaller runoff generation area however it can be noted an overall concordance of adjusted λ among spatial resolutions for each rainfall runoff event for instance the variation among events is much larger than among spatial resolutions in this work the λ value for each event and each simulated dtm and dem was allowed to be adjusted to provide this understanding of the scale effect and the initial moisture conditions in practice however the adjustment of this parameter for each simulation is not recommended future research will evaluate an alternative formulation that incorporates the soil moisture conditions in the λ equation or directly from the excess rainfall while considering the spatial heterogeneity of the physical characteristics of the river basin 3 2 1 model performance with the highest spatial resolution dem a comparison between the calculated and observed hydrographs generated from the 1 m lidar dtm is shown in fig 11 one first analysis is a comparison between the calculated and the observed hydrographs using λ 0 2 for several events such as those on 16feb1980 and 31aug1980 no surface flow was generated with λ 0 2 however with λ 0 02 and 0 05 the hydrograph was properly simulated in events such as those on 03aug1979 and 05dec1981 λ 0 2 generated flow but it was much less than expected the hydrographs for these events were only reproduced satisfactorily when setting λ to 0 11 and 0 13 respectively a few events had atypical behaviors such as that on 20sep1981 amc iii in which fitted λ ranged between 0 65 and 0 7 and that on 03mar1980 also amc iii in which λ was less than 0 05 the spatial heterogeneity of the rainfall may be one reason for such a difference between these events as the amc was estimated from a rain gauge outside the basin 3 2 2 model performance considering different dem sources and spatial resolutions at the highest available spatial resolution 1 m lidar dtm the observed hydrographs were reproduced satisfactorily when λ was adjusted but there were different performances among the events qp was underestimated in 15 of the 18 events but with relative errors res bellow 12 except for two of the lowest events observed which had re of approximately 20 figs 12 and 13 in the estimates of the total drained volume tdv and peak time tp the res were higher than those of qp mostly showing an underestimation of the observed values that is although the method satisfactorily represented the hydrographs it had difficulties in reproducing the volume of and delay in the observed runoff the absolute errors in qp tp and tdv are also shown in fig 12 and present the same inter event variability patterns these results were somehow expected as the proposed model does not directly represent anthropic effects over the connectivity of surface and subsurface flow paths such as roads and or sewer networks see for instance rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 as its aims at scarce data regions even if this is a very common approach in urban storm water modeling gironás et al 2010 and has been applied successfully by several authors e g doan 2000 jordan and grimison 2001 barco et al 2008 with similar results to the presented in this paper and especially with good results with previous version of hidropixel e g costa et al 2019 should be noted for instance gironás et al 2010 reported errors of up to 30 in peak discharge when the channel system is not explicitly represented however it is worth noting that the three events with the greatest relative errors in tp 05feb80 31may80 and 14dec80 numbered as 4 7 and 12 in fig 12 were extremely concentrated they last just 2 or 3 time steps in terms of the 30 min records and more than 93 of the total precipitation occurred in the first instant of the recorded time this demonstrates that the time step of recording the events made it difficult to estimate the temporal variation of the storm and the consequent rainfall runoff modeling coarsening the spatial resolution of the lidar dtms the simulation results led to patterns similar to those reported for the 1 m lidar dtm fig 14 however the decrease in spatial resolution tended to result in even greater underestimations of tp and tdv this outcome occurred because shorter flow paths were obtained with increasing pixel size reducing the runoff travel time increasing the underestimation of the peak time and causing the runoff from several parts of the basin to arrive in a more concentrated manner and thus increase qp in contrast the greater underestimation of the runoff volume is related to the decrease in the size of the basin with increasing pixel size the purpose of varying λ according to dtm or dem spatial resolution was also to detect how much the adjustment of this parameter could vary according to pixel size however considering the model as calibrated using 1 m lidar data the highest dem resolution was carried out a group of model runs keeping constant the value of λ while coarsening the spatial resolution results showed that with 2 m 10 m and 30 m spatial resolutions the coarsening led to peak flow increase by approximately 7 9 31 0 and 53 4 respectively fig 15 in contrast time to peak decreased by 1 6 6 3 and 9 2 respectively due to grid coarsening from 1 m to 2 m 10 m and 30 m runoff does not show significant changes 0 4 within the spatial resolution degradation in a slight oversimplified way it could be expressed that for every meter in cell size increase a non linear mean increase of 2 in peak flow and a more constant decrease of 0 5 in peak time is expected 4 summary and conclusions as correctly pointed out by moglen 2000 there is a trend in hydrological modeling that spatial resolutions are increasing due to the myriad of information available this study proposed an approach to the hydrological simulation by adapting the nrcs cn and nrcs tuh methods to work in a distributed manner the hydrological model called hidropixel which was initially presented by costa et al 2019 allows for a distributed estimation of the flow rates with little additional information compared to the traditional nrcs cn tuh methodology despite the various disadvantages and criticisms of the nrcs cn tuh method that have been presented in the literature a methodology based on it was chosen focusing on scarce data regions in developing countries but taking advantage of freely available remote sensing data the results obtained from the case study showed the potential of this methodology for estimating hydrographs based on rainfall as well as the basic and commonly available data required for most hydrological studies such as dems soil types land use types and the general characteristics of the drainage network cross section and slope improved results were obtained by calibrating the parameter representative of the initial losses showing consistency with the results of several previous studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 we also observed a relationship between this adjusted value and the amc highlighting the importance of incorporating soil moisture as proposed by several authors e g jain et al 2006 babu and mishra n d sahu et al 2010 durán barroso et al 2016 michel et al 2005 this will be evaluated in future studies using the distributed approach presented herein the combination of the adjusted λ parameter and cn may also be evaluated but such an evaluation was not performed in this study the performance of the proposed approach to reproduce the observed hydrographs was generally satisfactory to reproduce for peak flows 15 out of 18 events had relative errors of about 12 or less however this performance was not reliable for most events for time to peak and runoff volume with almost consistent underestimations it is also worth noting that the existing formulations in the literature were adjusted to the scale available at the time of their determination and that their application to smaller scales may introduce inconsistencies the need to evaluate the use of other formulations to estimate the runoff travel time is clear however it must be creative to explore the available data the performance also decreased with spatial resolution coarsening which tended to shorten the flow paths and underestimate the basin area and particularly affected the simulation flow travel times nevertheless there was also a tendency to underestimate the peak times due to the difficulty in simulating extremely short and concentrated rain events relative to the temporal resolution of the available information the methodology showed the potential for simulating peak flows in data deprived regions hidropixel can represent land use changes by explicitly considering the spatial variability of the physical characteristics of the basin which could also consider the spatial variability of rainfall and its effect on the formation of floods with little additional information compared to the traditional nrcs cn tuh methodology despite the parameter representative of initial losses λ showing variation when changing spatial resolution its variation was much larger between rainfall runoff events thus for recommending the application of hidropixel for other sites further studies are needed in order to overcome this issue perhaps by evaluating an alternative formulation that incorporates the soil moisture conditions in the λ estimative or directly from the excess rainfall declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by scholarships from coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 to the first two authors and from conselho nacional de desenvolvimento científico e tecnológico cnpq brazil to the last three authors and was also funded as a research project by cnpq edital universal 420936 2016 5 coordinated by the fourth author the authors also thank the data provided by former dep prefeitura de porto alegre especially to the engineers stanley amaral and daniela bemfica for their contributions appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104695 
26043,the hidropixel high resolution pixel to pixel distributed hydrological simulation approach was proposed based on digital elevation model dem and adaptations of the curve number and unit hydrograph methods this paper presents a reference evaluation of hidropixel showing how sensible the model is to spatial resolution and assessing the effect of different dem data sources a small peri urban brazilian catchment 6 km2 is studied using a 1 m lidar dem 6 million pixels and aggregated 2 m 10 m and 30 m and srtm 30 m resolutions peak flows were satisfactorily reproduced with model performance decreasing with the spatial resolution coarsening which tended to shorten the flow paths and underestimate the drainage area for short and concentrated rain events peak times were anticipated best results were obtained by adjusting the initial losses parameter this methodology could easily be applied to other catchments incorporating high resolution dem and simulating both land use changes and spatial rainfall variability keywords rainfall runoff lidar spatial resolution digital elevation model terrain modeling 1 introduction one of the ways to improve hydrological models is the incorporation of the spatial variability of the physical characteristics of the basin both for large basins tens of thousands of square kilometers and small basins urban or rural basins covering a few square kilometers in this sense distributed hydrological models have been proposed and applied and they take advantage of the greater availability of diverse spatial data e g topography soil types land use the ease of integration of these data into hydrological models using geoprocessing tools and geographic information systems giss and the increase in the available computational capacity white 1988 maidment et al 1996 bates 2012 sheffield et al 2018 kite and pietroniro 1996 pina et al 2016 moglen 2000 in particular distributed modeling is impacted by improvements in topographic representation obtained through digital elevation models dems and the development of procedures for the automated processing of dems for the extraction of different types of products such as flow paths river drainage network lengths and slopes of river reaches olivera 2001 pullar and springer 2000 paz and collischonn 2007 in the last years several authors explored dems obtained from high definition surveys such as lidar light detection and ranging and satellite products including aw3d tadono et al 2015 on the improvement of topographic representations e g zhang et al 2019 the drainage network e g roelens et al 2018 maderal et al 2016 moretti and orlandini 2018 and hydrological simulations e g meesuk et al 2015 lopez and maxwell 2016 noh et al 2018 advances in the representation of land surfaces and drainage networks are particularly important for urban drainage studies consequently several methods used for urban drainage have been developed or revised to make better use of remote sensing information and modern geoprocessing techniques gironás et al 2010 verma et al 2017 du et al 2009 jena et al 2012 gibbs et al 2010 sarangi et al 2006 grimaldi et al 2012 pina et al 2016 melesse and graham 2004 moglen 2000 bartlett et al 2016 rodriguez et al 2005 sanzana et al 2017 the diversity of the proposed models and approaches is vast and each methodology is suitable for a given situation according to the objectives of the study the characteristics of the area and the availability of data among other factors singh and frevert 2006 zoppou 2001 fread 1992 gironás et al 2010 for example in developing countries and especially in brazil upgrades of stormwater facilities are often designed with very limited data and engineers must be creative in developing approaches to improve stormwater management for instance the existing system plans may be non existent or miss key information the design rainfall criteria may not be specified watershed monitoring data is usually sparse and pre development conditions are poorly documented as funding for data collection is limited and must compete with other population needs e g goldenfum et al 2007 pmpa 2005 in this light several good approaches e g rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 to correctly simulate urban systems could not be applied to the region and methods must rely on the available information in this sense it is desirable to seek a compromise between the level of detail of the model representation the accuracy required by the study objectives and the computational efficiency dottori et al 2013 on the other hand several simplified rainfall runoff modeling approaches have been proposed for the estimation of small scale project hydrographs in basins lacking data however the curve number cn methodology proposed by the u s natural resources conservation service nrcs formerly scs scs 1972 usda 2007 combined with the triangular unit hydrograph tuh also known as tr55 usda 1986 2007 is still the most commonly used method in macrodrainage because of its simplicity ease of use and widespread acceptance verma et al 2017 rajib and merwade 2016 bartlett et al 2016 garen and moore 2005 ponce and hawkins 1996 babu and mishra n d several disadvantages and criticisms of the nrcs cn method have been presented in the literature such as that the method considers the basin as lumped was developed based on regional data from agricultural areas sets the initial abstractions at 20 of the maximum storage capacity of the basin and does not incorporate scale effects ponce and hawkins 1996 ogden et al 2017 garen and moore 2005 however the experience peer acceptance and familiarity with this hydrological model have strongly influenced the preference for its use often even when other approaches may be more suitable for an application addor and melsen 2019 garen and moore 2005 the existence of tables and graphs that enable its satisfactory use with a variety of soil type and land use conditions has also contributed to the wide use of the cn method nearing et al 1996 in addition to being widely used for hydraulic structure projects the cn method has also been used for hydrological simulations of the effect of urbanization zhang and pan 2014 shuster et al 2005 dozens of modifications have been proposed since the original development of the nrcs cn method and continue to be presented in the scientific literature with different focuses including a to propose changes in the formulation of the method with other relationships between the main variables e g ajmal and kim 2015 bartlett et al 2016 jain et al 2006 babu and mishra n d sahu et al 2010 mishra et al 2014 b to test and recommend calibrations of coefficients that were originally considered to be constants e g jain et al 2006 woodward et al 2003 d asaro et al 2014 c to present calibration approaches for the cn parameter ajmal and kim 2015 d asaro et al 2014 schneider and mccuen 2005 stewart et al 2012 ponce and hawkins 1996 cunha et al 2015 d to propose alternatives to the recommended cn values based on soil infiltration tests christianson et al 2016 e to obtain cn values for surfaces not covered by the method s recommendations such as green roofs fassman beck et al 2016 f to adapt the method for continuous hydrological simulations williams et al 2012 sahu et al 2010 g to incorporate the effects of variations in the intensity and duration of precipitation babu and mishra n d h to incorporate the antecedent soil moisture conditions in the formulation of the estimated excess rainfall durán barroso et al 2016 michel et al 2005 and i to adapt the methodology to consider the spatial variability of the physical characteristics of the basin to make the method applicable in a distributed way verma et al 2017 jena et al 2012 paudel et al 2006 melesse and graham 2004 grove et al 1998 white 1988 moglen 2000 bartlett et al 2016 in parallel studies of the unit hydrograph uh theory have been developed by proposing modifications to the formulation itself duband et al 1993 including a the adjustment of empirical coefficients for a synthetic uh tucci 2003 b the development of a geomorphological uh grimaldi et al 2012 moussa 2009 sarangi et al 2006 rodriguez et al 2005 and c the use of gis platforms or remote sensing data to apply to the uh gibbs et al 2010 grimaldi et al 2012 noto and la loggia 2007 sarangi et al 2006 maidment et al 1996 paudel et al 2006 sanzana et al 2017 in the scope of the uh theory the synthetic tuh proposed by the nrcs is the most widely used method which is usually combined with the runoff generation estimate of the cn method in the traditional nrcs cn tuh version which currently predominates the formulation for determining the excess rainfall and unit hydrograph is applied by considering the basin as a lumped entity however for hydrological simulations of land use changes the spatial variability is a key element due to the significant spatial heterogeneity elga et al 2015 moglen 2000 melesse and graham 2004 pina et al 2016 which also allows the identification of how each portion of the basin contributes to the flow at a certain site greene and cruise 1995 depending on the characteristics of the region the spatial variability of the rainfall may also be relevant for hydrological simulations e g cristiano et al 2019 lobligeois et al 2014 smith et al 2004 and in urban regions the anthropic effects over the connectivity of surface and subsurface flow paths rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 this research presents an approach to high spatial resolution pixel to pixel distributed hydrological simulations using dem processing tools and adaptations of the nrcs cn and nrcs tuh methods this hydrological model called hidropixel was initially presented by costa et al 2019 and allowed the distributed estimation of the flow rates without a significant increase in the required inputs or computational information compared to the traditional nrcs cn tuh methodology in this sense the model was targeted to aid urban design studies in small catchments focused on scarce data regions in developing countries where data is hard to acquire and if it openly exists it often has questionable quality e g williams et al 2014 this paper has three major objectives i to be a reference evaluation of hidropixel which is different from existing distributed approaches for the nrcs cn tuh methodology and thus enhancing the first analysis and proposition of this model presented in the earlier paper costa et al 2019 ii to show how sensible the model is to spatial resolution and the sources of sensitivity iii and to assess the effect of considering different data sources for the dem a small peri urban basin catchment called saint hilaire which is located in the arroio dilúvio river basin in porto alegre southern brazil is used as a case study due to the availability of data of observed rainfall and flow events and a high spatial resolution dem based on lidar data the effect of the spatial resolution is investigated by degrading this dem to resolutions of 2 m 10 m and 30 m and comparing these results with a dem from 30 m shuttle radar topography mission srtm data 2 methodology 2 1 characterization of the study area the saint hilaire catchment has a drainage area of approximately 6 km2 and is located on the border between the municipalities of porto alegre and viamão in the state of rio grande do sul southern brazil fig 1 this region includes the saint hilaire natural park and is part of the arroio dilúvio river basin in this light has been mostly preserved in natural conditions historically this region contained large areas of farming and livestock lands and rural characteristics predominate even after the region underwent an industrial expansion and rapid population growth in the 1960s and 1970s according to historical records and the analysis of land use and vegetation cover based on images from the landsat 5 tm sensor satellite from august 1987 the cover of this region was characterized as urban areas 12 exposed soil 15 and natural vegetation 73 2 2 observed rainfall and flow event data the available rainfall and flow data are part of a monitoring study carried out throughout the arroio dilúvio river basin which was supported by 11 linigraphs and 14 rain gauges from 1978 to 1982 silveira 2000 the linigraph and rain gauge networks operated automatically and recorded the observed rainfall and flow on paper every 30 min this temporal resolution was not ideal for all of the catchments involved in the project due to the speed of flood events in urbanized areas silveira 1996 2000 despite these limitations these data have been used for hydrological modeling studies in the region silveira and desbordes 1999 motta and tucci 1984 silveira et al 1998 diaz and tucci 1987 tucci 2003 for this study data were made available from the former water and sewer department of porto alegre dep in portuguese and the flow database of brazilian urban basins tucci et al 1998 eighteen rainfall and flow events were selected table 1 and the surface runoff was separated from groundwater using the graphical method 2 3 digital elevation model processing two data sources were used to obtain the dems i 30 m srtm data spatial resolution of 30 m which were available free of charge rabus et al 2003 and ii data collected by a lidar survey of the entire city of porto alegre in august 2010 and made available by the former porto alegre s department of rainwater engineering dep which had a spatial resolution of 1 m zanardi et al 2013 important to note that dems are from the 2010s and data from the early 1980s however as this region has been mostly a natural park drainage conditions have not changed significantly over the years in general the 30 m srtm dem and the 1 m lidar dtm had the same pattern of terrain elevation variation fig 2 but the lidar dtm clearly showed greater details of the topographic gradient and the srtm dem tends to overestimate the elevations due either to the grouping of information into 30 m pixels or to the influence of vegetation or buildings these artifacts over surface terrain were removed from 1 m lidar digital surface model dsm to obtain the corresponding dtm the difference between dsm and dtm highlights how vegetation and buildings were removed approximately 37 2 of the catchment showed a difference of fewer than 1 m between the dsm and the dtm 17 5 of the catchment had a difference between 1 and 5 m the dsm was 5 15 m higher than the dtm in 40 of the catchment area and for approximately 5 3 this difference was higher than 15 m several studies have indicated that the cell size of a dem may have a greater impact on hydrological modeling than the method by which the dem was produced e g murphy et al 2008 yang et al 2014 therefore the lidar data were resampled via bilinear interpolation to generate degraded dtms with spatial resolutions of 2 10 and 30 m table 2 the basin discretization ranged from nearly 6 million pixels hyper resolution with a spatial resolution of 1 m to less than 6500 pixels at the lower spatial resolution of 30 m for each dem and dtm the procedure for obtaining the flow directions for one of the eight neighbors was performed through a priority first search pfs algorithm as described in sedgewick 1992 and used by jones 2002 the pfs algorithm implemented in the terrset software clark labs 2019 was used and consisted of two stages for the removal of depressions i searching for a path that directs the flow out of the depression and ii adjusting the elevations of the pixels along the flow path to decrease monotonically based on the flow directions the accumulated drainage areas were obtained and the river basin was delimited a reference drainage network hasenack et al 2008 was considered to determine the starting points of the drainage 2 4 the hidropixel hydrologic modeling approach 2 4 1 overview hidropixel is a distributed hydrological modeling approach with pixel level discretization based on dem processing that was initially proposed by costa et al 2019 in this methodology the flow in each pixel is initially estimated based on the information about land use and type using the nrcs cn methodology then these flows are propagated by the tuh methodology to obtain the resulting pixel level hydrographs subsequently the surface flow is propagated though the basin by considering the flow paths and their characteristics e g slope extension roughness surface type hidropixel is currently fully designed in the form of computational routines in the fortran language and inputs of the model include rainfall cn and manning roughness coefficient at each pixel cn and manning roughness coefficient depends in turn of lulc and output are the basin hydrograph and travel times and hydrographs generated at each pixel 2 4 2 excess rainfall the nrcs cn method is used considering its conventional formulation for estimating excess rainfall equations 1 and 2 based on the estimation of the maximum water storage capacity s in equation 3 which is a function of the cn parameter cn is usually obtained from tables related to the land type and use assuming the antecedent moisture condition amc from the precipitation over the previous days 1 p e x c p λ s 2 p λ s s 2 p e x c 0 i f p λ s 3 s 25400 c n 254 where pexc is the excess rainfall mm s is the water storage capacity mm p is the precipitation mm λ is the initial abstraction rate and cn is a dimensionless parameter whose value ranges between 0 and 100 where 0 corresponds to a soil of infinite infiltration capacity and 100 corresponds to a completely waterproof soil the cn parameter varies as a function of three conditions soil type land use and amc in the tables of typical values from the literature whereas it is conventional to adopt the same value of λ for any basin and any rainy event in the original nrcs cn method λ 0 2 is recommended that is the initial losses in the transformation of precipitation into surface runoff are approximately 20 of the maximum storage s ponce and hawkins 1996 many studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 ogden et al 2017 have indicated that values of λ different from the original values are more representative in the application of the nrcs cn method for this reason hidropixel allows the definition of λ values different from 0 2 2 4 3 triangular unit hydrograph to obtain the hydrograph resulting from a rain event hidropixel uses the concept of the unit hydrograph using the equations proposed by the nrcs for the tuh and considering each pixel as if it has a watershed area microbasin equal to the surface of the pixel dx2 where dx is the pixel dimension the tuh generated by the pixel is triangular with the peak flow peak time and base time determined as functions of the area and concentration time of the microbasin equations 4 6 4 t p d 2 0 6 t c 5 t b 2 67 t p 6 q p 0 208 a t p where t p is the peak time h d is the duration of precipitation h t c is the time of concentration h of the microbasin following the concept described below t b is the base time h q p is the peak flow rate in m³ s 1 mm 1 and a is the basin area in this case the pixel or dx2 in km2 2 4 4 runoff travel time to apply the nrcs tuh approach it is also necessary to estimate t c of each pixel which in this study was adapted to calculate the travel time of the runoff originating in each pixel to the outlet of the basin fig 3 thus the resulting hydrograph of each pixel is already conceptually positioned at the basin outlet that is it already represents the response of that pixel in terms of its contribution to the outlet of the basin after repeating this process for each pixel the resulting hydrographs are added to obtain the final response of the basin q t o t o u t for the estimation of t c of each pixel the flow path is determined to reach the basin outlet based on the flow directions resulting from the dem processing along this flowing track we identify the path in which the surface runoff occurs ravines and grooves or is channeled into the drainage network the surface runoff stretch is subdivided according to land use into smaller homogeneous stretches with length ls and the travel time td is estimated by the tr55 method equation 7 for each small stretch the slope is taken as the elevation difference between the end and initial pixels of the stretch divided by the length ls in the example shown in fig 4 the water travels a stretch of exposed soil followed by a vegetated surface before finding the drainage network the stretch along the drainage network is also subdivided into smaller stretches that are considered homogeneous in terms of slope coefficient of roughness and cross sectional area for each stretch the manning equation is used to estimate the travel time equations 8 and 9 thus the travel time from a pixel to the outlet of the basin is given by the sum of the individual travel times of the surface stretches tds and the drainage network stretches tdd equation 10 7 t d s 5 74 n s l s 0 8 p 24 0 5 s s 0 4 8 v r h 2 3 s s 1 2 n s 9 t d d l s v 10 t d i 1 n s t d s i j 1 n d t d d j where rh is the hydraulic radius of the section m v is the runoff velocity m s ns is the manning roughness coefficient of the stretch surface or drainage network ls m and ss m m are the length and slope of the stretch respectively and p24 is the precipitation over 24 h mm for the return period of the event considered 2 4 5 application of hidropixel to the study area hidropixel was applied to the 30 m srtm dem and the lidar dtms with resolutions of 1 m 2 m 10 m and 30 m simulation time step was 1min for all resolutions and values were compared to observed hydrographs at 30min interval of the original observed data according to the soil map of the city of porto alegre hasenack et al 2008 the basin soils include red argisols and red yellow argisols with haplic cambisols according to sartori et al 2005 these soils are considered hydrological group b in the nrcs classification according to the soil types and land uses of the basin the cn values table 3 were defined for each amc based on usda 2007 for each rainfall event the amc was determined by taking the cumulative rainfall of the previous five days from the historical precipitation data of the porto alegre station code 03051011 which are available in the hidroweb system of the national water agency ana and the data of the also named porto alegre station same name but other location and code 83967 which are available from the national institute of meteorology inmet although some studies have suggested adjusting cn based on the observed rainfall and flow data this study proposes adjusting λ which we consider to be much more uncertain some authors e g schneiderman et al 2007 michel et al 2005 jain et al 2006 mishra and singh 2004 sahu et al 2010 have proposed to account for soil moisture variability to improve the accuracy of cn based models these studies showed that introducing soil moisture values in the model through the adjustment of cn or the initial abstraction improves the accuracy of the estimated runoff thus to estimate the excess rainfall the λ value of the nrcs cn method was considered variable for each event and dem dtm following previous studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 that indicated the inadequacy of the original value of 0 2 for each event spatial resolution and dtm the value of λ was selected by trial and error to identify the value that provided the lowest peak relative error other statistics used to verify the calibration were the relative error in time to peak and runoff volume as well as the best visual agreement between the observed and calculated hydrographs in contrast the cn value recommended from the literature was kept unchanged table 3 time discretization of 1 min was also adopted for the application of the distributed nrcs cn the same value was used for the duration of the unitary excess rainfall in the application of the nrcs tuh method based on the processing of the dem or dtm the distances and slopes for the surface stretches were determined in the calculation of the runoff travel time the p24 value was determined from the intensity duration frequency idf curve recommended for the basin region in the urban drainage master plan of porto alegre pmpa 2005 and considering the return period tr estimated for each event to define the manning roughness coefficient was identified the farthest point from the outlet and estimated its time of concentration using equations 7 to 10 as the flow path downstream to this point passes only through surface stretches with vegetation until reaching the drainage network and considering that this surface type represents 73 of the basin we chose to adjust manning roughness coefficient nveg by comparing the concentration times estimated from the observed rainfall and flow data tc obs and those calculated tc calc tc obs was estimated as the time elapsed from the end of the excess rainfall until the end of the surface runoff hydrograph for each event nveg was determined by trial and error and provided a better fit between tc obs and tc calc subsequently the nveg value that provided the best concordance between tc obs and tc calc for all events was determined this value was defined as nveg 0 29 for the other land use types exposed soil n 0 013 urban area n 0 024 and for the drainage channels which are considered to be of small scale and largely influenced by roughness effects caused by the vegetation or morphology n 0 08 manning roughness coefficient were chosen from the literature chow 1959 due to the lack of data trapezoidal cross sections were determined for the drainage network with four types of river stretches with homogeneous cross sectional characteristics fig 5 a and the distances of the stretches were obtained based on the reference drainage network and the slopes according to the dtm the scattering of the points between tc obs and tc calc is shown in fig 5 b 3 results and discussion 3 1 dtm dem processing and runoff travel time the length of the main river measured in the drainage network extracted from each dtm decreased with decreasing spatial resolution fig 6 from 5 10 km in the 1 m dtm to 3 98 km in the 30 m dtm decrease of 22 this decrease was about 18 8 in the 30 m srtm dem compared to the 1 m dtm this effect was identified and reported in several previous studies colombo et al 2007 heine et al 2004 and occurred because coarser resolutions have more difficulty in representing the complexities of the drainage consequently the river network becomes less sinuous and distance shortening occurs fekete et al 2001 yang et al 2014 the decrease in spatial resolution has a smaller impact on the catchment delimitation than on the length of the main river errors of commission and omission of less than 2 occur in the catchment delimitations from the resampled lidar dtm compared to the delimitation based on the lidar 1 m dtm fig 7 the difference is greater for the delimitation of the basin based on the 30 m srtm dem but it can still be considered relatively small with errors of commission and omission of less than 6 this contrasts with gironás et al 2010 results that showed much larger differences the travel times of the surface and channel runoff and the total times were obtained from the products derived from the dtms and dem and the application of the nrcs method equation fig 8 shows the results obtained from the 10 m lidar dtm and the 30 m srtm dem for the event on may 18 1979 longer surface travel times can be observed in the eastern and southeastern regions of the catchment due to the larger stretches with vegetated surfaces which are more than 16 h for the 1 m lidar dtm and 8 h for the 30 m srtm dem as expected the travel time in the channel network is much lower up to 80 min from the upstream points to the outlet the spatial variations in the total travel time are similar to the surface travel time map fig 9 shows the total travel times of the pixels for the events on may 18 1979 total rainfall of 33 mm and march 03 1980 total rainfall of 11 mm for both events it is clear that i coarsening the spatial resolution of the lidar dtm led to a decrease in the travel times as a result of the decrease in the lengths mentioned previously for example for may 18 event all basin drains with less than 700 min for 30 m resolution but takes more than 2000 min for 1 m resolution and ii for the same spatial resolution 30 m the travel times obtained from the srtm data are systematically lower than those obtained based on the lidar data we can also observe the effect of the larger size of the event on 05 18 1979 which resulted in shorter travel times than in the 03 03 1980 event this result highlights the positive characteristics of the travel time estimation method which allows rainfall events to be differentiated by considering the parameter p24 in the formulation the dependence of the basin time of concentration on the event intensity is a striking feature of the nonlinearity of the rainfall runoff transformation that hinders the reproduction of the flows observed by hydrological models michailidi et al 2018 3 2 initial losses scale effect and model calibration the fitted initial losses during almost all of the events are lower than the original value used in the method 20 or λ 0 2 fig 10 corroborating the results of other studies e g ajmal and kim 2015 shi et al 2009 that indicated that this value is too high and recommended λ values of approximately 0 05 a recent study by lautharte 2015 on catchments in the arroio dilúvio river basin also indicated a λ value of approximately 0 05 it should be noted that in this study we did not calibrate the cn parameter but rather used the recommended value from the literature and calibrate λ the results indicated that there was a general pattern in which the lower the amc was the lower the adjusted λ value was that is the drier the moisture conditions were the lower the value of λ required to reduce the losses to fit the simulation to the observed data better the inverse was also true the wetter the amc conditions were the greater the fitted value of λ was these results contradict the use of the same value of λ for any event or amc condition this is somewhat consistent with the actual rainfall runoff transformation process which does not occur with constant initial losses for every event and moisture condition moreover the flow generation is nonlinear and different parts of the catchment contribute differently to the flow in time and space due to the simplified formulation proposed in the nrcs cn which does not represent this spatiotemporal variation and does not explicitly consider the soil moisture conditions the variation in λ as a function of the antecedent soil moisture may be a reasonable counterbalance also there are alternative approaches to the original nrcs cn method that explicitly incorporate the total antecedent rainfall over the previous 5 day as a quantitative variable when calculating the excess rainfall e g jain et al 2006 babu and mishra n d sahu et al 2010 as well as approaches that propose to directly incorporate a state variable related to the soil moisture in the excess rainfall formulation e g durán barroso et al 2016 michel et al 2005 these efforts follow the growing line of research that incorporates soil moisture as an improvement to hydrological modeling for hydrological flood studies cea and fraga 2018 schoener and stone 2019 hettiarachchi et al 2019 the adjusted values of λ are very similar for simulations considering the dtms and dem and these values decrease slightly with the coarsening in the spatial resolution in the formulation of the cn method a smaller λ value entails fewer initial losses and a greater volume of water that turns into runoff the slight tendency for the basin area to decrease with spatial resolution coarsening as illustrated in fig 7 contributed to the slight increase in λ to compensate for the smaller runoff generation area however it can be noted an overall concordance of adjusted λ among spatial resolutions for each rainfall runoff event for instance the variation among events is much larger than among spatial resolutions in this work the λ value for each event and each simulated dtm and dem was allowed to be adjusted to provide this understanding of the scale effect and the initial moisture conditions in practice however the adjustment of this parameter for each simulation is not recommended future research will evaluate an alternative formulation that incorporates the soil moisture conditions in the λ equation or directly from the excess rainfall while considering the spatial heterogeneity of the physical characteristics of the river basin 3 2 1 model performance with the highest spatial resolution dem a comparison between the calculated and observed hydrographs generated from the 1 m lidar dtm is shown in fig 11 one first analysis is a comparison between the calculated and the observed hydrographs using λ 0 2 for several events such as those on 16feb1980 and 31aug1980 no surface flow was generated with λ 0 2 however with λ 0 02 and 0 05 the hydrograph was properly simulated in events such as those on 03aug1979 and 05dec1981 λ 0 2 generated flow but it was much less than expected the hydrographs for these events were only reproduced satisfactorily when setting λ to 0 11 and 0 13 respectively a few events had atypical behaviors such as that on 20sep1981 amc iii in which fitted λ ranged between 0 65 and 0 7 and that on 03mar1980 also amc iii in which λ was less than 0 05 the spatial heterogeneity of the rainfall may be one reason for such a difference between these events as the amc was estimated from a rain gauge outside the basin 3 2 2 model performance considering different dem sources and spatial resolutions at the highest available spatial resolution 1 m lidar dtm the observed hydrographs were reproduced satisfactorily when λ was adjusted but there were different performances among the events qp was underestimated in 15 of the 18 events but with relative errors res bellow 12 except for two of the lowest events observed which had re of approximately 20 figs 12 and 13 in the estimates of the total drained volume tdv and peak time tp the res were higher than those of qp mostly showing an underestimation of the observed values that is although the method satisfactorily represented the hydrographs it had difficulties in reproducing the volume of and delay in the observed runoff the absolute errors in qp tp and tdv are also shown in fig 12 and present the same inter event variability patterns these results were somehow expected as the proposed model does not directly represent anthropic effects over the connectivity of surface and subsurface flow paths such as roads and or sewer networks see for instance rodriguez et al 2005 gironás et al 2010 sanzana et al 2017 as its aims at scarce data regions even if this is a very common approach in urban storm water modeling gironás et al 2010 and has been applied successfully by several authors e g doan 2000 jordan and grimison 2001 barco et al 2008 with similar results to the presented in this paper and especially with good results with previous version of hidropixel e g costa et al 2019 should be noted for instance gironás et al 2010 reported errors of up to 30 in peak discharge when the channel system is not explicitly represented however it is worth noting that the three events with the greatest relative errors in tp 05feb80 31may80 and 14dec80 numbered as 4 7 and 12 in fig 12 were extremely concentrated they last just 2 or 3 time steps in terms of the 30 min records and more than 93 of the total precipitation occurred in the first instant of the recorded time this demonstrates that the time step of recording the events made it difficult to estimate the temporal variation of the storm and the consequent rainfall runoff modeling coarsening the spatial resolution of the lidar dtms the simulation results led to patterns similar to those reported for the 1 m lidar dtm fig 14 however the decrease in spatial resolution tended to result in even greater underestimations of tp and tdv this outcome occurred because shorter flow paths were obtained with increasing pixel size reducing the runoff travel time increasing the underestimation of the peak time and causing the runoff from several parts of the basin to arrive in a more concentrated manner and thus increase qp in contrast the greater underestimation of the runoff volume is related to the decrease in the size of the basin with increasing pixel size the purpose of varying λ according to dtm or dem spatial resolution was also to detect how much the adjustment of this parameter could vary according to pixel size however considering the model as calibrated using 1 m lidar data the highest dem resolution was carried out a group of model runs keeping constant the value of λ while coarsening the spatial resolution results showed that with 2 m 10 m and 30 m spatial resolutions the coarsening led to peak flow increase by approximately 7 9 31 0 and 53 4 respectively fig 15 in contrast time to peak decreased by 1 6 6 3 and 9 2 respectively due to grid coarsening from 1 m to 2 m 10 m and 30 m runoff does not show significant changes 0 4 within the spatial resolution degradation in a slight oversimplified way it could be expressed that for every meter in cell size increase a non linear mean increase of 2 in peak flow and a more constant decrease of 0 5 in peak time is expected 4 summary and conclusions as correctly pointed out by moglen 2000 there is a trend in hydrological modeling that spatial resolutions are increasing due to the myriad of information available this study proposed an approach to the hydrological simulation by adapting the nrcs cn and nrcs tuh methods to work in a distributed manner the hydrological model called hidropixel which was initially presented by costa et al 2019 allows for a distributed estimation of the flow rates with little additional information compared to the traditional nrcs cn tuh methodology despite the various disadvantages and criticisms of the nrcs cn tuh method that have been presented in the literature a methodology based on it was chosen focusing on scarce data regions in developing countries but taking advantage of freely available remote sensing data the results obtained from the case study showed the potential of this methodology for estimating hydrographs based on rainfall as well as the basic and commonly available data required for most hydrological studies such as dems soil types land use types and the general characteristics of the drainage network cross section and slope improved results were obtained by calibrating the parameter representative of the initial losses showing consistency with the results of several previous studies e g ajmal and kim 2015 shi et al 2009 woodward et al 2003 we also observed a relationship between this adjusted value and the amc highlighting the importance of incorporating soil moisture as proposed by several authors e g jain et al 2006 babu and mishra n d sahu et al 2010 durán barroso et al 2016 michel et al 2005 this will be evaluated in future studies using the distributed approach presented herein the combination of the adjusted λ parameter and cn may also be evaluated but such an evaluation was not performed in this study the performance of the proposed approach to reproduce the observed hydrographs was generally satisfactory to reproduce for peak flows 15 out of 18 events had relative errors of about 12 or less however this performance was not reliable for most events for time to peak and runoff volume with almost consistent underestimations it is also worth noting that the existing formulations in the literature were adjusted to the scale available at the time of their determination and that their application to smaller scales may introduce inconsistencies the need to evaluate the use of other formulations to estimate the runoff travel time is clear however it must be creative to explore the available data the performance also decreased with spatial resolution coarsening which tended to shorten the flow paths and underestimate the basin area and particularly affected the simulation flow travel times nevertheless there was also a tendency to underestimate the peak times due to the difficulty in simulating extremely short and concentrated rain events relative to the temporal resolution of the available information the methodology showed the potential for simulating peak flows in data deprived regions hidropixel can represent land use changes by explicitly considering the spatial variability of the physical characteristics of the basin which could also consider the spatial variability of rainfall and its effect on the formation of floods with little additional information compared to the traditional nrcs cn tuh methodology despite the parameter representative of initial losses λ showing variation when changing spatial resolution its variation was much larger between rainfall runoff events thus for recommending the application of hidropixel for other sites further studies are needed in order to overcome this issue perhaps by evaluating an alternative formulation that incorporates the soil moisture conditions in the λ estimative or directly from the excess rainfall declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by scholarships from coordenação de aperfeiçoamento de pessoal de nível superior brazil capes finance code 001 to the first two authors and from conselho nacional de desenvolvimento científico e tecnológico cnpq brazil to the last three authors and was also funded as a research project by cnpq edital universal 420936 2016 5 coordinated by the fourth author the authors also thank the data provided by former dep prefeitura de porto alegre especially to the engineers stanley amaral and daniela bemfica for their contributions appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104695 
26044,the piscine stream community estimation system pisces provides users with a hypothesized fish community for any stream reach in the conterminous united states using information obtained from nature serve the us geological survey usgs streamcat and the peterson field guide to freshwater fishes of north america for over 1000 native and non native freshwater fish species pisces can filter huc8 based fish assemblages based on species specific occurrence models create a community abundance biomass distribution by relating relative abundance to mean body weight of each species and allow users to query its database to see ancillary characteristics of each species e g habitat preferences and maximum size future efforts will aim to improve the accuracy of the species distribution database and refine augment increase the occurrence models the pisces tool is accessible at the epa s quantitative environmental domain qed website at https qed epacdx net pisces keywords fish distributions community structure community size spectra 1 introduction there are over 3 5 million miles of rivers and streams in the united states and many contain fish fish abundance and diversity have been used as biological indicators of stream condition e g indices of biotic integrity in addition to macroinvertebrate metrics e g ept taxa and standard water quality measurements e g do ph conductivity davis et al 1996 hughes et al 1999 karr 1981 karr and dudley 1981 karr et al 1986 miller et al 1988 simon et al 1995 hill et al 2017 carlisle et al 2009 maloney et al 2009 because fish are longer lived than aquatic macroinvertebrates they integrate a wide array of stream and watershed factors related to the quality of lotic systems on the order of years plafkin et al 1989 karr and chu 1999 wesche et al 1999 kovacs et al 2002 fish species are grouped into tolerant and intolerant categories based on known habitat affinities with integrity indices developed for use within states and regions of interest fausch et al 1990 simon 1999 stepenuck et al 2002 stoddard et al 2006 given that a fish community reflects on the state of the system it occupies government agencies federal state local non governmental groups and academic researchers routinely conduct field sampling to ascertain what fishes are present weaver and garman 1994 yoder et al 1998 angermeier and winston 1999 barbour et al 1999 wang et al 2000 usepa 2013 sampling methods vary but some of the most popular are backpack electrofishing multiple pass and depletion seining electric and otherwise and boat shocking many factors determine where fish species are found including physical stream habitat e g flow depth woody debris presence and substrate quality ecological interactions including introduced and invasive species levels of stressors sedimentation ph temperature nutrients and historical biogeography fausch et al 1990 simon 1999 jackson et al 2001 quist et al 2004 rashleigh et al 2005 bertolo and magnan 2006 kennard et al 2007 dauwalter et al 2008 pool et al 2010 baxter and hauer 2000 fish distributions are not static but change through time as functions of life history disturbance seasonal and prevailing hydrologic regimes species introductions climate change and food availability shuter and post 1990 taylor and warren 2001 rahel 2002 taylor et al 2006 2008 bib taylor et al 2006 bib taylor et al 2008 schaefer et al 2012 erős et al 2014 field sampling however can be time consuming expensive biased by gear selectivity and compromised by the dynamic nature of fish assemblages in lotic systems alternative methods of estimating fish species and abundance are needed to augment field sampling efforts and a variety of models have been developed for this purpose oakes et al 2005 fransen et al 2006 mccleary and hassan 2008 an empirical modeling approach derived from field data would have wide geographic application and utility for stream condition assessment multivariate statistical methods have been used to relate fish distributions to environmental characteristics using a variety of analytical techniques angermeier and winston 1999 kelso and johnson 1991 madejczyk et al 1998 ornellas and coutinho 1998 saiki and martin 2001 kendrick and francis 2002 schweizer and jager 2011 troia and mcmanamay 2020 brenden et al 2008 leathwick et al 2011 stream sampling data collected by the us environmental protection agency usepa in the mid atlantic highlands region of the eastern us herlihy et al 2000 was used for a k means cluster analysis of relative abundance data followed by a discriminant analysis to predict a stream s potential fish assemblage based on stream and watershed characteristics cyterski and barber 2006 mccormick peck mccormick et al 2000 found that taxonomic grouping of these data based on cluster analysis had higher classification strength than groupings based on geographic catchment ecoregion or stream order these methods and data have also been used to develop a decision support tool for fisheries management and stream habitat restoration what if usepa usepa 2006 however fish community data are not available in all locations and not always internet accessible even when present data availability accessibility and quality are therefore barriers to the widespread use of fish as biological indicators to overcome the reliance on field data and the resources needed to compile and interpret fish sampling databases an alternative approach to stream fish assemblage modeling was developed the piscine stream community estimation system or pisces pisces is a tool for determining credible fish communities for streams and rivers across the conterminous us historic and current range data for over 1000 native and non native freshwater fish species were combined with information on species characteristics and habitat preferences natureserve 2010 page and burr 2011 fishbase org pisces incorporates the results of analyses conducted on stream and watershed characteristics to determine species specific probabilistic occurrence models which are used to modify presence absence information based simply on the geographic distributions of each species the motivation to develop pisces was based in the lack of publicly available fish community data for many us lotic freshwater habitats because field sampling is cost prohibitive for all potential streams and rivers of interest fisheries data i e fish species enumeration with accompanying abundance length and weight measurements are also not typically available online in the absence of field data modeling conducted to evaluate changes in ecosystem services such as the impact of multiple stressors e g landcover change riparian buffer zone creation and corresponding changes in suspended and dissolved inputs on fish community provisioning also requires one to specify a fish community as an initial condition for a stream or river of interest therefore a reliable fish community dataset is essential to accurately forecast fish community biomass this includes integrated modeling approaches in which ecological models e g bass barber 2012 and hsi rashleigh et al 2005 are coupled with hydrologic and water quality models johnston et al 2011 but that are limited in their transferability to other watersheds including nearby freshwater systems with differing habitats and fish autecology pisces solves this problem by providing a reliable estimate of the fish community for lotic systems throughout the conus while also accounting for habitat suitability constraints on fish species development of pisces enhanced the transferability of an integrated ecological modeling system in a prior study johnston et al 2017 pisces also improves the ability to conduct cumulative impact assessment under the national environmental policy act nepa http www epa gov compliance nepa index html and other regulatory frameworks e g clean water act total maximum daily load in developing pisces we strove to combine the best available geographic data on fish distributions with species specific occurrence models and to package this information in a user friendly web based software tool pisces can be used for research purposes in support of ecological modeling e g johnston et al 2017 or to provide information to an interested citizen scientist curious about what fish species may be present in their local stream or river 2 software description the pisces core is written in the python programming language the fish properties and distributional ranges based on 8 digit hydrologic basins heretofore huc8 are stored in a postgis relational database the software is deployed as a web application using the django framework for server side processing the graphical user interface gui is built using html css and javascript the pisces core functionality is exposed through a collection of restful web services that can be accessed independently of the browser based gui the pisces gui contains three separate tabs distribution explorer assemblage predictor database explorer 2 1 distribution explorer here the user can access a navigable map of the us where they can pan zoom and select a huc8 defined by the watershed boundary dataset obtained from the usgs at http nhd usgs gov wbd html to see what species are expected in that huc8 given their known ranges fig 1 a link at the top of the page will redirect the user to the usgs water resources site for the watershed users can also search the pisces species database by common or scientific name clicking on a species in the list to the right of the map will display the currently known geographic distribution for that species as well as provide species characteristics in a table below links to a google image search and the wikipedia page for the selected species can also be found at the bottom of the page 2 2 assemblage predictor a map depicting the 1 100 000 scale stream segments of the national hydrography dataset version 2 nhdplusv2 mckay bondelid mckay et al 2012 for the entire us are displayed fig 2 note that the map must be zoomed to see these individual stream segments satellite imagery and map features can assist in stream identification once a user clicks an individual stream segment the entire fish assemblage for that huc8 is shown in a table on the bottom left of the page above the map is a link to the usepa s watershed report that provides basin characteristics for the chosen segment below the map are values for five characteristics of the chosen stream segment which are used to calculate occurrence models to estimate a more plausible fish community for the given stream segment drainage area km2 stream slope mean catchment elevation m the index of watershed integrity iwi and the probability of the segment having a good benthic invertebrate multimetric index bmmi these covariates are taken from the streamcat hill et al 2016 and nhdplusv2 databases the iwi attempts to summarize in a multimetric index the capacity of a watershed to support a full range of ecological processes and functions necessary for sustaining biotic integrity thornbrugh et al 2018 it assesses the status of six watershed functions hydrologic regulation water chemistry sediment hydrologic connectivity temperature and habitat provisioning the probability of the stream segment having a good community of benthic invertebrates is predicted by a random forest model model development described in hill et al 2017 the user may change the iwi and the bmmi values each can vary from 0 to 1 for scenario investigations in addition any species can be manually excluded or included from the community by clicking unclicking the checkbox to the left of the species name under the parameter values is a drop down menu threshold filter used to set the cutoff for assessing the probability of species specific occurrence models which shall be discussed later there is also a button display hide calculator which can be toggled to show hide the community abundance biomass calculator fig 3 which will estimate the distribution of total biomass or number of fish amongst the community members the assemblage predictor output depends on several databases model calculations and user input fig 4 shows a schematic of how beginning with a user s choice of a stream reach dark blue triangle at the upper left various pieces of information come together to produce a prediction of numbers or biomass of a fish community for that stream light blue circle at bottom right these components will be discussed later 2 3 database explorer this page allows a user to interact with the pisces species database via a query builder that can be manipulated to reveal all species that fit a chosen profile fig 5 such as those having some level of rarity attaining some maximum body size or those species that are benthic and prefer riffles the list of species that match the query parameters are shown below the selection boxes once a query is submitted clicking on a species in this list brings up a table with species characteristics as well as google image search and wikipedia links for that species 3 scientific foundations scientific and common names for fish species were adopted from page espinosa pérez page et al 2013 stream segmentation for the conterminous us was derived from the nhdplusv2 dataset in addition the following information for each fish species was obtained from the peterson field guide to north american fishes page and burr 2011 the online natureserve explorer http explorer natureserve org and fishbase http www fishbase org the rarity of each species inside its range the maximum size body length that each species attains assorted habitat preferences for each species 3 1 fish distributions the basis of pisces fish assemblage predictions are known current geographic distributions of fish species which were obtained primarily from two sources shapefiles of huc8 based species distributions obtained from natureserve 2010 huc8 based records of species introductions for native and non native fishes from the usgs nonindigenous aquatic species program nas er usgs gov taxgroup fish default aspx usgs and natureserve personnel communicate to keep species distributions primarily those introduced outside of their native ranges up to date larry page florida museum of natural history provided shapefiles for the polygons that appear in the peterson field guide pfg these polygons are imprecise at the boundaries of species distributions whenever possible we chose to use the natureserve usgs data the pfg however provided distributions for the following 16 species sub species not found in the natureserve or usgs databases campostoma spadiceum highland stoneroller cottus hubbsi columbia sculpin erimyzon claviformis western creek chubsucker etheostoma atripinne cumberland snubnose darter etheostoma erythrozonum meramec saddled darter etheostoma occidentale westrim darter etheostoma orientale eastrim darter etheostoma planasaxatile duck darter etheostoma spilotum cumberland plateau darter etheostoma tennesseense tennessee darter lepomis peltastes northern sunfish oncorhynchus mykiss newberrii great basin rainbow trout oncorhynchus mykiss gilberti kern rainbow trout oncorhynchus mykiss stonei sacramento rainbow trout oncorhynchus clarkii macdonaldi yellowfin cutthroat trout percina apristis guadalupe darter for these fish the pfg polygons were used to convert these polygons which were constructed by drawing a boundary around locations where species have been captured to hydrologically based areas to increase distributional precision we examined the overlap between the polygons and the map of huc8 s considering watershed drainage patterns to determine what basins should be defined as probable locations for the species of interest huc8 s with at least 50 of their area inside the pfg distributional polygon were considered to contain that species we also included huc8 s in a species distribution with overlap greater than 0 but less than 50 if the huc8 was directly upstream or downstream of a huc8 with greater than 50 overlap when a distributional polygon was relatively small i e intersecting or wholly contained within only a few huc8 s then each huc8 intersecting the polygon was included in the species distribution 3 2 species rarity as noted in the pfg rarity is not synonymous with the spatial extent of a species range a species can be very abundant within a tiny range like a few pools or springs in the case of certain desert pupfish or a species can be uncommon rare and yet have a widespread distribution across a large geographic expanse for our purposes rarity relates to how likely a species would be found at a suitable location within its range we converted the rarity descriptor in the pfg into a numeric scale 1 abundant 6 uncommon 2 abundant common 7 uncommon rare 3 common 8 rare 4 fairly common 9 extremely rare 5 common uncommon 10 extinct a pfg rarity of 10 indicates the species was historically seen in the huc8 but is currently extinct 3 3 probabilistic occurrence models we compiled a dataset of presence absence fish survey information from a variety of sources usgs biodata retrieval system https aquatic biodata usgs gov landing action usgs stream surveys conducted from 1993 to 2017 the multistate aquatic resources information system maris https www sciencebase gov catalog item 54998234e4b08b255be64e6e surveys conducted by state agencies during 1990 2014 usepa national rivers and streams assessment nrsa https www epa gov national aquatic resource surveys nrsa usepa surveys conducted during 2008 2009 usepa mid atlantic highlands assessment emap maha https archive epa gov emap archive emap web html index 167 html records span 1993 1996 usepa western assessment emap west https archive epa gov emap archive emap web html wstream html records span 1999 2000 and 2002 2006 in total this dataset represented 39 073 surveys done on freshwater rivers and streams across the contiguous us fig 6 a for model development we used the following covariates available from the nhdplusv2 and streamcat databases for each survey site and described earlier in section 2 2 drainage area km2 mean catchment elevation m stream slope the index of watershed integrity iwi and the probability of the segment having a good benthic invertebrate multimetric index bmmi species specific probabilistic occurrence models were developed using a generalized boosting method in python and the xgboost package chen and guestrin 2016 models were initially trained using data from 75 of the sites with 25 of the sites randomly withheld for validation purposes fig 6b the process for developing species specific occurrence models was as follows 1 identify all fish species caught in at least 25 surveys within the training dataset 432 species out of a total of 564 species 2 for each species create a dataset of survey sites where it was captured and survey sites within huc8s where the species occurs but was not captured 3 for these sites obtain the five covariate stream parameters from the streamcat database stream slope from the nhdplusv2 database 4 run the xgboost package using the xgbclassifier function for a binary response variable to create a species specific model of the probability of occurrence for each of the 432 species the 432 species represent over 99 of the species by survey site combinations in the training dataset 301 400 303 229 after calculating validation metrics based on applying the fitted models to the withheld testing sites the testing data were combined with the training data and new occurrence models were developed for the final pisces deployment for those species seen in at least 25 surveys in the combined dataset n 449 the xgboost package has an array of model parameters that can affect the fitting process and efficacy of the eventual solution below are the values we used for developing these models n estimators 500 learning rate 0 05 subsample 0 75 min samples leaf 3 max depth 3 n iter no change 10 for more details of the effect of these parameters on the fitting algorithm see the xgboost documentation https xgboost readthedocs io en latest python the maximum number of trees in a solution n estimators was set to 500 this number produced satisfactory results for all species the subsample fraction 0 75 results in each successive tree in the iterative algorithm being fit to a random 75 of the observations in the training data which mitigates overfitting max depth 3 means that two and three way interactions of model covariates could be captured by the model the min samples leaf parameter prevents the model from being unduly influenced by outliers odd samples smaller values of the learning rate can increase model accuracy but at the cost of increased computational time and adding trees to the eventual solution we found a value of 0 05 to work well for these data as measured by quick convergence to a solution without exceeding the maximum number of allowable estimators as more trees are added to the solution the training data error will continue to decline the validation error assessed using 10 fold cross validation initially declines but then rises if too many trees are used i e the model becomes overfit the n iter no change option will stop the iterative solution process if the validation error is not improved over the specified number of iterations 3 4 fish abundance once the initial stream fish assemblage based simply on huc8 distributional information is reduced to a more plausible community a collection of species that could likely be found in a certain stream given its characteristics a user may want to estimate the abundance or biomass of individuals of each species in the stream reach which can be done on the assemblage predictor tab for the integrated modeling system and the fish community simulation model that pisces was developed to support johnston et al 2011 2017 this was a necessary initial condition to estimate pisces uses several pieces of information to perform this task one is the user specified total abundance or total biomass of fish in the stream reach for context we note that in an extensive analysis of stream fish collection data barber et al 2015 found that mean total density of fish was about 7150 fish ha and mean total fish biomass was about 45 kg ha but the variability of these estimates was very large a second piece of information is the general negative relationship between the body size of an organism and its abundance in a community and or population sheldon et al 1972 pope et al 1982 han and straškraba 1998 boicourt et al 2004 white et al 2007 mcgill 2008 mcgarvey et al 2010 equation 1 a b u n d a n c e m e a n w e i g h t g β pisces uses a species specific β thinning exponent based on the mean weight of a species as the thinning intensity is also generally size dependent mcgarvey et al 2010 pisces sets a lower limit for β at 0 5 for very small species 1g and an upper limit of 0 75 for the largest species 1000g these are considered reasonable values for community level thinning exponents bohlin et al 1994 carbone and gittleman 2002 rincón and lobón cerviá 2002 savage et al 2004 for species between 1 and 1000g mean weight the following equation is used to determine β equation 2 β 0 5 m e a n w e i g h t g 0 06 smaller β values in equation 2 lead to a flatter size spectrum where the abundance of larger individuals does not drop off as steeply relative to the abundance of smaller individuals larger β values produce a steeper decline in abundance with increasing size as is often the case in heavily exploited fisheries duplisea and castonguay 2006 the user can change the default β value for any species but we suggest staying within the 0 5 0 75 range as the number of larger fish is already being curtailed by the inverse abundance weight relationship described by equation 1 making the impact of larger weight on β too severe equation 2 leads to very small relative biomass of the largest species in a community which does not agree with the general findings of barber et al 2015 the pisces database contains the maximum age mean weight and mean length for many species based on the data analyses of barber et al 2015 for those species not addressed by that study parameter values were based on regressions of these three parameters versus maximum length which we had for all species primarily from the peterson guide the derived regression equations and their r2 values equation 3 mean species weight g 0 00654 m a x s p e c i e s l e n g t h c m 2 1675 r 2 0 74 equation 4 mean species length cm 4 7 m e a n s p e c i e s w e i g h t g 0 3184 r 2 0 96 equation 5a max species age yr 1 333 m a x s p e c i e s l e n g t h c m 0 428 r 2 0 37 the pisces database also provides from barber et al 2015 species specific values of the coefficients in a power function for weight g wet weight versus length cm w a l b for those species for which these values were not given by barber et al 2015 we used the average coefficient across the dataset for a and b these were 0 01135 and 3 07 pisces provides a calculator on the distribution explorer for converting length to weight and vice versa for any species there is undoubtedly variability in the demographics of fish populations in different streams growth and mortality affecting the mean body weight of a species depending on the quality of the habitat they occupy density of competitors and predators etc the pisces gui allows the user to modify default values of mean species weight for investigative purposes e g if the user has better information on the mean weight of a species in a specific lotic system or wants to examine what a hypothetical rise or decrease in mean species weight would mean for a species within a community within pisces this is close to a zero sum game as total community biomass doesn t increase decrease greatly if the mean weight of a species is increased decreased instead the abundance of that species declines increases to compensate for the weight gain loss because community abundance is derived from relative abundance the number of individuals in the other species of the community also rise fall to a lesser extent to compensate for the weight change in a species in an absolute sense the numbers of the smallest species change much more than the numbers of the largest fish but the changes should be similar on a percentage basis table 1 shows how pisces would handle a hypothetical community of seven fish species ranging in mean weight from 0 1 to 200g e g small cyprinids to largemouth bass given a total community abundance of 10 000 fish column two provides the weight based thinning exponent equation 2 column three is weight based species abundance equation 1 but these values are difficult to interpret because magnitudes are dependent on the units of weight and choice of β the relative species abundance in column four is more useful column three values divided by the sum of column three relative abundance is multiplied by total abundance to provide an estimate of the number of individuals of each species column five column six shows the total biomass of each species n mean weight table 1 conforms with conditions seen in most stream fish communities i e the smallest species typically dominate relative abundance as do the smallest individuals in a population but their total biomass is relatively small larger species have more relative biomass but there are far fewer of them if the user specifies a total biomass for the community pisces will find the total abundance that produces the desired community biomass for example the community in table 1 has a total biomass of 32 kg if the user had specified a different total biomass pisces would use the results of an initial attempt as a starting point for adjusting total abundance to attain the desired total biomass a completely size based approach to community estimation is obviously over simplified ignoring competitive fitness and environmental tolerance of each species but the pisces abundance biomass calculator is meant as a first pass approximation of a community spectrum estimates should give a logarithmic sense of species abundance i e would the species occur in the tens hundreds or thousands of individuals if a user wants to simulate the abundance of a particularly hardy tolerant species they could decrease its weight based thinning exponent in the same manner a user might want to increase the thinning exponent for a sensitive intolerant species under adverse conditions we found a negative relationship fig 7 between mean species weight g and mean density fish m2 for 108 species found in 8 or more sample surveys using the data presented in barber et al 2015 clearly more factors than mean species weight are important for determining a species density however any analysis of fish abundance from electrofishing survey data is severely hampered by problems with gear and sampler selectivity typically biased to over represent large fish versus smaller fish in the 2008 2009 nrsa data across all surveys over 300 000 fish were caught whose mean species weight according to barber et al 2015 is under 10 g about half that number of fish were caught whose mean species weight is between 10 and 100 g and about 100 000 fish were caught whose mean species weight is greater than 100 g given the gear and sampler selectivity bias for large fish true population numbers are likely skewed more heavily towards smaller fish than these data indicate interestingly we also found a positive relationship fig 8 between the number of surveys that a species was found in and its residual in fig 7 more commonly found species generally existed at greater densities than their size would suggest while less common species existed at lower densities than their size would predict when examining similarly sized species within the nrsa data we also found a positive correlation between the number of surveys a species occurred in and it s mean density within those surveys based on these findings we modified the β values for these 108 species equation 5b β β δ equation 6 δ 0 15 ε 3 σ where ɛ is the species specific residual in fig 8 and σ is the standard deviation of the residuals σ 0 65 for this dataset thus δ is 0 15 for ɛ that are 3 standard deviations from the mean 0 1 units for residuals that are 2 standard deviations from the mean and 0 05 for ɛ that are 1 standard deviation from the mean since β ranges from 0 5 to 0 75 we deemed the scale of this adjustment to be an appropriate magnitude note that subtraction of δ from β ensures that species with a positive ϵ in fig 8 have β β leading to a higher relative abundance in a community in the future if similar analyses can be done for other species and datasets we could add δ values for more species to the pisces database a complex variety of factors interact to affect the density of a species in each system physiological and morphological properties of the species itself habitat suitability ecological interactions etc the raw data on species densities across sites looks much less organized than the mean value plot shown in fig 7 we don t try to distill the importance of these various factors onto δ rather we target a mean species response across all systems where it occurs and assume a complex interaction of factors drives the deviation from the trend line in fig 8 i e the residual for that species 3 5 species distribution characteristics based on our development of empirical occurrence models for the most commonly found species in the large survey database described in section 3 3 we calculated four species characteristics describing how often and where species were found these characteristics can be used to filter the pisces species database on the database explorer page fig 5 ubiquity 100 of surveys a species was found of surveys conducted within 8 digit hucs where the species is known to occur a percentage measure of how easily a species can be found within its known geographic extent calculated for all species found in the survey database n 564 ubiquity ranged from 0 093 to 74 4 extent 100 the number of 8 digit hucs a species occurs in 2200 a percentage measure of the geographic extent of a species 2200 is an estimate of the total number of hucs in the contiguous u s extent ranged 0 05 to 70 0 for the species in the pisces database with known distributions within the contiguous u s n 993 tolerance percent of predicted occurrences using the xgboost models within 10 000 streams with randomly generated values of watershed area elevation slope iwi and bmmi we used the cholesky algorithm within the scipy linalg library in python https docs scipy org doc scipy 0 14 0 reference linalg html module scipy linalg to generate 10 000 random sets of these 5 parameters with a variance covariance matrix equivalent to the empirical data tolerance is a measure of the diversity of environmental conditions a species is predicted to endure independent of its geographical distribution tolerance varied from 0 02 to 93 9 for the 449 species with probabilistic occurrence models two species tallapoosa sculpin and tallapoosa darter with the highest tolerance values were likely overestimated because they had a very small extent occurring in only a few hucs but were easily found in those hucs high ubiquity as a result the probabilistic occurrence models for these species were insensitive to the stream characteristics at the survey sites i e they predict a high occurrence probability for these species across a wide range of stream characteristics even though many of those combinations of stream characteristics are well outside the range of characteristics of streams where these species are found when it comes to predicting the occurrence of species at actual stream sites using the assemblage predictor however pisces only examines species that are known to occur within the huc8 that the stream in question resides in so overestimation of occurrence probabilities for species with small extent should not be an issue robustness a metric that combines ubiquity extent and tolerance calculated as extent0 33 tolerance0 33 ubiquity0 33 robustness highlights species that occur in many hucs across many different stream conditions and are typically seen in fish surveys within these hucs if any of these three conditions aren t met the robustness of that species will be reduced robustness ranged from 0 56 to 46 3 for the 449 species with all three values necessary to calculate it the robustness of tallapoosa sculpin and tallapoosa darter were only average due to their minimal extent even though their ubiquity and tolerance were quite high 3 6 tribe on the database explorer the user can filter the pisces database to show groups of species tribes that share evolutionary commonality a tribe is a taxonomic rank above genus but below family 3 7 ancillary characteristics the pisces database also has the following information for each species origin native to us or introduced beneficial use sport fish non game subsistence typical systems occupied caves springs headwaters creeks small rivers medium river large rivers lakes impoundments ponds canals ditches swamp marsh bayou coastal ocean preferred lotic habitat riffles runs flowing pools pools backwaters preferred location within the system benthic surface nearshore littoral pelagic preferred substrate mud silt detritus sand gravel rocks rubble boulders vegetation woody debris brush other preferred water characteristics clear turbid warm cool cold lowland low gradient upland high gradient these descriptors were taken from the peterson guide natureserve com and fishbase org information on subsistence species was found in kappen allison kappen et al 2012 for most fish groups species whose maximum body size was over 25 cm were considered sport fishes unless their rarity measure was 7 or greater for salmonids this threshold was 20 cm for sunfish and black bass the threshold was 15 cm species under these thresholds were designated as non game the finalized pisces database contains information on 1018 fish species representing 202 genera table 2 shows categorization of the 48 tribes into sport fishes and non game fishes some tribes have members in each of these classes but the tribe was defined based on most of its members subsistence species these tribes can be sportfish or non game and those entirely exotic to the contiguous u s 4 validation there are three components of pisces that interact to determine the community estimate for a stream huc8 fish distribution information probabilistic occurrence models community abundance 4 1 huc8 fish distributions the huc8s where a species can be found within the united states are based on data provided by usgs and natureserve along with the distributional polygons in the peterson field guide for several species as explained earlier however there may be errors of omission fish not listed in hucs where they are present and commission fish listed in hucs where they are not present in our database one of the advantages of pisces as an evolving web based service is that this database is easily updated to rectify discovered errors and these changes are then instantly available to pisces users to address errors of omission we compiled a dataset of actual survey information from the databases delineated in section 3 3 it was not critical that each database be completely independent of the others as duplicate records specific species huc combinations were easily filtered out as stated earlier the compiled database had almost 40 000 unique species huc combinations representing 564 species when compared to the existing pisces database about 92 000 unique species huc records we identified almost 7400 errors of omission and the database was subsequently updated errors of commission are not possible to address using survey data but must rely on expert knowledge of local fish biodiversity however if these types of errors are brought to our attention the database can be easily modified 4 2 occurrence modeling comparisons of modeled fish communities with actual survey samples often suffer from shortcomings gear sampler bias seasonal movements stochastic weather events etc that introduce temporal and spatial variability into survey data freeman et al 1988 grossman et al 1990 mihaljevic et al 2015 falcy et al 2016 however using the parameters of watershed area mean elevation stream slope iwi and bmmi to derive probabilistic occurrence models would hopefully allow estimation of a more plausible fish community the species specific xgboost models of species occurrence were tested against a validation dataset of almost 5000 site surveys the confusion matrices below table 3 summarize results across the 432 species for which training data occurrence models were calculated these values were obtained using two different species specific probability thresholds to determine whether the predicted probability of occurrence would be tabulated as a presence or absence for that species both thresholds were calculated using modeling results on the training data the table on the left 3a used the average modeled probability of survey sites where the species was present p1 and absent p0 for example for species x if p1 was 0 55 and p0 was 0 23 the threshold probability would be 0 55 0 23 2 0 39 the table on the right 3b used the maximum value of p1 sd p1 and p0 where sd p1 was the standard deviation of modeled probabilities for sites where the species was found this threshold produces fewer false negatives lower left cell but more false positives upper right cell for a given application it may be more important to accurately predict the presence of a species when it occurs versus accurately predicting the absence of a species when it isn t there if this is the case this second threshold would provide better results the pisces interface will allow the user to choose from several thresholds for deciding species presence absence based on predicted probabilities of occurrence cohen s kappa is a statistic often recommended for measurement of model fit based on a confusion matrix manel et al 2001 fielding 1999 the numbers in table 3 produce a kappa of 0 39 for the results on the left and 0 32 for the data on the right which indicates moderate model performance landis and koch 1977 based on data on the left the overall model accuracy for the testing sites was 82 75 for the data on the right the sensitivity correct prediction of true positives was 63 74 for the right data and the specificity correct prediction of true negatives was 85 76 for the right data this shows the tradeoffs of raising lowering the decision threshold lowering the threshold as resulted from the alternate threshold calculation for the data on the right increased the model s sensitivity but decreased its specificity using this threshold would lower the chances of the model predicting the absence of a species when it occurs while increasing the likelihood that the model predicts the presence of a species when it doesn t occur 4 3 community abundance the ecological concept that there should be many more small bodied organisms in a community at the base of the food chain and lesser numbers of larger species higher on the food chain is robust and well supported see references to the negative relationship of body size to abundance in a community given earlier even so the calculator in pisces that implements this concept using thinning coefficients and mean body size of all the species in a community is admittedly an oversimplification the size spectrum is meant to give the user a sense of relative abundance within a community that exhibits body size diversity in communities where most species have nearly the same body size a mixture of various minnows and darters for example species relative abundance could be highly variable from stream to stream depending on competitive interactions and stochastic historic events 5 conclusion in summarizing pisces development outcomes and the introductory discussion on motivation design and intended use three major benefits are derived from its final design and functionality in stand alone mode pisces allows users to develop hypothesized fish communities based on known distributions in lotic systems across the us this functionality has numerous applications to serve a multitude of current assessment programs and research endeavors secondly within an integrated environmental modeling framework johnston et al 2011 2017 pisces provides a service necessary to perform hydroecological assessments which link mechanistic hydrology models with ecological models to achieve prediction goals finally pisces general flexibility allows users to modify the best estimate of a fish community based on additional waterbody specific data this functionality established as an important design requirement enhances the capabilities of both standalone use and integrated modeling applications for which it was created 6 availability pisces is freely available on the web at https qed epacdx net pisces funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors this document has been reviewed and approved in accordance with u s environmental protection agency policy mention of trade names or commercial products does not constitute endorsement or recommendation for use declaration of competing interest none acknowledgements we are indebted to the following people larry page florida museum of natural history for fish distribution maps and advice on interpreting the information contained in page and burr 2011 matthew cannister pamela fuller and matthew nielson usgs nonindigenous aquatic species program for distributional information on native and introduced species jason mcnees and lynn kutner natureserve for assistance in obtaining fish species distributional information brenda rashleigh joe ebersole and marcia snyder of the usepa for cogent reviews and comments on the original manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104703 
26044,the piscine stream community estimation system pisces provides users with a hypothesized fish community for any stream reach in the conterminous united states using information obtained from nature serve the us geological survey usgs streamcat and the peterson field guide to freshwater fishes of north america for over 1000 native and non native freshwater fish species pisces can filter huc8 based fish assemblages based on species specific occurrence models create a community abundance biomass distribution by relating relative abundance to mean body weight of each species and allow users to query its database to see ancillary characteristics of each species e g habitat preferences and maximum size future efforts will aim to improve the accuracy of the species distribution database and refine augment increase the occurrence models the pisces tool is accessible at the epa s quantitative environmental domain qed website at https qed epacdx net pisces keywords fish distributions community structure community size spectra 1 introduction there are over 3 5 million miles of rivers and streams in the united states and many contain fish fish abundance and diversity have been used as biological indicators of stream condition e g indices of biotic integrity in addition to macroinvertebrate metrics e g ept taxa and standard water quality measurements e g do ph conductivity davis et al 1996 hughes et al 1999 karr 1981 karr and dudley 1981 karr et al 1986 miller et al 1988 simon et al 1995 hill et al 2017 carlisle et al 2009 maloney et al 2009 because fish are longer lived than aquatic macroinvertebrates they integrate a wide array of stream and watershed factors related to the quality of lotic systems on the order of years plafkin et al 1989 karr and chu 1999 wesche et al 1999 kovacs et al 2002 fish species are grouped into tolerant and intolerant categories based on known habitat affinities with integrity indices developed for use within states and regions of interest fausch et al 1990 simon 1999 stepenuck et al 2002 stoddard et al 2006 given that a fish community reflects on the state of the system it occupies government agencies federal state local non governmental groups and academic researchers routinely conduct field sampling to ascertain what fishes are present weaver and garman 1994 yoder et al 1998 angermeier and winston 1999 barbour et al 1999 wang et al 2000 usepa 2013 sampling methods vary but some of the most popular are backpack electrofishing multiple pass and depletion seining electric and otherwise and boat shocking many factors determine where fish species are found including physical stream habitat e g flow depth woody debris presence and substrate quality ecological interactions including introduced and invasive species levels of stressors sedimentation ph temperature nutrients and historical biogeography fausch et al 1990 simon 1999 jackson et al 2001 quist et al 2004 rashleigh et al 2005 bertolo and magnan 2006 kennard et al 2007 dauwalter et al 2008 pool et al 2010 baxter and hauer 2000 fish distributions are not static but change through time as functions of life history disturbance seasonal and prevailing hydrologic regimes species introductions climate change and food availability shuter and post 1990 taylor and warren 2001 rahel 2002 taylor et al 2006 2008 bib taylor et al 2006 bib taylor et al 2008 schaefer et al 2012 erős et al 2014 field sampling however can be time consuming expensive biased by gear selectivity and compromised by the dynamic nature of fish assemblages in lotic systems alternative methods of estimating fish species and abundance are needed to augment field sampling efforts and a variety of models have been developed for this purpose oakes et al 2005 fransen et al 2006 mccleary and hassan 2008 an empirical modeling approach derived from field data would have wide geographic application and utility for stream condition assessment multivariate statistical methods have been used to relate fish distributions to environmental characteristics using a variety of analytical techniques angermeier and winston 1999 kelso and johnson 1991 madejczyk et al 1998 ornellas and coutinho 1998 saiki and martin 2001 kendrick and francis 2002 schweizer and jager 2011 troia and mcmanamay 2020 brenden et al 2008 leathwick et al 2011 stream sampling data collected by the us environmental protection agency usepa in the mid atlantic highlands region of the eastern us herlihy et al 2000 was used for a k means cluster analysis of relative abundance data followed by a discriminant analysis to predict a stream s potential fish assemblage based on stream and watershed characteristics cyterski and barber 2006 mccormick peck mccormick et al 2000 found that taxonomic grouping of these data based on cluster analysis had higher classification strength than groupings based on geographic catchment ecoregion or stream order these methods and data have also been used to develop a decision support tool for fisheries management and stream habitat restoration what if usepa usepa 2006 however fish community data are not available in all locations and not always internet accessible even when present data availability accessibility and quality are therefore barriers to the widespread use of fish as biological indicators to overcome the reliance on field data and the resources needed to compile and interpret fish sampling databases an alternative approach to stream fish assemblage modeling was developed the piscine stream community estimation system or pisces pisces is a tool for determining credible fish communities for streams and rivers across the conterminous us historic and current range data for over 1000 native and non native freshwater fish species were combined with information on species characteristics and habitat preferences natureserve 2010 page and burr 2011 fishbase org pisces incorporates the results of analyses conducted on stream and watershed characteristics to determine species specific probabilistic occurrence models which are used to modify presence absence information based simply on the geographic distributions of each species the motivation to develop pisces was based in the lack of publicly available fish community data for many us lotic freshwater habitats because field sampling is cost prohibitive for all potential streams and rivers of interest fisheries data i e fish species enumeration with accompanying abundance length and weight measurements are also not typically available online in the absence of field data modeling conducted to evaluate changes in ecosystem services such as the impact of multiple stressors e g landcover change riparian buffer zone creation and corresponding changes in suspended and dissolved inputs on fish community provisioning also requires one to specify a fish community as an initial condition for a stream or river of interest therefore a reliable fish community dataset is essential to accurately forecast fish community biomass this includes integrated modeling approaches in which ecological models e g bass barber 2012 and hsi rashleigh et al 2005 are coupled with hydrologic and water quality models johnston et al 2011 but that are limited in their transferability to other watersheds including nearby freshwater systems with differing habitats and fish autecology pisces solves this problem by providing a reliable estimate of the fish community for lotic systems throughout the conus while also accounting for habitat suitability constraints on fish species development of pisces enhanced the transferability of an integrated ecological modeling system in a prior study johnston et al 2017 pisces also improves the ability to conduct cumulative impact assessment under the national environmental policy act nepa http www epa gov compliance nepa index html and other regulatory frameworks e g clean water act total maximum daily load in developing pisces we strove to combine the best available geographic data on fish distributions with species specific occurrence models and to package this information in a user friendly web based software tool pisces can be used for research purposes in support of ecological modeling e g johnston et al 2017 or to provide information to an interested citizen scientist curious about what fish species may be present in their local stream or river 2 software description the pisces core is written in the python programming language the fish properties and distributional ranges based on 8 digit hydrologic basins heretofore huc8 are stored in a postgis relational database the software is deployed as a web application using the django framework for server side processing the graphical user interface gui is built using html css and javascript the pisces core functionality is exposed through a collection of restful web services that can be accessed independently of the browser based gui the pisces gui contains three separate tabs distribution explorer assemblage predictor database explorer 2 1 distribution explorer here the user can access a navigable map of the us where they can pan zoom and select a huc8 defined by the watershed boundary dataset obtained from the usgs at http nhd usgs gov wbd html to see what species are expected in that huc8 given their known ranges fig 1 a link at the top of the page will redirect the user to the usgs water resources site for the watershed users can also search the pisces species database by common or scientific name clicking on a species in the list to the right of the map will display the currently known geographic distribution for that species as well as provide species characteristics in a table below links to a google image search and the wikipedia page for the selected species can also be found at the bottom of the page 2 2 assemblage predictor a map depicting the 1 100 000 scale stream segments of the national hydrography dataset version 2 nhdplusv2 mckay bondelid mckay et al 2012 for the entire us are displayed fig 2 note that the map must be zoomed to see these individual stream segments satellite imagery and map features can assist in stream identification once a user clicks an individual stream segment the entire fish assemblage for that huc8 is shown in a table on the bottom left of the page above the map is a link to the usepa s watershed report that provides basin characteristics for the chosen segment below the map are values for five characteristics of the chosen stream segment which are used to calculate occurrence models to estimate a more plausible fish community for the given stream segment drainage area km2 stream slope mean catchment elevation m the index of watershed integrity iwi and the probability of the segment having a good benthic invertebrate multimetric index bmmi these covariates are taken from the streamcat hill et al 2016 and nhdplusv2 databases the iwi attempts to summarize in a multimetric index the capacity of a watershed to support a full range of ecological processes and functions necessary for sustaining biotic integrity thornbrugh et al 2018 it assesses the status of six watershed functions hydrologic regulation water chemistry sediment hydrologic connectivity temperature and habitat provisioning the probability of the stream segment having a good community of benthic invertebrates is predicted by a random forest model model development described in hill et al 2017 the user may change the iwi and the bmmi values each can vary from 0 to 1 for scenario investigations in addition any species can be manually excluded or included from the community by clicking unclicking the checkbox to the left of the species name under the parameter values is a drop down menu threshold filter used to set the cutoff for assessing the probability of species specific occurrence models which shall be discussed later there is also a button display hide calculator which can be toggled to show hide the community abundance biomass calculator fig 3 which will estimate the distribution of total biomass or number of fish amongst the community members the assemblage predictor output depends on several databases model calculations and user input fig 4 shows a schematic of how beginning with a user s choice of a stream reach dark blue triangle at the upper left various pieces of information come together to produce a prediction of numbers or biomass of a fish community for that stream light blue circle at bottom right these components will be discussed later 2 3 database explorer this page allows a user to interact with the pisces species database via a query builder that can be manipulated to reveal all species that fit a chosen profile fig 5 such as those having some level of rarity attaining some maximum body size or those species that are benthic and prefer riffles the list of species that match the query parameters are shown below the selection boxes once a query is submitted clicking on a species in this list brings up a table with species characteristics as well as google image search and wikipedia links for that species 3 scientific foundations scientific and common names for fish species were adopted from page espinosa pérez page et al 2013 stream segmentation for the conterminous us was derived from the nhdplusv2 dataset in addition the following information for each fish species was obtained from the peterson field guide to north american fishes page and burr 2011 the online natureserve explorer http explorer natureserve org and fishbase http www fishbase org the rarity of each species inside its range the maximum size body length that each species attains assorted habitat preferences for each species 3 1 fish distributions the basis of pisces fish assemblage predictions are known current geographic distributions of fish species which were obtained primarily from two sources shapefiles of huc8 based species distributions obtained from natureserve 2010 huc8 based records of species introductions for native and non native fishes from the usgs nonindigenous aquatic species program nas er usgs gov taxgroup fish default aspx usgs and natureserve personnel communicate to keep species distributions primarily those introduced outside of their native ranges up to date larry page florida museum of natural history provided shapefiles for the polygons that appear in the peterson field guide pfg these polygons are imprecise at the boundaries of species distributions whenever possible we chose to use the natureserve usgs data the pfg however provided distributions for the following 16 species sub species not found in the natureserve or usgs databases campostoma spadiceum highland stoneroller cottus hubbsi columbia sculpin erimyzon claviformis western creek chubsucker etheostoma atripinne cumberland snubnose darter etheostoma erythrozonum meramec saddled darter etheostoma occidentale westrim darter etheostoma orientale eastrim darter etheostoma planasaxatile duck darter etheostoma spilotum cumberland plateau darter etheostoma tennesseense tennessee darter lepomis peltastes northern sunfish oncorhynchus mykiss newberrii great basin rainbow trout oncorhynchus mykiss gilberti kern rainbow trout oncorhynchus mykiss stonei sacramento rainbow trout oncorhynchus clarkii macdonaldi yellowfin cutthroat trout percina apristis guadalupe darter for these fish the pfg polygons were used to convert these polygons which were constructed by drawing a boundary around locations where species have been captured to hydrologically based areas to increase distributional precision we examined the overlap between the polygons and the map of huc8 s considering watershed drainage patterns to determine what basins should be defined as probable locations for the species of interest huc8 s with at least 50 of their area inside the pfg distributional polygon were considered to contain that species we also included huc8 s in a species distribution with overlap greater than 0 but less than 50 if the huc8 was directly upstream or downstream of a huc8 with greater than 50 overlap when a distributional polygon was relatively small i e intersecting or wholly contained within only a few huc8 s then each huc8 intersecting the polygon was included in the species distribution 3 2 species rarity as noted in the pfg rarity is not synonymous with the spatial extent of a species range a species can be very abundant within a tiny range like a few pools or springs in the case of certain desert pupfish or a species can be uncommon rare and yet have a widespread distribution across a large geographic expanse for our purposes rarity relates to how likely a species would be found at a suitable location within its range we converted the rarity descriptor in the pfg into a numeric scale 1 abundant 6 uncommon 2 abundant common 7 uncommon rare 3 common 8 rare 4 fairly common 9 extremely rare 5 common uncommon 10 extinct a pfg rarity of 10 indicates the species was historically seen in the huc8 but is currently extinct 3 3 probabilistic occurrence models we compiled a dataset of presence absence fish survey information from a variety of sources usgs biodata retrieval system https aquatic biodata usgs gov landing action usgs stream surveys conducted from 1993 to 2017 the multistate aquatic resources information system maris https www sciencebase gov catalog item 54998234e4b08b255be64e6e surveys conducted by state agencies during 1990 2014 usepa national rivers and streams assessment nrsa https www epa gov national aquatic resource surveys nrsa usepa surveys conducted during 2008 2009 usepa mid atlantic highlands assessment emap maha https archive epa gov emap archive emap web html index 167 html records span 1993 1996 usepa western assessment emap west https archive epa gov emap archive emap web html wstream html records span 1999 2000 and 2002 2006 in total this dataset represented 39 073 surveys done on freshwater rivers and streams across the contiguous us fig 6 a for model development we used the following covariates available from the nhdplusv2 and streamcat databases for each survey site and described earlier in section 2 2 drainage area km2 mean catchment elevation m stream slope the index of watershed integrity iwi and the probability of the segment having a good benthic invertebrate multimetric index bmmi species specific probabilistic occurrence models were developed using a generalized boosting method in python and the xgboost package chen and guestrin 2016 models were initially trained using data from 75 of the sites with 25 of the sites randomly withheld for validation purposes fig 6b the process for developing species specific occurrence models was as follows 1 identify all fish species caught in at least 25 surveys within the training dataset 432 species out of a total of 564 species 2 for each species create a dataset of survey sites where it was captured and survey sites within huc8s where the species occurs but was not captured 3 for these sites obtain the five covariate stream parameters from the streamcat database stream slope from the nhdplusv2 database 4 run the xgboost package using the xgbclassifier function for a binary response variable to create a species specific model of the probability of occurrence for each of the 432 species the 432 species represent over 99 of the species by survey site combinations in the training dataset 301 400 303 229 after calculating validation metrics based on applying the fitted models to the withheld testing sites the testing data were combined with the training data and new occurrence models were developed for the final pisces deployment for those species seen in at least 25 surveys in the combined dataset n 449 the xgboost package has an array of model parameters that can affect the fitting process and efficacy of the eventual solution below are the values we used for developing these models n estimators 500 learning rate 0 05 subsample 0 75 min samples leaf 3 max depth 3 n iter no change 10 for more details of the effect of these parameters on the fitting algorithm see the xgboost documentation https xgboost readthedocs io en latest python the maximum number of trees in a solution n estimators was set to 500 this number produced satisfactory results for all species the subsample fraction 0 75 results in each successive tree in the iterative algorithm being fit to a random 75 of the observations in the training data which mitigates overfitting max depth 3 means that two and three way interactions of model covariates could be captured by the model the min samples leaf parameter prevents the model from being unduly influenced by outliers odd samples smaller values of the learning rate can increase model accuracy but at the cost of increased computational time and adding trees to the eventual solution we found a value of 0 05 to work well for these data as measured by quick convergence to a solution without exceeding the maximum number of allowable estimators as more trees are added to the solution the training data error will continue to decline the validation error assessed using 10 fold cross validation initially declines but then rises if too many trees are used i e the model becomes overfit the n iter no change option will stop the iterative solution process if the validation error is not improved over the specified number of iterations 3 4 fish abundance once the initial stream fish assemblage based simply on huc8 distributional information is reduced to a more plausible community a collection of species that could likely be found in a certain stream given its characteristics a user may want to estimate the abundance or biomass of individuals of each species in the stream reach which can be done on the assemblage predictor tab for the integrated modeling system and the fish community simulation model that pisces was developed to support johnston et al 2011 2017 this was a necessary initial condition to estimate pisces uses several pieces of information to perform this task one is the user specified total abundance or total biomass of fish in the stream reach for context we note that in an extensive analysis of stream fish collection data barber et al 2015 found that mean total density of fish was about 7150 fish ha and mean total fish biomass was about 45 kg ha but the variability of these estimates was very large a second piece of information is the general negative relationship between the body size of an organism and its abundance in a community and or population sheldon et al 1972 pope et al 1982 han and straškraba 1998 boicourt et al 2004 white et al 2007 mcgill 2008 mcgarvey et al 2010 equation 1 a b u n d a n c e m e a n w e i g h t g β pisces uses a species specific β thinning exponent based on the mean weight of a species as the thinning intensity is also generally size dependent mcgarvey et al 2010 pisces sets a lower limit for β at 0 5 for very small species 1g and an upper limit of 0 75 for the largest species 1000g these are considered reasonable values for community level thinning exponents bohlin et al 1994 carbone and gittleman 2002 rincón and lobón cerviá 2002 savage et al 2004 for species between 1 and 1000g mean weight the following equation is used to determine β equation 2 β 0 5 m e a n w e i g h t g 0 06 smaller β values in equation 2 lead to a flatter size spectrum where the abundance of larger individuals does not drop off as steeply relative to the abundance of smaller individuals larger β values produce a steeper decline in abundance with increasing size as is often the case in heavily exploited fisheries duplisea and castonguay 2006 the user can change the default β value for any species but we suggest staying within the 0 5 0 75 range as the number of larger fish is already being curtailed by the inverse abundance weight relationship described by equation 1 making the impact of larger weight on β too severe equation 2 leads to very small relative biomass of the largest species in a community which does not agree with the general findings of barber et al 2015 the pisces database contains the maximum age mean weight and mean length for many species based on the data analyses of barber et al 2015 for those species not addressed by that study parameter values were based on regressions of these three parameters versus maximum length which we had for all species primarily from the peterson guide the derived regression equations and their r2 values equation 3 mean species weight g 0 00654 m a x s p e c i e s l e n g t h c m 2 1675 r 2 0 74 equation 4 mean species length cm 4 7 m e a n s p e c i e s w e i g h t g 0 3184 r 2 0 96 equation 5a max species age yr 1 333 m a x s p e c i e s l e n g t h c m 0 428 r 2 0 37 the pisces database also provides from barber et al 2015 species specific values of the coefficients in a power function for weight g wet weight versus length cm w a l b for those species for which these values were not given by barber et al 2015 we used the average coefficient across the dataset for a and b these were 0 01135 and 3 07 pisces provides a calculator on the distribution explorer for converting length to weight and vice versa for any species there is undoubtedly variability in the demographics of fish populations in different streams growth and mortality affecting the mean body weight of a species depending on the quality of the habitat they occupy density of competitors and predators etc the pisces gui allows the user to modify default values of mean species weight for investigative purposes e g if the user has better information on the mean weight of a species in a specific lotic system or wants to examine what a hypothetical rise or decrease in mean species weight would mean for a species within a community within pisces this is close to a zero sum game as total community biomass doesn t increase decrease greatly if the mean weight of a species is increased decreased instead the abundance of that species declines increases to compensate for the weight gain loss because community abundance is derived from relative abundance the number of individuals in the other species of the community also rise fall to a lesser extent to compensate for the weight change in a species in an absolute sense the numbers of the smallest species change much more than the numbers of the largest fish but the changes should be similar on a percentage basis table 1 shows how pisces would handle a hypothetical community of seven fish species ranging in mean weight from 0 1 to 200g e g small cyprinids to largemouth bass given a total community abundance of 10 000 fish column two provides the weight based thinning exponent equation 2 column three is weight based species abundance equation 1 but these values are difficult to interpret because magnitudes are dependent on the units of weight and choice of β the relative species abundance in column four is more useful column three values divided by the sum of column three relative abundance is multiplied by total abundance to provide an estimate of the number of individuals of each species column five column six shows the total biomass of each species n mean weight table 1 conforms with conditions seen in most stream fish communities i e the smallest species typically dominate relative abundance as do the smallest individuals in a population but their total biomass is relatively small larger species have more relative biomass but there are far fewer of them if the user specifies a total biomass for the community pisces will find the total abundance that produces the desired community biomass for example the community in table 1 has a total biomass of 32 kg if the user had specified a different total biomass pisces would use the results of an initial attempt as a starting point for adjusting total abundance to attain the desired total biomass a completely size based approach to community estimation is obviously over simplified ignoring competitive fitness and environmental tolerance of each species but the pisces abundance biomass calculator is meant as a first pass approximation of a community spectrum estimates should give a logarithmic sense of species abundance i e would the species occur in the tens hundreds or thousands of individuals if a user wants to simulate the abundance of a particularly hardy tolerant species they could decrease its weight based thinning exponent in the same manner a user might want to increase the thinning exponent for a sensitive intolerant species under adverse conditions we found a negative relationship fig 7 between mean species weight g and mean density fish m2 for 108 species found in 8 or more sample surveys using the data presented in barber et al 2015 clearly more factors than mean species weight are important for determining a species density however any analysis of fish abundance from electrofishing survey data is severely hampered by problems with gear and sampler selectivity typically biased to over represent large fish versus smaller fish in the 2008 2009 nrsa data across all surveys over 300 000 fish were caught whose mean species weight according to barber et al 2015 is under 10 g about half that number of fish were caught whose mean species weight is between 10 and 100 g and about 100 000 fish were caught whose mean species weight is greater than 100 g given the gear and sampler selectivity bias for large fish true population numbers are likely skewed more heavily towards smaller fish than these data indicate interestingly we also found a positive relationship fig 8 between the number of surveys that a species was found in and its residual in fig 7 more commonly found species generally existed at greater densities than their size would suggest while less common species existed at lower densities than their size would predict when examining similarly sized species within the nrsa data we also found a positive correlation between the number of surveys a species occurred in and it s mean density within those surveys based on these findings we modified the β values for these 108 species equation 5b β β δ equation 6 δ 0 15 ε 3 σ where ɛ is the species specific residual in fig 8 and σ is the standard deviation of the residuals σ 0 65 for this dataset thus δ is 0 15 for ɛ that are 3 standard deviations from the mean 0 1 units for residuals that are 2 standard deviations from the mean and 0 05 for ɛ that are 1 standard deviation from the mean since β ranges from 0 5 to 0 75 we deemed the scale of this adjustment to be an appropriate magnitude note that subtraction of δ from β ensures that species with a positive ϵ in fig 8 have β β leading to a higher relative abundance in a community in the future if similar analyses can be done for other species and datasets we could add δ values for more species to the pisces database a complex variety of factors interact to affect the density of a species in each system physiological and morphological properties of the species itself habitat suitability ecological interactions etc the raw data on species densities across sites looks much less organized than the mean value plot shown in fig 7 we don t try to distill the importance of these various factors onto δ rather we target a mean species response across all systems where it occurs and assume a complex interaction of factors drives the deviation from the trend line in fig 8 i e the residual for that species 3 5 species distribution characteristics based on our development of empirical occurrence models for the most commonly found species in the large survey database described in section 3 3 we calculated four species characteristics describing how often and where species were found these characteristics can be used to filter the pisces species database on the database explorer page fig 5 ubiquity 100 of surveys a species was found of surveys conducted within 8 digit hucs where the species is known to occur a percentage measure of how easily a species can be found within its known geographic extent calculated for all species found in the survey database n 564 ubiquity ranged from 0 093 to 74 4 extent 100 the number of 8 digit hucs a species occurs in 2200 a percentage measure of the geographic extent of a species 2200 is an estimate of the total number of hucs in the contiguous u s extent ranged 0 05 to 70 0 for the species in the pisces database with known distributions within the contiguous u s n 993 tolerance percent of predicted occurrences using the xgboost models within 10 000 streams with randomly generated values of watershed area elevation slope iwi and bmmi we used the cholesky algorithm within the scipy linalg library in python https docs scipy org doc scipy 0 14 0 reference linalg html module scipy linalg to generate 10 000 random sets of these 5 parameters with a variance covariance matrix equivalent to the empirical data tolerance is a measure of the diversity of environmental conditions a species is predicted to endure independent of its geographical distribution tolerance varied from 0 02 to 93 9 for the 449 species with probabilistic occurrence models two species tallapoosa sculpin and tallapoosa darter with the highest tolerance values were likely overestimated because they had a very small extent occurring in only a few hucs but were easily found in those hucs high ubiquity as a result the probabilistic occurrence models for these species were insensitive to the stream characteristics at the survey sites i e they predict a high occurrence probability for these species across a wide range of stream characteristics even though many of those combinations of stream characteristics are well outside the range of characteristics of streams where these species are found when it comes to predicting the occurrence of species at actual stream sites using the assemblage predictor however pisces only examines species that are known to occur within the huc8 that the stream in question resides in so overestimation of occurrence probabilities for species with small extent should not be an issue robustness a metric that combines ubiquity extent and tolerance calculated as extent0 33 tolerance0 33 ubiquity0 33 robustness highlights species that occur in many hucs across many different stream conditions and are typically seen in fish surveys within these hucs if any of these three conditions aren t met the robustness of that species will be reduced robustness ranged from 0 56 to 46 3 for the 449 species with all three values necessary to calculate it the robustness of tallapoosa sculpin and tallapoosa darter were only average due to their minimal extent even though their ubiquity and tolerance were quite high 3 6 tribe on the database explorer the user can filter the pisces database to show groups of species tribes that share evolutionary commonality a tribe is a taxonomic rank above genus but below family 3 7 ancillary characteristics the pisces database also has the following information for each species origin native to us or introduced beneficial use sport fish non game subsistence typical systems occupied caves springs headwaters creeks small rivers medium river large rivers lakes impoundments ponds canals ditches swamp marsh bayou coastal ocean preferred lotic habitat riffles runs flowing pools pools backwaters preferred location within the system benthic surface nearshore littoral pelagic preferred substrate mud silt detritus sand gravel rocks rubble boulders vegetation woody debris brush other preferred water characteristics clear turbid warm cool cold lowland low gradient upland high gradient these descriptors were taken from the peterson guide natureserve com and fishbase org information on subsistence species was found in kappen allison kappen et al 2012 for most fish groups species whose maximum body size was over 25 cm were considered sport fishes unless their rarity measure was 7 or greater for salmonids this threshold was 20 cm for sunfish and black bass the threshold was 15 cm species under these thresholds were designated as non game the finalized pisces database contains information on 1018 fish species representing 202 genera table 2 shows categorization of the 48 tribes into sport fishes and non game fishes some tribes have members in each of these classes but the tribe was defined based on most of its members subsistence species these tribes can be sportfish or non game and those entirely exotic to the contiguous u s 4 validation there are three components of pisces that interact to determine the community estimate for a stream huc8 fish distribution information probabilistic occurrence models community abundance 4 1 huc8 fish distributions the huc8s where a species can be found within the united states are based on data provided by usgs and natureserve along with the distributional polygons in the peterson field guide for several species as explained earlier however there may be errors of omission fish not listed in hucs where they are present and commission fish listed in hucs where they are not present in our database one of the advantages of pisces as an evolving web based service is that this database is easily updated to rectify discovered errors and these changes are then instantly available to pisces users to address errors of omission we compiled a dataset of actual survey information from the databases delineated in section 3 3 it was not critical that each database be completely independent of the others as duplicate records specific species huc combinations were easily filtered out as stated earlier the compiled database had almost 40 000 unique species huc combinations representing 564 species when compared to the existing pisces database about 92 000 unique species huc records we identified almost 7400 errors of omission and the database was subsequently updated errors of commission are not possible to address using survey data but must rely on expert knowledge of local fish biodiversity however if these types of errors are brought to our attention the database can be easily modified 4 2 occurrence modeling comparisons of modeled fish communities with actual survey samples often suffer from shortcomings gear sampler bias seasonal movements stochastic weather events etc that introduce temporal and spatial variability into survey data freeman et al 1988 grossman et al 1990 mihaljevic et al 2015 falcy et al 2016 however using the parameters of watershed area mean elevation stream slope iwi and bmmi to derive probabilistic occurrence models would hopefully allow estimation of a more plausible fish community the species specific xgboost models of species occurrence were tested against a validation dataset of almost 5000 site surveys the confusion matrices below table 3 summarize results across the 432 species for which training data occurrence models were calculated these values were obtained using two different species specific probability thresholds to determine whether the predicted probability of occurrence would be tabulated as a presence or absence for that species both thresholds were calculated using modeling results on the training data the table on the left 3a used the average modeled probability of survey sites where the species was present p1 and absent p0 for example for species x if p1 was 0 55 and p0 was 0 23 the threshold probability would be 0 55 0 23 2 0 39 the table on the right 3b used the maximum value of p1 sd p1 and p0 where sd p1 was the standard deviation of modeled probabilities for sites where the species was found this threshold produces fewer false negatives lower left cell but more false positives upper right cell for a given application it may be more important to accurately predict the presence of a species when it occurs versus accurately predicting the absence of a species when it isn t there if this is the case this second threshold would provide better results the pisces interface will allow the user to choose from several thresholds for deciding species presence absence based on predicted probabilities of occurrence cohen s kappa is a statistic often recommended for measurement of model fit based on a confusion matrix manel et al 2001 fielding 1999 the numbers in table 3 produce a kappa of 0 39 for the results on the left and 0 32 for the data on the right which indicates moderate model performance landis and koch 1977 based on data on the left the overall model accuracy for the testing sites was 82 75 for the data on the right the sensitivity correct prediction of true positives was 63 74 for the right data and the specificity correct prediction of true negatives was 85 76 for the right data this shows the tradeoffs of raising lowering the decision threshold lowering the threshold as resulted from the alternate threshold calculation for the data on the right increased the model s sensitivity but decreased its specificity using this threshold would lower the chances of the model predicting the absence of a species when it occurs while increasing the likelihood that the model predicts the presence of a species when it doesn t occur 4 3 community abundance the ecological concept that there should be many more small bodied organisms in a community at the base of the food chain and lesser numbers of larger species higher on the food chain is robust and well supported see references to the negative relationship of body size to abundance in a community given earlier even so the calculator in pisces that implements this concept using thinning coefficients and mean body size of all the species in a community is admittedly an oversimplification the size spectrum is meant to give the user a sense of relative abundance within a community that exhibits body size diversity in communities where most species have nearly the same body size a mixture of various minnows and darters for example species relative abundance could be highly variable from stream to stream depending on competitive interactions and stochastic historic events 5 conclusion in summarizing pisces development outcomes and the introductory discussion on motivation design and intended use three major benefits are derived from its final design and functionality in stand alone mode pisces allows users to develop hypothesized fish communities based on known distributions in lotic systems across the us this functionality has numerous applications to serve a multitude of current assessment programs and research endeavors secondly within an integrated environmental modeling framework johnston et al 2011 2017 pisces provides a service necessary to perform hydroecological assessments which link mechanistic hydrology models with ecological models to achieve prediction goals finally pisces general flexibility allows users to modify the best estimate of a fish community based on additional waterbody specific data this functionality established as an important design requirement enhances the capabilities of both standalone use and integrated modeling applications for which it was created 6 availability pisces is freely available on the web at https qed epacdx net pisces funding this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors this document has been reviewed and approved in accordance with u s environmental protection agency policy mention of trade names or commercial products does not constitute endorsement or recommendation for use declaration of competing interest none acknowledgements we are indebted to the following people larry page florida museum of natural history for fish distribution maps and advice on interpreting the information contained in page and burr 2011 matthew cannister pamela fuller and matthew nielson usgs nonindigenous aquatic species program for distributional information on native and introduced species jason mcnees and lynn kutner natureserve for assistance in obtaining fish species distributional information brenda rashleigh joe ebersole and marcia snyder of the usepa for cogent reviews and comments on the original manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104703 
