index,text
5310,non stationarity approaches have been increasingly popular in hydrology reflecting scientific concerns regarding intensification of the water cycle due to global warming a considerable share of relevant studies is dominated by the practice of identifying linear trends in data through in sample analysis in this work we reframe the problem of trend identification using the out of sample predictive performance of trends as a reference point we devise a systematic methodological framework in which linear trends are compared to simpler mean models based on their performance in predicting climatic scale 30 year annual rainfall indices i e maxima totals wet day average and probability dry from long term daily records the models are calibrated in two different schemes block moving i e fitted on the recent 30 years of data obtaining the local trend and local mean and global moving i e fitted on the whole period known to an observer moving in time thus obtaining the global trend and global mean the investigation of empirical records spanning over 150 years of daily data suggests that a great degree of variability has been ever present in the rainfall process leaving small potential for long term predictability the local mean model ranks first in terms of average predictive performance followed by the global mean and the global trend in decreasing order of performance while the local trend model ranks last among the models showing the worst performance overall parallel experiments from synthetic timeseries characterized by persistence corroborated this finding suggesting that future long term variability of persistent processes is better captured using parsimonious features of the past in line with the empirical findings it is shown that prediction wise simple is preferable to trendy keywords trends rainfall extremes probability dry out of sample validation predictive performance rainfall projections 1 introduction a trend is a trend is a trend but the question is will it bend will it alter its course through some unforeseen force and come to a premature end sir alec cairncross 1969 signing as stein age forecaster in the past decades there has been a plethora of trend analyses in rainfall studies bunting et al 1976 haylock and nicholls 2000 2000 rotstayn and lohmann 2002 modarres et al 2007 ntegeka and willems 2008 kumar et al 2010 and it could be argued that relevant studies are still on the rise e g biasutti 2019 degefu et al 2019 folton et al 2019 khan et al 2019 papalexiou and montanari 2019 de quadros et al 2019 rahimi and fatemi 2019 for a quantitative analysis of the relevant literature the reader is referred to appendix i this boom of trend studies has had various scopes most of which are related to global warming assessment ipcc 2013 these include historic climate variability quantification attribution to deterministic drivers projections to the future and impact assessments e g kumar et al 2010 parmesan and yohe 2003 biasutti 2013 rotstayn and lohmann 2002 arguably what is common in the majority of trend studies even when not explicitly stated is the expectation for a monotonically changing future which as a result has initiated a growing discourse on the appropriate modelling approach in climatology and hydrology there has been an ongoing debate between stationary vs nonstationary methods with the former representing a well established hydrological practice montanari and koutsoyiannis 2014 koutsoyiannis and montanari 2015 and the latter reflecting recent attempts of the scientific community to find a new way to respond to change and uncertainty under the anthropogenic climate change scenario milly et al 2008 craig 2010 milly et al 2015 yet deterministic trend modelling has been examined and mostly criticized on different grounds namely with respect to empirical evidence mckitrick and christy 2019 cohn and lins 2005 theoretical consistency koutsoyiannis and montanari 2015 modelling efficiency montanari and koutsoyiannis 2014 and meaningfulness of the results serinaldi et al 2018 it has also been argued that the concepts of change and uncertainty are already well represented within the stationarity framework koutsoyiannis and montanari 2007 serinaldi and kilsby 2018 in this research we examine the trend modelling framework from a new perspective through the evaluation of its out of sample modelling qualities namely its predictive powers for a given record for this purpose we introduce a validation framework for the evaluation of the results adding simpler mean models in the pool of candidates and basing the reasoning of model selection on the statistical out of sample performance of the models while split sample techniques klemeš 1986 and multi model approaches georgakakos et al 2004 duan et al 2007 are certainly not new in hydrology they are usually disregarded as concepts in the field of trend modelling where the research question typically revolves around explanatory performance mostly by means of in sample measures as hypothesis testing shmueli 2010 in this work we extend the simple split sample validation by introducing a moving window calibration and validation approach that progressively scans each record by sliding windows of climatic length i e 30 years according to the common climate definition ipcc 2013 in this manner we obtain a sample of estimates of the models predictive performance instead of a single value by shifting the focus to the predictive modelling of linear trend this analysis seeks to answer the following key questions a how well are the rainfall statistics of the most recent climatic period predicted by the linear trend calibrated to the prior 30 year period and b how do the statistics of the predictive performance of linear trends compare to the ones derived from application of simple mean models the first question is driven by the omnipresent scientific concerns regarding intensification of extremes due to global warming during the last decades e g houghton et al 1991 parmesan and yohe 2003 oreskes 2004 solomon et al 2007 mccarl et al 2008 moss et al 2010 craig 2010 pachauri et al 2014 kellogg 2019 according to the fifth latest ipcc assessment ipcc 2013 the expected intensification mechanism suggests a 6 7 increase of the global water vapour per c of warming followed by a 1 3 increase in global mean precipitation recently the physical assumptions behind these estimates have been questioned and revisited in light of global datasets koutsoyiannis 2020a while the evaluation of hydrological impacts from increased greenhouse emissions remains an open research subject with often conflicting evidence e g hirsch and ryberg 2012 marani and zanetti 2015 blöschl et al 2019 therefore the first examination of predictability is consciously biased in favour of a model capturing the variability of the most recent period of data the second question introduces the abovementioned methodological framework for validating model predictions which is applied to the empirical long term rainfall records as well as to synthetic series produced in order to mimic the natural long term variability of the rainfall process a discussion on the relevance of the framework in light of potential deterministic changes is also provided 2 dataset our dataset is an update of the previous long term dataset explored in iliopoulou et al 2018a of long rainfall records surpassing 150 years of daily values it includes the 60 longest available daily rainfall records collected from global datasets i e the global historical climatology network daily database menne et al 2012 the european climate assessment and dataset klein tank et al 2002 as well as third parties listed in in the appendix ii table a1 along with a brief summary of the stations properties the geographic location of the rain gauges is shown in fig 1 the length of the timeseries provides rare insights into long term rainfall variability and enables the statistical evaluation of the predictive performance of linear trends from multiple time windows 3 methodological framework 3 1 overview of literature approaches to trend modelling from explanatory trends to out of sample performance it is well known that studying the explanatory power of trends in hydroclimatic data is a very active research field see the literature analysis included in the appendix i for the rising use of relevant in text words as well as in title words from google scholar before discussing literature modelling strategies for trends it is imperative to define the meaning of a trend per se although trends are frequently used as a synonym of temporal changes fig a3 provides a quantitative analysis on the use of both words and their notion has sometimes been extended to encompass stochastic stationary models fatichi et al 2009 chandler and scott 2011 the general idea behind the trend concept is that the expected value of a response variable y is specified as a deterministic function of time t e y f t the function f may take different forms the linear model being only the first one adopted and the most widely used indeed this definition of a trend can be traced back to the development of the field of econometrics in the early 20th century when secular trends meaning long term trends were deemed to be a component of financial timeseries along with seasonal variation cycles and residual elements persons 1922 mitchell 1930 decomposition of a timeseries into components one of them being a trend continued to dominate the econometrics literature although even at early times certain critiques were raised slutsky 1927 the most established technique to evaluate fitted trends is statistical hypothesis testing i e a statistical inference technique that estimates the probability of an outcome as far from what is expected as the observed under the assumption that the null hypothesis is true gauch et al 2003 the latter is known as the p value and is compared to predefined significance levels in order to reject or not the null hypothesis this is a scientific method for model evaluation which has been in part misused for instance its misuse in hydrology has been showcased by seminal studies e g cohn and lins 2005 koutsoyiannis and montanari 2007 serinaldi et al 2018 which have established the fact that for hydrological non i i d data the null hypothesis which tacitly contains independence is a priori wrong and its rejection if correctly interpreted should point out to the wrong independence assumption still the common practice has been to misinterpret outcomes in favour of trends part of the statistician community argues against the concept of significance testing nuzzo 2014 wasserstein and lazar 2016 amrhein and greenland 2018 trafimow et al 2018 wasserstein et al 2019 with the main critique summarized in the statement of the american statistical association that the widespread use of statistical significance generally interpreted as p 0 05 as a license for making a claim of a scientific finding or implied truth leads to considerable distortion of the scientific process wasserstein and lazar 2016 other inference techniques for assessing the plausibility of changes under an a priori assumed model are also used most notably change point analysis hinkley 1970 which attempts to identify points of abrupt changes in the data this approach too is very sensitive on a priori hypotheses about the expected degree of variability in the data a brief discussion on the issue in provided in chandler and scott 2011 with a stronger focus on modelling power rather than confirmatory analysis model selection criteria have been developed arising from akaike s work akaike 1969 akaike has contributed to the introduction of information theory into model selection criteria akaike 1974 which are now established worldwide in model inference anderson and burnham 2004 and are increasingly adopted in hydrology as well e g ye et al 2008 laio et al 2009 iliopoulou et al 2018a information criteria are useful in that they try to achieve a better out of sample performance by prompting for parsimony when fitting the model to the calibration set there is a vast literature on the asymptotic equivalence of information criteria and out of sample prediction measures under specific conditions stone 1977 shibata 1980 wei 1992 inoue and kilian 2006 which typically though imply large record lengths a discourse regarding the relative powers of the abovementioned in sample measures compared to the assessment of predictive or out of sample performance is active in numerous scientific fields breiman 2001 stein 2002 inoue and kilian 2006 yarkoni and westfall 2017 shmueli 2010 while in fact it has been argued that the distinction between the two approaches might only arise due to the different objectives of each study gauch et al 2003 inoue and kilian 2005 obviously predictive modelling dominates in operational fields concerned with short term prediction as numerical weather prediction lorenc 1986 and in such domains it is widely acknowledged that the model yielding the best predictions in non stochastic terms is not necessarily the true one shmueli 2010 the premise of this work is that while explanatory performance of trends has been thoroughly explored in hydrological studies e g chandler and scott 2011 provide a comprehensive review on the matter much less attention has been given to the predictive performance of trend modelling a simple explanation might lie in the fact that in many environmental studies trends have been employed as descriptors of changes or causal effects and less as models for predictions in spite of the fact that they strongly communicate expectations for the future by suggesting causal mechanisms e g fig a2 on the combined use of the word trends and projections the second reason could be related to the scarcity of long term environmental data for out of sample validation therefore our aim is to assess the relevance of long term trend modelling in terms of point prediction not examining elements of stochastic prediction and categorically not engaging in the identification of a true model for the data we deem that this shift in point of view may provide contrasting insights to current literature with respect to the relevance of trends for operational applications 3 2 out of sample validation schemes cross validation techniques are a systematic way to assess predictive power stone 1974 simonoff 2012 the procedure typically entails multiple runs of validation schemes on random partitions of the original dataset and summarizes the model skill from the sample of all validation scores standard cross validation is not straightforward to apply for timeseries data where the order of the data must be respected instead the use of a holdout set for validation is frequently applied e g in hydrology this is done by reserving some data for validation while the rest are used for calibration klemeš 1986 we consider an alternative approach respecting the data order by performing calibration and validation in moving window partitions of the original dataset that constantly shift forward in time till the end of the record is reached this approach is known as walk forward analysis in the field of econometrics kirkpatrick and dahlquist 2010 and it is advantageous in that instead of a single measure of out of sample performance obtained by the split sample approach a sample of values is obtained which can be statistically analysed further it compensates for hindsight bias providing realistic estimates of historical predictability of changes by a given model the statistics of a model s past performance can be considered a proxy of its future performance 3 2 1 static calibration and validation we apply this type of analysis to the rainfall records by formulating two distinct calibration validation schemes which are illustrated in fig 2 in the first scheme fig 2a we evaluate the models performance in capturing the variability of the recent 30 year period of each station based on calibration on the prior 30 year period by this static validation scheme we intend to evaluate whether extremes have changed in a consistent manner in the second half of the 20th century as they are commonly assumed we also examine the performance of the models in backward validation i e in predicting observations occurring before the calibration period fig 2a in order to maximize the exploitation of the length of each record we apply this evaluation to the most recent period of each station even if the final dates of all records do not coincide we favour separate treatment of each station since in this case our focus is placed on the operational exploitation of records for predictive purposes and less on a summary of the results for a specific time period however the majority of the records span the whole 20th century and extend beyond with a few exceptions that are mentioned in table a1 in a second examination we directly evaluate changes in the predictive performance of each model throughout the past 110 years up to 2009 specifically we compare the prediction errors of each model for the following climatic periods 1900 1929 calibration period 1870 1899 1930 1959 calibration period 1900 1929 1960 1989 calibration period 1930 1959 and 1980 2009 calibration period 1950 1979 the end year 2009 of the last period overlapping with the previous one by 10 years is selected in order to maximize the number of stations having predictions for all four periods this results to 52 stations for the am and 51 for the at wdav and pd indices 3 2 2 dynamic calibration and validation the second scheme fig 2b focuses on the historical performance of the models by the dynamic else walk forward validation scheme introduced before it assumes a hypothetical observer moving in time and making predictions for the future 30 year period updating the models as access to new information progressively becomes available we formulate two different schemes for making these predictions in the first which we call block moving calibration and validation the models are calibrated on 30 year periods and validated by the next unobserved 30 years and this procedure is repeated by rolling the calibration and validation origin in time fig 2bi new information is gradually taking the place of the past information which is discarded by the 30 year sliding windows the start of the first moving window coincides with the start of each station while the start of the last calibration moving window is 59 years prior to the end of the station so that 30 years of validation data remain available this last validation window is the recent 30 year window that is exploited for validation in the static scheme fig 2a the second scheme of the dynamic calibration validation which we call global moving validates the models using sliding 30 year periods exactly as in the prior scheme but calibrates the models on the whole available record that is known at each time step to the observer therefore the origin of the calibration window remains stable but the window gradually extends in length as more data are assimilated into the model while no data are discarded fig 2bii this scheme explores the potential of employing all available information to make a prediction for the future since the validation periods are the same in both schemes results between the two can be directly compared for the evaluation of the candidate models we estimate the root mean square error a standard and established metric of goodness of fit sharma et al 2019 the rmse is defined as the square root of the mean square error of the predicted values x i with respect to the observed xi 1 r m s e i 1 n x i x i 2 n where n is the length of the data we present the sample rmse distribution of the models for each station and we summarize the results by computing the average rmse for each station and its standard deviation for the longest uninterrupted record of the station we present a comprehensive analysis including the temporal evolution of the errors 3 3 predictive models let x i be a stochastic process in discrete time i i e a collection of random variables x i and x x 1 xn a single realization observation of the latter i e a timeseries we assume that in time i n the hypothetical observer makes a forecast based on a subset of the historical information namely from the entire available information that we have the observed series x 1 xn we assume that the hypothetical observer knows only the subseries x x 1 xi to predict the unobserved periods past or future we employ two model structures the first is the typical linear trend model encompassing two parameters a slope b and an intercept a whose mean μ is a deterministic linear function of time t 2 μ t a b t the trend model is fitted via least squares regression robust regression techniques are also explored namely median quantile regression koenker and hallock 2001 and the theil sen slope estimation sen 1968 theil 1992 but they did not yield better predictions and hence the least squares approach which is also more rigorous in theoretical terms e g papoulis 1990 was retained for details on the application and discussion of the results the reader is referred to the analysis presented in appendix iii the second model considered is the mean model including only one parameter the mean of the calibration period extrapolated to the unobserved periods 3 μ t a according to the followed calibration scheme fitted to block moving local 30 years or to all the known global period the trend model is termed local trend l trend and global trend g trend respectively and likewise the mean model is termed local mean l mean and global mean g mean in the local models the period i 59 i 30 is used for calibration and the i 29 i for validation while in the global models the period 1 i 30 is used for calibration and the i 29 i period for validation as in the former scheme we note that these two seemingly simplistic predictive models i e the linear model fitted with least squares and the local average can be found in a variety of theoretical results in statistical sciences for instance use of temporally local data constitutes a central concept in the k nearest neighbours technique as discussed in hastie et al 2005 as well as in local regression as discussed in chandler and scott 2011 3 4 selected indices of rainfall extremes and quality control we examine four statistical indices of rainfall annual maxima am annual totals at annual wet day average rainfall wdav and probability dry pd also computed at the annual scale as wet we consider any day with rainfall surpassing the threshold of 1 mm while values below this threshold are counted as dry days taken into account for the pd estimation we employ the following criteria for missing values for the annual maxima we use a methodology proposed by papalexiou and koutsoyiannis 2013 according to which an annual maximum in a year with missing values is not accepted if a it belongs to the lowest 40 of the annual maxima values and b 30 or more of the observations for that year are missing for the rest of the indices we do not compute the yearly index in years with more than 15 of missing values in general most records have low percentages of missing values table a1 which in most cases are clustered in the beginning of the records a few records have consecutive missing periods which might imply a change of instrumentation or relocation of the gauge to avoid possible artefacts in trend estimation in static validation in backward validation that may arise from such cases we analyse periods containing less than 5 of consecutive missing values of the yearly indices for the dynamic calibration and validation scheme we fit the models only if there exist at least 27 valid indices in each of the 30 year periods of calibration and validation 3 5 predictability of climatic changes under natural variability in order to understand the predictive performance of the considered models under typical conditions of natural variability we run similar experiments with synthetic timeseries reproducing increasing degrees of persistence we recall that persistence also known as hurst kolmogorov dynamics is associated with enhanced natural variability at all scales koutsoyiannis 2003 which in turn implies increased unpredictability at large time horizons with some potential for predictability at short time steps due to the presence of temporal clustering dimitriadis et al 2016 this provides a scientifically relevant comparison to the empirical data as rainfall series are known to exhibit mild to moderate degree of persistence e g iliopoulou et al 2018b iliopoulou and koutsoyiannis 2019 moreover segments of persistent series resemble trends and can easily be misinterpreted as such cohn and lins 2005 therefore we examine both the comparative predictive performance of the four models for persistent processes where long term changes are the rule serinaldi and kilsby 2018 and the effect of available record length on the quality of the model predictions the latter becomes relevant in the global moving scheme in which the calibration period varies in length 4 results 4 1 models performance in static validation results from the performance of the local mean and local trend models on the last 30 years of each station as well as on the years preceding the 30 year calibration are shown in fig 3 for all studied indices the local mean model performs on average better than the local trend model for all indices in capturing their most recent changes of extremes while the performance of the local trend deteriorates considerably with respect to hindcasting the past interestingly the larger discrepancies of the trends both in future and past validation periods are encountered in the annual maxima followed by probability dry in most of the opposite cases of trends showing a better performance the fitted slope is very mild thus hardly differing from the local mean a visual examination of the plots of the 60 long term stations provided in the appendix figures a4 a7 suggests a positive answer to the opening question providing empirical evidence that climatic trends fluctuate and in fact abruptly reverse in order to gain further insights into temporal changes of predictability we compare the predictive performance of each model l mean l trend for four distinct climatic periods covering the past 110 years up to year 2009 it is observed fig 4 that the error distribution of the l trend model does not present pronounced temporal differences for the indices among these periods with the exception of pd which shows a larger yet not consistent variability over these periods among the four periods the l trend model performed best in the prediction of the 1960 1989 period based on calibration on 1930 1959 a period which however does not include the decades of pronounced increase in greenhouse emissions from the 60 s and thereafter the predictive performance of trends on the latest period is not markedly different from the previous periods if not it is slightly worse for some indices e g the at a particular pattern is neither observed for the l mean as it will be discussed next these results seem to be well within the range of the statistical variability of the predictive skill of each model evaluated from the whole record finally in this examination as well the l mean model proves superior to the l trend only one or two exceptions are seen 4 2 moving window validation of predictive performance in this section we explore the predictive qualities of the models by delving into the statistical analysis of the whole record considering the models from the global moving calibration as well namely the global trend and the global mean 4 2 1 an examination of one of the longest records as an illustration of the application of the methodology we first explore the longest uninterrupted station of our dataset i e the prague station in czech republic 211 years shown in fig 5 the models error evolution pattern is reflective of their performance for the majority of time the mean models are at the lower front of the errors with the local mean model showing slightly superior performance the local trend model results in higher errors and its predictions may quickly deteriorate taking longer to converge to the mean models predictions in areas of lower errors fig 5 this is attributed to the fact that the trend model projects to the future sensitive features of the calibration period i e extreme observations or trendy behaviour which do not have a high chance to survive the end of the calibration sample the more parsimonious structure of the mean model encapsulates minimal but robust knowledge of the process behaviour which is more likely to characterize its future evolution as well in the absence of an underlying global trend and as the sample grows larger the global trend model converges to the predictions of the mean models but its performance remains slightly inferior even towards the end of the record 4 2 2 application to all records figs 6 9 show the empirical distributions of the models prediction rmse for each rainfall index and for all 60 stations for most stations the local mean and global mean models have the lower probabilities of exceeding high errors contrary to the local trend model whose error distribution is clearly shifted to the right in the higher error area the distribution of the prediction rmse of the global trend model is located in between the two showing in general a better behaviour than the local trend a summary of the distributional properties of the prediction rmse of all stations shown in figs 6 9 is provided in fig 10 in terms of the average and the standard deviation of the rmse distribution of each station the average values of the latter also summarized in table 1 accordingly the models performance can be ranked from best to worst as follows 1 local mean 2 global mean 3 global trend and 4 local trend the local mean model marginally outperforms the global mean with respect to the average rmse yet in terms of the standard deviation of the rmse distribution fig 10b d f h it is evident that the local mean model prevails showing smaller standard deviation of prediction errors and thus more reliable performance in this case the linear trend model shows markedly inferior performance 4 3 models performance under natural variability 4 3 1 an experiment with synthetic series following the rationale outlined in section 3 5 the goal of this experiment is to test the performance of the predictive models in conditions of enhanced structured uncertainty characterized by changes at all scales and trend like behaviour for small periods as the latter are distinctive features of persistent processes koutsoyiannis 2002 we produce five long term timeseries from a standard normal distribution with length n 10 000 that reproduce hk dynamics using the sma algorithm koutsoyiannis 2000 dimitriadis and koutsoyiannis 2018 the series are generated with increasing degree of persistence quantified through the hurst parameter h from mild persistence h 0 6 to very strong h 0 99 in order to explore the impact of record length we also examine smaller segments of the same timeseries of lengths n 100 and n 1000 because smaller segments are impacted by larger estimation uncertainty we plot the average ecdf of the prediction rmse estimated from non overlapping segments extracted from the original timeseries of length n 10000 therefore the n 100 plots correspond to the average of 100 timeseries of length 100 derived from the 10 000 series likewise the n 1000 series are the average of 10 timeseries of length 1000 the plots of the ecdf distribution fig 11 of the prediction rmse for the four predictive models are produced employing the same dynamic validation schemes applied for the real world stations the contrasting performance of the two local models is observed here as well local features are better exploited by the mean rather than the trend model irrespective of the record size the latter becomes important when the global models are considered in the absence of a global underlying trend the increased variability encountered in small calibration samples n 100 leads the global trend model to bad predictions when the trend model is calibrated from larger series the trend component is smoothed out and therefore the prediction performance approaches the one from the mean models regarding the competition between global and local mean it appears that it is a function of both the record length and degree of persistence for large record lengths and h 0 7 the local mean model prevails while for small record lengths and medium persistence the two are comparable in persistent process where clustering arises local information is likely to be more relevant for prediction yet for long term prediction as is the case here local may need to extend a few steps back in the past which for small record lengths could be within the reach of the calibration period employed for the global mean model obviously though results from the global model become less relevant when the sample is large and therefore global information extends too far in the past a thorough treatment of the theoretical basis and practical formulation of local mean models in relation to the persistence properties of the parent process is given by koutsoyiannis 2020b we note that the behavior observed in the n 100 plots is qualitatively consistent with the one observed from the rainfall records moreover indices known for their persistence properties such as annual totals iliopoulou et al 2018b tyralis et al 2018 and probability dry koutsoyiannis 2006 show a slight preference for the local mean model while others where persistence is less manifested as annual maxima iliopoulou and koutsoyiannis 2019 the performance of the global and the local mean model in terms of the average rmse are indistinguishable fig 10 the variance of the errors still being smaller for the latter 4 3 2 a discussion on parsimony and predictive accuracy in the above controlled experiment where the generating mechanism of the data is known it is evident that among the four false models the local mean yields the most accurate predictions in terms of rmse using in sample data more efficiently by means of its single parameter the increase in predictive accuracy and statistical efficiency is tightly associated with the notion of parsimony which is a dual criterion measuring the model s fit to the data as well its simplicity gauch et al 2003 in these terms the local mean model is deemed to be a parsimonious model since it fits the out of sample data either better or at least equally well to the more complicated trend model the reason behind the sometimes interchangeable use of the words parsimony and simplicity is a certain tendency of simple models to make reliable predictions which among other approaches as information criteria discussed in section 3 1 is also incorporated as a concept in bayesian analysis assigning higher prior probabilities to simpler models and a posteriori favouring the simpler model berger and bernardo 1992 berger and pericchi 1996 gauch et al 2003 and references therein more recent developments from the bayesian standpoint include constructing penalized complexity priors simpson et al 2017 while the concept informs variable selection in linear regression though various techniques as the lasso and ridge regression tibshirani 1996 another demonstration of the relation between predictive accuracy and simplicity is the possibly better predictive performance in terms of mean square error of simpler yet misspecified models compared to the ones derived from the correctly structured model hocking 1976 for instance wu et al 2007 provided a set of conditions for which this holds true in the case of linear models therefore theoretical arguments are in favour of simpler predictive models all the more so in the case of natural processes characterized by a great degree of variability for which our understanding is limited a comprehensive discussion on the connection of simplicity to wider epistemological and philosophical principles is provided in gauch et al 2003 4 3 3 on alternative climatic predictors of rainfall it is beyond the scope of the paper to formulate and suggest a good climatic prediction method for rainfall having shown however that past climatic trends of rainfall are not useful predictors of its future evolution it is tempting to reflect on a common alternative option for long term prediction namely the use of large scale climatic oscillations the latter are considered a potential source of decadal climatic predictability latif et al 2006 the predictive skill arising from the use of a climatic oscillation as a covariate for prediction relies upon two factors existence of significant correlation of rainfall with large scale climatic oscillations and reliable predictability of the latter on the over decadal climatic scale examined here fulfilment of both conditions is challenging there is an increasing number of studies relating climatic oscillations to decadal rainfall but both the type of the correlated oscillation and the specification of the correlation type lagged response are region specific e g krichak et al 2002 scaife et al 2008 lee and ouarda 2010 sun et al 2015 krishnamurthy and krishnamurthy 2016 nalley et al 2019 therefore with respect to multi sites analyses the identification of robust response patterns of decadal rainfall to climatic oscillations constitutes a nontrivial research subject even more challenging is the predictability of the climatic oscillations themselves on the 30 year scale for instance it is only during the last 5 years that prediction of the north atlantic oscillation nao has become skilful on the seasonal scale and at the moment research efforts are directed towards predictability on beyond annual scales scaife et al 2014 smith et al 2016 while some progress has been reported in terms of the decadal predictability of climatic oscillations related to the nao as the atlantic multi decadal oscillation amo predictability of the actual values of the nao beyond the seasonal scale remains very limited smith et al 2016 yeager and robson 2017 a relevant case study by lee and ouarda 2010 concluded that predictions of decadal streamflow extremes using the nao as a covariate were impacted by large uncertainty to the point of almost being non informative although a promising research subject it appears that in the best case there is still way to go before attaining hydrologically relevant climatic predictions based on climatic oscillations at least to the degree that this is becoming possible at the seasonal scale for some regions e g scaife et al 2014 yet the case that this proves to be infeasible cannot be excluded koutsoyiannis 2010 4 3 4 can a stationary framework be compatible with a deterministic forcing a question that often arises is the relevance of past predictability under the hypothesis of a climate impacted by monotonic anthropogenic forcing not existing in the past in this case it could be argued that the examination of the predictive performance in the past in which stationarity is implicitly assumed is an irrelevant approach as the past might no longer representative be of the future as a first remark it is worth recalling that change is not synonymous to non stationarity while in the presence of uncertainty in every real world system the choice of a stationary versus a non stationary model is done in terms of modelling convenience rather than based on the existence or co existence of deterministic drivers montanari and koutsoyiannis 2014 koutsoyiannis and montanari 2015 de luca et al 2019 yet shed further light on this misconception by the following experiment they show that artificially imposed trends of the projected magnitude of climate scenarios on the parameters of a sub hourly rainfall generator regarding bursts intensity duration and number of occurrences were masked on coarser temporal scales and as a result they could be adequately modelled by a stationary extreme value model this suggests that the presence of deterministic drivers in a system does not disfavour stationary modelling for there is the possibility that even systematic changes may not be manifested at the scales of interest to the degree that they warrant a more complicated representation for the future hence the examination of a stationary framework is justified also in the presence of monotonic and accelerating forcing as it aligns with the abovementioned principle of parsimonious modelling therefore the question shifts from the existence or not of deterministic drivers to evaluation of the degree to which observed changes require a more complicated modelling in our case it is assumed that the past is still representative enough for the future in order to achieve a similar degree of predictability by the given models which is not falsified by the examination of the recent period the entire question however relies on a simplistic view of complex systems i e that just one factor or the change thereof suffices to determine the system s future evolution in our view this is not a logically consistent framework for dealing with complex systems 5 summary and conclusions under the popular assumption of intensification of the water cycle due to global warming a considerable deal of contemporary research in hydrology revolves around the study of temporal changes of extremes with the application of trend analyses being on the rise during the past two decades as illustrated in appendix i while the explanatory analysis of trends has dominated the relevant studies assessment of the predictive skill of trend models has not been equally assessed despite the apparent significance of such a task for risk planning this research reframes the problem of trend evaluation as a model selection problem oriented towards identifying the model with the best predictive qualities in deterministic terms which is neither equivalent to the true model nor to the model better at explaining the in sample data for this purpose we introduce a systematic framework for evaluating projections of trends by means of comparing the prediction rmse to the one obtained from simpler mean models we perform a variation of cross validation also known as walk forward analysis devising two distinct calibration and validation schemes fig 2 in block moving calibration we fit the linear trend and mean models to 30 years of data local trend and local mean and we validate the results based on the outcome of their predictions for the next 30 years repeating the procedure using sliding windows till the end of the record is met in global moving calibration we fit the models to all the known period global trend and global mean assuming that in the beginning one knows only the first 30 years and progressively the calibration sample grows larger in this case too we evaluate the outcome of the predictions of the models for the next 30 years therefore the projections of the four models can be compared in terms of the statistics of their empirical distribution of errors the models compete in predicting the out of sample behaviour of four rainfall indices annual maxima annual totals annual wet day average rainfall and probability dry at the annual scale as estimated from a unique dataset comprising the 60 longest rainfall records surpassing 150 years of daily data results show that models rank from best to worst as follows local mean global mean global trend and local trend a separate examination of the latest 30 year period for each station confirmed the above rank of the models as well the temporal changes in the prediction error distribution among four fixed climatic periods common for all stations covering 110 years up to 2009 are also investigated fluctuations of predictability do occur among the climatic periods yet no increase in predictability is achieved by the local trend model for the latest period 1980 2009 compared to earlier periods results from both analyses show that future rainfall variability is on average better predicted by mean models since local trend models identify features of the process that are unlikely to survive the end of the calibration period either being extreme observations or trend like behaviour these features are smoothed out in longer segments which is the reason behind the better performance of global trends robust regression techniques were also employed for the calibration of local trends but perhaps not surprisingly did not improve the out of sample predictions see discussion in appendix iii in an attempt to reproduce the observed behaviour we generate long term timeseries exhibiting long term persistence or hk dynamics koutsoyiannis 2011 o connell et al 2016 dimitriadis 2017 and carry out the same analysis persistent processes show enhanced variability and a user unfamiliar with their properties may misinterpret segments of their timeseries as trends which perhaps explains why trend claims have been that common lately results from the synthetic records show qualitative similarities with the ones from empirical rainfall records known to exhibit persistence depending on the scale and studied index koutsoyiannis 2006 markonis and koutsoyiannis 2016 iliopoulou et al 2018b iliopoulou and koutsoyiannis 2019 the local and global mean outperform the local trend model for all degrees of persistence and sample sizes while for small record lengths n 100 the performance of the global trend model is notably inferior too local and global mean models hardly show differences for medium degrees of persistence but the local mean prevails for strong persistence from a systematic investigation of long term rainfall records corroborated by simulation results we have verified that local trends have poor out of sample performance being outperformed in their predictions by simpler models as the local mean this empirical finding suggests that the large inherent variability present in the rainfall process makes the practice of extrapolating local features in the long term future dubious especially when the complexity of the latter increases this in turn questions the theoretical and practical relevance of projections of rainfall trends and the grounds of the related abundant publications credit authorship contribution statement theano iliopoulou conceptualization methodology data curation formal analysis software visualization writing original draft demetris koutsoyiannis conceptualization methodology validation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the editor andras bardossy for handling the review of the paper as well as the associate editor felix frances the eponymous reviewer robert m hirsch and an anonymous reviewer for providing constructive comments which resulted in substantial improvements we greatly thank the radcliffe meteorological station the icelandic meteorological office trausti jónsson the czech hydrometeorological institute the finnish meteorological institute the national observatory of athens the department of earth sciences of the uppsala university and the regional hydrologic service of the tuscany region servizio idrologico regione toscana it for providing the required data for each region respectively we are also grateful to professor ricardo machado trigo university of lisbon for providing the lisbon timeseries to professor marco marani university of padua for providing the padua timeseries and to professor joo heon lee joongbu university for providing the seoul timeseries all the above data were freely provided after contacting the acknowledged sources the remaining timeseries are publicly available by the data providers in the eca d project http www ecad eu and in the ghcn daily database https data noaa gov dataset global historical climatology network daily ghcn daily version 3 the analyses were performed in the python 2 6 python software foundation python language reference version 2 7 available at http www python org using the contributed packages pandas scipy and seaborn academic word occurrence code developed by strobel 2018 available at http doi org 10 5281 zenodo 1218409 appendix i a brief quantitative literature review the aim of this literature review is to evaluate the academic interest in trends of rainfall variables by means of a quantitative analysis of research papers appearing in google scholar we base this analysis on the quantification of the occurrence of associated words in google scholar using python code developed by strobel 2018 omitting results related to citations and patents this analysis was performed on 21 10 2019 and in order to refer to full calendar years it contains results published till the end of 2018 in fig a1 we show the temporal evolution of the ratio of appearance of the word trends in items also containing the complete list of words precipitation hydrology extremes results have been randomly varying from the beginning till the mid 20th century when there were less than 100 results per year fulfilling the criteria of containing the list in the denominator of the ratio it can be seen though that approximately from the 1960 and later on there has been an increasing trend in relevant publications containing the word trends reaching 89 in 2018 obviously results belonging to a different context than the one assumed might have been calculated as well but we assume their effect to be analogous both in the nominator and the denominator of the ratio thus not significantly affecting the conclusion to further refine our search to more technical papers explicitly referring to rainfall trends we define the following search terms word combination a is the full list precipitation rainfall trends precipitation rainfall data records where the symbol refers to or and word combinations inside should be found together i e one possible combination is the list precipitation trends rainfall data word combination b is an extension of word combination a that also includes the word projections while word combination c is an extension of word combination a also including the word sequence linear trend trends model regression the absolute numbers of the results are shown in fig a2a while in fig a2b we show their relative ratio expectedly the total number of studies containing rainfall trends are rising however this is not surprising in terms of absolute numbers considering the increasing availability of papers in scholar over the years however the use of the word projections appears to be increasing in relative terms as well the relative use of word combination c related to the linear trend has slightly increased too over the years stabilizing over the past 5 year period to approximately half of the related publications fig a2b as a final refinement we consider words appearing only in the title of papers which should limit the results to strictly related papers results are shown in fig a3 the standard term that is contained in every result is rainfall precipitation followed by the appearance anywhere in the title of the single terms trends trend variability change changes and non stationary non stationarity nonstationary nonstationarity note that we consider also plural terms where applicable as well as possible differences in spelling while this time we do not require words to be found in a specific order as in the previous in text search for instance it could be trends in rainfall or rainfall trends in the we do not compute ratios over the items containing in their title the words rainfall precipitation because these terms alone are too generic and can be found in a variety of studies a significant part of which are only loosely related to hydrology e g physics chemistry radar technologies etc instead to provide a more relevant reference point for comparison we use two words semantically uncharged with the trend concept which are however widely used in combination with the standard terms namely the words model and distribution e g a rainfall model or the distribution of the precipitation apparently the conceptually more inclusive terms changes and variability are ranking first in the related search terms with the explicit use of the word trend s ranking third yielding consistently over the last ten years above 200 results per year 288 in 2018 as per results appearing on google scholar on 21 10 2019 terms related to non stationarity are slowly rising over the past ten years 39 in title results in 2018 while being close to zero before 2000 it is interesting to note the evolution of the use of terms explicitly associated with the temporal properties of rainfall compared to the terms more related to marginal properties distribution or being more of a general use perhaps implying both properties model the mere use of the word trend s has exceeded the use of an all times classic word for rainfall i e distribution which clearly shows a certain shift in academic interest likewise the ever higher scoring word model has been outnumbered in the past three years by the word change s in conjunction these results suggest that over the last two decades there has been a rising scientific interest in the temporal properties of rainfall and their future evolution with trends taking up a considerable share of this emerging focus appendix ii rainfall records properties and long term variability table a1 summarizes the properties of the long term rainfall stations in figs a4 a7 we illustrate the static validation scheme showing results from the projections of the local trend and the local mean model for all rainfall indices appendix iii fitting algorithms least squares vs robust regression we explore the effect of the linear trend definition and fitting algorithm on the results of the local trends as trends in small segments are expected to be more sensitive to the choice of the fitting algorithm santer et al 2000 the first algorithm is the widely used ordinary least square estimation ols which fits eq 2 to the data by minimizing the sum of the squares of the differences between the observed data and the predictions of the linear model secondly two alternative trend calibration approaches are explored that place less weight on influential observations outliers and thus belong to the range of robust regression techniques the first is the least absolute deviations lad method which estimates the regression coefficients by minimising the sum of absolute deviations of the predicted from the observed values and is a special case of quantile regression fitting the trend line to the median of the observations rather than the mean chandler and scott 2011 the second is the non parametric method of theil sen slope estimation sen 1968 theil 1992 which estimates the slope b of the linear model as the median of the pairwise slopes of all sample points among the different approaches that exist for the intercept coefficient we follow conover 1980 and estimated the intercept as a y 0 5 b x 0 5 where y 0 5 and x 0 5 are the sample medians results from the comparison of the prediction rmse from these three algorithms are shown in fig a8 evidently the ordinary least square regression performs better than the lad regression while its results are very close to the theil sen regression therefore the ols estimator is retained for the main analysis due to its better performance compared to the lad estimator non ambiguity in definition compared to the theil sen estimator and well studied mathematical properties papoulis 1990 as a final note we underline that the notion of robustness of statistical regression has arisen as a positive trait for systems with known and expected behaviour where extreme values are considered either outliers or erroneous measurements which contaminate the record yet for natural systems producing extremes as part of a large and inherent variability and exhibiting irregular trends difficult or perhaps impossible to attribute to causal mechanisms we deem that there might be no theoretical reason behind the expected superiority of robust statistics which is in fact empirically shown in this experiment 
5310,non stationarity approaches have been increasingly popular in hydrology reflecting scientific concerns regarding intensification of the water cycle due to global warming a considerable share of relevant studies is dominated by the practice of identifying linear trends in data through in sample analysis in this work we reframe the problem of trend identification using the out of sample predictive performance of trends as a reference point we devise a systematic methodological framework in which linear trends are compared to simpler mean models based on their performance in predicting climatic scale 30 year annual rainfall indices i e maxima totals wet day average and probability dry from long term daily records the models are calibrated in two different schemes block moving i e fitted on the recent 30 years of data obtaining the local trend and local mean and global moving i e fitted on the whole period known to an observer moving in time thus obtaining the global trend and global mean the investigation of empirical records spanning over 150 years of daily data suggests that a great degree of variability has been ever present in the rainfall process leaving small potential for long term predictability the local mean model ranks first in terms of average predictive performance followed by the global mean and the global trend in decreasing order of performance while the local trend model ranks last among the models showing the worst performance overall parallel experiments from synthetic timeseries characterized by persistence corroborated this finding suggesting that future long term variability of persistent processes is better captured using parsimonious features of the past in line with the empirical findings it is shown that prediction wise simple is preferable to trendy keywords trends rainfall extremes probability dry out of sample validation predictive performance rainfall projections 1 introduction a trend is a trend is a trend but the question is will it bend will it alter its course through some unforeseen force and come to a premature end sir alec cairncross 1969 signing as stein age forecaster in the past decades there has been a plethora of trend analyses in rainfall studies bunting et al 1976 haylock and nicholls 2000 2000 rotstayn and lohmann 2002 modarres et al 2007 ntegeka and willems 2008 kumar et al 2010 and it could be argued that relevant studies are still on the rise e g biasutti 2019 degefu et al 2019 folton et al 2019 khan et al 2019 papalexiou and montanari 2019 de quadros et al 2019 rahimi and fatemi 2019 for a quantitative analysis of the relevant literature the reader is referred to appendix i this boom of trend studies has had various scopes most of which are related to global warming assessment ipcc 2013 these include historic climate variability quantification attribution to deterministic drivers projections to the future and impact assessments e g kumar et al 2010 parmesan and yohe 2003 biasutti 2013 rotstayn and lohmann 2002 arguably what is common in the majority of trend studies even when not explicitly stated is the expectation for a monotonically changing future which as a result has initiated a growing discourse on the appropriate modelling approach in climatology and hydrology there has been an ongoing debate between stationary vs nonstationary methods with the former representing a well established hydrological practice montanari and koutsoyiannis 2014 koutsoyiannis and montanari 2015 and the latter reflecting recent attempts of the scientific community to find a new way to respond to change and uncertainty under the anthropogenic climate change scenario milly et al 2008 craig 2010 milly et al 2015 yet deterministic trend modelling has been examined and mostly criticized on different grounds namely with respect to empirical evidence mckitrick and christy 2019 cohn and lins 2005 theoretical consistency koutsoyiannis and montanari 2015 modelling efficiency montanari and koutsoyiannis 2014 and meaningfulness of the results serinaldi et al 2018 it has also been argued that the concepts of change and uncertainty are already well represented within the stationarity framework koutsoyiannis and montanari 2007 serinaldi and kilsby 2018 in this research we examine the trend modelling framework from a new perspective through the evaluation of its out of sample modelling qualities namely its predictive powers for a given record for this purpose we introduce a validation framework for the evaluation of the results adding simpler mean models in the pool of candidates and basing the reasoning of model selection on the statistical out of sample performance of the models while split sample techniques klemeš 1986 and multi model approaches georgakakos et al 2004 duan et al 2007 are certainly not new in hydrology they are usually disregarded as concepts in the field of trend modelling where the research question typically revolves around explanatory performance mostly by means of in sample measures as hypothesis testing shmueli 2010 in this work we extend the simple split sample validation by introducing a moving window calibration and validation approach that progressively scans each record by sliding windows of climatic length i e 30 years according to the common climate definition ipcc 2013 in this manner we obtain a sample of estimates of the models predictive performance instead of a single value by shifting the focus to the predictive modelling of linear trend this analysis seeks to answer the following key questions a how well are the rainfall statistics of the most recent climatic period predicted by the linear trend calibrated to the prior 30 year period and b how do the statistics of the predictive performance of linear trends compare to the ones derived from application of simple mean models the first question is driven by the omnipresent scientific concerns regarding intensification of extremes due to global warming during the last decades e g houghton et al 1991 parmesan and yohe 2003 oreskes 2004 solomon et al 2007 mccarl et al 2008 moss et al 2010 craig 2010 pachauri et al 2014 kellogg 2019 according to the fifth latest ipcc assessment ipcc 2013 the expected intensification mechanism suggests a 6 7 increase of the global water vapour per c of warming followed by a 1 3 increase in global mean precipitation recently the physical assumptions behind these estimates have been questioned and revisited in light of global datasets koutsoyiannis 2020a while the evaluation of hydrological impacts from increased greenhouse emissions remains an open research subject with often conflicting evidence e g hirsch and ryberg 2012 marani and zanetti 2015 blöschl et al 2019 therefore the first examination of predictability is consciously biased in favour of a model capturing the variability of the most recent period of data the second question introduces the abovementioned methodological framework for validating model predictions which is applied to the empirical long term rainfall records as well as to synthetic series produced in order to mimic the natural long term variability of the rainfall process a discussion on the relevance of the framework in light of potential deterministic changes is also provided 2 dataset our dataset is an update of the previous long term dataset explored in iliopoulou et al 2018a of long rainfall records surpassing 150 years of daily values it includes the 60 longest available daily rainfall records collected from global datasets i e the global historical climatology network daily database menne et al 2012 the european climate assessment and dataset klein tank et al 2002 as well as third parties listed in in the appendix ii table a1 along with a brief summary of the stations properties the geographic location of the rain gauges is shown in fig 1 the length of the timeseries provides rare insights into long term rainfall variability and enables the statistical evaluation of the predictive performance of linear trends from multiple time windows 3 methodological framework 3 1 overview of literature approaches to trend modelling from explanatory trends to out of sample performance it is well known that studying the explanatory power of trends in hydroclimatic data is a very active research field see the literature analysis included in the appendix i for the rising use of relevant in text words as well as in title words from google scholar before discussing literature modelling strategies for trends it is imperative to define the meaning of a trend per se although trends are frequently used as a synonym of temporal changes fig a3 provides a quantitative analysis on the use of both words and their notion has sometimes been extended to encompass stochastic stationary models fatichi et al 2009 chandler and scott 2011 the general idea behind the trend concept is that the expected value of a response variable y is specified as a deterministic function of time t e y f t the function f may take different forms the linear model being only the first one adopted and the most widely used indeed this definition of a trend can be traced back to the development of the field of econometrics in the early 20th century when secular trends meaning long term trends were deemed to be a component of financial timeseries along with seasonal variation cycles and residual elements persons 1922 mitchell 1930 decomposition of a timeseries into components one of them being a trend continued to dominate the econometrics literature although even at early times certain critiques were raised slutsky 1927 the most established technique to evaluate fitted trends is statistical hypothesis testing i e a statistical inference technique that estimates the probability of an outcome as far from what is expected as the observed under the assumption that the null hypothesis is true gauch et al 2003 the latter is known as the p value and is compared to predefined significance levels in order to reject or not the null hypothesis this is a scientific method for model evaluation which has been in part misused for instance its misuse in hydrology has been showcased by seminal studies e g cohn and lins 2005 koutsoyiannis and montanari 2007 serinaldi et al 2018 which have established the fact that for hydrological non i i d data the null hypothesis which tacitly contains independence is a priori wrong and its rejection if correctly interpreted should point out to the wrong independence assumption still the common practice has been to misinterpret outcomes in favour of trends part of the statistician community argues against the concept of significance testing nuzzo 2014 wasserstein and lazar 2016 amrhein and greenland 2018 trafimow et al 2018 wasserstein et al 2019 with the main critique summarized in the statement of the american statistical association that the widespread use of statistical significance generally interpreted as p 0 05 as a license for making a claim of a scientific finding or implied truth leads to considerable distortion of the scientific process wasserstein and lazar 2016 other inference techniques for assessing the plausibility of changes under an a priori assumed model are also used most notably change point analysis hinkley 1970 which attempts to identify points of abrupt changes in the data this approach too is very sensitive on a priori hypotheses about the expected degree of variability in the data a brief discussion on the issue in provided in chandler and scott 2011 with a stronger focus on modelling power rather than confirmatory analysis model selection criteria have been developed arising from akaike s work akaike 1969 akaike has contributed to the introduction of information theory into model selection criteria akaike 1974 which are now established worldwide in model inference anderson and burnham 2004 and are increasingly adopted in hydrology as well e g ye et al 2008 laio et al 2009 iliopoulou et al 2018a information criteria are useful in that they try to achieve a better out of sample performance by prompting for parsimony when fitting the model to the calibration set there is a vast literature on the asymptotic equivalence of information criteria and out of sample prediction measures under specific conditions stone 1977 shibata 1980 wei 1992 inoue and kilian 2006 which typically though imply large record lengths a discourse regarding the relative powers of the abovementioned in sample measures compared to the assessment of predictive or out of sample performance is active in numerous scientific fields breiman 2001 stein 2002 inoue and kilian 2006 yarkoni and westfall 2017 shmueli 2010 while in fact it has been argued that the distinction between the two approaches might only arise due to the different objectives of each study gauch et al 2003 inoue and kilian 2005 obviously predictive modelling dominates in operational fields concerned with short term prediction as numerical weather prediction lorenc 1986 and in such domains it is widely acknowledged that the model yielding the best predictions in non stochastic terms is not necessarily the true one shmueli 2010 the premise of this work is that while explanatory performance of trends has been thoroughly explored in hydrological studies e g chandler and scott 2011 provide a comprehensive review on the matter much less attention has been given to the predictive performance of trend modelling a simple explanation might lie in the fact that in many environmental studies trends have been employed as descriptors of changes or causal effects and less as models for predictions in spite of the fact that they strongly communicate expectations for the future by suggesting causal mechanisms e g fig a2 on the combined use of the word trends and projections the second reason could be related to the scarcity of long term environmental data for out of sample validation therefore our aim is to assess the relevance of long term trend modelling in terms of point prediction not examining elements of stochastic prediction and categorically not engaging in the identification of a true model for the data we deem that this shift in point of view may provide contrasting insights to current literature with respect to the relevance of trends for operational applications 3 2 out of sample validation schemes cross validation techniques are a systematic way to assess predictive power stone 1974 simonoff 2012 the procedure typically entails multiple runs of validation schemes on random partitions of the original dataset and summarizes the model skill from the sample of all validation scores standard cross validation is not straightforward to apply for timeseries data where the order of the data must be respected instead the use of a holdout set for validation is frequently applied e g in hydrology this is done by reserving some data for validation while the rest are used for calibration klemeš 1986 we consider an alternative approach respecting the data order by performing calibration and validation in moving window partitions of the original dataset that constantly shift forward in time till the end of the record is reached this approach is known as walk forward analysis in the field of econometrics kirkpatrick and dahlquist 2010 and it is advantageous in that instead of a single measure of out of sample performance obtained by the split sample approach a sample of values is obtained which can be statistically analysed further it compensates for hindsight bias providing realistic estimates of historical predictability of changes by a given model the statistics of a model s past performance can be considered a proxy of its future performance 3 2 1 static calibration and validation we apply this type of analysis to the rainfall records by formulating two distinct calibration validation schemes which are illustrated in fig 2 in the first scheme fig 2a we evaluate the models performance in capturing the variability of the recent 30 year period of each station based on calibration on the prior 30 year period by this static validation scheme we intend to evaluate whether extremes have changed in a consistent manner in the second half of the 20th century as they are commonly assumed we also examine the performance of the models in backward validation i e in predicting observations occurring before the calibration period fig 2a in order to maximize the exploitation of the length of each record we apply this evaluation to the most recent period of each station even if the final dates of all records do not coincide we favour separate treatment of each station since in this case our focus is placed on the operational exploitation of records for predictive purposes and less on a summary of the results for a specific time period however the majority of the records span the whole 20th century and extend beyond with a few exceptions that are mentioned in table a1 in a second examination we directly evaluate changes in the predictive performance of each model throughout the past 110 years up to 2009 specifically we compare the prediction errors of each model for the following climatic periods 1900 1929 calibration period 1870 1899 1930 1959 calibration period 1900 1929 1960 1989 calibration period 1930 1959 and 1980 2009 calibration period 1950 1979 the end year 2009 of the last period overlapping with the previous one by 10 years is selected in order to maximize the number of stations having predictions for all four periods this results to 52 stations for the am and 51 for the at wdav and pd indices 3 2 2 dynamic calibration and validation the second scheme fig 2b focuses on the historical performance of the models by the dynamic else walk forward validation scheme introduced before it assumes a hypothetical observer moving in time and making predictions for the future 30 year period updating the models as access to new information progressively becomes available we formulate two different schemes for making these predictions in the first which we call block moving calibration and validation the models are calibrated on 30 year periods and validated by the next unobserved 30 years and this procedure is repeated by rolling the calibration and validation origin in time fig 2bi new information is gradually taking the place of the past information which is discarded by the 30 year sliding windows the start of the first moving window coincides with the start of each station while the start of the last calibration moving window is 59 years prior to the end of the station so that 30 years of validation data remain available this last validation window is the recent 30 year window that is exploited for validation in the static scheme fig 2a the second scheme of the dynamic calibration validation which we call global moving validates the models using sliding 30 year periods exactly as in the prior scheme but calibrates the models on the whole available record that is known at each time step to the observer therefore the origin of the calibration window remains stable but the window gradually extends in length as more data are assimilated into the model while no data are discarded fig 2bii this scheme explores the potential of employing all available information to make a prediction for the future since the validation periods are the same in both schemes results between the two can be directly compared for the evaluation of the candidate models we estimate the root mean square error a standard and established metric of goodness of fit sharma et al 2019 the rmse is defined as the square root of the mean square error of the predicted values x i with respect to the observed xi 1 r m s e i 1 n x i x i 2 n where n is the length of the data we present the sample rmse distribution of the models for each station and we summarize the results by computing the average rmse for each station and its standard deviation for the longest uninterrupted record of the station we present a comprehensive analysis including the temporal evolution of the errors 3 3 predictive models let x i be a stochastic process in discrete time i i e a collection of random variables x i and x x 1 xn a single realization observation of the latter i e a timeseries we assume that in time i n the hypothetical observer makes a forecast based on a subset of the historical information namely from the entire available information that we have the observed series x 1 xn we assume that the hypothetical observer knows only the subseries x x 1 xi to predict the unobserved periods past or future we employ two model structures the first is the typical linear trend model encompassing two parameters a slope b and an intercept a whose mean μ is a deterministic linear function of time t 2 μ t a b t the trend model is fitted via least squares regression robust regression techniques are also explored namely median quantile regression koenker and hallock 2001 and the theil sen slope estimation sen 1968 theil 1992 but they did not yield better predictions and hence the least squares approach which is also more rigorous in theoretical terms e g papoulis 1990 was retained for details on the application and discussion of the results the reader is referred to the analysis presented in appendix iii the second model considered is the mean model including only one parameter the mean of the calibration period extrapolated to the unobserved periods 3 μ t a according to the followed calibration scheme fitted to block moving local 30 years or to all the known global period the trend model is termed local trend l trend and global trend g trend respectively and likewise the mean model is termed local mean l mean and global mean g mean in the local models the period i 59 i 30 is used for calibration and the i 29 i for validation while in the global models the period 1 i 30 is used for calibration and the i 29 i period for validation as in the former scheme we note that these two seemingly simplistic predictive models i e the linear model fitted with least squares and the local average can be found in a variety of theoretical results in statistical sciences for instance use of temporally local data constitutes a central concept in the k nearest neighbours technique as discussed in hastie et al 2005 as well as in local regression as discussed in chandler and scott 2011 3 4 selected indices of rainfall extremes and quality control we examine four statistical indices of rainfall annual maxima am annual totals at annual wet day average rainfall wdav and probability dry pd also computed at the annual scale as wet we consider any day with rainfall surpassing the threshold of 1 mm while values below this threshold are counted as dry days taken into account for the pd estimation we employ the following criteria for missing values for the annual maxima we use a methodology proposed by papalexiou and koutsoyiannis 2013 according to which an annual maximum in a year with missing values is not accepted if a it belongs to the lowest 40 of the annual maxima values and b 30 or more of the observations for that year are missing for the rest of the indices we do not compute the yearly index in years with more than 15 of missing values in general most records have low percentages of missing values table a1 which in most cases are clustered in the beginning of the records a few records have consecutive missing periods which might imply a change of instrumentation or relocation of the gauge to avoid possible artefacts in trend estimation in static validation in backward validation that may arise from such cases we analyse periods containing less than 5 of consecutive missing values of the yearly indices for the dynamic calibration and validation scheme we fit the models only if there exist at least 27 valid indices in each of the 30 year periods of calibration and validation 3 5 predictability of climatic changes under natural variability in order to understand the predictive performance of the considered models under typical conditions of natural variability we run similar experiments with synthetic timeseries reproducing increasing degrees of persistence we recall that persistence also known as hurst kolmogorov dynamics is associated with enhanced natural variability at all scales koutsoyiannis 2003 which in turn implies increased unpredictability at large time horizons with some potential for predictability at short time steps due to the presence of temporal clustering dimitriadis et al 2016 this provides a scientifically relevant comparison to the empirical data as rainfall series are known to exhibit mild to moderate degree of persistence e g iliopoulou et al 2018b iliopoulou and koutsoyiannis 2019 moreover segments of persistent series resemble trends and can easily be misinterpreted as such cohn and lins 2005 therefore we examine both the comparative predictive performance of the four models for persistent processes where long term changes are the rule serinaldi and kilsby 2018 and the effect of available record length on the quality of the model predictions the latter becomes relevant in the global moving scheme in which the calibration period varies in length 4 results 4 1 models performance in static validation results from the performance of the local mean and local trend models on the last 30 years of each station as well as on the years preceding the 30 year calibration are shown in fig 3 for all studied indices the local mean model performs on average better than the local trend model for all indices in capturing their most recent changes of extremes while the performance of the local trend deteriorates considerably with respect to hindcasting the past interestingly the larger discrepancies of the trends both in future and past validation periods are encountered in the annual maxima followed by probability dry in most of the opposite cases of trends showing a better performance the fitted slope is very mild thus hardly differing from the local mean a visual examination of the plots of the 60 long term stations provided in the appendix figures a4 a7 suggests a positive answer to the opening question providing empirical evidence that climatic trends fluctuate and in fact abruptly reverse in order to gain further insights into temporal changes of predictability we compare the predictive performance of each model l mean l trend for four distinct climatic periods covering the past 110 years up to year 2009 it is observed fig 4 that the error distribution of the l trend model does not present pronounced temporal differences for the indices among these periods with the exception of pd which shows a larger yet not consistent variability over these periods among the four periods the l trend model performed best in the prediction of the 1960 1989 period based on calibration on 1930 1959 a period which however does not include the decades of pronounced increase in greenhouse emissions from the 60 s and thereafter the predictive performance of trends on the latest period is not markedly different from the previous periods if not it is slightly worse for some indices e g the at a particular pattern is neither observed for the l mean as it will be discussed next these results seem to be well within the range of the statistical variability of the predictive skill of each model evaluated from the whole record finally in this examination as well the l mean model proves superior to the l trend only one or two exceptions are seen 4 2 moving window validation of predictive performance in this section we explore the predictive qualities of the models by delving into the statistical analysis of the whole record considering the models from the global moving calibration as well namely the global trend and the global mean 4 2 1 an examination of one of the longest records as an illustration of the application of the methodology we first explore the longest uninterrupted station of our dataset i e the prague station in czech republic 211 years shown in fig 5 the models error evolution pattern is reflective of their performance for the majority of time the mean models are at the lower front of the errors with the local mean model showing slightly superior performance the local trend model results in higher errors and its predictions may quickly deteriorate taking longer to converge to the mean models predictions in areas of lower errors fig 5 this is attributed to the fact that the trend model projects to the future sensitive features of the calibration period i e extreme observations or trendy behaviour which do not have a high chance to survive the end of the calibration sample the more parsimonious structure of the mean model encapsulates minimal but robust knowledge of the process behaviour which is more likely to characterize its future evolution as well in the absence of an underlying global trend and as the sample grows larger the global trend model converges to the predictions of the mean models but its performance remains slightly inferior even towards the end of the record 4 2 2 application to all records figs 6 9 show the empirical distributions of the models prediction rmse for each rainfall index and for all 60 stations for most stations the local mean and global mean models have the lower probabilities of exceeding high errors contrary to the local trend model whose error distribution is clearly shifted to the right in the higher error area the distribution of the prediction rmse of the global trend model is located in between the two showing in general a better behaviour than the local trend a summary of the distributional properties of the prediction rmse of all stations shown in figs 6 9 is provided in fig 10 in terms of the average and the standard deviation of the rmse distribution of each station the average values of the latter also summarized in table 1 accordingly the models performance can be ranked from best to worst as follows 1 local mean 2 global mean 3 global trend and 4 local trend the local mean model marginally outperforms the global mean with respect to the average rmse yet in terms of the standard deviation of the rmse distribution fig 10b d f h it is evident that the local mean model prevails showing smaller standard deviation of prediction errors and thus more reliable performance in this case the linear trend model shows markedly inferior performance 4 3 models performance under natural variability 4 3 1 an experiment with synthetic series following the rationale outlined in section 3 5 the goal of this experiment is to test the performance of the predictive models in conditions of enhanced structured uncertainty characterized by changes at all scales and trend like behaviour for small periods as the latter are distinctive features of persistent processes koutsoyiannis 2002 we produce five long term timeseries from a standard normal distribution with length n 10 000 that reproduce hk dynamics using the sma algorithm koutsoyiannis 2000 dimitriadis and koutsoyiannis 2018 the series are generated with increasing degree of persistence quantified through the hurst parameter h from mild persistence h 0 6 to very strong h 0 99 in order to explore the impact of record length we also examine smaller segments of the same timeseries of lengths n 100 and n 1000 because smaller segments are impacted by larger estimation uncertainty we plot the average ecdf of the prediction rmse estimated from non overlapping segments extracted from the original timeseries of length n 10000 therefore the n 100 plots correspond to the average of 100 timeseries of length 100 derived from the 10 000 series likewise the n 1000 series are the average of 10 timeseries of length 1000 the plots of the ecdf distribution fig 11 of the prediction rmse for the four predictive models are produced employing the same dynamic validation schemes applied for the real world stations the contrasting performance of the two local models is observed here as well local features are better exploited by the mean rather than the trend model irrespective of the record size the latter becomes important when the global models are considered in the absence of a global underlying trend the increased variability encountered in small calibration samples n 100 leads the global trend model to bad predictions when the trend model is calibrated from larger series the trend component is smoothed out and therefore the prediction performance approaches the one from the mean models regarding the competition between global and local mean it appears that it is a function of both the record length and degree of persistence for large record lengths and h 0 7 the local mean model prevails while for small record lengths and medium persistence the two are comparable in persistent process where clustering arises local information is likely to be more relevant for prediction yet for long term prediction as is the case here local may need to extend a few steps back in the past which for small record lengths could be within the reach of the calibration period employed for the global mean model obviously though results from the global model become less relevant when the sample is large and therefore global information extends too far in the past a thorough treatment of the theoretical basis and practical formulation of local mean models in relation to the persistence properties of the parent process is given by koutsoyiannis 2020b we note that the behavior observed in the n 100 plots is qualitatively consistent with the one observed from the rainfall records moreover indices known for their persistence properties such as annual totals iliopoulou et al 2018b tyralis et al 2018 and probability dry koutsoyiannis 2006 show a slight preference for the local mean model while others where persistence is less manifested as annual maxima iliopoulou and koutsoyiannis 2019 the performance of the global and the local mean model in terms of the average rmse are indistinguishable fig 10 the variance of the errors still being smaller for the latter 4 3 2 a discussion on parsimony and predictive accuracy in the above controlled experiment where the generating mechanism of the data is known it is evident that among the four false models the local mean yields the most accurate predictions in terms of rmse using in sample data more efficiently by means of its single parameter the increase in predictive accuracy and statistical efficiency is tightly associated with the notion of parsimony which is a dual criterion measuring the model s fit to the data as well its simplicity gauch et al 2003 in these terms the local mean model is deemed to be a parsimonious model since it fits the out of sample data either better or at least equally well to the more complicated trend model the reason behind the sometimes interchangeable use of the words parsimony and simplicity is a certain tendency of simple models to make reliable predictions which among other approaches as information criteria discussed in section 3 1 is also incorporated as a concept in bayesian analysis assigning higher prior probabilities to simpler models and a posteriori favouring the simpler model berger and bernardo 1992 berger and pericchi 1996 gauch et al 2003 and references therein more recent developments from the bayesian standpoint include constructing penalized complexity priors simpson et al 2017 while the concept informs variable selection in linear regression though various techniques as the lasso and ridge regression tibshirani 1996 another demonstration of the relation between predictive accuracy and simplicity is the possibly better predictive performance in terms of mean square error of simpler yet misspecified models compared to the ones derived from the correctly structured model hocking 1976 for instance wu et al 2007 provided a set of conditions for which this holds true in the case of linear models therefore theoretical arguments are in favour of simpler predictive models all the more so in the case of natural processes characterized by a great degree of variability for which our understanding is limited a comprehensive discussion on the connection of simplicity to wider epistemological and philosophical principles is provided in gauch et al 2003 4 3 3 on alternative climatic predictors of rainfall it is beyond the scope of the paper to formulate and suggest a good climatic prediction method for rainfall having shown however that past climatic trends of rainfall are not useful predictors of its future evolution it is tempting to reflect on a common alternative option for long term prediction namely the use of large scale climatic oscillations the latter are considered a potential source of decadal climatic predictability latif et al 2006 the predictive skill arising from the use of a climatic oscillation as a covariate for prediction relies upon two factors existence of significant correlation of rainfall with large scale climatic oscillations and reliable predictability of the latter on the over decadal climatic scale examined here fulfilment of both conditions is challenging there is an increasing number of studies relating climatic oscillations to decadal rainfall but both the type of the correlated oscillation and the specification of the correlation type lagged response are region specific e g krichak et al 2002 scaife et al 2008 lee and ouarda 2010 sun et al 2015 krishnamurthy and krishnamurthy 2016 nalley et al 2019 therefore with respect to multi sites analyses the identification of robust response patterns of decadal rainfall to climatic oscillations constitutes a nontrivial research subject even more challenging is the predictability of the climatic oscillations themselves on the 30 year scale for instance it is only during the last 5 years that prediction of the north atlantic oscillation nao has become skilful on the seasonal scale and at the moment research efforts are directed towards predictability on beyond annual scales scaife et al 2014 smith et al 2016 while some progress has been reported in terms of the decadal predictability of climatic oscillations related to the nao as the atlantic multi decadal oscillation amo predictability of the actual values of the nao beyond the seasonal scale remains very limited smith et al 2016 yeager and robson 2017 a relevant case study by lee and ouarda 2010 concluded that predictions of decadal streamflow extremes using the nao as a covariate were impacted by large uncertainty to the point of almost being non informative although a promising research subject it appears that in the best case there is still way to go before attaining hydrologically relevant climatic predictions based on climatic oscillations at least to the degree that this is becoming possible at the seasonal scale for some regions e g scaife et al 2014 yet the case that this proves to be infeasible cannot be excluded koutsoyiannis 2010 4 3 4 can a stationary framework be compatible with a deterministic forcing a question that often arises is the relevance of past predictability under the hypothesis of a climate impacted by monotonic anthropogenic forcing not existing in the past in this case it could be argued that the examination of the predictive performance in the past in which stationarity is implicitly assumed is an irrelevant approach as the past might no longer representative be of the future as a first remark it is worth recalling that change is not synonymous to non stationarity while in the presence of uncertainty in every real world system the choice of a stationary versus a non stationary model is done in terms of modelling convenience rather than based on the existence or co existence of deterministic drivers montanari and koutsoyiannis 2014 koutsoyiannis and montanari 2015 de luca et al 2019 yet shed further light on this misconception by the following experiment they show that artificially imposed trends of the projected magnitude of climate scenarios on the parameters of a sub hourly rainfall generator regarding bursts intensity duration and number of occurrences were masked on coarser temporal scales and as a result they could be adequately modelled by a stationary extreme value model this suggests that the presence of deterministic drivers in a system does not disfavour stationary modelling for there is the possibility that even systematic changes may not be manifested at the scales of interest to the degree that they warrant a more complicated representation for the future hence the examination of a stationary framework is justified also in the presence of monotonic and accelerating forcing as it aligns with the abovementioned principle of parsimonious modelling therefore the question shifts from the existence or not of deterministic drivers to evaluation of the degree to which observed changes require a more complicated modelling in our case it is assumed that the past is still representative enough for the future in order to achieve a similar degree of predictability by the given models which is not falsified by the examination of the recent period the entire question however relies on a simplistic view of complex systems i e that just one factor or the change thereof suffices to determine the system s future evolution in our view this is not a logically consistent framework for dealing with complex systems 5 summary and conclusions under the popular assumption of intensification of the water cycle due to global warming a considerable deal of contemporary research in hydrology revolves around the study of temporal changes of extremes with the application of trend analyses being on the rise during the past two decades as illustrated in appendix i while the explanatory analysis of trends has dominated the relevant studies assessment of the predictive skill of trend models has not been equally assessed despite the apparent significance of such a task for risk planning this research reframes the problem of trend evaluation as a model selection problem oriented towards identifying the model with the best predictive qualities in deterministic terms which is neither equivalent to the true model nor to the model better at explaining the in sample data for this purpose we introduce a systematic framework for evaluating projections of trends by means of comparing the prediction rmse to the one obtained from simpler mean models we perform a variation of cross validation also known as walk forward analysis devising two distinct calibration and validation schemes fig 2 in block moving calibration we fit the linear trend and mean models to 30 years of data local trend and local mean and we validate the results based on the outcome of their predictions for the next 30 years repeating the procedure using sliding windows till the end of the record is met in global moving calibration we fit the models to all the known period global trend and global mean assuming that in the beginning one knows only the first 30 years and progressively the calibration sample grows larger in this case too we evaluate the outcome of the predictions of the models for the next 30 years therefore the projections of the four models can be compared in terms of the statistics of their empirical distribution of errors the models compete in predicting the out of sample behaviour of four rainfall indices annual maxima annual totals annual wet day average rainfall and probability dry at the annual scale as estimated from a unique dataset comprising the 60 longest rainfall records surpassing 150 years of daily data results show that models rank from best to worst as follows local mean global mean global trend and local trend a separate examination of the latest 30 year period for each station confirmed the above rank of the models as well the temporal changes in the prediction error distribution among four fixed climatic periods common for all stations covering 110 years up to 2009 are also investigated fluctuations of predictability do occur among the climatic periods yet no increase in predictability is achieved by the local trend model for the latest period 1980 2009 compared to earlier periods results from both analyses show that future rainfall variability is on average better predicted by mean models since local trend models identify features of the process that are unlikely to survive the end of the calibration period either being extreme observations or trend like behaviour these features are smoothed out in longer segments which is the reason behind the better performance of global trends robust regression techniques were also employed for the calibration of local trends but perhaps not surprisingly did not improve the out of sample predictions see discussion in appendix iii in an attempt to reproduce the observed behaviour we generate long term timeseries exhibiting long term persistence or hk dynamics koutsoyiannis 2011 o connell et al 2016 dimitriadis 2017 and carry out the same analysis persistent processes show enhanced variability and a user unfamiliar with their properties may misinterpret segments of their timeseries as trends which perhaps explains why trend claims have been that common lately results from the synthetic records show qualitative similarities with the ones from empirical rainfall records known to exhibit persistence depending on the scale and studied index koutsoyiannis 2006 markonis and koutsoyiannis 2016 iliopoulou et al 2018b iliopoulou and koutsoyiannis 2019 the local and global mean outperform the local trend model for all degrees of persistence and sample sizes while for small record lengths n 100 the performance of the global trend model is notably inferior too local and global mean models hardly show differences for medium degrees of persistence but the local mean prevails for strong persistence from a systematic investigation of long term rainfall records corroborated by simulation results we have verified that local trends have poor out of sample performance being outperformed in their predictions by simpler models as the local mean this empirical finding suggests that the large inherent variability present in the rainfall process makes the practice of extrapolating local features in the long term future dubious especially when the complexity of the latter increases this in turn questions the theoretical and practical relevance of projections of rainfall trends and the grounds of the related abundant publications credit authorship contribution statement theano iliopoulou conceptualization methodology data curation formal analysis software visualization writing original draft demetris koutsoyiannis conceptualization methodology validation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the editor andras bardossy for handling the review of the paper as well as the associate editor felix frances the eponymous reviewer robert m hirsch and an anonymous reviewer for providing constructive comments which resulted in substantial improvements we greatly thank the radcliffe meteorological station the icelandic meteorological office trausti jónsson the czech hydrometeorological institute the finnish meteorological institute the national observatory of athens the department of earth sciences of the uppsala university and the regional hydrologic service of the tuscany region servizio idrologico regione toscana it for providing the required data for each region respectively we are also grateful to professor ricardo machado trigo university of lisbon for providing the lisbon timeseries to professor marco marani university of padua for providing the padua timeseries and to professor joo heon lee joongbu university for providing the seoul timeseries all the above data were freely provided after contacting the acknowledged sources the remaining timeseries are publicly available by the data providers in the eca d project http www ecad eu and in the ghcn daily database https data noaa gov dataset global historical climatology network daily ghcn daily version 3 the analyses were performed in the python 2 6 python software foundation python language reference version 2 7 available at http www python org using the contributed packages pandas scipy and seaborn academic word occurrence code developed by strobel 2018 available at http doi org 10 5281 zenodo 1218409 appendix i a brief quantitative literature review the aim of this literature review is to evaluate the academic interest in trends of rainfall variables by means of a quantitative analysis of research papers appearing in google scholar we base this analysis on the quantification of the occurrence of associated words in google scholar using python code developed by strobel 2018 omitting results related to citations and patents this analysis was performed on 21 10 2019 and in order to refer to full calendar years it contains results published till the end of 2018 in fig a1 we show the temporal evolution of the ratio of appearance of the word trends in items also containing the complete list of words precipitation hydrology extremes results have been randomly varying from the beginning till the mid 20th century when there were less than 100 results per year fulfilling the criteria of containing the list in the denominator of the ratio it can be seen though that approximately from the 1960 and later on there has been an increasing trend in relevant publications containing the word trends reaching 89 in 2018 obviously results belonging to a different context than the one assumed might have been calculated as well but we assume their effect to be analogous both in the nominator and the denominator of the ratio thus not significantly affecting the conclusion to further refine our search to more technical papers explicitly referring to rainfall trends we define the following search terms word combination a is the full list precipitation rainfall trends precipitation rainfall data records where the symbol refers to or and word combinations inside should be found together i e one possible combination is the list precipitation trends rainfall data word combination b is an extension of word combination a that also includes the word projections while word combination c is an extension of word combination a also including the word sequence linear trend trends model regression the absolute numbers of the results are shown in fig a2a while in fig a2b we show their relative ratio expectedly the total number of studies containing rainfall trends are rising however this is not surprising in terms of absolute numbers considering the increasing availability of papers in scholar over the years however the use of the word projections appears to be increasing in relative terms as well the relative use of word combination c related to the linear trend has slightly increased too over the years stabilizing over the past 5 year period to approximately half of the related publications fig a2b as a final refinement we consider words appearing only in the title of papers which should limit the results to strictly related papers results are shown in fig a3 the standard term that is contained in every result is rainfall precipitation followed by the appearance anywhere in the title of the single terms trends trend variability change changes and non stationary non stationarity nonstationary nonstationarity note that we consider also plural terms where applicable as well as possible differences in spelling while this time we do not require words to be found in a specific order as in the previous in text search for instance it could be trends in rainfall or rainfall trends in the we do not compute ratios over the items containing in their title the words rainfall precipitation because these terms alone are too generic and can be found in a variety of studies a significant part of which are only loosely related to hydrology e g physics chemistry radar technologies etc instead to provide a more relevant reference point for comparison we use two words semantically uncharged with the trend concept which are however widely used in combination with the standard terms namely the words model and distribution e g a rainfall model or the distribution of the precipitation apparently the conceptually more inclusive terms changes and variability are ranking first in the related search terms with the explicit use of the word trend s ranking third yielding consistently over the last ten years above 200 results per year 288 in 2018 as per results appearing on google scholar on 21 10 2019 terms related to non stationarity are slowly rising over the past ten years 39 in title results in 2018 while being close to zero before 2000 it is interesting to note the evolution of the use of terms explicitly associated with the temporal properties of rainfall compared to the terms more related to marginal properties distribution or being more of a general use perhaps implying both properties model the mere use of the word trend s has exceeded the use of an all times classic word for rainfall i e distribution which clearly shows a certain shift in academic interest likewise the ever higher scoring word model has been outnumbered in the past three years by the word change s in conjunction these results suggest that over the last two decades there has been a rising scientific interest in the temporal properties of rainfall and their future evolution with trends taking up a considerable share of this emerging focus appendix ii rainfall records properties and long term variability table a1 summarizes the properties of the long term rainfall stations in figs a4 a7 we illustrate the static validation scheme showing results from the projections of the local trend and the local mean model for all rainfall indices appendix iii fitting algorithms least squares vs robust regression we explore the effect of the linear trend definition and fitting algorithm on the results of the local trends as trends in small segments are expected to be more sensitive to the choice of the fitting algorithm santer et al 2000 the first algorithm is the widely used ordinary least square estimation ols which fits eq 2 to the data by minimizing the sum of the squares of the differences between the observed data and the predictions of the linear model secondly two alternative trend calibration approaches are explored that place less weight on influential observations outliers and thus belong to the range of robust regression techniques the first is the least absolute deviations lad method which estimates the regression coefficients by minimising the sum of absolute deviations of the predicted from the observed values and is a special case of quantile regression fitting the trend line to the median of the observations rather than the mean chandler and scott 2011 the second is the non parametric method of theil sen slope estimation sen 1968 theil 1992 which estimates the slope b of the linear model as the median of the pairwise slopes of all sample points among the different approaches that exist for the intercept coefficient we follow conover 1980 and estimated the intercept as a y 0 5 b x 0 5 where y 0 5 and x 0 5 are the sample medians results from the comparison of the prediction rmse from these three algorithms are shown in fig a8 evidently the ordinary least square regression performs better than the lad regression while its results are very close to the theil sen regression therefore the ols estimator is retained for the main analysis due to its better performance compared to the lad estimator non ambiguity in definition compared to the theil sen estimator and well studied mathematical properties papoulis 1990 as a final note we underline that the notion of robustness of statistical regression has arisen as a positive trait for systems with known and expected behaviour where extreme values are considered either outliers or erroneous measurements which contaminate the record yet for natural systems producing extremes as part of a large and inherent variability and exhibiting irregular trends difficult or perhaps impossible to attribute to causal mechanisms we deem that there might be no theoretical reason behind the expected superiority of robust statistics which is in fact empirically shown in this experiment 
5311,information about the distribution and characteristics of existing sinkholes is critical for understanding karst aquifer systems and evaluating sinkhole hazards lidar provides accurate and high resolution topographic information and has been used to improve delineation of sinkholes in many karst regions lidar data also reveal many topographic depressions however and identifying sinkholes from these depressions through manual visual inspection can be slow and laborious to improve the efficiency of the identification process we applied six machine learning methods logistic regression naive bayes neural network random forests rusboost and support vector machine to a dataset of morphometric characteristics of lidar derived topographic depressions sinkhole data from bourbon woodford and jessamine counties in the bluegrass region of kentucky were used to derive the dataset for training and testing the machine learning methods the dataset consisted of 22 884 records with 10 variables for each record for each method a random subset of 80 of the records was used for training and the remaining 20 was used for testing the test receiver operating characteristic curves showed that all six methods were applicable to the dataset as demonstrated by all area under the curves aucs being greater than 0 87 neural network emerged as the method that performed best with an auc of 0 95 and a testing average accuracy of 0 85 to further improve the sinkhole mapping process we subsequently developed a two step process that combined the trained neural network classifier and manual visual inspection and applied the process to scott county also in the bluegrass region we were able to locate 97 of the sinkholes in the county by manually inspecting only 27 of the topographic depressions the neural network classified as having relatively high probabilities of being sinkholes this study showed that machine learning is a promising method for improving sinkhole identification efficiency in karst areas in which high resolution topographic information is available keywords sinkhole lidar machine learning topographic depression morphometric characteristic 1 introduction approximately 15 of the ice free land surface globally is underlain by karst terrain and approximately 20 25 of the global populations depends largely or entirely on the aquifers associated with this terrain ford and williams 2007 many large population centers rely on these aquifers as their primary water supplies chen et al 2017 karst aquifers typically have distinct physiographic features that result from the dissolution of bedrock typically carbonate rocks and as a result these aquifers are usually characterized by a network of fractures and conduits that connect to the surface water through sinkholes sinking streams and springs sinkholes are the most well known features associated with karst schwartz and zhang 2003 sinkholes serve as a major connection between surface water and groundwater by collecting rainfall and funneling it internally to the subsurface often via fast flow sinkholes also cause damage to property and infrastructure in karst regions throughout the world in the united states alone the costs of sinkhole related damage is estimated to range from 125 million to 300 million dollars annually kuniansky et al 2016 dinger et al 2007 estimated that in kentucky the damage associated with sinkholes costs approximately 20 million to 24 million dollars per year the u s disaster mitigation act of 2000 requires states to have a state mitigation plan approved by the federal emergency management agency in order to be eligible for federal hazard mitigation funding the mitigation plan must include the identification and assessment of natural hazards such as sinkholes detailed information on sinkholes is therefore essential for understanding karst aquifer systems and mitigating sinkhole hazard in many karst regions sinkholes appear as depressions on the earth s surface and can be identified with topographic information in kentucky a sinkhole database paylor et al 2003 derived from 1 24 000 scale topographic maps was used to assess the statewide sinkhole hazard kentucky emergency management 2013 the topographic maps used to compile the database were low resolution and were mostly created prior to the 1970s as a result many small or newly formed sinkholes were not included in the database zhu et al 2014 lidar is a remote sensing technique that provides high density and high accuracy data for depicting small topographic features therefore providing a great opportunity for mapping karst sinkholes in high resolution and with great detail some researchers seale et al 2008 alexander et al 2013 have manually located sinkholes based on lidar derived digital elevation models dems or their derivative maps directly others have used a sink fill method jenson and domingue 1988 planchon and darboux 2001 wang and liu 2006 to automatically extract surface depressions from lidar zhu et al 2014 wu et al 2016 wall et al 2017 although the sink fill method can locate sinkholes it also extracts other surface features such as stream channels meander cutoffs and more commonly man made structures e g farm ponds culverts swimming pools therefore an additional step is needed to separate sinkholes from these other features zhu et al 2014 used a manual visual inspection method with auxiliary data e g satellite images but this can be slow and laborious for large areas in which tens of thousands of surface depressions can be revealed from lidar we decided to apply machine learning methods to tackle this problem machine learning is a branch of artificial intelligence in which the goal is to construct computer based systems that improve automatically through training experience mitchell 1997 over the last two decades machine learning has advanced dramatically with broad applications across many scientific fields including biology cosmology medical science and social science jordan and mitchell 2015 machine learning has also been applied to sinkhole related problems miao et al 2013 trained a random forests model with a high training accuracy of 87 9 but their model was built on a small dataset of 66 records and was not tested in a different area zhu and pierskalla 2016 trained a weighted random forests model from 8427 records but they found the accuracy decreased considerably when the trained model was tested in a nearby area taheri et al 2019 applied four machine learning methods to evaluate sinkhole susceptibility factors using a small dataset of less than 50 records of existing sinkholes identifying sinkholes from a large number of surface depressions quickly and efficiently however remains a challenge in this study we aimed to identify sinkholes by exploring multiple machine learning methods using a large dataset and developing an efficient way to apply trained machine learning models 2 study area the study area consists of bourbon woodford jessamine and scott counties in central kentucky fig 1 most of the study area is in the inner bluegrass region the second largest karst region in kentucky currens 2002 the inner bluegrass is mostly underlain by the middle ordovician lexington limestone cressman and peterson 1986 which is predominantly a limestone unit with interbedded shales that has developed numerous karst features such as sinkholes and sinking streams the kentucky river flows along the western boundary of woodford county and the southwestern boundary of jessamine county the kentucky river palisades and the lower parts of the river s tributaries inside the two counties are underlain by the middle ordovician high bridge group which is mainly composed of limestone and dolomite and is the oldest stratigraphic unit exposed in kentucky cressman and peterson 1986 northern scott county southeastern bourbon county and southern jessamine county are in the eden shale belt a band of round hills and ridges around the inner bluegrass newell 1986 these parts of the study area are underlain by the upper ordovician garrard siltstone and clays ferry formations which are mostly shale with interbedded siltstone and minor limestone and have very few karst features developed on them cressman and peterson 1986 3 methods 3 1 create a sinkhole dataset karst sinkholes in bourbon jessamine and woodford counties were first mapped using the method of zhu et al 2014 and the karst sinkhole data were then used to create a dataset of sinkhole morphometric characteristics for training and testing machine learning methods sinkhole morphometric characteristics have been used to remove depressions that are not sinkholes filin and baruch 2010 rahimi and alexander 2013 doctor and young 2013 wu et al 2016 zhu and pierskalla 2016 we selected 10 morphometric variables to describe the three dimensional characteristics of the topographic depressions the plan view of a depression i e a polygon representing the closed contour of the depression on the surface was characterized by three variables perimeter area and compactness the compactness also called circularity c measures how closely a shape resembles a circle one way to measure the compactness is by cole 1964 1 c a a c where a is the area of the polygon and a c is the area of the smallest circle circumscribing the polygon values of compactness range from 0 to 1 and equal 1 when the polygon is a perfect circle natural sinkholes tend to have a circular shape with a high compactness value although large sinkholes are more likely to have complex shapes to capture characteristics of the depressions in the vertical direction we calculated statistics of depths in each depression and statistics of slopes of a 9 m ring slope ring surrounding each depression fig 2 variables selected for characterizing depths were maximum depth mean depth depth standard deviation and depth sum depth sum variable is the sum of the depth of every cell within a depression when multiplied by the cell size of the elevation raster 1 524 m in this study the depth sum variable becomes the depression volume variables selected to describe the slope ring were mean slope and slope standard deviation to see if there is a relation between depth and the surface area of a sinkhole we selected a depth index d i defined as 2 d i d max a π where d max is the maximum depth and a is the surface area i e the area of the polygon on the surface the depth index reflects the slope by assuming that a sinkhole is an inverted cone miao et al 2013 3 2 train and test machine learning models training an algorithm to identify sinkholes using a dataset with known sinkhole non sinkhole classification is considered as supervised learning in machine learning supervised learning systems rely on known responses to learn how to map inputs to predictions there are many mapping techniques for supervised learning including bayesian classifiers decision trees decision forests logistic regression kernel machines neural networks and support vector machines hastie et al 2011 we selected six methods logistic regression naive bayes support vector machine neural network rusboost and random forests logistic regression applies the logit function the logarithm of the odds with a linear combination of inputs to estimate the probability of response variables usually binary naive bayes uses the bayes theorem to predict the posterior probability of each class while assuming that inputs are conditionally independent a support vector machine svm makes predictions by seeking a hyperplane that provides the maximum separating margin for inputs svms rely on different kernel functions to transform inputs into a separable form a neural network is a two stage model the key idea is to derive features through a linear combination of inputs at the first stage and then model the responses using a nonlinear function of these derived features at the second stage hastie et al 2011 rusboost is a decision forest method designed to handle imbalanced data it uses rus random under sampling to achieve a balance between classes in the sampled data a common sampling strategy in rusboost is to have the same number of observations from each class the random forests method was applied to compare this study with our previous study zhu and pierskalla 2016 which also used the random forests method both the random forests and rusboost grow multiple decision trees but in the random forests the trees are independent of each other i e bagging whereas in rusboost the later trees are adaptive to the earlier trees i e boosting a more detailed description of these methods can be found in hastie et al 2011 seiffert et al 2010 and breiman 2001 we used matlab 2017 to build machine learning classifiers from the sinkhole dataset matlab provides built in functions for many machine learning methods for the support vector machine we used a quadratic polynomial kernel for rusboost we grew 1000 trees for random forests we grew 300 trees the same number of trees used in zhu and pierskalla 2016 for neural network we used one hidden layer with 10 nodes and scaled conjugate gradient backpropagation training function for logistic regression and naive bayes we used the option requiring no additional parameters besides the dataset each method was trained by using 80 of a randomly selected subset of the full dataset the trained machine learning models were then tested using the remaining 20 of the dataset for two class classification problems a widely used tool to evaluate the performance of a machine learning method is a receiver operating characteristic roc curve fawcett 2006 a roc curve plots false positive rate vs true positive rate under different classification thresholds the true positive rate is the proportion of positive cases that are correctly classified the false positive rate is the proportion of negative cases that are incorrectly classified as positive as a result in a roc curve increases in true positive rate are often accompanied by increases in false positive rate the performance can be evaluated through how well a method separates the true positive rate from the false positive rate the area under the roc curve or auc provides a straightforward measure of this an auc of 1 represents a perfect test and an auc of 0 5 represents a worthless test the closer the auc is to 1 the better the test a roc curve with an auc above 0 9 generally indicates an excellent classifier although a roc curve is widely used to measure the performance of binary classifiers fawcett 2006 it is not sensitive to data imbalance to better evaluate the performance of the classifiers to an imbalanced dataset such as the sinkhole dataset in this study we applied precision recall pr curves precision is defined as the number of correct positive predictions divided by the sum of true positive cases and false positive cases the number of false positive predictions depends on the number of actual positive cases precision measures the portion of predicted positives that are actually correct recall also known as true positive rate measures the portion of actual positives that are identified correctly consequently a pr curve is considered a more appropriate evaluating measure than a roc curve for imbalanced datasets saito and rehmsmeier 2015 in a pr curve improving precision typically reduces recall and vice versa the area under the pr curve pr auc provides a measure of performance a high pr auc value represents both high recall and high precision showing that the classifier not only returns high accuracy in positive predictions but also identifies a high portion of actual positives the roc and pr curves evaluate the overall performance of the classifiers prediction accuracy of the classifiers was further assessed using confusion matrices from the testing data a confusion matrix lists actual and predicted classifications in a matrix form from the confusion matrices of the six classifiers we calculated overall accuracy average accuracy precision recall and f measure overall accuracy is the ratio of the total number of correct predictions to the total number of records the overall accuracy is a widely used evaluating metric but it can be misleading for very imbalanced data in which a classification missing all minority classes can still achieve high overall accuracy the average accuracy is the average between true positive rate and true negative rate which takes into account class imbalance the true negative rate is the ratio of correct negative predictions to total actual negatives and measures the portion of actual negatives that are identified correctly f measure is the harmonic mean of precision and recall 3 3 model application to investigate how to effectively apply a trained classifier to a new location we developed a two step procedure that combined the best performing classifier and visual inspection we anticipated that a trained classifier would make some wrong predictions so the two step procedure was aimed to combine human intervention and the machine learning classifier to improve sinkhole mapping accuracy the accuracy assessment metrics described in section 3 2 used a confusion matrix calculated from a commonly used classification threshold of 0 5 meaning that a depression is classified as a sinkhole when its predicted probability of being a sinkhole above 0 5 a different threshold can be applied based on the nature of the application in sinkhole mapping the mistake of mapping a non sinkhole as a sinkhole is a bigger error than the mistake of missing a sinkhole so the goal is to reduce false positives while maintaining a high true positive rate reducing the false positive rate often decreases the true positive rate however thus the first step of the two step procedure was to apply a machine learning classifier to predict probability of depressions being sinkholes then a probability threshold was selected so that most true sinkholes were classified into the sinkhole category by doing that the sinkhole category inevitably contained some non sinkholes we then used visual inspection to remove non sinkholes from the sinkhole category in the second step 4 results and discussion 4 1 sinkhole dataset karst sinkholes in bourbon jessamine and woodford counties were used to create the dataset for training and testing machine learning methods using the method in zhu et al 2014 a total of 22 884 depressions were extracted from lidar derived 1 524 m dems of which 5631 24 6 were identified as probable sinkholes we field checked 148 randomly selected probable sinkholes and confirmed that 144 97 3 of them were actual sinkholes a summary of the results for each county is listed in table 1 and the locations of field checked sinkholes are shown in fig 1 for the purposes of training and testing machine learning methods the sinkhole classification result was considered to be a true classification the true classification is not entirely accurate as demonstrated by the 2 7 of error rate from the field checked results the 10 morphometric variables were then calculated for all the 22 884 depressions a response variable with a binary classification sinkhole or non sinkhole was created using sinkhole mapping result the resulting dataset was imbalanced as only 24 6 of the records were classified as sinkholes the dataset was skewed toward the non sinkhole class 4 2 model testing results the roc curves fig 3 show that all the methods worked well for the sinkhole dataset with aucs ranging from 0 874 0 950 the best performing methods were neural network auc 0 950 random forests auc 0 947 and rusboost auc 0 942 the pr curves fig 4 show that neural network pr auc 0 860 performed the best among the six methods followed by random forests pr auc 0 851 and support vector machine pr auc 0 828 overall the roc curves and pr curves gave similar assessment results for these methods table 2 shows that neural network had the highest overall accuracy average accuracy and f measure random forests and rusboost achieved very close performance to neural network 4 3 model application results the performance evaluation of the six classifiers showed that the dataset derived using the morphometry of the depressions from the three counties provides adequate information for machine learning to separate sinkholes from other depressions the evaluation also showed that neural network worked best among the six methods however although the neural network correctly identified 830 sinkholes it also missed 255 actual sinkholes and misclassified 206 non sinkholes as sinkholes table 3 we needed to find a way to take advantage of the classifier while minimizing loss in accuracy we applied the two step procedure to scott county another county in the bluegrass region fig 1 we retrained a neural network classifier using all 22 884 records collected from bourbon woodford and jessamine counties using the depression extraction method by zhu et al 2014 we extracted 10 626 topographic depressions from a lidar derived dem of scott county the same 10 variables describing morphometric characteristics of these depressions were calculated the trained neural network classifier was then applied to predict the probability of these depressions being sinkholes because most of scott county has similar geology as the other three counties we expected that the ratio of sinkholes to non sinkholes in the scott county dataset would be similar to the ratio in the training data 0 33 using this ratio with some added safety margins we used a probability threshold of 0 1 to separate the depressions into a sinkhole group and a non sinkhole group so that all records in the sinkhole group had a predicted sinkhole probability of 0 1 or higher and all records in the non sinkhole group had a predicted sinkhole probability below 0 1 the resulting sinkhole group had 2889 27 records and the non sinkhole group had 7737 73 records a ratio of 0 37 we then visually inspected the sinkhole group and identified 888 of them as sinkholes to see how many sinkholes could be missed by this two step procedure we also visually inspected the non sinkhole group and found that 31 of them were sinkholes this suggested that with the assistance of a machine learning classifier we would be able to identify 97 of sinkholes by inspecting only 27 of the total depressions for scott county the procedure saved more than 70 of the manual labor in visual inspection with a cost of missing only a small number of sinkholes when inspecting the 31 sinkholes the neural network classifier predicted with low probability of being sinkholes 0 1 we found their morphometric characteristics were not typical as sinkholes for example some of them had a naturally irregular surficial shape that was very different from the circular shape of typical sinkholes fig 5 a some had been partially modified by human activities such as road constructions fig 5b some were groups of small sinkholes that were too small to be classified as sinkholes individually fig 5c fig 5c shows the limits of the dataset in which each depression was considered independently spatially we have observed that sinkholes tend to form in clusters along major rivers or joints and lineaments zhu et al 2014 visual inspection can naturally take this spatial pattern into consideration but extracting variables to reflect that pattern can be difficult these cases showed a small number of sinkholes that cannot be characterized by their morphometric characteristics alone 4 4 discussion in this study the trained neural network model was applied to an area that has similar geologic and geographic conditions as the area for which the training dataset was developed development of sinkholes is influenced by many geologic topographic and climatologic factors and morphometry of sinkholes may not be equivalent from one region to another taylor and doctor 2016 to see if the trained neural network model is applicable to another karst region we tested the model in oldham county kentucky where sinkholes have been mapped previously using lidar data zhu and pierskalla 2016 oldham county is approximately 100 km northwest of the study area and is underlain by limestone and dolomite of late ordovician and silurian age newell 1986 the application of the two step procedure to oldham county showed that a sinkhole probability threshold of 0 1 classified 60 of depressions as non sinkhole but the sinkhole group missed 14 of actual sinkholes when a threshold of 0 025 was used 43 of the polygons were classified as non sinkhole whereas the sinkhole group missed only 4 of actual sinkholes this suggests that the trained classification model may yield less accurate results when applied to other karst regions which is not surprising to apply the method described in this paper to other karst regions a better way would be to re train the machine learning models using data from the same region on the other hand the model trained in this study can still be potentially useful for another karst region if used as a screening tool to remove obvious non sinkholes in this case the threshold used for screening depressions should be tested and adjusted for the region a comparison of performance metrics between this study and our previous study zhu and pierskalla 2016 showed the random forests model in this study achieved higher accuracy than our previous random forests model the improvement may be attributed to the larger training dataset used in this study 18 308 records compared to 8427 records used previously the performance difference may also be attributed to how the two models were tested in zhu and pierskalla 2016 the trained model was tested in an area adjacent to the area where the training data were extracted in this study the testing data and training data were from the same area and separation of the two subsets was done randomly sinkholes have different sizes and shapes the 10 morphometric variables certainly did not capture all the details of the three dimensional nature of sinkholes the machine learning models may be improved if additional morphometric variables can be developed and added to the training data on the other hand deep learning can use images of sinkholes directly as training data and offers an alternate approach that may further improve classification accuracy and expedite the sinkhole mapping process 5 conclusions we tested six machine learning methods to locate karst sinkholes from lidar data in the bluegrass region of kentucky we built a dataset of morphometric characteristics of mapped sinkholes in bourbon jessamine and woodford counties and trained and tested classifiers using logistic regression naive bayes support vector machine neural network random forests and rusboost we then used a two step procedure that combined the best performing classifier with manual inspection in scott county to improve sinkhole mapping efficiency our study concluded 1 morphometric characteristics of sinkholes provided sufficient information for separating most sinkholes from other forms of surface depressions 2 neural network performed the best among the six machine learning methods in identifying sinkholes from other depressions neural network achieved the highest auc values from the receiver operating characteristic curves and the precision recall curves and best values for overall accuracy average accuracy and f measure 3 the two step procedure of combining a machine learning classifier with manual visual inspection improved efficiency while maintaining accuracy with the assistance of a neural network classifier we located 97 of sinkholes by inspecting only 27 of the topographic depressions in scott county credit authorship contribution statement junfeng zhu conceptualization methodology formal analysis investigation writing original draft writing review editing visualization supervision project administration adam m nolte investigation resources data curation writing review editing nathan jacobs methodology validation formal analysis writing review editing ming ye conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank dr anke meyer baese and amirhessam tahmassebi from florida state university for their collaboration with us on machine learning we also thank kalli beasley ethan davis megan hackett and steve webb for their help in mapping sinkholes for the study area our appreciation also goes to the associate editor and the anonymous reviewers for their constructive comments we thank meg smath for her editorial review the last author was supported by national science foundation grant ear 1828827 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125049 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5311,information about the distribution and characteristics of existing sinkholes is critical for understanding karst aquifer systems and evaluating sinkhole hazards lidar provides accurate and high resolution topographic information and has been used to improve delineation of sinkholes in many karst regions lidar data also reveal many topographic depressions however and identifying sinkholes from these depressions through manual visual inspection can be slow and laborious to improve the efficiency of the identification process we applied six machine learning methods logistic regression naive bayes neural network random forests rusboost and support vector machine to a dataset of morphometric characteristics of lidar derived topographic depressions sinkhole data from bourbon woodford and jessamine counties in the bluegrass region of kentucky were used to derive the dataset for training and testing the machine learning methods the dataset consisted of 22 884 records with 10 variables for each record for each method a random subset of 80 of the records was used for training and the remaining 20 was used for testing the test receiver operating characteristic curves showed that all six methods were applicable to the dataset as demonstrated by all area under the curves aucs being greater than 0 87 neural network emerged as the method that performed best with an auc of 0 95 and a testing average accuracy of 0 85 to further improve the sinkhole mapping process we subsequently developed a two step process that combined the trained neural network classifier and manual visual inspection and applied the process to scott county also in the bluegrass region we were able to locate 97 of the sinkholes in the county by manually inspecting only 27 of the topographic depressions the neural network classified as having relatively high probabilities of being sinkholes this study showed that machine learning is a promising method for improving sinkhole identification efficiency in karst areas in which high resolution topographic information is available keywords sinkhole lidar machine learning topographic depression morphometric characteristic 1 introduction approximately 15 of the ice free land surface globally is underlain by karst terrain and approximately 20 25 of the global populations depends largely or entirely on the aquifers associated with this terrain ford and williams 2007 many large population centers rely on these aquifers as their primary water supplies chen et al 2017 karst aquifers typically have distinct physiographic features that result from the dissolution of bedrock typically carbonate rocks and as a result these aquifers are usually characterized by a network of fractures and conduits that connect to the surface water through sinkholes sinking streams and springs sinkholes are the most well known features associated with karst schwartz and zhang 2003 sinkholes serve as a major connection between surface water and groundwater by collecting rainfall and funneling it internally to the subsurface often via fast flow sinkholes also cause damage to property and infrastructure in karst regions throughout the world in the united states alone the costs of sinkhole related damage is estimated to range from 125 million to 300 million dollars annually kuniansky et al 2016 dinger et al 2007 estimated that in kentucky the damage associated with sinkholes costs approximately 20 million to 24 million dollars per year the u s disaster mitigation act of 2000 requires states to have a state mitigation plan approved by the federal emergency management agency in order to be eligible for federal hazard mitigation funding the mitigation plan must include the identification and assessment of natural hazards such as sinkholes detailed information on sinkholes is therefore essential for understanding karst aquifer systems and mitigating sinkhole hazard in many karst regions sinkholes appear as depressions on the earth s surface and can be identified with topographic information in kentucky a sinkhole database paylor et al 2003 derived from 1 24 000 scale topographic maps was used to assess the statewide sinkhole hazard kentucky emergency management 2013 the topographic maps used to compile the database were low resolution and were mostly created prior to the 1970s as a result many small or newly formed sinkholes were not included in the database zhu et al 2014 lidar is a remote sensing technique that provides high density and high accuracy data for depicting small topographic features therefore providing a great opportunity for mapping karst sinkholes in high resolution and with great detail some researchers seale et al 2008 alexander et al 2013 have manually located sinkholes based on lidar derived digital elevation models dems or their derivative maps directly others have used a sink fill method jenson and domingue 1988 planchon and darboux 2001 wang and liu 2006 to automatically extract surface depressions from lidar zhu et al 2014 wu et al 2016 wall et al 2017 although the sink fill method can locate sinkholes it also extracts other surface features such as stream channels meander cutoffs and more commonly man made structures e g farm ponds culverts swimming pools therefore an additional step is needed to separate sinkholes from these other features zhu et al 2014 used a manual visual inspection method with auxiliary data e g satellite images but this can be slow and laborious for large areas in which tens of thousands of surface depressions can be revealed from lidar we decided to apply machine learning methods to tackle this problem machine learning is a branch of artificial intelligence in which the goal is to construct computer based systems that improve automatically through training experience mitchell 1997 over the last two decades machine learning has advanced dramatically with broad applications across many scientific fields including biology cosmology medical science and social science jordan and mitchell 2015 machine learning has also been applied to sinkhole related problems miao et al 2013 trained a random forests model with a high training accuracy of 87 9 but their model was built on a small dataset of 66 records and was not tested in a different area zhu and pierskalla 2016 trained a weighted random forests model from 8427 records but they found the accuracy decreased considerably when the trained model was tested in a nearby area taheri et al 2019 applied four machine learning methods to evaluate sinkhole susceptibility factors using a small dataset of less than 50 records of existing sinkholes identifying sinkholes from a large number of surface depressions quickly and efficiently however remains a challenge in this study we aimed to identify sinkholes by exploring multiple machine learning methods using a large dataset and developing an efficient way to apply trained machine learning models 2 study area the study area consists of bourbon woodford jessamine and scott counties in central kentucky fig 1 most of the study area is in the inner bluegrass region the second largest karst region in kentucky currens 2002 the inner bluegrass is mostly underlain by the middle ordovician lexington limestone cressman and peterson 1986 which is predominantly a limestone unit with interbedded shales that has developed numerous karst features such as sinkholes and sinking streams the kentucky river flows along the western boundary of woodford county and the southwestern boundary of jessamine county the kentucky river palisades and the lower parts of the river s tributaries inside the two counties are underlain by the middle ordovician high bridge group which is mainly composed of limestone and dolomite and is the oldest stratigraphic unit exposed in kentucky cressman and peterson 1986 northern scott county southeastern bourbon county and southern jessamine county are in the eden shale belt a band of round hills and ridges around the inner bluegrass newell 1986 these parts of the study area are underlain by the upper ordovician garrard siltstone and clays ferry formations which are mostly shale with interbedded siltstone and minor limestone and have very few karst features developed on them cressman and peterson 1986 3 methods 3 1 create a sinkhole dataset karst sinkholes in bourbon jessamine and woodford counties were first mapped using the method of zhu et al 2014 and the karst sinkhole data were then used to create a dataset of sinkhole morphometric characteristics for training and testing machine learning methods sinkhole morphometric characteristics have been used to remove depressions that are not sinkholes filin and baruch 2010 rahimi and alexander 2013 doctor and young 2013 wu et al 2016 zhu and pierskalla 2016 we selected 10 morphometric variables to describe the three dimensional characteristics of the topographic depressions the plan view of a depression i e a polygon representing the closed contour of the depression on the surface was characterized by three variables perimeter area and compactness the compactness also called circularity c measures how closely a shape resembles a circle one way to measure the compactness is by cole 1964 1 c a a c where a is the area of the polygon and a c is the area of the smallest circle circumscribing the polygon values of compactness range from 0 to 1 and equal 1 when the polygon is a perfect circle natural sinkholes tend to have a circular shape with a high compactness value although large sinkholes are more likely to have complex shapes to capture characteristics of the depressions in the vertical direction we calculated statistics of depths in each depression and statistics of slopes of a 9 m ring slope ring surrounding each depression fig 2 variables selected for characterizing depths were maximum depth mean depth depth standard deviation and depth sum depth sum variable is the sum of the depth of every cell within a depression when multiplied by the cell size of the elevation raster 1 524 m in this study the depth sum variable becomes the depression volume variables selected to describe the slope ring were mean slope and slope standard deviation to see if there is a relation between depth and the surface area of a sinkhole we selected a depth index d i defined as 2 d i d max a π where d max is the maximum depth and a is the surface area i e the area of the polygon on the surface the depth index reflects the slope by assuming that a sinkhole is an inverted cone miao et al 2013 3 2 train and test machine learning models training an algorithm to identify sinkholes using a dataset with known sinkhole non sinkhole classification is considered as supervised learning in machine learning supervised learning systems rely on known responses to learn how to map inputs to predictions there are many mapping techniques for supervised learning including bayesian classifiers decision trees decision forests logistic regression kernel machines neural networks and support vector machines hastie et al 2011 we selected six methods logistic regression naive bayes support vector machine neural network rusboost and random forests logistic regression applies the logit function the logarithm of the odds with a linear combination of inputs to estimate the probability of response variables usually binary naive bayes uses the bayes theorem to predict the posterior probability of each class while assuming that inputs are conditionally independent a support vector machine svm makes predictions by seeking a hyperplane that provides the maximum separating margin for inputs svms rely on different kernel functions to transform inputs into a separable form a neural network is a two stage model the key idea is to derive features through a linear combination of inputs at the first stage and then model the responses using a nonlinear function of these derived features at the second stage hastie et al 2011 rusboost is a decision forest method designed to handle imbalanced data it uses rus random under sampling to achieve a balance between classes in the sampled data a common sampling strategy in rusboost is to have the same number of observations from each class the random forests method was applied to compare this study with our previous study zhu and pierskalla 2016 which also used the random forests method both the random forests and rusboost grow multiple decision trees but in the random forests the trees are independent of each other i e bagging whereas in rusboost the later trees are adaptive to the earlier trees i e boosting a more detailed description of these methods can be found in hastie et al 2011 seiffert et al 2010 and breiman 2001 we used matlab 2017 to build machine learning classifiers from the sinkhole dataset matlab provides built in functions for many machine learning methods for the support vector machine we used a quadratic polynomial kernel for rusboost we grew 1000 trees for random forests we grew 300 trees the same number of trees used in zhu and pierskalla 2016 for neural network we used one hidden layer with 10 nodes and scaled conjugate gradient backpropagation training function for logistic regression and naive bayes we used the option requiring no additional parameters besides the dataset each method was trained by using 80 of a randomly selected subset of the full dataset the trained machine learning models were then tested using the remaining 20 of the dataset for two class classification problems a widely used tool to evaluate the performance of a machine learning method is a receiver operating characteristic roc curve fawcett 2006 a roc curve plots false positive rate vs true positive rate under different classification thresholds the true positive rate is the proportion of positive cases that are correctly classified the false positive rate is the proportion of negative cases that are incorrectly classified as positive as a result in a roc curve increases in true positive rate are often accompanied by increases in false positive rate the performance can be evaluated through how well a method separates the true positive rate from the false positive rate the area under the roc curve or auc provides a straightforward measure of this an auc of 1 represents a perfect test and an auc of 0 5 represents a worthless test the closer the auc is to 1 the better the test a roc curve with an auc above 0 9 generally indicates an excellent classifier although a roc curve is widely used to measure the performance of binary classifiers fawcett 2006 it is not sensitive to data imbalance to better evaluate the performance of the classifiers to an imbalanced dataset such as the sinkhole dataset in this study we applied precision recall pr curves precision is defined as the number of correct positive predictions divided by the sum of true positive cases and false positive cases the number of false positive predictions depends on the number of actual positive cases precision measures the portion of predicted positives that are actually correct recall also known as true positive rate measures the portion of actual positives that are identified correctly consequently a pr curve is considered a more appropriate evaluating measure than a roc curve for imbalanced datasets saito and rehmsmeier 2015 in a pr curve improving precision typically reduces recall and vice versa the area under the pr curve pr auc provides a measure of performance a high pr auc value represents both high recall and high precision showing that the classifier not only returns high accuracy in positive predictions but also identifies a high portion of actual positives the roc and pr curves evaluate the overall performance of the classifiers prediction accuracy of the classifiers was further assessed using confusion matrices from the testing data a confusion matrix lists actual and predicted classifications in a matrix form from the confusion matrices of the six classifiers we calculated overall accuracy average accuracy precision recall and f measure overall accuracy is the ratio of the total number of correct predictions to the total number of records the overall accuracy is a widely used evaluating metric but it can be misleading for very imbalanced data in which a classification missing all minority classes can still achieve high overall accuracy the average accuracy is the average between true positive rate and true negative rate which takes into account class imbalance the true negative rate is the ratio of correct negative predictions to total actual negatives and measures the portion of actual negatives that are identified correctly f measure is the harmonic mean of precision and recall 3 3 model application to investigate how to effectively apply a trained classifier to a new location we developed a two step procedure that combined the best performing classifier and visual inspection we anticipated that a trained classifier would make some wrong predictions so the two step procedure was aimed to combine human intervention and the machine learning classifier to improve sinkhole mapping accuracy the accuracy assessment metrics described in section 3 2 used a confusion matrix calculated from a commonly used classification threshold of 0 5 meaning that a depression is classified as a sinkhole when its predicted probability of being a sinkhole above 0 5 a different threshold can be applied based on the nature of the application in sinkhole mapping the mistake of mapping a non sinkhole as a sinkhole is a bigger error than the mistake of missing a sinkhole so the goal is to reduce false positives while maintaining a high true positive rate reducing the false positive rate often decreases the true positive rate however thus the first step of the two step procedure was to apply a machine learning classifier to predict probability of depressions being sinkholes then a probability threshold was selected so that most true sinkholes were classified into the sinkhole category by doing that the sinkhole category inevitably contained some non sinkholes we then used visual inspection to remove non sinkholes from the sinkhole category in the second step 4 results and discussion 4 1 sinkhole dataset karst sinkholes in bourbon jessamine and woodford counties were used to create the dataset for training and testing machine learning methods using the method in zhu et al 2014 a total of 22 884 depressions were extracted from lidar derived 1 524 m dems of which 5631 24 6 were identified as probable sinkholes we field checked 148 randomly selected probable sinkholes and confirmed that 144 97 3 of them were actual sinkholes a summary of the results for each county is listed in table 1 and the locations of field checked sinkholes are shown in fig 1 for the purposes of training and testing machine learning methods the sinkhole classification result was considered to be a true classification the true classification is not entirely accurate as demonstrated by the 2 7 of error rate from the field checked results the 10 morphometric variables were then calculated for all the 22 884 depressions a response variable with a binary classification sinkhole or non sinkhole was created using sinkhole mapping result the resulting dataset was imbalanced as only 24 6 of the records were classified as sinkholes the dataset was skewed toward the non sinkhole class 4 2 model testing results the roc curves fig 3 show that all the methods worked well for the sinkhole dataset with aucs ranging from 0 874 0 950 the best performing methods were neural network auc 0 950 random forests auc 0 947 and rusboost auc 0 942 the pr curves fig 4 show that neural network pr auc 0 860 performed the best among the six methods followed by random forests pr auc 0 851 and support vector machine pr auc 0 828 overall the roc curves and pr curves gave similar assessment results for these methods table 2 shows that neural network had the highest overall accuracy average accuracy and f measure random forests and rusboost achieved very close performance to neural network 4 3 model application results the performance evaluation of the six classifiers showed that the dataset derived using the morphometry of the depressions from the three counties provides adequate information for machine learning to separate sinkholes from other depressions the evaluation also showed that neural network worked best among the six methods however although the neural network correctly identified 830 sinkholes it also missed 255 actual sinkholes and misclassified 206 non sinkholes as sinkholes table 3 we needed to find a way to take advantage of the classifier while minimizing loss in accuracy we applied the two step procedure to scott county another county in the bluegrass region fig 1 we retrained a neural network classifier using all 22 884 records collected from bourbon woodford and jessamine counties using the depression extraction method by zhu et al 2014 we extracted 10 626 topographic depressions from a lidar derived dem of scott county the same 10 variables describing morphometric characteristics of these depressions were calculated the trained neural network classifier was then applied to predict the probability of these depressions being sinkholes because most of scott county has similar geology as the other three counties we expected that the ratio of sinkholes to non sinkholes in the scott county dataset would be similar to the ratio in the training data 0 33 using this ratio with some added safety margins we used a probability threshold of 0 1 to separate the depressions into a sinkhole group and a non sinkhole group so that all records in the sinkhole group had a predicted sinkhole probability of 0 1 or higher and all records in the non sinkhole group had a predicted sinkhole probability below 0 1 the resulting sinkhole group had 2889 27 records and the non sinkhole group had 7737 73 records a ratio of 0 37 we then visually inspected the sinkhole group and identified 888 of them as sinkholes to see how many sinkholes could be missed by this two step procedure we also visually inspected the non sinkhole group and found that 31 of them were sinkholes this suggested that with the assistance of a machine learning classifier we would be able to identify 97 of sinkholes by inspecting only 27 of the total depressions for scott county the procedure saved more than 70 of the manual labor in visual inspection with a cost of missing only a small number of sinkholes when inspecting the 31 sinkholes the neural network classifier predicted with low probability of being sinkholes 0 1 we found their morphometric characteristics were not typical as sinkholes for example some of them had a naturally irregular surficial shape that was very different from the circular shape of typical sinkholes fig 5 a some had been partially modified by human activities such as road constructions fig 5b some were groups of small sinkholes that were too small to be classified as sinkholes individually fig 5c fig 5c shows the limits of the dataset in which each depression was considered independently spatially we have observed that sinkholes tend to form in clusters along major rivers or joints and lineaments zhu et al 2014 visual inspection can naturally take this spatial pattern into consideration but extracting variables to reflect that pattern can be difficult these cases showed a small number of sinkholes that cannot be characterized by their morphometric characteristics alone 4 4 discussion in this study the trained neural network model was applied to an area that has similar geologic and geographic conditions as the area for which the training dataset was developed development of sinkholes is influenced by many geologic topographic and climatologic factors and morphometry of sinkholes may not be equivalent from one region to another taylor and doctor 2016 to see if the trained neural network model is applicable to another karst region we tested the model in oldham county kentucky where sinkholes have been mapped previously using lidar data zhu and pierskalla 2016 oldham county is approximately 100 km northwest of the study area and is underlain by limestone and dolomite of late ordovician and silurian age newell 1986 the application of the two step procedure to oldham county showed that a sinkhole probability threshold of 0 1 classified 60 of depressions as non sinkhole but the sinkhole group missed 14 of actual sinkholes when a threshold of 0 025 was used 43 of the polygons were classified as non sinkhole whereas the sinkhole group missed only 4 of actual sinkholes this suggests that the trained classification model may yield less accurate results when applied to other karst regions which is not surprising to apply the method described in this paper to other karst regions a better way would be to re train the machine learning models using data from the same region on the other hand the model trained in this study can still be potentially useful for another karst region if used as a screening tool to remove obvious non sinkholes in this case the threshold used for screening depressions should be tested and adjusted for the region a comparison of performance metrics between this study and our previous study zhu and pierskalla 2016 showed the random forests model in this study achieved higher accuracy than our previous random forests model the improvement may be attributed to the larger training dataset used in this study 18 308 records compared to 8427 records used previously the performance difference may also be attributed to how the two models were tested in zhu and pierskalla 2016 the trained model was tested in an area adjacent to the area where the training data were extracted in this study the testing data and training data were from the same area and separation of the two subsets was done randomly sinkholes have different sizes and shapes the 10 morphometric variables certainly did not capture all the details of the three dimensional nature of sinkholes the machine learning models may be improved if additional morphometric variables can be developed and added to the training data on the other hand deep learning can use images of sinkholes directly as training data and offers an alternate approach that may further improve classification accuracy and expedite the sinkhole mapping process 5 conclusions we tested six machine learning methods to locate karst sinkholes from lidar data in the bluegrass region of kentucky we built a dataset of morphometric characteristics of mapped sinkholes in bourbon jessamine and woodford counties and trained and tested classifiers using logistic regression naive bayes support vector machine neural network random forests and rusboost we then used a two step procedure that combined the best performing classifier with manual inspection in scott county to improve sinkhole mapping efficiency our study concluded 1 morphometric characteristics of sinkholes provided sufficient information for separating most sinkholes from other forms of surface depressions 2 neural network performed the best among the six machine learning methods in identifying sinkholes from other depressions neural network achieved the highest auc values from the receiver operating characteristic curves and the precision recall curves and best values for overall accuracy average accuracy and f measure 3 the two step procedure of combining a machine learning classifier with manual visual inspection improved efficiency while maintaining accuracy with the assistance of a neural network classifier we located 97 of sinkholes by inspecting only 27 of the topographic depressions in scott county credit authorship contribution statement junfeng zhu conceptualization methodology formal analysis investigation writing original draft writing review editing visualization supervision project administration adam m nolte investigation resources data curation writing review editing nathan jacobs methodology validation formal analysis writing review editing ming ye conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank dr anke meyer baese and amirhessam tahmassebi from florida state university for their collaboration with us on machine learning we also thank kalli beasley ethan davis megan hackett and steve webb for their help in mapping sinkholes for the study area our appreciation also goes to the associate editor and the anonymous reviewers for their constructive comments we thank meg smath for her editorial review the last author was supported by national science foundation grant ear 1828827 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125049 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5312,the conterminous united states conus extends over a region of contrasting climates with an uneven distribution of freshwater resources under climate change most predictions concur on critical disturbances in the terrestrial hydrological cycle with consequences on freshwater resources availability in the case of the us an exacerbation of the contrast between dry and wet regions is expected and could drastically affect local ecosystems agriculture practices and communities hence efforts to better understand long term spatial and temporal patterns of freshwater resources are needed to plan and anticipate responses since 2002 the gravity recovery and climate experiment grace and grace follow on grace fo satellite observations provide estimates of large scale land water storage changes with an unprecedented accuracy however the limited lifetime and observation gaps of the grace mission have sparked research interest for grace like data reconstruction hence this study developed a predictive modeling approach to quantify monthly land liquid water equivalence thickness anomaly lwe using climate variables including total precipitation pre number of wet day wet air temperature tmp and potential evapotranspiration pet the approach builds on the achievements of the grace mission by determining lwe footprints using a multivariate regression on principal components model with lag signals the performance evaluation of the model with a lag signals consideration shows 0 5 r2 0 8 for 41 2 of the conus however the model s predictive power is unevenly distributed the model could be useful for predicting and monitoring freshwater resources anomalies for the locations with high model performances keywords climate water resources grace satellite multivariate model lag signals conterminous us 1 introduction worldwide the long term availability of freshwater resources has become a major concern as many countries have experienced a decline of per capita available water while the demand is continuously increasing grafton et al 2013 shiklomanov and rodda 2004 with the ongoing climate change many indicators presage significant disturbances in the future hydrological cycle leading to an exacerbation of the freshwater resources decline du plessis 2019 oki and kanae 2006 held and soden 2006 as freshwater resources are unequally distributed in time and space across the globe a further decline of the existing resources is likely to affect human communities and disturb local ecosystems in the conterminous united states conus the unequal distribution of freshwater resources is very pronounced and aligns with the contrasting climate which ranges from arid in the southwest to humid in the southeast and the northeast across the country freshwater resources are used in various sectors including agriculture i e irrigation livestock aquaculture energy production mining industries recreation and domestic supply among these sectors agriculture sustainability concerns often rise because of a high reliance on irrigation for instance irrigation water withdrawal in the us during 2015 has been estimated as 118 billion gallons accounting for 42 of the total freshwater withdrawal dieter et al 2018 since 1960 the annual irrigation water withdrawal in us has been continuously above 110 billion gallons dieter et al 2018 as consequences of this continuous pressure on water over the last six decades evidences of freshwater resources depletion e g groundwater decline are being widely reported across the us multsch et al 2016 holzer and galloway 2005 this situation has raised concerns regarding the sustainability of us agriculture and the need to adapt water resources management plans in response to climate variability the components of terrestrial freshwater resources include surface water glaciers soil water and groundwater understanding the holistic pattern of these components is critical to envision an effective water management at large scale satellite images such as those from the gravity recovery and climate experiment grace and grace follow on grace fo missions enable large scale understanding of earth surface processes indeed the grace satellite mission was launched in march 2002 and has continuously collected detailed measurements of earth s gravity field anomalies for about 15 years march 2002 to october 2017 grace data have been used to estimate the land water storage anomalies at a monthly basis with an accuracy of 1 5 cm equivalent water height famiglietti and rodell 2013 scanlon et al 2012 even though this capacity of grace to provide comprehensive measurement of land water storage anomalies landerer and swenson 2012 is an undeniably prominent achievement the data gaps and short time frame of grace observations is a limitation for long term appreciation of land water storage patterns the need to reconstruct grace like land water storage changes outside grace mission periods has led researchers to investigate data driven modeling approaches using climate inputs li et al 2020 yin et al 2019 humphrey and gudmundsson 2019 nie et al 2016 for instance humphrey et al 2017 reported a grid point land water storage data reconstruction for the period 1985 to 2015 using a statistical model based on precipitation and temperature likewise yin et al 2019 attempted to reconstruct long term grace like data for a period prior to 2002 using precipitation runoff and evapotranspiration recently li et al 2020 evaluated various analytical approaches for land water storage change retrieval at basin scale using precipitation land surface temperature sea surface temperature and climate indices while these studies contributed significantly to the understanding of grace like water storage anomalies more research efforts are needed to reach an unified predictive approach indeed the perspective of forecasting these anomalies is relevant for water resources planning for instance an accurate estimate of past and future land water storage anomalies at a given location could be used to plan or improve water resources management strategies hence the aim of the present study is to propose a potentially predictive framework of land water storage anomalies using climate variables with an inclusion of lag signals this study builds on the achievement of the fifteen year grace satellite mission by developing a predictive method for retrieving monthly land water storage signals from climate variables the use of climate inputs for grace like anomalies estimate assumes that the temporal change of land water storage is governed by land atmosphere exchange sadeghi et al 2020 crow et al 2017 individually climate variables exert an influence on the terrestrial water cycle such that for certain regions of the globe these variables are the main drivers of the water balance mueller schmied et al 2016 milly 1994 thus in this study large scale monthly land water storage anomalies are assumed to be primarily determined by climate variables in addition to reporting the method and results this paper analytically discusses the outcomes and lays the ground for potential considerations in freshwater resources management across the conus 2 data and method 2 1 data in accordance with the study s scope which is to develop a modeling framework to predict land water storage anomalies 15 years remote sensing and climate datasets were used the remote sensing dataset consisted of the liquid water equivalence thickness anomalies lwe derived from grace satellite mission measurement of earth gravity field variation swenson 2012 landerer and swenson 2012 lwe is a measurement of the variation of the vertical extent of land water storage including snow surface water i e rivers lakes reservoirs soil moisture and groundwater grace s lwe anomalies are estimated in centimeters of equivalent water thickness and released as monthly gridded time series with a spatial resolution of 1 in both latitude and longitude at a given grid the monthly grace land water storage deviations were estimated relative to a baseline temporal average of the period 2004 2009 cooley and landerer 2019 as grace satellite s science mission spanned from march 2002 to october 2017 continuous monthly lwe estimates were processed and released separately by three mandated institutions including the center for space research csr the geo forschungs zentrum gfz and the jet propulsion laboratory jpl the 15 years monthly gridded time series data released by crs gfz and jpl were collected from the national aeronautics and space administration nasa database www nasa gov as recommended by sakumura et al 2014 the ensemble average of the three lwe datasets i e crs gfz and jpl was computed to limit uncertainties along with the ensemble averaged lwe dataset the study used monthly climate data including total precipitation pre number of wet days wet average air temperature tmp and the potential evapotranspiration pet the climate data were collected from the university of east anglia s climatic research unit cru datasets harris et al 2014 especially the cru s time series version 4 03 datasets were considered and the 0 5 0 5 gridded time series of pre wet tmp and pet were retrieved for the time span 2002 2017 matching the remote sensing data availability period to generate monthly timeseries of pre wet and tmp the cru uses two major sources of historical climate data including the world meteorological organization wmo and the national oceanographic and atmospheric administration noaa databases harris et al 2014 however the cru s pet time series were estimated using the food and agricultural organization s penman monteith method harris et al 2014 ekstrom et al 2007 as the study focused on the conus regions only the grids encompassed by the region were considered for the study to match the grid resolution of the climate data the lwe data were rescaled to a 0 5 0 5 resolution table 1 presents an overview of all the data 2 2 method in general the terrestrial water balance is influenced by climatic anthropogenic geologic pedologic topographic and ecological factors mueller schmied et al 2016 oki and kanae 2006 milly 1994 these factors affect differently the hydrosphere such that in many regions of the globe the variations of land water storage are mainly driven by a few dominant factors this is true with climate factors which are known to play a major role in the terrestrial water cycle mueller schmied et al 2016 kunstmann et al 2008 the present study proposes a multivariate model for predicting monthly land water storage variations based on climate variables the monthly climate variables include pre wet tmp and pet a general challenge with multivariate models is the risk of redundancy in the explanatory variables todeschini et al 2004 in the present case the interplays of climate variables are factual and need to be understood in order to enhance the variables representation in a multivariate model hence the analytical approach used in the study included i trend analyses of lwe anomalies ii marginal correlation analysis between lwe and individual climate variable with and without lag time consideration iii multivariate modeling of land water storage changes all the analyses were conducted for individual 0 5 0 5 grid encompassed by the conus territory 3452 grids in total the trend analyses were conducted on the 15 years monthly gridded time series of lwe the objective was to investigate regional patterns of land water storage anomalies across the conus for the analysis the mann kendall monotonic trend hamed 2008 was tested for individual grid indeed each grid j is associated with a time series lw e j lw e j i d a t e i lw e j n d a t e n where 1 i n lwej i is the measured land water storage anomaly of j at datei comprised between april 2002 and june 2017 kendall s τ values bolboaca and jäntschi 2006 were estimated at grids level and the significance at p value 0 05 was determined to classify each grid as positive trend negative trend or no trend given a random grid j associated with the time series lwej the corresponding kendall s τ j is calculated using the equation 1 where nc and nd are respectively the numbers of concordant and discordant pairs t and u the number of ties within lwe and dates 1 kendall τ j n c n d n n 1 2 t n n 1 2 u 0 5 marginal correlation analyses were separately conducted by coupling the time series of lwe anomalies with each climate variable i e pre wet tmp pet time lags of 0 1 2 3 months were considered between lwe and each climate variable x for a random grid j the coefficient of determination r lag 2 j was estimated with lag times lag 0 1 2 3 using the equation 2 where lwe j and x j are respectively the average land water storage anomaly and the average climate variable value for the grid j 2 r lag 2 j i 1 n l w e j i lwe j x j i l a g x j 2 i 1 n l w e j i lwe j 2 i 1 n x j i l a g x j 2 the objective of the marginal correlation analysis was to evaluate lag signals and for eventual inclusion in the modeling approach the proposed model was a multivariate regression on principal components sousa et al 2007 jolliffe 1982 indeed analytical methods developed to investigate the grace like lwe retrieval include multilinear regressions artificial neural network autoregressive model etc yin et al 2019 yang et al 2018 humphrey et al 2017 nie et al 2016 recently li et al 2020 compared several of these climate based analytical methods for grace data reconstruction and concluded on the robustness of the multilinear regression on principal components this study sought to fill an information gap by exploring the joint inclusion of critical land atmosphere components such a pre wet tmp pet along with their related marginal lag effects the modeling framework developed in the study included two stages which were both carried at grid level the first stage is an application of principal component analysis pca on the four climate variables represented by their time series for each grid the pca application generated four principal components pcs which were orthogonal but captured the essential variance imbedded in the original four climate variables i e pre wet tmp and pet hence pca was used here to eliminate redundant effects among the four explanatory climate variables abdi and williams 2010 the second stage of the model framework was an application of a multivariate regression on pcs scores for estimating lwe anomalies for a grid j equation 3 presents the model where pc1j pc2j pc3j pc4j are the principal components α j β j χ j δ j and ε j are the parameters of the model 3 lw e j i α j p c 1 j i β j p c 2 j i χ j p c 3 j i δ j p c 4 j i ε j at this stage the inclusion of lag time signals was evaluated to propose a potentially predictive framework for lwe with pcs scores as inputs the performances of the model with and without lag signals inclusion were evaluated at grids level by calculating indicators such as r2 and the root mean squared errors rmse the rmse is given by equation 4 where lw e j i and lw e j i are respectively the observed and simulated land water storage anomaly for grid j at date i 4 rmse j 1 n i 1 n l w e j i l w e j i 2 0 5 3 results 3 1 trends of land water storage anomalies average lwe anomalies have been calculated for the 15 years monthly land water storage changes estimated by grace satellite mission fig 1 a presents the spatial distribution of these average values across the conus overall the average land water storage anomalies in the conus gradually change from north to south and east to west specifically fig 1a shows northward positive average land water storage anomalies while negative anomalies are observed in the southwestern part of the us these tendencies may be linked with the results of the mann kendall trend analysis reported in fig 1b which shows a demarcation of three zones of lwe anomalies trends these include a zone of positive trend in the north a zone of negative trend in the southwest and both zones separated by a transitional zone with no significant trend the patterns observed in both fig 1a and b are consistent and they confirm the uneven distribution of freshwater resources across the conus a persistence of the decreasing trend in the southwest and an increasing trend in the north and the east coast is likely to accentuate the regional water resources contrast on the long run such contrast could have a profound impact on human activities and the environment 3 2 lag signals analysis the marginal inter relations between lwe anomalies and each of the explanatory variables i e pre wet tmp and pet were evaluated using correlation analyses the outcomes are presented as boxplots of r2 values figs 2 b d 3 b d along with maps showing the spatial distribution of the highest lag signals figs 2a c 3a c especially fig 2 reports the analyses related to the couples lwe pre and lwe wet while fig 3 reports the analyses of lwe tmp and lwe pet the lag time signals analyses show some similitudes between the couples lwe pre and lwe wet in fig 2 and the couples lwe tmp and lwe pet in fig 3 specially for the couples lwe tmp and lwe pet the two month lag time signals are the strongest fig 3b and d for instance the inclusion of a two months lag time raises the median of r2 values from 0 07 to 0 37 for lwe tmp and from 0 02 to 0 38 for lwe pet similitudes are also noticeable in fig 3a and c which display the spatial distribution of the r2 with the two month lag time in the case of the couples lwe pre and lwe wet the disparity among the lag signals fig 2b and d are not as remarkable as it is in fig 3b and b however a closer appraisal shows a higher median and interquartile range for the one month lag signals particularly in fig 2d fig 2a and c present the spatial distribution of the r2 with one month lag for the couples lwe pre and lwe wet respectively overall the lag time analyses suggest predictive relationships between lwe anomalies and the climate events during the previous months these signals can henceforth be considered when developing a predictive framework for land water storage anomaly estimates 3 3 predictive model for land water storage anomalies two scenarios of multivariate regression on pcs were applied to the climate variables for estimating land water storage anomalies the first scenario assumed no lag time between the explanatory variables and the response i e lwe while the second scenario emphasized the inclusion of lag time between the explanatory variables and the response in accordance with the lag signals analysis the second scenario considered one month lag time for pre and wet two month lag time for tmp and pet for each of the scenarios the model performances were evaluated by calculating the rmse and the r2 values of individual grid the results of this evaluation are reported in table 2 and fig 4 table 2 presents the percentage areas of the conus associated with different ranges of r2 and rmse values for each scenario with no lag in the model 7 7 of the total area has r2 0 5 while the inclusion of lag signals increases this percentage to 41 2 this remarkable increase as portrayed by fig 4a and b indicates a significant improvement of the ability of the model to estimate land water storage anomalies this tendency corroborates with the rmse analysis which showed a remarkable increase of accuracy fig 4c and d as the percentage of areas with rmse 0 05 shifts from 43 4 to 66 4 hence the multivariate regression on pcs performed better with the inclusion of lag signals interestingly the lag signal inclusion also shows the opportunity of predicting closely the land water storage anomalies at a given month based on the knowledge of pre and wet from the previous month and tmp and pet from two months prior the model performance of the model varies across the conus this aspect is presented in fig 5 which shows the spatial distribution of the performance indicator values r2 and rmse for both modeled scenarios i e no lag with lag a juxtaposition of fig 5a and b shows an improvement of the lag signals inclusion on the model performance likewise a comparison between fig 5c and d shows an expansion of areas with lower rmse which indicates an enhancement of the model estimates in addition relevant spatial patterns are noticeable in the scenario with lag signals inclusion for instance in fig 5b grids with high model performances e g 0 5 r2 0 8 are collocated this collocation offers the possibility to delineate regions where this model could be used for predicting and monitoring water resources anomalies 3 4 testing the model s predictive capacity the model s predictive capacity was tested for all the conus grids using the period 2002 2014 for calibration and the period 2015 2017 for validation the calibration procedure consists in estimating the parameters α j β j χ j δ j and ε j in equation 3 the estimated parameters are thereafter used in the model to predict grace like lwe anomalies for the validation period the model performance during the calibration and the validation stage were analyzed and reported in fig 6 a and b which present boxplots of performance indicators at the validation stage based on ranges of r2 and rmse at the calibration stage hence in fig 6a the boxplots corresponding to the grids with r2 0 50 at calibration show medians close or above 0 50 this result sustains the predictive capacity of the model for the grids with high model performance values in fig 6c and d the performance indicators of the model when calibrated based on the period 2002 2014 subset of the data availability period were compared to those based on the period 2002 2017 entire data availability period the results show that the calibration period 2002 2014 is representative to the period 2002 2017 however such a configuration may not be the case when a shorter subset the satellite records time period is used to calibrate the model for grace like lwe anomalies predictions owing to the statistical uncertainties related to the lack of data the use of large time periods data for calibration is desirable for a robust computational model setting lee et al 2019 4 synthesis and discussion the study unveiled salient patterns of freshwater resources across the conus the mann kendall trend analysis of the 15 years grace s lwe anomalies revealed three major zones in the conus including a zone with an increasing trend in the north a zone with a decreasing trend in the southwest and a transitional zone with no significant trend fig 1b the decreasing trend of lwe anomalies observed in the southwest is consistent with previous studies which reported evidences of freshwater resources decline in the southwest us sohoulande 2017 scanlon et al 2012 holzer and galloway 2005 in the long term a persistence of the declining trend could affect human society and disturb local ecosystems as all organisms require water for their survival oki and kanae 2006 this could be perceived as an alert to envision plans for freshwater resources sustainability for instance with the high dependency of us agricultural sector on groundwater withdrawal dieter et al 2018 food security could be compromised as the population grows while water resources decline hence the sustainability of human society depends on freshwater availability in time and space at a given location the land water storage includes snow surface water soil moisture and groundwater the fluctuation of land water storage is often a result of multiple interplays between biophysical factors bosilovich et al 2017 wang et al 2012 understanding these interplays is important for modeling the land water storage at large scales grace s lwe anomalies are good estimates of the monthly variation of the vertical extent of land water storage cooley and landerer 2019 famiglietti and rodell 2013 as intended 15 years monthly grace s lwe and climate data have been used to develop a potentially predictive framework for land water storage anomalies the study evaluated the marginal relationships between the monthly grace s lwe anomalies and each of the climate variables pre wet tmp and pet the overall results show low r2 values but lag signal analyses unveil a substantial increase of r2 values particularly for the couples lwe tmp and lwe pet for instance with a two month lag time the median of r2 reached 0 37 for lwe tmp and 0 38 for lwe pet in view of the spatial scale the lag signals are probably the result of complex biophysical interplays which can be portrayed as the delayed effect of rain on surface flow muthanna et al 2008 or vegetation sohoulande et al 2015 the lag signals have been integrated in a multivariate regression on pcs model sousa et al 2007 jolliffe 1982 for estimating land water storage anomalies the modeling framework has two steps the first step is a principal component analysis on climate variables i e pre wet tmp and pet the second step is a multivariate regression carried on the principal components li et al 2020 asserted the robustness of the multivariate regression on pcs for grace like water storage change retrieval at basin levels the pca eliminates redundant signals among the targeted climate variables the resulting pcs are orthogonal variables abdi and williams 2010 and are henceforth used as inputs in lieu of the original explanatory climate variables for individual 0 5 0 5 grid encompassing the conus the parameters of the model have been estimated for two distinct scenarios one with no lag and another with lag signals the grid wise evaluation of the model across the conus shows different performance levels fig 5 however the inclusion of lag signals has clearly enhanced the model performance in addition the spatial patterns of the performance indicators i e r2 and rmse suggest potential usage of the model for land water storage monitoring indeed acceptable performances i e r2 0 5 were noted for approximatively 41 2 of the conus for the corresponding grids one can assume that the temporal change of land water storage is explained by climate variables fluctuations the predictive capacity of the model was tested for all the conus grids using the time slices 2002 2014 and 2015 2017 for calibration and validation respectively the model performance at validation sustained its potential use as a predictive tool however the use of long data period for model calibration is desirable as it reduces statistical uncertainties in the simulations lee et al 2019 hence the model could be recommended for parts of the conus shown in fig 5b by the green areas with r2 0 50 as an example fig 7 illustrate a comparison of the model simulations to grace s lwe at a random location i e latitude 36 25 longitude 82 25 with high model performance r2 0 65 for such a location the multivariate regression on pcs with an inclusion of lag signals can valuably complement grace s lwe measurements thus the model could be used to provide estimates of land water storage anomalies for months with no satellite records of earth gravity field change e g periods preceding grace satellite mission likewise the model could serve to fill gaps within the satellite records time periods overall the study shows that the joint inclusion of pre wet tmp pet along with their related marginal lag effects could help achieve acceptable estimates of grace like land water storage anomalies the multivariate regression on pcs with lag signals show an uneven predictive power across the conus this result corroborates with previous studies focus on grace like data retrieval which also highlighted the variability of data driven analytical models performance across study regions li et al 2020 yin et al 2019 yang et al 2018 in general computational models imbed three categories of uncertainties including physical modeling and statistical lee et al 2019 harmel et al 2010 the physical uncertainties are associated to measurements while the modeling uncertainties are intrinsic to the model itself and the statistical ones are inherent to the lack of data lee et al 2019 these uncertainties are undeniably represented in this study and could somewhat explain the spatial variability of the model performance across the conus for instance landerer and swenson 2012 assessed the accuracy of gridded grace estimates of terrestrial water storage and reported spatial variations in the accuracy of grace measurements likewise the spatial accuracy of the climate inputs is arguable since the gridded cru datasets are generated using noaa stations which are unevenly distributed across the conus sohoulande et al 2019 harris et al 2014 in this context the model performance is likely to vary from grid to grid confirming the tendency in fig 5 besides the bias associated to the input data and the modeling procedure the noted spatial variability of the model performance could also be explained by the geophysical ecological or anthropological configurations of the study region for instance sadeghi et al 2020 reported that grace based retrieval of surface soil wetness is more effective in the wet region of the conus compared to arid regions this contrast seems to be true in the present case study fig 5b as the retrieval of grace like lwe appeared less effective in the arid region southwest conus compared to the wet region east coastal and northwest conus regardless this uneven spatial distribution of the model s predictive power a value of the model could be its potential use for predicting with a month in advance the land water storage anomalies such predictions of land water storage variations can be useful to plan the enhancement of water resources allocation and management 5 conclusion the study provides insight into the spatial patterns of land water storage anomalies across the conus using 15 years grace satellite mission data a multivariate regression on pcs model has been employed to evaluate the predictability of monthly land water storage anomalies based on climate variables inclusion of lag signals in the model has enhanced its performance and offers an option for predicting land water storage variations based on climate information even though the model performed unequally across the conus the outcomes are consistent and lead to the following conclusions i lag signals of climate variables such as monthly precipitation number of wet days air temperature and evapotranspiration explain more than 50 of the variance i e r2 0 5 of land water storage changes for at least 41 of the conus territory ii when climate data are available the multivariate regression on pcs with lag signals inclusion can complement satellite measurements of earth gravity field variations by providing estimates of land water storage anomalies for months outside the satellite mission periods overall the outcomes corroborate previous studies which related temporal changes in local water balance with the fluctuation of climate variables such as precipitation temperature and evapotranspiration crow et al 2017 wang et al 2012 milly 1994 for certain locations the low model performance illustrates the limitation of relying only on climate variables and a single model to predict land water storage change in view of this drawback and the limitations noted in previous studies focused on grace like lwe anomalies reconstruction li et al 2020 yin et al 2019 humphrey et al 2017 additional research is needed to achieve a spatially uniform model performance perhaps future studies could capitalize all the scientific contributions by investigating a multi model approach including anthropogenic geologic pedologic topographic and ecological variables in addition to the climate ones disclaimer mention of trade names or commercial products in this article is solely for the purpose of providing specific information and does not imply recommendation or endorsement by the u s department of agriculture credit authorship contribution statement clement d d sohoulande conceptualization methodology data curation formal analysis writing original draft writing review editing jerry martin data curation writing review editing ariel szogi supervision writing review editing kenneth stone supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
5312,the conterminous united states conus extends over a region of contrasting climates with an uneven distribution of freshwater resources under climate change most predictions concur on critical disturbances in the terrestrial hydrological cycle with consequences on freshwater resources availability in the case of the us an exacerbation of the contrast between dry and wet regions is expected and could drastically affect local ecosystems agriculture practices and communities hence efforts to better understand long term spatial and temporal patterns of freshwater resources are needed to plan and anticipate responses since 2002 the gravity recovery and climate experiment grace and grace follow on grace fo satellite observations provide estimates of large scale land water storage changes with an unprecedented accuracy however the limited lifetime and observation gaps of the grace mission have sparked research interest for grace like data reconstruction hence this study developed a predictive modeling approach to quantify monthly land liquid water equivalence thickness anomaly lwe using climate variables including total precipitation pre number of wet day wet air temperature tmp and potential evapotranspiration pet the approach builds on the achievements of the grace mission by determining lwe footprints using a multivariate regression on principal components model with lag signals the performance evaluation of the model with a lag signals consideration shows 0 5 r2 0 8 for 41 2 of the conus however the model s predictive power is unevenly distributed the model could be useful for predicting and monitoring freshwater resources anomalies for the locations with high model performances keywords climate water resources grace satellite multivariate model lag signals conterminous us 1 introduction worldwide the long term availability of freshwater resources has become a major concern as many countries have experienced a decline of per capita available water while the demand is continuously increasing grafton et al 2013 shiklomanov and rodda 2004 with the ongoing climate change many indicators presage significant disturbances in the future hydrological cycle leading to an exacerbation of the freshwater resources decline du plessis 2019 oki and kanae 2006 held and soden 2006 as freshwater resources are unequally distributed in time and space across the globe a further decline of the existing resources is likely to affect human communities and disturb local ecosystems in the conterminous united states conus the unequal distribution of freshwater resources is very pronounced and aligns with the contrasting climate which ranges from arid in the southwest to humid in the southeast and the northeast across the country freshwater resources are used in various sectors including agriculture i e irrigation livestock aquaculture energy production mining industries recreation and domestic supply among these sectors agriculture sustainability concerns often rise because of a high reliance on irrigation for instance irrigation water withdrawal in the us during 2015 has been estimated as 118 billion gallons accounting for 42 of the total freshwater withdrawal dieter et al 2018 since 1960 the annual irrigation water withdrawal in us has been continuously above 110 billion gallons dieter et al 2018 as consequences of this continuous pressure on water over the last six decades evidences of freshwater resources depletion e g groundwater decline are being widely reported across the us multsch et al 2016 holzer and galloway 2005 this situation has raised concerns regarding the sustainability of us agriculture and the need to adapt water resources management plans in response to climate variability the components of terrestrial freshwater resources include surface water glaciers soil water and groundwater understanding the holistic pattern of these components is critical to envision an effective water management at large scale satellite images such as those from the gravity recovery and climate experiment grace and grace follow on grace fo missions enable large scale understanding of earth surface processes indeed the grace satellite mission was launched in march 2002 and has continuously collected detailed measurements of earth s gravity field anomalies for about 15 years march 2002 to october 2017 grace data have been used to estimate the land water storage anomalies at a monthly basis with an accuracy of 1 5 cm equivalent water height famiglietti and rodell 2013 scanlon et al 2012 even though this capacity of grace to provide comprehensive measurement of land water storage anomalies landerer and swenson 2012 is an undeniably prominent achievement the data gaps and short time frame of grace observations is a limitation for long term appreciation of land water storage patterns the need to reconstruct grace like land water storage changes outside grace mission periods has led researchers to investigate data driven modeling approaches using climate inputs li et al 2020 yin et al 2019 humphrey and gudmundsson 2019 nie et al 2016 for instance humphrey et al 2017 reported a grid point land water storage data reconstruction for the period 1985 to 2015 using a statistical model based on precipitation and temperature likewise yin et al 2019 attempted to reconstruct long term grace like data for a period prior to 2002 using precipitation runoff and evapotranspiration recently li et al 2020 evaluated various analytical approaches for land water storage change retrieval at basin scale using precipitation land surface temperature sea surface temperature and climate indices while these studies contributed significantly to the understanding of grace like water storage anomalies more research efforts are needed to reach an unified predictive approach indeed the perspective of forecasting these anomalies is relevant for water resources planning for instance an accurate estimate of past and future land water storage anomalies at a given location could be used to plan or improve water resources management strategies hence the aim of the present study is to propose a potentially predictive framework of land water storage anomalies using climate variables with an inclusion of lag signals this study builds on the achievement of the fifteen year grace satellite mission by developing a predictive method for retrieving monthly land water storage signals from climate variables the use of climate inputs for grace like anomalies estimate assumes that the temporal change of land water storage is governed by land atmosphere exchange sadeghi et al 2020 crow et al 2017 individually climate variables exert an influence on the terrestrial water cycle such that for certain regions of the globe these variables are the main drivers of the water balance mueller schmied et al 2016 milly 1994 thus in this study large scale monthly land water storage anomalies are assumed to be primarily determined by climate variables in addition to reporting the method and results this paper analytically discusses the outcomes and lays the ground for potential considerations in freshwater resources management across the conus 2 data and method 2 1 data in accordance with the study s scope which is to develop a modeling framework to predict land water storage anomalies 15 years remote sensing and climate datasets were used the remote sensing dataset consisted of the liquid water equivalence thickness anomalies lwe derived from grace satellite mission measurement of earth gravity field variation swenson 2012 landerer and swenson 2012 lwe is a measurement of the variation of the vertical extent of land water storage including snow surface water i e rivers lakes reservoirs soil moisture and groundwater grace s lwe anomalies are estimated in centimeters of equivalent water thickness and released as monthly gridded time series with a spatial resolution of 1 in both latitude and longitude at a given grid the monthly grace land water storage deviations were estimated relative to a baseline temporal average of the period 2004 2009 cooley and landerer 2019 as grace satellite s science mission spanned from march 2002 to october 2017 continuous monthly lwe estimates were processed and released separately by three mandated institutions including the center for space research csr the geo forschungs zentrum gfz and the jet propulsion laboratory jpl the 15 years monthly gridded time series data released by crs gfz and jpl were collected from the national aeronautics and space administration nasa database www nasa gov as recommended by sakumura et al 2014 the ensemble average of the three lwe datasets i e crs gfz and jpl was computed to limit uncertainties along with the ensemble averaged lwe dataset the study used monthly climate data including total precipitation pre number of wet days wet average air temperature tmp and the potential evapotranspiration pet the climate data were collected from the university of east anglia s climatic research unit cru datasets harris et al 2014 especially the cru s time series version 4 03 datasets were considered and the 0 5 0 5 gridded time series of pre wet tmp and pet were retrieved for the time span 2002 2017 matching the remote sensing data availability period to generate monthly timeseries of pre wet and tmp the cru uses two major sources of historical climate data including the world meteorological organization wmo and the national oceanographic and atmospheric administration noaa databases harris et al 2014 however the cru s pet time series were estimated using the food and agricultural organization s penman monteith method harris et al 2014 ekstrom et al 2007 as the study focused on the conus regions only the grids encompassed by the region were considered for the study to match the grid resolution of the climate data the lwe data were rescaled to a 0 5 0 5 resolution table 1 presents an overview of all the data 2 2 method in general the terrestrial water balance is influenced by climatic anthropogenic geologic pedologic topographic and ecological factors mueller schmied et al 2016 oki and kanae 2006 milly 1994 these factors affect differently the hydrosphere such that in many regions of the globe the variations of land water storage are mainly driven by a few dominant factors this is true with climate factors which are known to play a major role in the terrestrial water cycle mueller schmied et al 2016 kunstmann et al 2008 the present study proposes a multivariate model for predicting monthly land water storage variations based on climate variables the monthly climate variables include pre wet tmp and pet a general challenge with multivariate models is the risk of redundancy in the explanatory variables todeschini et al 2004 in the present case the interplays of climate variables are factual and need to be understood in order to enhance the variables representation in a multivariate model hence the analytical approach used in the study included i trend analyses of lwe anomalies ii marginal correlation analysis between lwe and individual climate variable with and without lag time consideration iii multivariate modeling of land water storage changes all the analyses were conducted for individual 0 5 0 5 grid encompassed by the conus territory 3452 grids in total the trend analyses were conducted on the 15 years monthly gridded time series of lwe the objective was to investigate regional patterns of land water storage anomalies across the conus for the analysis the mann kendall monotonic trend hamed 2008 was tested for individual grid indeed each grid j is associated with a time series lw e j lw e j i d a t e i lw e j n d a t e n where 1 i n lwej i is the measured land water storage anomaly of j at datei comprised between april 2002 and june 2017 kendall s τ values bolboaca and jäntschi 2006 were estimated at grids level and the significance at p value 0 05 was determined to classify each grid as positive trend negative trend or no trend given a random grid j associated with the time series lwej the corresponding kendall s τ j is calculated using the equation 1 where nc and nd are respectively the numbers of concordant and discordant pairs t and u the number of ties within lwe and dates 1 kendall τ j n c n d n n 1 2 t n n 1 2 u 0 5 marginal correlation analyses were separately conducted by coupling the time series of lwe anomalies with each climate variable i e pre wet tmp pet time lags of 0 1 2 3 months were considered between lwe and each climate variable x for a random grid j the coefficient of determination r lag 2 j was estimated with lag times lag 0 1 2 3 using the equation 2 where lwe j and x j are respectively the average land water storage anomaly and the average climate variable value for the grid j 2 r lag 2 j i 1 n l w e j i lwe j x j i l a g x j 2 i 1 n l w e j i lwe j 2 i 1 n x j i l a g x j 2 the objective of the marginal correlation analysis was to evaluate lag signals and for eventual inclusion in the modeling approach the proposed model was a multivariate regression on principal components sousa et al 2007 jolliffe 1982 indeed analytical methods developed to investigate the grace like lwe retrieval include multilinear regressions artificial neural network autoregressive model etc yin et al 2019 yang et al 2018 humphrey et al 2017 nie et al 2016 recently li et al 2020 compared several of these climate based analytical methods for grace data reconstruction and concluded on the robustness of the multilinear regression on principal components this study sought to fill an information gap by exploring the joint inclusion of critical land atmosphere components such a pre wet tmp pet along with their related marginal lag effects the modeling framework developed in the study included two stages which were both carried at grid level the first stage is an application of principal component analysis pca on the four climate variables represented by their time series for each grid the pca application generated four principal components pcs which were orthogonal but captured the essential variance imbedded in the original four climate variables i e pre wet tmp and pet hence pca was used here to eliminate redundant effects among the four explanatory climate variables abdi and williams 2010 the second stage of the model framework was an application of a multivariate regression on pcs scores for estimating lwe anomalies for a grid j equation 3 presents the model where pc1j pc2j pc3j pc4j are the principal components α j β j χ j δ j and ε j are the parameters of the model 3 lw e j i α j p c 1 j i β j p c 2 j i χ j p c 3 j i δ j p c 4 j i ε j at this stage the inclusion of lag time signals was evaluated to propose a potentially predictive framework for lwe with pcs scores as inputs the performances of the model with and without lag signals inclusion were evaluated at grids level by calculating indicators such as r2 and the root mean squared errors rmse the rmse is given by equation 4 where lw e j i and lw e j i are respectively the observed and simulated land water storage anomaly for grid j at date i 4 rmse j 1 n i 1 n l w e j i l w e j i 2 0 5 3 results 3 1 trends of land water storage anomalies average lwe anomalies have been calculated for the 15 years monthly land water storage changes estimated by grace satellite mission fig 1 a presents the spatial distribution of these average values across the conus overall the average land water storage anomalies in the conus gradually change from north to south and east to west specifically fig 1a shows northward positive average land water storage anomalies while negative anomalies are observed in the southwestern part of the us these tendencies may be linked with the results of the mann kendall trend analysis reported in fig 1b which shows a demarcation of three zones of lwe anomalies trends these include a zone of positive trend in the north a zone of negative trend in the southwest and both zones separated by a transitional zone with no significant trend the patterns observed in both fig 1a and b are consistent and they confirm the uneven distribution of freshwater resources across the conus a persistence of the decreasing trend in the southwest and an increasing trend in the north and the east coast is likely to accentuate the regional water resources contrast on the long run such contrast could have a profound impact on human activities and the environment 3 2 lag signals analysis the marginal inter relations between lwe anomalies and each of the explanatory variables i e pre wet tmp and pet were evaluated using correlation analyses the outcomes are presented as boxplots of r2 values figs 2 b d 3 b d along with maps showing the spatial distribution of the highest lag signals figs 2a c 3a c especially fig 2 reports the analyses related to the couples lwe pre and lwe wet while fig 3 reports the analyses of lwe tmp and lwe pet the lag time signals analyses show some similitudes between the couples lwe pre and lwe wet in fig 2 and the couples lwe tmp and lwe pet in fig 3 specially for the couples lwe tmp and lwe pet the two month lag time signals are the strongest fig 3b and d for instance the inclusion of a two months lag time raises the median of r2 values from 0 07 to 0 37 for lwe tmp and from 0 02 to 0 38 for lwe pet similitudes are also noticeable in fig 3a and c which display the spatial distribution of the r2 with the two month lag time in the case of the couples lwe pre and lwe wet the disparity among the lag signals fig 2b and d are not as remarkable as it is in fig 3b and b however a closer appraisal shows a higher median and interquartile range for the one month lag signals particularly in fig 2d fig 2a and c present the spatial distribution of the r2 with one month lag for the couples lwe pre and lwe wet respectively overall the lag time analyses suggest predictive relationships between lwe anomalies and the climate events during the previous months these signals can henceforth be considered when developing a predictive framework for land water storage anomaly estimates 3 3 predictive model for land water storage anomalies two scenarios of multivariate regression on pcs were applied to the climate variables for estimating land water storage anomalies the first scenario assumed no lag time between the explanatory variables and the response i e lwe while the second scenario emphasized the inclusion of lag time between the explanatory variables and the response in accordance with the lag signals analysis the second scenario considered one month lag time for pre and wet two month lag time for tmp and pet for each of the scenarios the model performances were evaluated by calculating the rmse and the r2 values of individual grid the results of this evaluation are reported in table 2 and fig 4 table 2 presents the percentage areas of the conus associated with different ranges of r2 and rmse values for each scenario with no lag in the model 7 7 of the total area has r2 0 5 while the inclusion of lag signals increases this percentage to 41 2 this remarkable increase as portrayed by fig 4a and b indicates a significant improvement of the ability of the model to estimate land water storage anomalies this tendency corroborates with the rmse analysis which showed a remarkable increase of accuracy fig 4c and d as the percentage of areas with rmse 0 05 shifts from 43 4 to 66 4 hence the multivariate regression on pcs performed better with the inclusion of lag signals interestingly the lag signal inclusion also shows the opportunity of predicting closely the land water storage anomalies at a given month based on the knowledge of pre and wet from the previous month and tmp and pet from two months prior the model performance of the model varies across the conus this aspect is presented in fig 5 which shows the spatial distribution of the performance indicator values r2 and rmse for both modeled scenarios i e no lag with lag a juxtaposition of fig 5a and b shows an improvement of the lag signals inclusion on the model performance likewise a comparison between fig 5c and d shows an expansion of areas with lower rmse which indicates an enhancement of the model estimates in addition relevant spatial patterns are noticeable in the scenario with lag signals inclusion for instance in fig 5b grids with high model performances e g 0 5 r2 0 8 are collocated this collocation offers the possibility to delineate regions where this model could be used for predicting and monitoring water resources anomalies 3 4 testing the model s predictive capacity the model s predictive capacity was tested for all the conus grids using the period 2002 2014 for calibration and the period 2015 2017 for validation the calibration procedure consists in estimating the parameters α j β j χ j δ j and ε j in equation 3 the estimated parameters are thereafter used in the model to predict grace like lwe anomalies for the validation period the model performance during the calibration and the validation stage were analyzed and reported in fig 6 a and b which present boxplots of performance indicators at the validation stage based on ranges of r2 and rmse at the calibration stage hence in fig 6a the boxplots corresponding to the grids with r2 0 50 at calibration show medians close or above 0 50 this result sustains the predictive capacity of the model for the grids with high model performance values in fig 6c and d the performance indicators of the model when calibrated based on the period 2002 2014 subset of the data availability period were compared to those based on the period 2002 2017 entire data availability period the results show that the calibration period 2002 2014 is representative to the period 2002 2017 however such a configuration may not be the case when a shorter subset the satellite records time period is used to calibrate the model for grace like lwe anomalies predictions owing to the statistical uncertainties related to the lack of data the use of large time periods data for calibration is desirable for a robust computational model setting lee et al 2019 4 synthesis and discussion the study unveiled salient patterns of freshwater resources across the conus the mann kendall trend analysis of the 15 years grace s lwe anomalies revealed three major zones in the conus including a zone with an increasing trend in the north a zone with a decreasing trend in the southwest and a transitional zone with no significant trend fig 1b the decreasing trend of lwe anomalies observed in the southwest is consistent with previous studies which reported evidences of freshwater resources decline in the southwest us sohoulande 2017 scanlon et al 2012 holzer and galloway 2005 in the long term a persistence of the declining trend could affect human society and disturb local ecosystems as all organisms require water for their survival oki and kanae 2006 this could be perceived as an alert to envision plans for freshwater resources sustainability for instance with the high dependency of us agricultural sector on groundwater withdrawal dieter et al 2018 food security could be compromised as the population grows while water resources decline hence the sustainability of human society depends on freshwater availability in time and space at a given location the land water storage includes snow surface water soil moisture and groundwater the fluctuation of land water storage is often a result of multiple interplays between biophysical factors bosilovich et al 2017 wang et al 2012 understanding these interplays is important for modeling the land water storage at large scales grace s lwe anomalies are good estimates of the monthly variation of the vertical extent of land water storage cooley and landerer 2019 famiglietti and rodell 2013 as intended 15 years monthly grace s lwe and climate data have been used to develop a potentially predictive framework for land water storage anomalies the study evaluated the marginal relationships between the monthly grace s lwe anomalies and each of the climate variables pre wet tmp and pet the overall results show low r2 values but lag signal analyses unveil a substantial increase of r2 values particularly for the couples lwe tmp and lwe pet for instance with a two month lag time the median of r2 reached 0 37 for lwe tmp and 0 38 for lwe pet in view of the spatial scale the lag signals are probably the result of complex biophysical interplays which can be portrayed as the delayed effect of rain on surface flow muthanna et al 2008 or vegetation sohoulande et al 2015 the lag signals have been integrated in a multivariate regression on pcs model sousa et al 2007 jolliffe 1982 for estimating land water storage anomalies the modeling framework has two steps the first step is a principal component analysis on climate variables i e pre wet tmp and pet the second step is a multivariate regression carried on the principal components li et al 2020 asserted the robustness of the multivariate regression on pcs for grace like water storage change retrieval at basin levels the pca eliminates redundant signals among the targeted climate variables the resulting pcs are orthogonal variables abdi and williams 2010 and are henceforth used as inputs in lieu of the original explanatory climate variables for individual 0 5 0 5 grid encompassing the conus the parameters of the model have been estimated for two distinct scenarios one with no lag and another with lag signals the grid wise evaluation of the model across the conus shows different performance levels fig 5 however the inclusion of lag signals has clearly enhanced the model performance in addition the spatial patterns of the performance indicators i e r2 and rmse suggest potential usage of the model for land water storage monitoring indeed acceptable performances i e r2 0 5 were noted for approximatively 41 2 of the conus for the corresponding grids one can assume that the temporal change of land water storage is explained by climate variables fluctuations the predictive capacity of the model was tested for all the conus grids using the time slices 2002 2014 and 2015 2017 for calibration and validation respectively the model performance at validation sustained its potential use as a predictive tool however the use of long data period for model calibration is desirable as it reduces statistical uncertainties in the simulations lee et al 2019 hence the model could be recommended for parts of the conus shown in fig 5b by the green areas with r2 0 50 as an example fig 7 illustrate a comparison of the model simulations to grace s lwe at a random location i e latitude 36 25 longitude 82 25 with high model performance r2 0 65 for such a location the multivariate regression on pcs with an inclusion of lag signals can valuably complement grace s lwe measurements thus the model could be used to provide estimates of land water storage anomalies for months with no satellite records of earth gravity field change e g periods preceding grace satellite mission likewise the model could serve to fill gaps within the satellite records time periods overall the study shows that the joint inclusion of pre wet tmp pet along with their related marginal lag effects could help achieve acceptable estimates of grace like land water storage anomalies the multivariate regression on pcs with lag signals show an uneven predictive power across the conus this result corroborates with previous studies focus on grace like data retrieval which also highlighted the variability of data driven analytical models performance across study regions li et al 2020 yin et al 2019 yang et al 2018 in general computational models imbed three categories of uncertainties including physical modeling and statistical lee et al 2019 harmel et al 2010 the physical uncertainties are associated to measurements while the modeling uncertainties are intrinsic to the model itself and the statistical ones are inherent to the lack of data lee et al 2019 these uncertainties are undeniably represented in this study and could somewhat explain the spatial variability of the model performance across the conus for instance landerer and swenson 2012 assessed the accuracy of gridded grace estimates of terrestrial water storage and reported spatial variations in the accuracy of grace measurements likewise the spatial accuracy of the climate inputs is arguable since the gridded cru datasets are generated using noaa stations which are unevenly distributed across the conus sohoulande et al 2019 harris et al 2014 in this context the model performance is likely to vary from grid to grid confirming the tendency in fig 5 besides the bias associated to the input data and the modeling procedure the noted spatial variability of the model performance could also be explained by the geophysical ecological or anthropological configurations of the study region for instance sadeghi et al 2020 reported that grace based retrieval of surface soil wetness is more effective in the wet region of the conus compared to arid regions this contrast seems to be true in the present case study fig 5b as the retrieval of grace like lwe appeared less effective in the arid region southwest conus compared to the wet region east coastal and northwest conus regardless this uneven spatial distribution of the model s predictive power a value of the model could be its potential use for predicting with a month in advance the land water storage anomalies such predictions of land water storage variations can be useful to plan the enhancement of water resources allocation and management 5 conclusion the study provides insight into the spatial patterns of land water storage anomalies across the conus using 15 years grace satellite mission data a multivariate regression on pcs model has been employed to evaluate the predictability of monthly land water storage anomalies based on climate variables inclusion of lag signals in the model has enhanced its performance and offers an option for predicting land water storage variations based on climate information even though the model performed unequally across the conus the outcomes are consistent and lead to the following conclusions i lag signals of climate variables such as monthly precipitation number of wet days air temperature and evapotranspiration explain more than 50 of the variance i e r2 0 5 of land water storage changes for at least 41 of the conus territory ii when climate data are available the multivariate regression on pcs with lag signals inclusion can complement satellite measurements of earth gravity field variations by providing estimates of land water storage anomalies for months outside the satellite mission periods overall the outcomes corroborate previous studies which related temporal changes in local water balance with the fluctuation of climate variables such as precipitation temperature and evapotranspiration crow et al 2017 wang et al 2012 milly 1994 for certain locations the low model performance illustrates the limitation of relying only on climate variables and a single model to predict land water storage change in view of this drawback and the limitations noted in previous studies focused on grace like lwe anomalies reconstruction li et al 2020 yin et al 2019 humphrey et al 2017 additional research is needed to achieve a spatially uniform model performance perhaps future studies could capitalize all the scientific contributions by investigating a multi model approach including anthropogenic geologic pedologic topographic and ecological variables in addition to the climate ones disclaimer mention of trade names or commercial products in this article is solely for the purpose of providing specific information and does not imply recommendation or endorsement by the u s department of agriculture credit authorship contribution statement clement d d sohoulande conceptualization methodology data curation formal analysis writing original draft writing review editing jerry martin data curation writing review editing ariel szogi supervision writing review editing kenneth stone supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
5313,cap and trade policy is generally considered an effective instrument in groundwater markets since it can facilitate environmental protection and sustainable groundwater use while this policy is implemented in several aquifers all over the world there is a limited understanding of its social impacts like how compliance and noncompliance behaviors may emerge this study presents an agent based groundwater model to evaluate the effects of monitoring and enforcement levels on farmers social behaviors namely boldness and vengefulness the social economic and hydrologic impacts of implementing the cap and trade policy in the rafsanjan plain located in iran are assessed to this end the groundwater market model is evaluated under different monitoring and enforcement scenarios results show that the efficacy of the cap and trade policy in groundwater markets substantially depends on the monitoring level and enforcement power the appropriate monitoring and enforcement settings can lead to the emergence of a social norm that is enough to discourage violation and can bring about a functioning market in which the farmers can be better off economically and the annual drawdown can become less severe furthermore water buyback programs can increase market competition compliance level and farmers profits this study specifically demonstrates that as a result of the implementation of the cap and trade policy social norms emerge that affect the whole system from farmer agents to the efficacy of the policy while this study concentrated on the application of the cap and trade policy in groundwater management the results can provide a foundation for specifying frameworks of the cap and trade policy for managing other limited resources or greenhouse gasses emission keywords groundwater market cap and trade policy agent based modeling social norms collective action socio hydrology 1 introduction water markets are generally considered efficacious methods capable of increasing users profit bekchanov et al 2015 du et al 2017 environmental protection ancev 2015 iftekhar et al 2013 and social welfare ghosh et al 2014 during drought periods to assess these impacts of water markets some studies have scrutinized the economic alarcón and juana 2016 bekchanov et al 2015 du et al 2017 socio economic hadjigeorgalis and lillywhite 2004 solís and zhu 2015 hydro economic aghaie et al 2020 kahil et al 2015 khan and brown 2019 smajgl et al 2009 and socio hydrologic alamdarlo et al 2019 effects of water markets other studies have evaluated the impacts of governments water buyback programs in order to meet environmental requirements ancev 2015 marchiori et al 2012 tisdell 2010 some of the conducted studies assessed the impacts of the cap and trade policy on surface water and groundwater resources which is widely considered as one of the putative solutions for sustainable use of limited resources edwards and null 2019 gonzales and ajami 2019 gonzales et al 2017 grafton and wheeler 2018 khan and brown 2019 smajgl et al 2009 thompson et al 2009 the main idea of this policy is to put a restriction on the extraction of limited resources or pollutants emission and facilitate the trades of permits this policy may effectively be used to meet the environmental demands and give the users an incentive to trade their permits from low value uses to high value uses thompson et al 2009 notwithstanding the theoretical success of water markets some researchers claim that water markets do not live up to the expectations in the real world hadjigeorgalis 2008 there are several operating water markets in australia the success and failure of which were analyzed in previous studies crase et al 2004 one of the most salient factors affecting the water market performance is users compliance with the market regulations the users tend to violate the law and refuse to cooperate when it comes to permit caps or limiting regulations the lack of enforcement power and monitoring level are generally considered as the main rationale behind these violations recent studies have widely recognized that monitoring and enforcement power play a crucial role in the effectiveness of the cap and trade policy for water markets grafton and wheeler 2018 marchiori et al 2012 wheeler et al 2017 and greenhouse gases emission stoerk et al 2019 stranlund et al 2002 agricultural water demand is one of the main water users all over the world so water markets can play a significant role in agriculture and irrigation of farms du et al 2017 many studies have asserted that these farms are integrated social ecological systems where farmers can bring about social and environmental changes for instance farmers myopic water usage can reduce soil fertility intensify soil erosion and decrease biodiversity their farms are homes to a variety of flora and fauna and can be considered as recreational sites providing people with natural places to enjoy mcguire et al 2015 an environmental change in such social ecological systems can influence farmers behaviors beliefs and attitudes and the change in their behaviors affects the environment through feedback loops meyfroidt 2013 verburg et al 2015 these continuous feedback loops can bring about behavioral changes and social norms through time which affects decision making processes of farmers burton 2004 and their self concepts seabrook and higgins 1988 sustainable water management policies and regulations may take several decades to be fully implemented without any guarantees that water users will comply when it comes to these sustainable development policies water users can benefit from collective actions which are considerably affected by social norms castilla rho et al 2017 smajgl et al 2009 the most common meanings of social norms stem from society s values behaviors and expectations which give rise to socially important events based on the behavioral definition of social norms a specific norm exists in a community if its members behave in a certain way and punish the individuals who do not act accordingly hence whether an action is a norm can be discerned from the number of its execution and the number of punishment exerted on non followers axelrod 1986 castilla rho et al 2017 farmers participating in a water market have many different choices and desires including how much to bid how much to irrigate whether to comply etc many socio economic factors can affect farmers decision to participate in water markets such as water quality and age of their gardens jaghdani and brümmer 2016 they may change their perspectives in view of complex interactions and feedbacks in the whole system for instance farmers may affect their neighbors decisions when it comes to selling their water permits haensch et al 2019 such systems which comprise autonomous interacting and adaptive agents are known as complex adaptive systems macal and north 2010 many researchers have asserted that one of the most useful techniques for analyzing and evaluating complex adaptive systems is agent based modeling abm abm can take into account heterogeneity of a complex adaptive system acquire the overall result of the system known as emergence and facilitate the comprehension of complex real world phenomena by using a bottom up approach and considering the hierarchical interactions between all of the elements of the system bonabeau 2002 macal and north 2010 tesfatsion 2003 wilensky and rand 2015 while there are numerous studies on water markets using centralized top down approaches alarcón and juana 2016 dinar and letey 1991 erfani et al 2014 he and horbulyk 2010 manjunatha et al 2011 solís and zhu 2015 tisdell 2001 vaux and howitt 1984 zekri and easter 2005 it has been asserted that bottom up approaches such as abm are needed to take into account the complex nature of water markets and individual level heterogeneity du et al 2017 in recent years several studies have evaluated water market performance as a complex adaptive system under different institutional and hydrological conditions using abm du et al 2017 gonzales and ajami 2019 iftekhar et al 2013 smajgl et al 2009 however most of the previous studies have not had a deep appreciation of how users compliance collective actions and social norms may emerge in the water markets du et al 2017 in particular evaluated the joint impacts of farmers behavioral parameters on the performance of a hypothetical water market where farmer agents had no abilities to violate their water permit by extracting water more than what is allowed there are some studies however like castilla rho et al 2017 to consider the farmers social behavior for violation in the context of water management nevertheless the main assumption of such studies about farmers violation was that farmers have perfect information about their environment where they simply imitate their social behaviors from their neighbors this study presents an agent based groundwater market model to investigate the conditions on which collective action and farmers compliance may emerge when the cap and trade policy is adopted as a means to mitigate water shortage problems we consider the possibility of violation in farmers water extraction mathematically by quantifying farmer s social behaviors namely boldness and vengefulness and use these behaviors to understand how social norms may emerge when implementing the cap and trade policy furthermore we consider that the farmers do not have perfect information and update their behavioral parameters vengefulness and boldness based on the available information using two different mathematical approaches presented in this study to this end this study simulates a groundwater market using agent based modeling addressing interactions between social institutional economic and groundwater subsystems the market institution presented in this study caps farmers groundwater permits to ensure sustainable groundwater abstraction facilitates trading of permits between farmers and provides the government with the opportunity to buy water back from farmers in the following section 2 presents the case study and its water management problems section 3 entails the methodology that is composed of four modules addressing the agents behavioral parameters agents decision making processes the market institution and finally section 4 discusses and analyzes the results 2 implementing groundwater market of rafsanjan the daranjir saghand basin is located in an arid region in the central part of iran fig 1 a b rafsanjan plain with an area of 16096 km2 constitutes a main part of the basin and entails more than 60 000 ha of farmlands fig 1c ninety seven percent of total agricultural land use are pistachio orchards and the primary water demand of the region for domestic industrial and agricultural purposes is supplied by groundwater resources there are more than 1424 agricultural domestic and industrial wells which supply almost 99 percent of the region s water demand fig 1d fig 1e illustrates the location of piezometers as well as boundary conditions of the rafsanjan aquifer with an area approximately equal to 4100 km2 parsapour moghaddam et al 2015 rahnama and zamzam 2013 due to an unremitting over extraction of groundwater in the past decades 200 million cubic meters more than aquifer s safe yield the aquifer s overall water table is significantly declined not only is the aquifer drawdown intensifying but also the water salinity and land subsidence are rising rahnama and zamzam 2013 the local authorities are going to come up with effective measures in order to cease the deleterious consequences of over abstraction two of which are water transfer project and the cap and trade policy karamouz et al 2011 motagh et al 2017 however there is uncertainty in this regard as to what policy should be implemented and whether it can be effective we argue that the implementation of a groundwater market based on the cap and trade policy may help control the undesired situation as there are no formal water markets in the region and thus farmers entitlements are defined traditionally it is of importance to analyze such policy implementation which includes capping on entitlements and prepare a basis to analyze consequences such as dissatisfaction and violation 3 methodology the proposed agent based modeling approach integrates social institutional economic and groundwater modules in an interactive structure fig 2 the social module simulates farmers behavior focusing on their violations of groundwater pumping the institutional module introduces the market institution regulating the performance of the proposed water market the groundwater module is a groundwater flow simulation model that simulates the hydrological process in the aquifer to estimate the changes in groundwater level the economic module is similar to a hydro economic model that presents computational routines for calculation of all economic variables such as bid amounts bid prices pumping costs crop yields social welfare etc as illustrated the market institution is in the heart of the system interacting with the other three modules through specified nexuses fig 2 the behavior of the modules and their interactions with each other and the market institution is addressed with an agent based model the agents consist of a market moderator i e government trying to buy water back from the farmers for environmental protection and 200 farmer agents each of which has unique behavioral parameters the farmer agents behavioral parameters consist of their violation behaviors described in the social module and their bidding behaviors and irrigating strategies which are explained in the economic module the market moderator s behavior is addressed by its bidding behavior explained in the economic module the general framework of the agent based model is presented in fig 3 as illustrated in fig 3 the market institution caps farmers entitlements based on the regional groundwater tables monitors farmers groundwater pumping and imposes fine on violators the groundwater table fluctuates with farmers groundwater withdrawal and the government s water buyback accounting for these interactions the social and economic modules determine the groundwater pumping rates which determines groundwater level in the aquifer the modules shown in fig 2 are coded in netlogo which is an interactive and popular programmable modeling environment for developing agent based and system dynamic models wilensky and rand 2015 the netlogo platform benefits from some facilitating packages and extensions including gis extension for loading gis layers matrix extension for performing matrix operations behavior search extension for optimization and searching a specific systemic behavior by heuristic algorithms and behavior space for parameter sweeping and inspecting its impacts on the system in the following sections detailed explanations about the aforementioned modules are proposed 3 1 social module it has been widely established that when the water authorities enact a new rule in line with sustainable development policies e g the cap and trade policy the water users may have a propensity for violating the new rule castilla rho et al 2019 here in the water market context every member of the farmers society can decide not to follow the rules and extract water more than what is allowed i e their water permit grafton and wheeler 2018 marchiori et al 2012 to assess farmers social behaviors and evaluate their possible violations two social behavioral parameters namely boldness and vengefulness are assigned to each farmer agent the boldness is the farmers proclivity for extracting water more than what is allowed and the vengefulness is their tendency towards reporting breaching neighbors in fact when the market institution caps entitlements two social behaviors emerge first farmers may want to pump groundwater more than their new water permits which are addressed by their boldness second farmers may report the violators to the market institution based on their vengefulness the combination of these two behaviors forms social norms in the farmer society these social norms can be called emergence which is defined as a structure behavior or property appearing in the system level owing to manifold and hierarchical interactions and feedbacks between agent agent and agent environment macal and north 2010 sawyer and sawyer 2005 the most prominent characteristic of emergence is downward causation the downward causation concept simply states that the emergent phenomenon which is emerged because of lower level interactions interacts with the lower level elements and restricts them corning 2002 therefore we expect that an emerged social norm as a result of permit caps to restrict its lower level elements giving rise to the emerged social norm i e farmers behaviors such as boldness and vengefulness based on the behavioral definition of the social norm the norm strength emerged in the farmer society as a result of permit caps can mathematically be expressed as castilla rho et al 2017 1 ns t i v i t b i t n where v i t represents an agent s vengefulness and b i t stands for the agent s boldness eqs 2 and 3 n is the number of farmers and ns t is the emerged norm strength in time step t it is worth noting that ns t varies in the range 1 1 if most of the farmer agents comply with the market regulations i e v t 1 b t 0 and ns t 1 collective action may be deduced and strong social norm emerges on the other hand if the social norm strength approaches 1 it can be concluded that a norm of non compliance emerges the emerged social norm has an impact on the farmer agents social behaviors vengefulness v and boldness b based on the downward causation concept as a result the vengefulness of i th farmer agent toward its j th neighbor at t th time step i e probability of reporting the j th neighbor to the market institution is analytically expressed by 2 v i j t 1 y i t y j t ns t 1 2 where y i t kg ha 1 is average crop yield of agents working in the i th agent s neighborhood y j t kg ha 1 represents the crop yield of the neighbor i e the j th farmer agent accordingly the representative vengefulness for each agent v i t which is utilized in the definition of norm strength in eq 1 is considered to be the maximum of the agent s vengefulness probability towards all of the neighbors similar to vengefulness boldness associated with i th farmer agent at t th time step i e probability of exceeding its water permit is mathematically defined as 3 b i t 1 wp i t wp i 0 1 fm t mp t 100 ns t 1 2 where wp i 0 cubic meter yr and wp i t cubic meter yr respectively represent the farmer s water permit before and after implementation of the cap and trade policy mp t denotes percent of well s that are monitored at t th time and fm t 0 1 is a dimensionless variable standing for fine magnitude in fact the farmer would breach with the probability of b i t and up to volume w p i 0 wp i t farmers social interactions according to these two behavioral parameters b i t v i j t are depicted in fig 4 accordingly the violation breached volume of water cubic meter yr is estimated by 4 br i t w p i 0 wp i t 1 fm t mp t 100 1 b i t 3 2 market institution the market institution plays a crucial role in the function of the water market the market institution caps farmers water permits based on the regional groundwater tables on a yearly basis it also receives farmer agents reports and based on the reports and well meters finds and fines the violators the agents bid amounts and bid prices are also sent to the institution and it performs the matching process in order to discover water prices and transfer water permits from sellers to buyers for the price discovery in the water market this market institution uses double auction which is widely considered to be an effective structure for water markets double auctions can be operated either as a centralized market or a decentralized market in the centralized market uniform price double auction a uniform price is determined by a central market institution and all goods will be transacted at the specified price on the other hand in the decentralized market discriminatory price double auction there is no obligations for specifying a specific price prices can be different per transaction and the prices are determined by the participants bids du et al 2017 gonzales and ajami 2019 smajgl et al 2009 this study simulates an agent based groundwater market using a discriminatory price double auction the procedures of the discriminatory price double auction used in this study are explained as follows at the beginning of each year possible buyers and sellers send their bid prices and bid amounts to the market institution the market institution sorts the bids according to their proposed prices buyers sellers bid prices are sorted in descending ascending order as long as the first buyer s bid price who is in the priority in the first line is greater than or equal to the first seller s offer price who is in the first sellers priority the transaction is performed if the bid amount of the first buyer seller is fully transacted the first buyer seller leaves the market and the second buyer seller in the list moves to the priority this process will continue until the total supply becomes exhausted or the total demand is satisfied or no buyer has the bid price higher than the sellers offers 3 3 economic module this section explains farmers irrigation policy in section 3 3 1 farmers bidding behavior in section 3 3 2 governmental water buyback program in section 3 3 3 and farmers social welfare in section 3 3 4 3 3 1 irrigation policy there are many factors that affect a farmer s irrigation policy including sensitivity to soil water deficit region s climate precipitation water availability technological capabilities etc du et al 2017 van duinen et al 2016 the net irrigation requirement stress avoidance irrigation requirement for each farmer agent may be estimated as smajgl et al 2009 5 id i t rmw i t pcp i t 100 a i where rmw i t mm yr 1 represents recommended crop water requirement crop evapotranspiration pcp i t mm yr 1 stands for effective precipitation and a i ha is irrigated area each farmer may or may not wish to apply deficit irrigation as addressed by his irrigation strategy s t i t the heterogeneity in farmers irrigation policy is taken into account by assigning a behavioral parameter to farmer agents as he selects an irrigation strategy 6 ai i t id i t st i t where ai i t represents the farmer s actual irrigation requirement for given irrigation strategy defined by the selected value for st i t initially the irrigation strategy s t i t is assumed to be a random variable 0 1 with uniform distribution moreover i and t are indices representing a farmer agent and time period year in this study here st i t 1 indicates that for t th time step i th farmer select an irrigation strategy so that the crop experiences no water stress st i t 0 stands for the situation that the farmer opts for the rainfed agriculture and finally 0 st i t 1 represents different levels of deficit irrigations the irrigation strategy parameter is updated based upon the farmers net benefit given that the agents are goal based as they attempt to obtain the most profitable irrigation strategy by learning from their previous experiences regarding bounded rationality coined by arthur 1994 stating that humans information and rationality are limited we assume that farmer agents strive to attain the most profitable irrigation strategy using a simple algorithm based on their previous experiences as follows in the first two years of the simulation each farmer agent chooses a random irrigation strategy the farmers then choose the most economically profitable strategies between those two first choices and follow the trend until it reverses in other words as long as increasing decreasing the irrigation strategy brings about more profit they increase decrease it this process goes on until the end of the simulation the farmers obtain more information regarding strategies and their related profits in time so they can estimate more accurately a profitable strategy through time a pseudo code of the adaptation process for irrigation strategy s t is as follows for each farmer agent if time step 0 or time step 1 then set st randomly if time step 1 then select the agent s st associated with highest profit existed in memory stopt and its previous st stpr if stpr stopt then set st stpr rand between 0 0 1 set st stpr rand between 0 0 1 3 3 2 farmers bidding behavior farmers bidding behavior is the process in which they decide on water transactions determining their bid amounts and bid prices and the way they adapt this behavior du et al 2017 the farmers bidding behavior is comprised of two variables the first variable is the volume of water supply demand for a seller buyer agent and the second variable is the water price a farmer agent estimates its volume of water supply to demand from the market q i t cubic meter yr based on its volumes of water permit wp i t its breached amount br i t and its actual irrigation requirement for a given irrigation strategy ai i t as below 7 q i t max 0 ai i t wp i t br i t forbuyers wp i t ai i t br i t forsellers where br i t and ai i t are defined by eqs 4 and 5 the market institution caps farmers water permits in each year based on regional drawdowns in order to ensure sustainable groundwater abstraction so the water permit of each farmer wp i t may change on a yearly basis the water permit of each farmer wp i t cubic meter yr determines their maximum allowable level of withdrawing while bidding price depends on a variety of factors here we assume that the bidding prices are mainly affected by two factors of 1 farmer agent s rent seeking behavioral parameter μ i t tendency for gaining more profit and 2 farmer agent s reservation price η i t irr cubic meter maximum minimum price a buyer seller agent is willing to pay sell du et al 2017 therefore the bidding price irr cubic meter is calculated as follows 8 p i t 1 μ i t η i t for buyer 1 μ i t η i t for seller in order to eliminate complicated structures of agents memory based adaptation we employ zero intelligence plus algorithm based on which an agent adapts its rent seeking with respect to its success in the last transaction cliff and bruten 1997 9 μ i t 1 μ i t β i τ i t p i t η i t where τ i t is the reference trading price that the agent strives to move towards and is set to last transaction price if the agent succeeded in the transaction and is set to the average last market prices if the agent failed to transact furthermore β i 0 1 is a dimensionless behavioral parameter representing farmers learning rate which is considered as a uniformly distributed random variable additional equations regarding the procedures for deriving the reservation price can be obtained from the supporting information 3 3 3 governmental water buyback program the governments can either recruit a number of environmental agencies to procure water for the environmental flow requirements or take action into their own hands accordingly water protection objectives can be achieved through buyback programs ancev 2015 grafton and wheeler 2018 marchiori et al 2012 tisdell 2010 wheeler et al 2013 the buyback program implemented in this study aims to reduce the overall caps on water extractions in order to act as a compensation based approach and better off farmers as well as the environment assuming a cobb douglas utility function based on which the buyback program is implemented and considering a budget constraint the optimal government s bid amount can be estimated as hamill and gilbert 2015 10 w t optimal α bc t p t where bc t irr represents the budget constraint and p t irr cubic meter stands for the buyback related bid price which is estimated using eq 8 furthermore α 0 1 is a parameter denoting the protecting agent s i e the government tendency for acquiring water for the environment the greater the parameter s value is the more keen on water protection and buyback the government will be finally the protecting agent s rent seeking is updated based upon eq 9 the behavioral parameters of agents are shown in table 1 in the absence of reliable data all of the farmers behavioral parameters are initially assumed uniform distribution the initial rent seeking and the learning rate behavioral parameters of the government agent are assumed to be 0 5 and 0 6 respectively 3 3 4 farmers social welfare market participants attempt to increase their own welfares a farmer agent s individual welfare is estimated based on the difference between the transacted price τ i t and the agent s reservation price η i t the individual social welfare is known as producer surplus i e seller s welfare or consumer surplus i e buyer s welfare the total producers and consumers surpluses associated with t th time step are calculated as 11 ps t i q i t τ i t η i t 12 cs t i q i t η i t τ i t where q i t and q i t cubic meter yr are i th agent sold and bought water permit eventually the social welfare of all the market participants can be estimated by summing up the overall producers and consumers surpluses xu et al 2018 3 4 groundwater module the groundwater abm in this study is the finite difference groundwater modeling part of the flowlogo interface which is developed by castilla rhoet al 2015 in netlogo the flowlogo is a modeling environment which conspicuously facilitates the development of coupled agent based groundwater models the flowlogo modeling environment is capable of modeling different boundary conditions no flow fixed head and constant flux and a variety of sources and sinks pumping and injection wells springs streams and accordingly it can simulate transient and steady state 2d groundwater flow in confined and unconfined aquifers castilla rho et al 2015 3 5 calibration and validation because no water market is implemented in the case study area and no formal information of probable trades is available we calibrated the groundwater module under the status quo condition where no water market is in operation the calibration is performed in two distinct steps steady state and transient groundwater flow simulation the steady state step is as follows by analyzing the piezometers data and their hydrographs we observed that in spring 2002 the piezometers had roughly had constant values hence we assumed that underground recharge was in balance with pumping well discharge in this period this means that the discharge and recharge were approximately equal so the only unknown parameter is hydraulic conductivity to be estimated by calibration we performed the steady state step of calibration by minimizing the differences in the observed and calculated heads in 42 piezometers we used the behavior search package for this optimization which is a software tool including heuristic algorithms for optimization therefore the hydraulic conductivity coefficients are obtained with an rmse approximately equal to 2 8 m shown in fig 5 after assigning the hydraulic conductivity coefficients to the aquifer we proceeded with the transient model simulation in order to obtain the second unknown parameter i e specific yield over an 11 year time period 2002 2012 using behavior search the genetic algorithm which is one of the heuristic algorithms in behavior search is used to minimize the difference between observed data and simulated heads over the time period of 2002 2012 after large numbers of generations one of the best coincidence occurred between simulated and observed values with an rmse roughly equal to 7 m after the calibration of the groundwater module we verified the groundwater module for five remaining years i e 2012 2017 validation of agent based modeling approaches may be carried out using two ways of structural and outcome validations while the structural validation is essentially pertinent to the consistency between the model structure and the experts opinion and theoretical mechanisms the outcome validation makes a comparison between the calculated results and empirical data du et al 2017 gonzales and ajami 2019 in the light of non existence of any market institutions in the rasanjan plain and the aims of this study to understand how farmers social behaviors may emerge the focus of this study is only on the structural validation in the future after implementing a real water market institution in rafsanjan plain it is possible to perform outcome validation using the model s results and obtained data 4 results and discussion the results of this study are presented in three sections the first section is a sensitivity analysis which analyzes all of the possible scenarios regarding monitoring and enforcement settings and tries to find a setting that is most beneficial socially environmentally and economically the second section uses the first section to design five scenarios in order to assess the cap and trade policy finally the last section analyzes the social economic and hydrologic impacts of the designed scenarios 4 1 sensitivity analysis results in this section the market is evaluated without any buyback programs to assess the effects of implementing a water market between farmer agents the agent based market model was run in the period of 2002 2017 years to assess hydrologic economic and particularly social impacts of the cap and trade policy under different monitoring and enforcement settings we seek a condition or conditions where the monitoring and enforcement level are enough to simultaneously discourage violation reduce aquifer s drawdown benefit farmers economically and more importantly bring about a functioning water market these conditions seem to happen at neutral social norms as shown in fig 6 a by a dashed line when the monitoring and enforcement settings are at levels that neutral social norms emerge fig 6a the economic fig 6b g and hydrologic fig 6h impacts of the cap and trade policy are acceptable and a functioning market will emerge these social norms can be called emergence which is defined as a structure behavior or property appearing in the system level that did not exist before macal and north 2010 sawyer and sawyer 2005 that is before implementing the cap and trade policy farmer agents neither had any propensity for violating their water permits due to permit caps nor had any tendency to report violators considering market competition in terms of number of participants in the market and volume of traded water fig 6b and c illustrate that the neutral social norm conditions dashed lines can be strong enough to bring about a functioning water market with a competition as high as the most severe enforcement and monitoring levels i e monitoring percent 100 and fine magnitude 1 the dashed lines shown in fig 6a can be considered the social leverage points where the system can potentially be shifted from one regime to another with little change in the inputs in this case monitoring percent and fine magnitude it can be seen that in these leverage points social norms are shifted abruptly from negative values regime of noncompliance to positive norms emergence of compliance these leverage points can be crucial for emergence of a functioning water market as approximately all of the market features change abruptly with little change in the inputs fig 6b h farmers are better off in these leverage points since they experience high social welfare fig 6e crop yields with little stress fig 6f and a high net benefit fig 6g besides in fig 6h it is obvious that the leverage points make the hydrological performance of the cap and trade better than most of the other possible scenarios considering the amount of budgets needed for monitoring the wells the amount of fines imposed on violators and their trade offs all in all the sensitivity analysis shows that as a result of implementing the cap and trade policy for groundwater resources and farmers reactions to this policy social norms emerge in the farmer society depending highly on its setting i e monitoring level and enforcement power the emerged social norms can affect the efficiency of the water market as any change in social norms results in a change in other features of the market in particular when the norms are at the leverage points 4 2 scenario definition as presented in the previous section there are numerous scenarios based on monitoring level and enforcement power in this study five main scenarios are presented in order to evaluate the cap and trade policy table 2 presents how the scenarios are defined the first scenario abbreviated by nwm represents the status quo where no water market is implemented the second scenario shortened to sme and the third scenario abbreviated by wme successively denote conditions in which the monitoring level and enforcement power are at their highest and lowest possible levels respectively the fourth scenario named dme represents a middle condition regarding the monitoring level mp t and enforcement power fm t where the fm t is equal to 0 1 and mp 0 is initially equal to 40 percent which means that 40 of farmer wells are monitored in time step zero and detected violators from these 40 monitored wells will be fined an amount equal to 0 1 of their net benefit considering the technical problems of wells monitoring and their recovery data the mp t changes over time the market institution assigns a yearly budget to equip 10 of unequipped wells with meters but after every three years 15 of total meters fail to work based on the available data the fifth scenario called dmebp has an extra buyback program in addition to conditions of the dme scenario and the government s budget is set to minimize the hydrological differences between dme and dmebp in order to compare their economic and social results 4 3 scenario based results in this section the time series results of the five described scenarios are presented and discussed it is worth mentioning that the cap and trade policy is an instrument that is recommended in order to alleviate drought conditions and manage water shortage problems as expected fig 7 a suggests that the emerged social norms approach their maximum and minimum amounts under sme and wme scenarios respectively notwithstanding the first rise in the social norm in the dme scenario it starts declining because of malfunction of 15 percent of wells meters monitoring percent in time step 4 every three years 15 percent of wells meters fail to work assuming that the market institution assigns a budget to add well meters to 10 of all of the unequipped wells on a yearly basis this action cannot stop social norms decline and finally a rather weak norm emerges in dme scenario however a stronger social norm emerges in the dmebp scenario which just has a buyback program in addition to dme considering the same conditions in dme and dmebp scenarios fig 7a indicates that buyback programs can facilitate the emergence of strong social norms since they put a less severe restriction on farmers water permits to act as a compensation based approach for farmers economic situation fig 7e according to the emerged social norms the farmers breaches are at their highest and lowest levels in wme and sme scenarios besides the positive effect of the governmental buyback program can be seen in fig 7b in comparison with dme scenario as the farmers breaches are reduced roughly by 50 percent in dmebp scenario following previous studies highlighting the need for providing incentives for water users compliance with the regulations castilla rho et al 2017 grafton and wheeler 2018 this study introduces the water buyback program as an impetus for water users compliance in that it can bring about a stronger social norm as expected fig 7c illustrates that for all of the scenarios the water market effectively contributes to lessening the severity of groundwater drawdown in comparison with the status quo scenario nwm in particular the sme and wme scenarios have respectively shown the best and the worst hydrologic performance between the four market scenarios each of which in turn causes 47 cm and 60 cm annual drawdown it is also perceptible that owing to the water transactions the weak monitoring and enforcement scenario wme has a better hydrologic performance than the status quo scenario nwm which engenders a yearly water table drawdown of 80 cm it is worth mentioning that the differences in hydrological performances of dme and dmebp scenarios are minimized by optimizing the government s budget in order to compare their social and economic performances and analyze the governmental buyback program fig 7d shows the farmers net benefit time series under different monitoring and enforcement scenarios as expected in the sme scenario the net benefits are reduced in comparison with the nwm scenario because the farmers water permit are capped and they cannot violate to increase their profits owing to the severity of fines in the sme scenario farmers violate at the first time step but the severity of fines make them comply afterwards where a strong social norm emerges in wme scenario farmers violate and increase their net benefits so they eventually can reach a net benefit even more than the nwm scenario the economically positive impact of the buyback program can be seen in fig 7d where the net benefits of farmers are roughly 25 percent more than the dme scenario despite the similar hydrologic performance of dme and dmebp scenarios this result suggests that the buyback program can negate the economic losses experienced by farmers owing to the permit caps which is in line with the previous studies grafton and wheeler 2018 fig 7e and f show the water permits and the average flow rates of withdrawal by the farmers as expected the wme scenario has the most reduction in water permits through time because the water table decreased more quickly and this makes the caps more severe therefore the emergence of strong norms can lead to a reduction in caps on water permits through time and this is an extra benefit for water users who may take it for granted furthermore while the overall water permits under the dmebp scenario are more than the dme scenario the overall flow rates are roughly equal this can either mean that farmer agents in dmebp scenario choose to participate in the market by selling their water permits to the government or the farmers in dme scenario pump groundwater more than their groundwater permits considering the two driest years of the simulation the 9th and 15th years it can be perceived that almost always drought causes a reduction in values of the norm strength fig 7a with an exception for scenarios with strong emerged social norms i e sme and dmebp scenarios the farmers breached amounts of water have significantly increased during these dry years fig 7b therefore encouraging farmers to comply with the market regulations such as giving the fines imposed on violators to the reporting farmers or increasing water permits of farmers reported violators correctly can bring about a social norm that is enough to discourage violation even in the driest years fig 8 a b shows that the emergence of strong norms can bring about a functioning market where most of the farmers participate in the water market accordingly the dmebp scenario is the most competitive market scenario in which the volume of water traded and the number of market participants are more than other scenarios on the other hand the wme scenario can retard the emergence of a functioning market and can reduce market functionality in time as both the number of market participants and traded volume are diminishing through time the emerged norm in dme scenario is not weak enough to cease a functioning market fig 7a which makes this market function rather weaker than the sme scenario the number of market participants in dme approaches the participants in sme fig 8a and the difference in volume of traded water is negligible fig 8b as fig 8c illustrates without any buyback programs when the norm of compliance emerges farmers put a higher value on water and vice versa this occurs because of supply and demand interactions in other words when monitoring and enforcement are high i e under the sme scenario there is no rationale behind violation all farmers comply with their water permits therefore the market supply shrinks and market demand increases and this is the main reason for higher bid prices on the other hand regarding the wme scenario the norm of non compliance emerges because the farmers aim to increase their benefits by violations therefore market supply increases and market demand decreases and this will cause a reduction in water prices similarly in the buyback scenario market supply increases and market demand decreases as the caps put on farmers water permits are less severe fig 7e therefore the water prices in dmebp scenario are fewer than water prices in dme scenario finally fig 8d shows the social welfare in different scenarios it indicates that the sme and wme scenarios bring about the most and the least social welfare for farmer agents with this in mind it can be seen that the difference between social welfare in dme and sme scenarios are negligible so the dme scenario is a scenario that can engender a satisfactory degree of social welfare for the farmer agents however the dmebp scenario has a social welfare level lower than sme and dme scenarios this is because although the volume of traded water in dmebp is more than dme and sme fig 8b the water prices in dmebp scenario are fewer than dme and sme scenarios fig 8c 5 conclusion in the face of water scarcity it is of paramount importance to effectively analyze and implement policies that may lead to sustainable groundwater use and collective action therefore this study evaluates the efficacy of one demand side management technique that is the cap and trade policy in the case study area of rafsanjan plain four main scenarios are analyzed the two first scenarios are wme and sme which are the extreme scenarios with weak and strong monitoring and enforcement power the lowest and highest monitoring and fines for violators the dme and dmebp scenarios are assessed to determine the applicability of the policy the dme scenario is a market scenario with dynamic monitoring levels and a rational enforcement power and the dmebp scenario is the dme scenario as well as a buyback program for environmental protection the results indicate that dme scenario can reduce the aquifers annual drawdown from 80 cm status quo to 53 cm furthermore the water buyback program dmebp reduces the farmers breaches by 50 percent in comparison with the market without any buyback programs dme moreover the buyback program increases the total farmers net benefit by 25 percent and imposes an annual cost on government which is equal to 1 5 1012 irr therefore water buyback programs can increase the market competition level and farmers profits and it can decrease farmers violations according to the results of the study the monitoring level and enforcement power have a substantial impact on farmers compliance in the cap and trade policy and the emerged social norms can significantly affect the market performance the results show that as a result of implementing the cap and trade policy social norms emerge which affect markets performances if the emerged social norm is a strong one the market will function in a way that most individuals will participate and more water will be traded and vice versa thus this study shows that the market competition level has a direct relationship with the emerging norm therefore groundwater permits can be effectively transferred from low value uses to high value uses by providing a condition on which strong social norms emerge regarding the limitations of this study it is worth mentioning that this study does not take into account spatial distribution of socio hydrologic and economic impacts of the cap and trade policy spatially heterogeneous impacts of groundwater markets are important as the groundwater flow is affected by topography therefore for future studies the spatial effects of groundwater markets based on the cap and trade policy can be explored credit authorship contribution statement vahid aghaie conceptualization methodology software validation writing original draft hosein alizadeh conceptualization methodology validation writing review editing supervision abbas afshar conceptualization methodology validation writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125057 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5313,cap and trade policy is generally considered an effective instrument in groundwater markets since it can facilitate environmental protection and sustainable groundwater use while this policy is implemented in several aquifers all over the world there is a limited understanding of its social impacts like how compliance and noncompliance behaviors may emerge this study presents an agent based groundwater model to evaluate the effects of monitoring and enforcement levels on farmers social behaviors namely boldness and vengefulness the social economic and hydrologic impacts of implementing the cap and trade policy in the rafsanjan plain located in iran are assessed to this end the groundwater market model is evaluated under different monitoring and enforcement scenarios results show that the efficacy of the cap and trade policy in groundwater markets substantially depends on the monitoring level and enforcement power the appropriate monitoring and enforcement settings can lead to the emergence of a social norm that is enough to discourage violation and can bring about a functioning market in which the farmers can be better off economically and the annual drawdown can become less severe furthermore water buyback programs can increase market competition compliance level and farmers profits this study specifically demonstrates that as a result of the implementation of the cap and trade policy social norms emerge that affect the whole system from farmer agents to the efficacy of the policy while this study concentrated on the application of the cap and trade policy in groundwater management the results can provide a foundation for specifying frameworks of the cap and trade policy for managing other limited resources or greenhouse gasses emission keywords groundwater market cap and trade policy agent based modeling social norms collective action socio hydrology 1 introduction water markets are generally considered efficacious methods capable of increasing users profit bekchanov et al 2015 du et al 2017 environmental protection ancev 2015 iftekhar et al 2013 and social welfare ghosh et al 2014 during drought periods to assess these impacts of water markets some studies have scrutinized the economic alarcón and juana 2016 bekchanov et al 2015 du et al 2017 socio economic hadjigeorgalis and lillywhite 2004 solís and zhu 2015 hydro economic aghaie et al 2020 kahil et al 2015 khan and brown 2019 smajgl et al 2009 and socio hydrologic alamdarlo et al 2019 effects of water markets other studies have evaluated the impacts of governments water buyback programs in order to meet environmental requirements ancev 2015 marchiori et al 2012 tisdell 2010 some of the conducted studies assessed the impacts of the cap and trade policy on surface water and groundwater resources which is widely considered as one of the putative solutions for sustainable use of limited resources edwards and null 2019 gonzales and ajami 2019 gonzales et al 2017 grafton and wheeler 2018 khan and brown 2019 smajgl et al 2009 thompson et al 2009 the main idea of this policy is to put a restriction on the extraction of limited resources or pollutants emission and facilitate the trades of permits this policy may effectively be used to meet the environmental demands and give the users an incentive to trade their permits from low value uses to high value uses thompson et al 2009 notwithstanding the theoretical success of water markets some researchers claim that water markets do not live up to the expectations in the real world hadjigeorgalis 2008 there are several operating water markets in australia the success and failure of which were analyzed in previous studies crase et al 2004 one of the most salient factors affecting the water market performance is users compliance with the market regulations the users tend to violate the law and refuse to cooperate when it comes to permit caps or limiting regulations the lack of enforcement power and monitoring level are generally considered as the main rationale behind these violations recent studies have widely recognized that monitoring and enforcement power play a crucial role in the effectiveness of the cap and trade policy for water markets grafton and wheeler 2018 marchiori et al 2012 wheeler et al 2017 and greenhouse gases emission stoerk et al 2019 stranlund et al 2002 agricultural water demand is one of the main water users all over the world so water markets can play a significant role in agriculture and irrigation of farms du et al 2017 many studies have asserted that these farms are integrated social ecological systems where farmers can bring about social and environmental changes for instance farmers myopic water usage can reduce soil fertility intensify soil erosion and decrease biodiversity their farms are homes to a variety of flora and fauna and can be considered as recreational sites providing people with natural places to enjoy mcguire et al 2015 an environmental change in such social ecological systems can influence farmers behaviors beliefs and attitudes and the change in their behaviors affects the environment through feedback loops meyfroidt 2013 verburg et al 2015 these continuous feedback loops can bring about behavioral changes and social norms through time which affects decision making processes of farmers burton 2004 and their self concepts seabrook and higgins 1988 sustainable water management policies and regulations may take several decades to be fully implemented without any guarantees that water users will comply when it comes to these sustainable development policies water users can benefit from collective actions which are considerably affected by social norms castilla rho et al 2017 smajgl et al 2009 the most common meanings of social norms stem from society s values behaviors and expectations which give rise to socially important events based on the behavioral definition of social norms a specific norm exists in a community if its members behave in a certain way and punish the individuals who do not act accordingly hence whether an action is a norm can be discerned from the number of its execution and the number of punishment exerted on non followers axelrod 1986 castilla rho et al 2017 farmers participating in a water market have many different choices and desires including how much to bid how much to irrigate whether to comply etc many socio economic factors can affect farmers decision to participate in water markets such as water quality and age of their gardens jaghdani and brümmer 2016 they may change their perspectives in view of complex interactions and feedbacks in the whole system for instance farmers may affect their neighbors decisions when it comes to selling their water permits haensch et al 2019 such systems which comprise autonomous interacting and adaptive agents are known as complex adaptive systems macal and north 2010 many researchers have asserted that one of the most useful techniques for analyzing and evaluating complex adaptive systems is agent based modeling abm abm can take into account heterogeneity of a complex adaptive system acquire the overall result of the system known as emergence and facilitate the comprehension of complex real world phenomena by using a bottom up approach and considering the hierarchical interactions between all of the elements of the system bonabeau 2002 macal and north 2010 tesfatsion 2003 wilensky and rand 2015 while there are numerous studies on water markets using centralized top down approaches alarcón and juana 2016 dinar and letey 1991 erfani et al 2014 he and horbulyk 2010 manjunatha et al 2011 solís and zhu 2015 tisdell 2001 vaux and howitt 1984 zekri and easter 2005 it has been asserted that bottom up approaches such as abm are needed to take into account the complex nature of water markets and individual level heterogeneity du et al 2017 in recent years several studies have evaluated water market performance as a complex adaptive system under different institutional and hydrological conditions using abm du et al 2017 gonzales and ajami 2019 iftekhar et al 2013 smajgl et al 2009 however most of the previous studies have not had a deep appreciation of how users compliance collective actions and social norms may emerge in the water markets du et al 2017 in particular evaluated the joint impacts of farmers behavioral parameters on the performance of a hypothetical water market where farmer agents had no abilities to violate their water permit by extracting water more than what is allowed there are some studies however like castilla rho et al 2017 to consider the farmers social behavior for violation in the context of water management nevertheless the main assumption of such studies about farmers violation was that farmers have perfect information about their environment where they simply imitate their social behaviors from their neighbors this study presents an agent based groundwater market model to investigate the conditions on which collective action and farmers compliance may emerge when the cap and trade policy is adopted as a means to mitigate water shortage problems we consider the possibility of violation in farmers water extraction mathematically by quantifying farmer s social behaviors namely boldness and vengefulness and use these behaviors to understand how social norms may emerge when implementing the cap and trade policy furthermore we consider that the farmers do not have perfect information and update their behavioral parameters vengefulness and boldness based on the available information using two different mathematical approaches presented in this study to this end this study simulates a groundwater market using agent based modeling addressing interactions between social institutional economic and groundwater subsystems the market institution presented in this study caps farmers groundwater permits to ensure sustainable groundwater abstraction facilitates trading of permits between farmers and provides the government with the opportunity to buy water back from farmers in the following section 2 presents the case study and its water management problems section 3 entails the methodology that is composed of four modules addressing the agents behavioral parameters agents decision making processes the market institution and finally section 4 discusses and analyzes the results 2 implementing groundwater market of rafsanjan the daranjir saghand basin is located in an arid region in the central part of iran fig 1 a b rafsanjan plain with an area of 16096 km2 constitutes a main part of the basin and entails more than 60 000 ha of farmlands fig 1c ninety seven percent of total agricultural land use are pistachio orchards and the primary water demand of the region for domestic industrial and agricultural purposes is supplied by groundwater resources there are more than 1424 agricultural domestic and industrial wells which supply almost 99 percent of the region s water demand fig 1d fig 1e illustrates the location of piezometers as well as boundary conditions of the rafsanjan aquifer with an area approximately equal to 4100 km2 parsapour moghaddam et al 2015 rahnama and zamzam 2013 due to an unremitting over extraction of groundwater in the past decades 200 million cubic meters more than aquifer s safe yield the aquifer s overall water table is significantly declined not only is the aquifer drawdown intensifying but also the water salinity and land subsidence are rising rahnama and zamzam 2013 the local authorities are going to come up with effective measures in order to cease the deleterious consequences of over abstraction two of which are water transfer project and the cap and trade policy karamouz et al 2011 motagh et al 2017 however there is uncertainty in this regard as to what policy should be implemented and whether it can be effective we argue that the implementation of a groundwater market based on the cap and trade policy may help control the undesired situation as there are no formal water markets in the region and thus farmers entitlements are defined traditionally it is of importance to analyze such policy implementation which includes capping on entitlements and prepare a basis to analyze consequences such as dissatisfaction and violation 3 methodology the proposed agent based modeling approach integrates social institutional economic and groundwater modules in an interactive structure fig 2 the social module simulates farmers behavior focusing on their violations of groundwater pumping the institutional module introduces the market institution regulating the performance of the proposed water market the groundwater module is a groundwater flow simulation model that simulates the hydrological process in the aquifer to estimate the changes in groundwater level the economic module is similar to a hydro economic model that presents computational routines for calculation of all economic variables such as bid amounts bid prices pumping costs crop yields social welfare etc as illustrated the market institution is in the heart of the system interacting with the other three modules through specified nexuses fig 2 the behavior of the modules and their interactions with each other and the market institution is addressed with an agent based model the agents consist of a market moderator i e government trying to buy water back from the farmers for environmental protection and 200 farmer agents each of which has unique behavioral parameters the farmer agents behavioral parameters consist of their violation behaviors described in the social module and their bidding behaviors and irrigating strategies which are explained in the economic module the market moderator s behavior is addressed by its bidding behavior explained in the economic module the general framework of the agent based model is presented in fig 3 as illustrated in fig 3 the market institution caps farmers entitlements based on the regional groundwater tables monitors farmers groundwater pumping and imposes fine on violators the groundwater table fluctuates with farmers groundwater withdrawal and the government s water buyback accounting for these interactions the social and economic modules determine the groundwater pumping rates which determines groundwater level in the aquifer the modules shown in fig 2 are coded in netlogo which is an interactive and popular programmable modeling environment for developing agent based and system dynamic models wilensky and rand 2015 the netlogo platform benefits from some facilitating packages and extensions including gis extension for loading gis layers matrix extension for performing matrix operations behavior search extension for optimization and searching a specific systemic behavior by heuristic algorithms and behavior space for parameter sweeping and inspecting its impacts on the system in the following sections detailed explanations about the aforementioned modules are proposed 3 1 social module it has been widely established that when the water authorities enact a new rule in line with sustainable development policies e g the cap and trade policy the water users may have a propensity for violating the new rule castilla rho et al 2019 here in the water market context every member of the farmers society can decide not to follow the rules and extract water more than what is allowed i e their water permit grafton and wheeler 2018 marchiori et al 2012 to assess farmers social behaviors and evaluate their possible violations two social behavioral parameters namely boldness and vengefulness are assigned to each farmer agent the boldness is the farmers proclivity for extracting water more than what is allowed and the vengefulness is their tendency towards reporting breaching neighbors in fact when the market institution caps entitlements two social behaviors emerge first farmers may want to pump groundwater more than their new water permits which are addressed by their boldness second farmers may report the violators to the market institution based on their vengefulness the combination of these two behaviors forms social norms in the farmer society these social norms can be called emergence which is defined as a structure behavior or property appearing in the system level owing to manifold and hierarchical interactions and feedbacks between agent agent and agent environment macal and north 2010 sawyer and sawyer 2005 the most prominent characteristic of emergence is downward causation the downward causation concept simply states that the emergent phenomenon which is emerged because of lower level interactions interacts with the lower level elements and restricts them corning 2002 therefore we expect that an emerged social norm as a result of permit caps to restrict its lower level elements giving rise to the emerged social norm i e farmers behaviors such as boldness and vengefulness based on the behavioral definition of the social norm the norm strength emerged in the farmer society as a result of permit caps can mathematically be expressed as castilla rho et al 2017 1 ns t i v i t b i t n where v i t represents an agent s vengefulness and b i t stands for the agent s boldness eqs 2 and 3 n is the number of farmers and ns t is the emerged norm strength in time step t it is worth noting that ns t varies in the range 1 1 if most of the farmer agents comply with the market regulations i e v t 1 b t 0 and ns t 1 collective action may be deduced and strong social norm emerges on the other hand if the social norm strength approaches 1 it can be concluded that a norm of non compliance emerges the emerged social norm has an impact on the farmer agents social behaviors vengefulness v and boldness b based on the downward causation concept as a result the vengefulness of i th farmer agent toward its j th neighbor at t th time step i e probability of reporting the j th neighbor to the market institution is analytically expressed by 2 v i j t 1 y i t y j t ns t 1 2 where y i t kg ha 1 is average crop yield of agents working in the i th agent s neighborhood y j t kg ha 1 represents the crop yield of the neighbor i e the j th farmer agent accordingly the representative vengefulness for each agent v i t which is utilized in the definition of norm strength in eq 1 is considered to be the maximum of the agent s vengefulness probability towards all of the neighbors similar to vengefulness boldness associated with i th farmer agent at t th time step i e probability of exceeding its water permit is mathematically defined as 3 b i t 1 wp i t wp i 0 1 fm t mp t 100 ns t 1 2 where wp i 0 cubic meter yr and wp i t cubic meter yr respectively represent the farmer s water permit before and after implementation of the cap and trade policy mp t denotes percent of well s that are monitored at t th time and fm t 0 1 is a dimensionless variable standing for fine magnitude in fact the farmer would breach with the probability of b i t and up to volume w p i 0 wp i t farmers social interactions according to these two behavioral parameters b i t v i j t are depicted in fig 4 accordingly the violation breached volume of water cubic meter yr is estimated by 4 br i t w p i 0 wp i t 1 fm t mp t 100 1 b i t 3 2 market institution the market institution plays a crucial role in the function of the water market the market institution caps farmers water permits based on the regional groundwater tables on a yearly basis it also receives farmer agents reports and based on the reports and well meters finds and fines the violators the agents bid amounts and bid prices are also sent to the institution and it performs the matching process in order to discover water prices and transfer water permits from sellers to buyers for the price discovery in the water market this market institution uses double auction which is widely considered to be an effective structure for water markets double auctions can be operated either as a centralized market or a decentralized market in the centralized market uniform price double auction a uniform price is determined by a central market institution and all goods will be transacted at the specified price on the other hand in the decentralized market discriminatory price double auction there is no obligations for specifying a specific price prices can be different per transaction and the prices are determined by the participants bids du et al 2017 gonzales and ajami 2019 smajgl et al 2009 this study simulates an agent based groundwater market using a discriminatory price double auction the procedures of the discriminatory price double auction used in this study are explained as follows at the beginning of each year possible buyers and sellers send their bid prices and bid amounts to the market institution the market institution sorts the bids according to their proposed prices buyers sellers bid prices are sorted in descending ascending order as long as the first buyer s bid price who is in the priority in the first line is greater than or equal to the first seller s offer price who is in the first sellers priority the transaction is performed if the bid amount of the first buyer seller is fully transacted the first buyer seller leaves the market and the second buyer seller in the list moves to the priority this process will continue until the total supply becomes exhausted or the total demand is satisfied or no buyer has the bid price higher than the sellers offers 3 3 economic module this section explains farmers irrigation policy in section 3 3 1 farmers bidding behavior in section 3 3 2 governmental water buyback program in section 3 3 3 and farmers social welfare in section 3 3 4 3 3 1 irrigation policy there are many factors that affect a farmer s irrigation policy including sensitivity to soil water deficit region s climate precipitation water availability technological capabilities etc du et al 2017 van duinen et al 2016 the net irrigation requirement stress avoidance irrigation requirement for each farmer agent may be estimated as smajgl et al 2009 5 id i t rmw i t pcp i t 100 a i where rmw i t mm yr 1 represents recommended crop water requirement crop evapotranspiration pcp i t mm yr 1 stands for effective precipitation and a i ha is irrigated area each farmer may or may not wish to apply deficit irrigation as addressed by his irrigation strategy s t i t the heterogeneity in farmers irrigation policy is taken into account by assigning a behavioral parameter to farmer agents as he selects an irrigation strategy 6 ai i t id i t st i t where ai i t represents the farmer s actual irrigation requirement for given irrigation strategy defined by the selected value for st i t initially the irrigation strategy s t i t is assumed to be a random variable 0 1 with uniform distribution moreover i and t are indices representing a farmer agent and time period year in this study here st i t 1 indicates that for t th time step i th farmer select an irrigation strategy so that the crop experiences no water stress st i t 0 stands for the situation that the farmer opts for the rainfed agriculture and finally 0 st i t 1 represents different levels of deficit irrigations the irrigation strategy parameter is updated based upon the farmers net benefit given that the agents are goal based as they attempt to obtain the most profitable irrigation strategy by learning from their previous experiences regarding bounded rationality coined by arthur 1994 stating that humans information and rationality are limited we assume that farmer agents strive to attain the most profitable irrigation strategy using a simple algorithm based on their previous experiences as follows in the first two years of the simulation each farmer agent chooses a random irrigation strategy the farmers then choose the most economically profitable strategies between those two first choices and follow the trend until it reverses in other words as long as increasing decreasing the irrigation strategy brings about more profit they increase decrease it this process goes on until the end of the simulation the farmers obtain more information regarding strategies and their related profits in time so they can estimate more accurately a profitable strategy through time a pseudo code of the adaptation process for irrigation strategy s t is as follows for each farmer agent if time step 0 or time step 1 then set st randomly if time step 1 then select the agent s st associated with highest profit existed in memory stopt and its previous st stpr if stpr stopt then set st stpr rand between 0 0 1 set st stpr rand between 0 0 1 3 3 2 farmers bidding behavior farmers bidding behavior is the process in which they decide on water transactions determining their bid amounts and bid prices and the way they adapt this behavior du et al 2017 the farmers bidding behavior is comprised of two variables the first variable is the volume of water supply demand for a seller buyer agent and the second variable is the water price a farmer agent estimates its volume of water supply to demand from the market q i t cubic meter yr based on its volumes of water permit wp i t its breached amount br i t and its actual irrigation requirement for a given irrigation strategy ai i t as below 7 q i t max 0 ai i t wp i t br i t forbuyers wp i t ai i t br i t forsellers where br i t and ai i t are defined by eqs 4 and 5 the market institution caps farmers water permits in each year based on regional drawdowns in order to ensure sustainable groundwater abstraction so the water permit of each farmer wp i t may change on a yearly basis the water permit of each farmer wp i t cubic meter yr determines their maximum allowable level of withdrawing while bidding price depends on a variety of factors here we assume that the bidding prices are mainly affected by two factors of 1 farmer agent s rent seeking behavioral parameter μ i t tendency for gaining more profit and 2 farmer agent s reservation price η i t irr cubic meter maximum minimum price a buyer seller agent is willing to pay sell du et al 2017 therefore the bidding price irr cubic meter is calculated as follows 8 p i t 1 μ i t η i t for buyer 1 μ i t η i t for seller in order to eliminate complicated structures of agents memory based adaptation we employ zero intelligence plus algorithm based on which an agent adapts its rent seeking with respect to its success in the last transaction cliff and bruten 1997 9 μ i t 1 μ i t β i τ i t p i t η i t where τ i t is the reference trading price that the agent strives to move towards and is set to last transaction price if the agent succeeded in the transaction and is set to the average last market prices if the agent failed to transact furthermore β i 0 1 is a dimensionless behavioral parameter representing farmers learning rate which is considered as a uniformly distributed random variable additional equations regarding the procedures for deriving the reservation price can be obtained from the supporting information 3 3 3 governmental water buyback program the governments can either recruit a number of environmental agencies to procure water for the environmental flow requirements or take action into their own hands accordingly water protection objectives can be achieved through buyback programs ancev 2015 grafton and wheeler 2018 marchiori et al 2012 tisdell 2010 wheeler et al 2013 the buyback program implemented in this study aims to reduce the overall caps on water extractions in order to act as a compensation based approach and better off farmers as well as the environment assuming a cobb douglas utility function based on which the buyback program is implemented and considering a budget constraint the optimal government s bid amount can be estimated as hamill and gilbert 2015 10 w t optimal α bc t p t where bc t irr represents the budget constraint and p t irr cubic meter stands for the buyback related bid price which is estimated using eq 8 furthermore α 0 1 is a parameter denoting the protecting agent s i e the government tendency for acquiring water for the environment the greater the parameter s value is the more keen on water protection and buyback the government will be finally the protecting agent s rent seeking is updated based upon eq 9 the behavioral parameters of agents are shown in table 1 in the absence of reliable data all of the farmers behavioral parameters are initially assumed uniform distribution the initial rent seeking and the learning rate behavioral parameters of the government agent are assumed to be 0 5 and 0 6 respectively 3 3 4 farmers social welfare market participants attempt to increase their own welfares a farmer agent s individual welfare is estimated based on the difference between the transacted price τ i t and the agent s reservation price η i t the individual social welfare is known as producer surplus i e seller s welfare or consumer surplus i e buyer s welfare the total producers and consumers surpluses associated with t th time step are calculated as 11 ps t i q i t τ i t η i t 12 cs t i q i t η i t τ i t where q i t and q i t cubic meter yr are i th agent sold and bought water permit eventually the social welfare of all the market participants can be estimated by summing up the overall producers and consumers surpluses xu et al 2018 3 4 groundwater module the groundwater abm in this study is the finite difference groundwater modeling part of the flowlogo interface which is developed by castilla rhoet al 2015 in netlogo the flowlogo is a modeling environment which conspicuously facilitates the development of coupled agent based groundwater models the flowlogo modeling environment is capable of modeling different boundary conditions no flow fixed head and constant flux and a variety of sources and sinks pumping and injection wells springs streams and accordingly it can simulate transient and steady state 2d groundwater flow in confined and unconfined aquifers castilla rho et al 2015 3 5 calibration and validation because no water market is implemented in the case study area and no formal information of probable trades is available we calibrated the groundwater module under the status quo condition where no water market is in operation the calibration is performed in two distinct steps steady state and transient groundwater flow simulation the steady state step is as follows by analyzing the piezometers data and their hydrographs we observed that in spring 2002 the piezometers had roughly had constant values hence we assumed that underground recharge was in balance with pumping well discharge in this period this means that the discharge and recharge were approximately equal so the only unknown parameter is hydraulic conductivity to be estimated by calibration we performed the steady state step of calibration by minimizing the differences in the observed and calculated heads in 42 piezometers we used the behavior search package for this optimization which is a software tool including heuristic algorithms for optimization therefore the hydraulic conductivity coefficients are obtained with an rmse approximately equal to 2 8 m shown in fig 5 after assigning the hydraulic conductivity coefficients to the aquifer we proceeded with the transient model simulation in order to obtain the second unknown parameter i e specific yield over an 11 year time period 2002 2012 using behavior search the genetic algorithm which is one of the heuristic algorithms in behavior search is used to minimize the difference between observed data and simulated heads over the time period of 2002 2012 after large numbers of generations one of the best coincidence occurred between simulated and observed values with an rmse roughly equal to 7 m after the calibration of the groundwater module we verified the groundwater module for five remaining years i e 2012 2017 validation of agent based modeling approaches may be carried out using two ways of structural and outcome validations while the structural validation is essentially pertinent to the consistency between the model structure and the experts opinion and theoretical mechanisms the outcome validation makes a comparison between the calculated results and empirical data du et al 2017 gonzales and ajami 2019 in the light of non existence of any market institutions in the rasanjan plain and the aims of this study to understand how farmers social behaviors may emerge the focus of this study is only on the structural validation in the future after implementing a real water market institution in rafsanjan plain it is possible to perform outcome validation using the model s results and obtained data 4 results and discussion the results of this study are presented in three sections the first section is a sensitivity analysis which analyzes all of the possible scenarios regarding monitoring and enforcement settings and tries to find a setting that is most beneficial socially environmentally and economically the second section uses the first section to design five scenarios in order to assess the cap and trade policy finally the last section analyzes the social economic and hydrologic impacts of the designed scenarios 4 1 sensitivity analysis results in this section the market is evaluated without any buyback programs to assess the effects of implementing a water market between farmer agents the agent based market model was run in the period of 2002 2017 years to assess hydrologic economic and particularly social impacts of the cap and trade policy under different monitoring and enforcement settings we seek a condition or conditions where the monitoring and enforcement level are enough to simultaneously discourage violation reduce aquifer s drawdown benefit farmers economically and more importantly bring about a functioning water market these conditions seem to happen at neutral social norms as shown in fig 6 a by a dashed line when the monitoring and enforcement settings are at levels that neutral social norms emerge fig 6a the economic fig 6b g and hydrologic fig 6h impacts of the cap and trade policy are acceptable and a functioning market will emerge these social norms can be called emergence which is defined as a structure behavior or property appearing in the system level that did not exist before macal and north 2010 sawyer and sawyer 2005 that is before implementing the cap and trade policy farmer agents neither had any propensity for violating their water permits due to permit caps nor had any tendency to report violators considering market competition in terms of number of participants in the market and volume of traded water fig 6b and c illustrate that the neutral social norm conditions dashed lines can be strong enough to bring about a functioning water market with a competition as high as the most severe enforcement and monitoring levels i e monitoring percent 100 and fine magnitude 1 the dashed lines shown in fig 6a can be considered the social leverage points where the system can potentially be shifted from one regime to another with little change in the inputs in this case monitoring percent and fine magnitude it can be seen that in these leverage points social norms are shifted abruptly from negative values regime of noncompliance to positive norms emergence of compliance these leverage points can be crucial for emergence of a functioning water market as approximately all of the market features change abruptly with little change in the inputs fig 6b h farmers are better off in these leverage points since they experience high social welfare fig 6e crop yields with little stress fig 6f and a high net benefit fig 6g besides in fig 6h it is obvious that the leverage points make the hydrological performance of the cap and trade better than most of the other possible scenarios considering the amount of budgets needed for monitoring the wells the amount of fines imposed on violators and their trade offs all in all the sensitivity analysis shows that as a result of implementing the cap and trade policy for groundwater resources and farmers reactions to this policy social norms emerge in the farmer society depending highly on its setting i e monitoring level and enforcement power the emerged social norms can affect the efficiency of the water market as any change in social norms results in a change in other features of the market in particular when the norms are at the leverage points 4 2 scenario definition as presented in the previous section there are numerous scenarios based on monitoring level and enforcement power in this study five main scenarios are presented in order to evaluate the cap and trade policy table 2 presents how the scenarios are defined the first scenario abbreviated by nwm represents the status quo where no water market is implemented the second scenario shortened to sme and the third scenario abbreviated by wme successively denote conditions in which the monitoring level and enforcement power are at their highest and lowest possible levels respectively the fourth scenario named dme represents a middle condition regarding the monitoring level mp t and enforcement power fm t where the fm t is equal to 0 1 and mp 0 is initially equal to 40 percent which means that 40 of farmer wells are monitored in time step zero and detected violators from these 40 monitored wells will be fined an amount equal to 0 1 of their net benefit considering the technical problems of wells monitoring and their recovery data the mp t changes over time the market institution assigns a yearly budget to equip 10 of unequipped wells with meters but after every three years 15 of total meters fail to work based on the available data the fifth scenario called dmebp has an extra buyback program in addition to conditions of the dme scenario and the government s budget is set to minimize the hydrological differences between dme and dmebp in order to compare their economic and social results 4 3 scenario based results in this section the time series results of the five described scenarios are presented and discussed it is worth mentioning that the cap and trade policy is an instrument that is recommended in order to alleviate drought conditions and manage water shortage problems as expected fig 7 a suggests that the emerged social norms approach their maximum and minimum amounts under sme and wme scenarios respectively notwithstanding the first rise in the social norm in the dme scenario it starts declining because of malfunction of 15 percent of wells meters monitoring percent in time step 4 every three years 15 percent of wells meters fail to work assuming that the market institution assigns a budget to add well meters to 10 of all of the unequipped wells on a yearly basis this action cannot stop social norms decline and finally a rather weak norm emerges in dme scenario however a stronger social norm emerges in the dmebp scenario which just has a buyback program in addition to dme considering the same conditions in dme and dmebp scenarios fig 7a indicates that buyback programs can facilitate the emergence of strong social norms since they put a less severe restriction on farmers water permits to act as a compensation based approach for farmers economic situation fig 7e according to the emerged social norms the farmers breaches are at their highest and lowest levels in wme and sme scenarios besides the positive effect of the governmental buyback program can be seen in fig 7b in comparison with dme scenario as the farmers breaches are reduced roughly by 50 percent in dmebp scenario following previous studies highlighting the need for providing incentives for water users compliance with the regulations castilla rho et al 2017 grafton and wheeler 2018 this study introduces the water buyback program as an impetus for water users compliance in that it can bring about a stronger social norm as expected fig 7c illustrates that for all of the scenarios the water market effectively contributes to lessening the severity of groundwater drawdown in comparison with the status quo scenario nwm in particular the sme and wme scenarios have respectively shown the best and the worst hydrologic performance between the four market scenarios each of which in turn causes 47 cm and 60 cm annual drawdown it is also perceptible that owing to the water transactions the weak monitoring and enforcement scenario wme has a better hydrologic performance than the status quo scenario nwm which engenders a yearly water table drawdown of 80 cm it is worth mentioning that the differences in hydrological performances of dme and dmebp scenarios are minimized by optimizing the government s budget in order to compare their social and economic performances and analyze the governmental buyback program fig 7d shows the farmers net benefit time series under different monitoring and enforcement scenarios as expected in the sme scenario the net benefits are reduced in comparison with the nwm scenario because the farmers water permit are capped and they cannot violate to increase their profits owing to the severity of fines in the sme scenario farmers violate at the first time step but the severity of fines make them comply afterwards where a strong social norm emerges in wme scenario farmers violate and increase their net benefits so they eventually can reach a net benefit even more than the nwm scenario the economically positive impact of the buyback program can be seen in fig 7d where the net benefits of farmers are roughly 25 percent more than the dme scenario despite the similar hydrologic performance of dme and dmebp scenarios this result suggests that the buyback program can negate the economic losses experienced by farmers owing to the permit caps which is in line with the previous studies grafton and wheeler 2018 fig 7e and f show the water permits and the average flow rates of withdrawal by the farmers as expected the wme scenario has the most reduction in water permits through time because the water table decreased more quickly and this makes the caps more severe therefore the emergence of strong norms can lead to a reduction in caps on water permits through time and this is an extra benefit for water users who may take it for granted furthermore while the overall water permits under the dmebp scenario are more than the dme scenario the overall flow rates are roughly equal this can either mean that farmer agents in dmebp scenario choose to participate in the market by selling their water permits to the government or the farmers in dme scenario pump groundwater more than their groundwater permits considering the two driest years of the simulation the 9th and 15th years it can be perceived that almost always drought causes a reduction in values of the norm strength fig 7a with an exception for scenarios with strong emerged social norms i e sme and dmebp scenarios the farmers breached amounts of water have significantly increased during these dry years fig 7b therefore encouraging farmers to comply with the market regulations such as giving the fines imposed on violators to the reporting farmers or increasing water permits of farmers reported violators correctly can bring about a social norm that is enough to discourage violation even in the driest years fig 8 a b shows that the emergence of strong norms can bring about a functioning market where most of the farmers participate in the water market accordingly the dmebp scenario is the most competitive market scenario in which the volume of water traded and the number of market participants are more than other scenarios on the other hand the wme scenario can retard the emergence of a functioning market and can reduce market functionality in time as both the number of market participants and traded volume are diminishing through time the emerged norm in dme scenario is not weak enough to cease a functioning market fig 7a which makes this market function rather weaker than the sme scenario the number of market participants in dme approaches the participants in sme fig 8a and the difference in volume of traded water is negligible fig 8b as fig 8c illustrates without any buyback programs when the norm of compliance emerges farmers put a higher value on water and vice versa this occurs because of supply and demand interactions in other words when monitoring and enforcement are high i e under the sme scenario there is no rationale behind violation all farmers comply with their water permits therefore the market supply shrinks and market demand increases and this is the main reason for higher bid prices on the other hand regarding the wme scenario the norm of non compliance emerges because the farmers aim to increase their benefits by violations therefore market supply increases and market demand decreases and this will cause a reduction in water prices similarly in the buyback scenario market supply increases and market demand decreases as the caps put on farmers water permits are less severe fig 7e therefore the water prices in dmebp scenario are fewer than water prices in dme scenario finally fig 8d shows the social welfare in different scenarios it indicates that the sme and wme scenarios bring about the most and the least social welfare for farmer agents with this in mind it can be seen that the difference between social welfare in dme and sme scenarios are negligible so the dme scenario is a scenario that can engender a satisfactory degree of social welfare for the farmer agents however the dmebp scenario has a social welfare level lower than sme and dme scenarios this is because although the volume of traded water in dmebp is more than dme and sme fig 8b the water prices in dmebp scenario are fewer than dme and sme scenarios fig 8c 5 conclusion in the face of water scarcity it is of paramount importance to effectively analyze and implement policies that may lead to sustainable groundwater use and collective action therefore this study evaluates the efficacy of one demand side management technique that is the cap and trade policy in the case study area of rafsanjan plain four main scenarios are analyzed the two first scenarios are wme and sme which are the extreme scenarios with weak and strong monitoring and enforcement power the lowest and highest monitoring and fines for violators the dme and dmebp scenarios are assessed to determine the applicability of the policy the dme scenario is a market scenario with dynamic monitoring levels and a rational enforcement power and the dmebp scenario is the dme scenario as well as a buyback program for environmental protection the results indicate that dme scenario can reduce the aquifers annual drawdown from 80 cm status quo to 53 cm furthermore the water buyback program dmebp reduces the farmers breaches by 50 percent in comparison with the market without any buyback programs dme moreover the buyback program increases the total farmers net benefit by 25 percent and imposes an annual cost on government which is equal to 1 5 1012 irr therefore water buyback programs can increase the market competition level and farmers profits and it can decrease farmers violations according to the results of the study the monitoring level and enforcement power have a substantial impact on farmers compliance in the cap and trade policy and the emerged social norms can significantly affect the market performance the results show that as a result of implementing the cap and trade policy social norms emerge which affect markets performances if the emerged social norm is a strong one the market will function in a way that most individuals will participate and more water will be traded and vice versa thus this study shows that the market competition level has a direct relationship with the emerging norm therefore groundwater permits can be effectively transferred from low value uses to high value uses by providing a condition on which strong social norms emerge regarding the limitations of this study it is worth mentioning that this study does not take into account spatial distribution of socio hydrologic and economic impacts of the cap and trade policy spatially heterogeneous impacts of groundwater markets are important as the groundwater flow is affected by topography therefore for future studies the spatial effects of groundwater markets based on the cap and trade policy can be explored credit authorship contribution statement vahid aghaie conceptualization methodology software validation writing original draft hosein alizadeh conceptualization methodology validation writing review editing supervision abbas afshar conceptualization methodology validation writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125057 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5314,climate variation and human activities are two prime drivers influencing the hydrological cycle and the stationarity of hydrologic systems hydrological drought is caused by significant negative variation from normal hydrologic conditions influenced by climate variation and human activities traditional methods employed for quantifying the impacts of climate change and human activities are based on the assumption of stationarity which is no longer valid under the current changing environment in this study a heuristic segmentation method was used to identify the change point in streamflow time series by considering its non linearity and trend analysis was performed on hydro meteorological variables before and after the change point a non stationary standardized runoff index srins was constructed using generalized additive models in location scale and shape gamlss finally the influences of climate change and human activities on hydrological drought were quantified at various time scales the results reveal change points in the streamflow time series after the 1990s significant decreases in precipitation and streamflow were also observed after the change points in all study watersheds whereas the trend of potential evapotranspiration increased at a higher rate after the change points the impact of climate change on the seasonal three month time scale was greater in the winter and spring seasons whereas the impact of human activities was significantly higher in the summer and autumn seasons the influence of climate change on hydrological drought was dominant at longer 6 and 12 month time scales whereas human activities accounted for 25 6 and 20 of the changes in watersheds 1018 and 1019 on the 12 month time scale respectively keywords climate change hydrological drought human activities heuristic segmentation method non stationarity 1 introduction drought is documented as a composite natural phenomenon that commonly begins with a lack of precipitation leading to deficits in soil moisture storage due to evapotranspiration and river flow adversely affecting plant growth and human life li et al 2013 among various natural disasters reoccurring drought is one of the most impactful having negative impacts on the economy environment and society mishra and singh 2010 for example the 2012 drought in the united states resulted in economic losses of over usd 12 billion and indirectly affected global food prices crutchfield 2012 drought is classified into four categories meteorological agricultural hydrological and socioeconomic based on types of water deficit in precipitation soil moisture storage streamflow and water resources heim 2002 of these categories hydrological drought that is caused by inadequate surface or subsurface water resources is considered the most important shukla and wood 2008 van loon 2015 because various sectors such as agriculture urban life industry and hydropower generation depend mainly upon surface water resources vasiliades et al 2011 a remarkable change has been observed in the global climate over the last century the hydrological cycle and its available water resources are greatly influenced by climate change the consequences of which give rise to extreme natural disasters such as floods and droughts dai 2013 increased evapotranspiration due to rise in temperature without enhancement in precipitation has heightened the intensity and frequency of hydrological droughts in the 21st century worldwide sheffield et al 2012 dai 2013 in addition to climate change the impacts of human activities on hydrological drought are undeniable agricultural irrigation water extraction land use cover changes urbanization industrialization and reservoir regulation alter hydrological cycles which eventually result in variability of hydrological drought characteristics sheffield et al 2012 van loon et al 2016 the most common method of characterizing drought is development of a suitable drought index with which to identify drought and its characteristics and to evaluate its quantitative impacts heim 2002 dai et al 2020 gu et al 2020a b jehanzaib and kim 2020 various drought indices have been proposed including the standardized precipitation index spi the standardized precipitation evapotranspiration index spei the palmer drought severity index pdsi and the standardized runoff index sri the sri is extensively used for monitoring hydrological drought due to its simplicity in computation relatively low data requirements and comparability at various time scales shukla and wood 2008 moreover the sri involves information about environmental conditions as well as human interruptions within watersheds zhang et al 2018 calculation of the sri requires fitting suitable probability distributions to runoff time series based on the assumption of stationarity however due to intensification of climate variation and anthropogenic activities that assumption is no longer valid zou et al 2018 under non stationary circumstances drought characteristics estimated using stationary drought indices might be inaccurate therefore it is necessary to establish an adequate non stationary drought index for reliable quantification of hydrological drought under changing environments accordingly this study adopted the generalized additive models for location scale and shape gamlss proposed by rigby and stasinopoulos 2005 to model runoff time series with non stationary marginal distributions there has been considerable attention focused on the effects of climate change and human activities on streamflows mccabe and wolock 2011 ahn and merwade 2014 saidi et al 2018 yuan et al 2018 mccabe and wolock 2011 found that precipitation has the predominant impact on streamflow after examining the separate impacts of precipitation and temperature on streamflow variability in the united states ahn and merwade 2014 concluded that the impact of human activities varies spatially after investigating the impact of environmental variation on streamflows in four u s states using three different methods saidi et al 2018 found that climate change accounted for an 85 decrease in runoff and remaining changes were caused by land use cover change in alpine river yuan et al 2018 reported noticeable anthropogenic climate change fingerprints on the changes in annual streamflow in yellow river basin china in addition margariti et al 2019 found that human activities increase drought termination rates in all case studies of europe however as discussed by zhang et al 2018 studies concerning the impacts of natural and anthropogenic activities on hydrological droughts are still rare moreover previous studies that investigated the impact of environmental changes on hydrological droughts were based on the assumption of stationarity which is no longer valid under changing environments as the influences of climate variation and human activities change over time dai 2013 it is important to examine their impacts on hydrological droughts at various time scales to date there have been few studies that appraised the impacts of climate variation and human activities on hydrological droughts at multiple time scales considering the non stationarity of hydrological variables zou et al 2018 even though the key point of environmental impact assessment studies was to calculate change points from the standpoint of non stationarity the main downside of previous studies was the use of conventional methods to calculate change point in the streamflow time series jiang et al 2019 zhang et al 2018 zou et al 2018 jehanzaib et al 2020a therefore there is a need to develop a framework which is entirely based on non stationary approaches for reliable evaluation of environmental changes on hydrological drought the innovative feature of this study as contrasted with other studies is to adopt a non stationary framework for evaluating the impacts of climate change and human activities on hydrological droughts at multiple time scales the non stationary framework can consider the uncertainty of environmental conditions and provide an estimate of environmental effects on hydrological drought the primary objectives are 1 to apply a non stationary heuristic segmentation method for detecting change points in streamflow time series 2 to reconstruct natural runoff time series based on water balance 3 to develop a non stationary sri using a gamlss algorithm and 4 to evaluate both climatic and human impacts on hydrological drought in the han river basin of south korea 2 study area and data in this study four watersheds of the han river basin were selected as shown in fig 1 more than 75 of the population of the han river basin is concentrated in these watersheds which cover drainage areas ranging from 605 to 1537 km2 with an average elevation of 150 m the annual average temperature and annual average precipitation of the study area are 12 c and 1300 mm respectively during the period 1973 2016 lee et al 2019 the geographic features water usage and population density of the studied watersheds are presented in table 1 the meteorological data of daily precipitation and temperature for the period 1973 2016 were collected from the korea meteorological administration kma https www data kma go kr the thiessen polygon method was adapted to convert point data into watershed scale the daily streamflow data of hydrological stations that lie in the study area were collected from the water resources management information system wamis http www wamis go kr main aspx for the period 1966 2016 the annual water usage and water demand data were also collected from the wamis for the period 1970 2016 the gross domestic product gdp and population data of the study area were obtained from the statistics korea http www kosis kr for the period 1970 2016 3 methodology the complete framework of the study is shown in fig 2 3 1 heuristic segmentation method to investigate the effects of climate change and human activities on hydrological droughts it was necessary to divide the streamflow time series into natural and human impacted periods statistical methods that are widely used to estimate the change point in the time series are mann kendall test pettitt test rank sum test sliding f test and sliding t test all these methods are based on the hypothesis that the samples come from the linear process however hydrological variables are highly nonlinear due to the variability of hydrological processes this results in challenges when trying to identify real change points using the existing techniques hence in this study the heuristic segmentation algorithm based on the concept of the sliding t test was modified to identify change points in the annual streamflow time series of the han river basin following the methods of pedro et al 2001 a sliding pointer was gradually displaced from left to right throughout the entire time series to partition the non stationary time series into several stationary sections the mean of the series on the two sides μ1 and μ2 of the pointer was then calculated for two normally distributed random series the significance of the distinction between the average values of the two series was calculated by the student s t test statistic as in eq 1 1 t μ 1 μ 2 s d 2 s d n 1 1 s 1 2 n 2 1 s 2 2 n 1 n 2 2 1 2 1 n 1 1 n 2 1 2 where sd is the pooled variance n 1 and n 2 are the numbers of data points in the two series and s 1 and s 2 are the standard deviations of the two series the position of the pointer that produced the maximum value of the t statistic was determined the maximum value t max indicates that the averages of the two series are significantly different and is a good indicator of a change point huang et al 2016 finally the statistical significance of that maximum value p t max was computed note that p t max is not a result of the standard student s t test press et al 1988 because sample series are not autonomous and cannot be obtained in a closed analysis therefore p t max was mathematically estimated by eq 3 3 p t max 1 i v v t max 2 φ v φ η where v n 2 n is the total number of time series i a x y is an incomplete beta function η 4 19 ln n 11 54 and φ 0 40 according to monte carlo simulation the time series will split if the difference between the mean values is statistically significant i e it is greater than the threshold normally set as 0 95 and vice versa zhang et al 2019 we continued to iterate the above process on the sub series after splitting the original time series until the significance value was less than the 0 95 3 2 sen s slope estimator sen s slope estimator is a nonparametric linear method that is widely used for calculating the slope of trend in hydro meteorological time series da silva et al 2015 jehanzaib et al 2020a first a series with a linear slope is estimated by eq 4 4 s i y i y j i j f o r k 1 n where y i and y j are the data values at times i and j i j respectively the n values of slope s i are arranged in ascending order and the median of slope b med is estimated by eq 5 5 b med m e d i a n s i the value of b med shows the gradient and its sign shows the direction negative or positive of the trend we used sen s slope estimator in this study to estimate the trends of precipitation potential evapotranspiration and streamflow time series before and after the detected change points 3 3 hydrological modeling it is necessary to reconstruct natural streamflow time series using a hydrological model for human impact assessment among various hydrological models with different strengths and limitations the abcd model proposed by thomas 1981 is one of the most extensively used as a lumped conceptual model the abcd model integrates a highly realistic illustration of the infiltration process and is employed in many studies saidi et al 2018 zhang et al 2018 jehanzaib et al 2020a this model consists of two moisture storage compartments such as soil moisture storage in the upper layer and groundwater storage in the lower layer as shown in fig 3 with four parameters i e a b c and d the abcd model generates streamflow as output taking monthly precipitation and monthly potential evapotranspiration pet as input zhang et al 2018 in our study pet was estimated using the most common temperature based hargreaves method hargreaves and samani 1985 the abcd model was calibrated using a genetic algorithm for the natural period and then used for simulation in the impacted period the efficiency of the abcd model was calculated based on three performance assessment criteria nash sutcliffe efficiency nse kling gupta efficiency kge and water balance error wbe nash and sutcliffe 1970 gupta et al 2009 6 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 7 kge 1 1 r 2 1 θ 2 1 ϕ 2 8 wbe i 1 n q obs i q sim i i 1 n q obs i where r is the pearson correlation coefficient θ σ s σ o is the relative variability ϕ μ s μ o is the bias ratio between observed streamflow q obs and simulated streamflow q sim and n is the total number of observations σ o and μ o are the standard deviation and mean of the observed streamflow respectively σ s and μ s are the standard deviation and mean of the simulated streamflow respectively the nse and kge measure correlation and overall fitness respectively with optimal values of one the wbe measures under prediction or over prediction with an optimal value of zero between observations and simulations 3 4 standardized runoff index the standardized runoff index was originally proposed by shukla and wood 2008 and is widely used for monitoring and evaluating hydrological drought the calculation of the sri involves fitting a two parameter lognormal distribution as suggested by nalbantis and tsakiris 2009 to long term streamflow data the cumulative distribution function cdf of the fitted marginal distribution is transformed into a standard normal variate z using eq 9 9 sri t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 t ln 1 f x 2 0 f x 0 5 t ln 1 1 f x 2 0 5 f x 1 where f x is the cdf of the marginal distribution and c0 c1 c2 d1 d2 and d3 are constants once the sri is computed using eq 9 hereafter denoted as sric drought severity is divided into five classes based on index value i e sri 0 no drought 1 sri 0 mild drought 1 5 sri 1 moderate drought 2 sri 1 5 severe drought and sri 2 extreme drought 3 5 non stationary standardized runoff index it is challenging to deal with hydrological data due to rapidly changing environmental conditions which lead to non stationarity in this study the non stationary standardized runoff index srins was defined analogously to the sric but the long term streamflow data were fitted to a non stationary marginal distribution with time varying parameters the generalized additive models in location scale and shape gamlss proposed by rigby and stasinopoulos 2005 is widely used for analyzing non stationary behavior of time series the general distribution functions supported by gamlss are discrete highly skewed and or kurtotic continuous distributions in the gamlss algorithm the time series y t of time t 1 2 n are assumed to be independent and are fitted to a probability distribution function f y t α t conditional on α t α 1 t 1 α 2 t 2 α p tn representing a vector of p distribution parameters at time t the distribution parameters account for the location scale and shape associated with explanatory variables via the monotonic link function η k given by eq 10 10 η k α k x k θ k θ 0 k θ 1 k x θ qk x q k 1 2 p where x k represents the explanatory variables θ k are polynomial coefficients p is the number of parameters and q is the degree of the polynomial in this study a long term streamflow time series was fitted to a non stationary lognormal distribution with its location parameter μ linked with time the optimal degree of the polynomial was selected based on the akaike information criterion aic finally the cdf of the non stationary distribution was transformed into a standard normal variate using eq 9 the calculations regarding gamlss modeling were performed using the gamlss package in r software stasinopoulos and rigby 2007 3 6 quantification of effects of natural and human activities on hydrological drought climate change and human activity are two main factors that alter hydrological cycle processes the overall influence of these factors on runoff can be expressed mathematically as follows 11 δ q total δ q climate δ q human where δ q total δ q climate and δ q human represent total variation in runoff variation in runoff due to climate change and variation in runoff caused by human activities respectively the runoff simulated by the hydrological model after calibrating its parameters in the natural period represents natural runoff and the runoff observed after the change point represents the influence of human activities zhan et al 2014 therefore it is reasonable to presume that variations in hydrological drought might be equivalent to those shown in runoff because the hydrological drought is derived from runoff time series wang et al 2015 in this study the sri was applied to reconstructed natural runoff by the abcd model to characterize changes in hydrological drought due to climate change which was denoted as srirecon the srins was constructed using the gamlss algorithm to characterize total variation in hydrological drought resulting from both climate change and human activates finally the contribution of human activities to hydrological drought was calculated as the difference between srins and srirecon which was denoted by sriha the percentage impacts of climate change pcc and human activities pha on hydrological drought were calculated using eqs 12 and 13 12 pcc sri recon sri ha sri recon 100 13 pha sri h a sri ha sri recon 100 where sri recon and sri ha are absolute values of sum of values of srirecon and sriha respectively 4 results and discussion 4 1 identification of change points according to the fifth assessment report ar5 of the intergovernmental panel on climate change ipcc the global average surface temperature is likely to increase by 3 7 c by the end of the 21st century ipcc 2013 a rise in surface temperature leads to high evaporation into the atmosphere which alters hydrological processes detection of change points in this process is important to estimate changes in hydrological regimes we adopted a non stationary heuristic segmentation algorithm to detect change points in annual streamflow series of the han river basin the change points in watersheds 1018 and 1019 were observed after 1995 whereas those in watersheds 1015 and 1016 were observed after 2000 as shown in fig 4 a significant decrease in precipitation and an increase in potential evapotranspiration were observed after these detected change points which is evidence that the streamflow was directly influenced by these drivers moreover more than 85 of the population of the han river basin lives in watersheds 1018 and 1010 which has indirect influences on streamflow our change point findings were in accordance with those of jehanzaib et al 2020a which showed change points in the han river basin after the 1990s table 2 clearly indicates that the p values in watersheds 1015 1016 and 1018 were greater than the selected threshold 0 95 in watershed 1019 though the value of p t max was slightly less than the selected threshold it was nevertheless considered a probable change point the results of the heuristic segmentation algorithm showed that the annual streamflow series of the han river basin was significantly affected by varying environmental conditions during the study period 4 2 trend analysis due to climate change variations in precipitation and potential evapotranspiration were observed throughout the study area trend analyses were performed for annual precipitation potential evapotranspiration and streamflow series before and after the detected change points using sen s slope test the trend analysis showed that annual precipitation increased before the change point in all the watersheds with an average value of 7 56 mm yr after the change point there were significant reductions in annual precipitation averaging 31 25 mm yr similarly there was a significant increase in potential evapotranspiration after the change point with an average value of 2 73 mm yr fig 5 summarizes the results of trend analyses of precipitation and potential evapotranspiration in watersheds 1016 and 1018 the variation in streamflow time series observed throughout the study area was due to significant variation in environmental conditions the results indicate that streamflow decreased at an average rate of 2 48 mm yr before the change point after the change point the streamflow began to decrease significantly at an average rate of 25 1 mm yr the results of trend analysis are in accordance with those of bae et al 2008 the comprehensive results of trend analysis of streamflow in all the watersheds are shown in fig 6 4 3 streamflow simulation by hydrological model the abcd model was calibrated and validated in the natural period before reconstructing natural runoff in the human impacted period the performance of the abcd model in the four watersheds is shown in fig 7 the results reveal that the abcd model accurately presented the natural conditions with the nse greater than 0 90 in both calibration and validation periods in all the watersheds these findings are in accordance with zhang et al 2018 in which the nse ranged from 0 87 to 0 93 in china similarly the value of kge was greater than 0 90 in all the watersheds in the calibration period in the validation period the average value of kge in all the watersheds was greater than 0 85 evidence that the abcd model was able to perform accurate simulations in the human impacted period the comprehensive results of all performance measures kge nse and wbe in both calibration and validation periods of all the watersheds are shown in table 3 the wbe in all the watersheds for both calibration and validation periods was less than 0 additional evidence of a good fit based on the performance indicators the abcd model produced robust estimates of monthly streamflows in all the watersheds during both calibration and validation periods 4 4 modeling with the gamlss algorithm the monthly streamflow series was fitted to a non stationary two parameter lognormal distribution using the gamlss algorithm to construct a probabilistic model the location parameter of the distribution varied as a polynomial function of time in this study the degree of the polynomial q was less than 4 to avoid convolution and provide adequate flexibility to describe the fluctuation the optimal time varying model was selected at each time scale for each watershed based on minimum aic the results of two watersheds at three month seasonal six month biannual and 12 month annual time scales in july are shown in fig 8 as this was the month of highest variation in streamflow fig 8 shows that the gamlss algorithm is able to capture the variation in streamflow data because most of the points of both watersheds lie between the 5 and 95 centile curves on different time scales the results of these centile plots are in accordance with wang et al 2015 and bazrafshan and hejabi 2018 and confirm that the selected models fairly characterized the variability of data at various time scales finally the results of the non stationary log normal probability distribution with time varying parameters were compared with the log normal probability distribution with stationary parameters at various time scales due to space limitation only the comparative results of the conventional and non stationary probability distributions in watershed 1018 are shown in fig 9 the non stationary probability distribution more accurately presented the actual conditions than did the conventional probability distribution at all time scales and can be used for drought calculation in the human impacted period 4 5 quantifying the impacts of climate change and human activities on drought the influence of climate variation and anthropogenic activities on hydrological drought was investigated at seasonal biannual and annual time scales by calculating sri and srins for the natural and human impacted period respectively seasonal sri was calculated at the three month time scale to observe the influence of the four seasons the six month sri calculated for june was selected for biannual analysis and the 12 month sri calculated for december was chosen for annual analysis the percentage contributions of climate variation pcc and human activities pha to hydrological drought were investigated using eqs 12 and 13 as an example the independent impacts of climate change and anthropogenic activities on hydrological drought in watershed 1018 at various time scales are shown in fig 10 the comprehensive results of all the watersheds demonstrating the impacts of climate variation and human activities are summarized in table 4 these results demonstrate that the impact of climate change was high at all time scales but the human impacts were significantly stronger at the seasonal time scale especially in summer and fall the greatest anthropogenic effect was observed in summer 47 1 38 6 and 44 6 of the overall effect in watersheds 1015 1018 and 1019 respectively at the seasonal time scale at the biannual time scale the impact of climate change was significantly high 85 while the impact of human activities was less than 30 in all the watersheds at the annual time scale the results of this research are in general accordance with jehanzaib et al 2020a in south korea which stated that the impact of human activities on hydrological drought was less than 10 the results of our study followed similar trends but showed higher human impacts 4 6 discussion the majority of relevant studies in the literature address the impacts of climate variation and human activities on hydrological drought based on the assumption of stationarity of the hydrologic system jiang et al 2019 zhang et al 2018 however due to significant human interventions this assumption is no longer valid and is the main drawback of previous studies hence non stationary approaches were adopted in this study to estimate the contribution of human activities to hydrological drought in recent decades in our study area the population has increased gradually while the gdp has increased rapidly as shown in fig 11 a this sudden increase in gdp occurred after the 1990 s due to significant human interventions such as changes in land use land cover industrialization urbanization reservoir regulation and agricultural irrigation similarly fig 11 b shows that most of the increase in water usage in the study area occurred after the 1990s interestingly the figure shows that water demand was much higher than water usage toward the end of the 1970 2016 which is evidence that the study area was already facing water shortages in 2016 likely because more than 85 of the population of the han river basin is densely crowed in these watersheds this viewpoint was verified by estimating change points in the streamflow series using a non stationary heuristic segmentation method relevant change points were detected after the 1990s by 2016 less water was being used for agriculture because of use of modern irrigation technologies which allowed more water to be allocated to the domestic sector to fulfill the needs of people the impact of human activities was significant at the seasonal time scale especially in spring summer and fall because the most important crop in this area is rice which is usually sown from mid april to mid july and harvested from september to november the rice crop needs intensive flood irrigation which may cause high evapotranspiration especially in summer when the temperature is high this requires farmers to collect more runoff from the waterways which then directly lessens the runoff additionally more than 30 of the entire south korea population is concentrated in the study area where water consumption is high to meet the needs of the people the relative influences of climate change on hydrological drought are stronger than those of human activities at the six month and 12 month time scales because meteorological drought enters into the hydrological cycle due to lack of precipitation throughout the region and can propagate into hydrological drought along the drainage system at longer time scales van loon et al 2014 the propagation process from meteorological drought to hydrological drought is mostly affected by climate change at longer time scales because climate change is a long term process jehanzaib and kim 2020 jehanzaib et al 2020b 5 conclusions this study quantified the relative contributions of climate change and human activities to hydrological drought in the han river basin of south korea by adopting a non stationary framework which is an advancement over past studies the change points in the non linear annual hydrological time series were detected by a heuristic segmentation method and the natural streamflow series was constructed using the abcd lumped hydrological model finally a non stationary standardized runoff index was modeled using the gamlss algorithm which was further employed for analyzing the impact of environmental drivers on hydrological drought at various time scales the primary findings are summarized below 1 the change points in the annual streamflow series of all four watersheds were detected during the period 1997 2002 the slope of the trend of precipitation increased at the rate of 7 56 mm yr on average before the change points and decreased at the rate of 31 25 mm yr after the change point in all the watersheds a significant increase in potential evapotranspiration was observed after the change points with an average value of 2 73 mm yr streamflow also revealed significant decreasing trend in all the watersheds after the change points with an average value of 25 1 mm yr 2 hydrological drought was substantially influenced by climate variation and human activities but the impacts of these drivers varied on different time scales on the seasonal time scale e g three month human activities significantly affected production of hydrological drought especially in the summer and fall seasons whereas climate change was the dominant driving force in the other two seasons and also on longer time scales 6 and 12 months this study discussed the impacts of climate variation and human activities on hydrological drought further analysis is needed to quantify the impacts of individual factors such as precipitation temperature evapotranspiration population urbanization and agricultural irrigation on hydrological drought the findings of this research will be very useful for drought management decision making and risk assessment under varying environments credit authorship contribution statement muhammad jehanzaib formal analysis methodology writing original draft sabab ali shah investigation visualization jiyoung yoo visualization validation tae woong kim conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the korea environment industry technology institute keiti through the advanced water management research program funded by the korea ministry of environment grant 83070 and the national research foundation of the korean government grant no nrf 2020r1c1c1014636 the first author is thankful to the higher education commission hec and the government of pakistan for the scholarship under the project hrd initiative ms leading to ph d program of faculty development for uestps phase 1 and batch v for hanyang university south korea appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125052 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5314,climate variation and human activities are two prime drivers influencing the hydrological cycle and the stationarity of hydrologic systems hydrological drought is caused by significant negative variation from normal hydrologic conditions influenced by climate variation and human activities traditional methods employed for quantifying the impacts of climate change and human activities are based on the assumption of stationarity which is no longer valid under the current changing environment in this study a heuristic segmentation method was used to identify the change point in streamflow time series by considering its non linearity and trend analysis was performed on hydro meteorological variables before and after the change point a non stationary standardized runoff index srins was constructed using generalized additive models in location scale and shape gamlss finally the influences of climate change and human activities on hydrological drought were quantified at various time scales the results reveal change points in the streamflow time series after the 1990s significant decreases in precipitation and streamflow were also observed after the change points in all study watersheds whereas the trend of potential evapotranspiration increased at a higher rate after the change points the impact of climate change on the seasonal three month time scale was greater in the winter and spring seasons whereas the impact of human activities was significantly higher in the summer and autumn seasons the influence of climate change on hydrological drought was dominant at longer 6 and 12 month time scales whereas human activities accounted for 25 6 and 20 of the changes in watersheds 1018 and 1019 on the 12 month time scale respectively keywords climate change hydrological drought human activities heuristic segmentation method non stationarity 1 introduction drought is documented as a composite natural phenomenon that commonly begins with a lack of precipitation leading to deficits in soil moisture storage due to evapotranspiration and river flow adversely affecting plant growth and human life li et al 2013 among various natural disasters reoccurring drought is one of the most impactful having negative impacts on the economy environment and society mishra and singh 2010 for example the 2012 drought in the united states resulted in economic losses of over usd 12 billion and indirectly affected global food prices crutchfield 2012 drought is classified into four categories meteorological agricultural hydrological and socioeconomic based on types of water deficit in precipitation soil moisture storage streamflow and water resources heim 2002 of these categories hydrological drought that is caused by inadequate surface or subsurface water resources is considered the most important shukla and wood 2008 van loon 2015 because various sectors such as agriculture urban life industry and hydropower generation depend mainly upon surface water resources vasiliades et al 2011 a remarkable change has been observed in the global climate over the last century the hydrological cycle and its available water resources are greatly influenced by climate change the consequences of which give rise to extreme natural disasters such as floods and droughts dai 2013 increased evapotranspiration due to rise in temperature without enhancement in precipitation has heightened the intensity and frequency of hydrological droughts in the 21st century worldwide sheffield et al 2012 dai 2013 in addition to climate change the impacts of human activities on hydrological drought are undeniable agricultural irrigation water extraction land use cover changes urbanization industrialization and reservoir regulation alter hydrological cycles which eventually result in variability of hydrological drought characteristics sheffield et al 2012 van loon et al 2016 the most common method of characterizing drought is development of a suitable drought index with which to identify drought and its characteristics and to evaluate its quantitative impacts heim 2002 dai et al 2020 gu et al 2020a b jehanzaib and kim 2020 various drought indices have been proposed including the standardized precipitation index spi the standardized precipitation evapotranspiration index spei the palmer drought severity index pdsi and the standardized runoff index sri the sri is extensively used for monitoring hydrological drought due to its simplicity in computation relatively low data requirements and comparability at various time scales shukla and wood 2008 moreover the sri involves information about environmental conditions as well as human interruptions within watersheds zhang et al 2018 calculation of the sri requires fitting suitable probability distributions to runoff time series based on the assumption of stationarity however due to intensification of climate variation and anthropogenic activities that assumption is no longer valid zou et al 2018 under non stationary circumstances drought characteristics estimated using stationary drought indices might be inaccurate therefore it is necessary to establish an adequate non stationary drought index for reliable quantification of hydrological drought under changing environments accordingly this study adopted the generalized additive models for location scale and shape gamlss proposed by rigby and stasinopoulos 2005 to model runoff time series with non stationary marginal distributions there has been considerable attention focused on the effects of climate change and human activities on streamflows mccabe and wolock 2011 ahn and merwade 2014 saidi et al 2018 yuan et al 2018 mccabe and wolock 2011 found that precipitation has the predominant impact on streamflow after examining the separate impacts of precipitation and temperature on streamflow variability in the united states ahn and merwade 2014 concluded that the impact of human activities varies spatially after investigating the impact of environmental variation on streamflows in four u s states using three different methods saidi et al 2018 found that climate change accounted for an 85 decrease in runoff and remaining changes were caused by land use cover change in alpine river yuan et al 2018 reported noticeable anthropogenic climate change fingerprints on the changes in annual streamflow in yellow river basin china in addition margariti et al 2019 found that human activities increase drought termination rates in all case studies of europe however as discussed by zhang et al 2018 studies concerning the impacts of natural and anthropogenic activities on hydrological droughts are still rare moreover previous studies that investigated the impact of environmental changes on hydrological droughts were based on the assumption of stationarity which is no longer valid under changing environments as the influences of climate variation and human activities change over time dai 2013 it is important to examine their impacts on hydrological droughts at various time scales to date there have been few studies that appraised the impacts of climate variation and human activities on hydrological droughts at multiple time scales considering the non stationarity of hydrological variables zou et al 2018 even though the key point of environmental impact assessment studies was to calculate change points from the standpoint of non stationarity the main downside of previous studies was the use of conventional methods to calculate change point in the streamflow time series jiang et al 2019 zhang et al 2018 zou et al 2018 jehanzaib et al 2020a therefore there is a need to develop a framework which is entirely based on non stationary approaches for reliable evaluation of environmental changes on hydrological drought the innovative feature of this study as contrasted with other studies is to adopt a non stationary framework for evaluating the impacts of climate change and human activities on hydrological droughts at multiple time scales the non stationary framework can consider the uncertainty of environmental conditions and provide an estimate of environmental effects on hydrological drought the primary objectives are 1 to apply a non stationary heuristic segmentation method for detecting change points in streamflow time series 2 to reconstruct natural runoff time series based on water balance 3 to develop a non stationary sri using a gamlss algorithm and 4 to evaluate both climatic and human impacts on hydrological drought in the han river basin of south korea 2 study area and data in this study four watersheds of the han river basin were selected as shown in fig 1 more than 75 of the population of the han river basin is concentrated in these watersheds which cover drainage areas ranging from 605 to 1537 km2 with an average elevation of 150 m the annual average temperature and annual average precipitation of the study area are 12 c and 1300 mm respectively during the period 1973 2016 lee et al 2019 the geographic features water usage and population density of the studied watersheds are presented in table 1 the meteorological data of daily precipitation and temperature for the period 1973 2016 were collected from the korea meteorological administration kma https www data kma go kr the thiessen polygon method was adapted to convert point data into watershed scale the daily streamflow data of hydrological stations that lie in the study area were collected from the water resources management information system wamis http www wamis go kr main aspx for the period 1966 2016 the annual water usage and water demand data were also collected from the wamis for the period 1970 2016 the gross domestic product gdp and population data of the study area were obtained from the statistics korea http www kosis kr for the period 1970 2016 3 methodology the complete framework of the study is shown in fig 2 3 1 heuristic segmentation method to investigate the effects of climate change and human activities on hydrological droughts it was necessary to divide the streamflow time series into natural and human impacted periods statistical methods that are widely used to estimate the change point in the time series are mann kendall test pettitt test rank sum test sliding f test and sliding t test all these methods are based on the hypothesis that the samples come from the linear process however hydrological variables are highly nonlinear due to the variability of hydrological processes this results in challenges when trying to identify real change points using the existing techniques hence in this study the heuristic segmentation algorithm based on the concept of the sliding t test was modified to identify change points in the annual streamflow time series of the han river basin following the methods of pedro et al 2001 a sliding pointer was gradually displaced from left to right throughout the entire time series to partition the non stationary time series into several stationary sections the mean of the series on the two sides μ1 and μ2 of the pointer was then calculated for two normally distributed random series the significance of the distinction between the average values of the two series was calculated by the student s t test statistic as in eq 1 1 t μ 1 μ 2 s d 2 s d n 1 1 s 1 2 n 2 1 s 2 2 n 1 n 2 2 1 2 1 n 1 1 n 2 1 2 where sd is the pooled variance n 1 and n 2 are the numbers of data points in the two series and s 1 and s 2 are the standard deviations of the two series the position of the pointer that produced the maximum value of the t statistic was determined the maximum value t max indicates that the averages of the two series are significantly different and is a good indicator of a change point huang et al 2016 finally the statistical significance of that maximum value p t max was computed note that p t max is not a result of the standard student s t test press et al 1988 because sample series are not autonomous and cannot be obtained in a closed analysis therefore p t max was mathematically estimated by eq 3 3 p t max 1 i v v t max 2 φ v φ η where v n 2 n is the total number of time series i a x y is an incomplete beta function η 4 19 ln n 11 54 and φ 0 40 according to monte carlo simulation the time series will split if the difference between the mean values is statistically significant i e it is greater than the threshold normally set as 0 95 and vice versa zhang et al 2019 we continued to iterate the above process on the sub series after splitting the original time series until the significance value was less than the 0 95 3 2 sen s slope estimator sen s slope estimator is a nonparametric linear method that is widely used for calculating the slope of trend in hydro meteorological time series da silva et al 2015 jehanzaib et al 2020a first a series with a linear slope is estimated by eq 4 4 s i y i y j i j f o r k 1 n where y i and y j are the data values at times i and j i j respectively the n values of slope s i are arranged in ascending order and the median of slope b med is estimated by eq 5 5 b med m e d i a n s i the value of b med shows the gradient and its sign shows the direction negative or positive of the trend we used sen s slope estimator in this study to estimate the trends of precipitation potential evapotranspiration and streamflow time series before and after the detected change points 3 3 hydrological modeling it is necessary to reconstruct natural streamflow time series using a hydrological model for human impact assessment among various hydrological models with different strengths and limitations the abcd model proposed by thomas 1981 is one of the most extensively used as a lumped conceptual model the abcd model integrates a highly realistic illustration of the infiltration process and is employed in many studies saidi et al 2018 zhang et al 2018 jehanzaib et al 2020a this model consists of two moisture storage compartments such as soil moisture storage in the upper layer and groundwater storage in the lower layer as shown in fig 3 with four parameters i e a b c and d the abcd model generates streamflow as output taking monthly precipitation and monthly potential evapotranspiration pet as input zhang et al 2018 in our study pet was estimated using the most common temperature based hargreaves method hargreaves and samani 1985 the abcd model was calibrated using a genetic algorithm for the natural period and then used for simulation in the impacted period the efficiency of the abcd model was calculated based on three performance assessment criteria nash sutcliffe efficiency nse kling gupta efficiency kge and water balance error wbe nash and sutcliffe 1970 gupta et al 2009 6 nse 1 i 1 n q obs i q sim i 2 i 1 n q obs i q obs 2 7 kge 1 1 r 2 1 θ 2 1 ϕ 2 8 wbe i 1 n q obs i q sim i i 1 n q obs i where r is the pearson correlation coefficient θ σ s σ o is the relative variability ϕ μ s μ o is the bias ratio between observed streamflow q obs and simulated streamflow q sim and n is the total number of observations σ o and μ o are the standard deviation and mean of the observed streamflow respectively σ s and μ s are the standard deviation and mean of the simulated streamflow respectively the nse and kge measure correlation and overall fitness respectively with optimal values of one the wbe measures under prediction or over prediction with an optimal value of zero between observations and simulations 3 4 standardized runoff index the standardized runoff index was originally proposed by shukla and wood 2008 and is widely used for monitoring and evaluating hydrological drought the calculation of the sri involves fitting a two parameter lognormal distribution as suggested by nalbantis and tsakiris 2009 to long term streamflow data the cumulative distribution function cdf of the fitted marginal distribution is transformed into a standard normal variate z using eq 9 9 sri t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 t c 0 c 1 t c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 t ln 1 f x 2 0 f x 0 5 t ln 1 1 f x 2 0 5 f x 1 where f x is the cdf of the marginal distribution and c0 c1 c2 d1 d2 and d3 are constants once the sri is computed using eq 9 hereafter denoted as sric drought severity is divided into five classes based on index value i e sri 0 no drought 1 sri 0 mild drought 1 5 sri 1 moderate drought 2 sri 1 5 severe drought and sri 2 extreme drought 3 5 non stationary standardized runoff index it is challenging to deal with hydrological data due to rapidly changing environmental conditions which lead to non stationarity in this study the non stationary standardized runoff index srins was defined analogously to the sric but the long term streamflow data were fitted to a non stationary marginal distribution with time varying parameters the generalized additive models in location scale and shape gamlss proposed by rigby and stasinopoulos 2005 is widely used for analyzing non stationary behavior of time series the general distribution functions supported by gamlss are discrete highly skewed and or kurtotic continuous distributions in the gamlss algorithm the time series y t of time t 1 2 n are assumed to be independent and are fitted to a probability distribution function f y t α t conditional on α t α 1 t 1 α 2 t 2 α p tn representing a vector of p distribution parameters at time t the distribution parameters account for the location scale and shape associated with explanatory variables via the monotonic link function η k given by eq 10 10 η k α k x k θ k θ 0 k θ 1 k x θ qk x q k 1 2 p where x k represents the explanatory variables θ k are polynomial coefficients p is the number of parameters and q is the degree of the polynomial in this study a long term streamflow time series was fitted to a non stationary lognormal distribution with its location parameter μ linked with time the optimal degree of the polynomial was selected based on the akaike information criterion aic finally the cdf of the non stationary distribution was transformed into a standard normal variate using eq 9 the calculations regarding gamlss modeling were performed using the gamlss package in r software stasinopoulos and rigby 2007 3 6 quantification of effects of natural and human activities on hydrological drought climate change and human activity are two main factors that alter hydrological cycle processes the overall influence of these factors on runoff can be expressed mathematically as follows 11 δ q total δ q climate δ q human where δ q total δ q climate and δ q human represent total variation in runoff variation in runoff due to climate change and variation in runoff caused by human activities respectively the runoff simulated by the hydrological model after calibrating its parameters in the natural period represents natural runoff and the runoff observed after the change point represents the influence of human activities zhan et al 2014 therefore it is reasonable to presume that variations in hydrological drought might be equivalent to those shown in runoff because the hydrological drought is derived from runoff time series wang et al 2015 in this study the sri was applied to reconstructed natural runoff by the abcd model to characterize changes in hydrological drought due to climate change which was denoted as srirecon the srins was constructed using the gamlss algorithm to characterize total variation in hydrological drought resulting from both climate change and human activates finally the contribution of human activities to hydrological drought was calculated as the difference between srins and srirecon which was denoted by sriha the percentage impacts of climate change pcc and human activities pha on hydrological drought were calculated using eqs 12 and 13 12 pcc sri recon sri ha sri recon 100 13 pha sri h a sri ha sri recon 100 where sri recon and sri ha are absolute values of sum of values of srirecon and sriha respectively 4 results and discussion 4 1 identification of change points according to the fifth assessment report ar5 of the intergovernmental panel on climate change ipcc the global average surface temperature is likely to increase by 3 7 c by the end of the 21st century ipcc 2013 a rise in surface temperature leads to high evaporation into the atmosphere which alters hydrological processes detection of change points in this process is important to estimate changes in hydrological regimes we adopted a non stationary heuristic segmentation algorithm to detect change points in annual streamflow series of the han river basin the change points in watersheds 1018 and 1019 were observed after 1995 whereas those in watersheds 1015 and 1016 were observed after 2000 as shown in fig 4 a significant decrease in precipitation and an increase in potential evapotranspiration were observed after these detected change points which is evidence that the streamflow was directly influenced by these drivers moreover more than 85 of the population of the han river basin lives in watersheds 1018 and 1010 which has indirect influences on streamflow our change point findings were in accordance with those of jehanzaib et al 2020a which showed change points in the han river basin after the 1990s table 2 clearly indicates that the p values in watersheds 1015 1016 and 1018 were greater than the selected threshold 0 95 in watershed 1019 though the value of p t max was slightly less than the selected threshold it was nevertheless considered a probable change point the results of the heuristic segmentation algorithm showed that the annual streamflow series of the han river basin was significantly affected by varying environmental conditions during the study period 4 2 trend analysis due to climate change variations in precipitation and potential evapotranspiration were observed throughout the study area trend analyses were performed for annual precipitation potential evapotranspiration and streamflow series before and after the detected change points using sen s slope test the trend analysis showed that annual precipitation increased before the change point in all the watersheds with an average value of 7 56 mm yr after the change point there were significant reductions in annual precipitation averaging 31 25 mm yr similarly there was a significant increase in potential evapotranspiration after the change point with an average value of 2 73 mm yr fig 5 summarizes the results of trend analyses of precipitation and potential evapotranspiration in watersheds 1016 and 1018 the variation in streamflow time series observed throughout the study area was due to significant variation in environmental conditions the results indicate that streamflow decreased at an average rate of 2 48 mm yr before the change point after the change point the streamflow began to decrease significantly at an average rate of 25 1 mm yr the results of trend analysis are in accordance with those of bae et al 2008 the comprehensive results of trend analysis of streamflow in all the watersheds are shown in fig 6 4 3 streamflow simulation by hydrological model the abcd model was calibrated and validated in the natural period before reconstructing natural runoff in the human impacted period the performance of the abcd model in the four watersheds is shown in fig 7 the results reveal that the abcd model accurately presented the natural conditions with the nse greater than 0 90 in both calibration and validation periods in all the watersheds these findings are in accordance with zhang et al 2018 in which the nse ranged from 0 87 to 0 93 in china similarly the value of kge was greater than 0 90 in all the watersheds in the calibration period in the validation period the average value of kge in all the watersheds was greater than 0 85 evidence that the abcd model was able to perform accurate simulations in the human impacted period the comprehensive results of all performance measures kge nse and wbe in both calibration and validation periods of all the watersheds are shown in table 3 the wbe in all the watersheds for both calibration and validation periods was less than 0 additional evidence of a good fit based on the performance indicators the abcd model produced robust estimates of monthly streamflows in all the watersheds during both calibration and validation periods 4 4 modeling with the gamlss algorithm the monthly streamflow series was fitted to a non stationary two parameter lognormal distribution using the gamlss algorithm to construct a probabilistic model the location parameter of the distribution varied as a polynomial function of time in this study the degree of the polynomial q was less than 4 to avoid convolution and provide adequate flexibility to describe the fluctuation the optimal time varying model was selected at each time scale for each watershed based on minimum aic the results of two watersheds at three month seasonal six month biannual and 12 month annual time scales in july are shown in fig 8 as this was the month of highest variation in streamflow fig 8 shows that the gamlss algorithm is able to capture the variation in streamflow data because most of the points of both watersheds lie between the 5 and 95 centile curves on different time scales the results of these centile plots are in accordance with wang et al 2015 and bazrafshan and hejabi 2018 and confirm that the selected models fairly characterized the variability of data at various time scales finally the results of the non stationary log normal probability distribution with time varying parameters were compared with the log normal probability distribution with stationary parameters at various time scales due to space limitation only the comparative results of the conventional and non stationary probability distributions in watershed 1018 are shown in fig 9 the non stationary probability distribution more accurately presented the actual conditions than did the conventional probability distribution at all time scales and can be used for drought calculation in the human impacted period 4 5 quantifying the impacts of climate change and human activities on drought the influence of climate variation and anthropogenic activities on hydrological drought was investigated at seasonal biannual and annual time scales by calculating sri and srins for the natural and human impacted period respectively seasonal sri was calculated at the three month time scale to observe the influence of the four seasons the six month sri calculated for june was selected for biannual analysis and the 12 month sri calculated for december was chosen for annual analysis the percentage contributions of climate variation pcc and human activities pha to hydrological drought were investigated using eqs 12 and 13 as an example the independent impacts of climate change and anthropogenic activities on hydrological drought in watershed 1018 at various time scales are shown in fig 10 the comprehensive results of all the watersheds demonstrating the impacts of climate variation and human activities are summarized in table 4 these results demonstrate that the impact of climate change was high at all time scales but the human impacts were significantly stronger at the seasonal time scale especially in summer and fall the greatest anthropogenic effect was observed in summer 47 1 38 6 and 44 6 of the overall effect in watersheds 1015 1018 and 1019 respectively at the seasonal time scale at the biannual time scale the impact of climate change was significantly high 85 while the impact of human activities was less than 30 in all the watersheds at the annual time scale the results of this research are in general accordance with jehanzaib et al 2020a in south korea which stated that the impact of human activities on hydrological drought was less than 10 the results of our study followed similar trends but showed higher human impacts 4 6 discussion the majority of relevant studies in the literature address the impacts of climate variation and human activities on hydrological drought based on the assumption of stationarity of the hydrologic system jiang et al 2019 zhang et al 2018 however due to significant human interventions this assumption is no longer valid and is the main drawback of previous studies hence non stationary approaches were adopted in this study to estimate the contribution of human activities to hydrological drought in recent decades in our study area the population has increased gradually while the gdp has increased rapidly as shown in fig 11 a this sudden increase in gdp occurred after the 1990 s due to significant human interventions such as changes in land use land cover industrialization urbanization reservoir regulation and agricultural irrigation similarly fig 11 b shows that most of the increase in water usage in the study area occurred after the 1990s interestingly the figure shows that water demand was much higher than water usage toward the end of the 1970 2016 which is evidence that the study area was already facing water shortages in 2016 likely because more than 85 of the population of the han river basin is densely crowed in these watersheds this viewpoint was verified by estimating change points in the streamflow series using a non stationary heuristic segmentation method relevant change points were detected after the 1990s by 2016 less water was being used for agriculture because of use of modern irrigation technologies which allowed more water to be allocated to the domestic sector to fulfill the needs of people the impact of human activities was significant at the seasonal time scale especially in spring summer and fall because the most important crop in this area is rice which is usually sown from mid april to mid july and harvested from september to november the rice crop needs intensive flood irrigation which may cause high evapotranspiration especially in summer when the temperature is high this requires farmers to collect more runoff from the waterways which then directly lessens the runoff additionally more than 30 of the entire south korea population is concentrated in the study area where water consumption is high to meet the needs of the people the relative influences of climate change on hydrological drought are stronger than those of human activities at the six month and 12 month time scales because meteorological drought enters into the hydrological cycle due to lack of precipitation throughout the region and can propagate into hydrological drought along the drainage system at longer time scales van loon et al 2014 the propagation process from meteorological drought to hydrological drought is mostly affected by climate change at longer time scales because climate change is a long term process jehanzaib and kim 2020 jehanzaib et al 2020b 5 conclusions this study quantified the relative contributions of climate change and human activities to hydrological drought in the han river basin of south korea by adopting a non stationary framework which is an advancement over past studies the change points in the non linear annual hydrological time series were detected by a heuristic segmentation method and the natural streamflow series was constructed using the abcd lumped hydrological model finally a non stationary standardized runoff index was modeled using the gamlss algorithm which was further employed for analyzing the impact of environmental drivers on hydrological drought at various time scales the primary findings are summarized below 1 the change points in the annual streamflow series of all four watersheds were detected during the period 1997 2002 the slope of the trend of precipitation increased at the rate of 7 56 mm yr on average before the change points and decreased at the rate of 31 25 mm yr after the change point in all the watersheds a significant increase in potential evapotranspiration was observed after the change points with an average value of 2 73 mm yr streamflow also revealed significant decreasing trend in all the watersheds after the change points with an average value of 25 1 mm yr 2 hydrological drought was substantially influenced by climate variation and human activities but the impacts of these drivers varied on different time scales on the seasonal time scale e g three month human activities significantly affected production of hydrological drought especially in the summer and fall seasons whereas climate change was the dominant driving force in the other two seasons and also on longer time scales 6 and 12 months this study discussed the impacts of climate variation and human activities on hydrological drought further analysis is needed to quantify the impacts of individual factors such as precipitation temperature evapotranspiration population urbanization and agricultural irrigation on hydrological drought the findings of this research will be very useful for drought management decision making and risk assessment under varying environments credit authorship contribution statement muhammad jehanzaib formal analysis methodology writing original draft sabab ali shah investigation visualization jiyoung yoo visualization validation tae woong kim conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the korea environment industry technology institute keiti through the advanced water management research program funded by the korea ministry of environment grant 83070 and the national research foundation of the korean government grant no nrf 2020r1c1c1014636 the first author is thankful to the higher education commission hec and the government of pakistan for the scholarship under the project hrd initiative ms leading to ph d program of faculty development for uestps phase 1 and batch v for hanyang university south korea appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125052 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
