index,text
5320,the streamflow from the headwater areas of the tibetan plateau tp provides critical support for downstream regions yet understanding of the streamflow complexity on the tp which is essential for hydrological modeling and water resource management remains scarce this study aims to measure streamflow complexity in the headwater areas of the tp and investigate the coupling effects of climatic variables i e precipitation and air temperature on the streamflow complexity across multiple timescales using daily streamflow records we employ permutation entropy as the measure of annual streamflow complexity in the upper heihe river uhr watershed in the northeastern tp from 1960 to 2014 additionally wavelet coherence is applied to evaluate the impact of climate i e precipitation and temperature change our results show 1 due to climate change streamflow complexity has significantly increased since 1972 in the uhr watershed 2 the periods of warmer and wetter weather have a longer term influence on streamflow complexity specifically before 1972 dryer colder weather in the tp would significantly affect the complexity of the streamflow every three to four years but after that date these climatic events occurred less frequently with gaps of between eight and twelve years during which the weather was much warmer and wetter and 3 the influence of precipitation on the streamflow complexity decreased while that of air temperature increased therefore the impact of climate change on streamflow complexity relating to the dynamic structure of streamflow should be regarded as significant to the work of hydrologists and water resource management agencies keywords climate change streamflow complexity permutation entropy wavelet analysis tibetan plateau 1 introduction the tibetan plateau tp sometimes known as the asian water tower is the origin of the major asian rivers yangtze yellow indus and ganges xu et al 2008 it is also one of the most sensitive and vulnerable regions on earth with regard to climate change brown et al 2007 immerzeel et al 2010 streamflow from the headwater areas on the tp continuously provides essential water resources that support the habitation socio economic development and ecosystem services of 1 4 billion people bibi et al 2018 milly et al 2005 oki and kanae 2006 affected by anthropogenic activity climate change and the landscape streamflow exhibits typical nonlinear behavior which varies in both time and space parajka et al 2013 sivakumar 2009 sivakumar and singh 2012 zhang et al 2016 zhang et al 2017 thus the term streamflow represents a typical complex hydrological system streamflow complexity is defined as the variability and uncertainty of streamflow and reflects the dynamic structure of streamflow singh 1997 sivakumar and singh 2012 therefore measuring streamflow complexity in the tp and investigating its temporal changes is vital to improving our understanding of the hydrometeorological process not just in the affected areas but across the globe there have been numerous efforts to study streamflow complexity in recent decades ranging in scale from a single river to an entire continent huang et al 2017 mihailović et al 2019 sen 2009 serinaldi et al 2014 srivalli et al 2019 most studies concentrate on streamflow complexity in the middle and downstream areas huang et al 2011 srivalli et al 2019 stosic et al 2016 wang et al 2020 zhang et al 2012 rather than at the headwater and information on streamflow complexity at headwaters remains scarce though these areas represent a critical stage in the hydrological cycle and land surface system meanwhile existing work looks at how streamflow complexity is affected by human activity such as reservoir operations huang et al 2011 liu et al 2017 zhang et al 2019a dam construction luo et al 2019 stosic et al 2016 zhang et al 2012 zhou et al 2012 and land use land cover changes li and zhang 2008 liu et al 2018 in addition researchers have used streamflow complexity as a metric for the evaluation of hydrological changes jovanovic et al 2017 catchment classification sivakumar and singh 2012 and basin complexity pande and moayeri 2018 however the effect of climate change on the streamcomplexity is unclear the streamflow complexity of the tp is significant due to the mountainous landscape and sophisticated cryospheric changes in this region the headwater areas of the tp are typical alpine watersheds with a wide distribution of permafrost glaciers and snow covered mountains the snow and glacier melt not only provide critical water resource to the downstream areas in dry seasons but also add to the streamflow complexity huss and hock 2018 singh and bengtsson 2005 wulf et al 2016 the lack of in situ observations and measurements has restricted our understanding of the streamflow in mountainous glacial alpine watersheds wang et al 2019 to improve our understanding of the hydrological system in the tp it is crucial to measure the streamflow complexity in the headwater areas of this region furthermore our understanding of the influence of climate change on streamflow complexity is also insufficient the tp as one of the world s regions with the most significant climate change chen et al 2015 kuang and jiao 2016 is still lacking studies that investigated the impact of climate change on sections of the streamflow complexity in the tp observation data analyses and model simulations show that the air temperature in the tp has increased significantly during the last 50 years kuang and jiao 2016 you et al 2016 zhong et al 2011 and the warming rate is twice the global average over the same period chen et al 2015 meanwhile despite the substantial spatial heterogeneity of precipitation on the tp the overall precipitation has also slightly increased kuang and jiao 2016 compared with the air temperature the impact of precipitation on the streamflow complexity has attracted more attention because of its significant role in the hydrological cycle chou 2014 huang et al 2011 pan et al 2012 however the air temperature is also likely to affect the hydrological cycle by changing the processes in the cryosphere biosphere and atmosphere cuo et al 2015 deng et al 2017 gao et al 2018 investigating the impact of climate i e air temperature and precipitation change on the streamflow complexity will also expand our knowledge of hydrothermal interaction in cold and arid regions the impact of climate variables i e precipitation and air temperature on streamflow complexity also has multi timescale characteristics liu et al 2019 chou found that the complexity of the rainfall runoff coefficient series which indicates the precipitation streamflow relationship increased along with the increase of scale factor chou 2012 huang et al 2017 analyzed a streamflow series and also found that the streamflow complexity increased from daily to seasonal timescales streamflow precipitation and air temperature individually also show different characteristics at diurnal monthly seasonal annual and decadal timescales büntgen et al 2005 jones et al 1999 sang et al 2009 sharifi et al 2018 su et al 2017 given the lack of relevant works new research probing the influence of precipitation and air temperature at multiple timescales is necessary for additional insight into streamflow complexity this study has two main objectives 1 to measure the streamflow complexity and understand its changes in the headwater area of the tp and 2 to investigate the impact of climate change on the streamflow complexity at multiple timescales to achieve these objectives we used a capable and robust entropy based measure permutation entropy pe to quantifying streamflow complexity in the tp we also used the mann kendall test to evaluate the trends and change points of the complexity and wavelet transform coherence wtc which is a scale dependent and reliable method to analyze localized scattered periodicities of the influence of precipitation and air temperature in particular we focused on the upper heihe river uhr basin on the northeast tp the streamflow from the uhr basin accounts for approximately 70 of the total streamflow in the heihe river the paper is organized as follows in section 2 we introduce the study area and data in section 3 we describe pe the mann kendall test and wtc the main results of this study are presented in section 4 and finally we provide discussion and conclusions in sections 5 and 6 respectively 2 study area and data 2 1 study area as the headwater of the heihe river basin hrb the uhr watershed fig 1 provides most of the water supply for the hrb the second largest inland river in china the two tributaries of the uhr the babaohe river bbr and the yeniugou river yngr converge into the mainstream and cross the qilian mountains at the yingluoxia ylx gauging station into the middle reaches of the heihe river the average annual mean temperature in the uhr basin ranges from 9 c to 5 c and the average annual precipitation exceeds 400 mm the uhr watershed is a typical alpine glacial region with wide distribution of permafrost and seasonal frozen ground it locates in the qilian mountains on the northeastern edge of the tp and has experienced significant climate change the climate in the uhr basin has been getting warmer and wetter in recent decades tree ring based reconstructed temperature series suggest that the 20th century was the warmest 100 years in the area s history wang et al 2016 moreover the upward trend of the air temperature has become steeper since the 1980 s wang et al 2010 meanwhile precipitation has also experienced a significant increase at a rate of 1 04 mm year from 1961 to 2016 zhong et al 2019 in addition glacier coverage areas in the uhr have declined from 66 3 km2 in 1990 to 13 37 km2 in 2010 generally attributed to climate change cai et al 2014 the lower limit of permafrost has climbed from 100 to 200 m and the permafrost has retreated 10 20 km along the major highways of the yngr watershed since 1985 wang et al 2017 the maximum thickness of the seasonal frozen ground has also decreased by about 20 cm wang et al 2015 2 2 data data used in this study include daily streamflow records from 1960 to 2014 and climatic data i e precipitation and air temperature from 1960 to 2014 daily streamflow records in the yingluoxia gauge station coordinates 38 49 12 n 100 10 48 e elevation 1700 m were obtained from the environmental and ecological science data center for west china http www heihedata org the climatic data consists of the daily mean air temperature and daily cumulative precipitation at three national meteorological stations qilian ql coordinates 38 10 48 n 100 15 0 e elevation 2787 4 m yeniugou yng coordinates 38 45 48 n 99 36 00 e elevation 3314 m and tuole tl coordinates 38 49 12 n 98 25 12 e elevation 3367 m these were downloaded from the national meteorological information center of the china meteorological administration http data cma cn it is worth noting that the precipitation data in this article include both rainfall and snowfall because of a lack of observation data for precipitation air temperature or streamflow in individual years we chose 1960 2014 as the joint period 3 methods 3 1 permutation entropy pe was proposed to finely measure the complexity of time series by bandt and pompe 2002 having no requirement for assumptions on linearity or normality entropy theory has been widely used to study and understand hydrological systems singh 1997 singh 2011 in recent decades various entropy methods have been employed to measure streamflow complexity such as sample entropy huang et al 2011 wang et al 2020 multi scale sample entropy huang et al 2017 li and zhang 2008 zhang et al 2012 wavelet based entropy sang et al 2011 shannon entropy castillo et al 2015 krasovskaia 1995 and kolmogorov entropy mihailović et al 2014 in contrast to these entropy measures pe considers the ordinal pattern of the values in a time series stosic et al 2016 due to its simplicity and robustness pe has attracted attention from researchers and been applied in hydrology and other domains including finance hou et al 2017 zunino et al 2009 meteorology zhang et al 2019b and bioinformatics zanin et al 2012 the calculation process of pe can be described as follows a given time series s i i 1 2 n s i represents the embedding vector s i s i τ s i d 1 τ where d denotes the embedding dimension and τ indicates the delay time we can sort the elements in vector s i in ascending order as s i j 1 1 τ x i j 2 1 τ s i j d 1 τ while the series j 1 j 2 j d denotes the indices of elements in s i in particular when there is equality in a time series we can sort them according to their original orders for instance if s i j t 1 1 τ s i j t 2 τ and j t 1 j t 2 then these two elements can be sorted as s i j t 1 1 τ s i j t 2 τ therefore the original vector s i can be mapped to a symbolic permutation π j 1 j 2 j d which is one of d possible permutations assuming the number of unique permutations is k the probability of each π denotes as p 1 p 2 p h the pe of the time series si is computed as h d h 1 k p h l n p h when p 1 p 2 p h 1 l n d h d has the maximum value l n d therefore the pe can be normalized as pe d h d ln d a normalized pe is restricted between 0 and 1 pe close to zero means the times series is a more deterministic increasing or decreasing series conversely a pe close to one means the time series is more random and chaotic before computing the pe of a time series it is split into non overlapping segments of short length and then the pe of each segment is computed changes in the pe measurements can be investigated to explore dynamic change in a time series the embedding dimension d usually depends on the observed phenomenon for useful statistics it is generally recommended to choose the maximum d according to n 5 d ribeiro et al 2012 for this study we computed the pe from the daily streamflow records of the yingluoxia gauge station for each calendar year the embedding dimension d and delay time τ were set to 4 and 1 respectively 3 2 mann kendall test the mann kendall test m k test is a nonparametric and robust method for detecting trends in time series originally proposed by mann 1945 and improved by kendall 1975 since it has been widely applied and verified in hydrological studies we employed it to identify the trends from the streamflow pe series a detailed description of the m k test can be found in hamed and ramachandra rao 1998 and sang et al 2014 3 3 wavelet transform coherence wavelet transform coherence wtc which describes the coherence of two time series can be regarded as a localized correlation coefficient between two time series in time and frequency space cazelles et al 2008 grinsted et al 2004 torrence and compo 1998 torrence and webster 1999 defined the wtc of two times series x and y as follows r n 2 s s s 1 w n xy s 2 s s 1 w n x s 2 s s 1 w n y s 2 where w n x s and w n y s denote the wavelet transformation of x and y respectively w n xy s denotes the cross wavelet transformation of x and y s is a smoothing operator depending on the wavelet used in general the smoothing operator s for a wavelet is written as s w s s s t w n s in which the s s and s t are smoothing along the wavelet scale axis and the time respectively w n s denotes the wavelet transformation of a time series where s indicates the wavelet scale factor r n 2 s denotes the value of wtc and ranges between 0 and 1 as with the correlation coefficient a value equal to zero depicts an independent two time series while the value equal to one depicts that the two times series perfectly co vary we estimated the statistical significance level of the wtc against a first order autoregressive red noise series assumption using monte carlo methods in this study the significance level was 0 05 it is worth noting that only the values outside the cone of influence coi are taken to estimate the significance level for each scale the coi indicates the areas in the wavelet coherence likely to be impacted by the edge effect artifacts we chose the morlet wavelet as the mother wavelet function owing to its balance between time and frequency grinsted et al 2004 more details of this method of computing wtc can be found in the work of grinsted et al 2004 4 results 4 1 streamflow complexity in the uhr watershed we applied a normalized pe measure on the daily streamflow records daily mean air temperature and daily cumulative precipitation in the uhr watershed to each year from 1960 to 2014 fig 2 in fig 2a the solid cyan red and yellow lines represent the annual pe of the air temperature the cyan red and yellow dashed lines represent the annual pe of the precipitation the blue line represents the pe of the streamflow from fig 2 it can be seen that the complexity of the streamflow in the uhr was a significantly nonstationary process that had a turning point in the year 1972 the m k test result showed an increasing trend in the streamflow complexity uf larger than 0 in fig 2 with the last changing point in 1972 there was an increasingly fluctuating trend in most years after 1980 in which the uf value was larger than the threshold 1 96 this phenomenon coincided with increasing air temperature in the eastern tp since the 1980s kuang and jiao 2016 therefore we partitioned the pe series into two different periods from 1960 to 1972 and from 1973 to 2014 in the first period the pe of the streamflow experienced a process of dramatic increase followed by a sharp decrease the average pe value during this period was 0 84 however the pe values after 1972 were higher and relatively stable the average pe value after 1972 was 0 89 this result suggests that after 1972 the dynamic features and structures of the streamflow in the uhr become more complex overall the complexity of the streamflow is essentially the dynamic between air temperature and precipitation notably after 1972 the pe of the streamflow was closer to that of the air temperature than before implying that the influence of the air temperature in the uhr watershed on the streamflow complexity may have increased after 1972 meanwhile we found that even the lowest pe 0 73 of streamflow was still higher than the pe of precipitation i e ql 0 61 yng 0 65 tl 0 51 in the corresponding year 1961 additionally it is worth noting that the pe troughs of streamflow and precipitation did not always occur at the same time the upward results indicate that the streamflow was a more complex uncertain and chaotic process than the precipitation in the uhr watershed we summarized the statistics table 1 and drew boxplots fig 3 of the pe of streamflow before and after 1972 before 1972 the mean median and quantiles of the pe of streamflow were located between those of air temperature and precipitation moreover the standard deviation of the streamflow s complexity was close to that of the precipitation while the streamflow had the most extensive range of complexity which indicates that the streamflow complexity varied greatly more dramatically than the air temperature and precipitation and its variation was more similar to the complexity of the precipitation after 1972 however it is clear that the statistics of the pe of streamflow were higher and more stable than before and the complexity of the air temperature remained steady while the range of the complexity of precipitation expanded this result implies that the streamflow complexity had increased and then stabilized in a stale phase after 1972 although the complexity of the air temperature was relatively stable the complexity of the precipitation varied greatly these changes in the streamflow complexity imply that the dynamic structure and uncertainty of streamflow may have changed to more complex and higher 4 2 impact of air temperature on streamflow complexity at multiple timescales to investigate the impact of the air temperature on the streamflow complexity we applied a wtc analysis of the annual mean air temperature and annual normalized pe of the streamflow fig 4 shows the result the black contours denote the 0 05 significance level against the red noise the shadow region denotes the coi the small arrows denote the relative phase relationship with in phase pointing right and anti phase pointing left in fig 4 two different bands of wavelet coherence show between the streamflow s complexity and air temperature for the streamflow complexity the wavelet coherence with the air temperature at three stations depicts high interannual covariance over a series of 2 4 year periods between 1962 and 1970 with the in phase however the wavelet coherence between the air temperature and streamflow complexity had a quasi decadal period during 1994 2008 with the anti phase with half of this region inside the coi considering the 5 high significance level and the vast region of wavelet coherence this quasi decadal period can extend to 1988 2012 this result indicates that the influence of air temperature on the streamflow complexity changes from a short timescale to a long timescale the change from in phase to anti phase indicates that the relationship between the air temperature and the streamflow complexity had to transform from a positive to a negative relation additionally we noticed that the wtc disappeared at tl station fig 4c which may imply that the role of air temperature in the marginal area of the uhr watershed was weakening because air temperature can accelerate the glacier melting rate permafrost degradation and the ratio of solid and liquid precipitation the indirect impact of temperature on the streamflow changed to more significant at the long timescale but at the marginal area the impact of temperature was weak due to the high latitude 4 3 impact of precipitation on the streamflow complexity at multiple timescales we also applied a wtc analysis to investigate the impact of precipitation on the streamflow complexity at multiple timescales the annual cumulative precipitation and the annual normalized pe of streamflow were used the result of the wtc between the precipitation and the streamflow complexity is shown in fig 5 the wavelet coherence between the precipitation and the streamflow complexity also exhibits two discrete regions there is a 2 4 year band of high covariance between 1964 and 1972 and the down arrows indicate that the precipitation led to a streamflow complexity of approximately 90 about 0 5 1 year the wtc between the precipitation and the streamflow complexity also had a long term 4 6 year band between 1988 and 2006 and the up arrows indicate that the precipitation led to a streamflow complexity of approximately 270 about 3 4 5 years the results show that although the degree of covariance between the precipitation and the streamflow complexity slightly weakened after 1972 the timescales and range both substantially extended in addition we found that the influence of precipitation at tl station on the streamflow complexity was significantly weaker than that at ql and yng stations this result is almost the same as the air temperature and may imply that the weakening impact of climate on the marginal area of the uhr maybe not be mere chance 4 4 climate change regarding the streamflow complexity to further investigate the possible impact of climate change on the observed shifts in streamflow complexity we conducted a comparative analysis between two specific periods the wtc analysis as mentioned above indicated that air temperature and precipitation both influence streamflow complexity but their different phases show that the influence changed before and after 1971 according to the regions with high wtcs of precipitation and air temperature we chose 1964 1970 and 1988 2012 for our two comparative time periods to illustrate the air temperature and precipitation changes in the uhr watershed the annual mean air temperature and annual accumulative precipitation anomalies relative to the 1960 2014 base period were calculated fig 6 shows the interannual variations of the air temperature and precipitation anomalies and the shadow regions indicate the two time periods with high wtcs before 1972 most air temperature and precipitation anomalies at the three stations were negative except for some discrete years additionally two low air temperature anomalies appeared during the 1964 1970 period with high wtcs the results demonstrate that a coupling impact of unusual low temperature and normal precipitation may create variations in streamflow complexity however more continuous and marked anomalies of air temperature and precipitation occurred after 1972 and especially after 1988 besides there were clear rising plateaus of air temperature anomalies at all three stations and two distinct rising plateaus of precipitation anomalies at the yng and tl stations interestingly the rising plateaus all emerged when the air temperature and precipitation had significantly high wtcs with the streamflow complexity these results suggest that there is a relationship between climate change and streamflow complexity table 2 provides the multi year average annual air temperature maat multi year average annual precipitation map average air temperature anomalies aata and average precipitation anomalies apa during the two periods with high wtcs it shows that all the average annual air temperatures at the three stations were relatively low and their anomalies were negative during 1964 1970 and the anomalies of average annual precipitation were also negative this result suggests that the area experienced a colder and drier process during this period during 1988 2012 all the average annual air temperatures and the average annual precipitation figures at the three stations were positive and increased from 0 86 to 1 15 c and 12 2 61 04 mm respectively these results suggest that the climate began to be warmer and wetter during 1988 2012 5 discussion the streamflow complexity of the uhr watershed was measured using pe based on 55 years of data on an annual scale although many studies have focused on the influence of climate change on streamflow or water availability barnett et al 2005 naz et al 2018 few have looked into the impact of climate change on the streamflow complexity however the relationship between precipitation and streamflow complexity has been discussed more chou 2014 huang et al 2011 though only a limited number have investigated how air temperature change impacts streamflow complexity in inland alpine glacier regions the results in this paper show that air temperatures also have a critical influence on stream complexity in a glacial alpine watershed first the streamflow complexity was shown to have changed in 1972 which is highly likely to be due to climate change the changes in streamflow complexity were distinct and generally detected in rivers affected by dam constructions stosic et al 2016 and reservoir operations zhang et al 2019a as there were no large scale dam constructions in the uhr watershed during the research period or other disturbances of the land use land cover this change was likely due to climate change in the region several studies have reported variations in the streamflow caused by climate change in the uhr since the 1980s cai et al 2014 gao et al 2018 luo et al 2016 our results also show that after 1972 and especially after 1988 the air temperature and precipitation had long term significant covariance with the stream complexity meanwhile the air temperature showed an upward trend at the watershed and precipitation increased fig 6 therefore climate change not only altered the volume of streamflow but also played a critical role in changing the streamflow complexity this find means that the temporal distribution of streamflow also can be altered by climate change hence it is critical for water management agencies of the arid and semi arid areas which are very sensitive to the temporal distribution of water resources to pay attention to the distribution changes of daily streamflow to improve better water resource regulation second air temperature impacted the streamflow complexity to a weaker degree but across longer timescales than precipitation the periods of higher air temperature and precipitation began to increase from around three to four years until they reached record lengths of up to twelve years a comparison of the two results of wtcs between air temperature and precipitation on streamflow complexity showed that although the degree of influence of air temperature significantly increased it was still relatively weaker than that of precipitation the complex hydrometeorological processes may have caused a longer timescale and weaker influence of air temperature in the alpine glacier watershed increasing air temperature can affect the streamflow in the uhr in three typical ways 1 it can accelerate the rate of glacier melting and positively affect the streamflow in glacierized watersheds barnett et al 2005 bibi et al 2018 2 it can lead to permafrost degradation and then affect the streamflow through the increase of base flow cuo et al 2015 qin et al 2016 and 3 it can change solid precipitation to liquid precipitation resulting in a decrease in snowpack and earlier snowmelt barnett et al 2005 berghuijs et al 2014 deng et al 2017 since all three are indirect and cover multiple land surface processes the impact of air temperature on streamflow complexity is weaker than for precipitation additionally the clearly weakened wtcs between the air precipitation the precipitation at the tl station and the streamflow complexity can be explained from two perspectives on the one hand the tl station is located far from the mainstream and tributaries and closer to another sub watershed and this could be why the effects of climate variables there decreased after 1988 on the other hand the extremely low temperatures and low precipitation climate events highly likely caused the significant wtcs between the air temperature precipitation at the three stations and the streamflow complexity during 1964 1970 hence the significant relationship between the climate variables at the tl station and the complexity of stream is evident for the large scale extreme climate event notably the results in this study did not consider all the possible affecting factors for the change of streamflow complexity such as vegetation variation and land use land cover change more influencing factors and their combination with climate change will be discussed in the future it is important to emphasize that the streamflow complexity showed low wtc with the air temperature and the precipitation may be caused by the low degree or slowly developing trend of climate change from 1972 to 1988 6 conclusions in this study we applied pe to measure streamflow complexity at the headwaters of the uhr watershed on the northeastern tp we found that the streamflow complexity in the uhr watershed had significantly increased since 1972 and could be explained by climate change the increase of streamflow complexity in the headwater area on the tp had not been uncovered in previous studies before 1972 periods of low precipitation and very low air temperatures occurred every 3 4 years however after 1972 and especially after 1998 greater precipitation and higher air temperatures over longer periods have impacted streamflow complexity therefore climate change has not only altered the streamflow but also increased its complexity our results indicate that the dynamic structure and features of streamflow have been transformed by climate change in the uhr watershed and this may well have significance for water resource management agencies and researchers investigating streamflow complexity in other headwater areas across the globe credit authorship contribution statement shi shen conceptualization methodology software data curation formal analysis writing original draft writing review editing changqing song conceptualization investigation supervision funding acquisition changxiu cheng conceptualization funding acquisition writing review editing sijing ye software validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank the prof zhang qiang for his constructive suggestions this work is supported by the national key research and development plan of china grant number 2019yfa0606901 the second tibetan plateau scientific expedition and research program step grant number 2019qzkk0608 national natural science foundation of china grant numbers 41801300 41901316 the fundamental research funds for the central universities grant number 2019ntst01 we would also like to thank the center for geodata and analysis faculty of geographical science beijing normal university https gda bnu edu cn for their high performance computing support 
5320,the streamflow from the headwater areas of the tibetan plateau tp provides critical support for downstream regions yet understanding of the streamflow complexity on the tp which is essential for hydrological modeling and water resource management remains scarce this study aims to measure streamflow complexity in the headwater areas of the tp and investigate the coupling effects of climatic variables i e precipitation and air temperature on the streamflow complexity across multiple timescales using daily streamflow records we employ permutation entropy as the measure of annual streamflow complexity in the upper heihe river uhr watershed in the northeastern tp from 1960 to 2014 additionally wavelet coherence is applied to evaluate the impact of climate i e precipitation and temperature change our results show 1 due to climate change streamflow complexity has significantly increased since 1972 in the uhr watershed 2 the periods of warmer and wetter weather have a longer term influence on streamflow complexity specifically before 1972 dryer colder weather in the tp would significantly affect the complexity of the streamflow every three to four years but after that date these climatic events occurred less frequently with gaps of between eight and twelve years during which the weather was much warmer and wetter and 3 the influence of precipitation on the streamflow complexity decreased while that of air temperature increased therefore the impact of climate change on streamflow complexity relating to the dynamic structure of streamflow should be regarded as significant to the work of hydrologists and water resource management agencies keywords climate change streamflow complexity permutation entropy wavelet analysis tibetan plateau 1 introduction the tibetan plateau tp sometimes known as the asian water tower is the origin of the major asian rivers yangtze yellow indus and ganges xu et al 2008 it is also one of the most sensitive and vulnerable regions on earth with regard to climate change brown et al 2007 immerzeel et al 2010 streamflow from the headwater areas on the tp continuously provides essential water resources that support the habitation socio economic development and ecosystem services of 1 4 billion people bibi et al 2018 milly et al 2005 oki and kanae 2006 affected by anthropogenic activity climate change and the landscape streamflow exhibits typical nonlinear behavior which varies in both time and space parajka et al 2013 sivakumar 2009 sivakumar and singh 2012 zhang et al 2016 zhang et al 2017 thus the term streamflow represents a typical complex hydrological system streamflow complexity is defined as the variability and uncertainty of streamflow and reflects the dynamic structure of streamflow singh 1997 sivakumar and singh 2012 therefore measuring streamflow complexity in the tp and investigating its temporal changes is vital to improving our understanding of the hydrometeorological process not just in the affected areas but across the globe there have been numerous efforts to study streamflow complexity in recent decades ranging in scale from a single river to an entire continent huang et al 2017 mihailović et al 2019 sen 2009 serinaldi et al 2014 srivalli et al 2019 most studies concentrate on streamflow complexity in the middle and downstream areas huang et al 2011 srivalli et al 2019 stosic et al 2016 wang et al 2020 zhang et al 2012 rather than at the headwater and information on streamflow complexity at headwaters remains scarce though these areas represent a critical stage in the hydrological cycle and land surface system meanwhile existing work looks at how streamflow complexity is affected by human activity such as reservoir operations huang et al 2011 liu et al 2017 zhang et al 2019a dam construction luo et al 2019 stosic et al 2016 zhang et al 2012 zhou et al 2012 and land use land cover changes li and zhang 2008 liu et al 2018 in addition researchers have used streamflow complexity as a metric for the evaluation of hydrological changes jovanovic et al 2017 catchment classification sivakumar and singh 2012 and basin complexity pande and moayeri 2018 however the effect of climate change on the streamcomplexity is unclear the streamflow complexity of the tp is significant due to the mountainous landscape and sophisticated cryospheric changes in this region the headwater areas of the tp are typical alpine watersheds with a wide distribution of permafrost glaciers and snow covered mountains the snow and glacier melt not only provide critical water resource to the downstream areas in dry seasons but also add to the streamflow complexity huss and hock 2018 singh and bengtsson 2005 wulf et al 2016 the lack of in situ observations and measurements has restricted our understanding of the streamflow in mountainous glacial alpine watersheds wang et al 2019 to improve our understanding of the hydrological system in the tp it is crucial to measure the streamflow complexity in the headwater areas of this region furthermore our understanding of the influence of climate change on streamflow complexity is also insufficient the tp as one of the world s regions with the most significant climate change chen et al 2015 kuang and jiao 2016 is still lacking studies that investigated the impact of climate change on sections of the streamflow complexity in the tp observation data analyses and model simulations show that the air temperature in the tp has increased significantly during the last 50 years kuang and jiao 2016 you et al 2016 zhong et al 2011 and the warming rate is twice the global average over the same period chen et al 2015 meanwhile despite the substantial spatial heterogeneity of precipitation on the tp the overall precipitation has also slightly increased kuang and jiao 2016 compared with the air temperature the impact of precipitation on the streamflow complexity has attracted more attention because of its significant role in the hydrological cycle chou 2014 huang et al 2011 pan et al 2012 however the air temperature is also likely to affect the hydrological cycle by changing the processes in the cryosphere biosphere and atmosphere cuo et al 2015 deng et al 2017 gao et al 2018 investigating the impact of climate i e air temperature and precipitation change on the streamflow complexity will also expand our knowledge of hydrothermal interaction in cold and arid regions the impact of climate variables i e precipitation and air temperature on streamflow complexity also has multi timescale characteristics liu et al 2019 chou found that the complexity of the rainfall runoff coefficient series which indicates the precipitation streamflow relationship increased along with the increase of scale factor chou 2012 huang et al 2017 analyzed a streamflow series and also found that the streamflow complexity increased from daily to seasonal timescales streamflow precipitation and air temperature individually also show different characteristics at diurnal monthly seasonal annual and decadal timescales büntgen et al 2005 jones et al 1999 sang et al 2009 sharifi et al 2018 su et al 2017 given the lack of relevant works new research probing the influence of precipitation and air temperature at multiple timescales is necessary for additional insight into streamflow complexity this study has two main objectives 1 to measure the streamflow complexity and understand its changes in the headwater area of the tp and 2 to investigate the impact of climate change on the streamflow complexity at multiple timescales to achieve these objectives we used a capable and robust entropy based measure permutation entropy pe to quantifying streamflow complexity in the tp we also used the mann kendall test to evaluate the trends and change points of the complexity and wavelet transform coherence wtc which is a scale dependent and reliable method to analyze localized scattered periodicities of the influence of precipitation and air temperature in particular we focused on the upper heihe river uhr basin on the northeast tp the streamflow from the uhr basin accounts for approximately 70 of the total streamflow in the heihe river the paper is organized as follows in section 2 we introduce the study area and data in section 3 we describe pe the mann kendall test and wtc the main results of this study are presented in section 4 and finally we provide discussion and conclusions in sections 5 and 6 respectively 2 study area and data 2 1 study area as the headwater of the heihe river basin hrb the uhr watershed fig 1 provides most of the water supply for the hrb the second largest inland river in china the two tributaries of the uhr the babaohe river bbr and the yeniugou river yngr converge into the mainstream and cross the qilian mountains at the yingluoxia ylx gauging station into the middle reaches of the heihe river the average annual mean temperature in the uhr basin ranges from 9 c to 5 c and the average annual precipitation exceeds 400 mm the uhr watershed is a typical alpine glacial region with wide distribution of permafrost and seasonal frozen ground it locates in the qilian mountains on the northeastern edge of the tp and has experienced significant climate change the climate in the uhr basin has been getting warmer and wetter in recent decades tree ring based reconstructed temperature series suggest that the 20th century was the warmest 100 years in the area s history wang et al 2016 moreover the upward trend of the air temperature has become steeper since the 1980 s wang et al 2010 meanwhile precipitation has also experienced a significant increase at a rate of 1 04 mm year from 1961 to 2016 zhong et al 2019 in addition glacier coverage areas in the uhr have declined from 66 3 km2 in 1990 to 13 37 km2 in 2010 generally attributed to climate change cai et al 2014 the lower limit of permafrost has climbed from 100 to 200 m and the permafrost has retreated 10 20 km along the major highways of the yngr watershed since 1985 wang et al 2017 the maximum thickness of the seasonal frozen ground has also decreased by about 20 cm wang et al 2015 2 2 data data used in this study include daily streamflow records from 1960 to 2014 and climatic data i e precipitation and air temperature from 1960 to 2014 daily streamflow records in the yingluoxia gauge station coordinates 38 49 12 n 100 10 48 e elevation 1700 m were obtained from the environmental and ecological science data center for west china http www heihedata org the climatic data consists of the daily mean air temperature and daily cumulative precipitation at three national meteorological stations qilian ql coordinates 38 10 48 n 100 15 0 e elevation 2787 4 m yeniugou yng coordinates 38 45 48 n 99 36 00 e elevation 3314 m and tuole tl coordinates 38 49 12 n 98 25 12 e elevation 3367 m these were downloaded from the national meteorological information center of the china meteorological administration http data cma cn it is worth noting that the precipitation data in this article include both rainfall and snowfall because of a lack of observation data for precipitation air temperature or streamflow in individual years we chose 1960 2014 as the joint period 3 methods 3 1 permutation entropy pe was proposed to finely measure the complexity of time series by bandt and pompe 2002 having no requirement for assumptions on linearity or normality entropy theory has been widely used to study and understand hydrological systems singh 1997 singh 2011 in recent decades various entropy methods have been employed to measure streamflow complexity such as sample entropy huang et al 2011 wang et al 2020 multi scale sample entropy huang et al 2017 li and zhang 2008 zhang et al 2012 wavelet based entropy sang et al 2011 shannon entropy castillo et al 2015 krasovskaia 1995 and kolmogorov entropy mihailović et al 2014 in contrast to these entropy measures pe considers the ordinal pattern of the values in a time series stosic et al 2016 due to its simplicity and robustness pe has attracted attention from researchers and been applied in hydrology and other domains including finance hou et al 2017 zunino et al 2009 meteorology zhang et al 2019b and bioinformatics zanin et al 2012 the calculation process of pe can be described as follows a given time series s i i 1 2 n s i represents the embedding vector s i s i τ s i d 1 τ where d denotes the embedding dimension and τ indicates the delay time we can sort the elements in vector s i in ascending order as s i j 1 1 τ x i j 2 1 τ s i j d 1 τ while the series j 1 j 2 j d denotes the indices of elements in s i in particular when there is equality in a time series we can sort them according to their original orders for instance if s i j t 1 1 τ s i j t 2 τ and j t 1 j t 2 then these two elements can be sorted as s i j t 1 1 τ s i j t 2 τ therefore the original vector s i can be mapped to a symbolic permutation π j 1 j 2 j d which is one of d possible permutations assuming the number of unique permutations is k the probability of each π denotes as p 1 p 2 p h the pe of the time series si is computed as h d h 1 k p h l n p h when p 1 p 2 p h 1 l n d h d has the maximum value l n d therefore the pe can be normalized as pe d h d ln d a normalized pe is restricted between 0 and 1 pe close to zero means the times series is a more deterministic increasing or decreasing series conversely a pe close to one means the time series is more random and chaotic before computing the pe of a time series it is split into non overlapping segments of short length and then the pe of each segment is computed changes in the pe measurements can be investigated to explore dynamic change in a time series the embedding dimension d usually depends on the observed phenomenon for useful statistics it is generally recommended to choose the maximum d according to n 5 d ribeiro et al 2012 for this study we computed the pe from the daily streamflow records of the yingluoxia gauge station for each calendar year the embedding dimension d and delay time τ were set to 4 and 1 respectively 3 2 mann kendall test the mann kendall test m k test is a nonparametric and robust method for detecting trends in time series originally proposed by mann 1945 and improved by kendall 1975 since it has been widely applied and verified in hydrological studies we employed it to identify the trends from the streamflow pe series a detailed description of the m k test can be found in hamed and ramachandra rao 1998 and sang et al 2014 3 3 wavelet transform coherence wavelet transform coherence wtc which describes the coherence of two time series can be regarded as a localized correlation coefficient between two time series in time and frequency space cazelles et al 2008 grinsted et al 2004 torrence and compo 1998 torrence and webster 1999 defined the wtc of two times series x and y as follows r n 2 s s s 1 w n xy s 2 s s 1 w n x s 2 s s 1 w n y s 2 where w n x s and w n y s denote the wavelet transformation of x and y respectively w n xy s denotes the cross wavelet transformation of x and y s is a smoothing operator depending on the wavelet used in general the smoothing operator s for a wavelet is written as s w s s s t w n s in which the s s and s t are smoothing along the wavelet scale axis and the time respectively w n s denotes the wavelet transformation of a time series where s indicates the wavelet scale factor r n 2 s denotes the value of wtc and ranges between 0 and 1 as with the correlation coefficient a value equal to zero depicts an independent two time series while the value equal to one depicts that the two times series perfectly co vary we estimated the statistical significance level of the wtc against a first order autoregressive red noise series assumption using monte carlo methods in this study the significance level was 0 05 it is worth noting that only the values outside the cone of influence coi are taken to estimate the significance level for each scale the coi indicates the areas in the wavelet coherence likely to be impacted by the edge effect artifacts we chose the morlet wavelet as the mother wavelet function owing to its balance between time and frequency grinsted et al 2004 more details of this method of computing wtc can be found in the work of grinsted et al 2004 4 results 4 1 streamflow complexity in the uhr watershed we applied a normalized pe measure on the daily streamflow records daily mean air temperature and daily cumulative precipitation in the uhr watershed to each year from 1960 to 2014 fig 2 in fig 2a the solid cyan red and yellow lines represent the annual pe of the air temperature the cyan red and yellow dashed lines represent the annual pe of the precipitation the blue line represents the pe of the streamflow from fig 2 it can be seen that the complexity of the streamflow in the uhr was a significantly nonstationary process that had a turning point in the year 1972 the m k test result showed an increasing trend in the streamflow complexity uf larger than 0 in fig 2 with the last changing point in 1972 there was an increasingly fluctuating trend in most years after 1980 in which the uf value was larger than the threshold 1 96 this phenomenon coincided with increasing air temperature in the eastern tp since the 1980s kuang and jiao 2016 therefore we partitioned the pe series into two different periods from 1960 to 1972 and from 1973 to 2014 in the first period the pe of the streamflow experienced a process of dramatic increase followed by a sharp decrease the average pe value during this period was 0 84 however the pe values after 1972 were higher and relatively stable the average pe value after 1972 was 0 89 this result suggests that after 1972 the dynamic features and structures of the streamflow in the uhr become more complex overall the complexity of the streamflow is essentially the dynamic between air temperature and precipitation notably after 1972 the pe of the streamflow was closer to that of the air temperature than before implying that the influence of the air temperature in the uhr watershed on the streamflow complexity may have increased after 1972 meanwhile we found that even the lowest pe 0 73 of streamflow was still higher than the pe of precipitation i e ql 0 61 yng 0 65 tl 0 51 in the corresponding year 1961 additionally it is worth noting that the pe troughs of streamflow and precipitation did not always occur at the same time the upward results indicate that the streamflow was a more complex uncertain and chaotic process than the precipitation in the uhr watershed we summarized the statistics table 1 and drew boxplots fig 3 of the pe of streamflow before and after 1972 before 1972 the mean median and quantiles of the pe of streamflow were located between those of air temperature and precipitation moreover the standard deviation of the streamflow s complexity was close to that of the precipitation while the streamflow had the most extensive range of complexity which indicates that the streamflow complexity varied greatly more dramatically than the air temperature and precipitation and its variation was more similar to the complexity of the precipitation after 1972 however it is clear that the statistics of the pe of streamflow were higher and more stable than before and the complexity of the air temperature remained steady while the range of the complexity of precipitation expanded this result implies that the streamflow complexity had increased and then stabilized in a stale phase after 1972 although the complexity of the air temperature was relatively stable the complexity of the precipitation varied greatly these changes in the streamflow complexity imply that the dynamic structure and uncertainty of streamflow may have changed to more complex and higher 4 2 impact of air temperature on streamflow complexity at multiple timescales to investigate the impact of the air temperature on the streamflow complexity we applied a wtc analysis of the annual mean air temperature and annual normalized pe of the streamflow fig 4 shows the result the black contours denote the 0 05 significance level against the red noise the shadow region denotes the coi the small arrows denote the relative phase relationship with in phase pointing right and anti phase pointing left in fig 4 two different bands of wavelet coherence show between the streamflow s complexity and air temperature for the streamflow complexity the wavelet coherence with the air temperature at three stations depicts high interannual covariance over a series of 2 4 year periods between 1962 and 1970 with the in phase however the wavelet coherence between the air temperature and streamflow complexity had a quasi decadal period during 1994 2008 with the anti phase with half of this region inside the coi considering the 5 high significance level and the vast region of wavelet coherence this quasi decadal period can extend to 1988 2012 this result indicates that the influence of air temperature on the streamflow complexity changes from a short timescale to a long timescale the change from in phase to anti phase indicates that the relationship between the air temperature and the streamflow complexity had to transform from a positive to a negative relation additionally we noticed that the wtc disappeared at tl station fig 4c which may imply that the role of air temperature in the marginal area of the uhr watershed was weakening because air temperature can accelerate the glacier melting rate permafrost degradation and the ratio of solid and liquid precipitation the indirect impact of temperature on the streamflow changed to more significant at the long timescale but at the marginal area the impact of temperature was weak due to the high latitude 4 3 impact of precipitation on the streamflow complexity at multiple timescales we also applied a wtc analysis to investigate the impact of precipitation on the streamflow complexity at multiple timescales the annual cumulative precipitation and the annual normalized pe of streamflow were used the result of the wtc between the precipitation and the streamflow complexity is shown in fig 5 the wavelet coherence between the precipitation and the streamflow complexity also exhibits two discrete regions there is a 2 4 year band of high covariance between 1964 and 1972 and the down arrows indicate that the precipitation led to a streamflow complexity of approximately 90 about 0 5 1 year the wtc between the precipitation and the streamflow complexity also had a long term 4 6 year band between 1988 and 2006 and the up arrows indicate that the precipitation led to a streamflow complexity of approximately 270 about 3 4 5 years the results show that although the degree of covariance between the precipitation and the streamflow complexity slightly weakened after 1972 the timescales and range both substantially extended in addition we found that the influence of precipitation at tl station on the streamflow complexity was significantly weaker than that at ql and yng stations this result is almost the same as the air temperature and may imply that the weakening impact of climate on the marginal area of the uhr maybe not be mere chance 4 4 climate change regarding the streamflow complexity to further investigate the possible impact of climate change on the observed shifts in streamflow complexity we conducted a comparative analysis between two specific periods the wtc analysis as mentioned above indicated that air temperature and precipitation both influence streamflow complexity but their different phases show that the influence changed before and after 1971 according to the regions with high wtcs of precipitation and air temperature we chose 1964 1970 and 1988 2012 for our two comparative time periods to illustrate the air temperature and precipitation changes in the uhr watershed the annual mean air temperature and annual accumulative precipitation anomalies relative to the 1960 2014 base period were calculated fig 6 shows the interannual variations of the air temperature and precipitation anomalies and the shadow regions indicate the two time periods with high wtcs before 1972 most air temperature and precipitation anomalies at the three stations were negative except for some discrete years additionally two low air temperature anomalies appeared during the 1964 1970 period with high wtcs the results demonstrate that a coupling impact of unusual low temperature and normal precipitation may create variations in streamflow complexity however more continuous and marked anomalies of air temperature and precipitation occurred after 1972 and especially after 1988 besides there were clear rising plateaus of air temperature anomalies at all three stations and two distinct rising plateaus of precipitation anomalies at the yng and tl stations interestingly the rising plateaus all emerged when the air temperature and precipitation had significantly high wtcs with the streamflow complexity these results suggest that there is a relationship between climate change and streamflow complexity table 2 provides the multi year average annual air temperature maat multi year average annual precipitation map average air temperature anomalies aata and average precipitation anomalies apa during the two periods with high wtcs it shows that all the average annual air temperatures at the three stations were relatively low and their anomalies were negative during 1964 1970 and the anomalies of average annual precipitation were also negative this result suggests that the area experienced a colder and drier process during this period during 1988 2012 all the average annual air temperatures and the average annual precipitation figures at the three stations were positive and increased from 0 86 to 1 15 c and 12 2 61 04 mm respectively these results suggest that the climate began to be warmer and wetter during 1988 2012 5 discussion the streamflow complexity of the uhr watershed was measured using pe based on 55 years of data on an annual scale although many studies have focused on the influence of climate change on streamflow or water availability barnett et al 2005 naz et al 2018 few have looked into the impact of climate change on the streamflow complexity however the relationship between precipitation and streamflow complexity has been discussed more chou 2014 huang et al 2011 though only a limited number have investigated how air temperature change impacts streamflow complexity in inland alpine glacier regions the results in this paper show that air temperatures also have a critical influence on stream complexity in a glacial alpine watershed first the streamflow complexity was shown to have changed in 1972 which is highly likely to be due to climate change the changes in streamflow complexity were distinct and generally detected in rivers affected by dam constructions stosic et al 2016 and reservoir operations zhang et al 2019a as there were no large scale dam constructions in the uhr watershed during the research period or other disturbances of the land use land cover this change was likely due to climate change in the region several studies have reported variations in the streamflow caused by climate change in the uhr since the 1980s cai et al 2014 gao et al 2018 luo et al 2016 our results also show that after 1972 and especially after 1988 the air temperature and precipitation had long term significant covariance with the stream complexity meanwhile the air temperature showed an upward trend at the watershed and precipitation increased fig 6 therefore climate change not only altered the volume of streamflow but also played a critical role in changing the streamflow complexity this find means that the temporal distribution of streamflow also can be altered by climate change hence it is critical for water management agencies of the arid and semi arid areas which are very sensitive to the temporal distribution of water resources to pay attention to the distribution changes of daily streamflow to improve better water resource regulation second air temperature impacted the streamflow complexity to a weaker degree but across longer timescales than precipitation the periods of higher air temperature and precipitation began to increase from around three to four years until they reached record lengths of up to twelve years a comparison of the two results of wtcs between air temperature and precipitation on streamflow complexity showed that although the degree of influence of air temperature significantly increased it was still relatively weaker than that of precipitation the complex hydrometeorological processes may have caused a longer timescale and weaker influence of air temperature in the alpine glacier watershed increasing air temperature can affect the streamflow in the uhr in three typical ways 1 it can accelerate the rate of glacier melting and positively affect the streamflow in glacierized watersheds barnett et al 2005 bibi et al 2018 2 it can lead to permafrost degradation and then affect the streamflow through the increase of base flow cuo et al 2015 qin et al 2016 and 3 it can change solid precipitation to liquid precipitation resulting in a decrease in snowpack and earlier snowmelt barnett et al 2005 berghuijs et al 2014 deng et al 2017 since all three are indirect and cover multiple land surface processes the impact of air temperature on streamflow complexity is weaker than for precipitation additionally the clearly weakened wtcs between the air precipitation the precipitation at the tl station and the streamflow complexity can be explained from two perspectives on the one hand the tl station is located far from the mainstream and tributaries and closer to another sub watershed and this could be why the effects of climate variables there decreased after 1988 on the other hand the extremely low temperatures and low precipitation climate events highly likely caused the significant wtcs between the air temperature precipitation at the three stations and the streamflow complexity during 1964 1970 hence the significant relationship between the climate variables at the tl station and the complexity of stream is evident for the large scale extreme climate event notably the results in this study did not consider all the possible affecting factors for the change of streamflow complexity such as vegetation variation and land use land cover change more influencing factors and their combination with climate change will be discussed in the future it is important to emphasize that the streamflow complexity showed low wtc with the air temperature and the precipitation may be caused by the low degree or slowly developing trend of climate change from 1972 to 1988 6 conclusions in this study we applied pe to measure streamflow complexity at the headwaters of the uhr watershed on the northeastern tp we found that the streamflow complexity in the uhr watershed had significantly increased since 1972 and could be explained by climate change the increase of streamflow complexity in the headwater area on the tp had not been uncovered in previous studies before 1972 periods of low precipitation and very low air temperatures occurred every 3 4 years however after 1972 and especially after 1998 greater precipitation and higher air temperatures over longer periods have impacted streamflow complexity therefore climate change has not only altered the streamflow but also increased its complexity our results indicate that the dynamic structure and features of streamflow have been transformed by climate change in the uhr watershed and this may well have significance for water resource management agencies and researchers investigating streamflow complexity in other headwater areas across the globe credit authorship contribution statement shi shen conceptualization methodology software data curation formal analysis writing original draft writing review editing changqing song conceptualization investigation supervision funding acquisition changxiu cheng conceptualization funding acquisition writing review editing sijing ye software validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we would like to thank the prof zhang qiang for his constructive suggestions this work is supported by the national key research and development plan of china grant number 2019yfa0606901 the second tibetan plateau scientific expedition and research program step grant number 2019qzkk0608 national natural science foundation of china grant numbers 41801300 41901316 the fundamental research funds for the central universities grant number 2019ntst01 we would also like to thank the center for geodata and analysis faculty of geographical science beijing normal university https gda bnu edu cn for their high performance computing support 
5321,surface runoff is often poorly quantified in hydrologic studies of subsurface drained fields as it is a relatively minor component of the water balance and difficult to measure in large fields however conservation practices that seek to mitigate pollutant transport through subsurface drainage may increase surface runoff and therefore it needs to be better understood the goal of this study was to determine the frequency and extent of occurrence of surface ponding and runoff and to understand their generation processes in a seasonally frozen subsurface drained agricultural field in eastern indiana three different methods were used surface ponding was monitored with a time lapse camera at the edge of the field for three years a water table threshold for surface ponding was determined using photo evidence of ponding together with water table depth measurements and used to estimate ponding the drainmod hydrologic model was calibrated and validated by comparing model predictions of subsurface drainage and water table depth with 10 years of field observations and used to predict surface ponding and runoff the simulation results indicated that surface runoff represented 1 10 of annual precipitation while subsurface drainage represented between 26 and 45 on average 45 of simulated ponding occurred during the cold season december march indicating the importance of soil freezing and snow accumulation however during parts of the cold season drainmod simulations of snow accumulation and melt were poor resulting in drain flow under prediction and runoff over prediction during these periods water table depth measurements above the defined threshold provided a simple alternate for prediction of saturation excess ponding events in the absence of direct measurements results from both simulations and observations indicated that all of the ponding events in this location were generated by saturation excess rather than infiltration excess processes keywords time lapse photos water table depth subsurface drainage drainmod freeze thaw condition agricultural field 1 introduction surface runoff has often been found to be a minor flowpath in subsurface drained areas for example tan and zhang 2011 found that surface runoff was only 3 of total flow volume leaving the field in a 5 year study in canada and kalita et al 2006 found that surface runoff was small or negligible in their tile drained illinois watershed based on their 12 year study however surface runoff from agricultural fields is a pathway by which sediments nutrients and pesticides are carried away and deposited into surface waters so even if the magnitude is small understanding and quantifying this pathway is critical for implementing appropriate management practices to reduce export of sediments and associated pollutants one suggested practice for mitigating water quality issues caused by subsurface drainage in agricultural fields is controlled drainage in which the drainage outlet elevation is managed in order to reduce drain flow and nitrate loss through subsurface drainage however controlled drainage has the potential to increase surface runoff ale et al 2009 2010 which can result in additional water quality concerns although it is difficult to quantify because of the large uncertainty in the frequency and magnitude of surface runoff quantifying surface runoff is also important for closing the land surface water balance and understanding the hydrological connectivity of surface and subsurface flow this understanding allows identification of runoff and subsurface flow contribution to nitrate and phosphorus loss through agricultural fields which has been a major concern for decades e g thomas et al 1992 turner and rabalais 1994 sharpley et al 2015 surface ponding and runoff may occur due to infiltration excess horton 1933 when the rainfall intensity exceeds the infiltration capacity of the soil or it may occur due to saturation excess when the water table level rises to the ground surface dunne and black 1970 both types can occur in an agricultural watershed throughout the year depending on climate conditions and infiltration capacity of the soil for instance in poorly drained soils in the netherlands saturation excess runoff appeared to be more common in winter while infiltration excess predominated in summer kwaad 1991 ritsema et al 1996 additionally during winter in seasonally frozen landscapes frozen ground can reduce infiltration rates and as a result surface ponding and runoff from rainfall or snowmelt can increase shanley and chalmers 1999 cade menun et al 2013 surface ponding results when precipitation does not immediately infiltrate into the soil or the water table rises above the surface not every ponding event leads to surface runoff leaving the field particularly in depressional topography or areas with high surface roughness accumulated water can infiltrate back into the soil before leaving the field and contribute to the subsurface flow or get lost through evaporation therefore ponding and runoff need to be studied separately although generated by similar processes processes generating surface ponding and runoff and their frequency of incidence in subsurface drained agricultural fields are poorly understood the conditions under which surface ponding and runoff can occur as well as the distinctions between ponding and runoff have received little attention in the literature in many field studies of subsurface drained fields the non growing season has been found to be a critical time for phosphorus loss through surface runoff in regions with cold climates particularly where significant snow cover and winter thaws are experienced e g goulet et al 2006 coelho et al 2012 van esbroeck et al 2016 therefore it is important to have an estimation of surface ponding and runoff in all seasons however monitoring surface ponding and runoff is challenging especially in the cold season and many studies that included winter observations of surface runoff have experienced data gaps due to freezing and equipment malfunction e g goulet et al 2006 jamieson et al 2003 thus hydrological models are often used to simulate surface runoff drainmod skaggs 1978 is one of the most widely used models developed for simulating drainage hydrology it is a field scale process based model that simulates the performance of agricultural drainage and related water management systems in poorly drained soils it has been extensively tested and widely applied in many parts of the world for a wide range of agronomic and climatic conditions e g skaggs et al 1981 ale et al 2009 skaggs et al 2012 drainmod was modified in 2000 to simulate freeze and thaw processes supporting its use in cold climates luo et al 2000 2001 many researchers have used the modified version of the model in cold regions for example wang et al 2006 found that the modified version performed better in winter months in canada than the original model morrison et al 2014 simulated the hydrology of agricultural drained land in canada using drainmod and reported that during the snowmelt period the model performed slightly better in predicting surface runoff than drain flow in this study a 10 year simulation was conducted using drainmod to predict surface runoff in a relatively flat and seasonally frozen subsurface drained agricultural field in eastern indiana the evidence of surface ponding and runoff from this field was also monitored for three years with a time lapse camera and by measuring water table depths for ten years the overall goal of this study is to evaluate the generation of surface ponding and runoff processes at the study site specific objectives of the study were to 1 determine the frequency and extent of surface ponding and runoff 2 determine the relative frequency of infiltration excess and saturation excess processes in generating surface ponding and runoff 3 understand when and how the freeze thaw processes influence simulated surface ponding and runoff in drainmod simulations 2 methods 2 1 site description the study was conducted in the southwest sw quadrant of field w at davis purdue agricultural center dpac a research farm in eastern indiana fig 1 over the 10 years of the study 2007 2016 the mean annual precipitation at this site was 990 mm with approximately 6 of the precipitation falling as snow the mean monthly precipitation was highest in june and the mean snowfall was highest in january and february fig 2 the 10 year mean temperature ranged from 4 4 c in january to 22 6 c in june the study site is relatively flat slope 1 with an area of 3 5 ha consisting of very poorly drained to somewhat poorly drained soil series the subsurface drainage system at this site was installed in 2004 in an experiment to assess the impacts of controlled drainage on ground water recession rate saadat et al 2017 and water and nutrient loss through subsurface drains saadat et al 2018a b a more detailed description of this field can be found in these studies 2 2 field observations water table depth was measured throughout the study period 2007 2016 using an observation well located at the midpoint between two drains 25 m from the outlet and 0 2 m higher in elevation fig 1 the observation well was installed to a depth of approximately 2 m a pressure transducer global water wl 16 was used to measure water table level every hour because of uncertainties associated with the absolute water table elevation caused by water table sensor replacement during maintenance the recorded water table elevation was adjusted up or down by a fixed amount relative to the drain elevation during periods between maintenance activities based on the assumption that drains flow only when water table is above the drain details of this process are provided in saadat et al 2017 small gaps in water table depth measurements fig 3 mainly during the summertime when water table level was often below the drain were excluded from the analysis the end of day water table depth was used as the daily value hourly drain flow was measured using an electromagnetic flow meter krohne waterflux 3070 since 2012 prior to flow meter installation and during the missing periods drain flow was estimated using a theoretical drainage equation hooghoudt and water table depth measurements a daily drain flow record was then constructed from drain flow measurements combined with drain flow estimated using the hooghoudt equation together with linear regression equations as described fully in saadat et al 2018a small gaps still remained in drain flow records mainly during the summertime when drain flow was relatively low compared to other times of the year fig 3 and were excluded from the analysis soil temperature was measured at depths of 10 20 40 60 and 100 cm using soil moisture and temperature sensors decagon 5te 10 cm 5tm others beginning in june of 2011 sensors were installed near the observation well fig 1 in actively farmed areas requiring that the 10 and 20 cm sensors be removed during tillage operations and replaced following planting hourly wind speed and precipitation were measured at the on farm weather station that was located on the western side of the field close to the outlet fig 1 a tipping bucket was used to measure liquid precipitation only because it was not modified to measure solid precipitation daily precipitation liquid and solid as well as daily maximum and minimum air temperatures were measured at the national climatic data center coop station coop 122825 farmland 5 nnw located at dpac precipitation data from the coop station was used to supplement the on farm measurements missing or erroneous wind speed precipitation solar radiation and air temperature data were supplemented by 30 minute data from the purdue automated station https iclimate org 30 min purdue automated also located at dpac in order to collect evidence of surface ponding and runoff a time lapse camera was installed in december 2014 near the drainage outlet to take photos from the field every hour during the daytime the approximate angle of view and the location of the camera are shown in fig 1 two staff gages were made from 5 cm pvc pipes covered by colored tape with each color representing 5 cm depth these staff gages were installed in the field in the camera angle of view for a few months before planting and provided an indicator of ponding depth captured in the photos fig 4 2 3 surface ponding and runoff three different methods two based on observations and one based on model simulations were used to determine the frequency and extent of surface ponding and runoff the first method was based on the hourly time lapse photos the second method used water table depth measurements along with photos and simulation of surface ponding and runoff with the drainmod model was the third method 2 3 1 time lapse photos and processing a total of 13 000 hourly photos were collected from december 2014 to october 2017 due to the camera angle being changed by strong winds the field was not completely visible in photos from july to november 2016 and mid january to early march 2017 therefore these photos were excluded from the analysis photos were classified into five categories based on the ponding depth and extent table 1 fig 5 the ponding classification was based on visual inspection of photos in addition to the approximate measurements obtained from the staff gages that were installed in the field for part of the year fig 4 in the cold season snowmelt ponding was identified if accumulated snow was melted and ponded on the ground the classification of ponding for snowmelt events was similar to rain events using the ponding categories a photo time series was generated for all times when photos were available for the field 2 3 2 water table depth method water table level above the ground surface could be an indication of surface ponding in the field however the measurements only represented the water table level at the well location and since this field is not completely flat the water table level can vary across the field therefore the photo time series was compared to water table depth wtd to find a threshold above which there was evidence of ponding in the field fig 6 a threshold of 35 cm compared well to periods of ponding observed in photos and the same was used to indicate the timing duration and frequency of ponding events in years in which photo evidence of ponding was not available 2 3 3 drainmod drainmod is a process based model that can predict hydrologic variables including infiltration subsurface drainage surface runoff evapotranspiration vertical and lateral seepage and water table depth in the soil profile on a daily monthly or yearly basis skaggs et al 2012 the green ampt equation is used to predict infiltration and surface runoff is characterized by the depth of depression storage that must be filled before runoff can begin in drainmod if the ponded water on the ground surface exceeds the maximum surface storage surface runoff begins otherwise the surface storage indicates the ponding depth that does not lead to runoff leaving the field when the profile is saturated and water is ponded on the surface the drainage rate is calculated using equations developed by kirkham 1957 otherwise the steady state hooghoudt equation bouwer and van schilfgaarde 1963 is used to calculate drainage rate a detailed description of the model can be found in skaggs 1978 2 3 4 model inputs inputs to drainmod include weather soil properties site characteristics drainage system parameters inputs related to the crop and management factors such as timing and manipulation of drainage outlets described in the following paragraphs weather data inputs to drainmod are hourly precipitation maximum and minimum daily air temperatures and daily potential evapotranspiration pet values continuous hourly precipitation and daily maximum and minimum air temperature records 2007 2016 were generated for the study site using measurements from the three different weather stations described in the weather data measurements the daily pet was calculated with the penman monteith equation using the on site measured weather parameters such as shortwave radiation and wind speed chiu 2013 the drain depth drain spacing and drainage coefficient were known for this drainage system table 2 soil survey and additional soil property measurements were used to estimate the depth and thickness of the restrictive layer and the piezometric head of the aquifer was set to be 0 at the top of the restricting layer the equivalent depth from drain to impermeable layer and the kirkham s coefficient were calculated based on the distance between drains and effective drain radius as well as the distance between the drain and the impermeable layer by the internal drainmod subroutine table 2 drainmod requires the effective rooting depth over time which defines the zone from which water can be removed to supply et the corn effective rooting depths were estimated from a minimum of 3 cm to a maximum of 45 cm ale et al 2009 based on a typical planting and harvest date at the site over the study period required soil property inputs to drainmod include lateral saturated hydraulic conductivity and the volumetric water contents of the soil profile at tension values from 0 to 15000 cm table 3 the lateral saturated hydraulic conductivity was estimated for three soil layers using the hooghoudt equation and the measured water table depth and drain flow as described in saadat et al 2018a on site soil volumetric water contents measurements were available at 0 3 50 100 330 and 15000 cm tensions these measurements were obtained from the soil samples which were collected in 2011 2013 and 2015 at four depths from three different sub plots with three replicates kladivko et al 2014 the lower limit of water content in the root zone 0 27 cm3 cm3 was taken from the volumetric water content of the topsoil layer at 15000 cm tension wilting point these soil properties were also used in the drainmod soil utility program to estimate unsaturated hydraulic conductivities volume drained upward flux and green ampt infiltration parameters as a function of water table depth drainmod requires additional inputs in order to reflect the freeze thaw processes luo et al 2000 two soil thermal conductivity constants tka and tkb which are used to calculate soil thermal conductivity as a function of soil water content were obtained from an empirical model with three input parameters including saturated water content of 0 5 cm3 cm3 volume fraction of organic matter content of 0 05 and thermal conductivity of soil solids 10 cal c s c the coefficients of computational depth function az bz were estimated using eq 1 luo et al 2000 by assuming a thermal damping depth of 4 m where annual fluctuation of temperatures are damped out and the soil temperature is assumed constant below this depth table 4 1 z n 1 z n a z b z n 1 n 1 2 20 where zn is the nodal depth from the soil surface e g z1 0 at the soil surface the constants az and bz were calculated by trial and error in order to reach the z21 of 4 m the soil temperature at the bottom of the profile was assumed to be equal to the long term average air temperature penrod et al 1958 the snow melt coefficient and the critical ice content above which infiltration stops were adjusted during the calibration process other soil temperature parameters were taken from luo et al 2000 table 4 the soil freezing characteristic curve sfc describing the relationship between unfrozen water content and soil temperature was derived from eq 2 as described in luo et al 2000 2 h 122 t where t is the below zero temperature c and h is the pressure head in the soil that results from a given t m however since 15000 cm 15 bar was the highest pressure head for which soil water content was measured the only part of the sfc curve obtained from eq 2 and the measured soil water characteristic curve was 0 to 1 2 c therefore the values given in luo et al 2000 were used as initial values for the rest of the curve and were then adjusted in the calibration process table 5 as explained later in the results 2 3 5 surface roughness and infiltration parameters surface runoff is characterized in drainmod by the maximum depth of depression storage that must be filled before runoff occurs if the ponded water on the ground surface exceeds the maximum surface storage sm surface runoff begins otherwise the surface storage does not lead to runoff the maximum surface storage and the minor surface depressional storage sl representing storage in small depressions were taken from the literature and were adjusted during the calibration process table 3 the green ampt equation is used to characterize infiltration in drainmod skaggs 1990 during cold seasons the infiltration may be limited by soil ice content when ice is formed in the soil soil hydraulic conductivities and fillable porosity are modified based on the volumetric content of ice and unfrozen water in the soil luo et al 2000 when the ice content exceeds the critical ice content given as model input infiltration stops and water is accumulated as surface storage ponding when the rainfall rate exceeds the infiltration capacity calculated by eq s1 the excess water is accumulated as surface storage ponding and when the surface storage exceeds the maximum surface storage depth the additional excess is surface runoff skaggs 1978 2 3 6 calibration and validation strategy the drainmod model was calibrated by adjusting the sensitive parameter inputs that were not available from direct measurements within an established range table 6 the parameter range was based on a guideline provided by skaggs et al 2012 and the values reported by other researchers especially for soil temperature parameters luo et al 2000 sands et al 2003 wang et al 2006 singh et al 2006 yang et al 2007 ale et al 2009 morrison et al 2014 garmdareh et al 2018 daily observed and predicted water table depths and drainage volumes from 2007 to 2016 were plotted and compared visually with respect to both the timing of occurrence and the magnitude of response observations from 2010 to 2014 were used for validation and other years were used for calibration of the model calibration and validation periods were specified in a way that each period contains both wet and dry years as well as measured drain flow additionally the surface ponding time series created from time lapse photos from 2015 and 2016 were visually compared to the drainmod ponding and runoff predictions for qualitative calibration of surface storage parameters the maximum surface storage parameter in drainmod was adjusted to find the best agreement between the photo time series and drainmod estimates of surface ponding and runoff the agreements between monthly predicted and measured drain flow and daily water table depth were quantified by statistics including the nash sutcliffe efficiency nse nash and sutcliffe 1970 and percent bias pe which are relative error measures as well as the average deviation ad which is an absolute error measure please see supplemental information for additional details 3 results 3 1 surface ponding and runoff 3 1 1 photo estimate of ponding the majority of ponding events observed with cameras were classified in categories 1 and 2 fig 6 in each year there were only a few severe and extreme ponding events category 3 4 that were expected to cause surface runoff table 7 indicating ponding does not always lead to runoff however the photo time series was not available for the entire year in 2016 and 2017 due to the camera angle being changed by strong winds the field was also buffered by grass at the edges for most of the time fig 8 therefore accumulated water often infiltrated into the soil or evaporated before it could run off the field 3 1 2 water table depth estimate of ponding during the periods when both photo and water table depth wtd observations were available 32 ponding events were captured by both methods for each event in which there was photo evidence of ponding the wtd was always below the threshold 35 cm there was only one ponding event estimated with the wtd method that was not captured by the photo method because it occurred during the night when the camera was turned off the 100 correspondence between water table estimate of ponding and photo estimate of ponding suggests that saturation excess was the driving force for all ponding events observed at this site the ponding frequency and duration varied over years table 8 ponding frequency ranged from 8 to 24 events per year and the total duration of ponding in a year ranged from 15 to 43 days there was not a correlation between the frequency and duration of ponding for instance ponding duration in 2009 with 8 ponding events was similar to that in 2010 and 2014 with 22 events with the wtd method unlike the photo method the ponding events were not classified into different categories however the inverse correlation between photo category and the minimum measured water table depth during a wtd ponding event provides indirect information on the extent of ponding fig 9 when the wtd was close to the ground surface there was photo evidence of runoff photo category 3 4 all of the ponding events that likely led to runoff according to photos occurred when the wtd was below 8 cm therefore runoff was not expected when the wtd 8 cm but not all of the ponding events with wtd 8 cm led to runoff 3 1 3 drainmod estimate of ponding and runoff the simulated annual water balance indicated that on average surface runoff accounted for 7 of the annual precipitation while et and drain flow accounted for 51 and 34 respectively fig 10 the range over the 10 years was from 24 to 53 cm yr 1 and 1 to 12 cm yr 1 for annual drain flow and runoff respectively on average over 10 years water loss through drain flow and runoff was the highest in march and the lowest in september fig 10 the number of ponding and runoff events and total duration of ponding events simulated with drainmod are listed in table 8 the simulated ponding frequency ranged from 4 to 13 events per year and total ponding duration ranged from 4 to 34 days per year around 50 of all simulated ponding events produced surface runoff when drainmod predicted a ponding event the simulated water table depth was zero meaning that all of the drainmod estimates of ponding were saturation excess ponding 4 discussion 4 1 comparison of ponding frequency and duration obtained from time lapse photos water table observations and simulations the comparison between photo wtd and drainmod results indicated that drainmod predicted fewer ponding events than what was observed in the field according to photos and water table depth measurements fig 11 on average over 10 years 2007 2016 drainmod predicted 8 ponding events per year 16 days total while the water table depth wtd method estimated 18 ponding events 30 days total runoff occurred only 4 times per year on average according to both drainmod and photo estimates meaning that drainmod under predicted the frequency of ponding more than it under predicted runoff the under prediction of ponding events in drainmod could be due to the spatial variability in ponding generation and drainmod s limitations in representing spatial variability drainmod assumes that the field is completely flat therefore it only predicted the extreme ponding events that occurred when the entire field reached saturation however in reality there was an approximately 2 m elevation change in the study field and water usually accumulated in the corner of the field where the time lapse camera was located and captured the ponding events that occurred when just a portion of the field was saturated to determine the impact of elevation change on drainmod ponding predictions similar to the wtd method the threshold of 35 cm was used instead of the ground surface for identifying saturation excess ponding events using the drainmod simulated water table results indicated that drainmod would predict around 13 ponding events per year on average which is closer to the 18 events per year observed on average overall the low percentage of generated runoff 7 of the annual precipitation was comparable to what others have found in drained agricultural fields for example in a simulation study in iowa singh et al 2007 reported that only 5 of annual precipitation contributed to surface runoff from an experimental study conducted in three agricultural fields in ontario canada van esbroeck et al 2016 also concluded that only 5 10 of precipitation contributed to surface runoff 4 2 runoff generation processes according to all three methods a portion of ponding events occurred during the cold season dec mar indicating that cold season processes may also affect the ponding and runoff generation at this field table 9 the seasonal distribution of observed and simulated ponding events varied in each year however ponding resulting from snowmelt was not very frequent in this field during the period in which photo evidence of ponding was available dec 2014 to oct 2017 only three events were observed that were generated by snowmelt or snowmelt combined with rain events shown in fig 12 both simulated and observed results indicated that all ponding events were due to saturation excess rather than infiltration excess according to water table depth which was below the threshold 35 cm for every ponding event simulated or observed in the field in the cold season soil temperature at 10 cm depth was less than or equal to 0 c about 6 of the time however none of the cold season ponding events occurred at these times suggesting that partially frozen soil rarely if ever contributed to the ponding generation process simulation of infiltration excess ponding is dependent on parameter selection for the infiltration equation in drainmod green ampt and so could in theory be calibrated to occur more frequently however saturation excess ponding predicted with the model was comparable to the photo evidence of ponding which always occurred when wtd was below the threshold 35 cm additionally the results found in this study were in agreement with the findings of bou lahdou 2014 for the dpac site they found that when surface ponding occurred at the field according to water table measurements the average precipitation intensity was low indicating that saturation excess was the driver of ponding generation rather than infiltration excess appels et al 2016 found that not only the field topography but also the type of surface runoff generation process is an important factor in the dynamics of the hydrological connectivity in flat agricultural fields in the netherlands it is important to understand that both topography and process can impact the relationship between precipitation volume and connectivity this understanding can help to improve the use of hydrological connectivity indicators in watershed scale hydrological models 4 3 limitations in simulating cold season processes in drainmod drain flow was over predicted in march in some years due to the freeze thaw processes and snowmelt impacts however it was mainly under predicted in cold months likely due to soil freezing impacts frozen soil limits infiltration so soil temperature plays a key role in simulating infiltration and drain flow in drainmod soil surface temperature is set equal to air temperature except during periods of snowcover when the snowpack on the ground insulates the soil and lowers the heat losses from the soil surface however drainmod did not predict the snow accumulation and melt accurately for parts of the cold season fig 13 a partly because of using the daily average air temperature as a basis for dividing snow and rain while there were frequent changes in hourly air temperatures in indiana additionally drainmod possibly did not simulate insulation of the soil surface due to snow sufficiently therefore the soil surface temperature boundary condition tended to be too low during periods of observed snow cover resulting in under prediction of soil temperatures throughout the soil column shown for the 10 cm depth in fig 13 b excessively cold simulated soil temperature led to a reduction in infiltration and drain flow estimations fig 13 c and it increased the water storage as ice in the soil profile by reducing infiltration and slowing drain flow the simulated frozen soil can also contribute to generating ponding and runoff or add to the existing conditions under which ponding is generated to increase the depth and extent of ponding and runoff during the times when the soil was not frozen march april drain flow was very well predicted in that year in order to overcome the impacts of excessively cold simulated soil temperatures on drain flow and runoff predictions the freezing characteristic curve sfc was adjusted for temperatures below 0 c by assigning greater unfrozen water contents than what were obtained from the method described in luo et al 2000 table 5 in addition the soil freezing curve needed to be defined down to 30 c in order to achieve model stability lamya negm personal communication adjusting the sfc improved drain flow predictions by increasing the flow peaks and consequently reduced surface runoff slightly fig 14 other drainmod users also reported similar difficulties in cold regions for example yang et al 2007 used drainmod n in ontario canada to simulate nitrate movement and concluded that the model had difficulty in simulating drain flow accurately when soils were frozen in winter and thawed in spring in another study sands et al 2003 used drainmod to predict drain flow in minnesota and concluded that the model over estimated drain flow during snowmelt soil freeze and thaw processes play important roles in the hydrology of seasonally frozen regions yet are not easy to predict future research can further investigate the impacts of these processes in a drained agricultural field and improve drainmod predictions in seasonally frozen regions 5 conclusions surface ponding and runoff were estimated in a seasonally frozen drained agricultural field in eastern indiana using three methods including photo observations water table monitoring and model simulations resulting in the following conclusions multiple lines of evidence of surface ponding and runoff provided more information than just one photos provided direct evidence of ponding but only on a small portion of the field for parts of the study period water table depth provided a simple alternate method for identifying saturation excess ponding drainmod predicted surface ponding and runoff over the whole field assuming it is flat but not the spatial variability of ponding surface ponding was more frequent than runoff indicating not every ponding event led to runoff the estimated annual water balance indicated that 7 of annual precipitation contributed to surface runoff while 93 contributed to et subsurface drainage and seepage results from both simulation and observation methods indicated that all of the ponding events were generated as a result of saturation excess processes rather than infiltration excess the seasonal distribution of ponding events varied in different years but on average the wtd method and drainmod results both indicated that about 45 of ponding events over 10 years occurred in the cold season dec mar adjusting the soil freezing characteristic curve sfc in drainmod improved the simulation results in cold season by preventing under prediction of drain flow and over prediction of runoff the drainmod model results together with field observations contribute to a better understanding of surface ponding and runoff generation in an agricultural drained field as well as understanding the long term water balance and the role of surface storage in flood mitigation erosion prediction and generation of ephemeral gullies this understanding will be useful for model development and management recommendations for water resources at the field or watershed scales credit authorship contribution statement samaneh saadat conceptualization data curation formal analysis methodology validation visualization writing original draft writing review editing jane frankenberger supervision resources writing review editing laura bowling supervision resources writing review editing srinivasulu ale writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this material is based upon work that is supported by the national institute of food and agriculture u s department of agriculture under award number 2011 68002 30190 cropping systems coordinated agricultural project climate change mitigation and adaptation in corn based cropping systems http sustainablecorn org and award number 2015 68007 23193 managing water for increased resiliency of drained agricultural landscapes http transformingdrainage org any opinions findings conclusions or recommendations expressed in this publication are those of the author s and do not necessarily reflect the view of the u s department of agriculture we thank charlotte lee from the purdue agronomy department for helping with the calculation of daily potential evapotranspirations and lamya negm from north carolina state university for her guidance and providing a new executable file for drainmod that provides the simulated snow depth as an output appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124985 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5321,surface runoff is often poorly quantified in hydrologic studies of subsurface drained fields as it is a relatively minor component of the water balance and difficult to measure in large fields however conservation practices that seek to mitigate pollutant transport through subsurface drainage may increase surface runoff and therefore it needs to be better understood the goal of this study was to determine the frequency and extent of occurrence of surface ponding and runoff and to understand their generation processes in a seasonally frozen subsurface drained agricultural field in eastern indiana three different methods were used surface ponding was monitored with a time lapse camera at the edge of the field for three years a water table threshold for surface ponding was determined using photo evidence of ponding together with water table depth measurements and used to estimate ponding the drainmod hydrologic model was calibrated and validated by comparing model predictions of subsurface drainage and water table depth with 10 years of field observations and used to predict surface ponding and runoff the simulation results indicated that surface runoff represented 1 10 of annual precipitation while subsurface drainage represented between 26 and 45 on average 45 of simulated ponding occurred during the cold season december march indicating the importance of soil freezing and snow accumulation however during parts of the cold season drainmod simulations of snow accumulation and melt were poor resulting in drain flow under prediction and runoff over prediction during these periods water table depth measurements above the defined threshold provided a simple alternate for prediction of saturation excess ponding events in the absence of direct measurements results from both simulations and observations indicated that all of the ponding events in this location were generated by saturation excess rather than infiltration excess processes keywords time lapse photos water table depth subsurface drainage drainmod freeze thaw condition agricultural field 1 introduction surface runoff has often been found to be a minor flowpath in subsurface drained areas for example tan and zhang 2011 found that surface runoff was only 3 of total flow volume leaving the field in a 5 year study in canada and kalita et al 2006 found that surface runoff was small or negligible in their tile drained illinois watershed based on their 12 year study however surface runoff from agricultural fields is a pathway by which sediments nutrients and pesticides are carried away and deposited into surface waters so even if the magnitude is small understanding and quantifying this pathway is critical for implementing appropriate management practices to reduce export of sediments and associated pollutants one suggested practice for mitigating water quality issues caused by subsurface drainage in agricultural fields is controlled drainage in which the drainage outlet elevation is managed in order to reduce drain flow and nitrate loss through subsurface drainage however controlled drainage has the potential to increase surface runoff ale et al 2009 2010 which can result in additional water quality concerns although it is difficult to quantify because of the large uncertainty in the frequency and magnitude of surface runoff quantifying surface runoff is also important for closing the land surface water balance and understanding the hydrological connectivity of surface and subsurface flow this understanding allows identification of runoff and subsurface flow contribution to nitrate and phosphorus loss through agricultural fields which has been a major concern for decades e g thomas et al 1992 turner and rabalais 1994 sharpley et al 2015 surface ponding and runoff may occur due to infiltration excess horton 1933 when the rainfall intensity exceeds the infiltration capacity of the soil or it may occur due to saturation excess when the water table level rises to the ground surface dunne and black 1970 both types can occur in an agricultural watershed throughout the year depending on climate conditions and infiltration capacity of the soil for instance in poorly drained soils in the netherlands saturation excess runoff appeared to be more common in winter while infiltration excess predominated in summer kwaad 1991 ritsema et al 1996 additionally during winter in seasonally frozen landscapes frozen ground can reduce infiltration rates and as a result surface ponding and runoff from rainfall or snowmelt can increase shanley and chalmers 1999 cade menun et al 2013 surface ponding results when precipitation does not immediately infiltrate into the soil or the water table rises above the surface not every ponding event leads to surface runoff leaving the field particularly in depressional topography or areas with high surface roughness accumulated water can infiltrate back into the soil before leaving the field and contribute to the subsurface flow or get lost through evaporation therefore ponding and runoff need to be studied separately although generated by similar processes processes generating surface ponding and runoff and their frequency of incidence in subsurface drained agricultural fields are poorly understood the conditions under which surface ponding and runoff can occur as well as the distinctions between ponding and runoff have received little attention in the literature in many field studies of subsurface drained fields the non growing season has been found to be a critical time for phosphorus loss through surface runoff in regions with cold climates particularly where significant snow cover and winter thaws are experienced e g goulet et al 2006 coelho et al 2012 van esbroeck et al 2016 therefore it is important to have an estimation of surface ponding and runoff in all seasons however monitoring surface ponding and runoff is challenging especially in the cold season and many studies that included winter observations of surface runoff have experienced data gaps due to freezing and equipment malfunction e g goulet et al 2006 jamieson et al 2003 thus hydrological models are often used to simulate surface runoff drainmod skaggs 1978 is one of the most widely used models developed for simulating drainage hydrology it is a field scale process based model that simulates the performance of agricultural drainage and related water management systems in poorly drained soils it has been extensively tested and widely applied in many parts of the world for a wide range of agronomic and climatic conditions e g skaggs et al 1981 ale et al 2009 skaggs et al 2012 drainmod was modified in 2000 to simulate freeze and thaw processes supporting its use in cold climates luo et al 2000 2001 many researchers have used the modified version of the model in cold regions for example wang et al 2006 found that the modified version performed better in winter months in canada than the original model morrison et al 2014 simulated the hydrology of agricultural drained land in canada using drainmod and reported that during the snowmelt period the model performed slightly better in predicting surface runoff than drain flow in this study a 10 year simulation was conducted using drainmod to predict surface runoff in a relatively flat and seasonally frozen subsurface drained agricultural field in eastern indiana the evidence of surface ponding and runoff from this field was also monitored for three years with a time lapse camera and by measuring water table depths for ten years the overall goal of this study is to evaluate the generation of surface ponding and runoff processes at the study site specific objectives of the study were to 1 determine the frequency and extent of surface ponding and runoff 2 determine the relative frequency of infiltration excess and saturation excess processes in generating surface ponding and runoff 3 understand when and how the freeze thaw processes influence simulated surface ponding and runoff in drainmod simulations 2 methods 2 1 site description the study was conducted in the southwest sw quadrant of field w at davis purdue agricultural center dpac a research farm in eastern indiana fig 1 over the 10 years of the study 2007 2016 the mean annual precipitation at this site was 990 mm with approximately 6 of the precipitation falling as snow the mean monthly precipitation was highest in june and the mean snowfall was highest in january and february fig 2 the 10 year mean temperature ranged from 4 4 c in january to 22 6 c in june the study site is relatively flat slope 1 with an area of 3 5 ha consisting of very poorly drained to somewhat poorly drained soil series the subsurface drainage system at this site was installed in 2004 in an experiment to assess the impacts of controlled drainage on ground water recession rate saadat et al 2017 and water and nutrient loss through subsurface drains saadat et al 2018a b a more detailed description of this field can be found in these studies 2 2 field observations water table depth was measured throughout the study period 2007 2016 using an observation well located at the midpoint between two drains 25 m from the outlet and 0 2 m higher in elevation fig 1 the observation well was installed to a depth of approximately 2 m a pressure transducer global water wl 16 was used to measure water table level every hour because of uncertainties associated with the absolute water table elevation caused by water table sensor replacement during maintenance the recorded water table elevation was adjusted up or down by a fixed amount relative to the drain elevation during periods between maintenance activities based on the assumption that drains flow only when water table is above the drain details of this process are provided in saadat et al 2017 small gaps in water table depth measurements fig 3 mainly during the summertime when water table level was often below the drain were excluded from the analysis the end of day water table depth was used as the daily value hourly drain flow was measured using an electromagnetic flow meter krohne waterflux 3070 since 2012 prior to flow meter installation and during the missing periods drain flow was estimated using a theoretical drainage equation hooghoudt and water table depth measurements a daily drain flow record was then constructed from drain flow measurements combined with drain flow estimated using the hooghoudt equation together with linear regression equations as described fully in saadat et al 2018a small gaps still remained in drain flow records mainly during the summertime when drain flow was relatively low compared to other times of the year fig 3 and were excluded from the analysis soil temperature was measured at depths of 10 20 40 60 and 100 cm using soil moisture and temperature sensors decagon 5te 10 cm 5tm others beginning in june of 2011 sensors were installed near the observation well fig 1 in actively farmed areas requiring that the 10 and 20 cm sensors be removed during tillage operations and replaced following planting hourly wind speed and precipitation were measured at the on farm weather station that was located on the western side of the field close to the outlet fig 1 a tipping bucket was used to measure liquid precipitation only because it was not modified to measure solid precipitation daily precipitation liquid and solid as well as daily maximum and minimum air temperatures were measured at the national climatic data center coop station coop 122825 farmland 5 nnw located at dpac precipitation data from the coop station was used to supplement the on farm measurements missing or erroneous wind speed precipitation solar radiation and air temperature data were supplemented by 30 minute data from the purdue automated station https iclimate org 30 min purdue automated also located at dpac in order to collect evidence of surface ponding and runoff a time lapse camera was installed in december 2014 near the drainage outlet to take photos from the field every hour during the daytime the approximate angle of view and the location of the camera are shown in fig 1 two staff gages were made from 5 cm pvc pipes covered by colored tape with each color representing 5 cm depth these staff gages were installed in the field in the camera angle of view for a few months before planting and provided an indicator of ponding depth captured in the photos fig 4 2 3 surface ponding and runoff three different methods two based on observations and one based on model simulations were used to determine the frequency and extent of surface ponding and runoff the first method was based on the hourly time lapse photos the second method used water table depth measurements along with photos and simulation of surface ponding and runoff with the drainmod model was the third method 2 3 1 time lapse photos and processing a total of 13 000 hourly photos were collected from december 2014 to october 2017 due to the camera angle being changed by strong winds the field was not completely visible in photos from july to november 2016 and mid january to early march 2017 therefore these photos were excluded from the analysis photos were classified into five categories based on the ponding depth and extent table 1 fig 5 the ponding classification was based on visual inspection of photos in addition to the approximate measurements obtained from the staff gages that were installed in the field for part of the year fig 4 in the cold season snowmelt ponding was identified if accumulated snow was melted and ponded on the ground the classification of ponding for snowmelt events was similar to rain events using the ponding categories a photo time series was generated for all times when photos were available for the field 2 3 2 water table depth method water table level above the ground surface could be an indication of surface ponding in the field however the measurements only represented the water table level at the well location and since this field is not completely flat the water table level can vary across the field therefore the photo time series was compared to water table depth wtd to find a threshold above which there was evidence of ponding in the field fig 6 a threshold of 35 cm compared well to periods of ponding observed in photos and the same was used to indicate the timing duration and frequency of ponding events in years in which photo evidence of ponding was not available 2 3 3 drainmod drainmod is a process based model that can predict hydrologic variables including infiltration subsurface drainage surface runoff evapotranspiration vertical and lateral seepage and water table depth in the soil profile on a daily monthly or yearly basis skaggs et al 2012 the green ampt equation is used to predict infiltration and surface runoff is characterized by the depth of depression storage that must be filled before runoff can begin in drainmod if the ponded water on the ground surface exceeds the maximum surface storage surface runoff begins otherwise the surface storage indicates the ponding depth that does not lead to runoff leaving the field when the profile is saturated and water is ponded on the surface the drainage rate is calculated using equations developed by kirkham 1957 otherwise the steady state hooghoudt equation bouwer and van schilfgaarde 1963 is used to calculate drainage rate a detailed description of the model can be found in skaggs 1978 2 3 4 model inputs inputs to drainmod include weather soil properties site characteristics drainage system parameters inputs related to the crop and management factors such as timing and manipulation of drainage outlets described in the following paragraphs weather data inputs to drainmod are hourly precipitation maximum and minimum daily air temperatures and daily potential evapotranspiration pet values continuous hourly precipitation and daily maximum and minimum air temperature records 2007 2016 were generated for the study site using measurements from the three different weather stations described in the weather data measurements the daily pet was calculated with the penman monteith equation using the on site measured weather parameters such as shortwave radiation and wind speed chiu 2013 the drain depth drain spacing and drainage coefficient were known for this drainage system table 2 soil survey and additional soil property measurements were used to estimate the depth and thickness of the restrictive layer and the piezometric head of the aquifer was set to be 0 at the top of the restricting layer the equivalent depth from drain to impermeable layer and the kirkham s coefficient were calculated based on the distance between drains and effective drain radius as well as the distance between the drain and the impermeable layer by the internal drainmod subroutine table 2 drainmod requires the effective rooting depth over time which defines the zone from which water can be removed to supply et the corn effective rooting depths were estimated from a minimum of 3 cm to a maximum of 45 cm ale et al 2009 based on a typical planting and harvest date at the site over the study period required soil property inputs to drainmod include lateral saturated hydraulic conductivity and the volumetric water contents of the soil profile at tension values from 0 to 15000 cm table 3 the lateral saturated hydraulic conductivity was estimated for three soil layers using the hooghoudt equation and the measured water table depth and drain flow as described in saadat et al 2018a on site soil volumetric water contents measurements were available at 0 3 50 100 330 and 15000 cm tensions these measurements were obtained from the soil samples which were collected in 2011 2013 and 2015 at four depths from three different sub plots with three replicates kladivko et al 2014 the lower limit of water content in the root zone 0 27 cm3 cm3 was taken from the volumetric water content of the topsoil layer at 15000 cm tension wilting point these soil properties were also used in the drainmod soil utility program to estimate unsaturated hydraulic conductivities volume drained upward flux and green ampt infiltration parameters as a function of water table depth drainmod requires additional inputs in order to reflect the freeze thaw processes luo et al 2000 two soil thermal conductivity constants tka and tkb which are used to calculate soil thermal conductivity as a function of soil water content were obtained from an empirical model with three input parameters including saturated water content of 0 5 cm3 cm3 volume fraction of organic matter content of 0 05 and thermal conductivity of soil solids 10 cal c s c the coefficients of computational depth function az bz were estimated using eq 1 luo et al 2000 by assuming a thermal damping depth of 4 m where annual fluctuation of temperatures are damped out and the soil temperature is assumed constant below this depth table 4 1 z n 1 z n a z b z n 1 n 1 2 20 where zn is the nodal depth from the soil surface e g z1 0 at the soil surface the constants az and bz were calculated by trial and error in order to reach the z21 of 4 m the soil temperature at the bottom of the profile was assumed to be equal to the long term average air temperature penrod et al 1958 the snow melt coefficient and the critical ice content above which infiltration stops were adjusted during the calibration process other soil temperature parameters were taken from luo et al 2000 table 4 the soil freezing characteristic curve sfc describing the relationship between unfrozen water content and soil temperature was derived from eq 2 as described in luo et al 2000 2 h 122 t where t is the below zero temperature c and h is the pressure head in the soil that results from a given t m however since 15000 cm 15 bar was the highest pressure head for which soil water content was measured the only part of the sfc curve obtained from eq 2 and the measured soil water characteristic curve was 0 to 1 2 c therefore the values given in luo et al 2000 were used as initial values for the rest of the curve and were then adjusted in the calibration process table 5 as explained later in the results 2 3 5 surface roughness and infiltration parameters surface runoff is characterized in drainmod by the maximum depth of depression storage that must be filled before runoff occurs if the ponded water on the ground surface exceeds the maximum surface storage sm surface runoff begins otherwise the surface storage does not lead to runoff the maximum surface storage and the minor surface depressional storage sl representing storage in small depressions were taken from the literature and were adjusted during the calibration process table 3 the green ampt equation is used to characterize infiltration in drainmod skaggs 1990 during cold seasons the infiltration may be limited by soil ice content when ice is formed in the soil soil hydraulic conductivities and fillable porosity are modified based on the volumetric content of ice and unfrozen water in the soil luo et al 2000 when the ice content exceeds the critical ice content given as model input infiltration stops and water is accumulated as surface storage ponding when the rainfall rate exceeds the infiltration capacity calculated by eq s1 the excess water is accumulated as surface storage ponding and when the surface storage exceeds the maximum surface storage depth the additional excess is surface runoff skaggs 1978 2 3 6 calibration and validation strategy the drainmod model was calibrated by adjusting the sensitive parameter inputs that were not available from direct measurements within an established range table 6 the parameter range was based on a guideline provided by skaggs et al 2012 and the values reported by other researchers especially for soil temperature parameters luo et al 2000 sands et al 2003 wang et al 2006 singh et al 2006 yang et al 2007 ale et al 2009 morrison et al 2014 garmdareh et al 2018 daily observed and predicted water table depths and drainage volumes from 2007 to 2016 were plotted and compared visually with respect to both the timing of occurrence and the magnitude of response observations from 2010 to 2014 were used for validation and other years were used for calibration of the model calibration and validation periods were specified in a way that each period contains both wet and dry years as well as measured drain flow additionally the surface ponding time series created from time lapse photos from 2015 and 2016 were visually compared to the drainmod ponding and runoff predictions for qualitative calibration of surface storage parameters the maximum surface storage parameter in drainmod was adjusted to find the best agreement between the photo time series and drainmod estimates of surface ponding and runoff the agreements between monthly predicted and measured drain flow and daily water table depth were quantified by statistics including the nash sutcliffe efficiency nse nash and sutcliffe 1970 and percent bias pe which are relative error measures as well as the average deviation ad which is an absolute error measure please see supplemental information for additional details 3 results 3 1 surface ponding and runoff 3 1 1 photo estimate of ponding the majority of ponding events observed with cameras were classified in categories 1 and 2 fig 6 in each year there were only a few severe and extreme ponding events category 3 4 that were expected to cause surface runoff table 7 indicating ponding does not always lead to runoff however the photo time series was not available for the entire year in 2016 and 2017 due to the camera angle being changed by strong winds the field was also buffered by grass at the edges for most of the time fig 8 therefore accumulated water often infiltrated into the soil or evaporated before it could run off the field 3 1 2 water table depth estimate of ponding during the periods when both photo and water table depth wtd observations were available 32 ponding events were captured by both methods for each event in which there was photo evidence of ponding the wtd was always below the threshold 35 cm there was only one ponding event estimated with the wtd method that was not captured by the photo method because it occurred during the night when the camera was turned off the 100 correspondence between water table estimate of ponding and photo estimate of ponding suggests that saturation excess was the driving force for all ponding events observed at this site the ponding frequency and duration varied over years table 8 ponding frequency ranged from 8 to 24 events per year and the total duration of ponding in a year ranged from 15 to 43 days there was not a correlation between the frequency and duration of ponding for instance ponding duration in 2009 with 8 ponding events was similar to that in 2010 and 2014 with 22 events with the wtd method unlike the photo method the ponding events were not classified into different categories however the inverse correlation between photo category and the minimum measured water table depth during a wtd ponding event provides indirect information on the extent of ponding fig 9 when the wtd was close to the ground surface there was photo evidence of runoff photo category 3 4 all of the ponding events that likely led to runoff according to photos occurred when the wtd was below 8 cm therefore runoff was not expected when the wtd 8 cm but not all of the ponding events with wtd 8 cm led to runoff 3 1 3 drainmod estimate of ponding and runoff the simulated annual water balance indicated that on average surface runoff accounted for 7 of the annual precipitation while et and drain flow accounted for 51 and 34 respectively fig 10 the range over the 10 years was from 24 to 53 cm yr 1 and 1 to 12 cm yr 1 for annual drain flow and runoff respectively on average over 10 years water loss through drain flow and runoff was the highest in march and the lowest in september fig 10 the number of ponding and runoff events and total duration of ponding events simulated with drainmod are listed in table 8 the simulated ponding frequency ranged from 4 to 13 events per year and total ponding duration ranged from 4 to 34 days per year around 50 of all simulated ponding events produced surface runoff when drainmod predicted a ponding event the simulated water table depth was zero meaning that all of the drainmod estimates of ponding were saturation excess ponding 4 discussion 4 1 comparison of ponding frequency and duration obtained from time lapse photos water table observations and simulations the comparison between photo wtd and drainmod results indicated that drainmod predicted fewer ponding events than what was observed in the field according to photos and water table depth measurements fig 11 on average over 10 years 2007 2016 drainmod predicted 8 ponding events per year 16 days total while the water table depth wtd method estimated 18 ponding events 30 days total runoff occurred only 4 times per year on average according to both drainmod and photo estimates meaning that drainmod under predicted the frequency of ponding more than it under predicted runoff the under prediction of ponding events in drainmod could be due to the spatial variability in ponding generation and drainmod s limitations in representing spatial variability drainmod assumes that the field is completely flat therefore it only predicted the extreme ponding events that occurred when the entire field reached saturation however in reality there was an approximately 2 m elevation change in the study field and water usually accumulated in the corner of the field where the time lapse camera was located and captured the ponding events that occurred when just a portion of the field was saturated to determine the impact of elevation change on drainmod ponding predictions similar to the wtd method the threshold of 35 cm was used instead of the ground surface for identifying saturation excess ponding events using the drainmod simulated water table results indicated that drainmod would predict around 13 ponding events per year on average which is closer to the 18 events per year observed on average overall the low percentage of generated runoff 7 of the annual precipitation was comparable to what others have found in drained agricultural fields for example in a simulation study in iowa singh et al 2007 reported that only 5 of annual precipitation contributed to surface runoff from an experimental study conducted in three agricultural fields in ontario canada van esbroeck et al 2016 also concluded that only 5 10 of precipitation contributed to surface runoff 4 2 runoff generation processes according to all three methods a portion of ponding events occurred during the cold season dec mar indicating that cold season processes may also affect the ponding and runoff generation at this field table 9 the seasonal distribution of observed and simulated ponding events varied in each year however ponding resulting from snowmelt was not very frequent in this field during the period in which photo evidence of ponding was available dec 2014 to oct 2017 only three events were observed that were generated by snowmelt or snowmelt combined with rain events shown in fig 12 both simulated and observed results indicated that all ponding events were due to saturation excess rather than infiltration excess according to water table depth which was below the threshold 35 cm for every ponding event simulated or observed in the field in the cold season soil temperature at 10 cm depth was less than or equal to 0 c about 6 of the time however none of the cold season ponding events occurred at these times suggesting that partially frozen soil rarely if ever contributed to the ponding generation process simulation of infiltration excess ponding is dependent on parameter selection for the infiltration equation in drainmod green ampt and so could in theory be calibrated to occur more frequently however saturation excess ponding predicted with the model was comparable to the photo evidence of ponding which always occurred when wtd was below the threshold 35 cm additionally the results found in this study were in agreement with the findings of bou lahdou 2014 for the dpac site they found that when surface ponding occurred at the field according to water table measurements the average precipitation intensity was low indicating that saturation excess was the driver of ponding generation rather than infiltration excess appels et al 2016 found that not only the field topography but also the type of surface runoff generation process is an important factor in the dynamics of the hydrological connectivity in flat agricultural fields in the netherlands it is important to understand that both topography and process can impact the relationship between precipitation volume and connectivity this understanding can help to improve the use of hydrological connectivity indicators in watershed scale hydrological models 4 3 limitations in simulating cold season processes in drainmod drain flow was over predicted in march in some years due to the freeze thaw processes and snowmelt impacts however it was mainly under predicted in cold months likely due to soil freezing impacts frozen soil limits infiltration so soil temperature plays a key role in simulating infiltration and drain flow in drainmod soil surface temperature is set equal to air temperature except during periods of snowcover when the snowpack on the ground insulates the soil and lowers the heat losses from the soil surface however drainmod did not predict the snow accumulation and melt accurately for parts of the cold season fig 13 a partly because of using the daily average air temperature as a basis for dividing snow and rain while there were frequent changes in hourly air temperatures in indiana additionally drainmod possibly did not simulate insulation of the soil surface due to snow sufficiently therefore the soil surface temperature boundary condition tended to be too low during periods of observed snow cover resulting in under prediction of soil temperatures throughout the soil column shown for the 10 cm depth in fig 13 b excessively cold simulated soil temperature led to a reduction in infiltration and drain flow estimations fig 13 c and it increased the water storage as ice in the soil profile by reducing infiltration and slowing drain flow the simulated frozen soil can also contribute to generating ponding and runoff or add to the existing conditions under which ponding is generated to increase the depth and extent of ponding and runoff during the times when the soil was not frozen march april drain flow was very well predicted in that year in order to overcome the impacts of excessively cold simulated soil temperatures on drain flow and runoff predictions the freezing characteristic curve sfc was adjusted for temperatures below 0 c by assigning greater unfrozen water contents than what were obtained from the method described in luo et al 2000 table 5 in addition the soil freezing curve needed to be defined down to 30 c in order to achieve model stability lamya negm personal communication adjusting the sfc improved drain flow predictions by increasing the flow peaks and consequently reduced surface runoff slightly fig 14 other drainmod users also reported similar difficulties in cold regions for example yang et al 2007 used drainmod n in ontario canada to simulate nitrate movement and concluded that the model had difficulty in simulating drain flow accurately when soils were frozen in winter and thawed in spring in another study sands et al 2003 used drainmod to predict drain flow in minnesota and concluded that the model over estimated drain flow during snowmelt soil freeze and thaw processes play important roles in the hydrology of seasonally frozen regions yet are not easy to predict future research can further investigate the impacts of these processes in a drained agricultural field and improve drainmod predictions in seasonally frozen regions 5 conclusions surface ponding and runoff were estimated in a seasonally frozen drained agricultural field in eastern indiana using three methods including photo observations water table monitoring and model simulations resulting in the following conclusions multiple lines of evidence of surface ponding and runoff provided more information than just one photos provided direct evidence of ponding but only on a small portion of the field for parts of the study period water table depth provided a simple alternate method for identifying saturation excess ponding drainmod predicted surface ponding and runoff over the whole field assuming it is flat but not the spatial variability of ponding surface ponding was more frequent than runoff indicating not every ponding event led to runoff the estimated annual water balance indicated that 7 of annual precipitation contributed to surface runoff while 93 contributed to et subsurface drainage and seepage results from both simulation and observation methods indicated that all of the ponding events were generated as a result of saturation excess processes rather than infiltration excess the seasonal distribution of ponding events varied in different years but on average the wtd method and drainmod results both indicated that about 45 of ponding events over 10 years occurred in the cold season dec mar adjusting the soil freezing characteristic curve sfc in drainmod improved the simulation results in cold season by preventing under prediction of drain flow and over prediction of runoff the drainmod model results together with field observations contribute to a better understanding of surface ponding and runoff generation in an agricultural drained field as well as understanding the long term water balance and the role of surface storage in flood mitigation erosion prediction and generation of ephemeral gullies this understanding will be useful for model development and management recommendations for water resources at the field or watershed scales credit authorship contribution statement samaneh saadat conceptualization data curation formal analysis methodology validation visualization writing original draft writing review editing jane frankenberger supervision resources writing review editing laura bowling supervision resources writing review editing srinivasulu ale writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this material is based upon work that is supported by the national institute of food and agriculture u s department of agriculture under award number 2011 68002 30190 cropping systems coordinated agricultural project climate change mitigation and adaptation in corn based cropping systems http sustainablecorn org and award number 2015 68007 23193 managing water for increased resiliency of drained agricultural landscapes http transformingdrainage org any opinions findings conclusions or recommendations expressed in this publication are those of the author s and do not necessarily reflect the view of the u s department of agriculture we thank charlotte lee from the purdue agronomy department for helping with the calculation of daily potential evapotranspirations and lamya negm from north carolina state university for her guidance and providing a new executable file for drainmod that provides the simulated snow depth as an output appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 124985 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5322,reference evapotranspiration eto is one of the key components of the hydrological cycle that is effective in water resources planning irrigation and agricultural management and other hydrological processes accurate estimation of eto is valuable for various applications of water resource engineering especially in developing countries such as iran which has no advanced meteorological stations and lacks facilities and information also due to the existence of different climates in iran the estimate of eto has become a challenge to this end the aim of this study is to estimate the eto to eliminate the two limitations of the absence of a comprehensive model for all climates and the scarcity of meteorological information in iran the present study investigates the ability of the hybrid artificial neural network gray wolf optimization ann gwo model to estimate eto for iran the accuracy of ann gwo was evaluated versus least square support vector regression ls svr and standalone ann the development of models is based on meteorological data of iran s 31 provinces consists of 5 different climates based on empirical equations and least inputs seven different input scenarios were introduced and penman monteith reference evapotranspiration was considered as the output of the models several statistical indicators including si mae u95 r2 global performance indicator gpi and taylor diagram were used to evaluate the performance of the models the results showed that the gwo algorithm acted as an efficient tool in optimizing the structure of the ann and the ann gwo model was more accurate than ann and ls svr in all scenarios ann gwo6 with inputs of wind speed maximum and minimum temperatures had the lowest error and decreased in terms of si index by 42 compared to ann6 and 30 compared to ls svr6 furthermore based on gpi it is in the first place with a 99 reduction compared to ann6 and ls svr6 the hybrid approach used in this study can be developed as a trustful expert intelligent system for estimating eto in iran keywords artificial neural network grey wolf optimization hybrid model least square support vector regression reference evapotranspiration shannon entropy 1 introduction in developing countries such as iran the main reason for the water shortages is not necessarily the lack of access to water resources but the misuse of water evaporation is a key process in the hydrological cycle that is one of the essential factors in the planning and utilization of water resources penman 1948 stewart 1984 the average annual rainfall in iran is 251 mm over 70 of which is spent on evapotranspiration et kousari and ahani 2012 therefore the accuracy estimation of crop water requirement is a necessity allen et al 1998 the united nations food and agriculture organization fao has proposed the use of reference et eto to calculate crop evapotranspiration doorenbos 1975 eto is the evaporative potential of the atmosphere regardless of the management method crop type and growth stages of the plant fao has proposed the penman monteith equation fao56 pm as a standard method for estimating eto and calibration of other empirical and semi empirical models droogers and allen 2002 a significant limitation of using fao56 pm is in its high number of meteorological variables and their uncertainty the dynamic nature of meteorological variables is due to their non linearity non stationary and stochastic properties therefore evapotranspiration as a complex phenomenon requires methods beyond empirical models in recent decades artificial intelligence ai techniques have proven their ability to model complex nonlinear phenomena such as eto baba et al 2013 ferreira et al 2019 kişi 2006 kumar et al 2011 kumar et al 2002 nourani et al 2019 nourani et al 2020 sanikhani et al 2019 shiri 2018 shiri 2019 tabari et al 2012 as well as water resource management issues emamgholizadeh et al 2014 maroufpoor et al 2018 maroufpoor et al 2017 maroufpoor et al 2019b sanikhani et al 2019 few studies have reported the integration of ai models with meta heuristic approaches prasad et al 2018 shamshirband et al 2016 shekofteh et al 2017 tao et al 2018 yaseen et al 2018 the meta heuristic approaches are divided into two groups of single solution based and population based the single solution based search process starts with one candidate and improves in subsequent iterations but in population based the optimization is done using a set of solutions population the search process starts with a random initial population random solutions and improves with iteration this population will also result in this approach not being trapped in optimal local solutions mirjalili et al 2014 introduced the gray wolf optimization gwo algorithm as a multi solution meta heuristic approach the gwo algorithm is coupled with ai approaches and improves their performance in prediction problems amar et al 2018 behnood and golafshani 2018 dai et al 2018 hadavandi et al 2018 maroufpoor et al 2019a sweidan et al 2015 yu and lu 2018 zein et al 2019 another important factor in modeling is the selection of effective variables these variables are obtained using the pearson s correlation coefficient the parameters in the empirical and semi empirical equations or the sensitivity analysis of each variable in the model however with the rise of entropy theory in hydrology the importance of each variable can be assessed this theory which is based on shannon 1948 has been extended to various subjects and has been applied to hydrological studies singh 1997 singh 2013a singh 2013b unlike statistical methods entropy theory does not require prior assumptions of the type of distribution function linearity or normality of the variable ellenburg et al 2018 in the present study it is attempted to investigate the uncertainties of variables using informational entropy principles providing a comprehensive model for a country or an entire region relying on fewer input variables is one of the crucial issues with eto modeling jing et al 2019 which is the basis of the present research objectives previous researches on eto in iran have proved the ability of ai models to estimate eto under certain climatic conditions e g kiafar et al 2017 rahimi khoob 2008 shiri 2017 shiri 2018 however in the present study this limitation has been eliminated to great extent by developing and testing the applied models based on comprehensive meteorological data gathered throughout the entire area of iran including 5 different climatic regimes further a major problem in some areas of country is data scarcity for producing reliable eto values to be used in different necessities the models developed in this research however utilize fewer meteorological variables so their applications under data scarcity conditions will be valuable from practical viewpoint finally although most of the eto modeling studies developed their ai models in concordance to the available empirical equations the present study have tested an additional entropy analysis to test and importance of each variable at each location with different climatic context also to achieve promising results gwo integrated with artificial neural network ann was introduced as a powerful hybrid method in estimating the eto in iran in addition the performance of ann gwo against least square support vector regression ls svr and standalone ann models is evaluated it is worth noting despite the numerous applications of gwo in various subjects to the best of the authors knowledge the ability of the gwo algorithm to estimate eto in iran has not yet been investigated 2 materials and method 2 1 case study and data description the studied area in this research is the entire region of iran s geographical area 25 00 n and 38 39 n latitudes between 44 00 e and 63 25 e longitudes including 31 provinces with an area of about 1650000 km2 fig 1 the loss of 70 of annual mean precipitation through et in iran kousari and ahani 2012 has a significant impact on the hydrological cycle of the country therefore it is necessary to obtain an accuracy estimate of et in different climates of iran as shown in fig 1 the monthly meteorological data for the 31 provinces including maximum and minimum temperatures tmax tmin c relative humidity rh wind speed u2 m s sunshine hours ssh h and precipitation were collected from the meteorological organization the data was selected during 2012 2017 but due to the lack of significant changes in meteorological variables 2017 was introduced as the representative of the 6 year period to evaluate the ann gwo hybrid model it should be noted that the long term average of meteorological variables was not used because of their random nature table 1 shows the general information of the applied provinces and the average of meteorological data the aridity index ia was also calculated as an indicator of climate drought according to equation 1 unep 1992 table 1 1 i a p e t 0 where p mm is average annual precipitation and eto mm is the annual reference evapotranspiration based on ia the provinces can be divided into three main cluster hyper arid and arid area ia 0 2 semi arid 0 2 ia 0 5 and sub humid and humid ia 0 5 unep 1992 according to table 1 the main clusters of hyper arid and arid area semi arid and sub humid and humid include 7 13 and 11 provinces respectively 2 2 shannon entropy information content shannon 1948 showed that events with a high probability of occurrence provide less information and events with a low probability of occurrence provide more the information in other words entropy is mathematically a statistical measure of randomness or uncertainty in entropy theory information does not necessarily mean useful information it only specifies the randomness of the event the following steps will be used to calculate entropy the y matrix is made as follows 2 y 11 y 12 y 1 n y 21 y 22 y 2 n y m 1 y m 2 y mn where n is the number of samples of each variable i 1 2 3 n and m is the number of variables j 1 2 3 m the y matrix is then normalized using equation 3 3 z ij y ij y ij min y ij max y ij min where zij is the normalized variable yij min and yij max are the minimum and maximum values of each variable respectively the probability of each variable pij is calculated as follows 4 p ij y ij 0 0001 i 1 m y ij 0 0001 finally information entropy ej and entropy weight ew are expressed by eqs 5 and 6 respectively 5 e j 1 ln m i 1 m p ij ln p ij 6 e w j 1 e j j 1 n 1 e j ew shows the relative importance of the parameters the sum of the ews of the parameters is one so the more weighted parameter closer to one is more important 2 3 input combinations the eto calculated by the standard equation of fao56 pm was utilized as a benchmark for evaluating other applied models that is a common process as it was mentioned in the literature review martí et al 2015 shiri 2017 shiri 2019 shiri et al 2014b tikhamarine et al 2019 numerous studies have investigated various methods of estimating eto in different regions according to the united nations food and agriculture organization fao recommendation allen et al 1998 penman monteith equation fao56 pm i is approved as the standard method of estimating eto in different regions and climates without the need for calibration also to prove the performance of the fao56 pm method the american society of civil engineers asce investigated the performance of twenty different methods compared to lysimeter data from 11 regions with different climate conditions eventually each method was effective in unique climates and only fao56 pm s method was capable to provide reliable results for different climates allen et al 1998 therefore application in different climates and time periods is one of the advantages of the fao56 pm method to elect effective input combinations two factors were considered including empirical and semi empirical equations in eto estimation and least inputs empirical and semi empirical equations are divided into three categories mass transfer based brockamp and wenner 1963 dalton 1802 mahringer 1970 meyer 1926 penman 1948 rohwer 1931 trabert 1896 radiation based makkink 1957 priestley and taylor 1972 turc 1961 and temperature based hargreaves and samani 1985 in this study entropy weight and the absolute correlation coefficient were used to confirm the efficiency of the variables of these equations fig 2 it is clear that the correlation coefficient s values of all variables were above 0 6 except p but two variables of rh and p had inverse correlation coefficients also the highest entropy weight was related to rh ew 0 25 followed by tmin and tmax with 0 23 and 0 22 respectively the lowest ew was related to p ew 0 05 due to its high uncertainty finally the input scenarios were presented in table 2 based on all three categories of mass transfer radiation and temperature based as well as the literature review martí et al 2015 shiri 2019 shiri et al 2014b shiri et al 2019 tao et al 2018 tikhamarine et al 2019 yaseen et al 2020 the studied provinces were randomly divided into train 70 and test 30 groups as recommended by the previous literature pour ali baba et al 2013 shiri et al 2014a shiri et al 2013 to reach promising conclusions as the final model needs to be applied to all climates in iran 70 of the provinces in each cluster were considered as the train group and the rest of them as the test group thus 70 of the provinces with hyper arid and arid climate 5 provinces semi arid 9 provinces sub humid and humid 8 provinces were selected as inputs in the training section 3 applied ai models 3 1 least square support vector regression ls svr svr is one of the supervised learning methods in nonlinear prediction problems its initial algorithm was introduced by cortes and vapnik 1995 the basis for estimating the functions in the svr is the linear classification of the data and in separating the data it is attempted to determine a line with the most confidence level finding the optimal line equation is done by convex quadratic programming which is a well known method for solving bounded problems therefore solving large scale problems using this method requires high computational cost and also complicates the algorithm finally suykens and vandewalle 1999 proposed the ls svr model the ls svr also has the initial limitations of the svr model but uses linear equations to solve the problems which results in lower complexity higher accuracy and speed in this study based on the literature review chen et al 2019 eslamian et al 2009 moghaddamnia et al 2009 three types of kernel functions of linear polynomial and radial basis function rbf were used and the best kernel was selected based on minimum root mean square error rmse 3 2 artificial neural network ann was first introduced by rosenblatt 1958 as a computational method this method is based on parallel processes of biological nervous systems and is capable of communicating between inputs and outputs of a process without full knowledge of its physics the most common type of ann is feed forward network which is trained by the back propagation algorithm coulibaly et al 1999 the ann architecture usually consists of three layers input hidden and output the input layer has the role of acceptance and distribution of input variables the hidden layer performs data processing and finally the output layer contains a variable that is simulated for specified inputs mcclelland and rumelhart 1989 each layer consists of several neurons that are processor units the neurons in each layer have the same activation functions and the same training algorithm the most important characteristic of neurons in one layer is simultaneous computing in other words the calculations for one layer are entirely performed and then the next layer calculations are performed in this study three layers with back propagation algorithms were used and different propagation algorithms were evaluated for each input combination finally levenberg marquardt was utilized as the best training algorithm the activation functions and the number of neurons in the hidden layer were selected based on the trial and error and the lowest rmse value among the activation functions sigmoid tangent in the hidden layer and the linear function in the output layer had the least error 3 3 grey wolf optimization gwo the gwo is an evolutionary approach inspired by the behavior of gray wolves and follows a series of hunting steps of gray wolves in nature gwo has been introduced by mirjalili et al 2014 there are four groups of gray wolves including alpha α beta β delta δ and omega ω the gwo consists of three stages of the search surround and attack to prey muro et al 2011 alpha wolves have the highest social responsibility and all decisions e g hunting time and place of sleeping and awaking are made by them and their instructions must be followed by other groups alpha wolves are not necessarily the strongest members but they are more capable of manage the group than other wolves beta wolves follow the alpha and help them make decisions when an alpha wolf is lost the candidate wolves are selected from the beta group the wolves at the bottom level who are the victims are the omega wolves these wolves are obedient to other wolves and are the last group in terms of eating food the wolves other than the three groups of alpha beta and omega are called delta delta wolves are followed alpha and beta and have duties such as scouting guarding hunting and care taking in the gwo mathematical model each gray wolf is considered as a candidate solution initially a set of wolves is randomly generated candidate solution the wolves position is updated based on the target function then in the case of maximization or minimization of the problem the wolves are arranged in descending or ascending order finally the first three wolves alpha beta and delta respectively are considered as the best solutions more information about gwo can be found in mirjalili et al 2014 3 4 proposed hybrid approach the back propagation algorithm used in ann is a systematic way to train multilayer networks the purpose of training the network is to adjust the weights and bias values of each neuron so that the difference between the observed and simulated values is minimized the back propagation training algorithm is based on the error correction learning rule that follows two main paths in the network the first path is forward where the input vectors are applied to the network and by passing the hidden layer the answer is obtained in the output layer the second path is backward and from the output layer to the input layer in this path the error in the output layer is reduced by adjusting the parameters weight and bias therefore each layer is composed of one or more neurons which have specific tasks and set the basis of the network s performance and behavior the inputs are affected by the weights of each neuron and are mapped to an activation function with a constant value bias eventually some values will be produced in the layer and they will be presented to the other layer or will be the output of the network therefore the weight and bias of each neuron have the primary role in estimating the target variable with the least error mirjalili et al 2012 zhang et al 2007 in this study the gwo algorithm is introduced into the ann structure as a network training to determine the weight and bias of each neuron more accurately the selection of weight and bias in each iteration are updated based on the gwo algorithm so gwo seeks to limit the decision space to cross the local optimal values and achieve a global solution in the training phase where error between the estimated and the target values of eto are used to update the parameters the gwo generates the initial population of alpha beta and delta wolves and determines the location of each wolf then the position of α β and δ are updated based on the target function which represents the error value between the estimated and the target values of eto the next step is updating the position of the other solutions other wolves with respect to the values of α β and δ the stopping condition is to reach the maximum number of iterations or the error lower than the specified threshold finally after placing the final solution in the ann the evaluation of the hybrid model in the test section is started and the eto value is estimated network training with the gwo will avoid problems such as overfitting or trapping in local optimizations and the ann gwo hybrid model can perform better than the ann mirjalili 2015 and achieve global optimization changing the objective function might alter the outcomes merely but it should be noted that the applied function in this research is root mean square error rmse or mean square error mse both relying on giving more weights on larger errors willmott and matsuura 2006 although mae might be applied here it could not assign weights to different errors because it simply calculates the errors as differences between the target and output values so information gathered based on rmse or mse would be more reliable than those of using mae one may also apply si the weighted rmse that exempts the results from the average values of the target parameter but as the goal with gwo is reducing the errors within the model structure both si and rmse would give the same results however applying si for assessing the models between different stations with different eto ranges would be preferable fig 3 shows the ann gwo flowchart the ls svr ann and ann gwo were implemented using by the toolbox of matlab 3 5 evaluation of models performance in this study different statistical indices including scatter index si coefficient of determination r2 and mean absolute error mae were used to evaluate the performance of models also uncertainty with 95 confidence level u95 behar et al 2015 gueymard 2014 and global performance indicator gpi stone 1993 were used to evaluate the models deviation from target values and to rank them respectively gpi is a 5 agent index including the simultaneous effect of mean bias error mbe t statistic test tstat u95 r2 and rmse the equations of the applied indices are as 8 si rmse e t c 1 n i 1 n e t ci e t ei 2 e t c 9 mae 1 n i 1 n e t c i e t e i 10 r 2 i 1 n e t ci e t c e t ei e t e i 1 n e t ci e t c 2 i 1 n e t ei e t e 2 2 11 t stat n 1 m b e 2 rms e 2 m b e 2 12 u 95 1 96 s d 2 r m s e 2 13 gpi m b e r m s e u 95 t stat 1 r 2 where etei and etci are ith eto values estimated and calculated by fao56 pm respectively and e t e and e t c are average values of eto estimated and calculated by fao56 pm respectively in addition n represents the number of data and sd is standard deviation difference between the estimated and calculated values of eto the closest value to zero indicates good performance for all indices except r2 and the best value for r2 is 1 according to li et al 2013 the si index is divided into four ranges for evaluating models performance including excellent when si 0 1 good if 0 1 si 0 2 fair if0 2 si 0 3 and poor if si 0 3 4 results and discussion 4 1 evaluation of models in this study seven input scenarios were used to calculate eto according to table 2 the scenarios presented were used to develop the ann model by the gwo algorithm table 3 presents the results of estimating eto by the ann ann gwo and ls svr models in the ls svr model among three kernel functions the linear kernel was the most used for four scenarios in terms of the lowest rmse value the ls svr6 model which includes inputs of tmin tmax u2 with si and mae of 0 105 and 0 410 mm respectively had the most accuracy and located in a good range based on si index ls svr6 had a decrease of 36 in si and 37 in mae compared to ls svr7 ls svr4 also showed the worst results with si and mae of 0 202 and 1 260 mm respectively fig 4 shows the scatterplots of estimated and calculated values of eto for different scenarios in ls svr fig 3 also confirms that the ls svr6 is most consistent with the 1 1 line y x kotz et al 1982 the literature have introduced ls svr as an efficient model for estimating eto kişi and cimen 2009 mohammadrezapour et al 2019 wen et al 2015 in the ann model for all the scenarios the lm algorithm was determined based on the least rmse the number of neurons in the hidden layer is an important factor in the ann structure that depends on the type and number of inputs faris et al 2019 the literature review has recommended many rules for determining it based on the number of inputs hecht nielsen 1987 hush 1989 kaastra and boyd 1996 kanellopoulos and wilkinson 1997 but generally there are no specific rules for determining it in this study to achieve the highest accuracy in ann the number of neurons in the hidden layer was determined by trial and error in the range of 1 20 this process was also repeated for gwo but the number of neurons in the hidden layer in ann gwo was equal to ann due to the fixed input type and number structure 2 4 1 represents 2 inputs corresponding to tmin tmax 4 neurons in the hidden layer and 1 output eto the number of iterations required to train the lm algorithm was 1000 and it was noteworthy that the increase in accuracy for the iterations of more than 1000 was negligible the ann4 model which includes the inputs of tmin tmax rh and ssh with si and mae of 0 122 and 0 454 mm has the most accuracy and followed by ann6 with si and mae of 0 133 and 0 506 mm all input scenarios in the ann except ann5 are within the good range based on the si index the ann4 had the largest number of input neurons 16 neurons in the hidden layer and this provided the basis for an acceptable accuracy of eto estimation in general increasing the number of neurons will increase the number of processing units in the model which will make the model more complex if the model is able to solve this complexity an accurate estimate is made otherwise the complexity will reduce the accuracy of the model the ann4 with 39 in si and 42 in mae had the highest improvement over ann5 fig 5 shows the scatterplots for the results of different ann scenarios according to fig 4 the ann4 regression equation with slope value near to one and the lowest intercept elevation had the best estimation of eto a number of studies have demonstrated the ability of the ann to estimate eto antonopoulos and antonopoulos 2017 ferreira et al 2019 kisi and kilic 2016 kumar et al 2002 landeras et al 2018 sudheer et al 2003 in the ann gwo hybrid model the initial population size and number of iterations were considered in the range of 15 30 and 200 1500 respectively based on the lowest rmse in intelligent optimization algorithms e g gwo diversity in the initial population reduces computational time and improves convergence in the global solution haupt and ellen haupt 2004 since the ann gwo models have been trained with different inputs at each scenario the structure of the models will be different accordingly to achieve the best results in each scenario the initial population and iterations were determined by trial and error and the results of which are presented in table 3 in the structure section nevertheless there is no fixed suggested rule to fix those values in these models in literature table 3 shows that for all scenarios ann gwo has superiority over ann and ls svr fig 6 shows the scatterplots of ann gwo in estimating eto the highest accordance with 1 1 line y x kotz et al 1982 is observed in ann gwo4 and ann gwo6 that evaluation of the regression line equation y ax b in ann gwo6 confirms that the values of a and b have the smallest difference δa 0 0011 δb 0 0192 with ideal values a 1 b 0 where indicating the ability of the model to estimate eto 4 2 comparison of the applied models according to table 3 ann gwo6 had the lowest si and mae of 0 07 and 0 279 mm respectively the structure used for ann gwo6 had an initial population of 30 and 1500 iterations also ann gwo4 with si and mae of 0 090 and 0 333 mm is located after ann gwo6 the si value illustrates the ann gwo4 and ann gwo6 performance at the excellent range according to li et al 2013 and the rest of the scenarios are in a good range the inputs in ann gwo6 were tmin tmax and u2 which can be easily measured at any station the comparison of inputs in the ann gwo6 against ann gwo4 illustrates the higher importance of wind speed which is in agreement with the conclusions obtained by as shiri 2017 in the hybrid model the highest improvement was observed for ann gwo6 in against ann gwo5 with a decrease of 59 in si and 61 in mae the 5th scenario with rh and ssh inputs has the least accuracy in both ann and ann gwo models although the 4th scenario in the ann si 0 122 mae 0 454 mm and ann gwo si 0 090 mae 0 333 mm had promising results but it showed the worst result in ls svr si 0 320 mae 1 268 mm this implies that model structure and type are two important factors for estimating reference evapotranspiration eto fig 7 illustrates gwo s ability to increase the accuracy of eto estimation in all scenarios comparing to ls svr and standalone ann models the most accuracy for ann gwo ann and ls svr models were for scenarios 6 4 and 6 respectively boxplot was used to analyze the residuals estimation error in the ann gwo6 ann4 and ls svr6 models fig 8 which show positive and negative estimation errors as under and over estimations respectively the boxplot is a standard way of showing the error distribution based on four values first quartile q1 third quartile q3 interquartile range iqr and a section inside the rectangle showing the median the position of these values has been illustrated in fig 9 q1 and q3 report for 25 and 75 percent of the errors respectively ann gwo6 with q1 of 0 203 performed better than both ann4 q1 0 284 and ls svr6 q1 0 315 it should be noted that the importance of q3 in error analysis is more than q1 because it covers 75 of the error that here ann gwo6 with a difference of δq3 0 244 compared to ann4 and δq3 0 163 compared to ls svr6 has higher performance accuracy the smaller iqr in ann gwo6 than the other two models clearly indicates that the error distribution is around zero and also the median line at the center of the rectangle shows the normality of error distribution in addition the iqr in the ls svr is lower than the ann based on the median line it can be concluded that ls svr and ann are overestimated and underestimated respectively seyedzadeh et al 2020 recommend that the u95 index to evaluate the results deeply and also the gpi index for overall ranking as an analyzes multiple can be used the u95 is used to show the deviation of the estimation results from the target values the results of the u95 for different scenarios have been shown in fig 9 the range of changes in this index was 1 03 4 24 that its lowest and highest values were related to ann gwo6 and ls svr4 respectively in this index ann gwo6 performance had less error than other scenarios in the three scenarios of 1 5 and 7 the performance of the models was similar and in other words there was no increase in the accuracy of estimation in different models this confirms that input combinations of 1 5 and 7 have reached their maximum fitting for eto the gpi index was used to investigate the collective effect of different statistical indices different indices analyze models at their individual levels but gpi as a reliable index shows the impact of rmse mbe tstat u95 and r2 indices simultaneously and is a tool for ranking models in estimating eto fig 10 shows the gpi values for models with gpi 0 01 based on the obtained gpis all models in fig 10 have high accuracy and performance for estimation gpi values ranged from 0 00005 to 1 the maximum gpi was related to the ls svr2 the ability of the ann gwo6 is clearly in comparison to other models and followed by ann2 however ann gwo6 had a 96 decrease compared to ann2 based on previous statistical indices ann4 and ls svr6 and based on gpi index ann2 and ann gwo2 models were close to ann gwo6 finally the taylor diagram was utilized to determine how much the estimated reference evapotranspiration eto is matched to the fao56 pm fig 11 the most accurate models compared to fao56 pm in terms of different statistical indices were ann gwo6 ann gwo4 ann gwo2 ann2 ann4 and ls svr6 which were evaluated in taylor diagram the highest and lowest accordance with fao56 pm standard deviation line was related to ann gwo6 and ann2 respectively moreover in the rmse index except for ann gwo6 and ann gwo4 the rest of models are in the second radius compared to the target point 5 conclusion the purpose of the present study was to estimate the reference evapotranspiration eto in the context of eliminating the two limitations of the lack of a comprehensive model for all climates and the scarcity of meteorological information in iran to this end the ann model was improved using the gray wolf optimization algorithm ann gwo eto was calculated for iran s 31 provinces and their different climates including hyper arid arid semi arid sub humid and humid seven scenarios were selected as inputs based on the empirical equations and least inputs the ann gwo results were evaluated for seven input scenarios and compared with ann and ls svr the results of different statistical indices showed that ann gwo was more efficient than ls svr and standalone ann in all scenarios and gwo algorithm was a powerful tool in optimizing ann structure the improvement of results using gwo compared to the standalone ann model illustrates the complexity of the eto process the most accurate model was ann gwo6 which included the inputs of tmin tmax and u2 and the next one was ann gwo4 whose inputs were tmin tmax rh and ssh the 6th scenario with only three inputs of tmin tmax and u2 with easy access to them in all areas showed its superiority over the other scenarios ann gwo as a practical model can estimate eto values for the whole of iran using the simplest climatic variables 5 1 present limits and possible improvements the literature has shown that most research on modeling eto in iran is limited by climate this limitation has been removed in the present study and the ann gwo6 will be a promising model for the whole of iran due to the complexity of black box models e g ann gwo it is difficult to extend these models to the rest of the world therefore evaluation is recommended before implementing in other regions one of the significant issues in hydrology is climate change the ai models in this study may not be accurate in climate change conditions so assessing the performance of ai models in climate change conditions will improve the results also the sensitivity of ai models to training datasets will change their behavior so more meteorological stations in each climate can be considered to increase reliability 5 2 future research directions some recommendations future research as follows 1 in recent years with the progress of machine learning a new technique called deep learning has been introduced deep learning seems to have overcome many of the limitations of ai and performed better so far has been applied in language translation natural language understanding speech recognition and financial markets collobert et al 2011 fischer and krauss 2018 hinton et al 2012 sutskever et al 2014 future research on reference evapotranspiration based on deep learning can be valuable 2 evaluation of ai models in estimation of crop evapotranspiration although it is possible to calculate crop evapotranspiration based on eto but a crop evapotranspiration model can reduce computation costs in agriculture 3 geographic information system gis and satellite data are one of the powerful tools in providing meteorological information evaluating ai models with satellite input data to estimate eto has the potential to solve the meteorological station scarcity problem credit authorship contribution statement saman maroufpoor methodology software data curation formal analysis writing original draft omid bozorg haddad project administration supervision funding acquisition eisa maroufpoor conceptualization validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thank iran s national science foundation insf for its financial support by of this research 
5322,reference evapotranspiration eto is one of the key components of the hydrological cycle that is effective in water resources planning irrigation and agricultural management and other hydrological processes accurate estimation of eto is valuable for various applications of water resource engineering especially in developing countries such as iran which has no advanced meteorological stations and lacks facilities and information also due to the existence of different climates in iran the estimate of eto has become a challenge to this end the aim of this study is to estimate the eto to eliminate the two limitations of the absence of a comprehensive model for all climates and the scarcity of meteorological information in iran the present study investigates the ability of the hybrid artificial neural network gray wolf optimization ann gwo model to estimate eto for iran the accuracy of ann gwo was evaluated versus least square support vector regression ls svr and standalone ann the development of models is based on meteorological data of iran s 31 provinces consists of 5 different climates based on empirical equations and least inputs seven different input scenarios were introduced and penman monteith reference evapotranspiration was considered as the output of the models several statistical indicators including si mae u95 r2 global performance indicator gpi and taylor diagram were used to evaluate the performance of the models the results showed that the gwo algorithm acted as an efficient tool in optimizing the structure of the ann and the ann gwo model was more accurate than ann and ls svr in all scenarios ann gwo6 with inputs of wind speed maximum and minimum temperatures had the lowest error and decreased in terms of si index by 42 compared to ann6 and 30 compared to ls svr6 furthermore based on gpi it is in the first place with a 99 reduction compared to ann6 and ls svr6 the hybrid approach used in this study can be developed as a trustful expert intelligent system for estimating eto in iran keywords artificial neural network grey wolf optimization hybrid model least square support vector regression reference evapotranspiration shannon entropy 1 introduction in developing countries such as iran the main reason for the water shortages is not necessarily the lack of access to water resources but the misuse of water evaporation is a key process in the hydrological cycle that is one of the essential factors in the planning and utilization of water resources penman 1948 stewart 1984 the average annual rainfall in iran is 251 mm over 70 of which is spent on evapotranspiration et kousari and ahani 2012 therefore the accuracy estimation of crop water requirement is a necessity allen et al 1998 the united nations food and agriculture organization fao has proposed the use of reference et eto to calculate crop evapotranspiration doorenbos 1975 eto is the evaporative potential of the atmosphere regardless of the management method crop type and growth stages of the plant fao has proposed the penman monteith equation fao56 pm as a standard method for estimating eto and calibration of other empirical and semi empirical models droogers and allen 2002 a significant limitation of using fao56 pm is in its high number of meteorological variables and their uncertainty the dynamic nature of meteorological variables is due to their non linearity non stationary and stochastic properties therefore evapotranspiration as a complex phenomenon requires methods beyond empirical models in recent decades artificial intelligence ai techniques have proven their ability to model complex nonlinear phenomena such as eto baba et al 2013 ferreira et al 2019 kişi 2006 kumar et al 2011 kumar et al 2002 nourani et al 2019 nourani et al 2020 sanikhani et al 2019 shiri 2018 shiri 2019 tabari et al 2012 as well as water resource management issues emamgholizadeh et al 2014 maroufpoor et al 2018 maroufpoor et al 2017 maroufpoor et al 2019b sanikhani et al 2019 few studies have reported the integration of ai models with meta heuristic approaches prasad et al 2018 shamshirband et al 2016 shekofteh et al 2017 tao et al 2018 yaseen et al 2018 the meta heuristic approaches are divided into two groups of single solution based and population based the single solution based search process starts with one candidate and improves in subsequent iterations but in population based the optimization is done using a set of solutions population the search process starts with a random initial population random solutions and improves with iteration this population will also result in this approach not being trapped in optimal local solutions mirjalili et al 2014 introduced the gray wolf optimization gwo algorithm as a multi solution meta heuristic approach the gwo algorithm is coupled with ai approaches and improves their performance in prediction problems amar et al 2018 behnood and golafshani 2018 dai et al 2018 hadavandi et al 2018 maroufpoor et al 2019a sweidan et al 2015 yu and lu 2018 zein et al 2019 another important factor in modeling is the selection of effective variables these variables are obtained using the pearson s correlation coefficient the parameters in the empirical and semi empirical equations or the sensitivity analysis of each variable in the model however with the rise of entropy theory in hydrology the importance of each variable can be assessed this theory which is based on shannon 1948 has been extended to various subjects and has been applied to hydrological studies singh 1997 singh 2013a singh 2013b unlike statistical methods entropy theory does not require prior assumptions of the type of distribution function linearity or normality of the variable ellenburg et al 2018 in the present study it is attempted to investigate the uncertainties of variables using informational entropy principles providing a comprehensive model for a country or an entire region relying on fewer input variables is one of the crucial issues with eto modeling jing et al 2019 which is the basis of the present research objectives previous researches on eto in iran have proved the ability of ai models to estimate eto under certain climatic conditions e g kiafar et al 2017 rahimi khoob 2008 shiri 2017 shiri 2018 however in the present study this limitation has been eliminated to great extent by developing and testing the applied models based on comprehensive meteorological data gathered throughout the entire area of iran including 5 different climatic regimes further a major problem in some areas of country is data scarcity for producing reliable eto values to be used in different necessities the models developed in this research however utilize fewer meteorological variables so their applications under data scarcity conditions will be valuable from practical viewpoint finally although most of the eto modeling studies developed their ai models in concordance to the available empirical equations the present study have tested an additional entropy analysis to test and importance of each variable at each location with different climatic context also to achieve promising results gwo integrated with artificial neural network ann was introduced as a powerful hybrid method in estimating the eto in iran in addition the performance of ann gwo against least square support vector regression ls svr and standalone ann models is evaluated it is worth noting despite the numerous applications of gwo in various subjects to the best of the authors knowledge the ability of the gwo algorithm to estimate eto in iran has not yet been investigated 2 materials and method 2 1 case study and data description the studied area in this research is the entire region of iran s geographical area 25 00 n and 38 39 n latitudes between 44 00 e and 63 25 e longitudes including 31 provinces with an area of about 1650000 km2 fig 1 the loss of 70 of annual mean precipitation through et in iran kousari and ahani 2012 has a significant impact on the hydrological cycle of the country therefore it is necessary to obtain an accuracy estimate of et in different climates of iran as shown in fig 1 the monthly meteorological data for the 31 provinces including maximum and minimum temperatures tmax tmin c relative humidity rh wind speed u2 m s sunshine hours ssh h and precipitation were collected from the meteorological organization the data was selected during 2012 2017 but due to the lack of significant changes in meteorological variables 2017 was introduced as the representative of the 6 year period to evaluate the ann gwo hybrid model it should be noted that the long term average of meteorological variables was not used because of their random nature table 1 shows the general information of the applied provinces and the average of meteorological data the aridity index ia was also calculated as an indicator of climate drought according to equation 1 unep 1992 table 1 1 i a p e t 0 where p mm is average annual precipitation and eto mm is the annual reference evapotranspiration based on ia the provinces can be divided into three main cluster hyper arid and arid area ia 0 2 semi arid 0 2 ia 0 5 and sub humid and humid ia 0 5 unep 1992 according to table 1 the main clusters of hyper arid and arid area semi arid and sub humid and humid include 7 13 and 11 provinces respectively 2 2 shannon entropy information content shannon 1948 showed that events with a high probability of occurrence provide less information and events with a low probability of occurrence provide more the information in other words entropy is mathematically a statistical measure of randomness or uncertainty in entropy theory information does not necessarily mean useful information it only specifies the randomness of the event the following steps will be used to calculate entropy the y matrix is made as follows 2 y 11 y 12 y 1 n y 21 y 22 y 2 n y m 1 y m 2 y mn where n is the number of samples of each variable i 1 2 3 n and m is the number of variables j 1 2 3 m the y matrix is then normalized using equation 3 3 z ij y ij y ij min y ij max y ij min where zij is the normalized variable yij min and yij max are the minimum and maximum values of each variable respectively the probability of each variable pij is calculated as follows 4 p ij y ij 0 0001 i 1 m y ij 0 0001 finally information entropy ej and entropy weight ew are expressed by eqs 5 and 6 respectively 5 e j 1 ln m i 1 m p ij ln p ij 6 e w j 1 e j j 1 n 1 e j ew shows the relative importance of the parameters the sum of the ews of the parameters is one so the more weighted parameter closer to one is more important 2 3 input combinations the eto calculated by the standard equation of fao56 pm was utilized as a benchmark for evaluating other applied models that is a common process as it was mentioned in the literature review martí et al 2015 shiri 2017 shiri 2019 shiri et al 2014b tikhamarine et al 2019 numerous studies have investigated various methods of estimating eto in different regions according to the united nations food and agriculture organization fao recommendation allen et al 1998 penman monteith equation fao56 pm i is approved as the standard method of estimating eto in different regions and climates without the need for calibration also to prove the performance of the fao56 pm method the american society of civil engineers asce investigated the performance of twenty different methods compared to lysimeter data from 11 regions with different climate conditions eventually each method was effective in unique climates and only fao56 pm s method was capable to provide reliable results for different climates allen et al 1998 therefore application in different climates and time periods is one of the advantages of the fao56 pm method to elect effective input combinations two factors were considered including empirical and semi empirical equations in eto estimation and least inputs empirical and semi empirical equations are divided into three categories mass transfer based brockamp and wenner 1963 dalton 1802 mahringer 1970 meyer 1926 penman 1948 rohwer 1931 trabert 1896 radiation based makkink 1957 priestley and taylor 1972 turc 1961 and temperature based hargreaves and samani 1985 in this study entropy weight and the absolute correlation coefficient were used to confirm the efficiency of the variables of these equations fig 2 it is clear that the correlation coefficient s values of all variables were above 0 6 except p but two variables of rh and p had inverse correlation coefficients also the highest entropy weight was related to rh ew 0 25 followed by tmin and tmax with 0 23 and 0 22 respectively the lowest ew was related to p ew 0 05 due to its high uncertainty finally the input scenarios were presented in table 2 based on all three categories of mass transfer radiation and temperature based as well as the literature review martí et al 2015 shiri 2019 shiri et al 2014b shiri et al 2019 tao et al 2018 tikhamarine et al 2019 yaseen et al 2020 the studied provinces were randomly divided into train 70 and test 30 groups as recommended by the previous literature pour ali baba et al 2013 shiri et al 2014a shiri et al 2013 to reach promising conclusions as the final model needs to be applied to all climates in iran 70 of the provinces in each cluster were considered as the train group and the rest of them as the test group thus 70 of the provinces with hyper arid and arid climate 5 provinces semi arid 9 provinces sub humid and humid 8 provinces were selected as inputs in the training section 3 applied ai models 3 1 least square support vector regression ls svr svr is one of the supervised learning methods in nonlinear prediction problems its initial algorithm was introduced by cortes and vapnik 1995 the basis for estimating the functions in the svr is the linear classification of the data and in separating the data it is attempted to determine a line with the most confidence level finding the optimal line equation is done by convex quadratic programming which is a well known method for solving bounded problems therefore solving large scale problems using this method requires high computational cost and also complicates the algorithm finally suykens and vandewalle 1999 proposed the ls svr model the ls svr also has the initial limitations of the svr model but uses linear equations to solve the problems which results in lower complexity higher accuracy and speed in this study based on the literature review chen et al 2019 eslamian et al 2009 moghaddamnia et al 2009 three types of kernel functions of linear polynomial and radial basis function rbf were used and the best kernel was selected based on minimum root mean square error rmse 3 2 artificial neural network ann was first introduced by rosenblatt 1958 as a computational method this method is based on parallel processes of biological nervous systems and is capable of communicating between inputs and outputs of a process without full knowledge of its physics the most common type of ann is feed forward network which is trained by the back propagation algorithm coulibaly et al 1999 the ann architecture usually consists of three layers input hidden and output the input layer has the role of acceptance and distribution of input variables the hidden layer performs data processing and finally the output layer contains a variable that is simulated for specified inputs mcclelland and rumelhart 1989 each layer consists of several neurons that are processor units the neurons in each layer have the same activation functions and the same training algorithm the most important characteristic of neurons in one layer is simultaneous computing in other words the calculations for one layer are entirely performed and then the next layer calculations are performed in this study three layers with back propagation algorithms were used and different propagation algorithms were evaluated for each input combination finally levenberg marquardt was utilized as the best training algorithm the activation functions and the number of neurons in the hidden layer were selected based on the trial and error and the lowest rmse value among the activation functions sigmoid tangent in the hidden layer and the linear function in the output layer had the least error 3 3 grey wolf optimization gwo the gwo is an evolutionary approach inspired by the behavior of gray wolves and follows a series of hunting steps of gray wolves in nature gwo has been introduced by mirjalili et al 2014 there are four groups of gray wolves including alpha α beta β delta δ and omega ω the gwo consists of three stages of the search surround and attack to prey muro et al 2011 alpha wolves have the highest social responsibility and all decisions e g hunting time and place of sleeping and awaking are made by them and their instructions must be followed by other groups alpha wolves are not necessarily the strongest members but they are more capable of manage the group than other wolves beta wolves follow the alpha and help them make decisions when an alpha wolf is lost the candidate wolves are selected from the beta group the wolves at the bottom level who are the victims are the omega wolves these wolves are obedient to other wolves and are the last group in terms of eating food the wolves other than the three groups of alpha beta and omega are called delta delta wolves are followed alpha and beta and have duties such as scouting guarding hunting and care taking in the gwo mathematical model each gray wolf is considered as a candidate solution initially a set of wolves is randomly generated candidate solution the wolves position is updated based on the target function then in the case of maximization or minimization of the problem the wolves are arranged in descending or ascending order finally the first three wolves alpha beta and delta respectively are considered as the best solutions more information about gwo can be found in mirjalili et al 2014 3 4 proposed hybrid approach the back propagation algorithm used in ann is a systematic way to train multilayer networks the purpose of training the network is to adjust the weights and bias values of each neuron so that the difference between the observed and simulated values is minimized the back propagation training algorithm is based on the error correction learning rule that follows two main paths in the network the first path is forward where the input vectors are applied to the network and by passing the hidden layer the answer is obtained in the output layer the second path is backward and from the output layer to the input layer in this path the error in the output layer is reduced by adjusting the parameters weight and bias therefore each layer is composed of one or more neurons which have specific tasks and set the basis of the network s performance and behavior the inputs are affected by the weights of each neuron and are mapped to an activation function with a constant value bias eventually some values will be produced in the layer and they will be presented to the other layer or will be the output of the network therefore the weight and bias of each neuron have the primary role in estimating the target variable with the least error mirjalili et al 2012 zhang et al 2007 in this study the gwo algorithm is introduced into the ann structure as a network training to determine the weight and bias of each neuron more accurately the selection of weight and bias in each iteration are updated based on the gwo algorithm so gwo seeks to limit the decision space to cross the local optimal values and achieve a global solution in the training phase where error between the estimated and the target values of eto are used to update the parameters the gwo generates the initial population of alpha beta and delta wolves and determines the location of each wolf then the position of α β and δ are updated based on the target function which represents the error value between the estimated and the target values of eto the next step is updating the position of the other solutions other wolves with respect to the values of α β and δ the stopping condition is to reach the maximum number of iterations or the error lower than the specified threshold finally after placing the final solution in the ann the evaluation of the hybrid model in the test section is started and the eto value is estimated network training with the gwo will avoid problems such as overfitting or trapping in local optimizations and the ann gwo hybrid model can perform better than the ann mirjalili 2015 and achieve global optimization changing the objective function might alter the outcomes merely but it should be noted that the applied function in this research is root mean square error rmse or mean square error mse both relying on giving more weights on larger errors willmott and matsuura 2006 although mae might be applied here it could not assign weights to different errors because it simply calculates the errors as differences between the target and output values so information gathered based on rmse or mse would be more reliable than those of using mae one may also apply si the weighted rmse that exempts the results from the average values of the target parameter but as the goal with gwo is reducing the errors within the model structure both si and rmse would give the same results however applying si for assessing the models between different stations with different eto ranges would be preferable fig 3 shows the ann gwo flowchart the ls svr ann and ann gwo were implemented using by the toolbox of matlab 3 5 evaluation of models performance in this study different statistical indices including scatter index si coefficient of determination r2 and mean absolute error mae were used to evaluate the performance of models also uncertainty with 95 confidence level u95 behar et al 2015 gueymard 2014 and global performance indicator gpi stone 1993 were used to evaluate the models deviation from target values and to rank them respectively gpi is a 5 agent index including the simultaneous effect of mean bias error mbe t statistic test tstat u95 r2 and rmse the equations of the applied indices are as 8 si rmse e t c 1 n i 1 n e t ci e t ei 2 e t c 9 mae 1 n i 1 n e t c i e t e i 10 r 2 i 1 n e t ci e t c e t ei e t e i 1 n e t ci e t c 2 i 1 n e t ei e t e 2 2 11 t stat n 1 m b e 2 rms e 2 m b e 2 12 u 95 1 96 s d 2 r m s e 2 13 gpi m b e r m s e u 95 t stat 1 r 2 where etei and etci are ith eto values estimated and calculated by fao56 pm respectively and e t e and e t c are average values of eto estimated and calculated by fao56 pm respectively in addition n represents the number of data and sd is standard deviation difference between the estimated and calculated values of eto the closest value to zero indicates good performance for all indices except r2 and the best value for r2 is 1 according to li et al 2013 the si index is divided into four ranges for evaluating models performance including excellent when si 0 1 good if 0 1 si 0 2 fair if0 2 si 0 3 and poor if si 0 3 4 results and discussion 4 1 evaluation of models in this study seven input scenarios were used to calculate eto according to table 2 the scenarios presented were used to develop the ann model by the gwo algorithm table 3 presents the results of estimating eto by the ann ann gwo and ls svr models in the ls svr model among three kernel functions the linear kernel was the most used for four scenarios in terms of the lowest rmse value the ls svr6 model which includes inputs of tmin tmax u2 with si and mae of 0 105 and 0 410 mm respectively had the most accuracy and located in a good range based on si index ls svr6 had a decrease of 36 in si and 37 in mae compared to ls svr7 ls svr4 also showed the worst results with si and mae of 0 202 and 1 260 mm respectively fig 4 shows the scatterplots of estimated and calculated values of eto for different scenarios in ls svr fig 3 also confirms that the ls svr6 is most consistent with the 1 1 line y x kotz et al 1982 the literature have introduced ls svr as an efficient model for estimating eto kişi and cimen 2009 mohammadrezapour et al 2019 wen et al 2015 in the ann model for all the scenarios the lm algorithm was determined based on the least rmse the number of neurons in the hidden layer is an important factor in the ann structure that depends on the type and number of inputs faris et al 2019 the literature review has recommended many rules for determining it based on the number of inputs hecht nielsen 1987 hush 1989 kaastra and boyd 1996 kanellopoulos and wilkinson 1997 but generally there are no specific rules for determining it in this study to achieve the highest accuracy in ann the number of neurons in the hidden layer was determined by trial and error in the range of 1 20 this process was also repeated for gwo but the number of neurons in the hidden layer in ann gwo was equal to ann due to the fixed input type and number structure 2 4 1 represents 2 inputs corresponding to tmin tmax 4 neurons in the hidden layer and 1 output eto the number of iterations required to train the lm algorithm was 1000 and it was noteworthy that the increase in accuracy for the iterations of more than 1000 was negligible the ann4 model which includes the inputs of tmin tmax rh and ssh with si and mae of 0 122 and 0 454 mm has the most accuracy and followed by ann6 with si and mae of 0 133 and 0 506 mm all input scenarios in the ann except ann5 are within the good range based on the si index the ann4 had the largest number of input neurons 16 neurons in the hidden layer and this provided the basis for an acceptable accuracy of eto estimation in general increasing the number of neurons will increase the number of processing units in the model which will make the model more complex if the model is able to solve this complexity an accurate estimate is made otherwise the complexity will reduce the accuracy of the model the ann4 with 39 in si and 42 in mae had the highest improvement over ann5 fig 5 shows the scatterplots for the results of different ann scenarios according to fig 4 the ann4 regression equation with slope value near to one and the lowest intercept elevation had the best estimation of eto a number of studies have demonstrated the ability of the ann to estimate eto antonopoulos and antonopoulos 2017 ferreira et al 2019 kisi and kilic 2016 kumar et al 2002 landeras et al 2018 sudheer et al 2003 in the ann gwo hybrid model the initial population size and number of iterations were considered in the range of 15 30 and 200 1500 respectively based on the lowest rmse in intelligent optimization algorithms e g gwo diversity in the initial population reduces computational time and improves convergence in the global solution haupt and ellen haupt 2004 since the ann gwo models have been trained with different inputs at each scenario the structure of the models will be different accordingly to achieve the best results in each scenario the initial population and iterations were determined by trial and error and the results of which are presented in table 3 in the structure section nevertheless there is no fixed suggested rule to fix those values in these models in literature table 3 shows that for all scenarios ann gwo has superiority over ann and ls svr fig 6 shows the scatterplots of ann gwo in estimating eto the highest accordance with 1 1 line y x kotz et al 1982 is observed in ann gwo4 and ann gwo6 that evaluation of the regression line equation y ax b in ann gwo6 confirms that the values of a and b have the smallest difference δa 0 0011 δb 0 0192 with ideal values a 1 b 0 where indicating the ability of the model to estimate eto 4 2 comparison of the applied models according to table 3 ann gwo6 had the lowest si and mae of 0 07 and 0 279 mm respectively the structure used for ann gwo6 had an initial population of 30 and 1500 iterations also ann gwo4 with si and mae of 0 090 and 0 333 mm is located after ann gwo6 the si value illustrates the ann gwo4 and ann gwo6 performance at the excellent range according to li et al 2013 and the rest of the scenarios are in a good range the inputs in ann gwo6 were tmin tmax and u2 which can be easily measured at any station the comparison of inputs in the ann gwo6 against ann gwo4 illustrates the higher importance of wind speed which is in agreement with the conclusions obtained by as shiri 2017 in the hybrid model the highest improvement was observed for ann gwo6 in against ann gwo5 with a decrease of 59 in si and 61 in mae the 5th scenario with rh and ssh inputs has the least accuracy in both ann and ann gwo models although the 4th scenario in the ann si 0 122 mae 0 454 mm and ann gwo si 0 090 mae 0 333 mm had promising results but it showed the worst result in ls svr si 0 320 mae 1 268 mm this implies that model structure and type are two important factors for estimating reference evapotranspiration eto fig 7 illustrates gwo s ability to increase the accuracy of eto estimation in all scenarios comparing to ls svr and standalone ann models the most accuracy for ann gwo ann and ls svr models were for scenarios 6 4 and 6 respectively boxplot was used to analyze the residuals estimation error in the ann gwo6 ann4 and ls svr6 models fig 8 which show positive and negative estimation errors as under and over estimations respectively the boxplot is a standard way of showing the error distribution based on four values first quartile q1 third quartile q3 interquartile range iqr and a section inside the rectangle showing the median the position of these values has been illustrated in fig 9 q1 and q3 report for 25 and 75 percent of the errors respectively ann gwo6 with q1 of 0 203 performed better than both ann4 q1 0 284 and ls svr6 q1 0 315 it should be noted that the importance of q3 in error analysis is more than q1 because it covers 75 of the error that here ann gwo6 with a difference of δq3 0 244 compared to ann4 and δq3 0 163 compared to ls svr6 has higher performance accuracy the smaller iqr in ann gwo6 than the other two models clearly indicates that the error distribution is around zero and also the median line at the center of the rectangle shows the normality of error distribution in addition the iqr in the ls svr is lower than the ann based on the median line it can be concluded that ls svr and ann are overestimated and underestimated respectively seyedzadeh et al 2020 recommend that the u95 index to evaluate the results deeply and also the gpi index for overall ranking as an analyzes multiple can be used the u95 is used to show the deviation of the estimation results from the target values the results of the u95 for different scenarios have been shown in fig 9 the range of changes in this index was 1 03 4 24 that its lowest and highest values were related to ann gwo6 and ls svr4 respectively in this index ann gwo6 performance had less error than other scenarios in the three scenarios of 1 5 and 7 the performance of the models was similar and in other words there was no increase in the accuracy of estimation in different models this confirms that input combinations of 1 5 and 7 have reached their maximum fitting for eto the gpi index was used to investigate the collective effect of different statistical indices different indices analyze models at their individual levels but gpi as a reliable index shows the impact of rmse mbe tstat u95 and r2 indices simultaneously and is a tool for ranking models in estimating eto fig 10 shows the gpi values for models with gpi 0 01 based on the obtained gpis all models in fig 10 have high accuracy and performance for estimation gpi values ranged from 0 00005 to 1 the maximum gpi was related to the ls svr2 the ability of the ann gwo6 is clearly in comparison to other models and followed by ann2 however ann gwo6 had a 96 decrease compared to ann2 based on previous statistical indices ann4 and ls svr6 and based on gpi index ann2 and ann gwo2 models were close to ann gwo6 finally the taylor diagram was utilized to determine how much the estimated reference evapotranspiration eto is matched to the fao56 pm fig 11 the most accurate models compared to fao56 pm in terms of different statistical indices were ann gwo6 ann gwo4 ann gwo2 ann2 ann4 and ls svr6 which were evaluated in taylor diagram the highest and lowest accordance with fao56 pm standard deviation line was related to ann gwo6 and ann2 respectively moreover in the rmse index except for ann gwo6 and ann gwo4 the rest of models are in the second radius compared to the target point 5 conclusion the purpose of the present study was to estimate the reference evapotranspiration eto in the context of eliminating the two limitations of the lack of a comprehensive model for all climates and the scarcity of meteorological information in iran to this end the ann model was improved using the gray wolf optimization algorithm ann gwo eto was calculated for iran s 31 provinces and their different climates including hyper arid arid semi arid sub humid and humid seven scenarios were selected as inputs based on the empirical equations and least inputs the ann gwo results were evaluated for seven input scenarios and compared with ann and ls svr the results of different statistical indices showed that ann gwo was more efficient than ls svr and standalone ann in all scenarios and gwo algorithm was a powerful tool in optimizing ann structure the improvement of results using gwo compared to the standalone ann model illustrates the complexity of the eto process the most accurate model was ann gwo6 which included the inputs of tmin tmax and u2 and the next one was ann gwo4 whose inputs were tmin tmax rh and ssh the 6th scenario with only three inputs of tmin tmax and u2 with easy access to them in all areas showed its superiority over the other scenarios ann gwo as a practical model can estimate eto values for the whole of iran using the simplest climatic variables 5 1 present limits and possible improvements the literature has shown that most research on modeling eto in iran is limited by climate this limitation has been removed in the present study and the ann gwo6 will be a promising model for the whole of iran due to the complexity of black box models e g ann gwo it is difficult to extend these models to the rest of the world therefore evaluation is recommended before implementing in other regions one of the significant issues in hydrology is climate change the ai models in this study may not be accurate in climate change conditions so assessing the performance of ai models in climate change conditions will improve the results also the sensitivity of ai models to training datasets will change their behavior so more meteorological stations in each climate can be considered to increase reliability 5 2 future research directions some recommendations future research as follows 1 in recent years with the progress of machine learning a new technique called deep learning has been introduced deep learning seems to have overcome many of the limitations of ai and performed better so far has been applied in language translation natural language understanding speech recognition and financial markets collobert et al 2011 fischer and krauss 2018 hinton et al 2012 sutskever et al 2014 future research on reference evapotranspiration based on deep learning can be valuable 2 evaluation of ai models in estimation of crop evapotranspiration although it is possible to calculate crop evapotranspiration based on eto but a crop evapotranspiration model can reduce computation costs in agriculture 3 geographic information system gis and satellite data are one of the powerful tools in providing meteorological information evaluating ai models with satellite input data to estimate eto has the potential to solve the meteorological station scarcity problem credit authorship contribution statement saman maroufpoor methodology software data curation formal analysis writing original draft omid bozorg haddad project administration supervision funding acquisition eisa maroufpoor conceptualization validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thank iran s national science foundation insf for its financial support by of this research 
5323,evaluating the risk of flows related to reservoir releases requires a comprehensive grasp of the associated hydrodynamic process due to the obstacle posed by bathymetry in mountainous areas the accuracy of the hydrodynamic simulation is hindered by the absence of reliable terrain data to evaluate both the overall parameter sensitivities e g sensitivities to cross section geometry and roughness within the feasible domain and the varying responses induced by changes in the input forcing e g inflow series we introduce a generalized global sensitivity indicator namely the input space sampled standardized regression coefficients iss src through mathematical derivation we found that the parameter whose iss src index is close to zero will not be significantly updated by the enkf thus iss src can be employed to assist the enkf by predicting the correction performance and reducing the dimensionality of identifiable factors the results of synthetic experiments confirm the connection between the evolution of the parameter ensemble and the dynamic sensitivity indicators the iss src assisted enkf is employed to modify the physical and geometrical parameters of riverbed sections in the hydrodynamic model of a real world reservoir release case and the simulation accuracy is greatly enhanced this success demonstrates the potential of obtaining reliable flood simulation results with only coarse resolution topographic information keywords global sensitivity analysis data assimilation topography correction hydrodynamic model 1 introduction with the increasing attention paid to the impact of reservoir operations on the ecological health and the human activity safety in downstream areas adams et al 2017 li et al 2018 the importance of accurately predicting the hydrodynamic process caused by reservoir releases which produce different pattern than natural runoff bi et al 2019 has increased shaw et al 2017 with the construction of hydropower projects in rugged areas it can be either technically or economically impractical to obtain the topographic data necessary for hydraulic simulations on site as an alternative to field measurements open access digital elevation model dem data sets and remote sensing measurements have been employed to facilitate flood modeling archer et al 2018 pham et al 2018 although the resolution of these data has been considerably enhanced it is still relatively difficult to guarantee the reliability of the underwater topographic information in addition the accuracy of existing data can decrease over time due to physical processes such as erosion sedimentation and slope collapse bi et al 2019 therefore correcting the errors in the coarse resolution terrain data thereby improving the simulation precision is crucial for refining reservoir flood control operations being concise yet effective the one dimensional 1 d hydrodynamic model based on the discrete form of the saint venant equations is a well developed tool for flow forecasting in rivers and canals roux and dartus 2005 xu et al 2017 wang et al 2018 the time invariant or quasistatic factors in the 1 d hydrodynamic model are mainly terrain physical and geometrical characteristics the flow resistance of the river canal bed is summarized by manning s roughness coefficient n and terrain geometry is commonly an interpolation of measurements in discretely sampled sections the difficulty of obtaining precise bathymetry measurements lai et al 2018 hu et al 2019 as well as the geomorphologic changes dysarz et al 2017 degrades the reliability of the available terrain data under such circumstances the section geometries must be conceptualized or reconstructed lai et al 2018 peña and nardi 2018 which raises the question of how to alleviate the accompanying distortion to the fullest possible extent by virtue of parameter correction skills many researchers have focused on the calibration of physical parameters in hydrodynamic models ayvaz 2013 mayo et al 2014 baatz et al 2017 while the simultaneous estimation of topographical and physical features has not been sufficiently studied yoon et al 2012 hence this paper aims to analyze the role of physical and terrain parameters from the perspective of model dynamics and obtain the optimal spatial heterogeneous topographic features based only on hydrological element observations while the real world is a continuum macroscopically parameters are finite dimensional in discrete numerical models which implies that they are intrinsically biased unfortunately only a small number of the parameters can be handled concurrently because an increase in the number of considered variables results in the growth of both the complexity of calculation and the difficulty of approaching the optimum bellman 1961 selecting the dominant factors that contribute the most to model errors requires meticulous investigation e g parameter sensitivity analysis sa principal component analysis pca etc the most straightforward approach to assess a parameter s impact given that the parameters are independent of each other is to calculate derivatives neumann 2012 this method merely gives information in the neighborhood around a specified point in the parameter space and is therefore regarded as a local sensitivity index saltelli et al 2005 chen et al 2019 the global sensitivity analysis gsa on the other hand aims to investigate the model response over the whole feasible parameter domain considering the variation in derivatives that stems from nonlinear responses and interparameter coupling effects gamerith et al 2013 razavi and gupta 2016 ge and menendez 2017 typical gsa methods include regression based standardized regression coefficients src one factor at a time oat based morris screening variance based fourier amplitude sensitivity tests and entropy based kullback leibler entropy methods neumann 2012 a wide range of studies have employed these methods to evaluate model response over the parameter domain saltelli et al 2005 gamerith et al 2013 razavi and gupta 2016 ge and menendez 2017 chen et al 2019 whereas the temporal evolution of the sensitivity index due to the varying input forcing boundaries has received less attention until recent decades for example massmann et al 2014 analyzed the dynamics of parameter sensitivities with time varying precipitation and temperature inputs in a conceptual rainfall runoff model gupta and razavi 2018 also investigated how the sensitivities vary with precipitation and potential evapotranspiration series in the hbv sask hydrologic model previous research implemented sensitivity evaluation to either support model calibration or understand model structures sieber and uhlenbrook 2005 reusser et al 2011 massmann et al 2014 while few researchers have focused on the connection between model dynamics and parameter correction effects in this paper we explore the mechanism by which varying model input forces affect the sensitivity indices and further determine the parameter correction process while sa tries to evaluate the effect of uncertain input factors on the outputs parameter correction aims to reduce the simulation errors manual trial and error is a simple approach to address parameter biases but suffers from a lack of reliability in experiential treatments and features an unacceptable workload liu et al 2019 parameter optimization is a commonly employed method that automatically adjusts the parameters by various algorithms ayvaz 2013 soltani et al 2019 lu et al 2019 with little consideration of the physical structure of models optimization methods are often hindered by the local optimum issues especially in nonlinear high dimensional cases moore et al 2010 qin et al 2018 data assimilation techniques treat various types of information statistically to minimize prediction errors evensen 2009 hostache et al 2018 song et al 2019 the ensemble kalman filter enkf first proposed by evensen evensen 1994 is a modified formulation of the conventional kalman filter kalman 1960 replacing the statistical error matrix with an error matrix based on an ensemble of random samples due to its explicit iterative nature the enkf features good robustness and acceptable computational cost franssen and kinzelbach 2008 xiong et al 2019 lei et al 2019 and has thus been introduced into parameter estimation as an alternative and productive approach mayo et al 2014 baatz et al 2017 siripatana et al 2018 although it is a common practice to correct the most sensitive parameters among numerous sources of error hu et al 2017 the mechanism connecting the parameter sensitivity features to the performance of the enkf based correction scheme has received little in depth investigation baatz et al 2017 lei et al 2019 in addition previous research suggest that a model warm up period is needed to harmonize model response with input and parameters before assimilation evensen 2003 xie and zhang 2010 nevertheless the criterion for the warm up duration in our reviewed literature is still unclear given these limitations of existing research we believe that clarifying the relationship between input output response and ensemble evolution in enkf would contribute to constructing a more explicit framework of the error identification correction procedure considering the aforementioned deficiencies in existing studies this paper addresses the following issues 1 establishing a sensitivity metric that considers both the variation within the parameter domain and the changing input conditions 2 investigating the performance of the enkf when estimating sensitivity varying parameters and explaining how the estimation process relates to the parameter importance indicators 3 identifying the primary sources of error in a simulation of reservoir operation triggered hydrodynamic processes using the proposed gsa method and addressing the biases imported by insufficient terrain data with the enkf correction scheme the remainder of this paper is organized as follows in section 2 we first present the conventional simulation assimilation and sa methods then approach issues 1 and 2 by proposing a new generalized gsa index and exploring its connection with the enkf in section 3 we further address issue 2 by carrying out sa and enkf based parameter correction in synthetic experiments section 4 utilizes the iss src assisted enkf in a real world reservoir release simulation case and verifies their validity by demonstrating improvements in output accuracy thus resolving issue 3 main findings are concluded in section 5 2 methods in this section we first provide an overview for the 1 d hydrodynamic model the enkf and src sensitivity index in sections 2 1 2 3 then in section 2 4 a generalized src index iss src is proposed and its logical relationship with enkf correction performance is given before introducing the methods it is necessary to clarify the definition of the terms parameter and input used in this paper by parameter we indicate the measure that characterizes the specific inherent nature of the model such as the roughness coefficient and gravity by input we refer to the unstable external forces that drive the model evolution such as inflow boundary conditions and precipitation it is worth noting that for underlying numerical algorithms there is no essential distinction between input forces and parameters nevertheless in the sense of physical meaning they play quite different roles thus we believe that treating them separately helps to analyze the model dynamics in a clearer manner 2 1 1 d hydrodynamic model the 1 d hydrodynamic model consists of mass and momentum conservation equations along the flow direction lei et al 2019 1 a t q x 0 2 q t x q 2 a g a z x s f 0 where a is the cross sectional flow area m2 q is the discharge rate m3 s x is the longitudinal coordinate m t denotes time s and z is the water level m since eqs 1 and 2 are hyperbolic partial differential equations their analytical solutions are not available in most cases the well known preissimann four point implicit discretization scheme laks 2019 is employed for linearized numerical iteration please refer to our previous work lei et al 2019 which used the same 1 d hydrodynamic algorithm as the present paper the so called frictional slope in eq 2 is given by the empirical manning s equation 3 s f n 2 u 2 r 4 3 in eq 3 the generalized effect of riverbed resistance is decided by the cross sectional geometry represented by hydraulic radius r flow rate represented by velocity u and bed physics represented by manning s roughness coefficient n 2 2 enkf the kalman filter was first proposed for filtering and prediction problems in linear dynamic systems kalman 1960 generally we have two independent sources of information prior model forecasts ψ f and observations d which are assumed to be gaussian 4 ψ f n ψ p r i o r c f 5 d n h ψ 0 c d where ψ p r i o r and ψ 0 are the prior mean of forecast and the true state respectively c is the error covariance matrix with superscripts f and d indicating forecast and observation respectively h is the linear operator that projects the state vector into the observation space the likelihood of the estimator ψ a a for analysis for the posterior state is inversely proportional to the function evensen 2009 6 j ψ a ψ f ψ a t c f 1 ψ f ψ a d h ψ a t c d 1 d h ψ a the best estimation that maximizes the likelihood is given as 7 ψ a ψ f k d h ψ f in eq 7 the so called kalman gain is formulated as 8 k c f h t h c f h t c d 1 the covariance of state forecast c f is also replaced by 9 c a i k h c f for linear dynamic systems a model with error can be written as 10 ψ t 0 g ψ t 1 0 q t 1 where the subscript indicates timestep g is the linear model operator and q t 1 represents the model error over a single time step generally q t 1 is unknown and the practical numerical model will evolve according to evensen 2009 11 ψ t f g ψ t 1 a 12 c t f g c t 1 a g t c t 1 q where ψ t f is the prior model forecast at t ψ t 1 a is the posterior state at t 1 c t f and c t 1 a are their covariances c t 1 q is the covariance matrix of q t 1 given the initial values for the model state and corresponding error eqs 7 12 sequentially assimilate model predictions with observations generating estimations with least squared variance for sophisticated systems in which g is nonlinear the propagation pattern in eq 12 of the model error covariance matrix no longer stands and a new approach to update error covariances is needed the enkf was proposed as a monte carlo solution for estimating the stochastic characteristics for error matrices evensen 1994 by sampling an ensemble ψ j f j 1 2 j of model states the statistical covariance matrix c f in eq 8 can be replaced by the sample covariance matrix 13 c f e e ψ f e ψ f ψ f e ψ f t where e represents the expectation and e indicates that the covariance matrix was sampled the observation vector is also sampled with a predefined measurement error burgers et al 1998 14 d j d j j n 0 c d 15 c d e e d e d d e d t therefore the analysis result ψ a in eq 7 changes to 16 ψ j a ψ j f c f e h t h c f e h t c d e 1 d j h ψ j f based on the central limit theorem the sample covariance matrix c f e will converge to the statistical covariance c f with the speed of j evensen 2003 the classic formulation of the enkf serves to assimilate simulation and observation results in inverse problems the state vector ψ f is replaced by the uncertain model parameters p r m the evolution operator g becomes an identity matrix implying that the parameters are constant with time and the observation matrix h is substituted by the model calculator g that relates input parameters with simulated observations 17 p j t f p j t 1 a 18 y j t g p j t f in which y r n is the model output vector corresponding to observations p j t f and p j t 1 a are the prior guess of the true parameter value at t and the posterior guess at t 1 respectively while their uncertainties are implicitly represented by the ensemble covariances the reformulated parameter estimating enkf is written as moradkhani et al 2005 19 p j t a p j t f c p y e c y y e c d e 1 d j y j t where the covariance matrices are ensemble expectations at time t correspondingly the kalman gain becomes 20 k c p y e c y y e c d e 1 2 3 src for model outputs y and parameters p a straightforward formulation of sensitivity is simply the partial derivative of the output y n to p m n and m refer to the n t h and m t h components of the output and parameter vector respectively saltelli et al 2005 21 y n p m y n p m in numerical models approximations to partial derivatives can be obtained by changing oat in the discretized partial differential scheme 22 s nm δ y n δ p m y n p 1 p 2 p m δ p m p m y n p 1 p 2 p m p m δ p m as a local sensitivity index the difference quotient in eq 22 merely gives the gradient at a specified parameter point conversely the gsa aims to assess the model response over the whole parameter space the src addresses such an issue by evaluating overall sensitivity with parameter output regression saltelli et al 2004 gamerith et al 2013 given a set of samples p j y j j 1 2 j the linear regression for the relationship is formulated as 23 y y c y p c p p 1 p p y m p p the variables with bars indicate the sample mean and c represents covariance the src denoted as a matrix s whose element s nm represents the response of output y n to parameter p m scales each linear coefficient in eq 23 with the corresponding sample standard deviation of the parameter and output 24 s nm σ p m σ y n m nm assuming that each parameter is sampled independently from the others we have 25 c p p m 1 m 2 m 1 m 2 c o v p m 1 p m 2 0 m nm c o v y 1 p 1 c o v y 1 p m c o v y n p 1 c o v y n p m σ p 1 2 0 0 σ p m 2 1 nm 26 c o v y n p m σ p m 2 27 s nm c o v y n p m σ y n σ p m c o r r y n p m eq 27 implies that under the specific sampling criterion the src can be interpreted as correlation coefficients of inputs and outputs eqs 27 and 19 indicate that both the enkf and the src involve monte carlo realizations and utilize the subsequent covariance information which implies that they are inherently connected therefore instead of other gsa methods the src neumann 2012 is selected in this paper to describe the parameter output relationship notably the src formulation in eq 27 avoids the possible numerical instability caused by matrix inversion when parameters vary greatly in their magnitudes 2 4 a generalized sensitivity index iss src and its relationship with enkf 2 4 1 input space sampled iss src as an alternative to the src the method proposed by morris 1991 addresses gsa problems by randomly sampling the point p p 1 p 2 p m p m t in eq 22 within the parameter space the sample mean of s nm is used to measure overall effects and the standard deviation represents the changes in model response caused by nonlinearity and cross parameter interactions although the variation in the parameter space can be handled by both approaches the fluctuation in sensitivity indices caused by the changing input forces still needs proper characterization previous studies investigated the dynamics of parameter sensitivity indices by illustrating their time sequence sieber and uhlenbrook 2005 reusser et al 2011 massmann et al 2014 which provides comprehensive yet complex information about model structure in this paper the variation in parameter sensitivity that derives from changing inputs is described from both time resolved and time aggregated perspectives the src indices are first sampled at each timestep eq 28 corresponding to different levels of model inputs the first and second order moments are then calculated to summarize the overall importance of the parameterization eqs 29 and 30 28 s nm t corr t y n p m t 1 2 t 29 s nm 1 t t s nm t 30 σ s nm 2 1 t 1 t s nm t s nm 2 these formulations are similar to that of the morris approach yet the samples are extracted with respect to variable input factors rather than in the parameter space in this sense the two proposed indices s nm and σ s nm represent the average effect of p m on y n within the whole input space and the variation that stems from the changing input forcing respectively 2 4 2 relationship between the filtered ensemble evolution pattern and the iss src index although the performance of the correction scheme is commonly suggested to be affected by the parameter s sensitivity there is insufficient logical proof for such a conclusion here we aim to establish a mathematical relationship between the iss src index and the enkf performance for the j 1 t h and j 2 t h ensemble members of parameter p m 1 the enkf update scheme is formulated as observation member error j omitted 31 δ p m 1 j 1 k m 1 d y j 1 32 δ p m 1 j 2 k m 1 d y j 2 the left side refers to the alterations made to the specific ensemble member and k m 1 indicates the m 1 t h row of the kalman gain matrix which represents the statistical relationship between p m 1 and y the update of member distance p m 1 j 1 p m 1 j 2 l m 1 j 1 j 2 is then 33 δ l m 1 j 1 j 2 k m 1 y j 2 y j 1 if p m 1 is not sensitive i e for all y n s n m 1 and σ s n m 1 are close to 0 thus c o r r y n p m 1 and c o v y n p m 1 are also close to 0 assume c y y c d is adequately large which naturally holds when model outputs have not converged we can derive from eq 20 34 c p m 1 y c y p m 1 0 k m 1 0 where c p m 1 y is the m 1 t h row of c p y and c y p m 1 is the m 1 t h column of c y p then 35 δ l m 1 j 1 j 2 0 36 δ p m 1 j 1 δ p m 1 j 2 0 thus the ensemble members of p m 1 will not change or converge more specifically consider the case in which the model output is one dimensional while the parameter is multi dimensional i e y y r 1 and p r m m 1 and all the components of p are updated simultaneously assuming two parameters p m 1 and p m 2 have the same prior ensemble variance σ p m 1 2 σ p m 2 2 a more straightforward interpretation can be given as 37 δ l m 1 j 1 j 2 δ l m 2 j 1 j 2 k m 1 y j 2 y j 1 k m 2 y j 2 y j 1 c p m 1 y c p m 2 y corr y p m 1 corr y p m 2 where c p m y is the covariance of p m and y therefore it is proven that the reduction in ensemble spread and the amount of correction are proportional to the parameter sensitivity index considering such a logical relationship between the iss src index and correction performance the significance of an elaborate analysis on parameter sensitivity and its temporal variability should be even more emphasized 3 synthetic experiments 3 1 case brief the study area is located downstream of the jinping i hydropower station jpihs sichuan china situated in the middle reaches of the yalong river the jpihs features a 305 m high arch dam one of the tallest arch dams in the world and a total capacity of 7 8 billion m3 the magnitude of the reservoir outflow ranges from 50 m3 s to 3500 m3 s with a maximum rising speed of more than 1500 m3 s per 30 min such an intense variation poses significant risks to downstream human activities urging the need for precise hydrodynamic process simulations fourteen automatic water level gauges are located in the 120 km long downstream channel fig 1 twenty two trapezoid terrain cross sections are provided by the yalong river hydropower development co ltd given the difficulty of measuring the channel topography on site these sections are conceptualized from the fusion of 30 m resolution dem data unmanned aerial vehicle uav measurements of above water topography and rough empirical estimations of the underwater terrain in the synthetic experiments ses we investigate the performance of the enkf when each gauged cross section has one or more parameter s as well as its relationship with the varying parameter sensitivity the terrain errors are temporarily ignored and further handled with the specific methods discussed in section 4 3 2 one parameter per section se1 the impact of model warmup one of the most commonly studied parameters in 1 d models is manning s roughness coefficient n eqs 2 and 3 the se1 is conducted as follows 1 specify an initial set of n s which is assumed as the true value and denoted as n 0 r 14 assign each component of n 0 to the corresponding gauged section 2 run the model with n 0 then record the sectional water level output series z 0 t z r 14 t 1 2 t as precise observations of reality 3 alter n 0 to n which represents a biased first guess of unknown parameters by multiplying each component with perturbation factors randomly chosen from 0 85 1 15 uniformly then sample gaussian initial ensembles n j j 1 2 j around n 4 update the ensemble sequentially using enkf until reaching the predefined number of corrections a 40 h hypothetical flood series is used in se1 with 40 enkf iterations and an ensemble population of 40 detailed settings can be found in tables 1 2 and fig 2 if the enkf is activated as soon as the simulation begins the ensemble spread will converge with considerable speed whereas the ensemble mean suffers dramatic fluctuations before approaching the true value fig 3 a significant improvements are obtained by specifying a model warmup period before assimilating i e allowing the ensemble realizations to evolve freely before the enkf intervenes fig 3b the instant convergence in the ensemble and decrease in error imply that the input output relationship is approximately linear in the investigated parameter domain since the generation of the initial state field is biased as in most dynamic models the parameter output correlations are unstable at preliminary stages fig 4 a b leading to poor correction performance without warming up although evensen 2003 claimed that the enkf should be launched after covering a few characteristic time scales of the dynamic model which has been given direct proof here yet rarely mentioned in the reviewed literature it is worth adding that such a characteristic time scale not only varies from model to model but also from scenario to scenario in hydrodynamic models it is controlled by the level of external forcing discussed further in section 4 1 a general criterion for determining the duration of the warmup phase should be whether the parameter output correlations are stable boundary conditions should be stationary in the same period to exclude input associated variation 38 s nm t δ t s nm t δ t s nm 0 3 3 two parameters per section se2 convergence features of sensitivity varying parameters considering that it is sometimes too idealistic to assume that each output element is principally manipulated by a single parameter we will now explore how the correction behavior reacts when the number of uncertain factors increases here a hypothetical relationship between roughness coefficient n and sectional water depth h is introduced xu et al 2017 39 n h k h b hence the bed physics varies with the changing boundary and is controlled by two independent parameters the gradient k and the intercept b substituting the n r 14 in se1 with p k t b t t r 28 the simulation correction procedure is repeated with 40 rounds of enkf iteration since the parameters are more strongly coupled the ensemble size is set to five times that of se1 see table 2 the input series includes a complete rise and fall process and can be referenced in fig 2 the parameter correction performance in se2 is not as satisfying as that in se1 fig 5 in the initial stage with lower water levels the ensembles of intercept b converge with considerable speed to the true value while the mean errors of the gradient k fluctuate with a steadily maintained ensemble spread until the water level rises figs 5b and 6 the inability to make reliable estimations at early stages derives from the inadequate information provided by the boundary forcing i e the contribution of the two factors to the output uncertainty is indistinguishable under steady input conditions as indicated in 2 4 2 such a time relevant correction performance stems from input dependent parameter sensitivity taking k 13 as an example its ensemble begins to converge as soon as s nm n m 13 rises due to the changing input forcing i e the arrival of the flood peak fig 6 with respect to the iss src indices s nm and σ s nm the intercept b exhibits a more significant overall impact than the gradient k fig 7 e while the system responses to the two factors both show evident variability throughout the whole process fig 7f variation in k s sensitivity is slightly more distinct than that in b s due to its connection with the changing water level and in fact the temporary reduction in s zb is a result of the increase in s zk hence introducing new factors will inevitably weaken the influence of the original ones in addition the results show that the upstream riverbed roughness influences the flow pattern in the entire downstream region fig 7b f yet the upstream water level responds only to the parameters of neighboring downstream sections fig 7b f these interactions are more pronounced when the discharge rate changes the variation in riverbed roughness results in variation in flow speed the wave phase and finally the water level 4 enhancing reservoir release simulation accuracy using the iss src assisted enkf as mentioned in 3 1 the lack of reliable terrain data reduces the accuracy of flood simulation because field measurements are not implementable for various reasons we turn our attention to how to maximize the use and possible correction of the available information following the methods described above this section seeks to identify and calibrate the dominant parameters by the iss src assisted enkf leading to the improvement in modeling reliability 4 1 uncertainty source identification using iss src even when high resolution topographic data are available the veracity of these data can be deteriorated by a variety of factors including sedimentation erosion measurement error and obsolescence issues despite the inevitable loss of detail the conceptualized section geometry is superior in terms of the convenience of characterization the applied trapezoid section in this paper features four factors bottom elevation be bottom width bw side slopes slp and manning s roughness coefficient n as shown in fig 1 uncertainty in cross section properties at the gauge stations stems not only from the terrain error but also from the distinction between the terrain section and the observation section in other words the geometry of the observation sections can only be derived from an interpolation of nearby terrain sections under such circumstances it is necessary to amend the interpolated geometry to obtain reliable simulation results the adjustment made to the interpolated be bw and slp at the gauges are parameterized as bea bwa and slpa for analytical convenience a for amendment naturally manning s n is included in the analysis yet defined by its absolute value rather than the amount of amendment the original and corrected section geometry are generated by the following steps 1 at model initialization the observation sections oss are interpolated from their nearby terrain sections tss 2 at each correction step the terrain amendments are first defined at the oss then linearly interpolated lengthwise between contiguous observation sections including the tss and the finer scaled model discretization sections to guarantee the smoothness of the longitudinal bed shape fig 8 to evaluate their contributions to model uncertainty the bea bwa slpa and n are included in the iss src analytical procedure with a 60 h hypothetical reservoir release sequence and a further expanded ensemble size due to the increase of parameter dimensions table 2 while a similar pattern in the sensitivity matrix emerges in the model warmup phase its duration extends to 19 2 h fig 9 a this increase is mainly due to the smaller initial discharge in the present case the initial discharge is 100 m3 s here and 400 m3 s in the ses which leads to a slower speed of wave propagation with newly introduced terrain modification parameters bea bwa and slpa the physical condition manning s n loses its dominance in the early stages the model outputs seem to be most sensitive to the sectional be fig 9b as the water level rises the impact of the bea decreases dramatically while the influences of bwa and roughness n increase fig 9d the absolute values of the average local response of the bea bwa and n are close to each other given the specified input with considerable variation in time the term local response refers to the sensitivity of the sectional output to the parameters defined at the same location while the slpa has no overall effect or significant variation fig 9e f in addition the parameter output interactions between the up and downstream sections exhibit a similar pattern as those in the ses fig 9c f fig 10 provides a more detailed view of the temporal evolution trends of the four parameters local responses in summary bea bwa and n all play an essential role in characterizing section properties while the slpa contributes little to the output uncertainty and is thus excluded from the subsequent parameter correction process note that the slpa can be neglected only in situations with a relatively broad and shallow riverbed shape in the present case bw 60 m and maximum water depth 15 m 4 2 amend riverbed parameters based on real world observation an actual jpihs outflow process ranging from 63 m3 s to 1767 m3 s that began at 0 00 september 13 2017 and ended at 2 00 september 15 2017 50 h in total referred to as the calibration period and the observed resulting water level series of the 14 gauges are used for simulation and assimilation respectively the reservoir release series displays a stepped pattern and discrete distribution of discharge frequency providing even less information for model calibration than natural runoff in this section the enkf scheme is implemented with 60 assimilation steps other settings shown in table 2 the correction processes of the three factors bea bwa and n are in accordance with the iss src assessments the bea serves as the primary factor in the initial stage and converges quickly due to the error in interpolated section elevation which is estimated to be up to nearly two meters fig 11 a it is neither practical nor sensible to compensate for such a sizable error by altering other factors after the release of manual discharge the influences of bwa and n increase and begin to comply with the revision made by enkf sequentially from upstream to downstream gauges the bwas exhibit significant alteration ranging from 15 to 80 m implying that the first guesses are globally overestimated fig 11b conversely the roughness coefficients though showing similar trends in time as the bwas are proven to be less influential and undergo minor corrections nevertheless manning s n for the 8th observation section still receives a 42 modification and shows a more remarkable ensemble convergence than those of other gauges fig 11c since a number of the parameters are considered to possess significant initial biases the above simulation correction procedure is repeated once the corrected parameters in fig 11 are used as first guesses of the second run namely c2 with other settings identical to c1 yielding average absolute amendments of 0 28 m for bea 7 4 m for bwa and 0 0011 for the roughness coefficients as the changes made are relatively minor the details of c2 are omitted as a verification we then apply the c1 and c2 corrected parameters to simulate a 480 h release process that began at 0 00 september 13 2017 and ended at 0 00 october 3 2017 fig 12 including the calibration period both corrected parameter sets present generally satisfying consistency with the observations and significant improvements from the uncorrected parameters with averaged rmses reduced from 0 654 m before correction to 0 199 m c1 and 0 154 m c2 fig 13 the c2 outputs only slightly outperform the c1 outputs which implies that one time correction is basically adequate several outliers appear in the fast rising phase that lies between the pre and postarrival moments of the flood peak which might be explained as follows as the water level rises considerably fast e g gauge station 4 observed a 1 72 m rise in 10 min at 23 57 september 13 2017 a small bias in the wave propagation speed could produce a large error in the water level hence it is quite challenging to achieve even higher precision with a limited spatial temporal model resolution while retaining a reasonable computational cost despite these minor flaws the iss src assisted enkf can produce reliable flood simulations for areas with poor terrain data to evaluate the significance of correctly identifying the critical input factors we investigated three contrasting parameter estimation scenarios i e correcting bea bwa slpa and n c0 correcting bwa slpa and n c3 and correcting bea slpa and n c4 all settings are compared in terms of the subsequent simulation rmse fig 14 as comparably sensitive factors the be and bw of the terrain section contribute considerably to the water level error and neglecting them strikingly degrades the parameter estimation improvement c3 and c4 vs c1 and c2 in addition ignoring the most primary parameter i e bea can even result in negative effects of parameter estimation c4 vs uncorrected in contrast discarding trivial details namely the slpa does not lead to the worsening of outcomes c0 vs c1 and c2 5 conclusions a generalized gsa method is proposed to assist the enkf in parameter correction problems in this paper by sampling in the input space and dynamically evaluating global parameter sensitivity we describe the model response of sensitivity varying parameters by the average and variation of their impact during the model process of interest we also obtain a quantitative relationship between the parameter ensemble evolution pattern and the relevant sensitivity index underlining the significance of identifying critical model features to ensure the enkf correction performance the factor identification correction methods are then employed to amend riverbed physical and geometrical characteristics in the simulation of a real world reservoir release case and the methods achieve decent results we present the following remarkable discoveries 1 in circumstances with a biased model initialization operation the enkf must be implemented after the model has warmed up i e when the effects of initialization error subside and a credible input output correlation has been established the appropriate length of the warmup period is decided by both the model s physical construction and the inputs 2 to evaluate the shifting model responses to multiple uncertain factors we analyze the src indices at each timestep to include both the interactions within the parameter space and the variation that stems from changing inputs the first and second order moments of the sampled indices are able to describe the overall effect and the fluctuation 3 we prove that the iss src analysis can predict the effect of the enkf correction process insensitive factors will not converge and thus can be removed from the correction procedure in addition the bias in one uncertain parameter will lead to misguided estimations for other related parameters because the accompanying error must be compensated such a preliminary investigation is particularly essential in high dimensional cases 4 with the support of the iss src analysis we manage to extract the dominant factors from the conceptualized section geometry in the hydrodynamic model we then revise these parameterizations using the enkf according to real world observations the consequent simulation performance based on corrected parameters is significantly enhanced although the advances in computational techniques have supported the progress of simulation capacity in terms of both fine geometrical resolution and substantial physical details utilizing a relatively simple model is still useful under specific circumstances as pointed out by loucks and van beek 2017 increasing model complexity may not only add to the cost of data collection but also introduce even more parameters and thus even more potential sources of error in the enkf scheme introducing unidentifiable parameters can lead to unsatisfying correction results in a more general sense it is crucial to investigate all possible influencing factors in the model before the optimization or calibration procedure and judge whether the specified simulation analysis scheme has covered the main features of the natural processes of interest the methods presented in this paper can be popularized to other data poor regions to avoid measurement difficulties without sacrificing simulation accuracy in further work parallel computing techniques could be applied in enkf practices to significantly improve calculation efficiency credit authorship contribution statement junyu wei conceptualization methodology software formal analysis investigation resources data curation writing original draft writing review editing visualization weihong liao resources writing review editing funding acquisition project administration zhao zhang methodology software conceptualization writing review editing xiaohui lei conceptualization supervision funding acquisition validation project administration jiabiao wang resources writing review editing hao wang supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper was jointly supported by the national key r d program of china 2017yfc0406004 the national natural science fund 51709273 and the key r d program of power construction corporation of china dj zdzx 2016 02 the reservoir release data water level gauge data and the topography data were provided by the yalong river hydropower development co ltd www ehdc com cn additional data and code may be obtained from the corresponding author appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125036 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5323,evaluating the risk of flows related to reservoir releases requires a comprehensive grasp of the associated hydrodynamic process due to the obstacle posed by bathymetry in mountainous areas the accuracy of the hydrodynamic simulation is hindered by the absence of reliable terrain data to evaluate both the overall parameter sensitivities e g sensitivities to cross section geometry and roughness within the feasible domain and the varying responses induced by changes in the input forcing e g inflow series we introduce a generalized global sensitivity indicator namely the input space sampled standardized regression coefficients iss src through mathematical derivation we found that the parameter whose iss src index is close to zero will not be significantly updated by the enkf thus iss src can be employed to assist the enkf by predicting the correction performance and reducing the dimensionality of identifiable factors the results of synthetic experiments confirm the connection between the evolution of the parameter ensemble and the dynamic sensitivity indicators the iss src assisted enkf is employed to modify the physical and geometrical parameters of riverbed sections in the hydrodynamic model of a real world reservoir release case and the simulation accuracy is greatly enhanced this success demonstrates the potential of obtaining reliable flood simulation results with only coarse resolution topographic information keywords global sensitivity analysis data assimilation topography correction hydrodynamic model 1 introduction with the increasing attention paid to the impact of reservoir operations on the ecological health and the human activity safety in downstream areas adams et al 2017 li et al 2018 the importance of accurately predicting the hydrodynamic process caused by reservoir releases which produce different pattern than natural runoff bi et al 2019 has increased shaw et al 2017 with the construction of hydropower projects in rugged areas it can be either technically or economically impractical to obtain the topographic data necessary for hydraulic simulations on site as an alternative to field measurements open access digital elevation model dem data sets and remote sensing measurements have been employed to facilitate flood modeling archer et al 2018 pham et al 2018 although the resolution of these data has been considerably enhanced it is still relatively difficult to guarantee the reliability of the underwater topographic information in addition the accuracy of existing data can decrease over time due to physical processes such as erosion sedimentation and slope collapse bi et al 2019 therefore correcting the errors in the coarse resolution terrain data thereby improving the simulation precision is crucial for refining reservoir flood control operations being concise yet effective the one dimensional 1 d hydrodynamic model based on the discrete form of the saint venant equations is a well developed tool for flow forecasting in rivers and canals roux and dartus 2005 xu et al 2017 wang et al 2018 the time invariant or quasistatic factors in the 1 d hydrodynamic model are mainly terrain physical and geometrical characteristics the flow resistance of the river canal bed is summarized by manning s roughness coefficient n and terrain geometry is commonly an interpolation of measurements in discretely sampled sections the difficulty of obtaining precise bathymetry measurements lai et al 2018 hu et al 2019 as well as the geomorphologic changes dysarz et al 2017 degrades the reliability of the available terrain data under such circumstances the section geometries must be conceptualized or reconstructed lai et al 2018 peña and nardi 2018 which raises the question of how to alleviate the accompanying distortion to the fullest possible extent by virtue of parameter correction skills many researchers have focused on the calibration of physical parameters in hydrodynamic models ayvaz 2013 mayo et al 2014 baatz et al 2017 while the simultaneous estimation of topographical and physical features has not been sufficiently studied yoon et al 2012 hence this paper aims to analyze the role of physical and terrain parameters from the perspective of model dynamics and obtain the optimal spatial heterogeneous topographic features based only on hydrological element observations while the real world is a continuum macroscopically parameters are finite dimensional in discrete numerical models which implies that they are intrinsically biased unfortunately only a small number of the parameters can be handled concurrently because an increase in the number of considered variables results in the growth of both the complexity of calculation and the difficulty of approaching the optimum bellman 1961 selecting the dominant factors that contribute the most to model errors requires meticulous investigation e g parameter sensitivity analysis sa principal component analysis pca etc the most straightforward approach to assess a parameter s impact given that the parameters are independent of each other is to calculate derivatives neumann 2012 this method merely gives information in the neighborhood around a specified point in the parameter space and is therefore regarded as a local sensitivity index saltelli et al 2005 chen et al 2019 the global sensitivity analysis gsa on the other hand aims to investigate the model response over the whole feasible parameter domain considering the variation in derivatives that stems from nonlinear responses and interparameter coupling effects gamerith et al 2013 razavi and gupta 2016 ge and menendez 2017 typical gsa methods include regression based standardized regression coefficients src one factor at a time oat based morris screening variance based fourier amplitude sensitivity tests and entropy based kullback leibler entropy methods neumann 2012 a wide range of studies have employed these methods to evaluate model response over the parameter domain saltelli et al 2005 gamerith et al 2013 razavi and gupta 2016 ge and menendez 2017 chen et al 2019 whereas the temporal evolution of the sensitivity index due to the varying input forcing boundaries has received less attention until recent decades for example massmann et al 2014 analyzed the dynamics of parameter sensitivities with time varying precipitation and temperature inputs in a conceptual rainfall runoff model gupta and razavi 2018 also investigated how the sensitivities vary with precipitation and potential evapotranspiration series in the hbv sask hydrologic model previous research implemented sensitivity evaluation to either support model calibration or understand model structures sieber and uhlenbrook 2005 reusser et al 2011 massmann et al 2014 while few researchers have focused on the connection between model dynamics and parameter correction effects in this paper we explore the mechanism by which varying model input forces affect the sensitivity indices and further determine the parameter correction process while sa tries to evaluate the effect of uncertain input factors on the outputs parameter correction aims to reduce the simulation errors manual trial and error is a simple approach to address parameter biases but suffers from a lack of reliability in experiential treatments and features an unacceptable workload liu et al 2019 parameter optimization is a commonly employed method that automatically adjusts the parameters by various algorithms ayvaz 2013 soltani et al 2019 lu et al 2019 with little consideration of the physical structure of models optimization methods are often hindered by the local optimum issues especially in nonlinear high dimensional cases moore et al 2010 qin et al 2018 data assimilation techniques treat various types of information statistically to minimize prediction errors evensen 2009 hostache et al 2018 song et al 2019 the ensemble kalman filter enkf first proposed by evensen evensen 1994 is a modified formulation of the conventional kalman filter kalman 1960 replacing the statistical error matrix with an error matrix based on an ensemble of random samples due to its explicit iterative nature the enkf features good robustness and acceptable computational cost franssen and kinzelbach 2008 xiong et al 2019 lei et al 2019 and has thus been introduced into parameter estimation as an alternative and productive approach mayo et al 2014 baatz et al 2017 siripatana et al 2018 although it is a common practice to correct the most sensitive parameters among numerous sources of error hu et al 2017 the mechanism connecting the parameter sensitivity features to the performance of the enkf based correction scheme has received little in depth investigation baatz et al 2017 lei et al 2019 in addition previous research suggest that a model warm up period is needed to harmonize model response with input and parameters before assimilation evensen 2003 xie and zhang 2010 nevertheless the criterion for the warm up duration in our reviewed literature is still unclear given these limitations of existing research we believe that clarifying the relationship between input output response and ensemble evolution in enkf would contribute to constructing a more explicit framework of the error identification correction procedure considering the aforementioned deficiencies in existing studies this paper addresses the following issues 1 establishing a sensitivity metric that considers both the variation within the parameter domain and the changing input conditions 2 investigating the performance of the enkf when estimating sensitivity varying parameters and explaining how the estimation process relates to the parameter importance indicators 3 identifying the primary sources of error in a simulation of reservoir operation triggered hydrodynamic processes using the proposed gsa method and addressing the biases imported by insufficient terrain data with the enkf correction scheme the remainder of this paper is organized as follows in section 2 we first present the conventional simulation assimilation and sa methods then approach issues 1 and 2 by proposing a new generalized gsa index and exploring its connection with the enkf in section 3 we further address issue 2 by carrying out sa and enkf based parameter correction in synthetic experiments section 4 utilizes the iss src assisted enkf in a real world reservoir release simulation case and verifies their validity by demonstrating improvements in output accuracy thus resolving issue 3 main findings are concluded in section 5 2 methods in this section we first provide an overview for the 1 d hydrodynamic model the enkf and src sensitivity index in sections 2 1 2 3 then in section 2 4 a generalized src index iss src is proposed and its logical relationship with enkf correction performance is given before introducing the methods it is necessary to clarify the definition of the terms parameter and input used in this paper by parameter we indicate the measure that characterizes the specific inherent nature of the model such as the roughness coefficient and gravity by input we refer to the unstable external forces that drive the model evolution such as inflow boundary conditions and precipitation it is worth noting that for underlying numerical algorithms there is no essential distinction between input forces and parameters nevertheless in the sense of physical meaning they play quite different roles thus we believe that treating them separately helps to analyze the model dynamics in a clearer manner 2 1 1 d hydrodynamic model the 1 d hydrodynamic model consists of mass and momentum conservation equations along the flow direction lei et al 2019 1 a t q x 0 2 q t x q 2 a g a z x s f 0 where a is the cross sectional flow area m2 q is the discharge rate m3 s x is the longitudinal coordinate m t denotes time s and z is the water level m since eqs 1 and 2 are hyperbolic partial differential equations their analytical solutions are not available in most cases the well known preissimann four point implicit discretization scheme laks 2019 is employed for linearized numerical iteration please refer to our previous work lei et al 2019 which used the same 1 d hydrodynamic algorithm as the present paper the so called frictional slope in eq 2 is given by the empirical manning s equation 3 s f n 2 u 2 r 4 3 in eq 3 the generalized effect of riverbed resistance is decided by the cross sectional geometry represented by hydraulic radius r flow rate represented by velocity u and bed physics represented by manning s roughness coefficient n 2 2 enkf the kalman filter was first proposed for filtering and prediction problems in linear dynamic systems kalman 1960 generally we have two independent sources of information prior model forecasts ψ f and observations d which are assumed to be gaussian 4 ψ f n ψ p r i o r c f 5 d n h ψ 0 c d where ψ p r i o r and ψ 0 are the prior mean of forecast and the true state respectively c is the error covariance matrix with superscripts f and d indicating forecast and observation respectively h is the linear operator that projects the state vector into the observation space the likelihood of the estimator ψ a a for analysis for the posterior state is inversely proportional to the function evensen 2009 6 j ψ a ψ f ψ a t c f 1 ψ f ψ a d h ψ a t c d 1 d h ψ a the best estimation that maximizes the likelihood is given as 7 ψ a ψ f k d h ψ f in eq 7 the so called kalman gain is formulated as 8 k c f h t h c f h t c d 1 the covariance of state forecast c f is also replaced by 9 c a i k h c f for linear dynamic systems a model with error can be written as 10 ψ t 0 g ψ t 1 0 q t 1 where the subscript indicates timestep g is the linear model operator and q t 1 represents the model error over a single time step generally q t 1 is unknown and the practical numerical model will evolve according to evensen 2009 11 ψ t f g ψ t 1 a 12 c t f g c t 1 a g t c t 1 q where ψ t f is the prior model forecast at t ψ t 1 a is the posterior state at t 1 c t f and c t 1 a are their covariances c t 1 q is the covariance matrix of q t 1 given the initial values for the model state and corresponding error eqs 7 12 sequentially assimilate model predictions with observations generating estimations with least squared variance for sophisticated systems in which g is nonlinear the propagation pattern in eq 12 of the model error covariance matrix no longer stands and a new approach to update error covariances is needed the enkf was proposed as a monte carlo solution for estimating the stochastic characteristics for error matrices evensen 1994 by sampling an ensemble ψ j f j 1 2 j of model states the statistical covariance matrix c f in eq 8 can be replaced by the sample covariance matrix 13 c f e e ψ f e ψ f ψ f e ψ f t where e represents the expectation and e indicates that the covariance matrix was sampled the observation vector is also sampled with a predefined measurement error burgers et al 1998 14 d j d j j n 0 c d 15 c d e e d e d d e d t therefore the analysis result ψ a in eq 7 changes to 16 ψ j a ψ j f c f e h t h c f e h t c d e 1 d j h ψ j f based on the central limit theorem the sample covariance matrix c f e will converge to the statistical covariance c f with the speed of j evensen 2003 the classic formulation of the enkf serves to assimilate simulation and observation results in inverse problems the state vector ψ f is replaced by the uncertain model parameters p r m the evolution operator g becomes an identity matrix implying that the parameters are constant with time and the observation matrix h is substituted by the model calculator g that relates input parameters with simulated observations 17 p j t f p j t 1 a 18 y j t g p j t f in which y r n is the model output vector corresponding to observations p j t f and p j t 1 a are the prior guess of the true parameter value at t and the posterior guess at t 1 respectively while their uncertainties are implicitly represented by the ensemble covariances the reformulated parameter estimating enkf is written as moradkhani et al 2005 19 p j t a p j t f c p y e c y y e c d e 1 d j y j t where the covariance matrices are ensemble expectations at time t correspondingly the kalman gain becomes 20 k c p y e c y y e c d e 1 2 3 src for model outputs y and parameters p a straightforward formulation of sensitivity is simply the partial derivative of the output y n to p m n and m refer to the n t h and m t h components of the output and parameter vector respectively saltelli et al 2005 21 y n p m y n p m in numerical models approximations to partial derivatives can be obtained by changing oat in the discretized partial differential scheme 22 s nm δ y n δ p m y n p 1 p 2 p m δ p m p m y n p 1 p 2 p m p m δ p m as a local sensitivity index the difference quotient in eq 22 merely gives the gradient at a specified parameter point conversely the gsa aims to assess the model response over the whole parameter space the src addresses such an issue by evaluating overall sensitivity with parameter output regression saltelli et al 2004 gamerith et al 2013 given a set of samples p j y j j 1 2 j the linear regression for the relationship is formulated as 23 y y c y p c p p 1 p p y m p p the variables with bars indicate the sample mean and c represents covariance the src denoted as a matrix s whose element s nm represents the response of output y n to parameter p m scales each linear coefficient in eq 23 with the corresponding sample standard deviation of the parameter and output 24 s nm σ p m σ y n m nm assuming that each parameter is sampled independently from the others we have 25 c p p m 1 m 2 m 1 m 2 c o v p m 1 p m 2 0 m nm c o v y 1 p 1 c o v y 1 p m c o v y n p 1 c o v y n p m σ p 1 2 0 0 σ p m 2 1 nm 26 c o v y n p m σ p m 2 27 s nm c o v y n p m σ y n σ p m c o r r y n p m eq 27 implies that under the specific sampling criterion the src can be interpreted as correlation coefficients of inputs and outputs eqs 27 and 19 indicate that both the enkf and the src involve monte carlo realizations and utilize the subsequent covariance information which implies that they are inherently connected therefore instead of other gsa methods the src neumann 2012 is selected in this paper to describe the parameter output relationship notably the src formulation in eq 27 avoids the possible numerical instability caused by matrix inversion when parameters vary greatly in their magnitudes 2 4 a generalized sensitivity index iss src and its relationship with enkf 2 4 1 input space sampled iss src as an alternative to the src the method proposed by morris 1991 addresses gsa problems by randomly sampling the point p p 1 p 2 p m p m t in eq 22 within the parameter space the sample mean of s nm is used to measure overall effects and the standard deviation represents the changes in model response caused by nonlinearity and cross parameter interactions although the variation in the parameter space can be handled by both approaches the fluctuation in sensitivity indices caused by the changing input forces still needs proper characterization previous studies investigated the dynamics of parameter sensitivity indices by illustrating their time sequence sieber and uhlenbrook 2005 reusser et al 2011 massmann et al 2014 which provides comprehensive yet complex information about model structure in this paper the variation in parameter sensitivity that derives from changing inputs is described from both time resolved and time aggregated perspectives the src indices are first sampled at each timestep eq 28 corresponding to different levels of model inputs the first and second order moments are then calculated to summarize the overall importance of the parameterization eqs 29 and 30 28 s nm t corr t y n p m t 1 2 t 29 s nm 1 t t s nm t 30 σ s nm 2 1 t 1 t s nm t s nm 2 these formulations are similar to that of the morris approach yet the samples are extracted with respect to variable input factors rather than in the parameter space in this sense the two proposed indices s nm and σ s nm represent the average effect of p m on y n within the whole input space and the variation that stems from the changing input forcing respectively 2 4 2 relationship between the filtered ensemble evolution pattern and the iss src index although the performance of the correction scheme is commonly suggested to be affected by the parameter s sensitivity there is insufficient logical proof for such a conclusion here we aim to establish a mathematical relationship between the iss src index and the enkf performance for the j 1 t h and j 2 t h ensemble members of parameter p m 1 the enkf update scheme is formulated as observation member error j omitted 31 δ p m 1 j 1 k m 1 d y j 1 32 δ p m 1 j 2 k m 1 d y j 2 the left side refers to the alterations made to the specific ensemble member and k m 1 indicates the m 1 t h row of the kalman gain matrix which represents the statistical relationship between p m 1 and y the update of member distance p m 1 j 1 p m 1 j 2 l m 1 j 1 j 2 is then 33 δ l m 1 j 1 j 2 k m 1 y j 2 y j 1 if p m 1 is not sensitive i e for all y n s n m 1 and σ s n m 1 are close to 0 thus c o r r y n p m 1 and c o v y n p m 1 are also close to 0 assume c y y c d is adequately large which naturally holds when model outputs have not converged we can derive from eq 20 34 c p m 1 y c y p m 1 0 k m 1 0 where c p m 1 y is the m 1 t h row of c p y and c y p m 1 is the m 1 t h column of c y p then 35 δ l m 1 j 1 j 2 0 36 δ p m 1 j 1 δ p m 1 j 2 0 thus the ensemble members of p m 1 will not change or converge more specifically consider the case in which the model output is one dimensional while the parameter is multi dimensional i e y y r 1 and p r m m 1 and all the components of p are updated simultaneously assuming two parameters p m 1 and p m 2 have the same prior ensemble variance σ p m 1 2 σ p m 2 2 a more straightforward interpretation can be given as 37 δ l m 1 j 1 j 2 δ l m 2 j 1 j 2 k m 1 y j 2 y j 1 k m 2 y j 2 y j 1 c p m 1 y c p m 2 y corr y p m 1 corr y p m 2 where c p m y is the covariance of p m and y therefore it is proven that the reduction in ensemble spread and the amount of correction are proportional to the parameter sensitivity index considering such a logical relationship between the iss src index and correction performance the significance of an elaborate analysis on parameter sensitivity and its temporal variability should be even more emphasized 3 synthetic experiments 3 1 case brief the study area is located downstream of the jinping i hydropower station jpihs sichuan china situated in the middle reaches of the yalong river the jpihs features a 305 m high arch dam one of the tallest arch dams in the world and a total capacity of 7 8 billion m3 the magnitude of the reservoir outflow ranges from 50 m3 s to 3500 m3 s with a maximum rising speed of more than 1500 m3 s per 30 min such an intense variation poses significant risks to downstream human activities urging the need for precise hydrodynamic process simulations fourteen automatic water level gauges are located in the 120 km long downstream channel fig 1 twenty two trapezoid terrain cross sections are provided by the yalong river hydropower development co ltd given the difficulty of measuring the channel topography on site these sections are conceptualized from the fusion of 30 m resolution dem data unmanned aerial vehicle uav measurements of above water topography and rough empirical estimations of the underwater terrain in the synthetic experiments ses we investigate the performance of the enkf when each gauged cross section has one or more parameter s as well as its relationship with the varying parameter sensitivity the terrain errors are temporarily ignored and further handled with the specific methods discussed in section 4 3 2 one parameter per section se1 the impact of model warmup one of the most commonly studied parameters in 1 d models is manning s roughness coefficient n eqs 2 and 3 the se1 is conducted as follows 1 specify an initial set of n s which is assumed as the true value and denoted as n 0 r 14 assign each component of n 0 to the corresponding gauged section 2 run the model with n 0 then record the sectional water level output series z 0 t z r 14 t 1 2 t as precise observations of reality 3 alter n 0 to n which represents a biased first guess of unknown parameters by multiplying each component with perturbation factors randomly chosen from 0 85 1 15 uniformly then sample gaussian initial ensembles n j j 1 2 j around n 4 update the ensemble sequentially using enkf until reaching the predefined number of corrections a 40 h hypothetical flood series is used in se1 with 40 enkf iterations and an ensemble population of 40 detailed settings can be found in tables 1 2 and fig 2 if the enkf is activated as soon as the simulation begins the ensemble spread will converge with considerable speed whereas the ensemble mean suffers dramatic fluctuations before approaching the true value fig 3 a significant improvements are obtained by specifying a model warmup period before assimilating i e allowing the ensemble realizations to evolve freely before the enkf intervenes fig 3b the instant convergence in the ensemble and decrease in error imply that the input output relationship is approximately linear in the investigated parameter domain since the generation of the initial state field is biased as in most dynamic models the parameter output correlations are unstable at preliminary stages fig 4 a b leading to poor correction performance without warming up although evensen 2003 claimed that the enkf should be launched after covering a few characteristic time scales of the dynamic model which has been given direct proof here yet rarely mentioned in the reviewed literature it is worth adding that such a characteristic time scale not only varies from model to model but also from scenario to scenario in hydrodynamic models it is controlled by the level of external forcing discussed further in section 4 1 a general criterion for determining the duration of the warmup phase should be whether the parameter output correlations are stable boundary conditions should be stationary in the same period to exclude input associated variation 38 s nm t δ t s nm t δ t s nm 0 3 3 two parameters per section se2 convergence features of sensitivity varying parameters considering that it is sometimes too idealistic to assume that each output element is principally manipulated by a single parameter we will now explore how the correction behavior reacts when the number of uncertain factors increases here a hypothetical relationship between roughness coefficient n and sectional water depth h is introduced xu et al 2017 39 n h k h b hence the bed physics varies with the changing boundary and is controlled by two independent parameters the gradient k and the intercept b substituting the n r 14 in se1 with p k t b t t r 28 the simulation correction procedure is repeated with 40 rounds of enkf iteration since the parameters are more strongly coupled the ensemble size is set to five times that of se1 see table 2 the input series includes a complete rise and fall process and can be referenced in fig 2 the parameter correction performance in se2 is not as satisfying as that in se1 fig 5 in the initial stage with lower water levels the ensembles of intercept b converge with considerable speed to the true value while the mean errors of the gradient k fluctuate with a steadily maintained ensemble spread until the water level rises figs 5b and 6 the inability to make reliable estimations at early stages derives from the inadequate information provided by the boundary forcing i e the contribution of the two factors to the output uncertainty is indistinguishable under steady input conditions as indicated in 2 4 2 such a time relevant correction performance stems from input dependent parameter sensitivity taking k 13 as an example its ensemble begins to converge as soon as s nm n m 13 rises due to the changing input forcing i e the arrival of the flood peak fig 6 with respect to the iss src indices s nm and σ s nm the intercept b exhibits a more significant overall impact than the gradient k fig 7 e while the system responses to the two factors both show evident variability throughout the whole process fig 7f variation in k s sensitivity is slightly more distinct than that in b s due to its connection with the changing water level and in fact the temporary reduction in s zb is a result of the increase in s zk hence introducing new factors will inevitably weaken the influence of the original ones in addition the results show that the upstream riverbed roughness influences the flow pattern in the entire downstream region fig 7b f yet the upstream water level responds only to the parameters of neighboring downstream sections fig 7b f these interactions are more pronounced when the discharge rate changes the variation in riverbed roughness results in variation in flow speed the wave phase and finally the water level 4 enhancing reservoir release simulation accuracy using the iss src assisted enkf as mentioned in 3 1 the lack of reliable terrain data reduces the accuracy of flood simulation because field measurements are not implementable for various reasons we turn our attention to how to maximize the use and possible correction of the available information following the methods described above this section seeks to identify and calibrate the dominant parameters by the iss src assisted enkf leading to the improvement in modeling reliability 4 1 uncertainty source identification using iss src even when high resolution topographic data are available the veracity of these data can be deteriorated by a variety of factors including sedimentation erosion measurement error and obsolescence issues despite the inevitable loss of detail the conceptualized section geometry is superior in terms of the convenience of characterization the applied trapezoid section in this paper features four factors bottom elevation be bottom width bw side slopes slp and manning s roughness coefficient n as shown in fig 1 uncertainty in cross section properties at the gauge stations stems not only from the terrain error but also from the distinction between the terrain section and the observation section in other words the geometry of the observation sections can only be derived from an interpolation of nearby terrain sections under such circumstances it is necessary to amend the interpolated geometry to obtain reliable simulation results the adjustment made to the interpolated be bw and slp at the gauges are parameterized as bea bwa and slpa for analytical convenience a for amendment naturally manning s n is included in the analysis yet defined by its absolute value rather than the amount of amendment the original and corrected section geometry are generated by the following steps 1 at model initialization the observation sections oss are interpolated from their nearby terrain sections tss 2 at each correction step the terrain amendments are first defined at the oss then linearly interpolated lengthwise between contiguous observation sections including the tss and the finer scaled model discretization sections to guarantee the smoothness of the longitudinal bed shape fig 8 to evaluate their contributions to model uncertainty the bea bwa slpa and n are included in the iss src analytical procedure with a 60 h hypothetical reservoir release sequence and a further expanded ensemble size due to the increase of parameter dimensions table 2 while a similar pattern in the sensitivity matrix emerges in the model warmup phase its duration extends to 19 2 h fig 9 a this increase is mainly due to the smaller initial discharge in the present case the initial discharge is 100 m3 s here and 400 m3 s in the ses which leads to a slower speed of wave propagation with newly introduced terrain modification parameters bea bwa and slpa the physical condition manning s n loses its dominance in the early stages the model outputs seem to be most sensitive to the sectional be fig 9b as the water level rises the impact of the bea decreases dramatically while the influences of bwa and roughness n increase fig 9d the absolute values of the average local response of the bea bwa and n are close to each other given the specified input with considerable variation in time the term local response refers to the sensitivity of the sectional output to the parameters defined at the same location while the slpa has no overall effect or significant variation fig 9e f in addition the parameter output interactions between the up and downstream sections exhibit a similar pattern as those in the ses fig 9c f fig 10 provides a more detailed view of the temporal evolution trends of the four parameters local responses in summary bea bwa and n all play an essential role in characterizing section properties while the slpa contributes little to the output uncertainty and is thus excluded from the subsequent parameter correction process note that the slpa can be neglected only in situations with a relatively broad and shallow riverbed shape in the present case bw 60 m and maximum water depth 15 m 4 2 amend riverbed parameters based on real world observation an actual jpihs outflow process ranging from 63 m3 s to 1767 m3 s that began at 0 00 september 13 2017 and ended at 2 00 september 15 2017 50 h in total referred to as the calibration period and the observed resulting water level series of the 14 gauges are used for simulation and assimilation respectively the reservoir release series displays a stepped pattern and discrete distribution of discharge frequency providing even less information for model calibration than natural runoff in this section the enkf scheme is implemented with 60 assimilation steps other settings shown in table 2 the correction processes of the three factors bea bwa and n are in accordance with the iss src assessments the bea serves as the primary factor in the initial stage and converges quickly due to the error in interpolated section elevation which is estimated to be up to nearly two meters fig 11 a it is neither practical nor sensible to compensate for such a sizable error by altering other factors after the release of manual discharge the influences of bwa and n increase and begin to comply with the revision made by enkf sequentially from upstream to downstream gauges the bwas exhibit significant alteration ranging from 15 to 80 m implying that the first guesses are globally overestimated fig 11b conversely the roughness coefficients though showing similar trends in time as the bwas are proven to be less influential and undergo minor corrections nevertheless manning s n for the 8th observation section still receives a 42 modification and shows a more remarkable ensemble convergence than those of other gauges fig 11c since a number of the parameters are considered to possess significant initial biases the above simulation correction procedure is repeated once the corrected parameters in fig 11 are used as first guesses of the second run namely c2 with other settings identical to c1 yielding average absolute amendments of 0 28 m for bea 7 4 m for bwa and 0 0011 for the roughness coefficients as the changes made are relatively minor the details of c2 are omitted as a verification we then apply the c1 and c2 corrected parameters to simulate a 480 h release process that began at 0 00 september 13 2017 and ended at 0 00 october 3 2017 fig 12 including the calibration period both corrected parameter sets present generally satisfying consistency with the observations and significant improvements from the uncorrected parameters with averaged rmses reduced from 0 654 m before correction to 0 199 m c1 and 0 154 m c2 fig 13 the c2 outputs only slightly outperform the c1 outputs which implies that one time correction is basically adequate several outliers appear in the fast rising phase that lies between the pre and postarrival moments of the flood peak which might be explained as follows as the water level rises considerably fast e g gauge station 4 observed a 1 72 m rise in 10 min at 23 57 september 13 2017 a small bias in the wave propagation speed could produce a large error in the water level hence it is quite challenging to achieve even higher precision with a limited spatial temporal model resolution while retaining a reasonable computational cost despite these minor flaws the iss src assisted enkf can produce reliable flood simulations for areas with poor terrain data to evaluate the significance of correctly identifying the critical input factors we investigated three contrasting parameter estimation scenarios i e correcting bea bwa slpa and n c0 correcting bwa slpa and n c3 and correcting bea slpa and n c4 all settings are compared in terms of the subsequent simulation rmse fig 14 as comparably sensitive factors the be and bw of the terrain section contribute considerably to the water level error and neglecting them strikingly degrades the parameter estimation improvement c3 and c4 vs c1 and c2 in addition ignoring the most primary parameter i e bea can even result in negative effects of parameter estimation c4 vs uncorrected in contrast discarding trivial details namely the slpa does not lead to the worsening of outcomes c0 vs c1 and c2 5 conclusions a generalized gsa method is proposed to assist the enkf in parameter correction problems in this paper by sampling in the input space and dynamically evaluating global parameter sensitivity we describe the model response of sensitivity varying parameters by the average and variation of their impact during the model process of interest we also obtain a quantitative relationship between the parameter ensemble evolution pattern and the relevant sensitivity index underlining the significance of identifying critical model features to ensure the enkf correction performance the factor identification correction methods are then employed to amend riverbed physical and geometrical characteristics in the simulation of a real world reservoir release case and the methods achieve decent results we present the following remarkable discoveries 1 in circumstances with a biased model initialization operation the enkf must be implemented after the model has warmed up i e when the effects of initialization error subside and a credible input output correlation has been established the appropriate length of the warmup period is decided by both the model s physical construction and the inputs 2 to evaluate the shifting model responses to multiple uncertain factors we analyze the src indices at each timestep to include both the interactions within the parameter space and the variation that stems from changing inputs the first and second order moments of the sampled indices are able to describe the overall effect and the fluctuation 3 we prove that the iss src analysis can predict the effect of the enkf correction process insensitive factors will not converge and thus can be removed from the correction procedure in addition the bias in one uncertain parameter will lead to misguided estimations for other related parameters because the accompanying error must be compensated such a preliminary investigation is particularly essential in high dimensional cases 4 with the support of the iss src analysis we manage to extract the dominant factors from the conceptualized section geometry in the hydrodynamic model we then revise these parameterizations using the enkf according to real world observations the consequent simulation performance based on corrected parameters is significantly enhanced although the advances in computational techniques have supported the progress of simulation capacity in terms of both fine geometrical resolution and substantial physical details utilizing a relatively simple model is still useful under specific circumstances as pointed out by loucks and van beek 2017 increasing model complexity may not only add to the cost of data collection but also introduce even more parameters and thus even more potential sources of error in the enkf scheme introducing unidentifiable parameters can lead to unsatisfying correction results in a more general sense it is crucial to investigate all possible influencing factors in the model before the optimization or calibration procedure and judge whether the specified simulation analysis scheme has covered the main features of the natural processes of interest the methods presented in this paper can be popularized to other data poor regions to avoid measurement difficulties without sacrificing simulation accuracy in further work parallel computing techniques could be applied in enkf practices to significantly improve calculation efficiency credit authorship contribution statement junyu wei conceptualization methodology software formal analysis investigation resources data curation writing original draft writing review editing visualization weihong liao resources writing review editing funding acquisition project administration zhao zhang methodology software conceptualization writing review editing xiaohui lei conceptualization supervision funding acquisition validation project administration jiabiao wang resources writing review editing hao wang supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper was jointly supported by the national key r d program of china 2017yfc0406004 the national natural science fund 51709273 and the key r d program of power construction corporation of china dj zdzx 2016 02 the reservoir release data water level gauge data and the topography data were provided by the yalong river hydropower development co ltd www ehdc com cn additional data and code may be obtained from the corresponding author appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125036 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
5324,the use of the walk on grid wog approach for the reliable evaluation of the green s function associated with groundwater flow scenarios in heterogeneous geologic media is explored the study rests on the observation that while the green s function method gfm is one of the most significant and convenient approaches to tackle groundwater flow green s function evaluation is fraught with remarkable difficulties in the presence of realistic groundwater settings taking place in complex heterogeneous geologic formations here wog approach is used to simulate pressure dissipation by lattice random walk and establish a quantitative relationship between space time distribution of random walkers and the green s function associated with the underlying flow problem wog based green s function method is tested a in three scenarios where analytical formulations are available for the green s function and b in two groundwater flow systems with increased level of complexity our results show that wog can a accurately evaluate the green s function being highly efficient when the latter can be analytically expressed in terms of infinite series and b accurately and efficiently evaluate temporal evolutions of hydraulic heads at target locations in the heterogeneous systems as such a wog based approach can be employed as an efficient surrogate model in scenarios involving groundwater flow in complex heterogeneous domains keywords heterogeneity lattice random walk feynman kac formula diffusion equation aquifer connectivity external forcing 1 introduction the green s function method gfm is a convenient and powerful approach to solve a variety of environmental and earth science problems its applications in the context of groundwater flow scenarios are wide and numerous including head calculation permeability scaling uncertainty quantification moment equation solving subsurface imaging superimposition in time domain etc see e g amongst others borcea et al 2002 dagan 1989 gomez torres verdin 2019 hristopulos christakos 1999 lembcke et al 2016 liu ball 1998 naff vecchia 1986 nan et al 2019 neuman orr 1993 olsthoorn 2008 park zhan 2001 sanskrityayn et al 2017 zhang 2001 a key strength of the approach is that the evaluation of the green s function for a given set of boundary types enables one to tackle a large variety of related flow scenarios subject to diverse strengths of the corresponding boundary terms and a potentially unlimited range of source terms a feature which is appealing in the context of water management practices evaluation of the green s function also yields insights about the relative strength of the possibly competing effects of diverse source terms on a target state variable throughout the system in many groundwater problems one is not interested in evaluating hydraulic heads everywhere in a subsurface formation and is otherwise focused on hydraulic heads at a few specified locations for engineering and or environmental studies for example hydraulic heads from some observation wells are used as constraints or references in contaminant source identification aquifer parameter estimation aquifer management see e g ayvaz karahan 2008 saffi cheddadi 2007 hou lu 2018 liang zhang 2012 mckinney lin 1994 liu et al 2015 for such cases solutions formulated in terms of green s function can constitute an efficient and convenient tool to evaluate hydraulic heads and their temporal series green s functions of analytical or semi analytical form are generally obtained through approaches based on a laplace transform b separation of variables c eigen function expansion or d the method of images cole et al 2011 and reference therein by searching green s function libraries e g cole 2019 one may find out whether a green s function solution is available for a type of problems however dealing with practical complex domain features such as e g irregular geometry and heterogeneity of system attributes can still constitute a formidable challenge to the best of our knowledge there is no green s function available to assist solving groundwater flow taking place in generally heterogeneous aquifers potentially characterized by boundaries of irregular shape scenarios linked to relative simple heterogeneity patterns e g stratified or block heterogeneous media consisting of non overlapping homogeneous regions can be tackled upon relying on a series of basis functions to yield an approximate expression of green s functions cole et al 2011 hahn özişik 2012 a key weakness of this approach is that ad hoc basis functions need to be constructed for each region forming the internal architecture of the zoned system the increased number of such basis functions can be a highly limiting factor in media of complex zonal heterogeneity in highly heterogeneous aquifers classic numerical approaches like finite difference or finite element methods can be used to solve problem dependent green s function equation eq 5 directly olsthoorn 2008 guadagnini neuman 1999 however the existence of dirac function greatly undermines the accuracy stability and convergence of numerical solutions of green s functions barajas solano tartakovsky 2013 chen et al 2007 often leading to failure of convergence during numerical calculation the main objective of this study is to present a general numerical approach which can resolve these difficulties stably and efficiently and then assess its potential through a collection of test problems backward random walk was applied to solve a diffusion type partial differential equation pde based on the feynman kac theorem maire nguyen 2016 nan wu 2018 nan et al 2019 some studies pointed out the relation between the green s function and the probability density of a walker that is absorbed at a domain boundary in homogenous media deaconu lejay 2006 hwang mascagni 2003 and references therein i e in a laplacian boundary value problem δ u x 2 f x on a domain ω where u x φ x on boundary ω if the corresponding green s function g s x s exists the probability density p ω x s at point x of a brownian particle starting from point s and being absorbed at point x on boundary ω is given by 1 p ω x s g s x s n x ω s ω where n is an outward unit vector normal to the domain boundary and the probability of finding the particle inside the domain p inside x s satisfies the diffusion equation and is proportional to green s function g s x s of the problem i e 2 p inside x s g s x s x s ω the solution to this problem is deaconu lejay 2006 3 u x 0 ω p inside x x 0 f x d x ω p ω x x 0 φ x d v where v is a spatial element which coincides with a length or an area for one and two dimensional boundaries in euclidean space respectively on boundary ω for a homogenous domain with a simple geometry such as rectangles spheres and or cylinders analytical forms of g s x s are readily available to derive p ω x s and p inside x s thus forming the basis for random walk simulation algorithms the latter include e g walk on spheres wos walk on rectangles wor and green s function first passage method gffp see e g muller 1956 deaconu lejay 2006 hwang et al 2001 hwang mascagni 2003 milstein tretyakov 1999 efforts have also been devoted to extend wos and gffp to stratified media e g lejay martinez 2006 lejay marie 2013 lejay pichot 2012 maire nguyen 2016 still these methods are mainly effective for media characterized by a relatively low number of zones layers that are otherwise demarcated by regular straight or circular internal boundaries thus being somewhat limited for routine applications to complex environmental scenarios lejay pichot 2016 expressing hydraulic heads in natural aquifers through a green s function approach entails eqs 1 and 2 to hold for general heterogeneity patterns while noting that p ω x s was analytically derived in a two phase material for a very simplified internal geometry sahimi 2003 torquato et al 1999 key questions that are not yet fully addressed and now being tackled in this study are of the kind do equations 1 and 2 hold in media where heterogeneity patterns are not limited to some simplifying assumptions and if so how can one evaluate g s x s and even transient g x t s τ effectively and accurately in this study the relation between green s function and walker density is extended to general heterogeneous media by leveraging on the work of nan and wu 2018 and relying on a grid based random walk i e the so called walk on grid wog to estimate p inside x s and g s x s in heterogeneous aquifers is computed by evaluating p inside x s via random walk simulations and provide test examples with increased degrees of complexity which start from simplified settings associated with analytical green s function formulations and then considering highly heterogeneous aquifers in the presence of generally transient flow the work is organized as follows the methodology and test cases are introduced in section 2 section 3 is devoted to validation of our wog based green s function method in five case tests wog based green s functions are firstly compared to their analytical counterparts in three simple scenarios and then applied to a estimate exchange rates between a one dimensional unconfined heterogeneous porous medium and a river and b calculate temporal variations of heads in a two dimensional heterogeneous aquifer efficiency of our approach is discussed at the end of section 3 and conclusions are drawn in section 4 2 methodology 2 1 governing equations of groundwater flow and green s function solution three dimensional transient groundwater flow in a fully saturated geologic medium can be described by the following equation 4 k x h w x t s s x t h x t x ω h x t h 0 x t 0 h x t φ x t x γ d k x h n b x h r x t x γ r where h x t l is hydraulic head x x y z t is spatial location vector within domain ω k x lt 1 is hydraulic conductivity and s s x l 1 is specific storage w x t t 1 is a source sink term γ d and γ r are dirichlet and robin boundaries respectively n is the outward normal to γ r whose direction depends on the shape of γ r by introducing a linear operator l s s x t k x the first in eq 4 is rewritten as l h x t w x t the corresponding green s function g l 2 associated with eq 4 satisfies the following auxiliary equation 5 l g x t s τ δ x s δ t τ x s ω t τ g x t s τ 0 t τ g x t s τ 0 x γ d k x g n b x g x t s τ 0 x γ r the solution to eq 4 can then be expressed as cole et al 2011 6a h x t h s h r h d h i where 6b h s 0 t ω g x t s τ w s τ d s d τ 6c h r 0 t γ r g x t s τ r s τ d v d τ 6d h d 0 t γ d k φ s τ n g x t s τ d v d τ 6e h i ω g x t s 0 h 0 s s s d s here h s h r h d and h i l in equations 6b 6e represent the contributions to h x t due to source sink term robin boundary dirichlet boundary and the initial condition respectively note that robin boundary includes neumann boundary as a special case i e when b x 0 in two and one dimensional problems the dimensions of green s functions are l 1 and and the framework above still works 2 2 relation between expected passage frequency and green s function following the feynman kac theorem see e g nan wu 2018 lejay marie 2013 hydraulic head at a point x ω can be expressed as 7a h x t f s f r f d f i where 7b f s 0 t e t w z τ τ s s d τ z t x 7c f r 0 t e t r z τ τ d τ z t x 7d f d φ z e t e 1 t e 0 z t x 7e f i h 0 z e 1 t e 0 z t x where z t l is an itô process described as 8 d z t k x s s x d t 2 k x s s x d w t here w t t1 2 is a wiener process exit time t e is the time at which z t arrives at boundary for the first time 0 t e max 0 t e z t x represents expectation with respect to random z t conditional to z being at location x at time t 1 t e 0 1 if t e 0 and 0 otherwise similar for 1 t e 0 the terms f s f r f d and f i l in eq 7 represent the impact of sources sinks robin boundary dirichlet boundary and initial conditions respectively noting that eq 7a is virtually identical to eq 6a it follows that f s h s f r h r f d h d and f i h i in view of such equivalence one may choose to evaluate the easier one in eqs 6 and 7 when the green s function is easier to obtain eq 7 can be directly evaluated through green s function formulation 6 for example f s in 7b can be rendered using green s function by 9 f s ω 0 t w s τ g x t s τ d τ d v conversely if direct evaluation of green s function is difficult such as in irregular domains of general heterogeneity evaluation of eq 7 is recommended which requires a numerical approximation of the stochastic path integral in this context one may take z t in eq 7 as e g a simple lattice random walk denoted as z t in fig 1 where the walker can jump solely to neighboring sites which coincide with centers of cells in fig 1 an approximation of the path integral is then evaluated along the lattice random path see e g klebaner 2005 note that the lattice random walk z t in fig 1 is an approximation of the actual random walk z t for ease of notation the lattice random walk is hereafter termed as z t for a realization of the lattice random walk passing through location x at time t one has t δ t t w z τ τ s s d τ w x t δ v x c x t where δ v x is the volume of the cell at x c x t s s δ v δ t i 1 n c i c i being hydraulic conductance between the current cell and a neighboring cell defined later see c x in section 2 3 quantity c x t can be treated as a coefficient governing head variations under unit source impulse increasing the value of c yields enhanced dampening of head variations induced by water injection the approximation above leads to the lagrangian formulation 10 0 t e t w z τ τ s s d τ j 1 n s w z t j t j δ v z t j c z t j t j where n s is the number of time steps of the lattice random walk note that c x t is time invariant i e c x t c x if the time interval δ t is uniform eq 10 can be recast into its corresponding eulerian form 11 0 t e t w z τ τ s s d τ m 1 n t k 1 n ω i k m ω w x k t m δ v x k c x k where n ω is the total number of cells in the computational grid n t is the total number of time steps in 0 t ω is the index identifying a random walk realization the random passage frequency i k m ω is either zero or a positive integer and corresponds to the number of times the random walk realization of index ω passes through the cell of x k during the time window t m 1 t m hence one has 12 f s 0 t e t w z τ τ s s d τ z t x 1 n mc ω 1 n mc m 1 n t k 1 n ω i k m ω w x k t m δ v x k c x k m 1 n t k 1 n ω i k m w x k t m δ v x k c x k where the expected passage frequency 13 i k m 1 n mc ω 1 n mc i k m ω represents the number of times on average the random walk passes the cell of x k during time window t m 1 t m on the other hand according to eq 6b one has 14 h s m 1 n t k 1 n ω w x k t m g x t x k t m δ t δ v by recalling that f s h s and comparing eqs 12 and 14 one has 15 g x t x k t m 1 c x k δ t i k m according to cole et al 2011 eq 3 89 with α 1 green s functions for transient and steady state scenarios are related as g s x s lim t 0 t g x t s τ d τ the subscript s stands for steady state thus the green s function associated with the steady state flow formulation is 16 g s x x k 1 c x k m 1 i k m 2 3 numerical evaluation of green s functions via wog according to eq 7 lattice random walk realizations have to be simulated on condition that z passes through location x at time t conditional simulation of z realizations can be circumvented by simulating z realizations backwards as suggested by nan and wu 2018 in this sense random walk realizations start at x t trace backwards in time and stop at t e 0 on boundary or until t 0 taking a three dimensional heterogeneous aquifer as an example simulation of a wog realization based on equation 4 can be performed according to the following workflow 1 discretize the domain into a lattice whose nodes are centers of cells associated with a system of orthogonal coordinates x y z 2 let p x p x p y p y p z and p z be the probabilities that the walker jumps from cell i j k to cells i 1 j k i 1 j k i j 1 k i j 1 k i j k 1 i j k 1 respectively and p t be the probability that the walker stays at i j k in time window t m 1 t m calculate the jump probabilities as follows 17 p x c x c s 18 p t c t c s 19 c t δ v i j k s s δ t m 20 c s c x c x c y c y c z c z c t c x is the inter cell conductance between cells i j k and i 1 j k defined as c x k i 1 i δ a i 1 i x i j k x i 1 j k in mcdonald and harbaugh 1988 where k i 1 i δ a i 1 i and x i j k x i 1 j k is the effective hydraulic conductivity interface area and distance between cells i j k and i 1 j k respectively similarly c x c y c y c z c z represent inter cell conductance along the remaining 5 directions of a three dimensional system p x p y p y p z and p z can be defined similar to eq 17 c t represents the storage induced inertia which dampens head change in the cell δ v i j k is the volume of cell i j k 3 starting from a specific space time point x t randomly displace a walker to a neighboring cell according to values of local p x p x p y p y p z p z and p t the walker is then continuously displaced until it reaches the system boundaries or t 0 4 simulate a large number of random walkers to estimate expected passage frequency according to eq 13 at each cell and time step 5 evaluate green s function g according to eqs 15 or 16 note that in steady state problems no initial condition exists p t 0 and all random walkers will be terminated on boundary 2 4 five test cases to verify wog based green s functions five test problems of groundwater flow are introduced in the first three problems the analytical green s function can be found and used as references to validate wog based green s functions directly the other two problems involve pointwise heterogeneity in hydraulic parameters and no analytical green s function are available thus wog based green s functions are verified through their resulting hydraulic heads which are compared to numerical solutions of head calculated by the widely used modflow 2000 harbaugh et al 2000 2 4 1 test case 1 fig 2 presents a one dimensional homogeneous unconfined aquifer neumann and robin boundaries are imposed at the left and right ends respectively transient groundwater flow in the aquifer shown in fig 2 is described by 21 k x h h x w u x t μ h t h x 0 x 0 k h h x k b 2 l b h l t h b t h l t h b t x l h x t h 0 x t 0 assume that variations of h are small compared to average thickness of the aquifer eq 21 can be linearized and analytically solved by green s function more details can be found in appendix a 2 4 2 test case 2 consider two dimensional transient flow in a homogeneous confined aquifer of size l x l y 1440 m 800 m transmissivity t 0 5 m2 d and storativity s 10 4 dirichlet boundaries are imposed at x 0 and x 1440 m neumann boundaries are set at y 0 and y 800 m analytical expressions of the green s function are provided by cole et al 2011 their eqs x11 2 and x22 3 2 4 3 test case 3 solving for green s function analytically in the presence of a large number of interfaces zones and in higher dimensions with complex boundary conditions is problem specified and typically challenging especially in transient cases for the sake of simplicity consider a boundary value problem in a one dimensional aquifer in which k may be homogeneous or block heterogeneous the analytical green s function g s x s corresponding to the homogeneous setting is after cole et al 2011 table x 3 22 g s x s 1 x l s k s x 1 s l x k x s in the presence of multiple conductivity zones g s x s has to meet interface conditions 23 k s g s x s s k s g s x s s g s x s s g s x s s which are rooted in continuities of flux and hydraulic head respectively expressions of g s x s for two zone and three zone cases are shown in section 3 below 2 4 4 test case 4 test case 4 is a heterogeneous version of test case 1 in which hydraulic conductivity k and specific yield μ are point wise heterogeneous fig 3 a b such a model is similar to the one liang and zhang 2013 tried to handle through analytical formulation but much more general the natural logarithm of k is characterized by a mean value of 0 2 variance of 0 9 and an exponential variogram of integral scale of 25 m the spatial distribution of lnk is simulated by a sequential gaussian simulator deutsch journel 1998 k and μ are treated to be correlated according to μ 0 3 0 04 ln k ξ where ξ is a random variable following a standard normal distribution and correlation between lnk and μ is 0 7 daily series of precipitation events r t and river stage h b t are synthetically generated to reflect common hydrologic features and are depicted in fig 3 c d the recharge coefficient varies linearly between 0 7 0 9 from x 0 to x l so that effective recharge to the aquifer varies spatially and temporally to calculate the flow rate per unit width from the river to the aquifer as q t 1 2 k b h l t h b t h l t h b t l b head on the right end h x l t is calculated by both modflow 2000 and wog in both methods time step length δ t 0 1 d and discretization length δ x 0 5 m are used 2 4 5 test case 5 test case 5 considers a horizontal two dimensional unconfined aquifer of non uniform hydraulic conductivity k and specific yield μ fields of lnk with mean equal to 0 2 and variance 0 8 and μ with mean of 0 3 and variance 0 001 are independently obtained by sequential gaussian simulation deutsch journel 1998 using an exponential variogram of integral scale equal to 500 m fig 4 depicts the conceptual model of the system and maps of the spatial distribution of lnk and μ there exists an active well with pumping rate q t l3t 1 and a spatially uniform but temporally varying areal recharge p t lt 1 the former is located at the center of the domain i e at x w y w 500 m 400 m and is operated according to a prescribed time schedule fig 5 two observation boreholes are set at x 1 y 1 450 m 400 m and x 2 y 2 550 m 400 m the east boundary is a prescribed head boundary with head equal to φ y t the remaining boundaries being impervious even as both wog and modflow allow considering any functional form for φ y t we set φ y t 50 m for simplicity the initial head h 0 x y 50 m and the study period is of 20 d groundwater flow is governed by 24 x kh h x y kh h y w u x y t μ h t h x 0 x 0 h y 0 y 0 or l y h x y t φ y t x l x h x y t h 0 x y t 0 here l x 1000 m l y 800 m and the total thickness is h 50 m w u x y t p t q t δ x w y w case 5 can be numerically solved by modflow 2000 or wog based green s function method below similar to linearization technique illustrated in appendix a eq 24 can be rewritten as 25 x k u x y k u y 2 w u x y t s e u t u x 0 x 0 u y 0 y 0 or l y u x y t φ 2 y t x l x u x y t h 0 2 x y t 0 wog based solution to eq 25 is 26a u x y t u i u d u s where 26b u i 0 l x d x 0 l y h 0 2 x y s e x y g x y t x y τ 0 d y 26c u d 0 t d τ 0 l y k φ 2 y τ x g x y t x l x y τ d y 26d u s 0 t d τ 0 l x d x 0 l y 2 w u x y τ g x y t x y τ d y represent the contributions to u or equivalently h x y t of initial condition dirichlet boundary and source sink terms respectively recalling that w u x y t p t q t δ x w y w then u s 0 t 2 p τ ρ p x y t τ d τ 0 t 2 q τ ρ q x y t x w y w τ d τ here 27 ρ p x y t τ 0 l x d x 0 l y g x y t x y τ d y quantifies the influence to u x y t of areal recharge at time τ and 28 ρ q x y t x w y w τ g x y t x w y w τ provides an indication of the influence to u x y t of pumping at time τ at location x w y w if φ y t φ t i e independent of location then u d 0 t φ 2 τ ρ d x y t τ d τ where 29 ρ d x y t τ 0 l y k x g x y t x l x y τ d y in other words ρ q ρ p and ρ d can be considered as the weights of source and boundary histories to impact u x y t once g x y t x y τ is evaluated by wog method ρ q ρ p and ρ d can be found afterwards h x y t can be calculated and compared to modflow simulation table 1 summarizes the dimensions of quantities mentioned in this study which may help validate the correctness of analyses in this study 3 results and discussion 3 1 test case 1 wog based green s function for case 1 and its analytical counterpart are evaluated for a setting corresponding to l 100 m k 1 m d μ 0 3 h 30 m s e 0 01 m 1 k b 0 1 m d l b 0 1 m and a 10 days temporal window wog based green s function uses a uniform domain discretization length δ x 0 5 m and time step length δ t 0 05 d the number of random walk realizations is n mc 106 on the other hand one hundred terms are included in the evaluation of the analytical expression eq a3 fig 6 depicts results obtained at 4 illustrative locations x 25 m 50 m 75 m and 100 m across the temporal range 0 t 10 d while the wog based results display some oscillations at low values they virtually coincide with the analytical solution according to eq 15 the observed numerical errors are related to the precision of i i e 1 n mc and are noticeable only when i is comparable to 1 n mc on these bases one can note that the smallest non zero value that can be represented by eq 15 in this example is g 4 9 10 6 i e ln g 12 2 which provides sufficient precision for our purpose the location corresponding to this value corresponds to the right end in fig 5 d i e the robin boundary this result is consistent with a dampening impact of this boundary type note that the green s function at x 100 m will always vanish when k b l b in conformity with the fact that the robin boundary tends to a dirichlet boundary for k b l b thus wog based green s function matches its analytical counterpart with good accuracy 3 2 test case 2 a uniform spatial discretization δ x δ y 20 m and time step δ t 0 1 d across a 10 days temporal window are used in wog method an example of the comparison between the green s function results obtained through analytical and wog methods is depicted in fig 7 denoting a good agreement between them even in the presence of some numerical errors at low values results of the same quality are obtained at other locations and observation times not shown for brevity it suggests that wog based green s function is reliable 3 3 test case 3 by taking into account all interface conditions mathematical expressions of green s functions g s x s in case 3 for x 0 15 l 0 25 l and 0 35 l are found and plotted in fig 8 by red dashed lines corresponding wog based g s x s obtained with a uniform domain discretization δx l 10 3 are also depicted by black lines it is seen that wog based green s function matches analytical counterparts very well thus supporting the validity of eq 16 in both homogeneous and heterogeneous media 3 4 test case 4 fig 9 a b reports head and flow rate at right end h x l t and q t computed through modflow and wog based green s function these results are complemented by fig 9 c which depicts the relative differences between h x l t evaluated by wog and modflow it is seen that differences in h x l t from two methods are very limited results of q t are also very close thus green s function evaluated by wog approach is able to yield accurate solutions to groundwater flow in heterogeneous aquifers and the effectiveness of wog based green s function method is further validated 3 5 test case 5 in both modflow and wog based green s function methods δ x δ y 10 m and time step δ t 0 1 d fig 10 a depicts the wog based green s function g x w y w t x y τ at the pumping well until t 20 d fig 10 b d depicts spatial contours of g x w y w t x y τ for τ 20 d τ 10 d and τ 0 d when t 20 d fig 11 depicts the evolution of ρ q x y t x w y w τ ρ p x y t τ and ρ d x y t τ across 0 τ t for t 20 d at the pumping and observation wells fig 4 values of ρ q at the pumping well are consistently largest it is in agreement on the fact that pumping at x w y w naturally affects heads at x w y w stronger than at other locations it is also found that ρ q at observation well 2 is close to but greater than its counterpart evaluated at observation well 1 implying an stronger hydraulic connection between the pumping well and well 2 due to heterogeneity according to ρ d the impact of dirichlet boundary is remarkable at observation well 2 but almost negligible at observation well 1 since ρ q ρ p and ρ d embed point to point hydraulic connections in a quantitative manner a further evolution of the study could be the analysis of the possibility to enhance our understanding about aquifer connectivity upon relying on metrics derived from a green s function approach head variation δ h x y t h x y t h 0 x y evaluated at the two observation wells and at the pumping well are denoted as δ h 1 δ h 2 and δ h w respectively δ h 1 δ h 2 and δ h w calculated through modflow and wog are compared in fig 12 a c fig 12 d depicts the relative differences between heads obtained by the two methods at the three target locations these results clearly demonstrate the accuracy of the wog based green s function method its computational costs are discussed in section 3 6 where it is shown that wog based green s function is very efficient when there is the need to assess the action of various combinations of φ y t h 0 x y q t and p t once the green s function is found by wog 3 6 advantages of wog based green s function method two of several major advantages wog based green s function approach bears are computational stability and efficiency as mentioned in the introduction irregularity produced by dirac function in green s function pde equation 5 often leads to difficulty in convergence and errors which is further exacerbated by discontinuous coefficients e g hydraulic conductivities in the pde barajas solano tartakovsky 2013 repeating failures of convergences have been observed while attempting to solve eq 5 directly by modflow that s the reason why we don t compare green s function from wog to that from modflow in test case 4 and case 5 in contrast wog based method seems work stably in all cases in our investigation here the second advantage is computational efficiency of this approach it is mainly attributed to a parallelizability in simulating random walks and b framework of green s function method which allows efficient recalculations for various combinations of boundary conditions and forcing terms table 2 lists details of time costs in all of the computational studies illustrated above for the sake of accuracy one hundred terms are included in the evaluation of analytical expression of the green s function in test case 1 a choice that yields computationally intensive evaluations one can note that in this case the wog based green s function evaluation is more efficient than its analytical counterpart otherwise analytical expressions associated with test case 2 and case 3 are in closed form and very efficient in test case 4 and case 5 the wog based approach first evaluates numerically green s functions and then calculate hydraulic heads based on these green s functions the most computational cost is spent in the first step i e green s function evaluation and the second step is very fast about 10 2 s or less furthermore the computational cost in the first step can be remarkably reduced through parallelization and more efficient than using modflow on the other hand modflow directly solves for heads at each time step while this computational suite is typically considered as an efficient tool when compared to other groundwater solvers one can see that it is still not fast enough in many scenario simulations which may require calling solver routines a large number of times for example addressing data assimilation uncertainty analysis and or source identification problems see e g ayvaz karahan 2008 nan wu 2011 wu zeng 2013 yeh 2015 in the presence of uncertain forcing terms and or boundary conditions often requires relying on a high number of direct solutions of the flow scenarios as such surrogate models are developed to speed up the solution often at the cost of a decreased accuracy see e g asher et al 2015 and references therein when considering a wog based green s function approach performing multiple calls to scenario simulation the second step above is only a marginal issue because the first step i e green s function evaluation needs to be implemented only once and the computational cost of the second step is negligible therefore our results evidence the potential benefit in terms of computational cost of relying on a wog based green s function approach when there is the need for a high number of repeated solutions of the groundwater flow problem as driven by uncertain forcing and or boundary terms 4 conclusions this study leads to the following major conclusions 1 the relation between green s functions and random walk is extended to heterogeneous aquifers upon deriving a quantitative relationship between green s function and expected passage frequency of random walk this enables one to numerically evaluate green s functions of groundwater flow problems in aquifer systems of complex geometries and spatial heterogeneity patterns this new method rests on the walk on grid wog approach and its capabilities are illustrated through a suite of five test scenarios involving steady state and transient flow various boundary conditions the action of spatially and or temporally varying source terms of various nature as well as diverse spatial distributions of system attributes e g hydraulic conductivity and storativity 2 numerical green s functions calculated by wog are compared against exact analytical solutions under a variety of settings results figs 6 8 show that the wog based green s functions are virtually indistinguishable from their analytical counterparts an exception being given by values that are too low to be properly captured by expected passage frequency of random walk numerical errors in the wog based evaluation of green s functions are controlled by the precision associated with the calculated expected passage frequency i which in turn depends on the number of random walk realizations i e n mc one million realizations are used in all of our examples which is shown to be sufficient to capture the main information in green s functions 3 the findings corresponding to settings of increased level of complexity where analytical solutions are not available reveal that relative differences between heads calculated via our wog based approach and their counterparts based on numerical solution of the widely tested computational suite modflow are very small i e 0 02 in fig 9 c and 0 09 in fig 12 d these results strengthen our confidence on the accuracy of wog based green s functions for groundwater flow scenarios 4 as compared against available analytical formulations the wog approach may be computationally more efficient in the evaluation of green s functions when the former are expressed in terms of infinite series 5 the wog based green s function method avoids limitations of applicability to complex media which are typical of traditional approaches to the numerical evaluation of green s functions i e it can efficiently handle various combinations of boundary conditions and forcing and is applicable to aquifers of general heterogeneous structure with excellent accuracy 6 while wog based green s function method appears to be more computationally demanding than modflow it is recalled that evaluation of heads is associated with negligible computational time once the green s function is calculated thus in terms of computational cost the potential benefit of relying on a wog based green s function method tends to increase when one has to perform a high number of repeated solutions of the groundwater flow problem as driven by uncertain forcing and or boundary terms potential application examples in this context which one could consider on future studies include the assessment of the evolution of groundwater resources as driven by various climatic scenarios or the quantification of the sustainability of multiple extraction scenarios in a given aquifer system 7 finally this study allows discriminating clearly the contributions to head distributions due to boundary and source terms on these bases our results form the basis upon which one can build future studies to analyze the concept of aquifer connectivity through metrics derived from a green s function method declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by the national natural science foundation of china grant nos 41730856 41972245 41602250 china postdoctoral science foundation grant no 2017m611782 and the fundamental research funds for the central universities grant nos 0206 14380032 and 0206 14380091 part of the work was developed while prof a guadagnini was at the university of strasbourg with funding from région grand est and strasbourg eurométropole through the chair gutenberg we declare that we have no conflict of interest data included in this study can be downloaded at https www researchgate net profile tongchao nan publications appendix a we assume that the total saturated thickness is much larger than the amplitude of spatiotemporal variations of head setting h 2 u and s e μ h where h is the spatially averaged saturated thickness whose temporal variation we take as much smaller than h eq 23 can be linearized as a1 2 u x 2 2 w u x t k s e k u t u x 0 x 0 k u x k b l b u x t k b l b h b 2 t x l u x t h 0 2 x t 0 boundary conditions can be recast as α i u x x x i β i u x i t γ i t with x 1 0 α 1 1 β 1 0 γ 1 0 x 2 l α 2 k β 2 k b l b γ 2 k b l b h b 2 t the solution of eq a1 can be expressed as a2 u x t 0 l h 0 2 s g x t s τ 0 s e d s 2 0 t d τ 0 l w u s τ g x t s τ d s 0 t d τ i 1 2 γ i τ α i g x t s x i τ where a3 g x t s τ 2 s e l m 1 exp λ m 2 k t τ s e l 2 λ m 2 d 2 λ m 2 d 2 d cos λ m x l cos λ m s l λ m being the m th root of λ m tan λ m d with d 2 β 2 l k 2 k b l l b k 
5324,the use of the walk on grid wog approach for the reliable evaluation of the green s function associated with groundwater flow scenarios in heterogeneous geologic media is explored the study rests on the observation that while the green s function method gfm is one of the most significant and convenient approaches to tackle groundwater flow green s function evaluation is fraught with remarkable difficulties in the presence of realistic groundwater settings taking place in complex heterogeneous geologic formations here wog approach is used to simulate pressure dissipation by lattice random walk and establish a quantitative relationship between space time distribution of random walkers and the green s function associated with the underlying flow problem wog based green s function method is tested a in three scenarios where analytical formulations are available for the green s function and b in two groundwater flow systems with increased level of complexity our results show that wog can a accurately evaluate the green s function being highly efficient when the latter can be analytically expressed in terms of infinite series and b accurately and efficiently evaluate temporal evolutions of hydraulic heads at target locations in the heterogeneous systems as such a wog based approach can be employed as an efficient surrogate model in scenarios involving groundwater flow in complex heterogeneous domains keywords heterogeneity lattice random walk feynman kac formula diffusion equation aquifer connectivity external forcing 1 introduction the green s function method gfm is a convenient and powerful approach to solve a variety of environmental and earth science problems its applications in the context of groundwater flow scenarios are wide and numerous including head calculation permeability scaling uncertainty quantification moment equation solving subsurface imaging superimposition in time domain etc see e g amongst others borcea et al 2002 dagan 1989 gomez torres verdin 2019 hristopulos christakos 1999 lembcke et al 2016 liu ball 1998 naff vecchia 1986 nan et al 2019 neuman orr 1993 olsthoorn 2008 park zhan 2001 sanskrityayn et al 2017 zhang 2001 a key strength of the approach is that the evaluation of the green s function for a given set of boundary types enables one to tackle a large variety of related flow scenarios subject to diverse strengths of the corresponding boundary terms and a potentially unlimited range of source terms a feature which is appealing in the context of water management practices evaluation of the green s function also yields insights about the relative strength of the possibly competing effects of diverse source terms on a target state variable throughout the system in many groundwater problems one is not interested in evaluating hydraulic heads everywhere in a subsurface formation and is otherwise focused on hydraulic heads at a few specified locations for engineering and or environmental studies for example hydraulic heads from some observation wells are used as constraints or references in contaminant source identification aquifer parameter estimation aquifer management see e g ayvaz karahan 2008 saffi cheddadi 2007 hou lu 2018 liang zhang 2012 mckinney lin 1994 liu et al 2015 for such cases solutions formulated in terms of green s function can constitute an efficient and convenient tool to evaluate hydraulic heads and their temporal series green s functions of analytical or semi analytical form are generally obtained through approaches based on a laplace transform b separation of variables c eigen function expansion or d the method of images cole et al 2011 and reference therein by searching green s function libraries e g cole 2019 one may find out whether a green s function solution is available for a type of problems however dealing with practical complex domain features such as e g irregular geometry and heterogeneity of system attributes can still constitute a formidable challenge to the best of our knowledge there is no green s function available to assist solving groundwater flow taking place in generally heterogeneous aquifers potentially characterized by boundaries of irregular shape scenarios linked to relative simple heterogeneity patterns e g stratified or block heterogeneous media consisting of non overlapping homogeneous regions can be tackled upon relying on a series of basis functions to yield an approximate expression of green s functions cole et al 2011 hahn özişik 2012 a key weakness of this approach is that ad hoc basis functions need to be constructed for each region forming the internal architecture of the zoned system the increased number of such basis functions can be a highly limiting factor in media of complex zonal heterogeneity in highly heterogeneous aquifers classic numerical approaches like finite difference or finite element methods can be used to solve problem dependent green s function equation eq 5 directly olsthoorn 2008 guadagnini neuman 1999 however the existence of dirac function greatly undermines the accuracy stability and convergence of numerical solutions of green s functions barajas solano tartakovsky 2013 chen et al 2007 often leading to failure of convergence during numerical calculation the main objective of this study is to present a general numerical approach which can resolve these difficulties stably and efficiently and then assess its potential through a collection of test problems backward random walk was applied to solve a diffusion type partial differential equation pde based on the feynman kac theorem maire nguyen 2016 nan wu 2018 nan et al 2019 some studies pointed out the relation between the green s function and the probability density of a walker that is absorbed at a domain boundary in homogenous media deaconu lejay 2006 hwang mascagni 2003 and references therein i e in a laplacian boundary value problem δ u x 2 f x on a domain ω where u x φ x on boundary ω if the corresponding green s function g s x s exists the probability density p ω x s at point x of a brownian particle starting from point s and being absorbed at point x on boundary ω is given by 1 p ω x s g s x s n x ω s ω where n is an outward unit vector normal to the domain boundary and the probability of finding the particle inside the domain p inside x s satisfies the diffusion equation and is proportional to green s function g s x s of the problem i e 2 p inside x s g s x s x s ω the solution to this problem is deaconu lejay 2006 3 u x 0 ω p inside x x 0 f x d x ω p ω x x 0 φ x d v where v is a spatial element which coincides with a length or an area for one and two dimensional boundaries in euclidean space respectively on boundary ω for a homogenous domain with a simple geometry such as rectangles spheres and or cylinders analytical forms of g s x s are readily available to derive p ω x s and p inside x s thus forming the basis for random walk simulation algorithms the latter include e g walk on spheres wos walk on rectangles wor and green s function first passage method gffp see e g muller 1956 deaconu lejay 2006 hwang et al 2001 hwang mascagni 2003 milstein tretyakov 1999 efforts have also been devoted to extend wos and gffp to stratified media e g lejay martinez 2006 lejay marie 2013 lejay pichot 2012 maire nguyen 2016 still these methods are mainly effective for media characterized by a relatively low number of zones layers that are otherwise demarcated by regular straight or circular internal boundaries thus being somewhat limited for routine applications to complex environmental scenarios lejay pichot 2016 expressing hydraulic heads in natural aquifers through a green s function approach entails eqs 1 and 2 to hold for general heterogeneity patterns while noting that p ω x s was analytically derived in a two phase material for a very simplified internal geometry sahimi 2003 torquato et al 1999 key questions that are not yet fully addressed and now being tackled in this study are of the kind do equations 1 and 2 hold in media where heterogeneity patterns are not limited to some simplifying assumptions and if so how can one evaluate g s x s and even transient g x t s τ effectively and accurately in this study the relation between green s function and walker density is extended to general heterogeneous media by leveraging on the work of nan and wu 2018 and relying on a grid based random walk i e the so called walk on grid wog to estimate p inside x s and g s x s in heterogeneous aquifers is computed by evaluating p inside x s via random walk simulations and provide test examples with increased degrees of complexity which start from simplified settings associated with analytical green s function formulations and then considering highly heterogeneous aquifers in the presence of generally transient flow the work is organized as follows the methodology and test cases are introduced in section 2 section 3 is devoted to validation of our wog based green s function method in five case tests wog based green s functions are firstly compared to their analytical counterparts in three simple scenarios and then applied to a estimate exchange rates between a one dimensional unconfined heterogeneous porous medium and a river and b calculate temporal variations of heads in a two dimensional heterogeneous aquifer efficiency of our approach is discussed at the end of section 3 and conclusions are drawn in section 4 2 methodology 2 1 governing equations of groundwater flow and green s function solution three dimensional transient groundwater flow in a fully saturated geologic medium can be described by the following equation 4 k x h w x t s s x t h x t x ω h x t h 0 x t 0 h x t φ x t x γ d k x h n b x h r x t x γ r where h x t l is hydraulic head x x y z t is spatial location vector within domain ω k x lt 1 is hydraulic conductivity and s s x l 1 is specific storage w x t t 1 is a source sink term γ d and γ r are dirichlet and robin boundaries respectively n is the outward normal to γ r whose direction depends on the shape of γ r by introducing a linear operator l s s x t k x the first in eq 4 is rewritten as l h x t w x t the corresponding green s function g l 2 associated with eq 4 satisfies the following auxiliary equation 5 l g x t s τ δ x s δ t τ x s ω t τ g x t s τ 0 t τ g x t s τ 0 x γ d k x g n b x g x t s τ 0 x γ r the solution to eq 4 can then be expressed as cole et al 2011 6a h x t h s h r h d h i where 6b h s 0 t ω g x t s τ w s τ d s d τ 6c h r 0 t γ r g x t s τ r s τ d v d τ 6d h d 0 t γ d k φ s τ n g x t s τ d v d τ 6e h i ω g x t s 0 h 0 s s s d s here h s h r h d and h i l in equations 6b 6e represent the contributions to h x t due to source sink term robin boundary dirichlet boundary and the initial condition respectively note that robin boundary includes neumann boundary as a special case i e when b x 0 in two and one dimensional problems the dimensions of green s functions are l 1 and and the framework above still works 2 2 relation between expected passage frequency and green s function following the feynman kac theorem see e g nan wu 2018 lejay marie 2013 hydraulic head at a point x ω can be expressed as 7a h x t f s f r f d f i where 7b f s 0 t e t w z τ τ s s d τ z t x 7c f r 0 t e t r z τ τ d τ z t x 7d f d φ z e t e 1 t e 0 z t x 7e f i h 0 z e 1 t e 0 z t x where z t l is an itô process described as 8 d z t k x s s x d t 2 k x s s x d w t here w t t1 2 is a wiener process exit time t e is the time at which z t arrives at boundary for the first time 0 t e max 0 t e z t x represents expectation with respect to random z t conditional to z being at location x at time t 1 t e 0 1 if t e 0 and 0 otherwise similar for 1 t e 0 the terms f s f r f d and f i l in eq 7 represent the impact of sources sinks robin boundary dirichlet boundary and initial conditions respectively noting that eq 7a is virtually identical to eq 6a it follows that f s h s f r h r f d h d and f i h i in view of such equivalence one may choose to evaluate the easier one in eqs 6 and 7 when the green s function is easier to obtain eq 7 can be directly evaluated through green s function formulation 6 for example f s in 7b can be rendered using green s function by 9 f s ω 0 t w s τ g x t s τ d τ d v conversely if direct evaluation of green s function is difficult such as in irregular domains of general heterogeneity evaluation of eq 7 is recommended which requires a numerical approximation of the stochastic path integral in this context one may take z t in eq 7 as e g a simple lattice random walk denoted as z t in fig 1 where the walker can jump solely to neighboring sites which coincide with centers of cells in fig 1 an approximation of the path integral is then evaluated along the lattice random path see e g klebaner 2005 note that the lattice random walk z t in fig 1 is an approximation of the actual random walk z t for ease of notation the lattice random walk is hereafter termed as z t for a realization of the lattice random walk passing through location x at time t one has t δ t t w z τ τ s s d τ w x t δ v x c x t where δ v x is the volume of the cell at x c x t s s δ v δ t i 1 n c i c i being hydraulic conductance between the current cell and a neighboring cell defined later see c x in section 2 3 quantity c x t can be treated as a coefficient governing head variations under unit source impulse increasing the value of c yields enhanced dampening of head variations induced by water injection the approximation above leads to the lagrangian formulation 10 0 t e t w z τ τ s s d τ j 1 n s w z t j t j δ v z t j c z t j t j where n s is the number of time steps of the lattice random walk note that c x t is time invariant i e c x t c x if the time interval δ t is uniform eq 10 can be recast into its corresponding eulerian form 11 0 t e t w z τ τ s s d τ m 1 n t k 1 n ω i k m ω w x k t m δ v x k c x k where n ω is the total number of cells in the computational grid n t is the total number of time steps in 0 t ω is the index identifying a random walk realization the random passage frequency i k m ω is either zero or a positive integer and corresponds to the number of times the random walk realization of index ω passes through the cell of x k during the time window t m 1 t m hence one has 12 f s 0 t e t w z τ τ s s d τ z t x 1 n mc ω 1 n mc m 1 n t k 1 n ω i k m ω w x k t m δ v x k c x k m 1 n t k 1 n ω i k m w x k t m δ v x k c x k where the expected passage frequency 13 i k m 1 n mc ω 1 n mc i k m ω represents the number of times on average the random walk passes the cell of x k during time window t m 1 t m on the other hand according to eq 6b one has 14 h s m 1 n t k 1 n ω w x k t m g x t x k t m δ t δ v by recalling that f s h s and comparing eqs 12 and 14 one has 15 g x t x k t m 1 c x k δ t i k m according to cole et al 2011 eq 3 89 with α 1 green s functions for transient and steady state scenarios are related as g s x s lim t 0 t g x t s τ d τ the subscript s stands for steady state thus the green s function associated with the steady state flow formulation is 16 g s x x k 1 c x k m 1 i k m 2 3 numerical evaluation of green s functions via wog according to eq 7 lattice random walk realizations have to be simulated on condition that z passes through location x at time t conditional simulation of z realizations can be circumvented by simulating z realizations backwards as suggested by nan and wu 2018 in this sense random walk realizations start at x t trace backwards in time and stop at t e 0 on boundary or until t 0 taking a three dimensional heterogeneous aquifer as an example simulation of a wog realization based on equation 4 can be performed according to the following workflow 1 discretize the domain into a lattice whose nodes are centers of cells associated with a system of orthogonal coordinates x y z 2 let p x p x p y p y p z and p z be the probabilities that the walker jumps from cell i j k to cells i 1 j k i 1 j k i j 1 k i j 1 k i j k 1 i j k 1 respectively and p t be the probability that the walker stays at i j k in time window t m 1 t m calculate the jump probabilities as follows 17 p x c x c s 18 p t c t c s 19 c t δ v i j k s s δ t m 20 c s c x c x c y c y c z c z c t c x is the inter cell conductance between cells i j k and i 1 j k defined as c x k i 1 i δ a i 1 i x i j k x i 1 j k in mcdonald and harbaugh 1988 where k i 1 i δ a i 1 i and x i j k x i 1 j k is the effective hydraulic conductivity interface area and distance between cells i j k and i 1 j k respectively similarly c x c y c y c z c z represent inter cell conductance along the remaining 5 directions of a three dimensional system p x p y p y p z and p z can be defined similar to eq 17 c t represents the storage induced inertia which dampens head change in the cell δ v i j k is the volume of cell i j k 3 starting from a specific space time point x t randomly displace a walker to a neighboring cell according to values of local p x p x p y p y p z p z and p t the walker is then continuously displaced until it reaches the system boundaries or t 0 4 simulate a large number of random walkers to estimate expected passage frequency according to eq 13 at each cell and time step 5 evaluate green s function g according to eqs 15 or 16 note that in steady state problems no initial condition exists p t 0 and all random walkers will be terminated on boundary 2 4 five test cases to verify wog based green s functions five test problems of groundwater flow are introduced in the first three problems the analytical green s function can be found and used as references to validate wog based green s functions directly the other two problems involve pointwise heterogeneity in hydraulic parameters and no analytical green s function are available thus wog based green s functions are verified through their resulting hydraulic heads which are compared to numerical solutions of head calculated by the widely used modflow 2000 harbaugh et al 2000 2 4 1 test case 1 fig 2 presents a one dimensional homogeneous unconfined aquifer neumann and robin boundaries are imposed at the left and right ends respectively transient groundwater flow in the aquifer shown in fig 2 is described by 21 k x h h x w u x t μ h t h x 0 x 0 k h h x k b 2 l b h l t h b t h l t h b t x l h x t h 0 x t 0 assume that variations of h are small compared to average thickness of the aquifer eq 21 can be linearized and analytically solved by green s function more details can be found in appendix a 2 4 2 test case 2 consider two dimensional transient flow in a homogeneous confined aquifer of size l x l y 1440 m 800 m transmissivity t 0 5 m2 d and storativity s 10 4 dirichlet boundaries are imposed at x 0 and x 1440 m neumann boundaries are set at y 0 and y 800 m analytical expressions of the green s function are provided by cole et al 2011 their eqs x11 2 and x22 3 2 4 3 test case 3 solving for green s function analytically in the presence of a large number of interfaces zones and in higher dimensions with complex boundary conditions is problem specified and typically challenging especially in transient cases for the sake of simplicity consider a boundary value problem in a one dimensional aquifer in which k may be homogeneous or block heterogeneous the analytical green s function g s x s corresponding to the homogeneous setting is after cole et al 2011 table x 3 22 g s x s 1 x l s k s x 1 s l x k x s in the presence of multiple conductivity zones g s x s has to meet interface conditions 23 k s g s x s s k s g s x s s g s x s s g s x s s which are rooted in continuities of flux and hydraulic head respectively expressions of g s x s for two zone and three zone cases are shown in section 3 below 2 4 4 test case 4 test case 4 is a heterogeneous version of test case 1 in which hydraulic conductivity k and specific yield μ are point wise heterogeneous fig 3 a b such a model is similar to the one liang and zhang 2013 tried to handle through analytical formulation but much more general the natural logarithm of k is characterized by a mean value of 0 2 variance of 0 9 and an exponential variogram of integral scale of 25 m the spatial distribution of lnk is simulated by a sequential gaussian simulator deutsch journel 1998 k and μ are treated to be correlated according to μ 0 3 0 04 ln k ξ where ξ is a random variable following a standard normal distribution and correlation between lnk and μ is 0 7 daily series of precipitation events r t and river stage h b t are synthetically generated to reflect common hydrologic features and are depicted in fig 3 c d the recharge coefficient varies linearly between 0 7 0 9 from x 0 to x l so that effective recharge to the aquifer varies spatially and temporally to calculate the flow rate per unit width from the river to the aquifer as q t 1 2 k b h l t h b t h l t h b t l b head on the right end h x l t is calculated by both modflow 2000 and wog in both methods time step length δ t 0 1 d and discretization length δ x 0 5 m are used 2 4 5 test case 5 test case 5 considers a horizontal two dimensional unconfined aquifer of non uniform hydraulic conductivity k and specific yield μ fields of lnk with mean equal to 0 2 and variance 0 8 and μ with mean of 0 3 and variance 0 001 are independently obtained by sequential gaussian simulation deutsch journel 1998 using an exponential variogram of integral scale equal to 500 m fig 4 depicts the conceptual model of the system and maps of the spatial distribution of lnk and μ there exists an active well with pumping rate q t l3t 1 and a spatially uniform but temporally varying areal recharge p t lt 1 the former is located at the center of the domain i e at x w y w 500 m 400 m and is operated according to a prescribed time schedule fig 5 two observation boreholes are set at x 1 y 1 450 m 400 m and x 2 y 2 550 m 400 m the east boundary is a prescribed head boundary with head equal to φ y t the remaining boundaries being impervious even as both wog and modflow allow considering any functional form for φ y t we set φ y t 50 m for simplicity the initial head h 0 x y 50 m and the study period is of 20 d groundwater flow is governed by 24 x kh h x y kh h y w u x y t μ h t h x 0 x 0 h y 0 y 0 or l y h x y t φ y t x l x h x y t h 0 x y t 0 here l x 1000 m l y 800 m and the total thickness is h 50 m w u x y t p t q t δ x w y w case 5 can be numerically solved by modflow 2000 or wog based green s function method below similar to linearization technique illustrated in appendix a eq 24 can be rewritten as 25 x k u x y k u y 2 w u x y t s e u t u x 0 x 0 u y 0 y 0 or l y u x y t φ 2 y t x l x u x y t h 0 2 x y t 0 wog based solution to eq 25 is 26a u x y t u i u d u s where 26b u i 0 l x d x 0 l y h 0 2 x y s e x y g x y t x y τ 0 d y 26c u d 0 t d τ 0 l y k φ 2 y τ x g x y t x l x y τ d y 26d u s 0 t d τ 0 l x d x 0 l y 2 w u x y τ g x y t x y τ d y represent the contributions to u or equivalently h x y t of initial condition dirichlet boundary and source sink terms respectively recalling that w u x y t p t q t δ x w y w then u s 0 t 2 p τ ρ p x y t τ d τ 0 t 2 q τ ρ q x y t x w y w τ d τ here 27 ρ p x y t τ 0 l x d x 0 l y g x y t x y τ d y quantifies the influence to u x y t of areal recharge at time τ and 28 ρ q x y t x w y w τ g x y t x w y w τ provides an indication of the influence to u x y t of pumping at time τ at location x w y w if φ y t φ t i e independent of location then u d 0 t φ 2 τ ρ d x y t τ d τ where 29 ρ d x y t τ 0 l y k x g x y t x l x y τ d y in other words ρ q ρ p and ρ d can be considered as the weights of source and boundary histories to impact u x y t once g x y t x y τ is evaluated by wog method ρ q ρ p and ρ d can be found afterwards h x y t can be calculated and compared to modflow simulation table 1 summarizes the dimensions of quantities mentioned in this study which may help validate the correctness of analyses in this study 3 results and discussion 3 1 test case 1 wog based green s function for case 1 and its analytical counterpart are evaluated for a setting corresponding to l 100 m k 1 m d μ 0 3 h 30 m s e 0 01 m 1 k b 0 1 m d l b 0 1 m and a 10 days temporal window wog based green s function uses a uniform domain discretization length δ x 0 5 m and time step length δ t 0 05 d the number of random walk realizations is n mc 106 on the other hand one hundred terms are included in the evaluation of the analytical expression eq a3 fig 6 depicts results obtained at 4 illustrative locations x 25 m 50 m 75 m and 100 m across the temporal range 0 t 10 d while the wog based results display some oscillations at low values they virtually coincide with the analytical solution according to eq 15 the observed numerical errors are related to the precision of i i e 1 n mc and are noticeable only when i is comparable to 1 n mc on these bases one can note that the smallest non zero value that can be represented by eq 15 in this example is g 4 9 10 6 i e ln g 12 2 which provides sufficient precision for our purpose the location corresponding to this value corresponds to the right end in fig 5 d i e the robin boundary this result is consistent with a dampening impact of this boundary type note that the green s function at x 100 m will always vanish when k b l b in conformity with the fact that the robin boundary tends to a dirichlet boundary for k b l b thus wog based green s function matches its analytical counterpart with good accuracy 3 2 test case 2 a uniform spatial discretization δ x δ y 20 m and time step δ t 0 1 d across a 10 days temporal window are used in wog method an example of the comparison between the green s function results obtained through analytical and wog methods is depicted in fig 7 denoting a good agreement between them even in the presence of some numerical errors at low values results of the same quality are obtained at other locations and observation times not shown for brevity it suggests that wog based green s function is reliable 3 3 test case 3 by taking into account all interface conditions mathematical expressions of green s functions g s x s in case 3 for x 0 15 l 0 25 l and 0 35 l are found and plotted in fig 8 by red dashed lines corresponding wog based g s x s obtained with a uniform domain discretization δx l 10 3 are also depicted by black lines it is seen that wog based green s function matches analytical counterparts very well thus supporting the validity of eq 16 in both homogeneous and heterogeneous media 3 4 test case 4 fig 9 a b reports head and flow rate at right end h x l t and q t computed through modflow and wog based green s function these results are complemented by fig 9 c which depicts the relative differences between h x l t evaluated by wog and modflow it is seen that differences in h x l t from two methods are very limited results of q t are also very close thus green s function evaluated by wog approach is able to yield accurate solutions to groundwater flow in heterogeneous aquifers and the effectiveness of wog based green s function method is further validated 3 5 test case 5 in both modflow and wog based green s function methods δ x δ y 10 m and time step δ t 0 1 d fig 10 a depicts the wog based green s function g x w y w t x y τ at the pumping well until t 20 d fig 10 b d depicts spatial contours of g x w y w t x y τ for τ 20 d τ 10 d and τ 0 d when t 20 d fig 11 depicts the evolution of ρ q x y t x w y w τ ρ p x y t τ and ρ d x y t τ across 0 τ t for t 20 d at the pumping and observation wells fig 4 values of ρ q at the pumping well are consistently largest it is in agreement on the fact that pumping at x w y w naturally affects heads at x w y w stronger than at other locations it is also found that ρ q at observation well 2 is close to but greater than its counterpart evaluated at observation well 1 implying an stronger hydraulic connection between the pumping well and well 2 due to heterogeneity according to ρ d the impact of dirichlet boundary is remarkable at observation well 2 but almost negligible at observation well 1 since ρ q ρ p and ρ d embed point to point hydraulic connections in a quantitative manner a further evolution of the study could be the analysis of the possibility to enhance our understanding about aquifer connectivity upon relying on metrics derived from a green s function approach head variation δ h x y t h x y t h 0 x y evaluated at the two observation wells and at the pumping well are denoted as δ h 1 δ h 2 and δ h w respectively δ h 1 δ h 2 and δ h w calculated through modflow and wog are compared in fig 12 a c fig 12 d depicts the relative differences between heads obtained by the two methods at the three target locations these results clearly demonstrate the accuracy of the wog based green s function method its computational costs are discussed in section 3 6 where it is shown that wog based green s function is very efficient when there is the need to assess the action of various combinations of φ y t h 0 x y q t and p t once the green s function is found by wog 3 6 advantages of wog based green s function method two of several major advantages wog based green s function approach bears are computational stability and efficiency as mentioned in the introduction irregularity produced by dirac function in green s function pde equation 5 often leads to difficulty in convergence and errors which is further exacerbated by discontinuous coefficients e g hydraulic conductivities in the pde barajas solano tartakovsky 2013 repeating failures of convergences have been observed while attempting to solve eq 5 directly by modflow that s the reason why we don t compare green s function from wog to that from modflow in test case 4 and case 5 in contrast wog based method seems work stably in all cases in our investigation here the second advantage is computational efficiency of this approach it is mainly attributed to a parallelizability in simulating random walks and b framework of green s function method which allows efficient recalculations for various combinations of boundary conditions and forcing terms table 2 lists details of time costs in all of the computational studies illustrated above for the sake of accuracy one hundred terms are included in the evaluation of analytical expression of the green s function in test case 1 a choice that yields computationally intensive evaluations one can note that in this case the wog based green s function evaluation is more efficient than its analytical counterpart otherwise analytical expressions associated with test case 2 and case 3 are in closed form and very efficient in test case 4 and case 5 the wog based approach first evaluates numerically green s functions and then calculate hydraulic heads based on these green s functions the most computational cost is spent in the first step i e green s function evaluation and the second step is very fast about 10 2 s or less furthermore the computational cost in the first step can be remarkably reduced through parallelization and more efficient than using modflow on the other hand modflow directly solves for heads at each time step while this computational suite is typically considered as an efficient tool when compared to other groundwater solvers one can see that it is still not fast enough in many scenario simulations which may require calling solver routines a large number of times for example addressing data assimilation uncertainty analysis and or source identification problems see e g ayvaz karahan 2008 nan wu 2011 wu zeng 2013 yeh 2015 in the presence of uncertain forcing terms and or boundary conditions often requires relying on a high number of direct solutions of the flow scenarios as such surrogate models are developed to speed up the solution often at the cost of a decreased accuracy see e g asher et al 2015 and references therein when considering a wog based green s function approach performing multiple calls to scenario simulation the second step above is only a marginal issue because the first step i e green s function evaluation needs to be implemented only once and the computational cost of the second step is negligible therefore our results evidence the potential benefit in terms of computational cost of relying on a wog based green s function approach when there is the need for a high number of repeated solutions of the groundwater flow problem as driven by uncertain forcing and or boundary terms 4 conclusions this study leads to the following major conclusions 1 the relation between green s functions and random walk is extended to heterogeneous aquifers upon deriving a quantitative relationship between green s function and expected passage frequency of random walk this enables one to numerically evaluate green s functions of groundwater flow problems in aquifer systems of complex geometries and spatial heterogeneity patterns this new method rests on the walk on grid wog approach and its capabilities are illustrated through a suite of five test scenarios involving steady state and transient flow various boundary conditions the action of spatially and or temporally varying source terms of various nature as well as diverse spatial distributions of system attributes e g hydraulic conductivity and storativity 2 numerical green s functions calculated by wog are compared against exact analytical solutions under a variety of settings results figs 6 8 show that the wog based green s functions are virtually indistinguishable from their analytical counterparts an exception being given by values that are too low to be properly captured by expected passage frequency of random walk numerical errors in the wog based evaluation of green s functions are controlled by the precision associated with the calculated expected passage frequency i which in turn depends on the number of random walk realizations i e n mc one million realizations are used in all of our examples which is shown to be sufficient to capture the main information in green s functions 3 the findings corresponding to settings of increased level of complexity where analytical solutions are not available reveal that relative differences between heads calculated via our wog based approach and their counterparts based on numerical solution of the widely tested computational suite modflow are very small i e 0 02 in fig 9 c and 0 09 in fig 12 d these results strengthen our confidence on the accuracy of wog based green s functions for groundwater flow scenarios 4 as compared against available analytical formulations the wog approach may be computationally more efficient in the evaluation of green s functions when the former are expressed in terms of infinite series 5 the wog based green s function method avoids limitations of applicability to complex media which are typical of traditional approaches to the numerical evaluation of green s functions i e it can efficiently handle various combinations of boundary conditions and forcing and is applicable to aquifers of general heterogeneous structure with excellent accuracy 6 while wog based green s function method appears to be more computationally demanding than modflow it is recalled that evaluation of heads is associated with negligible computational time once the green s function is calculated thus in terms of computational cost the potential benefit of relying on a wog based green s function method tends to increase when one has to perform a high number of repeated solutions of the groundwater flow problem as driven by uncertain forcing and or boundary terms potential application examples in this context which one could consider on future studies include the assessment of the evolution of groundwater resources as driven by various climatic scenarios or the quantification of the sustainability of multiple extraction scenarios in a given aquifer system 7 finally this study allows discriminating clearly the contributions to head distributions due to boundary and source terms on these bases our results form the basis upon which one can build future studies to analyze the concept of aquifer connectivity through metrics derived from a green s function method declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is funded by the national natural science foundation of china grant nos 41730856 41972245 41602250 china postdoctoral science foundation grant no 2017m611782 and the fundamental research funds for the central universities grant nos 0206 14380032 and 0206 14380091 part of the work was developed while prof a guadagnini was at the university of strasbourg with funding from région grand est and strasbourg eurométropole through the chair gutenberg we declare that we have no conflict of interest data included in this study can be downloaded at https www researchgate net profile tongchao nan publications appendix a we assume that the total saturated thickness is much larger than the amplitude of spatiotemporal variations of head setting h 2 u and s e μ h where h is the spatially averaged saturated thickness whose temporal variation we take as much smaller than h eq 23 can be linearized as a1 2 u x 2 2 w u x t k s e k u t u x 0 x 0 k u x k b l b u x t k b l b h b 2 t x l u x t h 0 2 x t 0 boundary conditions can be recast as α i u x x x i β i u x i t γ i t with x 1 0 α 1 1 β 1 0 γ 1 0 x 2 l α 2 k β 2 k b l b γ 2 k b l b h b 2 t the solution of eq a1 can be expressed as a2 u x t 0 l h 0 2 s g x t s τ 0 s e d s 2 0 t d τ 0 l w u s τ g x t s τ d s 0 t d τ i 1 2 γ i τ α i g x t s x i τ where a3 g x t s τ 2 s e l m 1 exp λ m 2 k t τ s e l 2 λ m 2 d 2 λ m 2 d 2 d cos λ m x l cos λ m s l λ m being the m th root of λ m tan λ m d with d 2 β 2 l k 2 k b l l b k 
