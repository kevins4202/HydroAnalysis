index,text
3370,causes and water sources of flowing artesian wells attracted the interest of many hydrogeologists throughout history however a quantitative model that satisfactorily considers the roles of topography groundwater recharge discharge and aquitards on hydraulics of flowing wells is still lacking in this study a three layer river valley basin with a recharge boundary is used to obtain the basinal flow field spatial distribution and transient discharge rates of flowing wells even if there is an aquitard separating the unconfined and the confined aquifers groundwater discharge to the river still plays a critical role in occurrence of flowing wells an aquitard with lower permeability would enlarge the zone with flowing wells implying that flowing wells are more likely to occur in basins with continuous aquitards by comparing flowpaths and inter aquifer leakages before and after numerically installing a flowing well in a three layer basin we find decreased upward leakage in the discharge limb plays a much larger role than increased downward leakage in the recharge limb in the stable discharge rate of a flowing well this recognition is different from previous studies where the stable discharge rate is supported only by downward leakage from the overlying aquifer by considering well hydraulics in a basinal background flow field this study improves understanding of the mechanisms of flowing artesian wells and the interaction of surface water and deep groundwater indicating that flowing wells are valuable for sampling deep groundwater representative of deep and old groundwater in the discharge area of a basin keywords flowing well well hydraulics leaky aquifer artesian basin cross formational flow topography driven flow 1 introduction quantifying the sources of water derived in wells and the interaction between groundwater withdrawal and river water has been one of the most fundamental tasks of groundwater hydrology since the 1940s de graaf et al 2019 kollet and zlotnik 2003 theis 1940 zhou 2009 because flowing artesian wells were widespread in many sedimentary basins and are spectacular visual evidence of groundwater occurrence many classical studies of groundwater hydrology were inspired by flowing wells jiang et al 2020 in the 19th century hydrogeologists bond 1865 chamberlin 1885 darton 1897 de thury 1830 garnier 1822 had realized that a confined aquifer bounded by aquitards an adequate water supply in recharge areas and a higher head in recharge areas than the well outlet are qualifying conditions of flowing wells due to the widespread occurrence of aquitards in sedimentary basins an overlying aquitard was long regarded to be an indispensable condition of flowing wells by plotting how groundwater flows from topographic highs to lows in unconfined homogeneous aquifers hubbert 1940 found flowing wells could occur in topographic lows with depth increasing hydraulic head and explicitly pointed out that an overlying aquitard is not a necessary condition at all in the classic textbook by freeze and cherry 1979 flowing wells were divided into geologically controlled and topographically controlled the former refers to flowing wells in confined aquifers while the latter in unconfined aquifers in fact many geologically controlled flowing wells were drilled near large rivers two typical examples are shown in fig 1 implying that they are also associated with the upward groundwater discharge through aquitards in topographic lows considering the pattern of basinal groundwater circulation and the role of aquitards in inter aquifer leakage are widely acknowledged since the 1940s this study aims to revisit the causes and water sources of flowing wells by considering the simultaneous controls of basinal topographic undulation combination of aquifers and aquitards and groundwater recharge discharge sources of water derived in wells include storage release decreased discharge to surface water also called baseflow reduction and various forms of induced recharge feinstein et al 2016 konikow and leake 2014 theis 1940 jacob and lohman s 1952 model of flowing wells tapping confined aquifers accounted for the effect of storage release on decaying discharge rate hantush s 1959 model of flowing wells tapping semi confined aquifers accounted for not only the contribution of storage release at the early stage but also the role of induced recharge near the well at the later stage the hantush model is useful for parameter estimation by using constant head well tests feng and zhan 2019 van der kamp 2001 wen et al 2011 however from the perspective of causes water sources and sustainability of flowing wells the hantush model has several limitations the first is the assumption of spatially uniform initial heads in the semi confined aquifer which does not fulfill the precondition that recharge area should have higher head than the flowing well in fact as shown in fig s1 which is reproduced from dupuit 1863 the potentiometric surface around a flowing well is influenced by the regional hydraulic gradient in recent decades it has been recognized that neglecting background regional flow field would lead to a misleading understanding of the source of water in pumping or observation wells church and granato 1996 elçi et al 2003 ma et al 2014 poulsen et al 2019 reilly et al 1989 zinn and konikow 2007 the second is hantush assumed that there is downward inter aquifer leakage from the whole unconfined aquifer to the semi confined aquifer after drilling a flowing well which is invalid because the semi confined aquifer where the flowing well penetrates should have hydraulic heads permanently higher than the elevations of the land surface and the water table the third is hantush assumed that the overlying unconfined aquifer has an unchanged water table as already pointed out by neuman and witherspoon 1969 such an assumption could be valid for short term well tests but is invalid for long term well tests implying that hantush s 1959 model cannot be used to interpret the sustainability of flowing wells that have had been gushing for more than one century fig 1 tóth 1962 1963 proposed mathematical models to quantify basinal groundwater flow in unit basins and complex basins which was considered as a paradigm shift in hydrogeology anderson 2008 bredehoeft 2018 mádl szőnyi 2008 one limitation of tóth s model is the water table undulation is pre defined not controlled by recharge rate and hydraulic conductivity this limitation has been pointed out in many studies bresciani et al 2016 dai et al 2021 gleeson and manning 2008 goderniaux et al 2013 haitjema and mitchell bruker 2005 liang et al 2013 in this study to emphasize the roles of recharge from precipitation and inter aquifer leakage we improve tóth s unit basin model by using a recharge boundary and introducing a continuous aquitard between two aquifers such an improved model is ideal for generating a regional gradient in the semi confined aquifer as well as for considering the effect of groundwater recharge by specifying a wide range of parameters of the aquitard as reported in the literature chapman et al 2018 grisak and cherry 1975 keller et al 1989 kuang et al 2020 wolff 1970 we examine the role of aquitards in the occurrence of flowing wells as well as in the transient discharge rates under a series of scenarios a comparison of inter aquifer leakages before and after drilling leads to a clear understanding of sources of water discharged in flowing artesian wells 2 methods 2 1 the conceptual model of flowing wells in layered river valley basins many flowing artesian wells in the history were very close to rivers for example the city lille where the first flowing artesian well was drilled in 12th century in the ancient province artois in france the latin name of artois is artesia which gave birth to the name of artesian well is located near the la marque river the two historically well known flowing artesian wells in paris shown in fig 1a were both less than 2 km away from the seine river moreover there were numerous flowing artesian wells in the arkansas river valley of southeastern colorado in the missouri river valley of north dakota south dakota and nebraska and in the mississippi river valley of wisconsin minnesota and iowa darton 1905 konikow and leake 2014 the wide occurrence of flowing wells near rivers can be explained by the fact that rivers usually correspond to the discharge area of regional groundwater flow in topographic lows therefore we adopt a 3d river valley basin to examine the influencing factors of flowing wells flowing wells are numerically installed in topographic lows which is referred to as drilling in the current study to examine the transient behaviors and sources of groundwater discharge tóth s 2d cross sectional model has been found to be useful to quantify the occurrence of flowing wells in the discharge area of a homogeneous unit basin wang et al 2015 following wang et al 2015 the undulating topography from the valley to the basin divide is characterized by a cosine function in the form of 1 z s x y z 0 h r cos π 2 1 x l where z 0 is the elevation of land surface at the valley as well as the head of the river l h r is the amplitude of the regional undulation of topography l l is the distance from the valley to the basin divide l and x is the distance to the valley l following zhang et al 2018b the 2d cross section is first extended to a 2d complete basin which is symmetric with respect to the river valley and is then extruded along the y direction to obtain a 3d basin with a width of w fig 2 because continuous aquitards are widespread in many sedimentary basins with occurrences of flowing artesian wells bredehoeft et al 1983 contoux et al 2013 habermehl 2020 toulier et al 2019 young 1992 we assume that the river valley basin is composed of an unconfined aquifer aq1 and a semi confined aquifer aq2 which are separated by an aquitard at fig 2 the basin bottom and the four lateral boundaries have no flow boundary conditions in the field of well hydraulics most existing studies assume that hydraulic head in the overlying unconfined aquifer would not change with groundwater development in fact before drilling the basin scale water table undulation is controlled by recharge rate and distribution of sinks and sources which is dependent on topography after drilling water table in the unconfined aquifer would reach a new equilibrium between recharge and various forms of discharge konikow and leake 2014 zlotnik and tartakovsky 2008 therefore we employ a specified flux upper boundary condition to obtain the water table undulation before and after drilling a fully penetrating flowing well in aq2 near the river denoted as model a to compare with previous studies we also investigate the transient behaviors of flowing wells in three more scenarios denoted as models b c and d the flowing well taps the semi confined aquifer in models b and c and taps a purely confined aquifer in model d model b has a spatially undulating and time invariant water table equaling that of model a before drilling and all other conditions are the same as those in model a model c has spatially uniform heads in aq1 and aq2 equaling the initial head at the flowing well obtained by model a and the head in aq1 is time invariant which are similar to hantush 1959 in model d the confined aquifer has a spatially uniform initial head equaling the initial head at the flowing well obtained by model a which is similar to jacob and lohman 1952 note that an infinite confined aquifer and a bounded confined aquifer are both considered in model d 2 2 the numerical model and treatment of flowing wells to reduce the effect of the no flow lateral boundary on the discharge of flowing wells the length and width of the 3d basin in models a b and c are set to be 20 km by setting z 0 1000 m and h r 50 m the thickness of the basin increases from 1000 m at the valley to 1100 m at the divide the semi confined aquifer aq2 has a uniform thickness of 400 m the aquitard has a uniform thickness of 200 m while the unconfined aquifer aq1 has a thickness of 400 m at the valley and 500 m at the divide to ensure that steady state discharge rate can be attained the duration of the transient simulations is set to be 4 105 days 1096 years in model d the length and width are both set to be 20 km for the bounded confined aquifer model and are both set to be 200 km to represent the infinite confined aquifer model of jacob and lohman 1952 aq1 and aq2 have the same hydraulic conductivity k equaling 1 m d and the same specific storage s s equaling 1 10 5 m 1 the first layer of the unconfined aquifer aq1 has a recharge rate of 250 mm yr 6 85 10 4 m d and a specific yield of 0 15 the recharge rate is reduced to 187 5 mm yr 5 13 10 4 m d 75 of the base case or increased to 312 5 mm yr 8 56 10 4 m d 125 of the base case for sensitivity analysis the ratio of recharge rate to hydraulic conductivity ranges from 5 1 10 4 to 8 6 10 4 which is within the range from 10 6 to 10 3 in most productive aquifers that usable quantities of water can be pumped haitjema and mitchell bruker 2005 in the base case we set the hydraulic conductivity k of the aquitard to be 0 01 m d corresponding to a k k of 100 while the specific storage ss of the aquitard to be 0 to examine the role of the aquitard based on values identified in the literature chapman et al 2018 grisak and cherry 1975 keller et al 1989 kuang et al 2020 van der kamp 1976 zlotnik and zurbuchen 2003 we select a wide range of k from 0 001 m d to 1 m d and ss from 1 10 5 m 1 to 5 10 3 m 1 for sensitivity analysis modflow nwt harbaugh 2005 niswonger et al 2011 which is robust in treating dry and rewet cells hunt and feinstein 2012 is adopted for simulation the model is vertically discretized into 50 layers the top layer is variable in thickness while each of the other 49 layers has a uniform thickness of 20 m the drain boundary which has the capability to remove water from the aquifer when the head rises above the drain elevation is set at the land surface to characterize the seepage area like wetlands in the discharge area feinstein et al 2016 goderniaux et al 2013 the revised multi node well mnw2 package konikow et al 2009 is adopted to treat the flowing well in all models a fully penetrating flowing well with a radius of 0 2 m is specified at the center of the confined aquifer or semi confined aquifer in all models the grid size is 1 2 m near the well and gradually increases to 500 m at the edge of the basin by setting the head of the flowing well equaling the elevation of land surface and specifying an artificially very large discharge rate at the outlet of the flowing well the discharge rate q of the flowing well is calculated by konikow et al 2009 2 q i 1 n h well h n c w c where hn is the hydraulic head in each well grid hwell is the water level in the well and cwc is cell to well conductance calculated by 3 cwc ln r 0 r w 2 π b k x k z 1 where r0 is the equivalent radius of a finite difference cell l rw is the actual well radius l b is the saturated length of the flowing well penetrating the semi confined aquifer l and kx and kz are horizontal and vertical hydraulic conductivities respectively l t 3 results and discussion 3 1 the distribution of flowing wells and controlling factors in a homogeneous unit basin with a pre defined water table there is a midline separating the basin into two parts with equal sizes i e a recharge limb with a component of downward flow and a discharge limb with a component of upward flow tóth 1962 wang et al 2015 in the current study under the control of a uniform recharge rate throughout the whole basin and a river in the valley the recharge limb with downward flow covers a much larger area at the surface than the discharge limb with upward flow fig 3 to obtain the subsurface parts of recharge and discharge limbs we introduce the concept of dynamic head increment proposed by tóth 1978 which was defined as the difference between the hydraulic head at a specific point and the corresponding water table elevation a negative dynamic head increment corresponds to the recharge limb where groundwater flows away from the water table while a positive dynamic head increment corresponds to the discharge limb where groundwater flows towards the water table among the eight scenarios shown in fig 3 although there are similar flow patterns from topographic highs to lows the size of the discharge limb is sensitive to hydraulic conductivity and thickness of the aquitard and the recharge rate from precipitation to demonstrate the size of zone with flowing wells we introduce wang et al s 2015 definition of head exceeding land surface initially called artesian head i e the difference between the hydraulic head at a specific point and the corresponding elevation of land surface when all other conditions are kept the same a lower hydraulic conductivity fig 3a d or a thicker aquitard fig 3g h leads to a higher head difference between the divide and the valley thus a larger discharge limb as well as a larger zone with flowing wells when the recharge rate is changed although the size of the discharge limb changes little in the semi confined aquifer the size of the zone with flowing wells changes greatly fig 3e f these findings are consistent with wang et al 2015 that the zone with flowing wells is always located inside the discharge limb and increases with the head difference between the divide and the valley as indicated by equation 2 the discharge rate of a flowing well is controlled by the head exceeding land surface if hwell equals the elevation of land surface once a flowing well is drilled the head at the well drops instantaneously to hwell due to the consumption of storage in the semi confined aquifer the decreasing head in the semi confined aquifer leads to a time decaying discharge rate at the flowing well before reaching a stable discharge rate fig s2 compared with the base case k 0 01 m d and x 0 m as the flowing well is located farther away from the valley the discharge rate becomes much smaller fig s2a which is consistent with the spatial distribution of head exceeding land surface shown in fig 3 as k increases the discharge rate also decreases significantly fig s2b due to the smaller head exceeding land surface in the semi confined aquifer as a direct result of the control of recharge rate on water table undulation the discharge rate of flowing wells increases with the recharge rate from precipitation fig s2c when the aquitard is incompressible s s 0 the aquitard simply acts as a pathway for leakage when the aquitard is compressible s s 0 a larger specific storage results in a larger discharge rate showing a greater deviation from the incompressible case at the intermediate stage fig s2d this role of aquitard compressibility is consistent with hantush s 1964 and neuman and witherspoon s 1969 studies on the effect of aquitard storage on drawdown in constant rate well tests 3 2 spatial distributions of steady state flowpaths and capture rate the role of inter aquifer leakage an increasing drawdown in the aquifer is a direct manifestation of gradual consumption of storage the spatial distribution of drawdown reaches a steady state when there is no more consumption of storage in the semi confined aquifer fig 4 shows the spatial distributions of steady state drawdown and the potentiometric surfaces around a flowing well located at x 1500 m obtained by models a and c the drawdowns obtained by models a and c differ little but the potentiometric heads near the flowing wells differ greatly note that model a has a potentiometric head distribution similar to that shown in fig s1 given by dupuit 1863 indicating the control of regional gradient from topographic highs to lows when the drawdown reaches the steady state groundwater discharge in the flowing well is totally contributed by capture fig 4 also shows the drastically different flowpaths reaching the flowing wells obtained by models a and c in model a groundwater reaching the flowing well comes from the recharge area in topographic highs the flowpaths of which have long travel distances in model c however groundwater reaching the flowing well comes from the overlying unconfined aquifer around the well and the flowpaths reaching the top part of the well have short travel distances therefore ignoring the background basinal flow field would cause a misleading understanding of sources of water derived in a flowing well capture induced by a well is composed of increased recharge and decreased discharge barlow and leake 2012 barlow et al 2018 bredehoeft and durbin 2009 konikow and leake 2014 leake 2011 zhou 2009 because the flowing well screened only in the semi confined aquifer interacts with the outside through the overlying aquitard we show the spatial distributions of inter aquifer leakage rate before drilling and steady state inter aquifer leakage rate after drilling at x 0 m fig 5 a in model a before installing a flowing well the downward leakage through the aquitard in the recharge limb constitutes recharge to the semi confined aquifer and the upward leakage through the aquitard in the discharge limb constitutes a form of discharge in the semi confined aquifer fig 3 and fig 5b1 after drilling as a result of the drawdown in the semi confined aquifer the downward leakage rate increases in the recharge limb causing an induced recharge from the unconfined aquifer while the upward leakage rate decreases in the discharge limb resulting in a reduced discharge to the unconfined aquifer and thus reduced baseflow of the river fig 5b2 the shadowed zone in fig 5a shows the difference between inter aquifer leakage rates at the two states which can be interpreted as the spatial distribution of capture rate therefore increased recharge increased downward inter aquifer leakage in the recharge limb and decreased discharge decreased upward inter aquifer leakage in the discharge limb both have contributions to capture as shown in fig 5a decreased discharge is much larger than increased recharge note that model b with a pre defined water table undulation would lead to similar distributions of inter aquifer leakage and capture as model a the results of model b are not shown as a result of spatially uniform and equal heads in aq1 and aq2 model c has an initial leakage rate equaling 0 throughout the whole aquitard fig 5c1 after drilling the drawdown in the semi confined aquifer leads to downward leakage recharge throughout the whole aquifer system fig 5c2 based on the downward flowpaths shown in fig 4b if there is a river nearby the flowing well river water could flow to the semi confined aquifer the classic hantush 1959 model would lead to a similar conclusion on the interaction between groundwater withdrawal and river water to sum up although the spatial distributions of drawdown and capture rate differ little between models a and c the two models have drastically different physical processes concerning the sources of groundwater derived in flowing wells and different relationship of interaction between surface water and groundwater in model a surface water in the river is not likely to enter the semi confined aquifer but in model c river water would easily enter the semi confined aquifer as demonstrated in fig s3 this recognition is also applicable to basins with lower k k 3 3 temporal evolution of inter aquifer capture and its dominant source because discharge rate is proportional to drawdown at the flowing well s w we follow jacob and lohman 1952 and define the dimensionless discharge rate q d in the form of q 2 π t s w fig 6 a shows the dimensionless discharge rate versus dimensionless time t d t t s r w 2 under five different conditions when the flowing well is drilled in an infinite and purely confined aquifer the discharge rate decays exponentially with time curve 1 when the purely confined aquifer is bounded the length and the width both equal 20 km the curve of q d versus t d curve 2 deviates from the case of an infinite aquifer when t d 108 which is similar to the effect of no flow lateral boundary conditions on drawdown in a confined aquifer bear 1979 ferris et al 1962 for a semi confined aquifer with the same dimension as the bounded confined aquifer the discharge is totally supported by storage of the semi confined aquifer at the early stage in the base case k k 100 of model a the curve of q d versus t d curve 3 coincides with curve 2 when t d 107 but deviates from curve 2 as a result of the inter aquifer leakage labeled as capture in fig 5a which is to be discussed in detail later if k is larger curves of q d versus t d curves 4 and 5 start to deviate from curve 2 at earlier times due to the stronger inter aquifer leakage the control of k k on q d at the later stage is consistent with hantush 1959 we also investigate the effect of upper boundary conditions on how q d changes with t d fig 6b model b with a spatially variable head in the unconfined aquifer has the same discharge rate as model c with a spatially uniform head which is a direct result of the same cone of depression near the flowing well fig s4a and the same evolution of drawdown fig s4b however model a with a specified flux upper boundary has a smaller discharge rate and larger drawdown at the later stage therefore models b and c both overestimate the stable discharge rate of flowing wells because the specified head which is invariant with time could provide unlimited water supply this demonstrates that models with specified head upper boundary conditions are not suitable for interpretation of long term sustainability of flowing wells in the following our discussion is restricted to results obtained by model a in constant rate pumping tests the plot of fraction of capture to total discharge versus time is widely used to interpret the sustainable yield of a groundwater basin bredehoeft and durbin 2009 konikow et al 2009 zhou 2009 in the current study as indicated in fig 4a the capture rate increases with time and approaches to the stable discharge rate at the later stage although the discharge rate of the flowing well decreases with time fig 6 the capture fraction increases exponentially while the storage depletion fraction decreases exponentially fig s5 which are similar to scenarios in constant rate pumping tests therefore the plot of capture fraction is also valuable to interpret sustainability of a flowing well although the fraction of capture to discharge does not change with well location fig 7 a if the capture is divided into increased recharge and decreased discharge each is slightly influenced by well location moreover we find the fraction of decreased discharge is always larger than the fraction of increased recharge we also find the occurrence of decreased discharge is always earlier than the occurrence of increased recharge which is a direct result of the propagation of drawdown from the flowing well towards topographic highs therefore the decreased discharge plays a more important role in the discharge rate of a flowing well because the hydraulic parameters are critical to the inter aquifer leakage we also examined the control of aquitard hydraulic conductivity k and aquitard thickness b on the evolution of capture fraction fig 7b we introduce the term leakage parameter b 2 which was defined by hantush and jacob 1955 to be kb b k as k increases or b decreases both of which lead to a decreasing b 2 there is an earlier occurrence of capture as well as an earlier time to reach equilibrium this is reasonable because both factors would promote inter aquifer leakage as b 2 decreases although increased recharge occurs earlier the fraction of increased recharge becomes lower fig 7c and d which corresponds to a larger fraction of decreased discharge this also demonstrates that decreased discharge plays a more important role than increased recharge in the discharge rate of flowing wells 4 conclusions and implications in this study by extending tóth s 1962 homogeneous unit basin model to a three layer basin with a specified flux upper boundary condition we examined the simultaneous controls of topography geology sources and sinks of groundwater on occurrences of flowing wells we find the undulating water table which is determined by topography recharge rate and hydraulic conductivity largely controls the distribution of flowing wells the zone with flowing wells is always inside the discharge limb near the river and its size increases with the recharge rate the occurrence of an aquitard would enlarge the discharge limb as well as the zone with flowing wells implying that flowing wells are more likely to be drilled in a semi confined aquifer with a low permeability aquitard this finding well explains why it was long thought that an overlying aquitard is a necessary condition of flowing wells by comparing models with or without considering regional hydraulic gradient we find the two approaches lead to similar capture rates but drastically different recognitions on sources of water discharged in flowing wells if the regional hydraulic gradient is not considered the only source of capture is induced downward leakage from the whole overlying aquifer however if the regional hydraulic gradient is considered there are two different sources and decreased upward leakage in the discharge limb plays a much greater role than increased downward leakage in the recharge limb the dominant source of capture from decreased upward leakage in the discharge limb has implications for sampling deep groundwater in semi confined aquifers from flowing wells recent studies showed that intensive groundwater pumping would lead to the widespread risk of stream loss into surrounding aquifers jasechko et al 2021 larkin and sharp 1992 implying that aquifers could easily be mixed with stream water in fact if a flowing well occurs in the discharge area of a layered basin the upward hydraulic gradient indicates that streams are impossible to lose water into the semi confined aquifer because flowing wells still widely occur in many basins throughout the world gaber 2005 pétré et al 2016 smerdon and ransley 2012 toulier et al 2019 wang et al 2015 xiao et al 2017 we expect that flowing wells would play important roles in tracing water rock interactions zhang et al 2018a and climate change seltzer et al 2021 from deep and old groundwater that has traveled long distances from recharge areas credit authorship contribution statement yi peng zhang methodology software formal analysis writing original draft xiao wei jiang conceptualization methodology formal analysis writing review editing funding acquisition john cherry conceptualization writing review editing zhi yuan zhang methodology validation xu sheng wang conceptualization li wan conceptualization supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the national natural science foundation of china 42172270 the fundamental research funds for the central universities of china the national program for support of top notch young professionals and the 111 project b20010 we thank brian smerdon and an anonymous reviewer and the associate editor okke batelaan for their constructive suggestions no field data is used in the current study the numerical models in the current study are built using the modflow nwt which is publicly available from the usgs appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127714 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3370,causes and water sources of flowing artesian wells attracted the interest of many hydrogeologists throughout history however a quantitative model that satisfactorily considers the roles of topography groundwater recharge discharge and aquitards on hydraulics of flowing wells is still lacking in this study a three layer river valley basin with a recharge boundary is used to obtain the basinal flow field spatial distribution and transient discharge rates of flowing wells even if there is an aquitard separating the unconfined and the confined aquifers groundwater discharge to the river still plays a critical role in occurrence of flowing wells an aquitard with lower permeability would enlarge the zone with flowing wells implying that flowing wells are more likely to occur in basins with continuous aquitards by comparing flowpaths and inter aquifer leakages before and after numerically installing a flowing well in a three layer basin we find decreased upward leakage in the discharge limb plays a much larger role than increased downward leakage in the recharge limb in the stable discharge rate of a flowing well this recognition is different from previous studies where the stable discharge rate is supported only by downward leakage from the overlying aquifer by considering well hydraulics in a basinal background flow field this study improves understanding of the mechanisms of flowing artesian wells and the interaction of surface water and deep groundwater indicating that flowing wells are valuable for sampling deep groundwater representative of deep and old groundwater in the discharge area of a basin keywords flowing well well hydraulics leaky aquifer artesian basin cross formational flow topography driven flow 1 introduction quantifying the sources of water derived in wells and the interaction between groundwater withdrawal and river water has been one of the most fundamental tasks of groundwater hydrology since the 1940s de graaf et al 2019 kollet and zlotnik 2003 theis 1940 zhou 2009 because flowing artesian wells were widespread in many sedimentary basins and are spectacular visual evidence of groundwater occurrence many classical studies of groundwater hydrology were inspired by flowing wells jiang et al 2020 in the 19th century hydrogeologists bond 1865 chamberlin 1885 darton 1897 de thury 1830 garnier 1822 had realized that a confined aquifer bounded by aquitards an adequate water supply in recharge areas and a higher head in recharge areas than the well outlet are qualifying conditions of flowing wells due to the widespread occurrence of aquitards in sedimentary basins an overlying aquitard was long regarded to be an indispensable condition of flowing wells by plotting how groundwater flows from topographic highs to lows in unconfined homogeneous aquifers hubbert 1940 found flowing wells could occur in topographic lows with depth increasing hydraulic head and explicitly pointed out that an overlying aquitard is not a necessary condition at all in the classic textbook by freeze and cherry 1979 flowing wells were divided into geologically controlled and topographically controlled the former refers to flowing wells in confined aquifers while the latter in unconfined aquifers in fact many geologically controlled flowing wells were drilled near large rivers two typical examples are shown in fig 1 implying that they are also associated with the upward groundwater discharge through aquitards in topographic lows considering the pattern of basinal groundwater circulation and the role of aquitards in inter aquifer leakage are widely acknowledged since the 1940s this study aims to revisit the causes and water sources of flowing wells by considering the simultaneous controls of basinal topographic undulation combination of aquifers and aquitards and groundwater recharge discharge sources of water derived in wells include storage release decreased discharge to surface water also called baseflow reduction and various forms of induced recharge feinstein et al 2016 konikow and leake 2014 theis 1940 jacob and lohman s 1952 model of flowing wells tapping confined aquifers accounted for the effect of storage release on decaying discharge rate hantush s 1959 model of flowing wells tapping semi confined aquifers accounted for not only the contribution of storage release at the early stage but also the role of induced recharge near the well at the later stage the hantush model is useful for parameter estimation by using constant head well tests feng and zhan 2019 van der kamp 2001 wen et al 2011 however from the perspective of causes water sources and sustainability of flowing wells the hantush model has several limitations the first is the assumption of spatially uniform initial heads in the semi confined aquifer which does not fulfill the precondition that recharge area should have higher head than the flowing well in fact as shown in fig s1 which is reproduced from dupuit 1863 the potentiometric surface around a flowing well is influenced by the regional hydraulic gradient in recent decades it has been recognized that neglecting background regional flow field would lead to a misleading understanding of the source of water in pumping or observation wells church and granato 1996 elçi et al 2003 ma et al 2014 poulsen et al 2019 reilly et al 1989 zinn and konikow 2007 the second is hantush assumed that there is downward inter aquifer leakage from the whole unconfined aquifer to the semi confined aquifer after drilling a flowing well which is invalid because the semi confined aquifer where the flowing well penetrates should have hydraulic heads permanently higher than the elevations of the land surface and the water table the third is hantush assumed that the overlying unconfined aquifer has an unchanged water table as already pointed out by neuman and witherspoon 1969 such an assumption could be valid for short term well tests but is invalid for long term well tests implying that hantush s 1959 model cannot be used to interpret the sustainability of flowing wells that have had been gushing for more than one century fig 1 tóth 1962 1963 proposed mathematical models to quantify basinal groundwater flow in unit basins and complex basins which was considered as a paradigm shift in hydrogeology anderson 2008 bredehoeft 2018 mádl szőnyi 2008 one limitation of tóth s model is the water table undulation is pre defined not controlled by recharge rate and hydraulic conductivity this limitation has been pointed out in many studies bresciani et al 2016 dai et al 2021 gleeson and manning 2008 goderniaux et al 2013 haitjema and mitchell bruker 2005 liang et al 2013 in this study to emphasize the roles of recharge from precipitation and inter aquifer leakage we improve tóth s unit basin model by using a recharge boundary and introducing a continuous aquitard between two aquifers such an improved model is ideal for generating a regional gradient in the semi confined aquifer as well as for considering the effect of groundwater recharge by specifying a wide range of parameters of the aquitard as reported in the literature chapman et al 2018 grisak and cherry 1975 keller et al 1989 kuang et al 2020 wolff 1970 we examine the role of aquitards in the occurrence of flowing wells as well as in the transient discharge rates under a series of scenarios a comparison of inter aquifer leakages before and after drilling leads to a clear understanding of sources of water discharged in flowing artesian wells 2 methods 2 1 the conceptual model of flowing wells in layered river valley basins many flowing artesian wells in the history were very close to rivers for example the city lille where the first flowing artesian well was drilled in 12th century in the ancient province artois in france the latin name of artois is artesia which gave birth to the name of artesian well is located near the la marque river the two historically well known flowing artesian wells in paris shown in fig 1a were both less than 2 km away from the seine river moreover there were numerous flowing artesian wells in the arkansas river valley of southeastern colorado in the missouri river valley of north dakota south dakota and nebraska and in the mississippi river valley of wisconsin minnesota and iowa darton 1905 konikow and leake 2014 the wide occurrence of flowing wells near rivers can be explained by the fact that rivers usually correspond to the discharge area of regional groundwater flow in topographic lows therefore we adopt a 3d river valley basin to examine the influencing factors of flowing wells flowing wells are numerically installed in topographic lows which is referred to as drilling in the current study to examine the transient behaviors and sources of groundwater discharge tóth s 2d cross sectional model has been found to be useful to quantify the occurrence of flowing wells in the discharge area of a homogeneous unit basin wang et al 2015 following wang et al 2015 the undulating topography from the valley to the basin divide is characterized by a cosine function in the form of 1 z s x y z 0 h r cos π 2 1 x l where z 0 is the elevation of land surface at the valley as well as the head of the river l h r is the amplitude of the regional undulation of topography l l is the distance from the valley to the basin divide l and x is the distance to the valley l following zhang et al 2018b the 2d cross section is first extended to a 2d complete basin which is symmetric with respect to the river valley and is then extruded along the y direction to obtain a 3d basin with a width of w fig 2 because continuous aquitards are widespread in many sedimentary basins with occurrences of flowing artesian wells bredehoeft et al 1983 contoux et al 2013 habermehl 2020 toulier et al 2019 young 1992 we assume that the river valley basin is composed of an unconfined aquifer aq1 and a semi confined aquifer aq2 which are separated by an aquitard at fig 2 the basin bottom and the four lateral boundaries have no flow boundary conditions in the field of well hydraulics most existing studies assume that hydraulic head in the overlying unconfined aquifer would not change with groundwater development in fact before drilling the basin scale water table undulation is controlled by recharge rate and distribution of sinks and sources which is dependent on topography after drilling water table in the unconfined aquifer would reach a new equilibrium between recharge and various forms of discharge konikow and leake 2014 zlotnik and tartakovsky 2008 therefore we employ a specified flux upper boundary condition to obtain the water table undulation before and after drilling a fully penetrating flowing well in aq2 near the river denoted as model a to compare with previous studies we also investigate the transient behaviors of flowing wells in three more scenarios denoted as models b c and d the flowing well taps the semi confined aquifer in models b and c and taps a purely confined aquifer in model d model b has a spatially undulating and time invariant water table equaling that of model a before drilling and all other conditions are the same as those in model a model c has spatially uniform heads in aq1 and aq2 equaling the initial head at the flowing well obtained by model a and the head in aq1 is time invariant which are similar to hantush 1959 in model d the confined aquifer has a spatially uniform initial head equaling the initial head at the flowing well obtained by model a which is similar to jacob and lohman 1952 note that an infinite confined aquifer and a bounded confined aquifer are both considered in model d 2 2 the numerical model and treatment of flowing wells to reduce the effect of the no flow lateral boundary on the discharge of flowing wells the length and width of the 3d basin in models a b and c are set to be 20 km by setting z 0 1000 m and h r 50 m the thickness of the basin increases from 1000 m at the valley to 1100 m at the divide the semi confined aquifer aq2 has a uniform thickness of 400 m the aquitard has a uniform thickness of 200 m while the unconfined aquifer aq1 has a thickness of 400 m at the valley and 500 m at the divide to ensure that steady state discharge rate can be attained the duration of the transient simulations is set to be 4 105 days 1096 years in model d the length and width are both set to be 20 km for the bounded confined aquifer model and are both set to be 200 km to represent the infinite confined aquifer model of jacob and lohman 1952 aq1 and aq2 have the same hydraulic conductivity k equaling 1 m d and the same specific storage s s equaling 1 10 5 m 1 the first layer of the unconfined aquifer aq1 has a recharge rate of 250 mm yr 6 85 10 4 m d and a specific yield of 0 15 the recharge rate is reduced to 187 5 mm yr 5 13 10 4 m d 75 of the base case or increased to 312 5 mm yr 8 56 10 4 m d 125 of the base case for sensitivity analysis the ratio of recharge rate to hydraulic conductivity ranges from 5 1 10 4 to 8 6 10 4 which is within the range from 10 6 to 10 3 in most productive aquifers that usable quantities of water can be pumped haitjema and mitchell bruker 2005 in the base case we set the hydraulic conductivity k of the aquitard to be 0 01 m d corresponding to a k k of 100 while the specific storage ss of the aquitard to be 0 to examine the role of the aquitard based on values identified in the literature chapman et al 2018 grisak and cherry 1975 keller et al 1989 kuang et al 2020 van der kamp 1976 zlotnik and zurbuchen 2003 we select a wide range of k from 0 001 m d to 1 m d and ss from 1 10 5 m 1 to 5 10 3 m 1 for sensitivity analysis modflow nwt harbaugh 2005 niswonger et al 2011 which is robust in treating dry and rewet cells hunt and feinstein 2012 is adopted for simulation the model is vertically discretized into 50 layers the top layer is variable in thickness while each of the other 49 layers has a uniform thickness of 20 m the drain boundary which has the capability to remove water from the aquifer when the head rises above the drain elevation is set at the land surface to characterize the seepage area like wetlands in the discharge area feinstein et al 2016 goderniaux et al 2013 the revised multi node well mnw2 package konikow et al 2009 is adopted to treat the flowing well in all models a fully penetrating flowing well with a radius of 0 2 m is specified at the center of the confined aquifer or semi confined aquifer in all models the grid size is 1 2 m near the well and gradually increases to 500 m at the edge of the basin by setting the head of the flowing well equaling the elevation of land surface and specifying an artificially very large discharge rate at the outlet of the flowing well the discharge rate q of the flowing well is calculated by konikow et al 2009 2 q i 1 n h well h n c w c where hn is the hydraulic head in each well grid hwell is the water level in the well and cwc is cell to well conductance calculated by 3 cwc ln r 0 r w 2 π b k x k z 1 where r0 is the equivalent radius of a finite difference cell l rw is the actual well radius l b is the saturated length of the flowing well penetrating the semi confined aquifer l and kx and kz are horizontal and vertical hydraulic conductivities respectively l t 3 results and discussion 3 1 the distribution of flowing wells and controlling factors in a homogeneous unit basin with a pre defined water table there is a midline separating the basin into two parts with equal sizes i e a recharge limb with a component of downward flow and a discharge limb with a component of upward flow tóth 1962 wang et al 2015 in the current study under the control of a uniform recharge rate throughout the whole basin and a river in the valley the recharge limb with downward flow covers a much larger area at the surface than the discharge limb with upward flow fig 3 to obtain the subsurface parts of recharge and discharge limbs we introduce the concept of dynamic head increment proposed by tóth 1978 which was defined as the difference between the hydraulic head at a specific point and the corresponding water table elevation a negative dynamic head increment corresponds to the recharge limb where groundwater flows away from the water table while a positive dynamic head increment corresponds to the discharge limb where groundwater flows towards the water table among the eight scenarios shown in fig 3 although there are similar flow patterns from topographic highs to lows the size of the discharge limb is sensitive to hydraulic conductivity and thickness of the aquitard and the recharge rate from precipitation to demonstrate the size of zone with flowing wells we introduce wang et al s 2015 definition of head exceeding land surface initially called artesian head i e the difference between the hydraulic head at a specific point and the corresponding elevation of land surface when all other conditions are kept the same a lower hydraulic conductivity fig 3a d or a thicker aquitard fig 3g h leads to a higher head difference between the divide and the valley thus a larger discharge limb as well as a larger zone with flowing wells when the recharge rate is changed although the size of the discharge limb changes little in the semi confined aquifer the size of the zone with flowing wells changes greatly fig 3e f these findings are consistent with wang et al 2015 that the zone with flowing wells is always located inside the discharge limb and increases with the head difference between the divide and the valley as indicated by equation 2 the discharge rate of a flowing well is controlled by the head exceeding land surface if hwell equals the elevation of land surface once a flowing well is drilled the head at the well drops instantaneously to hwell due to the consumption of storage in the semi confined aquifer the decreasing head in the semi confined aquifer leads to a time decaying discharge rate at the flowing well before reaching a stable discharge rate fig s2 compared with the base case k 0 01 m d and x 0 m as the flowing well is located farther away from the valley the discharge rate becomes much smaller fig s2a which is consistent with the spatial distribution of head exceeding land surface shown in fig 3 as k increases the discharge rate also decreases significantly fig s2b due to the smaller head exceeding land surface in the semi confined aquifer as a direct result of the control of recharge rate on water table undulation the discharge rate of flowing wells increases with the recharge rate from precipitation fig s2c when the aquitard is incompressible s s 0 the aquitard simply acts as a pathway for leakage when the aquitard is compressible s s 0 a larger specific storage results in a larger discharge rate showing a greater deviation from the incompressible case at the intermediate stage fig s2d this role of aquitard compressibility is consistent with hantush s 1964 and neuman and witherspoon s 1969 studies on the effect of aquitard storage on drawdown in constant rate well tests 3 2 spatial distributions of steady state flowpaths and capture rate the role of inter aquifer leakage an increasing drawdown in the aquifer is a direct manifestation of gradual consumption of storage the spatial distribution of drawdown reaches a steady state when there is no more consumption of storage in the semi confined aquifer fig 4 shows the spatial distributions of steady state drawdown and the potentiometric surfaces around a flowing well located at x 1500 m obtained by models a and c the drawdowns obtained by models a and c differ little but the potentiometric heads near the flowing wells differ greatly note that model a has a potentiometric head distribution similar to that shown in fig s1 given by dupuit 1863 indicating the control of regional gradient from topographic highs to lows when the drawdown reaches the steady state groundwater discharge in the flowing well is totally contributed by capture fig 4 also shows the drastically different flowpaths reaching the flowing wells obtained by models a and c in model a groundwater reaching the flowing well comes from the recharge area in topographic highs the flowpaths of which have long travel distances in model c however groundwater reaching the flowing well comes from the overlying unconfined aquifer around the well and the flowpaths reaching the top part of the well have short travel distances therefore ignoring the background basinal flow field would cause a misleading understanding of sources of water derived in a flowing well capture induced by a well is composed of increased recharge and decreased discharge barlow and leake 2012 barlow et al 2018 bredehoeft and durbin 2009 konikow and leake 2014 leake 2011 zhou 2009 because the flowing well screened only in the semi confined aquifer interacts with the outside through the overlying aquitard we show the spatial distributions of inter aquifer leakage rate before drilling and steady state inter aquifer leakage rate after drilling at x 0 m fig 5 a in model a before installing a flowing well the downward leakage through the aquitard in the recharge limb constitutes recharge to the semi confined aquifer and the upward leakage through the aquitard in the discharge limb constitutes a form of discharge in the semi confined aquifer fig 3 and fig 5b1 after drilling as a result of the drawdown in the semi confined aquifer the downward leakage rate increases in the recharge limb causing an induced recharge from the unconfined aquifer while the upward leakage rate decreases in the discharge limb resulting in a reduced discharge to the unconfined aquifer and thus reduced baseflow of the river fig 5b2 the shadowed zone in fig 5a shows the difference between inter aquifer leakage rates at the two states which can be interpreted as the spatial distribution of capture rate therefore increased recharge increased downward inter aquifer leakage in the recharge limb and decreased discharge decreased upward inter aquifer leakage in the discharge limb both have contributions to capture as shown in fig 5a decreased discharge is much larger than increased recharge note that model b with a pre defined water table undulation would lead to similar distributions of inter aquifer leakage and capture as model a the results of model b are not shown as a result of spatially uniform and equal heads in aq1 and aq2 model c has an initial leakage rate equaling 0 throughout the whole aquitard fig 5c1 after drilling the drawdown in the semi confined aquifer leads to downward leakage recharge throughout the whole aquifer system fig 5c2 based on the downward flowpaths shown in fig 4b if there is a river nearby the flowing well river water could flow to the semi confined aquifer the classic hantush 1959 model would lead to a similar conclusion on the interaction between groundwater withdrawal and river water to sum up although the spatial distributions of drawdown and capture rate differ little between models a and c the two models have drastically different physical processes concerning the sources of groundwater derived in flowing wells and different relationship of interaction between surface water and groundwater in model a surface water in the river is not likely to enter the semi confined aquifer but in model c river water would easily enter the semi confined aquifer as demonstrated in fig s3 this recognition is also applicable to basins with lower k k 3 3 temporal evolution of inter aquifer capture and its dominant source because discharge rate is proportional to drawdown at the flowing well s w we follow jacob and lohman 1952 and define the dimensionless discharge rate q d in the form of q 2 π t s w fig 6 a shows the dimensionless discharge rate versus dimensionless time t d t t s r w 2 under five different conditions when the flowing well is drilled in an infinite and purely confined aquifer the discharge rate decays exponentially with time curve 1 when the purely confined aquifer is bounded the length and the width both equal 20 km the curve of q d versus t d curve 2 deviates from the case of an infinite aquifer when t d 108 which is similar to the effect of no flow lateral boundary conditions on drawdown in a confined aquifer bear 1979 ferris et al 1962 for a semi confined aquifer with the same dimension as the bounded confined aquifer the discharge is totally supported by storage of the semi confined aquifer at the early stage in the base case k k 100 of model a the curve of q d versus t d curve 3 coincides with curve 2 when t d 107 but deviates from curve 2 as a result of the inter aquifer leakage labeled as capture in fig 5a which is to be discussed in detail later if k is larger curves of q d versus t d curves 4 and 5 start to deviate from curve 2 at earlier times due to the stronger inter aquifer leakage the control of k k on q d at the later stage is consistent with hantush 1959 we also investigate the effect of upper boundary conditions on how q d changes with t d fig 6b model b with a spatially variable head in the unconfined aquifer has the same discharge rate as model c with a spatially uniform head which is a direct result of the same cone of depression near the flowing well fig s4a and the same evolution of drawdown fig s4b however model a with a specified flux upper boundary has a smaller discharge rate and larger drawdown at the later stage therefore models b and c both overestimate the stable discharge rate of flowing wells because the specified head which is invariant with time could provide unlimited water supply this demonstrates that models with specified head upper boundary conditions are not suitable for interpretation of long term sustainability of flowing wells in the following our discussion is restricted to results obtained by model a in constant rate pumping tests the plot of fraction of capture to total discharge versus time is widely used to interpret the sustainable yield of a groundwater basin bredehoeft and durbin 2009 konikow et al 2009 zhou 2009 in the current study as indicated in fig 4a the capture rate increases with time and approaches to the stable discharge rate at the later stage although the discharge rate of the flowing well decreases with time fig 6 the capture fraction increases exponentially while the storage depletion fraction decreases exponentially fig s5 which are similar to scenarios in constant rate pumping tests therefore the plot of capture fraction is also valuable to interpret sustainability of a flowing well although the fraction of capture to discharge does not change with well location fig 7 a if the capture is divided into increased recharge and decreased discharge each is slightly influenced by well location moreover we find the fraction of decreased discharge is always larger than the fraction of increased recharge we also find the occurrence of decreased discharge is always earlier than the occurrence of increased recharge which is a direct result of the propagation of drawdown from the flowing well towards topographic highs therefore the decreased discharge plays a more important role in the discharge rate of a flowing well because the hydraulic parameters are critical to the inter aquifer leakage we also examined the control of aquitard hydraulic conductivity k and aquitard thickness b on the evolution of capture fraction fig 7b we introduce the term leakage parameter b 2 which was defined by hantush and jacob 1955 to be kb b k as k increases or b decreases both of which lead to a decreasing b 2 there is an earlier occurrence of capture as well as an earlier time to reach equilibrium this is reasonable because both factors would promote inter aquifer leakage as b 2 decreases although increased recharge occurs earlier the fraction of increased recharge becomes lower fig 7c and d which corresponds to a larger fraction of decreased discharge this also demonstrates that decreased discharge plays a more important role than increased recharge in the discharge rate of flowing wells 4 conclusions and implications in this study by extending tóth s 1962 homogeneous unit basin model to a three layer basin with a specified flux upper boundary condition we examined the simultaneous controls of topography geology sources and sinks of groundwater on occurrences of flowing wells we find the undulating water table which is determined by topography recharge rate and hydraulic conductivity largely controls the distribution of flowing wells the zone with flowing wells is always inside the discharge limb near the river and its size increases with the recharge rate the occurrence of an aquitard would enlarge the discharge limb as well as the zone with flowing wells implying that flowing wells are more likely to be drilled in a semi confined aquifer with a low permeability aquitard this finding well explains why it was long thought that an overlying aquitard is a necessary condition of flowing wells by comparing models with or without considering regional hydraulic gradient we find the two approaches lead to similar capture rates but drastically different recognitions on sources of water discharged in flowing wells if the regional hydraulic gradient is not considered the only source of capture is induced downward leakage from the whole overlying aquifer however if the regional hydraulic gradient is considered there are two different sources and decreased upward leakage in the discharge limb plays a much greater role than increased downward leakage in the recharge limb the dominant source of capture from decreased upward leakage in the discharge limb has implications for sampling deep groundwater in semi confined aquifers from flowing wells recent studies showed that intensive groundwater pumping would lead to the widespread risk of stream loss into surrounding aquifers jasechko et al 2021 larkin and sharp 1992 implying that aquifers could easily be mixed with stream water in fact if a flowing well occurs in the discharge area of a layered basin the upward hydraulic gradient indicates that streams are impossible to lose water into the semi confined aquifer because flowing wells still widely occur in many basins throughout the world gaber 2005 pétré et al 2016 smerdon and ransley 2012 toulier et al 2019 wang et al 2015 xiao et al 2017 we expect that flowing wells would play important roles in tracing water rock interactions zhang et al 2018a and climate change seltzer et al 2021 from deep and old groundwater that has traveled long distances from recharge areas credit authorship contribution statement yi peng zhang methodology software formal analysis writing original draft xiao wei jiang conceptualization methodology formal analysis writing review editing funding acquisition john cherry conceptualization writing review editing zhi yuan zhang methodology validation xu sheng wang conceptualization li wan conceptualization supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the national natural science foundation of china 42172270 the fundamental research funds for the central universities of china the national program for support of top notch young professionals and the 111 project b20010 we thank brian smerdon and an anonymous reviewer and the associate editor okke batelaan for their constructive suggestions no field data is used in the current study the numerical models in the current study are built using the modflow nwt which is publicly available from the usgs appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127714 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3371,north china nc is faced groundwater shortage in the past decades to understand the characteristics of groundwater storage gws change in nc gws anomaly gwsa is analyzed by using independent component analysis ica with the high resolution time variable gravity field model tongji reggrace2019 and hydrological models according to the spatiotemporal characteristics of independent components ics the driving factors and corresponding driving mechanism of gws changes are further investigated results show that the gws in nc is decreased with a rate of 0 87 0 04 cm yr from january 2004 to december 2015 and the rate increased to 3 71 0 49 cm yr from january 2014 to december 2015 among the first four ics of gwsa the first and second ics ic1 and ic2 cooperatively reflect long term and intra annual gws changes caused by water consumption of coal mining and agricultural irrigation in northern and southern shanxi province with the correlation coefficients of 0 91 and 0 85 respectively ic3 indicates the signal of semi annual gws change related to agricultural irrigation water consumption in southern hebei province with a correlation coefficient of 0 85 besides ic4 suggests the effect of monsoon precipitation and evaporation in front of taihang mountain hence the driving factors including uneven spatiotemporal distribution of precipitation intense seasonal evaporation severe loss by coal mining coupled with exhaustive exploitation for irrigation jointly restrict the gws rise and fall at different time nodes keywords north china groundwater depletion grace independent component analysis driving factor 1 introduction water resource is indispensable for human survival as a primary source of freshwater groundwater plays a crucial role in sustaining industrial development agricultural irrigation and domestic activities feng et al 2013 yin et al 2018 zhao et al 2019 however heavily dependent on groundwater the development of human society and the associated increasing food demand have caused widespread water crises around the world especially in north china nc where groundwater storage gws is being depleted at an alarming rate consequently a series of ecological disasters such as land subsidence and soil salinization have been occurred which in turn have caused huge impacts on socio economic stability and sustainable development cao et al 2013 hao et al 2021 at present formulations of reasonable strategies for groundwater exploitation and utilization are of great importance in nc obviously the fundamental bases of those management strategies depend on effective monitoring of gws changes and in turn to determine the potential driving factors and mechanisms however limited by complex underground circumstances no reliable means are available to detect gws changes directly the conventional data acquisition methods including ground based measurement and numerical simulation cao et al 2013 qin et al 2013 feng et al 2013 have some shortcomings the ground based monitoring wells are easily affected by surrounding environment and with sparse spatial coverage hence which makes it nearly impossible to monitor large scale gws changes su et al 2020 as for the modeling method based on numerical simulation it is usually difficult to collect background information and field data for groundwater models comprehensively thus significant uncertainties are associated with such models zheng et al 2015 ebead et al 2017 fortunately by using the twin satellite observations of the gravity recovery and climate experiment grace the time variable gravity field models with various temporal and spatial resolutions have been developed to monitor the large scale surface mass transport and redistribution with unprecedented accuracy tapley et al 2004 rowlands 2005 ramillien et al 2011 among which the quantitative inversion of global or regional terrestrial water storage tws change is particularly prominent wahr 2004 schmidt et al 2006 syed et al 2008 xavier et al 2012 the sufficiently reliable information from grace observations in monitoring tws change also ushers in a new era of large scale gws change estimation tws signal from grace observations is defined as an integrated measure of all forms of water stored on and below the surface of the earth which mainly includes surface water storage sws snow water equivalent storage swes soil moisture storage sms and gws feng et al 2013 tang et al 2013 in other words after sws swes and sms are deducted from tws the remaining part can be regarded as gws which has been proved to be effective in estimating gws changes over many typical watersheds around the world such as india rodell et al 2009 tiwari et al 2009 central valley of california scanlon et al 2012 middle east voss et al 2013 forootan et al 2017 the time variable gravity field models from grace observations are also used to investigate gws change in nc previous studies involved mainly focused on estimating the gws depletion rates using existing grace models in different sub regions of nc over different periods moiwo et al 2009 2013 su et al 2011 feng et al 2013 2018 huang et al 2015 ebead et al 2017 pan et al 2017 to improve the accuracy of estimated gws some modified inversion methods specific to the actual characteristics in nc were proposed such as the point mass modeling method feng et al 2017 mascon solution based on the three cornered hat method zhao et al 2019 downscaling method yin et al 2018 and data assimilation method yin et al 2020 according to the achievements of previous studies it is indisputable that the groundwater in nc is seriously depleted and the depletion rate has been confidently estimated besides the driving factors of gws changes have been qualitatively discussed including the influence of reservoir regulation water diversion and coal transport tang et al 2013 the reducing precipitation and agricultural irrigation su et al 2020 and the damages of coal mining to groundwater in shanxi and its surrounding areas qiao et al 2011 chen et al 2020 the quantitative investigation of gws changes relative to the driving factors is of great importance nevertheless limited by the previous grace models the spatial resolution of gws changes in nc is only about 300 km and thus gws change signals are always regarded as a whole when discussing the driving factors however nc consists of several provinces with different natural and anthropogenic activities it is worthy to determine the gws changes and separate the impacts of different activities in different sub regions as well as to identify the veritable driving factors therefore some effective signal separation techniques should be employed to determine the prominent source signals with the development of high resolution gravity field models the gws change in nc is looking forward to achieving better spatial resolution by which the underlying source signals can be isolated more effectively and therefore the driving factors including natural and anthropogenic factors and the driving mechanism can be discussed and analyzed more comprehensively therefore the main objectives of this work focus on three aspects 1 to apply the latest gravity model tongji reggrace2019 chen et al 2021 to get gws anomaly gwsa estimation with a higher spatial resolution 2 to implement spatiotemporal decomposition for gwsa with independent component analysis ica approach and analyze the periodic characteristics of each source signal since gws change is a mixture of different periodic signals and long term trends produced by several kinds of physical processes 3 to determine the driving factors and driving mechanism for each gwsa source signal in the following sections section 2 briefly describes the study area data and methodology section 3 presents the independent components ics of gwsa based on ica decomposition section 4 discusses the driving factors and driving mechanisms finally the conclusions are drawn in section 5 2 study area data and methodology 2 1 study area the nc confined within 110 120 e and 34 44 n is one of the seven geographical regions in china the main provinces and municipalities include beijing tianjin shanxi and hebei fig 1 with an area of about 370000 km2 and a permanent population of about 140 million the mean annual temperature is 8 c 13 c and the perennial mean precipitation ranges from 500 to 600 mm cao et al 2013 yin et al 2018 there are four distinct seasons in nc with hot summer and cold winter which is a typical temperate monsoon climate as one of the main grain production bases in china nc has played a crucial role in guaranteeing food demand supplying about 30 of wheat and 20 of maize output each year guo and shen 2015a the planting pattern here is the annual double cropping system namely cultivated with a rotation between winter wheat october to june and summer maize june to october jeong et al 2014 pan et al 2017 however due to the limited and uneven distribution of precipitation a large amount of groundwater is required for crop irrigation furthermore nc is well known for its rich coal resources especially in shanxi where the annual output of raw coal reaches billions of tons chen et al 2020 unfortunately since the unreasonable coal mining ground subsidence and vegetation damage have occurred which eventually destroy the aquifer and cause a rapid loss of groundwater qiao et al 2011 xie et al 2018 according to the relevant researches many groundwater funnels have been formed in nc feng et al 2013 2 2 data 2 2 1 grace data in this study the tws anomaly twsa from january 2004 to december 2015 is computed with the new tongji reggrace2019 monthly gravity field model up to degree and order d o 180 chen et al 2021 which is a regularized solution and thereby can be used directly without further smoothing the degree one coefficients have been added with that from swenson et al 2008 the c20 coefficients are replaced by those derived from satellite laser ranging data cheng et al 2011 and glacial isostatic adjustment correction is also completed based on the model of peltier et al 2018 compared to the previous spherical harmonic models the tongji reggrace2019 model has a greatly enhanced spatial resolution of 1 1 chen et al 2021 after the mean field from 2004 to 2009 is removed the twsa time series is computed with the well known formula of wahr et al 1998 2004 and expressed with 0 5 0 5 gird in the form of equivalent water height ewh in which the positive and negative values represent wetter and dryer than normal respectively the 14 missing months over the study period in the twsa time series are filled with the cubic spline interpolation method 2 2 2 hydrological models two hydrological models used in this study include the global land data assimilation system gldas rodell et al 2004 pan et al 2017 https disc gsfc nasa gov datasets keywords gldas page 1 and the watergap global hydrology model wghm döll et al 2003 schmied et al 2020 https doi pangaea de https doi org 10 1594 pangaea 918447 the monthly grid datasets of the sms anomaly smsa and swes anomaly swesa are simulated by the noah lsm model of gldas 2 1 and these grid data are converted from 0 25 0 25 to 0 5 0 5 to reconcile with grace data the smsa data is expressed in the sum of 4 vertical layers with the depth of 0 10 10 40 40 100 100 200 cm respectively although the sws anomaly swsa in nc is reported to be extremely limited and often ignored in terrestrial based water resource analysis moiwo et al 2009 2013 we still calculate the swsa the total water storage anomalies of reservoirs rivers lakes and wetlands from wghm version 2 2d to isolate the gwsa from twsa more accurately moreover gwsa is also simulated by wghm 2 2d independently which is used to verify the gwsa derived from tongji reggrace2019 gravity field models 2 2 3 meteorological data precipitation data from january 2004 to december 2015 are obtained from the global monthly weighted precipitation product provided by hydroshare public repository xu 2020 which are estimated by merging several precipitation datasets with different scales based on generalized three cornered hat tch method compared to individual precipitation product tch based weighted precipitation data has the advantage that the random error is substantially reduced and is also better than those mean based merger precipitation data in reproducing the inter annual and seasonal variations xu et al 2020 the global land evaporation amsterdam model gleam is dedicated to estimating different components of land evaporation gleam aims to maximize the recovery of information on evaporation contained in current satellite observations of climatic and environmental variables miralles et al 2011 martens et al 2017 since its development in 2011 gleam has been continually revised and updated and a third version gleam v3 was released in 2017 in this work the monthly evaporation grid data of gleam v3 3b is used and resampled to a spatial resolution of 0 5 0 5 https www gleam eu 2 2 4 ground based measurement the groundwater level data of 123 wells including 52 unconfined wells and 71 confined wells shown in fig 1 are collected from groundwater level yearbook for china geological environment monitoring institute of china geological environment monitoring 2005 2013 https www cigem cgs gov cn spanning january 2005 to december 2013 after data quality is checked groundwater level time series of 96 wells are determined to be qualified the distribution map of specific yield for unconfined aquifer and storativity for confined aquifer in nc provided by feng et al 2018 ranges widely from 0 025 to 0 22 given the unevenly distributed wells we segmented the study area into the cells of 0 5 by 0 5 grid where each cell was assigned the mean value of all groundwater levels within it feng et al 2018 then gwsa in terms of ewh over the region is calculated with su et al 2020 1 gwsa well j 1 n s j h j cos θ j j 1 n cos θ j where n is the number of cells divided in study area s is the specific yield for unconfined aquifers or storativity for confined aquifers θ is cell s latitude h refers to the mean of groundwater level variations in each cell 2 2 5 human activities according to relevant statistics and research human activities including agricultural irrigation industrial development and coal mining are with large water consumption in nc cao et al 2013 moiwo et al 2013 chen et al 2020 the agricultural irrigation and industrial water consumption data are sorted out from shanxi provincial bureau of statistics https tjj shanxi gov cn haihe river water conservancy commission https www hwcc gov cn and china statistical yearbook national bureau of statistics of china 2004 2015 https www stats gov cn tjsj ndsj the two kinds of data are with a temporal resolution of 1 year and the same period data as grace are downloaded monthly and annual raw coal production data in shanxi are collected from shanxi provincial bureau of statistics and national bureau of statistics of china since the monthly data from april 2011 to february 2015 are missing we only use the available data when calculating the monthly average time series according to chen et al 2020 the water consumption q water can be estimated from raw coal production q coal with the equation q water μ q coal where the conversion coefficient μ m3 ton is 0 87 in shanxi xie et al 2018 chen et al 2020 2 2 6 vegetation coverage data as a bond to connect atmosphere water and soil land surface vegetation is a sensitive indicator to monitor global climate change cornelissen et al 2007 therefore as an important interaction parameter among the atmosphere hydrosphere and lithosphere vegetation index is usually used to monitor the dynamic changes of vegetation and reflect the status of regional soil erosion wardlow and egbert 2008 the most widely used vegetation index is the normalized difference vegetation index ndvi that represents the degree of vegetation coverage and vegetation growth pettorelli et al 2005 the used ndvi spatial distribution dataset provided by the resource and environmental science and data center https www resdc cn is generated through the maximum value composite mvc method based on spot satellite remote sensing data a 0 5 confidence level was used to obtain the maximum and minimum ndvi then ndviveg is the average of the maximum 0 5 ndvi value and ndvisoil is the average of the minimum 0 5 ndvi value with the temporal and spatial resolutions of 1 month and 1 km respectively the range of ndvi is 1 to 1 whose very low values smaller than 0 1 correspond to bare soil rock and zero indicates the water body ramachandra et al 2012 since we focus on the vegetation distribution a segmentation was implemented for the ndvi spatial distribution product to extract vegetation boundary by a threshold of 0 1 i e ndvi values less than 0 1 are excluded due to the small variation of forest and other vegetation in nc for a long time the monthly ndvi time series can be characterized as the changes of crops to a large extent 2 3 methodology 2 3 1 independent component analysis ica in theory geophysical observations such as gwsa can be regarded as a mixture of several periodical signals and long term trends from different physical processes these potential source signals are traditionally estimated by using least squares fitting however the long term trends are usually not perfectly linear in time and the periodical signals are often more complicated than the fundamental sinusoidal cycles forootan and kusche 2012 generally no prior information is known about the sources and mixing modes and thus the signal extraction is actually a blind source separation problem the ica approach is an efficient statistical technique for dealing with this kind of task which can separate the mixed signals into multiple statistically independent source signals by maximizing the high order statistics after the temporal means are removed the grid time series are stored in an m n matrix x x t j t 1 2 m j 1 2 n where t denotes observed epoch and j represents grid point the matrix x is firstly decomposed with principal component analysis pca as 2 x m n p m n e n n t where p is an orthogonal matrix and each column of p denotes a principal component pc e contains the orthogonal eigenvectors of x since pca allows to concentrate a large amount of variance in relatively few components the first r r n components explaining the maximum amount of variability present in the observations are selected for further ica analysis forootan and kusche 2012 banerjee and kumar 2018 then eq 2 is adjusted as 3 x m n p m r e r n t the derived pcs i e the column vectors of matrix p are uncorrelated but not mutually independent to derive independent components a unitary matrix w w 1 w 2 w r is introduced to rotate the pc matrix so that the column vectors are as independent as possible thus eq 3 is rewritten as 4 x m n p m r w r r w r r t e r n t s m r a r n t where s pw and each column of s represents an independent temporal component a ew and its column is usually interpreted as a spatial pattern forootan et al 2014 feng et al 2021 each temporal component along with the corresponding spatial pattern denotes an independent component ic once an appropriate w is given the ics can be uniquely determined on contrary the matrix w can be determined based on the condition that the column vectors of s are as independent as possible in this work the joint approximate diagonalization of eigenmatrices jade algorithm is used to estimate the rotation matrix due to its better separability and robustness the details for the jade algorithm can be referred to forootan et al 2012 2014 2 3 2 correlation analysis method pearson s correlation coefficient and grey absolute correlation degree are adopted to evaluate the relationships between gwsa and potential driving factors pearson s correlation coefficient is defined as the quotient of covariance and standard deviation between two random variables yin et al 2020 the grey absolute correlation degree is comprehensively determined by the approximate degree of slope between two time series its computational step can refer to mei 1992 the grey absolute correlation degree reflects the information differences between gwsa and the driving factors during the dynamic change process and thereby can effectively make up for some deficiencies of pearson s correlation coefficient for example the grey absolute correlation degree can analyze the impact of multiple factors simultaneously and rank their importance in addition pearson s correlation coefficient is only suitable for the identification of linear relationships while the grey absolute correlation degree has no such limitation 3 independent component decomposition of gwsa 3 1 accuracy assessment of gwsa derived from tongji reggrace2019 solution the latitude weighted time series of twsa is derived from tongji reggrace2019 and shown in fig 2 where a certain difference can be observed in the variation trends at different periods and thus the whole study period is divided into three periods first the tws decreases from january 2004 to december 2009 with the rate of 1 96 0 12 cm yr then increases from january 2010 to december 2013 with 0 72 0 27 cm yr due to the intensive precipitation fig 2 and then rapidly decreases again from january 2014 to december 2015 with the rate of 4 64 0 54 cm yr for the whole study period the tws exhibits a decreasing trend with the rate of 1 00 0 06 cm yr the above rates are estimated by the least squares fitting method huang et al 2015 and corresponding uncertainties are fitting error 1 sigma the twsa derived from grace models is the total water storage integrated over vertical columns to separate the gwsa hereinafter referred to as gwsa grace the smsa swesa and swsa are removed also the gwsa time series can be derived from the monitoring well called gwsa well and wghm model called gwsa wghm respectively the three gwsa time series are shown in fig 3 with the cross correlation coefficients are 0 86 between grace and wghm 0 81 between grace and well and 0 84 between wghm and well respectively indicating a high consistency in phase since this statistical metric mainly measures the match in timing huang et al 2015 to quantitatively analyze the difference between two gwsa time series the root mean squared error rmse is computed as follows 5 rmse 1 m t 1 m y t z t 2 where y and z represent the gwsa time series from different means and m is the number of epochs the rmse between gwsa grace and gwsa wghm is 3 37 cm which is probably due to the difference in original data collections and processing strategies between grace and wghm döll et al 2014 and feng et al 2017 pointed out that both the 2 2a and 2 2b versions of wghm are prone to overestimate the gws depletion signal in the nc compared to the independent estimation from grace and this overestimation is attributed to the strong underestimation of diffuse groundwater recharge from wghm döll et al 2014 besides an overestimation of the gws in the latest wghm 2 2d was also demonstrated by su et al 2020 relatively gwsa grace and gwsa well agree more favorably with the rmse of 1 94 cm due to the limited number of available monitoring wells it is difficult to reflect the holistic variation of gws in some large areas su et al 2020 notably both gwsa grace and gwsa well present a short term recovery benefit from the intensive precipitation from 2012 to 2014 indicating that grace and monitoring well are more sensitive to the actual change of gws wang et al 2017 during the whole study period the depletion rates of gwsa grace and gwsa wghm are 0 87 0 04 cm yr and 1 51 0 01 cm yr respectively however there are significant discrepancies of gws depletion rates in different periods especially from 2014 to 2015 the rates from gwsa grace and gwsa wghm are 3 71 0 49 cm yr and 2 11 0 07 cm yr respectively other studies also reported that nc experienced severe drought from 2014 to 2015 zhao et al 2019 moreover the gwsa well depletion rate from 2005 to 2013 is 0 80 0 03 cm yr which is basically consistent with 0 85 0 06 cm yr of gwsa grace while smaller than 1 43 0 01 cm yr of the gwsa wghm in the same period the linear trends of gwsa grace from previous studies and this work are summarized in table 1 in which our result is basically consistent with those in similar study areas the discrepancies in gws decrease rates could be attributed to the differences in 1 the actual coverage of study areas 2 the periods of data involved 3 different versions of grace and hydrological models for instance some studies used the early version of grace models which are inevitably contaminated by the leakage and amplitude damping effects the above differences will affect the computed twsa and hence the estimation of the gws depletion rate moreover we plot the spatial trend map of gwsa in fig 4 from which we can see that gws is depleted with a variable degree in different sub regions especially for the northern shanxi and south central hebei to sum up gwsa from tongji reggrace2019 is reliable in describing the water resource changes in nc and can be used for further analysis 3 2 spatiotemporal decomposition for grace derived gwsa as shown in fig 3 the gwsa in nc derived from tongji reggrace2019 is characterized by a primary long term trend superimposed seasonal and inter annual oscillations before performing the ica separation procedure it is necessary to check the non gaussianity of the data following forootan and kusche 2012 we compute the kurtosis of grid gwsa time series data with kurtosis x j e x j 4 e x j 2 2 3 where x j is the jth grid gwsa time series and e is the expectation operator the computed kurtosis values are summarized in fig 5 showing that 68 of grids exhibit the absolute kurtosis value over 0 5 and thus the gwsa time series data have high order statistical properties therefore ica is further employed to analyze the gwsa time series data the percentages of the cumulative variances of derived pcs are shown in fig 6 using the f test shen et al 2014 at the 95 significance level the first four pcs are dominant and contain about 89 of total variance are well separated from the rest pcs which can sufficiently represent the required gwsa signals thus the first four pcs were retained for further resolving four ics we rearranged ics in descending order according to their contribution ratios defined by liu et al 2017 since the order of ics is random the temporal components and spatial patterns of the first four ics are illustrated in fig 7 where the temporal components are normalized by dividing their standard deviations and the spatial patterns are scaled by multiplying the normalization factors forootan and kusche 2012 from ic1 with the contribution ratio of 36 a decreasing trend accompanied by periodic signals dominated by semi annual cycle is clustered in the northern shanxi coincidentally the remarkable gravity change in this area was also detected by using the slepian localization analysis method and terrestrial gravity measurements han et al 2021 in particular large signal damping can be seen in 2011 which is related to the substantial increase in coal mining and groundwater leakage accidents deng et al 2018 ic2 32 contribution ratio shows a mixed signal that contains intra and inter annual variations along with the long term trend ic3 18 contribution ratio reflects a concentration of semi annual cycle dominated over the southern hebei and the temporal component shows a slight rise and followed by a rapid decline from january 2013 to december 2014 which is in step with the precipitation in this period fig 2 in addition due to the dramatic decrease in precipitation after 2013 and the demand for agricultural irrigation the stored precipitation has been exhausted in 2014 and thus the groundwater presents a sharp fall in the sowing period from march to july 2015 it is worth mentioning that both ic2 and ic3 show sharp changes from november 2010 to february 2011 according to records a well documented extreme drought event jointly triggered by the arctic oscillation and la niña occurred in nc during this period shen et al 2012 huang et al 2015 especially central and southern nc are severely impacted which is highly consistent with ic2 and ic3 in spatial distribution ic4 14 contribution ratio is a significant annual signal over the whole nc with a large response in the east central hebei the hydro meteorological elements involved in the regional water cycle mainly include precipitation evaporation and runoff moiwo et al 2013 pan et al 2017 however the surface runoff is extremely limited in nc due to the extensive construction of dams in recent years moiwo et al 2009 2013 therefore we further perform ica decomposition for the grid time series of precipitation and evaporation respectively and show results in figs 8 and 9 as for precipitation the cumulative variance of the first two pcs is as high as 93 of the total variance hence the first two pcs are retained to derive two ics ic1 consists of both annual and semi annual signals although the spatial distribution of ic1 covers entire nc the intensity of response has obvious clustering characteristics the large response values are located in the windward slope of the piedmont of taihang yanshan mountains owing to the combined effect of sea surface temperature subtropical high east asian monsoon and topography when the sea possesses lower temperature and higher pressure sea land thermal difference leads to the phenomenon of atmospheric circulation and then generates the monsoon which can transport water vapor to nc however due to the forced uplift effect by the terrain of mountains precipitation is easy to form on the windward slope wang et al 2008 thus precipitations are mostly concentrated in the eastern foothills of taihang mountain and the southern foothills of yanshan mountain similar seasonal signals also exist in ic2 and the two ics are correlated after a month s time lag with a correlation coefficient of 0 6 besides the large response values of ic2 are mainly distributed in south central nc which is different from that of ic1 as for evaporation ic1 and ic2 show significant annual and semi annual variations respectively whose spatial distribution patterns are somewhat similar to that of precipitation namely ic1 covers the whole nc while ic2 is more concentrated in southern nc 4 driving factor and corresponding mechanism of the gws changes 4 1 driving factor determination of the gwsa ics generally the distribution patterns of gwsa depend on various forms of groundwater recharge or utilization therefore we can draw some appropriate inferences about the driving factors for each gwsa ic by considering the practical locations where signals are clustered as the most important water input way in nc there is no doubt that close relationships exist between precipitation and gwsa ics especially gwsa ic4 which can be considered as one of the potential driving factors of gws changes correspondingly evaporation should be treated equally however a large part of groundwater consumption is caused by human activities besides natural volatilization for example agricultural irrigation is by far the largest groundwater use in the study area moiwo et al 2013 feng et al 2013 according to the distribution map of ndvi fig 1 the southern hebei with ndvi values close to 0 8 is the major crop growing area winter wheat and summer maize interestingly this position is basically superposition with the spatial pattern of gwsa ic3 in addition both gwsa ic1 and gwsa ic2 reflect the gws changes in shanxi as we all know several large coalfields with a total area of 57 700 km2 mainly include datong ningwu xishan qinshui hedong huoxi are all located in shanxi fig 1 over the years the underground aquifers of mining areas have been seriously destroyed owing to unreasonable mining and a large amount of groundwater has been lost as a result qiao et al 2011 xie et al 2018 hence besides agricultural irrigation coal mining is another potential driving factor of gwsa ic1 and gwsa ic2 to a certain extent it should also be noted that the industry in beijing tianjin hebei urban agglomeration is well developed and its groundwater consumption cannot be ignored which is one of the possible driving factors notably one can reconstruct each gwsa ic by multiplying the temporal component with the corresponding spatial pattern which represents the actual gws changes figs 10 and 11 present the time series of coal mining water consumption and irrigation water consumption in shanxi respectively since the two time series show similar changes with a high correlation coefficient of 0 95 the correlations with the two potential driving factors are bound to be very close regardless of ic1 or ic2 thus it is difficult to distinguish which factor resulting in the change characteristics of ic1 and ic2 respectively moreover limited by the difficulties in defining the spatial distribution boundaries of ic1 and ic2 we cannot accurately extract the water consumption time series of irrigation coal mining and industrial development in two signal clustered areas from the water consumption time series of whole shanxi in view of the above situations we combine ic1 and ic2 to present the gwsa time series of the whole shanxi denoted by gwsa ic1 2 it can be seen from fig 10 that gwsa ic1 2 fluctuates greatly from 2004 to 2015 showing a decreasing trend on the whole while coal mining water consumption time series shows an increasing trend except 2009 and 2015 which is opposite to the gwsa ic1 2 completely a similar scene is true for irrigation water consumption time series fig 11 the pearson s correlation coefficients between gwsa ic1 2 and coal mining water consumption and irrigation water consumption are 0 91 and 0 85 respectively the significant negative correlations indicate that the increase of coal mining and agricultural irrigation is directly related to the reduction of gws and both of them are the important driving factors of gws changes in shanxi however since the magnitude are different between gwsa ic1 2 and the water consumption of coal mining and irrigation these two factors can only account for part of the gws depletion in shanxi thus there may be other factors that need further study different from coal mining water consumption and irrigation water consumption the industrial water consumption in shanxi is unstable fig 12 with the increased trends from 2004 to 2006 and 2009 to 2012 while decreasing rapidly from 2006 to 2009 and 2012 to 2015 the curve of industrial water consumption shows an inverse w like shape and appears no obvious causal relationship with gwsa ic1 2 with the pearson s correlation coefficient only 0 06 indicating that industrial development has little impact on gws changes for the reason that most of the industrial districts in shanxi are located in metropolises and the tap water used is generally from the surface water stored in reservoirs and rivers fig 13 illustrates the correlation analysis of gwsa ic3 time series and irrigation water consumption refer to winter wheat and summer maize in hebei as expected gwsa ic3 exhibits a declining trend on the contrary irrigation water consumption continually increases during the whole study period the pearson s correlation coefficient between gwsa ic3 and irrigation water consumption is as high as 0 85 indicating that irrigation groundwater pumping in this area has a great effect on the gws changes unusually although irrigation water consumption remains to increase from 2012 to 2013 gwsa gets a rise which is benefit from the abundant precipitation during this period and further demonstrate the importance of precipitation to gws wang et al 2017 furthermore fig 14 depicts the correlation analysis between gwsa ic3 and industrial water consumption in hebei where the industrial water consumption shows a decreasing fluctuation which is attributed to the constant optimization of industrial structures notwithstanding that the trend of industrial water consumption is similar to that of gwsa ic3 and the pearson s correlation coefficient between them reaches 0 58 this association is contrary to the theoretical relationship i e the water storage change should be positively correlated with the water replenishment factors and negatively correlated with the water consumption factors theoretically between the two variables chen et al 2020 therefore industrial development is not the main driving factor of gws reduction in southern hebei figs 15 and 16 illustrate the correlation analysis between gwsa ic4 and each of p ic1 and e ic1 respectively clearly gwsa ic4 presents twice upward trends in the first 7 years and a continuous decline during the remaining period although the correlation coefficients 0 30 for gwsa ic4 and p ic1 0 49 for gwsa ic4 and e ic1 indicate that gwsa ic4 is not highly correlated with the two hydro meteorological factors some perceptible associations can be revealed by comparing their time series from different sub periods for instance from 2012 to 2015 p ic1 first decreases and then increases and the gwsa ic4 shows the same behavior from 2007 to 2009 e ic1 fluctuates greatly while gwsa ic4 always moves in the opposite directions with roughly similar amplitudes therefore gwsa ic4 can represent the gws changes under the synergistic effect of annual monsoon precipitation and evaporation to a certain extent the relatively small correlation coefficients possibly because the relationships among three variables are hidden in the basin scale water budget equation tws change precipitation evaporation runoff moiwo et al 2013 pan et al 2017 this equation is directly related to tws change that gws is just one part of it and thus the evaporation involved includes the total evaporation quality of various water bodies moreover surface water and soil moisture are first replenished by precipitation and then converted to groundwater through a slow penetration process therefore it is difficult to determine the relationship between the three variables directly just based on the correlation analysis an in depth examination is needed by adopting other means we also implement the correlation analysis between p ic2 and e ic2 due to their similar spatial distributions as illustrated in fig 17 the change direction of p ic2 for any two consecutive years is basically the same as that of e ic2 except 2010 and 2011 the difference is mainly reflected in the magnitude indicating that p ic2 and e ic2 jointly reflect a hydrological cycle process in the south central nc as described above we identify the driving factors of gwsa by establishing a one to one correlation analysis between gwsa ics and the potential factors to ensure the reliability of the results we put each gwsa ic and preliminarily determined driving factors into a grey system use the grey absolute correlation analysis method to further evaluate the relational degree and compare the importance of each driving factor result is shown in fig 18 in terms of gwsa ic1 2 relational degree values of irrigation water consumption and coal mining water consumption are very close and greater than 0 7 indicating that two factors are indeed closely related to gws changes and the importance is almost equal especially relational degree values of irrigation and coal mining for gwsa ic1 2 and irrigation for gwsa ic3 are much larger than those of p ic1 and e ic1 for gwsa ic4 whose relational degree values with p ic1 and e ic1 are significantly improved compared to pearson s correlation coefficients which is a further confirmation of the driving factors for gwsa ic4 based on the above analysis the driving factors of gws changes in nc are finally determined which include precipitation evaporation agricultural irrigation and coal mining 4 2 driving mechanism analysis of gws changes natural factors refer to precipitation and evaporation without human intervention however part of groundwater abstracted by human activities flows back to the ground and the rest evaporates or runs away evaporation from gleam model thus is actually the sum of spontaneous and anthropogenic quantities we are not able to distinguish them because lack of effective means to estimate separately for this reason we focus on the driving mechanism discussion of joint impact by all factors the time series of gwsa precipitation and evaporation are reconstructed by corresponding ics i e the first four gwsa ics two p ics and two e ics respectively fig 19 plots the gwsa time series in nc and its driving factors at the monthly and seasonal scales respectively as shown in fig 19 a and e the changes of time series of precipitation and evaporation are highly consistent with the correlation coefficients of 0 91 and 0 95 under the monthly and seasonal scales respectively which suggests that these two variables are the main participants of hydrological circulation in nc moiwo et al 2013 comparing the monthly time series of gwsa and precipitation gws fluctuates in the wake of the fluctuations of precipitation and the changes of gws slightly lag behind precipitation because precipitation must experience a slowly ground penetration process to recharge groundwater in particular as mentioned in section 3 1 gws from 2012 to 2014 shows an obvious recovery due to the heavy rainfall from the averaged time series of each month fig 19 b and each season fig 19 f the precipitation amplitudes are generally high in summer june august and low in winter december february with a peak of 12 01 cm in july and a trough of 0 28 cm in january the significant difference between the maximum and minimum indicates that the intra annual distribution of precipitation in nc is extremely uneven according to fig 19 c some distinctive features in trends can be observed from the averaged gwsa time series of each month roughly taking july as a demarcation point gws continually declines throughout the first half of the year and then reaches the annual low in july 4 07 cm before increasing rapidly during july to august following by a gradual reduction again the intra annual pattern of gwsa divided into three stages is contributed by both natural and human impacts as we can see from the averaged time series of each month fig 19 d the coal mining water consumption increases prominently from february to june and then reaches a local peak 4 06 107 m3 in june resulting in a continual decline of gws in the first half year moreover the ndvi of each month ndvi is used to replace the irrigation water consumption highlights a bimodal distribution may and august within a year which matches with the growing season annual double cropping system of crops in nc among them may is the growth peak of winter wheat yang et al 2010 since the high demand for water and low precipitation groundwater is intensively pumped for irrigation resulting in a rapid decline of gws from may to june noting that early june is the harvest time of winter wheat the vegetation coverage in the planting area is narrowing out and thus the ndvi value decreases apparently meanwhile june to july is the seeding time of maize and other crops which means that groundwater withdrawal is required again therefore the rapid depletion of gws in the first stage is the common effect of coal mining and agricultural irrigation subsequently gws shows a sharp increase from july to august after experiencing a rainy season august is the growth peak of summer maize yang et al 2010 however the irrigation pressure with groundwater is effectively alleviated due to the accumulation of heavy rainfall in the last stage under the situation that winter wheat of next year is started to be sowed in early october and the coal mining water consumption increases from october gws decreases again from october to november however the decrease is limited which is still benefited from the past wet season and so that the dependence on groundwater is greatly reduced in summary the intra annual distribution characteristics of gwsa in nc are complicated and volatile and the driving factors jointly restrict the changes of gws at different time nodes 5 conclusions this contribution aims to quantify gws changes from january 2004 to december 2015 in nc by combining the grace data and hydrological models and then explore the driving factors leading to the gws changes according to the results from tongji reggrace2019 the gws in nc is depleted with a rate of 0 87 0 04 cm yr from january 2004 to december 2015 and this depletion increases to 3 71 0 49 cm yr from january 2014 to december 2015 meanwhile the gws depletion rate from monitoring well between january 2005 and december 2013 is 0 80 0 03 cm yr which is basically consistent with that from tongji reggrace2019 0 85 0 06 cm yr while smaller than the simulation of the wghm model 1 43 0 01 cm yr during the same period notably gwsa time series from tongji reggrace2019 and monitoring well present a short term increase benefit from the intensive precipitation from 2012 and 2014 while wghm does not show such a phenomenon indicating that the gws quantification based on grace and monitoring well is more practical than wghm model alone spatiotemporal decomposition is performed for gwsa precipitation and evaporation by the ica approach respectively in terms of gwsa the first four ics accounting for 89 of the total variance respectively reflect the intra or inter annual cycles of gws changes located in northern shanxi southern shanxi southern hebei and east central hebei arguably the temporal component of each gwsa ic is generally less clustered by different time cycles and the spatial pattern shows distinct localized characteristics moreover two ics of precipitation show a phase difference of a month and the large response values of the first p ic reflect the process of rainfall in the piedmont of taihang mountain induced by the east asian monsoon by establishing a one to one correspondence between the gwsa ic and potential physical processes the driving factors that are highly related to gws changes in nc include precipitation evaporation coal mining and agricultural irrigation the changes of gws can be reasonably explained by these natural and anthropogenic driving factors from the intra annual scale the increase of gws in the middle of the year profits from the recharge of precipitation conversely the gws depletion in the first half of the year and the last stage are the combined effect of coal mining and agricultural irrigation as far as the current situation is concerned the implementation of the south to north water diversion project is one of the important measures to alleviate the contradiction between the supply and demand of water resources in nc zhang et al 2021 however the thorough relief of the groundwater crisis must start from controlling the source of groundwater depletion accordingly the accurate detection of gws changes and the comprehensive identification of driving factors can help to provide theoretical supports for establishing targeted regulation policies and finally achieve the sustainable utilization of groundwater credit authorship contribution statement tengfei feng methodology validation formal analysis investigation writing original draft yunzhong shen conceptualization methodology writing review editing qiujie chen methodology validation supervision fengwei wang validation writing review editing supervision xingfu zhang data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors are grateful to the two anonymous reviewers and the editor whose comments and suggestions have significantly improved the manuscript this work was primarily supported by the national natural science foundation of china grant numbers 42061134010 41974002 we thanks wei feng for his constructive suggestions and data assistance on the manuscript data available the data used in this paper can be downloaded from some references and public websites tongji reggrace2019 gravity field data can be referenced to chen et al 2020 which will be shortly uploaded to the international centre for global earth models http icgem gfz potsdam de series the gldas and wghm data were downloaded from https disc gsfc nasa gov datasets keywords gldas page 1 last accessed may 10 2021 and https doi pangaea de 10 1594 pangaea 918447 last accessed may 10 2021 respectively the evaporation and precipitation data were available at https www gleam eu last accessed march 15 2021 and http www hydroshare org resource 63c8cd8f63ec49ebabdca45826219a60 last accessed march 12 2021 respectively the groundwater level data of monitoring wells were available at http www cigem cgs gov cn last accessed april 20 2021 the data of agricultural irrigation water consumption industrial water consumption and production of coal mining were collected from http tjj shanxi gov cn http www hwcc gov cn and http www stats gov cn tjsj ndsj last accessed april 05 2021 the resource and environmental science and data center also should be given our sincere acknowledgments for providing us the ndvi dataset which were available at http www resdc cn last accessed april 15 2021 
3371,north china nc is faced groundwater shortage in the past decades to understand the characteristics of groundwater storage gws change in nc gws anomaly gwsa is analyzed by using independent component analysis ica with the high resolution time variable gravity field model tongji reggrace2019 and hydrological models according to the spatiotemporal characteristics of independent components ics the driving factors and corresponding driving mechanism of gws changes are further investigated results show that the gws in nc is decreased with a rate of 0 87 0 04 cm yr from january 2004 to december 2015 and the rate increased to 3 71 0 49 cm yr from january 2014 to december 2015 among the first four ics of gwsa the first and second ics ic1 and ic2 cooperatively reflect long term and intra annual gws changes caused by water consumption of coal mining and agricultural irrigation in northern and southern shanxi province with the correlation coefficients of 0 91 and 0 85 respectively ic3 indicates the signal of semi annual gws change related to agricultural irrigation water consumption in southern hebei province with a correlation coefficient of 0 85 besides ic4 suggests the effect of monsoon precipitation and evaporation in front of taihang mountain hence the driving factors including uneven spatiotemporal distribution of precipitation intense seasonal evaporation severe loss by coal mining coupled with exhaustive exploitation for irrigation jointly restrict the gws rise and fall at different time nodes keywords north china groundwater depletion grace independent component analysis driving factor 1 introduction water resource is indispensable for human survival as a primary source of freshwater groundwater plays a crucial role in sustaining industrial development agricultural irrigation and domestic activities feng et al 2013 yin et al 2018 zhao et al 2019 however heavily dependent on groundwater the development of human society and the associated increasing food demand have caused widespread water crises around the world especially in north china nc where groundwater storage gws is being depleted at an alarming rate consequently a series of ecological disasters such as land subsidence and soil salinization have been occurred which in turn have caused huge impacts on socio economic stability and sustainable development cao et al 2013 hao et al 2021 at present formulations of reasonable strategies for groundwater exploitation and utilization are of great importance in nc obviously the fundamental bases of those management strategies depend on effective monitoring of gws changes and in turn to determine the potential driving factors and mechanisms however limited by complex underground circumstances no reliable means are available to detect gws changes directly the conventional data acquisition methods including ground based measurement and numerical simulation cao et al 2013 qin et al 2013 feng et al 2013 have some shortcomings the ground based monitoring wells are easily affected by surrounding environment and with sparse spatial coverage hence which makes it nearly impossible to monitor large scale gws changes su et al 2020 as for the modeling method based on numerical simulation it is usually difficult to collect background information and field data for groundwater models comprehensively thus significant uncertainties are associated with such models zheng et al 2015 ebead et al 2017 fortunately by using the twin satellite observations of the gravity recovery and climate experiment grace the time variable gravity field models with various temporal and spatial resolutions have been developed to monitor the large scale surface mass transport and redistribution with unprecedented accuracy tapley et al 2004 rowlands 2005 ramillien et al 2011 among which the quantitative inversion of global or regional terrestrial water storage tws change is particularly prominent wahr 2004 schmidt et al 2006 syed et al 2008 xavier et al 2012 the sufficiently reliable information from grace observations in monitoring tws change also ushers in a new era of large scale gws change estimation tws signal from grace observations is defined as an integrated measure of all forms of water stored on and below the surface of the earth which mainly includes surface water storage sws snow water equivalent storage swes soil moisture storage sms and gws feng et al 2013 tang et al 2013 in other words after sws swes and sms are deducted from tws the remaining part can be regarded as gws which has been proved to be effective in estimating gws changes over many typical watersheds around the world such as india rodell et al 2009 tiwari et al 2009 central valley of california scanlon et al 2012 middle east voss et al 2013 forootan et al 2017 the time variable gravity field models from grace observations are also used to investigate gws change in nc previous studies involved mainly focused on estimating the gws depletion rates using existing grace models in different sub regions of nc over different periods moiwo et al 2009 2013 su et al 2011 feng et al 2013 2018 huang et al 2015 ebead et al 2017 pan et al 2017 to improve the accuracy of estimated gws some modified inversion methods specific to the actual characteristics in nc were proposed such as the point mass modeling method feng et al 2017 mascon solution based on the three cornered hat method zhao et al 2019 downscaling method yin et al 2018 and data assimilation method yin et al 2020 according to the achievements of previous studies it is indisputable that the groundwater in nc is seriously depleted and the depletion rate has been confidently estimated besides the driving factors of gws changes have been qualitatively discussed including the influence of reservoir regulation water diversion and coal transport tang et al 2013 the reducing precipitation and agricultural irrigation su et al 2020 and the damages of coal mining to groundwater in shanxi and its surrounding areas qiao et al 2011 chen et al 2020 the quantitative investigation of gws changes relative to the driving factors is of great importance nevertheless limited by the previous grace models the spatial resolution of gws changes in nc is only about 300 km and thus gws change signals are always regarded as a whole when discussing the driving factors however nc consists of several provinces with different natural and anthropogenic activities it is worthy to determine the gws changes and separate the impacts of different activities in different sub regions as well as to identify the veritable driving factors therefore some effective signal separation techniques should be employed to determine the prominent source signals with the development of high resolution gravity field models the gws change in nc is looking forward to achieving better spatial resolution by which the underlying source signals can be isolated more effectively and therefore the driving factors including natural and anthropogenic factors and the driving mechanism can be discussed and analyzed more comprehensively therefore the main objectives of this work focus on three aspects 1 to apply the latest gravity model tongji reggrace2019 chen et al 2021 to get gws anomaly gwsa estimation with a higher spatial resolution 2 to implement spatiotemporal decomposition for gwsa with independent component analysis ica approach and analyze the periodic characteristics of each source signal since gws change is a mixture of different periodic signals and long term trends produced by several kinds of physical processes 3 to determine the driving factors and driving mechanism for each gwsa source signal in the following sections section 2 briefly describes the study area data and methodology section 3 presents the independent components ics of gwsa based on ica decomposition section 4 discusses the driving factors and driving mechanisms finally the conclusions are drawn in section 5 2 study area data and methodology 2 1 study area the nc confined within 110 120 e and 34 44 n is one of the seven geographical regions in china the main provinces and municipalities include beijing tianjin shanxi and hebei fig 1 with an area of about 370000 km2 and a permanent population of about 140 million the mean annual temperature is 8 c 13 c and the perennial mean precipitation ranges from 500 to 600 mm cao et al 2013 yin et al 2018 there are four distinct seasons in nc with hot summer and cold winter which is a typical temperate monsoon climate as one of the main grain production bases in china nc has played a crucial role in guaranteeing food demand supplying about 30 of wheat and 20 of maize output each year guo and shen 2015a the planting pattern here is the annual double cropping system namely cultivated with a rotation between winter wheat october to june and summer maize june to october jeong et al 2014 pan et al 2017 however due to the limited and uneven distribution of precipitation a large amount of groundwater is required for crop irrigation furthermore nc is well known for its rich coal resources especially in shanxi where the annual output of raw coal reaches billions of tons chen et al 2020 unfortunately since the unreasonable coal mining ground subsidence and vegetation damage have occurred which eventually destroy the aquifer and cause a rapid loss of groundwater qiao et al 2011 xie et al 2018 according to the relevant researches many groundwater funnels have been formed in nc feng et al 2013 2 2 data 2 2 1 grace data in this study the tws anomaly twsa from january 2004 to december 2015 is computed with the new tongji reggrace2019 monthly gravity field model up to degree and order d o 180 chen et al 2021 which is a regularized solution and thereby can be used directly without further smoothing the degree one coefficients have been added with that from swenson et al 2008 the c20 coefficients are replaced by those derived from satellite laser ranging data cheng et al 2011 and glacial isostatic adjustment correction is also completed based on the model of peltier et al 2018 compared to the previous spherical harmonic models the tongji reggrace2019 model has a greatly enhanced spatial resolution of 1 1 chen et al 2021 after the mean field from 2004 to 2009 is removed the twsa time series is computed with the well known formula of wahr et al 1998 2004 and expressed with 0 5 0 5 gird in the form of equivalent water height ewh in which the positive and negative values represent wetter and dryer than normal respectively the 14 missing months over the study period in the twsa time series are filled with the cubic spline interpolation method 2 2 2 hydrological models two hydrological models used in this study include the global land data assimilation system gldas rodell et al 2004 pan et al 2017 https disc gsfc nasa gov datasets keywords gldas page 1 and the watergap global hydrology model wghm döll et al 2003 schmied et al 2020 https doi pangaea de https doi org 10 1594 pangaea 918447 the monthly grid datasets of the sms anomaly smsa and swes anomaly swesa are simulated by the noah lsm model of gldas 2 1 and these grid data are converted from 0 25 0 25 to 0 5 0 5 to reconcile with grace data the smsa data is expressed in the sum of 4 vertical layers with the depth of 0 10 10 40 40 100 100 200 cm respectively although the sws anomaly swsa in nc is reported to be extremely limited and often ignored in terrestrial based water resource analysis moiwo et al 2009 2013 we still calculate the swsa the total water storage anomalies of reservoirs rivers lakes and wetlands from wghm version 2 2d to isolate the gwsa from twsa more accurately moreover gwsa is also simulated by wghm 2 2d independently which is used to verify the gwsa derived from tongji reggrace2019 gravity field models 2 2 3 meteorological data precipitation data from january 2004 to december 2015 are obtained from the global monthly weighted precipitation product provided by hydroshare public repository xu 2020 which are estimated by merging several precipitation datasets with different scales based on generalized three cornered hat tch method compared to individual precipitation product tch based weighted precipitation data has the advantage that the random error is substantially reduced and is also better than those mean based merger precipitation data in reproducing the inter annual and seasonal variations xu et al 2020 the global land evaporation amsterdam model gleam is dedicated to estimating different components of land evaporation gleam aims to maximize the recovery of information on evaporation contained in current satellite observations of climatic and environmental variables miralles et al 2011 martens et al 2017 since its development in 2011 gleam has been continually revised and updated and a third version gleam v3 was released in 2017 in this work the monthly evaporation grid data of gleam v3 3b is used and resampled to a spatial resolution of 0 5 0 5 https www gleam eu 2 2 4 ground based measurement the groundwater level data of 123 wells including 52 unconfined wells and 71 confined wells shown in fig 1 are collected from groundwater level yearbook for china geological environment monitoring institute of china geological environment monitoring 2005 2013 https www cigem cgs gov cn spanning january 2005 to december 2013 after data quality is checked groundwater level time series of 96 wells are determined to be qualified the distribution map of specific yield for unconfined aquifer and storativity for confined aquifer in nc provided by feng et al 2018 ranges widely from 0 025 to 0 22 given the unevenly distributed wells we segmented the study area into the cells of 0 5 by 0 5 grid where each cell was assigned the mean value of all groundwater levels within it feng et al 2018 then gwsa in terms of ewh over the region is calculated with su et al 2020 1 gwsa well j 1 n s j h j cos θ j j 1 n cos θ j where n is the number of cells divided in study area s is the specific yield for unconfined aquifers or storativity for confined aquifers θ is cell s latitude h refers to the mean of groundwater level variations in each cell 2 2 5 human activities according to relevant statistics and research human activities including agricultural irrigation industrial development and coal mining are with large water consumption in nc cao et al 2013 moiwo et al 2013 chen et al 2020 the agricultural irrigation and industrial water consumption data are sorted out from shanxi provincial bureau of statistics https tjj shanxi gov cn haihe river water conservancy commission https www hwcc gov cn and china statistical yearbook national bureau of statistics of china 2004 2015 https www stats gov cn tjsj ndsj the two kinds of data are with a temporal resolution of 1 year and the same period data as grace are downloaded monthly and annual raw coal production data in shanxi are collected from shanxi provincial bureau of statistics and national bureau of statistics of china since the monthly data from april 2011 to february 2015 are missing we only use the available data when calculating the monthly average time series according to chen et al 2020 the water consumption q water can be estimated from raw coal production q coal with the equation q water μ q coal where the conversion coefficient μ m3 ton is 0 87 in shanxi xie et al 2018 chen et al 2020 2 2 6 vegetation coverage data as a bond to connect atmosphere water and soil land surface vegetation is a sensitive indicator to monitor global climate change cornelissen et al 2007 therefore as an important interaction parameter among the atmosphere hydrosphere and lithosphere vegetation index is usually used to monitor the dynamic changes of vegetation and reflect the status of regional soil erosion wardlow and egbert 2008 the most widely used vegetation index is the normalized difference vegetation index ndvi that represents the degree of vegetation coverage and vegetation growth pettorelli et al 2005 the used ndvi spatial distribution dataset provided by the resource and environmental science and data center https www resdc cn is generated through the maximum value composite mvc method based on spot satellite remote sensing data a 0 5 confidence level was used to obtain the maximum and minimum ndvi then ndviveg is the average of the maximum 0 5 ndvi value and ndvisoil is the average of the minimum 0 5 ndvi value with the temporal and spatial resolutions of 1 month and 1 km respectively the range of ndvi is 1 to 1 whose very low values smaller than 0 1 correspond to bare soil rock and zero indicates the water body ramachandra et al 2012 since we focus on the vegetation distribution a segmentation was implemented for the ndvi spatial distribution product to extract vegetation boundary by a threshold of 0 1 i e ndvi values less than 0 1 are excluded due to the small variation of forest and other vegetation in nc for a long time the monthly ndvi time series can be characterized as the changes of crops to a large extent 2 3 methodology 2 3 1 independent component analysis ica in theory geophysical observations such as gwsa can be regarded as a mixture of several periodical signals and long term trends from different physical processes these potential source signals are traditionally estimated by using least squares fitting however the long term trends are usually not perfectly linear in time and the periodical signals are often more complicated than the fundamental sinusoidal cycles forootan and kusche 2012 generally no prior information is known about the sources and mixing modes and thus the signal extraction is actually a blind source separation problem the ica approach is an efficient statistical technique for dealing with this kind of task which can separate the mixed signals into multiple statistically independent source signals by maximizing the high order statistics after the temporal means are removed the grid time series are stored in an m n matrix x x t j t 1 2 m j 1 2 n where t denotes observed epoch and j represents grid point the matrix x is firstly decomposed with principal component analysis pca as 2 x m n p m n e n n t where p is an orthogonal matrix and each column of p denotes a principal component pc e contains the orthogonal eigenvectors of x since pca allows to concentrate a large amount of variance in relatively few components the first r r n components explaining the maximum amount of variability present in the observations are selected for further ica analysis forootan and kusche 2012 banerjee and kumar 2018 then eq 2 is adjusted as 3 x m n p m r e r n t the derived pcs i e the column vectors of matrix p are uncorrelated but not mutually independent to derive independent components a unitary matrix w w 1 w 2 w r is introduced to rotate the pc matrix so that the column vectors are as independent as possible thus eq 3 is rewritten as 4 x m n p m r w r r w r r t e r n t s m r a r n t where s pw and each column of s represents an independent temporal component a ew and its column is usually interpreted as a spatial pattern forootan et al 2014 feng et al 2021 each temporal component along with the corresponding spatial pattern denotes an independent component ic once an appropriate w is given the ics can be uniquely determined on contrary the matrix w can be determined based on the condition that the column vectors of s are as independent as possible in this work the joint approximate diagonalization of eigenmatrices jade algorithm is used to estimate the rotation matrix due to its better separability and robustness the details for the jade algorithm can be referred to forootan et al 2012 2014 2 3 2 correlation analysis method pearson s correlation coefficient and grey absolute correlation degree are adopted to evaluate the relationships between gwsa and potential driving factors pearson s correlation coefficient is defined as the quotient of covariance and standard deviation between two random variables yin et al 2020 the grey absolute correlation degree is comprehensively determined by the approximate degree of slope between two time series its computational step can refer to mei 1992 the grey absolute correlation degree reflects the information differences between gwsa and the driving factors during the dynamic change process and thereby can effectively make up for some deficiencies of pearson s correlation coefficient for example the grey absolute correlation degree can analyze the impact of multiple factors simultaneously and rank their importance in addition pearson s correlation coefficient is only suitable for the identification of linear relationships while the grey absolute correlation degree has no such limitation 3 independent component decomposition of gwsa 3 1 accuracy assessment of gwsa derived from tongji reggrace2019 solution the latitude weighted time series of twsa is derived from tongji reggrace2019 and shown in fig 2 where a certain difference can be observed in the variation trends at different periods and thus the whole study period is divided into three periods first the tws decreases from january 2004 to december 2009 with the rate of 1 96 0 12 cm yr then increases from january 2010 to december 2013 with 0 72 0 27 cm yr due to the intensive precipitation fig 2 and then rapidly decreases again from january 2014 to december 2015 with the rate of 4 64 0 54 cm yr for the whole study period the tws exhibits a decreasing trend with the rate of 1 00 0 06 cm yr the above rates are estimated by the least squares fitting method huang et al 2015 and corresponding uncertainties are fitting error 1 sigma the twsa derived from grace models is the total water storage integrated over vertical columns to separate the gwsa hereinafter referred to as gwsa grace the smsa swesa and swsa are removed also the gwsa time series can be derived from the monitoring well called gwsa well and wghm model called gwsa wghm respectively the three gwsa time series are shown in fig 3 with the cross correlation coefficients are 0 86 between grace and wghm 0 81 between grace and well and 0 84 between wghm and well respectively indicating a high consistency in phase since this statistical metric mainly measures the match in timing huang et al 2015 to quantitatively analyze the difference between two gwsa time series the root mean squared error rmse is computed as follows 5 rmse 1 m t 1 m y t z t 2 where y and z represent the gwsa time series from different means and m is the number of epochs the rmse between gwsa grace and gwsa wghm is 3 37 cm which is probably due to the difference in original data collections and processing strategies between grace and wghm döll et al 2014 and feng et al 2017 pointed out that both the 2 2a and 2 2b versions of wghm are prone to overestimate the gws depletion signal in the nc compared to the independent estimation from grace and this overestimation is attributed to the strong underestimation of diffuse groundwater recharge from wghm döll et al 2014 besides an overestimation of the gws in the latest wghm 2 2d was also demonstrated by su et al 2020 relatively gwsa grace and gwsa well agree more favorably with the rmse of 1 94 cm due to the limited number of available monitoring wells it is difficult to reflect the holistic variation of gws in some large areas su et al 2020 notably both gwsa grace and gwsa well present a short term recovery benefit from the intensive precipitation from 2012 to 2014 indicating that grace and monitoring well are more sensitive to the actual change of gws wang et al 2017 during the whole study period the depletion rates of gwsa grace and gwsa wghm are 0 87 0 04 cm yr and 1 51 0 01 cm yr respectively however there are significant discrepancies of gws depletion rates in different periods especially from 2014 to 2015 the rates from gwsa grace and gwsa wghm are 3 71 0 49 cm yr and 2 11 0 07 cm yr respectively other studies also reported that nc experienced severe drought from 2014 to 2015 zhao et al 2019 moreover the gwsa well depletion rate from 2005 to 2013 is 0 80 0 03 cm yr which is basically consistent with 0 85 0 06 cm yr of gwsa grace while smaller than 1 43 0 01 cm yr of the gwsa wghm in the same period the linear trends of gwsa grace from previous studies and this work are summarized in table 1 in which our result is basically consistent with those in similar study areas the discrepancies in gws decrease rates could be attributed to the differences in 1 the actual coverage of study areas 2 the periods of data involved 3 different versions of grace and hydrological models for instance some studies used the early version of grace models which are inevitably contaminated by the leakage and amplitude damping effects the above differences will affect the computed twsa and hence the estimation of the gws depletion rate moreover we plot the spatial trend map of gwsa in fig 4 from which we can see that gws is depleted with a variable degree in different sub regions especially for the northern shanxi and south central hebei to sum up gwsa from tongji reggrace2019 is reliable in describing the water resource changes in nc and can be used for further analysis 3 2 spatiotemporal decomposition for grace derived gwsa as shown in fig 3 the gwsa in nc derived from tongji reggrace2019 is characterized by a primary long term trend superimposed seasonal and inter annual oscillations before performing the ica separation procedure it is necessary to check the non gaussianity of the data following forootan and kusche 2012 we compute the kurtosis of grid gwsa time series data with kurtosis x j e x j 4 e x j 2 2 3 where x j is the jth grid gwsa time series and e is the expectation operator the computed kurtosis values are summarized in fig 5 showing that 68 of grids exhibit the absolute kurtosis value over 0 5 and thus the gwsa time series data have high order statistical properties therefore ica is further employed to analyze the gwsa time series data the percentages of the cumulative variances of derived pcs are shown in fig 6 using the f test shen et al 2014 at the 95 significance level the first four pcs are dominant and contain about 89 of total variance are well separated from the rest pcs which can sufficiently represent the required gwsa signals thus the first four pcs were retained for further resolving four ics we rearranged ics in descending order according to their contribution ratios defined by liu et al 2017 since the order of ics is random the temporal components and spatial patterns of the first four ics are illustrated in fig 7 where the temporal components are normalized by dividing their standard deviations and the spatial patterns are scaled by multiplying the normalization factors forootan and kusche 2012 from ic1 with the contribution ratio of 36 a decreasing trend accompanied by periodic signals dominated by semi annual cycle is clustered in the northern shanxi coincidentally the remarkable gravity change in this area was also detected by using the slepian localization analysis method and terrestrial gravity measurements han et al 2021 in particular large signal damping can be seen in 2011 which is related to the substantial increase in coal mining and groundwater leakage accidents deng et al 2018 ic2 32 contribution ratio shows a mixed signal that contains intra and inter annual variations along with the long term trend ic3 18 contribution ratio reflects a concentration of semi annual cycle dominated over the southern hebei and the temporal component shows a slight rise and followed by a rapid decline from january 2013 to december 2014 which is in step with the precipitation in this period fig 2 in addition due to the dramatic decrease in precipitation after 2013 and the demand for agricultural irrigation the stored precipitation has been exhausted in 2014 and thus the groundwater presents a sharp fall in the sowing period from march to july 2015 it is worth mentioning that both ic2 and ic3 show sharp changes from november 2010 to february 2011 according to records a well documented extreme drought event jointly triggered by the arctic oscillation and la niña occurred in nc during this period shen et al 2012 huang et al 2015 especially central and southern nc are severely impacted which is highly consistent with ic2 and ic3 in spatial distribution ic4 14 contribution ratio is a significant annual signal over the whole nc with a large response in the east central hebei the hydro meteorological elements involved in the regional water cycle mainly include precipitation evaporation and runoff moiwo et al 2013 pan et al 2017 however the surface runoff is extremely limited in nc due to the extensive construction of dams in recent years moiwo et al 2009 2013 therefore we further perform ica decomposition for the grid time series of precipitation and evaporation respectively and show results in figs 8 and 9 as for precipitation the cumulative variance of the first two pcs is as high as 93 of the total variance hence the first two pcs are retained to derive two ics ic1 consists of both annual and semi annual signals although the spatial distribution of ic1 covers entire nc the intensity of response has obvious clustering characteristics the large response values are located in the windward slope of the piedmont of taihang yanshan mountains owing to the combined effect of sea surface temperature subtropical high east asian monsoon and topography when the sea possesses lower temperature and higher pressure sea land thermal difference leads to the phenomenon of atmospheric circulation and then generates the monsoon which can transport water vapor to nc however due to the forced uplift effect by the terrain of mountains precipitation is easy to form on the windward slope wang et al 2008 thus precipitations are mostly concentrated in the eastern foothills of taihang mountain and the southern foothills of yanshan mountain similar seasonal signals also exist in ic2 and the two ics are correlated after a month s time lag with a correlation coefficient of 0 6 besides the large response values of ic2 are mainly distributed in south central nc which is different from that of ic1 as for evaporation ic1 and ic2 show significant annual and semi annual variations respectively whose spatial distribution patterns are somewhat similar to that of precipitation namely ic1 covers the whole nc while ic2 is more concentrated in southern nc 4 driving factor and corresponding mechanism of the gws changes 4 1 driving factor determination of the gwsa ics generally the distribution patterns of gwsa depend on various forms of groundwater recharge or utilization therefore we can draw some appropriate inferences about the driving factors for each gwsa ic by considering the practical locations where signals are clustered as the most important water input way in nc there is no doubt that close relationships exist between precipitation and gwsa ics especially gwsa ic4 which can be considered as one of the potential driving factors of gws changes correspondingly evaporation should be treated equally however a large part of groundwater consumption is caused by human activities besides natural volatilization for example agricultural irrigation is by far the largest groundwater use in the study area moiwo et al 2013 feng et al 2013 according to the distribution map of ndvi fig 1 the southern hebei with ndvi values close to 0 8 is the major crop growing area winter wheat and summer maize interestingly this position is basically superposition with the spatial pattern of gwsa ic3 in addition both gwsa ic1 and gwsa ic2 reflect the gws changes in shanxi as we all know several large coalfields with a total area of 57 700 km2 mainly include datong ningwu xishan qinshui hedong huoxi are all located in shanxi fig 1 over the years the underground aquifers of mining areas have been seriously destroyed owing to unreasonable mining and a large amount of groundwater has been lost as a result qiao et al 2011 xie et al 2018 hence besides agricultural irrigation coal mining is another potential driving factor of gwsa ic1 and gwsa ic2 to a certain extent it should also be noted that the industry in beijing tianjin hebei urban agglomeration is well developed and its groundwater consumption cannot be ignored which is one of the possible driving factors notably one can reconstruct each gwsa ic by multiplying the temporal component with the corresponding spatial pattern which represents the actual gws changes figs 10 and 11 present the time series of coal mining water consumption and irrigation water consumption in shanxi respectively since the two time series show similar changes with a high correlation coefficient of 0 95 the correlations with the two potential driving factors are bound to be very close regardless of ic1 or ic2 thus it is difficult to distinguish which factor resulting in the change characteristics of ic1 and ic2 respectively moreover limited by the difficulties in defining the spatial distribution boundaries of ic1 and ic2 we cannot accurately extract the water consumption time series of irrigation coal mining and industrial development in two signal clustered areas from the water consumption time series of whole shanxi in view of the above situations we combine ic1 and ic2 to present the gwsa time series of the whole shanxi denoted by gwsa ic1 2 it can be seen from fig 10 that gwsa ic1 2 fluctuates greatly from 2004 to 2015 showing a decreasing trend on the whole while coal mining water consumption time series shows an increasing trend except 2009 and 2015 which is opposite to the gwsa ic1 2 completely a similar scene is true for irrigation water consumption time series fig 11 the pearson s correlation coefficients between gwsa ic1 2 and coal mining water consumption and irrigation water consumption are 0 91 and 0 85 respectively the significant negative correlations indicate that the increase of coal mining and agricultural irrigation is directly related to the reduction of gws and both of them are the important driving factors of gws changes in shanxi however since the magnitude are different between gwsa ic1 2 and the water consumption of coal mining and irrigation these two factors can only account for part of the gws depletion in shanxi thus there may be other factors that need further study different from coal mining water consumption and irrigation water consumption the industrial water consumption in shanxi is unstable fig 12 with the increased trends from 2004 to 2006 and 2009 to 2012 while decreasing rapidly from 2006 to 2009 and 2012 to 2015 the curve of industrial water consumption shows an inverse w like shape and appears no obvious causal relationship with gwsa ic1 2 with the pearson s correlation coefficient only 0 06 indicating that industrial development has little impact on gws changes for the reason that most of the industrial districts in shanxi are located in metropolises and the tap water used is generally from the surface water stored in reservoirs and rivers fig 13 illustrates the correlation analysis of gwsa ic3 time series and irrigation water consumption refer to winter wheat and summer maize in hebei as expected gwsa ic3 exhibits a declining trend on the contrary irrigation water consumption continually increases during the whole study period the pearson s correlation coefficient between gwsa ic3 and irrigation water consumption is as high as 0 85 indicating that irrigation groundwater pumping in this area has a great effect on the gws changes unusually although irrigation water consumption remains to increase from 2012 to 2013 gwsa gets a rise which is benefit from the abundant precipitation during this period and further demonstrate the importance of precipitation to gws wang et al 2017 furthermore fig 14 depicts the correlation analysis between gwsa ic3 and industrial water consumption in hebei where the industrial water consumption shows a decreasing fluctuation which is attributed to the constant optimization of industrial structures notwithstanding that the trend of industrial water consumption is similar to that of gwsa ic3 and the pearson s correlation coefficient between them reaches 0 58 this association is contrary to the theoretical relationship i e the water storage change should be positively correlated with the water replenishment factors and negatively correlated with the water consumption factors theoretically between the two variables chen et al 2020 therefore industrial development is not the main driving factor of gws reduction in southern hebei figs 15 and 16 illustrate the correlation analysis between gwsa ic4 and each of p ic1 and e ic1 respectively clearly gwsa ic4 presents twice upward trends in the first 7 years and a continuous decline during the remaining period although the correlation coefficients 0 30 for gwsa ic4 and p ic1 0 49 for gwsa ic4 and e ic1 indicate that gwsa ic4 is not highly correlated with the two hydro meteorological factors some perceptible associations can be revealed by comparing their time series from different sub periods for instance from 2012 to 2015 p ic1 first decreases and then increases and the gwsa ic4 shows the same behavior from 2007 to 2009 e ic1 fluctuates greatly while gwsa ic4 always moves in the opposite directions with roughly similar amplitudes therefore gwsa ic4 can represent the gws changes under the synergistic effect of annual monsoon precipitation and evaporation to a certain extent the relatively small correlation coefficients possibly because the relationships among three variables are hidden in the basin scale water budget equation tws change precipitation evaporation runoff moiwo et al 2013 pan et al 2017 this equation is directly related to tws change that gws is just one part of it and thus the evaporation involved includes the total evaporation quality of various water bodies moreover surface water and soil moisture are first replenished by precipitation and then converted to groundwater through a slow penetration process therefore it is difficult to determine the relationship between the three variables directly just based on the correlation analysis an in depth examination is needed by adopting other means we also implement the correlation analysis between p ic2 and e ic2 due to their similar spatial distributions as illustrated in fig 17 the change direction of p ic2 for any two consecutive years is basically the same as that of e ic2 except 2010 and 2011 the difference is mainly reflected in the magnitude indicating that p ic2 and e ic2 jointly reflect a hydrological cycle process in the south central nc as described above we identify the driving factors of gwsa by establishing a one to one correlation analysis between gwsa ics and the potential factors to ensure the reliability of the results we put each gwsa ic and preliminarily determined driving factors into a grey system use the grey absolute correlation analysis method to further evaluate the relational degree and compare the importance of each driving factor result is shown in fig 18 in terms of gwsa ic1 2 relational degree values of irrigation water consumption and coal mining water consumption are very close and greater than 0 7 indicating that two factors are indeed closely related to gws changes and the importance is almost equal especially relational degree values of irrigation and coal mining for gwsa ic1 2 and irrigation for gwsa ic3 are much larger than those of p ic1 and e ic1 for gwsa ic4 whose relational degree values with p ic1 and e ic1 are significantly improved compared to pearson s correlation coefficients which is a further confirmation of the driving factors for gwsa ic4 based on the above analysis the driving factors of gws changes in nc are finally determined which include precipitation evaporation agricultural irrigation and coal mining 4 2 driving mechanism analysis of gws changes natural factors refer to precipitation and evaporation without human intervention however part of groundwater abstracted by human activities flows back to the ground and the rest evaporates or runs away evaporation from gleam model thus is actually the sum of spontaneous and anthropogenic quantities we are not able to distinguish them because lack of effective means to estimate separately for this reason we focus on the driving mechanism discussion of joint impact by all factors the time series of gwsa precipitation and evaporation are reconstructed by corresponding ics i e the first four gwsa ics two p ics and two e ics respectively fig 19 plots the gwsa time series in nc and its driving factors at the monthly and seasonal scales respectively as shown in fig 19 a and e the changes of time series of precipitation and evaporation are highly consistent with the correlation coefficients of 0 91 and 0 95 under the monthly and seasonal scales respectively which suggests that these two variables are the main participants of hydrological circulation in nc moiwo et al 2013 comparing the monthly time series of gwsa and precipitation gws fluctuates in the wake of the fluctuations of precipitation and the changes of gws slightly lag behind precipitation because precipitation must experience a slowly ground penetration process to recharge groundwater in particular as mentioned in section 3 1 gws from 2012 to 2014 shows an obvious recovery due to the heavy rainfall from the averaged time series of each month fig 19 b and each season fig 19 f the precipitation amplitudes are generally high in summer june august and low in winter december february with a peak of 12 01 cm in july and a trough of 0 28 cm in january the significant difference between the maximum and minimum indicates that the intra annual distribution of precipitation in nc is extremely uneven according to fig 19 c some distinctive features in trends can be observed from the averaged gwsa time series of each month roughly taking july as a demarcation point gws continually declines throughout the first half of the year and then reaches the annual low in july 4 07 cm before increasing rapidly during july to august following by a gradual reduction again the intra annual pattern of gwsa divided into three stages is contributed by both natural and human impacts as we can see from the averaged time series of each month fig 19 d the coal mining water consumption increases prominently from february to june and then reaches a local peak 4 06 107 m3 in june resulting in a continual decline of gws in the first half year moreover the ndvi of each month ndvi is used to replace the irrigation water consumption highlights a bimodal distribution may and august within a year which matches with the growing season annual double cropping system of crops in nc among them may is the growth peak of winter wheat yang et al 2010 since the high demand for water and low precipitation groundwater is intensively pumped for irrigation resulting in a rapid decline of gws from may to june noting that early june is the harvest time of winter wheat the vegetation coverage in the planting area is narrowing out and thus the ndvi value decreases apparently meanwhile june to july is the seeding time of maize and other crops which means that groundwater withdrawal is required again therefore the rapid depletion of gws in the first stage is the common effect of coal mining and agricultural irrigation subsequently gws shows a sharp increase from july to august after experiencing a rainy season august is the growth peak of summer maize yang et al 2010 however the irrigation pressure with groundwater is effectively alleviated due to the accumulation of heavy rainfall in the last stage under the situation that winter wheat of next year is started to be sowed in early october and the coal mining water consumption increases from october gws decreases again from october to november however the decrease is limited which is still benefited from the past wet season and so that the dependence on groundwater is greatly reduced in summary the intra annual distribution characteristics of gwsa in nc are complicated and volatile and the driving factors jointly restrict the changes of gws at different time nodes 5 conclusions this contribution aims to quantify gws changes from january 2004 to december 2015 in nc by combining the grace data and hydrological models and then explore the driving factors leading to the gws changes according to the results from tongji reggrace2019 the gws in nc is depleted with a rate of 0 87 0 04 cm yr from january 2004 to december 2015 and this depletion increases to 3 71 0 49 cm yr from january 2014 to december 2015 meanwhile the gws depletion rate from monitoring well between january 2005 and december 2013 is 0 80 0 03 cm yr which is basically consistent with that from tongji reggrace2019 0 85 0 06 cm yr while smaller than the simulation of the wghm model 1 43 0 01 cm yr during the same period notably gwsa time series from tongji reggrace2019 and monitoring well present a short term increase benefit from the intensive precipitation from 2012 and 2014 while wghm does not show such a phenomenon indicating that the gws quantification based on grace and monitoring well is more practical than wghm model alone spatiotemporal decomposition is performed for gwsa precipitation and evaporation by the ica approach respectively in terms of gwsa the first four ics accounting for 89 of the total variance respectively reflect the intra or inter annual cycles of gws changes located in northern shanxi southern shanxi southern hebei and east central hebei arguably the temporal component of each gwsa ic is generally less clustered by different time cycles and the spatial pattern shows distinct localized characteristics moreover two ics of precipitation show a phase difference of a month and the large response values of the first p ic reflect the process of rainfall in the piedmont of taihang mountain induced by the east asian monsoon by establishing a one to one correspondence between the gwsa ic and potential physical processes the driving factors that are highly related to gws changes in nc include precipitation evaporation coal mining and agricultural irrigation the changes of gws can be reasonably explained by these natural and anthropogenic driving factors from the intra annual scale the increase of gws in the middle of the year profits from the recharge of precipitation conversely the gws depletion in the first half of the year and the last stage are the combined effect of coal mining and agricultural irrigation as far as the current situation is concerned the implementation of the south to north water diversion project is one of the important measures to alleviate the contradiction between the supply and demand of water resources in nc zhang et al 2021 however the thorough relief of the groundwater crisis must start from controlling the source of groundwater depletion accordingly the accurate detection of gws changes and the comprehensive identification of driving factors can help to provide theoretical supports for establishing targeted regulation policies and finally achieve the sustainable utilization of groundwater credit authorship contribution statement tengfei feng methodology validation formal analysis investigation writing original draft yunzhong shen conceptualization methodology writing review editing qiujie chen methodology validation supervision fengwei wang validation writing review editing supervision xingfu zhang data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors are grateful to the two anonymous reviewers and the editor whose comments and suggestions have significantly improved the manuscript this work was primarily supported by the national natural science foundation of china grant numbers 42061134010 41974002 we thanks wei feng for his constructive suggestions and data assistance on the manuscript data available the data used in this paper can be downloaded from some references and public websites tongji reggrace2019 gravity field data can be referenced to chen et al 2020 which will be shortly uploaded to the international centre for global earth models http icgem gfz potsdam de series the gldas and wghm data were downloaded from https disc gsfc nasa gov datasets keywords gldas page 1 last accessed may 10 2021 and https doi pangaea de 10 1594 pangaea 918447 last accessed may 10 2021 respectively the evaporation and precipitation data were available at https www gleam eu last accessed march 15 2021 and http www hydroshare org resource 63c8cd8f63ec49ebabdca45826219a60 last accessed march 12 2021 respectively the groundwater level data of monitoring wells were available at http www cigem cgs gov cn last accessed april 20 2021 the data of agricultural irrigation water consumption industrial water consumption and production of coal mining were collected from http tjj shanxi gov cn http www hwcc gov cn and http www stats gov cn tjsj ndsj last accessed april 05 2021 the resource and environmental science and data center also should be given our sincere acknowledgments for providing us the ndvi dataset which were available at http www resdc cn last accessed april 15 2021 
3372,this study presents the strengths of polynomial chaos kriging pck a new surrogate model that merges polynomial chaos extension pce and gaussian process with kriging variance this combination enabled streamflow prediction for extreme events that deviated significantly from the trained data space and allowed for quantifying predictive uncertainty robustly and efficiently the uncertainty quantification results to eight testing flood events through a modeling framework that applies generalized likelihood uncertainty estimation glue to surrogate models are as follows 1 pck outperformed pce and ordinary kriging ok in mimicking predictive and sensitive behaviors of the original model with a smaller sized training dataset 2 three surrogate models trained on the identical dataset exhibited equivalent predictability with the original model for six smaller events similar to their training data space however for two extreme events which differed significantly from the training set only pck was found to accurately predict the hydrograph and flood peaks 3 since two types of acceptance thresholds defined here as accuracy aimed or efficiency aimed threshold have their own pros and cons the type and size of the threshold should be determined depending on the availability of computational resources and the degree of accuracy needed 4 a new performance score is proposed here to assess the overall performance of the surrogate models this compensates for situations in which the performance of a surrogate model can be misjudged through individual indices of efficiency or accuracy in the process of uncertainty quantification keywords surrogate model polynomial chaos kriging uncertainty quantification extrapolation performance score 1 introduction floods have long been studied in practical and scientific fields because they cause severe damage to the environment and societies around the world hirabayashi et al 2013 ward et al 2013 timely and accurate predictions of extreme flood events play a pivotal role in decision making processes to mitigate risk ward et al 2013 sanders et al 2020 however predictions are confronted with various uncertainties due to incomplete understanding of the actual natural systems kim et al 2016c kim et al 2016b and unknown distributions of the parameters that are difficult to measure directly moradkhani and sorooshian 2008 kim and ivanov 2014 kim et al 2016a rigorous enforcement of high fidelity predictions through understanding quantifying and reducing such uncertainties often requires a calibration optimization or assimilation process that adjusts a modeling system to the available measurements e g streamflow beven and freer 2001 moradkhani and sorooshian 2008 tran and kim 2021a however this inverse type of modeling generally entails significant computational resources because it relies on a considerable number of repeated model runs for various scenarios liu and gupta 2007 keating et al 2010 beven and binley 2014 recently a very attractive solution has been developed and applied that can drastically reduce the computational costs for the model run this approach substitutes a high cost deterministic model with a cheap to run surrogate model that reproduces comparable physical properties but has a lower computational cost razavi et al 2012b asher et al 2015 tran et al 2020 ivanov et al 2021 surrogate models that originated in a wide range of disciplines are being developed and implemented for water resources problems razavi et al 2012a sargsyan et al 2014 dwelle et al 2019 tran et al 2020 the central premise for a surrogate model to provide results consistent with the original model is to be able to approximate the relationship between input and output similar to the original model smith 2013 asher et al 2015 however the current surrogate models based on this relationship cannot provide a reliable prognosis for outliers or extremes beyond the training data space although they generally have excellent predictive power for regions within the training data razavi et al 2012b asher et al 2015 matos et al 2017 tran et al 2020 this is because the surrogate model is adapted locally to a constrained number of training points also referred to as design sites and thus only sites close to the training space can be diagnosed bowden et al 2012 for example in the context of water resource problems there will be a high probability of extreme events that due to climate change have not been experienced in the past prein et al 2016 bao et al 2017 bloschl et al 2020 there is also the possibility that extreme events that deviate from recorded events will occur due to climate internal variability even assuming that climate stationarity is maintained matos et al 2017 kim et al 2018 doi and kim 2020 2021 therefore a common solution for ensuring the predictive power in the entire data space is to expand the data range of the design site to cover all possible cases schöbi et al 2017 however obtaining sufficient collections of extreme events for training is unfeasible so one needs to develop an alternative solution to ensure predictability for the events beyond the data space generalized likelihood uncertainty estimation glue one of the informal bayesian methods is an uncertainty quantification framework that has been frequently used in different research disciplines over the past 30 years more than 2 700 citations as of july 2021 from the web of science glue estimates the posterior distribution of model parameters following the concept of equifinality whereby various combinations of parameter values can provide equivalently accurate predictions beven and binley 1992 beven 2006 this concept was later reappraised by stedinger et al 2008 which found that glue does not account for nonnormal heteroscedastic and serially correlated model residuals it has been debated that it cannot reasonably reflect the sampling distribution of model error and cannot provide coherent estimate of prediction uncertainty mantovan and todini 2006 stedinger et al 2008 vrugt et al 2008 clark et al 2011 on the other hand it has also argued that those issues are rare or may have little effect on the overall performance of glue in uncertainty assessments many publications have confirmed the practical effectiveness of glue sadegh and vrugt 2013 beven and binley 2014 and comparisons with the formal bayesian based dream differential evolution adaptive metropolis can produce very similar estimates of uncertainty in total streamflow vrugt et al 2008 despite numerous in depth research on glue however setting up an acceptance threshold one of the most important features for determining the posterior distribution in the glue implementation appears to have received less attention this acceptance threshold has a direct impact on the accuracy and computational cost of glue blasone et al 2008a stedinger et al 2008 but has been arbitrarily determined as either an allowable degree of simulation error or a fixed ratio of the total number of simulations blasone et al 2008b vrugt et al 2008 the former approach is to repeat simulations continuously until the number that satisfies the desired accuracy is reached while the latter is to select only the top few percent of the simulation results performed basically the ability to obtain good behavioral results from both approaches is proportional to the number of simulations that is performing as many simulations as possible is a way to achieve better results but this is not always feasible and effective especially for models with many uncertain parameters and high computational cost beven and binley 2014 therefore it is of interest to better understand how the trade off between the accuracy and efficiency of glue varies according to the use of different acceptance thresholds the literature demonstrates that revolutionary surrogate modeling has been applied for many models and has proven its strengths in a wealth of publications however those studies simply focused on the development of new surrogate models and compared their accuracy with other models e g kriging support vector machines or radial basis functions razavi et al 2012a schöbi et al 2015 rajabi 2019 xing et al 2019 zhang et al 2020 based on multiple accuracy scores in their construction processes e g relative mean squared error leave one out error or leave one out cross validation blatman and sudret 2011 lüthen et al 2020 training a surrogate model with data of sufficiently large size can usually achieve high accuracy but unfortunately this may greatly reduce its efficiency razavi et al 2012b recalling that surrogate models are fashioned to offset the expensive computational cost of the original models one cannot simply sacrifice efficiency for a slight improvement in accuracy it is therefore paramount to strike a balance between accuracy and efficiency in order to fully exploit the power of surrogate models in this work a primary goal is to gain comprehensive knowledge of building a well organized surrogate model that can provide reliable ensemble results even for extreme events that deviate significantly from the training data space for this purpose we here present a new surrogate model named polynomial chaos kriging pck that combines the advantages of two well known surrogate models polynomial chaos expansion pce and kriging we also present a unified modeling framework that applies glue to the construction of the proposed surrogate model in this framework we investigate and discuss the effects of the acceptance threshold types on the model accuracy and efficiency finally we propose a new performance score that indicates how much better the accuracy and efficiency of the surrogate model are over the original model thereby providing a guideline for selecting an appropriate surrogate emulator 2 methodology 2 1 surrogate modeling polynomial chaos kriging we designed a surrogate model polynomial chaos kriging pck with the aim of combining the merits of both polynomial chaos expansion pce for capturing the global tendency of the original model with a set of orthogonal polynomials sudret 2008 and kriging for handling the local approximation at training points via gaussian processes echard et al 2011 while the pck model has been used and validated in the field of structural engineering with some common simple benchmarks of both smooth and non smooth outputs such as ishigami rosenbrock or sobol functions schöbi et al 2014 weinmeister et al 2018 leifsson et al 2020 little research has been done with it on water resources or geophysical problems such as extreme flood prediction for simplicity we denote a hydrological model of concern in the following form 1 y m x where m is a model with an input x including parameters θ states x and forcings u y denotes the corresponding model outputs i e quantity of interest qoi which can be a scalar quantity or a vector with multiple qois the number of inputs n x is equal to a summation of the number of parameters n p the number of states n s and the number of forcings n i once we have a training dataset for the input output relationship described in eq 1 we endeavor to construct a surrogate model m s u that supplants the original model m here the pck consists of two mathematical terms with respect to x 2 y m s u x pck x α 1 p ε α ψ α x σ 2 z x note that the first term on the right side α 1 p ε α ψ α x is equivalent to the mathematical expression of pce in eq s1 and serves as a trend function within the formulation in eq s4 of kriging ψ α x is the multivariate polynomials orthogonal to the random input x determined using the weiner askey scheme for uniform gaussian beta and gamma distributions xiu and karniadakis 2002 α is a multi index that identifies the components of the multivariate polynomials ε α is the unknown pce coefficients corresponding to ψ α x p denotes the number of polynomial basis terms or the number of pce coefficients that depends on n x and the polynomial degree p as 3 p n x p n x p in the second term of eq 2 σ 2 z x σ 2 is the variance or kriging variance of the gaussian process z x with zero mean and unit variance the gaussian process z x is characterized by an autocorrelation function between two arbitrary input samples x and x i e r x x r x x δ and its hyperparameters δ which represent the amplitude and the lengths of the correlation bachoc 2013 various autocorrelation functions can be used such as linear dirac exponential squared exponential or gaussian and matérn santner et al 2003 bachoc 2013 schöbi et al 2015 in this paper the matérn autocorrelation function is adopted as it was favored in previous studies schöbi et al 2015 lataniotis et al 2020 wang 2021 the pck was established through three primary procedures schöbi et al 2015 the first procedure was to estimate the pce coefficients ε α using several methods such as projection least square regression bayesian compressive sensing and least angle regression here we used the least angle regression lar method in estimating the pce coefficients because it has advantages in the presence of a large number of uncertain inputs it is suitable for both smooth and non smooth cases and it requires a smaller training dataset due to downsizing the number of coefficients that need to be estimated blatman and sudret 2011 tran and kim 2021b given the experimental design x x 1 x n x consisting of n x samples of model inputs x and the model outputs corresponding to x y y 1 y n x m x 1 m x n x the optimal pce coefficients can be estimated as blatman and sudret 2011 4 ε arg min ε h p 1 n x k 1 n x y k α 1 p ε α ψ α x k 2 λ ε 1 where k is an index for n x λ is a non negative constant and ε 1 is a regularization term that forces a minimization to favor the sparse solution computed as ε 1 α p ε α eq 4 is equivalent to 5 ε f t f 1 f t y where f is the n x p information matrix its generic term reads 6 f k α ψ α x k k 1 n x α 1 p the second procedure is to determine the parameter δ of the autocorrelation function and the gaussian process variance σ 2 the parameter δ can be obtained through a maximum likelihood estimate marrel et al 2008 or a leave one out cross validation bachoc 2013 the latter method was used in this work because it provides more robust results bachoc 2013 as 7 δ a r g m i n δ y t r δ 1 d i a g r δ 1 2 r δ 1 y where δ denotes the optimal δ r δ r x k 1 x k 2 δ is the correlation matrix of two samples x k 1 and x k 2 among the experimental design x with k 1 k 2 1 n x the third procedure is to optimize the gaussian variance σ 2 given x y r x x δ and ε α ψ α x wherein ε α ψ α x are considered candidates for the trend part of kriging with the number of p candidates α 1 p an iterative algorithm is then employed with p iterations the initialization α 1 is a pck with one single polynomial i e ε 1 ψ 1 x in the trend part iteratively the polynomials are added one by one to the trend part at each iteration the gaussian variance σ 2 is estimated as follows 8 σ 2 1 n x y f ε α t r δ 1 y f ε α α 1 p where r δ r x k 1 x k 2 δ is the optimal correlation matrix f is the information matrix computed as eq 6 for each iteration a surrogate model p c k α with a different variance σ 2 is constructed among the number of p constructed pcks an optimal pck with a minimal deviation from the original model result is selected schöbi et al 2015 to quantify this deviation a leave one out error in eq 9 is used blatman and sudret 2011 vapnik 2013 9 1 n x k 1 n x m x k p c k x k x k 2 where p c k x k denotes the pck model built by using the experimental design x k x 1 x 2 x k 1 x k 1 x n x with the size of n x 1 2 2 parameter inference using glue parameter inference is to deduce which values of uncertain parameters θ are likely to provide predictions consistent with observations from the inference results one can generate a posterior distribution of parameters given the observed streamflow and demonstrate the possible ensemble outcomes for that distribution the posterior distribution of θ conditioned on observations y obs is generally expressed using bayes rule as tarantola 2005 10 π θ y obs x u l y obs x u θ ρ θ where ρ θ is the prior distribution of θ generated based on their prior knowledge l y obs x u θ is the likelihood which represents the conditional probability of the model results given the set of parameters and π θ y obs x u is the posterior distribution of θ this study employs the glue the informal bayesian approach which is straightforward to implement and allows flexibility in choosing an informal likelihood function and its cutoff threshold beven 2006 this method avoids over conditioning and excludes some of the model parameter sets that may not ensure predictive performance beven and freer 2001 various likelihood functions can be utilized in the context of glue to characterize deviations for the shape peak and volume of a flood hydrograph simultaneously a combination of nash sutcliffe efficiency nse peak error pe and volume error ve is presented as a likelihood function l 11 l t 1 t y t obs y t 2 t 1 t y t obs y obs 2 y max obs y max y max obs v obs v v obs 3 where y t obs and y t are the observed and simulated streamflow at time t respectively t is the total number of time steps over the flood event y max obs and y max are the observed and simulated streamflow at peak respectively v obs and v denote the total volume of observed and simulated hydrographs respectively note that the sub equations in the three parentheses represent the complementary nse 1 n s e pe and ve respectively this likelihood function has a value in the range of 0 to 1 and the closer this value is to the minimum the smaller the error the cutoff threshold can be specified as either an allowable deviation of the likelihood function here named accuracy aimed threshold or a fixed ratio of the total number of simulations here named efficiency aimed threshold beven and freer 2001 vrugt et al 2008 the entire simulations performed are divided into the runs that satisfy behavioral or do not meet non behavioral this threshold condition where the behavioral runs are leveraged to trace out π θ y obs x u 2 3 a framework of a surrogate model based uncertainty quantification fig 1 presents a general framework for constructing pck and inferring the model parameters in a computationally efficient manner by coupling pck and glue generally one uses the set of inputs and outputs or the experimental design and model response of an original hydrological model box a to construct a pck surrogate model box b that allows for fast computation of the inverse inference for uncertain parameters of the hydrological model box c specifically in box a the experimental design x consists of n x sets of θ x and u wherein the θ values are chosen randomly from the uniform prior distribution ρ θ using latin hypercube sampling lhs the states x are initialized with zero vectors and the forcing u values are collected by using the climate data i e rainfall from historical events the corresponding response y values are then obtained by applying x to the hydrological model m box b illustrates the construction procedure of pck given x and y the pce coefficients ε α are first estimated by lar eq 4 given x y and the polynomial degree p the hyperparameter δ of the autocorrelation function r x x is then optimized as eq 7 once both ε α and δ are determined an iterative algorithm begins to optimize the gaussian variance σ 2 eq 8 and construct a surrogate pck eq 2 and this continues until p number of iterations among the p constructed pcks the pck having the smallest leave one out error computed in eq 9 is selected as the optimal pck once a surrogate model has been constructed one can use it for computationally inexpensive parameter inference glue box c provides the posterior or behavioral distribution of the parameters π θ y obs x u and the uncertain interval of the simulated streamflow y the latter predictions match with the observed streamflow y obs and satisfy the acceptance threshold in this study two types of acceptance thresholds the accuracy aimed threshold and the efficiency aimed threshold are unitized in glue θ and x are initialized similarly to box a while the forcing u values are used from potential future events that include possible extreme events 2 4 performance metrics to investigate how accurately the three surrogate models i e pce ordinary kriging ok and pck mimic the original model for the experimental design during the training process one often uses the leave one out error in eq 9 a smaller indicates a more accurate emulator for ensemble predictions assessment through deterministic and probabilistic measures is necessary the likelihood function l adopted in glue is also exploited as a deterministic measure for the probabilistic measures the continuously ranked probability score crps and spread spread are selected the crps measures the proximity between distributions of the ensemble predictions and observation at a single time step gneiting and raftery 2007 in this study the average of crps crps over a flood event in eq 12 is of concern its ideal value is equal to zero the second probabilistic metric spread signifies a dispersion of the ensemble predictions as compared to observation smaller values depict more reliable predictions fortin et al 2014 spread equals the square root of the average ensemble variance over the evaluation period as formulated in eq 13 12 crps 1 t t 1 t f y f y obs 2 d y 13 spread 1 t t 1 t 1 n e 1 l 1 n e y l y obs 2 where f y and f y obs are the cumulative distribution of the ensemble streamflow prediction and observation respectively at time t l is an index for the ensemble members of the model predictions with a size of n e other than the metrics above a new performance score ps is proposed that can evaluate the overall performance of surrogate models m s u by weighting the accuracy and efficiency of the surrogate model as compared to the original model 14 p s m s u d l m s u l m d g l u e m s u g l u e m 15 d l m s u l m l 1 n e l m s u l l m l 2 16 d g l u e m s u g l u e m r t m s u n runs m s u r t m n runs m where l m s u and l m signify the values of the likelihood function for the behavioral runs of the surrogate and original models respectively g l u e m s u and g l u e m are the total runtimes to attain the behavioral runs of the surrogate and original models by glue r t m s u and r t m denote the runtimes needed for a single run for the surrogate and original models respectively and n runs m s u and n runs m respectively signify the number of prior runs required to acquire a predefined number of behavioral runs that satisfy the condition of cutoff threshold the first term d l m s u l m represents the accuracy of the performance defined as the euclidean distance between the two ensemble sets l m s u and l m in eq 15 a smaller d l m s u l m indicates that the surrogate model has the equivalent accuracy as the original model and effectively replaced the original model on the other hand the second term d g l u e m s u g l u e m represents the efficiency performance defined as the relative difference in the total runtimes needed for uncertainty quantification if this term is small it means that the efficiency of a surrogate model is very good therefore the range of possible values of ps combining those two terms is from 0 to infinity when ps is close to 0 it means that the chosen surrogate model has accuracy similar to the original model and finishes the uncertainty quantification in a very short time when ps approaches infinity both the accuracy and efficiency of the surrogate model are very low 3 study design 3 1 study area and flood events the study area was the thu bon river mountainous basin located in central vietnam part of the monsoon region of the tropical continent fig 2 it covers an area of 3 208 km2 and has a very steep slope of 22 4 on average along a long flow path of 105 km the altitude ranges from 15 m at its outlet the nong son to 2 530 m at the highest point of the basin the average annual precipitation is over 2 000 mm year and most of the rain falls from september to december this region is vulnerable to inundation as it has experienced a number of torrential rains and severely damaging floods hourly hydrometeorological data including rainfall and discharge for all of the simulation experiments were obtained from the vietnam national centre for hydro meteorological forecasting https www nchmf gov vn the mean areal rainfall was calculated over the three rain gauge stations using the thiessen method and the potential evapotranspiration value was assumed to be zero during rainy events a total of eight testing flood events corresponding to low middle and high flows were specifically selected for the verification of the surrogate models table 1 and fig s1 information of dataset on training the surrogate models is addressed in sec 3 3 1 3 2 hydrological model in this study the well known nedbør afstrømnings model nam nielsen and hansen 1973 was employed nam is a conceptual parsimonious lumped hydrologic model containing five model states n s 5 and nine parameters n p 9 and a forcing i e rainfall n i 1 the five model states refer to the water contents on the surface u and in lower storage l overland flow of interflow if and base flow bf the nine parameters are the maximum water contents in surface storage um and lower storage lm the overland flow cqof the time constants for routing interflow ckif overland flow ck12 and base flow ckbf and the thresholds of the root zone for overland flow tof interflow tif and groundwater recharge tg table 2 using these states and parameters the model can control the amount of water stored in three different and mutually integrated storages i e surface lower zone and groundwater storage and three routing components i e overland flow interflow and base flow the nam has six outputs i e qois including the streamflow y and the five model states x u l of if bf that is y y x the y is the key qoi known as the primary objective of hydrological prediction and is often used to evaluate the capabilities of a hydrological model in producing accurate streamflow predictions the remaining qois are the updated states that are continuously used as the inputs for the next computational time steps 3 3 experimental setup this study highlights the robustness of pck in its ability to capture the original model sufficiently even with small experimental designs and also to predict extreme flood events that are very different from the training events compared to two popular surrogate models of pce and ok for more descriptions of pce and ok refer to s 1 and s 2 in the supplementary material respectively all experiments conducted for the three surrogate models are listed as follows 3 3 1 setup for constructing the surrogate models to construct the experimental design with the size n x we initialized the ensemble of the states as zero specified the ensemble of the parameters with the values sampled from the uniform prior distribution and generated random rainfall values over a bounded interval regarding the ensemble of forcings i e hourly rainfall in order to extract the rainfall data for training it was assumed that the range of possible rainfall was 0 to 20 mm hr the reason for assuming 20 mm hr was to use a value much smaller than the actual maximum rainfall 34 1 mm hr the largest value among the rainfall events in table 1 in order to emphasize the predictability of the surrogate models for events beyond the training data space the experimental design was established as n x 1 000 which was considered a reasonable size to adequately construct a surrogate model for nam tran et al 2020 for the polynomial degree p of pce and pck we chose 3 the most preferred value in prior studies fan et al 2016 wang et al 2017 hu et al 2019 tran and kim 2019 tran et al 2020 3 3 2 setup for the parameter sensitivity analysis once the surrogate models were constructed a sensitivity analysis sa of the nine parameters was performed to investigate how similar the sensitive behaviors of the surrogate models and nam were a sobol sensitivity analysis was selected since it has been extensively employed as one of the most effective and attractive methods sobol 2001 saltelli 2002 sudret 2008 our sa results were analyzed based on the main total order index s main of sobol see section s 3 calculated with 22 000 random runs as suggested in tran and kim 2019 their parameter sets were randomly generated by lhs these sa experiments were done for the four models nam pce ok and pck for the eight selected rainfall events 3 3 3 setup for the parameter inference glue was applied to infer the parameter uncertainties for the eight flood events and the two types of cutoff thresholds were adopted the first threshold was the accuracy aimed threshold that can control the accuracy and a value of 0 1 was specified as the threshold for the likelihood function l defined in eq 11 this threshold corresponds to a combination of accuracies of about 0 8 5 and 5 for nse pe and ve respectively tran and kim 2019 the implementation of glue can be stopped when 1 000 behavioral sets are attained or intentionally stopped when the number of random runs reaches 100 million even if 1 000 behavioral sets are not obtained the second threshold is the efficiency aimed threshold to control the efficiency and for a total of 100 000 random runs generated by lhs the acceptance rate of the top 1 was set as the threshold i e among 100 000 runs the 1 000 runs with higher accuracy were selected 4 results 4 1 training error for constructing surrogate models using the same experimental design with the same size n x 1 000 assembled in section 3 3 1 three surrogate models of pce ok and pck were constructed and the leave one out error was computed for six qois i e streamflow and the five model states as reported in fig 3 quantitative inspection of this figure indicates that pck always has a smaller value which outperforms both pce and ok in capturing the nam behavior while pce and ok have almost identical performance except for the two qois of u and of specifically the of pck is always 0 01 for all the qois and is about two to seven times smaller than that of pce and ok fig 3 thus pck was particularly effective in accurately estimating important qois such as y the primary output of interest u and of two model states that have a significant impact on runoff especially in the flood season for example the values computed for y are 0 006 0 0252 and 0 0248 and those for u are 0 004 0 0194 and 0 0121 for pck pce and ok respectively for of the pck value was about 4 4 and 7 2 times smaller compared to those of pce and ok respectively 4 2 parameter sensitivity of surrogate and original models the comparison results for the sensitivities of the nine parameters with respect to the four models are displayed in figs 4 and s2 a parameter with a large value of the sobol main index s main indicates that it is relatively sensitive to l overall several of the parameters cqof ck12 and lm are the most sensitive parameters but the more extreme the event the more absolute the influence of one parameter cqof see s main of cqof for the smallest event event 2 and the largest event event 8 in fig 4 a b rather than comparing the relative sensitivities among the parameters comparing the sensitivities between the three surrogate models and nam showed that the sensitivity results of pck were more consistent with those of nam than with those of pce and ok especially for the three sensitive parameters lm ck12 and cqof the similarity of these parameter sensitivities was further confirmed by calculating the coefficient of determination r2 for a 1 1 comparison of the main indices between the surrogates and nam for the eight rainfall events fig 4c among the three surrogate models the sensitivity similarity between pck and nam was the highest r2 0 83 whereas pce and ok were somewhat different from the sensitivity of the original model r2 0 54 and 0 48 respectively in summary the sensitivity analysis demonstrated that pck had parametric characteristics and behaviors comparable to nam 4 3 predictability skills of the surrogate models using the constructed surrogate models and the two types of cutoff thresholds designed in section 3 3 3 we quantified the uncertainty of the flood prediction by glue a total of eight selected flood events were used for this experiment table 1 first the results of glue using the accuracy aimed threshold of 0 1 are shown in figs 5 and 6 fig 5 shows the hydrographs predicted by nam and the three surrogate models pce ok and pck with a 95 confidence interval quantified from 1 000 behavioral runs of glue for the small to medium events events 1 to 6 the nam and the three surrogate models have very narrow uncertainty ranges and provide good results close to the observations however for the extreme flood events events 7 and 8 of the three surrogate models only pck provides satisfactory results i e close to the observations and nam we further clarified these latter results by comparing the quantitative magnitudes of the various accuracy metrics in fig 6 the values of l crps and s p r e a d show that pck outperforms pce and ok in characterizing the extreme flows events 7 and 8 all the values of l for pck are smaller than 0 1 and are almost equal to those of nam its values of crps and s p r e a d are equivalent to those of nam then we quantified the results of glue using an efficiency aimed threshold of 1 out of a total of 100 000 runs shown in figs 7 and 8 for the two extreme events only pck gave satisfactory results that agreed with the observations although its range of uncertainty was wide compared to nam for the rest of the normal sized events the simulated results of the surrogate models were all similar in terms of accuracy and uncertainty range fig 7 the values of l crps and s p r e a d reported in fig 8 further confirm that pck made more accurate predictions for all the events compared to the other surrogate models pce and ok the values of all the pck metrics are relatively similar to those of nam and some have better values on the other hand the values for pce and ok were greater giving worse results than those for nam and pck specifically the values of l mean of l crps and s p r e a d for pce were about 2 8 1 4 and 1 6 times larger than those for nam respectively at for event 7 and about 3 5 2 2 and 2 6 times larger for event 8 these values for ok were about 3 1 6 and 1 8 times larger than nam for event 7 and about 3 9 2 5 and 2 8 times larger for event 8 in comparing the flood peaks for the two extreme events pce and ok could not predict the observed peaks at all while pck did have some predictive ability 4 4 performance score of surrogate models to acceptance thresholds our evaluations of both the accuracy and the efficiency of the behavior sets were carried out simultaneously we used the performance score ps given in in eq 14 for this purpose and the changes in ps according to the different levels of criteria are shown in figs 9 and 10 first fig 9 shows the change in ps with respect to the accuracy aimed threshold for a fixed threshold both the denominator and numerator of the first term of ps in eq 14 have comparable values that is d l m s u l m o 0 so the difference in ps values was greatly affected by the second term d g l u e m s u g l u e m overall pck showed smaller ps values i e had better performance than pce and ok also the stricter the accuracy criterion that was applied the greater this performance difference was especially in the extreme events events 7 and 8 this was because only pck quickly provided behavior sets that satisfied the small acceptance thresholds in the cases of pce and ok the time for uncertainty quantification was much longer than that of pck and we could not find any behavior sets that satisfied the thresholds of 0 2 for pce and 0 4 for ok fig 10 shows the change in ps with respect to the efficiency aimed fixed threshold both the denominator and numerator of the second term of the ps have similar values that is d g l u e m s u g l u e m o 0 so the difference in ps values was greatly affected by the first term d l m s u l m therefore the performance difference depends on the difference in predictability for the behavior sets between the models as before pck showed smaller ps values i e had better performance than pce and ok and this trend was especially pronounced in the extreme events see fig 10g h 5 discussion 5 1 how can pck accurately diagnose extreme events theoretically a surrogate model has the predictive power of its original model provided that the amount of data required to construct it is sufficient therefore when past events are repeated countless times and serve as big data a surrogate model can become a great tool to replace the original model however in the absence of such sufficient data for a variety of reasons a surrogate model will not be properly constructed this is indeed problematic if one attempts to predict extreme events outside the training data space the results in section 4 demonstrated the promise of pck to perform better than conventional surrogate models in predicting unknown extreme events that is the potential data space that pck could simulate was much wider than that of pce and ok even though all three models were trained with the same experimental design training set this extraordinary capability of pck can be explained by its ability to grasp real trends with a set of orthogonal polynomials ψ α x associated with pce coefficients varying between 0 and 10 429 m3 s instead of using a trend as a fixed value e g 3 216 m3 s in ok it is further explained by an ability to broaden the predictable data space in combination with a stochastic kriging variance adding this variance stochastically can increase the overall accuracy of model simulations compared to single pce when predicting points located in a sparse or rare design data space bichon et al 2011 echard et al 2011 schöbi et al 2014 by coupling both the ability of pce to accurately capture global behaviors and the ability of ok to secure more prediction margins locally the possibility of effectively addressing the extrapolation tasks which is difficult with existing data driven models is confirmed 5 2 a practical compromise between accuracy and efficiency of uncertainty quantification from the simulation results presented in sections 4 3 and 4 4 it is apparent that both forms of the cutoff threshold have a significant impact on the accuracy and efficiency of the glue products each has its pros and cons so it is difficult to discern which method is better from a practical standpoint if one has enough computational resources and it is more important to attain accurate outcomes it is better to select the accuracy aimed threshold it can consistently guarantee the accuracy of the simulation fig 11 a although it can lead to a computational burden because a substantial number of model runs up to billions is entailed fig 11b therefore this method is impractical when applied to expensive computational models iorgulescu et al 2007 tran et al 2020 one should always mind the possibility that glue will fail to converge fig 9 if one desires too accurate results i e if the threshold selection is not appropriate on the other hand if one is concerned about non convergence or it is important to finalize the quantification of uncertainty within an allocated time use of the efficiency aimed threshold is recommended this method can control computational efficiency with a predefined number of random runs fig 11d but may provide merely ordinary performance if the predefined number is insufficient see the results of pce and ok for events 7 and 8 in figs 7 and 8 note that if one arbitrarily selects a small efficiency aimed threshold to yield more accurate behavioral results the disadvantage of the increased computational burden may be greater than the advantage of improved accuracy this is because the accuracy improvement of the posterior simulations is not linear with the change in the efficiency aimed thresholds for example reducing the threshold by a factor of 2 from 2 to 1 only reduces l averaged over the ensemble by about 1 13 1 10 1 05 and 1 21 times for nam pce ok and pck respectively fig 11c and s3 in summary the choice of the acceptance threshold needed to attain the behavioral set of a model depends on the availability of computational resources and the degree of accuracy desired and must be estimated a priori like the determination of hyperparameters 5 3 essentials of p s and superiority of pck in uncertainty quantification can it be said that this surrogate model has excellent performance if its calculation speed is faster than that of its original model or if its results are comparable with the original model in the process of quantifying uncertainty through inverse modeling simply comparing and evaluating computation speed and errors may fail to characterize a good surrogate model first comparing the time taken for simple iterative tasks as well as to obtain the results of uncertainty quantification it can be seen that the performances of the surrogate models considered here are significantly different in this study for simple iterations the computational speed was improved by about 500 times by pce and 600 times by ok and pck compared to nam this is because the cpu runtimes required for each single execution were approximately 2 5 10 4 sec for pce to 2 0 10 4 sec for ok and pck and about 0 12 sec for nam in the case of a single run or simple repeated runs such an improvement stands on its own merit however when uncertainty needs to be quantified through inverse modeling not limited to glue the effort required to retrieve the behavioral set does not always offset and this speedup does not always follow this is because the number of random runs n runs required to obtain 1 000 behavior sets varies greatly depending on the models or events used table 3 for example for event 4 the surrogate models have more random runs while for event 6 the original model does in addition the surrogate models pce and ok which were considered not able to adequately capture the original model failed to achieve a single behavioral set even after 100 million random runs see events 7 and 8 in such events where uncertainty quantification is time consuming using the surrogate models pce and ok to improve efficiency is of no benefit at all second when determining an appropriate size for an experimental design by a conventional approach using a relative error the performance of surrogate models may be misjudged in general the relative error of a surrogate model in this work decreases as the size of the experimental design increases and the error tends not to decrease beyond a certain size fig 12 a a surrogate model with a sufficiently small and guaranteed accuracy should be generated based on the experimental design of a certain size or larger i e the elbows in fig 12a schöbi et al 2017 tran and kim 2021a but securing the size of the design x also increases the time rt x required to construct the training set from the experimental design x to the model response y moreover the computational runtime rt of pck and ok tends to be longer as n x is larger fig 12b because it takes a substantial amount of time to compute the gaussian variance in eq 8 for pck and eq s7 for ok razavi et al 2012b vigsnes et al 2017 this leads to a sharp drop in the performance of pck as evidenced by the increase of ps in fig 12c in this study fig 12a shows that to construct pce ok and pck to be tolerant of sufficiently small errors e g 0 01 the sizes of their experimental designs i e the elbows in fig 12a need to be about 4 500 4 000 and 4 000 respectively this is an agreed upon standard from a traditional point of view for constructing a surrogate model however if uncertainty quantification is involved this criterion may need to be changed that is its performance efficiency and accuracy in the process of uncertainty quantification must be reflected in the performance evaluation of the surrogate model it can be seen that the result of fig 12c using the ps proposed in this study is very different from that of fig 12a an experimental design with a size of 4 500 for pce and 1 000 for pck is required to exhibit sufficiently high performance ps 0 001 which is very different from the results of fig 12a interestingly in the case of pck the size of the experimental design required was drastically reduced from 4 000 to 1 000 this indicates that one can build high performing surrogate models by leveraging a much more limited training data size fig s4 highlighting the superiority of pck in that it helps modelers dramatically save computational resources 5 4 counsels for improving outlier performance of machine learning predicting outliers extrapolation seems to be a long lasting challenge in applications of surrogate model as well as machine learning kratzert et al 2019 frame et al 2021 nearing et al 2021 tran et al 2021 in hypothesis this would not be a challenge if the amount of data for training was sufficient and covers all possible even low frequency extreme events however in reality it is difficult to collect such comprehensive observation data when targeting rare or exceptional phenomena this study underlines three keys that have been carried out to improve the predictive power of extreme events that do not have enough data and deviate significantly from the training data first high fidelity samples supervised by physical relationships as well as actual observations should be utilized to ensure sufficient learning when the number of training samples is small data generated by physics based models or governing equations can improve the understanding of physical processes in machine learning models ivanov et al 2021 the second suggestion is to enhance the extrapolation ability by extending the scope of the prediction space by additionally taking into account input noise and parameter or learnable network weights uncertainty fang et al 2020 abdar et al 2021 in this study model parameters were considered as uncertain input vectors and glue was used to quantify their uncertainty the last suggestion is to build a hybrid model by combining a predictive model with a model with extrapolation capabilities in this study pce a global model that plays the role of trend and kriging an interpolation model that computes local changes are combined instead of using pce other techniques that can increase extrapolation capabilities would be applied such as richardson extrapolation bach 2020 spectral mixing kernel wilson et al 2014 extrapolation algorithms bakas 2019 sparse identification of nonlinear dynamics champion et al 2019 and generative models hatakeyama sato and oyaizu 2021 in this work we used pck with the three aforementioned approaches to obtain satisfactory results for extreme values such a discovery will inspire novel designs of potentially more comprehensive hybrid models 6 summary and conclusion this study presents a new surrogate model pck that can not only efficiently quantify streamflow uncertainty but also accurately predict even extreme events that deviate significantly from the trained data space to enhance the extrapolation capability this study underlines three keys enriching the understanding of physical processes by establishing high fidelity training samples supervised by physical relationships broadening the scope of the prediction space by additionally taking into account input noise and parameter uncertainty and creating a new hybrid model e g pck that combines a local predictive model with a model with extrapolation capabilities the advantages of pck were confirmed by investigating how well the results of glue matched observations for eight testing flood events in the thu bon watershed compared to two well known surrogate models pce and ok the principal results of this study are summarized as follows first with a relatively small sized experimental design n x 1 000 pck outperforms pce and ok in mimicking the behavior of the original model with smaller leave one out error values for all qois also from the sensitivity analysis of nine parameters the sensitivity results of pck were closer to those of nam especially for the three most sensitive parameters cqof ck12 and lm than were pce and ok as a result of applying glue to the eight testing events for the three surrogate models trained on the identical dataset see the framework in fig 1 all of the surrogate models provided predictions equivalent to the original model for six smaller events that were similar to the training data space however for extreme events 7 and 8 which differed significantly from the training experimental design only pck was found to accurately predict the hydrograph and flood peaks regardless of the type of acceptance threshold accuracy or efficiency aimed while both pce and ok failed the simulation results in sections 4 3 and 4 4 confirmed that both types of acceptance thresholds had a significant impact on the performance of glue selecting the accuracy aimed threshold can ensure the consistent accuracy of uncertain simulations but can lead to a computational burden because of the substantial number of repeated runs needed in contrast the efficiency aimed threshold can control the computational efficiency with a predefined number of random runs but can only provide ordinary performance since each has its own pros and cons from a practical point of view the type and size of the threshold should be determined based on the availability of sufficient computational resources and the degree of accuracy needed the performance of a surrogate model cannot be said to be superior just because its calculation speed is faster than that of its original model or because its calculation results are comparable to the original s merely comparing and evaluating computational speed and error in a traditional way can lead to a misjudgment in selecting a good surrogate model in this study we propose a new performance score ps that can measure the overall performance including both accuracy and efficiency of a surrogate model compared to its original model this ps allows for assessing the actual achievement that arises in quantifying uncertainty and helps to efficiently construct surrogate models and save computational budgets by limiting unnecessary increases in their experimental design sizes ultimately the combined surrogate model presented here can not only predict outlier events that deviate significantly from the trained data space but can greatly reduce the computational burden of uncertainty quantification such a discovery will inspire novel designs of potentially more comprehensive surrogate c learning research as well as surrogate modeling credit authorship contribution statement vinh ngoc tran conceptualization methodology formal analysis investigation visualization writing original draft jongho kim conceptualization validation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the 2022 research fund of university of ulsan we acknowledge the uncertainty quantification group uqlab of eth zurich for sharing open source algorithms appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127716 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3372,this study presents the strengths of polynomial chaos kriging pck a new surrogate model that merges polynomial chaos extension pce and gaussian process with kriging variance this combination enabled streamflow prediction for extreme events that deviated significantly from the trained data space and allowed for quantifying predictive uncertainty robustly and efficiently the uncertainty quantification results to eight testing flood events through a modeling framework that applies generalized likelihood uncertainty estimation glue to surrogate models are as follows 1 pck outperformed pce and ordinary kriging ok in mimicking predictive and sensitive behaviors of the original model with a smaller sized training dataset 2 three surrogate models trained on the identical dataset exhibited equivalent predictability with the original model for six smaller events similar to their training data space however for two extreme events which differed significantly from the training set only pck was found to accurately predict the hydrograph and flood peaks 3 since two types of acceptance thresholds defined here as accuracy aimed or efficiency aimed threshold have their own pros and cons the type and size of the threshold should be determined depending on the availability of computational resources and the degree of accuracy needed 4 a new performance score is proposed here to assess the overall performance of the surrogate models this compensates for situations in which the performance of a surrogate model can be misjudged through individual indices of efficiency or accuracy in the process of uncertainty quantification keywords surrogate model polynomial chaos kriging uncertainty quantification extrapolation performance score 1 introduction floods have long been studied in practical and scientific fields because they cause severe damage to the environment and societies around the world hirabayashi et al 2013 ward et al 2013 timely and accurate predictions of extreme flood events play a pivotal role in decision making processes to mitigate risk ward et al 2013 sanders et al 2020 however predictions are confronted with various uncertainties due to incomplete understanding of the actual natural systems kim et al 2016c kim et al 2016b and unknown distributions of the parameters that are difficult to measure directly moradkhani and sorooshian 2008 kim and ivanov 2014 kim et al 2016a rigorous enforcement of high fidelity predictions through understanding quantifying and reducing such uncertainties often requires a calibration optimization or assimilation process that adjusts a modeling system to the available measurements e g streamflow beven and freer 2001 moradkhani and sorooshian 2008 tran and kim 2021a however this inverse type of modeling generally entails significant computational resources because it relies on a considerable number of repeated model runs for various scenarios liu and gupta 2007 keating et al 2010 beven and binley 2014 recently a very attractive solution has been developed and applied that can drastically reduce the computational costs for the model run this approach substitutes a high cost deterministic model with a cheap to run surrogate model that reproduces comparable physical properties but has a lower computational cost razavi et al 2012b asher et al 2015 tran et al 2020 ivanov et al 2021 surrogate models that originated in a wide range of disciplines are being developed and implemented for water resources problems razavi et al 2012a sargsyan et al 2014 dwelle et al 2019 tran et al 2020 the central premise for a surrogate model to provide results consistent with the original model is to be able to approximate the relationship between input and output similar to the original model smith 2013 asher et al 2015 however the current surrogate models based on this relationship cannot provide a reliable prognosis for outliers or extremes beyond the training data space although they generally have excellent predictive power for regions within the training data razavi et al 2012b asher et al 2015 matos et al 2017 tran et al 2020 this is because the surrogate model is adapted locally to a constrained number of training points also referred to as design sites and thus only sites close to the training space can be diagnosed bowden et al 2012 for example in the context of water resource problems there will be a high probability of extreme events that due to climate change have not been experienced in the past prein et al 2016 bao et al 2017 bloschl et al 2020 there is also the possibility that extreme events that deviate from recorded events will occur due to climate internal variability even assuming that climate stationarity is maintained matos et al 2017 kim et al 2018 doi and kim 2020 2021 therefore a common solution for ensuring the predictive power in the entire data space is to expand the data range of the design site to cover all possible cases schöbi et al 2017 however obtaining sufficient collections of extreme events for training is unfeasible so one needs to develop an alternative solution to ensure predictability for the events beyond the data space generalized likelihood uncertainty estimation glue one of the informal bayesian methods is an uncertainty quantification framework that has been frequently used in different research disciplines over the past 30 years more than 2 700 citations as of july 2021 from the web of science glue estimates the posterior distribution of model parameters following the concept of equifinality whereby various combinations of parameter values can provide equivalently accurate predictions beven and binley 1992 beven 2006 this concept was later reappraised by stedinger et al 2008 which found that glue does not account for nonnormal heteroscedastic and serially correlated model residuals it has been debated that it cannot reasonably reflect the sampling distribution of model error and cannot provide coherent estimate of prediction uncertainty mantovan and todini 2006 stedinger et al 2008 vrugt et al 2008 clark et al 2011 on the other hand it has also argued that those issues are rare or may have little effect on the overall performance of glue in uncertainty assessments many publications have confirmed the practical effectiveness of glue sadegh and vrugt 2013 beven and binley 2014 and comparisons with the formal bayesian based dream differential evolution adaptive metropolis can produce very similar estimates of uncertainty in total streamflow vrugt et al 2008 despite numerous in depth research on glue however setting up an acceptance threshold one of the most important features for determining the posterior distribution in the glue implementation appears to have received less attention this acceptance threshold has a direct impact on the accuracy and computational cost of glue blasone et al 2008a stedinger et al 2008 but has been arbitrarily determined as either an allowable degree of simulation error or a fixed ratio of the total number of simulations blasone et al 2008b vrugt et al 2008 the former approach is to repeat simulations continuously until the number that satisfies the desired accuracy is reached while the latter is to select only the top few percent of the simulation results performed basically the ability to obtain good behavioral results from both approaches is proportional to the number of simulations that is performing as many simulations as possible is a way to achieve better results but this is not always feasible and effective especially for models with many uncertain parameters and high computational cost beven and binley 2014 therefore it is of interest to better understand how the trade off between the accuracy and efficiency of glue varies according to the use of different acceptance thresholds the literature demonstrates that revolutionary surrogate modeling has been applied for many models and has proven its strengths in a wealth of publications however those studies simply focused on the development of new surrogate models and compared their accuracy with other models e g kriging support vector machines or radial basis functions razavi et al 2012a schöbi et al 2015 rajabi 2019 xing et al 2019 zhang et al 2020 based on multiple accuracy scores in their construction processes e g relative mean squared error leave one out error or leave one out cross validation blatman and sudret 2011 lüthen et al 2020 training a surrogate model with data of sufficiently large size can usually achieve high accuracy but unfortunately this may greatly reduce its efficiency razavi et al 2012b recalling that surrogate models are fashioned to offset the expensive computational cost of the original models one cannot simply sacrifice efficiency for a slight improvement in accuracy it is therefore paramount to strike a balance between accuracy and efficiency in order to fully exploit the power of surrogate models in this work a primary goal is to gain comprehensive knowledge of building a well organized surrogate model that can provide reliable ensemble results even for extreme events that deviate significantly from the training data space for this purpose we here present a new surrogate model named polynomial chaos kriging pck that combines the advantages of two well known surrogate models polynomial chaos expansion pce and kriging we also present a unified modeling framework that applies glue to the construction of the proposed surrogate model in this framework we investigate and discuss the effects of the acceptance threshold types on the model accuracy and efficiency finally we propose a new performance score that indicates how much better the accuracy and efficiency of the surrogate model are over the original model thereby providing a guideline for selecting an appropriate surrogate emulator 2 methodology 2 1 surrogate modeling polynomial chaos kriging we designed a surrogate model polynomial chaos kriging pck with the aim of combining the merits of both polynomial chaos expansion pce for capturing the global tendency of the original model with a set of orthogonal polynomials sudret 2008 and kriging for handling the local approximation at training points via gaussian processes echard et al 2011 while the pck model has been used and validated in the field of structural engineering with some common simple benchmarks of both smooth and non smooth outputs such as ishigami rosenbrock or sobol functions schöbi et al 2014 weinmeister et al 2018 leifsson et al 2020 little research has been done with it on water resources or geophysical problems such as extreme flood prediction for simplicity we denote a hydrological model of concern in the following form 1 y m x where m is a model with an input x including parameters θ states x and forcings u y denotes the corresponding model outputs i e quantity of interest qoi which can be a scalar quantity or a vector with multiple qois the number of inputs n x is equal to a summation of the number of parameters n p the number of states n s and the number of forcings n i once we have a training dataset for the input output relationship described in eq 1 we endeavor to construct a surrogate model m s u that supplants the original model m here the pck consists of two mathematical terms with respect to x 2 y m s u x pck x α 1 p ε α ψ α x σ 2 z x note that the first term on the right side α 1 p ε α ψ α x is equivalent to the mathematical expression of pce in eq s1 and serves as a trend function within the formulation in eq s4 of kriging ψ α x is the multivariate polynomials orthogonal to the random input x determined using the weiner askey scheme for uniform gaussian beta and gamma distributions xiu and karniadakis 2002 α is a multi index that identifies the components of the multivariate polynomials ε α is the unknown pce coefficients corresponding to ψ α x p denotes the number of polynomial basis terms or the number of pce coefficients that depends on n x and the polynomial degree p as 3 p n x p n x p in the second term of eq 2 σ 2 z x σ 2 is the variance or kriging variance of the gaussian process z x with zero mean and unit variance the gaussian process z x is characterized by an autocorrelation function between two arbitrary input samples x and x i e r x x r x x δ and its hyperparameters δ which represent the amplitude and the lengths of the correlation bachoc 2013 various autocorrelation functions can be used such as linear dirac exponential squared exponential or gaussian and matérn santner et al 2003 bachoc 2013 schöbi et al 2015 in this paper the matérn autocorrelation function is adopted as it was favored in previous studies schöbi et al 2015 lataniotis et al 2020 wang 2021 the pck was established through three primary procedures schöbi et al 2015 the first procedure was to estimate the pce coefficients ε α using several methods such as projection least square regression bayesian compressive sensing and least angle regression here we used the least angle regression lar method in estimating the pce coefficients because it has advantages in the presence of a large number of uncertain inputs it is suitable for both smooth and non smooth cases and it requires a smaller training dataset due to downsizing the number of coefficients that need to be estimated blatman and sudret 2011 tran and kim 2021b given the experimental design x x 1 x n x consisting of n x samples of model inputs x and the model outputs corresponding to x y y 1 y n x m x 1 m x n x the optimal pce coefficients can be estimated as blatman and sudret 2011 4 ε arg min ε h p 1 n x k 1 n x y k α 1 p ε α ψ α x k 2 λ ε 1 where k is an index for n x λ is a non negative constant and ε 1 is a regularization term that forces a minimization to favor the sparse solution computed as ε 1 α p ε α eq 4 is equivalent to 5 ε f t f 1 f t y where f is the n x p information matrix its generic term reads 6 f k α ψ α x k k 1 n x α 1 p the second procedure is to determine the parameter δ of the autocorrelation function and the gaussian process variance σ 2 the parameter δ can be obtained through a maximum likelihood estimate marrel et al 2008 or a leave one out cross validation bachoc 2013 the latter method was used in this work because it provides more robust results bachoc 2013 as 7 δ a r g m i n δ y t r δ 1 d i a g r δ 1 2 r δ 1 y where δ denotes the optimal δ r δ r x k 1 x k 2 δ is the correlation matrix of two samples x k 1 and x k 2 among the experimental design x with k 1 k 2 1 n x the third procedure is to optimize the gaussian variance σ 2 given x y r x x δ and ε α ψ α x wherein ε α ψ α x are considered candidates for the trend part of kriging with the number of p candidates α 1 p an iterative algorithm is then employed with p iterations the initialization α 1 is a pck with one single polynomial i e ε 1 ψ 1 x in the trend part iteratively the polynomials are added one by one to the trend part at each iteration the gaussian variance σ 2 is estimated as follows 8 σ 2 1 n x y f ε α t r δ 1 y f ε α α 1 p where r δ r x k 1 x k 2 δ is the optimal correlation matrix f is the information matrix computed as eq 6 for each iteration a surrogate model p c k α with a different variance σ 2 is constructed among the number of p constructed pcks an optimal pck with a minimal deviation from the original model result is selected schöbi et al 2015 to quantify this deviation a leave one out error in eq 9 is used blatman and sudret 2011 vapnik 2013 9 1 n x k 1 n x m x k p c k x k x k 2 where p c k x k denotes the pck model built by using the experimental design x k x 1 x 2 x k 1 x k 1 x n x with the size of n x 1 2 2 parameter inference using glue parameter inference is to deduce which values of uncertain parameters θ are likely to provide predictions consistent with observations from the inference results one can generate a posterior distribution of parameters given the observed streamflow and demonstrate the possible ensemble outcomes for that distribution the posterior distribution of θ conditioned on observations y obs is generally expressed using bayes rule as tarantola 2005 10 π θ y obs x u l y obs x u θ ρ θ where ρ θ is the prior distribution of θ generated based on their prior knowledge l y obs x u θ is the likelihood which represents the conditional probability of the model results given the set of parameters and π θ y obs x u is the posterior distribution of θ this study employs the glue the informal bayesian approach which is straightforward to implement and allows flexibility in choosing an informal likelihood function and its cutoff threshold beven 2006 this method avoids over conditioning and excludes some of the model parameter sets that may not ensure predictive performance beven and freer 2001 various likelihood functions can be utilized in the context of glue to characterize deviations for the shape peak and volume of a flood hydrograph simultaneously a combination of nash sutcliffe efficiency nse peak error pe and volume error ve is presented as a likelihood function l 11 l t 1 t y t obs y t 2 t 1 t y t obs y obs 2 y max obs y max y max obs v obs v v obs 3 where y t obs and y t are the observed and simulated streamflow at time t respectively t is the total number of time steps over the flood event y max obs and y max are the observed and simulated streamflow at peak respectively v obs and v denote the total volume of observed and simulated hydrographs respectively note that the sub equations in the three parentheses represent the complementary nse 1 n s e pe and ve respectively this likelihood function has a value in the range of 0 to 1 and the closer this value is to the minimum the smaller the error the cutoff threshold can be specified as either an allowable deviation of the likelihood function here named accuracy aimed threshold or a fixed ratio of the total number of simulations here named efficiency aimed threshold beven and freer 2001 vrugt et al 2008 the entire simulations performed are divided into the runs that satisfy behavioral or do not meet non behavioral this threshold condition where the behavioral runs are leveraged to trace out π θ y obs x u 2 3 a framework of a surrogate model based uncertainty quantification fig 1 presents a general framework for constructing pck and inferring the model parameters in a computationally efficient manner by coupling pck and glue generally one uses the set of inputs and outputs or the experimental design and model response of an original hydrological model box a to construct a pck surrogate model box b that allows for fast computation of the inverse inference for uncertain parameters of the hydrological model box c specifically in box a the experimental design x consists of n x sets of θ x and u wherein the θ values are chosen randomly from the uniform prior distribution ρ θ using latin hypercube sampling lhs the states x are initialized with zero vectors and the forcing u values are collected by using the climate data i e rainfall from historical events the corresponding response y values are then obtained by applying x to the hydrological model m box b illustrates the construction procedure of pck given x and y the pce coefficients ε α are first estimated by lar eq 4 given x y and the polynomial degree p the hyperparameter δ of the autocorrelation function r x x is then optimized as eq 7 once both ε α and δ are determined an iterative algorithm begins to optimize the gaussian variance σ 2 eq 8 and construct a surrogate pck eq 2 and this continues until p number of iterations among the p constructed pcks the pck having the smallest leave one out error computed in eq 9 is selected as the optimal pck once a surrogate model has been constructed one can use it for computationally inexpensive parameter inference glue box c provides the posterior or behavioral distribution of the parameters π θ y obs x u and the uncertain interval of the simulated streamflow y the latter predictions match with the observed streamflow y obs and satisfy the acceptance threshold in this study two types of acceptance thresholds the accuracy aimed threshold and the efficiency aimed threshold are unitized in glue θ and x are initialized similarly to box a while the forcing u values are used from potential future events that include possible extreme events 2 4 performance metrics to investigate how accurately the three surrogate models i e pce ordinary kriging ok and pck mimic the original model for the experimental design during the training process one often uses the leave one out error in eq 9 a smaller indicates a more accurate emulator for ensemble predictions assessment through deterministic and probabilistic measures is necessary the likelihood function l adopted in glue is also exploited as a deterministic measure for the probabilistic measures the continuously ranked probability score crps and spread spread are selected the crps measures the proximity between distributions of the ensemble predictions and observation at a single time step gneiting and raftery 2007 in this study the average of crps crps over a flood event in eq 12 is of concern its ideal value is equal to zero the second probabilistic metric spread signifies a dispersion of the ensemble predictions as compared to observation smaller values depict more reliable predictions fortin et al 2014 spread equals the square root of the average ensemble variance over the evaluation period as formulated in eq 13 12 crps 1 t t 1 t f y f y obs 2 d y 13 spread 1 t t 1 t 1 n e 1 l 1 n e y l y obs 2 where f y and f y obs are the cumulative distribution of the ensemble streamflow prediction and observation respectively at time t l is an index for the ensemble members of the model predictions with a size of n e other than the metrics above a new performance score ps is proposed that can evaluate the overall performance of surrogate models m s u by weighting the accuracy and efficiency of the surrogate model as compared to the original model 14 p s m s u d l m s u l m d g l u e m s u g l u e m 15 d l m s u l m l 1 n e l m s u l l m l 2 16 d g l u e m s u g l u e m r t m s u n runs m s u r t m n runs m where l m s u and l m signify the values of the likelihood function for the behavioral runs of the surrogate and original models respectively g l u e m s u and g l u e m are the total runtimes to attain the behavioral runs of the surrogate and original models by glue r t m s u and r t m denote the runtimes needed for a single run for the surrogate and original models respectively and n runs m s u and n runs m respectively signify the number of prior runs required to acquire a predefined number of behavioral runs that satisfy the condition of cutoff threshold the first term d l m s u l m represents the accuracy of the performance defined as the euclidean distance between the two ensemble sets l m s u and l m in eq 15 a smaller d l m s u l m indicates that the surrogate model has the equivalent accuracy as the original model and effectively replaced the original model on the other hand the second term d g l u e m s u g l u e m represents the efficiency performance defined as the relative difference in the total runtimes needed for uncertainty quantification if this term is small it means that the efficiency of a surrogate model is very good therefore the range of possible values of ps combining those two terms is from 0 to infinity when ps is close to 0 it means that the chosen surrogate model has accuracy similar to the original model and finishes the uncertainty quantification in a very short time when ps approaches infinity both the accuracy and efficiency of the surrogate model are very low 3 study design 3 1 study area and flood events the study area was the thu bon river mountainous basin located in central vietnam part of the monsoon region of the tropical continent fig 2 it covers an area of 3 208 km2 and has a very steep slope of 22 4 on average along a long flow path of 105 km the altitude ranges from 15 m at its outlet the nong son to 2 530 m at the highest point of the basin the average annual precipitation is over 2 000 mm year and most of the rain falls from september to december this region is vulnerable to inundation as it has experienced a number of torrential rains and severely damaging floods hourly hydrometeorological data including rainfall and discharge for all of the simulation experiments were obtained from the vietnam national centre for hydro meteorological forecasting https www nchmf gov vn the mean areal rainfall was calculated over the three rain gauge stations using the thiessen method and the potential evapotranspiration value was assumed to be zero during rainy events a total of eight testing flood events corresponding to low middle and high flows were specifically selected for the verification of the surrogate models table 1 and fig s1 information of dataset on training the surrogate models is addressed in sec 3 3 1 3 2 hydrological model in this study the well known nedbør afstrømnings model nam nielsen and hansen 1973 was employed nam is a conceptual parsimonious lumped hydrologic model containing five model states n s 5 and nine parameters n p 9 and a forcing i e rainfall n i 1 the five model states refer to the water contents on the surface u and in lower storage l overland flow of interflow if and base flow bf the nine parameters are the maximum water contents in surface storage um and lower storage lm the overland flow cqof the time constants for routing interflow ckif overland flow ck12 and base flow ckbf and the thresholds of the root zone for overland flow tof interflow tif and groundwater recharge tg table 2 using these states and parameters the model can control the amount of water stored in three different and mutually integrated storages i e surface lower zone and groundwater storage and three routing components i e overland flow interflow and base flow the nam has six outputs i e qois including the streamflow y and the five model states x u l of if bf that is y y x the y is the key qoi known as the primary objective of hydrological prediction and is often used to evaluate the capabilities of a hydrological model in producing accurate streamflow predictions the remaining qois are the updated states that are continuously used as the inputs for the next computational time steps 3 3 experimental setup this study highlights the robustness of pck in its ability to capture the original model sufficiently even with small experimental designs and also to predict extreme flood events that are very different from the training events compared to two popular surrogate models of pce and ok for more descriptions of pce and ok refer to s 1 and s 2 in the supplementary material respectively all experiments conducted for the three surrogate models are listed as follows 3 3 1 setup for constructing the surrogate models to construct the experimental design with the size n x we initialized the ensemble of the states as zero specified the ensemble of the parameters with the values sampled from the uniform prior distribution and generated random rainfall values over a bounded interval regarding the ensemble of forcings i e hourly rainfall in order to extract the rainfall data for training it was assumed that the range of possible rainfall was 0 to 20 mm hr the reason for assuming 20 mm hr was to use a value much smaller than the actual maximum rainfall 34 1 mm hr the largest value among the rainfall events in table 1 in order to emphasize the predictability of the surrogate models for events beyond the training data space the experimental design was established as n x 1 000 which was considered a reasonable size to adequately construct a surrogate model for nam tran et al 2020 for the polynomial degree p of pce and pck we chose 3 the most preferred value in prior studies fan et al 2016 wang et al 2017 hu et al 2019 tran and kim 2019 tran et al 2020 3 3 2 setup for the parameter sensitivity analysis once the surrogate models were constructed a sensitivity analysis sa of the nine parameters was performed to investigate how similar the sensitive behaviors of the surrogate models and nam were a sobol sensitivity analysis was selected since it has been extensively employed as one of the most effective and attractive methods sobol 2001 saltelli 2002 sudret 2008 our sa results were analyzed based on the main total order index s main of sobol see section s 3 calculated with 22 000 random runs as suggested in tran and kim 2019 their parameter sets were randomly generated by lhs these sa experiments were done for the four models nam pce ok and pck for the eight selected rainfall events 3 3 3 setup for the parameter inference glue was applied to infer the parameter uncertainties for the eight flood events and the two types of cutoff thresholds were adopted the first threshold was the accuracy aimed threshold that can control the accuracy and a value of 0 1 was specified as the threshold for the likelihood function l defined in eq 11 this threshold corresponds to a combination of accuracies of about 0 8 5 and 5 for nse pe and ve respectively tran and kim 2019 the implementation of glue can be stopped when 1 000 behavioral sets are attained or intentionally stopped when the number of random runs reaches 100 million even if 1 000 behavioral sets are not obtained the second threshold is the efficiency aimed threshold to control the efficiency and for a total of 100 000 random runs generated by lhs the acceptance rate of the top 1 was set as the threshold i e among 100 000 runs the 1 000 runs with higher accuracy were selected 4 results 4 1 training error for constructing surrogate models using the same experimental design with the same size n x 1 000 assembled in section 3 3 1 three surrogate models of pce ok and pck were constructed and the leave one out error was computed for six qois i e streamflow and the five model states as reported in fig 3 quantitative inspection of this figure indicates that pck always has a smaller value which outperforms both pce and ok in capturing the nam behavior while pce and ok have almost identical performance except for the two qois of u and of specifically the of pck is always 0 01 for all the qois and is about two to seven times smaller than that of pce and ok fig 3 thus pck was particularly effective in accurately estimating important qois such as y the primary output of interest u and of two model states that have a significant impact on runoff especially in the flood season for example the values computed for y are 0 006 0 0252 and 0 0248 and those for u are 0 004 0 0194 and 0 0121 for pck pce and ok respectively for of the pck value was about 4 4 and 7 2 times smaller compared to those of pce and ok respectively 4 2 parameter sensitivity of surrogate and original models the comparison results for the sensitivities of the nine parameters with respect to the four models are displayed in figs 4 and s2 a parameter with a large value of the sobol main index s main indicates that it is relatively sensitive to l overall several of the parameters cqof ck12 and lm are the most sensitive parameters but the more extreme the event the more absolute the influence of one parameter cqof see s main of cqof for the smallest event event 2 and the largest event event 8 in fig 4 a b rather than comparing the relative sensitivities among the parameters comparing the sensitivities between the three surrogate models and nam showed that the sensitivity results of pck were more consistent with those of nam than with those of pce and ok especially for the three sensitive parameters lm ck12 and cqof the similarity of these parameter sensitivities was further confirmed by calculating the coefficient of determination r2 for a 1 1 comparison of the main indices between the surrogates and nam for the eight rainfall events fig 4c among the three surrogate models the sensitivity similarity between pck and nam was the highest r2 0 83 whereas pce and ok were somewhat different from the sensitivity of the original model r2 0 54 and 0 48 respectively in summary the sensitivity analysis demonstrated that pck had parametric characteristics and behaviors comparable to nam 4 3 predictability skills of the surrogate models using the constructed surrogate models and the two types of cutoff thresholds designed in section 3 3 3 we quantified the uncertainty of the flood prediction by glue a total of eight selected flood events were used for this experiment table 1 first the results of glue using the accuracy aimed threshold of 0 1 are shown in figs 5 and 6 fig 5 shows the hydrographs predicted by nam and the three surrogate models pce ok and pck with a 95 confidence interval quantified from 1 000 behavioral runs of glue for the small to medium events events 1 to 6 the nam and the three surrogate models have very narrow uncertainty ranges and provide good results close to the observations however for the extreme flood events events 7 and 8 of the three surrogate models only pck provides satisfactory results i e close to the observations and nam we further clarified these latter results by comparing the quantitative magnitudes of the various accuracy metrics in fig 6 the values of l crps and s p r e a d show that pck outperforms pce and ok in characterizing the extreme flows events 7 and 8 all the values of l for pck are smaller than 0 1 and are almost equal to those of nam its values of crps and s p r e a d are equivalent to those of nam then we quantified the results of glue using an efficiency aimed threshold of 1 out of a total of 100 000 runs shown in figs 7 and 8 for the two extreme events only pck gave satisfactory results that agreed with the observations although its range of uncertainty was wide compared to nam for the rest of the normal sized events the simulated results of the surrogate models were all similar in terms of accuracy and uncertainty range fig 7 the values of l crps and s p r e a d reported in fig 8 further confirm that pck made more accurate predictions for all the events compared to the other surrogate models pce and ok the values of all the pck metrics are relatively similar to those of nam and some have better values on the other hand the values for pce and ok were greater giving worse results than those for nam and pck specifically the values of l mean of l crps and s p r e a d for pce were about 2 8 1 4 and 1 6 times larger than those for nam respectively at for event 7 and about 3 5 2 2 and 2 6 times larger for event 8 these values for ok were about 3 1 6 and 1 8 times larger than nam for event 7 and about 3 9 2 5 and 2 8 times larger for event 8 in comparing the flood peaks for the two extreme events pce and ok could not predict the observed peaks at all while pck did have some predictive ability 4 4 performance score of surrogate models to acceptance thresholds our evaluations of both the accuracy and the efficiency of the behavior sets were carried out simultaneously we used the performance score ps given in in eq 14 for this purpose and the changes in ps according to the different levels of criteria are shown in figs 9 and 10 first fig 9 shows the change in ps with respect to the accuracy aimed threshold for a fixed threshold both the denominator and numerator of the first term of ps in eq 14 have comparable values that is d l m s u l m o 0 so the difference in ps values was greatly affected by the second term d g l u e m s u g l u e m overall pck showed smaller ps values i e had better performance than pce and ok also the stricter the accuracy criterion that was applied the greater this performance difference was especially in the extreme events events 7 and 8 this was because only pck quickly provided behavior sets that satisfied the small acceptance thresholds in the cases of pce and ok the time for uncertainty quantification was much longer than that of pck and we could not find any behavior sets that satisfied the thresholds of 0 2 for pce and 0 4 for ok fig 10 shows the change in ps with respect to the efficiency aimed fixed threshold both the denominator and numerator of the second term of the ps have similar values that is d g l u e m s u g l u e m o 0 so the difference in ps values was greatly affected by the first term d l m s u l m therefore the performance difference depends on the difference in predictability for the behavior sets between the models as before pck showed smaller ps values i e had better performance than pce and ok and this trend was especially pronounced in the extreme events see fig 10g h 5 discussion 5 1 how can pck accurately diagnose extreme events theoretically a surrogate model has the predictive power of its original model provided that the amount of data required to construct it is sufficient therefore when past events are repeated countless times and serve as big data a surrogate model can become a great tool to replace the original model however in the absence of such sufficient data for a variety of reasons a surrogate model will not be properly constructed this is indeed problematic if one attempts to predict extreme events outside the training data space the results in section 4 demonstrated the promise of pck to perform better than conventional surrogate models in predicting unknown extreme events that is the potential data space that pck could simulate was much wider than that of pce and ok even though all three models were trained with the same experimental design training set this extraordinary capability of pck can be explained by its ability to grasp real trends with a set of orthogonal polynomials ψ α x associated with pce coefficients varying between 0 and 10 429 m3 s instead of using a trend as a fixed value e g 3 216 m3 s in ok it is further explained by an ability to broaden the predictable data space in combination with a stochastic kriging variance adding this variance stochastically can increase the overall accuracy of model simulations compared to single pce when predicting points located in a sparse or rare design data space bichon et al 2011 echard et al 2011 schöbi et al 2014 by coupling both the ability of pce to accurately capture global behaviors and the ability of ok to secure more prediction margins locally the possibility of effectively addressing the extrapolation tasks which is difficult with existing data driven models is confirmed 5 2 a practical compromise between accuracy and efficiency of uncertainty quantification from the simulation results presented in sections 4 3 and 4 4 it is apparent that both forms of the cutoff threshold have a significant impact on the accuracy and efficiency of the glue products each has its pros and cons so it is difficult to discern which method is better from a practical standpoint if one has enough computational resources and it is more important to attain accurate outcomes it is better to select the accuracy aimed threshold it can consistently guarantee the accuracy of the simulation fig 11 a although it can lead to a computational burden because a substantial number of model runs up to billions is entailed fig 11b therefore this method is impractical when applied to expensive computational models iorgulescu et al 2007 tran et al 2020 one should always mind the possibility that glue will fail to converge fig 9 if one desires too accurate results i e if the threshold selection is not appropriate on the other hand if one is concerned about non convergence or it is important to finalize the quantification of uncertainty within an allocated time use of the efficiency aimed threshold is recommended this method can control computational efficiency with a predefined number of random runs fig 11d but may provide merely ordinary performance if the predefined number is insufficient see the results of pce and ok for events 7 and 8 in figs 7 and 8 note that if one arbitrarily selects a small efficiency aimed threshold to yield more accurate behavioral results the disadvantage of the increased computational burden may be greater than the advantage of improved accuracy this is because the accuracy improvement of the posterior simulations is not linear with the change in the efficiency aimed thresholds for example reducing the threshold by a factor of 2 from 2 to 1 only reduces l averaged over the ensemble by about 1 13 1 10 1 05 and 1 21 times for nam pce ok and pck respectively fig 11c and s3 in summary the choice of the acceptance threshold needed to attain the behavioral set of a model depends on the availability of computational resources and the degree of accuracy desired and must be estimated a priori like the determination of hyperparameters 5 3 essentials of p s and superiority of pck in uncertainty quantification can it be said that this surrogate model has excellent performance if its calculation speed is faster than that of its original model or if its results are comparable with the original model in the process of quantifying uncertainty through inverse modeling simply comparing and evaluating computation speed and errors may fail to characterize a good surrogate model first comparing the time taken for simple iterative tasks as well as to obtain the results of uncertainty quantification it can be seen that the performances of the surrogate models considered here are significantly different in this study for simple iterations the computational speed was improved by about 500 times by pce and 600 times by ok and pck compared to nam this is because the cpu runtimes required for each single execution were approximately 2 5 10 4 sec for pce to 2 0 10 4 sec for ok and pck and about 0 12 sec for nam in the case of a single run or simple repeated runs such an improvement stands on its own merit however when uncertainty needs to be quantified through inverse modeling not limited to glue the effort required to retrieve the behavioral set does not always offset and this speedup does not always follow this is because the number of random runs n runs required to obtain 1 000 behavior sets varies greatly depending on the models or events used table 3 for example for event 4 the surrogate models have more random runs while for event 6 the original model does in addition the surrogate models pce and ok which were considered not able to adequately capture the original model failed to achieve a single behavioral set even after 100 million random runs see events 7 and 8 in such events where uncertainty quantification is time consuming using the surrogate models pce and ok to improve efficiency is of no benefit at all second when determining an appropriate size for an experimental design by a conventional approach using a relative error the performance of surrogate models may be misjudged in general the relative error of a surrogate model in this work decreases as the size of the experimental design increases and the error tends not to decrease beyond a certain size fig 12 a a surrogate model with a sufficiently small and guaranteed accuracy should be generated based on the experimental design of a certain size or larger i e the elbows in fig 12a schöbi et al 2017 tran and kim 2021a but securing the size of the design x also increases the time rt x required to construct the training set from the experimental design x to the model response y moreover the computational runtime rt of pck and ok tends to be longer as n x is larger fig 12b because it takes a substantial amount of time to compute the gaussian variance in eq 8 for pck and eq s7 for ok razavi et al 2012b vigsnes et al 2017 this leads to a sharp drop in the performance of pck as evidenced by the increase of ps in fig 12c in this study fig 12a shows that to construct pce ok and pck to be tolerant of sufficiently small errors e g 0 01 the sizes of their experimental designs i e the elbows in fig 12a need to be about 4 500 4 000 and 4 000 respectively this is an agreed upon standard from a traditional point of view for constructing a surrogate model however if uncertainty quantification is involved this criterion may need to be changed that is its performance efficiency and accuracy in the process of uncertainty quantification must be reflected in the performance evaluation of the surrogate model it can be seen that the result of fig 12c using the ps proposed in this study is very different from that of fig 12a an experimental design with a size of 4 500 for pce and 1 000 for pck is required to exhibit sufficiently high performance ps 0 001 which is very different from the results of fig 12a interestingly in the case of pck the size of the experimental design required was drastically reduced from 4 000 to 1 000 this indicates that one can build high performing surrogate models by leveraging a much more limited training data size fig s4 highlighting the superiority of pck in that it helps modelers dramatically save computational resources 5 4 counsels for improving outlier performance of machine learning predicting outliers extrapolation seems to be a long lasting challenge in applications of surrogate model as well as machine learning kratzert et al 2019 frame et al 2021 nearing et al 2021 tran et al 2021 in hypothesis this would not be a challenge if the amount of data for training was sufficient and covers all possible even low frequency extreme events however in reality it is difficult to collect such comprehensive observation data when targeting rare or exceptional phenomena this study underlines three keys that have been carried out to improve the predictive power of extreme events that do not have enough data and deviate significantly from the training data first high fidelity samples supervised by physical relationships as well as actual observations should be utilized to ensure sufficient learning when the number of training samples is small data generated by physics based models or governing equations can improve the understanding of physical processes in machine learning models ivanov et al 2021 the second suggestion is to enhance the extrapolation ability by extending the scope of the prediction space by additionally taking into account input noise and parameter or learnable network weights uncertainty fang et al 2020 abdar et al 2021 in this study model parameters were considered as uncertain input vectors and glue was used to quantify their uncertainty the last suggestion is to build a hybrid model by combining a predictive model with a model with extrapolation capabilities in this study pce a global model that plays the role of trend and kriging an interpolation model that computes local changes are combined instead of using pce other techniques that can increase extrapolation capabilities would be applied such as richardson extrapolation bach 2020 spectral mixing kernel wilson et al 2014 extrapolation algorithms bakas 2019 sparse identification of nonlinear dynamics champion et al 2019 and generative models hatakeyama sato and oyaizu 2021 in this work we used pck with the three aforementioned approaches to obtain satisfactory results for extreme values such a discovery will inspire novel designs of potentially more comprehensive hybrid models 6 summary and conclusion this study presents a new surrogate model pck that can not only efficiently quantify streamflow uncertainty but also accurately predict even extreme events that deviate significantly from the trained data space to enhance the extrapolation capability this study underlines three keys enriching the understanding of physical processes by establishing high fidelity training samples supervised by physical relationships broadening the scope of the prediction space by additionally taking into account input noise and parameter uncertainty and creating a new hybrid model e g pck that combines a local predictive model with a model with extrapolation capabilities the advantages of pck were confirmed by investigating how well the results of glue matched observations for eight testing flood events in the thu bon watershed compared to two well known surrogate models pce and ok the principal results of this study are summarized as follows first with a relatively small sized experimental design n x 1 000 pck outperforms pce and ok in mimicking the behavior of the original model with smaller leave one out error values for all qois also from the sensitivity analysis of nine parameters the sensitivity results of pck were closer to those of nam especially for the three most sensitive parameters cqof ck12 and lm than were pce and ok as a result of applying glue to the eight testing events for the three surrogate models trained on the identical dataset see the framework in fig 1 all of the surrogate models provided predictions equivalent to the original model for six smaller events that were similar to the training data space however for extreme events 7 and 8 which differed significantly from the training experimental design only pck was found to accurately predict the hydrograph and flood peaks regardless of the type of acceptance threshold accuracy or efficiency aimed while both pce and ok failed the simulation results in sections 4 3 and 4 4 confirmed that both types of acceptance thresholds had a significant impact on the performance of glue selecting the accuracy aimed threshold can ensure the consistent accuracy of uncertain simulations but can lead to a computational burden because of the substantial number of repeated runs needed in contrast the efficiency aimed threshold can control the computational efficiency with a predefined number of random runs but can only provide ordinary performance since each has its own pros and cons from a practical point of view the type and size of the threshold should be determined based on the availability of sufficient computational resources and the degree of accuracy needed the performance of a surrogate model cannot be said to be superior just because its calculation speed is faster than that of its original model or because its calculation results are comparable to the original s merely comparing and evaluating computational speed and error in a traditional way can lead to a misjudgment in selecting a good surrogate model in this study we propose a new performance score ps that can measure the overall performance including both accuracy and efficiency of a surrogate model compared to its original model this ps allows for assessing the actual achievement that arises in quantifying uncertainty and helps to efficiently construct surrogate models and save computational budgets by limiting unnecessary increases in their experimental design sizes ultimately the combined surrogate model presented here can not only predict outlier events that deviate significantly from the trained data space but can greatly reduce the computational burden of uncertainty quantification such a discovery will inspire novel designs of potentially more comprehensive surrogate c learning research as well as surrogate modeling credit authorship contribution statement vinh ngoc tran conceptualization methodology formal analysis investigation visualization writing original draft jongho kim conceptualization validation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the 2022 research fund of university of ulsan we acknowledge the uncertainty quantification group uqlab of eth zurich for sharing open source algorithms appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127716 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3373,air water two phase flow is a common phenomenon during irrigation or intense rainfall in soils the competition between air and water phases has been recognized for long but few attempts have been made to study the effect of pore size distribution on the air water displacement processes at pore scale in this study micro computed tomography experiments and pore network simulations are employed to study air water flow in the pore space experimental and simulated results show that as the water saturation changes the diameters of water occupied pores change more quickly than air occupied pores while the connectivity of air clusters is more fragile than water clusters compared with single phase conditions air water two phase flow is more sensitive to pore network connectivity it can also be found that due to the decreasing diameter of water occupied pores and decreasing connectivity of air clusters the air water flow rate decreases as the pore size distribution becomes skewed keywords air water two phase flow pore size distribution pore network connectivity micro computed tomography experiments 1 introduction the characteristics of pore network have a large impact on the efficiency of water infiltration and air aeration as reported by the previous researchers well connected pore network facilitates fluxes of water and gas through the soil while a poor connected pore network may restrict water infiltration and gas aeration thus resulting in problems of water runoff soil erosion and anoxic conditions that limit plant growth rabot et al 2018 according to dexter and czyż 2000 rapid water infiltration requires well connected pores of larger diameter while storage of water for plants usually requires pores of smaller diameter on the other hand as indicated by reynolds et al 2009 when soil pore size is limited into a narrow range the soil usually shows poor aeration capacity furthermore when air water two phase flow is considered the effect of pore network on air and water flow could be amplified due to the impedance between air and water in the pore space for example during irrigation or intense rainfall water may quickly seal most of the pores on the soil surface thus air outflow will be constrained significantly by the water phase kravchenko et al 2015 negassa et al 2015 thus in order to bring deeper insight of the displacement processes between air and water phases in pore space the effect of pore characteristics on air water two phase flow should be further investigated the effect of pore characteristics on water infiltration or air aeration has been well recognized several parameters such as pore diameter and pore size distribution were employed to capture the pore network characteristics of different soils previous researchers dexter 1988 logsdon et al 1990 azooz et al 1996 turturro et al 2021 found that as the mean pore diameter decreased the hydraulic conductivity decreased rapidly pagliai and vignozzi 2002 carried out a series of field experiments and in their study higher hydraulic conductivity was observed as the macroporosity pore diameter 50 μm of the soils became greater more recently in studies of paradelo et al 2016 and sandin et al 2017 micro computed tomography micro ct was employed and found that the ct derived macroporosity correlated well with the air and water permeability on the other hand romero ruiz et al 2018 found that topology of the pore network was also a key parameter for water and air transport in the soils according to pagliai and vignozzi 2002 the soil was more likely to be sealed by water when the pores were very regularly elongated hilfer 2002 reviewed the previous studies concerning the microstructure of porous media and pointed out that the connectivity of the pore space provided a robust indicator for the flow properties of the porous medium later luo et al 2010 carried out a series of experiments and found out that the saturated hydraulic conductivity was controlled by the path number of the soil sample i e number of independent and continuous macropore paths between two boundaries ghanbarian et al 2017 showed that saturated hydraulic conductivity could be well estimated from the critical pore throat radius and pore connectivity in the studies of herring et al 2013 2015 three dimensional 3 d micro ct experiments were performed under different wettability conditions and found that connectivity analysis quantitatively demonstrated the change of fluid migration patterns many previous studies suggested that the pore network parameters were important in air water two phase flow wei et al 2020 ghanbarian et al 2017 beven and germann 2013 vogel 2000 as mentioned by vogel 2000 during air water two phase flow water preferentially occupied pores of smaller sizes while air transported in the pores of larger sizes on the other hand it was also pointed out by lin et al 1996 and beven and germann 2013 that the macropores which occupied 5 of the total porosity may contribute more than 80 of the total water flux thus the arrangement of large and small pores might have a significant effect on the air water exchange efficiency in the soils more recently wei et al 2020 found that the critical infiltration rate that might lead to air compression had a close relationship with the pore size distribution of the porous media but the underlying mechanisms were still not clear although the importance of pore network parameters on air water two phase flow has been noticed in the previous studies these darcy scale studies mentioned above offer only very little insight into the underlying pore scale mechanisms where competetion between air and water phases in the pore space plays a dominating role recently a series of interesting work have been carried out to study the pore scale displacement mechanisms using micro ct berg et al 2014 kimbrel et al 2015 armstrong et al 2016 armstrong et al 2019 however few attempts have been made to study the effect of pore size distribution on the air water displacement processes in the pore space the main aim of this study was to investigate the effect of pore characteristics especially pore size distribution on the processes of air water two phase flow in the porous media in order to achieve this aim micro ct experiments were carried out firstly to identify the major factors controlling the flow of air and water phases at pore scale then pore network models were constructed and verified by comparing the experimental results with the simulated ones at last the effect of pore network connectivity and pore size distribution on the processes of air water two phase flow were discussed 2 materials and methods 2 1 micro ct experiments 2 1 1 experimental setup and procedures three different kinds of materials natural silica sand accusand 30 40 grade unimin corp ottawa mn crushed silica sand 26 40 grade zhili environmental friendly material corp zhengzhou china and crushed limestone 7 20 grade mined in hengyang county hunan province china were used as the porous media in the experiments the mean particle size d ranged from 0 60 to 0 85 mm for natural silica sand 0 71 to 0 85 mm for crushed silica sand and 0 85 to 2 8 mm for crushed limestone both the natural silica sand and crushed silica sand had a sio2 content of over 99 wt and according to the x ray fluorescence measurement shi et al 2018 the limestone consists mainly of cao 48 8 wt with small amount of sio2 mgo al2o3 and k2o all of the three materials contain very low level of organic carbon 0 1 wt and can be seen as water wet materials the sands and limestone were washed with tap first and then deionized water and oven dried at 45 for at least 48 h before being packed into the columns the columns used in the experiments were made up of acrylic cylindrical tubes 27 cm long with inner diameter of 2 9 cm thus the inner volume of the columns was v0 179 25 cm3 the sand and limestone were added into the columns in 5 cm increment with shaking and tapping employed between each successive addition to achieve uniform packing and repeatable porosities during packing the mass of the dry sand ms added into the columns were recorded thus the volume of the sand limestone particles vs can be calculated by vs ms ρs and the porosity of the sand limestone can be calculated by φ 1 vs v0 once packed the columns were scanned using an x ray ct scanner hiscan xm micro ct suzhou hiscan information technology co ltd at dry conditions the x ray tube settings were 80 kv and 100 μa and images were acquired at 25 μm resolution a 0 5 rotation step through a 360 angular range with 50 ms exposure per step was used during the scanning fig 1 showed the photos and micro ct processed images for all the three materials used in the experiments after the columns were scanned at dry conditions they were placed vertically and water was injected at the bottom of the columns using a peristaltic pump fig 2 a up to 200 ml of water was injected into each column and the excess water was expelled from the outlet at the top of the column when the water injection was completed the columns were placed horizontally in the x ray ct scanner and the air water distributions in the columns were scanned under different water saturation fig 2b the column water saturation was controlled by lowering the outlet tube as tubes were lowered water flowed out of the column from the outlet and air flowed into the column from the inlet the volume of water that flowed out of the column vw was recorded during the experiments thus the actual water saturation can be calculated by 1 vw v0 vs for each column the outlet tube was lowered to three specific heights thus the air water phase distribution under conditions of the three different water saturations can be discussed in this study 2 1 2 image processing the scanned slice images were integrated to reconstruct 3 d images by using the python toolkit vtk https pypi org project vtk vtk is an open source toolkit for image process and 3 d volume rendering for the following image analysis the original images were resampled at the resolution of 50 μm to reduce computation time after resampling the constructed 3 d micro ct images were then analyzed using the image analysis tool porespy https porespy org an outline of the porespy package was given in gostick et al 2019 in general the porespy package analyzes the ct in the steps of image segmentation and pore network extraction the original ct images were grayscale and had a trimodal distribution atrimodal distributionis aprobability distributionwith three differentmodes with the first mode corresponding to the signal from the air phase the second mode to the signal from the water phase and the third mode to the signal from the solid phase in this study a threshold procedure for image segmentation was selected to match the predetermined porosity and water saturation after image segmentation the pore network was extracted using the snow algorithm in porespy gostick 2017 after the pore network was extracted the equivalent pore diameter of each nodal pore can be determined by assuming the pores were spheres the pore coordination number was that a pore in the network had an average number connected neighbor pores and it can also be obtained by counting the connected pores of each nodal pore during network extraction the pores containing more than 50 vol water phase were determined as water occupied pores and otherwise air occupied pores the flowchart of the micro ct image processing steps are generalized in fig 3 after the segmentation of the 3 d images the connectivity of the air and water phases in the pore space can then be calculated the connectivity denoted as γ is the proportion of the pairs of cells that are connected amongst all the pairs of permeable cells renard allard 2013 and it can be calculated using the following equation 1 γ 1 n s 2 i 1 n n i 2 where n s is the total number of cells occupied by the air water phase and n i is the number of cells within air water cluster i n is the total number of air water clusters γ is in fact the second order moment of the distributions of the air water clusters and is referred to in the literature as global connectivity index renard allard 2013 2 2 pore network modelling the simulations of air water flow through soils were carried out using the open source project openpnm https www openpnm org developed by gostick et al 2016 the cubic lattice pore networks used in this study had a domain size of 20000 μm 20000 μm 20000 μm with 125 000 pores 50 50 50 in each network the diameters of these pores were assigned stochastically using the weibull function 2 f d λ β β λ d λ β 1 e d λ β where d was the pore diameter m f d λ β was the probability function of pore diameter λ was the scale factor m and the mean pore diameter increased with increasing λ β was the shape factor which controlled the pore size distribution of the pore networks the pore size distribution of these networks became increasingly skewed as β became larger once the sizes of the pores were assigned the pores were randomly connected to their neighbor pores the connectivity of the pore networks was controlled by changing the coordination number c a pore network of coordination number c meant that a pore in this network had an average of c connected neighbor pores in order to evaluate the effect of pore characteristics on the processes of air water flow pore networks of different parameters were generated in this study we used β and c as the indicator parameter of different pore networks and the parameters used for generating these pore networks were presented in table 1 the scale factor λ was set to be 40 μm throughout the simulations for each set of β and c 40 parallel networks were generated and the results were averaged to minimize the random effect fig 4 showed two typical pore networks with the size of only 10 10 10 here generated using different β and c stochastically with pores represented by spheres and connections represented by solid lines as the placement of air phase and water phase was determined under a given water saturation the conductance of air and water phases can then be calculated using the stokesflow algorithm program in openpnm as illustrated in fig 5 the stokesflow algorithm was conducted by applying one dimensional linear transport equations and nodal balance equations to each set of neighboring pores 3 j 1 n q ij j 1 n g h i j p j p i g h π r 4 4 l t μ where n was the total pore number q ij represented the flow rate from pore j to pore i m3 s 1 g h i j represented the conductance between pores j and i m3 pa 1 s 1 p i and p j were the pressure in pores i and j pa r was the radius of the throat between the two pores m and was assumed to be equal to the smaller one of r 1 and r 2 in fig 5 lt was the length of the throat m and μ was the viscosity of the fluid pa s the system of equations were then solved over the 3 d networks the boundary conditions were considered using the mass conservation equation for the whole network 4 q k 0 k r s a μ l p in p out where q represented the total flow rate through the pore network m3 s 1 k 0 represented the equivalent effective permeability of the pore network m2 k r s represented the relative permeability of the pore network and k r s changes with water saturation s a was the cross sectional area m2 p in and p out were the pressures at the inlet and outlet of the pore network pa as shown in fig 6 for water inflow the pores on the front face were set as the inlets and the pores on the back face were set as the outlets and for air outflow the pores on the back face were set as the inlets and the pores on the front face were set as the outlets for both water inflow and air outflow the pressure difference p in p out was set as the unit pressure 1 pa during air invasion process the relative permeability of water phase was severely reduced in air occupied pores and throats thus running stokesflow algorithms at successive stages of the percolation algorithm the water inflow and air outflow rates under different water saturation can be determined the maximum air water flow rate was achieved at the water saturation where the air outflow rate was balanced with the water inflow rate wei et al 2020 during simulation it was assumed that the relative permeability of one phase should be severely reduced in pores and throats occupied by the other phase and thus the reduced single phase conductance was multiplied by a factor of 1 10 6 the validity of this assumption needs to be assessed in further study according to tranter et al 2016 the water and air phases may form thin liquid films when the pore space was occupied by the other phase and through thin liquid films the water and air phases can percolate at a significantly larger conductance however since film flow was not the focus of the this study it was assumed that residual water and air phases did not effectively conduct in the present study 3 results and discussion 3 1 displacement processes of air and water phases in the pore space figure 7 shows the mean pore diameter d of air and water clusters under different water saturation s w measured by the experiments and simulated by the pore network models it can be found from fig 7a that both d of air and water clusters increase with s w similar increase of d with s w can also be found from the simulated results in fig 7b the simultaneous increase of d for both air and water clusters can be attribtued to the effect of capillary pressure due to the effect of capillary pressure the air phase predominantly occupies large pores and water phase predominantly occupies small pores thus as s w increases the water phase should gradually invade into the smallest pores first then into the medium pores and finally into the largest pores which means that the d of water cluster should increase with s w and simultaneously due to the gradual invasion of water phase the air phase should also withdraw from the smallest pores first then from the medium pores and finally from the largest pores which means that the d of air cluster should also increase with s w it can also be found from fig 7a that the d of water clusters is generally 1 2 3 4 the d of air clusters except for the conditions when s w approaches 0 7 when s w approaches 0 7 the pore network is nearly saturated by water and the pores occupied by air concentrates on the top of the column thus the measured mean diameter of the air occupied pores is not representative at that time the difference in diameter of air and water occupied pores can also be found from the simulated results in fig 7b the d of water clusters is generally 1 2 the d of air clusters as presented furthermore it can be found in fig 7a and 7b that as 0 2 s w 0 8 the changing rate of d for water clusters is generally larger than air clusters it can be inferred from fig 7 that air phase gets the advantage in occupying larger pores since the pore size of water clusters is more sensitive to s w than air clusters under most saturation conditions figure 8 shows the connectivity of air and water clusters under experimental and simulated conditions it can be seen in fig 8a that as s w increases from 0 3 to 0 7 under experimental conditions the connectivity of air phase decreases quickly from nearly 1 0 to around 0 2 while the connectivity of water phase remains 1 0 similar phenomenon can also be found in fig 8b as s w increases from 0 to 1 0 under simulated conditions the connectivity of air phase decreases gradually from 1 0 to 0 while the connectivity of water phase increases quickly from 0 to 1 0 at about s w 0 1 and remains around 1 0 when 0 1 s w 1 both the experimental and the simulated results indicate that under most saturation conditions the water clusters remain well connected while the connectivity of air clusters decreases dramatically with increasing s w this difference between air and water clusters can be attributed to the difference between the diameters of air and water occupied pores as mentioned in fig 8a and 8b when 0 2 s w 0 8 the mean pore diameter d of water occupied pores is nearly 1 2 3 4 of the air occupied pores the smaller d of water phase means that water phase generally occupies a larger number of pores than the air phase except for the conditions when s w is too low sw 0 1 thus as a result the connectivity of water clusters is always better than the air clusters when 0 1 s w 1 fig 8a and b the connectivity of air water clusters is important because during air water two phase flow the presence of water air phase can disconnect the other phase and thus lead to a significant decrease in air water flow capability it can be inferred from fig 8a and b that the water phase gets the advantage of maintaining cluster connectivity while connectivity of air clusters decreases significantly with increasing s w indicating that the air flow route would be constrained significantly by the surrounding water phase under high water saturation generally speaking it can be observed from both the experimental results and the simulated results that 1 the mean diameter of air occupied pores is larger than the water occupied pores 2 the connectivity of the air clusters is generally poorer than the water clusters it is obvious that the pore diameter itself had a significant effect on the air water flow capability g h r 4 as shown in equation 3 thus would be discussed further in the following section 3 2 effect of pore network connectivity on air water flow table 2 presents the simulated water inflow air outflow and air water two phase flow rate under different network connectivities as seen in table 2 both the water inflow and air outflow rates increase when the connectivity of the pore network becomes better as the coordinated number c increases from 3 0 to 5 0 the maximum water inflow rate increases by 14 times and the maximum air outflow flow rate also increases by 14 times from 36 1 to 510 10 13m3 s with the increasing c furthermore as also shown in table 2 the pore connectivity has a much larger effect on flow rate when air and water flow is considered simultaneously as c increases from 3 0 to 5 0 the air water flow rate increases dramatically from 0 11 to 4 27 10 13m3 s in other words as water inflow and air outflow rates increase by 14 times due to better pore connection the air water flow rate increases by 39 times thus when the flow of air and water is taken into consideration simultaneously the flow rate is more sensitive to the pore network connectivity under the conditions of air water two phase flow the amplified effect of pore connectivity can be explained by the disconnection of air clusters as seen in fig 9 a under experimental conditions when the connectivity of the networks is relatively good c 6 0 both the air clusters and the water clusters are well connected with γ 1 0 for water and γ approaches 0 8 for air when the connectivity of the networks becomes poor c 4 0 the γ for water remains around 1 0 while γ for air decreases to 0 6 similar phenomenon can also be observed from the simulated results in fig 9b as c decreases from 5 0 to 3 0 the γ for water remains around 1 0 while γ for air decreases slowly from over 0 6 to around 0 55 as mentioned in section 3 1 the connectivity of air clusters can be quite fragile and is more sensitive to sw while the connectivity of water clusters is not so sensitive to swthus as the overall connectivity of the networks becomes poor i e c 4 0 in fig 9a and 3 0 in fig 9b air clusters are more likely to break off into isolated parts the isolated air clusters constrained the air outflow significantly and under extreme cases the connectivity of air phase becomes so weak that a continuous air outflow cluster throughout the networks no longer exists as seen in table 2 as cdecreases from 5 0 to 3 0 the combined effect of pore network connectivity and air water impedance leads to a decrease of 97 4 in the air water flow rate thus compared with the single phase conditions under the conditions of air water two phase flow the effect of pore connectivity on flow rate is amplified significantly due to competition between air and water in the pore space 3 3 effect of pore size distribution on air water flow in order to study the effect of pore size distribution on air water flow the air water two phase flow in pore networks of different pore size distributions i e group 2 were simulated the pore size distributions of networks in group 2 are presented in fig 10 it can be found from fig 10 that as the shape factor β decreases from 0 80 to 0 20 the pore size distribution of these networks becomes increasingly skewed and the difference between the diameters of air and water clusters becomes larger when β is 0 80 the pore sizes of the network are normally distributed with the peak located at approximately 30 μm when β decreases to 0 50 the pore size distribution of the network becomes increasingly skewed with the peak located around 40 μm and a tail extending from 10 μm to 1 μm and when β further decreases to 0 20 the pore size distribution of the network becomes quite skewed with a peak located at approximately 100 μm and a very long tail extending from 100 μm down to 0 02 μm fig 11 shows the change of the diameters of water air occupied pores during air water two phase flow under different pore size distribution as seen in fig 11 the decrease in β generally leads to a decrease in the diameters of the pores occupied by water while diameters of the pores occupied by air increase with the decrease of β from fig 11a it can be found that as β decreases from 0 80 to 0 20 the slope of the d sw curve increases obviously which means that the lower β would lead to larger change in the mean diameter of water clusters under different sw as seen in fig 11b the pore size of air clusters also becomes more sensitive to s w as β becomes lower thus it can be inferred from fig 11 that as β decreases the competition for large pores between air and water phase generally becomes intenser figure 12 shows the normalized water inflow and air outflow rates under different β as seen in fig 12 when the pore sizes are uniform i e β 0 80 the balanced water inflow and air outflow rates are achieved at the critical water saturation of s w 0 6 while as β decreases to 0 20 the critical water saturation increases to s w 0 75 it can also be found from fig 12 that when β decreases from 0 80 to 0 20 the normalized air water flow rate decreases from around 0 4 to around 0 25 the increase of critical water saturation with decreasing β can be attributed to the change of the mean pore diameters of air and water clusters it has been mentioned that as β decreases the pore size distribution of the networks becomes increasingly skewed fig 10 thus the water inflow rate decreases at s w 0 6 due to the decrease in the diameters of water occupied pores while the air outflow rate increases at s w 0 6 due to the increase in the diameters of air occupied pores and as a result of the decreasing β the water inflow rate can not catch up with the air outflow rate at the original critical water saturation of s w 0 6 so the critical water saturation has to increase from around 0 6 to around 0 75 the increase in critical water saturation somewhat recoups the decrease of water inflow rate but at the same time leads to a significant decrease in air outflow rate due to the decrease in air cluster connectivity as seen in fig 13 as β decreases from 0 80 to 0 20 the air cluster connectivity decreases dramatically from 0 36 to 0 10 thus due to the decrease in both the diameter of water occupied pores and the connectivity of air occupied pores the air water flow rate decreases as the shape factor β decreases 4 conclusion both experiments and simulations were carried out to study the dispalcement processes of air and water phases in the pore space the results showed that the water phase got the advantage in maintaining cluster connectivity while the air phase got the advantage in occupying large pores due to the competition between air and water phases in the pore space air water two phase flow was more sensitive to the pore network connectivity than single phase flow because the connectivity of air clusters was more fragile than the water clusters the decrease in overall pore network connectivity may lead to the increase of isolated air clusters thus reduce air water flow rate significantly furthermore as the pore size distribution of the networks became more skewed the pore diameters of the water clusters became smaller and the connectivity of the air clusters became poorer thus the air water flow rate generally decreased as the pore size distribution became more skewed it should be mentioned that the volume change of the air phase and the effect of macropores on the preferential flow were not considered in this study credit authorship contribution statement k p chen conceptualization formal analysis methodology writing original draft writing review editing y b wei data curation investigation visualization writing original draft j c wu funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grant from the national natural science foundation of china grant nos 41730856 and 41772258 and partly from grant from national key research and development program of china 2020yfc1807601 the authors thank ge dong for his laboratory work 
3373,air water two phase flow is a common phenomenon during irrigation or intense rainfall in soils the competition between air and water phases has been recognized for long but few attempts have been made to study the effect of pore size distribution on the air water displacement processes at pore scale in this study micro computed tomography experiments and pore network simulations are employed to study air water flow in the pore space experimental and simulated results show that as the water saturation changes the diameters of water occupied pores change more quickly than air occupied pores while the connectivity of air clusters is more fragile than water clusters compared with single phase conditions air water two phase flow is more sensitive to pore network connectivity it can also be found that due to the decreasing diameter of water occupied pores and decreasing connectivity of air clusters the air water flow rate decreases as the pore size distribution becomes skewed keywords air water two phase flow pore size distribution pore network connectivity micro computed tomography experiments 1 introduction the characteristics of pore network have a large impact on the efficiency of water infiltration and air aeration as reported by the previous researchers well connected pore network facilitates fluxes of water and gas through the soil while a poor connected pore network may restrict water infiltration and gas aeration thus resulting in problems of water runoff soil erosion and anoxic conditions that limit plant growth rabot et al 2018 according to dexter and czyż 2000 rapid water infiltration requires well connected pores of larger diameter while storage of water for plants usually requires pores of smaller diameter on the other hand as indicated by reynolds et al 2009 when soil pore size is limited into a narrow range the soil usually shows poor aeration capacity furthermore when air water two phase flow is considered the effect of pore network on air and water flow could be amplified due to the impedance between air and water in the pore space for example during irrigation or intense rainfall water may quickly seal most of the pores on the soil surface thus air outflow will be constrained significantly by the water phase kravchenko et al 2015 negassa et al 2015 thus in order to bring deeper insight of the displacement processes between air and water phases in pore space the effect of pore characteristics on air water two phase flow should be further investigated the effect of pore characteristics on water infiltration or air aeration has been well recognized several parameters such as pore diameter and pore size distribution were employed to capture the pore network characteristics of different soils previous researchers dexter 1988 logsdon et al 1990 azooz et al 1996 turturro et al 2021 found that as the mean pore diameter decreased the hydraulic conductivity decreased rapidly pagliai and vignozzi 2002 carried out a series of field experiments and in their study higher hydraulic conductivity was observed as the macroporosity pore diameter 50 μm of the soils became greater more recently in studies of paradelo et al 2016 and sandin et al 2017 micro computed tomography micro ct was employed and found that the ct derived macroporosity correlated well with the air and water permeability on the other hand romero ruiz et al 2018 found that topology of the pore network was also a key parameter for water and air transport in the soils according to pagliai and vignozzi 2002 the soil was more likely to be sealed by water when the pores were very regularly elongated hilfer 2002 reviewed the previous studies concerning the microstructure of porous media and pointed out that the connectivity of the pore space provided a robust indicator for the flow properties of the porous medium later luo et al 2010 carried out a series of experiments and found out that the saturated hydraulic conductivity was controlled by the path number of the soil sample i e number of independent and continuous macropore paths between two boundaries ghanbarian et al 2017 showed that saturated hydraulic conductivity could be well estimated from the critical pore throat radius and pore connectivity in the studies of herring et al 2013 2015 three dimensional 3 d micro ct experiments were performed under different wettability conditions and found that connectivity analysis quantitatively demonstrated the change of fluid migration patterns many previous studies suggested that the pore network parameters were important in air water two phase flow wei et al 2020 ghanbarian et al 2017 beven and germann 2013 vogel 2000 as mentioned by vogel 2000 during air water two phase flow water preferentially occupied pores of smaller sizes while air transported in the pores of larger sizes on the other hand it was also pointed out by lin et al 1996 and beven and germann 2013 that the macropores which occupied 5 of the total porosity may contribute more than 80 of the total water flux thus the arrangement of large and small pores might have a significant effect on the air water exchange efficiency in the soils more recently wei et al 2020 found that the critical infiltration rate that might lead to air compression had a close relationship with the pore size distribution of the porous media but the underlying mechanisms were still not clear although the importance of pore network parameters on air water two phase flow has been noticed in the previous studies these darcy scale studies mentioned above offer only very little insight into the underlying pore scale mechanisms where competetion between air and water phases in the pore space plays a dominating role recently a series of interesting work have been carried out to study the pore scale displacement mechanisms using micro ct berg et al 2014 kimbrel et al 2015 armstrong et al 2016 armstrong et al 2019 however few attempts have been made to study the effect of pore size distribution on the air water displacement processes in the pore space the main aim of this study was to investigate the effect of pore characteristics especially pore size distribution on the processes of air water two phase flow in the porous media in order to achieve this aim micro ct experiments were carried out firstly to identify the major factors controlling the flow of air and water phases at pore scale then pore network models were constructed and verified by comparing the experimental results with the simulated ones at last the effect of pore network connectivity and pore size distribution on the processes of air water two phase flow were discussed 2 materials and methods 2 1 micro ct experiments 2 1 1 experimental setup and procedures three different kinds of materials natural silica sand accusand 30 40 grade unimin corp ottawa mn crushed silica sand 26 40 grade zhili environmental friendly material corp zhengzhou china and crushed limestone 7 20 grade mined in hengyang county hunan province china were used as the porous media in the experiments the mean particle size d ranged from 0 60 to 0 85 mm for natural silica sand 0 71 to 0 85 mm for crushed silica sand and 0 85 to 2 8 mm for crushed limestone both the natural silica sand and crushed silica sand had a sio2 content of over 99 wt and according to the x ray fluorescence measurement shi et al 2018 the limestone consists mainly of cao 48 8 wt with small amount of sio2 mgo al2o3 and k2o all of the three materials contain very low level of organic carbon 0 1 wt and can be seen as water wet materials the sands and limestone were washed with tap first and then deionized water and oven dried at 45 for at least 48 h before being packed into the columns the columns used in the experiments were made up of acrylic cylindrical tubes 27 cm long with inner diameter of 2 9 cm thus the inner volume of the columns was v0 179 25 cm3 the sand and limestone were added into the columns in 5 cm increment with shaking and tapping employed between each successive addition to achieve uniform packing and repeatable porosities during packing the mass of the dry sand ms added into the columns were recorded thus the volume of the sand limestone particles vs can be calculated by vs ms ρs and the porosity of the sand limestone can be calculated by φ 1 vs v0 once packed the columns were scanned using an x ray ct scanner hiscan xm micro ct suzhou hiscan information technology co ltd at dry conditions the x ray tube settings were 80 kv and 100 μa and images were acquired at 25 μm resolution a 0 5 rotation step through a 360 angular range with 50 ms exposure per step was used during the scanning fig 1 showed the photos and micro ct processed images for all the three materials used in the experiments after the columns were scanned at dry conditions they were placed vertically and water was injected at the bottom of the columns using a peristaltic pump fig 2 a up to 200 ml of water was injected into each column and the excess water was expelled from the outlet at the top of the column when the water injection was completed the columns were placed horizontally in the x ray ct scanner and the air water distributions in the columns were scanned under different water saturation fig 2b the column water saturation was controlled by lowering the outlet tube as tubes were lowered water flowed out of the column from the outlet and air flowed into the column from the inlet the volume of water that flowed out of the column vw was recorded during the experiments thus the actual water saturation can be calculated by 1 vw v0 vs for each column the outlet tube was lowered to three specific heights thus the air water phase distribution under conditions of the three different water saturations can be discussed in this study 2 1 2 image processing the scanned slice images were integrated to reconstruct 3 d images by using the python toolkit vtk https pypi org project vtk vtk is an open source toolkit for image process and 3 d volume rendering for the following image analysis the original images were resampled at the resolution of 50 μm to reduce computation time after resampling the constructed 3 d micro ct images were then analyzed using the image analysis tool porespy https porespy org an outline of the porespy package was given in gostick et al 2019 in general the porespy package analyzes the ct in the steps of image segmentation and pore network extraction the original ct images were grayscale and had a trimodal distribution atrimodal distributionis aprobability distributionwith three differentmodes with the first mode corresponding to the signal from the air phase the second mode to the signal from the water phase and the third mode to the signal from the solid phase in this study a threshold procedure for image segmentation was selected to match the predetermined porosity and water saturation after image segmentation the pore network was extracted using the snow algorithm in porespy gostick 2017 after the pore network was extracted the equivalent pore diameter of each nodal pore can be determined by assuming the pores were spheres the pore coordination number was that a pore in the network had an average number connected neighbor pores and it can also be obtained by counting the connected pores of each nodal pore during network extraction the pores containing more than 50 vol water phase were determined as water occupied pores and otherwise air occupied pores the flowchart of the micro ct image processing steps are generalized in fig 3 after the segmentation of the 3 d images the connectivity of the air and water phases in the pore space can then be calculated the connectivity denoted as γ is the proportion of the pairs of cells that are connected amongst all the pairs of permeable cells renard allard 2013 and it can be calculated using the following equation 1 γ 1 n s 2 i 1 n n i 2 where n s is the total number of cells occupied by the air water phase and n i is the number of cells within air water cluster i n is the total number of air water clusters γ is in fact the second order moment of the distributions of the air water clusters and is referred to in the literature as global connectivity index renard allard 2013 2 2 pore network modelling the simulations of air water flow through soils were carried out using the open source project openpnm https www openpnm org developed by gostick et al 2016 the cubic lattice pore networks used in this study had a domain size of 20000 μm 20000 μm 20000 μm with 125 000 pores 50 50 50 in each network the diameters of these pores were assigned stochastically using the weibull function 2 f d λ β β λ d λ β 1 e d λ β where d was the pore diameter m f d λ β was the probability function of pore diameter λ was the scale factor m and the mean pore diameter increased with increasing λ β was the shape factor which controlled the pore size distribution of the pore networks the pore size distribution of these networks became increasingly skewed as β became larger once the sizes of the pores were assigned the pores were randomly connected to their neighbor pores the connectivity of the pore networks was controlled by changing the coordination number c a pore network of coordination number c meant that a pore in this network had an average of c connected neighbor pores in order to evaluate the effect of pore characteristics on the processes of air water flow pore networks of different parameters were generated in this study we used β and c as the indicator parameter of different pore networks and the parameters used for generating these pore networks were presented in table 1 the scale factor λ was set to be 40 μm throughout the simulations for each set of β and c 40 parallel networks were generated and the results were averaged to minimize the random effect fig 4 showed two typical pore networks with the size of only 10 10 10 here generated using different β and c stochastically with pores represented by spheres and connections represented by solid lines as the placement of air phase and water phase was determined under a given water saturation the conductance of air and water phases can then be calculated using the stokesflow algorithm program in openpnm as illustrated in fig 5 the stokesflow algorithm was conducted by applying one dimensional linear transport equations and nodal balance equations to each set of neighboring pores 3 j 1 n q ij j 1 n g h i j p j p i g h π r 4 4 l t μ where n was the total pore number q ij represented the flow rate from pore j to pore i m3 s 1 g h i j represented the conductance between pores j and i m3 pa 1 s 1 p i and p j were the pressure in pores i and j pa r was the radius of the throat between the two pores m and was assumed to be equal to the smaller one of r 1 and r 2 in fig 5 lt was the length of the throat m and μ was the viscosity of the fluid pa s the system of equations were then solved over the 3 d networks the boundary conditions were considered using the mass conservation equation for the whole network 4 q k 0 k r s a μ l p in p out where q represented the total flow rate through the pore network m3 s 1 k 0 represented the equivalent effective permeability of the pore network m2 k r s represented the relative permeability of the pore network and k r s changes with water saturation s a was the cross sectional area m2 p in and p out were the pressures at the inlet and outlet of the pore network pa as shown in fig 6 for water inflow the pores on the front face were set as the inlets and the pores on the back face were set as the outlets and for air outflow the pores on the back face were set as the inlets and the pores on the front face were set as the outlets for both water inflow and air outflow the pressure difference p in p out was set as the unit pressure 1 pa during air invasion process the relative permeability of water phase was severely reduced in air occupied pores and throats thus running stokesflow algorithms at successive stages of the percolation algorithm the water inflow and air outflow rates under different water saturation can be determined the maximum air water flow rate was achieved at the water saturation where the air outflow rate was balanced with the water inflow rate wei et al 2020 during simulation it was assumed that the relative permeability of one phase should be severely reduced in pores and throats occupied by the other phase and thus the reduced single phase conductance was multiplied by a factor of 1 10 6 the validity of this assumption needs to be assessed in further study according to tranter et al 2016 the water and air phases may form thin liquid films when the pore space was occupied by the other phase and through thin liquid films the water and air phases can percolate at a significantly larger conductance however since film flow was not the focus of the this study it was assumed that residual water and air phases did not effectively conduct in the present study 3 results and discussion 3 1 displacement processes of air and water phases in the pore space figure 7 shows the mean pore diameter d of air and water clusters under different water saturation s w measured by the experiments and simulated by the pore network models it can be found from fig 7a that both d of air and water clusters increase with s w similar increase of d with s w can also be found from the simulated results in fig 7b the simultaneous increase of d for both air and water clusters can be attribtued to the effect of capillary pressure due to the effect of capillary pressure the air phase predominantly occupies large pores and water phase predominantly occupies small pores thus as s w increases the water phase should gradually invade into the smallest pores first then into the medium pores and finally into the largest pores which means that the d of water cluster should increase with s w and simultaneously due to the gradual invasion of water phase the air phase should also withdraw from the smallest pores first then from the medium pores and finally from the largest pores which means that the d of air cluster should also increase with s w it can also be found from fig 7a that the d of water clusters is generally 1 2 3 4 the d of air clusters except for the conditions when s w approaches 0 7 when s w approaches 0 7 the pore network is nearly saturated by water and the pores occupied by air concentrates on the top of the column thus the measured mean diameter of the air occupied pores is not representative at that time the difference in diameter of air and water occupied pores can also be found from the simulated results in fig 7b the d of water clusters is generally 1 2 the d of air clusters as presented furthermore it can be found in fig 7a and 7b that as 0 2 s w 0 8 the changing rate of d for water clusters is generally larger than air clusters it can be inferred from fig 7 that air phase gets the advantage in occupying larger pores since the pore size of water clusters is more sensitive to s w than air clusters under most saturation conditions figure 8 shows the connectivity of air and water clusters under experimental and simulated conditions it can be seen in fig 8a that as s w increases from 0 3 to 0 7 under experimental conditions the connectivity of air phase decreases quickly from nearly 1 0 to around 0 2 while the connectivity of water phase remains 1 0 similar phenomenon can also be found in fig 8b as s w increases from 0 to 1 0 under simulated conditions the connectivity of air phase decreases gradually from 1 0 to 0 while the connectivity of water phase increases quickly from 0 to 1 0 at about s w 0 1 and remains around 1 0 when 0 1 s w 1 both the experimental and the simulated results indicate that under most saturation conditions the water clusters remain well connected while the connectivity of air clusters decreases dramatically with increasing s w this difference between air and water clusters can be attributed to the difference between the diameters of air and water occupied pores as mentioned in fig 8a and 8b when 0 2 s w 0 8 the mean pore diameter d of water occupied pores is nearly 1 2 3 4 of the air occupied pores the smaller d of water phase means that water phase generally occupies a larger number of pores than the air phase except for the conditions when s w is too low sw 0 1 thus as a result the connectivity of water clusters is always better than the air clusters when 0 1 s w 1 fig 8a and b the connectivity of air water clusters is important because during air water two phase flow the presence of water air phase can disconnect the other phase and thus lead to a significant decrease in air water flow capability it can be inferred from fig 8a and b that the water phase gets the advantage of maintaining cluster connectivity while connectivity of air clusters decreases significantly with increasing s w indicating that the air flow route would be constrained significantly by the surrounding water phase under high water saturation generally speaking it can be observed from both the experimental results and the simulated results that 1 the mean diameter of air occupied pores is larger than the water occupied pores 2 the connectivity of the air clusters is generally poorer than the water clusters it is obvious that the pore diameter itself had a significant effect on the air water flow capability g h r 4 as shown in equation 3 thus would be discussed further in the following section 3 2 effect of pore network connectivity on air water flow table 2 presents the simulated water inflow air outflow and air water two phase flow rate under different network connectivities as seen in table 2 both the water inflow and air outflow rates increase when the connectivity of the pore network becomes better as the coordinated number c increases from 3 0 to 5 0 the maximum water inflow rate increases by 14 times and the maximum air outflow flow rate also increases by 14 times from 36 1 to 510 10 13m3 s with the increasing c furthermore as also shown in table 2 the pore connectivity has a much larger effect on flow rate when air and water flow is considered simultaneously as c increases from 3 0 to 5 0 the air water flow rate increases dramatically from 0 11 to 4 27 10 13m3 s in other words as water inflow and air outflow rates increase by 14 times due to better pore connection the air water flow rate increases by 39 times thus when the flow of air and water is taken into consideration simultaneously the flow rate is more sensitive to the pore network connectivity under the conditions of air water two phase flow the amplified effect of pore connectivity can be explained by the disconnection of air clusters as seen in fig 9 a under experimental conditions when the connectivity of the networks is relatively good c 6 0 both the air clusters and the water clusters are well connected with γ 1 0 for water and γ approaches 0 8 for air when the connectivity of the networks becomes poor c 4 0 the γ for water remains around 1 0 while γ for air decreases to 0 6 similar phenomenon can also be observed from the simulated results in fig 9b as c decreases from 5 0 to 3 0 the γ for water remains around 1 0 while γ for air decreases slowly from over 0 6 to around 0 55 as mentioned in section 3 1 the connectivity of air clusters can be quite fragile and is more sensitive to sw while the connectivity of water clusters is not so sensitive to swthus as the overall connectivity of the networks becomes poor i e c 4 0 in fig 9a and 3 0 in fig 9b air clusters are more likely to break off into isolated parts the isolated air clusters constrained the air outflow significantly and under extreme cases the connectivity of air phase becomes so weak that a continuous air outflow cluster throughout the networks no longer exists as seen in table 2 as cdecreases from 5 0 to 3 0 the combined effect of pore network connectivity and air water impedance leads to a decrease of 97 4 in the air water flow rate thus compared with the single phase conditions under the conditions of air water two phase flow the effect of pore connectivity on flow rate is amplified significantly due to competition between air and water in the pore space 3 3 effect of pore size distribution on air water flow in order to study the effect of pore size distribution on air water flow the air water two phase flow in pore networks of different pore size distributions i e group 2 were simulated the pore size distributions of networks in group 2 are presented in fig 10 it can be found from fig 10 that as the shape factor β decreases from 0 80 to 0 20 the pore size distribution of these networks becomes increasingly skewed and the difference between the diameters of air and water clusters becomes larger when β is 0 80 the pore sizes of the network are normally distributed with the peak located at approximately 30 μm when β decreases to 0 50 the pore size distribution of the network becomes increasingly skewed with the peak located around 40 μm and a tail extending from 10 μm to 1 μm and when β further decreases to 0 20 the pore size distribution of the network becomes quite skewed with a peak located at approximately 100 μm and a very long tail extending from 100 μm down to 0 02 μm fig 11 shows the change of the diameters of water air occupied pores during air water two phase flow under different pore size distribution as seen in fig 11 the decrease in β generally leads to a decrease in the diameters of the pores occupied by water while diameters of the pores occupied by air increase with the decrease of β from fig 11a it can be found that as β decreases from 0 80 to 0 20 the slope of the d sw curve increases obviously which means that the lower β would lead to larger change in the mean diameter of water clusters under different sw as seen in fig 11b the pore size of air clusters also becomes more sensitive to s w as β becomes lower thus it can be inferred from fig 11 that as β decreases the competition for large pores between air and water phase generally becomes intenser figure 12 shows the normalized water inflow and air outflow rates under different β as seen in fig 12 when the pore sizes are uniform i e β 0 80 the balanced water inflow and air outflow rates are achieved at the critical water saturation of s w 0 6 while as β decreases to 0 20 the critical water saturation increases to s w 0 75 it can also be found from fig 12 that when β decreases from 0 80 to 0 20 the normalized air water flow rate decreases from around 0 4 to around 0 25 the increase of critical water saturation with decreasing β can be attributed to the change of the mean pore diameters of air and water clusters it has been mentioned that as β decreases the pore size distribution of the networks becomes increasingly skewed fig 10 thus the water inflow rate decreases at s w 0 6 due to the decrease in the diameters of water occupied pores while the air outflow rate increases at s w 0 6 due to the increase in the diameters of air occupied pores and as a result of the decreasing β the water inflow rate can not catch up with the air outflow rate at the original critical water saturation of s w 0 6 so the critical water saturation has to increase from around 0 6 to around 0 75 the increase in critical water saturation somewhat recoups the decrease of water inflow rate but at the same time leads to a significant decrease in air outflow rate due to the decrease in air cluster connectivity as seen in fig 13 as β decreases from 0 80 to 0 20 the air cluster connectivity decreases dramatically from 0 36 to 0 10 thus due to the decrease in both the diameter of water occupied pores and the connectivity of air occupied pores the air water flow rate decreases as the shape factor β decreases 4 conclusion both experiments and simulations were carried out to study the dispalcement processes of air and water phases in the pore space the results showed that the water phase got the advantage in maintaining cluster connectivity while the air phase got the advantage in occupying large pores due to the competition between air and water phases in the pore space air water two phase flow was more sensitive to the pore network connectivity than single phase flow because the connectivity of air clusters was more fragile than the water clusters the decrease in overall pore network connectivity may lead to the increase of isolated air clusters thus reduce air water flow rate significantly furthermore as the pore size distribution of the networks became more skewed the pore diameters of the water clusters became smaller and the connectivity of the air clusters became poorer thus the air water flow rate generally decreased as the pore size distribution became more skewed it should be mentioned that the volume change of the air phase and the effect of macropores on the preferential flow were not considered in this study credit authorship contribution statement k p chen conceptualization formal analysis methodology writing original draft writing review editing y b wei data curation investigation visualization writing original draft j c wu funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by grant from the national natural science foundation of china grant nos 41730856 and 41772258 and partly from grant from national key research and development program of china 2020yfc1807601 the authors thank ge dong for his laboratory work 
3374,an accurate groundwater simulation model and an efficient optimization algorithm are critical for building a reliable remediation scheme using simulation optimization method the hydraulic conductivity k and the porosity n of aquifers are two main controlling parameters for groundwater flow and contaminant transport whose uncertainties are high and often coexists such coexisting uncertainties have not been fully considered in previous studies on the optimization of groundwater remediation system in this work a new multi objective optimization algorithm namely the probabilistic multi objective fast harmony search and genetic algorithm pmofhs ga is developed capable of finding pareto optimal solutions with high reliability the algorithm is applied on a case study in designing a groundwater remediation system based on pumping and treating pat technology considering different scenarios with varying k and n realizations furthermore a novel decision making strategy based on the reliability of different objective functions is proposed to help designers determining the final best remediation scheme from pareto optimal solutions results show that the coexisting uncertainties of k and n will cause significant impacts on final optimization results in addition if there is a correlation between uncertainties of k and n the reliability and variability of optimization results will be different from that under no correlation condition thus accurate information of aquifer parameters is critical for the final optimization results furthermore the proposed decision making strategy can help decision makers to identify the final contaminant remediation scheme more reasonably the pmofhs ga and decision making strategy developed in this study are promising methods which can help decision makers to design a groundwater contaminant remediation system effectively keywords groundwater remediation multi objective optimization pmofhs ga monte carlo analysis coexisting uncertainty 1 introduction groundwater contamination is a world wide environmental problem schwarzenbach 2006 zhang et al 2017 zheng and liu 2013 how to effectively remedy contaminated aquifers is critical for the protection of groundwater resources yet a groundwater remediation program is not only costly but also requires a long period which could last for hundred years nrc 2013 thus it is vital to properly design a groundwater remediation system at planning stage before implementation starts during the past decades the simulation optimization method has been successfully used to solve groundwater resources management problems alizadeh et al 2017 karatzas and finder 1996 1996 mayer et al 2002 2002 minsker and shoemaker 1998 naserizade et al 2021 rizzo and dougherty 1996 sprocati and rolle 2021 tiedeman and gorelick 1993 zheng and wang 1999a zheng and wang 1999b the superiority of the simulation optimization method is that it can account for the complexity of groundwater system and find the optimal strategy under a set of constraints wagner 1995 generally in a simulation optimization model of groundwater remediation system a simulation model is used to describe groundwater flow and solute transport and an optimization model is used to characterize optimization objectives luo et al 2014 reed et al 2013 design of a groundwater remediation system is a challenging task different aspects such as the cost and the final remediation effect should be considered thoroughly moreover different aspects are often in conflict with each other erickson et al 2002 luo et al 2014 2012 ritzel et al 1994 singh and minsker 2008 yang et al 2013 making the design problem a multi objective one which might be solved with the multi objective simulation optimization technique as seen in many water management literatures deb et al 2002 erickson et al 2002 luo et al 2020 2014 2012 reed et al 2007 2013 reed and minsker 2004 ritzel et al 1994 the hydrogeological condition of a real field is complex and the hydrogeological parameters are of high uncertainties e g arshadi et al 2020 de marsily et al 2005 robin et al 1993 rubin et al 2018 siirila woodburn and maxwell 2015 among many uncertain parameters that characterize an aquifer system the hydraulic conductivity k and porosity n are two of the main controlling ones in determining groundwater flow and contaminant transport they two might also correlates with each other in some cases shi et al 2012 studied the influences of coexisting uncertainties of k and n on the distribution of contaminant mass the results showed that consideration of the uncertainties of aquifer parameters could result in a contamination plume which was significantly different from that only considering the uncertainty of k the spread of contamination plume was small when the correlation coefficient ce between k and n was positive while large when ce was negative in general the accuracy of groundwater flow and solute transport simulation model determines the reliability of optimization results however due to the complexity in the hydrogeological conditions of a real field previous studies either underplayed the uncertainty of groundwater simulation models or only considered partial uncertainty of some parameters such as k erickson et al 2002 luo et al 2014 2012 singh and minsker 2008 yang et al 2013 which could impair the reliability of final remediation scheme or even lead to the failure of a remediation project therefore in this study we fully accounted the coexisting uncertainties of aquifer parameters k and n and investigated their influences on final remediation schemes multi objective evolutionary algorithms moeas are popular methods for finding the pareto optimal solutions in a multi objective optimization problem for the problem of optimization of groundwater contaminant remediation system erickson et al 2002 used a niched pareto genetic algorithm npga to optimally design groundwater remediation system with two objectives the optimization results proved the advantages of npga compared with single genetic algorithm sga and random search rs singh and minsker 2008 proposed a probabilistic multi objective genetic algorithm pmoga to find pareto optimal solutions considering uncertainties of objective functions luo et al 2012 developed a multi objective fast harmony search algorithm mofhs to find the pareto optimal solutions of a groundwater remediation problem in indiana usa yang et al 2013 presented a niched pareto tabu search algorithm npts and successfully applied it to optimally design a groundwater remediation system luo et al 2014 further improved the mofhs by adding a probabilistic sorting technique and developed the probabilistic multi objective fast harmony search algorithm pmofhs to solve optimization problems considering uncertainty of k the results showed that the pareto optimal solutions based on the pmofhs were characterized by high reliability and low variability for the problem of long term groundwater monitoring ltgm network design reed and minsker 2004 used nsgaii to find the pareto solutions of a ltgm network design problem the optimization results showed that the nsgaii can be used to find high order pareto solutions and balanced design of groundwater systems reed et al 2007 improved moea with interactive archives and used it to optimally design the ltgm network for other multi objective groundwater management problems alizadeh et al 2017 adopted the nsgaii to find the best management policies of hydro environmental management of groundwater resources luo et al 2020 applied the mofhs algorithm to sustainably manage the groundwater resources in spring fields all of those studies have indicated that moeas are promising for solving multi objective optimization problems of groundwater management generally the convergence efficiency the local and global searching ability are criteria used to evaluate the efficacy of a moea kollat and reed 2006 for the classic nsgaii the local searching ability and the convergence efficiency usually reduce at the late iteration stages for the pmofhs which can be used to find pareto solutions under uncertainties of objectives the global searching ability is limited in this study we developed a new moea the probabilistic multi objective fast harmony search and genetic algorithm pmofhs ga based on the pmofhs and nsgaii in the proposed pmofhs ga the simulated binary crossover and polynomial mutation operators which contribute to the global search ability of nsgaii are included into the pmofhs therefore the proposed pmofhs ga is expected to show not only better convergence efficiency but also improved ability in local and global search then the proposed pmofhs ga is applied on an optimal design problem of groundwater remediation system considering the coexisting uncertainties of aquifer k and n here we mainly focus on the multi objective optimization of groundwater remediation system based on the pumping and treating pat technique the paper proceeds as follows in section 2 an overview of the multi objective simulation optimization model of a groundwater remediation system and the proposed pmofhs ga are given the application problem detailed analysis of the optimization results and the proposed decision making strategy are given in section 3 finally the conclusions are summarized and the future works are presented 2 methodology generally a multi objective simulation optimization model of groundwater remediation system involves two main sub models and a solving algorithm a groundwater simulation model a multi objective optimization model and a solver i e a moea the groundwater simulation model is used to simulate groundwater flow and contaminant transport during a remediation period the multi objective optimization model is used to describe the management problem the solver is used to find pareto optimal solutions 2 1 the groundwater model for flow and contaminant transport in this study the modflow harbaugh et al 2000 and mt3dms zheng and wang 1999a zheng and wang 1999b were used to model groundwater flow and contaminant transport input files of modflow and mt3dms programs were prepared according to the hydrogeological condition and contaminant situation of the study area furthermore based on the framework of simulation optimization method the original programs of modflow and mt3dms were adapted so the model can be called by the main optimization program repeatedly luo et al 2014 2012 2 2 the multi objective optimization model of groundwater remediation system a multi objective optimization model consists a number of objectives and constraints for a pat based groundwater remediation system the objectives typically involve minimizing remediation cost remediation period remaining contaminant mass in aquifers and maximizing the reliability of final remediation schemes etc luo et al 2014 singh and minsker 2008 yang et al 2013 in this study we focus on the minimization of the remediation cost and the remaining contaminant mass in aquifers at the end of remediation period erickson et al 2002 luo et al 2014 singh and minsker 2008 yang et al 2013 specifically the remediation cost includes the capital cost of well drilling and installation operation cost of pumping and treatment the remaining contaminant mass in aquifer is measured by the percentage of contaminant mass remained in aquifers at the end of remediation period as compared with that at the initial stage the formulations are given in eqs 1 2 1 minimize f 1 α 1 i 1 nw p i α 2 i 1 nw t 1 n t p i q i t z i g h i t δ t t α 3 i 1 nw t 1 n t p i m i t 2 minimize f 2 mass end mass 0 100 where f 1 is the total remediation cost over a remediation period and nw is the number of potential pumping wells to be optimized pi is a binary variable indicating whether a well i is set or not pi 1 if a well i is set pi 0 otherwise qi t is the pumping rate associated with well i during the t th management period x j x 1 j x 2 j x n j is the pumping lift of a well i during the t th remediation period nt is the total number of management periods and δtt is the duration of the t th management period mi t is the amount of contaminant removed by a well i during the t th management period and αi i 1 2 3 is the cost coefficient associated with well drilling installation groundwater extraction and contaminant mass treatment respectively f 2 is the percentage of mass remaining in aquifers at the end of a remediation period where mass 0 and massend being the total contaminant mass in aquifers at the beginning and the end of a remediation period respectively the number of potential pumping wells nw and the pumping rate associated with a well i at a given period t q i t are the decision variables the constraints of the optimization problem can be described as follows 3 i 1 n w p i n w 4 h j min h j h j max j 1 2 n h 5 h k out h k in δ h k min k 1 2 n g 6 c l min c l c l max l 1 2 n c 7 q i min q i q i max i 1 2 n w where eq 3 is a constraint showing that the total number of remediation wells must not exceed a prescribed number nw eq 4 indicates that the hydraulic head at location j hj must be within specified lower and upper bounds hj min and hj max during any remediation period nh is the total number of head constraints to ensure the efficiency of the pat system eq 5 imposes a set of constraints on the difference between heads at down gradient and up gradient locations hk out and hk in such that it is smaller than a minimum value δhk min during the remediation period ng is the total number of head pairs eq 6 corresponds to constraints specifying that the solute concentration at a location l cl must be within a specified lower and upper limit cl min and cl max at the end of a remediation period with nc being the total number of such locations eq 7 indicates that the pumping capacity of a well i must be within a specified minimum and maximum value qi min and qi max together eqs 1 7 constitute the multi objective optimization model of the groundwater remediation system for the case study 2 3 the multi objective solver pmofhs ga the proposed pmofhs ga is based on two existing multi objective evolutionary algorithms moeas namely the pmofhs and nsgaii luo et al 2014 proposed the pmofhs by introducing the probabilistic sorting technique into the original mofhs to tackle with the uncertainty of objective functions however the global searching ability of pmofhs still need to be further improved on the other hand the nsgaii deb et al 2002 has been successfully used to solve various multi objective optimization problems comparing with the mofhs the nsgaii is good at finding global optimal solutions thanks to the simulated binary crossover and polynomial mutation operators however the local searching ability and the convergence efficiency of nsgaii reduce at the late iteration stage therefore the simulated binary crossover and polynomial mutation operators are introduced into the pmofhs to improve its searching ability and convergence efficiency the resulted algorithm is called pmofhs ga which tackle the uncertainty of objectives while at the same time has improved searching ability both locally and globally the main iteration steps of the pmofhs ga are described as follows step i initialization of the controlling parameters the controlling parameters of pmofhs ga include the harmony memory size hms the harmony memory considering rate hmcr the maximum and minimum values of the pitch adjustment rate par max and par min the crossover probability pcross and the maximum iteration steps ni step ii initialization of the harmony memory matrix hmm the hmm stores all the solution vectors and the corresponding objective function values the dimension of hmm depends on the value of hms shown in eq 8 8 x 1 1 x 2 1 x n 1 1 x n 1 x 1 2 x 2 2 x n 1 2 x n 2 x 1 hms 1 x 2 hms 1 x n 1 hms 1 x n hms 1 x 1 hms x 2 hms x n 1 hms x n hms f 1 x 1 f 2 x 1 f m x 1 f 1 x 2 f 2 x 2 f m x 2 f 1 x hms 1 f 2 x hms 1 f m x hms 1 f 1 x hms f 2 x hms f m x hms where x j x 1 j x 2 j x n j represents the j th solution vector n is the number of the decision variables f x j is the expected value of objective functions corresponding to the j th solution vector under uncertain conditions based on the strategy of noisy genetic algorithm nga wu et al 2006 m is the number of objective functions step iii improvement of the hmm a harmony vector x i in a new hmm is generated based on three rules 1 harmony memory consideration 2 pitch adjustment and 3 random selection in the pmofhs ga the simulated binary crossover and polynomial mutation operator is the new improvement which are added to the pitch adjustment and random selection process respectively the new memory consideration procedure can be presented as follows 9 δ 10 δ i 2 γ i 1 η m 1 1 i f γ i 0 5 δ i 1 2 1 γ i 1 η m 1 i f γ i 0 5 where rand 0 1 and γi are random numbers between 0 and 1 li and ui are the minimum and maximum value of the decision variable x i ηm is distribution index for mutation usually set to 20 deb et al 2002 the improved pitch adjustment procedure with simulated binary crossover is shown as follows 11 if r a n d 0 1 0 5 i f r a n d 0 1 p a r g n x i x i best 2 r a n d 0 1 1 x i best x i e n d i f e l s e i f r a n d 0 1 p c r o s s x i 0 5 1 β i x i j 1 1 β i x i j 2 o r x i 0 5 1 β i x i j 1 1 β i x i j 2 e n d i f e n d i f 12 par g n p a r min p a r max p a r min g n n i 13 β i 2 r i 1 η c 1 β i 1 2 1 r i 1 η c 1 if r i 0 5 if r i 0 5 where gn is the current iteration step xi best represents the current best solution x i j 1 and x i j 2 are two random solution vectors ri is a random number between 0 and 1 ηc is distribution index for crossover usually set to 20 deb et al 2002 step iv updating hmm before updating the hmm solution vectors in new and old hmm are ranked by probabilistic pareto sorting according to their objective values luo et al 2014 the best 50 of solution vectors and their objective values are then put back into the new hmms this strategy is named the elitist selection which can ensure the convergence speed and uniformity of the pareto solutions deb et al 2002 step v checking the stopping criterion if the iteration number reaches ni the pmofhs ga is terminated the final pareto solutions and the corresponding objective values are printed otherwise go to step iii and continue the search the performance measures of the pmofhs ga are given in the appendix the framework of pmofhs ga which combines with the modflow and mt3dms to solve the multi objective optimal design of groundwater remediation system under coexisting uncertainties of parameters are shown in fig 1 there are three main stages the first stage corresponds to initialization of the pmofhs ga and the optimization problem generation of the initial population of the pmofhs ga and the uncertain fields of aquifer uncertain parameters the second stage executes the optimization procedure of pmofhs ga to find pareto solutions for the groundwater remediation problem the state variables concentration of different locations used to calculate the objective functions are extracted from the modflow and mt3dms program the last stage checks the termination condition of the pmofhs ga 3 example case study 3 1 problem description the proposed method is applied on a hypothetical case study adapted from zheng and wang 2003 and luo et al 2014 which is about the optimal design of a groundwater remediation system based on the pat method the contaminated aquifer is two dimensional measuring 3450 m and 2550 m in the and y directions respectively the boundary conditions of the flow model are given as constant head on east and west sides and no flow on north and south sides the constant head values of east and west sides are 35 m and 25 m respectively the boundary conditions of the transport model are zero mass flux on north west and south sides and a specified advective flux on east side the flow in the contaminant aquifer is steady there are four potential pumping wells to remove contaminant mass in the aquifer shown in fig 2 the gray area shown in fig 2 is the constraint area for contaminant concentration 20 ppb at the end of the remediation period in this study while the pumping capacity for the 4 potential pumping wells are 10 000 m3 d each the multi objective optimization model is given by eqs 1 7 and the values of α 1 α 2 and α 3 are set to 10 000 usd u s dollar 0 04 usd m3m and 1 usd g in order to find the pareto optimal solutions the constraints must be modified to unconstrained fitness measures by addition of the constraint violations to the objective functions as penalties hence if the remediation schemes disobey constraints the objectives are penalized thus the solutions with lower fitness have little chance of surviving in the evolutionary process the remediation period is set as 5 years other input parameters for the flow and transport models are given in table 1 3 2 generalization of the coexisting uncertain fields of k and n in this study the k follows a lognormal distribution and satisfies a two dimensional separable exponential covariance function as follows 14 c y h σ y 2 exp s x λ x s y λ y where σ y 2 is the variance of the logarithmic k i e y lnk λ x and λ y are the correlation in x and y direction respectively s x and s y are the distance in x and y directions respectively in this study a karhunen loeve k l expansion is adopted to generate a set of k realizations zhang and lu 2004 the porosity n is also lognormally distributed the correlation between k and n can be calculated by the local mean and variance of n at any spatial position after generating the k fields eq 15 15 μ n i μ n ρ σ n σ y y i μ y σ n i 2 σ n 2 1 0 c e 2 where μ n i is the local mean value of n at a location i μ n and σ n are the global mean and variance of the random fields of n respectively μ y and σ y are the global mean and variance of lnk respectively σ n i 2 is the local variance value of n at a location i ce is the correlation coefficient of the lnk and n based on the above method the mean value and variance of n at a position i can be generated by random sampling from n μ n i σ n i 2 then the generated random value can be treated as a value of n at a position i by performing this operation on all grid nodes in the study area the generated random fields account for the correlation between n and k it should be noted that random sampling may lead to negative values of n thus the upper and lower bound of n are considered in our study 3 3 optimization results and analysis pareto optimal solutions of the application problem are calculated by the pmofhs ga then the reliability of pareto optimal solutions is evaluated by monte carlo mc analysis during the mc analysis the final pareto solutions for remediation schemes are reevaluated across all k and n realizations 1000 realizations in this study after that the statistical mean and the upper 95th percentile in this study and lower 5th percentile in this study bounds of the mc analysis are calculated the statistical mean values from the mc analysis are considered reference representing the most reliable and stable scheme singh and minsker 2008 if the difference between the upper and lower values bandwidth of the mc analysis is small the uncertainty of the scheme is low two indicators are adopted to evaluate the reliability of the final pareto optimal solutions the first indicator is the root mean square error rmse which measures the goodness of fit between the optimized schemes and the statistical means of mc analysis the second indicator is the average bandwidth of the uncertain intervals band which represents the variability of the final pareto solutions luo et al 2016 2014 the greater the rmse the lower the reliability of the pareto solutions and the greater the band the larger the variability of the pareto solutions the hydrogeological conditions of a contaminant field are complex and usually involve many uncertain parameters with the k and n being the main uncertain ones moreover in some cases the two parameters correlate with each other for instance for sandy soil k and n often show a positive correlation while for clay the correlation is usually negative therefore in this section different scenarios with varying k and n realizations shown in table 2 were considered and the influences of the coexistence of k and n uncertainties on final pareto solutions were discussed the main controlling parameters of the pmofhs ga were set as follows population size 100 hmcr 0 95 par min 0 1 par max 0 95 pcross 0 9 capacity of pareto set filter 100 ni 100 deb et al 2002 luo et al 2014 3 3 1 scenario 1 scenario 1 only considers the uncertainty of k fig 3 a shows the final pareto optimal solutions and the mc analysis results the red plus icons in fig 3 a correspond to the final pareto optimal solutions which indicate the conflicting objectives between the remediation cost and the remaining contaminant mass where the remaining contaminant mass decreases with the increasing remediation cost however when the remaining contaminant mass in aquifers decreases to a certain level 1 7 show in fig 3 a increasing remediation cost no longer improves the remediation effect of the pat method any more the pmofhs ga based pareto optimal solutions are located between the upper and lower bounds of the mc analysis and are extremely close to the average values of mc analysis the rmse of the remediation cost and remaining contaminant mass are 1 61 million usd and 0 22 respectively shown in table 3 and the band of mc analysis are 8 76 million usd and 2 53 for remediation cost and remaining contaminant mass respectively these results indicate that the pmofhs ga is an effective algorithm for finding pareto solutions of high reliability and low variability 3 3 2 scenario 2 fig 3 b shows the pareto optimal solutions and mc analysis results of pmofhs ga under the condition of uncertain porosity that is uncorrelated with uncertain k in fig 3 b the trend of the pareto front is similar with that of scenario 1 the pareto solutions are located between the upper and lower bounds of the mc analysis and are close to the average values of the mc analysis the statistics in table 3 show that the rmse of the remediation cost and remaining contaminant mass are 2 29 million usd and 0 33 respectively which are larger than that of scenario 1 this means the reliability of the pareto optimal solutions are lower than that of scenario 1 besides the band of mc analysis are 8 97 million usd and 3 88 which are also a little larger than that of scenario 1 therefore the variability of the pareto optimal solutions under coexisting uncertainties of k and n is higher than that which only considers the uncertainty of k therefore risk will arise if the uncertainty of n is neglected when designing groundwater remediation schemes fig 4 compares the standard deviation of the mc analysis for remediation cost and remaining contaminant mass for scenarios 1 and 2 results show that with the increasing of the average remediation cost the standard deviation values are almost aligned along a straight line this indicates that the uncertainty of n has no significant impact on the reliability of remediation cost the main reason for this is the definition of the first objective function in this study the remediation cost consists of three part 1 the fixed cost of well drilling and installation 2 the cost of groundwater extraction and 3 the cost of contaminant groundwater treatment among them the cost of water extraction is the main part which will not be significantly affected by the uncertainty of n however for the average remaining contaminant mass in aquifers the values of the standard deviation under the coexisting uncertainties of k and n are significantly bigger than that under a single uncertainty of k this indicates that the uncertainty of n plays an important role for the distribution of remaining contaminant mass in the aquifer which is consistent with previous studies li et al 2012 xue and xie 2007 thus both the uncertainty of k and n must be considered when searching for a reliable groundwater remediation scheme 3 3 3 scenario 3 in this scenario we first compared the optimization results considering the positive correlation between uncertain k and n scenario 3a shown in table 2 with scenario 1 and 2 to analyze the effects of correlation between uncertain k and n on the final pareto optimal solutions then different variances of n scenario 3b and scenario 3c shown in table 2 are considered to explore the influence of uncertainty degrees of n on the optimization results fig 3 c shows the pareto optimal solutions and mc analysis results of pmofhs ga under scenario 3a the trend of the pareto optimal solutions in fig 3 c is similar to that in scenario 1 and 2 meanwhile the pareto solutions are located between the upper and lower bounds of the mc analysis and fit well with the average values of the mc analysis however compared with the performances of scenario 1 and 2 in table 3 the rmse of the remediation cost and remaining mass are 1 61 million usd and 0 36 respectively which are larger than the values of scenario 1 but smaller than that of scenario 2 this means that the reliability of the pareto solutions is lower than that of scenario 1 but higher than that of scenario 2 the band of mc analysis are 11 37 million usd and 4 94 for the remediation cost and mass remaining respectively which are larger than that of scenario 1 and scenario 2 this indicates the variability of the pareto solutions is higher than the case that only considers the uncertainty of k or non correlated k and n therefore both the uncertainty of n and the correlation between uncertain k and n will affect the reliability and variability of the optimization results to further analyze the influence of the uncertain degrees of n on final optimization results another two conditions scenario 3b and scenario 3c are considered the pareto solutions and mc analysis results are shown in fig 5 pareto solutions fit well with the average values of mc analysis and all of them located between the upper and lower bounds of mc analysis however it can be seen that with the increasing of σ2 n there is an evident increase of the bandwidth between the upper and lower bounds this result can also be supported by the statistics in table 3 when the value of σ2 n increases from 0 001 0 005 to 0 01 the band of mc analysis for remediation cost increase from 9 10 million usd 11 37 million usd to 13 42 million usd and for the remaining mass it increases from 2 89 4 94 to 6 83 this indicates that with the increasing variance of n the variability of pareto optimal solutions increases fig 6 further shows the comparison of standard deviation of mc analysis for the remediation cost and mass remained in aquifer under scenario 1 and 3 for the remediation cost with the increasing of the average remediation cost the standard deviation values are almost aligned in a straight line under different scenarios except for a few points where the remediation cost is high this indicates that the uncertainty of n and the coefficient between uncertain k and n have no significant impact on the reliability of remediation cost however for the average contaminant mass remained in aquifers the value of the standard deviation increase with the increasement of σ2 n this indicates that the uncertainty of n plays an important role in the uncertainty of remaining contaminant mass in aquifers the correlation between uncertainties of k and n also affects the distribution of contaminant mass in aquifers the standard deviation of the average remaining mass under scenario 3 is larger than that under scenario 1 as shown in fig 6 therefore both the uncertainty of n and the correlation between uncertainties of k and n must be considered when looking for a reliable groundwater remediation scheme 3 3 4 scenario 4 fig 3 d shows the pareto solutions and mc analysis under the negative correlation between n and k it can be seen that all of pareto solutions are located between the upper and lower boundaries of the mc analysis and the pareto solutions are close to the average values of the mc analysis however compared with other conditions in fig 3 the bandwidth between the upper and lower boundaries are largest and the fitting between the pareto solutions and the average values of mc analysis are the worst in table 3 the rmse and band of remediation cost are 3 24 million usd and 12 31 million usd respectively and the rmse and band of remaining mass are 0 99 and 6 74 respectively all of the rmse and band of scenario 4 are larger than that under other conditions in table 3 it shows that the reliability of pareto solutions is the lowest and the variability is the largest when the correlation between uncertain k and n is negative fig 7 shows the distribution of the standard deviation of mc analysis for remediation cost and remaining contaminant mass in aquifer under different values of ce for the remediation cost the standard deviation values almost align in a straight line under different ce however for the average contaminant mass remained in aquifers the standard deviations differ significantly under different ce and the values which account for the impact of ce are much larger than that do not especially when ce is negative the results indicate that the ce must also be considered when searching for the best remediation scheme otherwise it will underestimate the uncertainty of remaining mass in aquifers and lead to low reliable remediation schemes in order to further analyze the influence of ce and uncertainty of n on the pumping schemes different values of mass remained in aquifer and the corresponding pumping rates are given in fig 8 the sequence of the pumping rate is q well2 q well3 q well1 q well4 under scenario 1 while the sequence changes to q well2 q well1 q well3 q well4 under scenario 2 when ce 0 the trend of pumping rates is similar but it can still be seen that the pumping schemes are quite different even under the same average mass since the location of well 2 is the closest to the center of the contaminant plume the pumping rate of well 2 is always the biggest instead the location of well 4 is far from the center of the contaminant plume and the pumping rate of well 4 is always close to 0 this is consistent with the common sense that setting remediation wells at the downstream of the plume center can obtain better remediation effects the reason for the changes of the pumping schemes is due to the uncertainties of aquifer k and n and the correlation between them which lead to different distributions of contaminant mass in aquifers fig 9 shows the distribution of the contaminant plume under random selected uncertain fields of k and n at the end of 5 years for different scenarios it is clear that the center of the contaminant plume and their distribution are different during the optimization process the pmofhs ga will constantly adjust the pumping scheme according to the distribution of the remaining mass in aquifer therefore the uncertainty of k n and the correlation between them must be considered at the same time otherwise it will lead to unreasonable remediation schemes in addition it might happen that in the optimization one only considers the uncertainty of one parameter e g k even though there is a coexisting uncertainty between k and n to investigate this issue fig 10 shows the cumulative probability distributions of the remaining mass for two remediation schemes obtained from scenario 1 but reevaluated under the k and n realizations of scenario 2 scenario 3a and scenario 4 in fig 10a the probability of the remaining mass in aquifer no larger than 10 can reach to 77 while for scenario 2 scenario 3a and scenario 4 the probability is 27 51 and 29 similarly in fig 10b the probability no larger than 20 can reach to 60 instead for scenario 2 scenario 3a and scenario 4 the probability is 38 58 and 37 respectively these results further confirmed that the uncertainty of aquifer n should not be neglected otherwise the risk of failure to achieve good remediation goals will increase meanwhile what will happen if pareto solutions which fail to consider the correlation between k and n are used as remediation schemes to answer this question fig 11 shows the cumulative probability distributions of the remaining mass by reevaluating the solution of scenario 2 with remaining mass close to 5 across the k and n realizations of scenario 3a and scenario 4 the probability of mass remained in aquifer no larger than 5 is 53 under scenario 2 instead the reevaluated probability under scenario 3 and scenario 4 is 72 and 34 respectively this indicates that the risk of failure to reach the remediation objective will increase when there is a negative correlation between k and n but the risk will decrease if such correlation is positive if the objective of remaining mass is no larger than 5 the remediation cost are 6 2 million usd 5 3 million usd and 7 3 million usd under scenario 2 scenario 3a and scenario 4 3 4 decision making of the final optimal remediation scheme how to select the final remediation scheme from final pareto optimal solutions is the last but an important step especially when there are uncertainties in objective functions decision makers may just want to get the final remediation strategy which can satisfy basic performance and is easy to implement however a more proper and scientific approach should fully consider the impact of various uncertain factors on the design results in order to improve the accuracy of every remediation strategy in this section a new decision making strategy which is based on the reliability of different objective functions is proposed to help decision makers to select the final optimal remediation scheme there are four steps in the proposed decision making strategy for the final remediation scheme i implementing mc analysis on every pareto solutions under all of the realizations of k and n fields ii getting the cumulative probability distribution function of the objective functions iii selecting a quantile according to the reliability request if the reliability request is 95 then the quantile is set to 95 for all pareto solutions then the pareto front under the select reliability request is gotten iv choosing the final remediation scheme according to the budget and expected remediation effect fig 12 shows the pareto fronts of a selected combinations of objective reliability under scenario 3a results show that with the increasing reliability the remediation cost will increase while the remaining mass in the aquifer stays the same similarly the remaining mass will increase with the increasing reliability without altering the remediation cost in practice if the decision maker request that reliabilities of remaining mass in the aquifer and the remediation cost no lower than 95 and 75 respectively and the mass remained in the aquifer must be less than 5 the pareto solution represented by the black diamond s1 in the blue pareto front can be selected as the final remediation scheme the detailed pumping scheme and corresponding objective values are shown in table 4 if the decision maker prefers that the reliabilities of the mass remaining in the aquifer and the remediation cost no lower than 95 at the same time and the mass remaining must be less than 10 the pareto solution represented by the black square s2 in the red pareto front can be selected as the final remediation scheme similarly if the reliabilities of the remaining mass and the remediation cost should be not lower than 75 and 95 respectively and the remediation cost be no more than 20 million usd then the black triangle s3 in the green pareto front can be selected as the final remediation scheme for other groundwater contaminant fields designers should firstly carry out hydrogeological survey and determine the hydrogeological parameters including the correlation between the hydrogeological parameters then they just need to replace the groundwater flow and contaminant mass transport simulation models and run the simulation optimization model proposed in this study after getting the pareto front the aforementioned decision making strategy can be implemented where designers calculate the new pareto front according to their desired reliability finally decision makers can decide the final remediation scheme according to the budget and repair effect requirements 4 conclusions this work focuses on the optimal design of groundwater remediation systems considering the coexisting uncertainties of aquifer k and n a new moea namely the pmofhs ga is proposed to find pareto solutions a benchmark test using conv1 and zdt4 problems has confirmed the high efficiency of the proposed pmofhs ga the method is applied on a hypothetical case for designing groundwater remediation schemes the optimization results under different scenarios considering uncertain k and n realization fields showed the high reliability and low variability of pareto solutions based on the pmofhs ga however the results were significantly affected by the coexisting uncertainties of k and n and the correlation between them especially for the reliability and variability of remaining mass in aquifers when the uncertainties of k and n were considered simultaneously the reliability of pareto solutions decreased and the variability of pareto solutions increased in addition different values of ce also affected the distribution of contaminant mass in aquifers the spread of the contaminant plume decreased when ce was positive while increased when ce was negative these eventually affected the reliability of the optimization results thus the detailed hydrogeological condition and correct identification of the correlation between uncertain k and n are critical for achieving reliable groundwater remediation schemes the proposed decision making strategy can facilitate decision makers to reasonably select the final groundwater remediation scheme which can be applied to other optimization problems under uncertainty the uncertainty sources in groundwater simulation include not only aquifer parameters but also model structures in future studies the uncertainty of model structures should also be considered simultaneously in the optimization process credit authorship contribution statement yun yang conceptualization methodology investigation data curation writing original draft jichun wu supervision writing review editing funding acquisition qiankun luo formal analysis software writing review editing project administration jianfeng wu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is financially supported by the national natural science foundation of china no 41730856 41502226 the authors are grateful to editors and reviewers for their invaluable suggestions on the manuscript appendix a the performance measures of pmofhs ga in order to test the efficiency of the pmofhs ga two classic multi objective benchmark functions conv1 and zdt4 were considered deb et al 2002 their mathematical forms are shown in eq a 1 and a 2 respectively two performance measures namely the convergence indicator γ and the diversity indicator δ were adopted to evaluate the results of pmofhs ga mofhs and nsgaii γ is used to measure the convergence of pareto solutions to the true pareto optimal front and δ measures the spread of optimized solutions deb et al 2002 luo et al 2012 if all pareto solutions lie exactly on the true pareto front the value of γ is 0 if all pareto solutions with the most widely and uniformly spread out set of nondominated solutions the value of δ will equal to 0 or close to 0 for other cases the value of δ would be greater than 0 a1 f 1 x x 1 1 4 i 2 n x i 1 2 f 2 x i 1 n x i 1 2 subject to 5 0 x i 5 0 i 1 2 30 a2 f 1 x x 1 f 2 x g x 1 f 1 x g x subject to 0 x 1 1 0 g x 1 10 n 1 i 2 n x i 2 10 cos 4 π x i 5 0 x i 5 0 i 2 3 10 fig a1 shows the true pareto fronts and the pareto solutions based on the pmofhs ga mofhs and nsgaii for the conv1 and zdt4 problems respectively compared with results from the mofhs and nsgaii the pareto solutions of pmofhs ga are more uniformly distributed and closer to the true pareto front table a1 shows the performance of γ and δ for the three algorithms for the conv1 function the values of γ and δ from pmofhs ga are 0 7430 and 0 2226 respectively significantly smaller than that of mofhs and nsgaii for the zdt4 function the values of γ and δ from pmofhs ga and mofhs are much smaller than that of nsgaii although the γ and δ from pmofhs ga are close to that of mofhs the pmofhs ga performs slightly better results indicate that the pmofhs ga is a promising moea for solving multi objective optimization problems 
3374,an accurate groundwater simulation model and an efficient optimization algorithm are critical for building a reliable remediation scheme using simulation optimization method the hydraulic conductivity k and the porosity n of aquifers are two main controlling parameters for groundwater flow and contaminant transport whose uncertainties are high and often coexists such coexisting uncertainties have not been fully considered in previous studies on the optimization of groundwater remediation system in this work a new multi objective optimization algorithm namely the probabilistic multi objective fast harmony search and genetic algorithm pmofhs ga is developed capable of finding pareto optimal solutions with high reliability the algorithm is applied on a case study in designing a groundwater remediation system based on pumping and treating pat technology considering different scenarios with varying k and n realizations furthermore a novel decision making strategy based on the reliability of different objective functions is proposed to help designers determining the final best remediation scheme from pareto optimal solutions results show that the coexisting uncertainties of k and n will cause significant impacts on final optimization results in addition if there is a correlation between uncertainties of k and n the reliability and variability of optimization results will be different from that under no correlation condition thus accurate information of aquifer parameters is critical for the final optimization results furthermore the proposed decision making strategy can help decision makers to identify the final contaminant remediation scheme more reasonably the pmofhs ga and decision making strategy developed in this study are promising methods which can help decision makers to design a groundwater contaminant remediation system effectively keywords groundwater remediation multi objective optimization pmofhs ga monte carlo analysis coexisting uncertainty 1 introduction groundwater contamination is a world wide environmental problem schwarzenbach 2006 zhang et al 2017 zheng and liu 2013 how to effectively remedy contaminated aquifers is critical for the protection of groundwater resources yet a groundwater remediation program is not only costly but also requires a long period which could last for hundred years nrc 2013 thus it is vital to properly design a groundwater remediation system at planning stage before implementation starts during the past decades the simulation optimization method has been successfully used to solve groundwater resources management problems alizadeh et al 2017 karatzas and finder 1996 1996 mayer et al 2002 2002 minsker and shoemaker 1998 naserizade et al 2021 rizzo and dougherty 1996 sprocati and rolle 2021 tiedeman and gorelick 1993 zheng and wang 1999a zheng and wang 1999b the superiority of the simulation optimization method is that it can account for the complexity of groundwater system and find the optimal strategy under a set of constraints wagner 1995 generally in a simulation optimization model of groundwater remediation system a simulation model is used to describe groundwater flow and solute transport and an optimization model is used to characterize optimization objectives luo et al 2014 reed et al 2013 design of a groundwater remediation system is a challenging task different aspects such as the cost and the final remediation effect should be considered thoroughly moreover different aspects are often in conflict with each other erickson et al 2002 luo et al 2014 2012 ritzel et al 1994 singh and minsker 2008 yang et al 2013 making the design problem a multi objective one which might be solved with the multi objective simulation optimization technique as seen in many water management literatures deb et al 2002 erickson et al 2002 luo et al 2020 2014 2012 reed et al 2007 2013 reed and minsker 2004 ritzel et al 1994 the hydrogeological condition of a real field is complex and the hydrogeological parameters are of high uncertainties e g arshadi et al 2020 de marsily et al 2005 robin et al 1993 rubin et al 2018 siirila woodburn and maxwell 2015 among many uncertain parameters that characterize an aquifer system the hydraulic conductivity k and porosity n are two of the main controlling ones in determining groundwater flow and contaminant transport they two might also correlates with each other in some cases shi et al 2012 studied the influences of coexisting uncertainties of k and n on the distribution of contaminant mass the results showed that consideration of the uncertainties of aquifer parameters could result in a contamination plume which was significantly different from that only considering the uncertainty of k the spread of contamination plume was small when the correlation coefficient ce between k and n was positive while large when ce was negative in general the accuracy of groundwater flow and solute transport simulation model determines the reliability of optimization results however due to the complexity in the hydrogeological conditions of a real field previous studies either underplayed the uncertainty of groundwater simulation models or only considered partial uncertainty of some parameters such as k erickson et al 2002 luo et al 2014 2012 singh and minsker 2008 yang et al 2013 which could impair the reliability of final remediation scheme or even lead to the failure of a remediation project therefore in this study we fully accounted the coexisting uncertainties of aquifer parameters k and n and investigated their influences on final remediation schemes multi objective evolutionary algorithms moeas are popular methods for finding the pareto optimal solutions in a multi objective optimization problem for the problem of optimization of groundwater contaminant remediation system erickson et al 2002 used a niched pareto genetic algorithm npga to optimally design groundwater remediation system with two objectives the optimization results proved the advantages of npga compared with single genetic algorithm sga and random search rs singh and minsker 2008 proposed a probabilistic multi objective genetic algorithm pmoga to find pareto optimal solutions considering uncertainties of objective functions luo et al 2012 developed a multi objective fast harmony search algorithm mofhs to find the pareto optimal solutions of a groundwater remediation problem in indiana usa yang et al 2013 presented a niched pareto tabu search algorithm npts and successfully applied it to optimally design a groundwater remediation system luo et al 2014 further improved the mofhs by adding a probabilistic sorting technique and developed the probabilistic multi objective fast harmony search algorithm pmofhs to solve optimization problems considering uncertainty of k the results showed that the pareto optimal solutions based on the pmofhs were characterized by high reliability and low variability for the problem of long term groundwater monitoring ltgm network design reed and minsker 2004 used nsgaii to find the pareto solutions of a ltgm network design problem the optimization results showed that the nsgaii can be used to find high order pareto solutions and balanced design of groundwater systems reed et al 2007 improved moea with interactive archives and used it to optimally design the ltgm network for other multi objective groundwater management problems alizadeh et al 2017 adopted the nsgaii to find the best management policies of hydro environmental management of groundwater resources luo et al 2020 applied the mofhs algorithm to sustainably manage the groundwater resources in spring fields all of those studies have indicated that moeas are promising for solving multi objective optimization problems of groundwater management generally the convergence efficiency the local and global searching ability are criteria used to evaluate the efficacy of a moea kollat and reed 2006 for the classic nsgaii the local searching ability and the convergence efficiency usually reduce at the late iteration stages for the pmofhs which can be used to find pareto solutions under uncertainties of objectives the global searching ability is limited in this study we developed a new moea the probabilistic multi objective fast harmony search and genetic algorithm pmofhs ga based on the pmofhs and nsgaii in the proposed pmofhs ga the simulated binary crossover and polynomial mutation operators which contribute to the global search ability of nsgaii are included into the pmofhs therefore the proposed pmofhs ga is expected to show not only better convergence efficiency but also improved ability in local and global search then the proposed pmofhs ga is applied on an optimal design problem of groundwater remediation system considering the coexisting uncertainties of aquifer k and n here we mainly focus on the multi objective optimization of groundwater remediation system based on the pumping and treating pat technique the paper proceeds as follows in section 2 an overview of the multi objective simulation optimization model of a groundwater remediation system and the proposed pmofhs ga are given the application problem detailed analysis of the optimization results and the proposed decision making strategy are given in section 3 finally the conclusions are summarized and the future works are presented 2 methodology generally a multi objective simulation optimization model of groundwater remediation system involves two main sub models and a solving algorithm a groundwater simulation model a multi objective optimization model and a solver i e a moea the groundwater simulation model is used to simulate groundwater flow and contaminant transport during a remediation period the multi objective optimization model is used to describe the management problem the solver is used to find pareto optimal solutions 2 1 the groundwater model for flow and contaminant transport in this study the modflow harbaugh et al 2000 and mt3dms zheng and wang 1999a zheng and wang 1999b were used to model groundwater flow and contaminant transport input files of modflow and mt3dms programs were prepared according to the hydrogeological condition and contaminant situation of the study area furthermore based on the framework of simulation optimization method the original programs of modflow and mt3dms were adapted so the model can be called by the main optimization program repeatedly luo et al 2014 2012 2 2 the multi objective optimization model of groundwater remediation system a multi objective optimization model consists a number of objectives and constraints for a pat based groundwater remediation system the objectives typically involve minimizing remediation cost remediation period remaining contaminant mass in aquifers and maximizing the reliability of final remediation schemes etc luo et al 2014 singh and minsker 2008 yang et al 2013 in this study we focus on the minimization of the remediation cost and the remaining contaminant mass in aquifers at the end of remediation period erickson et al 2002 luo et al 2014 singh and minsker 2008 yang et al 2013 specifically the remediation cost includes the capital cost of well drilling and installation operation cost of pumping and treatment the remaining contaminant mass in aquifer is measured by the percentage of contaminant mass remained in aquifers at the end of remediation period as compared with that at the initial stage the formulations are given in eqs 1 2 1 minimize f 1 α 1 i 1 nw p i α 2 i 1 nw t 1 n t p i q i t z i g h i t δ t t α 3 i 1 nw t 1 n t p i m i t 2 minimize f 2 mass end mass 0 100 where f 1 is the total remediation cost over a remediation period and nw is the number of potential pumping wells to be optimized pi is a binary variable indicating whether a well i is set or not pi 1 if a well i is set pi 0 otherwise qi t is the pumping rate associated with well i during the t th management period x j x 1 j x 2 j x n j is the pumping lift of a well i during the t th remediation period nt is the total number of management periods and δtt is the duration of the t th management period mi t is the amount of contaminant removed by a well i during the t th management period and αi i 1 2 3 is the cost coefficient associated with well drilling installation groundwater extraction and contaminant mass treatment respectively f 2 is the percentage of mass remaining in aquifers at the end of a remediation period where mass 0 and massend being the total contaminant mass in aquifers at the beginning and the end of a remediation period respectively the number of potential pumping wells nw and the pumping rate associated with a well i at a given period t q i t are the decision variables the constraints of the optimization problem can be described as follows 3 i 1 n w p i n w 4 h j min h j h j max j 1 2 n h 5 h k out h k in δ h k min k 1 2 n g 6 c l min c l c l max l 1 2 n c 7 q i min q i q i max i 1 2 n w where eq 3 is a constraint showing that the total number of remediation wells must not exceed a prescribed number nw eq 4 indicates that the hydraulic head at location j hj must be within specified lower and upper bounds hj min and hj max during any remediation period nh is the total number of head constraints to ensure the efficiency of the pat system eq 5 imposes a set of constraints on the difference between heads at down gradient and up gradient locations hk out and hk in such that it is smaller than a minimum value δhk min during the remediation period ng is the total number of head pairs eq 6 corresponds to constraints specifying that the solute concentration at a location l cl must be within a specified lower and upper limit cl min and cl max at the end of a remediation period with nc being the total number of such locations eq 7 indicates that the pumping capacity of a well i must be within a specified minimum and maximum value qi min and qi max together eqs 1 7 constitute the multi objective optimization model of the groundwater remediation system for the case study 2 3 the multi objective solver pmofhs ga the proposed pmofhs ga is based on two existing multi objective evolutionary algorithms moeas namely the pmofhs and nsgaii luo et al 2014 proposed the pmofhs by introducing the probabilistic sorting technique into the original mofhs to tackle with the uncertainty of objective functions however the global searching ability of pmofhs still need to be further improved on the other hand the nsgaii deb et al 2002 has been successfully used to solve various multi objective optimization problems comparing with the mofhs the nsgaii is good at finding global optimal solutions thanks to the simulated binary crossover and polynomial mutation operators however the local searching ability and the convergence efficiency of nsgaii reduce at the late iteration stage therefore the simulated binary crossover and polynomial mutation operators are introduced into the pmofhs to improve its searching ability and convergence efficiency the resulted algorithm is called pmofhs ga which tackle the uncertainty of objectives while at the same time has improved searching ability both locally and globally the main iteration steps of the pmofhs ga are described as follows step i initialization of the controlling parameters the controlling parameters of pmofhs ga include the harmony memory size hms the harmony memory considering rate hmcr the maximum and minimum values of the pitch adjustment rate par max and par min the crossover probability pcross and the maximum iteration steps ni step ii initialization of the harmony memory matrix hmm the hmm stores all the solution vectors and the corresponding objective function values the dimension of hmm depends on the value of hms shown in eq 8 8 x 1 1 x 2 1 x n 1 1 x n 1 x 1 2 x 2 2 x n 1 2 x n 2 x 1 hms 1 x 2 hms 1 x n 1 hms 1 x n hms 1 x 1 hms x 2 hms x n 1 hms x n hms f 1 x 1 f 2 x 1 f m x 1 f 1 x 2 f 2 x 2 f m x 2 f 1 x hms 1 f 2 x hms 1 f m x hms 1 f 1 x hms f 2 x hms f m x hms where x j x 1 j x 2 j x n j represents the j th solution vector n is the number of the decision variables f x j is the expected value of objective functions corresponding to the j th solution vector under uncertain conditions based on the strategy of noisy genetic algorithm nga wu et al 2006 m is the number of objective functions step iii improvement of the hmm a harmony vector x i in a new hmm is generated based on three rules 1 harmony memory consideration 2 pitch adjustment and 3 random selection in the pmofhs ga the simulated binary crossover and polynomial mutation operator is the new improvement which are added to the pitch adjustment and random selection process respectively the new memory consideration procedure can be presented as follows 9 δ 10 δ i 2 γ i 1 η m 1 1 i f γ i 0 5 δ i 1 2 1 γ i 1 η m 1 i f γ i 0 5 where rand 0 1 and γi are random numbers between 0 and 1 li and ui are the minimum and maximum value of the decision variable x i ηm is distribution index for mutation usually set to 20 deb et al 2002 the improved pitch adjustment procedure with simulated binary crossover is shown as follows 11 if r a n d 0 1 0 5 i f r a n d 0 1 p a r g n x i x i best 2 r a n d 0 1 1 x i best x i e n d i f e l s e i f r a n d 0 1 p c r o s s x i 0 5 1 β i x i j 1 1 β i x i j 2 o r x i 0 5 1 β i x i j 1 1 β i x i j 2 e n d i f e n d i f 12 par g n p a r min p a r max p a r min g n n i 13 β i 2 r i 1 η c 1 β i 1 2 1 r i 1 η c 1 if r i 0 5 if r i 0 5 where gn is the current iteration step xi best represents the current best solution x i j 1 and x i j 2 are two random solution vectors ri is a random number between 0 and 1 ηc is distribution index for crossover usually set to 20 deb et al 2002 step iv updating hmm before updating the hmm solution vectors in new and old hmm are ranked by probabilistic pareto sorting according to their objective values luo et al 2014 the best 50 of solution vectors and their objective values are then put back into the new hmms this strategy is named the elitist selection which can ensure the convergence speed and uniformity of the pareto solutions deb et al 2002 step v checking the stopping criterion if the iteration number reaches ni the pmofhs ga is terminated the final pareto solutions and the corresponding objective values are printed otherwise go to step iii and continue the search the performance measures of the pmofhs ga are given in the appendix the framework of pmofhs ga which combines with the modflow and mt3dms to solve the multi objective optimal design of groundwater remediation system under coexisting uncertainties of parameters are shown in fig 1 there are three main stages the first stage corresponds to initialization of the pmofhs ga and the optimization problem generation of the initial population of the pmofhs ga and the uncertain fields of aquifer uncertain parameters the second stage executes the optimization procedure of pmofhs ga to find pareto solutions for the groundwater remediation problem the state variables concentration of different locations used to calculate the objective functions are extracted from the modflow and mt3dms program the last stage checks the termination condition of the pmofhs ga 3 example case study 3 1 problem description the proposed method is applied on a hypothetical case study adapted from zheng and wang 2003 and luo et al 2014 which is about the optimal design of a groundwater remediation system based on the pat method the contaminated aquifer is two dimensional measuring 3450 m and 2550 m in the and y directions respectively the boundary conditions of the flow model are given as constant head on east and west sides and no flow on north and south sides the constant head values of east and west sides are 35 m and 25 m respectively the boundary conditions of the transport model are zero mass flux on north west and south sides and a specified advective flux on east side the flow in the contaminant aquifer is steady there are four potential pumping wells to remove contaminant mass in the aquifer shown in fig 2 the gray area shown in fig 2 is the constraint area for contaminant concentration 20 ppb at the end of the remediation period in this study while the pumping capacity for the 4 potential pumping wells are 10 000 m3 d each the multi objective optimization model is given by eqs 1 7 and the values of α 1 α 2 and α 3 are set to 10 000 usd u s dollar 0 04 usd m3m and 1 usd g in order to find the pareto optimal solutions the constraints must be modified to unconstrained fitness measures by addition of the constraint violations to the objective functions as penalties hence if the remediation schemes disobey constraints the objectives are penalized thus the solutions with lower fitness have little chance of surviving in the evolutionary process the remediation period is set as 5 years other input parameters for the flow and transport models are given in table 1 3 2 generalization of the coexisting uncertain fields of k and n in this study the k follows a lognormal distribution and satisfies a two dimensional separable exponential covariance function as follows 14 c y h σ y 2 exp s x λ x s y λ y where σ y 2 is the variance of the logarithmic k i e y lnk λ x and λ y are the correlation in x and y direction respectively s x and s y are the distance in x and y directions respectively in this study a karhunen loeve k l expansion is adopted to generate a set of k realizations zhang and lu 2004 the porosity n is also lognormally distributed the correlation between k and n can be calculated by the local mean and variance of n at any spatial position after generating the k fields eq 15 15 μ n i μ n ρ σ n σ y y i μ y σ n i 2 σ n 2 1 0 c e 2 where μ n i is the local mean value of n at a location i μ n and σ n are the global mean and variance of the random fields of n respectively μ y and σ y are the global mean and variance of lnk respectively σ n i 2 is the local variance value of n at a location i ce is the correlation coefficient of the lnk and n based on the above method the mean value and variance of n at a position i can be generated by random sampling from n μ n i σ n i 2 then the generated random value can be treated as a value of n at a position i by performing this operation on all grid nodes in the study area the generated random fields account for the correlation between n and k it should be noted that random sampling may lead to negative values of n thus the upper and lower bound of n are considered in our study 3 3 optimization results and analysis pareto optimal solutions of the application problem are calculated by the pmofhs ga then the reliability of pareto optimal solutions is evaluated by monte carlo mc analysis during the mc analysis the final pareto solutions for remediation schemes are reevaluated across all k and n realizations 1000 realizations in this study after that the statistical mean and the upper 95th percentile in this study and lower 5th percentile in this study bounds of the mc analysis are calculated the statistical mean values from the mc analysis are considered reference representing the most reliable and stable scheme singh and minsker 2008 if the difference between the upper and lower values bandwidth of the mc analysis is small the uncertainty of the scheme is low two indicators are adopted to evaluate the reliability of the final pareto optimal solutions the first indicator is the root mean square error rmse which measures the goodness of fit between the optimized schemes and the statistical means of mc analysis the second indicator is the average bandwidth of the uncertain intervals band which represents the variability of the final pareto solutions luo et al 2016 2014 the greater the rmse the lower the reliability of the pareto solutions and the greater the band the larger the variability of the pareto solutions the hydrogeological conditions of a contaminant field are complex and usually involve many uncertain parameters with the k and n being the main uncertain ones moreover in some cases the two parameters correlate with each other for instance for sandy soil k and n often show a positive correlation while for clay the correlation is usually negative therefore in this section different scenarios with varying k and n realizations shown in table 2 were considered and the influences of the coexistence of k and n uncertainties on final pareto solutions were discussed the main controlling parameters of the pmofhs ga were set as follows population size 100 hmcr 0 95 par min 0 1 par max 0 95 pcross 0 9 capacity of pareto set filter 100 ni 100 deb et al 2002 luo et al 2014 3 3 1 scenario 1 scenario 1 only considers the uncertainty of k fig 3 a shows the final pareto optimal solutions and the mc analysis results the red plus icons in fig 3 a correspond to the final pareto optimal solutions which indicate the conflicting objectives between the remediation cost and the remaining contaminant mass where the remaining contaminant mass decreases with the increasing remediation cost however when the remaining contaminant mass in aquifers decreases to a certain level 1 7 show in fig 3 a increasing remediation cost no longer improves the remediation effect of the pat method any more the pmofhs ga based pareto optimal solutions are located between the upper and lower bounds of the mc analysis and are extremely close to the average values of mc analysis the rmse of the remediation cost and remaining contaminant mass are 1 61 million usd and 0 22 respectively shown in table 3 and the band of mc analysis are 8 76 million usd and 2 53 for remediation cost and remaining contaminant mass respectively these results indicate that the pmofhs ga is an effective algorithm for finding pareto solutions of high reliability and low variability 3 3 2 scenario 2 fig 3 b shows the pareto optimal solutions and mc analysis results of pmofhs ga under the condition of uncertain porosity that is uncorrelated with uncertain k in fig 3 b the trend of the pareto front is similar with that of scenario 1 the pareto solutions are located between the upper and lower bounds of the mc analysis and are close to the average values of the mc analysis the statistics in table 3 show that the rmse of the remediation cost and remaining contaminant mass are 2 29 million usd and 0 33 respectively which are larger than that of scenario 1 this means the reliability of the pareto optimal solutions are lower than that of scenario 1 besides the band of mc analysis are 8 97 million usd and 3 88 which are also a little larger than that of scenario 1 therefore the variability of the pareto optimal solutions under coexisting uncertainties of k and n is higher than that which only considers the uncertainty of k therefore risk will arise if the uncertainty of n is neglected when designing groundwater remediation schemes fig 4 compares the standard deviation of the mc analysis for remediation cost and remaining contaminant mass for scenarios 1 and 2 results show that with the increasing of the average remediation cost the standard deviation values are almost aligned along a straight line this indicates that the uncertainty of n has no significant impact on the reliability of remediation cost the main reason for this is the definition of the first objective function in this study the remediation cost consists of three part 1 the fixed cost of well drilling and installation 2 the cost of groundwater extraction and 3 the cost of contaminant groundwater treatment among them the cost of water extraction is the main part which will not be significantly affected by the uncertainty of n however for the average remaining contaminant mass in aquifers the values of the standard deviation under the coexisting uncertainties of k and n are significantly bigger than that under a single uncertainty of k this indicates that the uncertainty of n plays an important role for the distribution of remaining contaminant mass in the aquifer which is consistent with previous studies li et al 2012 xue and xie 2007 thus both the uncertainty of k and n must be considered when searching for a reliable groundwater remediation scheme 3 3 3 scenario 3 in this scenario we first compared the optimization results considering the positive correlation between uncertain k and n scenario 3a shown in table 2 with scenario 1 and 2 to analyze the effects of correlation between uncertain k and n on the final pareto optimal solutions then different variances of n scenario 3b and scenario 3c shown in table 2 are considered to explore the influence of uncertainty degrees of n on the optimization results fig 3 c shows the pareto optimal solutions and mc analysis results of pmofhs ga under scenario 3a the trend of the pareto optimal solutions in fig 3 c is similar to that in scenario 1 and 2 meanwhile the pareto solutions are located between the upper and lower bounds of the mc analysis and fit well with the average values of the mc analysis however compared with the performances of scenario 1 and 2 in table 3 the rmse of the remediation cost and remaining mass are 1 61 million usd and 0 36 respectively which are larger than the values of scenario 1 but smaller than that of scenario 2 this means that the reliability of the pareto solutions is lower than that of scenario 1 but higher than that of scenario 2 the band of mc analysis are 11 37 million usd and 4 94 for the remediation cost and mass remaining respectively which are larger than that of scenario 1 and scenario 2 this indicates the variability of the pareto solutions is higher than the case that only considers the uncertainty of k or non correlated k and n therefore both the uncertainty of n and the correlation between uncertain k and n will affect the reliability and variability of the optimization results to further analyze the influence of the uncertain degrees of n on final optimization results another two conditions scenario 3b and scenario 3c are considered the pareto solutions and mc analysis results are shown in fig 5 pareto solutions fit well with the average values of mc analysis and all of them located between the upper and lower bounds of mc analysis however it can be seen that with the increasing of σ2 n there is an evident increase of the bandwidth between the upper and lower bounds this result can also be supported by the statistics in table 3 when the value of σ2 n increases from 0 001 0 005 to 0 01 the band of mc analysis for remediation cost increase from 9 10 million usd 11 37 million usd to 13 42 million usd and for the remaining mass it increases from 2 89 4 94 to 6 83 this indicates that with the increasing variance of n the variability of pareto optimal solutions increases fig 6 further shows the comparison of standard deviation of mc analysis for the remediation cost and mass remained in aquifer under scenario 1 and 3 for the remediation cost with the increasing of the average remediation cost the standard deviation values are almost aligned in a straight line under different scenarios except for a few points where the remediation cost is high this indicates that the uncertainty of n and the coefficient between uncertain k and n have no significant impact on the reliability of remediation cost however for the average contaminant mass remained in aquifers the value of the standard deviation increase with the increasement of σ2 n this indicates that the uncertainty of n plays an important role in the uncertainty of remaining contaminant mass in aquifers the correlation between uncertainties of k and n also affects the distribution of contaminant mass in aquifers the standard deviation of the average remaining mass under scenario 3 is larger than that under scenario 1 as shown in fig 6 therefore both the uncertainty of n and the correlation between uncertainties of k and n must be considered when looking for a reliable groundwater remediation scheme 3 3 4 scenario 4 fig 3 d shows the pareto solutions and mc analysis under the negative correlation between n and k it can be seen that all of pareto solutions are located between the upper and lower boundaries of the mc analysis and the pareto solutions are close to the average values of the mc analysis however compared with other conditions in fig 3 the bandwidth between the upper and lower boundaries are largest and the fitting between the pareto solutions and the average values of mc analysis are the worst in table 3 the rmse and band of remediation cost are 3 24 million usd and 12 31 million usd respectively and the rmse and band of remaining mass are 0 99 and 6 74 respectively all of the rmse and band of scenario 4 are larger than that under other conditions in table 3 it shows that the reliability of pareto solutions is the lowest and the variability is the largest when the correlation between uncertain k and n is negative fig 7 shows the distribution of the standard deviation of mc analysis for remediation cost and remaining contaminant mass in aquifer under different values of ce for the remediation cost the standard deviation values almost align in a straight line under different ce however for the average contaminant mass remained in aquifers the standard deviations differ significantly under different ce and the values which account for the impact of ce are much larger than that do not especially when ce is negative the results indicate that the ce must also be considered when searching for the best remediation scheme otherwise it will underestimate the uncertainty of remaining mass in aquifers and lead to low reliable remediation schemes in order to further analyze the influence of ce and uncertainty of n on the pumping schemes different values of mass remained in aquifer and the corresponding pumping rates are given in fig 8 the sequence of the pumping rate is q well2 q well3 q well1 q well4 under scenario 1 while the sequence changes to q well2 q well1 q well3 q well4 under scenario 2 when ce 0 the trend of pumping rates is similar but it can still be seen that the pumping schemes are quite different even under the same average mass since the location of well 2 is the closest to the center of the contaminant plume the pumping rate of well 2 is always the biggest instead the location of well 4 is far from the center of the contaminant plume and the pumping rate of well 4 is always close to 0 this is consistent with the common sense that setting remediation wells at the downstream of the plume center can obtain better remediation effects the reason for the changes of the pumping schemes is due to the uncertainties of aquifer k and n and the correlation between them which lead to different distributions of contaminant mass in aquifers fig 9 shows the distribution of the contaminant plume under random selected uncertain fields of k and n at the end of 5 years for different scenarios it is clear that the center of the contaminant plume and their distribution are different during the optimization process the pmofhs ga will constantly adjust the pumping scheme according to the distribution of the remaining mass in aquifer therefore the uncertainty of k n and the correlation between them must be considered at the same time otherwise it will lead to unreasonable remediation schemes in addition it might happen that in the optimization one only considers the uncertainty of one parameter e g k even though there is a coexisting uncertainty between k and n to investigate this issue fig 10 shows the cumulative probability distributions of the remaining mass for two remediation schemes obtained from scenario 1 but reevaluated under the k and n realizations of scenario 2 scenario 3a and scenario 4 in fig 10a the probability of the remaining mass in aquifer no larger than 10 can reach to 77 while for scenario 2 scenario 3a and scenario 4 the probability is 27 51 and 29 similarly in fig 10b the probability no larger than 20 can reach to 60 instead for scenario 2 scenario 3a and scenario 4 the probability is 38 58 and 37 respectively these results further confirmed that the uncertainty of aquifer n should not be neglected otherwise the risk of failure to achieve good remediation goals will increase meanwhile what will happen if pareto solutions which fail to consider the correlation between k and n are used as remediation schemes to answer this question fig 11 shows the cumulative probability distributions of the remaining mass by reevaluating the solution of scenario 2 with remaining mass close to 5 across the k and n realizations of scenario 3a and scenario 4 the probability of mass remained in aquifer no larger than 5 is 53 under scenario 2 instead the reevaluated probability under scenario 3 and scenario 4 is 72 and 34 respectively this indicates that the risk of failure to reach the remediation objective will increase when there is a negative correlation between k and n but the risk will decrease if such correlation is positive if the objective of remaining mass is no larger than 5 the remediation cost are 6 2 million usd 5 3 million usd and 7 3 million usd under scenario 2 scenario 3a and scenario 4 3 4 decision making of the final optimal remediation scheme how to select the final remediation scheme from final pareto optimal solutions is the last but an important step especially when there are uncertainties in objective functions decision makers may just want to get the final remediation strategy which can satisfy basic performance and is easy to implement however a more proper and scientific approach should fully consider the impact of various uncertain factors on the design results in order to improve the accuracy of every remediation strategy in this section a new decision making strategy which is based on the reliability of different objective functions is proposed to help decision makers to select the final optimal remediation scheme there are four steps in the proposed decision making strategy for the final remediation scheme i implementing mc analysis on every pareto solutions under all of the realizations of k and n fields ii getting the cumulative probability distribution function of the objective functions iii selecting a quantile according to the reliability request if the reliability request is 95 then the quantile is set to 95 for all pareto solutions then the pareto front under the select reliability request is gotten iv choosing the final remediation scheme according to the budget and expected remediation effect fig 12 shows the pareto fronts of a selected combinations of objective reliability under scenario 3a results show that with the increasing reliability the remediation cost will increase while the remaining mass in the aquifer stays the same similarly the remaining mass will increase with the increasing reliability without altering the remediation cost in practice if the decision maker request that reliabilities of remaining mass in the aquifer and the remediation cost no lower than 95 and 75 respectively and the mass remained in the aquifer must be less than 5 the pareto solution represented by the black diamond s1 in the blue pareto front can be selected as the final remediation scheme the detailed pumping scheme and corresponding objective values are shown in table 4 if the decision maker prefers that the reliabilities of the mass remaining in the aquifer and the remediation cost no lower than 95 at the same time and the mass remaining must be less than 10 the pareto solution represented by the black square s2 in the red pareto front can be selected as the final remediation scheme similarly if the reliabilities of the remaining mass and the remediation cost should be not lower than 75 and 95 respectively and the remediation cost be no more than 20 million usd then the black triangle s3 in the green pareto front can be selected as the final remediation scheme for other groundwater contaminant fields designers should firstly carry out hydrogeological survey and determine the hydrogeological parameters including the correlation between the hydrogeological parameters then they just need to replace the groundwater flow and contaminant mass transport simulation models and run the simulation optimization model proposed in this study after getting the pareto front the aforementioned decision making strategy can be implemented where designers calculate the new pareto front according to their desired reliability finally decision makers can decide the final remediation scheme according to the budget and repair effect requirements 4 conclusions this work focuses on the optimal design of groundwater remediation systems considering the coexisting uncertainties of aquifer k and n a new moea namely the pmofhs ga is proposed to find pareto solutions a benchmark test using conv1 and zdt4 problems has confirmed the high efficiency of the proposed pmofhs ga the method is applied on a hypothetical case for designing groundwater remediation schemes the optimization results under different scenarios considering uncertain k and n realization fields showed the high reliability and low variability of pareto solutions based on the pmofhs ga however the results were significantly affected by the coexisting uncertainties of k and n and the correlation between them especially for the reliability and variability of remaining mass in aquifers when the uncertainties of k and n were considered simultaneously the reliability of pareto solutions decreased and the variability of pareto solutions increased in addition different values of ce also affected the distribution of contaminant mass in aquifers the spread of the contaminant plume decreased when ce was positive while increased when ce was negative these eventually affected the reliability of the optimization results thus the detailed hydrogeological condition and correct identification of the correlation between uncertain k and n are critical for achieving reliable groundwater remediation schemes the proposed decision making strategy can facilitate decision makers to reasonably select the final groundwater remediation scheme which can be applied to other optimization problems under uncertainty the uncertainty sources in groundwater simulation include not only aquifer parameters but also model structures in future studies the uncertainty of model structures should also be considered simultaneously in the optimization process credit authorship contribution statement yun yang conceptualization methodology investigation data curation writing original draft jichun wu supervision writing review editing funding acquisition qiankun luo formal analysis software writing review editing project administration jianfeng wu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is financially supported by the national natural science foundation of china no 41730856 41502226 the authors are grateful to editors and reviewers for their invaluable suggestions on the manuscript appendix a the performance measures of pmofhs ga in order to test the efficiency of the pmofhs ga two classic multi objective benchmark functions conv1 and zdt4 were considered deb et al 2002 their mathematical forms are shown in eq a 1 and a 2 respectively two performance measures namely the convergence indicator γ and the diversity indicator δ were adopted to evaluate the results of pmofhs ga mofhs and nsgaii γ is used to measure the convergence of pareto solutions to the true pareto optimal front and δ measures the spread of optimized solutions deb et al 2002 luo et al 2012 if all pareto solutions lie exactly on the true pareto front the value of γ is 0 if all pareto solutions with the most widely and uniformly spread out set of nondominated solutions the value of δ will equal to 0 or close to 0 for other cases the value of δ would be greater than 0 a1 f 1 x x 1 1 4 i 2 n x i 1 2 f 2 x i 1 n x i 1 2 subject to 5 0 x i 5 0 i 1 2 30 a2 f 1 x x 1 f 2 x g x 1 f 1 x g x subject to 0 x 1 1 0 g x 1 10 n 1 i 2 n x i 2 10 cos 4 π x i 5 0 x i 5 0 i 2 3 10 fig a1 shows the true pareto fronts and the pareto solutions based on the pmofhs ga mofhs and nsgaii for the conv1 and zdt4 problems respectively compared with results from the mofhs and nsgaii the pareto solutions of pmofhs ga are more uniformly distributed and closer to the true pareto front table a1 shows the performance of γ and δ for the three algorithms for the conv1 function the values of γ and δ from pmofhs ga are 0 7430 and 0 2226 respectively significantly smaller than that of mofhs and nsgaii for the zdt4 function the values of γ and δ from pmofhs ga and mofhs are much smaller than that of nsgaii although the γ and δ from pmofhs ga are close to that of mofhs the pmofhs ga performs slightly better results indicate that the pmofhs ga is a promising moea for solving multi objective optimization problems 
