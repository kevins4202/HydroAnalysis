index,text
4415,the prerequisites for groundwater pollution remediation include providing accurate identification of hydraulic parameters of the contaminated site and retrospecting pollution source release history from sparse and discrete observation data however expensive time running and high nonlinearity of groundwater solute transport simulation model hinder precise and fast identification to overcome expensive running cost a deep regularization neural network drnn was introduced to emulate the highly nonlinear simulation model a hybrid heuristic algorithm integrating a particle swarm optimization pso and a differential evolution markov chain demc method was employed to provide reliable identification results of pollution source characteristics and hydraulic parameters in particular demc conducted a global search and pso performed a local search to evaluate transferability for various groundwater pollution cases the proposed method was utilized to provide an identification for a point source pollution case and a non point source pollution case the results indicated that drnn was capable of emulating input output relationship of a highly nonlinear and high time expense simulation model of two cases with a r2 of 0 997 and 0 984 respectively accelerating identification process furthermore when the pso was combined with demc the optimization was accelerated while escaping from the local optimum substantially improving the efficiency and accuracy of the identification task keywords groundwater pollution source simultaneous identification deep regularization neural network hybrid heuristic algorithm 1 introduction in recent years groundwater pollution poses a threat to drinking water safety drawing extensive attention however the high costs of remediation reagents and restoration scheme design make remediating contaminated aquifer a challenging task rendering it necessary to identify groundwater pollution source to charge for the responsible party tiyasha et al 2020 groundwater pollution source identification gpsi refers to retrospecting source release history and determining the source locations it is an inverse problem in mathematics but in real situations it is not feasible to directly identify groundwater pollution source characteristics and hydraulic parameters han et al 2020a thus accessibly relevant state variables such as time series monitoring data must be measured including hydraulic heads and contaminant concentrations to infer inaccessible parameters such as groundwater pollution source characteristics and field parameters a groundwater solute transport simulation model can illustrate the relationship between these parameters and spatial temporal distribution of contaminant concentrations armanuos et al 2020 in general gpsi is conducted by matching simulation model outputs with monitoring data by updating combinations of unknown variables xing et al 2019 however there are still some challenges associated with gpsi which must be addressed first fast and accurate identification has always been a key point in gpsi task the mathematical physical approaches employed to solve gpsi can be classified into two main categories as follows stochastic simulation statistic method guo et al 2020 zhang et al 2020 and simulation optimization method ayvaz 2010 zhao et al 2020 recently the simulation optimization method has drawn increasing attention owing to its high and stable estimation accuracy of optimal solutions datta et al 2011 when using the simulation optimization method a transport solute simulation model is embedded as an equality constraint for the optimization model where the objective function is to minimize the bias of simulation values and observation values li et al 2020 however solving the optimization model incurs thousands of invoking causing tremendous computational burden hou and lu 2018 therefore a surrogate system is employed to replace the simulation model which alleviates the computation burden during the optimization process this can substantially improve the efficiency of gpsi second most of the existing studies on groundwater pollution source release history characterization assume given release initial time which might be vague in real situation ayvaz 2010 jamshidi et al 2020 wang and lu 2020 to overcome this problem a suspicious release period with a long sequence must be defined in which the release initial time must be included however this will apparently increase the dimensions of parameters to estimate making the identification task a highly nonlinear inverse problem among all surrogate methods there are three main categories asher et al 2015 liu et al 2021 namely data driven surrogate systems projection based surrogate systems and hierarchical surrogate systems owing to high accuracy and swift invoking data driven surrogate systems are widely utilized as an alternative simulation models for data approximation in gpsi matott and rabideau 2008 in general the methods employed in data driven surrogate systems can be divided into shallow learning methods and deep learning methods according to the quantities of training parameters in the algorithm shallow learning methods such as kriging and support vector regression svr are widely exploited in simple flow models a relatively low nonlinear system and have shown promising performance as a surrogate model han et al 2020b mirarabi et al 2019 however with increasing dimensional inputs the nonlinearity of the mapping input output relationship gets stronger matott and rabideau 2008 and learning capacity of shallow learning methods including kriging and svr might become inadequate to support fitting such a highly nonlinear system causing underfitting to broaden the learning capacity more training data or a more complex structure are usually required shen 2018 as training data acquisition is limited by computational time and costs the present study aimed to choose deep learning methods with a complicated structure to efficiently improve the fitting accuracy with limited training samples among the deep learning methods deep neural networks dnn have drawn widespread attention in various fields owing to excellent descriptive and predictive ability jin et al 2019 popa 2018 zhou et al 2020 the massive training parameters in dnn substantially extend the learning capacity to complex problems making a dnn potentially viable surrogate system for highly nonlinear system most of the dnns are utilized for classification tasks but rarely for regression tasks guo et al 2016 rawat and wang 2017 and the surrogate system of gpsi is apparently a regression task thus a dnn for regression requires to be explored however training massive training parameters with limited data may cause overfitting gupta et al 2018 murakoshi 2005 which implies high accuracy for the training dataset but low accuracy for the validation dataset according to occam s razor regularization methods are introduced to efficiently alleviate overfitting in dnn without increasing data quantities resulting in promising performance for prediction poggio and girosi 1990 srivastava et al 2014 therefore in the present study l2 regularization and dropout regularization were employed to improve the dnn performance third the search efficiency of optimization algorithm for high dimensional space can be limited by the selection of initial solutions hatamlou 2013 he and wang 2007 an optimization process is a search path from the initial solutions to optimal solutions operated by a search algorithm leung and wang 2001 thus the initial solutions play essential roles in the optimization process kim et al 2017 and the closer the initial solution to the optimal solution the faster the speed of the optimization process the proper initial solutions can be determined by limited the search ranges as the goal of gpsi is to match simulation outputs to monitoring data by updating combinations of unknown variables the simulation optimization method may suffer from similar outputs of different inputs sodi however in traditional heuristic optimization algorithms including genetic algorithm and particle swarm optimization pso algorithm sodi can possibly cause the search process to fall into local optimum hou et al 2021 li et al 2021 hindering precise identification an effective way to alleviate sodi is to limit the ranges of unknown variables lopez et al 2015 mera et al 2003 recently differential evolution markov chain demc approach has been widely employed to infer the posterior distribution based on prior knowledge iglesias et al 2012 zhang et al 2016 enabling to limit the search ranges by estimating the posterior distribution of unknown variables in gpsi therefore in the present study to improve the search efficiency and accuracy of pso demc was introduced for the first time to provide reliable ranges of decision variables and select proper initial solutions for pso in gpsi in particular the demc was utilized to conduct a global search and pso was employed to perform a local search the demc pso hybrid algorithm is a global local search strategy for handling high dimensional optimization problem in gpsi in the present study a demc pso hybrid algorithm was introduced for the first time to improve search efficiency and accuracy of gpsi to relieve the huge computational burden when using simulation optimization method and tackle the challenge of approximating a complex nonlinear system a deep regularization neural network drnn was utilized as a surrogate system of transport simulation model to embed in optimization model the results indicated that the drnn surrogate based hybrid heuristic algorithm can provide stable and accurate estimation of the location initial release time release intensities and hydraulic conductivities for a point source pollution identification and non point source pollution identification the main contribution of the present study is to proposed a deep learning method for reducing expensive running burden of a highly nonlinear simulation model and apply a hybrid heuristic algorithm to substantially improve estimation efficiency and accuracy for complex nonlinear gpsi problems 2 methodology 2 1 numerical simulation model a groundwater numerical simulation model describes the process of groundwater flow and solute transport in the present study the transient saturated groundwater flow was considered to satisfy the following formula jiang et al 2018 1 x i k ij h x j w μ h t x y γ i j 1 2 t 0 where k ij is the hydraulic conductivity h is the hydraulic head w is the volumetric flux per unit volume μ is the specific yield and γ is the boundary of simulation domain coupled with the groundwater flow numeric equation the solute transport can be given as follows 2 c t x i d ij c x j x i u ij c r θ x y γ i j 1 2 t 0 3 u i k ij θ h x i i j 1 2 where c is the contamination concentration d ij is the dispersion coefficient u ij is the mean linear velocity of the groundwater flow following darcy s law r is the source or sink term θ is the effective porosity of the aquifer medium and γ is the boundary of simulation domain in particular the groundwater numerical simulation model was solved in the present study by exploiting the modflow module langevin et al 2003 and mt3d module zheng and wang 1999 in groundwater modeling systems gms 2 2 drnn 2 2 1 dnn structure artificial neural network ann is a mathematical algorithm for distributed information processing which mimics the behavior characteristics of the human nervous system schmidhuber 2015 typical anns consist of layers including input output and hidden layers and neurons as shown in fig 1 dnn commonly refers to ann with multiple hidden layers showing excellent capacity for feature extraction on classification and regression task arel et al 2010 in the dnn training process the raw input data are first entered through the input layer then passed to the hidden layers the hidden layers can extract complex and abstract characteristics through multiple nonlinear transformation finally the abstract characteristics are reverted into responses comparing with true output values it is assumed that there are m layers in dnn the i th neuron output in the k th layer z i k can be expressed as follows yuan et al 2020 4 z i k w i k a k 1 b i k k 1 2 m 5 a k g z k where w i k is the weight value of the i th neuron in the k th layer a k is the activation output of neurons in the k th layer w i k a k 1 denotes the dot product of w i k and a k b i k is the bias value of the i th neuron output in the k th layer and g z i k represents the activation function leaky relu in the present study the application of leaky relu activation function retains gradient for large positive inputs promoting the training process of dnn and can be expressed as wang et al 2018 6 g x max μ x x μ 0 1 where μ is the gradient constant with the default value set as 0 1 the weights and biases can be updated by minimizing the loss function between the responses and true targets the loss function e d can be optimized by adam algorithm and it can be expressed as burden and winkler 2008 7 e d 1 m i 1 m k 1 q z i k o i k 2 where z i k represents the i th neuron output in the k th layer o i k denotes the actual output of the i th neuron output in k th layer m signifies the numbers of neurons and q indicates numbers of layers in the present study the dnn was a typical feedback neural network which was utilized for fitting mapping relationship between unknown variables pollution source spatial temporal characteristics and hydraulic conductivities and contaminant concentrations observed in observation wells fig 2 2 2 2 l2 regularization and dropout regularization while multiple layers and massive neurons in the dnn significantly enhance the learning ability of highly nonlinear system it can also cause overfitting resulting in over characterization of training dataset and deviation of predictions to validation dataset to alleviate overfitting and improve generalization performance the strategy of regularization had been employed in dnn training process srivastava et al 2014 regularization is accomplished by transforming error function to improve algorithm generalization ability poggio and girosi 1990 according to the variables to be optimized regularization can be divided into five categories as follows data based davis et al 2018 nalepa et al 2019 network architecture based allred et al 2017 zhang et al 2019 error function based phaisangittisagul 2016 regularization term based and optimization based chan et al 2003 among the regularization methods error function based methods such as l2 regularization and dropout regularization have been widely utilized to improve dnn generalization performance with regard to l2 regularization the error function er can be given as follows rakitianskaia et al 2014 8 er e d λ e s 9 e s w 2 2 i w i 2 where e d is given in equation λ is the regularization coefficient and w 2 represents 2 norm of weight dropout regularization refers to randomly discarding a portion of the neuron output characteristics of hidden layers in the dnn with certain probability watt et al 2018 making training outputs in hidden layer not dependent on one single neuron in this way each neuron is forced to learn an informative feature independent of the surrounding hidden neurons srivastava et al 2014 tian and pan 2020 fig 3 shows a portion of dnn structure before and after dropout regularization which implied more streamlined network structure when using dropout propitious to alleviating overfitting and improving validation performance the dropout probability β is the probability that one neuron is disabled to the other neurons in the hidden layers in the present study β was set to 0 1 at dense 5 layer in general l2 regularization was applied to dense 1 4 layers and λ was set to 0 1 0 01 0 001 and 0 001 respectively dropout regularization was utilized in dense 5 layer the summary of the drnn structure is presented in table 1 2 3 kriging method kriging method has been widely used in spatial interpolation and surrogate system construction owing to its good ability to perform unbiased estimation hengl et al 2007 kleijnen 2017 simpson and mistree 2001 the proposed model is an ordinary kriging model which can be expressed as follows guo et al 2019 10 y x g x z x where x represents the inputs of the kriging model unknown variables y x denotes the outputs of the kriging model contaminant concentrations of observation wells g x is the global model of the origin function and z x signifies a gaussian random function and satisfies the following formula guo et al 2019 11 cov z x i z x j σ 2 r r x i x j i j 1 2 n 12 r x i x j exp k 1 n θ k x k i x k j 2 where r represents the correlation function r denotes the symmetric correlation matrix n is the number of samples x k i and x k j are the k th component of x i and x j respectively and θ k can be determined by minimizing the deviation between model predictions and actual values 2 4 svr svr is a transformation form of support vector machine to address regression task owing to its high data prediction accuracy svr has been widely utilized to construct surrogate system for groundwater inverse problem the nonlinear regression function can be expressed as follows hu et al 2014 13 y w t φ x b where y represents the contaminant concentrations of observation wells in the present study x denotes the unknown variables pollution spatial temporal characteristics and hydraulic conductivities φ x is the mapping function transforming the unknown variables to a higher dimensional feature space w is the fitting coefficients matrix and b is the fitting bias matrix generally kernel tricks strategy such as radial basis function rbf is exploited in svr to transform nonlinear problem to linear problem which can be expressed as constrained optimization problem chang and lin 2011 14 minimize e w 1 2 w 2 c i 0 m ξ i ξ i 15 s t y i w φ x b ε ξ i w φ x b y i ε ξ i ξ i ξ i 0 where w 2 represents 2 norm of w ξ i and ξ i are the relaxation coefficients w φ x is the dot product of w and φ x and ε is the acceptable bias calculated by using karush kuhn tucker condition methods the constraint optimization problem can be transformed as follows smola and scholkopf 2004 16 w i 1 m α i α i ϕ x i 17 f x i 1 m α i α i ϕ x i φ x b where α i and α i represent lagrange multipliers ϕ x i is the kernel function in the present study rbf kernel trick was employed in svr 2 5 demc pso hybrid algorithm the demc algorithm is a stochastic heuristic algorithm combining differential evolution and monte carlo markov chain and shows promising global search capacity for complex posterior distribution vrugt et al 2009 in the present study metropolis acceptance rule was exploited in demc algorithm to broaden search ergodicity and parallel multi candidate strategy was utilized to promote search efficiency the main demc processes were as follows vrugt 2016 step1 fixed parameter setting set the maximum generation number n current generation number k population individual numbers m unknown variables numbers n and default jumping rate γ the default jumping rate can be expressed as 18 γ 2 38 2 n step2 initializing create initial population x 0 x i 1 0 x i 2 0 x i m 0 and calculate the fitness function f the universal population expression can be expressed as 19 x k x i 1 k x i 2 k x i m k step3 mutation the i th individual mutates based on the following law ter braak 2006 20 x i k x i k γ x r a n d 1 k x r a n d 2 k ε where x i k is the mutation individual for k th generation x r a n d 1 k x r a n d 2 k are two individuals randomly selected from m individuals and ε is the minor disturbance step 4 selection metropolis probability p acc can be employed to determine whether to accept x i k as follows 21 p acc l x i k l x i k 22 l x t 1 n 1 2 π σ t 2 exp 1 2 y obs y t x σ t 2 where l x implies the fitness value y obs are the observation data y t x are the simulated outputs of simulation model the measurement error δ of the observation data obeys normal distribution δ 0 σ 2 n represents the number of observation data if p acc 1 u u r a n d 0 1 accept x i k otherwise keep x i k and reject x i k then mutation individual x i k 1 is determined repeat step2 4 until k n choose the best individual with the largest average fitness value as output finally analyze the confidence range and best generation with the highest fitness value of the best individual the pso algorithm is a bionic global optimization algorithm inspired by birds flight behavior kennedy and eberhart 2002 for n dimensional optimization case pso algorithm considers each individual as a particle without volume and mass in the n dimensional search space and flies at a certain speed in the search space the optimized search is guided by swarm intelligence generated by interparticle cooperation and competition in population clerc and kennedy 2002 yang et al 2019 in the optimization search process the particle position can be expressed as n dimensional vector x and the particle velocity can be expressed as vector v indicating search direction each particle position corresponds to a fitness value indicating the approximation degree between candidate point and optimal point and x and v are updated as follows yaseen et al 2019 21 x i t 1 x i t v i t 1 1 i m 22 v i t 1 w v i t c 1 r 1 t 1 x pbest i t x i t c 2 r 2 t 1 x nbest i t x i t where m is the population size w is the inertia weight determining new velocity in time t 1 c 1 and c 2 are learning rate r 1 t and r 2 t are random vectors from 0 1 normal distribution x pbest i t is the optimal position for particle i at time t and x nbest i t is the optimal position of all particles in population at time t the steps of pso algorithm can be given as follows step 1 fixed parameter setting set the search space low boundary lb and up boundary ub as confidence ranges generated by demc algorithm velocity low boundary vmin and up boundary v max population size m inertia weight w maximum iteration k learning rate c 1 c 2 and tolerance precision ε step 2 initializing and evaluation set the optimal solution generated by demc algorithm as initial population evaluate each particle fitness and calculate the fitness values step 3 check and selection update particle position x and velocity v based on equation 21 if v i v max set velocity to v max if v i v min set velocity to v min if fitness values of updated particle are smaller than particle before updating accept x i t 1 otherwise retain x i t step 4 go back to step 2 until max iteration or tolerance precision is reached in general in the demc pso hybrid algorithm demc algorithm was utilized to generate confidence ranges and initial particle for pso algorithm by conducting a global search whereas pso algorithm was employed to perform a local search in confidence ranges 3 method application 3 1 case overview as the present study was aimed to explore solving an inverse problem by utilizing the drnn hybrid heuristic algorithm see fig 4 two hypothetical cases were designed to evaluate the performance of the developed method 3 1 1 case 1 point source pollution identification the spatial domain comprised two dimensional heterogenous aquifer with a length of 400 m and width of 300 m the hydraulic conductivity field was divided into four zones according to medium particles as follows k1 k2 k3 and k4 the up and down boundaries were no flow boundaries whereas the left and right boundaries were specific linear head boundaries fig 5 the simulation time lasted for 10 years with 10 stress periods every year is one stress period a point groundwater pollution source released contaminants into aquifer during 2nd period to 9th period six observation wells 1 2 3 4 5 6 were established to monitor contaminant concentration in the aquifer per year the background contaminant concentration was set to 0 mg l and the contaminant transport process was assumed to be conservative involving no chemical transformation and biodegradation process in general the unknown variables to identify were characterized by 16 parameters location l x y release intensities during stress period s s ti and partitions hydraulic conductivities k k m where i 1 2 10 m 1 2 3 4 the site was spatially discretized into 30 000 200 150 grids the reference values and ranges of pollution source spatial and temporal characteristics and hydraulic parameters to estimate results of gpsi are listed in table 2 in particular location initial release time release intensities and hydraulic conductivities were set as unknown variables in the gpsi process unlike in the real situation as no authentic measured data are involved in the hypothetical case the location initial release time release intensities and hydraulic conductivities were considered as simulation model inputs in case 1 and the reference values are shown in table 3 the contaminant concentrations in the observation wells during the stress period were obtained as observation data in gpsi through treating reference values as inputs to forward run the simulation model fig 6 3 1 2 case 2 non point source pollution identification the spatial domain comprised two dimensional heterogenous aquifer with a length of 2000 m and width of 2500 m the hydraulic conductivity comprised four zones according to medium particles as follows k i k ii k iii and k iv the north and south boundaries were no flow boundary whereas the west and east boundaries were specific linear head boundaries fig 7 the aquifer and pollution relevant values and ranges are listed in table 4 the simulation time lasted for 5 stress periods every year is one stress period three plants were treated as potential non point sources and discharged contaminant into aquifer during stress periods nine observation wells obs1 9 were established to monitor contaminant concentration in the aquifer per year in total the unknown variables to identify were characterized by 19 parameters including partitions hydraulic conductivities k k i k i i k i i i k i v and release intensities during stress period s s d t q where d 1 2 q 1 2 5 table 5 listed the reference values of unknown variables the site was spatially discretized by 20 m 20 m bias cell the reference contaminant concentration distributions during stress period were shown in fig 8 3 2 application of drnn demc algorithm 3 2 1 establishment of surrogate model training data were required to extract hidden characteristics and laws of numerical simulation model whereas validation data were needed to evaluate surrogate model generalization ability latin hypercube sampling was exploited to ensure that the data uniformly covered sampling interval enhancing ergodicity of samples in the present study pollution source characteristics and partition hydraulic conductivities were treated as surrogate system inputs 16 dimensions for case 1 and 19 dimensions for case 2 the inputs were considered as independent variables surrogate system outputs were dynamic monitoring data of contaminant concentration in the observation wells 60 dimensions for case 1 and 45 dimensions for case 2 generated by forward running numerical simulation model it must be noted that inputs and outputs comprised dataset 1000 patterns for case 1 and 400 patterns for case 2 which was randomly divided into validation dataset 20 and training dataset 80 in the present study kriging svr normal dnn drnn were employed to establish surrogate system fed by training dataset and evaluated by validation dataset the performance of the surrogate system was assessed by a time cost and approximation accuracy the time cost can be estimated by the time required when invoking the same amount of iterations which was calculated on a pc with intel core i5 10400 cpu 2 90 ghz processor and 32 0 gb ram the approximation accuracy was evaluated by the following measurement criteria mean absolute error mae mean squared error mse root mean squared error rmse mean relative error mre and coefficient of determination r2 yuan et al 2020 mae can be determined as 23 mae 1 n i 1 n y i s y i d where y i s is the output of numerical simulation model and y i d is the output of surrogate system mse can be determined as 24 mse 1 n i 1 n y i s y i d 2 rmse can be calculated as 25 rmse mse 1 2 mre can be determined as 26 mre 1 n i 1 n y i s y i d y i s 100 r2 can be calculated as 27 r 2 1 i 1 n y i s y i d 2 y i s m i s 2 m i s 1 n i 1 n y i s after training with the dataset and validation by measurements the mapping relationship from unknown variables to contaminant concentration can be expressed by surrogate system as follows 28 c sim f s k where c sim is the numerical simulation model output which is replaced by the surrogate system output and s and k are described earlier see section 3 1 in the present study computation time was proposed to compare the computational burden of surrogate system and non surrogate system numerical simulation model 3 2 2 establishment of optimization model for case 1 gpsi can be described by constrained nonlinear programming cnp as follows 29 min z i 1 n t t 1 t m c i obs t c i sim t 2 30 s t c i sim f x y s t 1 s t 2 s t 3 s t 4 s t 5 s t 6 s t 7 s t 8 s t 9 s t 10 k 1 k 2 k 3 k 4 c l c i sim c u 0 x 100 170 y 270 0 s t 1 s t 2 s t 3 s t 10 540 30 k 1 k 2 k 3 k 4 50 where c i obs t denotes the contaminant concentration of the i th observation well at time t and c i sim t indicates contaminant concentration of the i th observation well at time t generated by the simulation model for case 2 gpsi can be described by cnp as follows 31 min z i 1 n t t 1 t m c i obs t c i sim t 2 32 s t s s m t k m 1 2 k 1 2 5 k k i k ii k iii k iv c i sim f s k c l c i sim c u 0 s 52 30 k 50 where c i obs t denotes the contaminant concentration of the i th observation well at time t and c i sim t indicates contaminant concentration of the i th observation well at time t generated by the simulation model c l and c u are the minimum and maximum values of c i sim t respectively in the optimization model the objective function was to minimize bias between the measurement values and simulation values of contaminant concentrations inequality constraints were upper and lower boundaries of decision variables unknown variables and contaminant concentrations respectively and surrogate system was embedded into cnp as an equality constraint replacing the simulation model the objective function was optimized by the demc pso hybrid algorithm characterizing locations release intensities during stress period of pollution source and partition hydraulic conductivities for the demc pso hybrid algorithm the options of individual numbers evolution iteration swarm size self adjustment weight min neighbors fraction and use parallel were set to 40 40000 400 1 9 1 and yes respectively 4 results and discussion 4 1 performance of surrogate system 4 1 1 case 1 normal dnn drnn svr and kriging were exploited and compared for case 1 all the above mentioned surrogate models were trained using 800 samples and validated using 200 samples total 200 60 sample points to compare the generalizing ability the surrogate systems were evaluated as described earlier see section 3 2 1 table 6 shows the quantitative performance of the surrogate systems to visualize the surrogate system performance r2 mre mae and rmse for responses from the surrogate systems were plotted fig 9 a e including scatter and histogram with regard to hyperparameter tuning the dnn structure was determined by the best performance with specific number of layers fig 10 shows the performance of dnn with specific numbers of hidden layers it must be noted that the neurons in the layers were selected through trial and error methods fig 10 shows the best performances of dnns with specific hidden layers plotted as y axis which indicated that the dnn structure with the best performance was 5 hidden layer structure the detailed neurons distribution can be noted in table1 the comparative performance fig 9 revealed that dnn methods presented higher r2 and lower mre mae and rmse than shallow learning methods svr and kriging indicating that dnn methods exhibit promising performance in constructing surrogate system for complex highly nonlinear inverse problem of point source pollution the performance of the dnn methods was further compared fig 9 a b and the drnn presented higher r2 0 997 and lower mre indicating that l2 regularization and dropout regularization effectively improved the accuracy of validation alleviating overfitting to some degree fig 11 a and b presents the training process of drnn showing relatively stable convergence profile the comparison between responses of unknown variables with reference values and observation data is presented in fig 12 with regard to the analysis of computational cost for case 1 the simulation model non surrogate system required 400 000 min for 400 000 calls whereas the drnn surrogate system required 35 min for the same amount of calls 4 1 2 case 2 for case 2 the surrogate systems were trained using 320 samples and validated using 80 samples total 80 45 sample points it must be noted that the hidden layer in the dnn structure remained the same as that presented in table1 to explore transferability of the proposed drnn the comparative performance of surrogate systems fig 13 showed that dnn methods had higher r2 and lower mre mae and rmse than svr and kriging whereas drnn presented higher accuracy to simulation model than normal dnn these findings indicated that deep learning methods showed better performance over shallow learning methods and that drnn improved normal dnn generalization accuracy in constructing surrogate system for a non point source pollution case furthermore with regard to case 2 the five hidden layer structure dnns showed the best performance with respect to the computational cost the simulation model for case 2 the simulation model needed nearly 600 000 min for 160 000 calls whereas the drnn surrogate system required approximately 46 min for the same amount of calls thus drnn was selected as surrogate system embedding into optimization model owing to the highest approximation degree of simulation model by contrasting fig 9 a d and fig 13 a d it is apparent that shallow learning methods presented fluctuation generalization for different case point source pollution and non point source pollution identification whereas deep learning methods showed stable and reliable generalization indicating that deep learning methods have better transferability than shallow learning methods the main reasons for the better transferability of deep learning methods can be derived from training parameters and data aspects as follows 1 the training parameters of deep learning methods are overwhelmingly larger than those of shallow learning methods it must be noted that nonlinear system of case 1 was more complex than that in case 2 owing to more categories of unknown variables three in case 1 whereas two in case 2 when solving relatively simple system case 2 the shallow learning methods and deep learning methods both showed a desired performance for case 1 as the system becomes more complex when comparing with case 2 the training parameters of shallow learning methods are inadequate to support approximation task whereas those of deep learning methods retains adequate moreover the regularization strategy could adaptively select proper structure ensuring the deep learning methods a stable generalization for different cases 2 the data size of case 1 is larger than that of case 2 for kriging and svr as the correlation matrix and the kernel matrix of the dataset are used to describe the similarity between samples the number of matrix elements increases with the increase of data size as a result the calculation of shallow learning methods might become difficult to process in contrast the massive parameters of deep learning methods allow handling of large data comparison of the performance of normal dnn fig 9 a and 13 a and drnn fig 9 b and 13 b demonstrated that drnn promoted generalization performance of normal dnn figs 11 and 14 show that drnn can provide smooth and steady training progress analysis of computational cost of drnns for different cases revealed swifter invoking than non surrogate model in general drnn presented promising and stable performance for constructing surrogate systems for different pollution source identification cases efficiently reduced the high computational cost and enhanced the accuracy of the numerical simulation model when compared with normal dnn svr and kriging methods 4 2 inverse characteristic result 4 2 1 case 1 as indicated earlier see section 3 2 1 drnn was established to replace numerical simulation model and then embedded as equal constraints in optimization model see section 3 2 2 the location release intensities with time series and partition hydraulic conductivities were determined by solving cnp utilizing demc pso hybrid algorithm the initial solutions and confidence ranges of the hybrid algorithm are shown in table 7 and figs 15 17 fig 18 presents the comparison of single pso algorithm and demc pso algorithm the fitness values of demc pso algorithm for 1000 iterations were 71 22 whereas those of single pso algorithm using random initial solutions for 1000 iterations was 1 1 105 by solving cnp using demc pso algorithm the location release intensities with time series and partition hydraulic conductivities were determined table 8 fig 19 illustrates the comparison of reference values and identification values of unknown variables for case 1 as the identification values of st1 and st10 were evidently lower than those during other periods it can be inferred that the initial release time was time period 1 and the termination release time was time period 10 furthermore the inference can be proven by reference values of st1 and st10 4 2 2 case 2 for case 2 the release intensities of three potential non point sources of pollution during stress period and hydraulic conductivities were determined table 9 shows the initial solutions and confidence ranges of the hybrid algorithm fig 20 presents comparison of single pso algorithm and demc pso algorithm it can be clearly observed that the best fitness values 4 09 10 3 of demc pso was lower than those 1 21 10 2 of single pso and that the fitness values of demc pso descended faster than those of single pso table 10 presents the comparison of reference and identification values for case 2 as s1t1 s1t5 s2t1 and s3t1 s3t2 were significantly lower close to 0 than the release intensities during other stress periods it can be deduced that s2 and s3 were real pollution source whereas s1 was non pollution source moreover s2 and s3 initial release time was during t2 period and t3 period respectively fig 21 illustrates the comparison of unknown variables reference and identification values showing subtle bias of reference and identification values comparison between reference and identification values figs 19 and 21 and best fitness values figs 18 and 20 for both the cases showed that in different cases the simulated concentrations were tweaked by demc pso to match well with observation data in observation wells by comparing the convergence profiles of the two cases figs 18 and 20 it was evident that the convergence curve of demc pso remained below that of single pso during the whole optimization process and the best fitness value of demc pso was lower than that of pso furthermore for case 1 the fitness values of single pso remained a slight change from 300 iterations till 1000 iterations whereas demc pso persistently decreased fig 18 these findings indicated that pso combined with demc could achieve faster search efficiency and avoid being trapped into the local optimum and the reasons for improvement in search efficiency and accuracy can be elaborated as follows 1 demc provided a reliable interval estimation for pso to narrow the search ranges which can alleviate sodi and escape from the local optimum while improving searching efficiency 2 demc generated proper initial solutions which are closer to the target solution for pso algorithm rather than producing random initial solutions in single pso in general the global local search strategy of demc pso remarkably improved search efficiency while ensuring accuracy of gpsi 5 conclusion in the present study a drnn surrogate based hybrid heuristic algorithm was proposed to simultaneously characterize groundwater pollution source spatial temporal characteristics and hydraulic conductivities a point source pollution case and a non point source pollution case were designed to evaluate the accuracy and transferability of the proposed method the estimation results for the two cases showed that the proposed method achieved promising estimation accuracy with swift estimation speed comparison of the two cases revealed the following conclusions 1 the drnn could emulate expensive running cost and highly nonlinear simulation model with a desired accuracy and swift running speed which substantially accelerated the estimation process of optimization furthermore comparison of drnn performance between the two cases indicated remarkable transferability of the drnn towards complex nonlinear systems moreover the proposed drnn could be an inspiration for the development of other regression or prediction task in hydrogeology domain the proposed surrogate system conducted a regression task from numeric features to numeric features and achieved promising performance however it only ensured the approximation of the observation wells but cannot completely represent the flow field excluding the monitoring locations thus more elaborate characterization of solute transport simulation model such as image to image regression methodology requires to be explored 2 the pollution source characteristics and hydraulic conductivities were determined by the demc pso hybrid algorithm the proper initial solutions and reliable ranges selected by demc profoundly improved the searching efficiency of pso algorithm resulting in faster and more precise estimation of unknown variables than single pso however monitoring data obtained in real situation are usually contaminated with random noise which can interfere with gpsi thus indicating that monitoring data quality is also essential for gpsi therefore monitoring data denoising technique must be explored to improve the inverse estimation task moreover the potential of demc pso under measurement noise must also be explored 3 pollution source identification considering initial release time could provide elaborate characterization of potential pollution source which can offer a reliable reference for the determination of pollution liability and further remediation task credit authorship contribution statement zidong pan conceptualization writing original draft software methodology wenxi lu methodology software zhenbo chang supervision validation han wang supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china no 41972252 the national key research and development program of china no 2018yfc1800405 and the graduate innovation fund of jilin university no 101832020cx246 
4415,the prerequisites for groundwater pollution remediation include providing accurate identification of hydraulic parameters of the contaminated site and retrospecting pollution source release history from sparse and discrete observation data however expensive time running and high nonlinearity of groundwater solute transport simulation model hinder precise and fast identification to overcome expensive running cost a deep regularization neural network drnn was introduced to emulate the highly nonlinear simulation model a hybrid heuristic algorithm integrating a particle swarm optimization pso and a differential evolution markov chain demc method was employed to provide reliable identification results of pollution source characteristics and hydraulic parameters in particular demc conducted a global search and pso performed a local search to evaluate transferability for various groundwater pollution cases the proposed method was utilized to provide an identification for a point source pollution case and a non point source pollution case the results indicated that drnn was capable of emulating input output relationship of a highly nonlinear and high time expense simulation model of two cases with a r2 of 0 997 and 0 984 respectively accelerating identification process furthermore when the pso was combined with demc the optimization was accelerated while escaping from the local optimum substantially improving the efficiency and accuracy of the identification task keywords groundwater pollution source simultaneous identification deep regularization neural network hybrid heuristic algorithm 1 introduction in recent years groundwater pollution poses a threat to drinking water safety drawing extensive attention however the high costs of remediation reagents and restoration scheme design make remediating contaminated aquifer a challenging task rendering it necessary to identify groundwater pollution source to charge for the responsible party tiyasha et al 2020 groundwater pollution source identification gpsi refers to retrospecting source release history and determining the source locations it is an inverse problem in mathematics but in real situations it is not feasible to directly identify groundwater pollution source characteristics and hydraulic parameters han et al 2020a thus accessibly relevant state variables such as time series monitoring data must be measured including hydraulic heads and contaminant concentrations to infer inaccessible parameters such as groundwater pollution source characteristics and field parameters a groundwater solute transport simulation model can illustrate the relationship between these parameters and spatial temporal distribution of contaminant concentrations armanuos et al 2020 in general gpsi is conducted by matching simulation model outputs with monitoring data by updating combinations of unknown variables xing et al 2019 however there are still some challenges associated with gpsi which must be addressed first fast and accurate identification has always been a key point in gpsi task the mathematical physical approaches employed to solve gpsi can be classified into two main categories as follows stochastic simulation statistic method guo et al 2020 zhang et al 2020 and simulation optimization method ayvaz 2010 zhao et al 2020 recently the simulation optimization method has drawn increasing attention owing to its high and stable estimation accuracy of optimal solutions datta et al 2011 when using the simulation optimization method a transport solute simulation model is embedded as an equality constraint for the optimization model where the objective function is to minimize the bias of simulation values and observation values li et al 2020 however solving the optimization model incurs thousands of invoking causing tremendous computational burden hou and lu 2018 therefore a surrogate system is employed to replace the simulation model which alleviates the computation burden during the optimization process this can substantially improve the efficiency of gpsi second most of the existing studies on groundwater pollution source release history characterization assume given release initial time which might be vague in real situation ayvaz 2010 jamshidi et al 2020 wang and lu 2020 to overcome this problem a suspicious release period with a long sequence must be defined in which the release initial time must be included however this will apparently increase the dimensions of parameters to estimate making the identification task a highly nonlinear inverse problem among all surrogate methods there are three main categories asher et al 2015 liu et al 2021 namely data driven surrogate systems projection based surrogate systems and hierarchical surrogate systems owing to high accuracy and swift invoking data driven surrogate systems are widely utilized as an alternative simulation models for data approximation in gpsi matott and rabideau 2008 in general the methods employed in data driven surrogate systems can be divided into shallow learning methods and deep learning methods according to the quantities of training parameters in the algorithm shallow learning methods such as kriging and support vector regression svr are widely exploited in simple flow models a relatively low nonlinear system and have shown promising performance as a surrogate model han et al 2020b mirarabi et al 2019 however with increasing dimensional inputs the nonlinearity of the mapping input output relationship gets stronger matott and rabideau 2008 and learning capacity of shallow learning methods including kriging and svr might become inadequate to support fitting such a highly nonlinear system causing underfitting to broaden the learning capacity more training data or a more complex structure are usually required shen 2018 as training data acquisition is limited by computational time and costs the present study aimed to choose deep learning methods with a complicated structure to efficiently improve the fitting accuracy with limited training samples among the deep learning methods deep neural networks dnn have drawn widespread attention in various fields owing to excellent descriptive and predictive ability jin et al 2019 popa 2018 zhou et al 2020 the massive training parameters in dnn substantially extend the learning capacity to complex problems making a dnn potentially viable surrogate system for highly nonlinear system most of the dnns are utilized for classification tasks but rarely for regression tasks guo et al 2016 rawat and wang 2017 and the surrogate system of gpsi is apparently a regression task thus a dnn for regression requires to be explored however training massive training parameters with limited data may cause overfitting gupta et al 2018 murakoshi 2005 which implies high accuracy for the training dataset but low accuracy for the validation dataset according to occam s razor regularization methods are introduced to efficiently alleviate overfitting in dnn without increasing data quantities resulting in promising performance for prediction poggio and girosi 1990 srivastava et al 2014 therefore in the present study l2 regularization and dropout regularization were employed to improve the dnn performance third the search efficiency of optimization algorithm for high dimensional space can be limited by the selection of initial solutions hatamlou 2013 he and wang 2007 an optimization process is a search path from the initial solutions to optimal solutions operated by a search algorithm leung and wang 2001 thus the initial solutions play essential roles in the optimization process kim et al 2017 and the closer the initial solution to the optimal solution the faster the speed of the optimization process the proper initial solutions can be determined by limited the search ranges as the goal of gpsi is to match simulation outputs to monitoring data by updating combinations of unknown variables the simulation optimization method may suffer from similar outputs of different inputs sodi however in traditional heuristic optimization algorithms including genetic algorithm and particle swarm optimization pso algorithm sodi can possibly cause the search process to fall into local optimum hou et al 2021 li et al 2021 hindering precise identification an effective way to alleviate sodi is to limit the ranges of unknown variables lopez et al 2015 mera et al 2003 recently differential evolution markov chain demc approach has been widely employed to infer the posterior distribution based on prior knowledge iglesias et al 2012 zhang et al 2016 enabling to limit the search ranges by estimating the posterior distribution of unknown variables in gpsi therefore in the present study to improve the search efficiency and accuracy of pso demc was introduced for the first time to provide reliable ranges of decision variables and select proper initial solutions for pso in gpsi in particular the demc was utilized to conduct a global search and pso was employed to perform a local search the demc pso hybrid algorithm is a global local search strategy for handling high dimensional optimization problem in gpsi in the present study a demc pso hybrid algorithm was introduced for the first time to improve search efficiency and accuracy of gpsi to relieve the huge computational burden when using simulation optimization method and tackle the challenge of approximating a complex nonlinear system a deep regularization neural network drnn was utilized as a surrogate system of transport simulation model to embed in optimization model the results indicated that the drnn surrogate based hybrid heuristic algorithm can provide stable and accurate estimation of the location initial release time release intensities and hydraulic conductivities for a point source pollution identification and non point source pollution identification the main contribution of the present study is to proposed a deep learning method for reducing expensive running burden of a highly nonlinear simulation model and apply a hybrid heuristic algorithm to substantially improve estimation efficiency and accuracy for complex nonlinear gpsi problems 2 methodology 2 1 numerical simulation model a groundwater numerical simulation model describes the process of groundwater flow and solute transport in the present study the transient saturated groundwater flow was considered to satisfy the following formula jiang et al 2018 1 x i k ij h x j w μ h t x y γ i j 1 2 t 0 where k ij is the hydraulic conductivity h is the hydraulic head w is the volumetric flux per unit volume μ is the specific yield and γ is the boundary of simulation domain coupled with the groundwater flow numeric equation the solute transport can be given as follows 2 c t x i d ij c x j x i u ij c r θ x y γ i j 1 2 t 0 3 u i k ij θ h x i i j 1 2 where c is the contamination concentration d ij is the dispersion coefficient u ij is the mean linear velocity of the groundwater flow following darcy s law r is the source or sink term θ is the effective porosity of the aquifer medium and γ is the boundary of simulation domain in particular the groundwater numerical simulation model was solved in the present study by exploiting the modflow module langevin et al 2003 and mt3d module zheng and wang 1999 in groundwater modeling systems gms 2 2 drnn 2 2 1 dnn structure artificial neural network ann is a mathematical algorithm for distributed information processing which mimics the behavior characteristics of the human nervous system schmidhuber 2015 typical anns consist of layers including input output and hidden layers and neurons as shown in fig 1 dnn commonly refers to ann with multiple hidden layers showing excellent capacity for feature extraction on classification and regression task arel et al 2010 in the dnn training process the raw input data are first entered through the input layer then passed to the hidden layers the hidden layers can extract complex and abstract characteristics through multiple nonlinear transformation finally the abstract characteristics are reverted into responses comparing with true output values it is assumed that there are m layers in dnn the i th neuron output in the k th layer z i k can be expressed as follows yuan et al 2020 4 z i k w i k a k 1 b i k k 1 2 m 5 a k g z k where w i k is the weight value of the i th neuron in the k th layer a k is the activation output of neurons in the k th layer w i k a k 1 denotes the dot product of w i k and a k b i k is the bias value of the i th neuron output in the k th layer and g z i k represents the activation function leaky relu in the present study the application of leaky relu activation function retains gradient for large positive inputs promoting the training process of dnn and can be expressed as wang et al 2018 6 g x max μ x x μ 0 1 where μ is the gradient constant with the default value set as 0 1 the weights and biases can be updated by minimizing the loss function between the responses and true targets the loss function e d can be optimized by adam algorithm and it can be expressed as burden and winkler 2008 7 e d 1 m i 1 m k 1 q z i k o i k 2 where z i k represents the i th neuron output in the k th layer o i k denotes the actual output of the i th neuron output in k th layer m signifies the numbers of neurons and q indicates numbers of layers in the present study the dnn was a typical feedback neural network which was utilized for fitting mapping relationship between unknown variables pollution source spatial temporal characteristics and hydraulic conductivities and contaminant concentrations observed in observation wells fig 2 2 2 2 l2 regularization and dropout regularization while multiple layers and massive neurons in the dnn significantly enhance the learning ability of highly nonlinear system it can also cause overfitting resulting in over characterization of training dataset and deviation of predictions to validation dataset to alleviate overfitting and improve generalization performance the strategy of regularization had been employed in dnn training process srivastava et al 2014 regularization is accomplished by transforming error function to improve algorithm generalization ability poggio and girosi 1990 according to the variables to be optimized regularization can be divided into five categories as follows data based davis et al 2018 nalepa et al 2019 network architecture based allred et al 2017 zhang et al 2019 error function based phaisangittisagul 2016 regularization term based and optimization based chan et al 2003 among the regularization methods error function based methods such as l2 regularization and dropout regularization have been widely utilized to improve dnn generalization performance with regard to l2 regularization the error function er can be given as follows rakitianskaia et al 2014 8 er e d λ e s 9 e s w 2 2 i w i 2 where e d is given in equation λ is the regularization coefficient and w 2 represents 2 norm of weight dropout regularization refers to randomly discarding a portion of the neuron output characteristics of hidden layers in the dnn with certain probability watt et al 2018 making training outputs in hidden layer not dependent on one single neuron in this way each neuron is forced to learn an informative feature independent of the surrounding hidden neurons srivastava et al 2014 tian and pan 2020 fig 3 shows a portion of dnn structure before and after dropout regularization which implied more streamlined network structure when using dropout propitious to alleviating overfitting and improving validation performance the dropout probability β is the probability that one neuron is disabled to the other neurons in the hidden layers in the present study β was set to 0 1 at dense 5 layer in general l2 regularization was applied to dense 1 4 layers and λ was set to 0 1 0 01 0 001 and 0 001 respectively dropout regularization was utilized in dense 5 layer the summary of the drnn structure is presented in table 1 2 3 kriging method kriging method has been widely used in spatial interpolation and surrogate system construction owing to its good ability to perform unbiased estimation hengl et al 2007 kleijnen 2017 simpson and mistree 2001 the proposed model is an ordinary kriging model which can be expressed as follows guo et al 2019 10 y x g x z x where x represents the inputs of the kriging model unknown variables y x denotes the outputs of the kriging model contaminant concentrations of observation wells g x is the global model of the origin function and z x signifies a gaussian random function and satisfies the following formula guo et al 2019 11 cov z x i z x j σ 2 r r x i x j i j 1 2 n 12 r x i x j exp k 1 n θ k x k i x k j 2 where r represents the correlation function r denotes the symmetric correlation matrix n is the number of samples x k i and x k j are the k th component of x i and x j respectively and θ k can be determined by minimizing the deviation between model predictions and actual values 2 4 svr svr is a transformation form of support vector machine to address regression task owing to its high data prediction accuracy svr has been widely utilized to construct surrogate system for groundwater inverse problem the nonlinear regression function can be expressed as follows hu et al 2014 13 y w t φ x b where y represents the contaminant concentrations of observation wells in the present study x denotes the unknown variables pollution spatial temporal characteristics and hydraulic conductivities φ x is the mapping function transforming the unknown variables to a higher dimensional feature space w is the fitting coefficients matrix and b is the fitting bias matrix generally kernel tricks strategy such as radial basis function rbf is exploited in svr to transform nonlinear problem to linear problem which can be expressed as constrained optimization problem chang and lin 2011 14 minimize e w 1 2 w 2 c i 0 m ξ i ξ i 15 s t y i w φ x b ε ξ i w φ x b y i ε ξ i ξ i ξ i 0 where w 2 represents 2 norm of w ξ i and ξ i are the relaxation coefficients w φ x is the dot product of w and φ x and ε is the acceptable bias calculated by using karush kuhn tucker condition methods the constraint optimization problem can be transformed as follows smola and scholkopf 2004 16 w i 1 m α i α i ϕ x i 17 f x i 1 m α i α i ϕ x i φ x b where α i and α i represent lagrange multipliers ϕ x i is the kernel function in the present study rbf kernel trick was employed in svr 2 5 demc pso hybrid algorithm the demc algorithm is a stochastic heuristic algorithm combining differential evolution and monte carlo markov chain and shows promising global search capacity for complex posterior distribution vrugt et al 2009 in the present study metropolis acceptance rule was exploited in demc algorithm to broaden search ergodicity and parallel multi candidate strategy was utilized to promote search efficiency the main demc processes were as follows vrugt 2016 step1 fixed parameter setting set the maximum generation number n current generation number k population individual numbers m unknown variables numbers n and default jumping rate γ the default jumping rate can be expressed as 18 γ 2 38 2 n step2 initializing create initial population x 0 x i 1 0 x i 2 0 x i m 0 and calculate the fitness function f the universal population expression can be expressed as 19 x k x i 1 k x i 2 k x i m k step3 mutation the i th individual mutates based on the following law ter braak 2006 20 x i k x i k γ x r a n d 1 k x r a n d 2 k ε where x i k is the mutation individual for k th generation x r a n d 1 k x r a n d 2 k are two individuals randomly selected from m individuals and ε is the minor disturbance step 4 selection metropolis probability p acc can be employed to determine whether to accept x i k as follows 21 p acc l x i k l x i k 22 l x t 1 n 1 2 π σ t 2 exp 1 2 y obs y t x σ t 2 where l x implies the fitness value y obs are the observation data y t x are the simulated outputs of simulation model the measurement error δ of the observation data obeys normal distribution δ 0 σ 2 n represents the number of observation data if p acc 1 u u r a n d 0 1 accept x i k otherwise keep x i k and reject x i k then mutation individual x i k 1 is determined repeat step2 4 until k n choose the best individual with the largest average fitness value as output finally analyze the confidence range and best generation with the highest fitness value of the best individual the pso algorithm is a bionic global optimization algorithm inspired by birds flight behavior kennedy and eberhart 2002 for n dimensional optimization case pso algorithm considers each individual as a particle without volume and mass in the n dimensional search space and flies at a certain speed in the search space the optimized search is guided by swarm intelligence generated by interparticle cooperation and competition in population clerc and kennedy 2002 yang et al 2019 in the optimization search process the particle position can be expressed as n dimensional vector x and the particle velocity can be expressed as vector v indicating search direction each particle position corresponds to a fitness value indicating the approximation degree between candidate point and optimal point and x and v are updated as follows yaseen et al 2019 21 x i t 1 x i t v i t 1 1 i m 22 v i t 1 w v i t c 1 r 1 t 1 x pbest i t x i t c 2 r 2 t 1 x nbest i t x i t where m is the population size w is the inertia weight determining new velocity in time t 1 c 1 and c 2 are learning rate r 1 t and r 2 t are random vectors from 0 1 normal distribution x pbest i t is the optimal position for particle i at time t and x nbest i t is the optimal position of all particles in population at time t the steps of pso algorithm can be given as follows step 1 fixed parameter setting set the search space low boundary lb and up boundary ub as confidence ranges generated by demc algorithm velocity low boundary vmin and up boundary v max population size m inertia weight w maximum iteration k learning rate c 1 c 2 and tolerance precision ε step 2 initializing and evaluation set the optimal solution generated by demc algorithm as initial population evaluate each particle fitness and calculate the fitness values step 3 check and selection update particle position x and velocity v based on equation 21 if v i v max set velocity to v max if v i v min set velocity to v min if fitness values of updated particle are smaller than particle before updating accept x i t 1 otherwise retain x i t step 4 go back to step 2 until max iteration or tolerance precision is reached in general in the demc pso hybrid algorithm demc algorithm was utilized to generate confidence ranges and initial particle for pso algorithm by conducting a global search whereas pso algorithm was employed to perform a local search in confidence ranges 3 method application 3 1 case overview as the present study was aimed to explore solving an inverse problem by utilizing the drnn hybrid heuristic algorithm see fig 4 two hypothetical cases were designed to evaluate the performance of the developed method 3 1 1 case 1 point source pollution identification the spatial domain comprised two dimensional heterogenous aquifer with a length of 400 m and width of 300 m the hydraulic conductivity field was divided into four zones according to medium particles as follows k1 k2 k3 and k4 the up and down boundaries were no flow boundaries whereas the left and right boundaries were specific linear head boundaries fig 5 the simulation time lasted for 10 years with 10 stress periods every year is one stress period a point groundwater pollution source released contaminants into aquifer during 2nd period to 9th period six observation wells 1 2 3 4 5 6 were established to monitor contaminant concentration in the aquifer per year the background contaminant concentration was set to 0 mg l and the contaminant transport process was assumed to be conservative involving no chemical transformation and biodegradation process in general the unknown variables to identify were characterized by 16 parameters location l x y release intensities during stress period s s ti and partitions hydraulic conductivities k k m where i 1 2 10 m 1 2 3 4 the site was spatially discretized into 30 000 200 150 grids the reference values and ranges of pollution source spatial and temporal characteristics and hydraulic parameters to estimate results of gpsi are listed in table 2 in particular location initial release time release intensities and hydraulic conductivities were set as unknown variables in the gpsi process unlike in the real situation as no authentic measured data are involved in the hypothetical case the location initial release time release intensities and hydraulic conductivities were considered as simulation model inputs in case 1 and the reference values are shown in table 3 the contaminant concentrations in the observation wells during the stress period were obtained as observation data in gpsi through treating reference values as inputs to forward run the simulation model fig 6 3 1 2 case 2 non point source pollution identification the spatial domain comprised two dimensional heterogenous aquifer with a length of 2000 m and width of 2500 m the hydraulic conductivity comprised four zones according to medium particles as follows k i k ii k iii and k iv the north and south boundaries were no flow boundary whereas the west and east boundaries were specific linear head boundaries fig 7 the aquifer and pollution relevant values and ranges are listed in table 4 the simulation time lasted for 5 stress periods every year is one stress period three plants were treated as potential non point sources and discharged contaminant into aquifer during stress periods nine observation wells obs1 9 were established to monitor contaminant concentration in the aquifer per year in total the unknown variables to identify were characterized by 19 parameters including partitions hydraulic conductivities k k i k i i k i i i k i v and release intensities during stress period s s d t q where d 1 2 q 1 2 5 table 5 listed the reference values of unknown variables the site was spatially discretized by 20 m 20 m bias cell the reference contaminant concentration distributions during stress period were shown in fig 8 3 2 application of drnn demc algorithm 3 2 1 establishment of surrogate model training data were required to extract hidden characteristics and laws of numerical simulation model whereas validation data were needed to evaluate surrogate model generalization ability latin hypercube sampling was exploited to ensure that the data uniformly covered sampling interval enhancing ergodicity of samples in the present study pollution source characteristics and partition hydraulic conductivities were treated as surrogate system inputs 16 dimensions for case 1 and 19 dimensions for case 2 the inputs were considered as independent variables surrogate system outputs were dynamic monitoring data of contaminant concentration in the observation wells 60 dimensions for case 1 and 45 dimensions for case 2 generated by forward running numerical simulation model it must be noted that inputs and outputs comprised dataset 1000 patterns for case 1 and 400 patterns for case 2 which was randomly divided into validation dataset 20 and training dataset 80 in the present study kriging svr normal dnn drnn were employed to establish surrogate system fed by training dataset and evaluated by validation dataset the performance of the surrogate system was assessed by a time cost and approximation accuracy the time cost can be estimated by the time required when invoking the same amount of iterations which was calculated on a pc with intel core i5 10400 cpu 2 90 ghz processor and 32 0 gb ram the approximation accuracy was evaluated by the following measurement criteria mean absolute error mae mean squared error mse root mean squared error rmse mean relative error mre and coefficient of determination r2 yuan et al 2020 mae can be determined as 23 mae 1 n i 1 n y i s y i d where y i s is the output of numerical simulation model and y i d is the output of surrogate system mse can be determined as 24 mse 1 n i 1 n y i s y i d 2 rmse can be calculated as 25 rmse mse 1 2 mre can be determined as 26 mre 1 n i 1 n y i s y i d y i s 100 r2 can be calculated as 27 r 2 1 i 1 n y i s y i d 2 y i s m i s 2 m i s 1 n i 1 n y i s after training with the dataset and validation by measurements the mapping relationship from unknown variables to contaminant concentration can be expressed by surrogate system as follows 28 c sim f s k where c sim is the numerical simulation model output which is replaced by the surrogate system output and s and k are described earlier see section 3 1 in the present study computation time was proposed to compare the computational burden of surrogate system and non surrogate system numerical simulation model 3 2 2 establishment of optimization model for case 1 gpsi can be described by constrained nonlinear programming cnp as follows 29 min z i 1 n t t 1 t m c i obs t c i sim t 2 30 s t c i sim f x y s t 1 s t 2 s t 3 s t 4 s t 5 s t 6 s t 7 s t 8 s t 9 s t 10 k 1 k 2 k 3 k 4 c l c i sim c u 0 x 100 170 y 270 0 s t 1 s t 2 s t 3 s t 10 540 30 k 1 k 2 k 3 k 4 50 where c i obs t denotes the contaminant concentration of the i th observation well at time t and c i sim t indicates contaminant concentration of the i th observation well at time t generated by the simulation model for case 2 gpsi can be described by cnp as follows 31 min z i 1 n t t 1 t m c i obs t c i sim t 2 32 s t s s m t k m 1 2 k 1 2 5 k k i k ii k iii k iv c i sim f s k c l c i sim c u 0 s 52 30 k 50 where c i obs t denotes the contaminant concentration of the i th observation well at time t and c i sim t indicates contaminant concentration of the i th observation well at time t generated by the simulation model c l and c u are the minimum and maximum values of c i sim t respectively in the optimization model the objective function was to minimize bias between the measurement values and simulation values of contaminant concentrations inequality constraints were upper and lower boundaries of decision variables unknown variables and contaminant concentrations respectively and surrogate system was embedded into cnp as an equality constraint replacing the simulation model the objective function was optimized by the demc pso hybrid algorithm characterizing locations release intensities during stress period of pollution source and partition hydraulic conductivities for the demc pso hybrid algorithm the options of individual numbers evolution iteration swarm size self adjustment weight min neighbors fraction and use parallel were set to 40 40000 400 1 9 1 and yes respectively 4 results and discussion 4 1 performance of surrogate system 4 1 1 case 1 normal dnn drnn svr and kriging were exploited and compared for case 1 all the above mentioned surrogate models were trained using 800 samples and validated using 200 samples total 200 60 sample points to compare the generalizing ability the surrogate systems were evaluated as described earlier see section 3 2 1 table 6 shows the quantitative performance of the surrogate systems to visualize the surrogate system performance r2 mre mae and rmse for responses from the surrogate systems were plotted fig 9 a e including scatter and histogram with regard to hyperparameter tuning the dnn structure was determined by the best performance with specific number of layers fig 10 shows the performance of dnn with specific numbers of hidden layers it must be noted that the neurons in the layers were selected through trial and error methods fig 10 shows the best performances of dnns with specific hidden layers plotted as y axis which indicated that the dnn structure with the best performance was 5 hidden layer structure the detailed neurons distribution can be noted in table1 the comparative performance fig 9 revealed that dnn methods presented higher r2 and lower mre mae and rmse than shallow learning methods svr and kriging indicating that dnn methods exhibit promising performance in constructing surrogate system for complex highly nonlinear inverse problem of point source pollution the performance of the dnn methods was further compared fig 9 a b and the drnn presented higher r2 0 997 and lower mre indicating that l2 regularization and dropout regularization effectively improved the accuracy of validation alleviating overfitting to some degree fig 11 a and b presents the training process of drnn showing relatively stable convergence profile the comparison between responses of unknown variables with reference values and observation data is presented in fig 12 with regard to the analysis of computational cost for case 1 the simulation model non surrogate system required 400 000 min for 400 000 calls whereas the drnn surrogate system required 35 min for the same amount of calls 4 1 2 case 2 for case 2 the surrogate systems were trained using 320 samples and validated using 80 samples total 80 45 sample points it must be noted that the hidden layer in the dnn structure remained the same as that presented in table1 to explore transferability of the proposed drnn the comparative performance of surrogate systems fig 13 showed that dnn methods had higher r2 and lower mre mae and rmse than svr and kriging whereas drnn presented higher accuracy to simulation model than normal dnn these findings indicated that deep learning methods showed better performance over shallow learning methods and that drnn improved normal dnn generalization accuracy in constructing surrogate system for a non point source pollution case furthermore with regard to case 2 the five hidden layer structure dnns showed the best performance with respect to the computational cost the simulation model for case 2 the simulation model needed nearly 600 000 min for 160 000 calls whereas the drnn surrogate system required approximately 46 min for the same amount of calls thus drnn was selected as surrogate system embedding into optimization model owing to the highest approximation degree of simulation model by contrasting fig 9 a d and fig 13 a d it is apparent that shallow learning methods presented fluctuation generalization for different case point source pollution and non point source pollution identification whereas deep learning methods showed stable and reliable generalization indicating that deep learning methods have better transferability than shallow learning methods the main reasons for the better transferability of deep learning methods can be derived from training parameters and data aspects as follows 1 the training parameters of deep learning methods are overwhelmingly larger than those of shallow learning methods it must be noted that nonlinear system of case 1 was more complex than that in case 2 owing to more categories of unknown variables three in case 1 whereas two in case 2 when solving relatively simple system case 2 the shallow learning methods and deep learning methods both showed a desired performance for case 1 as the system becomes more complex when comparing with case 2 the training parameters of shallow learning methods are inadequate to support approximation task whereas those of deep learning methods retains adequate moreover the regularization strategy could adaptively select proper structure ensuring the deep learning methods a stable generalization for different cases 2 the data size of case 1 is larger than that of case 2 for kriging and svr as the correlation matrix and the kernel matrix of the dataset are used to describe the similarity between samples the number of matrix elements increases with the increase of data size as a result the calculation of shallow learning methods might become difficult to process in contrast the massive parameters of deep learning methods allow handling of large data comparison of the performance of normal dnn fig 9 a and 13 a and drnn fig 9 b and 13 b demonstrated that drnn promoted generalization performance of normal dnn figs 11 and 14 show that drnn can provide smooth and steady training progress analysis of computational cost of drnns for different cases revealed swifter invoking than non surrogate model in general drnn presented promising and stable performance for constructing surrogate systems for different pollution source identification cases efficiently reduced the high computational cost and enhanced the accuracy of the numerical simulation model when compared with normal dnn svr and kriging methods 4 2 inverse characteristic result 4 2 1 case 1 as indicated earlier see section 3 2 1 drnn was established to replace numerical simulation model and then embedded as equal constraints in optimization model see section 3 2 2 the location release intensities with time series and partition hydraulic conductivities were determined by solving cnp utilizing demc pso hybrid algorithm the initial solutions and confidence ranges of the hybrid algorithm are shown in table 7 and figs 15 17 fig 18 presents the comparison of single pso algorithm and demc pso algorithm the fitness values of demc pso algorithm for 1000 iterations were 71 22 whereas those of single pso algorithm using random initial solutions for 1000 iterations was 1 1 105 by solving cnp using demc pso algorithm the location release intensities with time series and partition hydraulic conductivities were determined table 8 fig 19 illustrates the comparison of reference values and identification values of unknown variables for case 1 as the identification values of st1 and st10 were evidently lower than those during other periods it can be inferred that the initial release time was time period 1 and the termination release time was time period 10 furthermore the inference can be proven by reference values of st1 and st10 4 2 2 case 2 for case 2 the release intensities of three potential non point sources of pollution during stress period and hydraulic conductivities were determined table 9 shows the initial solutions and confidence ranges of the hybrid algorithm fig 20 presents comparison of single pso algorithm and demc pso algorithm it can be clearly observed that the best fitness values 4 09 10 3 of demc pso was lower than those 1 21 10 2 of single pso and that the fitness values of demc pso descended faster than those of single pso table 10 presents the comparison of reference and identification values for case 2 as s1t1 s1t5 s2t1 and s3t1 s3t2 were significantly lower close to 0 than the release intensities during other stress periods it can be deduced that s2 and s3 were real pollution source whereas s1 was non pollution source moreover s2 and s3 initial release time was during t2 period and t3 period respectively fig 21 illustrates the comparison of unknown variables reference and identification values showing subtle bias of reference and identification values comparison between reference and identification values figs 19 and 21 and best fitness values figs 18 and 20 for both the cases showed that in different cases the simulated concentrations were tweaked by demc pso to match well with observation data in observation wells by comparing the convergence profiles of the two cases figs 18 and 20 it was evident that the convergence curve of demc pso remained below that of single pso during the whole optimization process and the best fitness value of demc pso was lower than that of pso furthermore for case 1 the fitness values of single pso remained a slight change from 300 iterations till 1000 iterations whereas demc pso persistently decreased fig 18 these findings indicated that pso combined with demc could achieve faster search efficiency and avoid being trapped into the local optimum and the reasons for improvement in search efficiency and accuracy can be elaborated as follows 1 demc provided a reliable interval estimation for pso to narrow the search ranges which can alleviate sodi and escape from the local optimum while improving searching efficiency 2 demc generated proper initial solutions which are closer to the target solution for pso algorithm rather than producing random initial solutions in single pso in general the global local search strategy of demc pso remarkably improved search efficiency while ensuring accuracy of gpsi 5 conclusion in the present study a drnn surrogate based hybrid heuristic algorithm was proposed to simultaneously characterize groundwater pollution source spatial temporal characteristics and hydraulic conductivities a point source pollution case and a non point source pollution case were designed to evaluate the accuracy and transferability of the proposed method the estimation results for the two cases showed that the proposed method achieved promising estimation accuracy with swift estimation speed comparison of the two cases revealed the following conclusions 1 the drnn could emulate expensive running cost and highly nonlinear simulation model with a desired accuracy and swift running speed which substantially accelerated the estimation process of optimization furthermore comparison of drnn performance between the two cases indicated remarkable transferability of the drnn towards complex nonlinear systems moreover the proposed drnn could be an inspiration for the development of other regression or prediction task in hydrogeology domain the proposed surrogate system conducted a regression task from numeric features to numeric features and achieved promising performance however it only ensured the approximation of the observation wells but cannot completely represent the flow field excluding the monitoring locations thus more elaborate characterization of solute transport simulation model such as image to image regression methodology requires to be explored 2 the pollution source characteristics and hydraulic conductivities were determined by the demc pso hybrid algorithm the proper initial solutions and reliable ranges selected by demc profoundly improved the searching efficiency of pso algorithm resulting in faster and more precise estimation of unknown variables than single pso however monitoring data obtained in real situation are usually contaminated with random noise which can interfere with gpsi thus indicating that monitoring data quality is also essential for gpsi therefore monitoring data denoising technique must be explored to improve the inverse estimation task moreover the potential of demc pso under measurement noise must also be explored 3 pollution source identification considering initial release time could provide elaborate characterization of potential pollution source which can offer a reliable reference for the determination of pollution liability and further remediation task credit authorship contribution statement zidong pan conceptualization writing original draft software methodology wenxi lu methodology software zhenbo chang supervision validation han wang supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the national natural science foundation of china no 41972252 the national key research and development program of china no 2018yfc1800405 and the graduate innovation fund of jilin university no 101832020cx246 
4416,rainfall runoff models based on conceptual buckets are frequently used in climate change impact studies to provide runoff projections when these buckets approach empty the simulated evapotranspiration approaches zero which places an implicit limit on the soil moisture deficit that can accrue within the model such models may cease to properly track the moisture deficit accumulating in reality as dry conditions continue leading to overestimation of subsequent runoff and possible long term bias under drying climate here we suggest that model realism may be improved through alternatives which remove the upper limit on simulated soil moisture deficit such as bottomless buckets or deficit based soil moisture accounting while some existing models incorporate such measures no study until now has systematically assessed their impact on model realism under drying climate here we alter a common bucket model by changing the soil moisture storage to a deficit accounting system in such a way as to remove the upper limit on simulated soil moisture deficit tested on 38 australian catchments the altered model is better able to track the decline in soil moisture at the end of seasonal dry periods which leads to superior performance over varied historic climate including the 13 year millennium drought however groundwater and grace data reveal long term trends that are not matched in simulations indicating that further changes may be required nonetheless the results suggest that a broader adoption of bottomless buckets and or deficit accounting within conceptual rainfall runoff models may improve the realism of runoff projections under drying climate keywords rainfall runoff modelling runoff projections model improvement model realism drought climate change 1 introduction rainfall runoff models are an important tool for understanding the risks posed by a drying climate they are often applied to interpret the output of general circulation models or stochastic weather generators simulating the availability of water under a future hypothetical scenario bergström et al 2001 chiew et al 1995 2009 christensen et al 2004 faramarzi et al 2013 forzieri et al 2014 krysanova et al 2017 pechlivanidis et al 2017 samaniego et al 2017 singh et al 2014 smith et al 2014a 2014b given that many temperate areas of the world may see decreases in rainfall and reductions in water resources eg arnell 2004 oki and kanae 2006 it is imperative that rainfall runoff models can provide defensible simulations under drier climatic conditions than those seen in the past as required for water resource risk assessments under a drier future climate the importance of this issue is evident in its inclusion among the twenty three unsolved problems in hydrology particularly 1 3 19 and 20 blöschl et al 2019 and the iahs focus on change in hydrology and society through the panta rhei decade 2013 2022 montanari et al 2013 differential split sample studies indicate that rainfall runoff models struggle with changing climatic conditions model performance tends to decline in proportion to long term changes in climatic variables such as rainfall vaze et al 2010 see also broderick et al 2016 coron et al 2012 2014 freer et al 2003 refsgaard knudsen 1996 saft et al 2016 seiller anctil 2015 seiller et al 2012 models often underestimate the severity of hydrological drought arising from a given meteorological drought eg saft et al 2016 fowler et al 2018a and struggle to simulate catchment response to rainfall following dry periods resulting in poor seasonal transitions eg ambroise et al 1996 wagener et al 2003 these results cast doubt regarding the application of these models for climate change impact studies krysanova et al 2017 see also seibert and van meerveld 2016 in response to this problem two possible options are to focus on either the manner in which models are applied or on possible deficiencies in the model structures themselves examples of the first approach include i more rigorous guidelines for selection of calibration and evaluation data eg motavita et al 2019 zheng et al 2018 ii advanced calibration split sampling schemes eg coron et al 2012 gelfan and millionshchikova 2018 dakhlaoui et al 2019 iii increased attention to the impact of calibration objective function on split sample results and or to improve sensitivity to relevant processes eg fowler et al 2018a freer et al 2003 iv broader model evaluation criteria and new tests for evaluating model performance under changing climatic conditions eg thirel et al 2015 fowler et al 2018b and v extensions of split sample methods to examine the consistency of models over potential future climatic conditions eg guo et al 2018 2020 although the above studies show considerable promise results shown by fowler et al 2016 suggest that model structural deficiency plays a key role in most cases of poor performance thus the rest of the paper focusses on this issue numerous recent studies have examined hydrological model structural deficiencies under changing climate westra et al 2014 grigg and hughes 2018 deb et al 2019 guo et al 2017 stephens et al 2018 for example building on earlier studies of the dynamics of parameter values in time eg beck 1985 wagener et al 2003 moradkhani et al 2005 westra et al 2014 presented a method for detecting such deficiencies where one or more parameters change value with time based on selected co variates julian day recent climatic conditions or a linear trend if such a change leads to a significant increase in performance this method infers that problems exist with the corresponding model component see also beck 2002 guo et al 2017 showed that some model structures provide unrealistic simulated evapotranspiration et by comparing model internal dynamics with eddy flux measured et at an arid australian site grigg and hughes 2018 and deb et al 2019 addressed the question of groundwater impacts on streamflow the former through changes to a simple bucket model and the latter through coupling of a complex gridded hydrological model with a modflow groundwater model these latter studies suggest benefits in comparing simulations with independent data to verify simulations in a changing climate recently fowler et al 2020 used independent groundwater and gravity recovery and climate experiment grace data to demonstrate how rainfall runoff models lack long slow multi year dynamics observed in nature in this case in southern australia the present paper follows directly from this earlier research so we provide a detailed summary fig 1 fowler et al 2020 examined environmental state variables such as groundwater data from nineteen bores and grace data and compared these with simulations from five conceptual rainfall runoff models in 38 catchments they noted that all the conceptual buckets are seasonally emptying in most years prior to the drought in contrast the groundwater and grace data show strong multi year declines over the millennium drought giving little indication of approaching empty even after 13 years of dry conditions these declines are co located with catchments exhibiting hydrological shifts saft et al 2015 and poor performance of rainfall runoff models fig 1 in the following section we build on these findings to develop the rationale for the present study 2 rationale and study aim commonly when conceptual buckets approach empty the simulated evapotranspiration approaches zero which places a limit on the soil moisture deficit that can accrue within the model and may curtail seasonal or multi year accrual of deficits in reality many plants have coping mechanisms which allow transpiration to continue during extended dry periods de boer euser et al 2016 this may include tap roots which extend beyond the active root zone vervoort and van der zee 2009 to soil moisture in weathered bedrock anderson et al 1995 arkley 1981 jones and graham 1993 and or underlying groundwater agbakpe 2009 gow et al 2016 miller et al 2010 cf koirala et al 2017 barbeta and peñuelas 2017 compiled data on 71 species of plants and reported that groundwater use represented on average 49 of transpired water during dry seasons cramer et al 1999 ward and micin 2006 the sources and dynamics of water use depend on plant species zwieniecki and newton 1996 zunzunegui et al 2017 and recent climatic conditions for example rose et al 2003 reported preferential use of shallower sources of water when available progressing to deeper layers as dry conditions continue in addition the sources of water available to plants vary depending on their position in the landscape with locations of topographic convergence having access to relatively higher soil moisture and groundwater more often than other locations western et al 1999 even in the case of shallow rooted vegetation given the above evidence bucket models whose simulated evapotranspiration effectively ceases in the mid to late dry season should be treated with scepticism eliades et al 2018 the unrealistic behaviour of such models would be twofold i poor match with seasonal patterns of actual evapotranspiration aet since the months at the end of the dry season would have lower simulated aet as the model runs out of water and ii during multi year droughts that cause long term decline in measured state variables eg groundwater grace the models would be missing such downwards trends as stated by fowler et al 2020 once the drought begins there is little room for decline in the simulated storage because the model buckets are already emptying on a seasonal basis such dynamics have important implications for simulation bias when such models approach empty and evapotranspiration approaches zero the model may cease to properly track the moisture deficit that is accumulating in reality as dry conditions continue as shown in fowler et al 2020 if so this incorrect moisture deficit causes overestimation of runoff from subsequent rainfall events leading to long term model bias if dry conditions persist for multiple years or indefinitely under climate change the issue plays out differently for different models and will depend upon other model structural features including those that interact with low flows such as structural elements that govern inter catchment groundwater inflow or export perrin et al 2003 here we investigate whether model realism may be improved by removing the upper limit on simulated soil moisture deficit this can be achieved via either a bottomless bucket eg the penman model 1949 described by wagener et al 2003 or through adopting a deficit based soil moisture accounting scheme with no upper limit on deficit accrual while these two formulations may sound different they are mathematically similar since each formulation tracks soil moisture against some datum and each is unbounded in one direction and not the other that is there is a wettest possible state full bucket or zero deficit but not a driest possible state deficit models already exist in the literature but they are not as common as bucket models for example a recent compilation of 46 conceptual rainfall runoff models by knoben et al 2019 identified 162 examples of water storage formulation of which only 7 are deficit based however some deficit models are very widely applied such as topmodel beven and kirkby 1979 and successors such as dynamic topmodel beven and freer 2001 and decipher coxon et al 2019 other examples of deficit based models and bottomless buckets include the catchment moisture deficit version of ihacres evans and jakeman 1998 croke and jakeman 2004 see also ivkovic et al 2014 the classic model of crooks and naden 2007 the groundwater components of mod hydrolog chiew 1990 chiew and mcmahon 1994 and part of the routing component of gr6j pushpalatha et al 2011 thus deficit and bottomless bucket models are an established part of the existing literature however no prior study has considered whether these formulations are inherently better suited for application under a drying climate one difficulty is that no existing deficit model has an equivalent bucket model to serve as a benchmark ihacres comes close but the relevant versions have too many other differences for a direct comparison cf jakeman and hornberger 1993 evans and jakeman 1998 thus starting with a commonly used bucket model gr4j perrin et al 2003 see also santos et al 2018 the aim of this paper is aim to test whether removing the upper limit on simulated soil moisture deficit while ensuring that all other aspects of the model are unchanged improves the performance and realism of simulations both prior to and during a historic multi year drought we choose gr4j because of the five models tested by fowler et al 2016 it was the best performing at matching calibration data yet the least transferable to different climatic conditions such a model is a good candidate for exploring which alterations might improve transferability also other authors working in the same geographic region ie southern australia have sought to improve gr4j and comparing results between the variants westra et al 2014 grigg and hughes 2018 allows readers to put performance improvements in context while other gr models exist gr5j le moine 2008 gr6j pushpalatha et al 2011 their emphases on low flows differ from the present emphasis on long term multi year bias under extended dry conditions a recent study fowler et al 2018b proposed a model improvement framework to test whether model structural changes are required considering possible calibration deficiencies or data errors in this paper this framework is applied for the first time thus the method section includes a recap of this model improvement framework section 3 2 and our adopted testing regime includes many of the tests proposed in fowler et al 2018b to close this section and ward against misunderstanding the following three points are emphasised 1 we are not arguing that real catchments do not have driest possible states while driest possible states do exist in both reality and in most conceptual bucket models evidence suggests a profound mismatch between the two the case study in fowler et al 2020 showed that real catchments exhibited no sign of emptying even after 13 years of consecutive drought as judged by groundwater hydrographs in contrast conceptual bucket models emptied seasonally even pre drought implying that the moisture deficit that the calibrated models regard as empty was in fact far from it it seems likely that the driest possible state in the conceptual models was tuned to what staudinger et al 2017 term the dynamic storage but other types of storage exist see table 1 in staudinger et al 2017 in the case of the millennium drought the multiyear declines shown in fowler et al 2020 suggests these other types of storage may depleted by deep rooted vegetation and or may drain slowly of their own accord if unreplenished or under replenished for multiyear periods because these other storage types are commonly minimally involved in event or seasonal dynamics it is more difficult to quantify their size experimentally or via inference from observations or to know how extreme a sequence of climatic forcing needs to be to drive the catchment close to the point of exhausting their supplies thus it seems prudent to adopt model formulations that sidestep the issue of driest possible states entirely 2 we are not primarily seeking to introduce a new model but rather to systematically test the benefits on model realism of removing upper limits on simulated soil moisture deficit it is envisaged that the lessons learned in this experiment will be applicable to other conceptual bucket models as considered further in the discussion section 3 the reader may mistakenly believe that the removal of deficit limits may result in runaway accrual of deficits during extended dry periods however the removal of hard limits does not imply the removal of negative feedback by which we mean the more water is removed the harder it is to remove further water such feedbacks avoid runaway accrual of deficits even though the deficit itself can in principle take any positive value 3 method the method section is divided into three subsections section 3 1 describes the study catchments and model forcing data section 3 2 explains the set of tests which investigate whether gr4j requires structural changes and also characterise the impact of the model changes including via comparison with independent data lastly the model structural changes are presented section 3 3 3 1 study catchments and model forcing data as per fowler et al 2020 this study examines 38 catchments in the state of victoria in south east australia fig 1 the median catchment area is 240 km2 minimum 4 km2 maximum 1100 km2 all catchments are selected from the set of australia s hydrologic reference stations turner 2012 meaning they are unregulated headwater streams free from significant temporal changes eg in landuse and with long records for this study we often report results grouped by east and west as per fig 1 the eastern region contains the upland areas of victoria which are subject to steeper topography often 15 on average higher elevation up to 2000 m relatively high rainfall historic averages up to 2500 mm year and higher forest cover typically 80 in contrast the western region is flatter and drier on average ranging up to only 1200 m elevation and generally with rainfall less than 1000 mm year and with forest cover typically less than 50 both regions are subject to high potential evapotranspiration pet generally over 1000 mm year model forcing data of daily rain and daily pet are derived from gridded products by jones et al 2009 used for rainfall and jeffrey et al 2001 used for pet as described in fowler et al 2016 and now available publicly from the camels aus dataset fowler et al 2021 pet is based on morton s wet environment evaporation morton 1983 3 2 testing regime before describing the testing regime in detail we provide some broad comments on the link between the method and broader research goals as indicated in the title and abstract the broader research goal is improving streamflow projections under a drying climate projections refer to a future period so it is impossible to explicitly demonstrate improvement in future projections at least until the future time comes to pass thus common practice in hydrology as articulated by klemeš 1986 and others is to make use of historic data to conduct experiments that place the model in situations as close as possible to those in which it is supposed to be used in practice klemeš 1986 p13 despite the limitations of using the past as a proxy for the future eg fowler et al 2018b stephens et al 2020 such history based tests are the best available method for testing the ability of models to project the impact of climate change eg refsgaard et al 2014 this paper uses the millennium drought as a proxy for future drying climate prior studies which show poor split sample performance of models tested over this drought see introduction show that many common models and or model application procedures fail these tests and are thus inadequate for future streamflow projection 3 2 1 method to determine whether model changes are required as mentioned in the introduction poor split sample performance for a given case study is often due to causes other than poor model structure such as poor calibration methods lack of informative data or data errors therefore model structural changes should only be attempted after other causes have been considered fowler et al 2018b recently suggested a framework to approach this problem in a systematic way in the results section we apply steps of this framework to gr4j to demonstrate that model structural issues are contributing to poor split sample performance the steps of the framework are listed below note that this pre existing framework is concerned with model improvement over changing climatic conditions in general that is it is not specifically focussed on the issues outlined in section 2 ie issues of timing and persistence of evapotranspiration thus in a later section 3 2 3 we outline additional tests to examine these specific issues in more detail a conduct differential split sample testing step 1 from fowler et al 2018b as shown in fig 1 this step was conducted previously as per fowler et al 2018a two periods are defined dry period defined as the seven driest consecutive years on record and used as the independent evaluation period in the differential split sample test nondry period composed of every year that is not in the dry period and used as the calibration period in the differential split sample test two separate calibrations are conducted differing only by objective function the two objective functions tested are the refined index of agreement of willmott et al 2012 and the split kge of fowler et al 2018a an altered version of the kling gupta efficiency kge of gupta et al 2009 these objective functions have previously performed well relative to other objective functions in the present modelling context fowler et al 2018a in both cases the split sample test results are taken from fowler et al 2018a who used the covariance matrix adaptation evolution strategy cma es calibration algorithm hansen et al 2003 for all single objective optimisation for completeness a summary of the pre existing results is given in the results section of the present paper as per fowler et al 2018b in order to effectively compare results from different calibration methods it is necessary to choose a common evaluation method this could be a single acceptance metric or multiple in which to report all results regardless of which objective function is in focus it is useful for this reference metric or metrics to be related to the purpose of the modelling fowler et al 2018b since the rationale for the present study is to improve runoff projections primarily for water supply planning we adopt the kge as acceptance metric since its three components broadly describe some aspects of performance important to water resource managers the three components are matching the mean flow matching the variability in flow and matching the timing of flow gupta et al 2009 while we recognise the importance of multiple metrics in detailed performance assessments eg thirel et al 2015 fowler et al 2018a in this case we are presenting many tests and in the interests of keeping results tractable and intelligible it is best to limit the results presentation to only one metric thus readers should note that the metric used to report all results is different to both of the adopted objective functions b determine coverage of the objective space by the model structure steps 2 4 from fowler et al 2018b for the climatic periods adopted in a this step explores the limits of model performance and flexibility in matching flows from each period separately and also for all periods together as described in fowler et al 2018a 2018b this step involves either generating a large random ensemble of parameter sets plotting each parameter set according to the kge scores for the wetter period y axis and drier period x axis and identifying the limits of this cloud to quantify the limits of model performance or defining the limits of the cloud directly using a multi objective optimiser which is more computationally efficient here this step is undertaken using the amalgam multi objective optimiser vrugt and robinson 2007 using settings reported previously fowler et al 2016 2018b except in one case fig 3 in the results section which uses both methods for the purposes of demonstration of the principles involved once the cloud limit is determined the case study in question may be categorised by one of the following statements i parameter sets exist with good performance in the wetter period but not the drier period or vice versa ii parameter sets exist with good performance in the wetter period and other parameter sets exist with good performance in the drier period but no sets exist that have good performance for both periods in this case the model structure is flexible it can fit data it is calibrated to but not transferable good parameter sets in one period are poor in others fowler et al 2018b p3 this type of coverage is named β coverage by fowler et al 2018b as distinct from α coverage see next category iii parameter sets exist with acceptable performance in both periods simultaneously referred to as α coverage in fowler et al 2018b in which case no changes to the model structure are required to achieve acceptable performance and the priority should be to improve the calibration method so as to ensure these parameter sets are selected in a repeat split sample test c data checks and cross checks with other catchments steps 5 6 from fowler et al 2018b assuming that the model structure is not in category iii and therefore model changes are required this step aims to verify this conclusion by comparison with other catchments and also by double checking that the result is not due to catchment specific data errors here the catchment comparison is achieved because we are testing 38 different catchments data checks have previously been conducted for the study catchments fowler et al 2016 fowler 2017 and are not described here for brevity the order of presentation in this paper differs from the order that we undertook the tasks whereas here the model changes are described 3 3 prior to presenting the results of the above steps 4 1 in practice we first applied the above steps to demonstrate that gr4j requires model structural changes before formulating any changes to its structure 3 2 2 performance tests the first four results sub sections are structured around the following four aims all relating to the above tests and all of which characterise simulation quality via aggregate metrics ie the kge hence they are labelled performance tests 1 quantify split sample performance of the original gr4j as per a above 2 determine whether structural changes are required by determining coverage as per b and compare this across many catchments as per c 3 quantify the improved coverage made possible in theory by the structural changes and 4 quantify the improved split sample performance achieved in practice after calibration of the model after structural changes have been applied aim 4 is highly contingent on choice of calibration method whereas aim 3 is not that is the structural changes may mean that parameter sets now exist that provide good performance over a range of climatic conditions as revealed by the coverage plots however a split sample test may or may not choose such parameter sets fowler et al 2016 for additional interest the analysis for aim 3 is repeated for the aforementioned two other versions of gr4j namely those of westra et al 2014 and grigg and hughes 2018 this allows us to discuss section 5 3 the various methods employed by different authors to improve gr4j in the context of a changing climate and to comment on their relative effectiveness 3 2 3 assessing model realism the original framing of the need for model structural changes section 2 was primarily on grounds of physical realism with respect to non streamflow variables et groundwater rather than model performance issues with respect to streamflow therefore it is important to augment the above performance tests with analysis of whether the model changes provide improved plausibility and realism of simulations we follow fowler et al 2020 in providing comparison with the following independent data grace grace tapley et al 2004 data shows the evolution with time of terrestrial water which includes soil moisture and groundwater here we reuse the grace satellite data processed by fowler et al 2020 grace estimates were derived separately for the eastern and western half of the state of victoria as per fig 1 groundwater hydrographs we focus on three bores within or close to three catchments selected as case studies for plausibility testing in two cases the bores are within the catchments and in the last case it is less than ten kilometres distant where required the raw groundwater hydrographs from www vvg org au are temporally interpolated using the methods described in fowler et al 2020 the bore numbers and locations are shown later in fig 6 eddy flux tower actual evapotranspiration a small amount of actual et data is available for plausibility testing from the ozflux project www ozflux org au we use post processed data provided by the dynamic integrated gap filling and partitioning for ozflux dingo project beringer et al 2017 the selected sites and their locations relative to the catchments are shown later in fig 6 we note the following two points regarding comparison between model simulations and these data it is noted that there is considerable mismatch between the support of the data ie the spatial scale relating to each measurement type and the scale of modelling for example grace data has large support meaning that grace measurements relate to large areas typically 103 km2 or more conversely measurements from groundwater bores and eddy flux towers relate only to local areas within a short distance 10 2 to 100 km and may not be representative of the catchment scale readers should bear this limitation in mind however given that fowler et al 2020 noted multi year declines in storage both at a regional scale from grace and from multiple groundwater bores spread throughout the region there is considerable confidence that these declines are widespread particularly for catchments close to bores with the multiyear declines for grace which measures total water storage including soil moisture and groundwater the best point of comparison would be a timeseries of total water stored in the model ie the sum of the production and routing stores as done by fowler et al 2020 however here the comparison is limited to a selection of three catchments with good groundwater data namely 406213 406214 and 407230 and in each case the calibrated routing store was small less than 10 of the production storage capacity in each case see figure s6 of fowler et al 2020 thus we show only the production storage timeseries this allows readers to focus better on the effect of the model changes which are made exclusively to the production store as outlined in the following section 3 3 description of model changes as outlined in section 2 we seek to create a version of gr4j which has no upper limit on simulated soil moisture deficit since we do this by creating a deficit version of the model rather than a bottomless bucket we call the altered model gr4j dd where dd stands for deficit dynamics to create the altered model we first express the production state main model store not in terms of catchment storage s as per perrin et al 2003 but in terms of deficit in catchment storage d where d x1 s where x1 is the parameter controlling the capacity of the production store to illustrate this we focus on two of the three equations that depend on the production storage state firstly the partitioning of net rainfall pn such that a part ps is absorbed by the production store and the rest is passed to the routing algorithms and secondly the calculation of aet es from net pet en expressed in terms of storage deficit d these equations are as follows 1 p s x 1 1 1 d x 1 2 t a n h p n x 1 1 1 d x 1 t a n h p n x 1 2 e s x 1 d 2 1 d x 1 t a n h e n x 1 1 1 1 d x 1 t a n h e n x 1 the original gr4j versions of these equations are shown in fig 2 a for x1 600 mm net rainfall ps 6 mm d green and net pet es 6 mm d orange the change from s to d is a change in semantics rather than mathematics these formulas are functionally equivalent to equations 3 and 4 of the original authors however the benefit of moving from s to d is that this change allows further changes that would be nonsensical otherwise specifically instead of limiting the deficit to an arbitrary number in this case 600 mm there is no longer any need to place an absolute limit on moisture deficit d in the original version the actual evapotranspiration rate fig 2a orange line approaches zero as the bucket empties which results in the significant reductions in actual et during extended dry periods that were mentioned in the rationale section for gr4j dd the form of this curve is changed fig 2c so that no matter how high the deficit it is always possible to remove more et however the model retains a negative feedback to avoid runaway et the more water is taken from the catchment the harder it is to remove more the mathematical operations are described below this system is general and could be used to convert other bucket models than gr4j into deficit models at the beginning of the timestep an intermediate variable d is calculated as a function of three quantities d x1 and a new parameter termed the deficit dynamics parameter dd 0 dd 1 for the ranges of other parameters see fowler et al 2018a d is shown graphically in fig 2b for different values of dd having calculated d all other model operations including the percolation equation not in focus here perrin et al 2003 equation 6 are carried out as normal except that the value of d is used in place of d d is thus the middle step via which the value of the dd parameter influences the flux equations of the production store the equation relating d and d is shown below in two forms with d as the subject equation 3 and with d as the subject equation 4 3 d d 1 d d 1 1 d x 1 1 4 d x 1 d x 1 d 2 4 dd 1 d x 1 2 dd 1 equation 4 is the equation used in model operations it is derived by solving the quadratic equation to express d in terms of d note that a negative solution for d exists but is not of interest here although gr4j is used as the example here these equations could equally be applied to a different rainfall runoff model to test the impact of removing limits on simulated soil moisture deficit a key advantage of this formulation is its continuity with the existing model if dd 0 the new model is identical to standard gr4j this is because d d if dd 0 as per equation 3 and fig 2b it is only once dd 0 that the curves from fig 2a diverge from their gr4j counterparts particularly for higher values of dd fig 2b and 2c an initial misunderstanding of these changes may arise from the green runoff curves in fig 2 which seem to imply that flow generation has increased not decreased for a given deficit state in gr4j compared to gr4j dd however the orange evaporation curves have changed too and this means the soil moisture will decline faster in gr4j dd compared to gr4j during a period of low rainfall the altered model will potentially accrue more deficits so the changes will not necessarily increase flow generation for a given climate sequence 4 results in line with the previous section the results section is structured in two parts section 4 1 describes the results of the performance tests listed above applied to gr4j and gr4j dd section 4 2 focusses on the plausibility and realism of the simulations when compared with auxiliary observations such as groundwater grace and actual evapotranspiration 4 1 performance tests 4 1 1 split sample performance of original gr4j test 1 the first of the tests from fowler et al 2018b is the differential split sample test this test was already conducted by fowler et al 2020 and the results are shown in the recap of this paper in fig 1c above note that fig 1c only shows results when using index of agreement as objective function results using split kge are discussed below and shown graphically later section 4 1 4 in summary the performance of gr4j in split sample testing is variable over the 38 catchments and depends strongly on catchment characteristics among the 26 catchments in the eastern wetter and steeper half of the state the reference metric kge scores during the independent evaluation period the seven driest consecutive years see section 3 2 1 are higher relative to the western half with only one catchment below a kge of 0 5 and a median score of 0 75 when using the refined index of agreement as objective function and 0 74 when using split kge recall that all results are reported in terms of the reference metric kge regardless of the objective function used as per section 3 2 1 however in the western half of the state split sample performance is much poorer gr4j attains a kge greater than 0 5 in only three of the twelve catchments using the better performing of the two objective functions the median kge in independent evaluation among the twelve catchments is 0 23 when split kge is used and 0 32 when the refined index of agreement is used the difference may be because the split kge has a greater focus on learning from drier years in the calibration period and or because split kge is more similar to the kge and thus encourages model behaviours that provide a higher kge in independent evaluation see fowler et al 2018a for details the model simulations are biased tending to overestimate flow during the evaluation drought period so the kge component that contributes to the most to these low values is the match in the mean value in summary the gr4j model fails the differential split sample test in the western catchments because of this analyses presented in the remainder of the paper tend to focus more on the west than the east 4 1 2 determining whether structural changes are required to original gr4j test 2 as described in section 3 2 1 the aim here is to explore the limits of gr4j s performance flexibility and robustness in matching flows for each period separately and both periods together to determine if structural changes are required by flexibility we mean the ability to match wet periods and dry periods when each period is considered in isolation from the other and by robustness we mean having parameter sets that can perform well on both wet and dry periods simultaneously fig 3a shows a single catchment example plotting an ensemble of randomly generated parameter sets according to their performance in simulating the seven driest consecutive years on record x axis and the remaining years in the record nondry period y axis it is clear that for this catchment no parameter sets exist that exceed 0 7 on both axes simultaneously that is the gr4j model structure has no coverage of the subspace kgedry 0 7 kgenondry 0 7 in the terminology of fowler et al 2018b simultaneous coverage is called α coverage thus gr4j lacks α coverage in this case yet parameter sets exist with kgedry 0 7 while other parameter sets exist beyond axis limits with kgenondry 0 7 this one by one coverage is called β coverage by fowler et al 2018a 2018b further discussion of the meaning of the cloud limits can be found in fowler et al 2016 fig 4 provides results for other catchments summarised in the following statistics among eastern catchments ncatchments 26 gr4j has α coverage in 23 catchments at the kge 0 7 level decreasing to 19 catchments if the more stringent standard of kge 0 8 is used among western catchments ncatchments 12 gr4j has α coverage in 2 catchments at the kge 0 7 level decreasing to 1 catchment if the more stringent standard of kge 0 8 is used it is clear that the results are very poor in some western catchments eg 406224 415226 such catchments have already passed data quality checks as described in fowler et al 2016 including water balance checking double mass curve analysis and visual inspection thus it is likely that the poor performance is associated with model structure but the specific model structural issue is unclear in these two catchments considering the full set of western catchments gr4j lacks robust parameter sets for nearly all of the western catchments in most western catchments the gr4j model has good β coverage that is it is able to fit data it is calibrated to even if calibrated to the millennium drought however typically no parameter set is transferable from one climatic period to another as indicated by the low α coverage for western catchments this indicates structural change is required beck 2005 de vos et al 2010 fowler et al 2018b 4 1 3 improved performance due to structural changes test 3 among western catchments the structural changes make a significant difference to model performance so that gr4j dd has much better coverage both α and β than gr4j in fig 3c the limit of the cloud for the campaspe river example is shifted towards the perfect point 1 1 by more than 0 2 units and similar results are seen in at least 7 of the 12 western catchments as shown in fig 4 however this improvement is not sufficient to significantly increase α coverage statistics among western catchments up from two gr4j to four gr4j dd catchments out of twelve for kge 0 7 therefore we introduce an additional measure of performance that is continuous rather than discrete namely the minimum distance between model coverage and perfect point as shown in the boxplots in fig 4 this distance is typically significantly less for gr4j dd compared to gr4j for example the median value is 0 77 for gr4j and 0 56 for gr4j dd an improvement of 0 21 units among eastern catchments gr4j dd provides a modest improvement over gr4j and in numerous well performing catchments there is no discernible difference between the two eg 401208 401217 4 1 4 split sample performance after structural changes test 4 based on results above we now have a model structure which given the correct parameter set s is significantly more robust under changing climate than the original gr4j in western catchments this section asks will this parameter set s be chosen in split sample testing in split sample testing it is only permitted to use one period for calibration while the other is reserved for independent evaluation because the calibration can only see the hydrologic response over a limited range of climatic conditions in principle there is no guarantee that a robust parameter set will be chosen fowler et al 2016 in practice fig 5 there is minimal difference between the split sample performance of gr4j and gr4j dd for both eastern and western catchments using the same measure of performance as section 4 1 1 the median value among the western catchments improves from 0 32 to 0 07 when using the revised index of agreement as objective function while this may sound significant it is about the same difference as between the two objective functions tested see section 4 1 1 and in absolute terms the scores are still poor relative to what is possible for the new model structure cf coverage results in fig 4 regardless of the objective function used note that in general these findings hold even if the two worst performing catchments 406224 and 415226 are removed from the sample not shown there is also minimal difference in split sample performance for eastern catchments as discussed earlier by fowler et al 2016 these results indicate the dangers of relying solely on split sample test results to assess model improvements under changing climatic conditions particularly when based on optimisation to only one objective in cases of low parameter identifiability it is possible for split sample test results to be unchanged yet model coverage to significantly improve leading to a false conclusion that the model structure changes gave negligible benefit if future research uncovers calibration methods that are better able to identify robust parameter sets based on limited information this problem may lessen see also section 5 4 4 2 examining model realism finally the gr4j dd simulations are compared fig 6 against various independent measurements of state and flux variables to assess the plausibility and physical realism of model behaviour prior to considering these results recall that grace terrestrial water storage data have low resolution and thus relate only to very broad areas fig 1 and groundwater bore measurements may relate to the local area only and may not be representative of the catchment as a whole see also section 5 2 below but that the declines seen here are consistent with region wide climate induced groundwater decline reported by fowler et al 2020 who considered a wider set of nineteen bores further recall from section 2 that the following two behaviours are consistent with bucket models which are emptying on a seasonal basis i poor match with seasonal patterns of actual evapotranspiration aet since the months at the end of the dry season would have lower simulated aet as the model runs out of water ii during multi year droughts that cause long term decline in measured state variables eg groundwater grace the models would be missing such downwards trends as stated by fowler et al 2020 once the drought begins there is little room for decline in the simulated storage because the model buckets are already emptying on a seasonal basis we can now assess whether these behaviours are exhibited in gr4j and gr4j dd given that observations of environmental state variables such as grace terrestrial water storage and groundwater level data each show multi year downward trends during the millennium drought ideally hydrologic models should also exhibit multi year downwards trends in at least one state variable simulating the same drought point ii above however fig 6 shows that this is not the case for gr4j dd with respect to long term trends gr4j dd s behaviour is unchanged compared to gr4j both models lack long slow dynamics consistent with fowler et al 2020 thus gr4j dd fails this test this lack of multi year trends in the altered model is discussed further in section 5 3 however there is some improvement in point i regarding seasonality of storage dynamics to see an example consider the magnified section of fig 6 which focusses on simulated storage in the 2006 07 summer in catchment 406214 at the end of the prior wet season the wetness state of the two models is approximately equivalent two months of catchment drying then occur so that the gr4j model is almost empty practically speaking it runs out of water the decline in storage for gr4j ends because the model has no more stored water to evaporate or transpire and it continues in a near empty state for three further months until sustained rain ends the dry season during these three months the gr4j dd model continues to accrue an additional 40 mm of storage deficit over the hottest and driest months of the year this additional deficit means that the restoration of catchment wetness and flow generation fig 7 in gr4j dd is delayed relative to gr4j consistent with this interpretation the seasonality of aet in similar selected years 1997 1998 2004 2007 2009 differs between gr4j and gr4j dd fig 6b gr4j dd has a greater proportion of the seasonal pattern of simulated aet in the later months of the dry season january april in addition to simulated aet fig 6b shows flux tower based measured aet seasonal patterns although the available data has only short periods of record the seasonality of this data supports the interpretation above because it shows sustained aet for longer periods during the dry season even at the relatively dry whroo site furthermore the measured aet is more sustained throughout the dry season than in the gr4j dd simulations so further improvement is possible in this respect thus the available data suggests that the removal of the upper limit on soil moisture deficit ie it can no longer be empty allows gr4j dd to exhibit a more realistic seasonal pattern of actual evapotranspiration a more plausible accrual of moisture deficit followed by a more muted and or delayed flow response during wet seasons that follow long or severe dry seasons we suggest this is the reason for the increases in model performance in fig 4 we note the following with regards to aet timing each of the three flux towers are located in forested areas whereas the three catchments shown here have mixed landuse approximately 45 65 and 55 forested for 406213 406214 and 407230 respectively the aet in cleared areas is expected to be strongly driven by radiation whereas this is less the case for forested areas thus the seasonal patterns for aet in each catchment may have more pronounced seasonality than shown in fig 6 so that the difference between simulated and actual patterns may be less than shown one factor that has not yet been discussed is the ability of gr4j to simulate intercatchment groundwater exchange via its x2 parameter such exchanges where they occur could influence long term water balances in both the source areas and the receiving areas so it is informative to report on and interpret the value of the x2 parameter in the present case study the x2 parameter is almost uniformly negative and our interpretation is that this is unlikely to be indicative of actual groundwater loss from the study catchments for example for the calibrations corresponding to fig 5a every western catchment n 12 exhibited a negative value of x2 varying between 1 0 and 2 8 for gr4j while it is possible to explain these results by hypothesising that all 12 catchments are indeed losing groundwater further downslope this is considered unlikely because i a detailed review of groundwater literature and relevant government reports found little evidence for such regional groundwater flows occurring so far towards the headwaters of this region for more information see section 6 3 of fowler et al 2020 and references therein and ii similar results were obtained in earlier work covering the entire region of south east australia fowler 2017 which suggests a broader issue our interpretation is that the groundwater exchange feature of gr4j is compensating for structural issues relating to simulated et in semi arid areas aet is the dominating water balance flux after precipitation and so an automatic calibration procedure will place a high priority on representing the water that it removes from the system where possible in gr4j the x1 parameter which governs the aet equation is also the soil moisture store capacity thus it has a key role in determining moisture partitioning and this may set up trade offs between the various influences of x1 on different fluxes an automatic calibration procedure would logically use other parameters to lessen these tradeoffs where possible including parameters originally intended to govern groundwater exchange x2 and to a lesser extent x3 such a strategy would allow a greater level of flexibility to represent the dominant influence of aet on the water balance we note that this interpretation relates to the present study region only and is not a comment on the phenomenon of intercatchment groundwater flows nor the suitability of the relevant gr4j components to represent it finally we briefly discuss the hydrographs shown in fig 7 it is difficult to select one parameter set over all the other options presented by the coverage cloud limits in fig 4 in fig 7 we select the same parameter sets as in fig 6 the best trade off parameter set specifically the parameter set that is closest to the perfect point 1 1 in fig 4 in this case it is seen that the trade off is partially about model bias the models have a tendency to overestimate drought flows while pre drought flows are underestimated for 407230 this underestimation is also true of the drought ending flood in 2010 in terms of parameters the need to absorb drought rainfall is achieved via a larger x1 ie larger production store in gr4j and or a more negative x2 value more groundwater export from the catchment however pre drought and post drought both of these act to absorb too much of the rainfall leading to flow underestimation gr4j dd is better able to match both the pre drought and drought flows eg pre drought flows are less under predicted for gr4j dd but the tradeoff remains evident suggesting that some issues with gr4j remain unresolved with gr4j dd we delve into this in more detail in section 5 2 5 discussion 5 1 answer to research question recall from section 2 that the research question restated from the study aim is does removing the upper limit on simulated soil moisture deficit while ensuring that all other aspects of the model are unchanged improve the performance and realism of simulations both prior to and during a historic multi year drought with respect to performance there is undoubtedly an increase in model performance afforded by the deficit formation of gr4j dd fig 4 however this is subject to the following caveats a the increase in performance is much larger among the flatter drier western catchments than among the eastern catchments and b the increase in performance is mostly not apparent in differential split sample test results fig 5 because the calibration methods used here are unable to identify the robust parameter sets based only on pre drought data thus the coverage results figs 3 and 4 are the key indicator of the performance benefits of the deficit formulation we discuss the importance of calibration methods further in section 5 4 with respect to model realism some aspects are improved by the model changes while other aspects of unrealistic behaviour shown by gr4j are unchanged for gr4j dd on the positive side there is an improvement in within year patterns of deficit accumulation during the millennium drought the gr4j model ran out of water mid way through many of the dry seasons leading to temporary reductions in aet that were inconsistent with measured flux tower aet data due to the deficit formulation of gr4j dd this behaviour did not occur in the altered model although within year patterns improved the plausibility of between year patterns ie multi year trends did not improve point ii from section 2 recall from section 2 that part of the overall justification of the study is that measured state variables grace groundwater can exhibit multi year downward trends but that bucket models cannot because they have a driest possible state ie empty limiting the accumulation of deficits we might naively expect that the removal of this driest possible state in gr4j dd might lead to the development of long term accumulation of deficit in water storage unfortunately it does not this is considered further below 5 2 discussion and strategy in response to failed plausibility tests in our view the core issue appears to be that rainfall runoff models require time responses that are at least as long as the memory of the catchment fowler et al 2020 p22 the multi annual or possibly decadal memory of the western region catchments cannot be simulated by rainfall runoff models like gr4j because there is no component capable of harbouring multi annual dynamics instead gr4j and most other models rely on a single index of catchment wetness in gr4j the production store which tends to be tuned to seasonal and or event dynamics to explore the implications of relying on a single index of catchment wetness consider the following thought experiment if we were to force the single index to follow the observed multi year decline in storage during the drought the index values during late drought winters would be lower than the index values during pre drought summers thus the drought winters would have low or zero flow like the pre drought summers did fig 7 in reality the drought winters still had a flow response albeit muted relative to pre drought expectations the implication is that the relationship between total water stored in the catchment and streamflow was and is non stationary one way forward may be to adopt or invent model formulations with more than one index that tracks catchment wetness for example via multiple model storages in principle the model storage s that track long time response could be different to and interact with the storage s that track higher frequencies seasonal or shorter although this seems an undesirable increase in model complexity it should be remembered that multiple storages arise directly from the model conceptualisation in some existing models eg dynamic topmodel beven and freer 2001 coxon et al 2019 thus such models may already be able to demonstrate this behaviour without the need for significant alterations it is also possible that existing components in models could contribute to such behaviour in particular existing baseflow storages but it is important to note that multi year behaviour is very different from flow recession in any case if this hypothesis is correct and multiple storages are indeed required then the results are unsurprising since neither gr4j nor gr4j dd have multiple storages to track catchment wetness nor a dedicated place to track longer time responses 5 3 generality of concepts under a drying climate summarising the preceding two sections the removal of upper limits on soil moisture deficit helped ensure that the model did not run out of water on a seasonal basis but was not sufficient to help the model to develop long term decline in simulated storage given these factors we now consider how general the concept is that is can removal of upper limits on soil moisture deficit help improve conceptual rainfall runoff models in general or are the results particular to gr4j under a future drier climate the dry season may be longer and or drier than in the past this may cause bucket storages in models to seasonally approach empty even if this behaviour was unseen during historical simulations following the precautionary principle we argue that it is best to adopt a modelling approach that ensures that the model does not run out of water on a seasonal basis unless auxillary data is available indicating this is unrealistic here we achieve this via using a deficit formulation but this could also be achieved via a bottomless bucket penman 1949 wagener et al 2003 or conceivably by persisting with a standard bucket formation but adopting a bucket capacity such that it never empties even in the driest of simulations similar arguments apply to low frequency behaviour since multiyear trends can theoretically exist within a bucket storage provided its capacity is arbitrarily large what matters is the dynamics of evapotranspiration as the catchment dries rather than the choice between deficit and bucket formulations for the present case study the core issue is that the gr4j buckets are emptying on a seasonal basis an issue that was solved effectively via the deficit formulation since fowler et al 2020 also tested other models such as simhyd ihacres and sacramento and found similar dynamics of seasonal emptying it seems likely that similar treatment of these and other conceptual models may yield benefits like those shown here a caveat is that for more complex models such as sacramento it may be necessary to test a priori which of the storages is acting as the main soil moisture storage in order to know which storage to change formulation or alternatively remove deficit limits on all storages in order to achieve the desired results when assessing whether to pursue the approach in other models and or locations it is useful to consider how performance compares with other suggested model improvements to the same model applied in similar context ie southern australia and under changing climatic conditions fig 8 compares the performance of gr4j dd with two alternative gr4j variants westra et al 2014 altered the runoff production equation equation 1 here allowing the exponent to take values other than 2 in order to allow better fitting of recession behaviour also gr4j has an interception store of nil capacity westra et al 2014 removed this feature citing consideration of physical processes grigg and hughes 2018 repeated westra et al 2014 s strategy to allow the exponent to vary but also i repeated this for the exponent in the et equation ii added an additional scaling factor to the et equation and iii introduced a memory parameter that allowed sensitivity of storage dependant evaporation and streamflow production to differ significantly effectively mimicking catchment memory note that the part of their strategy that involved leaf area index data was not tested here given that smaller values are desirable see fig 4 the results clearly indicate that the removal of upper limits on deficits is a highly effective modelling strategy compared to the other candidates and is pleasingly parsimonious judged by number of parameters we suggest the approach is well suited to rainfall runoff modelling in temperate and semi arid climates over the historic record and by extension likely to be well suited to modelling in temperate regions that may increase in aridity under future drying climate 5 4 on the need for improved calibration methods practically speaking improved coverage is almost useless for projections without better calibration methods figs 4 and 5 show that the altered model structure is capable of being more robust to changing climate conditions but the parameter sets chosen in split sample testing are not capitalising on this capability the robust parameter values are not yet identifiable based on pre drought data alone we note that there has been some recent progress in improving calibration methods for changing climate including by i focussing on improving performance metrics to better relate to what is important in a given application and or by considering wetter and drier periods in the calibration period fowler et al 2018a see also numerous studies that are not specifically related to changing climate eg gharari et al 2013 and ii first steps towards improved calibration by directly calibrating to or evaluating against auxillary data such as remotely sensed et products fowler et al 2018b and or grace data rakovec et al 2016 however despite this progress further work is required possible approaches for improved calibration include actual evapotranspiration the data shown here fig 6 is consistent with previous work by fowler et al 2018b suggesting the possibility for aet to be used in multi objective calibration to increase model robustness particularly if effective remote sensing based estimates of aet can be identified this approach has strong potential for wide scale application eg viney et al 2014 similarly rakovec et al 2016 have demonstrated progress by calibrating regional scale hydrologic models to grace data and evaluating against independent et data fixing or regionalising parameters that govern long slow processes in previous studies the regionalisation of model parameters based on catchment characteristics has proved difficult for a variety of reasons hrachowitz et al 2013 some studies have found that indicators related to long slow processes such as groundwater have proved relatively more useful in the regionalisation context yadav et al 2007 as new rainfall runoff models are created with improved simulation of such processes in the context of changing climate researchers might revisit the question of whether the parameters relevant to long slow processes can be generalised or regionalised for example it may be acceptable to consider the dd parameter to be fixed at a given value for all catchments within a given region and or to vary in relationship with catchment characteristics in general parameters governing long slow processes may have poor identifiability in the absence of long decadal scale climatic variations and regional approaches that share information spatially may contribute to solving this issue see next dot point space for time methods as with rainfall runoff modelling more generally a key challenge with simulating runoff under changes in climate is parameter identifiability eg beven 2006 for a given catchment subject to climate drying it may be easier to pick plausible values of parameters if reference is made to other nearby catchments which are already drier in other words substituting space for time peel and blöschl 2011 singh et al 2011 the key drawback is the assumption that other hydrologically relevant characteristics are spatially and temporally constant cf roderick et al 2015 regarding the related issue of uncertainty since parameters will never be fully identifiable eg beven and binley 1992 uncertainty approaches remain an important aspect of hydrological simulation in the context of changing climate the first step is to develop models with improved coverage since this indicates that behaviours matching historic climatic variability are possible within the model structure uncertainty analysis may then alert hydrologists and system managers to a range of hydrological behaviours that are plausible in the future even if we are unsure which will eventuate which is useful for robust water resource planning 6 conclusions this study suggests that conceptual rainfall runoff models are limited in their ability to project streamflow under drying climate because of implicit upper limits on soil moisture deficit accrual using the example of gr4j we demonstrated a working mathematical scheme for converting an existing bucket model to a deficit model which removed the upper limit on deficits that was present in the original model the converted version called gr4j dd is capable of significantly improved model performance particularly in the drier catchments with intermittent flow regimes this improvement suggests that deficit models or equivalent bottomless bucket models of which others exist beyond gr4j dd may be well suited to application under a drying climate comparison with independent data such as grace groundwater and aet data demonstrate some significant improvements in realism but room for improvement remains gr4j dd has significantly improved seasonal dynamics of storage being able to track a large moisture deficit that was more consistent with groundwater records and exhibiting more sustained aet closer to seasonal patterns of flux tower et however further improvements are possible to better match seasonal patterns of aet and the improved model still lacks multi year trends in state variables that are seen in grace and groundwater data we have suggested possible future research to remedy these issues as argued by fowler et al 2020 hydrologists engaged in climate change impact assessments should routinely assess the plausibility of adopted model structures and their simulations bucket models applied under progressively drier climatic conditions may approach a driest possible state empty which may not correspond with reality given the evidence presented here such simulations are likely to be implausible and should not be adopted for decision support or impact assessment by fostering a culture of increased scrutiny of model simulations we hope to see an acceleration of research progress towards credible runoff projections under changing climatic conditions credit authorship contribution statement keirnan j a fowler conceptualization methodology writing original draft writing review editing gemma coxon supervision writing review editing jim e freer supervision writing review editing wouter j m knoben conceptualization writing review editing murray c peel conceptualization supervision project administration writing review editing thorsten wagener conceptualization supervision writing review editing andrew w western conceptualization supervision writing review editing ross a woods conceptualization supervision writing review editing lu zhang conceptualization supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was conducted with the support of the australian research council and the government of victoria via linkage projects lp170100598 and lp180100796 authors from the university of bristol acknowledge the support of the uk s natural environment research council grant marius managing the risks impacts and uncertainties of droughts and water scarcity ne l010399 1 and the engineering and physical sciences research council grant ep l016214 1 wise cdt streamflow precipitation and potential evapotranspiration data used in this study are publicly available as part of the camels aus project fowler et al 2021 at https doi pangaea de 10 1594 pangaea 921850 groundwater data were from www vvg org au the authors thankfully acknowledge the two anonymous reviewers whose feedback greatly improved the article 
4416,rainfall runoff models based on conceptual buckets are frequently used in climate change impact studies to provide runoff projections when these buckets approach empty the simulated evapotranspiration approaches zero which places an implicit limit on the soil moisture deficit that can accrue within the model such models may cease to properly track the moisture deficit accumulating in reality as dry conditions continue leading to overestimation of subsequent runoff and possible long term bias under drying climate here we suggest that model realism may be improved through alternatives which remove the upper limit on simulated soil moisture deficit such as bottomless buckets or deficit based soil moisture accounting while some existing models incorporate such measures no study until now has systematically assessed their impact on model realism under drying climate here we alter a common bucket model by changing the soil moisture storage to a deficit accounting system in such a way as to remove the upper limit on simulated soil moisture deficit tested on 38 australian catchments the altered model is better able to track the decline in soil moisture at the end of seasonal dry periods which leads to superior performance over varied historic climate including the 13 year millennium drought however groundwater and grace data reveal long term trends that are not matched in simulations indicating that further changes may be required nonetheless the results suggest that a broader adoption of bottomless buckets and or deficit accounting within conceptual rainfall runoff models may improve the realism of runoff projections under drying climate keywords rainfall runoff modelling runoff projections model improvement model realism drought climate change 1 introduction rainfall runoff models are an important tool for understanding the risks posed by a drying climate they are often applied to interpret the output of general circulation models or stochastic weather generators simulating the availability of water under a future hypothetical scenario bergström et al 2001 chiew et al 1995 2009 christensen et al 2004 faramarzi et al 2013 forzieri et al 2014 krysanova et al 2017 pechlivanidis et al 2017 samaniego et al 2017 singh et al 2014 smith et al 2014a 2014b given that many temperate areas of the world may see decreases in rainfall and reductions in water resources eg arnell 2004 oki and kanae 2006 it is imperative that rainfall runoff models can provide defensible simulations under drier climatic conditions than those seen in the past as required for water resource risk assessments under a drier future climate the importance of this issue is evident in its inclusion among the twenty three unsolved problems in hydrology particularly 1 3 19 and 20 blöschl et al 2019 and the iahs focus on change in hydrology and society through the panta rhei decade 2013 2022 montanari et al 2013 differential split sample studies indicate that rainfall runoff models struggle with changing climatic conditions model performance tends to decline in proportion to long term changes in climatic variables such as rainfall vaze et al 2010 see also broderick et al 2016 coron et al 2012 2014 freer et al 2003 refsgaard knudsen 1996 saft et al 2016 seiller anctil 2015 seiller et al 2012 models often underestimate the severity of hydrological drought arising from a given meteorological drought eg saft et al 2016 fowler et al 2018a and struggle to simulate catchment response to rainfall following dry periods resulting in poor seasonal transitions eg ambroise et al 1996 wagener et al 2003 these results cast doubt regarding the application of these models for climate change impact studies krysanova et al 2017 see also seibert and van meerveld 2016 in response to this problem two possible options are to focus on either the manner in which models are applied or on possible deficiencies in the model structures themselves examples of the first approach include i more rigorous guidelines for selection of calibration and evaluation data eg motavita et al 2019 zheng et al 2018 ii advanced calibration split sampling schemes eg coron et al 2012 gelfan and millionshchikova 2018 dakhlaoui et al 2019 iii increased attention to the impact of calibration objective function on split sample results and or to improve sensitivity to relevant processes eg fowler et al 2018a freer et al 2003 iv broader model evaluation criteria and new tests for evaluating model performance under changing climatic conditions eg thirel et al 2015 fowler et al 2018b and v extensions of split sample methods to examine the consistency of models over potential future climatic conditions eg guo et al 2018 2020 although the above studies show considerable promise results shown by fowler et al 2016 suggest that model structural deficiency plays a key role in most cases of poor performance thus the rest of the paper focusses on this issue numerous recent studies have examined hydrological model structural deficiencies under changing climate westra et al 2014 grigg and hughes 2018 deb et al 2019 guo et al 2017 stephens et al 2018 for example building on earlier studies of the dynamics of parameter values in time eg beck 1985 wagener et al 2003 moradkhani et al 2005 westra et al 2014 presented a method for detecting such deficiencies where one or more parameters change value with time based on selected co variates julian day recent climatic conditions or a linear trend if such a change leads to a significant increase in performance this method infers that problems exist with the corresponding model component see also beck 2002 guo et al 2017 showed that some model structures provide unrealistic simulated evapotranspiration et by comparing model internal dynamics with eddy flux measured et at an arid australian site grigg and hughes 2018 and deb et al 2019 addressed the question of groundwater impacts on streamflow the former through changes to a simple bucket model and the latter through coupling of a complex gridded hydrological model with a modflow groundwater model these latter studies suggest benefits in comparing simulations with independent data to verify simulations in a changing climate recently fowler et al 2020 used independent groundwater and gravity recovery and climate experiment grace data to demonstrate how rainfall runoff models lack long slow multi year dynamics observed in nature in this case in southern australia the present paper follows directly from this earlier research so we provide a detailed summary fig 1 fowler et al 2020 examined environmental state variables such as groundwater data from nineteen bores and grace data and compared these with simulations from five conceptual rainfall runoff models in 38 catchments they noted that all the conceptual buckets are seasonally emptying in most years prior to the drought in contrast the groundwater and grace data show strong multi year declines over the millennium drought giving little indication of approaching empty even after 13 years of dry conditions these declines are co located with catchments exhibiting hydrological shifts saft et al 2015 and poor performance of rainfall runoff models fig 1 in the following section we build on these findings to develop the rationale for the present study 2 rationale and study aim commonly when conceptual buckets approach empty the simulated evapotranspiration approaches zero which places a limit on the soil moisture deficit that can accrue within the model and may curtail seasonal or multi year accrual of deficits in reality many plants have coping mechanisms which allow transpiration to continue during extended dry periods de boer euser et al 2016 this may include tap roots which extend beyond the active root zone vervoort and van der zee 2009 to soil moisture in weathered bedrock anderson et al 1995 arkley 1981 jones and graham 1993 and or underlying groundwater agbakpe 2009 gow et al 2016 miller et al 2010 cf koirala et al 2017 barbeta and peñuelas 2017 compiled data on 71 species of plants and reported that groundwater use represented on average 49 of transpired water during dry seasons cramer et al 1999 ward and micin 2006 the sources and dynamics of water use depend on plant species zwieniecki and newton 1996 zunzunegui et al 2017 and recent climatic conditions for example rose et al 2003 reported preferential use of shallower sources of water when available progressing to deeper layers as dry conditions continue in addition the sources of water available to plants vary depending on their position in the landscape with locations of topographic convergence having access to relatively higher soil moisture and groundwater more often than other locations western et al 1999 even in the case of shallow rooted vegetation given the above evidence bucket models whose simulated evapotranspiration effectively ceases in the mid to late dry season should be treated with scepticism eliades et al 2018 the unrealistic behaviour of such models would be twofold i poor match with seasonal patterns of actual evapotranspiration aet since the months at the end of the dry season would have lower simulated aet as the model runs out of water and ii during multi year droughts that cause long term decline in measured state variables eg groundwater grace the models would be missing such downwards trends as stated by fowler et al 2020 once the drought begins there is little room for decline in the simulated storage because the model buckets are already emptying on a seasonal basis such dynamics have important implications for simulation bias when such models approach empty and evapotranspiration approaches zero the model may cease to properly track the moisture deficit that is accumulating in reality as dry conditions continue as shown in fowler et al 2020 if so this incorrect moisture deficit causes overestimation of runoff from subsequent rainfall events leading to long term model bias if dry conditions persist for multiple years or indefinitely under climate change the issue plays out differently for different models and will depend upon other model structural features including those that interact with low flows such as structural elements that govern inter catchment groundwater inflow or export perrin et al 2003 here we investigate whether model realism may be improved by removing the upper limit on simulated soil moisture deficit this can be achieved via either a bottomless bucket eg the penman model 1949 described by wagener et al 2003 or through adopting a deficit based soil moisture accounting scheme with no upper limit on deficit accrual while these two formulations may sound different they are mathematically similar since each formulation tracks soil moisture against some datum and each is unbounded in one direction and not the other that is there is a wettest possible state full bucket or zero deficit but not a driest possible state deficit models already exist in the literature but they are not as common as bucket models for example a recent compilation of 46 conceptual rainfall runoff models by knoben et al 2019 identified 162 examples of water storage formulation of which only 7 are deficit based however some deficit models are very widely applied such as topmodel beven and kirkby 1979 and successors such as dynamic topmodel beven and freer 2001 and decipher coxon et al 2019 other examples of deficit based models and bottomless buckets include the catchment moisture deficit version of ihacres evans and jakeman 1998 croke and jakeman 2004 see also ivkovic et al 2014 the classic model of crooks and naden 2007 the groundwater components of mod hydrolog chiew 1990 chiew and mcmahon 1994 and part of the routing component of gr6j pushpalatha et al 2011 thus deficit and bottomless bucket models are an established part of the existing literature however no prior study has considered whether these formulations are inherently better suited for application under a drying climate one difficulty is that no existing deficit model has an equivalent bucket model to serve as a benchmark ihacres comes close but the relevant versions have too many other differences for a direct comparison cf jakeman and hornberger 1993 evans and jakeman 1998 thus starting with a commonly used bucket model gr4j perrin et al 2003 see also santos et al 2018 the aim of this paper is aim to test whether removing the upper limit on simulated soil moisture deficit while ensuring that all other aspects of the model are unchanged improves the performance and realism of simulations both prior to and during a historic multi year drought we choose gr4j because of the five models tested by fowler et al 2016 it was the best performing at matching calibration data yet the least transferable to different climatic conditions such a model is a good candidate for exploring which alterations might improve transferability also other authors working in the same geographic region ie southern australia have sought to improve gr4j and comparing results between the variants westra et al 2014 grigg and hughes 2018 allows readers to put performance improvements in context while other gr models exist gr5j le moine 2008 gr6j pushpalatha et al 2011 their emphases on low flows differ from the present emphasis on long term multi year bias under extended dry conditions a recent study fowler et al 2018b proposed a model improvement framework to test whether model structural changes are required considering possible calibration deficiencies or data errors in this paper this framework is applied for the first time thus the method section includes a recap of this model improvement framework section 3 2 and our adopted testing regime includes many of the tests proposed in fowler et al 2018b to close this section and ward against misunderstanding the following three points are emphasised 1 we are not arguing that real catchments do not have driest possible states while driest possible states do exist in both reality and in most conceptual bucket models evidence suggests a profound mismatch between the two the case study in fowler et al 2020 showed that real catchments exhibited no sign of emptying even after 13 years of consecutive drought as judged by groundwater hydrographs in contrast conceptual bucket models emptied seasonally even pre drought implying that the moisture deficit that the calibrated models regard as empty was in fact far from it it seems likely that the driest possible state in the conceptual models was tuned to what staudinger et al 2017 term the dynamic storage but other types of storage exist see table 1 in staudinger et al 2017 in the case of the millennium drought the multiyear declines shown in fowler et al 2020 suggests these other types of storage may depleted by deep rooted vegetation and or may drain slowly of their own accord if unreplenished or under replenished for multiyear periods because these other storage types are commonly minimally involved in event or seasonal dynamics it is more difficult to quantify their size experimentally or via inference from observations or to know how extreme a sequence of climatic forcing needs to be to drive the catchment close to the point of exhausting their supplies thus it seems prudent to adopt model formulations that sidestep the issue of driest possible states entirely 2 we are not primarily seeking to introduce a new model but rather to systematically test the benefits on model realism of removing upper limits on simulated soil moisture deficit it is envisaged that the lessons learned in this experiment will be applicable to other conceptual bucket models as considered further in the discussion section 3 the reader may mistakenly believe that the removal of deficit limits may result in runaway accrual of deficits during extended dry periods however the removal of hard limits does not imply the removal of negative feedback by which we mean the more water is removed the harder it is to remove further water such feedbacks avoid runaway accrual of deficits even though the deficit itself can in principle take any positive value 3 method the method section is divided into three subsections section 3 1 describes the study catchments and model forcing data section 3 2 explains the set of tests which investigate whether gr4j requires structural changes and also characterise the impact of the model changes including via comparison with independent data lastly the model structural changes are presented section 3 3 3 1 study catchments and model forcing data as per fowler et al 2020 this study examines 38 catchments in the state of victoria in south east australia fig 1 the median catchment area is 240 km2 minimum 4 km2 maximum 1100 km2 all catchments are selected from the set of australia s hydrologic reference stations turner 2012 meaning they are unregulated headwater streams free from significant temporal changes eg in landuse and with long records for this study we often report results grouped by east and west as per fig 1 the eastern region contains the upland areas of victoria which are subject to steeper topography often 15 on average higher elevation up to 2000 m relatively high rainfall historic averages up to 2500 mm year and higher forest cover typically 80 in contrast the western region is flatter and drier on average ranging up to only 1200 m elevation and generally with rainfall less than 1000 mm year and with forest cover typically less than 50 both regions are subject to high potential evapotranspiration pet generally over 1000 mm year model forcing data of daily rain and daily pet are derived from gridded products by jones et al 2009 used for rainfall and jeffrey et al 2001 used for pet as described in fowler et al 2016 and now available publicly from the camels aus dataset fowler et al 2021 pet is based on morton s wet environment evaporation morton 1983 3 2 testing regime before describing the testing regime in detail we provide some broad comments on the link between the method and broader research goals as indicated in the title and abstract the broader research goal is improving streamflow projections under a drying climate projections refer to a future period so it is impossible to explicitly demonstrate improvement in future projections at least until the future time comes to pass thus common practice in hydrology as articulated by klemeš 1986 and others is to make use of historic data to conduct experiments that place the model in situations as close as possible to those in which it is supposed to be used in practice klemeš 1986 p13 despite the limitations of using the past as a proxy for the future eg fowler et al 2018b stephens et al 2020 such history based tests are the best available method for testing the ability of models to project the impact of climate change eg refsgaard et al 2014 this paper uses the millennium drought as a proxy for future drying climate prior studies which show poor split sample performance of models tested over this drought see introduction show that many common models and or model application procedures fail these tests and are thus inadequate for future streamflow projection 3 2 1 method to determine whether model changes are required as mentioned in the introduction poor split sample performance for a given case study is often due to causes other than poor model structure such as poor calibration methods lack of informative data or data errors therefore model structural changes should only be attempted after other causes have been considered fowler et al 2018b recently suggested a framework to approach this problem in a systematic way in the results section we apply steps of this framework to gr4j to demonstrate that model structural issues are contributing to poor split sample performance the steps of the framework are listed below note that this pre existing framework is concerned with model improvement over changing climatic conditions in general that is it is not specifically focussed on the issues outlined in section 2 ie issues of timing and persistence of evapotranspiration thus in a later section 3 2 3 we outline additional tests to examine these specific issues in more detail a conduct differential split sample testing step 1 from fowler et al 2018b as shown in fig 1 this step was conducted previously as per fowler et al 2018a two periods are defined dry period defined as the seven driest consecutive years on record and used as the independent evaluation period in the differential split sample test nondry period composed of every year that is not in the dry period and used as the calibration period in the differential split sample test two separate calibrations are conducted differing only by objective function the two objective functions tested are the refined index of agreement of willmott et al 2012 and the split kge of fowler et al 2018a an altered version of the kling gupta efficiency kge of gupta et al 2009 these objective functions have previously performed well relative to other objective functions in the present modelling context fowler et al 2018a in both cases the split sample test results are taken from fowler et al 2018a who used the covariance matrix adaptation evolution strategy cma es calibration algorithm hansen et al 2003 for all single objective optimisation for completeness a summary of the pre existing results is given in the results section of the present paper as per fowler et al 2018b in order to effectively compare results from different calibration methods it is necessary to choose a common evaluation method this could be a single acceptance metric or multiple in which to report all results regardless of which objective function is in focus it is useful for this reference metric or metrics to be related to the purpose of the modelling fowler et al 2018b since the rationale for the present study is to improve runoff projections primarily for water supply planning we adopt the kge as acceptance metric since its three components broadly describe some aspects of performance important to water resource managers the three components are matching the mean flow matching the variability in flow and matching the timing of flow gupta et al 2009 while we recognise the importance of multiple metrics in detailed performance assessments eg thirel et al 2015 fowler et al 2018a in this case we are presenting many tests and in the interests of keeping results tractable and intelligible it is best to limit the results presentation to only one metric thus readers should note that the metric used to report all results is different to both of the adopted objective functions b determine coverage of the objective space by the model structure steps 2 4 from fowler et al 2018b for the climatic periods adopted in a this step explores the limits of model performance and flexibility in matching flows from each period separately and also for all periods together as described in fowler et al 2018a 2018b this step involves either generating a large random ensemble of parameter sets plotting each parameter set according to the kge scores for the wetter period y axis and drier period x axis and identifying the limits of this cloud to quantify the limits of model performance or defining the limits of the cloud directly using a multi objective optimiser which is more computationally efficient here this step is undertaken using the amalgam multi objective optimiser vrugt and robinson 2007 using settings reported previously fowler et al 2016 2018b except in one case fig 3 in the results section which uses both methods for the purposes of demonstration of the principles involved once the cloud limit is determined the case study in question may be categorised by one of the following statements i parameter sets exist with good performance in the wetter period but not the drier period or vice versa ii parameter sets exist with good performance in the wetter period and other parameter sets exist with good performance in the drier period but no sets exist that have good performance for both periods in this case the model structure is flexible it can fit data it is calibrated to but not transferable good parameter sets in one period are poor in others fowler et al 2018b p3 this type of coverage is named β coverage by fowler et al 2018b as distinct from α coverage see next category iii parameter sets exist with acceptable performance in both periods simultaneously referred to as α coverage in fowler et al 2018b in which case no changes to the model structure are required to achieve acceptable performance and the priority should be to improve the calibration method so as to ensure these parameter sets are selected in a repeat split sample test c data checks and cross checks with other catchments steps 5 6 from fowler et al 2018b assuming that the model structure is not in category iii and therefore model changes are required this step aims to verify this conclusion by comparison with other catchments and also by double checking that the result is not due to catchment specific data errors here the catchment comparison is achieved because we are testing 38 different catchments data checks have previously been conducted for the study catchments fowler et al 2016 fowler 2017 and are not described here for brevity the order of presentation in this paper differs from the order that we undertook the tasks whereas here the model changes are described 3 3 prior to presenting the results of the above steps 4 1 in practice we first applied the above steps to demonstrate that gr4j requires model structural changes before formulating any changes to its structure 3 2 2 performance tests the first four results sub sections are structured around the following four aims all relating to the above tests and all of which characterise simulation quality via aggregate metrics ie the kge hence they are labelled performance tests 1 quantify split sample performance of the original gr4j as per a above 2 determine whether structural changes are required by determining coverage as per b and compare this across many catchments as per c 3 quantify the improved coverage made possible in theory by the structural changes and 4 quantify the improved split sample performance achieved in practice after calibration of the model after structural changes have been applied aim 4 is highly contingent on choice of calibration method whereas aim 3 is not that is the structural changes may mean that parameter sets now exist that provide good performance over a range of climatic conditions as revealed by the coverage plots however a split sample test may or may not choose such parameter sets fowler et al 2016 for additional interest the analysis for aim 3 is repeated for the aforementioned two other versions of gr4j namely those of westra et al 2014 and grigg and hughes 2018 this allows us to discuss section 5 3 the various methods employed by different authors to improve gr4j in the context of a changing climate and to comment on their relative effectiveness 3 2 3 assessing model realism the original framing of the need for model structural changes section 2 was primarily on grounds of physical realism with respect to non streamflow variables et groundwater rather than model performance issues with respect to streamflow therefore it is important to augment the above performance tests with analysis of whether the model changes provide improved plausibility and realism of simulations we follow fowler et al 2020 in providing comparison with the following independent data grace grace tapley et al 2004 data shows the evolution with time of terrestrial water which includes soil moisture and groundwater here we reuse the grace satellite data processed by fowler et al 2020 grace estimates were derived separately for the eastern and western half of the state of victoria as per fig 1 groundwater hydrographs we focus on three bores within or close to three catchments selected as case studies for plausibility testing in two cases the bores are within the catchments and in the last case it is less than ten kilometres distant where required the raw groundwater hydrographs from www vvg org au are temporally interpolated using the methods described in fowler et al 2020 the bore numbers and locations are shown later in fig 6 eddy flux tower actual evapotranspiration a small amount of actual et data is available for plausibility testing from the ozflux project www ozflux org au we use post processed data provided by the dynamic integrated gap filling and partitioning for ozflux dingo project beringer et al 2017 the selected sites and their locations relative to the catchments are shown later in fig 6 we note the following two points regarding comparison between model simulations and these data it is noted that there is considerable mismatch between the support of the data ie the spatial scale relating to each measurement type and the scale of modelling for example grace data has large support meaning that grace measurements relate to large areas typically 103 km2 or more conversely measurements from groundwater bores and eddy flux towers relate only to local areas within a short distance 10 2 to 100 km and may not be representative of the catchment scale readers should bear this limitation in mind however given that fowler et al 2020 noted multi year declines in storage both at a regional scale from grace and from multiple groundwater bores spread throughout the region there is considerable confidence that these declines are widespread particularly for catchments close to bores with the multiyear declines for grace which measures total water storage including soil moisture and groundwater the best point of comparison would be a timeseries of total water stored in the model ie the sum of the production and routing stores as done by fowler et al 2020 however here the comparison is limited to a selection of three catchments with good groundwater data namely 406213 406214 and 407230 and in each case the calibrated routing store was small less than 10 of the production storage capacity in each case see figure s6 of fowler et al 2020 thus we show only the production storage timeseries this allows readers to focus better on the effect of the model changes which are made exclusively to the production store as outlined in the following section 3 3 description of model changes as outlined in section 2 we seek to create a version of gr4j which has no upper limit on simulated soil moisture deficit since we do this by creating a deficit version of the model rather than a bottomless bucket we call the altered model gr4j dd where dd stands for deficit dynamics to create the altered model we first express the production state main model store not in terms of catchment storage s as per perrin et al 2003 but in terms of deficit in catchment storage d where d x1 s where x1 is the parameter controlling the capacity of the production store to illustrate this we focus on two of the three equations that depend on the production storage state firstly the partitioning of net rainfall pn such that a part ps is absorbed by the production store and the rest is passed to the routing algorithms and secondly the calculation of aet es from net pet en expressed in terms of storage deficit d these equations are as follows 1 p s x 1 1 1 d x 1 2 t a n h p n x 1 1 1 d x 1 t a n h p n x 1 2 e s x 1 d 2 1 d x 1 t a n h e n x 1 1 1 1 d x 1 t a n h e n x 1 the original gr4j versions of these equations are shown in fig 2 a for x1 600 mm net rainfall ps 6 mm d green and net pet es 6 mm d orange the change from s to d is a change in semantics rather than mathematics these formulas are functionally equivalent to equations 3 and 4 of the original authors however the benefit of moving from s to d is that this change allows further changes that would be nonsensical otherwise specifically instead of limiting the deficit to an arbitrary number in this case 600 mm there is no longer any need to place an absolute limit on moisture deficit d in the original version the actual evapotranspiration rate fig 2a orange line approaches zero as the bucket empties which results in the significant reductions in actual et during extended dry periods that were mentioned in the rationale section for gr4j dd the form of this curve is changed fig 2c so that no matter how high the deficit it is always possible to remove more et however the model retains a negative feedback to avoid runaway et the more water is taken from the catchment the harder it is to remove more the mathematical operations are described below this system is general and could be used to convert other bucket models than gr4j into deficit models at the beginning of the timestep an intermediate variable d is calculated as a function of three quantities d x1 and a new parameter termed the deficit dynamics parameter dd 0 dd 1 for the ranges of other parameters see fowler et al 2018a d is shown graphically in fig 2b for different values of dd having calculated d all other model operations including the percolation equation not in focus here perrin et al 2003 equation 6 are carried out as normal except that the value of d is used in place of d d is thus the middle step via which the value of the dd parameter influences the flux equations of the production store the equation relating d and d is shown below in two forms with d as the subject equation 3 and with d as the subject equation 4 3 d d 1 d d 1 1 d x 1 1 4 d x 1 d x 1 d 2 4 dd 1 d x 1 2 dd 1 equation 4 is the equation used in model operations it is derived by solving the quadratic equation to express d in terms of d note that a negative solution for d exists but is not of interest here although gr4j is used as the example here these equations could equally be applied to a different rainfall runoff model to test the impact of removing limits on simulated soil moisture deficit a key advantage of this formulation is its continuity with the existing model if dd 0 the new model is identical to standard gr4j this is because d d if dd 0 as per equation 3 and fig 2b it is only once dd 0 that the curves from fig 2a diverge from their gr4j counterparts particularly for higher values of dd fig 2b and 2c an initial misunderstanding of these changes may arise from the green runoff curves in fig 2 which seem to imply that flow generation has increased not decreased for a given deficit state in gr4j compared to gr4j dd however the orange evaporation curves have changed too and this means the soil moisture will decline faster in gr4j dd compared to gr4j during a period of low rainfall the altered model will potentially accrue more deficits so the changes will not necessarily increase flow generation for a given climate sequence 4 results in line with the previous section the results section is structured in two parts section 4 1 describes the results of the performance tests listed above applied to gr4j and gr4j dd section 4 2 focusses on the plausibility and realism of the simulations when compared with auxiliary observations such as groundwater grace and actual evapotranspiration 4 1 performance tests 4 1 1 split sample performance of original gr4j test 1 the first of the tests from fowler et al 2018b is the differential split sample test this test was already conducted by fowler et al 2020 and the results are shown in the recap of this paper in fig 1c above note that fig 1c only shows results when using index of agreement as objective function results using split kge are discussed below and shown graphically later section 4 1 4 in summary the performance of gr4j in split sample testing is variable over the 38 catchments and depends strongly on catchment characteristics among the 26 catchments in the eastern wetter and steeper half of the state the reference metric kge scores during the independent evaluation period the seven driest consecutive years see section 3 2 1 are higher relative to the western half with only one catchment below a kge of 0 5 and a median score of 0 75 when using the refined index of agreement as objective function and 0 74 when using split kge recall that all results are reported in terms of the reference metric kge regardless of the objective function used as per section 3 2 1 however in the western half of the state split sample performance is much poorer gr4j attains a kge greater than 0 5 in only three of the twelve catchments using the better performing of the two objective functions the median kge in independent evaluation among the twelve catchments is 0 23 when split kge is used and 0 32 when the refined index of agreement is used the difference may be because the split kge has a greater focus on learning from drier years in the calibration period and or because split kge is more similar to the kge and thus encourages model behaviours that provide a higher kge in independent evaluation see fowler et al 2018a for details the model simulations are biased tending to overestimate flow during the evaluation drought period so the kge component that contributes to the most to these low values is the match in the mean value in summary the gr4j model fails the differential split sample test in the western catchments because of this analyses presented in the remainder of the paper tend to focus more on the west than the east 4 1 2 determining whether structural changes are required to original gr4j test 2 as described in section 3 2 1 the aim here is to explore the limits of gr4j s performance flexibility and robustness in matching flows for each period separately and both periods together to determine if structural changes are required by flexibility we mean the ability to match wet periods and dry periods when each period is considered in isolation from the other and by robustness we mean having parameter sets that can perform well on both wet and dry periods simultaneously fig 3a shows a single catchment example plotting an ensemble of randomly generated parameter sets according to their performance in simulating the seven driest consecutive years on record x axis and the remaining years in the record nondry period y axis it is clear that for this catchment no parameter sets exist that exceed 0 7 on both axes simultaneously that is the gr4j model structure has no coverage of the subspace kgedry 0 7 kgenondry 0 7 in the terminology of fowler et al 2018b simultaneous coverage is called α coverage thus gr4j lacks α coverage in this case yet parameter sets exist with kgedry 0 7 while other parameter sets exist beyond axis limits with kgenondry 0 7 this one by one coverage is called β coverage by fowler et al 2018a 2018b further discussion of the meaning of the cloud limits can be found in fowler et al 2016 fig 4 provides results for other catchments summarised in the following statistics among eastern catchments ncatchments 26 gr4j has α coverage in 23 catchments at the kge 0 7 level decreasing to 19 catchments if the more stringent standard of kge 0 8 is used among western catchments ncatchments 12 gr4j has α coverage in 2 catchments at the kge 0 7 level decreasing to 1 catchment if the more stringent standard of kge 0 8 is used it is clear that the results are very poor in some western catchments eg 406224 415226 such catchments have already passed data quality checks as described in fowler et al 2016 including water balance checking double mass curve analysis and visual inspection thus it is likely that the poor performance is associated with model structure but the specific model structural issue is unclear in these two catchments considering the full set of western catchments gr4j lacks robust parameter sets for nearly all of the western catchments in most western catchments the gr4j model has good β coverage that is it is able to fit data it is calibrated to even if calibrated to the millennium drought however typically no parameter set is transferable from one climatic period to another as indicated by the low α coverage for western catchments this indicates structural change is required beck 2005 de vos et al 2010 fowler et al 2018b 4 1 3 improved performance due to structural changes test 3 among western catchments the structural changes make a significant difference to model performance so that gr4j dd has much better coverage both α and β than gr4j in fig 3c the limit of the cloud for the campaspe river example is shifted towards the perfect point 1 1 by more than 0 2 units and similar results are seen in at least 7 of the 12 western catchments as shown in fig 4 however this improvement is not sufficient to significantly increase α coverage statistics among western catchments up from two gr4j to four gr4j dd catchments out of twelve for kge 0 7 therefore we introduce an additional measure of performance that is continuous rather than discrete namely the minimum distance between model coverage and perfect point as shown in the boxplots in fig 4 this distance is typically significantly less for gr4j dd compared to gr4j for example the median value is 0 77 for gr4j and 0 56 for gr4j dd an improvement of 0 21 units among eastern catchments gr4j dd provides a modest improvement over gr4j and in numerous well performing catchments there is no discernible difference between the two eg 401208 401217 4 1 4 split sample performance after structural changes test 4 based on results above we now have a model structure which given the correct parameter set s is significantly more robust under changing climate than the original gr4j in western catchments this section asks will this parameter set s be chosen in split sample testing in split sample testing it is only permitted to use one period for calibration while the other is reserved for independent evaluation because the calibration can only see the hydrologic response over a limited range of climatic conditions in principle there is no guarantee that a robust parameter set will be chosen fowler et al 2016 in practice fig 5 there is minimal difference between the split sample performance of gr4j and gr4j dd for both eastern and western catchments using the same measure of performance as section 4 1 1 the median value among the western catchments improves from 0 32 to 0 07 when using the revised index of agreement as objective function while this may sound significant it is about the same difference as between the two objective functions tested see section 4 1 1 and in absolute terms the scores are still poor relative to what is possible for the new model structure cf coverage results in fig 4 regardless of the objective function used note that in general these findings hold even if the two worst performing catchments 406224 and 415226 are removed from the sample not shown there is also minimal difference in split sample performance for eastern catchments as discussed earlier by fowler et al 2016 these results indicate the dangers of relying solely on split sample test results to assess model improvements under changing climatic conditions particularly when based on optimisation to only one objective in cases of low parameter identifiability it is possible for split sample test results to be unchanged yet model coverage to significantly improve leading to a false conclusion that the model structure changes gave negligible benefit if future research uncovers calibration methods that are better able to identify robust parameter sets based on limited information this problem may lessen see also section 5 4 4 2 examining model realism finally the gr4j dd simulations are compared fig 6 against various independent measurements of state and flux variables to assess the plausibility and physical realism of model behaviour prior to considering these results recall that grace terrestrial water storage data have low resolution and thus relate only to very broad areas fig 1 and groundwater bore measurements may relate to the local area only and may not be representative of the catchment as a whole see also section 5 2 below but that the declines seen here are consistent with region wide climate induced groundwater decline reported by fowler et al 2020 who considered a wider set of nineteen bores further recall from section 2 that the following two behaviours are consistent with bucket models which are emptying on a seasonal basis i poor match with seasonal patterns of actual evapotranspiration aet since the months at the end of the dry season would have lower simulated aet as the model runs out of water ii during multi year droughts that cause long term decline in measured state variables eg groundwater grace the models would be missing such downwards trends as stated by fowler et al 2020 once the drought begins there is little room for decline in the simulated storage because the model buckets are already emptying on a seasonal basis we can now assess whether these behaviours are exhibited in gr4j and gr4j dd given that observations of environmental state variables such as grace terrestrial water storage and groundwater level data each show multi year downward trends during the millennium drought ideally hydrologic models should also exhibit multi year downwards trends in at least one state variable simulating the same drought point ii above however fig 6 shows that this is not the case for gr4j dd with respect to long term trends gr4j dd s behaviour is unchanged compared to gr4j both models lack long slow dynamics consistent with fowler et al 2020 thus gr4j dd fails this test this lack of multi year trends in the altered model is discussed further in section 5 3 however there is some improvement in point i regarding seasonality of storage dynamics to see an example consider the magnified section of fig 6 which focusses on simulated storage in the 2006 07 summer in catchment 406214 at the end of the prior wet season the wetness state of the two models is approximately equivalent two months of catchment drying then occur so that the gr4j model is almost empty practically speaking it runs out of water the decline in storage for gr4j ends because the model has no more stored water to evaporate or transpire and it continues in a near empty state for three further months until sustained rain ends the dry season during these three months the gr4j dd model continues to accrue an additional 40 mm of storage deficit over the hottest and driest months of the year this additional deficit means that the restoration of catchment wetness and flow generation fig 7 in gr4j dd is delayed relative to gr4j consistent with this interpretation the seasonality of aet in similar selected years 1997 1998 2004 2007 2009 differs between gr4j and gr4j dd fig 6b gr4j dd has a greater proportion of the seasonal pattern of simulated aet in the later months of the dry season january april in addition to simulated aet fig 6b shows flux tower based measured aet seasonal patterns although the available data has only short periods of record the seasonality of this data supports the interpretation above because it shows sustained aet for longer periods during the dry season even at the relatively dry whroo site furthermore the measured aet is more sustained throughout the dry season than in the gr4j dd simulations so further improvement is possible in this respect thus the available data suggests that the removal of the upper limit on soil moisture deficit ie it can no longer be empty allows gr4j dd to exhibit a more realistic seasonal pattern of actual evapotranspiration a more plausible accrual of moisture deficit followed by a more muted and or delayed flow response during wet seasons that follow long or severe dry seasons we suggest this is the reason for the increases in model performance in fig 4 we note the following with regards to aet timing each of the three flux towers are located in forested areas whereas the three catchments shown here have mixed landuse approximately 45 65 and 55 forested for 406213 406214 and 407230 respectively the aet in cleared areas is expected to be strongly driven by radiation whereas this is less the case for forested areas thus the seasonal patterns for aet in each catchment may have more pronounced seasonality than shown in fig 6 so that the difference between simulated and actual patterns may be less than shown one factor that has not yet been discussed is the ability of gr4j to simulate intercatchment groundwater exchange via its x2 parameter such exchanges where they occur could influence long term water balances in both the source areas and the receiving areas so it is informative to report on and interpret the value of the x2 parameter in the present case study the x2 parameter is almost uniformly negative and our interpretation is that this is unlikely to be indicative of actual groundwater loss from the study catchments for example for the calibrations corresponding to fig 5a every western catchment n 12 exhibited a negative value of x2 varying between 1 0 and 2 8 for gr4j while it is possible to explain these results by hypothesising that all 12 catchments are indeed losing groundwater further downslope this is considered unlikely because i a detailed review of groundwater literature and relevant government reports found little evidence for such regional groundwater flows occurring so far towards the headwaters of this region for more information see section 6 3 of fowler et al 2020 and references therein and ii similar results were obtained in earlier work covering the entire region of south east australia fowler 2017 which suggests a broader issue our interpretation is that the groundwater exchange feature of gr4j is compensating for structural issues relating to simulated et in semi arid areas aet is the dominating water balance flux after precipitation and so an automatic calibration procedure will place a high priority on representing the water that it removes from the system where possible in gr4j the x1 parameter which governs the aet equation is also the soil moisture store capacity thus it has a key role in determining moisture partitioning and this may set up trade offs between the various influences of x1 on different fluxes an automatic calibration procedure would logically use other parameters to lessen these tradeoffs where possible including parameters originally intended to govern groundwater exchange x2 and to a lesser extent x3 such a strategy would allow a greater level of flexibility to represent the dominant influence of aet on the water balance we note that this interpretation relates to the present study region only and is not a comment on the phenomenon of intercatchment groundwater flows nor the suitability of the relevant gr4j components to represent it finally we briefly discuss the hydrographs shown in fig 7 it is difficult to select one parameter set over all the other options presented by the coverage cloud limits in fig 4 in fig 7 we select the same parameter sets as in fig 6 the best trade off parameter set specifically the parameter set that is closest to the perfect point 1 1 in fig 4 in this case it is seen that the trade off is partially about model bias the models have a tendency to overestimate drought flows while pre drought flows are underestimated for 407230 this underestimation is also true of the drought ending flood in 2010 in terms of parameters the need to absorb drought rainfall is achieved via a larger x1 ie larger production store in gr4j and or a more negative x2 value more groundwater export from the catchment however pre drought and post drought both of these act to absorb too much of the rainfall leading to flow underestimation gr4j dd is better able to match both the pre drought and drought flows eg pre drought flows are less under predicted for gr4j dd but the tradeoff remains evident suggesting that some issues with gr4j remain unresolved with gr4j dd we delve into this in more detail in section 5 2 5 discussion 5 1 answer to research question recall from section 2 that the research question restated from the study aim is does removing the upper limit on simulated soil moisture deficit while ensuring that all other aspects of the model are unchanged improve the performance and realism of simulations both prior to and during a historic multi year drought with respect to performance there is undoubtedly an increase in model performance afforded by the deficit formation of gr4j dd fig 4 however this is subject to the following caveats a the increase in performance is much larger among the flatter drier western catchments than among the eastern catchments and b the increase in performance is mostly not apparent in differential split sample test results fig 5 because the calibration methods used here are unable to identify the robust parameter sets based only on pre drought data thus the coverage results figs 3 and 4 are the key indicator of the performance benefits of the deficit formulation we discuss the importance of calibration methods further in section 5 4 with respect to model realism some aspects are improved by the model changes while other aspects of unrealistic behaviour shown by gr4j are unchanged for gr4j dd on the positive side there is an improvement in within year patterns of deficit accumulation during the millennium drought the gr4j model ran out of water mid way through many of the dry seasons leading to temporary reductions in aet that were inconsistent with measured flux tower aet data due to the deficit formulation of gr4j dd this behaviour did not occur in the altered model although within year patterns improved the plausibility of between year patterns ie multi year trends did not improve point ii from section 2 recall from section 2 that part of the overall justification of the study is that measured state variables grace groundwater can exhibit multi year downward trends but that bucket models cannot because they have a driest possible state ie empty limiting the accumulation of deficits we might naively expect that the removal of this driest possible state in gr4j dd might lead to the development of long term accumulation of deficit in water storage unfortunately it does not this is considered further below 5 2 discussion and strategy in response to failed plausibility tests in our view the core issue appears to be that rainfall runoff models require time responses that are at least as long as the memory of the catchment fowler et al 2020 p22 the multi annual or possibly decadal memory of the western region catchments cannot be simulated by rainfall runoff models like gr4j because there is no component capable of harbouring multi annual dynamics instead gr4j and most other models rely on a single index of catchment wetness in gr4j the production store which tends to be tuned to seasonal and or event dynamics to explore the implications of relying on a single index of catchment wetness consider the following thought experiment if we were to force the single index to follow the observed multi year decline in storage during the drought the index values during late drought winters would be lower than the index values during pre drought summers thus the drought winters would have low or zero flow like the pre drought summers did fig 7 in reality the drought winters still had a flow response albeit muted relative to pre drought expectations the implication is that the relationship between total water stored in the catchment and streamflow was and is non stationary one way forward may be to adopt or invent model formulations with more than one index that tracks catchment wetness for example via multiple model storages in principle the model storage s that track long time response could be different to and interact with the storage s that track higher frequencies seasonal or shorter although this seems an undesirable increase in model complexity it should be remembered that multiple storages arise directly from the model conceptualisation in some existing models eg dynamic topmodel beven and freer 2001 coxon et al 2019 thus such models may already be able to demonstrate this behaviour without the need for significant alterations it is also possible that existing components in models could contribute to such behaviour in particular existing baseflow storages but it is important to note that multi year behaviour is very different from flow recession in any case if this hypothesis is correct and multiple storages are indeed required then the results are unsurprising since neither gr4j nor gr4j dd have multiple storages to track catchment wetness nor a dedicated place to track longer time responses 5 3 generality of concepts under a drying climate summarising the preceding two sections the removal of upper limits on soil moisture deficit helped ensure that the model did not run out of water on a seasonal basis but was not sufficient to help the model to develop long term decline in simulated storage given these factors we now consider how general the concept is that is can removal of upper limits on soil moisture deficit help improve conceptual rainfall runoff models in general or are the results particular to gr4j under a future drier climate the dry season may be longer and or drier than in the past this may cause bucket storages in models to seasonally approach empty even if this behaviour was unseen during historical simulations following the precautionary principle we argue that it is best to adopt a modelling approach that ensures that the model does not run out of water on a seasonal basis unless auxillary data is available indicating this is unrealistic here we achieve this via using a deficit formulation but this could also be achieved via a bottomless bucket penman 1949 wagener et al 2003 or conceivably by persisting with a standard bucket formation but adopting a bucket capacity such that it never empties even in the driest of simulations similar arguments apply to low frequency behaviour since multiyear trends can theoretically exist within a bucket storage provided its capacity is arbitrarily large what matters is the dynamics of evapotranspiration as the catchment dries rather than the choice between deficit and bucket formulations for the present case study the core issue is that the gr4j buckets are emptying on a seasonal basis an issue that was solved effectively via the deficit formulation since fowler et al 2020 also tested other models such as simhyd ihacres and sacramento and found similar dynamics of seasonal emptying it seems likely that similar treatment of these and other conceptual models may yield benefits like those shown here a caveat is that for more complex models such as sacramento it may be necessary to test a priori which of the storages is acting as the main soil moisture storage in order to know which storage to change formulation or alternatively remove deficit limits on all storages in order to achieve the desired results when assessing whether to pursue the approach in other models and or locations it is useful to consider how performance compares with other suggested model improvements to the same model applied in similar context ie southern australia and under changing climatic conditions fig 8 compares the performance of gr4j dd with two alternative gr4j variants westra et al 2014 altered the runoff production equation equation 1 here allowing the exponent to take values other than 2 in order to allow better fitting of recession behaviour also gr4j has an interception store of nil capacity westra et al 2014 removed this feature citing consideration of physical processes grigg and hughes 2018 repeated westra et al 2014 s strategy to allow the exponent to vary but also i repeated this for the exponent in the et equation ii added an additional scaling factor to the et equation and iii introduced a memory parameter that allowed sensitivity of storage dependant evaporation and streamflow production to differ significantly effectively mimicking catchment memory note that the part of their strategy that involved leaf area index data was not tested here given that smaller values are desirable see fig 4 the results clearly indicate that the removal of upper limits on deficits is a highly effective modelling strategy compared to the other candidates and is pleasingly parsimonious judged by number of parameters we suggest the approach is well suited to rainfall runoff modelling in temperate and semi arid climates over the historic record and by extension likely to be well suited to modelling in temperate regions that may increase in aridity under future drying climate 5 4 on the need for improved calibration methods practically speaking improved coverage is almost useless for projections without better calibration methods figs 4 and 5 show that the altered model structure is capable of being more robust to changing climate conditions but the parameter sets chosen in split sample testing are not capitalising on this capability the robust parameter values are not yet identifiable based on pre drought data alone we note that there has been some recent progress in improving calibration methods for changing climate including by i focussing on improving performance metrics to better relate to what is important in a given application and or by considering wetter and drier periods in the calibration period fowler et al 2018a see also numerous studies that are not specifically related to changing climate eg gharari et al 2013 and ii first steps towards improved calibration by directly calibrating to or evaluating against auxillary data such as remotely sensed et products fowler et al 2018b and or grace data rakovec et al 2016 however despite this progress further work is required possible approaches for improved calibration include actual evapotranspiration the data shown here fig 6 is consistent with previous work by fowler et al 2018b suggesting the possibility for aet to be used in multi objective calibration to increase model robustness particularly if effective remote sensing based estimates of aet can be identified this approach has strong potential for wide scale application eg viney et al 2014 similarly rakovec et al 2016 have demonstrated progress by calibrating regional scale hydrologic models to grace data and evaluating against independent et data fixing or regionalising parameters that govern long slow processes in previous studies the regionalisation of model parameters based on catchment characteristics has proved difficult for a variety of reasons hrachowitz et al 2013 some studies have found that indicators related to long slow processes such as groundwater have proved relatively more useful in the regionalisation context yadav et al 2007 as new rainfall runoff models are created with improved simulation of such processes in the context of changing climate researchers might revisit the question of whether the parameters relevant to long slow processes can be generalised or regionalised for example it may be acceptable to consider the dd parameter to be fixed at a given value for all catchments within a given region and or to vary in relationship with catchment characteristics in general parameters governing long slow processes may have poor identifiability in the absence of long decadal scale climatic variations and regional approaches that share information spatially may contribute to solving this issue see next dot point space for time methods as with rainfall runoff modelling more generally a key challenge with simulating runoff under changes in climate is parameter identifiability eg beven 2006 for a given catchment subject to climate drying it may be easier to pick plausible values of parameters if reference is made to other nearby catchments which are already drier in other words substituting space for time peel and blöschl 2011 singh et al 2011 the key drawback is the assumption that other hydrologically relevant characteristics are spatially and temporally constant cf roderick et al 2015 regarding the related issue of uncertainty since parameters will never be fully identifiable eg beven and binley 1992 uncertainty approaches remain an important aspect of hydrological simulation in the context of changing climate the first step is to develop models with improved coverage since this indicates that behaviours matching historic climatic variability are possible within the model structure uncertainty analysis may then alert hydrologists and system managers to a range of hydrological behaviours that are plausible in the future even if we are unsure which will eventuate which is useful for robust water resource planning 6 conclusions this study suggests that conceptual rainfall runoff models are limited in their ability to project streamflow under drying climate because of implicit upper limits on soil moisture deficit accrual using the example of gr4j we demonstrated a working mathematical scheme for converting an existing bucket model to a deficit model which removed the upper limit on deficits that was present in the original model the converted version called gr4j dd is capable of significantly improved model performance particularly in the drier catchments with intermittent flow regimes this improvement suggests that deficit models or equivalent bottomless bucket models of which others exist beyond gr4j dd may be well suited to application under a drying climate comparison with independent data such as grace groundwater and aet data demonstrate some significant improvements in realism but room for improvement remains gr4j dd has significantly improved seasonal dynamics of storage being able to track a large moisture deficit that was more consistent with groundwater records and exhibiting more sustained aet closer to seasonal patterns of flux tower et however further improvements are possible to better match seasonal patterns of aet and the improved model still lacks multi year trends in state variables that are seen in grace and groundwater data we have suggested possible future research to remedy these issues as argued by fowler et al 2020 hydrologists engaged in climate change impact assessments should routinely assess the plausibility of adopted model structures and their simulations bucket models applied under progressively drier climatic conditions may approach a driest possible state empty which may not correspond with reality given the evidence presented here such simulations are likely to be implausible and should not be adopted for decision support or impact assessment by fostering a culture of increased scrutiny of model simulations we hope to see an acceleration of research progress towards credible runoff projections under changing climatic conditions credit authorship contribution statement keirnan j a fowler conceptualization methodology writing original draft writing review editing gemma coxon supervision writing review editing jim e freer supervision writing review editing wouter j m knoben conceptualization writing review editing murray c peel conceptualization supervision project administration writing review editing thorsten wagener conceptualization supervision writing review editing andrew w western conceptualization supervision writing review editing ross a woods conceptualization supervision writing review editing lu zhang conceptualization supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was conducted with the support of the australian research council and the government of victoria via linkage projects lp170100598 and lp180100796 authors from the university of bristol acknowledge the support of the uk s natural environment research council grant marius managing the risks impacts and uncertainties of droughts and water scarcity ne l010399 1 and the engineering and physical sciences research council grant ep l016214 1 wise cdt streamflow precipitation and potential evapotranspiration data used in this study are publicly available as part of the camels aus project fowler et al 2021 at https doi pangaea de 10 1594 pangaea 921850 groundwater data were from www vvg org au the authors thankfully acknowledge the two anonymous reviewers whose feedback greatly improved the article 
4417,evapotranspiration et prediction and forecasting play a vital role in improving water use in agriculturally intensive areas metrological and biophysical predictors that drive et in managed landscapes have complex nonlinear relationships deep learning and data driven methods have shown promising performance for identifying the dependencies among variables here we evaluated the potentials of random forest rf and long short term memory lstm neural networks to estimate and forecast daily et for corn soybeans and potatoes in diverse agricultural farms during 2003 2019 the modeling framework was applied for nineteen fields where eddy covariance et and meteorological observations in the midwest usa for growing season april october is available in this study we applied data driven models rf and lstm with 3 sets of predictors 5 11 and 16 predictors results show that a 16 predictor rf model rf 16 r2 0 7 willmott s skill score 0 90 outperformed a process based land surface model lsm r2 0 57 willmott s skill score 0 86 for predicting daily et while lstm performance was lower lstm 16 r2 0 65 willmott s skill score 0 89 and lstm 11 r2 0 62 willmott s skill score 0 86 than rf using the same sets of predictors vapor pressure and crop coefficients were identified as the most important predictors for irrigated crops while short wave radiation and enhanced vegetation index were key predictors for non irrigated crops for certain crop types such as corn and soybeans on fine grained soils silt loam a simpler version rf using only 11 drivers can provide comparable results r2 0 70 vs 0 69 and willmott s skill score 0 90 vs 0 88 for short term 3 day et forecasting lstm is more sensitive to uncertainty in ensemble forecast meteorology than rf et forecasts were strongly sensitive to forecast uncertainty of vapor pressure the proposed modeling architecture provides a field scale locally calibrated tool for accurate prediction and short term forecasting of daily et in areas where in situ et metrological and biophysical data are lacking keywords evapotranspiration machine learning agriculture drought irrigation forecasting 1 introduction terrestrial water in the biosphere and atmosphere is linked through evapotranspiration et donohue et al 2010 priestley and taylor 1972 wei et al 2017 et is the second largest term in the global land surface water budget barr et al 2014 narasimhan and srinivasan 2005 trenberth et al 2007 wang and dickinson 2012 in order to understand terrestrial ecosystem processes in a changing climate such as flash droughts kim et al 2019 otkin et al 2016 water resource management e g irrigation efficiency it is important to accurately estimate and forecast et allen et al 1998 anderson et al 2011 shugart 1998 hydrological applications geared towards conservation of water resources especially for irrigation require prediction and forecasting of et as a fundamental component hence for sustainable agriculture an et prediction and forecasting tool can be useful for farmers and water managers to handle water resource challenges djaman et al 2020 moratiel et al 2020 payero and irmak 2013 perera et al 2014 actual et can be measured directly using eddy covariance ec towers baldocchi et al 2001 barr et al 2012 wilson et al 2001 but costs logistics and measurement scale inhibit regional and long term studies such as ec and bowen ratio methods rosenberry et al 2007 further et needs to be assessed across a range of crop varieties and soil climate types that influence it requiring many observation sites hence there is a need for models that are based on more readily available drivers to predict and forecast et for broader applications data from satellite sensors have been used in earlier studies to estimate et over domains of different regional scales such as watershed or continent anderson et al 2021 crosbie et al 2015 filgueiras et al 2020 fisher et al 2020 scott et al 2008 yao et al 2013 though satellites are hampered by tradeoff in spatial resolution and revisit frequency cloud cover and model assumptions used in linking observations of surface reflectance or brightness temperatures to et in addition data assimilation methods meng et al 2009 xu et al 2018 zou et al 2017 as well as land surface models lian et al 2018 vinukollu et al 2012 have been used however the relative error range for et estimates compared with ground measurements is from 14 to 44 long et al 2014 velpuri et al 2013 due to factors such as spatial variation heterogeneity model parametrization and unconstrained water balance in addition while there are many studies to estimate or predict and forecast reference et in different climatic conditions e g fang et al 2018 li et al 2016 yang et al 2006 there are not many studies for forecasting actual et in intensively irrigated and non irrigated areas field scale crop models are another avenue for predicting et current crop models that are designed to simulate agricultural practices such as soil composition nutrients tilling practices and irrigation scheduling can be coupled with computational hydrologic and land atmosphere models pauwels et al 2007 the development of these physically based and spatially explicit representation of land surface interaction and agricultural processes at the farm scale have high computational costs chaney et al 2016 clark et al 2017 which requires significant parameterization and tuning subject to collection of a myriad of trait and driver datasets even though those models accurately simulate hydrological processes challenges in calibrating these biophysically based models make accurate physical process simulations at individual fields challenging in addition the available data for calibration and validation of these models e g three dimensional information about sub surface heterogeneity such as soil texture moisture and groundwater flow limit the application of those models for larger areas with intensive agriculture however these models are useful for small scale regional studies in addition to process based hydrological models empirical models based on statistical correlations of potential evapotranspiration with meteorological parameters have also been used valipour et al 2017 often variables like canopy cover is used in these methods to convert potential evapotranspiration to actual evapotranspiration the problem with such an approach is that performance may significantly depend on the estimate of canopy cover an alternate approach to existing empirical and physical based methods is to use data driven methods to estimate actual evapotranspiration a variety of data driven models have been used in et simulation studies deo and şahin 2015 fang et al 2018 izadifar and elshorbagy 2010 pandey et al 2017 it is efficient to combine information from readily available predictors from remote sensing along with ground observation by applying machine learning ml methods that may be able to predict and forecast et based on relationships between input predictors without utilizing field based physical parameters ml algorithms extract non linear relationships hidden in time series or spatial data and then apply those patterns to estimate and forecast future scenarios for example yang et al 2006 and tabari et al 2012 used a support vector machine svm approach to estimate eight day averaged et and reference et respectively using ground observation and remote sensing predictors landeras et al 2009 used autoregressive models to forecast weekly reference et and bodesheim et al 2018 applied a regression trees based random forest rf approach for et estimation without explicit training rf can manage high dimensional regression problems and extract the interaction among model predictors auret and aldrich 2012 te beest et al 2017 shiri 2018 used a coupled wavelet random forest model for estimating reference et and showed the potential of a tree based model in terms of the accuracy of the reference et model the use of ensemble trees and randomization makes this approach more flexible simple robust and avoids overfitting by making the best use of limited data and reliable performance on both training and test data zhang et al 2017 chen et al 2020a 2020b in addition to ensemble trees algorithms the artificial neural network ann approaches have been used for both reference and actual et prediction abdullah et al 2015 cobaner 2011 feng et al 2017 ferreira et al 2019 jung et al 2011 kisi and alizamir 2018 most of these ann approaches such as convoluted neural network cnn for et modeling are based on a feed forward neural network approach where the algorithm is introduced for a single layer tavares et al 2015 yassin et al 2016 however for time series analysis one of the drawbacks of feed forward anns is that any information about the sequence of inputs is lost and data pre processing for singular spectrum analysis of time series in these models require complicated procedures sahoo et al 2017 in addition traditional anns also have a problem of exploding or vanishing gradient rangapuram et al 2018 hence a special type of neural network architecture recurrent neural networks rnns is designed where input is processed in its sequential order to understand temporal dynamics carriere et al 1996 for problems such as et prediction and time series forecasting for which order of the input variables is important a specific kind of rnn is long short term memory lstm that can solve the problem of vanishing gradient since our study focuses on time series prediction and forecasting rnn such as lstm along with ensemble trees algorithm such as rf is a suitable choice in lstm connections between units and cells allow data to move in a forward and backward direction within the model framework this method helps to overcome the problem of learning lagged dependencies found in traditional rnn in the case of the water cycle such an approach allows the model to preserve previous information for future uses such as water storage effects e g snow or shallow groundwater driven systems kao et al 2020 used an lstm model to forecast floods in inundation prone areas and found that lstm can be used to link the sequence of rainfall with a sequence of runoff in addition kratzert et al 2019 applied process based constraints on an lstm modeling framework to simulate runoff for a variety of watersheds and found that lstm outperformed benchmark physically based coupled models as noted above challenges in existing methods for predicting and forecasting actual et are the need for extensive parametrization lack of relevant data drivers the computational cost of process based models and lack of direct estimate of actual et from empirical models knowledge of the performance of data driven models in different types of irrigated and non irrigated crops under different soil types is still partial and fragmented in addition models in existing studies have only been applied on limited test data sets few studies have evaluated the relative contributions of the different input datasets predictors to the accuracy and uncertainty of the actual et models in agricultural fields particularly across different management irrigated vs rain fed crop types and soil textures here we ask 1 how well can empirical ml models predict and forecast et 3 days in advance in irrigated and rain fed agricultural lands across the midwest us 2 what are important drivers for predicting and forecasting et 3 days in advance in irrigated and non irrigated areas we evaluate two different ml models rf and lstm with differing numbers of predictors 5 11 16 across a range of crop and soil texture types where eddy covariance observations were available between 2003 and 2019 the results of this evaluation allow us to better understand the predictors of accuracy and uncertainty in the et models and propose a multistep prediction and forecast agricultural et model that can be applied to locations with limited in situ observations since there is no clear understanding of minimum required predictors for accurate estimates of et our models with different sets of predictors 5 11 16 can help to understand the need for important or minimum drivers for different crop fields on various soil textures in areas with scarce data 2 methods in this paper prediction and forecasting models based on rf and lstm framework are proposed for et prediction rf and lstm model with 5 11 and 16 predictors are proposed for all model experiments simulations are based on data from 2003 to 2019 2 1 data description the proposed model performance was assessed by using the observed et data obtained from the ameriflux database or site investigators table 1 for 19 sites located in the agricultural areas of the us midwest in states of iowa illinois michigan minnesota nebraska ohio and wisconsin fig 1 out of those 19 sites five are irrigated and 14 are rainfed table 1 study sites were all located in a temperate climate with cool to cold winters and hot humid summers the dominant crops in those regions are soybeans potatoes and corn with coarse grained sandy loam loamy sand loam and fine grained silt loam and silt clay soils the data duration used during this study ranged from 2003 to 2019 with a daily time step for continuous variables after removing outliers only months with less than 3 days gap were used and years with more than one month of missing data were removed data gaps for quality controlled half hourly et observations were filled with post processing software reddyproc wutzler et al 2018 reddyproc method uses co variation and temporal autocorrelation of turbulent fluxes and gaps are filled based on available information about air temperature incoming solar radiation and vapor pressure deficient based on marginal distribution sampling additional meteorological data were obtained from daymet thornton et al 2014 and north american land data assimilation system nldas land surface model lsm xia et al 2012 in addition modis aqua modis myd09ga aqua modis myd09ga satellite data vermote 2015 was also used for enhanced vegetation index evi albedo and solar zenith angle table 1 describes the study site locations duration of measurements and ancillary information summary statistics such as mean maximum and variance of et across different observation sites is included in table 2 the selection of model input predictors was due to their influence on et and their availability for agricultural sites fig 2 sixteen model predictors used on daily time stamp for model predictions include moving average precipitation for 7 days prcp7 15 days prcp15 and 30 days prcp30 as proxies for soil moisture because direct soil moisture data was not present at all sites maximum air temperature tmax long wave radiation lw incoming short wave radiation sw solar zenith angle solarzenith albedo albedo enhanced vegetation index evi soil texture soil irrigated versus non irrigated proxy irr nonirr crop cover crop cover crop coefficient crop coeff cumulative growing degree days cumgdd wind speed wind and vapor pressure vp for rf 5 and lstm 5 daily air temperature tavg was used while for rf 11 rf 16 and lstm 11 and lstm 16 maximum air temperature tmax was used since rf 5 and lstm 5 were based on drivers from priestley taylor equation tavg was used instead of tmax or tmin for simpler models these predictors were chosen because of their ability to explain physical processes cobaner 2011 fao 2015 feng et al 2017 of et as well as easy availability in most regions the data source for 16 model predictors along with different commination for predictors for various model versions is included in table 1 and table 3 cumulative growing degree days cumgdd are associated with different phases of plant development cleland et al 2007 and calculated for all growing seasons based on the method described in anandhi 2016 crop coefficients were calculated based on the food and agriculture organization of the united nations the fao 56 method first proposed by allen et al 1998 fao 56 method provides both transpiration and evaporation from soil and reference et is calculated based on penman monteith equation based on the related version of fao 56 method allen et al 1998 adjustments were made according to local crop physical condition 2 2 random forest model framework rf is an ensemble of different trees where trees are built to explain the variability of the output by grouping data in homogenous sets unique trees are built by data splitting in random sets with replacement like bootstrapping as well as by random subsets of predictors which helps to increase diversity among trees breiman 2001 h x ó t t 1 2 3 4 t where daily et independent variable is represented by t is the number of distinct regression trees and predicted value of regression tree in form of et is represented by h x θ t hence random forest builds a large forest where each tree predicts a value for et in this study regression rf of daily et is affected by different predictors and the average of all those values is the final prediction of rf h x 1 t t 1 t h x ó t out of bag oob sampling is used for rf internal validation in addition the importance of each predictor can be determined by holding some predictors constant while permuting each predictor at a time and then comparing the oob error the paraments that are tuned during rf calibration include n estimator number of trees in the forest and min samples split minimum number of samples required to split an internal node and min samples leaf minimum number of samples required to be at a leaf node the mean of yearly and monthly observed et precipitation and air temperature was computed across various sites and then sites were split between training and testing dataset such a way that each data set has dry wet and average years for representation of site conditions three rf models rf 16 rf 11 and rf 5 were built with 16 11 and 5 predictors respectively table 3 with 70 of the data were used for training and 30 of the remaining data were used for evaluation validation based on the hold out method 2 3 long short term memory network lstm lstm is a special kind of rnn without the limitation to learn time series dependencies between input and output features one limitation of traditional rnn is the inability to remember a sequence with long lengths e g 10 bengio et al 1994 however the lstm framework retains memory about the previous timestamp which can help to model lags in energy balance fluxes the information about long term memory for each time step is contained in cell state or cell memory ct of lstm and sequence of inputs model predictors as is presented in the model and output predicted or forecast et is obtained as h while six parameters show in equations below are updated at each time step in each cell feed farward anns such as cnn does not store information in memory we compared lstm with cnn and chose lstm algorithm for our prediction and forecasting based on performance all lstm models outperformed cnn models for example nse and willmott s skill score for lstm 16 was 0 65 and 0 88 respectively while nse and willmott s skill score for cnn 16 was 0 53 and 0 84 fig s1 and table s1 in supplementary materials in lstm model a sigmoid function is computed by a forget gate ft on new input xt and previous result ht 1 the sigmoid function is a smooth differentiable nonlinear function that produces non binary activation where weights can be updated with every data point the differentiable activation function is necessary because it can compute the gradient which is required for training via backpropagation in addition it can be derived from a maximum entropy model the sigmoid function helps the forget gate to decide what information needs to be remembered and what information can be discarded from memory the sigmoid function is also provided with adjustable weights w and biases b in each lstm cell the new information that is going to be remembered is placed in a cell state with the help of the input gate it which is also calculated by a sigmoid function a tanh function is used to calculate a new cell state c t the output gate regulates the information of the state of cell ct using a sigmoid function 1 f t σ w f x t u f h t 1 b f 2 c t t a n h w c x t u c h t 1 b c 3 i t σ w i x t u i h t 1 b i 4 c t f i c t 1 i i c t 5 o t σ w o x t u o h t 1 b 0 6 h t tanh c t o t where matrices of weights from the input forget and output gates to the input are denoted by wi wf and wo respectively the bias vectors for input forget and output gates are shown by bi bf bo respectively the hidden layer matrix of weights from the input forget and output gates are represented by ui uf and uo respectively logistic sigmoid σ is an element wise non linear activation function and the element wise multiplication of two vectors is denoted with in this study three lstm models lstm 16 lstm 11 lstm 5 were built with 16 11 and 5 predictors respectively here the model with 16 predictors is assumed to account for more variability than a simple model of 5 predictors because it includes predictors related to both meteorological and biophysical processes the model with 5 predictors was built to make a model based on inputs from the common physical et model of priestley taylor while the model with 11 predictors was used as an intermediate framework between the complex and simple model each model had two fully connected layers the first layer is called the encoder layer with 50 neurons and that layer is responsible for reading and interpreting the input sequence initially the model was run with 25 50 100 and 200 neurons and an optimal number of 50 neurons was selected for layer 1 based on lower ubrmse and high erwillmott s index fig s2 in supplementary materials in order to combat the problem of overfitting a regularization method of dropout was applied after the first layer where the dropout value is a percentage between 0 no dropout and 1 no connection for lstm units kratzert et al 2019 models were tested using different values for dropout and evaluation statistics were calculated to find the optimal number of neurons in addition training and testing data performance was compared to avoid an overfitting or underfitting problem fig s2 in supplementary materials a dropout value of 0 10 was applied in lstm 16 and a dropout value of 0 25 was applied for lstm 11 and lstm 5 table 4 after the dropout function a decoder layer was applied which used the output of the encoder first layer as an input a second lstm layer that comes after the encoder had 25 50 and 100 neurons for lstm 5 11 and 16 respectively table 4 the optimal number of neurons was obtained by using different combinations of neurons and dropout factors until reduced ubrmse was obtained without overfitting or undefining model lastly two dense layers were applied the model was calibrated using adam adaptive moment estimation optimizer and mean squared error loss function a moderate rate of 0 001 is used for the adam optimizer for learning during the calibration process it was observed that a high learning rate of 0 1 missed the optimal point r2 0 6 and a smaller learning rate of 10 6 led to a longer convergence time for the model zhang et al 2018 randomly selected 70 of raw data were used for calibration and 30 of the remaining data were used for evaluation using the hold out method during the training and optimization of the learning algorithm a loss function was used to estimate the error of the current state of the model the purpose of this loss function is to reduce the loss of the next evaluation by updating weights kratzert et al 2019 during training initial loss function was 0 59 0 72 and 0 70 for lstm 16 lstm 11 and lstm 5 respectively that was reduced to 0 30 0 51 and 0 60 for lstm 16 lstm 11 and lstm 5 respectively by end of training 2 4 land surface model we benchmarked our empirical models against output from process based model et from the north american land data assimilation system nldas version 2 lsm model xia et al 2012 daily et data were downloaded from land data assimilation system ldas https ldas gsfc nasa gov nldas penman monteith equation is used in nldas noah lsm energy balance for latent heat flux here et is based on evaporation and plant transpiration is driven by soil moisture stress on the top layer of the soil profile chen et al 1996 hence under wet conditions et is equal to potential evapotranspiration richards richards 1931 equation is used in this model to simulate soil moisture dynamics root zone plant transpiration is driven by canopy interception and canopy resistance that is parameterized by solar radiation air temperature vapor pressure and soil moisture koster and suarez 1996 surface albedo is simulated based on diurnal variations and simulated lai 500 m resolution varies seasonally as well as spatially and the minimum stomatal resistance parameters are based on vegetation types in addition surface runoff is calculated based on the simple water balance swb model and baseflow is represented by gravity drainage chen and dudhia 2001 2 5 significant predictors the significance of each predictor variable with respect to its effect on the rf model is displayed by predictor importance the rf model algorithm calculates predictor importance internally to account for bias in test data liaw and wiener 2002 in decision trees the node uses predictors to split values of output et and similar values of the output et end up in the same set after the split predictor importance is measured by measuring how much each predictor contributes to decreasing the variance in order words importance of predictor is based on the frequency of its inclusion in the sample by all trees and it is a measure of how much removing a predictor decreases accuracy breiman 2002 pedregosa et al 2011 a decrease in variance from each predictor is averaged in a forest and predictors are ranked according to this measure we used the sklearn algorithm in python 3 7 to calculate the importance score for each predictor after training and the score is scaled to 1 to calculate the influence of each predictor on et therefore the sum of the importance of all predictors is equal to one and the higher the value associated with a predictor the more important that predictor the importance of model predictors was calculated for both prediction and forecast model versions of rf the lstm algorithm does not have a built in variable importance selection criterion so predictors importance was measured in terms of change in nse by removing certain predictors and by comparing the change in nse with the nse obtained from the original lstm 16 model 2 6 forecast model after evaluation of et prediction we also proposed a multistep forecast model that can forecast et three days ahead of time using rf and lstm models as described above fig 2 at each daily time step there are three et forecasts 1 day 1 et tomorrow et day 2 et et day after tomorrow day 3 et et three days from today forecasts were made by integrating the uncertainty of forecast meteorology through ensemble simulation hence along with 16 model predictions that were used for the prediction model table 3 input meteorological predictors from re forecasts from the national oceanic and atmospheric administration s noaa s national centers for environmental prediction ncep 11 member global ensemble forecast system reforecast version 2 gefsrv2 were propagated into each model to make forecasts hamill et al 2013 the uncertainty in meteorological forecasts of gefs was quantified by generating ten ensembles of multiple et forecasts each perturbed from the original observations or control rf 16 and lstm 16 versions were used for forecasting et rf 16 prediction model and initial forecasting model runs provided us with identification of important variables as described above we also measured the pearson correlation between predictors and et to evaluate forecast reliability in addition for lstm 16 we did some initial model runs with different combinations of predictors and only used those predictors that helped to improve the accuracy of the model using ubrmse mae aic criteria hence based on initial model runs information from the prediction model and literature review fang et al 2018 only those meteorological predictors were selected that were the main drivers of future et i e maximum and incoming solar radiation minimum temperature and precipitation so for the day 1 et forecast forecast meteorology for the next day was included in the model for day 2 et forecast meteorology of days 1 and 2 were included for day 3 et forecast meteorology of days 1 2 and 3 were included 2 7 model evaluations there are 19 sites with 14 rain fed sites and five irrigated sites with a total of seventeen site years growing season april october of observations or 26 331 daily observations of et thirteen of the 19 sites were used for training where for one of the sites 80 of data was used in training and the remaining 20 of data from the same site was used in testing these thirteen sites were used for training while seven sites were held out and used exclusively for testing in total 70 of observed et data 18 481 daily et observations from the 13 different agricultural sites for corn soybeans and potatoes was used for calibration and data from the remaining seven agricultural sites were used for evaluation for the time period 2003 2019 7 850 daily et observations to test the accuracy of the calibrated models a subset of data was used to determine the optimal number of trees in rf and hidden neurons and layers in lstm and an optimum or satisfactory point for the calibration without overfitting the models for one set of data for statistical analysis coefficient of determination r2 pearson correlation coefficient nash sutcliffe nse willmott s skill score or index of model performance willmott 1981 mean absolute error mae unbiased root mean square error ubrmse rmse observations standard deviation ratio rsr moriasi et al 2015 percentage bias pbias were used to assess the predictive ability of the proposed rf and lstm models in addition akaike s information criteria aic metric was also used to see the effect of penalization of additional drivers to the model akaike 1970 aic adds penalty by including additional predictors in the model that leads to higher error hence a more parsimonious model will have lower aic aic 2 ln l 2 k where l is the likelihood and k is the number of parameters likelihood is calculated as the log of mean square error 3 results 3 1 rf versus lstm prediction model evaluation fig 3 illustrated the performance of the two et prediction algorithms for the test data which demonstrated the ability of the calibrated models to generalize to unseen et observations test data from eddy covariance flux towers across multiple crop types the evaluation statistics shown in fig 3 indicated that there is a good agreement between the predicted and observed et values across corn soybeans and potatoes for rf 16 model r2 and nse values for the corn vary from 0 53 to 0 70 willmott s score 0 85 0 9 in the testing period and for lstm 16 the r2 range was 0 56 0 66 and willmott s skill score 0 80 0 89 further lstm 16 had less bias for the site with a smaller number of observations potatoes in loamy sand compared to rf 16 fig 3 the more complex model required a greater number of neurons for the lstm hidden layer the number of neurons for different versions of best fit lstm models varies from 25 to 100 table 4 for the lstm 16 model using more than two layers and more than 100 neurons did not improve the model performance on testing data the run time for the lstm 16 model and rf 16 model was ten and two minutes respectively on an intel core i7 9750h cpu windows 10 x64 based processor both model outputs products closely follow the seasonal growth of crops fig 4 during the shoulder months i e september to next may et is lower and as percentage canopy cover increased in june august so did et in addition both observations and models are consistent in showing that during dry years 2006 2010 and 2012 et is higher than compared to wet years 2014 2018 across crop types for example in the drought of 2012 the et at us ro1 and us ro3 was above 6 mm day 1 while it was less than 6 mm day 1 in the wet summer of 2015 the consistency of modeled et against the ground truth differs based on the regional characteristic and amount of data available for calibration for example in sites us cs1 and us cs3 rf model predictors could well track the dynamics of the water loss caused by an increase in canopy cover however lstm 16 had lower pbias 5 7 but higher error figs 3 and 4 than rf 16 24 1 pbias in general rf 16 had a higher bias but lower error compared to lstm 16 during months when irrigation and et are higher june july we also computed the empirical cumulative distribution function ecdf for the evaluation period under different soil conditions soil moisture variable precipitation under wet dry years and crop types the ecdfs of rf 16 and lstm 16 models match closely with the observations compared to extreme events the middle section of ecdfs curves is better represented by models 3 2 significant predictors the significance of each predictor variable with respect to its effect on the rf and lstm models is displayed by predictor variables importance four predictor variables that explained most of the variance in the data include enhanced vegetation index evi solar zenith angle incoming sw radiation and cumgdd these four predictors combined explain 62 of the model variance fig 5 also showed the pearson correlation coefficient between predictors and et which is positively correlated with vp and evi since most of the midwest regions are not moisture limited and have a humid climate with warm summers we expect to see a high correlation between et and maximum daily temperature during the growing season compared to the correlation between et and precipitation i e our soil moisture proxy in the form of moving average precipitation in irrigated fields nse was reduced from 0 7 to 0 52 by removing sw and solarzenith predictors fig 3s in supplementary materials in lstm in addition a change in nse from 0 6 to 0 47 was observed by removing sw and solarzenith from rainfed or non irrigated fields the positive correlation between maximum daily temperature can be seen in the ranking of the cumgdd predictor among the four most important predictors for rf fig 5 in contrast despite the low direct correlation of soil moisture proxy seven days average precipitation it is among the five most important predictors for the rf model fig 5 crop coefficient also improved model performance by explaining the dynamics of canopies cover fraction lai greenness our analysis for rf model showed that vp and crop coefficients were the most important predictors for irrigated crops while short wave radiation and enhanced vegetation index were key predictors for non irrigated crops fig 6 3 3 model performances different versions of the rf and lstm models complex versus simple models were also evaluated on a daily timestep in comparison with the daily predictions from the mechanistic model nldas noah table 5 overall the rf 16 model resulted in an r2 of 0 7 with a pbias of 4 7 while the rf 11 model had an r2 of 0 7 with pbias of 5 3 table 5 the nldas noah model had a 0 57 r2 with the lowest pbias of 0 3 fig 7 the lowest pbias for nldas noah was most likely a result of the averaged et prediction across a larger geographical area that leads to a wider spread from the mean estimate on the scatter plot with a ubrmse of 1 1 mm day and a lower r2 of 0 57 for the nldas noah model fig 7 residuals were obtained for each model time step daily by subtracting the observed et from the predicted et a negative residual value showed that the model underestimates et while a positive residual means that et is overestimated the distribution of residuals is the largest for the testing period based on residuals the rf 11 produced the most accurate results in april and june with 0 02 and 0 01 mm residuals respectively while the rf 16 was the most accurate model in september fig 8 in july and august the nldas noah model prediction was more accurate compared to other models this could be because mechanistic models such as nldas noah has constrained et by using soil moisture at different depths if soil moisture storage is significantly variable due to large et during the mid growing seasons july august the mechanistic model may outperform empirical models in shoulder months since et is lower the coupling interactions between soil moisture and et is also lower overall models residuals were lower for the shoulder months of april may september and october and were in the range from 0 003 to 0 1 mm overestimate of et while in peak warm months of june july and august residuals range from 0 2 to 0 6 mm underestimate of et for the overall evaluation data set rf 16 outperformed other models with the lowest aic and r2 of 0 7 the performance of the rf 11 was similar rf 5 and lstm 5 were the simplest version rf and lstm respectively and produced the highest daily ubrmse of 0 94 1 20 mm as the model complexity reduced ubrmse and aic error increased for both lstm and rf and overall rf consistently outperformed lstm supplementary materials include models results from training data 13 sites with 18 481 daily et observations and testing data seven sites with 7850 daily et observations in irrigated and rain fed fields and their comparison with benchmark model figs s4 s7 in supplementary materials in addition evaluation metrics for rf 16 overall best model are calculated for daily et is each year of testing data in table s2 in supplementary materials for non irrigated crops the predictors that improved rf 16 and rf 11 performance were similar and additional predictors such as soil texture crop cover crop coefficients and cumulative gdd did not significantly improve the model performance of rf 11 and rf 16 however this was not the case for the irrigated crops here et prediction was improved by including additional information related to physical properties of sites soil types crop coefficient cumulative gdd and relative aic error reduced from 0 16 to zero fig 9 making rf 16 the best model for irrigated crops aic score and r2 were also computed for sites with different crops and soil texture for all crop types the simplest versions of models such as rf 5 and lstm 5 fig 10 table 6 increased ubrmse and aic errors soybean and corn on fine grained soils such as silty loams did not show an increase in r2 or decrease in ubrmse and aic in models by including additional 5 parameters in rf 16 and lstm 16 model however corn and soybeans on coarser soil such as loam showed improved performance with additional information about crop planting and harvest dates cumulative gdd and crop coefficients 3 4 forecast model results the evaluation was performed for the retrospective period of 2003 2019 fig 11 for both rf and lstm the overall et estimate was comparable for day 1 day 2 and day 3 et forecast it is observed that as lead time increases uncertainty and error in forecast increases but for proposed rf and lstm models there was only a slight increase in mae from 0 74 to 0 75 mm and from 0 75 to 0 80 mm table 7 the mae for june july and august was higher in concordance with higher variance on gefs meteorology ensemble forecast spread fig 11 this bias was more evident in lstm models where ensembles estimates showed a wider spread from the mean estimate compared to rf overall the rf forecast model produced results with high confidence small ensemble standard deviation compared to lstm rf was also more precise and less biased than the lstm for example for day 3 et forecasting mae 0 75 vs 0 8 and pbias 4 1 vs 5 1 table 7 however overall the difference between the results of the two forecasting models is not significant p value for two tailed t test is 0 2 based on variable importance for rf forecast models fig 11 vp and solarzenith explained about 32 and 12 variance in the model other important model predictors include crop coeff cumgdd evi and sw day3 for lstm removing day 2 and day 3 sw radiation reduced model nse from 0 56 to 0 49 fig 11 for day 3 et indicating significance of meteorological forecast predictors while the forecasts appear reliable there are differences in soil type climate conditions and irrigation rf and lstm were consistent in prediction on sandy or loamy soils but underpredicted et on silty loam fig 12 the performance of the daily et forecast model decreases during extreme conditions fig 13 showed that rf outperforms lstm for et forecast for day 3 for irrigated crops rf nse 0 70 and willmott s skill score 0 91 vs lstm nse 0 67 and willmott s skill score 0 90 p value 0 0001 and non irrigated crops rf nse 0 53 and willmot skill score of 0 81 versus lstm nse 0 50 and willmott s skill score of 0 80 for non irrigated areas p value 0 07 the difference between rf and lstm model performance was significant for irrigated sites models performance was also tested for extreme events such as as floods and drought years fig 14 showed that for 2012 a dry year with a flash drought the difference between the model for day 3 et forecast estimate is larger during days july august with high temperatures and et similarly for the year 2017 a wet year the model for day 3 et forecast overestimated lower values 1 mm of et these analyses indicate that there are an under estimation and over estimation of the forecasted maximum and minimum values respectively 4 discussion 4 1 model evaluations overall we found that empirical ml models can accurately and precisely predict et across a range of crop and soil types in the upper midwest usa with r2 and nse equal to 0 70 and ubrmse from 0 75 and 0 89 mm day 1 for rf 16 and lstm 16 respectively in general different versions of rf models had higher r2 and nse and lower pbias than the lstm except for irrigated potatoes in sandy loam we suspect that this result is because we had data for only two growing seasons for irrigated potatoes thus our results support that while rf can be more accurate lstm may be more useful when available data for model calibration is smaller in addition the prominent soil type for sites with irrigated potatoes us cs1 and us cs3 is loamy sand which stimulates rapid water movement through coarse grains after precipitation and irrigation rf 16 could capture this pattern properly during months with high et and irrigation during months when et is higher but not during months with moderate or low et while lstm 16 had a larger variance than the bias during such extreme events this indicates that when irrigation and et are higher june and july rf 16 had a higher bias but lower error compared to lstm 16 the high bias for rf 16 for that site is likely because of rf s greater sensitivity to the size of the training sample the high bias of rf 16 can also be seen in iowa corn and soybeans rotation loamy soil minnesota corn soybean rotation silty loam and michigan corn sandy loam thus while rf models outperform lstm for crop et they require more training data time series analysis of observed and predicted et values fig 4 shows that data driven models are well trained for predicting the daily data hence errors in reproducing the daily anomalies are smaller when compared to the errors in the seasonal cycle because of their relative amplitude for the evaluation period of different versions of rf and lstm residuals simulated observed are roughly normally distributed during the growing season however negative residuals in range of 0 25 to 0 75 for different versions of models during peak et months july aug showed an underestimation of et this difference may also be due to errors in the input data from different sources or complexities that the model cannot explain e g more irrigation during the dry year or not capturing fluxes through the root zone of fine grained and coarse grained soils our current models do not have irrigation data as a predictor so including it in future research can be useful our work is consistent with earlier studies on using ml to estimate water cycle elements for example kratzert et al 2019 used lstm in an ungauged basin with an aridity index from 0 22 to 5 20 to estimate stream flow using static predictors e g soil geology water content max lai and non static parameters e g precipitation temperature solar radiation and found that ml models can be useful to predict information by extracting complex relationships between diverse data under heterogeneous condition 4 1 1 model complexity the complexity of an rf tree grows with an increase in the number of trees in the forest as well as the number of training samples hence a simple rf tree with small training samples could not account for variability in the potatoes et in rf we also limit the number of variables to split on in each split that can lead to higher bias in each tree especially when the sample size is small among the ml models we found that the best overall model to be rf 16 we also observed that more than 300 decision trees for the rf model only improved the accuracy of training data but did not show significant improvement in model accuracy on testing data and instead only made the proposed approach computationally more intensive the performance of the rf 16 model is comparable to the process based nldas noah model and needs relatively fewer parameters and drivers to estimate et the inner structure of rf allows the model to explain the non linear relationships among et and important predictors such as evi solar zenith angle and incoming sw radiation rf 16 models outperformed other smaller parameter number models for most of the locations except at corn and soybeans with silt loam soil texture and potatoes in sandy soils at those locations we found that a simple version of rf rf 11 performed better at those locations as well as for non irrigated crops for these sites the complex models with 16 predictors were overfitting on training data in other words for these crop and soil combinations an overall simpler model was able to learn the appropriate non linear relationship and memory in the case of lstm between predictors and memory hence we can expect the performance of lstm and rf to decline when models are trained on drivers beyond the leading predictors of a hydrologic system tennant et al 2020 observed this decline in performance in the lstm discharge prediction model in snow dominated catchment when trained on additional predictors another reason for the divergence in model performance among sites may be related to the observation that irrigated crops have high variability in et e g based on summary statistics in table 2 irrigated crops in us ne2 have maximum daily et at a higher end e g 9 mm day 1 with sample variance more than 3 mm compared to non irrigated crops although we did not observe this high variability in irrigated potatoes in us cs1 and us cs3 and irrigated corn in mi sites us jck jackson 1 because available data were only from wet years of 2018 and 2019 in addition when water is sufficient or close to sufficient the importance of additional predictors such as storage capacity soil texture and crop phenology crop coefficients become stronger and have a critical role in predicting et however this effect is masked when irrigation is not available or soil water storage is relatively low in non irrigated crops seneviratne et al 2010 when predictors were reduced to only 5 both rf and lstm performance contained large errors limiting their utility this outcome showed the importance of wind speed solar zenith angle maximum temperature albedo and 30 days average precipitation as soil moisture proxy that were excluded in the rf 5 and lstm 5 oliveira et al 2018 also noted that surface energy fluxes that drive et depend on rainfall and soil moisture and albedo s influence on net radiation estimates thus we argue that our 11 parameter model is the baseline minimum inputs required to predict et across a range of crop soil and irrigation types this also suggests that a number of predictors lower than 11 could not explain the variance in et and it is possible for some sites to build more robust models with 11 predictors instead of 16 however it s worth noting that the improvement of performance in lstm and rf is not just from more parameters but also the more complex models include a greater number of hidden neurons in the case of lstm or decision trees subsets and nodes in the case of rf the additional elements provide an additional benefit over easily implementable regression based models that cannot account for the non linear interactions among the predictors e g temperature and et for example chen et al 2020a found that temperature and humidity based ml models rf and lstm outperformed temperature and humidity based empirical models in areas with limited meteorological data compared to other techniques for et estimation the advantage of the proposed ml modeling approach is that these models monitor et by using fewer parameters and do not rely on the accurate parameterization of mechanistic models or collections of labor intensive field scale data e g field scale leaf area index however care must be taken in appropriate model selection because the models are location dependent and require sufficient calibration and testing data for example for soybeans and corn in silt loam corn with sandy loam soil texture and potatoes with loamy and sandy texture a comparable level of et prediction performance can be achieved without using additional parameters about crop coefficients crop cover or cumgdd hence et can be predicted by the readily available biophysical predictors for such locations in contrast to et prediction for corn and soybeans with loam soil texture where model performance is improved by including those biophysical parameters the importance of cumgdd in daily et prediction is encouraging as it is readily derived from low frequency temperature observations and more readily available across more sites than soil moisture we found good performance using the same crop coefficients for irrigated and non irrigated crops depending upon the objective and availability of data for a study different models can be built for a specific crop type and soil texture at a daily time step 4 2 significant predictors the predictors importance of the rf model fig 5 highlights driving predictors and combats with the black box nature of some ml models our study showed that evi solar zenith angle incoming sw radiation and cumulative growing degree days are important predictors to predict daily et for the growing season april october in the midwest similarly studies based on empirical models priestley and taylor 1972 jensen et al 1990 and data driven ml framework chen et al 2020a evaluated that most of the variation in reference et can be explained by solar radiation this result is consistent with our study where incoming solar radiation explaind about 10 20 variance for irrigated and non irrigated crops however in our study an additional variation of about 20 was explained by other variables such as evi and crop coefficient zhao et al 2018 also found that crop coefficients not only correlate with canopy development but also controls seasonal et partitioning and surface soil moisture this shows the importance of variable crop coefficients and evi in predicting et noting that lstm 5 and rf 5 residuals were high especially during peak et months models suggests that wind speed albedo and evi are leading factors that promote enhanced et for example the potential of plants to extract water from soil depth varies during different stages of crop growth so we can surmise through the lower residuals that it was captured by 11 and 16 predictors model versions evi has been used for agricultural drought monitoring song and ma 2011 and the results of this study also suggest the potential of evi and et as good indicators of short term and long term drought our work is consistent with earlier studies to estimate et for example cobaner 2011 used fuzzy inference system based grid partition to estimate reference et in the moderate mediterranean climate of california and found that solar radiation air temperature and relative humidity as important drivers for et prediction our model was built to estimate daily actual et for agricultural lands and found that evi non irrigated crops crop coefficients and vp irrigated crops to be better predictors than solar radiation in midwest humid temperate climate feng et al 2017 used temperature based rf and generalized regression neural networks grnn to estimate reference et and found that rf outperformed grnn they also noted that without using solar radiation temperature based rf and grnn underestimated reference et our model also found that incoming sw radiation was a more important driver than tmax for actual et walls et al 2020 used rnn model based on relu and sigmoid activation function to estimate actual et and found that without net radiation model performance goes down in our study we found incoming sw radiation explained higher variance for et compared to lw radiation and thus net radiation could be omitted in terms of rf and lstm comparison for other hydrological variables such as snowfall retrievals from microwave humidity sounders adhikari et al 2020 found that rf is more robust than lstm chen et al 2020b which developed an lstm based actual et prediction model irrigated maize corn found that leaf area index relative humidity and solar radiation as important features that drive corn dynamics in a continental monsoon climate those predictors are in agreement with physical processes that can affect corn et we also found that vp and crop coefficients were more important predictors for irrigated crops compared to non irrigated while incoming sw radiation explained more variation in non irrigated compared to irrigated crops irrigation influences surface temperature convection cloud formation lohar and pal 1995 and humidity jianping et al 2002 in irrigated crops additional water vapor boucher et al 2004 in the atmosphere due to evaporation of irrigated water can explain why vapor pressure is an important driver for irrigated crops while less surface cooling in non irrigated land can make incoming sw radiation important driver for those sites since our study had shown that evi is the most important variable for rain fed crops the uncertainty of evi and associated parameters used in other models e g for deriving leaf area index lai will greatly affect et estimation mapping across the globe and improvement in estimating lai can improve hydrologic and land surface models for et mapping thus methods to reduce uncertainty in evi can improve remote sensing estimate of et sharma et al 2016 we also found that soil texture is important in improving et estimation in irrigated fields which suggests the use of soil texture maps for et estimation in et mechanistic models in addition to soil moisture as a limiting factor dong et al 2020 showed that soil moisture and et coupling strength bias is caused by oversimplification of soil texture effects on soil evaporation stress a data driven based hydrodynamic prediction model can benefit from data sets of appropriate temporal and spatial coverage readily available meteorological biophysical variables and advanced rnn such as lstm kratzert et al 2019 as well as robust simple ensemble tree based rf algorithms 4 3 forecast models evaluations we found that rf and lstm framework can be used for forecasting for three days in advance using gridded forecast meteorology based on our hindcast analysis the rf forecast model provided higher accuracy overall than lstm consistent with prediction model evaluation lstm forecast model was more sensitive to gefs meteorology ensembles where a higher spread from mean forecast et was observed compared to the rf forecast model and rf can handle multivariate dimensionality belgiu and drăguţ 2016 better than rnn ml based actual et forecasts are a novel contribution of our research here and demonstrate significant performance across multiple irrigated and non irrigated crops and soil texture short term et forecasts have value for irrigation planning considering under irrigation and over irrigation can be detrimental for crops and local water supply quantity and quality we find that vapor pressure solar zenith angle and third day forecasted incoming sw radiation are important predictors for accurate and precise et forecasts ferreira and da cunha 2020 used similar meteorological predictors maximum air solar radiation for multistep forecasting of reference et and found that deep learning models such as lstm performed better than classic machine learning models this is because lstm process input in its sequential order and overcomes the problem of learning lagged dependencies in addition connections between neurons that allow data to move in forward and backward direction within the modeling framework of lstm and helps to learn temporal dependencies perera et al 2014 used numeric prediction output for reference et forecast in australia and found that forecasting based on air and dew point temperatures leads to better performance for all lead times compared to incoming sw radiation and attributed the poor performance of incoming sw radiation to error forecast weather meteorology our study found incoming sw radiation forecast a more important predictor compared to day air temperature for actual et forecast at all lead time higher et during dry seasons showed that water was not limited due to irrigation yin et al 2020 applied bi directional lstm bi lstm to forecast short term reference et one day lead time in areas with limited meteorological data by using inputs of maximum minimum temperature sunshine duration and observed that sunshine duration has a higher correlation with reference et than solar radiation hence including the sunshine duration in the forecast model can improve model accuracy this study was also able to the ability of bi lstm to represents the temporal variability of reference et over the year for our study in terms of accuracy the forecast showed a greater skill for irrigated crops compared to non irrigated crops we also found higher accuracy for coarse grained soils sandy loam loam results suggest that developed forecasting models are promising for simulating et in the growing season but the methods need to be improved for fine textured and non irrigated conditions the performance of et forecasting can be improved by selecting appropriate meteorological parameters as the input features of the model at the same time et had strong regional characteristics such as different accuracy for different soil types future work will involve testing how such forecasts could be directly implemented for irrigation management and what changes can be made to reduce model bias 4 4 limitations and future directions ml models such as rf and lstm models show better generalization than linear models and can perform well in space and time compared to one layer anns or autoregressive models fang et al 2017 while ml models are useful for et modeling they have limits for example the models here are locally calibrated while the calibration was pooled across multiple crop and soil types it is possible that some combinations of crops and soils were not well trained and could lead to inaccurate prediction of et at those locations significant training data is a limitation to the ml models long term climatic data can help data driven models to extract the climatic cycle influence on et hence models developed on those domains with long term flux tower locations would be more reliable to predict et and less sensitive to uncertainty than those regions with shorter term and fewer et data in cases with limited training data mechanistic models do have an indisputable advantage of estimating hydrological variables for any set of inputs as long as the limitations and assumptions of the model are valid in terms of parameters one limitation of our proposed model is the lack of root zone water dynamics for example when soils have enough water stored in them during the wet year actual et under non irrigated conditions is assumed to be equal to the potential crop et however during dry conditions limited soil water storage is often observed which can reduce actual et and plant et is more a function of soil moisture we also observed that soil moisture proxy predictors in form of prcp 7 and prcp 30 were of particular importance for non irrigated crops this could be because spells of heat waves during dry years e g 2012 2010 can lead to a more rapid decline in soil moisture in non irrigated sites compared to irrigated sites ml models also tend to perform poorly on extrapolation to conditions not observed in the data or during extreme or rare events we saw these results in fig 14 for extreme events in a dry year 2012 and a wet year 2017 the tendency of all ml models to regress to the mean limits their usefulness in flash drought or flooding type conditions that may become more prevalent with ongoing anthropogenic climate change in addition gupta et al 2009 also found that this result is more expected when using mse as a calibration objective function the future application of lstm and rf models will be catalyzed with the availability of more data under more conditions there is also promising research in improving the representation of processes within ml using reinforcement learning or physical constraint type approaches zhao et al 2019a 2019b for example it is possible to add physical properties to account for subsurface dynamics by including an additional input layer of tree nodes even though the proposed model does not have a representation of water balance it is possible to link neurons and trees to atmospheric and hydrological patterns such as heat fluxes so that water is conserved and allowing for less realistic et estimates to be rejected however this might come at a cost of requiring more input predictors that must be derived from data products that may or may not be available it is also possible to physically constraint ml models o gorman and dwyer 2018 zaherpour et al 2019 zhao et al 2019b which can help to conserve energy budget while accounting for physical transport processes of water vapor leading to a better generalization of physical processes during extremes camporeale 2019 also underscores the need to do more research into probabilistic based uncertainty estimates and the development of gray box models by combining mechanistic and ml approaches it will also be useful to collect more data from other climate regimes crops and soil types that can help us understand if the conclusions found here and related papers can be generalized to other regions and other crops this can be used to study the scale and location dependence of the drivers on et and help improve et forecasting in regional scales 5 conclusion we proposed a new framework based on a machine learning data driven network to estimate and forecast et and its uncertainty for corn soybeans and potatoes under different soil texture types in agricultural areas of the midwest usa the model was built by using biophysical and meteorological information acquired from ground observations and satellite sensor data the data sets used in the proposed model have been widely utilized in many studies for et prediction and related to ancillary data used in hydrological models such as swat and hspf the proposed model was calibrated using 13 field based eddy covariance et time series distributed across the region for the period of 2003 2019 for irrigated and rainfed agricultural areas in the midwest the model was evaluated in seven independent locations for the time period of 2003 2019 the evaluation results based on observed et measurements collected from seven different sites confirmed that the predicted models can be used for daily et estimates with ubrmse from 0 67 to 0 92 mm willmott s skill score from 0 80 to 0 90 and simulate the spatial heterogeneity of agricultural parameters and dynamics of water use by crops the prediction model estimates were reliable and on par with mechanistic model estimates from nldas the results of this study also revealed that the inclusion of evi solar zenith angle incoming sw radiation and cumgdd were the most important input predictors vapor pressure was of greater importance for forecasting future et the proposed model can also be applied to both rainfed and irrigated crop types overall our work supports the use of ml especially random forest approaches for prediction and short term forecasting of et in both rainfed and irrigated crops which had a range of valuable uses for irrigation management and water cycling evaluation expanding this work outward to tropical or semi arid regions may require further evaluation of additional predictors but overall the results here find that a general field scale regional et model is realizable across a range of soil characteristics and climatic patterns et prediction and forecasting by using this modeling framework can help policy makers to allocate water sustainability for irrigation and assist growers to spot water stress areas in farms credit authorship contribution statement ammara talib conceptualization methodology writing original draft ankur r desai visualization investigation writing review editing jingyi huang visualization investigation writing review editing tim j griffis visualization investigation writing review editing david e reed visualization investigation writing review editing jiquan chen visualization investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements ard and at acknowledge support from the wisconsin vegetable and potato growers association award to uw madison the wisconsin department of natural resources and the uw center for climatic research climate people and environment program and thank j thom t houlihan j pavelski for site support at us cs1 and us cs3 dr and jc are supported by the nasa carbon cycle ecosystems program nnx17ae16g appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126579 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4417,evapotranspiration et prediction and forecasting play a vital role in improving water use in agriculturally intensive areas metrological and biophysical predictors that drive et in managed landscapes have complex nonlinear relationships deep learning and data driven methods have shown promising performance for identifying the dependencies among variables here we evaluated the potentials of random forest rf and long short term memory lstm neural networks to estimate and forecast daily et for corn soybeans and potatoes in diverse agricultural farms during 2003 2019 the modeling framework was applied for nineteen fields where eddy covariance et and meteorological observations in the midwest usa for growing season april october is available in this study we applied data driven models rf and lstm with 3 sets of predictors 5 11 and 16 predictors results show that a 16 predictor rf model rf 16 r2 0 7 willmott s skill score 0 90 outperformed a process based land surface model lsm r2 0 57 willmott s skill score 0 86 for predicting daily et while lstm performance was lower lstm 16 r2 0 65 willmott s skill score 0 89 and lstm 11 r2 0 62 willmott s skill score 0 86 than rf using the same sets of predictors vapor pressure and crop coefficients were identified as the most important predictors for irrigated crops while short wave radiation and enhanced vegetation index were key predictors for non irrigated crops for certain crop types such as corn and soybeans on fine grained soils silt loam a simpler version rf using only 11 drivers can provide comparable results r2 0 70 vs 0 69 and willmott s skill score 0 90 vs 0 88 for short term 3 day et forecasting lstm is more sensitive to uncertainty in ensemble forecast meteorology than rf et forecasts were strongly sensitive to forecast uncertainty of vapor pressure the proposed modeling architecture provides a field scale locally calibrated tool for accurate prediction and short term forecasting of daily et in areas where in situ et metrological and biophysical data are lacking keywords evapotranspiration machine learning agriculture drought irrigation forecasting 1 introduction terrestrial water in the biosphere and atmosphere is linked through evapotranspiration et donohue et al 2010 priestley and taylor 1972 wei et al 2017 et is the second largest term in the global land surface water budget barr et al 2014 narasimhan and srinivasan 2005 trenberth et al 2007 wang and dickinson 2012 in order to understand terrestrial ecosystem processes in a changing climate such as flash droughts kim et al 2019 otkin et al 2016 water resource management e g irrigation efficiency it is important to accurately estimate and forecast et allen et al 1998 anderson et al 2011 shugart 1998 hydrological applications geared towards conservation of water resources especially for irrigation require prediction and forecasting of et as a fundamental component hence for sustainable agriculture an et prediction and forecasting tool can be useful for farmers and water managers to handle water resource challenges djaman et al 2020 moratiel et al 2020 payero and irmak 2013 perera et al 2014 actual et can be measured directly using eddy covariance ec towers baldocchi et al 2001 barr et al 2012 wilson et al 2001 but costs logistics and measurement scale inhibit regional and long term studies such as ec and bowen ratio methods rosenberry et al 2007 further et needs to be assessed across a range of crop varieties and soil climate types that influence it requiring many observation sites hence there is a need for models that are based on more readily available drivers to predict and forecast et for broader applications data from satellite sensors have been used in earlier studies to estimate et over domains of different regional scales such as watershed or continent anderson et al 2021 crosbie et al 2015 filgueiras et al 2020 fisher et al 2020 scott et al 2008 yao et al 2013 though satellites are hampered by tradeoff in spatial resolution and revisit frequency cloud cover and model assumptions used in linking observations of surface reflectance or brightness temperatures to et in addition data assimilation methods meng et al 2009 xu et al 2018 zou et al 2017 as well as land surface models lian et al 2018 vinukollu et al 2012 have been used however the relative error range for et estimates compared with ground measurements is from 14 to 44 long et al 2014 velpuri et al 2013 due to factors such as spatial variation heterogeneity model parametrization and unconstrained water balance in addition while there are many studies to estimate or predict and forecast reference et in different climatic conditions e g fang et al 2018 li et al 2016 yang et al 2006 there are not many studies for forecasting actual et in intensively irrigated and non irrigated areas field scale crop models are another avenue for predicting et current crop models that are designed to simulate agricultural practices such as soil composition nutrients tilling practices and irrigation scheduling can be coupled with computational hydrologic and land atmosphere models pauwels et al 2007 the development of these physically based and spatially explicit representation of land surface interaction and agricultural processes at the farm scale have high computational costs chaney et al 2016 clark et al 2017 which requires significant parameterization and tuning subject to collection of a myriad of trait and driver datasets even though those models accurately simulate hydrological processes challenges in calibrating these biophysically based models make accurate physical process simulations at individual fields challenging in addition the available data for calibration and validation of these models e g three dimensional information about sub surface heterogeneity such as soil texture moisture and groundwater flow limit the application of those models for larger areas with intensive agriculture however these models are useful for small scale regional studies in addition to process based hydrological models empirical models based on statistical correlations of potential evapotranspiration with meteorological parameters have also been used valipour et al 2017 often variables like canopy cover is used in these methods to convert potential evapotranspiration to actual evapotranspiration the problem with such an approach is that performance may significantly depend on the estimate of canopy cover an alternate approach to existing empirical and physical based methods is to use data driven methods to estimate actual evapotranspiration a variety of data driven models have been used in et simulation studies deo and şahin 2015 fang et al 2018 izadifar and elshorbagy 2010 pandey et al 2017 it is efficient to combine information from readily available predictors from remote sensing along with ground observation by applying machine learning ml methods that may be able to predict and forecast et based on relationships between input predictors without utilizing field based physical parameters ml algorithms extract non linear relationships hidden in time series or spatial data and then apply those patterns to estimate and forecast future scenarios for example yang et al 2006 and tabari et al 2012 used a support vector machine svm approach to estimate eight day averaged et and reference et respectively using ground observation and remote sensing predictors landeras et al 2009 used autoregressive models to forecast weekly reference et and bodesheim et al 2018 applied a regression trees based random forest rf approach for et estimation without explicit training rf can manage high dimensional regression problems and extract the interaction among model predictors auret and aldrich 2012 te beest et al 2017 shiri 2018 used a coupled wavelet random forest model for estimating reference et and showed the potential of a tree based model in terms of the accuracy of the reference et model the use of ensemble trees and randomization makes this approach more flexible simple robust and avoids overfitting by making the best use of limited data and reliable performance on both training and test data zhang et al 2017 chen et al 2020a 2020b in addition to ensemble trees algorithms the artificial neural network ann approaches have been used for both reference and actual et prediction abdullah et al 2015 cobaner 2011 feng et al 2017 ferreira et al 2019 jung et al 2011 kisi and alizamir 2018 most of these ann approaches such as convoluted neural network cnn for et modeling are based on a feed forward neural network approach where the algorithm is introduced for a single layer tavares et al 2015 yassin et al 2016 however for time series analysis one of the drawbacks of feed forward anns is that any information about the sequence of inputs is lost and data pre processing for singular spectrum analysis of time series in these models require complicated procedures sahoo et al 2017 in addition traditional anns also have a problem of exploding or vanishing gradient rangapuram et al 2018 hence a special type of neural network architecture recurrent neural networks rnns is designed where input is processed in its sequential order to understand temporal dynamics carriere et al 1996 for problems such as et prediction and time series forecasting for which order of the input variables is important a specific kind of rnn is long short term memory lstm that can solve the problem of vanishing gradient since our study focuses on time series prediction and forecasting rnn such as lstm along with ensemble trees algorithm such as rf is a suitable choice in lstm connections between units and cells allow data to move in a forward and backward direction within the model framework this method helps to overcome the problem of learning lagged dependencies found in traditional rnn in the case of the water cycle such an approach allows the model to preserve previous information for future uses such as water storage effects e g snow or shallow groundwater driven systems kao et al 2020 used an lstm model to forecast floods in inundation prone areas and found that lstm can be used to link the sequence of rainfall with a sequence of runoff in addition kratzert et al 2019 applied process based constraints on an lstm modeling framework to simulate runoff for a variety of watersheds and found that lstm outperformed benchmark physically based coupled models as noted above challenges in existing methods for predicting and forecasting actual et are the need for extensive parametrization lack of relevant data drivers the computational cost of process based models and lack of direct estimate of actual et from empirical models knowledge of the performance of data driven models in different types of irrigated and non irrigated crops under different soil types is still partial and fragmented in addition models in existing studies have only been applied on limited test data sets few studies have evaluated the relative contributions of the different input datasets predictors to the accuracy and uncertainty of the actual et models in agricultural fields particularly across different management irrigated vs rain fed crop types and soil textures here we ask 1 how well can empirical ml models predict and forecast et 3 days in advance in irrigated and rain fed agricultural lands across the midwest us 2 what are important drivers for predicting and forecasting et 3 days in advance in irrigated and non irrigated areas we evaluate two different ml models rf and lstm with differing numbers of predictors 5 11 16 across a range of crop and soil texture types where eddy covariance observations were available between 2003 and 2019 the results of this evaluation allow us to better understand the predictors of accuracy and uncertainty in the et models and propose a multistep prediction and forecast agricultural et model that can be applied to locations with limited in situ observations since there is no clear understanding of minimum required predictors for accurate estimates of et our models with different sets of predictors 5 11 16 can help to understand the need for important or minimum drivers for different crop fields on various soil textures in areas with scarce data 2 methods in this paper prediction and forecasting models based on rf and lstm framework are proposed for et prediction rf and lstm model with 5 11 and 16 predictors are proposed for all model experiments simulations are based on data from 2003 to 2019 2 1 data description the proposed model performance was assessed by using the observed et data obtained from the ameriflux database or site investigators table 1 for 19 sites located in the agricultural areas of the us midwest in states of iowa illinois michigan minnesota nebraska ohio and wisconsin fig 1 out of those 19 sites five are irrigated and 14 are rainfed table 1 study sites were all located in a temperate climate with cool to cold winters and hot humid summers the dominant crops in those regions are soybeans potatoes and corn with coarse grained sandy loam loamy sand loam and fine grained silt loam and silt clay soils the data duration used during this study ranged from 2003 to 2019 with a daily time step for continuous variables after removing outliers only months with less than 3 days gap were used and years with more than one month of missing data were removed data gaps for quality controlled half hourly et observations were filled with post processing software reddyproc wutzler et al 2018 reddyproc method uses co variation and temporal autocorrelation of turbulent fluxes and gaps are filled based on available information about air temperature incoming solar radiation and vapor pressure deficient based on marginal distribution sampling additional meteorological data were obtained from daymet thornton et al 2014 and north american land data assimilation system nldas land surface model lsm xia et al 2012 in addition modis aqua modis myd09ga aqua modis myd09ga satellite data vermote 2015 was also used for enhanced vegetation index evi albedo and solar zenith angle table 1 describes the study site locations duration of measurements and ancillary information summary statistics such as mean maximum and variance of et across different observation sites is included in table 2 the selection of model input predictors was due to their influence on et and their availability for agricultural sites fig 2 sixteen model predictors used on daily time stamp for model predictions include moving average precipitation for 7 days prcp7 15 days prcp15 and 30 days prcp30 as proxies for soil moisture because direct soil moisture data was not present at all sites maximum air temperature tmax long wave radiation lw incoming short wave radiation sw solar zenith angle solarzenith albedo albedo enhanced vegetation index evi soil texture soil irrigated versus non irrigated proxy irr nonirr crop cover crop cover crop coefficient crop coeff cumulative growing degree days cumgdd wind speed wind and vapor pressure vp for rf 5 and lstm 5 daily air temperature tavg was used while for rf 11 rf 16 and lstm 11 and lstm 16 maximum air temperature tmax was used since rf 5 and lstm 5 were based on drivers from priestley taylor equation tavg was used instead of tmax or tmin for simpler models these predictors were chosen because of their ability to explain physical processes cobaner 2011 fao 2015 feng et al 2017 of et as well as easy availability in most regions the data source for 16 model predictors along with different commination for predictors for various model versions is included in table 1 and table 3 cumulative growing degree days cumgdd are associated with different phases of plant development cleland et al 2007 and calculated for all growing seasons based on the method described in anandhi 2016 crop coefficients were calculated based on the food and agriculture organization of the united nations the fao 56 method first proposed by allen et al 1998 fao 56 method provides both transpiration and evaporation from soil and reference et is calculated based on penman monteith equation based on the related version of fao 56 method allen et al 1998 adjustments were made according to local crop physical condition 2 2 random forest model framework rf is an ensemble of different trees where trees are built to explain the variability of the output by grouping data in homogenous sets unique trees are built by data splitting in random sets with replacement like bootstrapping as well as by random subsets of predictors which helps to increase diversity among trees breiman 2001 h x ó t t 1 2 3 4 t where daily et independent variable is represented by t is the number of distinct regression trees and predicted value of regression tree in form of et is represented by h x θ t hence random forest builds a large forest where each tree predicts a value for et in this study regression rf of daily et is affected by different predictors and the average of all those values is the final prediction of rf h x 1 t t 1 t h x ó t out of bag oob sampling is used for rf internal validation in addition the importance of each predictor can be determined by holding some predictors constant while permuting each predictor at a time and then comparing the oob error the paraments that are tuned during rf calibration include n estimator number of trees in the forest and min samples split minimum number of samples required to split an internal node and min samples leaf minimum number of samples required to be at a leaf node the mean of yearly and monthly observed et precipitation and air temperature was computed across various sites and then sites were split between training and testing dataset such a way that each data set has dry wet and average years for representation of site conditions three rf models rf 16 rf 11 and rf 5 were built with 16 11 and 5 predictors respectively table 3 with 70 of the data were used for training and 30 of the remaining data were used for evaluation validation based on the hold out method 2 3 long short term memory network lstm lstm is a special kind of rnn without the limitation to learn time series dependencies between input and output features one limitation of traditional rnn is the inability to remember a sequence with long lengths e g 10 bengio et al 1994 however the lstm framework retains memory about the previous timestamp which can help to model lags in energy balance fluxes the information about long term memory for each time step is contained in cell state or cell memory ct of lstm and sequence of inputs model predictors as is presented in the model and output predicted or forecast et is obtained as h while six parameters show in equations below are updated at each time step in each cell feed farward anns such as cnn does not store information in memory we compared lstm with cnn and chose lstm algorithm for our prediction and forecasting based on performance all lstm models outperformed cnn models for example nse and willmott s skill score for lstm 16 was 0 65 and 0 88 respectively while nse and willmott s skill score for cnn 16 was 0 53 and 0 84 fig s1 and table s1 in supplementary materials in lstm model a sigmoid function is computed by a forget gate ft on new input xt and previous result ht 1 the sigmoid function is a smooth differentiable nonlinear function that produces non binary activation where weights can be updated with every data point the differentiable activation function is necessary because it can compute the gradient which is required for training via backpropagation in addition it can be derived from a maximum entropy model the sigmoid function helps the forget gate to decide what information needs to be remembered and what information can be discarded from memory the sigmoid function is also provided with adjustable weights w and biases b in each lstm cell the new information that is going to be remembered is placed in a cell state with the help of the input gate it which is also calculated by a sigmoid function a tanh function is used to calculate a new cell state c t the output gate regulates the information of the state of cell ct using a sigmoid function 1 f t σ w f x t u f h t 1 b f 2 c t t a n h w c x t u c h t 1 b c 3 i t σ w i x t u i h t 1 b i 4 c t f i c t 1 i i c t 5 o t σ w o x t u o h t 1 b 0 6 h t tanh c t o t where matrices of weights from the input forget and output gates to the input are denoted by wi wf and wo respectively the bias vectors for input forget and output gates are shown by bi bf bo respectively the hidden layer matrix of weights from the input forget and output gates are represented by ui uf and uo respectively logistic sigmoid σ is an element wise non linear activation function and the element wise multiplication of two vectors is denoted with in this study three lstm models lstm 16 lstm 11 lstm 5 were built with 16 11 and 5 predictors respectively here the model with 16 predictors is assumed to account for more variability than a simple model of 5 predictors because it includes predictors related to both meteorological and biophysical processes the model with 5 predictors was built to make a model based on inputs from the common physical et model of priestley taylor while the model with 11 predictors was used as an intermediate framework between the complex and simple model each model had two fully connected layers the first layer is called the encoder layer with 50 neurons and that layer is responsible for reading and interpreting the input sequence initially the model was run with 25 50 100 and 200 neurons and an optimal number of 50 neurons was selected for layer 1 based on lower ubrmse and high erwillmott s index fig s2 in supplementary materials in order to combat the problem of overfitting a regularization method of dropout was applied after the first layer where the dropout value is a percentage between 0 no dropout and 1 no connection for lstm units kratzert et al 2019 models were tested using different values for dropout and evaluation statistics were calculated to find the optimal number of neurons in addition training and testing data performance was compared to avoid an overfitting or underfitting problem fig s2 in supplementary materials a dropout value of 0 10 was applied in lstm 16 and a dropout value of 0 25 was applied for lstm 11 and lstm 5 table 4 after the dropout function a decoder layer was applied which used the output of the encoder first layer as an input a second lstm layer that comes after the encoder had 25 50 and 100 neurons for lstm 5 11 and 16 respectively table 4 the optimal number of neurons was obtained by using different combinations of neurons and dropout factors until reduced ubrmse was obtained without overfitting or undefining model lastly two dense layers were applied the model was calibrated using adam adaptive moment estimation optimizer and mean squared error loss function a moderate rate of 0 001 is used for the adam optimizer for learning during the calibration process it was observed that a high learning rate of 0 1 missed the optimal point r2 0 6 and a smaller learning rate of 10 6 led to a longer convergence time for the model zhang et al 2018 randomly selected 70 of raw data were used for calibration and 30 of the remaining data were used for evaluation using the hold out method during the training and optimization of the learning algorithm a loss function was used to estimate the error of the current state of the model the purpose of this loss function is to reduce the loss of the next evaluation by updating weights kratzert et al 2019 during training initial loss function was 0 59 0 72 and 0 70 for lstm 16 lstm 11 and lstm 5 respectively that was reduced to 0 30 0 51 and 0 60 for lstm 16 lstm 11 and lstm 5 respectively by end of training 2 4 land surface model we benchmarked our empirical models against output from process based model et from the north american land data assimilation system nldas version 2 lsm model xia et al 2012 daily et data were downloaded from land data assimilation system ldas https ldas gsfc nasa gov nldas penman monteith equation is used in nldas noah lsm energy balance for latent heat flux here et is based on evaporation and plant transpiration is driven by soil moisture stress on the top layer of the soil profile chen et al 1996 hence under wet conditions et is equal to potential evapotranspiration richards richards 1931 equation is used in this model to simulate soil moisture dynamics root zone plant transpiration is driven by canopy interception and canopy resistance that is parameterized by solar radiation air temperature vapor pressure and soil moisture koster and suarez 1996 surface albedo is simulated based on diurnal variations and simulated lai 500 m resolution varies seasonally as well as spatially and the minimum stomatal resistance parameters are based on vegetation types in addition surface runoff is calculated based on the simple water balance swb model and baseflow is represented by gravity drainage chen and dudhia 2001 2 5 significant predictors the significance of each predictor variable with respect to its effect on the rf model is displayed by predictor importance the rf model algorithm calculates predictor importance internally to account for bias in test data liaw and wiener 2002 in decision trees the node uses predictors to split values of output et and similar values of the output et end up in the same set after the split predictor importance is measured by measuring how much each predictor contributes to decreasing the variance in order words importance of predictor is based on the frequency of its inclusion in the sample by all trees and it is a measure of how much removing a predictor decreases accuracy breiman 2002 pedregosa et al 2011 a decrease in variance from each predictor is averaged in a forest and predictors are ranked according to this measure we used the sklearn algorithm in python 3 7 to calculate the importance score for each predictor after training and the score is scaled to 1 to calculate the influence of each predictor on et therefore the sum of the importance of all predictors is equal to one and the higher the value associated with a predictor the more important that predictor the importance of model predictors was calculated for both prediction and forecast model versions of rf the lstm algorithm does not have a built in variable importance selection criterion so predictors importance was measured in terms of change in nse by removing certain predictors and by comparing the change in nse with the nse obtained from the original lstm 16 model 2 6 forecast model after evaluation of et prediction we also proposed a multistep forecast model that can forecast et three days ahead of time using rf and lstm models as described above fig 2 at each daily time step there are three et forecasts 1 day 1 et tomorrow et day 2 et et day after tomorrow day 3 et et three days from today forecasts were made by integrating the uncertainty of forecast meteorology through ensemble simulation hence along with 16 model predictions that were used for the prediction model table 3 input meteorological predictors from re forecasts from the national oceanic and atmospheric administration s noaa s national centers for environmental prediction ncep 11 member global ensemble forecast system reforecast version 2 gefsrv2 were propagated into each model to make forecasts hamill et al 2013 the uncertainty in meteorological forecasts of gefs was quantified by generating ten ensembles of multiple et forecasts each perturbed from the original observations or control rf 16 and lstm 16 versions were used for forecasting et rf 16 prediction model and initial forecasting model runs provided us with identification of important variables as described above we also measured the pearson correlation between predictors and et to evaluate forecast reliability in addition for lstm 16 we did some initial model runs with different combinations of predictors and only used those predictors that helped to improve the accuracy of the model using ubrmse mae aic criteria hence based on initial model runs information from the prediction model and literature review fang et al 2018 only those meteorological predictors were selected that were the main drivers of future et i e maximum and incoming solar radiation minimum temperature and precipitation so for the day 1 et forecast forecast meteorology for the next day was included in the model for day 2 et forecast meteorology of days 1 and 2 were included for day 3 et forecast meteorology of days 1 2 and 3 were included 2 7 model evaluations there are 19 sites with 14 rain fed sites and five irrigated sites with a total of seventeen site years growing season april october of observations or 26 331 daily observations of et thirteen of the 19 sites were used for training where for one of the sites 80 of data was used in training and the remaining 20 of data from the same site was used in testing these thirteen sites were used for training while seven sites were held out and used exclusively for testing in total 70 of observed et data 18 481 daily et observations from the 13 different agricultural sites for corn soybeans and potatoes was used for calibration and data from the remaining seven agricultural sites were used for evaluation for the time period 2003 2019 7 850 daily et observations to test the accuracy of the calibrated models a subset of data was used to determine the optimal number of trees in rf and hidden neurons and layers in lstm and an optimum or satisfactory point for the calibration without overfitting the models for one set of data for statistical analysis coefficient of determination r2 pearson correlation coefficient nash sutcliffe nse willmott s skill score or index of model performance willmott 1981 mean absolute error mae unbiased root mean square error ubrmse rmse observations standard deviation ratio rsr moriasi et al 2015 percentage bias pbias were used to assess the predictive ability of the proposed rf and lstm models in addition akaike s information criteria aic metric was also used to see the effect of penalization of additional drivers to the model akaike 1970 aic adds penalty by including additional predictors in the model that leads to higher error hence a more parsimonious model will have lower aic aic 2 ln l 2 k where l is the likelihood and k is the number of parameters likelihood is calculated as the log of mean square error 3 results 3 1 rf versus lstm prediction model evaluation fig 3 illustrated the performance of the two et prediction algorithms for the test data which demonstrated the ability of the calibrated models to generalize to unseen et observations test data from eddy covariance flux towers across multiple crop types the evaluation statistics shown in fig 3 indicated that there is a good agreement between the predicted and observed et values across corn soybeans and potatoes for rf 16 model r2 and nse values for the corn vary from 0 53 to 0 70 willmott s score 0 85 0 9 in the testing period and for lstm 16 the r2 range was 0 56 0 66 and willmott s skill score 0 80 0 89 further lstm 16 had less bias for the site with a smaller number of observations potatoes in loamy sand compared to rf 16 fig 3 the more complex model required a greater number of neurons for the lstm hidden layer the number of neurons for different versions of best fit lstm models varies from 25 to 100 table 4 for the lstm 16 model using more than two layers and more than 100 neurons did not improve the model performance on testing data the run time for the lstm 16 model and rf 16 model was ten and two minutes respectively on an intel core i7 9750h cpu windows 10 x64 based processor both model outputs products closely follow the seasonal growth of crops fig 4 during the shoulder months i e september to next may et is lower and as percentage canopy cover increased in june august so did et in addition both observations and models are consistent in showing that during dry years 2006 2010 and 2012 et is higher than compared to wet years 2014 2018 across crop types for example in the drought of 2012 the et at us ro1 and us ro3 was above 6 mm day 1 while it was less than 6 mm day 1 in the wet summer of 2015 the consistency of modeled et against the ground truth differs based on the regional characteristic and amount of data available for calibration for example in sites us cs1 and us cs3 rf model predictors could well track the dynamics of the water loss caused by an increase in canopy cover however lstm 16 had lower pbias 5 7 but higher error figs 3 and 4 than rf 16 24 1 pbias in general rf 16 had a higher bias but lower error compared to lstm 16 during months when irrigation and et are higher june july we also computed the empirical cumulative distribution function ecdf for the evaluation period under different soil conditions soil moisture variable precipitation under wet dry years and crop types the ecdfs of rf 16 and lstm 16 models match closely with the observations compared to extreme events the middle section of ecdfs curves is better represented by models 3 2 significant predictors the significance of each predictor variable with respect to its effect on the rf and lstm models is displayed by predictor variables importance four predictor variables that explained most of the variance in the data include enhanced vegetation index evi solar zenith angle incoming sw radiation and cumgdd these four predictors combined explain 62 of the model variance fig 5 also showed the pearson correlation coefficient between predictors and et which is positively correlated with vp and evi since most of the midwest regions are not moisture limited and have a humid climate with warm summers we expect to see a high correlation between et and maximum daily temperature during the growing season compared to the correlation between et and precipitation i e our soil moisture proxy in the form of moving average precipitation in irrigated fields nse was reduced from 0 7 to 0 52 by removing sw and solarzenith predictors fig 3s in supplementary materials in lstm in addition a change in nse from 0 6 to 0 47 was observed by removing sw and solarzenith from rainfed or non irrigated fields the positive correlation between maximum daily temperature can be seen in the ranking of the cumgdd predictor among the four most important predictors for rf fig 5 in contrast despite the low direct correlation of soil moisture proxy seven days average precipitation it is among the five most important predictors for the rf model fig 5 crop coefficient also improved model performance by explaining the dynamics of canopies cover fraction lai greenness our analysis for rf model showed that vp and crop coefficients were the most important predictors for irrigated crops while short wave radiation and enhanced vegetation index were key predictors for non irrigated crops fig 6 3 3 model performances different versions of the rf and lstm models complex versus simple models were also evaluated on a daily timestep in comparison with the daily predictions from the mechanistic model nldas noah table 5 overall the rf 16 model resulted in an r2 of 0 7 with a pbias of 4 7 while the rf 11 model had an r2 of 0 7 with pbias of 5 3 table 5 the nldas noah model had a 0 57 r2 with the lowest pbias of 0 3 fig 7 the lowest pbias for nldas noah was most likely a result of the averaged et prediction across a larger geographical area that leads to a wider spread from the mean estimate on the scatter plot with a ubrmse of 1 1 mm day and a lower r2 of 0 57 for the nldas noah model fig 7 residuals were obtained for each model time step daily by subtracting the observed et from the predicted et a negative residual value showed that the model underestimates et while a positive residual means that et is overestimated the distribution of residuals is the largest for the testing period based on residuals the rf 11 produced the most accurate results in april and june with 0 02 and 0 01 mm residuals respectively while the rf 16 was the most accurate model in september fig 8 in july and august the nldas noah model prediction was more accurate compared to other models this could be because mechanistic models such as nldas noah has constrained et by using soil moisture at different depths if soil moisture storage is significantly variable due to large et during the mid growing seasons july august the mechanistic model may outperform empirical models in shoulder months since et is lower the coupling interactions between soil moisture and et is also lower overall models residuals were lower for the shoulder months of april may september and october and were in the range from 0 003 to 0 1 mm overestimate of et while in peak warm months of june july and august residuals range from 0 2 to 0 6 mm underestimate of et for the overall evaluation data set rf 16 outperformed other models with the lowest aic and r2 of 0 7 the performance of the rf 11 was similar rf 5 and lstm 5 were the simplest version rf and lstm respectively and produced the highest daily ubrmse of 0 94 1 20 mm as the model complexity reduced ubrmse and aic error increased for both lstm and rf and overall rf consistently outperformed lstm supplementary materials include models results from training data 13 sites with 18 481 daily et observations and testing data seven sites with 7850 daily et observations in irrigated and rain fed fields and their comparison with benchmark model figs s4 s7 in supplementary materials in addition evaluation metrics for rf 16 overall best model are calculated for daily et is each year of testing data in table s2 in supplementary materials for non irrigated crops the predictors that improved rf 16 and rf 11 performance were similar and additional predictors such as soil texture crop cover crop coefficients and cumulative gdd did not significantly improve the model performance of rf 11 and rf 16 however this was not the case for the irrigated crops here et prediction was improved by including additional information related to physical properties of sites soil types crop coefficient cumulative gdd and relative aic error reduced from 0 16 to zero fig 9 making rf 16 the best model for irrigated crops aic score and r2 were also computed for sites with different crops and soil texture for all crop types the simplest versions of models such as rf 5 and lstm 5 fig 10 table 6 increased ubrmse and aic errors soybean and corn on fine grained soils such as silty loams did not show an increase in r2 or decrease in ubrmse and aic in models by including additional 5 parameters in rf 16 and lstm 16 model however corn and soybeans on coarser soil such as loam showed improved performance with additional information about crop planting and harvest dates cumulative gdd and crop coefficients 3 4 forecast model results the evaluation was performed for the retrospective period of 2003 2019 fig 11 for both rf and lstm the overall et estimate was comparable for day 1 day 2 and day 3 et forecast it is observed that as lead time increases uncertainty and error in forecast increases but for proposed rf and lstm models there was only a slight increase in mae from 0 74 to 0 75 mm and from 0 75 to 0 80 mm table 7 the mae for june july and august was higher in concordance with higher variance on gefs meteorology ensemble forecast spread fig 11 this bias was more evident in lstm models where ensembles estimates showed a wider spread from the mean estimate compared to rf overall the rf forecast model produced results with high confidence small ensemble standard deviation compared to lstm rf was also more precise and less biased than the lstm for example for day 3 et forecasting mae 0 75 vs 0 8 and pbias 4 1 vs 5 1 table 7 however overall the difference between the results of the two forecasting models is not significant p value for two tailed t test is 0 2 based on variable importance for rf forecast models fig 11 vp and solarzenith explained about 32 and 12 variance in the model other important model predictors include crop coeff cumgdd evi and sw day3 for lstm removing day 2 and day 3 sw radiation reduced model nse from 0 56 to 0 49 fig 11 for day 3 et indicating significance of meteorological forecast predictors while the forecasts appear reliable there are differences in soil type climate conditions and irrigation rf and lstm were consistent in prediction on sandy or loamy soils but underpredicted et on silty loam fig 12 the performance of the daily et forecast model decreases during extreme conditions fig 13 showed that rf outperforms lstm for et forecast for day 3 for irrigated crops rf nse 0 70 and willmott s skill score 0 91 vs lstm nse 0 67 and willmott s skill score 0 90 p value 0 0001 and non irrigated crops rf nse 0 53 and willmot skill score of 0 81 versus lstm nse 0 50 and willmott s skill score of 0 80 for non irrigated areas p value 0 07 the difference between rf and lstm model performance was significant for irrigated sites models performance was also tested for extreme events such as as floods and drought years fig 14 showed that for 2012 a dry year with a flash drought the difference between the model for day 3 et forecast estimate is larger during days july august with high temperatures and et similarly for the year 2017 a wet year the model for day 3 et forecast overestimated lower values 1 mm of et these analyses indicate that there are an under estimation and over estimation of the forecasted maximum and minimum values respectively 4 discussion 4 1 model evaluations overall we found that empirical ml models can accurately and precisely predict et across a range of crop and soil types in the upper midwest usa with r2 and nse equal to 0 70 and ubrmse from 0 75 and 0 89 mm day 1 for rf 16 and lstm 16 respectively in general different versions of rf models had higher r2 and nse and lower pbias than the lstm except for irrigated potatoes in sandy loam we suspect that this result is because we had data for only two growing seasons for irrigated potatoes thus our results support that while rf can be more accurate lstm may be more useful when available data for model calibration is smaller in addition the prominent soil type for sites with irrigated potatoes us cs1 and us cs3 is loamy sand which stimulates rapid water movement through coarse grains after precipitation and irrigation rf 16 could capture this pattern properly during months with high et and irrigation during months when et is higher but not during months with moderate or low et while lstm 16 had a larger variance than the bias during such extreme events this indicates that when irrigation and et are higher june and july rf 16 had a higher bias but lower error compared to lstm 16 the high bias for rf 16 for that site is likely because of rf s greater sensitivity to the size of the training sample the high bias of rf 16 can also be seen in iowa corn and soybeans rotation loamy soil minnesota corn soybean rotation silty loam and michigan corn sandy loam thus while rf models outperform lstm for crop et they require more training data time series analysis of observed and predicted et values fig 4 shows that data driven models are well trained for predicting the daily data hence errors in reproducing the daily anomalies are smaller when compared to the errors in the seasonal cycle because of their relative amplitude for the evaluation period of different versions of rf and lstm residuals simulated observed are roughly normally distributed during the growing season however negative residuals in range of 0 25 to 0 75 for different versions of models during peak et months july aug showed an underestimation of et this difference may also be due to errors in the input data from different sources or complexities that the model cannot explain e g more irrigation during the dry year or not capturing fluxes through the root zone of fine grained and coarse grained soils our current models do not have irrigation data as a predictor so including it in future research can be useful our work is consistent with earlier studies on using ml to estimate water cycle elements for example kratzert et al 2019 used lstm in an ungauged basin with an aridity index from 0 22 to 5 20 to estimate stream flow using static predictors e g soil geology water content max lai and non static parameters e g precipitation temperature solar radiation and found that ml models can be useful to predict information by extracting complex relationships between diverse data under heterogeneous condition 4 1 1 model complexity the complexity of an rf tree grows with an increase in the number of trees in the forest as well as the number of training samples hence a simple rf tree with small training samples could not account for variability in the potatoes et in rf we also limit the number of variables to split on in each split that can lead to higher bias in each tree especially when the sample size is small among the ml models we found that the best overall model to be rf 16 we also observed that more than 300 decision trees for the rf model only improved the accuracy of training data but did not show significant improvement in model accuracy on testing data and instead only made the proposed approach computationally more intensive the performance of the rf 16 model is comparable to the process based nldas noah model and needs relatively fewer parameters and drivers to estimate et the inner structure of rf allows the model to explain the non linear relationships among et and important predictors such as evi solar zenith angle and incoming sw radiation rf 16 models outperformed other smaller parameter number models for most of the locations except at corn and soybeans with silt loam soil texture and potatoes in sandy soils at those locations we found that a simple version of rf rf 11 performed better at those locations as well as for non irrigated crops for these sites the complex models with 16 predictors were overfitting on training data in other words for these crop and soil combinations an overall simpler model was able to learn the appropriate non linear relationship and memory in the case of lstm between predictors and memory hence we can expect the performance of lstm and rf to decline when models are trained on drivers beyond the leading predictors of a hydrologic system tennant et al 2020 observed this decline in performance in the lstm discharge prediction model in snow dominated catchment when trained on additional predictors another reason for the divergence in model performance among sites may be related to the observation that irrigated crops have high variability in et e g based on summary statistics in table 2 irrigated crops in us ne2 have maximum daily et at a higher end e g 9 mm day 1 with sample variance more than 3 mm compared to non irrigated crops although we did not observe this high variability in irrigated potatoes in us cs1 and us cs3 and irrigated corn in mi sites us jck jackson 1 because available data were only from wet years of 2018 and 2019 in addition when water is sufficient or close to sufficient the importance of additional predictors such as storage capacity soil texture and crop phenology crop coefficients become stronger and have a critical role in predicting et however this effect is masked when irrigation is not available or soil water storage is relatively low in non irrigated crops seneviratne et al 2010 when predictors were reduced to only 5 both rf and lstm performance contained large errors limiting their utility this outcome showed the importance of wind speed solar zenith angle maximum temperature albedo and 30 days average precipitation as soil moisture proxy that were excluded in the rf 5 and lstm 5 oliveira et al 2018 also noted that surface energy fluxes that drive et depend on rainfall and soil moisture and albedo s influence on net radiation estimates thus we argue that our 11 parameter model is the baseline minimum inputs required to predict et across a range of crop soil and irrigation types this also suggests that a number of predictors lower than 11 could not explain the variance in et and it is possible for some sites to build more robust models with 11 predictors instead of 16 however it s worth noting that the improvement of performance in lstm and rf is not just from more parameters but also the more complex models include a greater number of hidden neurons in the case of lstm or decision trees subsets and nodes in the case of rf the additional elements provide an additional benefit over easily implementable regression based models that cannot account for the non linear interactions among the predictors e g temperature and et for example chen et al 2020a found that temperature and humidity based ml models rf and lstm outperformed temperature and humidity based empirical models in areas with limited meteorological data compared to other techniques for et estimation the advantage of the proposed ml modeling approach is that these models monitor et by using fewer parameters and do not rely on the accurate parameterization of mechanistic models or collections of labor intensive field scale data e g field scale leaf area index however care must be taken in appropriate model selection because the models are location dependent and require sufficient calibration and testing data for example for soybeans and corn in silt loam corn with sandy loam soil texture and potatoes with loamy and sandy texture a comparable level of et prediction performance can be achieved without using additional parameters about crop coefficients crop cover or cumgdd hence et can be predicted by the readily available biophysical predictors for such locations in contrast to et prediction for corn and soybeans with loam soil texture where model performance is improved by including those biophysical parameters the importance of cumgdd in daily et prediction is encouraging as it is readily derived from low frequency temperature observations and more readily available across more sites than soil moisture we found good performance using the same crop coefficients for irrigated and non irrigated crops depending upon the objective and availability of data for a study different models can be built for a specific crop type and soil texture at a daily time step 4 2 significant predictors the predictors importance of the rf model fig 5 highlights driving predictors and combats with the black box nature of some ml models our study showed that evi solar zenith angle incoming sw radiation and cumulative growing degree days are important predictors to predict daily et for the growing season april october in the midwest similarly studies based on empirical models priestley and taylor 1972 jensen et al 1990 and data driven ml framework chen et al 2020a evaluated that most of the variation in reference et can be explained by solar radiation this result is consistent with our study where incoming solar radiation explaind about 10 20 variance for irrigated and non irrigated crops however in our study an additional variation of about 20 was explained by other variables such as evi and crop coefficient zhao et al 2018 also found that crop coefficients not only correlate with canopy development but also controls seasonal et partitioning and surface soil moisture this shows the importance of variable crop coefficients and evi in predicting et noting that lstm 5 and rf 5 residuals were high especially during peak et months models suggests that wind speed albedo and evi are leading factors that promote enhanced et for example the potential of plants to extract water from soil depth varies during different stages of crop growth so we can surmise through the lower residuals that it was captured by 11 and 16 predictors model versions evi has been used for agricultural drought monitoring song and ma 2011 and the results of this study also suggest the potential of evi and et as good indicators of short term and long term drought our work is consistent with earlier studies to estimate et for example cobaner 2011 used fuzzy inference system based grid partition to estimate reference et in the moderate mediterranean climate of california and found that solar radiation air temperature and relative humidity as important drivers for et prediction our model was built to estimate daily actual et for agricultural lands and found that evi non irrigated crops crop coefficients and vp irrigated crops to be better predictors than solar radiation in midwest humid temperate climate feng et al 2017 used temperature based rf and generalized regression neural networks grnn to estimate reference et and found that rf outperformed grnn they also noted that without using solar radiation temperature based rf and grnn underestimated reference et our model also found that incoming sw radiation was a more important driver than tmax for actual et walls et al 2020 used rnn model based on relu and sigmoid activation function to estimate actual et and found that without net radiation model performance goes down in our study we found incoming sw radiation explained higher variance for et compared to lw radiation and thus net radiation could be omitted in terms of rf and lstm comparison for other hydrological variables such as snowfall retrievals from microwave humidity sounders adhikari et al 2020 found that rf is more robust than lstm chen et al 2020b which developed an lstm based actual et prediction model irrigated maize corn found that leaf area index relative humidity and solar radiation as important features that drive corn dynamics in a continental monsoon climate those predictors are in agreement with physical processes that can affect corn et we also found that vp and crop coefficients were more important predictors for irrigated crops compared to non irrigated while incoming sw radiation explained more variation in non irrigated compared to irrigated crops irrigation influences surface temperature convection cloud formation lohar and pal 1995 and humidity jianping et al 2002 in irrigated crops additional water vapor boucher et al 2004 in the atmosphere due to evaporation of irrigated water can explain why vapor pressure is an important driver for irrigated crops while less surface cooling in non irrigated land can make incoming sw radiation important driver for those sites since our study had shown that evi is the most important variable for rain fed crops the uncertainty of evi and associated parameters used in other models e g for deriving leaf area index lai will greatly affect et estimation mapping across the globe and improvement in estimating lai can improve hydrologic and land surface models for et mapping thus methods to reduce uncertainty in evi can improve remote sensing estimate of et sharma et al 2016 we also found that soil texture is important in improving et estimation in irrigated fields which suggests the use of soil texture maps for et estimation in et mechanistic models in addition to soil moisture as a limiting factor dong et al 2020 showed that soil moisture and et coupling strength bias is caused by oversimplification of soil texture effects on soil evaporation stress a data driven based hydrodynamic prediction model can benefit from data sets of appropriate temporal and spatial coverage readily available meteorological biophysical variables and advanced rnn such as lstm kratzert et al 2019 as well as robust simple ensemble tree based rf algorithms 4 3 forecast models evaluations we found that rf and lstm framework can be used for forecasting for three days in advance using gridded forecast meteorology based on our hindcast analysis the rf forecast model provided higher accuracy overall than lstm consistent with prediction model evaluation lstm forecast model was more sensitive to gefs meteorology ensembles where a higher spread from mean forecast et was observed compared to the rf forecast model and rf can handle multivariate dimensionality belgiu and drăguţ 2016 better than rnn ml based actual et forecasts are a novel contribution of our research here and demonstrate significant performance across multiple irrigated and non irrigated crops and soil texture short term et forecasts have value for irrigation planning considering under irrigation and over irrigation can be detrimental for crops and local water supply quantity and quality we find that vapor pressure solar zenith angle and third day forecasted incoming sw radiation are important predictors for accurate and precise et forecasts ferreira and da cunha 2020 used similar meteorological predictors maximum air solar radiation for multistep forecasting of reference et and found that deep learning models such as lstm performed better than classic machine learning models this is because lstm process input in its sequential order and overcomes the problem of learning lagged dependencies in addition connections between neurons that allow data to move in forward and backward direction within the modeling framework of lstm and helps to learn temporal dependencies perera et al 2014 used numeric prediction output for reference et forecast in australia and found that forecasting based on air and dew point temperatures leads to better performance for all lead times compared to incoming sw radiation and attributed the poor performance of incoming sw radiation to error forecast weather meteorology our study found incoming sw radiation forecast a more important predictor compared to day air temperature for actual et forecast at all lead time higher et during dry seasons showed that water was not limited due to irrigation yin et al 2020 applied bi directional lstm bi lstm to forecast short term reference et one day lead time in areas with limited meteorological data by using inputs of maximum minimum temperature sunshine duration and observed that sunshine duration has a higher correlation with reference et than solar radiation hence including the sunshine duration in the forecast model can improve model accuracy this study was also able to the ability of bi lstm to represents the temporal variability of reference et over the year for our study in terms of accuracy the forecast showed a greater skill for irrigated crops compared to non irrigated crops we also found higher accuracy for coarse grained soils sandy loam loam results suggest that developed forecasting models are promising for simulating et in the growing season but the methods need to be improved for fine textured and non irrigated conditions the performance of et forecasting can be improved by selecting appropriate meteorological parameters as the input features of the model at the same time et had strong regional characteristics such as different accuracy for different soil types future work will involve testing how such forecasts could be directly implemented for irrigation management and what changes can be made to reduce model bias 4 4 limitations and future directions ml models such as rf and lstm models show better generalization than linear models and can perform well in space and time compared to one layer anns or autoregressive models fang et al 2017 while ml models are useful for et modeling they have limits for example the models here are locally calibrated while the calibration was pooled across multiple crop and soil types it is possible that some combinations of crops and soils were not well trained and could lead to inaccurate prediction of et at those locations significant training data is a limitation to the ml models long term climatic data can help data driven models to extract the climatic cycle influence on et hence models developed on those domains with long term flux tower locations would be more reliable to predict et and less sensitive to uncertainty than those regions with shorter term and fewer et data in cases with limited training data mechanistic models do have an indisputable advantage of estimating hydrological variables for any set of inputs as long as the limitations and assumptions of the model are valid in terms of parameters one limitation of our proposed model is the lack of root zone water dynamics for example when soils have enough water stored in them during the wet year actual et under non irrigated conditions is assumed to be equal to the potential crop et however during dry conditions limited soil water storage is often observed which can reduce actual et and plant et is more a function of soil moisture we also observed that soil moisture proxy predictors in form of prcp 7 and prcp 30 were of particular importance for non irrigated crops this could be because spells of heat waves during dry years e g 2012 2010 can lead to a more rapid decline in soil moisture in non irrigated sites compared to irrigated sites ml models also tend to perform poorly on extrapolation to conditions not observed in the data or during extreme or rare events we saw these results in fig 14 for extreme events in a dry year 2012 and a wet year 2017 the tendency of all ml models to regress to the mean limits their usefulness in flash drought or flooding type conditions that may become more prevalent with ongoing anthropogenic climate change in addition gupta et al 2009 also found that this result is more expected when using mse as a calibration objective function the future application of lstm and rf models will be catalyzed with the availability of more data under more conditions there is also promising research in improving the representation of processes within ml using reinforcement learning or physical constraint type approaches zhao et al 2019a 2019b for example it is possible to add physical properties to account for subsurface dynamics by including an additional input layer of tree nodes even though the proposed model does not have a representation of water balance it is possible to link neurons and trees to atmospheric and hydrological patterns such as heat fluxes so that water is conserved and allowing for less realistic et estimates to be rejected however this might come at a cost of requiring more input predictors that must be derived from data products that may or may not be available it is also possible to physically constraint ml models o gorman and dwyer 2018 zaherpour et al 2019 zhao et al 2019b which can help to conserve energy budget while accounting for physical transport processes of water vapor leading to a better generalization of physical processes during extremes camporeale 2019 also underscores the need to do more research into probabilistic based uncertainty estimates and the development of gray box models by combining mechanistic and ml approaches it will also be useful to collect more data from other climate regimes crops and soil types that can help us understand if the conclusions found here and related papers can be generalized to other regions and other crops this can be used to study the scale and location dependence of the drivers on et and help improve et forecasting in regional scales 5 conclusion we proposed a new framework based on a machine learning data driven network to estimate and forecast et and its uncertainty for corn soybeans and potatoes under different soil texture types in agricultural areas of the midwest usa the model was built by using biophysical and meteorological information acquired from ground observations and satellite sensor data the data sets used in the proposed model have been widely utilized in many studies for et prediction and related to ancillary data used in hydrological models such as swat and hspf the proposed model was calibrated using 13 field based eddy covariance et time series distributed across the region for the period of 2003 2019 for irrigated and rainfed agricultural areas in the midwest the model was evaluated in seven independent locations for the time period of 2003 2019 the evaluation results based on observed et measurements collected from seven different sites confirmed that the predicted models can be used for daily et estimates with ubrmse from 0 67 to 0 92 mm willmott s skill score from 0 80 to 0 90 and simulate the spatial heterogeneity of agricultural parameters and dynamics of water use by crops the prediction model estimates were reliable and on par with mechanistic model estimates from nldas the results of this study also revealed that the inclusion of evi solar zenith angle incoming sw radiation and cumgdd were the most important input predictors vapor pressure was of greater importance for forecasting future et the proposed model can also be applied to both rainfed and irrigated crop types overall our work supports the use of ml especially random forest approaches for prediction and short term forecasting of et in both rainfed and irrigated crops which had a range of valuable uses for irrigation management and water cycling evaluation expanding this work outward to tropical or semi arid regions may require further evaluation of additional predictors but overall the results here find that a general field scale regional et model is realizable across a range of soil characteristics and climatic patterns et prediction and forecasting by using this modeling framework can help policy makers to allocate water sustainability for irrigation and assist growers to spot water stress areas in farms credit authorship contribution statement ammara talib conceptualization methodology writing original draft ankur r desai visualization investigation writing review editing jingyi huang visualization investigation writing review editing tim j griffis visualization investigation writing review editing david e reed visualization investigation writing review editing jiquan chen visualization investigation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements ard and at acknowledge support from the wisconsin vegetable and potato growers association award to uw madison the wisconsin department of natural resources and the uw center for climatic research climate people and environment program and thank j thom t houlihan j pavelski for site support at us cs1 and us cs3 dr and jc are supported by the nasa carbon cycle ecosystems program nnx17ae16g appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126579 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4418,the spatial variability of groundwater levels is often inferred from sparsely located hydraulic head observations in wells the spatial correlation structure derived from sparse observations is associated with uncertainties that spread to estimates at unsampled locations in areas where surface water represents the nearby groundwater level remote sensing techniques can estimate and increase the number of hydraulic head measurements this research uses light detection and ranging lidar to estimate lake surface water level to characterize the groundwater level in the nebraska sand hills nsh an area with few observation wells the lidar derived lake groundwater level accuracy was within 40 cm mean square error mse of the nearest observation wells the lake groundwater level estimates were used to predict the groundwater level at unsampled locations using universal kriging uk and kriging with an external drift ked the results indicate unbiased estimates of groundwater level in the nsh uk showed the influence of regional trends in groundwater level while ked revealed the local variation present in the groundwater level a 10 fold cross validation demonstrated ked with better mean squared error me 0 003 0 007 root mean square error rmse 2 39 4 46 residual prediction deviation rpd 1 32 0 71 and mean squared deviation ratio msdr 1 01 1 49 than uk the research highlights that the lake groundwater level provides an accurate and cost effective approach to measure and monitor the subtle changes in groundwater level in the nsh this methodology can be applied to other locations where surface water bodies represent the water level of the unconfined aquifer and the results can aid in groundwater management and modeling keywords groundwater level lake groundwater level light detection and ranging lidar universal kriging uk kriging with an external drift ked remote sensing lake surface area 1 introduction an accurate representation of groundwater level in aquifers is important to many problems in hydrologic and numerical model analysis and designs a large number of observation wells help to characterize and analyze the change and vulnerability of aquifers to natural or anthropogenic factors such as climate change and global warming desbarats et al 2002 döll et al 2012 meixner et al 2016 scanlon et al 2006 taylor et al 2013 groundwater level in aquifers however due to large installation and maintenance costs are often sparsely measured and monitored singh et al 2010 strassberg et al 2009 gaps at unsampled locations are often filled using geostatistics with the available measurements thus leading to uncertainty in the water level prediction the associated uncertainty can be reduced using an alternate approach such as satellite altimetry to measure and monitor the groundwater level satellite altimetry provides remote estimates of water level at the interface of groundwater and surface interaction and provides an increased number of hydraulic heads that can sufficiently characterize the spatial correlation structure and predict the groundwater level with adequate accuracy satellite altimetry measures the range distance from the satellite to surface by computing the travel time of the reflected and received pulse from the satellite antenna with the use of reference ellipsoid the relative height of the surface is thus determined nielsen et al 2017 many studies have used satellite altimetry to estimate water surface elevation asadzadeh jarihani et al 2013 satellite laser altimeters such as ice cloud and land elevation satellite 2 icesat 2 provides sufficient accuracy 10 cm to characterize large water bodies but fails to provide good accuracy of smaller and shallow water due to a larger footprint size and use of green 532 nm laser frequency that penetrates shallow water li et al 2017 ryan et al 2020 yuan et al 2020 zhang et al 2019 similarly synthetic aperture radar sar altimeters such as cryosat 2 with footprints of 300 m provide measurements within 15 cm accuracy for larger lakes or water bodies nielsen et al 2017 roohi et al 2021 airborne altimeters such as light detection and ranging lidar estimates lake surface elevation for small as well as large water bodies with accuracy ranging from 3 50 cm höfle et al 2009 hofton et al 2000 hopkinson et al 2011 paul et al 2020 zhang et al 2020 while airborne lidar provides high accuracy for smaller lakes the widely available topographic lidar data suffers from low backscatter and laser dropouts as the near infrared wavelengths are highly absorbed by water fernandez diaz et al 2014 milan et al 2010 the uncertainty associated with low backscatter however can be reduced using approaches such as the waterline method the waterline method uses the boundary between the water surface and landmass derived from the remotely sensed image and superimposes them on the elevations relative to mean sea level bell et al 2016 kang et al 2017 qi et al 2019 yue and liu 2019 the water surface boundary from satellite images is generally delineated using methods such as single band thresholding classification multi band subpixel and hybrid approaches bijeesh and narasimhamurthy 2020 du et al 2012 the accuracy is increased when the original bands are combined with transformed spectral bands such as image color space principal component analysis tasseled cap transformation tct and water indices balázs et al 2018 jiang et al 2012 ma et al 2019 verpoorter et al 2012 zhuang and chen 2018 satellite altimetry therefore provides remote estimates of groundwater levels in areas where surface and groundwater interact zhang et al 2017 the increased measurements thereby reduce the uncertainty and better characterizes the spatial variation in the groundwater level using geostatistical methods geostatistics are often used to fill the gaps in areas where field observations are sparse geostatistics estimate and define the spatial correlation structure from sampled locations and make predictions at unsampled locations stochastic methods such as ordinary kriging universal kriging uk kriging with an external drift ked and co kriging are extensively used to map the spatial and temporal variation of groundwater levels adhikary and dash 2017 boezio et al 2006 varouchakis and hristopulos 2013 ordinary kriging provides an optimal estimate of the groundwater level given the data follow a multivariate normal distribution with a theoretical variogram ahmadi and sedghamiz 2007 goovaerts 1997 theodoridou et al 2017 varouchakis et al 2016 varouchakis and hristopulos 2013 groundwater levels with effects of regional trends are modeled using the uk as the linear drift improves the accuracy of the interpolated heads adhikary and dash 2017 ahmed 2007 kambhammettu et al 2011 although uk provides better estimates of groundwater level when the observations are sparse and linearly associated with external variables ked improves the estimation of hydraulic heads boezio et al 2006 desbarats et al 2002 deutsch and journel 1992 rivest et al 2008 as groundwater is the subdued replica of topography condon and maxwell 2015 haitjema and mitchell bruker 2005 and is widely available digital elevation models are often used to define the external drift desbarats et al 2002 goovaerts 2000 for example desbarats et al 2002 used ked with topography as drift and found that the use of topography provides robust estimates of the water table elevation while methods such as co kriging incorporates more than one secondary variable in the covariance structure to explain the groundwater level variation the difference is not always significant ahmadi and sedghamiz 2008 and requires inference of direct and cross covariance functions co kriging is also cumbersome and time consuming when many secondary variables are used desbarats et al 2002 methods other than geostatistics such as multiple linear regression and neural networks are also used to predict the groundwater level these methods although provide higher accuracy require a large number of ancillary data to capture the water level variation in an aquifer regardless of the interpolation method the accuracy depends on the distribution number and quality of data from observation wells the spatial correlation structure derived from a few observations is unable to characterize the spatial variability present in the aquifer thus leading to higher uncertainties and coarser representation of aquifer water level buchanan and triantafilis 2009 li and heap 2008 this research combines airborne altimetry with geostatistics and provides a novel approach to estimate the groundwater level in areas of surface water groundwater interchange the objective of this research was to map the spatial variability of the groundwater levels estimated from lidar derived lake water level in the nebraska sand hills nsh the specific objectives of this research were to i estimate the feasibility of lidar derived groundwater level from lake water level ii evaluate uk and ked to characterize the groundwater levels and iii validate compare the interpolated groundwater levels to numerical model predicted hydraulic heads and published water table contours 2 methods 2 1 study area the nsh has an area of 50 000 km2 and is the largest grass stabilized dune field in the western hemisphere with 450 km2 of shallow lakes and 4500 km2 of subirrigated meadows fig 1 ahlbrandt and fryberger 1980 smith 1965 gosselin et al 2000 sweeney and loope 2001 the areas of the lakes range from 0 004 to 12 km2 with most lake depths averaging less than one meter gosselin et al 2000 table 1 shows the proportion of lake sizes used in the study the majority 76 of the lakes are smaller than 0 2 km2 the lakes are denser in the western and northern parts of the nsh and sparse in the south fig 1 the semiarid climate of nsh has temperatures ranging from 40 to 43 3 c with an average annual temperature of 8 9 c the annual average precipitation ranges from 450 mm in the west to 690 mm in the eastern part of nsh national climatic data center 2020 lake hydrology is dependent on precipitation and groundwater as inputs and evaporation and seepage losses as outputs winter 1986 high total dissolved solid concentrations and water levels lower than the regional potentiometric surface indicate that lakes are focused groundwater discharge areas gosselin et al 2000 ong 2010 winter 1986 zlotnik et al 2009 the evaporation from lakes exceeds the precipitation for example the alkali lake in the nsh from july to september of 2007 2009 averaged 5 1 mm day 1 of evaporation compared to 1 3 mm day 1 of precipitation riveros iregui et al 2017 nsh lies on the northern part of the high plains aquifer system the ogallala group is the dominant and major water bearing geologic unit in the nsh and is formed of moderate to low permeable sand sandstone and siltstones deposited during the mid tertiary age fig 1 the aquifer dips gently eastward at 0 9 1 3 m per kilometer gutentag et al 1984 and is part of the high plains aquifer system where saturated in nsh dunes of the quaternary age overlie the unconsolidated alluvial sand gravel silt and clay that overlie the ogallala group the dunes composed of very fine to medium sand form an important part of aquifer by promoting aquifer recharge gutentag et al 1984 peterson et al 2020 the arikaree formation and the white river group which lie beneath the ogallala group are also part of the high plains aquifer though are finer grained and only contain usable quantities of water locally at fractured or coarse grained area in the western nsh the arikaree group is underlain by the brule formation this unit is composed of very fine to fine grained sandstone with a maximum thickness of about 300 m mcguire 2017 due to the fine grained nature of the arikaree and brule formations they may or may not be hydraulically connected to overlying geologic units the cretaceous pierre shale forms the impermeable base of the high plains aquifer in the nsh although the nsh has the greatest volume of saturated sediment in the high plains aquifer and least net groundwater declines haacker et al 2016 mcguire 2017 peterson et al 2016 scanlon et al 2012 the area is vulnerable to climate change irrigation and redcedar juniperus virginiana encroachment adane et al 2019 burbach and joeckel 2006 loope and swinehart 2000 suttie et al 2005 zou et al 2018 for example irrigation wells increased from only a few hundred in 1940 to 7775 within a 10 km buffer of nsh in 2019 nebraska department of natural resources 2019 research suggests that the change in supply and demand of precipitation and evapotranspiration can decrease recharge by 25 50 and lead to desertification adane et al 2019 peterson et al 2020 with 23 continuous observation wells and 61 seasonal and annual wells the spatial variability present in the groundwater level is difficult to characterize as such the annual nebraska statewide groundwater level monitoring report only provides partial groundwater level change information for the nsh region young et al 2019 similarly the most widely used water table elevation maps of spring 1995 hand drawn and 2012 natural neighbor interpolation from the nsh region are based on limited observations rossman et al 2018 and uses method that do not account for the associated uncertainty this study therefore provides an alternative approach to assess the spatial variability of groundwater level in the nsh using remote measurement of the water level in thousands of shallow endorheic lakes 2 2 dataset the study uses sentinel 2 satellite images to delineate the boundary between the lake and land surface area sentinel 2 a constellation of sentinel 2a and sentinel 2b satellites operated by the european union copernicus program has a spatial resolution of 10 20 and 60 m with 13 spectral bands in the visible near infrared and shortwave infrared region the revisit frequency of each single satellite is 10 days and the combined constellation revisit is 5 days the level 2a images used in the study are bottom of atmosphere reflectance values corrected for radiometric geometric and atmospheric effects the lidar point cloud data was collected by united states geological survey usgs in 2016 and 2017 hatched lines in fig 1 in the nsh the lidar data has an aggregate nominal pulse spacing of 0 71 m and an aggregate nominal pulse density of 2 points per m2 the level 2 ql2 data used in the study has an absolute vertical accuracy of 10 cm root mean square elevation rmsez with navd88 and nad83 as a vertical and horizontal datum respectively we downloaded point cloud through the usgs ftp server and used fusion tools mcgaughey 2009 to clip filter and merge within the buffered boundary of lakes the time of lidar data sentinel 2 satellite images and observation wells were matched such that the water levels are measured at a similar timeframe the areas with missing point cloud fig 1 data were filled from 1 m resolution digital elevation model derived from lidar data the study also uses data from observation wells fig 1 the observation well data were hosted in the database maintained by the conservation and survey division school of natural resources university of nebraska lincoln and the nebraska department of natural resources these data have been checked for quality and consistency young et al 2019 the 23 observation wells have hourly measurements of the depth to water from the land surface the depth to water from the land surface was then subtracted from the surveyed elevation of the land surface to obtain the elevation of the water table or potentiometric surface fig 2 shows the overall method used to derive the lake groundwater variation in the nsh 2 3 lake area delineation the visible and near infrared bands of sentinel 2 images hosted in google earth engine gorelick et al 2017 were filtered for cloud cover less than 10 and were mosaicked using median values for may to june 2017 in correspondence with lidar data acquisition time the mosaicked images were transformed using tasseled cap coefficients derived from sentinel images shi and xu 2019 the brightness greenness and wetness components were stacked with original bands and classified into water and non water pixels using a random forest classifier in google earth engine the tasseled cap transformation reduces the influence of shadows and enhances water area detection and delineation zhuang and chen 2018 whereas the original bands provide the classifier with spectral variability present in water areas random forest classifier an ensemble of decision trees provides higher accuracy and is widely used in processing remotely sensed imagery including water and wetland classification shrestha et al 2021 tian et al 2016 wang et al 2018 2020 the classifier was trained using samples collected through visual image interpretation of national agriculture imagery program naip with 75 training 287 and 30 testing 109 set the classified image was converted into a shapefile and exported for further analysis lakes with an area less than 0 008 km2 were filtered and removed to reduce the effect of smaller misclassified pixels due to the ephemeral water areas that form near lakes and wetlands the smaller lakes were also removed to avoid the effect of clustering and overfitting the variogram goovaerts 1997 similarly lakes with a higher perimeter to area ratio were filtered to reduce the triangular and irregular shaped polygons the lakes were then buffered by 1 m to reduce the effect of missing lidar point cloud from water due to low backscatter 2 4 lake surface water level estimation and validation lake surface water level was estimated by combining the lake boundary and lidar point cloud using the waterline method the waterline method mainly used to evaluate the water level changes in coastal areas and lakes bell et al 2016 kang et al 2017 qi et al 2019 yue and liu 2019 zhang et al 2020 superimposes the boundary between the water surface and landmass on the elevations relative to mean sea level the overall process involves the following i delineate lake boundaries from sentinel 2 images and create a 1 m buffer ii superimpose the buffered lake boundary with the lidar point cloud to clip and filter the last returned lidar points and iii calculate the minimum maximum and mean value that represents the lake water level or lake groundwater level given the gentle dune topography the boundary between the lake and land surface is assumed to transition smoothly therefore a difference greater or equal to 5 m between the minimum and maximum lidar point cloud within the buffer was filtered as outliers the outliers were considered errors associated with an inaccurate representation of the boundary derived from sentinel 2 images a total of 2300 lakes were retained and converted to points for geostatistical analysis fig 3 shows the lakes thinned for visualization clusters at the western and northern part of the nsh while fewer or no lakes are present in the southern part the points that represent reservoirs or man made impoundments were manually removed the lake groundwater level derived from lidar data were validated against the water level from the observation wells the lakes and observation wells were selected fig 3 based on the following criteria i water level measurements from the observation wells were matched up with the time the lidar point cloud was collected ii since the lake water level represents the unconfined aquifer any wells that penetrated the confined aquifer based on the well drilling profile were filtered and iii lakes nearest and along the regional groundwater flow direction were retained the selected lakes were corrected for ambient hydraulic gradient and then compared with water levels in the observation wells in general the lidar data were acquired between may and june of 2017 and therefore represents the spring season or pre stress groundwater level of the 23 observation wells only eight were used and compared to the nearest lake level elevation the other 15 observation wells were not used for the following reasons four wells penetrated the confined aquifer and thus the water didn t interact directly with the lakes three wells were farther than 20 km from any lake four wells were missing lidar data and four wells data were missing at the time of lidar data collection 2 5 geostatistical estimation and prediction geostatistic based methods were used to estimate and predict the lake groundwater level in the nsh geostatistics uses the sampled attribute z at location si to estimate the z at unsampled location s0 the observation is decomposed into the mean and the stochastic component random variable as in eq 1 the mean or the trend component μ s is estimated either using the polynomial functions uk or auxiliary information such as elevation ked desbarats et al 2002 goovaerts 1997 the spatial dependence between the observations is estimated from residuals stochastic component using semivariogram and predicted for the unsampled locations additional detail on uk and ked equations are provided in desbarats et al 2002 deutsch and journel 1992 and goovaerts 1997 1 z s μ s z s we used uk and ked to estimate and predict the lake groundwater level variation in the nsh the lake groundwater level was checked for normality using histogram plots skewness and kurtosis coefficients the test showed that the raw data are skewed towards the left fig 4 a with a skewness coefficient of 0 89 and a kurtosis of 2 55 a skewness value closer to zero and kurtosis closer to 3 indicates a normal distribution 2 6 universal kriging uk is used when the data shows the presence of regionalized variables a semivariogram analysis of raw data not shown here shows the presence of a regional trend therefore first and second order polynomials were used to estimate the trend from the lake groundwater level a first and second order polynomial fit explained 96 and 98 of the variance present in the lake groundwater level respectively similarly the histogram plot fig 4b c and skewness coefficient of 0 02 and 0 51 and kurtosis coefficient of 1 93 and 2 77 for the residuals of first and second order polynomials respectively indicate a distribution closer to normal therefore we used a second order polynomial fit to remove the trend and estimate the residuals for further analysis the initial values of nugget range and sill were determined from the visual analysis of a semivariogram plot theoretical semivariogram models such as spherical gaussian exponential and bessel cressie and wikle 2015 deutsch and journel 1992 gringarten and deutsch 2001 were fitted to the empirical lake groundwater level data fig 5 a the model with the lowest residual sum of squares rss were used for modelling the spatial correlation structure anisotropy present were checked using directional variograms at four main directions 0 45 90 and 135 with an angle of tolerance of 22 5 goovaerts 1997 fig 5b shows the presence of anisotropy that were corrected using the angle and scaling factor the prediction was performed in 90 m resolution grid 2 7 kriging with an external drift the drift present in the lake groundwater level was estimated using the bare earth digital elevation model of 90 m resolution regression analysis between lake groundwater level and topography was used to determine the association of dependent and independent variables the results show that the lake water level was highly linear with the elevation r2 0 95 as with the uk the theoretical models with the least rss were used to determine the spatial correlation structure fig 6 a the semivariogram of residuals after trend removal does not show the presence of trend and anisotropy fig 6b the optimal resolution for ked prediction was determined by predicting and evaluating the surface at 90 200 500 700 and 1000 m grids the higher resolution grids 90 m were overwhelmed with the local topographic variation and resulted in noisy lake groundwater level a coarser resolution topography 500 m averaged the local groundwater level variation therefore a 200 m grid was selected as optimal resolution for ked we used the gstat package pebesma and graeler 2013 to implement the uk and ked approach to map the groundwater level variation in the nsh 2 8 validation the k fold cross validation measure was used to determine the accuracy of the predicted surface the method divides the data into multiple sets one subset is used to test while the other is used to predict based on the results of the cross validation the following evaluation statistics were used to compare the accuracy of the interpolation mean square error mse is sensitive to outliers as it measures the magnitude of the error root mean square error rmse provides a standard deviation of the residuals the mean squared deviation ratio msdr is the mean of the ratio of the squared prediction errors to the variance a msdr close to one indicates a good model modified index of agreement md is the ratio between the mean square error and the potential error md is like root mean square error with a value between 0 and 1 residual prediction deviation rpd is the standard deviation of the observation divided by the root mean square error of prediction a higher rpd value shows good prediction residual sum of squares rss is used to evaluate the degree of fitting between the empirical and theoretical variogram models 2 mse 1 n i 1 n z s i z s i 2 3 rss i 1 n z s i z s i 2 4 rmse 1 n i 1 n z s i z s i 2 5 msdr 1 n i 1 n z s i z s i 2 σ 2 s i 6 md 1 i 1 n z s i z s i i 1 n z s i z s i z s i z s i 7 rpd 1 n i 1 n z s i z s i 2 i 1 n z s i z s i the lake groundwater level derived from uk was validated against the contour from a comprehensive regional groundwater flow model rossman et al 2018 developed a two dimensional numerical groundwater flow model to simulate the hydraulic head distribution in the groundwater fed lakes system for the entire nhs they represented the high plains aquifer as a single layer with spatially varying hydraulic conductivities with a satellite derived distributed recharge applied from the top surface a finite difference numerical groundwater modeling code modflow was used to solve the governing groundwater flow equations under steady state conditions using a 1 km uniform horizontal grid discretization recharge and hydraulic conductivities were calibrated using a non linear automated calibration code pest parameter estimation a strong correlation coefficient of 0 99 was attained between simulated and observed heads after the pest calibration even though the hydrostratigraphy was represented as a single layer the numerical modeling approach captured the groundwater heads in the high plains aquifer in the nhs details on the model can be found in rossman et al 2018 the result of ked was compared against the groundwater level contour of spring 2012 derived by the conservation and survey division of the school of natural resources university of nebraska lincoln the contours were generated using the natural neighbor interpolation method gilmore et al 2019 that preserves the local variation of the groundwater level and were comparable with the results of ked the accuracy of extracted lake area was validated using the overall accuracy and kappa statistics stehman 1997 the samples were generated randomly and labeled using visual image interpretation of naip 3 results 3 1 accuracy of lake area and lake groundwater level lake area accuracy assessment shows an overall accuracy of 95 a kappa statistic of 0 94 shows that the lake s boundary is delineated better than chance the water level in the observation wells at the time of lidar data acquisition were compared with the minimum maximum and mean lake groundwater level the results table 2 show that the lowest mean square error mse was the maximum lake groundwater level and is twice as accurate as the mean and the minimum value the lakes on the southern well id 37 and easternmost part well id 11 12 and 51 fig 1 of the nsh had the largest error it is hypothesized that this is due to the pumping from irrigation wells and groundwater flow direction shrestha et al 2021 fig 3 the low mse highlights that the lake water level provides sufficient accuracy to characterize the groundwater levels in the nsh and the lidar data can be used to characterize the short term as well as long term water level variation 3 2 spatial dependence of lake groundwater level the semivariogram analysis reveals that the gaussian model provides the best fit for uk table 3 with rss of 0 27 while the bessel spherical and exponential models have rss of 0 95 5 03 and 6 19 respectively similarly the exponential model has the lowest rss of 0 00000609 followed by bessel spherical and gaussian for ked table 3 sill variance is consistent with all the theoretical semivariogram models for ked while it varies for uk ked shows a smaller range such that the semivariogram flattens at shorter distances than the uk a nugget to sill ratio of 0 013 for uk shows higher spatial dependence while 0 83 for ked showed a weak spatial dependence a variable has strong dependence when the nugget to sill ratio is less than 0 25 moderate dependence with values between 0 25 and 0 75 and weak dependence with values 0 75 liu et al 2006 3 3 groundwater level prediction the predicted map illustrates the spatial variability present in the groundwater level the western part contains higher groundwater elevation while the eastern part of nsh contains the lowest elevation fig 7 the uk approach that uses second order polynomial as trend surface provides smoother water level variation fig 7a that resembles the regional water flow regime predicted ked surface fig 7b however reveals the local variation in the groundwater level the streams along with areas with little or no observations are better represented by ked as compared to uk the advantage of uk is that no external variables are necessary to remove the trend and it is easy to implement ked however requires external variables to be linearly correlated with the groundwater level and must be present at the sampled and unsampled locations a 10 fold cross validation result shows that both uk and ked are unbiased with a mean error estimate closer to zero uk shows a slightly higher rmse of 4 46 m compared to 2 39 m of ked ked confirms better prediction with better msdr rpd and md than uk table 4 the taylor diagram fig 8 also highlights that ked provides a better approximation of groundwater level than the uk the standard deviation map fig 9 shows the error distribution of the kriging interpolation at nsh the southern and eastern part of nsh shows higher error both in uk fig 9a and in ked fig 9b where there are fewer lakes ked however shows lower standard deviation as the digital elevation model effectively removed the regional trend present in the data as compared to second order polynomials fitting of uk comparison between the contour lines generated using uk and the numerical model shows a high degree of correspondence fig 10 a shows that the hydraulic head contours match with lake groundwater level contours especially in the western part of the nsh where the lake density is higher in the parts where the head distributions are dominated by river aquifer interactions contours were less likely to match as the river aquifer interaction in the numerical model was represented by a head dependent flux boundary which resulted in a better estimation of the head near the stream network the difference could be attributed to the limitation of kriging that the groundwater flow is not necessarily conserved and fails to reproduce features such as boundary conditions rivest et al 2008 tonkin and larson 2002 ked generated contours and 2012 water table contours do not agree in many areas fig 10b the ked with a large number of lake groundwater level observations 2300 provides a better characterization of groundwater level and captures the trend and general pattern seen in the water table contours from 2012 ked also captured the variation along streams not well captured in uk the dissimilarity in water table contours may be due to the difference in methods and the number of hydraulic head measurements used for interpolation the contours of 2012 were generated using the natural neighbor interpolation technique for the spring season gilmore et al 2019 with fewer observation wells and some information from smaller scale contour maps a young personal communication 2020 4 discussion the results of this study show that the lake groundwater level derived using topographic lidar provides an accurate representation of groundwater levels in the nsh with lake water levels lower than the regional potentiometric surface and evaporation significantly higher than precipitation the lakes in general are areas of focused groundwater discharge gosselin et al 2000 winter 1986 zlotnik et al 2009 although the lake groundwater level follows the surface terrain at the regional scale significant differences are observed near lakes at local scales winter 1999 as seen on the predicted surface from uk and ked locally lake position in relation to the regional groundwater flow regime and the gradient between the regional and local head determines whether a lake gains or loses water from the groundwater system born et al 1979 zlotnik et al 2009 for example when lakes are closely spaced and are on a hummocky topography transient groundwater mounds forms the presence of groundwater mounds induces groundwater flow towards the lake while the absence of mounds induces the water to flow away from the lake leading to a change in lake water levels gosselin and khisty 2001 winter 1999 seasonal changes in groundwater configuration also alters the location magnitude and direction of groundwater flow into or out of the lake winter 1986 at a regional scale however the water table elevations in the nsh show minor spatiotemporal trends 2m since predevelopment 1953 and between 2001 and 2015 korus et al 2010 mcguire 2017 the accuracy of lake groundwater level derived from topographic lidar was based on eight observation wells a larger number of observation wells distributed across the study area would provide a better estimate of the groundwater level in this study however only eight observation wells satisfied the conditions defined in section 2 4 besides the number and distribution of the observation wells the estimated lake water level depends on the i accuracy of the boundary between the lake and adjacent landmass derived from satellite images ii strength of backscatter from topographic lidar from water areas and iii response of water level due to hydraulic stresses caused by drought or irrigation demand from neighboring irrigation wells the accuracy assessment shows that the sentinel 2 images with spatial resolution of 10 m provides proper representation of the lake area for the study however higher resolution satellite or aerial images such as national agriculture imagery program would reduce the uncertainty associated along the boundary between lake and landmass similarly the waterline method reduces uncertainty associated with the low backscatter and laser dropout of topographic lidar at deeper water the response of a local groundwater system to stress is dependent on the depth to water thickness and geologic composition of the unsaturated zone and the hydraulic characteristics of the aquifer burbach and joeckel 2006 for example the lake responses suggest the unconfined aquifer in the nsh has shorter response times 5 10 years rossman et al 2014 shrestha et al 2021 compared to confined aquifer hundreds of years the semivariogram analysis of raw lake groundwater level reveals the presence of a regional trend the regional trend present in the groundwater level overwhelms the local variation kitanidis 1997 and therefore has to be removed before using kriging goovaerts 1997 although the second order polynomial fitting in uk removes the trend it still shows the presence of anisotropy in the direction of groundwater flow the use of topography in ked effectively removes the trend and anisotropy fig 6b and captures the local variation present in the groundwater level therefore the use of topography as an explanatory variable provides a simple and powerful method to capture the local variation present in an area however in areas with sparse observation data secondary topographic features can cause undesirable variation in the interpolated water level when the drift captures the random and short scale fluctuations rather than the larger scale variations desbarats et al 2002 rivest et al 2008 the presence of sand dunes in the digital elevation model created an unrealistic representation of groundwater levels therefore several representations of topography desbarats et al 2002 at 90 200 500 700 and 1000 m were used to determine the appropriate relationship between the water table elevation and topography wolock and price 1994 found that the coarser topographic representations more accurately represent the water table configuration that are smoother than the land surface topography uk captured the regional pattern of groundwater level variation fig 7a similar to the results of the regional scale steady state groundwater flow model the comparison between the contours generated using uk and the numerical model shows good correspondence in areas with a large number of lake groundwater level observations although the ked and 2012 contour maps do not match perfectly they depict the magnitude and patterns of the groundwater level variation the difference in contours may be due to the use of different interpolation method number of hydraulic head measurement and change in water level between 2012 and 2017 for example the groundwater level increased by 0 6 3 m from spring 2013 to spring 2018 in the nsh young et al 2019 since the method has been validated with observation wells future work can use sentinel 2 images to create monthly or bi monthly water table maps this can be used to update managers with the status of the water depth and calibrate a transient groundwater model across the nsh to apply this method the lake level would have to be equal to or greater than the water level measured by lidar alternatively bathymetry survey could be integrated with lidar to create lakebed map and use it for estimating the lake groundwater level at regular intervals the method is applicable in semi arid and arid regions of north america africa carter 1995 asia chen et al 2004 ma and edmunds 2006 europe heine et al 2015 sacks et al 1992 and australia turner and townley 2006 tweed et al 2009 that hosts closed lakes with dominant groundwater hydrology the method may work with lakes in glaciated terrain composed of unconsolidated and permeable materials and connection to local and intermediate groundwater flow system e g holzbecher 2001 hunt et al 2013 lischeid et al 2010 merz and pekdeger 2011 speldrich et al 2021 the method can be tested in several geomorphological settings with lake closed hydrology primarily dominated by groundwater influx 5 conclusion the study shows that the lidar data accurately represents the groundwater level in the nebraska sand hills nsh the integration of optical and lidar sensor compensates each other and significantly increases the hydraulic head observations to characterize the spatial correlation structure present in the groundwater of nsh the study finds that kriging with an external drift ked provides better estimates of the groundwater level than universal kriging uk at unsampled locations the use of topography as an explanatory variable captures the local variation present in the groundwater level a higher correspondence of the predicted surface with a numerical model derived hydraulic head highlights the lidar derived lake groundwater level can calibrate or define the boundary conditions in numerical models the method can be applied to other areas where the surface water represents the groundwater level with the possibility of lidar instruments to mount on a platform near lakes or use current lidar data the study also provides a framework to monitor the groundwater level in the nsh at high spatial and temporal resolution similarly the study also provides the prospect to combine the high spatial resolution digital elevation model and bathymetry survey and thereby use lakes as observation wells for future research credit authorship contribution statement nawaraj shrestha data curation methodology formal analysis writing original draft visualization aaron r mittelstet conceptualization writing review editing supervision funding acquisition aaron r young writing review editing troy e gilmore conceptualization writing review editing david c gosselin writing review editing yi qi writing review editing caner zeyrek writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the u s department of agriculture national institute of food and agriculture hatch project 1015698 robert b daugherty water for food global institute at the university of nebraska lincoln and the water sustainability fund nebraska natural resource commission we would like to thank the editors and anonymous reviewers for constructive suggestion and feedback 
4418,the spatial variability of groundwater levels is often inferred from sparsely located hydraulic head observations in wells the spatial correlation structure derived from sparse observations is associated with uncertainties that spread to estimates at unsampled locations in areas where surface water represents the nearby groundwater level remote sensing techniques can estimate and increase the number of hydraulic head measurements this research uses light detection and ranging lidar to estimate lake surface water level to characterize the groundwater level in the nebraska sand hills nsh an area with few observation wells the lidar derived lake groundwater level accuracy was within 40 cm mean square error mse of the nearest observation wells the lake groundwater level estimates were used to predict the groundwater level at unsampled locations using universal kriging uk and kriging with an external drift ked the results indicate unbiased estimates of groundwater level in the nsh uk showed the influence of regional trends in groundwater level while ked revealed the local variation present in the groundwater level a 10 fold cross validation demonstrated ked with better mean squared error me 0 003 0 007 root mean square error rmse 2 39 4 46 residual prediction deviation rpd 1 32 0 71 and mean squared deviation ratio msdr 1 01 1 49 than uk the research highlights that the lake groundwater level provides an accurate and cost effective approach to measure and monitor the subtle changes in groundwater level in the nsh this methodology can be applied to other locations where surface water bodies represent the water level of the unconfined aquifer and the results can aid in groundwater management and modeling keywords groundwater level lake groundwater level light detection and ranging lidar universal kriging uk kriging with an external drift ked remote sensing lake surface area 1 introduction an accurate representation of groundwater level in aquifers is important to many problems in hydrologic and numerical model analysis and designs a large number of observation wells help to characterize and analyze the change and vulnerability of aquifers to natural or anthropogenic factors such as climate change and global warming desbarats et al 2002 döll et al 2012 meixner et al 2016 scanlon et al 2006 taylor et al 2013 groundwater level in aquifers however due to large installation and maintenance costs are often sparsely measured and monitored singh et al 2010 strassberg et al 2009 gaps at unsampled locations are often filled using geostatistics with the available measurements thus leading to uncertainty in the water level prediction the associated uncertainty can be reduced using an alternate approach such as satellite altimetry to measure and monitor the groundwater level satellite altimetry provides remote estimates of water level at the interface of groundwater and surface interaction and provides an increased number of hydraulic heads that can sufficiently characterize the spatial correlation structure and predict the groundwater level with adequate accuracy satellite altimetry measures the range distance from the satellite to surface by computing the travel time of the reflected and received pulse from the satellite antenna with the use of reference ellipsoid the relative height of the surface is thus determined nielsen et al 2017 many studies have used satellite altimetry to estimate water surface elevation asadzadeh jarihani et al 2013 satellite laser altimeters such as ice cloud and land elevation satellite 2 icesat 2 provides sufficient accuracy 10 cm to characterize large water bodies but fails to provide good accuracy of smaller and shallow water due to a larger footprint size and use of green 532 nm laser frequency that penetrates shallow water li et al 2017 ryan et al 2020 yuan et al 2020 zhang et al 2019 similarly synthetic aperture radar sar altimeters such as cryosat 2 with footprints of 300 m provide measurements within 15 cm accuracy for larger lakes or water bodies nielsen et al 2017 roohi et al 2021 airborne altimeters such as light detection and ranging lidar estimates lake surface elevation for small as well as large water bodies with accuracy ranging from 3 50 cm höfle et al 2009 hofton et al 2000 hopkinson et al 2011 paul et al 2020 zhang et al 2020 while airborne lidar provides high accuracy for smaller lakes the widely available topographic lidar data suffers from low backscatter and laser dropouts as the near infrared wavelengths are highly absorbed by water fernandez diaz et al 2014 milan et al 2010 the uncertainty associated with low backscatter however can be reduced using approaches such as the waterline method the waterline method uses the boundary between the water surface and landmass derived from the remotely sensed image and superimposes them on the elevations relative to mean sea level bell et al 2016 kang et al 2017 qi et al 2019 yue and liu 2019 the water surface boundary from satellite images is generally delineated using methods such as single band thresholding classification multi band subpixel and hybrid approaches bijeesh and narasimhamurthy 2020 du et al 2012 the accuracy is increased when the original bands are combined with transformed spectral bands such as image color space principal component analysis tasseled cap transformation tct and water indices balázs et al 2018 jiang et al 2012 ma et al 2019 verpoorter et al 2012 zhuang and chen 2018 satellite altimetry therefore provides remote estimates of groundwater levels in areas where surface and groundwater interact zhang et al 2017 the increased measurements thereby reduce the uncertainty and better characterizes the spatial variation in the groundwater level using geostatistical methods geostatistics are often used to fill the gaps in areas where field observations are sparse geostatistics estimate and define the spatial correlation structure from sampled locations and make predictions at unsampled locations stochastic methods such as ordinary kriging universal kriging uk kriging with an external drift ked and co kriging are extensively used to map the spatial and temporal variation of groundwater levels adhikary and dash 2017 boezio et al 2006 varouchakis and hristopulos 2013 ordinary kriging provides an optimal estimate of the groundwater level given the data follow a multivariate normal distribution with a theoretical variogram ahmadi and sedghamiz 2007 goovaerts 1997 theodoridou et al 2017 varouchakis et al 2016 varouchakis and hristopulos 2013 groundwater levels with effects of regional trends are modeled using the uk as the linear drift improves the accuracy of the interpolated heads adhikary and dash 2017 ahmed 2007 kambhammettu et al 2011 although uk provides better estimates of groundwater level when the observations are sparse and linearly associated with external variables ked improves the estimation of hydraulic heads boezio et al 2006 desbarats et al 2002 deutsch and journel 1992 rivest et al 2008 as groundwater is the subdued replica of topography condon and maxwell 2015 haitjema and mitchell bruker 2005 and is widely available digital elevation models are often used to define the external drift desbarats et al 2002 goovaerts 2000 for example desbarats et al 2002 used ked with topography as drift and found that the use of topography provides robust estimates of the water table elevation while methods such as co kriging incorporates more than one secondary variable in the covariance structure to explain the groundwater level variation the difference is not always significant ahmadi and sedghamiz 2008 and requires inference of direct and cross covariance functions co kriging is also cumbersome and time consuming when many secondary variables are used desbarats et al 2002 methods other than geostatistics such as multiple linear regression and neural networks are also used to predict the groundwater level these methods although provide higher accuracy require a large number of ancillary data to capture the water level variation in an aquifer regardless of the interpolation method the accuracy depends on the distribution number and quality of data from observation wells the spatial correlation structure derived from a few observations is unable to characterize the spatial variability present in the aquifer thus leading to higher uncertainties and coarser representation of aquifer water level buchanan and triantafilis 2009 li and heap 2008 this research combines airborne altimetry with geostatistics and provides a novel approach to estimate the groundwater level in areas of surface water groundwater interchange the objective of this research was to map the spatial variability of the groundwater levels estimated from lidar derived lake water level in the nebraska sand hills nsh the specific objectives of this research were to i estimate the feasibility of lidar derived groundwater level from lake water level ii evaluate uk and ked to characterize the groundwater levels and iii validate compare the interpolated groundwater levels to numerical model predicted hydraulic heads and published water table contours 2 methods 2 1 study area the nsh has an area of 50 000 km2 and is the largest grass stabilized dune field in the western hemisphere with 450 km2 of shallow lakes and 4500 km2 of subirrigated meadows fig 1 ahlbrandt and fryberger 1980 smith 1965 gosselin et al 2000 sweeney and loope 2001 the areas of the lakes range from 0 004 to 12 km2 with most lake depths averaging less than one meter gosselin et al 2000 table 1 shows the proportion of lake sizes used in the study the majority 76 of the lakes are smaller than 0 2 km2 the lakes are denser in the western and northern parts of the nsh and sparse in the south fig 1 the semiarid climate of nsh has temperatures ranging from 40 to 43 3 c with an average annual temperature of 8 9 c the annual average precipitation ranges from 450 mm in the west to 690 mm in the eastern part of nsh national climatic data center 2020 lake hydrology is dependent on precipitation and groundwater as inputs and evaporation and seepage losses as outputs winter 1986 high total dissolved solid concentrations and water levels lower than the regional potentiometric surface indicate that lakes are focused groundwater discharge areas gosselin et al 2000 ong 2010 winter 1986 zlotnik et al 2009 the evaporation from lakes exceeds the precipitation for example the alkali lake in the nsh from july to september of 2007 2009 averaged 5 1 mm day 1 of evaporation compared to 1 3 mm day 1 of precipitation riveros iregui et al 2017 nsh lies on the northern part of the high plains aquifer system the ogallala group is the dominant and major water bearing geologic unit in the nsh and is formed of moderate to low permeable sand sandstone and siltstones deposited during the mid tertiary age fig 1 the aquifer dips gently eastward at 0 9 1 3 m per kilometer gutentag et al 1984 and is part of the high plains aquifer system where saturated in nsh dunes of the quaternary age overlie the unconsolidated alluvial sand gravel silt and clay that overlie the ogallala group the dunes composed of very fine to medium sand form an important part of aquifer by promoting aquifer recharge gutentag et al 1984 peterson et al 2020 the arikaree formation and the white river group which lie beneath the ogallala group are also part of the high plains aquifer though are finer grained and only contain usable quantities of water locally at fractured or coarse grained area in the western nsh the arikaree group is underlain by the brule formation this unit is composed of very fine to fine grained sandstone with a maximum thickness of about 300 m mcguire 2017 due to the fine grained nature of the arikaree and brule formations they may or may not be hydraulically connected to overlying geologic units the cretaceous pierre shale forms the impermeable base of the high plains aquifer in the nsh although the nsh has the greatest volume of saturated sediment in the high plains aquifer and least net groundwater declines haacker et al 2016 mcguire 2017 peterson et al 2016 scanlon et al 2012 the area is vulnerable to climate change irrigation and redcedar juniperus virginiana encroachment adane et al 2019 burbach and joeckel 2006 loope and swinehart 2000 suttie et al 2005 zou et al 2018 for example irrigation wells increased from only a few hundred in 1940 to 7775 within a 10 km buffer of nsh in 2019 nebraska department of natural resources 2019 research suggests that the change in supply and demand of precipitation and evapotranspiration can decrease recharge by 25 50 and lead to desertification adane et al 2019 peterson et al 2020 with 23 continuous observation wells and 61 seasonal and annual wells the spatial variability present in the groundwater level is difficult to characterize as such the annual nebraska statewide groundwater level monitoring report only provides partial groundwater level change information for the nsh region young et al 2019 similarly the most widely used water table elevation maps of spring 1995 hand drawn and 2012 natural neighbor interpolation from the nsh region are based on limited observations rossman et al 2018 and uses method that do not account for the associated uncertainty this study therefore provides an alternative approach to assess the spatial variability of groundwater level in the nsh using remote measurement of the water level in thousands of shallow endorheic lakes 2 2 dataset the study uses sentinel 2 satellite images to delineate the boundary between the lake and land surface area sentinel 2 a constellation of sentinel 2a and sentinel 2b satellites operated by the european union copernicus program has a spatial resolution of 10 20 and 60 m with 13 spectral bands in the visible near infrared and shortwave infrared region the revisit frequency of each single satellite is 10 days and the combined constellation revisit is 5 days the level 2a images used in the study are bottom of atmosphere reflectance values corrected for radiometric geometric and atmospheric effects the lidar point cloud data was collected by united states geological survey usgs in 2016 and 2017 hatched lines in fig 1 in the nsh the lidar data has an aggregate nominal pulse spacing of 0 71 m and an aggregate nominal pulse density of 2 points per m2 the level 2 ql2 data used in the study has an absolute vertical accuracy of 10 cm root mean square elevation rmsez with navd88 and nad83 as a vertical and horizontal datum respectively we downloaded point cloud through the usgs ftp server and used fusion tools mcgaughey 2009 to clip filter and merge within the buffered boundary of lakes the time of lidar data sentinel 2 satellite images and observation wells were matched such that the water levels are measured at a similar timeframe the areas with missing point cloud fig 1 data were filled from 1 m resolution digital elevation model derived from lidar data the study also uses data from observation wells fig 1 the observation well data were hosted in the database maintained by the conservation and survey division school of natural resources university of nebraska lincoln and the nebraska department of natural resources these data have been checked for quality and consistency young et al 2019 the 23 observation wells have hourly measurements of the depth to water from the land surface the depth to water from the land surface was then subtracted from the surveyed elevation of the land surface to obtain the elevation of the water table or potentiometric surface fig 2 shows the overall method used to derive the lake groundwater variation in the nsh 2 3 lake area delineation the visible and near infrared bands of sentinel 2 images hosted in google earth engine gorelick et al 2017 were filtered for cloud cover less than 10 and were mosaicked using median values for may to june 2017 in correspondence with lidar data acquisition time the mosaicked images were transformed using tasseled cap coefficients derived from sentinel images shi and xu 2019 the brightness greenness and wetness components were stacked with original bands and classified into water and non water pixels using a random forest classifier in google earth engine the tasseled cap transformation reduces the influence of shadows and enhances water area detection and delineation zhuang and chen 2018 whereas the original bands provide the classifier with spectral variability present in water areas random forest classifier an ensemble of decision trees provides higher accuracy and is widely used in processing remotely sensed imagery including water and wetland classification shrestha et al 2021 tian et al 2016 wang et al 2018 2020 the classifier was trained using samples collected through visual image interpretation of national agriculture imagery program naip with 75 training 287 and 30 testing 109 set the classified image was converted into a shapefile and exported for further analysis lakes with an area less than 0 008 km2 were filtered and removed to reduce the effect of smaller misclassified pixels due to the ephemeral water areas that form near lakes and wetlands the smaller lakes were also removed to avoid the effect of clustering and overfitting the variogram goovaerts 1997 similarly lakes with a higher perimeter to area ratio were filtered to reduce the triangular and irregular shaped polygons the lakes were then buffered by 1 m to reduce the effect of missing lidar point cloud from water due to low backscatter 2 4 lake surface water level estimation and validation lake surface water level was estimated by combining the lake boundary and lidar point cloud using the waterline method the waterline method mainly used to evaluate the water level changes in coastal areas and lakes bell et al 2016 kang et al 2017 qi et al 2019 yue and liu 2019 zhang et al 2020 superimposes the boundary between the water surface and landmass on the elevations relative to mean sea level the overall process involves the following i delineate lake boundaries from sentinel 2 images and create a 1 m buffer ii superimpose the buffered lake boundary with the lidar point cloud to clip and filter the last returned lidar points and iii calculate the minimum maximum and mean value that represents the lake water level or lake groundwater level given the gentle dune topography the boundary between the lake and land surface is assumed to transition smoothly therefore a difference greater or equal to 5 m between the minimum and maximum lidar point cloud within the buffer was filtered as outliers the outliers were considered errors associated with an inaccurate representation of the boundary derived from sentinel 2 images a total of 2300 lakes were retained and converted to points for geostatistical analysis fig 3 shows the lakes thinned for visualization clusters at the western and northern part of the nsh while fewer or no lakes are present in the southern part the points that represent reservoirs or man made impoundments were manually removed the lake groundwater level derived from lidar data were validated against the water level from the observation wells the lakes and observation wells were selected fig 3 based on the following criteria i water level measurements from the observation wells were matched up with the time the lidar point cloud was collected ii since the lake water level represents the unconfined aquifer any wells that penetrated the confined aquifer based on the well drilling profile were filtered and iii lakes nearest and along the regional groundwater flow direction were retained the selected lakes were corrected for ambient hydraulic gradient and then compared with water levels in the observation wells in general the lidar data were acquired between may and june of 2017 and therefore represents the spring season or pre stress groundwater level of the 23 observation wells only eight were used and compared to the nearest lake level elevation the other 15 observation wells were not used for the following reasons four wells penetrated the confined aquifer and thus the water didn t interact directly with the lakes three wells were farther than 20 km from any lake four wells were missing lidar data and four wells data were missing at the time of lidar data collection 2 5 geostatistical estimation and prediction geostatistic based methods were used to estimate and predict the lake groundwater level in the nsh geostatistics uses the sampled attribute z at location si to estimate the z at unsampled location s0 the observation is decomposed into the mean and the stochastic component random variable as in eq 1 the mean or the trend component μ s is estimated either using the polynomial functions uk or auxiliary information such as elevation ked desbarats et al 2002 goovaerts 1997 the spatial dependence between the observations is estimated from residuals stochastic component using semivariogram and predicted for the unsampled locations additional detail on uk and ked equations are provided in desbarats et al 2002 deutsch and journel 1992 and goovaerts 1997 1 z s μ s z s we used uk and ked to estimate and predict the lake groundwater level variation in the nsh the lake groundwater level was checked for normality using histogram plots skewness and kurtosis coefficients the test showed that the raw data are skewed towards the left fig 4 a with a skewness coefficient of 0 89 and a kurtosis of 2 55 a skewness value closer to zero and kurtosis closer to 3 indicates a normal distribution 2 6 universal kriging uk is used when the data shows the presence of regionalized variables a semivariogram analysis of raw data not shown here shows the presence of a regional trend therefore first and second order polynomials were used to estimate the trend from the lake groundwater level a first and second order polynomial fit explained 96 and 98 of the variance present in the lake groundwater level respectively similarly the histogram plot fig 4b c and skewness coefficient of 0 02 and 0 51 and kurtosis coefficient of 1 93 and 2 77 for the residuals of first and second order polynomials respectively indicate a distribution closer to normal therefore we used a second order polynomial fit to remove the trend and estimate the residuals for further analysis the initial values of nugget range and sill were determined from the visual analysis of a semivariogram plot theoretical semivariogram models such as spherical gaussian exponential and bessel cressie and wikle 2015 deutsch and journel 1992 gringarten and deutsch 2001 were fitted to the empirical lake groundwater level data fig 5 a the model with the lowest residual sum of squares rss were used for modelling the spatial correlation structure anisotropy present were checked using directional variograms at four main directions 0 45 90 and 135 with an angle of tolerance of 22 5 goovaerts 1997 fig 5b shows the presence of anisotropy that were corrected using the angle and scaling factor the prediction was performed in 90 m resolution grid 2 7 kriging with an external drift the drift present in the lake groundwater level was estimated using the bare earth digital elevation model of 90 m resolution regression analysis between lake groundwater level and topography was used to determine the association of dependent and independent variables the results show that the lake water level was highly linear with the elevation r2 0 95 as with the uk the theoretical models with the least rss were used to determine the spatial correlation structure fig 6 a the semivariogram of residuals after trend removal does not show the presence of trend and anisotropy fig 6b the optimal resolution for ked prediction was determined by predicting and evaluating the surface at 90 200 500 700 and 1000 m grids the higher resolution grids 90 m were overwhelmed with the local topographic variation and resulted in noisy lake groundwater level a coarser resolution topography 500 m averaged the local groundwater level variation therefore a 200 m grid was selected as optimal resolution for ked we used the gstat package pebesma and graeler 2013 to implement the uk and ked approach to map the groundwater level variation in the nsh 2 8 validation the k fold cross validation measure was used to determine the accuracy of the predicted surface the method divides the data into multiple sets one subset is used to test while the other is used to predict based on the results of the cross validation the following evaluation statistics were used to compare the accuracy of the interpolation mean square error mse is sensitive to outliers as it measures the magnitude of the error root mean square error rmse provides a standard deviation of the residuals the mean squared deviation ratio msdr is the mean of the ratio of the squared prediction errors to the variance a msdr close to one indicates a good model modified index of agreement md is the ratio between the mean square error and the potential error md is like root mean square error with a value between 0 and 1 residual prediction deviation rpd is the standard deviation of the observation divided by the root mean square error of prediction a higher rpd value shows good prediction residual sum of squares rss is used to evaluate the degree of fitting between the empirical and theoretical variogram models 2 mse 1 n i 1 n z s i z s i 2 3 rss i 1 n z s i z s i 2 4 rmse 1 n i 1 n z s i z s i 2 5 msdr 1 n i 1 n z s i z s i 2 σ 2 s i 6 md 1 i 1 n z s i z s i i 1 n z s i z s i z s i z s i 7 rpd 1 n i 1 n z s i z s i 2 i 1 n z s i z s i the lake groundwater level derived from uk was validated against the contour from a comprehensive regional groundwater flow model rossman et al 2018 developed a two dimensional numerical groundwater flow model to simulate the hydraulic head distribution in the groundwater fed lakes system for the entire nhs they represented the high plains aquifer as a single layer with spatially varying hydraulic conductivities with a satellite derived distributed recharge applied from the top surface a finite difference numerical groundwater modeling code modflow was used to solve the governing groundwater flow equations under steady state conditions using a 1 km uniform horizontal grid discretization recharge and hydraulic conductivities were calibrated using a non linear automated calibration code pest parameter estimation a strong correlation coefficient of 0 99 was attained between simulated and observed heads after the pest calibration even though the hydrostratigraphy was represented as a single layer the numerical modeling approach captured the groundwater heads in the high plains aquifer in the nhs details on the model can be found in rossman et al 2018 the result of ked was compared against the groundwater level contour of spring 2012 derived by the conservation and survey division of the school of natural resources university of nebraska lincoln the contours were generated using the natural neighbor interpolation method gilmore et al 2019 that preserves the local variation of the groundwater level and were comparable with the results of ked the accuracy of extracted lake area was validated using the overall accuracy and kappa statistics stehman 1997 the samples were generated randomly and labeled using visual image interpretation of naip 3 results 3 1 accuracy of lake area and lake groundwater level lake area accuracy assessment shows an overall accuracy of 95 a kappa statistic of 0 94 shows that the lake s boundary is delineated better than chance the water level in the observation wells at the time of lidar data acquisition were compared with the minimum maximum and mean lake groundwater level the results table 2 show that the lowest mean square error mse was the maximum lake groundwater level and is twice as accurate as the mean and the minimum value the lakes on the southern well id 37 and easternmost part well id 11 12 and 51 fig 1 of the nsh had the largest error it is hypothesized that this is due to the pumping from irrigation wells and groundwater flow direction shrestha et al 2021 fig 3 the low mse highlights that the lake water level provides sufficient accuracy to characterize the groundwater levels in the nsh and the lidar data can be used to characterize the short term as well as long term water level variation 3 2 spatial dependence of lake groundwater level the semivariogram analysis reveals that the gaussian model provides the best fit for uk table 3 with rss of 0 27 while the bessel spherical and exponential models have rss of 0 95 5 03 and 6 19 respectively similarly the exponential model has the lowest rss of 0 00000609 followed by bessel spherical and gaussian for ked table 3 sill variance is consistent with all the theoretical semivariogram models for ked while it varies for uk ked shows a smaller range such that the semivariogram flattens at shorter distances than the uk a nugget to sill ratio of 0 013 for uk shows higher spatial dependence while 0 83 for ked showed a weak spatial dependence a variable has strong dependence when the nugget to sill ratio is less than 0 25 moderate dependence with values between 0 25 and 0 75 and weak dependence with values 0 75 liu et al 2006 3 3 groundwater level prediction the predicted map illustrates the spatial variability present in the groundwater level the western part contains higher groundwater elevation while the eastern part of nsh contains the lowest elevation fig 7 the uk approach that uses second order polynomial as trend surface provides smoother water level variation fig 7a that resembles the regional water flow regime predicted ked surface fig 7b however reveals the local variation in the groundwater level the streams along with areas with little or no observations are better represented by ked as compared to uk the advantage of uk is that no external variables are necessary to remove the trend and it is easy to implement ked however requires external variables to be linearly correlated with the groundwater level and must be present at the sampled and unsampled locations a 10 fold cross validation result shows that both uk and ked are unbiased with a mean error estimate closer to zero uk shows a slightly higher rmse of 4 46 m compared to 2 39 m of ked ked confirms better prediction with better msdr rpd and md than uk table 4 the taylor diagram fig 8 also highlights that ked provides a better approximation of groundwater level than the uk the standard deviation map fig 9 shows the error distribution of the kriging interpolation at nsh the southern and eastern part of nsh shows higher error both in uk fig 9a and in ked fig 9b where there are fewer lakes ked however shows lower standard deviation as the digital elevation model effectively removed the regional trend present in the data as compared to second order polynomials fitting of uk comparison between the contour lines generated using uk and the numerical model shows a high degree of correspondence fig 10 a shows that the hydraulic head contours match with lake groundwater level contours especially in the western part of the nsh where the lake density is higher in the parts where the head distributions are dominated by river aquifer interactions contours were less likely to match as the river aquifer interaction in the numerical model was represented by a head dependent flux boundary which resulted in a better estimation of the head near the stream network the difference could be attributed to the limitation of kriging that the groundwater flow is not necessarily conserved and fails to reproduce features such as boundary conditions rivest et al 2008 tonkin and larson 2002 ked generated contours and 2012 water table contours do not agree in many areas fig 10b the ked with a large number of lake groundwater level observations 2300 provides a better characterization of groundwater level and captures the trend and general pattern seen in the water table contours from 2012 ked also captured the variation along streams not well captured in uk the dissimilarity in water table contours may be due to the difference in methods and the number of hydraulic head measurements used for interpolation the contours of 2012 were generated using the natural neighbor interpolation technique for the spring season gilmore et al 2019 with fewer observation wells and some information from smaller scale contour maps a young personal communication 2020 4 discussion the results of this study show that the lake groundwater level derived using topographic lidar provides an accurate representation of groundwater levels in the nsh with lake water levels lower than the regional potentiometric surface and evaporation significantly higher than precipitation the lakes in general are areas of focused groundwater discharge gosselin et al 2000 winter 1986 zlotnik et al 2009 although the lake groundwater level follows the surface terrain at the regional scale significant differences are observed near lakes at local scales winter 1999 as seen on the predicted surface from uk and ked locally lake position in relation to the regional groundwater flow regime and the gradient between the regional and local head determines whether a lake gains or loses water from the groundwater system born et al 1979 zlotnik et al 2009 for example when lakes are closely spaced and are on a hummocky topography transient groundwater mounds forms the presence of groundwater mounds induces groundwater flow towards the lake while the absence of mounds induces the water to flow away from the lake leading to a change in lake water levels gosselin and khisty 2001 winter 1999 seasonal changes in groundwater configuration also alters the location magnitude and direction of groundwater flow into or out of the lake winter 1986 at a regional scale however the water table elevations in the nsh show minor spatiotemporal trends 2m since predevelopment 1953 and between 2001 and 2015 korus et al 2010 mcguire 2017 the accuracy of lake groundwater level derived from topographic lidar was based on eight observation wells a larger number of observation wells distributed across the study area would provide a better estimate of the groundwater level in this study however only eight observation wells satisfied the conditions defined in section 2 4 besides the number and distribution of the observation wells the estimated lake water level depends on the i accuracy of the boundary between the lake and adjacent landmass derived from satellite images ii strength of backscatter from topographic lidar from water areas and iii response of water level due to hydraulic stresses caused by drought or irrigation demand from neighboring irrigation wells the accuracy assessment shows that the sentinel 2 images with spatial resolution of 10 m provides proper representation of the lake area for the study however higher resolution satellite or aerial images such as national agriculture imagery program would reduce the uncertainty associated along the boundary between lake and landmass similarly the waterline method reduces uncertainty associated with the low backscatter and laser dropout of topographic lidar at deeper water the response of a local groundwater system to stress is dependent on the depth to water thickness and geologic composition of the unsaturated zone and the hydraulic characteristics of the aquifer burbach and joeckel 2006 for example the lake responses suggest the unconfined aquifer in the nsh has shorter response times 5 10 years rossman et al 2014 shrestha et al 2021 compared to confined aquifer hundreds of years the semivariogram analysis of raw lake groundwater level reveals the presence of a regional trend the regional trend present in the groundwater level overwhelms the local variation kitanidis 1997 and therefore has to be removed before using kriging goovaerts 1997 although the second order polynomial fitting in uk removes the trend it still shows the presence of anisotropy in the direction of groundwater flow the use of topography in ked effectively removes the trend and anisotropy fig 6b and captures the local variation present in the groundwater level therefore the use of topography as an explanatory variable provides a simple and powerful method to capture the local variation present in an area however in areas with sparse observation data secondary topographic features can cause undesirable variation in the interpolated water level when the drift captures the random and short scale fluctuations rather than the larger scale variations desbarats et al 2002 rivest et al 2008 the presence of sand dunes in the digital elevation model created an unrealistic representation of groundwater levels therefore several representations of topography desbarats et al 2002 at 90 200 500 700 and 1000 m were used to determine the appropriate relationship between the water table elevation and topography wolock and price 1994 found that the coarser topographic representations more accurately represent the water table configuration that are smoother than the land surface topography uk captured the regional pattern of groundwater level variation fig 7a similar to the results of the regional scale steady state groundwater flow model the comparison between the contours generated using uk and the numerical model shows good correspondence in areas with a large number of lake groundwater level observations although the ked and 2012 contour maps do not match perfectly they depict the magnitude and patterns of the groundwater level variation the difference in contours may be due to the use of different interpolation method number of hydraulic head measurement and change in water level between 2012 and 2017 for example the groundwater level increased by 0 6 3 m from spring 2013 to spring 2018 in the nsh young et al 2019 since the method has been validated with observation wells future work can use sentinel 2 images to create monthly or bi monthly water table maps this can be used to update managers with the status of the water depth and calibrate a transient groundwater model across the nsh to apply this method the lake level would have to be equal to or greater than the water level measured by lidar alternatively bathymetry survey could be integrated with lidar to create lakebed map and use it for estimating the lake groundwater level at regular intervals the method is applicable in semi arid and arid regions of north america africa carter 1995 asia chen et al 2004 ma and edmunds 2006 europe heine et al 2015 sacks et al 1992 and australia turner and townley 2006 tweed et al 2009 that hosts closed lakes with dominant groundwater hydrology the method may work with lakes in glaciated terrain composed of unconsolidated and permeable materials and connection to local and intermediate groundwater flow system e g holzbecher 2001 hunt et al 2013 lischeid et al 2010 merz and pekdeger 2011 speldrich et al 2021 the method can be tested in several geomorphological settings with lake closed hydrology primarily dominated by groundwater influx 5 conclusion the study shows that the lidar data accurately represents the groundwater level in the nebraska sand hills nsh the integration of optical and lidar sensor compensates each other and significantly increases the hydraulic head observations to characterize the spatial correlation structure present in the groundwater of nsh the study finds that kriging with an external drift ked provides better estimates of the groundwater level than universal kriging uk at unsampled locations the use of topography as an explanatory variable captures the local variation present in the groundwater level a higher correspondence of the predicted surface with a numerical model derived hydraulic head highlights the lidar derived lake groundwater level can calibrate or define the boundary conditions in numerical models the method can be applied to other areas where the surface water represents the groundwater level with the possibility of lidar instruments to mount on a platform near lakes or use current lidar data the study also provides a framework to monitor the groundwater level in the nsh at high spatial and temporal resolution similarly the study also provides the prospect to combine the high spatial resolution digital elevation model and bathymetry survey and thereby use lakes as observation wells for future research credit authorship contribution statement nawaraj shrestha data curation methodology formal analysis writing original draft visualization aaron r mittelstet conceptualization writing review editing supervision funding acquisition aaron r young writing review editing troy e gilmore conceptualization writing review editing david c gosselin writing review editing yi qi writing review editing caner zeyrek writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge the u s department of agriculture national institute of food and agriculture hatch project 1015698 robert b daugherty water for food global institute at the university of nebraska lincoln and the water sustainability fund nebraska natural resource commission we would like to thank the editors and anonymous reviewers for constructive suggestion and feedback 
4419,uncertainties associated with the initial conditions e g soil moisture content of a hydrologic model have been recognized as one of the main sources of errors in hydrologic predictions recent advances in sequential data assimilation da and variational da var da have focused on correcting these initial conditions for improving hydrologic predictions this study proposes a var da methodology that considers a basin wide single scaling correction factor for updating the soil moisture content of variable infiltration capacity vic land surface model lsm by assimilating gauge observed streamflow this simplified scaling factor reduces the computational demand of the var da in updating the soil moisture conditions of vic the proposed var da scheme is demonstrated in tar river basin in nc a rainfall runoff dominated watershed for improving monthly streamflow simulations and forecasting over a 20 year period 1991 2010 the role of two critical parameters of var da the update frequency the interval between da applications and the length of assimilation window in determining the skill of da improved streamflow predictions is also assessed we found that correcting vic model s initial conditions using a 7 day assimilation window results in the highest improvement in the skill of streamflow predictions quantified by kling gupta efficiency kge and nash sutcliffe efficiency nse metrics in addition the potential gain from var da framework is quantified and compared under two 1 month ahead streamflow forecasting schemes 1 var da corrected initial conditions of vic forced with echam4 5 gcm 1 month ahead precipitation forecasts and 2 ensemble streamflow prediction esp approach this study also examines the persistence of the da in improving monthly streamflow predictions by quantifying the enhanced accuracy in daily flows over extended forecast lead time blocks analyses show that the corrected initial state conditions continually enhance the 7 8 days ahead streamflow predictions but after that the errors in forcings dominate the da effects overall the application of proposed var da scheme results in improved monthly streamflow forecasting due to correcting initial conditions keywords variational data assimilation forecasting land surface model streamflow climate variability 1 introduction reliable monthly to seasonal m2s streamflow forecasting provides critical information for water system planning and management e g crop management such forecasts also facilitate the allocation of water supplies to different water users e g domestic agricultural etc and to meet environmental demands hamlet and lettenmaier 1999 wood et al 2002 devineni et al 2008 mcinerney et al 2020 over the past decades several strides have been made in m2s streamflow forecasting by utilizing climate forecasts from general circulation models gcms with watershed models schaake et al 2006 mazrooei et al 2015 ahmadalipour et al 2017 recently efforts have also focused on improving the skill of subseasonal to seasonal streamflow forecasting monhart et al 2019 li et al 2019 mcinerney et al 2020 quedi and fan 2020 which typically focuses on a lead time of 15 days to 90 days capturing on the intra seasonal variability of the atmosphere e g madden julian oscillation although several sources of uncertainty in streamflow forecasting have been identified e g uncertainty in model structure and model parameters inaccurate initial hydrologic conditions imprecise hydrometeorological forcings addressing such inherent uncertainties in the context of real time streamflow forecasting approaches have remained a long standing problem ajami et al 2007 salamon and feyen 2010 li et al 2019 hence systematic reduction of uncertainties from multiple sources provide an opportunity for enhancing the accuracy and reliability of hydrologic forecasts liu et al 2012 pappenberger et al 2011 sankarasubramanian et al 2009 li et al 2014 since rainfall is the major contributor to streamflow variability uncertainty in rainfall forecasts remains as the key source of uncertainty in m2s streamflow forecasting particularly for basins under rainfall runoff regime li et al 2009 mazrooei et al 2015 hence under rainfall runoff regime limited skill in precipitation forecasting is a determining factor for the skill of m2s streamflow forecasting but improving watershed model s initial conditions could overcome the limited skill of precipitation forecast and further improve streamflow forecast in rainfall runoff regimes mahanama et al 2012 thus correcting model s initial conditions using data assimilation techniques and forcing the model with m2s climate forecasts provide opportunities for improving m2s streamflow forecasting in rainfall runoff regimes mazrooei and sankarasubramanian 2019 data assimilation da is an effective methodology that is able to reduce the errors in model state variables and parameters and consequently improves the model predictability the basic idea behind da is to optimally combine the information from model predictions and available observations to correct the model initial conditions da have been widely applied in oceanography and atmospheric sciences especially in operational weather forecasting and its effectiveness has been well demonstrated furthermore considerable advances in the theoretical development of da techniques in hydrology have been proposed from simple direct insertion methods to complex sequential and smoothing filtering methods kumar et al 2009 dechant and moradkhani 2012 wang and cai 2008 aubert et al 2003 kumar et al 2014 yet its application in hydrologic studies on real time forecasting is at its infancy liu et al 2012 of these methods sequential da such as extended kalman filter ekf or ensemble kalman filter enkf is one of the earliest and commonly used methods that has been explored in hydrological studies moradkhani et al 2005 reichle et al 2008 clark et al 2008 the main limitation on the application of sequential da in distributed hydrologic models stems from the requirement of state space reformulation of model in a gridded form along with the substantial demand of the computational power arising from ensemble simulations mitchell et al 2004 alternatively variational data assimilation var da is a potentially simpler method as opposed to sequential da jazwinski 2007 var da is a commonly used technique in global atmospheric assimilation schemes for operational meteorological forecasting yet it has not been fully exploited in hydrological studies ide et al 1997 li and navon 2001 liu et al 2012 in spite of substantial research on hydrologic da limited number of studies have focused on var da formulation and application and also in quantifying its utility in m2s hydrologic forecasting for example seo et al 2003 employed var da to assimilate streamflow and precipitation observations for improving operational hydrological forecasting at short lead times they employed var da in a lumped watershed model sacramento model and found that it significantly improves the accuracy of 40 h ahead streamflow forecasts over few selected basins in the united states since sacramento model is commonly used in operational streamflow forecasts they also suggested var da in comparison to other da techniques is more suitable for real time forecasting since it requires less computational demand rüdiger et al 2006 employed var da coupled with the catchment land surface model clsm in order to assimilate observed streamflow and assessed the direct improvements in initial soil moisture states over three catchments in australia however the entire study is a synthetic study where observed forcings were used in improving streamflow and latent heat flux predictions thus there is potential for improving var da schemes for application in streamflow predictions the abundance of hydrologic observations collected over last decades from in situ measurements and satellite remote sensing has motivated the need to integrate them into da techniques for improving hydrologic predictions accordingly potential for da applications has increased due to availability of remotely sensed data of soil moisture and snow cover area extent from satellite observations in recent years pauwels et al 2001 andreadis and lettenmaier 2006 kumar et al 2016 clark et al 2008 reichle et al 2008 liu and mishra 2017 remotely sensed soil moisture conditions provides estimation of initial hydrologic conditions over a large spatial scale thus could be utilized in regional and continental da studies but they are available only for the past 10 20 years on the other hand historical in situ observations such as gauge measured streamflow records are available for a much longer period of time and contain substantially lower measurement errors compared to satellite observations loew et al 2017 ford and quiring 2019 swenson et al 2006 rüdiger et al 2006 showed that assimilating streamflow reduces the error in correcting the initial conditions as opposed to the soil moisture conditions using a synthetic setup since streamflow is an integrator of spatial variability in basin conditions and forcings hence assimilating gauge measured streamflow using var da provides a great opportunity to correct model s initial conditions and consequently can improve hydrologic predictions seo et al 2003 2009 vrugt et al 2005 clark et al 2008 moradkhani and sorooshian 2008 given that utilizing observed streamflow in da applications better reduces the errors in the initial conditions as opposed to soil moisture observations rüdiger et al 2006 the availability of long term streamflow observations at gauge and the ability of var da in assimilating point observations over gridded initial conditions in real time streamflow forecasting as opposed to sequential da methods seo et al 2003 we consider var da in this study for assimilating observed streamflow information into the variable infiltration capacity vic land surface model lsm the motivation of this study is to assess the utility of var da in improving vic lsm monthly streamflow forecasts through two forecasting approaches 1 using month ahead climate forecasts from a gcm and 2 probabilistic streamflow forecasting known as ensemble streamflow prediction esp that considers ensemble of initial conditions with climatological forcings past da studies have considered either a conceptual hydrologic model or a distributed model along with observed forcings for evaluating the utility of da in improving hydrologic simulations aka predictions or for short range forecasting lead times i e hourly to maximum weekly rather than m2s streamflow forecasting recently mazrooei and sankarasubramanian 2019 analyzed the improved skill of 1 month ahead streamflow forecasts over rainfall dominated basins across the united states by correcting the initial conditions of a conceptual hydrologic model using enkf but the application of enkf to a distributed hydrological model is computationally intensive due to ensemble executions furthermore vic a gridded lsm is selected in which more complex modeling components such as interactions between land surface and atmosphere vegetation dynamics soil temperature and streamflow response are explicitly incorporated with finer modelling time steps to better estimate land surface fluxes cox et al 2000 feddema et al 2005 bonan and levis 2006 zeng 2010 the challenge in coupling var da and vic lsm is in incorporating the error in point measurements i e observed streamflow at gauge to correct the initial conditions of the gridded vic states to the best of our knowledge there are limited efforts on assessing the application of var da using in situ streamflow observations in correcting vic lsm initial conditions and quantifying the resultant improvements in m2s streamflow forecasts here we propose a var da methodology that minimizes the errors in predicting the observed streamflow by correcting the spatially varying vic model s initial conditions thus the objectives of the study are a develop a var da methodology for assimilating observed streamflows to correct initial conditions and b assess the utility of var da in improving the monthly streamflow forecasts from vic which is forced with monthly climate forecasts our hypothesis here is that addressing the two sources of uncertainty correcting initial conditions and utilizing month ahead climate forecasts from gcm will provide us with improved monthly streamflow forecasts particularly for months with limited skill in climate forecasts e g summer season for months with significant skill in climate forecasts arose from enso conditions e g winter months we expect forcing vic with downscaled climate forecasts and corrected initial conditions using the proposed var da scheme could result in improved monthly streamflow skill this manuscript is organized as follows section 2 provides details about the used hydroclimatic data and study domain section 3 presents the candidate model var da approach and its implementation lastly section 4 presents the results of all the experiments followed by a discussion in section 5 2 study area and data 2 1 tar river basin all model simulations are executed over tar river basin fig 1 a rainfall dominated river basin located in north carolina state the selected study area is part of tar pamlico river basin which consists of two sub basins tar river headwaters huc03020101 and fishing watershed huc03020102 the total drainage area of this domain is 5654 square kilometers and the basin has experienced several flood events due to various hurricanes such as fran 1996 floyd 1999 and isabel 2003 daily streamflow from this basin also provides fresh water input to the tar pamlico estuary 2 2 streamflow observations daily observed streamflow data for the period 1949 2010 is obtained from the us geological survey usgs at tar river at tarboro usgs 02083500 this site is classified as one of the natural basins in us and is included in the hydro climatic data network hcdn slack et al 1993 database since it receives minimal influence from anthropogenic impacts such as upstream reservoir and groundwater pumping fig 1 also shows the seasonality of the observed flows for the tar river basin typically the basin experiences high flow season during winter jfm when 53 of the annual flow occurs and the low flows occur during summer jas with only 9 contribution to the mean annual flow 2 3 observed meteorological forcings observed meteorological data is obtained from maurer et al 2002 dataset in order to set up the hydrologic model this data is derived by interpolating the weather gauge observations across the country and it is available at 1 8 150 km2 cell area spatial resolution at daily time scale from january 1949 till december 2010 the meteorological time series are used as the model forcings including daily precipitation mm day maximum and minimum daily temperatures c and average 10 meter wind speed m s these four variables are the minimum set of variables required by the hydrologic model in this study section 3 1 in order to estimate terrestrial fluxes other forcing variables are also required by the hydrologic model which are described in section 3 1 2 4 echam4 5 precipitation forecasts streamflow forecasting using a land surface model has two steps a updating the initial conditions of the model and b forcing the model with atmospheric conditions i e mainly precipitation and temperature for the forecasting period so for step b one has to use either a gcm or a regional climate model to get the precipitation and temperature forecast we use climate forecasts from the echam4 5 general circulation model gcm developed by the max planck institute available from the international research institute of climate and society iri data library li and goddard 2005 for forcing the vic model the echam4 5 precipitation forecasts are available at monthly time scale and 2 8 spatial resolution including 24 ensemble members up to 7 month lead time constructed analogue sea surface temperature sst forecasts with 7 month lead time were forced with echam4 5 atmospheric gcm to develop climate forecasts these 7 month ahead climate forecasts from echam4 5 are developed retrospectively for every month from 1957 and it is also one of the atmospheric gcms currently used for climate forecasting at iri for this study we utilize only one month ahead precipitation forecast for developing streamflow forecast for the tar river basin several studies have successfully applied echam4 5 gcm retrospective forecasts for evaluating streamflow forecasting mazrooei et al 2015 sinha and sankarasubramanian 2012 and for data assimilation li et al 2016 since vic model accepts forcing with a finer spatio temporal resolution echam4 5 precipitation forecasts are spatially downscaled to 1 8 resolution and temporally disaggregated from monthly to daily time step for spatial downscaling at a given location a principal component regression pcr model is developed between the ensemble mean of the overlying 2 8 monthly precipitation forecasts and the monthly observed precipitation at 1 8 resolution pcr model is then trained for a given month during the period 1957 1990 and the downscaled monthly forecasts are modeled for the period 1991 2010 next a temporal disaggregation technique based on a k nn algorithm prairie et al 2007 is employed in order to resample daily precipitation forecasts from the downscaled monthly forecasts detailed performance of the k nn disaggregation algorithm is summarized in our previous studies sinha and sankarasubramanian 2013 further explanation of the spatial downscaling and temporal disaggregation schemes as well as the skill of downscaled precipitation forecasts can be found in mazrooei et al 2015 and mazrooei 2017 3 methodology 3 1 hydrologic model the selected hydrologic model in this study is consisted of two components 1 variable infiltration capacity vic wood et al 1992 liang et al 1994 liang et al 1996 model is executed which is a semi distributed physically based land surface model capable of simulating runoff and other terrestrial variables for a set of grid cells independently and 2 a routing model lohmann et al 1996 lohmann et al 1998 is then performed to transport surface runoff and baseflow from each grid cell to the river system and eventually estimate the total streamflow at the basin outlet here vic model is performed in 3 h time steps with 3 soil layers over 40 grid cells of the river basin fig 1 the direct runoff is quantified as the excess water from saturation and infiltration at the top two soil layers and the baseflow is derived from the bottom soil layer using a generalized version of the arno model franchini and pacciani 1991 vic model is manually calibrated for the tar river basin using 40 years of data 1951 1990 by minimizing root mean square error rmse between simulated and observed flows sinha and sankarasubramanian 2013 the parameters considered in the calibration process are listed as maximum soil moisture content infiltration shape parameter evapotranspiration parameter and baseflow parameter li et al 2016 vic model is typically implemented with daily meteorological forcings and evenly divides the daily totals into sub daily values to run at the model timestep other than those variables vic model also estimates forcings such as air pressure relative humidity incoming radiations etc through various complex algorithms kimball et al 1997 thornton and running 1999 bras 1990 subsequently after vic simulations runoff and baseflow fluxes are routed to the edge of each grid cell through the river network based on lohmann et al 1996 routing model using couple of input files containing information of each grid cell s flow direction flow velocity and unit hydrograph derived from delineating the watershed 3 2 variational data assimilation variational data assimilation var da methods are smoothers that seeks optimal initial conditions so that the model prediction best fits the observation within a user specified assimilation window in addition depending on the hydrologic problem the var technique can be utilized as one dimensional i e 1d var considering lumped catchment scale or taking multiple spatial dimensions into account e g 3d var 4d var where the time variable always comes in as the first dimension and the rest defines the dimensions in space basically var da minimizes the cost function j eq 1 based on a decision state variable x e g soil moisture the cost function is a weighted sum of squared distances from the decision state variable to the model background state j b cost function of background as well as the difference between the observed flows and the simulated flows when the model is initialized by x j o cost function of observations distributed over a specific time interval in fact j b component is the resistance of the background state to change penalized by the model background error i e regularization term and j o component penalizes the discrepancy between the model simulations and observations 1 j x 1 2 x x b t b 1 x x b j b 1 2 y h x t r 1 y h x j o where x is the model state x b denotes the background state y is observation h x is the operator that maps the model state x to the observation field b is the background error covariance matrix and r is the observational error covariance matrix b contains information on the reliability of the model background state in different locations and due to lack of observations of state space it is challenging if not impossible to quantify the errors against true states bannister 2008 studies have used ensemble methods or analysis of forecast differences in order to estimate b matrix as in the enkf evensen 2003 hamill et al 2001 finding an optimal solution to minimize cost function of var problems can be computationally expensive particularly due to large number of decision variables and parameters or due to high complexity and strong nonlinearity of hydrologic models thus for var applications mathematical approximations and simplifications are taken into account e g linearizing the state and or observation equations formulation of adjoint models is commonly used in meteorology in order to compute the gradient of the cost function of the controlled state vector yet it is very challenging in hydrologic applications particularly in the presence of strong nonlinearity in the distributed vic lsm coupled with a routing model nevertheless random search gradient search or brute force search i e generate and test methods can be adapted with a simplified version of the var problem to deal with computational limitations 3 3 implementation of var in vic model the goal of this study is to correct the vic model s initial state based on the available streamflow observations and evaluate the resultant improvements in monthly streamflow forecasts to the best of the authors knowledge this is the first effort in enhancing m2s streamflow forecasting through var assimilation of streamflow observations in a lsm hydrologic studies that have employed var technique suggest simplifications of the general cost function to reduce computational expenses and technical complexities in estimating model uncertainty in state space le dimet and talagrand 1986 liu and gupta 2007 lai et al 2014 liu et al 2008 suggested 4dvar using ensemble forecast using which background error has been computed but it is computationally challenging in implementing in a land surface model hence a common approach is to exclude the background error term j b from the general cost function in eq 1 since it has relatively minimal impact on the accuracy of var aided streamflow forecasts especially when the assimilation window is long chao and chang 1992 seo et al 2003 2009 the same approach is utilized here to implement the var da in vic lsm in which the objective is to minimize the cost function solely based on the observational error term within a predetermined assimilation window eq 2 fig 2 shows the schematic of the proposed var da approach soil moisture content is the state variable to be updated in vic lsm prior to each forecasting period i e x t 0 given the tar river basin the overall number of soil moisture elements containing in the vic state file is 804 product of 268 different sub grid vegetation land covers over the 40 grid cells and 3 soil layers running an optimization problem with this number of decision variables is beyond normal computational power thus a constant multiplier k is defined as the single decision variable in var in order to scale the background soil moisture elements in x b for the tar river basin one constant multiplier k was enough but for very large basins with substantially varying land surface and soil conditions one could consider multiple constant multipliers that have same values within the sub watersheds this single adjusting factor also reduces the computational demand of the var da and hence it provides an easy way to correct the initial conditions of the distributed lsm such as the vic model since there is a single adjusting factor applied to all the soil moisture variables the relative spatial variability of the model state would be preserved across the grid cells and layers hence minimizing the change in the background state i e regularization term can be neglected and the j cost function can be revised as 2 j x k j o t aw t 0 y t h t x k t r t 1 y t h t x k where in the above expression x k r 3 268 refers to the analysis state t 0 is the time of forecast t aw is the beginning of the assimilation window y r aw 1 is the vector of observations and h t x k is the simulated flow at time t when vic is initialized with x k r t is the daily observational error computed based on 0 05 of variance of observed daily flows over 62 years 1949 2010 considering the stage discharge relationship herschy 1994 here are the steps taken to implement var da i open loop ol simulation i e control run vic model is implemented with observed meteorological forcings to derive and store background state x b for all the days during study period 1991 2010 ii given a forecast time t 0 and assimilation window aw the model background state x b at t aw is linearly scaled by a k factor to generate the analysis state x k i e x k k x b k 0 2 vic is initialized based on x k and executed during the assimilation window using observed forcings to generate streamflow fluxes h t x k and the cost function j is computed based on streamflow observations this process repeats for all the k values range from 0 to 2 with 0 01 interval to find the minimum cost function and the optimal analysis state x k iii vic is then initialized by x k and executed in order to estimate the corrected state conditions x t 0 at the forecast time which is then used to update the model state the two main parameters in the explained da framework are 1 the length of assimilation window aw and 2 the state update frequency uf also known as da cycles a retrospective application of the var da in vic is performed throughout the study period 1991 2010 using different sets of aw and uf lengths selected from 7 days 10 days 15 days 20 days 1 month and 2 months which is presented in the result section time series of optimal k during 20 years of simulation under different aw and uf lengths are presented in the supplementary material fig s1 3 4 streamflow forecasting developing skillful monthly to seasonal m2s streamflow forecasts depends on two key contributors 1 accurate estimation of initial hydrologic conditions of the basin and 2 the skill of m2s climatic forecasts in this study two forecasting approaches deterministic and probabilistic are employed in order to develop monthly streamflow forecasts and assess the improvements due to var da application for deterministic streamflow forecasting vic model is forced with spatially and temporally downscaled precipitation forecasts from echam4 5 gcm along with daily climatology of temperature and wind speed forcings the echam4 5 forecasts used in this study are monthly updated 1 month ahead forecasts thus for consistency reasons model s initial conditions are updated at the begging of each month i e uf 1 month under forecasting schemes the second approach is probabilistic streamflow forecasting known as ensemble streamflow prediction esp day 1985 wood and lettenmaier 2008 using climatological forcings esp is a traditional forecasting approach in national weather service nws since it allows to estimate the uncertainty in forecasts under the esp scheme vic model is forced with an ensemble of observed meteorological forcings from the historical records over 42 years 1949 1990 prior to the study time frame 1991 2010 for example to develop an ensemble of streamflow forecasts for february 1993 vic is performed 42 times each time using observed meteorological forcings during the february of a single year from 1949 1990 note that vic uses same set of forcings year to year though the esp forecasts are not similar because of different model s initial conditions under both forecasting approaches echam4 5 and esp vic is initialized at the beginning of month either with state conditions from open loop simulation or with corrected state conditions obtained from var da application with different aw lengths the performance of vic streamflow simulations forecasts against observations is evaluated through different measures nash sutcliffe efficiency nse score kling gupta efficiency kge score relative root mean square error r rmse spearman s rank correlation coefficient and bias are computed for deterministic streamflow forecasts nash and sutcliffe 1970 gupta et al 2009 these verification metrics are also used in order to assess the overall performance of the esp scheme based on the ensemble mean however the added value of conducting the esp scheme is that it allows to quantify the forecasting skill for specific flow categories such as below normal bn or above normal an flows in this regard brier score and its decomposed components reliability resolution and uncertainty are computed to evaluate the esp probabilistic forecasts brier 1950 weigel et al 2007 further description of the evaluation metrics is given as appendix a 4 results 4 1 vic model performance daily flow predictions for the tar river basin were obtained by running the vic and routing models in an open loop scheme during the period 1988 2010 the first three years of simulations i e 1988 1990 are ignored as the model spin up period and the remaining twenty years are evaluated by comparing with the observed monthly flows at the tarboro usgs station table 1 summarizes the performance of the vic lsm in simulating monthly streamflows computed from daily vic outputs over the period 1991 2010 the overall nse during validation period is 0 75 the monthly nse and r rmse values suggest that the model is well calibrated for spring and summer seasons while it performs poorly during november january months low values of nse during these months are primarily due to the increased bias in the winter months which primarily arises from the inability of the model in predicting high winter flows thereby resulting in increased bias the monthly correlation coefficients are statistically significant i e greater than 1 96 n 3 where n 20 years for a given month steel and torrie 1960 which suggests the modeled flows capture the variability in observed flows but r rmse and bias metrics indicate that the error in predictions are relatively higher particularly during high flow seasons i e winter as the model exhibits positive bias indicating overestimation of observed flows we are not performing any bias correction of monthly flows as we wanted to quantify the improvements from var da without bias correction 4 2 role of var da in improving streamflow simulation as described in section 3 3 we performed multiple experiments in which vic model state conditions are corrected with different frequencies uf by assimilating a range of past streamflow observations aw these are the two key parameters that determine the strength of var da framework the skill of var aided streamflow simulations are then quantified based on the observed flows and are compared to the skill of the open loop streamflow simulation fig 3 shows a sample time series from a var da experiment with uf 15 days and aw 10 days along with the open loop simulation and the streamflow observations here the term simulation aka perfect forecast indicates that the hydrologic model is fed with all observed meteorological forcings fig 4 displays the difference between the kge score from var implemented simulations and the ol simulation the statistics shown in this figure are computed by using daily flows first row and mean monthly flows second row further detailed analyses of var da impact on low flows flows lesser than 10th percentile of the climatology and high flows flows greater than 90th percentile of the climatology are included in all experiments var da predictions are enhanced compared to the open loop simulation specifically for shorter assimilation windows of 7 15 days and update frequencies of 10 30 days on average kge of the predictions during the entire 20 years of study time frame is increased by about 0 3 which results in a kge score greater than 0 8 for both daily and monthly flow analyses skill of vic in predicting low flows are particularly lower than normal possibly due to the bias in model calibration however the strongest improvement from var da is found in low flow predictions in terms of kge nse metric is not used to determine the effect of var da in low high flow analyses since it is sensitive to extreme flow conditions on the other hand the least improvements are found when a long assimilation window is considered for example in the case of aw 60 days the initial conditions of the simulations are updated by incorporating past 2 months of daily streamflow observations which is beyond the residence time of basin and memory of the soil a longer aw also results in smoother changes in the scaling factor k because it behaves as a moving average window with a long bandwidth and overlaps between the past and future iterations are existing so minimal variations in the var implemented predictions are expected in addition updating model state conditions in shorter cycles i e higher frequencies does not necessarily result in significant improvements since soil state conditions might not have changed much over short cycles 4 3 role of var da in improving streamflow forecasts to assess the impact of var da in real time forecasting streamflow forecasts are developed using 1 month ahead precipitation forecasts from echam4 5 gcm or through the esp approach using precipitation climatology under each scheme vic model is initialized with state conditions from the open loop simulation and with the corrected state conditions from the var da framework prior to the forecast issue time fig 5 shows a sample timeseries of monthly streamflow forecasts developed under the mentioned scenarios comparison between these plots highlights the positive effect of var da application in streamflow forecasting in which correcting the initial conditions aids to keep the model on the observation track for instance over the period 2007 2009 the streamflow forecasts initialized with prior states from open loop simulations fig 5a start to drift apart from the streamflow observations while this divergence is minimized after correcting state conditions through var da also the same behavior is repeated in the case of esp forecasting in which the var aided ensemble forecast is shifted towards the observations and the ensemble spread is narrowed indicating the uncertainty reduction the skill in deterministic monthly streamflow forecasting from echam4 5 climate forecasts and ensemble mean from esp forecasting approach is summarized in table 2 along with the performance of the var aided forecasts note that this overall performance is average of the statistics across all the experiments with different aw lengths additional information is provided as supplementary material similarly the impact of var da on the skill of probabilistic forecasting using esp approach is assessed particularly for below normal bn below 33rd percentile climatology of observed monthly flows in a given month and above normal an above 67th percentile climatology of observed monthly flows in a given month streamflow months table 3 the presented performance of da implemented model is summarized by taking the average of the verification metrics across schemes with different aws where detailed statistics are given as supplementary material fig s2 results suggest that on average var da implementation is significantly effective in improving streamflow forecasts especially in reducing the forecast bias in general the var da framework enhances the skill in deterministic streamflow forecasting by 0 08 in terms of nse and 0 02 in terms of kge moreover the application of var da reduces the brier score by approximately 0 04 in bn and 0 02 in an months respectively this improved brier score is due to a slight improvement in resolution but mostly is related to the enhancement of the reliability score which can be interpreted as bias reduction in a probabilistic forecast in contrast to simulation scheme section 4 2 under forecasting experiment it is found that selecting a longer aw such as 15 20 days results in the largest improvement in the forecasting skill considering all the verification metrics detailed statistics are provided as supplementary material fig s2 however in the case of probabilistic forecasting assimilating a shorter window e g 7 15 days has the most positive impact as opposed to larger windows monthly statistical analysis results are not shown suggest that da improves forecasting skill mostly during fall and winter seasons compared to spring and summer seasons this is expected since the skill of streamflow forecasting over the southeast is particularly governed by soil moisture conditions rather than model forcings during wet seasons mahanama et al 2012 sinha and sankarasubramanian 2013 it is also notable that the improvements due to var da in the simulation schemes fig 4 is much larger than that of the forecasting schemes under the simulation scheme since vic model is fed with the observed meteorological forcings the role of forcing error is minimized and thus the skill difference between ol and da experiments is totally inherited from the corrected initial conditions on the other hand in the forecasting scheme the imprecision of forcings dominates the forecasting skill thus the improvements are found to be smaller and approximately similar across different aw lengths 4 4 impact of var da over forecast lead time to assess the contribution of corrected model initial conditions over sub monthly lead times the improvements due to var da δ kge kge da kge ol are computed for vic daily predictions fig 6 this analysis is conducted for both streamflow simulation and forecasting schemes in which var da is implemented at the beginning of each month i e uf 1 month and vic model is performed for a month ahead for example the effect of var da on 7 day ahead streamflow simulation in fig 6a is assessed by first averaging the simulated flows over the 1st day to the 7th day of each month i e resampling sub monthly flows and then quantifying δ kge throughout the entire study period 1991 2010 evidently the computed statistics for 30 day ahead streamflow simulations and forecasts in this figure should match our findings in fig 4 and table 2 respectively it is found that the positive effect of var da application increases in short range lead times up to 8 days from the forecast issue time meaning that the 8 day ahead streamflow simulation forecasting benefits the most from corrected state conditions for longer lead times the curves follow an approximately level pattern inferring that there is no additional contribution from the corrected state conditions on the other hand under the forecasting scheme fig 6b the arose improvements start to decline beyond the 8th day primarily due to the imprecision in the utilized precipitation forecasts it also indicates the domination of forcing errors over corrected initial conditions where the curves approaches back to zero nevertheless δ kge still remains positive even with long lead times indicating the net positive effect of da in monthly streamflow forecasting the overall time lag for the improvements to reach the peak can also be interpreted as a basin characteristic e g the time lag in the corrected soil moisture conditions to show its effect at the basin outlet thus it is expected to have earlier peak times for smaller basins also this analysis suggests that for a short range medium range forecasting it is better to use shorter longer assimilation windows 5 discussion and concluding remarks most hydrologic da studies employ sequential da for correcting initial conditions in hydrologic simulations further most da efforts have demonstrated the potential of assimilating remotely sensed observations while fewer studies have exploited ground based observations such as streamflow records in model state conditions towards this we proposed a scheme that applies var da in vic lsm in order to correct the initial conditions based on gauge measured streamflow observations and quantified the associated improvements in 1 month ahead streamflow forecast over a 20 year period 1991 2010 for the tar river basin the two key parameters in our var da framework are update frequency uf and assimilation window aw where the former determines the period between each da application i e da cycles and the latter specifies the length of past daily observations to be considered in da in order to examine the sensitivity of the proposed var da framework to these parameters totally 36 experiments were conducted and analyzed using different combinations of ufs and aws selected from a discrete set of time intervals ranges from 7 days to 2 months comparison of simulated streamflows i e using observed forcings to implement the vic lsm between open loop ol and da coupled experiments suggests that the var da application is successful in enhancing the streamflow modeling better performance of var da is found when a 7 day aw is selected with the uf around 20 days 7 days aw is more effective since it considers the recent information for updating the initial conditions this finding is consistent with other studies that show that weekly assimilation cycle is relevant for hydrological prediction with var da approach abbaszadeh et al 2019 thiboult and anctil 2015 given that the tar river basin is a rainfall runoff regime with uniform rainfall throughout the year the role of initial conditions is continuously changing with limited basin memory however the optimal uf is found longer e g 15 20 days and it is expected to be dependent on specific basin characteristics such as drainage area hydraulic conductivity and aridity of the basin the impact of var da on monthly streamflow forecasting through two different approaches based on climate forecasts and ensemble climatological forcings i e esp is also evaluated climate information based streamflow forecasts are developed by feeding the vic model with spatially downscaled and temporally disaggregated monthly precipitation forecasts from echam4 5 gcm the esp approach a probabilistic forecast uses an ensemble of climatological forcings based on the historical precipitation observations from 1949 to 1990 to implement the vic lsm the ensemble mean of esp forecasts is also computed and evaluated as a deterministic streamflow forecast for comparison with the echam4 5 approach assessing the var aided deterministic forecasts reveals that var da improves the skill of monthly forecasting by increasing nse metric by 0 08 and kge metric by 0 02 on average moreover it significantly decreases the bias in deterministic forecasts and the brier score in the probabilistic forecasts one key implication of these analyses is the reduced dependence of vic simulation forecast on bias correction techniques as var da addresses bias correction by improving the initial state conditions in advance when comparing the skill under simulation and 1 month ahead forecast it was noticed that the magnitude of improvements are considerably different indicating that the accuracy of climatic forcing dominates over the improved initial conditions considering this we examined the contribution of corrected initial conditions in daily streamflow predictions within the month it was found that the effectiveness of corrected initial conditions lasts for 7 8 days ahead from the forecast issue time and beyond that the accuracy of climatic forcings controls the skill in streamflow forecasts this indicates improvements from var da is only for a weekly period as the basin gets controlled more by the climate for the remaining period within the month this is because tar river basin is a rainfall runoff regime with no seasonality in rainfall thereby the basin s initial condition has limited memory in improving the skill of monthly streamflow forecast although it is debated that the application of var da methods are simpler than sequential da in hydrology but rendering a comprehensive var optimization problem for a distributed hydrologic model is very difficult and computationally intensive most of the var da studies often use numerical approximation algorithms or develop adjoint models to alleviate the optimization problem developing these algorithms also poses unique challenges because of non linearity in hydrologic systems in addition accurate estimation of the model background error covariance is challenging and usually it is obtained through an ensemble approach in which the model is executed with a set of perturbed observed forcings liu et al 2008 given this the complexity of da problem in this study is simplified to a 1 d problem by identifying one decision variable i e a multiplier factor that adjusts the model background soil moisture contents in different grid cells and in different soil layers over the selected basin since the analysis state is derived by scaling the background state in a uniform manner the spatial covariance in soil moisture is preserved this makes the cost function of background j b to heavily penalize any changes in the background state thus this term was excluded from the general var formulation and the observational cost function was exclusively considered it is shown that var da could be beneficial in improving m2s streamflow forecasts with the improvements primarily happening over the 7 8 daily streamflow data assimilation applications can be used not only for better state estimation but also to enhance parameter estimation or even improve model forcings in a combined approach seo et al 2003 moradkhani et al 2005 moreover data assimilation techniques are sometimes criticized for violating the water mass balance assumption in the hydrologic model hence its potential benefit in removing the bias and improving the model product is often undervalued in this context it is rational to quantify the effect of da in the absence of model bias with the intention of applying bias correction as well as quantifying the sole role of da in hydrologic forecasting a recursive bias estimation should be coupled into the da framework at each iteration resulting in a two stage estimation algorithm but this significantly increases the computational cost friedland 1969 dee and da silva 1998 in the presence of a high bias in the predicted flows da application is more successful in improving the prediction skill i e a better calibrated model decreases the positive role of var da our previous studies have shown that calibrating models based on flow conditions tends to improve the model performance li and sankarasubramanian 2012 yapo et al 1996 sinha and sankarasubramanian 2013 thus if we explicitly consider bias correction as part of model calibration the positive role of var da will be reduced majority of hydrologic da studies are focused on short term streamflow forecasting ranges from hourly to maximum few days but this study focused on m2s streamflow forecasting which provides critical information for water supply planning for real time streamflow forecasting the non linearity embedded in the hydrologic model and high dimensionality of the model initial conditions i e soil and groundwater storage poses technical complexities in da problem particularly increased computational cost in a distributed model our study showed that a simplified version of var da is overall beneficial in improving the forecast for below normal and above normal months but da also degrades the model predictions in certain months thus it is important to assess and quantify the negative effects of da and attribute those sources of errors to other issues such as model uncertainty and parameter estimation the tar river basin is selected as the case study since our previous studies have evaluated the role of climate forecasts in developing streamflow forecast in a rainfall runoff regime sinha and sankarasubramanian 2013 mazrooei et al 2015 one potential challenge of the proposed var da approach is in the application of our methodology in larger river basins since we are using downstream observed streamflow data in correcting the initial conditions of a distributed hydrologic model application of var da in large basins may have to consider streamflow with different lags another approach is to consider multiple sub basins within the large basin so that a spatially varying multiplier factors could be considered by assimilating streamflow information from multiple gauges within the large basin this essentially converts the var framework to a 3 d problem and be applied to each station grid cell within the basin in these conditions multiple streamflow observations could be considered with spatially varying k multiplier with the k to be correlated across space alternately this fits within a bayesian framework by assuming a prior distribution on k which could be used to update k simultaneously across the space to obtain the posterior distribution of the constant multiplier across the watershed that maximizes the joint likelihood of streamflow observations across the watershed moreover our varda framework is simplified to a 1 d problem along with excluding model background error term as it has a minimal impact on the var aided hydrologic forecasts liu and gupta 2007 seo et al 2003 here we apply a single k multiplier to adjust the sm contents and minimize the observational error term j o in case of including the background error term j b matrix b could be computed as the variance of vic lsm s sm simulations in an ensemble mode e g by executing vic lsm with perturbed observed forcings also one could consider the spatial varying background sm values x b across all the grid cells as the decision variables in the var da optimization problem however this significantly increases the computational demand of the analysis these are potential opportunities for future study focusing on improving var da using observed in situ information for correcting initial conditions of a distributed hydrologic model credit authorship contribution statement amir mazrooei investigation methodology data curation writing original draft a sankarasubramanian supervision validation funding acquisition writing review editing andrew w wood investigation formal analysis validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by national science foundation grants cbet 0954405 cbet 1204368 and ccf 1442909 we would like to thank the university corporation for atmospheric research ucar advanced studies program asp as well as national center for atmospheric research ncar for providing high performance computing support for this project yellowstone 2012 we are also thankful to the anonymous reviewers for their insightful comments appendix a evaluation metrics nash sutcliffe efficiency nse score is derived by taking the average of the squared differences between the modeled q t vic and observed flows q t obs normalized by the variance of the observed flows eq a 1 nse ranges between 1 i e perfect fit and whereas nse 0 means that the model is no better than the mean of observations as a predictor since nse is quantified using squared differences the model skill tends to be overestimated during low flows and underestimated during high flows hence nse is not suggested to use it as a verification metric for low flow and high flow predictions thus for extreme flow analyses kling gupta efficiency kge score is preferred which simultaneously accounts for correlation coefficient mean bias and relative variability in the predictions and observations eq a 2 kge also ranges between 1 to with 1 denoting a perfect prediction to further diagnose the model performance relative root mean square error r rmse eq a 3 spearman s rank correlation and bias metrics eq a 4 are also included a 1 nse 1 t 1 n q t vic q t obs 2 t 1 n q t obs q obs 2 a 2 kge 1 r 1 2 σ vic σ obs 1 2 q vic q obs 1 2 a 3 r rmse 1 n t 1 n q t vic q t obs 2 q obs a 4 bias 1 n t 1 n q t vic q t obs q t obs 100 for probabilistic forecasts we employed brier score bs eq a 5 as the verification metric and its decomposed components such as reliability eqn a 6 and resolution eq a 7 which provide a better insight into different aspects of forecast quality brier 1950 weigel et al 2007 basically the reliability metric rel represents the bias in the probabilistic forecasts a reliable forecaster has rel 0 and the resolution metric res indicates how much climatic uncertainty is explained in the forecast higher res infers a better forecaster wilks 2011 the first step to measure bs is to compute probabilistic forecast p t for a predefined category from esp runs for example for bn events the probabilistic forecast is quantified as the number of ensemble members with the forecasted streamflow below the 33rd percentile of streamflow climatology of the basin i e q q obs 33 rd then bs rel and res metrics can be measured based on following equations a 5 bs 1 n t 1 n p t y t 2 a 6 rel d 1 d n d n o d n d p d 2 a 7 res d 1 d n d n o d n d o 2 where n is the total number of forecasts y t is the observation transformed to a binary scale i e y t is 1 if the event happened and 0 otherwise d denotes the number of distinct forecast probabilities issued i e p t p 1 p d n d is the number of forecasts lies in the dth category o d is the total number of observed events when the dth forecast was issued and o is the climatological event frequency appendix b supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2021 126559 appendix b supplementary data the following are the supplementary data to this article supplementary material data profile 
4419,uncertainties associated with the initial conditions e g soil moisture content of a hydrologic model have been recognized as one of the main sources of errors in hydrologic predictions recent advances in sequential data assimilation da and variational da var da have focused on correcting these initial conditions for improving hydrologic predictions this study proposes a var da methodology that considers a basin wide single scaling correction factor for updating the soil moisture content of variable infiltration capacity vic land surface model lsm by assimilating gauge observed streamflow this simplified scaling factor reduces the computational demand of the var da in updating the soil moisture conditions of vic the proposed var da scheme is demonstrated in tar river basin in nc a rainfall runoff dominated watershed for improving monthly streamflow simulations and forecasting over a 20 year period 1991 2010 the role of two critical parameters of var da the update frequency the interval between da applications and the length of assimilation window in determining the skill of da improved streamflow predictions is also assessed we found that correcting vic model s initial conditions using a 7 day assimilation window results in the highest improvement in the skill of streamflow predictions quantified by kling gupta efficiency kge and nash sutcliffe efficiency nse metrics in addition the potential gain from var da framework is quantified and compared under two 1 month ahead streamflow forecasting schemes 1 var da corrected initial conditions of vic forced with echam4 5 gcm 1 month ahead precipitation forecasts and 2 ensemble streamflow prediction esp approach this study also examines the persistence of the da in improving monthly streamflow predictions by quantifying the enhanced accuracy in daily flows over extended forecast lead time blocks analyses show that the corrected initial state conditions continually enhance the 7 8 days ahead streamflow predictions but after that the errors in forcings dominate the da effects overall the application of proposed var da scheme results in improved monthly streamflow forecasting due to correcting initial conditions keywords variational data assimilation forecasting land surface model streamflow climate variability 1 introduction reliable monthly to seasonal m2s streamflow forecasting provides critical information for water system planning and management e g crop management such forecasts also facilitate the allocation of water supplies to different water users e g domestic agricultural etc and to meet environmental demands hamlet and lettenmaier 1999 wood et al 2002 devineni et al 2008 mcinerney et al 2020 over the past decades several strides have been made in m2s streamflow forecasting by utilizing climate forecasts from general circulation models gcms with watershed models schaake et al 2006 mazrooei et al 2015 ahmadalipour et al 2017 recently efforts have also focused on improving the skill of subseasonal to seasonal streamflow forecasting monhart et al 2019 li et al 2019 mcinerney et al 2020 quedi and fan 2020 which typically focuses on a lead time of 15 days to 90 days capturing on the intra seasonal variability of the atmosphere e g madden julian oscillation although several sources of uncertainty in streamflow forecasting have been identified e g uncertainty in model structure and model parameters inaccurate initial hydrologic conditions imprecise hydrometeorological forcings addressing such inherent uncertainties in the context of real time streamflow forecasting approaches have remained a long standing problem ajami et al 2007 salamon and feyen 2010 li et al 2019 hence systematic reduction of uncertainties from multiple sources provide an opportunity for enhancing the accuracy and reliability of hydrologic forecasts liu et al 2012 pappenberger et al 2011 sankarasubramanian et al 2009 li et al 2014 since rainfall is the major contributor to streamflow variability uncertainty in rainfall forecasts remains as the key source of uncertainty in m2s streamflow forecasting particularly for basins under rainfall runoff regime li et al 2009 mazrooei et al 2015 hence under rainfall runoff regime limited skill in precipitation forecasting is a determining factor for the skill of m2s streamflow forecasting but improving watershed model s initial conditions could overcome the limited skill of precipitation forecast and further improve streamflow forecast in rainfall runoff regimes mahanama et al 2012 thus correcting model s initial conditions using data assimilation techniques and forcing the model with m2s climate forecasts provide opportunities for improving m2s streamflow forecasting in rainfall runoff regimes mazrooei and sankarasubramanian 2019 data assimilation da is an effective methodology that is able to reduce the errors in model state variables and parameters and consequently improves the model predictability the basic idea behind da is to optimally combine the information from model predictions and available observations to correct the model initial conditions da have been widely applied in oceanography and atmospheric sciences especially in operational weather forecasting and its effectiveness has been well demonstrated furthermore considerable advances in the theoretical development of da techniques in hydrology have been proposed from simple direct insertion methods to complex sequential and smoothing filtering methods kumar et al 2009 dechant and moradkhani 2012 wang and cai 2008 aubert et al 2003 kumar et al 2014 yet its application in hydrologic studies on real time forecasting is at its infancy liu et al 2012 of these methods sequential da such as extended kalman filter ekf or ensemble kalman filter enkf is one of the earliest and commonly used methods that has been explored in hydrological studies moradkhani et al 2005 reichle et al 2008 clark et al 2008 the main limitation on the application of sequential da in distributed hydrologic models stems from the requirement of state space reformulation of model in a gridded form along with the substantial demand of the computational power arising from ensemble simulations mitchell et al 2004 alternatively variational data assimilation var da is a potentially simpler method as opposed to sequential da jazwinski 2007 var da is a commonly used technique in global atmospheric assimilation schemes for operational meteorological forecasting yet it has not been fully exploited in hydrological studies ide et al 1997 li and navon 2001 liu et al 2012 in spite of substantial research on hydrologic da limited number of studies have focused on var da formulation and application and also in quantifying its utility in m2s hydrologic forecasting for example seo et al 2003 employed var da to assimilate streamflow and precipitation observations for improving operational hydrological forecasting at short lead times they employed var da in a lumped watershed model sacramento model and found that it significantly improves the accuracy of 40 h ahead streamflow forecasts over few selected basins in the united states since sacramento model is commonly used in operational streamflow forecasts they also suggested var da in comparison to other da techniques is more suitable for real time forecasting since it requires less computational demand rüdiger et al 2006 employed var da coupled with the catchment land surface model clsm in order to assimilate observed streamflow and assessed the direct improvements in initial soil moisture states over three catchments in australia however the entire study is a synthetic study where observed forcings were used in improving streamflow and latent heat flux predictions thus there is potential for improving var da schemes for application in streamflow predictions the abundance of hydrologic observations collected over last decades from in situ measurements and satellite remote sensing has motivated the need to integrate them into da techniques for improving hydrologic predictions accordingly potential for da applications has increased due to availability of remotely sensed data of soil moisture and snow cover area extent from satellite observations in recent years pauwels et al 2001 andreadis and lettenmaier 2006 kumar et al 2016 clark et al 2008 reichle et al 2008 liu and mishra 2017 remotely sensed soil moisture conditions provides estimation of initial hydrologic conditions over a large spatial scale thus could be utilized in regional and continental da studies but they are available only for the past 10 20 years on the other hand historical in situ observations such as gauge measured streamflow records are available for a much longer period of time and contain substantially lower measurement errors compared to satellite observations loew et al 2017 ford and quiring 2019 swenson et al 2006 rüdiger et al 2006 showed that assimilating streamflow reduces the error in correcting the initial conditions as opposed to the soil moisture conditions using a synthetic setup since streamflow is an integrator of spatial variability in basin conditions and forcings hence assimilating gauge measured streamflow using var da provides a great opportunity to correct model s initial conditions and consequently can improve hydrologic predictions seo et al 2003 2009 vrugt et al 2005 clark et al 2008 moradkhani and sorooshian 2008 given that utilizing observed streamflow in da applications better reduces the errors in the initial conditions as opposed to soil moisture observations rüdiger et al 2006 the availability of long term streamflow observations at gauge and the ability of var da in assimilating point observations over gridded initial conditions in real time streamflow forecasting as opposed to sequential da methods seo et al 2003 we consider var da in this study for assimilating observed streamflow information into the variable infiltration capacity vic land surface model lsm the motivation of this study is to assess the utility of var da in improving vic lsm monthly streamflow forecasts through two forecasting approaches 1 using month ahead climate forecasts from a gcm and 2 probabilistic streamflow forecasting known as ensemble streamflow prediction esp that considers ensemble of initial conditions with climatological forcings past da studies have considered either a conceptual hydrologic model or a distributed model along with observed forcings for evaluating the utility of da in improving hydrologic simulations aka predictions or for short range forecasting lead times i e hourly to maximum weekly rather than m2s streamflow forecasting recently mazrooei and sankarasubramanian 2019 analyzed the improved skill of 1 month ahead streamflow forecasts over rainfall dominated basins across the united states by correcting the initial conditions of a conceptual hydrologic model using enkf but the application of enkf to a distributed hydrological model is computationally intensive due to ensemble executions furthermore vic a gridded lsm is selected in which more complex modeling components such as interactions between land surface and atmosphere vegetation dynamics soil temperature and streamflow response are explicitly incorporated with finer modelling time steps to better estimate land surface fluxes cox et al 2000 feddema et al 2005 bonan and levis 2006 zeng 2010 the challenge in coupling var da and vic lsm is in incorporating the error in point measurements i e observed streamflow at gauge to correct the initial conditions of the gridded vic states to the best of our knowledge there are limited efforts on assessing the application of var da using in situ streamflow observations in correcting vic lsm initial conditions and quantifying the resultant improvements in m2s streamflow forecasts here we propose a var da methodology that minimizes the errors in predicting the observed streamflow by correcting the spatially varying vic model s initial conditions thus the objectives of the study are a develop a var da methodology for assimilating observed streamflows to correct initial conditions and b assess the utility of var da in improving the monthly streamflow forecasts from vic which is forced with monthly climate forecasts our hypothesis here is that addressing the two sources of uncertainty correcting initial conditions and utilizing month ahead climate forecasts from gcm will provide us with improved monthly streamflow forecasts particularly for months with limited skill in climate forecasts e g summer season for months with significant skill in climate forecasts arose from enso conditions e g winter months we expect forcing vic with downscaled climate forecasts and corrected initial conditions using the proposed var da scheme could result in improved monthly streamflow skill this manuscript is organized as follows section 2 provides details about the used hydroclimatic data and study domain section 3 presents the candidate model var da approach and its implementation lastly section 4 presents the results of all the experiments followed by a discussion in section 5 2 study area and data 2 1 tar river basin all model simulations are executed over tar river basin fig 1 a rainfall dominated river basin located in north carolina state the selected study area is part of tar pamlico river basin which consists of two sub basins tar river headwaters huc03020101 and fishing watershed huc03020102 the total drainage area of this domain is 5654 square kilometers and the basin has experienced several flood events due to various hurricanes such as fran 1996 floyd 1999 and isabel 2003 daily streamflow from this basin also provides fresh water input to the tar pamlico estuary 2 2 streamflow observations daily observed streamflow data for the period 1949 2010 is obtained from the us geological survey usgs at tar river at tarboro usgs 02083500 this site is classified as one of the natural basins in us and is included in the hydro climatic data network hcdn slack et al 1993 database since it receives minimal influence from anthropogenic impacts such as upstream reservoir and groundwater pumping fig 1 also shows the seasonality of the observed flows for the tar river basin typically the basin experiences high flow season during winter jfm when 53 of the annual flow occurs and the low flows occur during summer jas with only 9 contribution to the mean annual flow 2 3 observed meteorological forcings observed meteorological data is obtained from maurer et al 2002 dataset in order to set up the hydrologic model this data is derived by interpolating the weather gauge observations across the country and it is available at 1 8 150 km2 cell area spatial resolution at daily time scale from january 1949 till december 2010 the meteorological time series are used as the model forcings including daily precipitation mm day maximum and minimum daily temperatures c and average 10 meter wind speed m s these four variables are the minimum set of variables required by the hydrologic model in this study section 3 1 in order to estimate terrestrial fluxes other forcing variables are also required by the hydrologic model which are described in section 3 1 2 4 echam4 5 precipitation forecasts streamflow forecasting using a land surface model has two steps a updating the initial conditions of the model and b forcing the model with atmospheric conditions i e mainly precipitation and temperature for the forecasting period so for step b one has to use either a gcm or a regional climate model to get the precipitation and temperature forecast we use climate forecasts from the echam4 5 general circulation model gcm developed by the max planck institute available from the international research institute of climate and society iri data library li and goddard 2005 for forcing the vic model the echam4 5 precipitation forecasts are available at monthly time scale and 2 8 spatial resolution including 24 ensemble members up to 7 month lead time constructed analogue sea surface temperature sst forecasts with 7 month lead time were forced with echam4 5 atmospheric gcm to develop climate forecasts these 7 month ahead climate forecasts from echam4 5 are developed retrospectively for every month from 1957 and it is also one of the atmospheric gcms currently used for climate forecasting at iri for this study we utilize only one month ahead precipitation forecast for developing streamflow forecast for the tar river basin several studies have successfully applied echam4 5 gcm retrospective forecasts for evaluating streamflow forecasting mazrooei et al 2015 sinha and sankarasubramanian 2012 and for data assimilation li et al 2016 since vic model accepts forcing with a finer spatio temporal resolution echam4 5 precipitation forecasts are spatially downscaled to 1 8 resolution and temporally disaggregated from monthly to daily time step for spatial downscaling at a given location a principal component regression pcr model is developed between the ensemble mean of the overlying 2 8 monthly precipitation forecasts and the monthly observed precipitation at 1 8 resolution pcr model is then trained for a given month during the period 1957 1990 and the downscaled monthly forecasts are modeled for the period 1991 2010 next a temporal disaggregation technique based on a k nn algorithm prairie et al 2007 is employed in order to resample daily precipitation forecasts from the downscaled monthly forecasts detailed performance of the k nn disaggregation algorithm is summarized in our previous studies sinha and sankarasubramanian 2013 further explanation of the spatial downscaling and temporal disaggregation schemes as well as the skill of downscaled precipitation forecasts can be found in mazrooei et al 2015 and mazrooei 2017 3 methodology 3 1 hydrologic model the selected hydrologic model in this study is consisted of two components 1 variable infiltration capacity vic wood et al 1992 liang et al 1994 liang et al 1996 model is executed which is a semi distributed physically based land surface model capable of simulating runoff and other terrestrial variables for a set of grid cells independently and 2 a routing model lohmann et al 1996 lohmann et al 1998 is then performed to transport surface runoff and baseflow from each grid cell to the river system and eventually estimate the total streamflow at the basin outlet here vic model is performed in 3 h time steps with 3 soil layers over 40 grid cells of the river basin fig 1 the direct runoff is quantified as the excess water from saturation and infiltration at the top two soil layers and the baseflow is derived from the bottom soil layer using a generalized version of the arno model franchini and pacciani 1991 vic model is manually calibrated for the tar river basin using 40 years of data 1951 1990 by minimizing root mean square error rmse between simulated and observed flows sinha and sankarasubramanian 2013 the parameters considered in the calibration process are listed as maximum soil moisture content infiltration shape parameter evapotranspiration parameter and baseflow parameter li et al 2016 vic model is typically implemented with daily meteorological forcings and evenly divides the daily totals into sub daily values to run at the model timestep other than those variables vic model also estimates forcings such as air pressure relative humidity incoming radiations etc through various complex algorithms kimball et al 1997 thornton and running 1999 bras 1990 subsequently after vic simulations runoff and baseflow fluxes are routed to the edge of each grid cell through the river network based on lohmann et al 1996 routing model using couple of input files containing information of each grid cell s flow direction flow velocity and unit hydrograph derived from delineating the watershed 3 2 variational data assimilation variational data assimilation var da methods are smoothers that seeks optimal initial conditions so that the model prediction best fits the observation within a user specified assimilation window in addition depending on the hydrologic problem the var technique can be utilized as one dimensional i e 1d var considering lumped catchment scale or taking multiple spatial dimensions into account e g 3d var 4d var where the time variable always comes in as the first dimension and the rest defines the dimensions in space basically var da minimizes the cost function j eq 1 based on a decision state variable x e g soil moisture the cost function is a weighted sum of squared distances from the decision state variable to the model background state j b cost function of background as well as the difference between the observed flows and the simulated flows when the model is initialized by x j o cost function of observations distributed over a specific time interval in fact j b component is the resistance of the background state to change penalized by the model background error i e regularization term and j o component penalizes the discrepancy between the model simulations and observations 1 j x 1 2 x x b t b 1 x x b j b 1 2 y h x t r 1 y h x j o where x is the model state x b denotes the background state y is observation h x is the operator that maps the model state x to the observation field b is the background error covariance matrix and r is the observational error covariance matrix b contains information on the reliability of the model background state in different locations and due to lack of observations of state space it is challenging if not impossible to quantify the errors against true states bannister 2008 studies have used ensemble methods or analysis of forecast differences in order to estimate b matrix as in the enkf evensen 2003 hamill et al 2001 finding an optimal solution to minimize cost function of var problems can be computationally expensive particularly due to large number of decision variables and parameters or due to high complexity and strong nonlinearity of hydrologic models thus for var applications mathematical approximations and simplifications are taken into account e g linearizing the state and or observation equations formulation of adjoint models is commonly used in meteorology in order to compute the gradient of the cost function of the controlled state vector yet it is very challenging in hydrologic applications particularly in the presence of strong nonlinearity in the distributed vic lsm coupled with a routing model nevertheless random search gradient search or brute force search i e generate and test methods can be adapted with a simplified version of the var problem to deal with computational limitations 3 3 implementation of var in vic model the goal of this study is to correct the vic model s initial state based on the available streamflow observations and evaluate the resultant improvements in monthly streamflow forecasts to the best of the authors knowledge this is the first effort in enhancing m2s streamflow forecasting through var assimilation of streamflow observations in a lsm hydrologic studies that have employed var technique suggest simplifications of the general cost function to reduce computational expenses and technical complexities in estimating model uncertainty in state space le dimet and talagrand 1986 liu and gupta 2007 lai et al 2014 liu et al 2008 suggested 4dvar using ensemble forecast using which background error has been computed but it is computationally challenging in implementing in a land surface model hence a common approach is to exclude the background error term j b from the general cost function in eq 1 since it has relatively minimal impact on the accuracy of var aided streamflow forecasts especially when the assimilation window is long chao and chang 1992 seo et al 2003 2009 the same approach is utilized here to implement the var da in vic lsm in which the objective is to minimize the cost function solely based on the observational error term within a predetermined assimilation window eq 2 fig 2 shows the schematic of the proposed var da approach soil moisture content is the state variable to be updated in vic lsm prior to each forecasting period i e x t 0 given the tar river basin the overall number of soil moisture elements containing in the vic state file is 804 product of 268 different sub grid vegetation land covers over the 40 grid cells and 3 soil layers running an optimization problem with this number of decision variables is beyond normal computational power thus a constant multiplier k is defined as the single decision variable in var in order to scale the background soil moisture elements in x b for the tar river basin one constant multiplier k was enough but for very large basins with substantially varying land surface and soil conditions one could consider multiple constant multipliers that have same values within the sub watersheds this single adjusting factor also reduces the computational demand of the var da and hence it provides an easy way to correct the initial conditions of the distributed lsm such as the vic model since there is a single adjusting factor applied to all the soil moisture variables the relative spatial variability of the model state would be preserved across the grid cells and layers hence minimizing the change in the background state i e regularization term can be neglected and the j cost function can be revised as 2 j x k j o t aw t 0 y t h t x k t r t 1 y t h t x k where in the above expression x k r 3 268 refers to the analysis state t 0 is the time of forecast t aw is the beginning of the assimilation window y r aw 1 is the vector of observations and h t x k is the simulated flow at time t when vic is initialized with x k r t is the daily observational error computed based on 0 05 of variance of observed daily flows over 62 years 1949 2010 considering the stage discharge relationship herschy 1994 here are the steps taken to implement var da i open loop ol simulation i e control run vic model is implemented with observed meteorological forcings to derive and store background state x b for all the days during study period 1991 2010 ii given a forecast time t 0 and assimilation window aw the model background state x b at t aw is linearly scaled by a k factor to generate the analysis state x k i e x k k x b k 0 2 vic is initialized based on x k and executed during the assimilation window using observed forcings to generate streamflow fluxes h t x k and the cost function j is computed based on streamflow observations this process repeats for all the k values range from 0 to 2 with 0 01 interval to find the minimum cost function and the optimal analysis state x k iii vic is then initialized by x k and executed in order to estimate the corrected state conditions x t 0 at the forecast time which is then used to update the model state the two main parameters in the explained da framework are 1 the length of assimilation window aw and 2 the state update frequency uf also known as da cycles a retrospective application of the var da in vic is performed throughout the study period 1991 2010 using different sets of aw and uf lengths selected from 7 days 10 days 15 days 20 days 1 month and 2 months which is presented in the result section time series of optimal k during 20 years of simulation under different aw and uf lengths are presented in the supplementary material fig s1 3 4 streamflow forecasting developing skillful monthly to seasonal m2s streamflow forecasts depends on two key contributors 1 accurate estimation of initial hydrologic conditions of the basin and 2 the skill of m2s climatic forecasts in this study two forecasting approaches deterministic and probabilistic are employed in order to develop monthly streamflow forecasts and assess the improvements due to var da application for deterministic streamflow forecasting vic model is forced with spatially and temporally downscaled precipitation forecasts from echam4 5 gcm along with daily climatology of temperature and wind speed forcings the echam4 5 forecasts used in this study are monthly updated 1 month ahead forecasts thus for consistency reasons model s initial conditions are updated at the begging of each month i e uf 1 month under forecasting schemes the second approach is probabilistic streamflow forecasting known as ensemble streamflow prediction esp day 1985 wood and lettenmaier 2008 using climatological forcings esp is a traditional forecasting approach in national weather service nws since it allows to estimate the uncertainty in forecasts under the esp scheme vic model is forced with an ensemble of observed meteorological forcings from the historical records over 42 years 1949 1990 prior to the study time frame 1991 2010 for example to develop an ensemble of streamflow forecasts for february 1993 vic is performed 42 times each time using observed meteorological forcings during the february of a single year from 1949 1990 note that vic uses same set of forcings year to year though the esp forecasts are not similar because of different model s initial conditions under both forecasting approaches echam4 5 and esp vic is initialized at the beginning of month either with state conditions from open loop simulation or with corrected state conditions obtained from var da application with different aw lengths the performance of vic streamflow simulations forecasts against observations is evaluated through different measures nash sutcliffe efficiency nse score kling gupta efficiency kge score relative root mean square error r rmse spearman s rank correlation coefficient and bias are computed for deterministic streamflow forecasts nash and sutcliffe 1970 gupta et al 2009 these verification metrics are also used in order to assess the overall performance of the esp scheme based on the ensemble mean however the added value of conducting the esp scheme is that it allows to quantify the forecasting skill for specific flow categories such as below normal bn or above normal an flows in this regard brier score and its decomposed components reliability resolution and uncertainty are computed to evaluate the esp probabilistic forecasts brier 1950 weigel et al 2007 further description of the evaluation metrics is given as appendix a 4 results 4 1 vic model performance daily flow predictions for the tar river basin were obtained by running the vic and routing models in an open loop scheme during the period 1988 2010 the first three years of simulations i e 1988 1990 are ignored as the model spin up period and the remaining twenty years are evaluated by comparing with the observed monthly flows at the tarboro usgs station table 1 summarizes the performance of the vic lsm in simulating monthly streamflows computed from daily vic outputs over the period 1991 2010 the overall nse during validation period is 0 75 the monthly nse and r rmse values suggest that the model is well calibrated for spring and summer seasons while it performs poorly during november january months low values of nse during these months are primarily due to the increased bias in the winter months which primarily arises from the inability of the model in predicting high winter flows thereby resulting in increased bias the monthly correlation coefficients are statistically significant i e greater than 1 96 n 3 where n 20 years for a given month steel and torrie 1960 which suggests the modeled flows capture the variability in observed flows but r rmse and bias metrics indicate that the error in predictions are relatively higher particularly during high flow seasons i e winter as the model exhibits positive bias indicating overestimation of observed flows we are not performing any bias correction of monthly flows as we wanted to quantify the improvements from var da without bias correction 4 2 role of var da in improving streamflow simulation as described in section 3 3 we performed multiple experiments in which vic model state conditions are corrected with different frequencies uf by assimilating a range of past streamflow observations aw these are the two key parameters that determine the strength of var da framework the skill of var aided streamflow simulations are then quantified based on the observed flows and are compared to the skill of the open loop streamflow simulation fig 3 shows a sample time series from a var da experiment with uf 15 days and aw 10 days along with the open loop simulation and the streamflow observations here the term simulation aka perfect forecast indicates that the hydrologic model is fed with all observed meteorological forcings fig 4 displays the difference between the kge score from var implemented simulations and the ol simulation the statistics shown in this figure are computed by using daily flows first row and mean monthly flows second row further detailed analyses of var da impact on low flows flows lesser than 10th percentile of the climatology and high flows flows greater than 90th percentile of the climatology are included in all experiments var da predictions are enhanced compared to the open loop simulation specifically for shorter assimilation windows of 7 15 days and update frequencies of 10 30 days on average kge of the predictions during the entire 20 years of study time frame is increased by about 0 3 which results in a kge score greater than 0 8 for both daily and monthly flow analyses skill of vic in predicting low flows are particularly lower than normal possibly due to the bias in model calibration however the strongest improvement from var da is found in low flow predictions in terms of kge nse metric is not used to determine the effect of var da in low high flow analyses since it is sensitive to extreme flow conditions on the other hand the least improvements are found when a long assimilation window is considered for example in the case of aw 60 days the initial conditions of the simulations are updated by incorporating past 2 months of daily streamflow observations which is beyond the residence time of basin and memory of the soil a longer aw also results in smoother changes in the scaling factor k because it behaves as a moving average window with a long bandwidth and overlaps between the past and future iterations are existing so minimal variations in the var implemented predictions are expected in addition updating model state conditions in shorter cycles i e higher frequencies does not necessarily result in significant improvements since soil state conditions might not have changed much over short cycles 4 3 role of var da in improving streamflow forecasts to assess the impact of var da in real time forecasting streamflow forecasts are developed using 1 month ahead precipitation forecasts from echam4 5 gcm or through the esp approach using precipitation climatology under each scheme vic model is initialized with state conditions from the open loop simulation and with the corrected state conditions from the var da framework prior to the forecast issue time fig 5 shows a sample timeseries of monthly streamflow forecasts developed under the mentioned scenarios comparison between these plots highlights the positive effect of var da application in streamflow forecasting in which correcting the initial conditions aids to keep the model on the observation track for instance over the period 2007 2009 the streamflow forecasts initialized with prior states from open loop simulations fig 5a start to drift apart from the streamflow observations while this divergence is minimized after correcting state conditions through var da also the same behavior is repeated in the case of esp forecasting in which the var aided ensemble forecast is shifted towards the observations and the ensemble spread is narrowed indicating the uncertainty reduction the skill in deterministic monthly streamflow forecasting from echam4 5 climate forecasts and ensemble mean from esp forecasting approach is summarized in table 2 along with the performance of the var aided forecasts note that this overall performance is average of the statistics across all the experiments with different aw lengths additional information is provided as supplementary material similarly the impact of var da on the skill of probabilistic forecasting using esp approach is assessed particularly for below normal bn below 33rd percentile climatology of observed monthly flows in a given month and above normal an above 67th percentile climatology of observed monthly flows in a given month streamflow months table 3 the presented performance of da implemented model is summarized by taking the average of the verification metrics across schemes with different aws where detailed statistics are given as supplementary material fig s2 results suggest that on average var da implementation is significantly effective in improving streamflow forecasts especially in reducing the forecast bias in general the var da framework enhances the skill in deterministic streamflow forecasting by 0 08 in terms of nse and 0 02 in terms of kge moreover the application of var da reduces the brier score by approximately 0 04 in bn and 0 02 in an months respectively this improved brier score is due to a slight improvement in resolution but mostly is related to the enhancement of the reliability score which can be interpreted as bias reduction in a probabilistic forecast in contrast to simulation scheme section 4 2 under forecasting experiment it is found that selecting a longer aw such as 15 20 days results in the largest improvement in the forecasting skill considering all the verification metrics detailed statistics are provided as supplementary material fig s2 however in the case of probabilistic forecasting assimilating a shorter window e g 7 15 days has the most positive impact as opposed to larger windows monthly statistical analysis results are not shown suggest that da improves forecasting skill mostly during fall and winter seasons compared to spring and summer seasons this is expected since the skill of streamflow forecasting over the southeast is particularly governed by soil moisture conditions rather than model forcings during wet seasons mahanama et al 2012 sinha and sankarasubramanian 2013 it is also notable that the improvements due to var da in the simulation schemes fig 4 is much larger than that of the forecasting schemes under the simulation scheme since vic model is fed with the observed meteorological forcings the role of forcing error is minimized and thus the skill difference between ol and da experiments is totally inherited from the corrected initial conditions on the other hand in the forecasting scheme the imprecision of forcings dominates the forecasting skill thus the improvements are found to be smaller and approximately similar across different aw lengths 4 4 impact of var da over forecast lead time to assess the contribution of corrected model initial conditions over sub monthly lead times the improvements due to var da δ kge kge da kge ol are computed for vic daily predictions fig 6 this analysis is conducted for both streamflow simulation and forecasting schemes in which var da is implemented at the beginning of each month i e uf 1 month and vic model is performed for a month ahead for example the effect of var da on 7 day ahead streamflow simulation in fig 6a is assessed by first averaging the simulated flows over the 1st day to the 7th day of each month i e resampling sub monthly flows and then quantifying δ kge throughout the entire study period 1991 2010 evidently the computed statistics for 30 day ahead streamflow simulations and forecasts in this figure should match our findings in fig 4 and table 2 respectively it is found that the positive effect of var da application increases in short range lead times up to 8 days from the forecast issue time meaning that the 8 day ahead streamflow simulation forecasting benefits the most from corrected state conditions for longer lead times the curves follow an approximately level pattern inferring that there is no additional contribution from the corrected state conditions on the other hand under the forecasting scheme fig 6b the arose improvements start to decline beyond the 8th day primarily due to the imprecision in the utilized precipitation forecasts it also indicates the domination of forcing errors over corrected initial conditions where the curves approaches back to zero nevertheless δ kge still remains positive even with long lead times indicating the net positive effect of da in monthly streamflow forecasting the overall time lag for the improvements to reach the peak can also be interpreted as a basin characteristic e g the time lag in the corrected soil moisture conditions to show its effect at the basin outlet thus it is expected to have earlier peak times for smaller basins also this analysis suggests that for a short range medium range forecasting it is better to use shorter longer assimilation windows 5 discussion and concluding remarks most hydrologic da studies employ sequential da for correcting initial conditions in hydrologic simulations further most da efforts have demonstrated the potential of assimilating remotely sensed observations while fewer studies have exploited ground based observations such as streamflow records in model state conditions towards this we proposed a scheme that applies var da in vic lsm in order to correct the initial conditions based on gauge measured streamflow observations and quantified the associated improvements in 1 month ahead streamflow forecast over a 20 year period 1991 2010 for the tar river basin the two key parameters in our var da framework are update frequency uf and assimilation window aw where the former determines the period between each da application i e da cycles and the latter specifies the length of past daily observations to be considered in da in order to examine the sensitivity of the proposed var da framework to these parameters totally 36 experiments were conducted and analyzed using different combinations of ufs and aws selected from a discrete set of time intervals ranges from 7 days to 2 months comparison of simulated streamflows i e using observed forcings to implement the vic lsm between open loop ol and da coupled experiments suggests that the var da application is successful in enhancing the streamflow modeling better performance of var da is found when a 7 day aw is selected with the uf around 20 days 7 days aw is more effective since it considers the recent information for updating the initial conditions this finding is consistent with other studies that show that weekly assimilation cycle is relevant for hydrological prediction with var da approach abbaszadeh et al 2019 thiboult and anctil 2015 given that the tar river basin is a rainfall runoff regime with uniform rainfall throughout the year the role of initial conditions is continuously changing with limited basin memory however the optimal uf is found longer e g 15 20 days and it is expected to be dependent on specific basin characteristics such as drainage area hydraulic conductivity and aridity of the basin the impact of var da on monthly streamflow forecasting through two different approaches based on climate forecasts and ensemble climatological forcings i e esp is also evaluated climate information based streamflow forecasts are developed by feeding the vic model with spatially downscaled and temporally disaggregated monthly precipitation forecasts from echam4 5 gcm the esp approach a probabilistic forecast uses an ensemble of climatological forcings based on the historical precipitation observations from 1949 to 1990 to implement the vic lsm the ensemble mean of esp forecasts is also computed and evaluated as a deterministic streamflow forecast for comparison with the echam4 5 approach assessing the var aided deterministic forecasts reveals that var da improves the skill of monthly forecasting by increasing nse metric by 0 08 and kge metric by 0 02 on average moreover it significantly decreases the bias in deterministic forecasts and the brier score in the probabilistic forecasts one key implication of these analyses is the reduced dependence of vic simulation forecast on bias correction techniques as var da addresses bias correction by improving the initial state conditions in advance when comparing the skill under simulation and 1 month ahead forecast it was noticed that the magnitude of improvements are considerably different indicating that the accuracy of climatic forcing dominates over the improved initial conditions considering this we examined the contribution of corrected initial conditions in daily streamflow predictions within the month it was found that the effectiveness of corrected initial conditions lasts for 7 8 days ahead from the forecast issue time and beyond that the accuracy of climatic forcings controls the skill in streamflow forecasts this indicates improvements from var da is only for a weekly period as the basin gets controlled more by the climate for the remaining period within the month this is because tar river basin is a rainfall runoff regime with no seasonality in rainfall thereby the basin s initial condition has limited memory in improving the skill of monthly streamflow forecast although it is debated that the application of var da methods are simpler than sequential da in hydrology but rendering a comprehensive var optimization problem for a distributed hydrologic model is very difficult and computationally intensive most of the var da studies often use numerical approximation algorithms or develop adjoint models to alleviate the optimization problem developing these algorithms also poses unique challenges because of non linearity in hydrologic systems in addition accurate estimation of the model background error covariance is challenging and usually it is obtained through an ensemble approach in which the model is executed with a set of perturbed observed forcings liu et al 2008 given this the complexity of da problem in this study is simplified to a 1 d problem by identifying one decision variable i e a multiplier factor that adjusts the model background soil moisture contents in different grid cells and in different soil layers over the selected basin since the analysis state is derived by scaling the background state in a uniform manner the spatial covariance in soil moisture is preserved this makes the cost function of background j b to heavily penalize any changes in the background state thus this term was excluded from the general var formulation and the observational cost function was exclusively considered it is shown that var da could be beneficial in improving m2s streamflow forecasts with the improvements primarily happening over the 7 8 daily streamflow data assimilation applications can be used not only for better state estimation but also to enhance parameter estimation or even improve model forcings in a combined approach seo et al 2003 moradkhani et al 2005 moreover data assimilation techniques are sometimes criticized for violating the water mass balance assumption in the hydrologic model hence its potential benefit in removing the bias and improving the model product is often undervalued in this context it is rational to quantify the effect of da in the absence of model bias with the intention of applying bias correction as well as quantifying the sole role of da in hydrologic forecasting a recursive bias estimation should be coupled into the da framework at each iteration resulting in a two stage estimation algorithm but this significantly increases the computational cost friedland 1969 dee and da silva 1998 in the presence of a high bias in the predicted flows da application is more successful in improving the prediction skill i e a better calibrated model decreases the positive role of var da our previous studies have shown that calibrating models based on flow conditions tends to improve the model performance li and sankarasubramanian 2012 yapo et al 1996 sinha and sankarasubramanian 2013 thus if we explicitly consider bias correction as part of model calibration the positive role of var da will be reduced majority of hydrologic da studies are focused on short term streamflow forecasting ranges from hourly to maximum few days but this study focused on m2s streamflow forecasting which provides critical information for water supply planning for real time streamflow forecasting the non linearity embedded in the hydrologic model and high dimensionality of the model initial conditions i e soil and groundwater storage poses technical complexities in da problem particularly increased computational cost in a distributed model our study showed that a simplified version of var da is overall beneficial in improving the forecast for below normal and above normal months but da also degrades the model predictions in certain months thus it is important to assess and quantify the negative effects of da and attribute those sources of errors to other issues such as model uncertainty and parameter estimation the tar river basin is selected as the case study since our previous studies have evaluated the role of climate forecasts in developing streamflow forecast in a rainfall runoff regime sinha and sankarasubramanian 2013 mazrooei et al 2015 one potential challenge of the proposed var da approach is in the application of our methodology in larger river basins since we are using downstream observed streamflow data in correcting the initial conditions of a distributed hydrologic model application of var da in large basins may have to consider streamflow with different lags another approach is to consider multiple sub basins within the large basin so that a spatially varying multiplier factors could be considered by assimilating streamflow information from multiple gauges within the large basin this essentially converts the var framework to a 3 d problem and be applied to each station grid cell within the basin in these conditions multiple streamflow observations could be considered with spatially varying k multiplier with the k to be correlated across space alternately this fits within a bayesian framework by assuming a prior distribution on k which could be used to update k simultaneously across the space to obtain the posterior distribution of the constant multiplier across the watershed that maximizes the joint likelihood of streamflow observations across the watershed moreover our varda framework is simplified to a 1 d problem along with excluding model background error term as it has a minimal impact on the var aided hydrologic forecasts liu and gupta 2007 seo et al 2003 here we apply a single k multiplier to adjust the sm contents and minimize the observational error term j o in case of including the background error term j b matrix b could be computed as the variance of vic lsm s sm simulations in an ensemble mode e g by executing vic lsm with perturbed observed forcings also one could consider the spatial varying background sm values x b across all the grid cells as the decision variables in the var da optimization problem however this significantly increases the computational demand of the analysis these are potential opportunities for future study focusing on improving var da using observed in situ information for correcting initial conditions of a distributed hydrologic model credit authorship contribution statement amir mazrooei investigation methodology data curation writing original draft a sankarasubramanian supervision validation funding acquisition writing review editing andrew w wood investigation formal analysis validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by national science foundation grants cbet 0954405 cbet 1204368 and ccf 1442909 we would like to thank the university corporation for atmospheric research ucar advanced studies program asp as well as national center for atmospheric research ncar for providing high performance computing support for this project yellowstone 2012 we are also thankful to the anonymous reviewers for their insightful comments appendix a evaluation metrics nash sutcliffe efficiency nse score is derived by taking the average of the squared differences between the modeled q t vic and observed flows q t obs normalized by the variance of the observed flows eq a 1 nse ranges between 1 i e perfect fit and whereas nse 0 means that the model is no better than the mean of observations as a predictor since nse is quantified using squared differences the model skill tends to be overestimated during low flows and underestimated during high flows hence nse is not suggested to use it as a verification metric for low flow and high flow predictions thus for extreme flow analyses kling gupta efficiency kge score is preferred which simultaneously accounts for correlation coefficient mean bias and relative variability in the predictions and observations eq a 2 kge also ranges between 1 to with 1 denoting a perfect prediction to further diagnose the model performance relative root mean square error r rmse eq a 3 spearman s rank correlation and bias metrics eq a 4 are also included a 1 nse 1 t 1 n q t vic q t obs 2 t 1 n q t obs q obs 2 a 2 kge 1 r 1 2 σ vic σ obs 1 2 q vic q obs 1 2 a 3 r rmse 1 n t 1 n q t vic q t obs 2 q obs a 4 bias 1 n t 1 n q t vic q t obs q t obs 100 for probabilistic forecasts we employed brier score bs eq a 5 as the verification metric and its decomposed components such as reliability eqn a 6 and resolution eq a 7 which provide a better insight into different aspects of forecast quality brier 1950 weigel et al 2007 basically the reliability metric rel represents the bias in the probabilistic forecasts a reliable forecaster has rel 0 and the resolution metric res indicates how much climatic uncertainty is explained in the forecast higher res infers a better forecaster wilks 2011 the first step to measure bs is to compute probabilistic forecast p t for a predefined category from esp runs for example for bn events the probabilistic forecast is quantified as the number of ensemble members with the forecasted streamflow below the 33rd percentile of streamflow climatology of the basin i e q q obs 33 rd then bs rel and res metrics can be measured based on following equations a 5 bs 1 n t 1 n p t y t 2 a 6 rel d 1 d n d n o d n d p d 2 a 7 res d 1 d n d n o d n d o 2 where n is the total number of forecasts y t is the observation transformed to a binary scale i e y t is 1 if the event happened and 0 otherwise d denotes the number of distinct forecast probabilities issued i e p t p 1 p d n d is the number of forecasts lies in the dth category o d is the total number of observed events when the dth forecast was issued and o is the climatological event frequency appendix b supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2021 126559 appendix b supplementary data the following are the supplementary data to this article supplementary material data profile 
