index,text
3320,water quality models are decision support tools for the planning and management of the aquatic environment however the application of the model needs an intricate calibration process due to the various ranges of numerous parameters to help improve the accuracy of model simulation and reduce the workload of parameter adjustment to similar surface waters parameter uncertainty and sensitivity analyses of the environmental fluid dynamics code efdc model were carried out in this study the efdc model was first calibrated and simulation results agree well with the measured data the generalised likelihood uncertainty estimation glue and regional sensitivity analysis rsa methods are then applied to analyze the uncertainty and sensitivity of the model eighteen kinetic parameters related to algae and organic matter are filtered and analyzed the results show that the sensitivities of the model to eighteen input parameters are significantly different the modeled algae levels measured as chlorophyll a chl a are highly sensitive to the optimal growth rate and the maximum basal metabolism rate of cyanobacteria bmrc and pmc with the sensitivity indices si at 0 66 and 0 78 respectively the inorganic nutrient levels phosphorus nitrate nitrogen and ammonia nitrogen are highly sensitive to minimum respiration rates of corresponding dissolved organic matter kdp and kdn with sis at 0 78 0 56 and 0 88 dissolved oxygen do is highly sensitive to pmc and kdc with their sis at 0 66 and 0 85 respectively the uncertainty interval is focused on the periods of high algae concentration the simulated uncertainty in the surface water is higher than that in middle layer water and might be related to algal transport processes like settlement and horizontal transport the results of the uncertainty and sensitivity analyses in this study support a better understand of the modeling mechanisms and provide scientific guidance for calibration in similar waterbodies keywords sensitivity analysis uncertainty analysis three gorges reservoir water quality simulation efdc 1 introduction water quality models have been widely used in studies of water environment problems since the development of the first river water quality model by streeter and phelps streeter phelps model in 1925 arnold et al 1998 brighenti et al 2019 krysanova and white 2015 xu et al 2013 these models can provide scientific support for water quality planning and environmental pollution research and they play important roles in identifying the dominant governing factors of water quality phenomena in surface waters it is very important to determine the dominant parameters controlling model behavior pappenberger et al 2006 for model development with the in depth research of physicochemical and biological processes in the lake and the improvement of computational performance many models are formed by comprehensive mechanisms at present many mechanistic models have been developed and commonly used such as efdc delft3d mike ce qual w2 wasp each model has its advantages and applicability arifin et al 2016 beck 1987 bieger et al 2017 james and boriah 2010 moses et al 2015 although mechanistic water quality models have been widely used identifying the right parameter values is still a challenge nature is a very complex system in which each biological chemical and ecological process is affected by various uncertain factors incomplete understanding of the mechanism will lead to the uncertainty of the models an appropriate method to optimize the simulation effect is to improve the accuracy of parameters which have great influence on the model results sensitivity analysis sa can improve the understanding of models responses to various parameters and is a useful tool to screen out highly sensitive parameters beck 1987 demirel et al 2018 jing and chen 2011 sensitivity analysis methods are classified as local sensitivity analysis lsa and global sensitivity analysis gsa in which the first approach affects a single parameter each time and the second approach focuses on the influence of multiple parameters and their relationships on the results lsa is easy to use but the results of gsa are more comprehensive and instructive the gsa methods including rsa method spear and hornberger 1980 sobol s method sobol 1993 and bayesian sensitivity analysis oakley and o hagan 2004 are commonly used in sa researches nowadays rsa has some gsa s global properties in consideration of the whole range of value of input factors and the variation of all factors at the same time for water quality models parameter values could be estimated and obtained from literature investigation or field measurement ejigu 2021 the modeling outputs based on different parameter values need to be compared with the observations proper values or valuable parameters are selected for further investigation the sensitive parameters vary in different water bodies because of the different environmental characteristics and main dynamic processes in many eutrophic surface water model results are sensitive to parameters related to biological processes of algae e g algal growth respiration and death missaghi et al 2013 due to algal ability to uptake and release nutrients and gases e g o2 and co2 biochemical transformations of nutrients e g mineralization denitrification jenny et al 2020 alter nutrient components and indirectly affect algal growth and metabolism the limiting factors of algae growth including nutrients light and temperature govern if algal bloom will occur however how these factors controlling the growth of algae are highly uncertain jiang et al 2018 in addition the spatial location and time differences also affect the simulation in a multi dimensional water body the temporal and spatial variations of modeling sensitivity and uncertainty in multi dimensional rivers lakes and reservoirs need to be evaluated biological reaction and nutrient cycles in surface waters are the focus of water quality simulation as algae and nutrients are two important components in the eutrophication process compared with consumers and macrophytes the biomass of algae can be large in some eutrophic waters and the nitrogen and phosphorus fluxes might be dominated by the nutrients uptake and release of algae qin 2009 ramin et al 2012 zou et al 2020 in efdc algae uses inorganic nutrient to increase biomass when growing and the biomass loss in basal metabolism is released into the water as a mixture of organic matter and inorganic nutrients availability of nutrient i e concentration of dissolved nutrient in the least supply limits production rate of algal group px thus reducing phosphorus concentration in freshwater has always been the main approach to control freshwater eutrophication kumar et al 2019 for the three state variables of organic matter particulate organic matter rpom and lpom can be decomposed into dissolved organic matter dom and dom can be mineralized into inorganic matter at the rate of krm klm and kdm in efdc fig 2 to effectively manage eutrophication it is necessary to consider the role of the nutrient cycle in the eutrophic water bodies that is the mechanism of material transformation and algae growth in this study we chose the three gorges reservoir as an example and the efdc model to conduct the sensitivity and uncertainty analysis the kinetic parameters of algae and organic matter were selected as the targets to be analyzed chl a do phosphate ammonia nitrogen and nitrate nitrogen were selected as model outputs the purpose of this study is to a quantify the sensitivity of water quality model to parameters and the uncertainty of model simulations b analyze the spatio temporal variability of uncertainty c explore the interaction between algae and organic matter under the simulated conditions of xiangxi bay with the low flow velocity the research results can deepen the understanding of parameter coupling relationships and mechanisms in the efdc model and provide insights to improve the calibration in similar waterbodies 2 methods 2 1 study area three gorges reservoir tgr the largest reservoir in china is an artificial lake formed by the impoundment of the three gorges dam tgd in the yangtze river the tgr is located across the hubei province and chongqing municipality 105 44 111 39 e 28 32 31 44 n and has a surface area of approximately 1084 km2 at the normal water level of 175 m the backwater end of the tgr reaches jiangjin district chongqing forming a channel type reservoir with a length of 667 km and an average width of 1100 m the flow rate of the yangtze river is generally 0 1 0 2 m s in the non flood season and 0 2 0 5 m s in the flood season the construction of tgd has changed the flow conditions of the river and made the flow velocity much lower than it would be under natural conditions nutrients concentration in yangtze river was above the thresholds for eutrophication total nitrogen 0 2 mg l total phosphorus 0 02 mg l yang et al 2010 algae blooms occurred in the daning river a tributary of the yangtze river after the first impoundment of tgr in 2003 and the increasing frequency of algal bloom outbreaks in tributaries is causing concern holbach et al 2013 liu et al 2016 zheng et al 2009 the xiangxi river situated in hubei province is the largest tributary of the yangtze river with a length of 94 km its river mouth is about 34 km upstream of the tgd and the watershed area is about 3099 km2 gao et al 2018 as the nearest tributary to the dam the hydrodynamic conditions of the xiangxi river have changed dramatically due to impounding after the impoundment of tgr a backwater zone with low flow velocity called xiangxi bay was formed in this tributary the temperature ranges from 7 c to 29 3 c and the precipitation ranges from 650 mm to 2100 mm in xiangxi bay the typical hydrological year for xiangxi bay consists of a dry season january march and december a wet season may september and a normal season april and october november the algae blooms in the xiangxi river are typical and prominent which have a great influence on water quality in front of the dam therefore this tributary is chosen as a vital research area 2 2 model description efdc originally developed by john hamrick hamrick 1992 is a comprehensive modeling system that integrates hydrodynamic sediment transport toxic contaminant eutrophication and water quality modules it is one of the most widely used ecological and hydrodynamic models applied to reservoir lake river and wetland research bai and lung 2005 gong et al 2016 he et al 2011 algae and organic matter are important components of the model algae occupy a central role in the water quality module and are grouped into three variables in the efdc model cyanobacteria diatoms and green algae the grouping is mainly based on growth rate metabolism rates settling velocities and influences of nutrients light and temperature on the growth rates of each class the sources and sinks of algae include production basal metabolism predation settling and external loads and the kinetic equation is 1 b x t p x b m x p r x b x z w s x b x w b x v where the subscript x is used to denote three algal groups c for cyanobacteria d for diatoms and g for green algae bx is algal biomass px is production rate bmx is basal metabolism rate prx is predation rate wsx is positive settling velocity wbx is external loads and v is cell volume the efdc model has three state variables for organic carbon nitrogen and phosphorus which are refractory particulate labile particulate and dissolved organic carbon nitrogen and phosphorus in the water quality module three states of organic matter convert into each other and affect the growth of algae fig 2 2 3 model configuration the computational fig 1domain fig 1 includes the reaches of the yangtze river and xiangxi tributary with the length of 70 km and 30 km respectively to fit the boundary better the orthogonal horizontal and curvilinear coordinates are put into use the computational domain is divided into 742 grid cells in the horizontal plane and 10 layers in the vertical sigma coordinate the simulated period is set to the year 2010 january december and the model runs at a 6 0 s model time step for a 365 d initial conditions of water level and water temperature are set as constant values because a previous study gao et al 2018 shows that the impacts of the boundary conditions make the interference of initial conditions on simulation disappear in a short time the upstream boundaries are the time series of inflow in the yangtze river and xiangxi river and the downstream boundary is the time series of outflow in tgd the upstream boundary conditions of water temperature are the observations at different depths other boundary conditions data including precipitation air temperature solar radiation atmospheric pressure and wind are obtained from china meteorological administration upstream loadings of nutrients are also included in the model fig 3 gao et al 2018 presents the observed values of total nitrogen and total phosphorus in the inflows of the yangtze river and xiangxi river in 2010 in the study area ten sampling sites are set along the xiangxi river xx01 xx10 and one site cj is set at the estuary of xiangxi tributary in yangtze river to monitor the water quality variables four sampling sites cj xx03 xx06 and xx09 are chosen in the research representing the different reaches of the river from the upstream xx09 to the downstream estuary xx03 the river channel gradually deepens and widens and the velocity slows down at cj site the flow with high velocity is influenced by the mainstream of the yangtze river the model calibration was conducted in a previous study gao et al 2018 the predicted results and observations of flow velocity and water temperature were compared to examine the model performance the model could simulate the flow velocity and water temperature with high accuracy in xiangxi bay but in the upper reaches of the xiangxi river the inaccuracy of the upstream boundary conditions leads to under predictions of flow velocity further the neglect of the spatial heterogeneity of meteorological conditions and heat exchange between the bottom water and riverbed resulted in slightly over prediction of temperature the results of the water quality simulation were in agreement with actual trends and distributions however boundary conditions also affected the simulation in the upper reaches the predictions of chl a concentration were lower in march and april and higher in summer and autumn than observations 2 4 analysis methods the uncertainty and sensitivity analysis of the efdc model for tgr and xiangxi river is based on glue and rsa methods the detailed analysis process is shown as follows 2 4 1 parameter identification understanding the water blooms in the yangtze river and xiangxi tributary is urgent since water blooms are increasingly likely to occur as previously mentioned interactions between algae and nutrients are important processes in eutrophication simulations in this study algal and organic matter parameters are selected as research priorities certain parameters of three algae groups were selected such as basal metabolism rate bmrx settling velocity wsx and maximum growth rate pmx with the consideration that the competitive relationship amongst different algae groups was not sufficiently evaluated in the previous study the half saturation constants for nitrogen and phosphorus uptake khnx and khpx are also major parameters of algal growth however since the nutrient concentrations of xiangxi tributary are at the eutrophication level and the half saturation constants for nutrients have no obvious influence on water quality simulation pmx is selected instead in this study the classification standard of organic matter in efdc is their decomposition rates the actual chemical components of these organic components are not known in related application researches the hydrolysis rates of nutrient components are mostly set as default values yi et al 2016 uncertainty in the values of hydrolysis rates introduces uncertainty to model results therefore the decomposition rates of organic matter are also selected eventually 18 parameters of algae biological parameters and organic matter dynamics parameters were selected in this study the ranges of these parameters determined through an investigation of the literature arhonditsis and brett 2005 he et al 2011 pang et al 2008 wang et al 2014a wang et al 2014b wu and xu 2011 zou et al 2020 are shown in table 1 with their descriptions 2 4 2 sampling of input parameters with the lhs method as a commonly used sampling method in uncertainty and sensitivity analysis latin hypercube sampling lhs combines the characteristics of random sampling and stratified sampling and could produce more stable analysis outcomes helton and davis 2003 the lhs method operates in the following manners to generate a sample of each parameter dividing the range of each parameter into disjoint intervals with equal size sampling one value randomly in each interval and randomly combining the distributions of each parameter into sampling sets the denser sampling number makes the uncertainty and sensitivity analysis result more stable sheikholeslami and razavi 2017 the parameter prior distribution adopts uniform distribution the annual average concentrations aac of water qualities output were used to characterize the performance of a behavioral simulation the convergence was judged by plotting the mean and variance of aacs of behavioral simulations in different numbers of model runs the mean μ and variance σ2 were calculated as μ n i 1 n θ n σ 2 n i 1 n θ μ 2 n 1 where n is the number of model runs n is the number of behavioral simulations in n and θ is the aac of water quality output these values were plotted against an increasing number of samples as shown in figs 4 5 to identify convergence the mean aac of five water qualities increased with the number of model runs but the values did not change significantly after n reached 400 the variances decreased rapidly with n but the variation continues to level off after n reached 400 these approximate mean values indicate small differences among the aac of water quality outputs of behavioral simulations for variances of aac the sharp decrease at the beginning should be due to the small number of behavioral simulations the variance of most water quality outputs after the sample size exceeded 400 shows some convergence for water qualities simulated in the upper layers at sites xx06 and xx09 the continuously slight decrease with the larger n larger than 500 of their variance is predictable in summary combining the convergence of the mean and variance and the calculation amount we consider that the sample size of 500 is acceptable for uncertainty and sensitivity analysis 2 4 3 uncertainty analysis with the glue method beven and binley beven and binley 1992 used the glue methodology for model identification in glue the likelihood measure value is associated with a parameter set and quantifies how well that the parameter value combination simulates the system beven and freer 2001 blasone et al 2008 glue methods are generally considered as informal bayesian or non classical bayesian methods and could avoid the optimal partial solution it is simple and feasible and is widely used in sa of water quality model 500 sets of input parameters obtained by lhs method were used in efdc and 500 sets of simulation results are obtained using the nash sutcliffe coefficient expresses the likelihood measure lm 3 l θ i 1 α i 2 α 0 2 where i indicates the ith model l θ i is the lm for the simulation results relative to the observations α i 2 is the error variance of simulation results and α 0 2 is the variance of the observations the likelihood measures are normalized in order to facilitate subsequent data processing 4 l θ i l θ i l min θ i l max θ i l min θ i where l θ i is the normalized likelihood measure l max θ i and l min θ i are the maximum and minimum values of all likelihood measures respectively nash sutcliffe efficiency nse indicates how well the plot of observed versus simulated data fits the 1 1 line and is generally used to verify the quality of hydrological model simulation results the simulations with lm above the threshold nse 0 are accepted as behavioral simulations the normalized likelihood measures are sorted by their values the 2 5th and 97 5th percentiles are selected as the lower and upper bounds of the confidence intervals the simulation uncertainty interval ui is represented by the distance between upper and lower bounds and the model uncertainty analysis is carried out by the ratio of the observations in the uncertainty interval ri and the distribution of the ui 2 4 4 sensitivity analysis with the rsa method the rsa methodology was established by spear and horn berger spear and hornberger 1980 for the parameter sensitivity analysis of the model the advantages of rsa method e g glue are its simple concept relative ease to implement and its generality to handle different models after simply improving its methods yang 2011 blasone et al 2008 a python safe toolbox wagener et al 2001 is used in rsa computation in this research the basic idea of rsa is as follows in rsa parameter sets are grouped based on model response measures kolmogorov smirnov k s test kottegoda and rosso 1997 is used to compare the distribution of sub samples we divide the input parameter sets into 10 groups based on normalized likelihood measures of their simulation results and use the cumulative distribution function cdf f x to represent the distribution of each group 5 f i n x 1 n k 1 n i x x k where subscript i and n means the number of parameter sets in the ith group is n i x is the indicator function equal to 1 if xk x and equal to 0 otherwise use d a k s test statistic to quantify the distance between two cdfs of two groups and the maximum vertical distance mvd of all groups is calculated as si 6 mvd d i j max f i m x f j n x the parameters are divided into three categories according to the si high sensitivity parameters si 0 7 medium sensitivity parameters 0 4 si 0 7 and low sensitivity parameters si 0 4 3 result 3 1 uncertainty analysis figures 6 10 shows the water quality simulation results of 95 confidence interval at four sampling sites cj xx03 xx06 and xx09 in the three gorges reservoir the simulation results of chl a do no3 n nh4 n and po4 p at the four stations show the same trend as the observation data the proportion of observations in uncertainty interval cr are mostly higher than or equal to 60 table 2 which means that the observed values are within the confidence interval it indicates that the simulation of the efdc model in three gorges reservoir and xiangxi bay is feasible the variation trends in chl a do and nutrient concentrations among the four sites and between the upper and middle layers at the same site showed a certain degree of consistency the simulated chl a concentrations have similar trends at 3 sites in xiangxi river the chl a reflects the survival of algae the algae did not grow on a large scale under the low temperature in spring affected by temperature and the release of nutrients upstream algae begin to proliferate explosively in summer and then wilt in winter the simulation is in good agreement with the timing of algal rapid growth in the xiangxi river due to light conditions algae mainly distribute on the surface water so chl a concentration in the middle layer is much lower than that in surface water the observed concentrations of chl a are close to the boundary of the confidence interval which meant the model estimates the outbreak intensity of algae higher than the actual one it may be that some factors interfering with the growth of algae have not been accurately reflected in the simulation the simulation results of do in xiangxi river are consistent with that of chl a when the algal biomass increases the do in water increases and vice versa the relationship indicates that no mass hypoxic death after the outbreak of algae and oxygen is not the limiting factor for the growth of algae the trend of nitrogen and phosphorus simulation results is opposite to that of chl a when the concentration of algae increases greatly in may june and august october the inorganic nitrogen and phosphorus in the waters decrease gradually and when algae bloom decreases in july september the nutrient concentration in the waters recovers again logically algae uptake may be the main reason for the decrease of dissolved nutrients during algae blooming the hydrodynamic and model boundary conditions have a clear and visible effect on the simulations at cj site and xx09 site the cj site is located in the yangtze river where the flow rate is fast during the flood season and algae are strongly scoured by water flow therefore the outbreak of chl a concentration starts in the non flood season after october with low intensity compared with the xiangxi river the occurrence time of the algal bloom in the yangtze river is delayed the do and nutrient simulations are also greatly affected by the high flow rate in the flood season at cj and xx09 sites the confidence interval of the simulation in summer is obviously similar to the boundary condition of upstream input and the upper and lower boundaries fluctuate slightly only at the end of the year in the upper layer at xx09 site the time series of chl a and nutrient concentrations shows several low valleys of which the values are close to 0 the two boundaries nearly draw close to one another in flood season because the site is close to the upstream of the xiangxi river the simulation is affected by the inflow boundary such as the river scouring by short storms in summer table 2 shows the four simulation indices of figs 6 10 the average ratio of uncertainty interval to the mean of the simulated values ri is used to measure the degree of uncertainty the ri of chl a at xx03 and xx06 sites and in the surface layer at cj site are high more than 20 showing that there is great uncertainty in chl a simulation in these sub areas the mean width of uncertain interval mu is about the same as the mean value of observations mo considering that discrete measurements do not fully represent the actual chl a concentration over a year e g more observations distributed over low concentrations the actual average concentration in terms of mo may have been underestimated here the ri of ammonia nitrogen at xx03 and xx06 sites are also at a high level more than 20 with mu accounting for nearly half of the mo the uncertainty of these two water quality simulation results cannot be ignored although the mo of ammonia nitrogen in this study area is slightly lower than that of nitrate nitrogen the uncertain contribution of ammonia nitrogen to nitrogen cycle simulation still needs to be noted compared with the simulation in the surface layer the simulation of ammonia nitrogen in the middle layer has slightly greater cr and lower ri cr varies slightly and the ri is lower for the simulations of phosphate and nitrate nitrogen in the middle layer considering the biological and environmental differences between surface and middle layer of water it may be due to errors in the simulation of algae participating in the water quality cycle or to the errors in the wind temperature and light parameters 3 2 parametric sensitivity analysis the si of the parameters are expressed by the maximum vertical distances mvd obtained by k s test of the rsa method fig 11 shows the parameter si of each simulation result in different zones pmc the maximum growth rate under optimal conditions of cyanobacteria has a great influence on almost every water quality simulation pmc affects the source of algae in the kinetic equation of efdc and increases the biomass of cyanobacteria photosynthesis during algae growth releases oxygen and sequestrates carbon diatoms and green algae in water compete with cyanobacteria however the effects of their biodynamic parameters on water quality simulation are at the same level and not significant si is less than 0 4 this indicates that cyanobacteria are dominant algae in the tgr and xiangxi bay in chl a simulation bmrc and pmc are high sensitivity parameters while wsc and kdn are medium sensitivity parameters in some zones bmrc and wsc directly affect the biomass sink of cyanobacteria in the dynamic equation the high sensitivity of chl a to wsc means that the uncertainty of surface algae concentration is brought to the algae simulation in the middle layer with sedimentation the si of kdn at xx03 and wsc at xx09 are slightly higher than those in other zones which means kdn and wsc have obvious spatial distribution differences and deserve attention in modeling simulation the most sensitive parameters in do simulation are kdc and pmc kdc represents the minimum dissolution rate of dissolved organic carbon and is also an important parameter of denitrification in the model kdc in efdc affects heterotrophic respiration of dissolved organic carbon which is a sink of do the si of middle layer kdc is higher than that of upper layer kdc in all zones and it can be explained by the low concentration of do in the middle layer anaerobic conditions can promote denitrification do simulation is mainly influenced by cyanobacteria simulation because their trends are the same kdp and kdn are high sensitivity parameters in phosphorus and nitrogen simulation respectively due to its fast decomposition rate dissolved organic matter in the model is very important in three organic matter components therefore the optimization of its decomposition rates plays a decisive role in the simulation of corresponding nutrients the effect of kdn on ammonia nitrogen is greater than that on nitrate nitrogen there are some differences between the sensitive parameters of the two inorganic nitrogen ammonia nitrogen simulation is more sensitive to kdn while nitrate nitrogen is more sensitive to pmc the sensitivities of kdc and bmrc in nitrogen simulation vary with indicator and spatial position phosphorus simulation is sensitive to various parameters at the same time the high sensitivity parameters are kdp and pmc while the medium sensitivity parameters are klp kdn and bmrc the decomposition of labile particulate organic phosphorus promotes the increase of nutrient concentration and increased nutrient concentration weakens the growth restriction of algae which in turn promotes the uptake of nitrogen and phosphorus nutrients 4 discussion 4 1 influence of input parameter categories the kinetic parameters of algae and organic matter were selected for the study the sensitivity of different parameters to different water quality simulations varies among the three algae groups the parameters of green algae and diatom had little influence on the model simulation the main reason may be that cyanobacteria are dominant species in the environment of the xiangxi river and the dynamic functions of green algae and diatoms could not be well reflected reasons for differences in sensitivity to the same kinetic parameter among different algae groups can be studied further in other water areas the settling rate of cyanobacteria is a highly sensitive parameter of the eutrophication models in wide and shallow lakes yi et al 2016 the vertical transport of algae is more significant in the simulation of static water conditions however in waters with intense hydrodynamic effects such as tributaries of the yangtze river settling velocity has become an overall low sensitivity parameter with high sensitivity only in a few sub regions of the xiangxi river there was a clear negative feedback relationship between the algal biomass and the concentration of inorganic nutrients in simulated time in interannual time scale high nutrient concentrations promote algae growth and chl a concentration but algae uptake of nutrients reduces nutrient concentration during algae blooms on an intra annual scale pmc is a sensitive parameter for water quality simulation suggesting that algae as an important biological component in the model are closely related to n and p cycles the parameters of dissolved organic matter are more sensitive than those of labile particulate and refractory particulate organic matter this is because dissolved organic matter can be converted to inorganic matter and then utilized by algae so it has a stronger effect on the concentration of inorganic nutrients among the parameters for organic carbon kdc which reflects denitrification rate has a great influence on water quality simulation denitrification mainly occurs at low do concentration and is an important path for nitrogen removal but in the model kdc has obvious disturbance to both nitrate nitrogen and do simulation which means that we need to pay attention to the model mechanism of kdc in future research organic phosphorus parameters have little influence on other water quality simulations but phosphorus simulation is sensitive to kdn considering that there is no direct effect between different nutrients we tend to use their relationship to algae to explain this phenomenon phosphorus in the xiangxi river is sufficient for algae growth and utilization while the available nitrogen content of organisms varies below the biological utilization threshold during the simulation period that is why phosphorus simulation sometimes shows moderate or even high sensitivity to kdn 4 2 temporal and spatial variability of uncertainty the uncertainty of model simulation has obvious space time variability the ris of simulation results especially ammonia nitrogen and chl a in the middle and lower reaches of the xiangxi river are generally higher than that of other sub areas which indicates that the simulation at xx03 and xx06 sites have lower accuracy the main reason is the difference in flow hydrodynamic conditions at the cj site there is a fast flow velocity of the yangtze river in flood season the flow velocity at the xx09 site is also fast with the small section of the upstream river the middle and lower reaches of the xiangxi river with lower average flow rates are suitable for algae growth and the high concentration brings large uncertainty in water quality simulation the ui of chl a at the cj site is mainly distributed in non flood season october december at this time the flow rate slows down and algae start to proliferate the chl a uncertainty intervals at xx03 and xx06 sites have two peaks at may june and august september the former peak is caused by the difference of algae outbreak time between the upper and lower boundaries while the latter is due to the difference in peak estimation the uncertainty interval distribution of do in the xiangxi river is different in the vertical direction surface do uncertainty is disturbed by chl a uncertainty with high uncertainty of do at high chl a concentration meanwhile the distribution of middle layer do is more uniform in time the uncertainty interval of nitrate nitrogen and inorganic phosphorus in the xiangxi river is also concentrated at the outbreak of algae blooms in summer and autumn with two peaks the uncertainty in simulations of ammonia nitrogen in the middle and lower reaches of the xiangxi river has been maintained at a high level the variation trend of upper and lower boundaries is the same but the concentration level differs greatly it shows that there is great uncertainty in the simulation of ammonia and nitrogen in the backwater area the uncertainty interval distribution of nitrate nitrogen and phosphate is similar to that of chl a suggesting that they are also affected by algae simulation 5 conclusions in this study five simulated outputs of chl a do nitrogen and phosphorus were selected and 18 parameters of algae and organic matter were sampled glue and rsa methods with lhs were used for uncertainty and parameter sensitivity analysis of efdc models in the three gorges reservoir and xiangxi river the simulation outputs in different water layers were compared in algae kinetic parameters pmc and bmrc were sensitive parameters among the three algae groups in the model cyanobacteria had the greatest impact on the simulation in the study area in organic matter kinetic parameters the minimum hydrolysis respiration rates of dissolved organic matter kdc kdn and kdp were sensitive parameters which affected the simulation of the corresponding nutrient cycle greatly algae was an important component of model simulation algal biological action provides a vital link between nitrogen and phosphorus cycles the uncertainty of algae simulation would be introduced to the simulations of various water quality with biological processes and it was also brought to other areas with transport processes such as settlement and horizontal transport therefore in the simulation in surface water with eutrophication problem with low flow velocity understanding the influence of algae parameters is critical denitrification an important process of nitrogen cycle showed a certain impact on the simulations of nitrate nitrogen and do in addition the modeling boundary conditions and strong hydrodynamic effect interfered with the water quality processes in the water column credit authorship contribution statement song xu methodology software visualization writing original draft guojian he conceptualization data curation software validation hongwei fang supervision sen bai software writing review editing xinghua wu investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this investigation was supported by the national natural science foundation of china no u2040214 and china three gorges corporation no 201903145 and the 111 project b18031 
3320,water quality models are decision support tools for the planning and management of the aquatic environment however the application of the model needs an intricate calibration process due to the various ranges of numerous parameters to help improve the accuracy of model simulation and reduce the workload of parameter adjustment to similar surface waters parameter uncertainty and sensitivity analyses of the environmental fluid dynamics code efdc model were carried out in this study the efdc model was first calibrated and simulation results agree well with the measured data the generalised likelihood uncertainty estimation glue and regional sensitivity analysis rsa methods are then applied to analyze the uncertainty and sensitivity of the model eighteen kinetic parameters related to algae and organic matter are filtered and analyzed the results show that the sensitivities of the model to eighteen input parameters are significantly different the modeled algae levels measured as chlorophyll a chl a are highly sensitive to the optimal growth rate and the maximum basal metabolism rate of cyanobacteria bmrc and pmc with the sensitivity indices si at 0 66 and 0 78 respectively the inorganic nutrient levels phosphorus nitrate nitrogen and ammonia nitrogen are highly sensitive to minimum respiration rates of corresponding dissolved organic matter kdp and kdn with sis at 0 78 0 56 and 0 88 dissolved oxygen do is highly sensitive to pmc and kdc with their sis at 0 66 and 0 85 respectively the uncertainty interval is focused on the periods of high algae concentration the simulated uncertainty in the surface water is higher than that in middle layer water and might be related to algal transport processes like settlement and horizontal transport the results of the uncertainty and sensitivity analyses in this study support a better understand of the modeling mechanisms and provide scientific guidance for calibration in similar waterbodies keywords sensitivity analysis uncertainty analysis three gorges reservoir water quality simulation efdc 1 introduction water quality models have been widely used in studies of water environment problems since the development of the first river water quality model by streeter and phelps streeter phelps model in 1925 arnold et al 1998 brighenti et al 2019 krysanova and white 2015 xu et al 2013 these models can provide scientific support for water quality planning and environmental pollution research and they play important roles in identifying the dominant governing factors of water quality phenomena in surface waters it is very important to determine the dominant parameters controlling model behavior pappenberger et al 2006 for model development with the in depth research of physicochemical and biological processes in the lake and the improvement of computational performance many models are formed by comprehensive mechanisms at present many mechanistic models have been developed and commonly used such as efdc delft3d mike ce qual w2 wasp each model has its advantages and applicability arifin et al 2016 beck 1987 bieger et al 2017 james and boriah 2010 moses et al 2015 although mechanistic water quality models have been widely used identifying the right parameter values is still a challenge nature is a very complex system in which each biological chemical and ecological process is affected by various uncertain factors incomplete understanding of the mechanism will lead to the uncertainty of the models an appropriate method to optimize the simulation effect is to improve the accuracy of parameters which have great influence on the model results sensitivity analysis sa can improve the understanding of models responses to various parameters and is a useful tool to screen out highly sensitive parameters beck 1987 demirel et al 2018 jing and chen 2011 sensitivity analysis methods are classified as local sensitivity analysis lsa and global sensitivity analysis gsa in which the first approach affects a single parameter each time and the second approach focuses on the influence of multiple parameters and their relationships on the results lsa is easy to use but the results of gsa are more comprehensive and instructive the gsa methods including rsa method spear and hornberger 1980 sobol s method sobol 1993 and bayesian sensitivity analysis oakley and o hagan 2004 are commonly used in sa researches nowadays rsa has some gsa s global properties in consideration of the whole range of value of input factors and the variation of all factors at the same time for water quality models parameter values could be estimated and obtained from literature investigation or field measurement ejigu 2021 the modeling outputs based on different parameter values need to be compared with the observations proper values or valuable parameters are selected for further investigation the sensitive parameters vary in different water bodies because of the different environmental characteristics and main dynamic processes in many eutrophic surface water model results are sensitive to parameters related to biological processes of algae e g algal growth respiration and death missaghi et al 2013 due to algal ability to uptake and release nutrients and gases e g o2 and co2 biochemical transformations of nutrients e g mineralization denitrification jenny et al 2020 alter nutrient components and indirectly affect algal growth and metabolism the limiting factors of algae growth including nutrients light and temperature govern if algal bloom will occur however how these factors controlling the growth of algae are highly uncertain jiang et al 2018 in addition the spatial location and time differences also affect the simulation in a multi dimensional water body the temporal and spatial variations of modeling sensitivity and uncertainty in multi dimensional rivers lakes and reservoirs need to be evaluated biological reaction and nutrient cycles in surface waters are the focus of water quality simulation as algae and nutrients are two important components in the eutrophication process compared with consumers and macrophytes the biomass of algae can be large in some eutrophic waters and the nitrogen and phosphorus fluxes might be dominated by the nutrients uptake and release of algae qin 2009 ramin et al 2012 zou et al 2020 in efdc algae uses inorganic nutrient to increase biomass when growing and the biomass loss in basal metabolism is released into the water as a mixture of organic matter and inorganic nutrients availability of nutrient i e concentration of dissolved nutrient in the least supply limits production rate of algal group px thus reducing phosphorus concentration in freshwater has always been the main approach to control freshwater eutrophication kumar et al 2019 for the three state variables of organic matter particulate organic matter rpom and lpom can be decomposed into dissolved organic matter dom and dom can be mineralized into inorganic matter at the rate of krm klm and kdm in efdc fig 2 to effectively manage eutrophication it is necessary to consider the role of the nutrient cycle in the eutrophic water bodies that is the mechanism of material transformation and algae growth in this study we chose the three gorges reservoir as an example and the efdc model to conduct the sensitivity and uncertainty analysis the kinetic parameters of algae and organic matter were selected as the targets to be analyzed chl a do phosphate ammonia nitrogen and nitrate nitrogen were selected as model outputs the purpose of this study is to a quantify the sensitivity of water quality model to parameters and the uncertainty of model simulations b analyze the spatio temporal variability of uncertainty c explore the interaction between algae and organic matter under the simulated conditions of xiangxi bay with the low flow velocity the research results can deepen the understanding of parameter coupling relationships and mechanisms in the efdc model and provide insights to improve the calibration in similar waterbodies 2 methods 2 1 study area three gorges reservoir tgr the largest reservoir in china is an artificial lake formed by the impoundment of the three gorges dam tgd in the yangtze river the tgr is located across the hubei province and chongqing municipality 105 44 111 39 e 28 32 31 44 n and has a surface area of approximately 1084 km2 at the normal water level of 175 m the backwater end of the tgr reaches jiangjin district chongqing forming a channel type reservoir with a length of 667 km and an average width of 1100 m the flow rate of the yangtze river is generally 0 1 0 2 m s in the non flood season and 0 2 0 5 m s in the flood season the construction of tgd has changed the flow conditions of the river and made the flow velocity much lower than it would be under natural conditions nutrients concentration in yangtze river was above the thresholds for eutrophication total nitrogen 0 2 mg l total phosphorus 0 02 mg l yang et al 2010 algae blooms occurred in the daning river a tributary of the yangtze river after the first impoundment of tgr in 2003 and the increasing frequency of algal bloom outbreaks in tributaries is causing concern holbach et al 2013 liu et al 2016 zheng et al 2009 the xiangxi river situated in hubei province is the largest tributary of the yangtze river with a length of 94 km its river mouth is about 34 km upstream of the tgd and the watershed area is about 3099 km2 gao et al 2018 as the nearest tributary to the dam the hydrodynamic conditions of the xiangxi river have changed dramatically due to impounding after the impoundment of tgr a backwater zone with low flow velocity called xiangxi bay was formed in this tributary the temperature ranges from 7 c to 29 3 c and the precipitation ranges from 650 mm to 2100 mm in xiangxi bay the typical hydrological year for xiangxi bay consists of a dry season january march and december a wet season may september and a normal season april and october november the algae blooms in the xiangxi river are typical and prominent which have a great influence on water quality in front of the dam therefore this tributary is chosen as a vital research area 2 2 model description efdc originally developed by john hamrick hamrick 1992 is a comprehensive modeling system that integrates hydrodynamic sediment transport toxic contaminant eutrophication and water quality modules it is one of the most widely used ecological and hydrodynamic models applied to reservoir lake river and wetland research bai and lung 2005 gong et al 2016 he et al 2011 algae and organic matter are important components of the model algae occupy a central role in the water quality module and are grouped into three variables in the efdc model cyanobacteria diatoms and green algae the grouping is mainly based on growth rate metabolism rates settling velocities and influences of nutrients light and temperature on the growth rates of each class the sources and sinks of algae include production basal metabolism predation settling and external loads and the kinetic equation is 1 b x t p x b m x p r x b x z w s x b x w b x v where the subscript x is used to denote three algal groups c for cyanobacteria d for diatoms and g for green algae bx is algal biomass px is production rate bmx is basal metabolism rate prx is predation rate wsx is positive settling velocity wbx is external loads and v is cell volume the efdc model has three state variables for organic carbon nitrogen and phosphorus which are refractory particulate labile particulate and dissolved organic carbon nitrogen and phosphorus in the water quality module three states of organic matter convert into each other and affect the growth of algae fig 2 2 3 model configuration the computational fig 1domain fig 1 includes the reaches of the yangtze river and xiangxi tributary with the length of 70 km and 30 km respectively to fit the boundary better the orthogonal horizontal and curvilinear coordinates are put into use the computational domain is divided into 742 grid cells in the horizontal plane and 10 layers in the vertical sigma coordinate the simulated period is set to the year 2010 january december and the model runs at a 6 0 s model time step for a 365 d initial conditions of water level and water temperature are set as constant values because a previous study gao et al 2018 shows that the impacts of the boundary conditions make the interference of initial conditions on simulation disappear in a short time the upstream boundaries are the time series of inflow in the yangtze river and xiangxi river and the downstream boundary is the time series of outflow in tgd the upstream boundary conditions of water temperature are the observations at different depths other boundary conditions data including precipitation air temperature solar radiation atmospheric pressure and wind are obtained from china meteorological administration upstream loadings of nutrients are also included in the model fig 3 gao et al 2018 presents the observed values of total nitrogen and total phosphorus in the inflows of the yangtze river and xiangxi river in 2010 in the study area ten sampling sites are set along the xiangxi river xx01 xx10 and one site cj is set at the estuary of xiangxi tributary in yangtze river to monitor the water quality variables four sampling sites cj xx03 xx06 and xx09 are chosen in the research representing the different reaches of the river from the upstream xx09 to the downstream estuary xx03 the river channel gradually deepens and widens and the velocity slows down at cj site the flow with high velocity is influenced by the mainstream of the yangtze river the model calibration was conducted in a previous study gao et al 2018 the predicted results and observations of flow velocity and water temperature were compared to examine the model performance the model could simulate the flow velocity and water temperature with high accuracy in xiangxi bay but in the upper reaches of the xiangxi river the inaccuracy of the upstream boundary conditions leads to under predictions of flow velocity further the neglect of the spatial heterogeneity of meteorological conditions and heat exchange between the bottom water and riverbed resulted in slightly over prediction of temperature the results of the water quality simulation were in agreement with actual trends and distributions however boundary conditions also affected the simulation in the upper reaches the predictions of chl a concentration were lower in march and april and higher in summer and autumn than observations 2 4 analysis methods the uncertainty and sensitivity analysis of the efdc model for tgr and xiangxi river is based on glue and rsa methods the detailed analysis process is shown as follows 2 4 1 parameter identification understanding the water blooms in the yangtze river and xiangxi tributary is urgent since water blooms are increasingly likely to occur as previously mentioned interactions between algae and nutrients are important processes in eutrophication simulations in this study algal and organic matter parameters are selected as research priorities certain parameters of three algae groups were selected such as basal metabolism rate bmrx settling velocity wsx and maximum growth rate pmx with the consideration that the competitive relationship amongst different algae groups was not sufficiently evaluated in the previous study the half saturation constants for nitrogen and phosphorus uptake khnx and khpx are also major parameters of algal growth however since the nutrient concentrations of xiangxi tributary are at the eutrophication level and the half saturation constants for nutrients have no obvious influence on water quality simulation pmx is selected instead in this study the classification standard of organic matter in efdc is their decomposition rates the actual chemical components of these organic components are not known in related application researches the hydrolysis rates of nutrient components are mostly set as default values yi et al 2016 uncertainty in the values of hydrolysis rates introduces uncertainty to model results therefore the decomposition rates of organic matter are also selected eventually 18 parameters of algae biological parameters and organic matter dynamics parameters were selected in this study the ranges of these parameters determined through an investigation of the literature arhonditsis and brett 2005 he et al 2011 pang et al 2008 wang et al 2014a wang et al 2014b wu and xu 2011 zou et al 2020 are shown in table 1 with their descriptions 2 4 2 sampling of input parameters with the lhs method as a commonly used sampling method in uncertainty and sensitivity analysis latin hypercube sampling lhs combines the characteristics of random sampling and stratified sampling and could produce more stable analysis outcomes helton and davis 2003 the lhs method operates in the following manners to generate a sample of each parameter dividing the range of each parameter into disjoint intervals with equal size sampling one value randomly in each interval and randomly combining the distributions of each parameter into sampling sets the denser sampling number makes the uncertainty and sensitivity analysis result more stable sheikholeslami and razavi 2017 the parameter prior distribution adopts uniform distribution the annual average concentrations aac of water qualities output were used to characterize the performance of a behavioral simulation the convergence was judged by plotting the mean and variance of aacs of behavioral simulations in different numbers of model runs the mean μ and variance σ2 were calculated as μ n i 1 n θ n σ 2 n i 1 n θ μ 2 n 1 where n is the number of model runs n is the number of behavioral simulations in n and θ is the aac of water quality output these values were plotted against an increasing number of samples as shown in figs 4 5 to identify convergence the mean aac of five water qualities increased with the number of model runs but the values did not change significantly after n reached 400 the variances decreased rapidly with n but the variation continues to level off after n reached 400 these approximate mean values indicate small differences among the aac of water quality outputs of behavioral simulations for variances of aac the sharp decrease at the beginning should be due to the small number of behavioral simulations the variance of most water quality outputs after the sample size exceeded 400 shows some convergence for water qualities simulated in the upper layers at sites xx06 and xx09 the continuously slight decrease with the larger n larger than 500 of their variance is predictable in summary combining the convergence of the mean and variance and the calculation amount we consider that the sample size of 500 is acceptable for uncertainty and sensitivity analysis 2 4 3 uncertainty analysis with the glue method beven and binley beven and binley 1992 used the glue methodology for model identification in glue the likelihood measure value is associated with a parameter set and quantifies how well that the parameter value combination simulates the system beven and freer 2001 blasone et al 2008 glue methods are generally considered as informal bayesian or non classical bayesian methods and could avoid the optimal partial solution it is simple and feasible and is widely used in sa of water quality model 500 sets of input parameters obtained by lhs method were used in efdc and 500 sets of simulation results are obtained using the nash sutcliffe coefficient expresses the likelihood measure lm 3 l θ i 1 α i 2 α 0 2 where i indicates the ith model l θ i is the lm for the simulation results relative to the observations α i 2 is the error variance of simulation results and α 0 2 is the variance of the observations the likelihood measures are normalized in order to facilitate subsequent data processing 4 l θ i l θ i l min θ i l max θ i l min θ i where l θ i is the normalized likelihood measure l max θ i and l min θ i are the maximum and minimum values of all likelihood measures respectively nash sutcliffe efficiency nse indicates how well the plot of observed versus simulated data fits the 1 1 line and is generally used to verify the quality of hydrological model simulation results the simulations with lm above the threshold nse 0 are accepted as behavioral simulations the normalized likelihood measures are sorted by their values the 2 5th and 97 5th percentiles are selected as the lower and upper bounds of the confidence intervals the simulation uncertainty interval ui is represented by the distance between upper and lower bounds and the model uncertainty analysis is carried out by the ratio of the observations in the uncertainty interval ri and the distribution of the ui 2 4 4 sensitivity analysis with the rsa method the rsa methodology was established by spear and horn berger spear and hornberger 1980 for the parameter sensitivity analysis of the model the advantages of rsa method e g glue are its simple concept relative ease to implement and its generality to handle different models after simply improving its methods yang 2011 blasone et al 2008 a python safe toolbox wagener et al 2001 is used in rsa computation in this research the basic idea of rsa is as follows in rsa parameter sets are grouped based on model response measures kolmogorov smirnov k s test kottegoda and rosso 1997 is used to compare the distribution of sub samples we divide the input parameter sets into 10 groups based on normalized likelihood measures of their simulation results and use the cumulative distribution function cdf f x to represent the distribution of each group 5 f i n x 1 n k 1 n i x x k where subscript i and n means the number of parameter sets in the ith group is n i x is the indicator function equal to 1 if xk x and equal to 0 otherwise use d a k s test statistic to quantify the distance between two cdfs of two groups and the maximum vertical distance mvd of all groups is calculated as si 6 mvd d i j max f i m x f j n x the parameters are divided into three categories according to the si high sensitivity parameters si 0 7 medium sensitivity parameters 0 4 si 0 7 and low sensitivity parameters si 0 4 3 result 3 1 uncertainty analysis figures 6 10 shows the water quality simulation results of 95 confidence interval at four sampling sites cj xx03 xx06 and xx09 in the three gorges reservoir the simulation results of chl a do no3 n nh4 n and po4 p at the four stations show the same trend as the observation data the proportion of observations in uncertainty interval cr are mostly higher than or equal to 60 table 2 which means that the observed values are within the confidence interval it indicates that the simulation of the efdc model in three gorges reservoir and xiangxi bay is feasible the variation trends in chl a do and nutrient concentrations among the four sites and between the upper and middle layers at the same site showed a certain degree of consistency the simulated chl a concentrations have similar trends at 3 sites in xiangxi river the chl a reflects the survival of algae the algae did not grow on a large scale under the low temperature in spring affected by temperature and the release of nutrients upstream algae begin to proliferate explosively in summer and then wilt in winter the simulation is in good agreement with the timing of algal rapid growth in the xiangxi river due to light conditions algae mainly distribute on the surface water so chl a concentration in the middle layer is much lower than that in surface water the observed concentrations of chl a are close to the boundary of the confidence interval which meant the model estimates the outbreak intensity of algae higher than the actual one it may be that some factors interfering with the growth of algae have not been accurately reflected in the simulation the simulation results of do in xiangxi river are consistent with that of chl a when the algal biomass increases the do in water increases and vice versa the relationship indicates that no mass hypoxic death after the outbreak of algae and oxygen is not the limiting factor for the growth of algae the trend of nitrogen and phosphorus simulation results is opposite to that of chl a when the concentration of algae increases greatly in may june and august october the inorganic nitrogen and phosphorus in the waters decrease gradually and when algae bloom decreases in july september the nutrient concentration in the waters recovers again logically algae uptake may be the main reason for the decrease of dissolved nutrients during algae blooming the hydrodynamic and model boundary conditions have a clear and visible effect on the simulations at cj site and xx09 site the cj site is located in the yangtze river where the flow rate is fast during the flood season and algae are strongly scoured by water flow therefore the outbreak of chl a concentration starts in the non flood season after october with low intensity compared with the xiangxi river the occurrence time of the algal bloom in the yangtze river is delayed the do and nutrient simulations are also greatly affected by the high flow rate in the flood season at cj and xx09 sites the confidence interval of the simulation in summer is obviously similar to the boundary condition of upstream input and the upper and lower boundaries fluctuate slightly only at the end of the year in the upper layer at xx09 site the time series of chl a and nutrient concentrations shows several low valleys of which the values are close to 0 the two boundaries nearly draw close to one another in flood season because the site is close to the upstream of the xiangxi river the simulation is affected by the inflow boundary such as the river scouring by short storms in summer table 2 shows the four simulation indices of figs 6 10 the average ratio of uncertainty interval to the mean of the simulated values ri is used to measure the degree of uncertainty the ri of chl a at xx03 and xx06 sites and in the surface layer at cj site are high more than 20 showing that there is great uncertainty in chl a simulation in these sub areas the mean width of uncertain interval mu is about the same as the mean value of observations mo considering that discrete measurements do not fully represent the actual chl a concentration over a year e g more observations distributed over low concentrations the actual average concentration in terms of mo may have been underestimated here the ri of ammonia nitrogen at xx03 and xx06 sites are also at a high level more than 20 with mu accounting for nearly half of the mo the uncertainty of these two water quality simulation results cannot be ignored although the mo of ammonia nitrogen in this study area is slightly lower than that of nitrate nitrogen the uncertain contribution of ammonia nitrogen to nitrogen cycle simulation still needs to be noted compared with the simulation in the surface layer the simulation of ammonia nitrogen in the middle layer has slightly greater cr and lower ri cr varies slightly and the ri is lower for the simulations of phosphate and nitrate nitrogen in the middle layer considering the biological and environmental differences between surface and middle layer of water it may be due to errors in the simulation of algae participating in the water quality cycle or to the errors in the wind temperature and light parameters 3 2 parametric sensitivity analysis the si of the parameters are expressed by the maximum vertical distances mvd obtained by k s test of the rsa method fig 11 shows the parameter si of each simulation result in different zones pmc the maximum growth rate under optimal conditions of cyanobacteria has a great influence on almost every water quality simulation pmc affects the source of algae in the kinetic equation of efdc and increases the biomass of cyanobacteria photosynthesis during algae growth releases oxygen and sequestrates carbon diatoms and green algae in water compete with cyanobacteria however the effects of their biodynamic parameters on water quality simulation are at the same level and not significant si is less than 0 4 this indicates that cyanobacteria are dominant algae in the tgr and xiangxi bay in chl a simulation bmrc and pmc are high sensitivity parameters while wsc and kdn are medium sensitivity parameters in some zones bmrc and wsc directly affect the biomass sink of cyanobacteria in the dynamic equation the high sensitivity of chl a to wsc means that the uncertainty of surface algae concentration is brought to the algae simulation in the middle layer with sedimentation the si of kdn at xx03 and wsc at xx09 are slightly higher than those in other zones which means kdn and wsc have obvious spatial distribution differences and deserve attention in modeling simulation the most sensitive parameters in do simulation are kdc and pmc kdc represents the minimum dissolution rate of dissolved organic carbon and is also an important parameter of denitrification in the model kdc in efdc affects heterotrophic respiration of dissolved organic carbon which is a sink of do the si of middle layer kdc is higher than that of upper layer kdc in all zones and it can be explained by the low concentration of do in the middle layer anaerobic conditions can promote denitrification do simulation is mainly influenced by cyanobacteria simulation because their trends are the same kdp and kdn are high sensitivity parameters in phosphorus and nitrogen simulation respectively due to its fast decomposition rate dissolved organic matter in the model is very important in three organic matter components therefore the optimization of its decomposition rates plays a decisive role in the simulation of corresponding nutrients the effect of kdn on ammonia nitrogen is greater than that on nitrate nitrogen there are some differences between the sensitive parameters of the two inorganic nitrogen ammonia nitrogen simulation is more sensitive to kdn while nitrate nitrogen is more sensitive to pmc the sensitivities of kdc and bmrc in nitrogen simulation vary with indicator and spatial position phosphorus simulation is sensitive to various parameters at the same time the high sensitivity parameters are kdp and pmc while the medium sensitivity parameters are klp kdn and bmrc the decomposition of labile particulate organic phosphorus promotes the increase of nutrient concentration and increased nutrient concentration weakens the growth restriction of algae which in turn promotes the uptake of nitrogen and phosphorus nutrients 4 discussion 4 1 influence of input parameter categories the kinetic parameters of algae and organic matter were selected for the study the sensitivity of different parameters to different water quality simulations varies among the three algae groups the parameters of green algae and diatom had little influence on the model simulation the main reason may be that cyanobacteria are dominant species in the environment of the xiangxi river and the dynamic functions of green algae and diatoms could not be well reflected reasons for differences in sensitivity to the same kinetic parameter among different algae groups can be studied further in other water areas the settling rate of cyanobacteria is a highly sensitive parameter of the eutrophication models in wide and shallow lakes yi et al 2016 the vertical transport of algae is more significant in the simulation of static water conditions however in waters with intense hydrodynamic effects such as tributaries of the yangtze river settling velocity has become an overall low sensitivity parameter with high sensitivity only in a few sub regions of the xiangxi river there was a clear negative feedback relationship between the algal biomass and the concentration of inorganic nutrients in simulated time in interannual time scale high nutrient concentrations promote algae growth and chl a concentration but algae uptake of nutrients reduces nutrient concentration during algae blooms on an intra annual scale pmc is a sensitive parameter for water quality simulation suggesting that algae as an important biological component in the model are closely related to n and p cycles the parameters of dissolved organic matter are more sensitive than those of labile particulate and refractory particulate organic matter this is because dissolved organic matter can be converted to inorganic matter and then utilized by algae so it has a stronger effect on the concentration of inorganic nutrients among the parameters for organic carbon kdc which reflects denitrification rate has a great influence on water quality simulation denitrification mainly occurs at low do concentration and is an important path for nitrogen removal but in the model kdc has obvious disturbance to both nitrate nitrogen and do simulation which means that we need to pay attention to the model mechanism of kdc in future research organic phosphorus parameters have little influence on other water quality simulations but phosphorus simulation is sensitive to kdn considering that there is no direct effect between different nutrients we tend to use their relationship to algae to explain this phenomenon phosphorus in the xiangxi river is sufficient for algae growth and utilization while the available nitrogen content of organisms varies below the biological utilization threshold during the simulation period that is why phosphorus simulation sometimes shows moderate or even high sensitivity to kdn 4 2 temporal and spatial variability of uncertainty the uncertainty of model simulation has obvious space time variability the ris of simulation results especially ammonia nitrogen and chl a in the middle and lower reaches of the xiangxi river are generally higher than that of other sub areas which indicates that the simulation at xx03 and xx06 sites have lower accuracy the main reason is the difference in flow hydrodynamic conditions at the cj site there is a fast flow velocity of the yangtze river in flood season the flow velocity at the xx09 site is also fast with the small section of the upstream river the middle and lower reaches of the xiangxi river with lower average flow rates are suitable for algae growth and the high concentration brings large uncertainty in water quality simulation the ui of chl a at the cj site is mainly distributed in non flood season october december at this time the flow rate slows down and algae start to proliferate the chl a uncertainty intervals at xx03 and xx06 sites have two peaks at may june and august september the former peak is caused by the difference of algae outbreak time between the upper and lower boundaries while the latter is due to the difference in peak estimation the uncertainty interval distribution of do in the xiangxi river is different in the vertical direction surface do uncertainty is disturbed by chl a uncertainty with high uncertainty of do at high chl a concentration meanwhile the distribution of middle layer do is more uniform in time the uncertainty interval of nitrate nitrogen and inorganic phosphorus in the xiangxi river is also concentrated at the outbreak of algae blooms in summer and autumn with two peaks the uncertainty in simulations of ammonia nitrogen in the middle and lower reaches of the xiangxi river has been maintained at a high level the variation trend of upper and lower boundaries is the same but the concentration level differs greatly it shows that there is great uncertainty in the simulation of ammonia and nitrogen in the backwater area the uncertainty interval distribution of nitrate nitrogen and phosphate is similar to that of chl a suggesting that they are also affected by algae simulation 5 conclusions in this study five simulated outputs of chl a do nitrogen and phosphorus were selected and 18 parameters of algae and organic matter were sampled glue and rsa methods with lhs were used for uncertainty and parameter sensitivity analysis of efdc models in the three gorges reservoir and xiangxi river the simulation outputs in different water layers were compared in algae kinetic parameters pmc and bmrc were sensitive parameters among the three algae groups in the model cyanobacteria had the greatest impact on the simulation in the study area in organic matter kinetic parameters the minimum hydrolysis respiration rates of dissolved organic matter kdc kdn and kdp were sensitive parameters which affected the simulation of the corresponding nutrient cycle greatly algae was an important component of model simulation algal biological action provides a vital link between nitrogen and phosphorus cycles the uncertainty of algae simulation would be introduced to the simulations of various water quality with biological processes and it was also brought to other areas with transport processes such as settlement and horizontal transport therefore in the simulation in surface water with eutrophication problem with low flow velocity understanding the influence of algae parameters is critical denitrification an important process of nitrogen cycle showed a certain impact on the simulations of nitrate nitrogen and do in addition the modeling boundary conditions and strong hydrodynamic effect interfered with the water quality processes in the water column credit authorship contribution statement song xu methodology software visualization writing original draft guojian he conceptualization data curation software validation hongwei fang supervision sen bai software writing review editing xinghua wu investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this investigation was supported by the national natural science foundation of china no u2040214 and china three gorges corporation no 201903145 and the 111 project b18031 
3321,this study assesses the performance and limitations of slim hole borehole nuclear magnetic resonance nmr technology from a hydrogeologic perspective in fractured porous rock nmr logging was carried out in dolomitic and sandstone bedrock boreholes at two research test sites in ontario canada where aquifer and aquitard units provide a range of clay contents as well as a variety of primary and secondary porosity types e g discrete fractures reefal structures vugs and karstic conduits results were compared to core measurements geophysical logs and hydrogeophysical testing the vertical response curve of the instrument tested was found to produce 60 of the signal from within a 0 2m span surrounding the measuring point the repeatability of the total porosity measurements in stationary mode is excellent where the porosity is greater than 0 15 below that threshold repeatability is scattered at 0 05 porosity about the mean with the variability primarily within the clay and capillary bound fractions the nmr porosity estimates agreed with core measurements to within 0 04 porosity in both the dolostone and sandstone but the correlation deteriorates in finely bedded lithologies and where fracturing is present much of the discrepancy is attributed to scaling in a finely layered geologic sequence as the core samples are much smaller than the entire volume measured with nmr probes data collection with the probe in motion continuous logging added variability to the response when compared to stationary recordings although broadscale trends were comparable the details and depth specific insights of the bound fluid fractions varied with logging rates overall nmr provides a robust measurement of the bulk matrix porosity and pore size distribution of lithologies intersected both of which are critically important parameters in understanding hydrogeologic conditions and contaminant distributions in layered sedimentary rock systems keywords nmr logging fractured rock hydrogeologic investigation resolution limitations porosity 1 introduction sedimentary bedrock aquifers are critically important to the supply of potable water for many communities throughout the world e g berkowitz 2002 brunton and brintnell 2020 protection of these resources often requires an advanced understanding of the local geology and hydrodynamic controls this often calls for the application and refinement of both existing and evolving geophysical hydro geophysical and hydrogeological technologies and techniques as new tools and approaches become more broadly used there is a need for impartial assessment and standardization between systems that can only be accomplished at well characterized real world field facilities with multiple data types that provide a consistent basis for comparison calibration standardization and assessment of borehole technologies in bedrock environments is critically important to a variety of disciplines such as environmental geotechnical mining and nuclear waste management one such emerging technology is slim hole borehole nuclear magnetic resonance nmr logging nmr is an established geophysical technology in the petroleum industry used to measure total porosity and distribution of pore fluids classed by mobility decades of research led to the development of models to estimate permeability or hydraulic conductivity in reservoir rocks from nmr data and material specific empirical constants e g allen et al 1997 coates xiao and prammer 1999 dunn bergman and latorraca 2002 over the past decade the technology has been adapted and nmr instrument dimensions have been reduced in size sucre et al 2011 walsh et al 2013 hopper et al 2017 allowing sondes to be deployed in narrow diameter bedrock and plastic cased sediment boreholes common to shallow environmental investigations this generated significant interest for application in unconsolidated sediment boreholes to estimate in situ water contents e g kass et al 2017 crow et al 2020 and develop empirical constants to estimate hydraulic conductivity in sediment e g dlubac et al 2013 dlugosch et al 2013 johnson et al 2014 parsekian et al 2015 knight et al 2016 maurer and knight 2016 kirkland and codd 2018 kendrick et al 2020 laboratory nmr systems were used to support the interpretation of slim hole nmr tools through the development of sediment sampling strategies behroozmand et al 2017 and the examination of magnetic gradients on nmr response e g fay et al 2015 keating et al 2020 case studies of the deployment of slim hole nmr tools in environmental studies in fractured bedrock aquifers have been presented by the usgs and others johnson et al 2015 day lewis et al 2017 ren et al 2018 johnson et al 2021 numerous hydrogeological studies identify variability in rock porosity as key to informing permeability and diffusion properties of porous media and thereby contaminant persistence and distribution e g berkowitz 2002 parker et al 1994 2010 chapman and parker 2005 which are often pervasive threats to aquifers the complexities of fracture and matrix flow in bedrock aquifers present unique challenges when applying nmr technology as instrument response is affected by a number of tool and acquisition factors as well as site specific geologic conditions this requires that users have a practical sense of the advantages and limitations of this technology such as instrument repeatability the length and shape of the tool s response function over the volume of measurement trade offs between logging speed and data quality the resolution limits of geological features important in fractured rock investigations i e fractures vugs pores as well as the relationships between core and downhole nmr measurements this article presents a unique controlled field study addressing these questions along with a discussion of the practical implications for the hydrogeological community studying fractured rock the study deploys slim hole nmr tools within fractured sedimentary bedrock boreholes at two calibration test sites the fractured rock observatory fro at the university of guelph fig 1 a and the geological survey of canada s gsc bells corners borehole calibration facility in ottawa both sites have rich datasets of continuous cores with porosity analyses as well as a broad suite of complementary geophysical logs and hydrogeophysical testing the study objective is to provide insight into nmr data collection interpretation and tool limitations as well as to assess the relationship between nmr response and other measurement approaches testing was designed to provide practical considerations for integrating this technology into hydrogeological studies and show how nmr measurements can add additional insight into insitu hydrogeologic conditions that are difficult to achieve with other means 1 1 geological setting and bedrock test sites the geology of southern ontario and the paleozoic st lawrence platform sanford 1993 are areas of significant hydrogeological interest largely because these include locally important aquifers and have characteristics in common with other sedimentary basin rocks of north america the fro site intersects a carbonate dominated succession that forms the regional water supply aquifer for guelph and surrounding communities the bells corners facility in ottawa is drilled through cambrian and ordovician siliciclastic and carbonate sediments e g johnson et al 1992 sanford and arnott 2010 utilized by several smaller communities surrounding ottawa the guelph facility is designed to support ongoing hydrogeologic research through multi institutional and inter disciplinary geoscience collaborations the borehole cluster fig 1b was diamond drilled in 2013 2014 using fresh water and consists of ten continuously cored boreholes six vertical and three inclined at 60 deg from the horizontal within an area of 0 6ha the five open vertical central boreholes 73 74 m deep 122mm diameter shown in blue are the focus of this nmr study the boreholes intersect a 60m thick dolostone sequence of the niagara escarpment region of southern ontario comprised of the eramosa goat island gasport irondequoit rockway and merritton formations each with varying clay content fig 1b and terminate in the top of the cabot head shale brunton 2009 brunton and brintnell 2020 the shale forms a roughly 10 39m thick regional aquitard singer et al 2003 the gasport formation along with the overlying guelph formation not intersected at the site are the target aquifers munn 2019 identified four main hydrogeologic units through the dolostone sequence at the facility the lower goat island formation niagara falls member gasport and irondequoit formations have generally low clay content with various forms of primary and secondary porosity including fractures of varying aperture reefal structures vugs voids and occasional dissolution enhanced fractures and matrix porosity features the ancaster member of the goat island formation and the vinemount and reformatory quarry members of the eramosa formation vary laterally locally acting as an aquitard above the regional groundwater aquifer that serves nearly one million people with drinking water the boreholes are pvc cased 0 15m diameter schedule 80 to facilitate geophysical testing through 12 15m of surficial quaternary age mud sand and gravel diamict and are located on the margin of a buried bedrock valley steelman et al 2018 these holes have undergone a broad range of hydrogeophysical testing with novel active line source als and distributed temperature sensing dts thermal techniques straddle packer and point dilution testing as part of ongoing research details of the site and geology are summarized in multiple theses kennel 2008 munn 2012 2019 fomenko 2015 maldaner 2017 and publications steelman et al 2018 maldaner et al 2019 munn et al 2020 in addition to detailed core analysis and documentation these works focus on thorough geophysical logging including video imaging optical and acoustic televiewers as well as gamma apparent conductivity and full waveform sonic for rock property measurements the ottawa facility was developed in the early 1980 s by the gsc to provide a national calibration site where geophysical instruments could be tested against a series of core and longer term repeated downhole log values killeen 1986 bernius 1996 mwenifumbo et al 2005 crow et al 2021 six vertical boreholes 76 mm to 96 mm in diameter were diamond drilled with fresh water ranging in depth from 75 m to 300 m are located within a one hectare area the holes intersect 4 5 m of fill plastic lined steel cased three lower paleozoic sedimentary formations before terminating in precambrian igneous and metasedimentary bedrock fig 1c the precambrian rock consists of 1 1 5 ga grenvillian syenites granites and gneisses bernius 1996 davidson 1998 the overlying sandstone of the nepean formation potsdam group consists of a quartz arenite of upper cambrian to lower ordovician age primarily derived from the grenville province sanford and arnott 2010 lowe et al 2017 cross bedding ripple marks and vertical burrows are commonly observed the overlying sedimentary rock units are part of the beekmantown group and consist of sandy dolostones of lower ordovician age theresa formation transitioning upward into the calcitic and non calcitic dolostone of the beauharnois formation bernstein 1992 dix et al 2004 the nepean sandstone is recognized as an important but vulnerable regional aquifer in southeastern ontario mrspr 2011 and its characteristics are the focus of a recent multidisciplinary study investigating its potential as a groundwater supply in outlying areas of ottawa undergoing municipal development pehme et al 2018 the site has and continues to undergo investigation by the gsc augmented by various industry and academic collaborators including core logging laboratory analyses a broad suite of geophysical logging as well as being the focus of past and upcoming hydrogeophysical testing 2 approach and methods this study is designed to assess the performance and application of slim hole nmr in these two sedimentary bedrock aquifer settings but the results have general implications on technology performance and limitations elsewhere specifically we examine the technology s performance in estimating the total fluid filled porosity of the formation whether the pores have mobile capillary or bound water and to what extent discontinuities fractures would contribute to the response as well as evaluating the compromises inherent in different modes of deployment data presentation and analysis includes assessing tool features and implementation options survey parameters as these influence response variabilities sensitivity and possible bias as well as the spatial resolution of various geologic features hydrogeologic conditions and total and effective porosity conditions based on comparison against independent geophysical and petrophysical datasets 2 1 borehole nmr systems borehole nmr logging applies the same principles as the well established laboratory nmr measurements e g mr imaging nmr spectroscopy except that the rock or sediment is outside the source sensors rather than inside this results in weaker and more variable magnetic fields across the sample volume design elements such as the magnet strength the configuration of the transmitting receiving antenna and the radio frequency rf pulse sequencing are key considerations in overcoming these challenges hürlimann and heaton 2015 details on the phenomena of nuclear magnetic relaxation and the technical evolution of nmr sondes can be found in books by coates et al 1999 and dunn et al 2002 briefly nmr logging technology uses the quantum mechanical response of proton spin to a changing magnetic field to investigate hydrogen in pore fluids hosted in sediments and rock outside the borehole the tools use strong magnets to polarize hydrogen in groundwater and then apply a series of rf pulses termed a cpmg pulse sequence transmitted by an antenna in the tool to induce a spin echo decay signal between each pulse fig 2 a for a magnetic field of fixed strength different rf pulses are sensitive to different diameters of investigation or cylindrical shells around the tool with a radial thickness of a few dm fig 2c and operational frequencies are chosen to optimize instrument performance while minimizing influence from other factors e g cultural interference such as radio waves etc the length of the cylindrical shell is approximately equal to the length of the rf coil although details are explored further below higher frequency signals have sensitivity closer to the tool and generally provide a better signal to noise sn ratio while lower frequencies may have poorer sn ratios but penetrate further into the formation and thus may be less affected by drilling disturbance the repeated pulsing creates measurable signals with diminishing amplitudes over time which are fit with a multi exponential curve representing the t2 relaxation time to improve the sn ratio the signals are stacked multiple times and averaged keeping the tool stationary during recording and increased stacking also improves the sn ratio walsh et al 2013 the initial signal amplitude of the t2 curve is directly proportional to the total volume of water excited by the tool the shape or decay of the t2 curve is influenced by the pore sizes generally the signal from water bound in clay or small capillary bound pores decays very quickly while the response from mobile water in larger pores decays relatively slowly an amplitude t2 distribution curve is calculated from an inversion of the t2 decay curve boundaries t2 cut off times are allocated within the t2 distribution curve to differentiate between bound capillary and mobile proportions of the total pore space fig 2b the cut off times depend on the lithology and are typically based on values from published laboratory studies of representative rock or sediment types see kenyon 1997 allen et al 2000 dunn et al 2002 in a logged borehole the t2 distribution curves are typically plotted as horizontal bars with colour representing amplitude against depth to show how volumetric water content porosity in fully saturated materials and pore size distributions are changing downhole this variability in total and mobile porosity with depth provide insights on subsurface heterogeneity informing permeability and diffusion properties of porous media it is the ability to differentiate the water content distribution that largely differentiates nmr from other earlier geophysical techniques used to estimate porosity such as neutron and gamma gamma density interpretation of neutron logs the only other geophysical technique that directly measures hydrogen content requires other data e g gamma logs etc to estimate the portion of the water bound in clays hearst et al 2000 estimating porosity from gamma gamma logs requires an assumption of matrix density to infer the water content e g keys 1997 the major disadvantage of using either neutron or density tools is that both are energized by radioactive sources with inherent regulatory storage and logistical requirements as well as liability concerns although other geophysical techniques such as full waveform sonic galvanic resistivity inductive conductivity etc can be used to infer porosity multiple rock parameters and empirical constants must be assumed which can vary dramatically with lithology although not generally a concern in shallow hydrogeologic applications interpretations of the porosity are further complicated for all techniques if the pore fluid also contains hydrocarbons e g oil gas etc an important consideration in the use of nmr technology is its sensitivity to the concentration and grain size of magnetic minerals primarily magnetite in the material surrounding the borehole internal gradients between the grains and the pore fluid if sufficiently strong will act to shorten the t2 relaxation times dunn et al 2002 keating and knight 2007 fay et al 2015 in carbonate bedrock and quartz sandstones such as those logged in this study magnetic minerals are typically not present in sufficient concentrations to affect nmr measurements however in clastic sedimentary or igneous bedrock settings where magnetic mineralogy may be present in higher concentrations porosity and pore size distribution estimates may be compromised or in some cases the nmr signal entirely disrupted currently there are two manufacturers providing a range of small diameter nmr tools available in north america vista clara mukilteo wa usa and more recently nmr services australia nmrsa perth australia each manufacturer has adopted their own approach to the design of their instruments walsh et al 2013 hopper et al 2017 respectively there are proprietary technological distinctions between the systems that primarily manifest as differences in the operating frequency bands vertical resolutions and the number of frequencies used during the measurements table 1 the nmrsa system uses a single nominal frequency which produces a comparatively thicker measurement zone a thin cylindrical shell at one diameter of investigation doi the vista clara system can collect two or four frequencies during the measurement sequence depending on the tool model producing a log with multiple radial distances into the formation each shell has a thinner measurement zone than the nmrsa system but these can be combined during processing so as to broaden the depth of investigation or selectively ignore extraneous noise at individual frequencies if present multiple shells also allow a user to examine response at different radial distances and exclude data inside a potentially disturbed zone but there are considerations when averaging across different volumes during data collection the nmrsa system is generally operated in continuous mode while vista clara tools are used in either a stepped mode incrementally pausing and taking readings at intervals equivalent to the instrument s rf coil length or in a continuous mode given the shell diameters relative to the borehole neither manufacturer specifies centralization although non metallic offsets are often used when the probes need to be passed through steel casing as was the case at the ottawa site but not at the guelph site 2 2 field work the fundamental challenge to assessing technology performance in field settings is that the standard against which the measurement s are compared is inherently poorly defined or unknown as well as the resolution subject to the uncertainties of other technologies and heterogeneity the approach adopted here is to collect the best data practical while minimizing other variables i e stationary nmr readings with extended sampling at 0 5m intervals in all the boreholes against this baseline additional targeted data were collected at higher density 0 1m intervals to assess repeatability and resolution of specific targets fractures and voids of varying apparent aperture as characterized by imaging tools finally measurement complexity was added in the form of probe motion at various logging speeds as well as with reduced measurement sampling and frequencies the performance of the probes is assessed against the baseline and results are compared against physical measurements on the core and relevant geophysical logs the majority of the data collected were acquired and processed by the authors with a vista clara system dart and javelin models henceforth referred to as the small and large diameter tools respectively the nmrsa system bmr 60 model was operated by nmrsa mount sopris personnel with support from dgi limited for one day at each site and the data subsequently processed by the manufacturer unless qualified as referring to nmrsa specifically data acquisition and results refer to a vista clara system the basic specifications of the systems used at the time of logging are provided in table 1 at the ottawa site nmr data were collected in one borehole bc81 2 76mm diameter over two days in july 2018 using the small and large diameter tools data acquisition were limited to the open hole in the sedimentary bedrock sequence 10 65m where magnetic susceptibilities were low 10 4si the precambrian bedrock contains intervals of elevated magnetic susceptibilities 10 2si that caused interference with nmr readings data were collected with the small diameter tool as stationary readings at 0 25 m increments in dual mode using two cpmg pulse sequences scan lengths each separated by fixed repetition times tr to capture both long tr 3s scan length 0 3ms 10 stacks and short relaxations tr 0 15s scan length 0 03 ms 50 stacks stationary data were collected with the large diameter tool at 0 5m increments in dual mode long tr 3s scan length 0 15ms 12 stacks short tr 0 1s scan length 0 02ms 20 stacks at the guelph site nmr data were collected in five vertical boreholes gdc 05 06 07 08 09 122mm diameter over seven days in june 2019 using the large diameter tool data were nominally acquired using all four frequencies in dual mode to capture both long tr 5s scan length 0 25ms 16 stacks and short tr 0 15s scan length 0 0ms 96 stacks relaxations one full run of each hole was collected over approximately 7 5h using stationary recordings at 0 5 m increments creating a basis of comparison for various other tests using different recording parameters stationary measurements were also recorded at tighter 0 1m increments over 2 3m intervals of interest in the borehole a void fractures of varying apertures identified from existing image logs to determine if additional insights could be gathered on porosity features and the instrument response function these additional data sets overlapped the baseline data sets so as to assess the repeatability of readings and augment a 15 m portion of gdc 05 that was repeated on subsequent days continuous runs were recorded at several speeds ranging between 0 17m min and 0 86 m min in gdc 05 and 08 to investigate the influence of probe movement during recording in some cases one of the noisier frequencies f3 was turned off to increase data collection speed the nmrsa system data were collected in continuous mode at the guelph site in gdc 05 and at the ottawa site in bc81 2 in a single up down run at approximately 1m min data collection parameters instrument repeatability response function and processing steps for the nmrsa tool were not examined by the authors therefore this study was not intended as a direct comparison of the two systems 2 3 data processing data from the small and large diameter tools were processed using javelinproplus software v 3 6 3 provided with the vista clara instruments the data collected with the large diameter tool at both sites were imported without impulse spike removal data collected with the small diameter tool at bells corners were imported with impulse removal in the upper 21m as an incoming electrical storm caused spikes as the tool approached the surface the t2 relaxation time series from each of the frequencies two for the small diameter tool three or all four for the large diameter tool were combined producing a set of total porosity estimates and pore distributions data were exported relative to ground surface without depth averaging for display and interpretation alongside existing geophysical logs in absence of site specific cut off times for these rock types the default cut off times between clay bound capillary bound and mobile water for limestone carbonates were used for the presentation of the guelph data 3ms and 90ms respectively for the bells corners site sandstone cut off times were used 3ms and 33ms respectively 2 4 laboratory analyses porosities from both test sites were independently calculated from gravimetric water content measurements performed on cylindrical core specimens using an immersion saturation method standard and d2216 19 2019 astm standard d7263 21 2021 the saturation method provides a measure of each sample s interconnected effective porosity and does not include fluids bound in isolated pores twenty three 23 samples of guelph core from gdc 05 sub cored to 38mm in diameter nominally 14mm in length maldaner et al 2019 were tested at the university of guelph ottawa core porosities were calculated from measurements performed at canmet mining s rock mechanics laboratory in ottawa on 17 core samples from bc81 2 nominally 47mm in diameter 35mm in length crow et al 2021 3 results the various nmr data sets collected at the two sites were collated regrouped as warranted and evaluated as well as compared to existing data to assess the tool performance as follows note to avoid confusion porosity is herein referred to as a unitless fraction ranging from 0 00 to 1 00 and refers to various comparisons e g difference between measurements 3 1 tool response function the instrument response function defines how the surrounding formation influences the tool response within the sampled volume and thereby represents volumetric changes in rock matrix and discontinuities i e fractures measured the large tool s theoretical vertical resolution of 0 5m was examined in a borehole setting by collecting recordings at 0 1m increments stepping into and then out of a water filled void dissolution enhanced zone in dolostone that extends over 1 84m in gdc 06 at the guelph site the results of this process using the lower and upper boundaries of the void are shown in fig 3 two curves are developed by dividing the probe response into 0 1m intervals and stepping the response between a uniform background rock porosity estimated from repeated similar readings and the void assumed initially to have a porosity of 1 0 once developed the area under each curve is normalized to be one by varying the porosity of the void the results from the lower blue and upper green boundaries are similar and averaged to create the estimated response curve red for the probe the curve indicates that the response has a central focus with longer tails of sensitivity the shape is slightly asymmetric incorporating the surrounding material from 0 3m below the position of the peak response to 0 5m above the peak response 0 8m in total breadth while the apparent asymmetry may be influenced by the variability in the shape of the void the majority 60 of the sensitivity is focused in the central 0 2m 0 10m of the assigned depth 3 2 repeatability the assessment of repeatability incorporates both the electronic stability of the instrument and the similarity of the volume being measured as the probe s measurement shell is very thin and potentially radially slightly asymmetric as shown above some reading variability may result from inclination of lithologic layering discontinuities in the rock or the presence of metal magnetic minerals within the volume sampled based on depth realignment and the side of the borehole the probe rests against these tests focused on short term repeatability of the instrument in water saturated conditions over hours to days in a stationary mode measurements recorded at 0 5m steps were compared to overlapping measurements recorded hours or days later at 0 1m increments in gdc 05 gdc 06 gdc 07 and gdc 09 using the same acquisition parameters fig 4 vertical realignment between tests is likely very close because the depth is referenced to tape marks on the cable the cable is plastic coated no tape slippage was identified and efforts were made to minimize parallax in aligning the tape at the top of the casing although minor cable stretch could have occurred it is reasonable to assume that would be similar in all runs spurious readings marked as x in fig 5 a occurred at 21 05m in gdc 05 detailed examination of the optical televiewer image identified a void containing oxidized rusty material on one side of the borehole we speculate that there are spurious metal fragments within the void and that the probe was running along that side of the borehole when it recorded the elevated porosity although there are irregular data at this depth in the two continuous nmr logs collected in gdc 05 no other data set in any of the other boreholes logged had such an irregular result see below this data point was therefore not considered in the regression the linear regression comparing the repeatability of the total porosity data sets has a slope of 0 98 an r2 of 0 99 and is dominated at high porosities by the large void in gdc 06 the crossplot has a low scatter particularly amongst the values at and above 0 15 porosity fig 4b focuses on the low porosity values and further subdivides the data to differentiate the mobile water from the combined clay and capillary porosity fractions the plot confirms that the correlation of the mobile water has relatively low scatter and a regression of 1 00 with an r2 that rounds to 1 00 table 2 summarizes the absolute difference between repeated porosity estimates subdividing between all the data from estimates above and below 0 15 porosity it confirms the difference in the higher porosity values is approximately a third of that below 0 15 porosity the largest variability is predominantly a consequence of variation in the estimate of the clay and capillary bound water fraction 3 3 acquisition modes instrument response was also examined when the tool was operating in stationary versus continuous logging modes the primary difference between the two modes is the depth of the tool as it cycles through the long and short pulse sequences across the four frequencies in continuous mode the instrument s sensitive region is changing during the recording the continuous logs will sample all of the rock but with a degree of averaging in the process for the continuous logging tests the speed was adjusted so that the tool s measurement point would pass by the 0 5m logging increment over the time required for the pulse sequences to run therefore as the logging speed is increased the duration of each reading needs to be reduced either by decreasing the number of stacks or collecting data over fewer frequencies or both introducing movement using the same logging parameters as the stationary run but turning off the noisiest frequency f3 300 khz required a logging speed of 0 17m min this short run was focused on the transition from the gasport formation into the finer grained overlying eramosa formation because of the contrasting porosity characteristics to increase the speed to a rate closer to 1 0m min the number of averages of the short and long cycles were reduced by 75 versus the stationary run and f3 was turned off with these parameters the logging speed was determined to be 0 86m min a third run was acquired with these parameters but doubling the vertical sampling interval 0 25m which required a slower logging speed of 0 25m min table 3 provides a summary of the various logging parameters for these runs with logs presented in fig 5a although the logs were collected over different depth intervals a logging time estimate is provided to complete a full pass of the open rock portion of the borehole 57 5m the average noise level of each run was tabulated over a common 20m depth interval 23m 43m so as to assess similar geologic variability to provide information at an intermediate logging speed of 0 44m min parameters from a short run in gdc 08 are also provided in table 3 spanning a 12m interval from 32m to 44m in a finely layered geologic sequence multiple competing factors lithologic layering changing volume of rock measured over the duration of a reading spatial averaging over that volume measurement density and the noise reduction reading with repeated scans all influence the variability observed and overall data quality separating the contribution of these factors when the actual standard reality is unknown is a formidable challenge as an initial visual comparison of the runs in fig 5a the general trends and variations of the clay capillary bound and free water components within the different stratigraphic units are repeated particularly in the free water fraction the 0 25m min run appears to be the most variable of the datasets a visual effect enhanced by doubling the vertical sampling rate to readings every 0 25m all three of the logs under motion show slightly higher total water contents and clay fractions in various portions of the logs in contrast the total water content of the 0 86m min run appears the smoothest of all the datasets with a few localized highs the t2 distributions in the continuous logs display more elevated amplitudes in the early decay times resulting in more clay bound porosity than was observed in the stepped measurements this could be attributed to fewer averages collected over the interval and therefore a lower sn ratio these tests indicated that while free water late decay is relatively consistently captured in all modes the response to bound water is more variably defined when the instrument is collecting fewer short scans to allow for faster logging speeds in continuous mode it is difficult to differentiate the effects of conflicting influences on variability and noise and define the quality of the reading to quantify the response variability the vc software calculates noise as the standard deviation of the cpmg decay curve as is reported in units relative to 100 water content note that the approach to calculating noise differs between instrument manufacturers the relationship between increased logging speed and average noise levels is shown in fig 5b noise from multiple frequencies is calculated based on weighted stacking of the frequencies with greater weight given to lower noise levels in this study reducing the number of stacks by three quarters from the stationary measurements allowed for a logging speed of 0 86m min and a significant reduction in logging time but led to an almost quadrupling of the average noise level 2 9 to 10 5 similarly halving the number of stacks to allow for a logging speed of 0 44m min led to a doubling of the noise levels 2 9 to 6 0 theoretically noise is assumed to be random and gaussian so halving the number of stacks would increase the noise by a factor of 2 or 1 414 in fig 5b the average noise within the specified boxed interval for the runs collected at 0 5m increments have a regression with an r2 of 0 98 not included in the regression the 0 25m min 0 25m increment run is a clear outlier although it was collected with near identical sampling parameters to the 0 86m min run and has the same level of noise the logging speed was reduced to accommodate the reduction in step size the implication is that the sampling parameters are the dominant control on the noise levels in these tests we observe a greater increase in noise than theory predicts would be attributed to a decrease in stacks for example with 16 long and 96 short scans a noise level of 2 5 was observed at 4 long and 24 short scans theoretically a noise level of 5 2 would be expected rather than 10 5 as observed however with these tests we cannot quantify the potentially countering effects of averaging over a larger portion of the rock as the probe speed increases against the possibility of measuring more varied lithologies and any influences of electrical noise created when the winch was in motion while these noise levels may be atypical to this setting the results indicate the choice of logging speed intertwined with the amount of stacking has a clear impact on the noise levels and thus data quality this is a particularly important consideration when defining the pore size distributions in materials containing finer grain sizes like shales and some dolomitic carbonates 3 4 fracture identification past studies using petroleum sector instruments examining the potential of nmr to estimate the apertures of thin saturated fractures nakashima and kikuchi 2007 xiao and li 2011 have predictably revealed that response is more pronounced as fracture apertures and fracture frequency increase beyond a minimum detectable aperture which is based on tool characteristics the t2 distribution is shown to be affected by the type of fluid in the well fracture dip and tool characteristics such as the echo spacing and antenna length a short antenna was found to be more sensitive to the identification of fractures than a long one xiao and li 2011 in this study large diameter tool responses were measured across selected water filled discontinuities fractures of varying apertures using 0 1m stepped intervals apertures were estimated at the borehole wall using televiewer data while this measurement is recognized to be oversimplified and should be considered as an apparent aperture because it represents a limited portion of the fracture and also depends on the interaction between the drill bit and the rock mass the value serves as the best gauge available for fracture aperture the threshold for fracture identification as a discrete feature by the larger tool is determined to be between 66mm the largest fracture that does not create a distinct nmr increase in the free water content above background water contents fig 6 a b and 102mm the smallest one that does fig 6c e where we observe distinct increases in free water the shape of the response varies between a narrow high peak gdc 07 60 8m fig 6e and a broad plateau in fractures of both smaller gdc 09 59 6m fig 6c and larger apertures gdc 07 53 2m fig 6d an explanation for this observation is that the dip of the fractures as they cross the instrument s sample volume broaden the response due to the vuggy nature of the fractures however the regularity of these features was difficult to assess features thinner than the minimum apparent identifiable aperture would be smeared by the resolution of the tool fluid in these saturated fractures would still be detected but appear as small increases of free water in the total water content 3 5 varying geological materials boreholes at the guelph and ottawa sites present a range of bedrock types and characteristics comparison with traditional geological core descriptions geophysical logs e g gamma resistivity gamma gamma density provide important lithological context about variation in clay content cementation and bulk densities properties that affect the hydrogeological characteristics of the bedrock matrix televiewer logs also provide continuous millimetric scale imagery of the borehole identifying contacts discontinuities and textures in the borehole wall some key logs were selected to assess how variations in geological materials are reflected in the nmr responses fig 7 at both sites there is generally excellent alignment between lithology as indicated by the gamma inductive resistivity and density logs fomenko 2015 guelph site crow et al 2021 ottawa site and the variation in the water content represented by the nmr logs at the guelph site silurian dolostone fig 7a all major geologic units identified in the core show further subdivisions as indicated by the gamma logs the nmr similarly shows distinct changes in either total porosity or proportions of bound or capillary water in the regionally discontinuous aquitard unit typically viewed as the vinemount member of the lower eramosa formation and the ancaster member of the goat island formation below the nmr log consistently shows little or no mobile water fig 7a segment i conversely in the regional aquifer gasport formation the nmr log displays the most elevated free water content in agreement with the increase in vugs and primary porous structures observed in the cores the nmr log suggests there are further refinements to be made within stratigraphic units particularly within the niagara falls member of the goat island formation and gasport formation that are traditionally interpreted to form the regional supply aquifer for example a distinct increase in the total porosity primarily as mobile water occurs from 56 to 63mbgs fig 7a segment ii which seems to align with a highly transmissive zone within the gasport formation at the ottawa site fig 7b the shallow sandy dolomitic rock above 20 5m displays lower nmr porosities with a relatively larger proportion of the porosity attributed to bound porewaters than in the nepean sandstone below 20 5m 64 5m within the sandstone relatively low gamma counts coincide with intervals of elevated porosities with a high proportion of free water content in beds of poorly cemented quartz sandstone e g 23m 32m fig 7b segment iii below 37m the quartz sandstone becomes intercalated with a series of bioturbated sandstone beds with increased mud content the gamma levels correspondingly increase and become more variable herein the nmr shows an increased clay and capillary bound fluid fraction with reduced free water content assuming generally uniform matrix properties bulk porosity is observed to be inversely proportional to density densities are generally lowest where free water porosities are most elevated e g 25m 32m 58m 61m fig 7b segments iii and v conversely increases in the density log correspond to reduced nmr porosities e g 32m 36m fig 7b segment vi 3 6 observations at the water table of note at the guelph site is that the nmr indicates the presence of elevated free water content in the upper eramosa spanning 13 22m above below the base of the plastic casing near the bedrock surface fig 7a segment vii and also clay bound water within the overlying diamict the mobile water is 1 to 2m above the water level measured during logging the upper portion of the bedrock is likely a chemically mechanically weathered highly fractured contact zone that has led to an increased secondary porosity the guelph site is on a local topographic high and there is a downward component of hydraulic gradient as confirmed by flow meter and straddle packer testing hydraulic head profiles from temporary transducer deployments and temperature data munn 2019 maldaner et al 2019 fomenko 2015 data from a sealed temporary deployment in nearby gdc 12 munn et al 2020 infers a water level in the overburden upper rock to be at approximately 6 4mbgs and that the interconnected fracture network under open hole conditions create a blended hydraulic head in the borehole that is deeper than the true water table in the surrounding rock given the known downward component of hydraulic gradient the water content indicated by the nmr likely represents both the true formation water level in the rock matrix between fractures and the capillary fringe this observation is also supported by a decrease in the inductive resistivity and temperature data above the open hole water level this suggests that nmr can be useful in assessing the reliability of blended water level measurements in open cross connecting boreholes as well as estimating the thickness and position of the capillary fringe due to the presence of a metal casing extending into the top of the bedrock at the ottawa test facility this effect could not be observed in borehole bc81 2 3 7 comparison with laboratory core porosities gravimetric porosities from core samples taken from both research facilities are shown overlying the nmr estimated porosities in fig 7 and as cross plots in fig 8 a and b at borehole gdc 05 in the finer grained layers of the upper and lower eramosa formation as well as the ancaster member of the goat island formation i e above 40mbgs the comparison between core and log porosity datasets is excellent through the niagara falls member of the goat island and the gasport formations approx depths of 40m 70m the higher values are similar except where the nmr is influenced by a large aperture fracture 58m in the zone from 40 to 70mbgs the core sample porosities are considerably more variable and in many cases show lower porosity values in comparison to the nmr borehole log near the bottom of the borehole where the borehole enters the cabot head shale approximately 70m the two porosity estimates become more consistent fig 8a shows cross plots of all the total porosity from the nearest stationary nmr data against the core sample porosities n 25 note that the depths of the two data sets do not always match exactly however the alternative approach of estimating nmr porosities by linear interpolation between readings found no appreciable difference as a comparison fig 8b refines the plot by removing three data points from above the blended water level in the borehole and two data points at 20 53m and 57 93m where large fractures are interpreted to have increased the nmr porosity estimate the removal of the selected data changes the slope of the regression from 1 14 to 1 00 and increases the r2 fit from 0 42 to 0 68 the average absolute deviation between nmr and core measurements is 0 014 but the difference was as high as 0 05 and the average and median values of the absolute difference 0 02 and 0 015 respectively although the 1 1 slope is ideal the scatter in fig 8b is further assessed by stratigraphic unit the data are colour coded with the higher clay content units with elevated gamma levels in shades of grey brown ancaster vinemount and reformatory quarry members and the low clay content layers niagara falls gasport and irondequoit higher transmissivity units and low gamma levels in shades of blue the higher clay content layers dominate the low porosity portions of the plot and generally have a much better fit to the regression line than the data from the higher porosity units the data points from the niagara falls member and gasport formation tend to be at or above the overall trend line shown in grey with more scatter in comparing the regressions on the two subsets although the data sets become smaller n 10 and 9 respectively the slopes of the best fit lines are similar 0 66 and 0 68 the r2 fit is 0 81 for the clay rich deposits and lower at 0 61 for the aquifer formations notably the intercept for the first group is 0 02 and the latter 0 05 implying an overall offset in the core mnr comparison in the porous units although it should also be noted that the line is projected further to reach the axis accentuating any skewness the increased variability and higher intercepts between nmr relative to core porosity estimates in the silurian dolostones as noted in figs 7 and 8 is attributed to the combined effects of the small sample volume of the core tested versus the much larger volume sampled by the nmr tool in an interval known to contain vuggy porosity as well as the absence of fracture porosity in core sample measurements made in the laboratory the core samples are inherently biased as only intact portions of the rock can be sub cored for testing whereby small scale porosity will be better represented than larger macroscopic pores and fractures that cannot be properly sampled for lab testing therefore core porosities do not completely represent the bulk rock mass although with few exceptions the general fracture frequency over 1m intervals of the higher clay content formations is slightly higher the fractures are predominantly low aperture bedding plane partings rather than the fewer but larger fractures in the aquifer other than grain size and fracturing the most notable difference between the two groups is the high occurrence of vugs observed in the core from the aquifer formations that likely further weaken the correlation at the ottawa site the core and nmr porosities also show close agreement table 4 fig 8c presents quantitative comparisons between effective core porosities and nmr porosities measured with the small and large diameter tools in intervals where the porosity is shown by lab tests to remain fairly consistent e g the 0 76m sandstone interval spanning 59 22 59 98m where five core porosity tests ranged from 0 084 to 0 094 the nearest core and large diameter tool s nmr porosity measurements are 0 094 and 0 093 respectively similarly in the 0 26m dolomitic sandstone interval spanning 17 56 17 82m where three lab porosity tests range from 0 0195 to 0 0312 the nearest nmr porosities with the large and small diameter tools are 0 052 and 0 02 respectively the regression line for the large diameter tool n 11 has a similar but slightly lower slope 0 60 than observed at the guelph site when lithologies were considered individually and an intercept 0 04 consistent with that observed for the dolostone the data for the small diameter tool n 7 has a slope of 1 35 and intersects close to the origin but is relatively poorly represented towards the higher end of the range with only two points with porosity above 0 08 that have the largest offsets from the core samples 0 07m and 0 11m and therefor less robust the nepean sandstone provides additional insights regarding contrasting porosity in thinly bedded 0 1 m to 0 3 m thick zones common in interlayered sedimentary deposits in intervals where the core porosity changes abruptly from bed to bed over short 0 1 m distances e g 29 58 29 90 m the direct comparison of the core and the nearest nmr reading reflects differences in the vertical scale of both geology and tool resolution as well as vertical offsets between nmr measurements and core samples the effects of fine scale bedding with contrasting porosities are further examined in this interval by directly comparing the responses of the small and large diameter tools where closely spaced lab measurements reveal interbedded low 0 015 and higher 0 08 0 124 porosity sandstone layers fig 9 with the large diameter tool the nearest nmr porosity to the series of lab measurements is 0 115 the longer shell of investigation is not strongly influenced by the 10 cm thick low porosity bed but does detect an increase in clay bound water which is consistent with the narrow response curve postulated above the nearest reading with the small diameter tool to the low porosity bed is 0 034 which increases to 0 145 as it enters the underlying higher porosity interval showing higher vertical resolution to changing porosity layers this comparison shows how increased vertical sampling measured over a smaller volume could provide a more refined estimate of porosity in finely interbedded sedimentary sequences where porosity conditions are changing abruptly 4 discussion tests performed at the two field research sites provide insights into the performance of the borehole nmr tools under various deployment modes examination of nmr logs relative to other existing high resolution geophysical logs and core porosity measurements provide unique insights and highlight relationships between nmr response and in situ formation characteristics in this section we discuss the implications of the field test results and practical considerations for integrating this technology into hydrogeological studies field tests with the large diameter tool suggest a response curve with sloping edges and an overall 0 8m vertical length the maximum contribution spans 0 2m centered over the measurement point contributing approximately 60 of the reading approximately 87 of the reading comes from the manufacturer s reported 0 5m vertical resolution of the instrument 0 25m above below tool s measurement point fig 3 and table 1 although the shape and vertical length of the response we calculated may be unique to this specific probe and or to some degree be influenced by the mineralogy and natural geological variability of the void edges this response shape is in close agreement with observations by dlugosch et al 2013 in their laboratory studies of instrument response conducted by changing the height of the water level in 0 03m increments inside a shielded tank they observed a similar response with a shape described as trapezoidal with a 0 75m vertical length although their studies were conducted with a different model of the tool j350 both instruments had the same reported vertical resolution of 0 5m these observations suggest that although design details will vary from probe to probe an instrument response function will extend slightly beyond the edges of the reported rf coil length from a hydrogeological perspective the shape and length of the response defines the achievable vertical resolution of the instrument and the level of detail and therefore cost required to achieve 100 coverage when that is a necessary project requirement as with other geophysical probes that measure a response to an input stimulus e g electrical induction active gamma neutron an nmr tool will sense all the material in the measurement zone but a central band dominates the measurement this will tend to smear thinner layers or features while accentuating the portion with maximum contribution as discussed below the coverage can be extended with motion but with other compromises tests of instrument repeatability with the large diameter tool confirmed that stationary measurements were highly repeatable over a time scale of hours to days qualitatively data collected on separate runs at the guelph site overlap very well figs 3 5 and 6 with slightly more scatter where fracture frequency increases fig 6 a and b it was observed that the mobile fluid portion is extremely repeatable within 0 8 the bound fluid clay capillary fractions displayed slightly higher variability between repeat readings 1 8 for porosity values below 0 15 porosity this observation has particular implications for nmr logging when defining the properties of aquitards or materials with very small pores these greater differences are attributed to a lower sn ratio in the detection of the short t2 components that could be improved by using a tool with a shorter echo spacing slim hole tools with echo spacings as low as 0 45ms are now available increasing the number of scans in the short t2 components could also improve the sn ratio if the tool is stationary during the recordings comparing instrument repeatability between stationary versus moving runs indicated that the choice of data collection settings number of averages scan lengths frequencies and logging modes stepped or continuous strongly influences the results each complete reading is comprised of a series of repeated cpmg measurements recorded over a user selected configuration of early and extended times so as to sample the complete t2 signal decay given the inherently low nmr signal strengths produced increasing the number of averages stacks within each scan window improves the sn ratio decreases the noise but also increases the recording time required increasing the number of short stacks is particularly important in rock with higher clay size content where most of the signal decay occurs in the early portions of the record the measurement time is further extended when performed over multiple frequencies to investigate various radial distances from the tool in selecting collection parameters a balance is required between the number of frequencies doi s the selection of signal recording parameters increased repetition to reduce noise and logging speed time and cost to optimize the process the appropriate balance of measurement parameters also depends on the complexity of the layering and stratigraphy both of which often change between intervals of the same hole in lithologies where porosity changes abruptly between thin beds i e distances less than the tool s vertical resolution selecting a tool with a shorter vertical resolution shorter coil length and with more closely spaced measurements resulted in closer agreement between nmr porosity and core measured porosity however this improvement came at the cost of increased logging time with respect to identification of fractures with nmr observations from field tests with the large diameter tool show a fracture was identified with a 102mm apparent aperture at the borehole wall while a fracture with a 66mm aperture was not identified as a discrete feature the implication is that fractures with high hydraulic transmissivity could remain unidentified by nmr logs alone an issue discussed further in the context of permeability estimation the log suite also demonstrates that even with 0 5m stepped readings the probe might not be optimally aligned to measure the maximum effect of the fracture fig 6c d and e this could have resulted in peak effective total porosity being underestimated by as much as 0 12 due to the averaging of fracture water content over the vertical extent of the sensitive volume where the 0 5m reading is less than optimally vertically aligned with the feature high resolution imaging data confirms the alignment of nmr readings with rock features and improves interpretation these results indicate that the advantage of slim hole nmr is its application to matrix porosity measurements and bulk hydrogeological properties comparisons of porosity between the large and small slim hole nmr tools against core measurements produced favourable results in bedrock with relatively homogeneous porosity however a more detailed examination of all the total porosity data shows that correlation varies with the nature of the lithology range in pore size and fracture occurrence generally nmr estimates of total bulk porosity range from 0 04 relative to laboratory measurements on core samples in the proximity of large fractures however this difference could reach up to 0 15 or more having additional information about fracturing such as image logs or core data improves understanding of cause and effect as observed the difference in vertical scale between lab measurements on a small unfractured core puck versus the larger volume of the nmr measurement can have a significant affect on the comparison close agreement between core and nmr porosities was observed in the more homogeneous intervals of sandstone at the ottawa site and in the finer grained units at the guelph site it is noteworthy that only one sample at the guelph site 34 76mbgs is interpreted to have the water content primarily as clay bound while all of the other samples in the fine grained units have water content predominantly in pores with capillary bound water since the lab measurement does not assess clay bound water it remains uncertain whether the correlation would be as strong in a rock with a pervasively higher clay component in the dolostone containing vuggy porosity the nmr detects more free water than is measured by core tests suggesting that the nmr characterization of the aquifer is more representative of the larger scale properties of the rock examples of nmr data collected in the same boreholes by two different equipment manufacturers are presented on fig 10 these data are presented to make the reader aware of the instruments available as well as data collection modes but not to provide a controlled head to head comparison of the systems although the trends in mobile water are similar in the profiles from all instruments differences in capillary and clay bound water volumes are observed at both sites the bmr 60 data are more variable than the baseline javelin 238 data collected in stationary mode at 0 5 m intervals however the former is both collected in continuous mode and at finer intervals both of which were shown in fig 5 to increase variability even when collected with the same system the variability of the bmr 60 data at the ottawa site is more similar in appearance to the data collected with the dart the dart when compared to the javelin has a higher frequency a narrower vertical resolution a 0 25m data collection interval and a shorter echo time see table 1 the other striking difference between the data sets is the higher proportion of clay bound water generally interpreted with the bmr 60 using a 3ms cut off for all t2 distributions the lack of differentiation between lithologies as well as the overall higher proportion of clay suggest that other influences are factors whether this result is inherent to the technology and or the nature of how the water is bound within the rock requires further investigation in cross plots of the total water estimated from the nmrsa tool against the vc baseline data from each site bc81 2 and gdc 05 fig 10b both the sandstone red and dolomite blue exhibit considerable scatter with an absolute mean difference in the total porosity of 0 042 in the sandstone and 0 03 in the dolomitic rock if the regression is forced through the origin the slopes are 1 12 and 1 10 respectively with r2 of 0 72 and 0 86 suggesting reasonable correlation however allowing the regression complete freedom respects the observation that in practice there is no presumption that instruments should respond similarly at low porosity levels in this case the correlation deteriorates dramatically r2 of 0 02 and 0 36 for bc81 2 and gdc 05 respectively the average difference of the nmrsa tool relative to the large diameter tool from the vista clara system is 0 03 bc81 2 and 0 02 gdc 05 suggesting overall readings are similar but maximum offsets are closer to 0 15 at both sites it should be noted that the tools have different designs see table 1 that the datasets were collected with different logging parameters the nmsra is under motion and processed using different settings software this comparison highlights the necessity for the user reader to have a clear understanding of all system characteristics as well as data collection and interpretation parameters to establish confidence levels in applying the results 4 1 permeability estimation an estimation of permeability k is a highly sought after parameter for a complete understanding of a formation s hydrogeologic characteristics several models have been developed to estimate k in porous materials from nmr measurements e g schlumberger doll research sdr equation kenyon et al 1988 straley et al 1997 the timur coates tc equation timur 1968 coates and dumanoir 1974 the sum of echoes soe model sezginer et al 1999 the kozeny godefroy kg model dlugosch et al 2013 and the seevers model seevers 1966 no matter the model the calculation of k from nmr data directly depends on the quality of the logs and our understanding of the material properties to inform appropriate equation parameters consequently how well the t2 components are characterized during data collection is critical in the estimation of k as the collection of high quality nmr data clearly depends on many variables this article has focused on first assessing the technological aspects of the instrument response and data collection rather than assessing models nmr estimation of k relies on kozeny carmen type flow where porosity and pore dimension are the main controls on flow however it is well documented that in a fractured rock setting groundwater flow will be predominantly through the discontinuities e g novakowski et al 2006 therefore given the relatively large apparent apertured features that are herein shown as undetected considerable flow could occur in fractures that are not identified as discrete features by the nmr tool additionally in fracture networks k can be dominated by interconnection of fractures which is not assessed by nmr consequently a bulk k estimated solely from nmr data could misrepresent the hydraulic characteristics of the broader rock formation a study by ren et al 2018 conducted in a fractured granite aquifer explores the integration of nmr logs with other downhole tests focused on fracture flow flute liner and slug testing to calculate a more representative knmr parker et al 1994 2010 and others have highlighted that matrix porosity and permeability are critical factors in the diffusion of contaminants into the matrix and consequently retardation of plumes in fractured sedimentary rock therefore despite the limitations of nmr in fracture identification the logs provide important matrix porosity estimates for such critical applications 4 2 practical integration of nmr technology into a hydrogeological study in comparison to other geophysical techniques for measuring porosity a key benefit of nmr is the direct measurement of water content while avoiding the complications and risks inherent in the use of nuclear sources required for gamma gamma or neutron tools for estimates of porosity the clear advantage of a slim hole nmr tool is in its application to matrix porosity measurements and bulk hydrogeologic properties rather than narrow bedding features and some fractures nmr measurements provide a broader scale estimate of downhole porosity variability than discrete core testing which is almost always by necessity more intermittent it also allows for in situ testing when core is unavailable for laboratory testing and when core is available nmr logs can guide core subsampling by providing broader context for physical samples nmr logging is very complementary to other downhole geophysical instruments that also respond to the various physical and chemical properties of the matrix a priori knowledge from core and or other geophysical logs such as gamma for lithology and imaging atv or otv is helpful in the deployment of nmr technology although in practice this full breadth of information is not always available factors like geology e g sediment vs bedrock vertical scale of beds grain size and magnetic mineralogy of matrix and borehole details e g diameter completion formation disturbance drilling fluid invasion have implications for the choice of tool e g rf coil length multi or single frequency echo time and data acquisition settings e g stacks stepped or continuous logging similarly the interpretation is optimized when complementary data is available to provide context for porosity variations a key consideration is selecting a tool with a diameter of investigation that will reach into undisturbed material beyond the borehole logistically acquisition parameters have an effect on the survey duration and thus cost stepped logging can be slow due to the time needed to move the instrument between readings and in turn potentially prone to user error but results in highest resolution however optimally slow continuous logging can require a similar time commitment the advantages of continuous mode include less user interfacing during the collection more complete sampling along the borehole and potentially faster data acquisition but as the speed is increased there will be a trade off in sn ratio resolution and reliability the underlying igneous bedrock at the ottawa site is a setting where the concentration of magnetic minerals is too elevated for nmr logging however not all igneous bedrock is enriched with magnetic minerals and a magnetic susceptibility ms log can provide needed information about intervals where the very high ms will need to be considered for data interpretation recent laboratory studies examining the effects of elevated ms in unconsolidated aquifers on slim hole tools can be found in fay et al 2015 and keating et al 2020 as instrument response depends not only on formation characteristics e g concentration and grain size of magnetic minerals pore size but also on tool design factors e g magnetic field strength echo time manufacturers can provide guidance on nmr logging in such settings other logistical considerations include that the tools cannot be operated in or within a few meters of metal casings proactive strategies must be taken to overcome the extremely strong magnets when lowering the sondes through steel casing into the measurement interval below spurious metal in a borehole e g from drilling activities can distort the signals making the data incoherent the instrument can also be sensitive to various forms of urban electromagnetic noise particularly at depths shallower than 10m over the course of this data collection interference from am radio frequencies operating in the same bandwidth as one of the probes was observed to very negatively affect instrument noise levels in the near surface an incoming electrical storm also caused spikes in the shallow data that were removed during processing the instruments can also be sensitive to borehole features such as washouts and decentralization in large boreholes 5 conclusions this study assessed the performance of available slim hole nmr technology in resolving critical hydrogeologic parameters of fractured sedimentary rock utilized as shallow municipal aquifers the study was conducted in the silurian dolomitic sequence at the university of guelph s fractured rock observatory in guelph ontario and the cambrian sandstone at the geological survey of canada s bells corners borehole calibration facility in ottawa ontario the datasets are presented to provide readers with awareness of the technology and what can and cannot be resolved from an independent user s perspective focusing on hydrogeologic concerns a key finding of this study is that nmr measurements provide insights into in situ hydrogeologic conditions that are difficult to achieve or interpret with other downhole and or core measurements in unfractured intervals of rock it is common for various forms of hydrogeophysical testing e g active line source active distributed temperature sensing high sensitivity flow meter testing straddle packer testing to indicate flow and or permeability where fractures are not observed this is particularly important in high porosity units such as those with vuggy carbonates nmr data has the potential to resolve these discrepancies by providing information about the broad scale matrix porosity the response does not resolve some discrete features fractures and thin beds that may significantly facilitate groundwater flow therefore nmr data is best interpreted in conjunction with other geophysical logs that provide indicators of lithology e g natural gamma density magnetic susceptibility fracturing e g atv and or otv caliper and fluid flow e g temperature fluid conductivity and flowmeter as is always the case having core calibration is also highly desirable matrix porosity and permeability are critically important factors in modeling contaminant diffusion and distribution and are required parameters in assessing the applicability and potential performance of remediation technologies the examples presented in this study show that nmr logs can improve groundwater resource characterization and contamination studies through the continuous downhole measurement of matrix porosity at submeter scales leading to better assessment of flow and chemical diffusion nmr is currently the only available technology to specifically measure water content and estimate its mobility in situ without using an active nuclear source nmr logs can help focus labour intensive core testing and complements core measurements by putting them into broader context clearly the technology and its application are complex and the details of the response dependent on the geologic hydrogeologic setting much more testing at other locations is warranted work continues to compare nmr data with other forms of core and downhole testing to improve understanding of the scaling issues identified in this study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements any use of trade firm or product names are for descriptive purposes only and does not imply endorsement by natural resources canada or the university of guelph the authors gratefully acknowledge collaboration in the field with tim cartwright and matthew griffiths mount sopris instruments and dgi geosciences elliot grunewald formerly vista clara for field support and comments nmrsa for data collection data processing and comments contributions of laboratory core data from steven gaines dru heagle jonathan munn and carlos maldaner as well as support data collected by andre formenko and others at the morwick g360 institute are much appreciated alt instruments as a long term sponsor of dr pehme s research associated with dr parker s research program at the morwick g360 institute providing access and support with wellcad as well as a nmsra collaborator both of which are important tools in this research review of the text by stéphanie larmagnat gsc and refinements suggested by reviewer s at joh this article represents gsc contribution number 20210226 funding support for this study was provided by the geological survey of canada s groundwater geoscience program and the university consortium for field focused groundwater research through the morwick g360 institute for groundwater research 
3321,this study assesses the performance and limitations of slim hole borehole nuclear magnetic resonance nmr technology from a hydrogeologic perspective in fractured porous rock nmr logging was carried out in dolomitic and sandstone bedrock boreholes at two research test sites in ontario canada where aquifer and aquitard units provide a range of clay contents as well as a variety of primary and secondary porosity types e g discrete fractures reefal structures vugs and karstic conduits results were compared to core measurements geophysical logs and hydrogeophysical testing the vertical response curve of the instrument tested was found to produce 60 of the signal from within a 0 2m span surrounding the measuring point the repeatability of the total porosity measurements in stationary mode is excellent where the porosity is greater than 0 15 below that threshold repeatability is scattered at 0 05 porosity about the mean with the variability primarily within the clay and capillary bound fractions the nmr porosity estimates agreed with core measurements to within 0 04 porosity in both the dolostone and sandstone but the correlation deteriorates in finely bedded lithologies and where fracturing is present much of the discrepancy is attributed to scaling in a finely layered geologic sequence as the core samples are much smaller than the entire volume measured with nmr probes data collection with the probe in motion continuous logging added variability to the response when compared to stationary recordings although broadscale trends were comparable the details and depth specific insights of the bound fluid fractions varied with logging rates overall nmr provides a robust measurement of the bulk matrix porosity and pore size distribution of lithologies intersected both of which are critically important parameters in understanding hydrogeologic conditions and contaminant distributions in layered sedimentary rock systems keywords nmr logging fractured rock hydrogeologic investigation resolution limitations porosity 1 introduction sedimentary bedrock aquifers are critically important to the supply of potable water for many communities throughout the world e g berkowitz 2002 brunton and brintnell 2020 protection of these resources often requires an advanced understanding of the local geology and hydrodynamic controls this often calls for the application and refinement of both existing and evolving geophysical hydro geophysical and hydrogeological technologies and techniques as new tools and approaches become more broadly used there is a need for impartial assessment and standardization between systems that can only be accomplished at well characterized real world field facilities with multiple data types that provide a consistent basis for comparison calibration standardization and assessment of borehole technologies in bedrock environments is critically important to a variety of disciplines such as environmental geotechnical mining and nuclear waste management one such emerging technology is slim hole borehole nuclear magnetic resonance nmr logging nmr is an established geophysical technology in the petroleum industry used to measure total porosity and distribution of pore fluids classed by mobility decades of research led to the development of models to estimate permeability or hydraulic conductivity in reservoir rocks from nmr data and material specific empirical constants e g allen et al 1997 coates xiao and prammer 1999 dunn bergman and latorraca 2002 over the past decade the technology has been adapted and nmr instrument dimensions have been reduced in size sucre et al 2011 walsh et al 2013 hopper et al 2017 allowing sondes to be deployed in narrow diameter bedrock and plastic cased sediment boreholes common to shallow environmental investigations this generated significant interest for application in unconsolidated sediment boreholes to estimate in situ water contents e g kass et al 2017 crow et al 2020 and develop empirical constants to estimate hydraulic conductivity in sediment e g dlubac et al 2013 dlugosch et al 2013 johnson et al 2014 parsekian et al 2015 knight et al 2016 maurer and knight 2016 kirkland and codd 2018 kendrick et al 2020 laboratory nmr systems were used to support the interpretation of slim hole nmr tools through the development of sediment sampling strategies behroozmand et al 2017 and the examination of magnetic gradients on nmr response e g fay et al 2015 keating et al 2020 case studies of the deployment of slim hole nmr tools in environmental studies in fractured bedrock aquifers have been presented by the usgs and others johnson et al 2015 day lewis et al 2017 ren et al 2018 johnson et al 2021 numerous hydrogeological studies identify variability in rock porosity as key to informing permeability and diffusion properties of porous media and thereby contaminant persistence and distribution e g berkowitz 2002 parker et al 1994 2010 chapman and parker 2005 which are often pervasive threats to aquifers the complexities of fracture and matrix flow in bedrock aquifers present unique challenges when applying nmr technology as instrument response is affected by a number of tool and acquisition factors as well as site specific geologic conditions this requires that users have a practical sense of the advantages and limitations of this technology such as instrument repeatability the length and shape of the tool s response function over the volume of measurement trade offs between logging speed and data quality the resolution limits of geological features important in fractured rock investigations i e fractures vugs pores as well as the relationships between core and downhole nmr measurements this article presents a unique controlled field study addressing these questions along with a discussion of the practical implications for the hydrogeological community studying fractured rock the study deploys slim hole nmr tools within fractured sedimentary bedrock boreholes at two calibration test sites the fractured rock observatory fro at the university of guelph fig 1 a and the geological survey of canada s gsc bells corners borehole calibration facility in ottawa both sites have rich datasets of continuous cores with porosity analyses as well as a broad suite of complementary geophysical logs and hydrogeophysical testing the study objective is to provide insight into nmr data collection interpretation and tool limitations as well as to assess the relationship between nmr response and other measurement approaches testing was designed to provide practical considerations for integrating this technology into hydrogeological studies and show how nmr measurements can add additional insight into insitu hydrogeologic conditions that are difficult to achieve with other means 1 1 geological setting and bedrock test sites the geology of southern ontario and the paleozoic st lawrence platform sanford 1993 are areas of significant hydrogeological interest largely because these include locally important aquifers and have characteristics in common with other sedimentary basin rocks of north america the fro site intersects a carbonate dominated succession that forms the regional water supply aquifer for guelph and surrounding communities the bells corners facility in ottawa is drilled through cambrian and ordovician siliciclastic and carbonate sediments e g johnson et al 1992 sanford and arnott 2010 utilized by several smaller communities surrounding ottawa the guelph facility is designed to support ongoing hydrogeologic research through multi institutional and inter disciplinary geoscience collaborations the borehole cluster fig 1b was diamond drilled in 2013 2014 using fresh water and consists of ten continuously cored boreholes six vertical and three inclined at 60 deg from the horizontal within an area of 0 6ha the five open vertical central boreholes 73 74 m deep 122mm diameter shown in blue are the focus of this nmr study the boreholes intersect a 60m thick dolostone sequence of the niagara escarpment region of southern ontario comprised of the eramosa goat island gasport irondequoit rockway and merritton formations each with varying clay content fig 1b and terminate in the top of the cabot head shale brunton 2009 brunton and brintnell 2020 the shale forms a roughly 10 39m thick regional aquitard singer et al 2003 the gasport formation along with the overlying guelph formation not intersected at the site are the target aquifers munn 2019 identified four main hydrogeologic units through the dolostone sequence at the facility the lower goat island formation niagara falls member gasport and irondequoit formations have generally low clay content with various forms of primary and secondary porosity including fractures of varying aperture reefal structures vugs voids and occasional dissolution enhanced fractures and matrix porosity features the ancaster member of the goat island formation and the vinemount and reformatory quarry members of the eramosa formation vary laterally locally acting as an aquitard above the regional groundwater aquifer that serves nearly one million people with drinking water the boreholes are pvc cased 0 15m diameter schedule 80 to facilitate geophysical testing through 12 15m of surficial quaternary age mud sand and gravel diamict and are located on the margin of a buried bedrock valley steelman et al 2018 these holes have undergone a broad range of hydrogeophysical testing with novel active line source als and distributed temperature sensing dts thermal techniques straddle packer and point dilution testing as part of ongoing research details of the site and geology are summarized in multiple theses kennel 2008 munn 2012 2019 fomenko 2015 maldaner 2017 and publications steelman et al 2018 maldaner et al 2019 munn et al 2020 in addition to detailed core analysis and documentation these works focus on thorough geophysical logging including video imaging optical and acoustic televiewers as well as gamma apparent conductivity and full waveform sonic for rock property measurements the ottawa facility was developed in the early 1980 s by the gsc to provide a national calibration site where geophysical instruments could be tested against a series of core and longer term repeated downhole log values killeen 1986 bernius 1996 mwenifumbo et al 2005 crow et al 2021 six vertical boreholes 76 mm to 96 mm in diameter were diamond drilled with fresh water ranging in depth from 75 m to 300 m are located within a one hectare area the holes intersect 4 5 m of fill plastic lined steel cased three lower paleozoic sedimentary formations before terminating in precambrian igneous and metasedimentary bedrock fig 1c the precambrian rock consists of 1 1 5 ga grenvillian syenites granites and gneisses bernius 1996 davidson 1998 the overlying sandstone of the nepean formation potsdam group consists of a quartz arenite of upper cambrian to lower ordovician age primarily derived from the grenville province sanford and arnott 2010 lowe et al 2017 cross bedding ripple marks and vertical burrows are commonly observed the overlying sedimentary rock units are part of the beekmantown group and consist of sandy dolostones of lower ordovician age theresa formation transitioning upward into the calcitic and non calcitic dolostone of the beauharnois formation bernstein 1992 dix et al 2004 the nepean sandstone is recognized as an important but vulnerable regional aquifer in southeastern ontario mrspr 2011 and its characteristics are the focus of a recent multidisciplinary study investigating its potential as a groundwater supply in outlying areas of ottawa undergoing municipal development pehme et al 2018 the site has and continues to undergo investigation by the gsc augmented by various industry and academic collaborators including core logging laboratory analyses a broad suite of geophysical logging as well as being the focus of past and upcoming hydrogeophysical testing 2 approach and methods this study is designed to assess the performance and application of slim hole nmr in these two sedimentary bedrock aquifer settings but the results have general implications on technology performance and limitations elsewhere specifically we examine the technology s performance in estimating the total fluid filled porosity of the formation whether the pores have mobile capillary or bound water and to what extent discontinuities fractures would contribute to the response as well as evaluating the compromises inherent in different modes of deployment data presentation and analysis includes assessing tool features and implementation options survey parameters as these influence response variabilities sensitivity and possible bias as well as the spatial resolution of various geologic features hydrogeologic conditions and total and effective porosity conditions based on comparison against independent geophysical and petrophysical datasets 2 1 borehole nmr systems borehole nmr logging applies the same principles as the well established laboratory nmr measurements e g mr imaging nmr spectroscopy except that the rock or sediment is outside the source sensors rather than inside this results in weaker and more variable magnetic fields across the sample volume design elements such as the magnet strength the configuration of the transmitting receiving antenna and the radio frequency rf pulse sequencing are key considerations in overcoming these challenges hürlimann and heaton 2015 details on the phenomena of nuclear magnetic relaxation and the technical evolution of nmr sondes can be found in books by coates et al 1999 and dunn et al 2002 briefly nmr logging technology uses the quantum mechanical response of proton spin to a changing magnetic field to investigate hydrogen in pore fluids hosted in sediments and rock outside the borehole the tools use strong magnets to polarize hydrogen in groundwater and then apply a series of rf pulses termed a cpmg pulse sequence transmitted by an antenna in the tool to induce a spin echo decay signal between each pulse fig 2 a for a magnetic field of fixed strength different rf pulses are sensitive to different diameters of investigation or cylindrical shells around the tool with a radial thickness of a few dm fig 2c and operational frequencies are chosen to optimize instrument performance while minimizing influence from other factors e g cultural interference such as radio waves etc the length of the cylindrical shell is approximately equal to the length of the rf coil although details are explored further below higher frequency signals have sensitivity closer to the tool and generally provide a better signal to noise sn ratio while lower frequencies may have poorer sn ratios but penetrate further into the formation and thus may be less affected by drilling disturbance the repeated pulsing creates measurable signals with diminishing amplitudes over time which are fit with a multi exponential curve representing the t2 relaxation time to improve the sn ratio the signals are stacked multiple times and averaged keeping the tool stationary during recording and increased stacking also improves the sn ratio walsh et al 2013 the initial signal amplitude of the t2 curve is directly proportional to the total volume of water excited by the tool the shape or decay of the t2 curve is influenced by the pore sizes generally the signal from water bound in clay or small capillary bound pores decays very quickly while the response from mobile water in larger pores decays relatively slowly an amplitude t2 distribution curve is calculated from an inversion of the t2 decay curve boundaries t2 cut off times are allocated within the t2 distribution curve to differentiate between bound capillary and mobile proportions of the total pore space fig 2b the cut off times depend on the lithology and are typically based on values from published laboratory studies of representative rock or sediment types see kenyon 1997 allen et al 2000 dunn et al 2002 in a logged borehole the t2 distribution curves are typically plotted as horizontal bars with colour representing amplitude against depth to show how volumetric water content porosity in fully saturated materials and pore size distributions are changing downhole this variability in total and mobile porosity with depth provide insights on subsurface heterogeneity informing permeability and diffusion properties of porous media it is the ability to differentiate the water content distribution that largely differentiates nmr from other earlier geophysical techniques used to estimate porosity such as neutron and gamma gamma density interpretation of neutron logs the only other geophysical technique that directly measures hydrogen content requires other data e g gamma logs etc to estimate the portion of the water bound in clays hearst et al 2000 estimating porosity from gamma gamma logs requires an assumption of matrix density to infer the water content e g keys 1997 the major disadvantage of using either neutron or density tools is that both are energized by radioactive sources with inherent regulatory storage and logistical requirements as well as liability concerns although other geophysical techniques such as full waveform sonic galvanic resistivity inductive conductivity etc can be used to infer porosity multiple rock parameters and empirical constants must be assumed which can vary dramatically with lithology although not generally a concern in shallow hydrogeologic applications interpretations of the porosity are further complicated for all techniques if the pore fluid also contains hydrocarbons e g oil gas etc an important consideration in the use of nmr technology is its sensitivity to the concentration and grain size of magnetic minerals primarily magnetite in the material surrounding the borehole internal gradients between the grains and the pore fluid if sufficiently strong will act to shorten the t2 relaxation times dunn et al 2002 keating and knight 2007 fay et al 2015 in carbonate bedrock and quartz sandstones such as those logged in this study magnetic minerals are typically not present in sufficient concentrations to affect nmr measurements however in clastic sedimentary or igneous bedrock settings where magnetic mineralogy may be present in higher concentrations porosity and pore size distribution estimates may be compromised or in some cases the nmr signal entirely disrupted currently there are two manufacturers providing a range of small diameter nmr tools available in north america vista clara mukilteo wa usa and more recently nmr services australia nmrsa perth australia each manufacturer has adopted their own approach to the design of their instruments walsh et al 2013 hopper et al 2017 respectively there are proprietary technological distinctions between the systems that primarily manifest as differences in the operating frequency bands vertical resolutions and the number of frequencies used during the measurements table 1 the nmrsa system uses a single nominal frequency which produces a comparatively thicker measurement zone a thin cylindrical shell at one diameter of investigation doi the vista clara system can collect two or four frequencies during the measurement sequence depending on the tool model producing a log with multiple radial distances into the formation each shell has a thinner measurement zone than the nmrsa system but these can be combined during processing so as to broaden the depth of investigation or selectively ignore extraneous noise at individual frequencies if present multiple shells also allow a user to examine response at different radial distances and exclude data inside a potentially disturbed zone but there are considerations when averaging across different volumes during data collection the nmrsa system is generally operated in continuous mode while vista clara tools are used in either a stepped mode incrementally pausing and taking readings at intervals equivalent to the instrument s rf coil length or in a continuous mode given the shell diameters relative to the borehole neither manufacturer specifies centralization although non metallic offsets are often used when the probes need to be passed through steel casing as was the case at the ottawa site but not at the guelph site 2 2 field work the fundamental challenge to assessing technology performance in field settings is that the standard against which the measurement s are compared is inherently poorly defined or unknown as well as the resolution subject to the uncertainties of other technologies and heterogeneity the approach adopted here is to collect the best data practical while minimizing other variables i e stationary nmr readings with extended sampling at 0 5m intervals in all the boreholes against this baseline additional targeted data were collected at higher density 0 1m intervals to assess repeatability and resolution of specific targets fractures and voids of varying apparent aperture as characterized by imaging tools finally measurement complexity was added in the form of probe motion at various logging speeds as well as with reduced measurement sampling and frequencies the performance of the probes is assessed against the baseline and results are compared against physical measurements on the core and relevant geophysical logs the majority of the data collected were acquired and processed by the authors with a vista clara system dart and javelin models henceforth referred to as the small and large diameter tools respectively the nmrsa system bmr 60 model was operated by nmrsa mount sopris personnel with support from dgi limited for one day at each site and the data subsequently processed by the manufacturer unless qualified as referring to nmrsa specifically data acquisition and results refer to a vista clara system the basic specifications of the systems used at the time of logging are provided in table 1 at the ottawa site nmr data were collected in one borehole bc81 2 76mm diameter over two days in july 2018 using the small and large diameter tools data acquisition were limited to the open hole in the sedimentary bedrock sequence 10 65m where magnetic susceptibilities were low 10 4si the precambrian bedrock contains intervals of elevated magnetic susceptibilities 10 2si that caused interference with nmr readings data were collected with the small diameter tool as stationary readings at 0 25 m increments in dual mode using two cpmg pulse sequences scan lengths each separated by fixed repetition times tr to capture both long tr 3s scan length 0 3ms 10 stacks and short relaxations tr 0 15s scan length 0 03 ms 50 stacks stationary data were collected with the large diameter tool at 0 5m increments in dual mode long tr 3s scan length 0 15ms 12 stacks short tr 0 1s scan length 0 02ms 20 stacks at the guelph site nmr data were collected in five vertical boreholes gdc 05 06 07 08 09 122mm diameter over seven days in june 2019 using the large diameter tool data were nominally acquired using all four frequencies in dual mode to capture both long tr 5s scan length 0 25ms 16 stacks and short tr 0 15s scan length 0 0ms 96 stacks relaxations one full run of each hole was collected over approximately 7 5h using stationary recordings at 0 5 m increments creating a basis of comparison for various other tests using different recording parameters stationary measurements were also recorded at tighter 0 1m increments over 2 3m intervals of interest in the borehole a void fractures of varying apertures identified from existing image logs to determine if additional insights could be gathered on porosity features and the instrument response function these additional data sets overlapped the baseline data sets so as to assess the repeatability of readings and augment a 15 m portion of gdc 05 that was repeated on subsequent days continuous runs were recorded at several speeds ranging between 0 17m min and 0 86 m min in gdc 05 and 08 to investigate the influence of probe movement during recording in some cases one of the noisier frequencies f3 was turned off to increase data collection speed the nmrsa system data were collected in continuous mode at the guelph site in gdc 05 and at the ottawa site in bc81 2 in a single up down run at approximately 1m min data collection parameters instrument repeatability response function and processing steps for the nmrsa tool were not examined by the authors therefore this study was not intended as a direct comparison of the two systems 2 3 data processing data from the small and large diameter tools were processed using javelinproplus software v 3 6 3 provided with the vista clara instruments the data collected with the large diameter tool at both sites were imported without impulse spike removal data collected with the small diameter tool at bells corners were imported with impulse removal in the upper 21m as an incoming electrical storm caused spikes as the tool approached the surface the t2 relaxation time series from each of the frequencies two for the small diameter tool three or all four for the large diameter tool were combined producing a set of total porosity estimates and pore distributions data were exported relative to ground surface without depth averaging for display and interpretation alongside existing geophysical logs in absence of site specific cut off times for these rock types the default cut off times between clay bound capillary bound and mobile water for limestone carbonates were used for the presentation of the guelph data 3ms and 90ms respectively for the bells corners site sandstone cut off times were used 3ms and 33ms respectively 2 4 laboratory analyses porosities from both test sites were independently calculated from gravimetric water content measurements performed on cylindrical core specimens using an immersion saturation method standard and d2216 19 2019 astm standard d7263 21 2021 the saturation method provides a measure of each sample s interconnected effective porosity and does not include fluids bound in isolated pores twenty three 23 samples of guelph core from gdc 05 sub cored to 38mm in diameter nominally 14mm in length maldaner et al 2019 were tested at the university of guelph ottawa core porosities were calculated from measurements performed at canmet mining s rock mechanics laboratory in ottawa on 17 core samples from bc81 2 nominally 47mm in diameter 35mm in length crow et al 2021 3 results the various nmr data sets collected at the two sites were collated regrouped as warranted and evaluated as well as compared to existing data to assess the tool performance as follows note to avoid confusion porosity is herein referred to as a unitless fraction ranging from 0 00 to 1 00 and refers to various comparisons e g difference between measurements 3 1 tool response function the instrument response function defines how the surrounding formation influences the tool response within the sampled volume and thereby represents volumetric changes in rock matrix and discontinuities i e fractures measured the large tool s theoretical vertical resolution of 0 5m was examined in a borehole setting by collecting recordings at 0 1m increments stepping into and then out of a water filled void dissolution enhanced zone in dolostone that extends over 1 84m in gdc 06 at the guelph site the results of this process using the lower and upper boundaries of the void are shown in fig 3 two curves are developed by dividing the probe response into 0 1m intervals and stepping the response between a uniform background rock porosity estimated from repeated similar readings and the void assumed initially to have a porosity of 1 0 once developed the area under each curve is normalized to be one by varying the porosity of the void the results from the lower blue and upper green boundaries are similar and averaged to create the estimated response curve red for the probe the curve indicates that the response has a central focus with longer tails of sensitivity the shape is slightly asymmetric incorporating the surrounding material from 0 3m below the position of the peak response to 0 5m above the peak response 0 8m in total breadth while the apparent asymmetry may be influenced by the variability in the shape of the void the majority 60 of the sensitivity is focused in the central 0 2m 0 10m of the assigned depth 3 2 repeatability the assessment of repeatability incorporates both the electronic stability of the instrument and the similarity of the volume being measured as the probe s measurement shell is very thin and potentially radially slightly asymmetric as shown above some reading variability may result from inclination of lithologic layering discontinuities in the rock or the presence of metal magnetic minerals within the volume sampled based on depth realignment and the side of the borehole the probe rests against these tests focused on short term repeatability of the instrument in water saturated conditions over hours to days in a stationary mode measurements recorded at 0 5m steps were compared to overlapping measurements recorded hours or days later at 0 1m increments in gdc 05 gdc 06 gdc 07 and gdc 09 using the same acquisition parameters fig 4 vertical realignment between tests is likely very close because the depth is referenced to tape marks on the cable the cable is plastic coated no tape slippage was identified and efforts were made to minimize parallax in aligning the tape at the top of the casing although minor cable stretch could have occurred it is reasonable to assume that would be similar in all runs spurious readings marked as x in fig 5 a occurred at 21 05m in gdc 05 detailed examination of the optical televiewer image identified a void containing oxidized rusty material on one side of the borehole we speculate that there are spurious metal fragments within the void and that the probe was running along that side of the borehole when it recorded the elevated porosity although there are irregular data at this depth in the two continuous nmr logs collected in gdc 05 no other data set in any of the other boreholes logged had such an irregular result see below this data point was therefore not considered in the regression the linear regression comparing the repeatability of the total porosity data sets has a slope of 0 98 an r2 of 0 99 and is dominated at high porosities by the large void in gdc 06 the crossplot has a low scatter particularly amongst the values at and above 0 15 porosity fig 4b focuses on the low porosity values and further subdivides the data to differentiate the mobile water from the combined clay and capillary porosity fractions the plot confirms that the correlation of the mobile water has relatively low scatter and a regression of 1 00 with an r2 that rounds to 1 00 table 2 summarizes the absolute difference between repeated porosity estimates subdividing between all the data from estimates above and below 0 15 porosity it confirms the difference in the higher porosity values is approximately a third of that below 0 15 porosity the largest variability is predominantly a consequence of variation in the estimate of the clay and capillary bound water fraction 3 3 acquisition modes instrument response was also examined when the tool was operating in stationary versus continuous logging modes the primary difference between the two modes is the depth of the tool as it cycles through the long and short pulse sequences across the four frequencies in continuous mode the instrument s sensitive region is changing during the recording the continuous logs will sample all of the rock but with a degree of averaging in the process for the continuous logging tests the speed was adjusted so that the tool s measurement point would pass by the 0 5m logging increment over the time required for the pulse sequences to run therefore as the logging speed is increased the duration of each reading needs to be reduced either by decreasing the number of stacks or collecting data over fewer frequencies or both introducing movement using the same logging parameters as the stationary run but turning off the noisiest frequency f3 300 khz required a logging speed of 0 17m min this short run was focused on the transition from the gasport formation into the finer grained overlying eramosa formation because of the contrasting porosity characteristics to increase the speed to a rate closer to 1 0m min the number of averages of the short and long cycles were reduced by 75 versus the stationary run and f3 was turned off with these parameters the logging speed was determined to be 0 86m min a third run was acquired with these parameters but doubling the vertical sampling interval 0 25m which required a slower logging speed of 0 25m min table 3 provides a summary of the various logging parameters for these runs with logs presented in fig 5a although the logs were collected over different depth intervals a logging time estimate is provided to complete a full pass of the open rock portion of the borehole 57 5m the average noise level of each run was tabulated over a common 20m depth interval 23m 43m so as to assess similar geologic variability to provide information at an intermediate logging speed of 0 44m min parameters from a short run in gdc 08 are also provided in table 3 spanning a 12m interval from 32m to 44m in a finely layered geologic sequence multiple competing factors lithologic layering changing volume of rock measured over the duration of a reading spatial averaging over that volume measurement density and the noise reduction reading with repeated scans all influence the variability observed and overall data quality separating the contribution of these factors when the actual standard reality is unknown is a formidable challenge as an initial visual comparison of the runs in fig 5a the general trends and variations of the clay capillary bound and free water components within the different stratigraphic units are repeated particularly in the free water fraction the 0 25m min run appears to be the most variable of the datasets a visual effect enhanced by doubling the vertical sampling rate to readings every 0 25m all three of the logs under motion show slightly higher total water contents and clay fractions in various portions of the logs in contrast the total water content of the 0 86m min run appears the smoothest of all the datasets with a few localized highs the t2 distributions in the continuous logs display more elevated amplitudes in the early decay times resulting in more clay bound porosity than was observed in the stepped measurements this could be attributed to fewer averages collected over the interval and therefore a lower sn ratio these tests indicated that while free water late decay is relatively consistently captured in all modes the response to bound water is more variably defined when the instrument is collecting fewer short scans to allow for faster logging speeds in continuous mode it is difficult to differentiate the effects of conflicting influences on variability and noise and define the quality of the reading to quantify the response variability the vc software calculates noise as the standard deviation of the cpmg decay curve as is reported in units relative to 100 water content note that the approach to calculating noise differs between instrument manufacturers the relationship between increased logging speed and average noise levels is shown in fig 5b noise from multiple frequencies is calculated based on weighted stacking of the frequencies with greater weight given to lower noise levels in this study reducing the number of stacks by three quarters from the stationary measurements allowed for a logging speed of 0 86m min and a significant reduction in logging time but led to an almost quadrupling of the average noise level 2 9 to 10 5 similarly halving the number of stacks to allow for a logging speed of 0 44m min led to a doubling of the noise levels 2 9 to 6 0 theoretically noise is assumed to be random and gaussian so halving the number of stacks would increase the noise by a factor of 2 or 1 414 in fig 5b the average noise within the specified boxed interval for the runs collected at 0 5m increments have a regression with an r2 of 0 98 not included in the regression the 0 25m min 0 25m increment run is a clear outlier although it was collected with near identical sampling parameters to the 0 86m min run and has the same level of noise the logging speed was reduced to accommodate the reduction in step size the implication is that the sampling parameters are the dominant control on the noise levels in these tests we observe a greater increase in noise than theory predicts would be attributed to a decrease in stacks for example with 16 long and 96 short scans a noise level of 2 5 was observed at 4 long and 24 short scans theoretically a noise level of 5 2 would be expected rather than 10 5 as observed however with these tests we cannot quantify the potentially countering effects of averaging over a larger portion of the rock as the probe speed increases against the possibility of measuring more varied lithologies and any influences of electrical noise created when the winch was in motion while these noise levels may be atypical to this setting the results indicate the choice of logging speed intertwined with the amount of stacking has a clear impact on the noise levels and thus data quality this is a particularly important consideration when defining the pore size distributions in materials containing finer grain sizes like shales and some dolomitic carbonates 3 4 fracture identification past studies using petroleum sector instruments examining the potential of nmr to estimate the apertures of thin saturated fractures nakashima and kikuchi 2007 xiao and li 2011 have predictably revealed that response is more pronounced as fracture apertures and fracture frequency increase beyond a minimum detectable aperture which is based on tool characteristics the t2 distribution is shown to be affected by the type of fluid in the well fracture dip and tool characteristics such as the echo spacing and antenna length a short antenna was found to be more sensitive to the identification of fractures than a long one xiao and li 2011 in this study large diameter tool responses were measured across selected water filled discontinuities fractures of varying apertures using 0 1m stepped intervals apertures were estimated at the borehole wall using televiewer data while this measurement is recognized to be oversimplified and should be considered as an apparent aperture because it represents a limited portion of the fracture and also depends on the interaction between the drill bit and the rock mass the value serves as the best gauge available for fracture aperture the threshold for fracture identification as a discrete feature by the larger tool is determined to be between 66mm the largest fracture that does not create a distinct nmr increase in the free water content above background water contents fig 6 a b and 102mm the smallest one that does fig 6c e where we observe distinct increases in free water the shape of the response varies between a narrow high peak gdc 07 60 8m fig 6e and a broad plateau in fractures of both smaller gdc 09 59 6m fig 6c and larger apertures gdc 07 53 2m fig 6d an explanation for this observation is that the dip of the fractures as they cross the instrument s sample volume broaden the response due to the vuggy nature of the fractures however the regularity of these features was difficult to assess features thinner than the minimum apparent identifiable aperture would be smeared by the resolution of the tool fluid in these saturated fractures would still be detected but appear as small increases of free water in the total water content 3 5 varying geological materials boreholes at the guelph and ottawa sites present a range of bedrock types and characteristics comparison with traditional geological core descriptions geophysical logs e g gamma resistivity gamma gamma density provide important lithological context about variation in clay content cementation and bulk densities properties that affect the hydrogeological characteristics of the bedrock matrix televiewer logs also provide continuous millimetric scale imagery of the borehole identifying contacts discontinuities and textures in the borehole wall some key logs were selected to assess how variations in geological materials are reflected in the nmr responses fig 7 at both sites there is generally excellent alignment between lithology as indicated by the gamma inductive resistivity and density logs fomenko 2015 guelph site crow et al 2021 ottawa site and the variation in the water content represented by the nmr logs at the guelph site silurian dolostone fig 7a all major geologic units identified in the core show further subdivisions as indicated by the gamma logs the nmr similarly shows distinct changes in either total porosity or proportions of bound or capillary water in the regionally discontinuous aquitard unit typically viewed as the vinemount member of the lower eramosa formation and the ancaster member of the goat island formation below the nmr log consistently shows little or no mobile water fig 7a segment i conversely in the regional aquifer gasport formation the nmr log displays the most elevated free water content in agreement with the increase in vugs and primary porous structures observed in the cores the nmr log suggests there are further refinements to be made within stratigraphic units particularly within the niagara falls member of the goat island formation and gasport formation that are traditionally interpreted to form the regional supply aquifer for example a distinct increase in the total porosity primarily as mobile water occurs from 56 to 63mbgs fig 7a segment ii which seems to align with a highly transmissive zone within the gasport formation at the ottawa site fig 7b the shallow sandy dolomitic rock above 20 5m displays lower nmr porosities with a relatively larger proportion of the porosity attributed to bound porewaters than in the nepean sandstone below 20 5m 64 5m within the sandstone relatively low gamma counts coincide with intervals of elevated porosities with a high proportion of free water content in beds of poorly cemented quartz sandstone e g 23m 32m fig 7b segment iii below 37m the quartz sandstone becomes intercalated with a series of bioturbated sandstone beds with increased mud content the gamma levels correspondingly increase and become more variable herein the nmr shows an increased clay and capillary bound fluid fraction with reduced free water content assuming generally uniform matrix properties bulk porosity is observed to be inversely proportional to density densities are generally lowest where free water porosities are most elevated e g 25m 32m 58m 61m fig 7b segments iii and v conversely increases in the density log correspond to reduced nmr porosities e g 32m 36m fig 7b segment vi 3 6 observations at the water table of note at the guelph site is that the nmr indicates the presence of elevated free water content in the upper eramosa spanning 13 22m above below the base of the plastic casing near the bedrock surface fig 7a segment vii and also clay bound water within the overlying diamict the mobile water is 1 to 2m above the water level measured during logging the upper portion of the bedrock is likely a chemically mechanically weathered highly fractured contact zone that has led to an increased secondary porosity the guelph site is on a local topographic high and there is a downward component of hydraulic gradient as confirmed by flow meter and straddle packer testing hydraulic head profiles from temporary transducer deployments and temperature data munn 2019 maldaner et al 2019 fomenko 2015 data from a sealed temporary deployment in nearby gdc 12 munn et al 2020 infers a water level in the overburden upper rock to be at approximately 6 4mbgs and that the interconnected fracture network under open hole conditions create a blended hydraulic head in the borehole that is deeper than the true water table in the surrounding rock given the known downward component of hydraulic gradient the water content indicated by the nmr likely represents both the true formation water level in the rock matrix between fractures and the capillary fringe this observation is also supported by a decrease in the inductive resistivity and temperature data above the open hole water level this suggests that nmr can be useful in assessing the reliability of blended water level measurements in open cross connecting boreholes as well as estimating the thickness and position of the capillary fringe due to the presence of a metal casing extending into the top of the bedrock at the ottawa test facility this effect could not be observed in borehole bc81 2 3 7 comparison with laboratory core porosities gravimetric porosities from core samples taken from both research facilities are shown overlying the nmr estimated porosities in fig 7 and as cross plots in fig 8 a and b at borehole gdc 05 in the finer grained layers of the upper and lower eramosa formation as well as the ancaster member of the goat island formation i e above 40mbgs the comparison between core and log porosity datasets is excellent through the niagara falls member of the goat island and the gasport formations approx depths of 40m 70m the higher values are similar except where the nmr is influenced by a large aperture fracture 58m in the zone from 40 to 70mbgs the core sample porosities are considerably more variable and in many cases show lower porosity values in comparison to the nmr borehole log near the bottom of the borehole where the borehole enters the cabot head shale approximately 70m the two porosity estimates become more consistent fig 8a shows cross plots of all the total porosity from the nearest stationary nmr data against the core sample porosities n 25 note that the depths of the two data sets do not always match exactly however the alternative approach of estimating nmr porosities by linear interpolation between readings found no appreciable difference as a comparison fig 8b refines the plot by removing three data points from above the blended water level in the borehole and two data points at 20 53m and 57 93m where large fractures are interpreted to have increased the nmr porosity estimate the removal of the selected data changes the slope of the regression from 1 14 to 1 00 and increases the r2 fit from 0 42 to 0 68 the average absolute deviation between nmr and core measurements is 0 014 but the difference was as high as 0 05 and the average and median values of the absolute difference 0 02 and 0 015 respectively although the 1 1 slope is ideal the scatter in fig 8b is further assessed by stratigraphic unit the data are colour coded with the higher clay content units with elevated gamma levels in shades of grey brown ancaster vinemount and reformatory quarry members and the low clay content layers niagara falls gasport and irondequoit higher transmissivity units and low gamma levels in shades of blue the higher clay content layers dominate the low porosity portions of the plot and generally have a much better fit to the regression line than the data from the higher porosity units the data points from the niagara falls member and gasport formation tend to be at or above the overall trend line shown in grey with more scatter in comparing the regressions on the two subsets although the data sets become smaller n 10 and 9 respectively the slopes of the best fit lines are similar 0 66 and 0 68 the r2 fit is 0 81 for the clay rich deposits and lower at 0 61 for the aquifer formations notably the intercept for the first group is 0 02 and the latter 0 05 implying an overall offset in the core mnr comparison in the porous units although it should also be noted that the line is projected further to reach the axis accentuating any skewness the increased variability and higher intercepts between nmr relative to core porosity estimates in the silurian dolostones as noted in figs 7 and 8 is attributed to the combined effects of the small sample volume of the core tested versus the much larger volume sampled by the nmr tool in an interval known to contain vuggy porosity as well as the absence of fracture porosity in core sample measurements made in the laboratory the core samples are inherently biased as only intact portions of the rock can be sub cored for testing whereby small scale porosity will be better represented than larger macroscopic pores and fractures that cannot be properly sampled for lab testing therefore core porosities do not completely represent the bulk rock mass although with few exceptions the general fracture frequency over 1m intervals of the higher clay content formations is slightly higher the fractures are predominantly low aperture bedding plane partings rather than the fewer but larger fractures in the aquifer other than grain size and fracturing the most notable difference between the two groups is the high occurrence of vugs observed in the core from the aquifer formations that likely further weaken the correlation at the ottawa site the core and nmr porosities also show close agreement table 4 fig 8c presents quantitative comparisons between effective core porosities and nmr porosities measured with the small and large diameter tools in intervals where the porosity is shown by lab tests to remain fairly consistent e g the 0 76m sandstone interval spanning 59 22 59 98m where five core porosity tests ranged from 0 084 to 0 094 the nearest core and large diameter tool s nmr porosity measurements are 0 094 and 0 093 respectively similarly in the 0 26m dolomitic sandstone interval spanning 17 56 17 82m where three lab porosity tests range from 0 0195 to 0 0312 the nearest nmr porosities with the large and small diameter tools are 0 052 and 0 02 respectively the regression line for the large diameter tool n 11 has a similar but slightly lower slope 0 60 than observed at the guelph site when lithologies were considered individually and an intercept 0 04 consistent with that observed for the dolostone the data for the small diameter tool n 7 has a slope of 1 35 and intersects close to the origin but is relatively poorly represented towards the higher end of the range with only two points with porosity above 0 08 that have the largest offsets from the core samples 0 07m and 0 11m and therefor less robust the nepean sandstone provides additional insights regarding contrasting porosity in thinly bedded 0 1 m to 0 3 m thick zones common in interlayered sedimentary deposits in intervals where the core porosity changes abruptly from bed to bed over short 0 1 m distances e g 29 58 29 90 m the direct comparison of the core and the nearest nmr reading reflects differences in the vertical scale of both geology and tool resolution as well as vertical offsets between nmr measurements and core samples the effects of fine scale bedding with contrasting porosities are further examined in this interval by directly comparing the responses of the small and large diameter tools where closely spaced lab measurements reveal interbedded low 0 015 and higher 0 08 0 124 porosity sandstone layers fig 9 with the large diameter tool the nearest nmr porosity to the series of lab measurements is 0 115 the longer shell of investigation is not strongly influenced by the 10 cm thick low porosity bed but does detect an increase in clay bound water which is consistent with the narrow response curve postulated above the nearest reading with the small diameter tool to the low porosity bed is 0 034 which increases to 0 145 as it enters the underlying higher porosity interval showing higher vertical resolution to changing porosity layers this comparison shows how increased vertical sampling measured over a smaller volume could provide a more refined estimate of porosity in finely interbedded sedimentary sequences where porosity conditions are changing abruptly 4 discussion tests performed at the two field research sites provide insights into the performance of the borehole nmr tools under various deployment modes examination of nmr logs relative to other existing high resolution geophysical logs and core porosity measurements provide unique insights and highlight relationships between nmr response and in situ formation characteristics in this section we discuss the implications of the field test results and practical considerations for integrating this technology into hydrogeological studies field tests with the large diameter tool suggest a response curve with sloping edges and an overall 0 8m vertical length the maximum contribution spans 0 2m centered over the measurement point contributing approximately 60 of the reading approximately 87 of the reading comes from the manufacturer s reported 0 5m vertical resolution of the instrument 0 25m above below tool s measurement point fig 3 and table 1 although the shape and vertical length of the response we calculated may be unique to this specific probe and or to some degree be influenced by the mineralogy and natural geological variability of the void edges this response shape is in close agreement with observations by dlugosch et al 2013 in their laboratory studies of instrument response conducted by changing the height of the water level in 0 03m increments inside a shielded tank they observed a similar response with a shape described as trapezoidal with a 0 75m vertical length although their studies were conducted with a different model of the tool j350 both instruments had the same reported vertical resolution of 0 5m these observations suggest that although design details will vary from probe to probe an instrument response function will extend slightly beyond the edges of the reported rf coil length from a hydrogeological perspective the shape and length of the response defines the achievable vertical resolution of the instrument and the level of detail and therefore cost required to achieve 100 coverage when that is a necessary project requirement as with other geophysical probes that measure a response to an input stimulus e g electrical induction active gamma neutron an nmr tool will sense all the material in the measurement zone but a central band dominates the measurement this will tend to smear thinner layers or features while accentuating the portion with maximum contribution as discussed below the coverage can be extended with motion but with other compromises tests of instrument repeatability with the large diameter tool confirmed that stationary measurements were highly repeatable over a time scale of hours to days qualitatively data collected on separate runs at the guelph site overlap very well figs 3 5 and 6 with slightly more scatter where fracture frequency increases fig 6 a and b it was observed that the mobile fluid portion is extremely repeatable within 0 8 the bound fluid clay capillary fractions displayed slightly higher variability between repeat readings 1 8 for porosity values below 0 15 porosity this observation has particular implications for nmr logging when defining the properties of aquitards or materials with very small pores these greater differences are attributed to a lower sn ratio in the detection of the short t2 components that could be improved by using a tool with a shorter echo spacing slim hole tools with echo spacings as low as 0 45ms are now available increasing the number of scans in the short t2 components could also improve the sn ratio if the tool is stationary during the recordings comparing instrument repeatability between stationary versus moving runs indicated that the choice of data collection settings number of averages scan lengths frequencies and logging modes stepped or continuous strongly influences the results each complete reading is comprised of a series of repeated cpmg measurements recorded over a user selected configuration of early and extended times so as to sample the complete t2 signal decay given the inherently low nmr signal strengths produced increasing the number of averages stacks within each scan window improves the sn ratio decreases the noise but also increases the recording time required increasing the number of short stacks is particularly important in rock with higher clay size content where most of the signal decay occurs in the early portions of the record the measurement time is further extended when performed over multiple frequencies to investigate various radial distances from the tool in selecting collection parameters a balance is required between the number of frequencies doi s the selection of signal recording parameters increased repetition to reduce noise and logging speed time and cost to optimize the process the appropriate balance of measurement parameters also depends on the complexity of the layering and stratigraphy both of which often change between intervals of the same hole in lithologies where porosity changes abruptly between thin beds i e distances less than the tool s vertical resolution selecting a tool with a shorter vertical resolution shorter coil length and with more closely spaced measurements resulted in closer agreement between nmr porosity and core measured porosity however this improvement came at the cost of increased logging time with respect to identification of fractures with nmr observations from field tests with the large diameter tool show a fracture was identified with a 102mm apparent aperture at the borehole wall while a fracture with a 66mm aperture was not identified as a discrete feature the implication is that fractures with high hydraulic transmissivity could remain unidentified by nmr logs alone an issue discussed further in the context of permeability estimation the log suite also demonstrates that even with 0 5m stepped readings the probe might not be optimally aligned to measure the maximum effect of the fracture fig 6c d and e this could have resulted in peak effective total porosity being underestimated by as much as 0 12 due to the averaging of fracture water content over the vertical extent of the sensitive volume where the 0 5m reading is less than optimally vertically aligned with the feature high resolution imaging data confirms the alignment of nmr readings with rock features and improves interpretation these results indicate that the advantage of slim hole nmr is its application to matrix porosity measurements and bulk hydrogeological properties comparisons of porosity between the large and small slim hole nmr tools against core measurements produced favourable results in bedrock with relatively homogeneous porosity however a more detailed examination of all the total porosity data shows that correlation varies with the nature of the lithology range in pore size and fracture occurrence generally nmr estimates of total bulk porosity range from 0 04 relative to laboratory measurements on core samples in the proximity of large fractures however this difference could reach up to 0 15 or more having additional information about fracturing such as image logs or core data improves understanding of cause and effect as observed the difference in vertical scale between lab measurements on a small unfractured core puck versus the larger volume of the nmr measurement can have a significant affect on the comparison close agreement between core and nmr porosities was observed in the more homogeneous intervals of sandstone at the ottawa site and in the finer grained units at the guelph site it is noteworthy that only one sample at the guelph site 34 76mbgs is interpreted to have the water content primarily as clay bound while all of the other samples in the fine grained units have water content predominantly in pores with capillary bound water since the lab measurement does not assess clay bound water it remains uncertain whether the correlation would be as strong in a rock with a pervasively higher clay component in the dolostone containing vuggy porosity the nmr detects more free water than is measured by core tests suggesting that the nmr characterization of the aquifer is more representative of the larger scale properties of the rock examples of nmr data collected in the same boreholes by two different equipment manufacturers are presented on fig 10 these data are presented to make the reader aware of the instruments available as well as data collection modes but not to provide a controlled head to head comparison of the systems although the trends in mobile water are similar in the profiles from all instruments differences in capillary and clay bound water volumes are observed at both sites the bmr 60 data are more variable than the baseline javelin 238 data collected in stationary mode at 0 5 m intervals however the former is both collected in continuous mode and at finer intervals both of which were shown in fig 5 to increase variability even when collected with the same system the variability of the bmr 60 data at the ottawa site is more similar in appearance to the data collected with the dart the dart when compared to the javelin has a higher frequency a narrower vertical resolution a 0 25m data collection interval and a shorter echo time see table 1 the other striking difference between the data sets is the higher proportion of clay bound water generally interpreted with the bmr 60 using a 3ms cut off for all t2 distributions the lack of differentiation between lithologies as well as the overall higher proportion of clay suggest that other influences are factors whether this result is inherent to the technology and or the nature of how the water is bound within the rock requires further investigation in cross plots of the total water estimated from the nmrsa tool against the vc baseline data from each site bc81 2 and gdc 05 fig 10b both the sandstone red and dolomite blue exhibit considerable scatter with an absolute mean difference in the total porosity of 0 042 in the sandstone and 0 03 in the dolomitic rock if the regression is forced through the origin the slopes are 1 12 and 1 10 respectively with r2 of 0 72 and 0 86 suggesting reasonable correlation however allowing the regression complete freedom respects the observation that in practice there is no presumption that instruments should respond similarly at low porosity levels in this case the correlation deteriorates dramatically r2 of 0 02 and 0 36 for bc81 2 and gdc 05 respectively the average difference of the nmrsa tool relative to the large diameter tool from the vista clara system is 0 03 bc81 2 and 0 02 gdc 05 suggesting overall readings are similar but maximum offsets are closer to 0 15 at both sites it should be noted that the tools have different designs see table 1 that the datasets were collected with different logging parameters the nmsra is under motion and processed using different settings software this comparison highlights the necessity for the user reader to have a clear understanding of all system characteristics as well as data collection and interpretation parameters to establish confidence levels in applying the results 4 1 permeability estimation an estimation of permeability k is a highly sought after parameter for a complete understanding of a formation s hydrogeologic characteristics several models have been developed to estimate k in porous materials from nmr measurements e g schlumberger doll research sdr equation kenyon et al 1988 straley et al 1997 the timur coates tc equation timur 1968 coates and dumanoir 1974 the sum of echoes soe model sezginer et al 1999 the kozeny godefroy kg model dlugosch et al 2013 and the seevers model seevers 1966 no matter the model the calculation of k from nmr data directly depends on the quality of the logs and our understanding of the material properties to inform appropriate equation parameters consequently how well the t2 components are characterized during data collection is critical in the estimation of k as the collection of high quality nmr data clearly depends on many variables this article has focused on first assessing the technological aspects of the instrument response and data collection rather than assessing models nmr estimation of k relies on kozeny carmen type flow where porosity and pore dimension are the main controls on flow however it is well documented that in a fractured rock setting groundwater flow will be predominantly through the discontinuities e g novakowski et al 2006 therefore given the relatively large apparent apertured features that are herein shown as undetected considerable flow could occur in fractures that are not identified as discrete features by the nmr tool additionally in fracture networks k can be dominated by interconnection of fractures which is not assessed by nmr consequently a bulk k estimated solely from nmr data could misrepresent the hydraulic characteristics of the broader rock formation a study by ren et al 2018 conducted in a fractured granite aquifer explores the integration of nmr logs with other downhole tests focused on fracture flow flute liner and slug testing to calculate a more representative knmr parker et al 1994 2010 and others have highlighted that matrix porosity and permeability are critical factors in the diffusion of contaminants into the matrix and consequently retardation of plumes in fractured sedimentary rock therefore despite the limitations of nmr in fracture identification the logs provide important matrix porosity estimates for such critical applications 4 2 practical integration of nmr technology into a hydrogeological study in comparison to other geophysical techniques for measuring porosity a key benefit of nmr is the direct measurement of water content while avoiding the complications and risks inherent in the use of nuclear sources required for gamma gamma or neutron tools for estimates of porosity the clear advantage of a slim hole nmr tool is in its application to matrix porosity measurements and bulk hydrogeologic properties rather than narrow bedding features and some fractures nmr measurements provide a broader scale estimate of downhole porosity variability than discrete core testing which is almost always by necessity more intermittent it also allows for in situ testing when core is unavailable for laboratory testing and when core is available nmr logs can guide core subsampling by providing broader context for physical samples nmr logging is very complementary to other downhole geophysical instruments that also respond to the various physical and chemical properties of the matrix a priori knowledge from core and or other geophysical logs such as gamma for lithology and imaging atv or otv is helpful in the deployment of nmr technology although in practice this full breadth of information is not always available factors like geology e g sediment vs bedrock vertical scale of beds grain size and magnetic mineralogy of matrix and borehole details e g diameter completion formation disturbance drilling fluid invasion have implications for the choice of tool e g rf coil length multi or single frequency echo time and data acquisition settings e g stacks stepped or continuous logging similarly the interpretation is optimized when complementary data is available to provide context for porosity variations a key consideration is selecting a tool with a diameter of investigation that will reach into undisturbed material beyond the borehole logistically acquisition parameters have an effect on the survey duration and thus cost stepped logging can be slow due to the time needed to move the instrument between readings and in turn potentially prone to user error but results in highest resolution however optimally slow continuous logging can require a similar time commitment the advantages of continuous mode include less user interfacing during the collection more complete sampling along the borehole and potentially faster data acquisition but as the speed is increased there will be a trade off in sn ratio resolution and reliability the underlying igneous bedrock at the ottawa site is a setting where the concentration of magnetic minerals is too elevated for nmr logging however not all igneous bedrock is enriched with magnetic minerals and a magnetic susceptibility ms log can provide needed information about intervals where the very high ms will need to be considered for data interpretation recent laboratory studies examining the effects of elevated ms in unconsolidated aquifers on slim hole tools can be found in fay et al 2015 and keating et al 2020 as instrument response depends not only on formation characteristics e g concentration and grain size of magnetic minerals pore size but also on tool design factors e g magnetic field strength echo time manufacturers can provide guidance on nmr logging in such settings other logistical considerations include that the tools cannot be operated in or within a few meters of metal casings proactive strategies must be taken to overcome the extremely strong magnets when lowering the sondes through steel casing into the measurement interval below spurious metal in a borehole e g from drilling activities can distort the signals making the data incoherent the instrument can also be sensitive to various forms of urban electromagnetic noise particularly at depths shallower than 10m over the course of this data collection interference from am radio frequencies operating in the same bandwidth as one of the probes was observed to very negatively affect instrument noise levels in the near surface an incoming electrical storm also caused spikes in the shallow data that were removed during processing the instruments can also be sensitive to borehole features such as washouts and decentralization in large boreholes 5 conclusions this study assessed the performance of available slim hole nmr technology in resolving critical hydrogeologic parameters of fractured sedimentary rock utilized as shallow municipal aquifers the study was conducted in the silurian dolomitic sequence at the university of guelph s fractured rock observatory in guelph ontario and the cambrian sandstone at the geological survey of canada s bells corners borehole calibration facility in ottawa ontario the datasets are presented to provide readers with awareness of the technology and what can and cannot be resolved from an independent user s perspective focusing on hydrogeologic concerns a key finding of this study is that nmr measurements provide insights into in situ hydrogeologic conditions that are difficult to achieve or interpret with other downhole and or core measurements in unfractured intervals of rock it is common for various forms of hydrogeophysical testing e g active line source active distributed temperature sensing high sensitivity flow meter testing straddle packer testing to indicate flow and or permeability where fractures are not observed this is particularly important in high porosity units such as those with vuggy carbonates nmr data has the potential to resolve these discrepancies by providing information about the broad scale matrix porosity the response does not resolve some discrete features fractures and thin beds that may significantly facilitate groundwater flow therefore nmr data is best interpreted in conjunction with other geophysical logs that provide indicators of lithology e g natural gamma density magnetic susceptibility fracturing e g atv and or otv caliper and fluid flow e g temperature fluid conductivity and flowmeter as is always the case having core calibration is also highly desirable matrix porosity and permeability are critically important factors in modeling contaminant diffusion and distribution and are required parameters in assessing the applicability and potential performance of remediation technologies the examples presented in this study show that nmr logs can improve groundwater resource characterization and contamination studies through the continuous downhole measurement of matrix porosity at submeter scales leading to better assessment of flow and chemical diffusion nmr is currently the only available technology to specifically measure water content and estimate its mobility in situ without using an active nuclear source nmr logs can help focus labour intensive core testing and complements core measurements by putting them into broader context clearly the technology and its application are complex and the details of the response dependent on the geologic hydrogeologic setting much more testing at other locations is warranted work continues to compare nmr data with other forms of core and downhole testing to improve understanding of the scaling issues identified in this study declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements any use of trade firm or product names are for descriptive purposes only and does not imply endorsement by natural resources canada or the university of guelph the authors gratefully acknowledge collaboration in the field with tim cartwright and matthew griffiths mount sopris instruments and dgi geosciences elliot grunewald formerly vista clara for field support and comments nmrsa for data collection data processing and comments contributions of laboratory core data from steven gaines dru heagle jonathan munn and carlos maldaner as well as support data collected by andre formenko and others at the morwick g360 institute are much appreciated alt instruments as a long term sponsor of dr pehme s research associated with dr parker s research program at the morwick g360 institute providing access and support with wellcad as well as a nmsra collaborator both of which are important tools in this research review of the text by stéphanie larmagnat gsc and refinements suggested by reviewer s at joh this article represents gsc contribution number 20210226 funding support for this study was provided by the geological survey of canada s groundwater geoscience program and the university consortium for field focused groundwater research through the morwick g360 institute for groundwater research 
3322,this study presents a spatially explicit sensitivity and uncertainty analysis approach to a gis based multi criteria groundwater potential zone model the study addressed a deficiency in the way groundwater potential mapping results are typically presented using discrete class outputs without assessment of their certainty with respect to variations in criteria weighting one of the main contributors to output uncertainty in gis based multi criteria decision analysis studies we argue moderating groundwater potential mapping results with localised uncertainty levels will help to refine and prioritise groundwater exploration efforts the approach also enables a better understanding of the underlying factors influencing uncertainty in model outputs which can help to inform the calibration of input parameters to improve model performance although the procedures presented in this study have been applied to other types of multi criteria evaluations its integration in gis based groundwater potential modelling has received little attention we provide a case study focused on a fractured rock environment surrounding the township of hawker in south australia where new groundwater resources are sought small incremental weight changes were applied one at a time and automated as a task in arcgis pro built using the arcpy python module that interacts with spatial tools allowing geographical analysis the approach is applicable to both continuous and discrete class based mapping outputs and enabled a deeper understanding of model output behaviour with respect to criteria weighting alternatives the case study findings demonstrate the potential value of the approach in mitigating uncertainty and improving confidence in locating sites with high groundwater potential abbreviations gpz groundwater potential zone gp groundwater potential sa sensitivity analysis ua uncertainty analysis oat one at a time ahp analytic hierarchy process twi topographic wetness index sd standard deviation rpc range of percent change ipc increment of percent change keywords geographical information system gis sensitivity analysis uncertainty analysis groundwater potential multi criteria decision analysis mcda analytic hierarchy process ahp 1 introduction groundwater potential zone gpz modelling assesses the possibility of groundwater occurrence in an area it has been recognised as a cost effective and efficient technique to underpin hydrogeological surveys in groundwater exploration efforts díaz alcaide and martínez santos 2019 most gpz models employ an expert knowledge driven approach where the quality of groundwater data is sparse or insufficient to employ data driven methods díaz alcaide and martínez santos 2019 thus most gpz models reflect a classic multi criteria decision analysis mcda problem eastman 1999 steele et al 2009 where geographical information system gis based methods are used to combine preferentially weighted criteria such as rainfall lithology landform lineaments soils land use slope flow accumulation etc as judged by experts to highlight areas more favourable for groundwater development while the mcda approach allows the best available evidence and proxies for missing data to be considered it is vulnerable to the behavioural biases affecting expert judgements in the decision making process ferretti and montibeller 2016 typically gis mcda involves defining a set of objectives and relevant criteria represented as spatial data layers standardising criteria values a method for specifying criteria preferences and an aggregation method that combines the preferential criteria to yield a final score the result of the procedure is a suitability or vulnerability map s showing the potential or vulnerability of a given location and is widely used in land use capability assessment site selection resource evaluation and land vulnerability assessment greene et al 2011 malczewski 2006 at the heart of mcda is the method used for preferential evaluation weighting of criteria widely used methods include the technique for order preference by similarity to ideal solution hwang and yoon 1981 the analytic network process saaty 1996 and the analytic hierarchy process ahp saaty 1977 where the latter has been employed by numerous authors to assess groundwater potential gp díaz alcaide and martínez santos 2019 the ahp technique for decision making was developed by saaty 1977 to minimise the challenges of ranking the relative importance of multiple criteria simultaneously pairwise comparisons by experts are used to rank the relative importance each criterion has on groundwater occurrence and presented as a matrix of comparisons final weights for each criterion are derived from the normalised values of the priority vector eigenvector determined from the row means of the normalised comparison matrix a consistency ratio measure is computed to show the overall consistency of pairwise judgments however while the ahp is an objective approach to mcda it does not account for the uncertainty and imprecision of the decision maker s perceptions conveyed into the final weight assignment chen et al 2013 which will propagate uncertainty in the mcda output among a range of input factors the assignment of criteria weights is considered the largest contributor to controversy and uncertainty in gis mcda outputs chen et al 2013 de brito et al 2019 feizizadeh and blaschke 2014 şalap ayça and jankowski 2016 notably any human judgment is to some degree imperfect boroushaki and malczewski 2008 sensitivity analysis sa and uncertainty analysis ua have been widely promoted in gis mcda to evaluate criteria contributions and uncertainty in model outputs under different weighting scenarios e g chen et al 2010 de brito et al 2019 dhami et al 2017 feizizadeh and blaschke 2014 xu and zhang 2013 and frameworks to do so proposed e g chen et al 2010 ligmann zielinska and jankowski 2008 2014 a well structured sa and ua are ideally integrated in one process where ua examines and quantifies the variability in model outputs as a result of the uncertainty in model inputs while sa examines how variability in the model outputs are attributed to uncertainty in the model inputs crosetto et al 2000 thus for gis mcda ua will help to quantify and moderate mapping results with localised uncertainty levels helping to refine and prioritise areas while sa will help to identify the most influential criteria those requiring further refinement and those that have little impact on results which in the interest of model simplification malczewski 2000 may be candidates for removal de brito et al 2019 notably as gis mcda model outputs are largely represented in the spatial domain spatially explicit sa and ua evaluations have been proposed where model output sensitivity to weighting alternatives is quantified and visualised geographically e g chen et al 2010 ferretti and montibeller 2016 malczewski 2011 several studies have integrated sa and ua of criteria weights in a spatially explicit context to detect localised variations of decision outcomes with a goal to better understand local parameter influences improve model performance and confidence in mapping results malczewski and rinner 2015 for gpz mapping identifying areas with highly favourable gp with low uncertainty or burdened by high uncertainty would not only refine the prioritisation of gpzs but would also enable an assessment of the aggregation of gp drivers criteria at specific locations that may contribute to uncertainty with respect to weighting alternatives both global sa and local sa have been employed in a spatially explicit context global sa may consider criteria weightings but also other input factors simultaneously providing a global representation of the full factors space pianosi et al 2016 global sa has been used to investigate model output sensitivity in land suitability mapping benke and pelizaro 2010 ligmann zielinska and jankowski 2014 landslide susceptibility mapping feizizadeh and blaschke 2014 ghorbanzadeh et al 2017 and in flood vulnerability mapping feizizadeh and kienberger 2017 tang et al 2018 in contrast local sa considers only one point of the factors space to estimate the local response of model outputs by varying the input factors one at a time oat it does so from a baseline or around a nominal point while holding all other factors constant mountford et al 2017 saltelli and annoni 2010 though typically adjusting them proportionately oat in a constrained summative model e g chen et al 2010 chen et al 2013 de brito et al 2019 thus the local sa oat method is best suited to single parameter evaluations such as changes in criteria weightings it has been used to assess the effect of criteria weight changes in land suitability mapping chen et al 2010 chen et al 2013 xu and zhang 2013 while dhami et al 2017 and more recently de brito et al 2019 used the oat method to investigate the influence criteria weights have on nature based tourism and flood vulnerability modelling despite these studies the incorporation of sa and ua in spatial mcda is not a common practice rather it is only rudimentarily applied or mostly absent de brito et al 2019 ferretti and montibeller 2016 in reviewing key challenges in multi criteria spatial decision support systems ferretti and montibeller 2016 suggest this is largely because of the technical complexities of implementation in the spatial domain relative to the well established tools for non spatial sa and ua and the lack of pre built sa and ua tools in existing gis software furthermore despite the significant advancements in both the theory and application of sa it is a relatively new area of research razavi et al 2021 in their recent multidisciplinary position paper on the current status of sa razavi et al 2021 review the key challenges for collective attention and engagement across all areas of science to help ensure the benefits of sa are fully realised this is particularly relevant to the geospatial sciences where the theory and application of sa and ua in spatial modelling remains underrepresented increased use of sa by spatial modellers and greater engagement in the broader science of sa is likely to have positive outcomes across many spatially related disciplines including hydrology as a result of the relatively small number of spatially explicit sa and ua studies there are few that demonstrate improved reliability over conventional mcda mapping this is also because of the difficulties in validating abstract conditions such as in land use capability land suitability and flood vulnerability assessment where spatially explicit sa and ua evaluations have been primarily implemented nevertheless its incorporation in areas such as landslide vulnerability assessment has been shown to improve predictability of mapping results e g feizizadeh and blaschke 2014 ghorbanzadeh et al 2017 for this current gpz mapping study the employment of a knowledge driven mcda method was motivated by the absence of good quality well data a barrier also for validating mapping results however the gpz model shares the same model structure criteria weighted linear aggregation and data format rasterised spatial data layers with those previously mentioned thus it is anticipated that incorporating a spatially explicit sa and ua will also improve the predictability of gp model outputs currently very few gpz mapping studies incorporate sa and most ignore ua only 3 of the 56 gp mapping studies recently reviewed by díaz alcaide and martínez santos 2019 incorporated some form of sa jahan et al 2018 oh et al 2011 patra et al 2018 along with more recent work by allafta et al 2020 these studies used map removal sa lodwick et al 1990 to assess the influence each criterion has on the output of the gpz model through iteratively excluding a single criterion while jahan et al 2018 also included a single parameter sa approach napolitano and fabbri 1996 to assess the influence of criteria weights on model output however to our knowledge there are no studies that integrate gis based gpz modelling with sa and ua in a combined spatially explicit context for evaluation thus the aim of this study is to better understand the effects of criteria weighting alternatives on the output of an ahp based gis mcda model of groundwater potential by conducting a spatially explicit sa and ua we demonstrate the approach using a gpz model initially developed by fildes et al 2020 for the areas surrounding the townships of quorn and hawker in the flinders ranges of south australia like most gpz modelling studies the mapping results of fildes et al 2020 reflected a conventional deterministic mcda output where gp classes were ranked from low to high potential without quantifying the uncertainties in the model output this study addressed this deficiency by moderating gp results with localised uncertainty levels to help refine and prioritise areas for groundwater exploration the goal is to provide critical information that will better inform the decision making process and improve model performance 2 methods 2 1 gis mcda groundwater potential zone modelling the spatially explicit sa and ua is demonstrated using data and criteria weights established from an integrated remote sensing and gis based study where ahp and the weighted linear combination were used to evaluate gp fildes et al 2020 the study was located in the semi arid and fractured rock region of the flinders ranges of south australia surrounding the townships of quorn and hawker water supply for these townships is currently under review by the south australian water corporation sa water as part of a groundwater security initiative for the region somaratne 2019 the area experiences hot dry summers cool to mild winters and a low annual average rainfall of approximately 300 mm bom 2020 the flinders ranges are a complex folded mountain range where groundwater exploration efforts are challenging the ridges are composed of resistant cambrian and neoproterozoic quartzites limestones and calcareous meta siltstones in the valleys these rocks are overlain by scree and alluvial deposits the ridges create groundwater divides and form the recharge zones for the more distal parts of the aquifer down dip in the basin fildes et al 2020 except for minor supplies in recent alluvial deposits the main groundwater supply for the townships is present in fractured neoproterozoic cambrian metasediments rock aquifers though little is known about the extent of groundwater resources to support future demands to demonstrate the effectiveness of the spatially explicit sa and ua a 15 km area around hawker was considered in this study fig 1 six key gp influencing factors criteria relevant to the local characteristics affecting groundwater accumulation were identified by hydrogeologists with experience and knowledge of the study area fildes et al 2020 and are shown in fig 2 a e they are 1 rainfall determines the amount of water available for groundwater recharge 2 aspect provides some control on the supply of rainfall 3 slope an indicator of runoff potential which provides some control on the opportunity for water to infiltrate 4 topographic wetness index twi a measure of the potential relative wetness and water accumulation within a catchment identifying areas with greater potential for water to infiltrate 5 lineament density identifies zones of faulting and fracturing which provide pathways for water infiltration and storage and 6 lithology areas with rock types that can affect water infiltration occurrence and distribution of groundwater fildes et al 2020 the chosen criteria were consistent with the main gp drivers present in almost all gis based gpz mapping studies reviewed by díaz alcaide and martínez santos 2019 and used as the primary input criteria for the sa and ua preferential evaluation of criteria was determined through expert elicitation facilitated by a participatory ahp mcda weighting approach by four experts with knowledge of the study area a pairwise comparison table was used to rank the relative importance each criterion has on groundwater occurrence from the most influential to the least influential on a scale of 1 9 where 1 indicates equality between factors and 9 indicates extreme importance of one factor over another sequential pairwise comparisons between factors resulted in a ratio of importance for each factor pair and were used to build a pairwise comparison matrix fildes et al 2020 four sets of alternative pairwise comparisons were developed to reflect the judgements of each participant from which a single and final consolidated set of normalised criteria weights was developed using a geometric mean aull hyde et al 2006 goepel 2013 table 1 the highest weight for each criterion indicates its highest possible influence the consolidated set of ahp derived weights was used as the primary base run or nominal point around which the full range of weighting alternatives and corresponding outputs was assessed by the combined spatially explicit sa and ua section 2 2 1 all criteria were spatially represented as raster datasets gridded to a 30 m spatial resolution and transformed to the same coordinate system each criterion grid cell was assigned a weight also developed using the ahp to reflect the relative importance of sub criterion classes e g low medium and high slope areas these class weights were rescaled between 0 and 1 to standardise their score range with other criteria malczewski 2000 gp was then derived by multiplying each cell value standardised weight by its corresponding criterion global weight before summing each raster layer together in a gis environment i e using the general form 1 gp j w j x ij where wj is the normalised ahp weight of the j th criterion and xi is the value function or standardised weight of the i th class of the j th criterion for each alternative grid cell location the weighted linear combination yielded a final standardised range of values between 0 and 1 representing the probability of gp per grid cell over the study area where 0 indicates no gp and 1 indicates the maximum gp this range was further classified into qualitative classes of very low to very high gpzs typical of many deterministic class based gis mcda mapping outputs fig 2f the gp map shown in fig 2f is also the base run output of the sa and ua process section 2 2 1 2 2 uncertainty in criteria weights for gpz modelling to investigate the effects of criteria weight changes on gp model outputs and their uncertainty a local sa oat method was used as the base function of the overall spatially explicit sa and ua the oat method is well suited to single parameter evaluations is methodologically simple computationally cheap and relatively easy to develop chen et al 2013 criterion weights used in traditional deterministic mcda models represent point estimates with varying precision with no indication of error or confidence benke and pelizaro 2010 in multi criteria evaluations of gp there may be different perceptions by experts and uncertainty on the influence each criterion has on surface water infiltration and groundwater occurrence these perceptions are routinely conveyed from the expert s opinion into the weight assignment feizizadeh et al 2014 in the study by fildes et al 2020 four participants ahp derived criteria weighting sets were used to model separate gp mapping results raster maps a standard deviation sd raster map was generated showing the degree of dispersion from the mean of all participants gp maps and was used as a measure of uncertainty for each raster grid cell over the geographical setting a low sd in a grid cell meant that participants gp values were more clustered around their mean indicating closer agreement and less uncertainty in results conversely a high sd meant greater variance between participant results indicating less agreement and greater uncertainty in results thus the sd map may be used to determine the uncertainty at any one location based on the degree of agreement between the individual participant gp mapping results derived using different criteria weightings e g benke and pelizaro 2010 de brito et al 2019 dhami et al 2017 ligmann zielinska and jankowski 2014 şalap ayça and jankowski 2016 this spatially explicit sa and ua study builds on this method to allow the criteria weights to vary over a much greater range to help understand and quantify the uncertainty in gp model outputs and sensitivity with respect to criteria weight changes 2 2 1 model process the study followed a similar oat method to that described by chen et al 2010 chen et al 2013 and more recently by de brito et al 2019 in this study the consolidated set of ahp derived weights table 1 was derived using the ahp microsoft excel template developed by goepel 2013 while the oat method was implemented as a task in arcgis pro built using the arcpy python module that interacts with spatial tools allowing geographical analysis the oat method consisted of a series of model runs where each criterion weight the main changing criterion was altered using a small increment of percent change ipc of 2 to capture the behaviour of gp output changes as the model runs progress to a specified range of percent change rpc e g 20 or 50 or 100 this is done while weights of the other criteria were adjusted proportionally to satisfy the summative constraint of the weighted linear aggregation method which requires all criteria weights to sum to 1 chen et al 2010 as described by chen et al 2010 when varying the weight of the main criterion c m under consideration its weight w c m p c at a certain percent change pc level can be calculated as 2 w c m p c w c m 0 w c m 0 p c 100 1 m n where w c m 0 is the weight of the main changing criterion c m at the base run and n is the total number of criteria to meet the summative constraint for all criteria per run the weights of the other criteria w c i p c are adjusted proportionally in accordance with w c m p c derived in equation 2 w c i p c 1 w c m p c w c i 0 1 w c m 0 3 i m 1 i n where w c i 0 is the weight of the i th criterion c i at the base run running the oat model simply requires the user to input the standardised criteria as raster data layers and then specify the ipc and rpc for the iterative model runs 2 2 2 model outputs following similar studies by chen et al 2010 mosadeghi et al 2015 and de brito et al 2019 we used a small ipc of 2 and a rpc of 100 thus the total number of model runs was 601 100 runs 6 criteria the main base weight run to produce an individual gp map for each run fig 3 shows the overall gis based gp model steps and the integrated spatially explicit sa and ua process notably the sa and ua conducted in this study is applicable to both continuous e g gp index values and discrete class e g very low gp to very high gp mapping outputs which satisfy specific mapping conventions and project objectives both common to many gp studies díaz alcaide and martínez santos 2019 specifically as core to the analysis the oat model a reads and adjusts the base weight for each main criterion sequentially within the aforementioned rpc and ipc using equations 2 and 3 repeatedly substituting these weights into equation 1 producing 100 gp maps for each criterion b reclassifies each map into 5 predefined fixed gp classes gpz map see table 2 c produces a map that counts and tracks the movement between gp classes on a cell by cell basis from to gp class switches between each model run where a greater number of class switches indicate a higher influence on model output with respect to weight changes d computes uncertainty maps based on the standard deviation sd of gp index values 0 1 calculated from the 100 gp model runs for each criterion e computes a total uncertainty map based on the sd of gp index values calculated from all 601 model runs f computes a final gpz uncertainty map combining the total uncertainty map with the base run gp map to geographically visualise the spatial distribution of gp classes and their uncertainty and finally g produces a comprehensive summary table that quantifies the changes in the gp map outputs for evaluation note class ranges shown in table 2 were developed based on preliminary gp mapping results by fildes et al 2020 where gp values 0 5 for quorn and hawker coincided with the higher yielding well areas between 6 and 10 l sec these areas were dominated by moderate to high permeability rock units moderated by higher lineament densities where groundwater resources are more likely gp values 0 5 largely coincided with higher elevation quartzite ridges with low lineament density where groundwater resources are less likely different geographical settings may result in different interpretations and class ranges though for this study gp values 0 5 medium high and very high gp classes delineate areas worthy of further investigation and are of key interest in the sa and ua upper and lower class ranges were determined subjectively using a histogram of the gp index min max range 0 10 0 90 furthermore a 3 class equal interval range was used to reclassify the total sd map total uncertainty map where sd values 66 6 of the total sd range were classified as having the highest uncertainty values between 33 3 and 66 6 classified as medium to low uncertainty and sd values 33 3 classified as areas with the lowest uncertainty 3 results using the oat method 601 gp index continuous and class based maps were generated from these both non spatial and spatial evaluations of gp output sensitivity to criteria weight changes are presented followed by a discussion of their implications for groundwater mapping to support exploration efforts 3 1 groundwater potential class based evaluation fig 4 shows the percentage of cells that remained in the same gp class between each model run per criterion these results can be used to evaluate the limits of acceptable variation in criteria weights for stable classification results de brito et al 2019 it is observed that the lineaments and lithology criteria had the largest influence on gp with respect to weight changes see table a 1 in the appendix for detailed results only 35 97 and 38 74 respectively of all cells remained in the same gp class when their weight was decreased by 100 compared with the base run and only 36 66 and 35 16 respectively remained in the same class when their weight was increased by 100 table a 1 the twi criterion had a moderate influence on gp results with approximately 74 of cells remaining in the same class when its weight was changed by 100 the slope and rainfall criteria had less influence with approximately 80 or more of cells remaining in the same class and the aspect criterion had the least influence with 90 of cells remaining in the same class when their weight was changed by 100 compared with the base run to evaluate those gp classes most vulnerable to criteria weight changes fig 5 shows the number of cells in each gp class between model runs with respect to criteria weight changes while most classes remained relatively stable considerable changes occurred for the medium high and very high gp classes classes 3 4 5 table 2 when increasing the weight for the lithology criterion and decreasing the weight for the lineaments criterion however it was gp classes low medium and high classes 2 3 4 that underwent more change when decreasing the weight for the lithology criterion and increasing the weight for the lineaments criterion this inverse relationship is common to the weighted linear aggregation method in gis outputs where higher importance given to one criterion trades off against others in a constrained model eastman 1999 all weights sum to 1 and its significance should not be lost in the weighting decision process the accumulative number of cells that changed from one gp class to another from to class switches with respect to criteria weight changes is shown in fig 6 for all model runs most changes occurred from gp classes 3 to 2 medium to low 24 34 3 to 4 medium to high 18 89 and 4 to 3 high to medium 16 09 and was largely associated with the lineaments and lithology criteria fig 6 also shows the overall extent to which each criterion influences gp results bar length and is consistent with the order of criteria influence presented in fig 4 to see where these gp class changes took place and analyse how similar the results are between model runs ten maps at increments of 20 weight change were generated for the most influential criterion lineaments fig 7 the spatial distribution of these gp class changes is controlled by the trade off between the main changing criterion weight lineaments and the relative weights of all other criteria and their local underlying class values these trade offs are most noticeable when a 100 weight change was applied to the lineaments criterion which removed its influence on gp altogether this promoted the relative importance of all other criteria and their underlying class values as observed gp increased from class 3 through to 5 medium through to very high in areas where highly influential lithology and twi classes dominate green blue areas while gp decreased from class 3 to 2 medium to low in areas where lineament density was high and where lithology and twi class values are less influential e g black squares conversely as the weight of the lineaments increased gp increased from class 3 through to 5 medium through to very high in areas of higher lineament density e g red squares while gp decreased from class 3 to 2 medium to low and 4 to 3 high to medium in areas of lower lineament density and where lithology and twi class values are highly influential orange and light green areas respectively thus the higher lithology and twi class values in these areas are reduced as they trade off with an increase in the lineament weighting which aggregate to an overall lowering of gp despite the increase in the global weight of the lineament criterion class 3 to 2 orange areas accounted for up to 27 33 of the study area see fig 7 table areas in white remained unchanged from their original class in the base run and thus they were insensitive to criteria weight changes for a complete evaluation of the spatial behaviour of gp class switches a full set of maps for each criterion at specified ipc would be required 3 2 groundwater potential index based evaluation the oat model generated a sd map calculated from the 100 gp model runs for each criterion fig 8 a f this enabled a more straightforward evaluation of localised criteria influence on gp model outputs accommodating index rather than class based mapping results e g benke and pelizaro 2010 de brito et al 2019 dhami et al 2017 the sd maps show that the lineaments and lithology criteria had the highest sd values while the aspect criterion had the lowest indicating their relative influence on gp outputs with respect to weight changes also observed is a good agreement between the spatial pattern of low to high sd values for the lineaments criterion fig 8d with areas of low to high range of class switches fig 7 with a goal to moderate gp mapping results with uncertainty levels the oat model also generated a sd map calculated from all 600 model runs total uncertainty map aggregating the influence of all criteria fig 8g results show a maximum sd of 0 079 or 7 9 and an average sd of 0 047 across the study area the total uncertainty map was numerically coded into 3 equal interval sd ranges to delineate areas with lower medium and higher uncertainty using value ranges of 33 3 33 3 66 6 and 66 6 respectively it was then summed together with the 5 class gp base run map combining both sets of information thus the final gpz uncertainty map of the hawker study area fig 8i shows the spatial distribution of very low to very high gpzs moderated by the three levels of uncertainty and can be compared with the original mapping by fildes et al 2020 shown in fig 2f 4 discussion the spatially explicit sa and ua enabled both discrete class and index based evaluations of model outputs from these the following summary can be derived regarding the reliability of the gp model with respect to criteria weight changes a for all 600 model runs gp class switches were relatively low with 81 76 of all cells remaining in the same gp class as they were in the base run 17 45 underwent a one class switch and only 0 79 underwent a two class switch b the lineaments and lithology criteria had the largest influence on class changes and gp output variation while the aspect criterion had the least influence c areas with gp index values 0 5 medium high and very high gp coinciding with lower model output variability medium to lower sd should be the focus of groundwater exploration efforts the overall relative stability in model outputs was also confirmed with a maximum sd of 0 079 7 9 over the study area fig 8g consistent with other similar gis mcda sa and ua studies de brito et al 2019 ligmann zielinska and jankowski 2014 şalap ayça and jankowski 2016 however local sensitivity to criteria weight changes were evident the spatial pattern of different uncertainty levels in the final gp mapping is largely the result of trade offs between criteria and their class values with respect to weight changes along with several other interrelated factors effecting model output behaviour an understanding of these factors will help to evaluate their local significance and focus efforts within the mcda process to minimise uncertainty and promote confidence in mapping results this cannot be achieved by considering only the overall measure of influence per criterion or class change 4 1 factors influencing model output behaviour the gp model employed a weighted linear combination method to aggregate criteria common to many gis based multi criteria analyses malczewski 2011 where the importance of one criterion trades off against others in a constrained model the behaviour of these trade offs is made clearer when evaluating the oat model outputs in a spatially explicit manner highlighting areas more vulnerable to weight changes fig 7 these trade offs are influenced by the starting weight value in the base run table 1 as observed in other studies e g de brito et al 2019 xu and zhang 2013 those criteria with higher weights tend to contribute more to output variation and uncertainty the same ipc applied to a higher starting weight will incur a greater progressive change and thus influence relative to criteria with smaller starting weights in the oat model this was observed for the lineaments lithology and twi criteria for this geographical setting thus an objective multi participant expert approach to weight development using tools such as the ahp is warranted to carefully assess the relative importance of each criterion particularly those considered to have greater importance as argued by de brito et al 2019 when a degree of consensus between multiple stakeholders with expertise are involved in the modelling process this tends to increase the reliability of results hence the sa and ua is better realised by helping to refine the calibration of input parameters using an iterative circular decision process fig 3 in this regard observed trade offs shown in fig 7 along with the small ipc 2 results in fig 4 and table a 1 can be used to evaluate the limits of acceptable variation in criteria weights for a desired stable classification of gpzs for example if a target of 80 of cells remaining unchanged is desired as the maximum acceptable uncertainty level in mapping results then participants judgements of criteria weightings for the lineaments and lithology criteria would need to be 20 in agreement fig 4 however this limit of weighting variation could be relaxed or require tightening depending on a whether more class switches occurred between a desired threshold of gp interest e g gp values cross between 0 5 or b where these class switches occurred e g for the lineaments criterion the majority of class switches occurred outside of the desired higher lineament density areas fig 7 in this regard the level of output uncertainty at any given location may be more or less significant the oat model produced a gp map for each ipc and for each main changing criterion allowing a full evaluation of the localised spatial behaviour of gp class switches notably it is not only the criteria weights but also the criteria class rankings that drive the trade offs between criteria in the aggregation process to test the influence of criteria class aggregation on model output the oat model was re run using the same original model parameters but using equal weights 0 1667 for each main criterion this in effect normalised the influence of the main criterion weight between each set of 100 runs and thus gp model results are largely driven by the spatial distribution of criteria class rankings and assigned class weight the results are presented in fig 9 and include the sd maps for each criterion observed is a reduction in the difference between each criterion s maximum sd relative to the differences in the original set of sd uncertainty maps in fig 8 along with a reduction in the maximum and average sd of the total sd uncertainty map fig 9g this comparison demonstrates a how applying different weights to criteria as opposed to equal weights increased the variability in model outputs and b given the similarities in the spatial pattern of gp mapping results between unequally and equally weighted criteria fig 8h i and fig 9h i respectively a focus on class weightings is as important as developing global criteria weights hence the lineaments lithology and twi criteria may warrant further careful criteria and class calibration as they have the highest influence on gp for this geographical setting in this regard the criteria weighting decision process should also extend to a critical review of the criteria class rankings and their weightings criteria calibration for continuous index based data such as lineament density slope twi and rainfall may comprise user defined linear or nonlinear class interval ranges or a value function e g linear sigmoidal j shape or user defined to represent zones of criteria behaviour on gp and for standardising disparate criteria measurements between 0 and 1 malczewski 2000 typically the value function and for this current study criteria class ranges were defined independently using expert judgement hence they are themselves subject to a degree of uncertainty not using a suitable value function or set of class ranges representative of a criterion s on ground spatial behaviour e g the influence of slope ranges on water runoff is likely to exacerbate errors in the model output irrespective of their assigned global weight while the relationship between real world phenomenon and their value function or class ranges as a spatial representation has been investigated by other authors eastman 1999 malczewski 2000 voogd 1982 it is not well justified within the gis based gp mapping literature other than a preference for the inclusion of specific criteria díaz alcaide and martínez santos 2019 this is a clear research gap another interrelated factor influencing gp output variability is the spatial resolution of input data de brito et al 2019 savage et al 2016 while all criterion maps were rasterised to a standard 30 m pixel resolution before aggregation the resolution of source data varied considerably and is largely related to the limited availability of spatial data at different capture scales when applying weight changes to criteria rasterised from broader scale generalised polygon datasets such as lithology classes or where higher resolution raster datasets such as slope or twi are reclassified into broader discrete class ranges areal units larger areas thus larger cell counts will be more vulnerable to class switches savage et al 2016 while this is more evident in class based model evaluations it is also inherent to index based outputs as well hence the capture scale of some criteria may require refining to ensure that the highest possible spatial variation in detail is captured to improve model results notably however even with a locally targeted mapping exercise the assumption of uniformity typically applies in spatial datasets such as lithological classes which do not take into account the often considerable variation within a unit hence the best way to take this into account is to undertake field observations and measurements to help site drill holes within the higher gp mapping zones 4 2 model limitations despite the oat model s efficiency and intuitive simplicity its limitations have been highlighted by several authors ligmann zielinska and jankowski 2014 saltelli et al 2019 saltelli and annoni 2010 firstly the oat moves one factor at a time e g criteria weights repeatedly from a baseline or nominal value which itself is an imprecise point estimate with no measure of confidence benke and pelizaro 2010 thus the full rpc from the base run may not reflect the true magnitude or influence the criterion has on output uncertainty ligmann zielinska and jankowski 2014 secondly the oat model while adjusting proportionally all other criterion weights as the main criterion weight is applied assumes the criteria are independent of one another and does not consider the fullness of criteria interactions on model output variation and uncertainty this is particularly problematic in spatially heterogeneous problems where model inputs can be spatially autocorrelated or can locally co vary ligmann zielinska and jankowski 2014 alternatively global sa often employ variance based methods that allow evaluation of independent criterion contributions to output uncertainty as well as total effect interactions between criteria saltelli and annoni 2010 however global sa also has its own shortcomings including its high computational cost ligmann zielinska and jankowski 2014 often requiring a much larger number of iterations compared with a oat model moreover the uncertainty in the input parameters is typically sampled with some probability density function the parameters of which are assumed known a priori crosetto et al 2000 potentially introducing model bias which may affect the true influence input parameters and their interaction have on output uncertainty this is also true for the oat method where the criteria weight is treated as a uniform random variable between a min max range and sampled using 2 increments however trade offs between computational resources and accuracy requirements necessary to meet the evaluation objectives should be considered when selecting which sa and ua method to use de brito et al 2019 notably the authors chose the oat method using the framework described by chen et al 2010 due to its practical simplicity and ease of integration with arcgis pro using arcpy based tasks allowing spatially explicit outputs and evaluations however other computationally efficient oat methods are possible such as the morris method morris 1991 which does not perturb factors from a single baseline but from a number of different starting points the morris method is a repeating randomised oat method and considered a global sa where factor interactions may be seen which cannot be achieved by varying factor values from a single baseline it is considered a reliable oat method for screening factors that have little influence on model outputs before more computationally expensive and robust variance based global sa methods are applied to a smaller set of influential factors crosetto and tarantola 2001 one of the key challenges of spatially explicit sa is the lack of methods inherently equipped to work in the spatial domain and or with common gis software programs an increasing range of sa methods are becoming more openly available built using different programming languages for example the salib open source python library herman and usher 2017 exposes modellers and researchers to a number of sa techniques including the morris method which could be developed and integrated into spatial modelling workflows as argued by ligmann zielinska and jankowski 2014 and de brito et al 2019 irrespective of the specific method used an essential requirement of a comprehensive sa and ua of a gis based mcda should be conducted in a spatially explicit manner given that gpz modelling results are generated from the aggregation of spatial datasets and presented as a map showing the spatial distribution of feasible alternatives in gp ua and sa should also be represented in a spatial format 4 3 groundwater potential for the hawker region for the hawker region areas with gp values 0 5 medium high and very high gp coinciding with lower model output uncertainty medium to lower sd should be the focus of groundwater exploration efforts and are shown in areas coloured green blue in fig 8i indeed this has reduced the search area from approximately 53 395 km2 when considering areas with gp value 0 5 only i e conventional mapping shown in fig 2f to approximately 23 173 km2 when excluding higher uncertainty areas from these results those most favourable areas with very high gp and lower uncertainty are circled in red in fig 8i and account for only 0 06 0 45 km2 of the study area given their closer proximity to the hawker township the two most easterly circled areas which were not immediately apparent in the original mapping have been noted for further on ground investigation they consist of highly favourable criteria gp drivers each aggregating to a gp value 0 85 the analysis has also helped refine several areas from a broader range of feasible alternatives throughout the long east west wonaka creek lineament zone and the v shaped lineament zone in the south east these new priority areas consist of highly favourable lineament densities lithology units lower slopes and twi classes conducive to groundwater occurrence and where mapping results are less susceptible to criteria weight changes notably areas of higher gp with higher uncertainty yellow red and pink areas fig 8i should not necessarily be excluded from consideration though more caution should be applied for example higher yielding wells are located between the two forementioned lineament zones which have been mapped as medium to high gp but with higher uncertainty the higher uncertainty was generated from trade offs shown in the oat outputs between lower lineament class values i e lower lineament density and more highly influential lithology highly porous limestone overlain by fluvial sediments twi and slope classes however the area is thought to have good groundwater prospects as evidenced by the higher yielding wells because it is bound by two adjacent pervasive lineament fault zones where fracturing is likely providing extra pathways for groundwater movement into this area despite this gp is not well represented here in the mapping results due to the coarse resolution and highly generalised lineaments and lithology source data future on ground investigations of local variations in lithology and the presence and nature of fracture patterns will confirm whether the influence from these fault zones extend beyond the current distances used in the modelling if so then a review of the lineament density extent or the introduction of a new distance from lineaments criterion may improve gp model output performance in this regard a review of the ahp criteria and class weightings would also be necessary to better represent the potential relative influence and interrelated behaviour of criteria the aim would be to ensure a degree of consensus between experts is reached on these new weightings to provide more confidence in mapping results the uncertainty mapping has prompted this review which was not apparent in the original gp mapping results shown in fig 2f and as presented in fildes et al 2020 5 conclusions the spatially explicit sa and ua enabled an important refinement of the traditional discrete gp class mapping approach by moderating the spatial distribution of mapping results with uncertainty levels thus improving the reliability of gp output alternatives the demonstrated approach is best suited in assisting gp exploration over large and hydrogeologically complex areas where the choice between feasible alternative locations is potentially much greater in this regard the incorporation of spatially explicit sa and ua in gp mapping helps to alleviate project constraints such as time cost and risk by refining the search area to better focus on groundwater exploration efforts leading to drilling the analysis enabled a more transparent understanding of the localised influence of criteria aggregations which vary over space this is especially important when choosing between locations with similar favourable gp and uncertainty levels aggregated from a different set of criteria and class weighting combinations thus identifying more favourable criteria combinations from a range of feasible alternatives helps to further prioritise gp areas the spatially explicit sa and ua will also help focus efforts on minimising uncertainty in gp mapping outputs by way of an investigative model development process fig 3 this can be achieved by a ensuring a degree of consensus among experts is reached on the relative importance of criteria weightings using an objective mcda approach such as the ahp to maintain a defined threshold of acceptable level of output uncertainty with a particular focus on those criteria assigned the highest weights note lineaments lithology and twi had the highest influence on output variability for this geographical setting b ensuring equal importance is given to developing suitable value functions for standardising criteria measures as well as class range intervals and their weighting with an emphasis on the most influential criteria c ensuring the highest possible quality of each criterion s spatial representation and its resolution either locally or more broadly across the study area and d evaluating the behaviour of criteria aggregation over all model runs at specific locations of interest in doing so a decision to review but not limited to any of the forementioned objectives may be implemented with a goal to improve certainty in mapping results weight development is one of the most important steps in mcda as it is arguably the most influential on model results if the results are to be used in policy and decision making then it is critical that some form of sa and ua is performed to evaluate the effect criteria weights have on model outputs while the spatially explicit sa and ua presented in this study can be applied to a range of multi criteria evaluations its application in gis based gpz modelling is underrepresented while acknowledging its limitations the oat method is cost effective transparent and allows decision makers to visualise geographically the effect criteria weight changes have on model output and to explore the underlying factors and gp drivers influencing uncertainty at specific locations before making final decisions on prioritising areas for groundwater exploration consequently in future gpz studies expert evaluation of an integrated spatially explicit sa and ua would be encouraged as part of a broader participatory mcda approach by doing so the analysis acts as an exploratory process by which decision makers attain a deeper understanding of the structure of the problem with a goal to improve gp mapping results more broadly across a specific geographical setting credit authorship contribution statement stephen geoffrey fildes conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization david bruce conceptualization writing review editing supervision ian francis clark conceptualization writing review editing supervision tom raimondo conceptualization supervision robert keane methodology software validation okke batelaan conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors are grateful to dr mariana madruga de brito helmholtz centre for environmental research ufz germany and to dr yun chen csiro australia for providing their oat model codes and ahp sa software tool respectively these provided initial guidance in developing the arcgis pro arcpy based tasks used in this research written by mr robert keane flinders university australia we also thank the reviewers for their valuable comments funding this research was supported by an australian government research training program scholarship and a commonwealth scientific and industrial research organisation csiro top up scholarship these funding sources were not involved in the study in any way source code and data the python scripts and data used in this work are available upon request appendix 
3322,this study presents a spatially explicit sensitivity and uncertainty analysis approach to a gis based multi criteria groundwater potential zone model the study addressed a deficiency in the way groundwater potential mapping results are typically presented using discrete class outputs without assessment of their certainty with respect to variations in criteria weighting one of the main contributors to output uncertainty in gis based multi criteria decision analysis studies we argue moderating groundwater potential mapping results with localised uncertainty levels will help to refine and prioritise groundwater exploration efforts the approach also enables a better understanding of the underlying factors influencing uncertainty in model outputs which can help to inform the calibration of input parameters to improve model performance although the procedures presented in this study have been applied to other types of multi criteria evaluations its integration in gis based groundwater potential modelling has received little attention we provide a case study focused on a fractured rock environment surrounding the township of hawker in south australia where new groundwater resources are sought small incremental weight changes were applied one at a time and automated as a task in arcgis pro built using the arcpy python module that interacts with spatial tools allowing geographical analysis the approach is applicable to both continuous and discrete class based mapping outputs and enabled a deeper understanding of model output behaviour with respect to criteria weighting alternatives the case study findings demonstrate the potential value of the approach in mitigating uncertainty and improving confidence in locating sites with high groundwater potential abbreviations gpz groundwater potential zone gp groundwater potential sa sensitivity analysis ua uncertainty analysis oat one at a time ahp analytic hierarchy process twi topographic wetness index sd standard deviation rpc range of percent change ipc increment of percent change keywords geographical information system gis sensitivity analysis uncertainty analysis groundwater potential multi criteria decision analysis mcda analytic hierarchy process ahp 1 introduction groundwater potential zone gpz modelling assesses the possibility of groundwater occurrence in an area it has been recognised as a cost effective and efficient technique to underpin hydrogeological surveys in groundwater exploration efforts díaz alcaide and martínez santos 2019 most gpz models employ an expert knowledge driven approach where the quality of groundwater data is sparse or insufficient to employ data driven methods díaz alcaide and martínez santos 2019 thus most gpz models reflect a classic multi criteria decision analysis mcda problem eastman 1999 steele et al 2009 where geographical information system gis based methods are used to combine preferentially weighted criteria such as rainfall lithology landform lineaments soils land use slope flow accumulation etc as judged by experts to highlight areas more favourable for groundwater development while the mcda approach allows the best available evidence and proxies for missing data to be considered it is vulnerable to the behavioural biases affecting expert judgements in the decision making process ferretti and montibeller 2016 typically gis mcda involves defining a set of objectives and relevant criteria represented as spatial data layers standardising criteria values a method for specifying criteria preferences and an aggregation method that combines the preferential criteria to yield a final score the result of the procedure is a suitability or vulnerability map s showing the potential or vulnerability of a given location and is widely used in land use capability assessment site selection resource evaluation and land vulnerability assessment greene et al 2011 malczewski 2006 at the heart of mcda is the method used for preferential evaluation weighting of criteria widely used methods include the technique for order preference by similarity to ideal solution hwang and yoon 1981 the analytic network process saaty 1996 and the analytic hierarchy process ahp saaty 1977 where the latter has been employed by numerous authors to assess groundwater potential gp díaz alcaide and martínez santos 2019 the ahp technique for decision making was developed by saaty 1977 to minimise the challenges of ranking the relative importance of multiple criteria simultaneously pairwise comparisons by experts are used to rank the relative importance each criterion has on groundwater occurrence and presented as a matrix of comparisons final weights for each criterion are derived from the normalised values of the priority vector eigenvector determined from the row means of the normalised comparison matrix a consistency ratio measure is computed to show the overall consistency of pairwise judgments however while the ahp is an objective approach to mcda it does not account for the uncertainty and imprecision of the decision maker s perceptions conveyed into the final weight assignment chen et al 2013 which will propagate uncertainty in the mcda output among a range of input factors the assignment of criteria weights is considered the largest contributor to controversy and uncertainty in gis mcda outputs chen et al 2013 de brito et al 2019 feizizadeh and blaschke 2014 şalap ayça and jankowski 2016 notably any human judgment is to some degree imperfect boroushaki and malczewski 2008 sensitivity analysis sa and uncertainty analysis ua have been widely promoted in gis mcda to evaluate criteria contributions and uncertainty in model outputs under different weighting scenarios e g chen et al 2010 de brito et al 2019 dhami et al 2017 feizizadeh and blaschke 2014 xu and zhang 2013 and frameworks to do so proposed e g chen et al 2010 ligmann zielinska and jankowski 2008 2014 a well structured sa and ua are ideally integrated in one process where ua examines and quantifies the variability in model outputs as a result of the uncertainty in model inputs while sa examines how variability in the model outputs are attributed to uncertainty in the model inputs crosetto et al 2000 thus for gis mcda ua will help to quantify and moderate mapping results with localised uncertainty levels helping to refine and prioritise areas while sa will help to identify the most influential criteria those requiring further refinement and those that have little impact on results which in the interest of model simplification malczewski 2000 may be candidates for removal de brito et al 2019 notably as gis mcda model outputs are largely represented in the spatial domain spatially explicit sa and ua evaluations have been proposed where model output sensitivity to weighting alternatives is quantified and visualised geographically e g chen et al 2010 ferretti and montibeller 2016 malczewski 2011 several studies have integrated sa and ua of criteria weights in a spatially explicit context to detect localised variations of decision outcomes with a goal to better understand local parameter influences improve model performance and confidence in mapping results malczewski and rinner 2015 for gpz mapping identifying areas with highly favourable gp with low uncertainty or burdened by high uncertainty would not only refine the prioritisation of gpzs but would also enable an assessment of the aggregation of gp drivers criteria at specific locations that may contribute to uncertainty with respect to weighting alternatives both global sa and local sa have been employed in a spatially explicit context global sa may consider criteria weightings but also other input factors simultaneously providing a global representation of the full factors space pianosi et al 2016 global sa has been used to investigate model output sensitivity in land suitability mapping benke and pelizaro 2010 ligmann zielinska and jankowski 2014 landslide susceptibility mapping feizizadeh and blaschke 2014 ghorbanzadeh et al 2017 and in flood vulnerability mapping feizizadeh and kienberger 2017 tang et al 2018 in contrast local sa considers only one point of the factors space to estimate the local response of model outputs by varying the input factors one at a time oat it does so from a baseline or around a nominal point while holding all other factors constant mountford et al 2017 saltelli and annoni 2010 though typically adjusting them proportionately oat in a constrained summative model e g chen et al 2010 chen et al 2013 de brito et al 2019 thus the local sa oat method is best suited to single parameter evaluations such as changes in criteria weightings it has been used to assess the effect of criteria weight changes in land suitability mapping chen et al 2010 chen et al 2013 xu and zhang 2013 while dhami et al 2017 and more recently de brito et al 2019 used the oat method to investigate the influence criteria weights have on nature based tourism and flood vulnerability modelling despite these studies the incorporation of sa and ua in spatial mcda is not a common practice rather it is only rudimentarily applied or mostly absent de brito et al 2019 ferretti and montibeller 2016 in reviewing key challenges in multi criteria spatial decision support systems ferretti and montibeller 2016 suggest this is largely because of the technical complexities of implementation in the spatial domain relative to the well established tools for non spatial sa and ua and the lack of pre built sa and ua tools in existing gis software furthermore despite the significant advancements in both the theory and application of sa it is a relatively new area of research razavi et al 2021 in their recent multidisciplinary position paper on the current status of sa razavi et al 2021 review the key challenges for collective attention and engagement across all areas of science to help ensure the benefits of sa are fully realised this is particularly relevant to the geospatial sciences where the theory and application of sa and ua in spatial modelling remains underrepresented increased use of sa by spatial modellers and greater engagement in the broader science of sa is likely to have positive outcomes across many spatially related disciplines including hydrology as a result of the relatively small number of spatially explicit sa and ua studies there are few that demonstrate improved reliability over conventional mcda mapping this is also because of the difficulties in validating abstract conditions such as in land use capability land suitability and flood vulnerability assessment where spatially explicit sa and ua evaluations have been primarily implemented nevertheless its incorporation in areas such as landslide vulnerability assessment has been shown to improve predictability of mapping results e g feizizadeh and blaschke 2014 ghorbanzadeh et al 2017 for this current gpz mapping study the employment of a knowledge driven mcda method was motivated by the absence of good quality well data a barrier also for validating mapping results however the gpz model shares the same model structure criteria weighted linear aggregation and data format rasterised spatial data layers with those previously mentioned thus it is anticipated that incorporating a spatially explicit sa and ua will also improve the predictability of gp model outputs currently very few gpz mapping studies incorporate sa and most ignore ua only 3 of the 56 gp mapping studies recently reviewed by díaz alcaide and martínez santos 2019 incorporated some form of sa jahan et al 2018 oh et al 2011 patra et al 2018 along with more recent work by allafta et al 2020 these studies used map removal sa lodwick et al 1990 to assess the influence each criterion has on the output of the gpz model through iteratively excluding a single criterion while jahan et al 2018 also included a single parameter sa approach napolitano and fabbri 1996 to assess the influence of criteria weights on model output however to our knowledge there are no studies that integrate gis based gpz modelling with sa and ua in a combined spatially explicit context for evaluation thus the aim of this study is to better understand the effects of criteria weighting alternatives on the output of an ahp based gis mcda model of groundwater potential by conducting a spatially explicit sa and ua we demonstrate the approach using a gpz model initially developed by fildes et al 2020 for the areas surrounding the townships of quorn and hawker in the flinders ranges of south australia like most gpz modelling studies the mapping results of fildes et al 2020 reflected a conventional deterministic mcda output where gp classes were ranked from low to high potential without quantifying the uncertainties in the model output this study addressed this deficiency by moderating gp results with localised uncertainty levels to help refine and prioritise areas for groundwater exploration the goal is to provide critical information that will better inform the decision making process and improve model performance 2 methods 2 1 gis mcda groundwater potential zone modelling the spatially explicit sa and ua is demonstrated using data and criteria weights established from an integrated remote sensing and gis based study where ahp and the weighted linear combination were used to evaluate gp fildes et al 2020 the study was located in the semi arid and fractured rock region of the flinders ranges of south australia surrounding the townships of quorn and hawker water supply for these townships is currently under review by the south australian water corporation sa water as part of a groundwater security initiative for the region somaratne 2019 the area experiences hot dry summers cool to mild winters and a low annual average rainfall of approximately 300 mm bom 2020 the flinders ranges are a complex folded mountain range where groundwater exploration efforts are challenging the ridges are composed of resistant cambrian and neoproterozoic quartzites limestones and calcareous meta siltstones in the valleys these rocks are overlain by scree and alluvial deposits the ridges create groundwater divides and form the recharge zones for the more distal parts of the aquifer down dip in the basin fildes et al 2020 except for minor supplies in recent alluvial deposits the main groundwater supply for the townships is present in fractured neoproterozoic cambrian metasediments rock aquifers though little is known about the extent of groundwater resources to support future demands to demonstrate the effectiveness of the spatially explicit sa and ua a 15 km area around hawker was considered in this study fig 1 six key gp influencing factors criteria relevant to the local characteristics affecting groundwater accumulation were identified by hydrogeologists with experience and knowledge of the study area fildes et al 2020 and are shown in fig 2 a e they are 1 rainfall determines the amount of water available for groundwater recharge 2 aspect provides some control on the supply of rainfall 3 slope an indicator of runoff potential which provides some control on the opportunity for water to infiltrate 4 topographic wetness index twi a measure of the potential relative wetness and water accumulation within a catchment identifying areas with greater potential for water to infiltrate 5 lineament density identifies zones of faulting and fracturing which provide pathways for water infiltration and storage and 6 lithology areas with rock types that can affect water infiltration occurrence and distribution of groundwater fildes et al 2020 the chosen criteria were consistent with the main gp drivers present in almost all gis based gpz mapping studies reviewed by díaz alcaide and martínez santos 2019 and used as the primary input criteria for the sa and ua preferential evaluation of criteria was determined through expert elicitation facilitated by a participatory ahp mcda weighting approach by four experts with knowledge of the study area a pairwise comparison table was used to rank the relative importance each criterion has on groundwater occurrence from the most influential to the least influential on a scale of 1 9 where 1 indicates equality between factors and 9 indicates extreme importance of one factor over another sequential pairwise comparisons between factors resulted in a ratio of importance for each factor pair and were used to build a pairwise comparison matrix fildes et al 2020 four sets of alternative pairwise comparisons were developed to reflect the judgements of each participant from which a single and final consolidated set of normalised criteria weights was developed using a geometric mean aull hyde et al 2006 goepel 2013 table 1 the highest weight for each criterion indicates its highest possible influence the consolidated set of ahp derived weights was used as the primary base run or nominal point around which the full range of weighting alternatives and corresponding outputs was assessed by the combined spatially explicit sa and ua section 2 2 1 all criteria were spatially represented as raster datasets gridded to a 30 m spatial resolution and transformed to the same coordinate system each criterion grid cell was assigned a weight also developed using the ahp to reflect the relative importance of sub criterion classes e g low medium and high slope areas these class weights were rescaled between 0 and 1 to standardise their score range with other criteria malczewski 2000 gp was then derived by multiplying each cell value standardised weight by its corresponding criterion global weight before summing each raster layer together in a gis environment i e using the general form 1 gp j w j x ij where wj is the normalised ahp weight of the j th criterion and xi is the value function or standardised weight of the i th class of the j th criterion for each alternative grid cell location the weighted linear combination yielded a final standardised range of values between 0 and 1 representing the probability of gp per grid cell over the study area where 0 indicates no gp and 1 indicates the maximum gp this range was further classified into qualitative classes of very low to very high gpzs typical of many deterministic class based gis mcda mapping outputs fig 2f the gp map shown in fig 2f is also the base run output of the sa and ua process section 2 2 1 2 2 uncertainty in criteria weights for gpz modelling to investigate the effects of criteria weight changes on gp model outputs and their uncertainty a local sa oat method was used as the base function of the overall spatially explicit sa and ua the oat method is well suited to single parameter evaluations is methodologically simple computationally cheap and relatively easy to develop chen et al 2013 criterion weights used in traditional deterministic mcda models represent point estimates with varying precision with no indication of error or confidence benke and pelizaro 2010 in multi criteria evaluations of gp there may be different perceptions by experts and uncertainty on the influence each criterion has on surface water infiltration and groundwater occurrence these perceptions are routinely conveyed from the expert s opinion into the weight assignment feizizadeh et al 2014 in the study by fildes et al 2020 four participants ahp derived criteria weighting sets were used to model separate gp mapping results raster maps a standard deviation sd raster map was generated showing the degree of dispersion from the mean of all participants gp maps and was used as a measure of uncertainty for each raster grid cell over the geographical setting a low sd in a grid cell meant that participants gp values were more clustered around their mean indicating closer agreement and less uncertainty in results conversely a high sd meant greater variance between participant results indicating less agreement and greater uncertainty in results thus the sd map may be used to determine the uncertainty at any one location based on the degree of agreement between the individual participant gp mapping results derived using different criteria weightings e g benke and pelizaro 2010 de brito et al 2019 dhami et al 2017 ligmann zielinska and jankowski 2014 şalap ayça and jankowski 2016 this spatially explicit sa and ua study builds on this method to allow the criteria weights to vary over a much greater range to help understand and quantify the uncertainty in gp model outputs and sensitivity with respect to criteria weight changes 2 2 1 model process the study followed a similar oat method to that described by chen et al 2010 chen et al 2013 and more recently by de brito et al 2019 in this study the consolidated set of ahp derived weights table 1 was derived using the ahp microsoft excel template developed by goepel 2013 while the oat method was implemented as a task in arcgis pro built using the arcpy python module that interacts with spatial tools allowing geographical analysis the oat method consisted of a series of model runs where each criterion weight the main changing criterion was altered using a small increment of percent change ipc of 2 to capture the behaviour of gp output changes as the model runs progress to a specified range of percent change rpc e g 20 or 50 or 100 this is done while weights of the other criteria were adjusted proportionally to satisfy the summative constraint of the weighted linear aggregation method which requires all criteria weights to sum to 1 chen et al 2010 as described by chen et al 2010 when varying the weight of the main criterion c m under consideration its weight w c m p c at a certain percent change pc level can be calculated as 2 w c m p c w c m 0 w c m 0 p c 100 1 m n where w c m 0 is the weight of the main changing criterion c m at the base run and n is the total number of criteria to meet the summative constraint for all criteria per run the weights of the other criteria w c i p c are adjusted proportionally in accordance with w c m p c derived in equation 2 w c i p c 1 w c m p c w c i 0 1 w c m 0 3 i m 1 i n where w c i 0 is the weight of the i th criterion c i at the base run running the oat model simply requires the user to input the standardised criteria as raster data layers and then specify the ipc and rpc for the iterative model runs 2 2 2 model outputs following similar studies by chen et al 2010 mosadeghi et al 2015 and de brito et al 2019 we used a small ipc of 2 and a rpc of 100 thus the total number of model runs was 601 100 runs 6 criteria the main base weight run to produce an individual gp map for each run fig 3 shows the overall gis based gp model steps and the integrated spatially explicit sa and ua process notably the sa and ua conducted in this study is applicable to both continuous e g gp index values and discrete class e g very low gp to very high gp mapping outputs which satisfy specific mapping conventions and project objectives both common to many gp studies díaz alcaide and martínez santos 2019 specifically as core to the analysis the oat model a reads and adjusts the base weight for each main criterion sequentially within the aforementioned rpc and ipc using equations 2 and 3 repeatedly substituting these weights into equation 1 producing 100 gp maps for each criterion b reclassifies each map into 5 predefined fixed gp classes gpz map see table 2 c produces a map that counts and tracks the movement between gp classes on a cell by cell basis from to gp class switches between each model run where a greater number of class switches indicate a higher influence on model output with respect to weight changes d computes uncertainty maps based on the standard deviation sd of gp index values 0 1 calculated from the 100 gp model runs for each criterion e computes a total uncertainty map based on the sd of gp index values calculated from all 601 model runs f computes a final gpz uncertainty map combining the total uncertainty map with the base run gp map to geographically visualise the spatial distribution of gp classes and their uncertainty and finally g produces a comprehensive summary table that quantifies the changes in the gp map outputs for evaluation note class ranges shown in table 2 were developed based on preliminary gp mapping results by fildes et al 2020 where gp values 0 5 for quorn and hawker coincided with the higher yielding well areas between 6 and 10 l sec these areas were dominated by moderate to high permeability rock units moderated by higher lineament densities where groundwater resources are more likely gp values 0 5 largely coincided with higher elevation quartzite ridges with low lineament density where groundwater resources are less likely different geographical settings may result in different interpretations and class ranges though for this study gp values 0 5 medium high and very high gp classes delineate areas worthy of further investigation and are of key interest in the sa and ua upper and lower class ranges were determined subjectively using a histogram of the gp index min max range 0 10 0 90 furthermore a 3 class equal interval range was used to reclassify the total sd map total uncertainty map where sd values 66 6 of the total sd range were classified as having the highest uncertainty values between 33 3 and 66 6 classified as medium to low uncertainty and sd values 33 3 classified as areas with the lowest uncertainty 3 results using the oat method 601 gp index continuous and class based maps were generated from these both non spatial and spatial evaluations of gp output sensitivity to criteria weight changes are presented followed by a discussion of their implications for groundwater mapping to support exploration efforts 3 1 groundwater potential class based evaluation fig 4 shows the percentage of cells that remained in the same gp class between each model run per criterion these results can be used to evaluate the limits of acceptable variation in criteria weights for stable classification results de brito et al 2019 it is observed that the lineaments and lithology criteria had the largest influence on gp with respect to weight changes see table a 1 in the appendix for detailed results only 35 97 and 38 74 respectively of all cells remained in the same gp class when their weight was decreased by 100 compared with the base run and only 36 66 and 35 16 respectively remained in the same class when their weight was increased by 100 table a 1 the twi criterion had a moderate influence on gp results with approximately 74 of cells remaining in the same class when its weight was changed by 100 the slope and rainfall criteria had less influence with approximately 80 or more of cells remaining in the same class and the aspect criterion had the least influence with 90 of cells remaining in the same class when their weight was changed by 100 compared with the base run to evaluate those gp classes most vulnerable to criteria weight changes fig 5 shows the number of cells in each gp class between model runs with respect to criteria weight changes while most classes remained relatively stable considerable changes occurred for the medium high and very high gp classes classes 3 4 5 table 2 when increasing the weight for the lithology criterion and decreasing the weight for the lineaments criterion however it was gp classes low medium and high classes 2 3 4 that underwent more change when decreasing the weight for the lithology criterion and increasing the weight for the lineaments criterion this inverse relationship is common to the weighted linear aggregation method in gis outputs where higher importance given to one criterion trades off against others in a constrained model eastman 1999 all weights sum to 1 and its significance should not be lost in the weighting decision process the accumulative number of cells that changed from one gp class to another from to class switches with respect to criteria weight changes is shown in fig 6 for all model runs most changes occurred from gp classes 3 to 2 medium to low 24 34 3 to 4 medium to high 18 89 and 4 to 3 high to medium 16 09 and was largely associated with the lineaments and lithology criteria fig 6 also shows the overall extent to which each criterion influences gp results bar length and is consistent with the order of criteria influence presented in fig 4 to see where these gp class changes took place and analyse how similar the results are between model runs ten maps at increments of 20 weight change were generated for the most influential criterion lineaments fig 7 the spatial distribution of these gp class changes is controlled by the trade off between the main changing criterion weight lineaments and the relative weights of all other criteria and their local underlying class values these trade offs are most noticeable when a 100 weight change was applied to the lineaments criterion which removed its influence on gp altogether this promoted the relative importance of all other criteria and their underlying class values as observed gp increased from class 3 through to 5 medium through to very high in areas where highly influential lithology and twi classes dominate green blue areas while gp decreased from class 3 to 2 medium to low in areas where lineament density was high and where lithology and twi class values are less influential e g black squares conversely as the weight of the lineaments increased gp increased from class 3 through to 5 medium through to very high in areas of higher lineament density e g red squares while gp decreased from class 3 to 2 medium to low and 4 to 3 high to medium in areas of lower lineament density and where lithology and twi class values are highly influential orange and light green areas respectively thus the higher lithology and twi class values in these areas are reduced as they trade off with an increase in the lineament weighting which aggregate to an overall lowering of gp despite the increase in the global weight of the lineament criterion class 3 to 2 orange areas accounted for up to 27 33 of the study area see fig 7 table areas in white remained unchanged from their original class in the base run and thus they were insensitive to criteria weight changes for a complete evaluation of the spatial behaviour of gp class switches a full set of maps for each criterion at specified ipc would be required 3 2 groundwater potential index based evaluation the oat model generated a sd map calculated from the 100 gp model runs for each criterion fig 8 a f this enabled a more straightforward evaluation of localised criteria influence on gp model outputs accommodating index rather than class based mapping results e g benke and pelizaro 2010 de brito et al 2019 dhami et al 2017 the sd maps show that the lineaments and lithology criteria had the highest sd values while the aspect criterion had the lowest indicating their relative influence on gp outputs with respect to weight changes also observed is a good agreement between the spatial pattern of low to high sd values for the lineaments criterion fig 8d with areas of low to high range of class switches fig 7 with a goal to moderate gp mapping results with uncertainty levels the oat model also generated a sd map calculated from all 600 model runs total uncertainty map aggregating the influence of all criteria fig 8g results show a maximum sd of 0 079 or 7 9 and an average sd of 0 047 across the study area the total uncertainty map was numerically coded into 3 equal interval sd ranges to delineate areas with lower medium and higher uncertainty using value ranges of 33 3 33 3 66 6 and 66 6 respectively it was then summed together with the 5 class gp base run map combining both sets of information thus the final gpz uncertainty map of the hawker study area fig 8i shows the spatial distribution of very low to very high gpzs moderated by the three levels of uncertainty and can be compared with the original mapping by fildes et al 2020 shown in fig 2f 4 discussion the spatially explicit sa and ua enabled both discrete class and index based evaluations of model outputs from these the following summary can be derived regarding the reliability of the gp model with respect to criteria weight changes a for all 600 model runs gp class switches were relatively low with 81 76 of all cells remaining in the same gp class as they were in the base run 17 45 underwent a one class switch and only 0 79 underwent a two class switch b the lineaments and lithology criteria had the largest influence on class changes and gp output variation while the aspect criterion had the least influence c areas with gp index values 0 5 medium high and very high gp coinciding with lower model output variability medium to lower sd should be the focus of groundwater exploration efforts the overall relative stability in model outputs was also confirmed with a maximum sd of 0 079 7 9 over the study area fig 8g consistent with other similar gis mcda sa and ua studies de brito et al 2019 ligmann zielinska and jankowski 2014 şalap ayça and jankowski 2016 however local sensitivity to criteria weight changes were evident the spatial pattern of different uncertainty levels in the final gp mapping is largely the result of trade offs between criteria and their class values with respect to weight changes along with several other interrelated factors effecting model output behaviour an understanding of these factors will help to evaluate their local significance and focus efforts within the mcda process to minimise uncertainty and promote confidence in mapping results this cannot be achieved by considering only the overall measure of influence per criterion or class change 4 1 factors influencing model output behaviour the gp model employed a weighted linear combination method to aggregate criteria common to many gis based multi criteria analyses malczewski 2011 where the importance of one criterion trades off against others in a constrained model the behaviour of these trade offs is made clearer when evaluating the oat model outputs in a spatially explicit manner highlighting areas more vulnerable to weight changes fig 7 these trade offs are influenced by the starting weight value in the base run table 1 as observed in other studies e g de brito et al 2019 xu and zhang 2013 those criteria with higher weights tend to contribute more to output variation and uncertainty the same ipc applied to a higher starting weight will incur a greater progressive change and thus influence relative to criteria with smaller starting weights in the oat model this was observed for the lineaments lithology and twi criteria for this geographical setting thus an objective multi participant expert approach to weight development using tools such as the ahp is warranted to carefully assess the relative importance of each criterion particularly those considered to have greater importance as argued by de brito et al 2019 when a degree of consensus between multiple stakeholders with expertise are involved in the modelling process this tends to increase the reliability of results hence the sa and ua is better realised by helping to refine the calibration of input parameters using an iterative circular decision process fig 3 in this regard observed trade offs shown in fig 7 along with the small ipc 2 results in fig 4 and table a 1 can be used to evaluate the limits of acceptable variation in criteria weights for a desired stable classification of gpzs for example if a target of 80 of cells remaining unchanged is desired as the maximum acceptable uncertainty level in mapping results then participants judgements of criteria weightings for the lineaments and lithology criteria would need to be 20 in agreement fig 4 however this limit of weighting variation could be relaxed or require tightening depending on a whether more class switches occurred between a desired threshold of gp interest e g gp values cross between 0 5 or b where these class switches occurred e g for the lineaments criterion the majority of class switches occurred outside of the desired higher lineament density areas fig 7 in this regard the level of output uncertainty at any given location may be more or less significant the oat model produced a gp map for each ipc and for each main changing criterion allowing a full evaluation of the localised spatial behaviour of gp class switches notably it is not only the criteria weights but also the criteria class rankings that drive the trade offs between criteria in the aggregation process to test the influence of criteria class aggregation on model output the oat model was re run using the same original model parameters but using equal weights 0 1667 for each main criterion this in effect normalised the influence of the main criterion weight between each set of 100 runs and thus gp model results are largely driven by the spatial distribution of criteria class rankings and assigned class weight the results are presented in fig 9 and include the sd maps for each criterion observed is a reduction in the difference between each criterion s maximum sd relative to the differences in the original set of sd uncertainty maps in fig 8 along with a reduction in the maximum and average sd of the total sd uncertainty map fig 9g this comparison demonstrates a how applying different weights to criteria as opposed to equal weights increased the variability in model outputs and b given the similarities in the spatial pattern of gp mapping results between unequally and equally weighted criteria fig 8h i and fig 9h i respectively a focus on class weightings is as important as developing global criteria weights hence the lineaments lithology and twi criteria may warrant further careful criteria and class calibration as they have the highest influence on gp for this geographical setting in this regard the criteria weighting decision process should also extend to a critical review of the criteria class rankings and their weightings criteria calibration for continuous index based data such as lineament density slope twi and rainfall may comprise user defined linear or nonlinear class interval ranges or a value function e g linear sigmoidal j shape or user defined to represent zones of criteria behaviour on gp and for standardising disparate criteria measurements between 0 and 1 malczewski 2000 typically the value function and for this current study criteria class ranges were defined independently using expert judgement hence they are themselves subject to a degree of uncertainty not using a suitable value function or set of class ranges representative of a criterion s on ground spatial behaviour e g the influence of slope ranges on water runoff is likely to exacerbate errors in the model output irrespective of their assigned global weight while the relationship between real world phenomenon and their value function or class ranges as a spatial representation has been investigated by other authors eastman 1999 malczewski 2000 voogd 1982 it is not well justified within the gis based gp mapping literature other than a preference for the inclusion of specific criteria díaz alcaide and martínez santos 2019 this is a clear research gap another interrelated factor influencing gp output variability is the spatial resolution of input data de brito et al 2019 savage et al 2016 while all criterion maps were rasterised to a standard 30 m pixel resolution before aggregation the resolution of source data varied considerably and is largely related to the limited availability of spatial data at different capture scales when applying weight changes to criteria rasterised from broader scale generalised polygon datasets such as lithology classes or where higher resolution raster datasets such as slope or twi are reclassified into broader discrete class ranges areal units larger areas thus larger cell counts will be more vulnerable to class switches savage et al 2016 while this is more evident in class based model evaluations it is also inherent to index based outputs as well hence the capture scale of some criteria may require refining to ensure that the highest possible spatial variation in detail is captured to improve model results notably however even with a locally targeted mapping exercise the assumption of uniformity typically applies in spatial datasets such as lithological classes which do not take into account the often considerable variation within a unit hence the best way to take this into account is to undertake field observations and measurements to help site drill holes within the higher gp mapping zones 4 2 model limitations despite the oat model s efficiency and intuitive simplicity its limitations have been highlighted by several authors ligmann zielinska and jankowski 2014 saltelli et al 2019 saltelli and annoni 2010 firstly the oat moves one factor at a time e g criteria weights repeatedly from a baseline or nominal value which itself is an imprecise point estimate with no measure of confidence benke and pelizaro 2010 thus the full rpc from the base run may not reflect the true magnitude or influence the criterion has on output uncertainty ligmann zielinska and jankowski 2014 secondly the oat model while adjusting proportionally all other criterion weights as the main criterion weight is applied assumes the criteria are independent of one another and does not consider the fullness of criteria interactions on model output variation and uncertainty this is particularly problematic in spatially heterogeneous problems where model inputs can be spatially autocorrelated or can locally co vary ligmann zielinska and jankowski 2014 alternatively global sa often employ variance based methods that allow evaluation of independent criterion contributions to output uncertainty as well as total effect interactions between criteria saltelli and annoni 2010 however global sa also has its own shortcomings including its high computational cost ligmann zielinska and jankowski 2014 often requiring a much larger number of iterations compared with a oat model moreover the uncertainty in the input parameters is typically sampled with some probability density function the parameters of which are assumed known a priori crosetto et al 2000 potentially introducing model bias which may affect the true influence input parameters and their interaction have on output uncertainty this is also true for the oat method where the criteria weight is treated as a uniform random variable between a min max range and sampled using 2 increments however trade offs between computational resources and accuracy requirements necessary to meet the evaluation objectives should be considered when selecting which sa and ua method to use de brito et al 2019 notably the authors chose the oat method using the framework described by chen et al 2010 due to its practical simplicity and ease of integration with arcgis pro using arcpy based tasks allowing spatially explicit outputs and evaluations however other computationally efficient oat methods are possible such as the morris method morris 1991 which does not perturb factors from a single baseline but from a number of different starting points the morris method is a repeating randomised oat method and considered a global sa where factor interactions may be seen which cannot be achieved by varying factor values from a single baseline it is considered a reliable oat method for screening factors that have little influence on model outputs before more computationally expensive and robust variance based global sa methods are applied to a smaller set of influential factors crosetto and tarantola 2001 one of the key challenges of spatially explicit sa is the lack of methods inherently equipped to work in the spatial domain and or with common gis software programs an increasing range of sa methods are becoming more openly available built using different programming languages for example the salib open source python library herman and usher 2017 exposes modellers and researchers to a number of sa techniques including the morris method which could be developed and integrated into spatial modelling workflows as argued by ligmann zielinska and jankowski 2014 and de brito et al 2019 irrespective of the specific method used an essential requirement of a comprehensive sa and ua of a gis based mcda should be conducted in a spatially explicit manner given that gpz modelling results are generated from the aggregation of spatial datasets and presented as a map showing the spatial distribution of feasible alternatives in gp ua and sa should also be represented in a spatial format 4 3 groundwater potential for the hawker region for the hawker region areas with gp values 0 5 medium high and very high gp coinciding with lower model output uncertainty medium to lower sd should be the focus of groundwater exploration efforts and are shown in areas coloured green blue in fig 8i indeed this has reduced the search area from approximately 53 395 km2 when considering areas with gp value 0 5 only i e conventional mapping shown in fig 2f to approximately 23 173 km2 when excluding higher uncertainty areas from these results those most favourable areas with very high gp and lower uncertainty are circled in red in fig 8i and account for only 0 06 0 45 km2 of the study area given their closer proximity to the hawker township the two most easterly circled areas which were not immediately apparent in the original mapping have been noted for further on ground investigation they consist of highly favourable criteria gp drivers each aggregating to a gp value 0 85 the analysis has also helped refine several areas from a broader range of feasible alternatives throughout the long east west wonaka creek lineament zone and the v shaped lineament zone in the south east these new priority areas consist of highly favourable lineament densities lithology units lower slopes and twi classes conducive to groundwater occurrence and where mapping results are less susceptible to criteria weight changes notably areas of higher gp with higher uncertainty yellow red and pink areas fig 8i should not necessarily be excluded from consideration though more caution should be applied for example higher yielding wells are located between the two forementioned lineament zones which have been mapped as medium to high gp but with higher uncertainty the higher uncertainty was generated from trade offs shown in the oat outputs between lower lineament class values i e lower lineament density and more highly influential lithology highly porous limestone overlain by fluvial sediments twi and slope classes however the area is thought to have good groundwater prospects as evidenced by the higher yielding wells because it is bound by two adjacent pervasive lineament fault zones where fracturing is likely providing extra pathways for groundwater movement into this area despite this gp is not well represented here in the mapping results due to the coarse resolution and highly generalised lineaments and lithology source data future on ground investigations of local variations in lithology and the presence and nature of fracture patterns will confirm whether the influence from these fault zones extend beyond the current distances used in the modelling if so then a review of the lineament density extent or the introduction of a new distance from lineaments criterion may improve gp model output performance in this regard a review of the ahp criteria and class weightings would also be necessary to better represent the potential relative influence and interrelated behaviour of criteria the aim would be to ensure a degree of consensus between experts is reached on these new weightings to provide more confidence in mapping results the uncertainty mapping has prompted this review which was not apparent in the original gp mapping results shown in fig 2f and as presented in fildes et al 2020 5 conclusions the spatially explicit sa and ua enabled an important refinement of the traditional discrete gp class mapping approach by moderating the spatial distribution of mapping results with uncertainty levels thus improving the reliability of gp output alternatives the demonstrated approach is best suited in assisting gp exploration over large and hydrogeologically complex areas where the choice between feasible alternative locations is potentially much greater in this regard the incorporation of spatially explicit sa and ua in gp mapping helps to alleviate project constraints such as time cost and risk by refining the search area to better focus on groundwater exploration efforts leading to drilling the analysis enabled a more transparent understanding of the localised influence of criteria aggregations which vary over space this is especially important when choosing between locations with similar favourable gp and uncertainty levels aggregated from a different set of criteria and class weighting combinations thus identifying more favourable criteria combinations from a range of feasible alternatives helps to further prioritise gp areas the spatially explicit sa and ua will also help focus efforts on minimising uncertainty in gp mapping outputs by way of an investigative model development process fig 3 this can be achieved by a ensuring a degree of consensus among experts is reached on the relative importance of criteria weightings using an objective mcda approach such as the ahp to maintain a defined threshold of acceptable level of output uncertainty with a particular focus on those criteria assigned the highest weights note lineaments lithology and twi had the highest influence on output variability for this geographical setting b ensuring equal importance is given to developing suitable value functions for standardising criteria measures as well as class range intervals and their weighting with an emphasis on the most influential criteria c ensuring the highest possible quality of each criterion s spatial representation and its resolution either locally or more broadly across the study area and d evaluating the behaviour of criteria aggregation over all model runs at specific locations of interest in doing so a decision to review but not limited to any of the forementioned objectives may be implemented with a goal to improve certainty in mapping results weight development is one of the most important steps in mcda as it is arguably the most influential on model results if the results are to be used in policy and decision making then it is critical that some form of sa and ua is performed to evaluate the effect criteria weights have on model outputs while the spatially explicit sa and ua presented in this study can be applied to a range of multi criteria evaluations its application in gis based gpz modelling is underrepresented while acknowledging its limitations the oat method is cost effective transparent and allows decision makers to visualise geographically the effect criteria weight changes have on model output and to explore the underlying factors and gp drivers influencing uncertainty at specific locations before making final decisions on prioritising areas for groundwater exploration consequently in future gpz studies expert evaluation of an integrated spatially explicit sa and ua would be encouraged as part of a broader participatory mcda approach by doing so the analysis acts as an exploratory process by which decision makers attain a deeper understanding of the structure of the problem with a goal to improve gp mapping results more broadly across a specific geographical setting credit authorship contribution statement stephen geoffrey fildes conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization david bruce conceptualization writing review editing supervision ian francis clark conceptualization writing review editing supervision tom raimondo conceptualization supervision robert keane methodology software validation okke batelaan conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors are grateful to dr mariana madruga de brito helmholtz centre for environmental research ufz germany and to dr yun chen csiro australia for providing their oat model codes and ahp sa software tool respectively these provided initial guidance in developing the arcgis pro arcpy based tasks used in this research written by mr robert keane flinders university australia we also thank the reviewers for their valuable comments funding this research was supported by an australian government research training program scholarship and a commonwealth scientific and industrial research organisation csiro top up scholarship these funding sources were not involved in the study in any way source code and data the python scripts and data used in this work are available upon request appendix 
3323,the flash flood registered in november 1997 in the city of badajoz spain in the basin of rivillas river is analysed by means of the numerical code iber this event constitutes one of the most destructive flash floods registered in an urban area in the iberian peninsula starting from precipitation data obtained from rain stations the runoff of the entire river basin was simulated to obtain the discharge of the rivillas river in badajoz the flood maps obtained with iber reproduce accurately the field data registered during the actual event likewise the numerical time evolution of the flood and water depths are in accordance with testimonies of the witnesses once the capability of iber to reproduce the event was assessed several scenarios were considered in order to analyse the main causes of the event in particular simulations show that the catastrophic magnitude of the flood was mainly due to the blockage of bridges different hypothetical scenarios were simulated to analyze the role of rain intensity and bridge maintenance concluding that similar floods can occur under much lower rainfall but with poor bridge maintenance keywords iber flash flood badajoz maintenance of hydraulic structures 1 introduction the recent release of the 6th assessment report by the international panel of climate change ipcc 2021 confirms that humans are already having a very significant impact in many branches of the climate system and that this will increase in the coming decades independently of the climate scenarios considered the effects of climate change are widespread including a number of changes in the hydrological cycle namely in terms of the increment of extreme precipitation events both in frequency and intensity groisman et al 2005 beniston 2009 morss et al 2011 it is within this context that most experts have framed the recent flood events registered in july 2021 in china and central europe germany and belgium that caused more than 500 deceases and billions of euros in economic loses efas 2021 therefore the capability to predict well in advance these events is a crucial task in order to minimise their future negative effects one of the main approaches to deal with this problem is through numerical simulations in recent years the development of numerical tools strongly sustained on the increment of the computational power has facilitated the ability of the numerical simulations to reproduce such events with increasing detail these simulations allow a far better understanding of the effect of climate change related with flood events and can contribute with relevant information to mitigate their downsides according to the european directive e d 2007 60 c it is important to assess potential risks derived from flood events through a description of the floods which have occurred in the past and which have had significant adverse impacts on human health the environment cultural heritage and economic activity and for which the likelihood of similar future events is still relevant including their flood extent and conveyance routes and an assessment of the adverse impacts they have entailed which highlights the importance of reproducing past extreme flood events with numerical tools literature shows many examples of past flash floods derived from extreme precipitation events vennari et al 2016 provide a database of about 500 flash flood events registered in small catchments located in campania southern italy from 1540 to 2015 zêzere et al 2020 provide a comprehensive collection of floods registered in mainland portugal in the period 1865 2015 located in the tagus douro mondego and vouga valleys trigo et al 2016 analyse the main causes behind one of the deadliest flash floods occurred in portugal which took place on the 25 and 26 november 1967 following a historical perspective eulenstein and kellerer pirklbauer 2020 provide a detailed description of the flood event registered in central europe catchments of danube and vltava in 1572 using geographical sources bárdossy et al 2020 analyse the historical flood event registered in 1882 in neckar catchment west germany using the fully distributed spatial modelling hbv bergström 1992 elleder et al 2020a describe the catastrophic flood registered in the bohemian moravian highlands sázava river in 1714 and elleder et al 2020b analyse the consequences of torrential rain event in the city of prague czech republic in 1872 other interesting works focused on past flood events are buzzi et al 1998 where the flood registered in 1994 in piedmont northwestern italy is reproduced or bartholmes and todini 2005 where the authors reproduce the extreme event registered in november 1994 in the catchment of the po river one of the most important years concerning the number and magnitude of flood events is 1876 the bibliography shows several examples of floods registered all over the world that year for example benito et al 1996 and font 1988 describe floods of several rivers in spain other countries were also affected during that year by extreme floods portugal gonzález 1995 trigo et al 2014 france and germany pfister et al 1999 recently gonzález cao et al 2021 have also applied a multi modelling approach to the analysis of historical floods in western iberia in that work the authors reproduce the flood event registered on 5 december 1876 in badajoz using the numerical code iber garcía feal et al 2018 and the effects in the city are analysed in detail the reader can find other interesting works related to historical floods in máyer suárez 2002 where a series of flood events registered in las palmas spain from 1865 to 1999 are described and in laguarda 1962 where the flood registered in valencia in 1957 is shown more recent events are analysed by chao et al 2021 this study analyses flood events registered from may 2013 to september 2014 in the daheba watershed china hermoso et al 2021 analyse the event registered on 12 and 13 september 2019 in several eastern areas of the iberian peninsula one of the most destructive flash floods registered in an urban area in the iberian peninsula during 20th century was registered on the 5th and 6th november 1997 in the city of badajoz during the last hours of 5th and the first hours of day 6th the rivillas river flooded several areas of the city causing 21 deceases and high economic losses as it was previously pointed the capability to reproduce and predict such events by means of numerical tools is a crucial task in order to minimise negative effects in future scenarios iber is a numerical code widely used in many fields of hydrology for example gonzález cao et al 2019 and fernández novoa et al 2020 developed an early warning system for flood prediction in the miño river northwestern spain based on rainfall forecast by coupling the code hec hms to model the runoff processes and iber to obtain hazard maps at several locations in gonzález cao et al 2020 the authors reproduced the flood derived by the break of malpasset dam france in 1959 bonasia and ceragene 2021 carried out an application of iber to define the potential flood points located in the ungauged river basin of la sabana river mexico related with past events benito et al 2021 reproduced a series of floods registered in the duero basin spain from 1250 to 1871 in this work iber allows an accurate estimation of the peak values of discharge associated to these events starting from field data obtained from documentary evidences as minute books newspapers and water marks in bermúdez et al 2021 iber was applied to analyse past and future flood events registered in coastal river areas analysing the effects of the climate change both in river discharges and in the rising of mean sea level similar to these works ruman et al 2021 applied iber to estimate the discharge of the flood event registered in december 2000 in crete greece by using six paleostage indicators to calibrate the model in addition to the analysis of flood events the iber model has been applied to other fields thus mateo lázaro et al 2020 shows an application of iber to analyse the impact of structures as for example bridges on the current of rivers comparing velocities and water depths before and after the installation of such structures aranda et al 2021 applied iber to design effective drainage systems of transportation facilities in garcía alén et al 2021 the authors applied iber to reproduce the water flow in the presence of obstacles as weirs a dataset of 194 experiments of nine different weir geometries were used to quantify the discrepancies of the numerical results finally to show the wide range of applications of iber the reader can find an interesting application to the analysis of water quality in garcía feal et al 2020 in this paper the authors develop the iberwq suite based on iber to compute the most relevant parameters used to evaluate water quality as for example dissolved oxygen organic nitrogen ammonia nitrates among others the main aim of the present work is both the numerical reproduction of the event registered on the 5th and 6th november 1997 in the city of badajoz using the iber numerical code and the analysis its causes through the reproduction of a series of hypothetical flood scenarios in order to prevent and reduce the risk of similar events in the future the document is organized as follows in section 2 the area of study the evolution of the flood event and its consequences in badajoz are described then the precipitation dataset along with hydraulic model used are briefly presented in section 3 the numerical results of discharge flow and the water depths registered during the flood event in badajoz are shown in section 4 moreover numerical results are also shown obtained for various hypothetical scenarios derived from the current one finally section 5 provides the main conclusions of this work 2 area of study and description of the event the whole area of study fig 1 can be divided into two subareas namely the basin of the rivillas river before reaching the city of badajoz and the urban area where the river is canalized the basin of the rivillas river is located in the south west of the iberian peninsula and covers an area of 314 km2 fig 1a the rivillas river has an approximate length of 41 km and as such can be considered a small tributary of the guadiana river the elevation of rivillas catchment ranges from 350 m a s l at the headwater near valverde de leganés see fig 1b to near 174 m a s l at the mouth located in badajoz spain calamón river is the main tributary of rivillas river and their junction located in the urban area of the river fig 1c is located 1 5 km upstream from the mouth of rivillas river several bridges are located in the urban area of the domain fig 2 shows the current location of these bridges some of them acted as barriers during the event registered in 1997 a detailed description of the rivillas river is shown in zamora cabanillas 1999 and in ortega 2007 badajoz suffered the most adverse effects derived from the floods registered on the 5th and 6th november 1997 the event corresponds to one of the most extreme precipitation events in the western iberian peninsula in 20th century other cities or villages like mérida or valverde de leganés in spain and several areas in portugal were also affected by this event but the consequences were less dramatic than in badajoz newspapers and testimonies of survivors are the main source of information related to the impact of this extreme precipitation event several newspapers in spain described in detail the evolution and consequences of the flood in the city of badajoz they highlight the consequences of the event 21 deceases and economic losses of 100 m usd first hand testimonies from survivors are also a valuable source of information in order to understand the evolution of the flood technical reports and other studies cedex 1998 zamora cabanillas 1999 ortega 2007 have also focused on this extreme flood all these works show that during the days 5th and 6th the precipitation registered in several rain stations near badajoz reached historical records for example in talavera la real the total amount for those two days from 8 a m 5th november to 8p m 6th november was 119 mm in la albuera 110 mm and in pantano de piedraguda 133 mm these figures far exceed previous historical peak values 75 mm in talavera la real 63 5 mm in la albuera and 56 5 mm in pantano de piedraguda the location of these rain stations is shown in fig 1b unfortunately only one of these stations talavera la real is equipped with a sensor that allows obtaining continuous precipitation data the hyetograph obtained from this station shows that the precipitation event started at 15 00 of 5th november and lasted 10 h the main stage of the event was registered between 23 00 and 24 00 of 5th november according to testimonies peak flows were reached in the first hours of 6th november all these data sources and additional information allow classifying the event as a flash flood brenna et al 2020 it is also important to note that precipitation recorded during the five previous days of the flood was quite high reaching a cumulated value near 84 mm in talavera la real rain station this value is a clear outlier since the mean cumulated precipitation in five days computed using the precipitation data registered in talavera la real rain station from january 1980 until january 2020 is equal to 5 9 mm this precipitation and the effect of blocked bridges located in the urban area of badajoz amplified the height of the water maximum level and therefore increased the damages derived from the flood according to testimonies the bridge puente nacional v bridge 2 in fig 2 was almost totally blocked by water conduction pipes even before the event this situation worsened during the event due the existence of heavy debris flows both in the rivillas and calamón rivers these debris also blocked the bridges located upstream bridge 2 bridges cerro de reyes salvador allende san mateo pardaleras and puente del obispo bridges 1 3 4 5 and 6 in fig 2 were also blocked almost from the beginning of the event bridges 7 to 10 see fig 2 were blocked but their influence on the dramatic consequences of the event was less than the effect produced by bridge 2 and bridges located upstream 3 material and methods 3 1 precipitation dataset the main precipitation dataset was obtained from meteorological station 4452 located in talavera la real base see fig 1b this station is managed by aemet agencia estatal de meteorología daily precipitation data is publicly available for the period january 1955 to january 2022 and can be freely downloaded from aemet opendata https opendata aemet es centrodedescargas productosaemet precipitation data recorded with a step time of ten minutes was used to define the hyetograph for the simulations carried out with iber additional precipitation data used as complementary information in this work was obtained from the rain stations of piedra aguda dam cod 4484 albuera cod cr2 42 and badajoz cod 4478 all represented in fig 1b these stations are managed by the chg confederación hidrográfica del guadiana the atypical nature of the event registered on 5 6 november 1997 is highlighted when comparing the volume of rainfall recorded during that event 119 mm with the historical time series of daily precipitation recorded from 1876 to 2022 table 1 3 2 hydraulic model iber iber is a numerical tool that solves the 2d depth averaged shallow water equations using the finite volume method bladé et al 2014 recently some of the authors garcía feal et al 2018 have developed a new implementation of the model in c and cuda nvidia 2020 namely iber this new implementation of iber improves the efficiency of the simulations by achieving a speed up of two orders of magnitude with the same precision by using gpu graphical processing unit computing hpc high performance computing techniques these optimizations rise the possibility to employ the model in large spatial and temporal domains gonzález cao et al 2020 garcía feal et al 2020 fernández nóvoa et al 2020 gonzalez cao et al 2021 or time constrained applications fraga et al 2020 gonzález cao et al 2019 also some applications of hybridization of iber with other computational fluid dynamics cfd models like dualsphysics domínguez et al 2021 have been developed to analyse the behaviour of dams in high precipitation scenarios gonzález cao et al 2018 the software package is freely available and can be downloaded from its official website https iberaula es it also includes a gui graphical user interface with both pre processing and post processing tools in the present study iber was applied to the rivillas river domain aiming to analyse the flood event registered in badajoz spain in november 1997 all the numerical simulations of iber in badajoz were performed using a gpu geforce rtx 2080 ti the domain defined in iber along with its inlet and outlet boundaries in the urban area of badajoz is shown in fig 3 the inlet condition is defined as a critical subcritical condition by defining the daily mean flow registered in the gage station 4030 of the chg confederación hidrográfica del guadiana located in badajoz during the event and the outlet condition is defined as a supercritical critical condition the hyetograph defined corresponds to the precipitation data recorded every ten minutes at the rain station located at talavera la real airbase the daily flow of guadiana river registered in badajoz and the precipitation registered in talavera la real airbase are shown in fig 4 panels a and b respectively the domain was discretized using a mesh of unstructured triangles whose characteristic size varies from 5 to 30 m with a total of 1 2 m of elements the highest mesh size was defined to discretize the basin of the rivillas river while the lowest values were defined to discretize urban areas of the domain in the city of badajoz near the urban reach of the river medium mesh size was defined in the rest of the numerical domain once the numerical domain was defined and discretized it was adapted to the topography of the area by means of a dem digital elevation model with a spatial resolution of 5 m that was retrieved from the web of the centro nacional de información geográfica cnig http centrodedescargas cnig es centrodescargas index jsp this dem corresponds to current topography of the area of study it should be stressed that some relevant modifications were carried out in the urban area in the city of badajoz since 1997 including the widening of the river channels upgrading works in the riverbanks of the river and the demolition of some of the riverine buildings however taking into account that these buildings were one of the main factors that increased the negative effects of the flood we decided that they should be included in the area of study the 3 d shapes of the buildings were obtained by digitizing old photographs and maps of the area also some footbridges were reconstructed after the flood as bridges all these modifications were taken into account to reproduce the physical constrains that led to the event as accurately as possible on the one hand land uses were obtained from raster data of european corine land use land cover data of 2000 clc 2000 and on the other hand data of infiltration was obtained from raster file of the cn of the iberian peninsula computed according to the methodology proposed by ferrer i juliá 2003 in the present work and taking into account that the volume of precipitation registered in the five previous days of the event is near 85 mm see fig 4c moist conditions for the cn were considered eq 2 the mean value of cn in the entire basin is equal to 85 5 fig 5 shows the maps of land uses and cn defined in the basin of the rivillas river one of the main difficulties in the numerical reproduction of historical flood events is the analysis of the uncertainty associated with the input data that is discharges rainfall dems land uses and values of cns when it comes to more recent events the available data is much larger than for historical events and therefore the analysis of the uncertainty is an affordable task the reader can find detailed analysis of uncertainty associated with hydrological analysis of recent events in xu et al 2006 jin et al 2010 shen et al 2012 abro et al 2020 or nanding et al 2021 specifically for the uncertainty associated with rain gauge data reynolds et al 2020 show the influence of limited discharge data for flood prediction and chen et al 2022 show the influence of rain gauge density and distribution on gauge satellite merged precipitation estimates furthermore the uncertainty associated with the accuracy of dems is often analysed for recent flood events pakoksung and takagi 2022 xu et al 2022 this is not the case when it comes to historical events where the amount of data is limited and therefore uncertainty analysis is beyond the scope of this type of works 1 cn 25400 i a 0 2 254 2 cn moist 23 c n 10 0 13 c n according to testimonies most of the bridges located in the urban area of the rivillas river were partially blocked from nearly the beginning of the flood event therefore in the iber simulations the bridges were considered as barriers with constant height during the entire simulation 4 results and discussion 4 1 estimation of the discharge flows in badajoz the flows obtained with iber for calamón and rivillas rivers at three control points are shown in fig 6 with the location of these three control points represented in the left panel initial time of simulations corresponds to 15 00 5th november control points 1 and 2 cp1 and cp2 in fig 6 correspond to flows of calamón and rivillas rivers respectively before reaching bridge 2 control point cpm corresponds to flow of rivillas river near the mouth of this river the right panel in fig 6 shows that the peak value of rivillas river obtained before bridge 2 is higher than the peak value obtained for calamón river 521 m3 s 1 and 441 m3 s 1 respectively the maximum value of rivillas is reached before around 2 40 a m than the maximum value of the calamón river around 3 50 a m on november 6 the maximum flow value of the rivillas river obtained at its mouth reached a value equal to 879 m3 s 1 observed at 3 00 a m 4 2 numerical analysis of the evolution of the flood event the maximum extent of the flood obtained with iber and the corresponding maximum extent obtained from field data in the urban area of the domain are shown in fig 7 left panel the numerical results area delimited with red lines reproduce quite well the field data area delimited with green lines there are some areas e g a b and c in fig 7 left panel where the numerical results overestimate the actual values of the extent these differences can be attributed at least partially to the resolution of the dem data and uncertainties associated to values of cn the right panel of fig 7 shows a detailed image of the area upstream near bridge 2 where the orange polygons refer to the buildings located within this area it is important to notice that this area corresponds to the sector of the city most affected by the flood during this event the blue area corresponds to the maximum flood extent situation obtained with iber confirming that it reached buildings located in both riverbanks of calamón and rivillas rivers therefore we can conclude that iber reproduce quite well the situation registered during the event however flash flood events evolve quite rapidly and therefore require a more dynamic assessment of the areas affected preferably at the sub hourly temporal scale fig 8 shows such evolution of the flood event water depth maps obtained with iber from 10 20p m to 10 30p m on 5 november flows of rivillas and calamón rivers arrive at urban areas of badajoz fig 8a flow of rivillas river reaches the canalisation before flow of calamón river near 0 45 a m on 6 november flow of rivillas impacts into bridge 2 fig 8b while flow of calamón overtop bridge 4 then flow from rivillas returns upstream following the calamón riverbed fig 8c at 1 00 a m on 6 november flows of rivillas and calamón impact near bridge 5 this causes the flood on the right and left riverbanks of calamón river fig 8d the maximum extent of the flood can be observed at 2 30 3 00 a m on 6 november fig 8e in addition to the evolution of the water depth maps the evolution of water depth at five control points is represented in fig 9 a control points cp1 and cp2 also depicted in fig 6 and cp5 and cp6 are located upstream near bridge 2 and control point cp3 is located downstream near bridge 2 cp1 is located in the riverbed of calamón river while cp2 and cp3 are located in rivillas riverbed control points cp4 and cp5 are located at the beginning of the canalisation of calamón and rivillas rivers respectively fig 9b shows that flow arrives downstream bridge 2 at the beginning of the simulation at cp3 this flow comes from guadiana river at around 1 00 a m on 6 november flows from rivillas and calamón reach control points cp1 and cp2 respectively from 9 00 a m on 6 november water depth is higher upstream bridge 2 than downstream this bridge this effect is due to the bridge 2 acting as a barrier during the event fig 9c confirms that flow from calamón arrives at the starting point of the canalisation i e before the flow from rivillas river this is because the beginning of canalisation of calamón river is located farther away from bridge 2 than the start of canalisation of rivillas river a temporal flow chart of the numerical model evolution vs field data obtained from testimonies is shown in fig 10 time evolution obtained through testimonies is quite similar to those obtained in the numerical simulations carried out with iber some discrepancy is observed in the timing for the maximum peak flow whereas timing obtained from field data is 1 30 a m on 6 november the corresponding timing from numerical simulations is situated near 3 a m nevertheless it is known that testimonies have some difficulty in defining exact timing of peak flow values during the event this difficulty results since they can be affected by subjective perceptions as well as the lack of objective references to measure peak values it is worth mentioning that it was night the electric lighting stopped working and the weather conditions were adverse with rain and strong gusts of wind moreover people do not usually stand at the same place during the entire event and this can lead to misleading perceptions to define accurately the time of peak flow once the numerical model has been validated to reproduce such event a more in depth analysis was carried out the characteristics of the implementation of iber allows an analysis of a series of hypothetical flood scenarios considering different conditions it can be stated from previous analysis that there are three main causes for the dramatic consequences of this event first the large amount of precipitation registered from 5 00p m on 5 november to 1 00 a m on 6 november second the high levels of antecedent soil moisture content due the continuous precipitation registered during the previous days of the event third the poor maintenance and cleaning conditions of most bridges that quickly become partially blocked during the event the precipitation and previous conditions of the soil are distributed over the entire basin of the river being related with meteorological conditions out of control of water management institutions on the other hand the conditions of the bridges only affect the urban area of the calamón and rivillas rivers and are directly controlled by water management institutions by means of a correct maintenance of these structures to analyse the effect of the conditions of the bridges in the flood event eight hypothetical scenarios with different conditions have been defined three different hyetographs have been defined starting from the actual one and reducing it a factor equal to 75 50 and 25 therefore in this study we analyse four hyetographs h100 h75 h50 and h25 the probability of occurrence of these three last hyetographs is much higher than the probability associated to h100 for each hyetograph two different conditions were analysed bridges partially blocked b b and free bridges f b the rest of conditions associated to the event i e the time distribution of the precipitation and the antecedent moisture soil content remain equal to the actual event for each scenario we obtain the maximum hazard maps according to cox et al 2010 and also the time evolution of the water depth at control point cp1 see fig 6 this control point is located in the area most affected during the actual flood event and therefore it can be considered representative to analyse the consequences of the event the results of this analysis are shown in fig 11 red areas of panels a b c and d stand for maximum hazard maps obtained with b b condition for the four different analysed hyetographs and green areas of these panels refer to maximum hazard maps cox et al 2010 obtained with f b conditions for h100 h75 h50 and h25 hyetographs respectively red and green lines of panels e f g and h stand for time evolution of water depth with b b and f b respectively for the analysed hyetographs maximum hazard maps obtained for h100 with b b and f b conditions fig 11a are similar to each other fig 11e shows that peak values of water depth obtained for b b and f b are also similar 8 1 and 7 6 m respectively difference 6 this is due the high total amount of precipitation accumulated during the event for h100 the recessing part of curve depicted in fig 11e obtained with b b is lower than the recessing part of the curve obtained with f b condition this effect increases the negative effects of the event since it prevents the access of rescue services to affected areas results obtained for h75 are similar to those obtained for h100 flooded areas are similar for b b and f b fig 11b in this case peak values of water depth obtained with b b and f b are 7 1 m and 6 m respectively therefore in this case the difference between peak values is near 15 this indicates that the effect of blocked bridges is greater that with h100 for h50 flooded areas downstream bridge 2 obtained for b b and f b fig 11c are similar but the difference between the flooded areas upstream bridge 2 are evident fig 11g shows that peak value of water depth for b b is much higher 6 3 m than peak value obtained with f b condition 3 7 m the difference between these values 2 6 m is greater than the difference between peak values obtained with the same conditions but for h100 and h75 0 6 m and 1 2 m respectively and represents a drop of almost 45 this stresses that for this case h50 the effect of blocked bridges increases its influence in the flooded areas versus the amount of water registered during the precipitation event this effect is even more obvious for h25 as in this case flooded areas obtained with b b fig 11d conditions are much higher than those obtained with f b peak value of water depth obtained with b b is near 5 m while peak value obtained with f b conditions is less than 1 m corresponding to 80 less finally the values of wet areas obtained with the four analysed hyetographs and the b b and f b conditions in the urban area of the rivillas river are depicted in fig 12 for both conditions wet areas increase as the amount of precipitation increases wet areas obtained with b b conditions are 31 ha 50 ha 65 ha and 73 ha for each hyetograph while for corresponding f b conditions wet areas are 12 ha 30 ha 56 ha and 67 ha the difference of wet areas obtained with b b and f b conditions decreases as peak values of hyetographs increases for h25 and h50 the difference is equal to 19 ha and 20 ha respectively for h75 is equal to 9 ha and for h100 is equal to 6 ha this means that the effect of the blocked bridges decreases as the amount of precipitation increases this is in accordance with the results of water depth 5 conclusions in this work the numerical simulation of the flood event registered in badajoz on 5th and 6th in november 1997 was carried out by means of the iber this event corresponds to one of the most catastrophic urban flash floods registered in the iberian peninsula in the 20th century the unprecedented level of this event is summed up by the amount of precipitation registered during the event the number of fatalities 21 and the economic losses the numerical simulations carried out with iber allows undertaking the coupled analysis the urban area and the rest of the basin of the rivillas river the urban area of the river is characterized by the canalization of the main stream of the rivillas river as well as of the main tributary of this river i e the calamón river in this urban area the existence of several bridges and buildings had a crucial impact in the evolution and the consequences of the urban flood especially for medium intensity hydrographs the numerical results obtained with iber reproduce quite well the event registered in 1997 both the extension and the temporal evolution of the flood compared with field data also peak values of water depths are in agreement with data provided by testimonies one of the conclusions of this work is that with a similar deficient maintenance the same temporal evolution and maximum flooded areas recorded during the past event would be reached today obviously the demolition of the houses located near the river bed would minimize the negative effects under a similar event according to the analysis there were three main factors that increased the negative effects of the event 1 the amount of precipitation registered from 5 00p m on 5 november to 1 00 a m on 6 november 2 the high levels of antecedent soil moisture content 3 the poor maintenance condition of bridges partially blocked during the event a series of hypothetical scenarios were considered to assess the effect of precipitation and the maintenance conditions of the bridges during the event four hyetographs h100 h75 h50 and h25 and two maintenance conditions partially blocked or free bridges were analysed the results show that a significant part of the area can be flooded even with low intensity hyetographs especially when the span of the bridge is blocked the flooded area is much smaller when the bridge is not blocked in summary the work has highlighted iber s ability to reproduce extreme flash flood events in urban areas moreover the model allowed designing hypothetical scenarios that can help to a better maintenance of hydraulic structures this can constitute a powerful tool within the present framework of climate change credit authorship contribution statement josé gonzález cao conceptualization formal analysis investigation methodology resources visualization writing original draft diego fernández nóvoa conceptualization formal analysis investigation methodology orlando garcía feal formal analysis investigation methodology jose r figueira conceptualization formal analysis investigation methodology resources josé m vaquero conceptualization resources supervision writing review editing ricardo m trigo conceptualization resources supervision writing review editing moncho gómez gesteira conceptualization formal analysis investigation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was partially supported by under project risc ml code 0034 risc ml 6 e co funded by the european regional development fund erdf and by xunta de galicia under project ed431c 2021 44 programa de consolidación e estruturación de unidades de investigación grupos de referencia competitiva dfn was supported by xunta de galicia through a post doctoral grant ed481b 2021 108 jmv was supported by the economy and infrastructure counselling of the junta of extremadura through project ib20080 and grants gr21080 co financed by the european regional development fund the aerial pictures used in this work are courtesy of the spanish ign instituto geográfico nacional and part of the pnoa plan nacional de ortofotografía aérea program 
3323,the flash flood registered in november 1997 in the city of badajoz spain in the basin of rivillas river is analysed by means of the numerical code iber this event constitutes one of the most destructive flash floods registered in an urban area in the iberian peninsula starting from precipitation data obtained from rain stations the runoff of the entire river basin was simulated to obtain the discharge of the rivillas river in badajoz the flood maps obtained with iber reproduce accurately the field data registered during the actual event likewise the numerical time evolution of the flood and water depths are in accordance with testimonies of the witnesses once the capability of iber to reproduce the event was assessed several scenarios were considered in order to analyse the main causes of the event in particular simulations show that the catastrophic magnitude of the flood was mainly due to the blockage of bridges different hypothetical scenarios were simulated to analyze the role of rain intensity and bridge maintenance concluding that similar floods can occur under much lower rainfall but with poor bridge maintenance keywords iber flash flood badajoz maintenance of hydraulic structures 1 introduction the recent release of the 6th assessment report by the international panel of climate change ipcc 2021 confirms that humans are already having a very significant impact in many branches of the climate system and that this will increase in the coming decades independently of the climate scenarios considered the effects of climate change are widespread including a number of changes in the hydrological cycle namely in terms of the increment of extreme precipitation events both in frequency and intensity groisman et al 2005 beniston 2009 morss et al 2011 it is within this context that most experts have framed the recent flood events registered in july 2021 in china and central europe germany and belgium that caused more than 500 deceases and billions of euros in economic loses efas 2021 therefore the capability to predict well in advance these events is a crucial task in order to minimise their future negative effects one of the main approaches to deal with this problem is through numerical simulations in recent years the development of numerical tools strongly sustained on the increment of the computational power has facilitated the ability of the numerical simulations to reproduce such events with increasing detail these simulations allow a far better understanding of the effect of climate change related with flood events and can contribute with relevant information to mitigate their downsides according to the european directive e d 2007 60 c it is important to assess potential risks derived from flood events through a description of the floods which have occurred in the past and which have had significant adverse impacts on human health the environment cultural heritage and economic activity and for which the likelihood of similar future events is still relevant including their flood extent and conveyance routes and an assessment of the adverse impacts they have entailed which highlights the importance of reproducing past extreme flood events with numerical tools literature shows many examples of past flash floods derived from extreme precipitation events vennari et al 2016 provide a database of about 500 flash flood events registered in small catchments located in campania southern italy from 1540 to 2015 zêzere et al 2020 provide a comprehensive collection of floods registered in mainland portugal in the period 1865 2015 located in the tagus douro mondego and vouga valleys trigo et al 2016 analyse the main causes behind one of the deadliest flash floods occurred in portugal which took place on the 25 and 26 november 1967 following a historical perspective eulenstein and kellerer pirklbauer 2020 provide a detailed description of the flood event registered in central europe catchments of danube and vltava in 1572 using geographical sources bárdossy et al 2020 analyse the historical flood event registered in 1882 in neckar catchment west germany using the fully distributed spatial modelling hbv bergström 1992 elleder et al 2020a describe the catastrophic flood registered in the bohemian moravian highlands sázava river in 1714 and elleder et al 2020b analyse the consequences of torrential rain event in the city of prague czech republic in 1872 other interesting works focused on past flood events are buzzi et al 1998 where the flood registered in 1994 in piedmont northwestern italy is reproduced or bartholmes and todini 2005 where the authors reproduce the extreme event registered in november 1994 in the catchment of the po river one of the most important years concerning the number and magnitude of flood events is 1876 the bibliography shows several examples of floods registered all over the world that year for example benito et al 1996 and font 1988 describe floods of several rivers in spain other countries were also affected during that year by extreme floods portugal gonzález 1995 trigo et al 2014 france and germany pfister et al 1999 recently gonzález cao et al 2021 have also applied a multi modelling approach to the analysis of historical floods in western iberia in that work the authors reproduce the flood event registered on 5 december 1876 in badajoz using the numerical code iber garcía feal et al 2018 and the effects in the city are analysed in detail the reader can find other interesting works related to historical floods in máyer suárez 2002 where a series of flood events registered in las palmas spain from 1865 to 1999 are described and in laguarda 1962 where the flood registered in valencia in 1957 is shown more recent events are analysed by chao et al 2021 this study analyses flood events registered from may 2013 to september 2014 in the daheba watershed china hermoso et al 2021 analyse the event registered on 12 and 13 september 2019 in several eastern areas of the iberian peninsula one of the most destructive flash floods registered in an urban area in the iberian peninsula during 20th century was registered on the 5th and 6th november 1997 in the city of badajoz during the last hours of 5th and the first hours of day 6th the rivillas river flooded several areas of the city causing 21 deceases and high economic losses as it was previously pointed the capability to reproduce and predict such events by means of numerical tools is a crucial task in order to minimise negative effects in future scenarios iber is a numerical code widely used in many fields of hydrology for example gonzález cao et al 2019 and fernández novoa et al 2020 developed an early warning system for flood prediction in the miño river northwestern spain based on rainfall forecast by coupling the code hec hms to model the runoff processes and iber to obtain hazard maps at several locations in gonzález cao et al 2020 the authors reproduced the flood derived by the break of malpasset dam france in 1959 bonasia and ceragene 2021 carried out an application of iber to define the potential flood points located in the ungauged river basin of la sabana river mexico related with past events benito et al 2021 reproduced a series of floods registered in the duero basin spain from 1250 to 1871 in this work iber allows an accurate estimation of the peak values of discharge associated to these events starting from field data obtained from documentary evidences as minute books newspapers and water marks in bermúdez et al 2021 iber was applied to analyse past and future flood events registered in coastal river areas analysing the effects of the climate change both in river discharges and in the rising of mean sea level similar to these works ruman et al 2021 applied iber to estimate the discharge of the flood event registered in december 2000 in crete greece by using six paleostage indicators to calibrate the model in addition to the analysis of flood events the iber model has been applied to other fields thus mateo lázaro et al 2020 shows an application of iber to analyse the impact of structures as for example bridges on the current of rivers comparing velocities and water depths before and after the installation of such structures aranda et al 2021 applied iber to design effective drainage systems of transportation facilities in garcía alén et al 2021 the authors applied iber to reproduce the water flow in the presence of obstacles as weirs a dataset of 194 experiments of nine different weir geometries were used to quantify the discrepancies of the numerical results finally to show the wide range of applications of iber the reader can find an interesting application to the analysis of water quality in garcía feal et al 2020 in this paper the authors develop the iberwq suite based on iber to compute the most relevant parameters used to evaluate water quality as for example dissolved oxygen organic nitrogen ammonia nitrates among others the main aim of the present work is both the numerical reproduction of the event registered on the 5th and 6th november 1997 in the city of badajoz using the iber numerical code and the analysis its causes through the reproduction of a series of hypothetical flood scenarios in order to prevent and reduce the risk of similar events in the future the document is organized as follows in section 2 the area of study the evolution of the flood event and its consequences in badajoz are described then the precipitation dataset along with hydraulic model used are briefly presented in section 3 the numerical results of discharge flow and the water depths registered during the flood event in badajoz are shown in section 4 moreover numerical results are also shown obtained for various hypothetical scenarios derived from the current one finally section 5 provides the main conclusions of this work 2 area of study and description of the event the whole area of study fig 1 can be divided into two subareas namely the basin of the rivillas river before reaching the city of badajoz and the urban area where the river is canalized the basin of the rivillas river is located in the south west of the iberian peninsula and covers an area of 314 km2 fig 1a the rivillas river has an approximate length of 41 km and as such can be considered a small tributary of the guadiana river the elevation of rivillas catchment ranges from 350 m a s l at the headwater near valverde de leganés see fig 1b to near 174 m a s l at the mouth located in badajoz spain calamón river is the main tributary of rivillas river and their junction located in the urban area of the river fig 1c is located 1 5 km upstream from the mouth of rivillas river several bridges are located in the urban area of the domain fig 2 shows the current location of these bridges some of them acted as barriers during the event registered in 1997 a detailed description of the rivillas river is shown in zamora cabanillas 1999 and in ortega 2007 badajoz suffered the most adverse effects derived from the floods registered on the 5th and 6th november 1997 the event corresponds to one of the most extreme precipitation events in the western iberian peninsula in 20th century other cities or villages like mérida or valverde de leganés in spain and several areas in portugal were also affected by this event but the consequences were less dramatic than in badajoz newspapers and testimonies of survivors are the main source of information related to the impact of this extreme precipitation event several newspapers in spain described in detail the evolution and consequences of the flood in the city of badajoz they highlight the consequences of the event 21 deceases and economic losses of 100 m usd first hand testimonies from survivors are also a valuable source of information in order to understand the evolution of the flood technical reports and other studies cedex 1998 zamora cabanillas 1999 ortega 2007 have also focused on this extreme flood all these works show that during the days 5th and 6th the precipitation registered in several rain stations near badajoz reached historical records for example in talavera la real the total amount for those two days from 8 a m 5th november to 8p m 6th november was 119 mm in la albuera 110 mm and in pantano de piedraguda 133 mm these figures far exceed previous historical peak values 75 mm in talavera la real 63 5 mm in la albuera and 56 5 mm in pantano de piedraguda the location of these rain stations is shown in fig 1b unfortunately only one of these stations talavera la real is equipped with a sensor that allows obtaining continuous precipitation data the hyetograph obtained from this station shows that the precipitation event started at 15 00 of 5th november and lasted 10 h the main stage of the event was registered between 23 00 and 24 00 of 5th november according to testimonies peak flows were reached in the first hours of 6th november all these data sources and additional information allow classifying the event as a flash flood brenna et al 2020 it is also important to note that precipitation recorded during the five previous days of the flood was quite high reaching a cumulated value near 84 mm in talavera la real rain station this value is a clear outlier since the mean cumulated precipitation in five days computed using the precipitation data registered in talavera la real rain station from january 1980 until january 2020 is equal to 5 9 mm this precipitation and the effect of blocked bridges located in the urban area of badajoz amplified the height of the water maximum level and therefore increased the damages derived from the flood according to testimonies the bridge puente nacional v bridge 2 in fig 2 was almost totally blocked by water conduction pipes even before the event this situation worsened during the event due the existence of heavy debris flows both in the rivillas and calamón rivers these debris also blocked the bridges located upstream bridge 2 bridges cerro de reyes salvador allende san mateo pardaleras and puente del obispo bridges 1 3 4 5 and 6 in fig 2 were also blocked almost from the beginning of the event bridges 7 to 10 see fig 2 were blocked but their influence on the dramatic consequences of the event was less than the effect produced by bridge 2 and bridges located upstream 3 material and methods 3 1 precipitation dataset the main precipitation dataset was obtained from meteorological station 4452 located in talavera la real base see fig 1b this station is managed by aemet agencia estatal de meteorología daily precipitation data is publicly available for the period january 1955 to january 2022 and can be freely downloaded from aemet opendata https opendata aemet es centrodedescargas productosaemet precipitation data recorded with a step time of ten minutes was used to define the hyetograph for the simulations carried out with iber additional precipitation data used as complementary information in this work was obtained from the rain stations of piedra aguda dam cod 4484 albuera cod cr2 42 and badajoz cod 4478 all represented in fig 1b these stations are managed by the chg confederación hidrográfica del guadiana the atypical nature of the event registered on 5 6 november 1997 is highlighted when comparing the volume of rainfall recorded during that event 119 mm with the historical time series of daily precipitation recorded from 1876 to 2022 table 1 3 2 hydraulic model iber iber is a numerical tool that solves the 2d depth averaged shallow water equations using the finite volume method bladé et al 2014 recently some of the authors garcía feal et al 2018 have developed a new implementation of the model in c and cuda nvidia 2020 namely iber this new implementation of iber improves the efficiency of the simulations by achieving a speed up of two orders of magnitude with the same precision by using gpu graphical processing unit computing hpc high performance computing techniques these optimizations rise the possibility to employ the model in large spatial and temporal domains gonzález cao et al 2020 garcía feal et al 2020 fernández nóvoa et al 2020 gonzalez cao et al 2021 or time constrained applications fraga et al 2020 gonzález cao et al 2019 also some applications of hybridization of iber with other computational fluid dynamics cfd models like dualsphysics domínguez et al 2021 have been developed to analyse the behaviour of dams in high precipitation scenarios gonzález cao et al 2018 the software package is freely available and can be downloaded from its official website https iberaula es it also includes a gui graphical user interface with both pre processing and post processing tools in the present study iber was applied to the rivillas river domain aiming to analyse the flood event registered in badajoz spain in november 1997 all the numerical simulations of iber in badajoz were performed using a gpu geforce rtx 2080 ti the domain defined in iber along with its inlet and outlet boundaries in the urban area of badajoz is shown in fig 3 the inlet condition is defined as a critical subcritical condition by defining the daily mean flow registered in the gage station 4030 of the chg confederación hidrográfica del guadiana located in badajoz during the event and the outlet condition is defined as a supercritical critical condition the hyetograph defined corresponds to the precipitation data recorded every ten minutes at the rain station located at talavera la real airbase the daily flow of guadiana river registered in badajoz and the precipitation registered in talavera la real airbase are shown in fig 4 panels a and b respectively the domain was discretized using a mesh of unstructured triangles whose characteristic size varies from 5 to 30 m with a total of 1 2 m of elements the highest mesh size was defined to discretize the basin of the rivillas river while the lowest values were defined to discretize urban areas of the domain in the city of badajoz near the urban reach of the river medium mesh size was defined in the rest of the numerical domain once the numerical domain was defined and discretized it was adapted to the topography of the area by means of a dem digital elevation model with a spatial resolution of 5 m that was retrieved from the web of the centro nacional de información geográfica cnig http centrodedescargas cnig es centrodescargas index jsp this dem corresponds to current topography of the area of study it should be stressed that some relevant modifications were carried out in the urban area in the city of badajoz since 1997 including the widening of the river channels upgrading works in the riverbanks of the river and the demolition of some of the riverine buildings however taking into account that these buildings were one of the main factors that increased the negative effects of the flood we decided that they should be included in the area of study the 3 d shapes of the buildings were obtained by digitizing old photographs and maps of the area also some footbridges were reconstructed after the flood as bridges all these modifications were taken into account to reproduce the physical constrains that led to the event as accurately as possible on the one hand land uses were obtained from raster data of european corine land use land cover data of 2000 clc 2000 and on the other hand data of infiltration was obtained from raster file of the cn of the iberian peninsula computed according to the methodology proposed by ferrer i juliá 2003 in the present work and taking into account that the volume of precipitation registered in the five previous days of the event is near 85 mm see fig 4c moist conditions for the cn were considered eq 2 the mean value of cn in the entire basin is equal to 85 5 fig 5 shows the maps of land uses and cn defined in the basin of the rivillas river one of the main difficulties in the numerical reproduction of historical flood events is the analysis of the uncertainty associated with the input data that is discharges rainfall dems land uses and values of cns when it comes to more recent events the available data is much larger than for historical events and therefore the analysis of the uncertainty is an affordable task the reader can find detailed analysis of uncertainty associated with hydrological analysis of recent events in xu et al 2006 jin et al 2010 shen et al 2012 abro et al 2020 or nanding et al 2021 specifically for the uncertainty associated with rain gauge data reynolds et al 2020 show the influence of limited discharge data for flood prediction and chen et al 2022 show the influence of rain gauge density and distribution on gauge satellite merged precipitation estimates furthermore the uncertainty associated with the accuracy of dems is often analysed for recent flood events pakoksung and takagi 2022 xu et al 2022 this is not the case when it comes to historical events where the amount of data is limited and therefore uncertainty analysis is beyond the scope of this type of works 1 cn 25400 i a 0 2 254 2 cn moist 23 c n 10 0 13 c n according to testimonies most of the bridges located in the urban area of the rivillas river were partially blocked from nearly the beginning of the flood event therefore in the iber simulations the bridges were considered as barriers with constant height during the entire simulation 4 results and discussion 4 1 estimation of the discharge flows in badajoz the flows obtained with iber for calamón and rivillas rivers at three control points are shown in fig 6 with the location of these three control points represented in the left panel initial time of simulations corresponds to 15 00 5th november control points 1 and 2 cp1 and cp2 in fig 6 correspond to flows of calamón and rivillas rivers respectively before reaching bridge 2 control point cpm corresponds to flow of rivillas river near the mouth of this river the right panel in fig 6 shows that the peak value of rivillas river obtained before bridge 2 is higher than the peak value obtained for calamón river 521 m3 s 1 and 441 m3 s 1 respectively the maximum value of rivillas is reached before around 2 40 a m than the maximum value of the calamón river around 3 50 a m on november 6 the maximum flow value of the rivillas river obtained at its mouth reached a value equal to 879 m3 s 1 observed at 3 00 a m 4 2 numerical analysis of the evolution of the flood event the maximum extent of the flood obtained with iber and the corresponding maximum extent obtained from field data in the urban area of the domain are shown in fig 7 left panel the numerical results area delimited with red lines reproduce quite well the field data area delimited with green lines there are some areas e g a b and c in fig 7 left panel where the numerical results overestimate the actual values of the extent these differences can be attributed at least partially to the resolution of the dem data and uncertainties associated to values of cn the right panel of fig 7 shows a detailed image of the area upstream near bridge 2 where the orange polygons refer to the buildings located within this area it is important to notice that this area corresponds to the sector of the city most affected by the flood during this event the blue area corresponds to the maximum flood extent situation obtained with iber confirming that it reached buildings located in both riverbanks of calamón and rivillas rivers therefore we can conclude that iber reproduce quite well the situation registered during the event however flash flood events evolve quite rapidly and therefore require a more dynamic assessment of the areas affected preferably at the sub hourly temporal scale fig 8 shows such evolution of the flood event water depth maps obtained with iber from 10 20p m to 10 30p m on 5 november flows of rivillas and calamón rivers arrive at urban areas of badajoz fig 8a flow of rivillas river reaches the canalisation before flow of calamón river near 0 45 a m on 6 november flow of rivillas impacts into bridge 2 fig 8b while flow of calamón overtop bridge 4 then flow from rivillas returns upstream following the calamón riverbed fig 8c at 1 00 a m on 6 november flows of rivillas and calamón impact near bridge 5 this causes the flood on the right and left riverbanks of calamón river fig 8d the maximum extent of the flood can be observed at 2 30 3 00 a m on 6 november fig 8e in addition to the evolution of the water depth maps the evolution of water depth at five control points is represented in fig 9 a control points cp1 and cp2 also depicted in fig 6 and cp5 and cp6 are located upstream near bridge 2 and control point cp3 is located downstream near bridge 2 cp1 is located in the riverbed of calamón river while cp2 and cp3 are located in rivillas riverbed control points cp4 and cp5 are located at the beginning of the canalisation of calamón and rivillas rivers respectively fig 9b shows that flow arrives downstream bridge 2 at the beginning of the simulation at cp3 this flow comes from guadiana river at around 1 00 a m on 6 november flows from rivillas and calamón reach control points cp1 and cp2 respectively from 9 00 a m on 6 november water depth is higher upstream bridge 2 than downstream this bridge this effect is due to the bridge 2 acting as a barrier during the event fig 9c confirms that flow from calamón arrives at the starting point of the canalisation i e before the flow from rivillas river this is because the beginning of canalisation of calamón river is located farther away from bridge 2 than the start of canalisation of rivillas river a temporal flow chart of the numerical model evolution vs field data obtained from testimonies is shown in fig 10 time evolution obtained through testimonies is quite similar to those obtained in the numerical simulations carried out with iber some discrepancy is observed in the timing for the maximum peak flow whereas timing obtained from field data is 1 30 a m on 6 november the corresponding timing from numerical simulations is situated near 3 a m nevertheless it is known that testimonies have some difficulty in defining exact timing of peak flow values during the event this difficulty results since they can be affected by subjective perceptions as well as the lack of objective references to measure peak values it is worth mentioning that it was night the electric lighting stopped working and the weather conditions were adverse with rain and strong gusts of wind moreover people do not usually stand at the same place during the entire event and this can lead to misleading perceptions to define accurately the time of peak flow once the numerical model has been validated to reproduce such event a more in depth analysis was carried out the characteristics of the implementation of iber allows an analysis of a series of hypothetical flood scenarios considering different conditions it can be stated from previous analysis that there are three main causes for the dramatic consequences of this event first the large amount of precipitation registered from 5 00p m on 5 november to 1 00 a m on 6 november second the high levels of antecedent soil moisture content due the continuous precipitation registered during the previous days of the event third the poor maintenance and cleaning conditions of most bridges that quickly become partially blocked during the event the precipitation and previous conditions of the soil are distributed over the entire basin of the river being related with meteorological conditions out of control of water management institutions on the other hand the conditions of the bridges only affect the urban area of the calamón and rivillas rivers and are directly controlled by water management institutions by means of a correct maintenance of these structures to analyse the effect of the conditions of the bridges in the flood event eight hypothetical scenarios with different conditions have been defined three different hyetographs have been defined starting from the actual one and reducing it a factor equal to 75 50 and 25 therefore in this study we analyse four hyetographs h100 h75 h50 and h25 the probability of occurrence of these three last hyetographs is much higher than the probability associated to h100 for each hyetograph two different conditions were analysed bridges partially blocked b b and free bridges f b the rest of conditions associated to the event i e the time distribution of the precipitation and the antecedent moisture soil content remain equal to the actual event for each scenario we obtain the maximum hazard maps according to cox et al 2010 and also the time evolution of the water depth at control point cp1 see fig 6 this control point is located in the area most affected during the actual flood event and therefore it can be considered representative to analyse the consequences of the event the results of this analysis are shown in fig 11 red areas of panels a b c and d stand for maximum hazard maps obtained with b b condition for the four different analysed hyetographs and green areas of these panels refer to maximum hazard maps cox et al 2010 obtained with f b conditions for h100 h75 h50 and h25 hyetographs respectively red and green lines of panels e f g and h stand for time evolution of water depth with b b and f b respectively for the analysed hyetographs maximum hazard maps obtained for h100 with b b and f b conditions fig 11a are similar to each other fig 11e shows that peak values of water depth obtained for b b and f b are also similar 8 1 and 7 6 m respectively difference 6 this is due the high total amount of precipitation accumulated during the event for h100 the recessing part of curve depicted in fig 11e obtained with b b is lower than the recessing part of the curve obtained with f b condition this effect increases the negative effects of the event since it prevents the access of rescue services to affected areas results obtained for h75 are similar to those obtained for h100 flooded areas are similar for b b and f b fig 11b in this case peak values of water depth obtained with b b and f b are 7 1 m and 6 m respectively therefore in this case the difference between peak values is near 15 this indicates that the effect of blocked bridges is greater that with h100 for h50 flooded areas downstream bridge 2 obtained for b b and f b fig 11c are similar but the difference between the flooded areas upstream bridge 2 are evident fig 11g shows that peak value of water depth for b b is much higher 6 3 m than peak value obtained with f b condition 3 7 m the difference between these values 2 6 m is greater than the difference between peak values obtained with the same conditions but for h100 and h75 0 6 m and 1 2 m respectively and represents a drop of almost 45 this stresses that for this case h50 the effect of blocked bridges increases its influence in the flooded areas versus the amount of water registered during the precipitation event this effect is even more obvious for h25 as in this case flooded areas obtained with b b fig 11d conditions are much higher than those obtained with f b peak value of water depth obtained with b b is near 5 m while peak value obtained with f b conditions is less than 1 m corresponding to 80 less finally the values of wet areas obtained with the four analysed hyetographs and the b b and f b conditions in the urban area of the rivillas river are depicted in fig 12 for both conditions wet areas increase as the amount of precipitation increases wet areas obtained with b b conditions are 31 ha 50 ha 65 ha and 73 ha for each hyetograph while for corresponding f b conditions wet areas are 12 ha 30 ha 56 ha and 67 ha the difference of wet areas obtained with b b and f b conditions decreases as peak values of hyetographs increases for h25 and h50 the difference is equal to 19 ha and 20 ha respectively for h75 is equal to 9 ha and for h100 is equal to 6 ha this means that the effect of the blocked bridges decreases as the amount of precipitation increases this is in accordance with the results of water depth 5 conclusions in this work the numerical simulation of the flood event registered in badajoz on 5th and 6th in november 1997 was carried out by means of the iber this event corresponds to one of the most catastrophic urban flash floods registered in the iberian peninsula in the 20th century the unprecedented level of this event is summed up by the amount of precipitation registered during the event the number of fatalities 21 and the economic losses the numerical simulations carried out with iber allows undertaking the coupled analysis the urban area and the rest of the basin of the rivillas river the urban area of the river is characterized by the canalization of the main stream of the rivillas river as well as of the main tributary of this river i e the calamón river in this urban area the existence of several bridges and buildings had a crucial impact in the evolution and the consequences of the urban flood especially for medium intensity hydrographs the numerical results obtained with iber reproduce quite well the event registered in 1997 both the extension and the temporal evolution of the flood compared with field data also peak values of water depths are in agreement with data provided by testimonies one of the conclusions of this work is that with a similar deficient maintenance the same temporal evolution and maximum flooded areas recorded during the past event would be reached today obviously the demolition of the houses located near the river bed would minimize the negative effects under a similar event according to the analysis there were three main factors that increased the negative effects of the event 1 the amount of precipitation registered from 5 00p m on 5 november to 1 00 a m on 6 november 2 the high levels of antecedent soil moisture content 3 the poor maintenance condition of bridges partially blocked during the event a series of hypothetical scenarios were considered to assess the effect of precipitation and the maintenance conditions of the bridges during the event four hyetographs h100 h75 h50 and h25 and two maintenance conditions partially blocked or free bridges were analysed the results show that a significant part of the area can be flooded even with low intensity hyetographs especially when the span of the bridge is blocked the flooded area is much smaller when the bridge is not blocked in summary the work has highlighted iber s ability to reproduce extreme flash flood events in urban areas moreover the model allowed designing hypothetical scenarios that can help to a better maintenance of hydraulic structures this can constitute a powerful tool within the present framework of climate change credit authorship contribution statement josé gonzález cao conceptualization formal analysis investigation methodology resources visualization writing original draft diego fernández nóvoa conceptualization formal analysis investigation methodology orlando garcía feal formal analysis investigation methodology jose r figueira conceptualization formal analysis investigation methodology resources josé m vaquero conceptualization resources supervision writing review editing ricardo m trigo conceptualization resources supervision writing review editing moncho gómez gesteira conceptualization formal analysis investigation supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was partially supported by under project risc ml code 0034 risc ml 6 e co funded by the european regional development fund erdf and by xunta de galicia under project ed431c 2021 44 programa de consolidación e estruturación de unidades de investigación grupos de referencia competitiva dfn was supported by xunta de galicia through a post doctoral grant ed481b 2021 108 jmv was supported by the economy and infrastructure counselling of the junta of extremadura through project ib20080 and grants gr21080 co financed by the european regional development fund the aerial pictures used in this work are courtesy of the spanish ign instituto geográfico nacional and part of the pnoa plan nacional de ortofotografía aérea program 
3324,splash is a widely studied phenomenon partly forming the phenomenon of erosion until now tracing the origin of splash water was a highly error prone or impossible task we propose a method for tracking splash water by means of stable isotope ratio mass spectrometry irms analysis we tested the method on a water water model checking the effect of drop height water layer thickness and the effect of water evaporation it turns out that the drop height and the thickness of the water layer have practically no effect on the origin of the water in the splash and all the water comes from the vessel not from the drops the only exception is when a thin layer of water is impacted with a drop in which case 23 of the water also comes from the drop the proposed method could be used to study more complex systems such as water soil keywords water splash soil splash isotope labelling splash tracing abbreviations irms isotope ratio mass spectrometry htc high temperature conversion vsmow vienna standard mean ocean water 1 introduction soil splash is the first stage of the water erosion process and it occurs when a droplet of water hits the soil surface marzen and iserloh 2021 serdar sari and taşkın öztaş 2021 this in turn causes several phenomena the detachment and displacement of soil particles erpul et al 2021 breakdown of aggregate fernández raga et al 2017 transport of bacteria wang et al 2018 and pollution ghadiri et al 2007 as well as surface runoff and crust formation beczek et al 2020 the splash phenomenon has been widely studied by various methods including monitoring the mass of transported soil beczek et al 2019 and splash distance analysis with different kinds of traps as well as the image analysis of intercepted particles long et al 2014 marzen et al 2016 other research has addressed soil aggregate breakdown wuddivira et al 2009 xiao et al 2017 as well as crater mazur et al 2020 wyser et al 2019 and crown formation after drop impact beczek et al 2017 marengo et al 2011 multiple researchers have used high speed cameras and particle tracking velocimetry for monitoring soil splash dynamics on various soil parameters ahn et al 2013 beczek et al 2020 long et al 2014 sochan et al 2019 one way of studying the splash phenomenon and the subsequent run off processes could be to use labelled water so far the labelling of water has been associated with colouring it rodriguez and mesler 1985 for example used water coloured with a food dye to examine how the liquids mixed during a splash manzello and yang 2002 also performed a similar experiment with dye used to track droplets in the ejecta additionally ersoy and eslamian 2019 used water dyed with methylene blue and methylene orange dyes the use of dyes to label water however has a drawback that in some studies can significantly bias the results the addition of dyes can significantly alter the surface tension of the water and to a lesser extent its density and viscosity therefore it is worth looking for other markers water enriched with a stable isotope of hydrogen deuterium can form such a marker an increased concentration of d2o in water is relatively easy to monitor using isotope ratio mass spectrometry wu et al 2020 this technique has been successfully applied in environmental stelmach et al 2016 geomorphological keil et al 2010 and environmental engineering onodera et al 2021 and paleolimnetic archaeological apolinarska and kurzawska 2020 and energy science wang et al 2020 as well as medical civil et al 2021 and microbiological weber et al 2021 research it has been used in very complex systems such as for example in metabolic studies in animals simonato et al 2022 and tracing water sources in plant tissues barbeta et al 2022 it is also employed in food origin tracing boito et al 2021 and in forensic science valenzuela et al 2021 however to the best of the authors knowledge until now no stable isotopes have been adopted to monitor the splash phenomenon this aim of this study was to show for the first time the possibility of using stable isotope labelling to monitor the splash phenomenon in a simple fully reproducible system water drop impacts on water surfaces of various depths it was performed through the labelling of water both water in a drop form and in separate experiments in plain surface water by deuterium and monitoring the isotope ratio between 1h and 2h in splashed droplets 2 material and methods water labelled with a higher concentration of deuterium henceforth referred to as labelled water was prepared through the evaporation of demineralized water henceforth referred to as plain water the initial deuterium content was δ2h 10 81 while after evaporation approximately two months it was δ2h 169 04 such a change in deuterium content was sufficient to monitor the mixing of labelled water with tap water but at the same time was small enough to practically not change the density of the water relative change 3 32 10 5 g cm 3 2 1 splash experiments water drops with a diameter of 4 2 mm were created using a peristaltic pump dosing water through a glass capillary the drops were created from plain water or labelled water depending on the variants described below the water dosing system was mounted on a vertically moving platform and drops fell freely from two separate heights 1 5 m and 7 m the impact velocity of the drops was about 4 99 m s 1 and 8 54 m s 1 respectively and the resulting kinetic energy of the drops falling from 1 5 m was equal to 0 49 mj and from 7 m 1 42 mj the selection of a 7 m drop falling height was because the impact velocity of the used drop was close to the terminal velocity observed during natural events about 95 of terminal velocity according to epema and riezebos 1983 in turn a height of 1 5 m was selected because this height was typical for drops falling in a throughfall phenomenon brandt 1989 levia et al 2017 the drops fell into a vessel with a diameter of 100 mm six distinct water depths were used in the vessel 1 7 3 5 7 0 14 0 35 0 and 55 0 mm the smallest depth was limited by the water surface tension the biggest depth was selected to ensure that the water layer was large enough to avoid the influence of the bottom of the vessel on the splash the smaller the thickness of the water layer the greater the influence of the bottom of the vessel on the course of the splash event for future comparative reasons taking into account the drop diameter the dimensionless parameter h cossali et al 1997 rioboo et al 2003 was calculated for every water layer depth equation 1 corresponding values of h and water depths are shown in table 1 1 h w h d d where wh water layer height mm dd drop diameter mm because the aim of this work was to propose a new isotope method for monitoring splash a combination of plain labelled variants water drop fall heights and surface water depths were chosen to represent all the most important methodological aspects the experiment was conducted in three parts i to check the impact of the drop fall height plain drop water water forming drops henceforth referred to as drop water and labelled surface water water in the vessel henceforth referred to as surface water were used ii to check the impact of the water layer depth both labelled drop water and plain surface water in the vessel were employed iii to check whether collection time i e evaporation time has an impact on splashed droplets the isotopic composition of two additional variants was checked a plain drop water plain surface water b labelled drop water labelled surface water to obtain the proper amount of water from the ejected droplets splashed water henceforth referred to as droplets unlike falling water henceforth referred to as drops each measurement treated as one repetition consisted of 30 successive drops hitting the water surface the effect of this water addition to the vessel on the isotopic composition of the whole of the water in the vessel was found to be negligible the splashed water droplets were collected into a dry open vessel and as quickly as possible using a 0 25 ml microsyringe sge analytical australia were transferred to a 2 ml vial with a 0 22 ml microinsert and tightly closed to avoid evaporation in order to assess to what extent the phenomenon of water fractionation during evaporation influences the measurement error using this method of deuterium labelled water δ2h measurements of the splashed water collected in subsequent time intervals were carried out the first collection was carried out 8 min min after the first of the 30 drop impacts onto the surface water and then every two and half minutes for a total of 18 min five samplings the initial 8 min was the time it took for all 30 drops to hit the water surface and for splash water to be collected for the first time the time intervals between drops were chosen to ensure that the water surface stabilizes between impacts the time needed to collect the right amount of water in subsequent samplings was approximately 2 min the collected water was then used for isotopic analysis 2 2 isotopic analysis isotope measurements were conducted on a delta v advantage isotope ratio mass spectrometer irms coupled with an elemental analyzer flash 2000ht thermo scientific usa a high temperature conversion reactor htc was used temperature 1420 c carrier flow 90 ml min 1 the δ2h value of the water was expressed vs vsmow vienna standard mean ocean water the isotope measurements were performed in eight replications in the experiment with plain water to counter the fractionation effects during evaporation the fractionation factor was calculated from the measured δ values and again recalculated to δ for comparative reasons according to the formulas adapted from the work of friedman and o neil 1977 1 α 1 δ 2 h tx 1000 1 δ 2 h 1000 2 δ cf 10 3 l n α 3 δ 2 h txc δ 2 h tx δ cf where α fractionation factor δ2htx measured δ value of hydrogen in splashed droplets in the variant in which plain water drops hit plain surface water δ2h measured δ value of hydrogen in drops as well plain surface water δ cf correction for measured δ2htx value δ2htxc corrected δ2htx value the ratio between the plain and labelled water in splash droplets was calculated according to equation 4 adapted from the iaea manual international atomic energy agency 2009 4 fraction l a b e l l e d δ mix δ u δ l δ u where δl measured δ value of hydrogen in labelled water δu measured δ value of hydrogen in plain water δmix measured δ value of hydrogen in splashed water 2 3 statistical analysis statistical analyses were performed using statistica 13 1 software tibco software inc usa one way anova analysis of variance as well as shapiro wilk normality tests and a tukey s post hoc test with a significance level of p 0 05 were performed 3 results 3 1 impact of drop fall height the influence of water drop fall height on drop and surface water mixing on the basis of the isotopic composition of splashed droplets was checked in the first stage of the investigations the plain drop water labelled water in a vessel variant was used in this stage and the depth of the water was 55 mm the results are presented in fig 1 two important observations can be made by analysing fig 1 i the fall height of the plain water drop into the deep surface water did not influence the δ2h of splashed water p 0 05 therefore we used only one height in the following stages we chose the 7 m because the impact velocity of such drops was nearly the same as in natural rainfall events ii the δ2h of splashed water was the same there were no statistically significant difference as the δ2h of labelled surface water 3 2 impact of water layer depth the labelled drop water plain surface water variant was used in the second stage of investigations for practical reasons a lower volume of labelled water was required this stage was extended to measure the impact of drops on surface water of various depths the results of this experiment are shown in fig 2 it can be seen in fig 2 that apart from the water layer depth of 0 4 1 7 mm there were no differences in the δ2h values of splashed droplets for all other water layer depths p 0 05 the δ2h of the droplets splashed in the case of the 0 4 water layer was significantly p 0 05 enriched in deuterium in relation to the splashed droplets in tests of other water depths however the deuterium content in all the splashed water was much smaller than in the falling water drop and at the same time significantly higher than in the plain surface water this is contrary to the observations from fig 1 where the splash from plain water droplets impacting labelled surface water was not significantly different 3 3 collection evaporation time impact since the water droplets collected after the splash were very small and thus had an extensive surface in relation to their volume there was a suspicion that from the time of splash to the time of collection for analysis the water from the ejected droplets could evaporate and thus the fractionization of hydrogen isotopes could take place kakiuchi and matsuo 1979 to estimate the influence of this phenomenon on the results presented above we investigated the potential changes in the δ2h of splashed water depending on the time interval between the splash and the moment of droplet collection this part of the investigation was carried out in two variants i splash of plain drop water plain surface water and ii labelled drop water labelled surface water the results are presented in fig 3 a difference can be seen in the changes of the two variants presented in fig 3 there is a marginally upward trend in the case of labelled water containing more deuterium atoms fig 3b while there is a visible uptrend in the case of the plain water variant fig 3a 3 4 share of labelled water in splashed droplets the share of labelled water in splashed droplets after the labelled drop water fell from a height of 7 m for different plain surface water depths fig 4 was calculated according to equation 4 data presented in fig 4 are for the same variant as in fig 2 but they were corrected according to equation 3 for comparison the uncorrected data i e calculated directly from the δ2h presented in fig 2 are also shown in fig 4 after analysing fig 4 two different observations can be seen the first one is methodological it is important to take into account the fractionation of deuterium during evaporation when plain water is investigated the second describes the splash phenomenon itself when the depth of the surface water is very small water in the ejected droplets comes from drop and surface water in the case of our experiment for the depth 0 4 1 7 mm the lowest depth which was able to be obtained because of surface water tension the share of drop water was slightly less than 25 for all the other tested surface water depths this was enough for practically all the water in the droplets to come from the water surface 4 discussion the fact that the δ2h of splashed water was the same for both heights fig 1 indicates that for a sufficient depth of the water layer the change in droplet energy does not affect the origin of the droplets ejected by the splash on the other hand sochan et al 2018 showed that there are significant differences between drop height variants in terms of the course of the splash including the corona shape size and number of splashed droplets but those differences do not have to be connected to the water origin the results presented in fig 1 plain drop water labelled surface water variant indicate that the whole of the water in the droplets comes from the surface water however the results from fig 2 obtained for the reverse layout labelled drop water plain surface water variant seem to lead to an apparently different conclusion water in the droplets comes both from the drop and surface water an explanation for this apparent contradiction is possible when taking into account the phenomenon of deuterium fractionation during water evaporation fig 4 the fractionation of deuterium during water evaporation is well known cappa 2003 horita and wesolowski 1994 kakiuchi and matsuo 1979 as h h bonds are broken more easily than d d bonds it is also known that the isotopic ratio 1h 2h changes up until the moment equilibrium is established kendall and mcdonnell 1998 there was no equilibrium in our plain water and therefore the δ2h in this system changed fig 3a however in our labelled water obtained via a long process of evaporation this equilibrium had been established fig 3b because this study is a methodological one for the convenience of those who wish to use the method of deuterium labelled water to analyse the splash phenomenon it would be useful to indicate the water evaporation time for obtaining the labelled water at an equilibrium of 1h 2h however such an indication is not possible this duration will be dependent on i the initial δ2h of the plain water ii the volume of water to be evaporated iii the difference between the water and air temperatures and iv air humidity therefore the δ2h after evaporation should be tested each time returning to the analysis of where the splashed water in the droplets comes from both the data presented in fig 2 and fig 4 corrected data lead to the conclusion that nearly all the water transported due to the splash comes from the surface water only in the case of very shallow surface water regarding our investigations the smallest water depth that it was possible to obtain because of surface water tension does the water from the falling drop form part of the ejected water droplets simply doubling the depth to 0 8 results in the fact that the splashed water in the droplets comes almost completely from the surface water there is no possibility to discuss our results with reference to other experimental works because to the best of the authors knowledge this is the first experimental confirmation of the phenomenon the described method has many potential advantages which could be useful in environmental studies as the tracer used is water the method does not change the physical properties of the system or affect biochemical processes occurring in the sample and is also safe for the environment the use of irms coupled with an htc reactor also makes the method very accurate and sensitive the analyses are relatively fast and do not require complicated preparation in combination with high speed cameras the method will provide the possibility to actually trace the splash and to infer the very moment of collision between the falling drop and the sample surface which would be useful in refining splash phenomenon models unfortunately the method also has several limitations and potential methodological problems hydrogen is a labile element and easily fractionates depending on temperature and humidity this makes it necessary to ensure stable measurement conditions and therefore limits the possibilities of field applications at this stage it is also difficult to estimate the influence of a more complex system e g soil on the change in the hydrogen isotopic ratio and thus the possibility of applying the investigated method to more complex systems this requires further research in addition the equipment required for isotopic determination is rather expensive complex and needs skilled operators 5 conclusions we showed a new method based on labelled water to monitor the splash of water droplets when a falling water drop hits the surface of water in the model system studied all the water making up the splash comes from the surface water and only in the specific case of a very thin layer of surface water in the vessel does it come partially from the falling droplet the height from which the drop falls has no effect on the isotopic ratio of the water in the splash the use of the presented method requires a few prerequisites such as stable temperature and air humidity conditions as well as that the correction for water evaporation during the experiment be taken into account the presented method seems promising for use in splash experiments but its wider application to more complex systems requires further investigation it is possible that the use of d2o labelled water can be useful for tracing and determining the origin of splashed water i e to what extent do the water from the falling drop and the water in the soil pores or water that constitutes a water surface mix with each other and where does the water forming droplets after the splash come from from the drop or from the surface the same analysis could be used for tracing water splash on plant leaves which might be employed in the tracking of pathogens as well as plant protection applications 6 data availability the data that support the findings of this study are available from the corresponding author upon reasonable request credit authorship contribution statement c polakowski conceptualization validation formal analysis investigation writing original draft writing review editing visualization m beczek validation investigation writing review editing r mazur validation investigation writing review editing a sochan formal analysis writing review editing m ryżak formal analysis resources writing review editing funding acquisition a bieganowski conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was partially financed by national science centre poland https www ncn gov pl in the frame of project no 2018 31 n st10 01757 the funder had no role in the study design data collection and analysis decision to publish or preparation of the manuscript 
3324,splash is a widely studied phenomenon partly forming the phenomenon of erosion until now tracing the origin of splash water was a highly error prone or impossible task we propose a method for tracking splash water by means of stable isotope ratio mass spectrometry irms analysis we tested the method on a water water model checking the effect of drop height water layer thickness and the effect of water evaporation it turns out that the drop height and the thickness of the water layer have practically no effect on the origin of the water in the splash and all the water comes from the vessel not from the drops the only exception is when a thin layer of water is impacted with a drop in which case 23 of the water also comes from the drop the proposed method could be used to study more complex systems such as water soil keywords water splash soil splash isotope labelling splash tracing abbreviations irms isotope ratio mass spectrometry htc high temperature conversion vsmow vienna standard mean ocean water 1 introduction soil splash is the first stage of the water erosion process and it occurs when a droplet of water hits the soil surface marzen and iserloh 2021 serdar sari and taşkın öztaş 2021 this in turn causes several phenomena the detachment and displacement of soil particles erpul et al 2021 breakdown of aggregate fernández raga et al 2017 transport of bacteria wang et al 2018 and pollution ghadiri et al 2007 as well as surface runoff and crust formation beczek et al 2020 the splash phenomenon has been widely studied by various methods including monitoring the mass of transported soil beczek et al 2019 and splash distance analysis with different kinds of traps as well as the image analysis of intercepted particles long et al 2014 marzen et al 2016 other research has addressed soil aggregate breakdown wuddivira et al 2009 xiao et al 2017 as well as crater mazur et al 2020 wyser et al 2019 and crown formation after drop impact beczek et al 2017 marengo et al 2011 multiple researchers have used high speed cameras and particle tracking velocimetry for monitoring soil splash dynamics on various soil parameters ahn et al 2013 beczek et al 2020 long et al 2014 sochan et al 2019 one way of studying the splash phenomenon and the subsequent run off processes could be to use labelled water so far the labelling of water has been associated with colouring it rodriguez and mesler 1985 for example used water coloured with a food dye to examine how the liquids mixed during a splash manzello and yang 2002 also performed a similar experiment with dye used to track droplets in the ejecta additionally ersoy and eslamian 2019 used water dyed with methylene blue and methylene orange dyes the use of dyes to label water however has a drawback that in some studies can significantly bias the results the addition of dyes can significantly alter the surface tension of the water and to a lesser extent its density and viscosity therefore it is worth looking for other markers water enriched with a stable isotope of hydrogen deuterium can form such a marker an increased concentration of d2o in water is relatively easy to monitor using isotope ratio mass spectrometry wu et al 2020 this technique has been successfully applied in environmental stelmach et al 2016 geomorphological keil et al 2010 and environmental engineering onodera et al 2021 and paleolimnetic archaeological apolinarska and kurzawska 2020 and energy science wang et al 2020 as well as medical civil et al 2021 and microbiological weber et al 2021 research it has been used in very complex systems such as for example in metabolic studies in animals simonato et al 2022 and tracing water sources in plant tissues barbeta et al 2022 it is also employed in food origin tracing boito et al 2021 and in forensic science valenzuela et al 2021 however to the best of the authors knowledge until now no stable isotopes have been adopted to monitor the splash phenomenon this aim of this study was to show for the first time the possibility of using stable isotope labelling to monitor the splash phenomenon in a simple fully reproducible system water drop impacts on water surfaces of various depths it was performed through the labelling of water both water in a drop form and in separate experiments in plain surface water by deuterium and monitoring the isotope ratio between 1h and 2h in splashed droplets 2 material and methods water labelled with a higher concentration of deuterium henceforth referred to as labelled water was prepared through the evaporation of demineralized water henceforth referred to as plain water the initial deuterium content was δ2h 10 81 while after evaporation approximately two months it was δ2h 169 04 such a change in deuterium content was sufficient to monitor the mixing of labelled water with tap water but at the same time was small enough to practically not change the density of the water relative change 3 32 10 5 g cm 3 2 1 splash experiments water drops with a diameter of 4 2 mm were created using a peristaltic pump dosing water through a glass capillary the drops were created from plain water or labelled water depending on the variants described below the water dosing system was mounted on a vertically moving platform and drops fell freely from two separate heights 1 5 m and 7 m the impact velocity of the drops was about 4 99 m s 1 and 8 54 m s 1 respectively and the resulting kinetic energy of the drops falling from 1 5 m was equal to 0 49 mj and from 7 m 1 42 mj the selection of a 7 m drop falling height was because the impact velocity of the used drop was close to the terminal velocity observed during natural events about 95 of terminal velocity according to epema and riezebos 1983 in turn a height of 1 5 m was selected because this height was typical for drops falling in a throughfall phenomenon brandt 1989 levia et al 2017 the drops fell into a vessel with a diameter of 100 mm six distinct water depths were used in the vessel 1 7 3 5 7 0 14 0 35 0 and 55 0 mm the smallest depth was limited by the water surface tension the biggest depth was selected to ensure that the water layer was large enough to avoid the influence of the bottom of the vessel on the splash the smaller the thickness of the water layer the greater the influence of the bottom of the vessel on the course of the splash event for future comparative reasons taking into account the drop diameter the dimensionless parameter h cossali et al 1997 rioboo et al 2003 was calculated for every water layer depth equation 1 corresponding values of h and water depths are shown in table 1 1 h w h d d where wh water layer height mm dd drop diameter mm because the aim of this work was to propose a new isotope method for monitoring splash a combination of plain labelled variants water drop fall heights and surface water depths were chosen to represent all the most important methodological aspects the experiment was conducted in three parts i to check the impact of the drop fall height plain drop water water forming drops henceforth referred to as drop water and labelled surface water water in the vessel henceforth referred to as surface water were used ii to check the impact of the water layer depth both labelled drop water and plain surface water in the vessel were employed iii to check whether collection time i e evaporation time has an impact on splashed droplets the isotopic composition of two additional variants was checked a plain drop water plain surface water b labelled drop water labelled surface water to obtain the proper amount of water from the ejected droplets splashed water henceforth referred to as droplets unlike falling water henceforth referred to as drops each measurement treated as one repetition consisted of 30 successive drops hitting the water surface the effect of this water addition to the vessel on the isotopic composition of the whole of the water in the vessel was found to be negligible the splashed water droplets were collected into a dry open vessel and as quickly as possible using a 0 25 ml microsyringe sge analytical australia were transferred to a 2 ml vial with a 0 22 ml microinsert and tightly closed to avoid evaporation in order to assess to what extent the phenomenon of water fractionation during evaporation influences the measurement error using this method of deuterium labelled water δ2h measurements of the splashed water collected in subsequent time intervals were carried out the first collection was carried out 8 min min after the first of the 30 drop impacts onto the surface water and then every two and half minutes for a total of 18 min five samplings the initial 8 min was the time it took for all 30 drops to hit the water surface and for splash water to be collected for the first time the time intervals between drops were chosen to ensure that the water surface stabilizes between impacts the time needed to collect the right amount of water in subsequent samplings was approximately 2 min the collected water was then used for isotopic analysis 2 2 isotopic analysis isotope measurements were conducted on a delta v advantage isotope ratio mass spectrometer irms coupled with an elemental analyzer flash 2000ht thermo scientific usa a high temperature conversion reactor htc was used temperature 1420 c carrier flow 90 ml min 1 the δ2h value of the water was expressed vs vsmow vienna standard mean ocean water the isotope measurements were performed in eight replications in the experiment with plain water to counter the fractionation effects during evaporation the fractionation factor was calculated from the measured δ values and again recalculated to δ for comparative reasons according to the formulas adapted from the work of friedman and o neil 1977 1 α 1 δ 2 h tx 1000 1 δ 2 h 1000 2 δ cf 10 3 l n α 3 δ 2 h txc δ 2 h tx δ cf where α fractionation factor δ2htx measured δ value of hydrogen in splashed droplets in the variant in which plain water drops hit plain surface water δ2h measured δ value of hydrogen in drops as well plain surface water δ cf correction for measured δ2htx value δ2htxc corrected δ2htx value the ratio between the plain and labelled water in splash droplets was calculated according to equation 4 adapted from the iaea manual international atomic energy agency 2009 4 fraction l a b e l l e d δ mix δ u δ l δ u where δl measured δ value of hydrogen in labelled water δu measured δ value of hydrogen in plain water δmix measured δ value of hydrogen in splashed water 2 3 statistical analysis statistical analyses were performed using statistica 13 1 software tibco software inc usa one way anova analysis of variance as well as shapiro wilk normality tests and a tukey s post hoc test with a significance level of p 0 05 were performed 3 results 3 1 impact of drop fall height the influence of water drop fall height on drop and surface water mixing on the basis of the isotopic composition of splashed droplets was checked in the first stage of the investigations the plain drop water labelled water in a vessel variant was used in this stage and the depth of the water was 55 mm the results are presented in fig 1 two important observations can be made by analysing fig 1 i the fall height of the plain water drop into the deep surface water did not influence the δ2h of splashed water p 0 05 therefore we used only one height in the following stages we chose the 7 m because the impact velocity of such drops was nearly the same as in natural rainfall events ii the δ2h of splashed water was the same there were no statistically significant difference as the δ2h of labelled surface water 3 2 impact of water layer depth the labelled drop water plain surface water variant was used in the second stage of investigations for practical reasons a lower volume of labelled water was required this stage was extended to measure the impact of drops on surface water of various depths the results of this experiment are shown in fig 2 it can be seen in fig 2 that apart from the water layer depth of 0 4 1 7 mm there were no differences in the δ2h values of splashed droplets for all other water layer depths p 0 05 the δ2h of the droplets splashed in the case of the 0 4 water layer was significantly p 0 05 enriched in deuterium in relation to the splashed droplets in tests of other water depths however the deuterium content in all the splashed water was much smaller than in the falling water drop and at the same time significantly higher than in the plain surface water this is contrary to the observations from fig 1 where the splash from plain water droplets impacting labelled surface water was not significantly different 3 3 collection evaporation time impact since the water droplets collected after the splash were very small and thus had an extensive surface in relation to their volume there was a suspicion that from the time of splash to the time of collection for analysis the water from the ejected droplets could evaporate and thus the fractionization of hydrogen isotopes could take place kakiuchi and matsuo 1979 to estimate the influence of this phenomenon on the results presented above we investigated the potential changes in the δ2h of splashed water depending on the time interval between the splash and the moment of droplet collection this part of the investigation was carried out in two variants i splash of plain drop water plain surface water and ii labelled drop water labelled surface water the results are presented in fig 3 a difference can be seen in the changes of the two variants presented in fig 3 there is a marginally upward trend in the case of labelled water containing more deuterium atoms fig 3b while there is a visible uptrend in the case of the plain water variant fig 3a 3 4 share of labelled water in splashed droplets the share of labelled water in splashed droplets after the labelled drop water fell from a height of 7 m for different plain surface water depths fig 4 was calculated according to equation 4 data presented in fig 4 are for the same variant as in fig 2 but they were corrected according to equation 3 for comparison the uncorrected data i e calculated directly from the δ2h presented in fig 2 are also shown in fig 4 after analysing fig 4 two different observations can be seen the first one is methodological it is important to take into account the fractionation of deuterium during evaporation when plain water is investigated the second describes the splash phenomenon itself when the depth of the surface water is very small water in the ejected droplets comes from drop and surface water in the case of our experiment for the depth 0 4 1 7 mm the lowest depth which was able to be obtained because of surface water tension the share of drop water was slightly less than 25 for all the other tested surface water depths this was enough for practically all the water in the droplets to come from the water surface 4 discussion the fact that the δ2h of splashed water was the same for both heights fig 1 indicates that for a sufficient depth of the water layer the change in droplet energy does not affect the origin of the droplets ejected by the splash on the other hand sochan et al 2018 showed that there are significant differences between drop height variants in terms of the course of the splash including the corona shape size and number of splashed droplets but those differences do not have to be connected to the water origin the results presented in fig 1 plain drop water labelled surface water variant indicate that the whole of the water in the droplets comes from the surface water however the results from fig 2 obtained for the reverse layout labelled drop water plain surface water variant seem to lead to an apparently different conclusion water in the droplets comes both from the drop and surface water an explanation for this apparent contradiction is possible when taking into account the phenomenon of deuterium fractionation during water evaporation fig 4 the fractionation of deuterium during water evaporation is well known cappa 2003 horita and wesolowski 1994 kakiuchi and matsuo 1979 as h h bonds are broken more easily than d d bonds it is also known that the isotopic ratio 1h 2h changes up until the moment equilibrium is established kendall and mcdonnell 1998 there was no equilibrium in our plain water and therefore the δ2h in this system changed fig 3a however in our labelled water obtained via a long process of evaporation this equilibrium had been established fig 3b because this study is a methodological one for the convenience of those who wish to use the method of deuterium labelled water to analyse the splash phenomenon it would be useful to indicate the water evaporation time for obtaining the labelled water at an equilibrium of 1h 2h however such an indication is not possible this duration will be dependent on i the initial δ2h of the plain water ii the volume of water to be evaporated iii the difference between the water and air temperatures and iv air humidity therefore the δ2h after evaporation should be tested each time returning to the analysis of where the splashed water in the droplets comes from both the data presented in fig 2 and fig 4 corrected data lead to the conclusion that nearly all the water transported due to the splash comes from the surface water only in the case of very shallow surface water regarding our investigations the smallest water depth that it was possible to obtain because of surface water tension does the water from the falling drop form part of the ejected water droplets simply doubling the depth to 0 8 results in the fact that the splashed water in the droplets comes almost completely from the surface water there is no possibility to discuss our results with reference to other experimental works because to the best of the authors knowledge this is the first experimental confirmation of the phenomenon the described method has many potential advantages which could be useful in environmental studies as the tracer used is water the method does not change the physical properties of the system or affect biochemical processes occurring in the sample and is also safe for the environment the use of irms coupled with an htc reactor also makes the method very accurate and sensitive the analyses are relatively fast and do not require complicated preparation in combination with high speed cameras the method will provide the possibility to actually trace the splash and to infer the very moment of collision between the falling drop and the sample surface which would be useful in refining splash phenomenon models unfortunately the method also has several limitations and potential methodological problems hydrogen is a labile element and easily fractionates depending on temperature and humidity this makes it necessary to ensure stable measurement conditions and therefore limits the possibilities of field applications at this stage it is also difficult to estimate the influence of a more complex system e g soil on the change in the hydrogen isotopic ratio and thus the possibility of applying the investigated method to more complex systems this requires further research in addition the equipment required for isotopic determination is rather expensive complex and needs skilled operators 5 conclusions we showed a new method based on labelled water to monitor the splash of water droplets when a falling water drop hits the surface of water in the model system studied all the water making up the splash comes from the surface water and only in the specific case of a very thin layer of surface water in the vessel does it come partially from the falling droplet the height from which the drop falls has no effect on the isotopic ratio of the water in the splash the use of the presented method requires a few prerequisites such as stable temperature and air humidity conditions as well as that the correction for water evaporation during the experiment be taken into account the presented method seems promising for use in splash experiments but its wider application to more complex systems requires further investigation it is possible that the use of d2o labelled water can be useful for tracing and determining the origin of splashed water i e to what extent do the water from the falling drop and the water in the soil pores or water that constitutes a water surface mix with each other and where does the water forming droplets after the splash come from from the drop or from the surface the same analysis could be used for tracing water splash on plant leaves which might be employed in the tracking of pathogens as well as plant protection applications 6 data availability the data that support the findings of this study are available from the corresponding author upon reasonable request credit authorship contribution statement c polakowski conceptualization validation formal analysis investigation writing original draft writing review editing visualization m beczek validation investigation writing review editing r mazur validation investigation writing review editing a sochan formal analysis writing review editing m ryżak formal analysis resources writing review editing funding acquisition a bieganowski conceptualization writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was partially financed by national science centre poland https www ncn gov pl in the frame of project no 2018 31 n st10 01757 the funder had no role in the study design data collection and analysis decision to publish or preparation of the manuscript 
