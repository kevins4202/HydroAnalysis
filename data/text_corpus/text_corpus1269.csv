index,text
6345,problems have a high rank in decision making when they are both urgent and important accordingly water has not earned the attention it deserves in public policy agenda because under normal circumstances it is not viewed as an urgent matter in the eyes of the public and politicians by creating a sense of urgency extreme events such as droughts floods conflicts and migrations can create opportunities for implementing some essential policy reforms that would be politically costly otherwise so despite their high short term costs extreme natural and societal events have the potential to increase the resilience of water systems in the long run it is argued here that the societal and political sense of urgency about water must be promoted through public outreach and information dissemination otherwise for useful reforms and long term improvements we will rely on costly and risky extreme events that sometimes have the potential to fully collapse the human natural system of systems keywords extreme events resilience water management environmental policy politics 1 addressing water bankruptcy the global water system is bankrupt with water consumption already exceeding the accessible renewable water leading to the overdraft of non renewable water resources and ecosystem damages in many parts of the world addressing water bankruptcy requires investment in both mitigation and adaptation the former normally involves efforts that seek to increase the volume of accessible water or cutting demand through technologic hard and sometimes policy soft solutions within the boundaries of water systems the latter on the other hand involves efforts that are of soft nature and typically out of the authority of water resource managers this type of policy and planning efforts appreciate the nexus of water systems with other systems such as food energy economy society and politics example mitigation measures include water storage and diversion desalination wastewater recycling water conservation technology invention developing drought resistant crops improving irrigation efficiency raising water prices and removing subsidies as well as metering and quota enforcement most if not all of these measures have been already proven to be unsustainable when implemented without considering their long term impacts and feedbacks see bahaddin et al 2018 and mirchi et al 2012 for a review of some common long term and unintended consequences of shortsighted water management solutions adaptation solutions however are supposed to be based on a more comprehensive understanding and appreciation of the complexity of human natural system of systems fig 1 adaptation measures do consider the problems of water sector as products of the complex inter related dynamics of a system of systems involving human and nature example adaptation measures include national and regional development plan reforms to make them less water dependant economic diversification and decoupling economic growth or political economy from water introduction of alternative jobs and livelihoods to farming increased water allocation to ecosystem revision of food security policies and changing crop patterns altering food trade strategies and land use amendments 2 mitigation or adaptation improving the resilience of water systems is realized through boosting their capacity for 1 preparation for 2 absorption of 3 recovering from and 4 adapting to human natural perturbations thus mitigation and adaptation solutions must be co employed in a complementary manner based on a portfolio approach for achieving resilient water systems nevertheless within the existing water and environmental management paradigms the decision makers are mainly concentrated on selective mitigation efforts for recovery in reaction to perturbations and to some extent preparation and absorption proactively based on stationary assumptions decision makers dealing with water systems rarely pursue adaptation strategies this is because they usually suffer from the lack of proper understanding of the complex and non stationary dynamics ristic and madani 2019 of human natural system of systems and are often not authorized to implement changes that involve multiple sectors more importantly effective adaptation solutions have considerable socio economic and political costs in the short run so they are less appealing to the politicians involved in popularity contests that are mainly concerned with maximizing the short term monetary gains of the public rather than investing in efforts and reforms that are unpleasant in the short run but effectively contribute to the long term sustainability of human ecological systems 3 importance versus urgency for a problem to be of top priority in the decision making agenda it should be both urgent and important fig 2 no matter how much we care about water as water users and experts water is currently a non urgent topic from a public policy standpoint even its level of importance to the high level decision makers under normal circumstances is disputed when compared with other issues such as economy employment defence foreign policy energy transportation food health public infrastructure and citizen satisfaction water is indeed a small component of complex human natural system of systems fig 3 a politician with inadequate resources and the goal of remaining popular for maintaining power or getting re elected bruce and madani 2015 is more interested in taking actions in relation to sectors that matter the most to the public during her his limited tenure while citizens generally assign some value to the state of the environment sustainable development and respecting the rights of future generations issues such as economy employment housing health politics and quality of public services infrastructure have higher weights in their utility function thus even if considered to be important rational policy makers do not naturally dedicate much attention efforts and resources to water unless it turns into an urgent issue under special circumstances such as when water shortage results in job losses major economic damages to farmers and even migration e g australia iran and california when water unavailability has potential to create public anger and health risks e g flint and cape town and when an upstream country uses water as a potential weapon to threaten downstream national security and limits the flow of a trans boundary river e g nile mekong tigris euphrates indus and jordan river systems 4 the value of extremes extreme water and societal events such as droughts floods water outage terrorist attacks to water infrastructure water alloction conflicts and water borne disease outbreaks are always expected to occur but their time frequency and magnitude of occurrence are hard to predict accurately they are always costly economically and politically and can sometimes get out of control e g it is believed that droughts functioned as a catalyst to the syrian internal war nevertheless they have the power to turn water into an urgent matter during their time of occurrence and in a limited time window afterwards once the society finds it both urgent and important water earns a high priority in the public policy agenda and a window of opportunity for reactive interventions opens up in this situation the potential political cost of public dissatisfaction with no action business as usual increases while the political cost of policy reforms drops and the economic cost of reactive interventions becomes justifiable for example the 2011 2017 california drought provided an invaluable opportunity window to justify and implement some major reforms that were politically costly otherwise such as the new legislation on regulating and monitoring groundwater in 2014 mitigation measure and the governor s executive order b 29 on a state wide 25 reduction in potable urban water in 2015 adaptation measure as another example the australia s millennium drought justified the implementation of a range of costly both economically and politically reactive mitigation and adaptation measures similarly the socio political fear of day zero and the risk of earning the infamous title of the world s first major city to run out of water justified unprecedented water use restrictions mainly mitigation strategies in cape town in 2018 with lasting impacts on the city s water consumption pattern 5 information and education water problems are developed gradually and are mostly invisible to the general public by the time they are noted by the society and politicians e g under extreme events or after a major ecosystem damage emotional and populist reactive measures and mitigation solutions are more likely as at that time it is usually too late to implement proactive fundamental reforms and adaptation measures once the window of intervention opportunity is closed as a result of public distraction to other important and urgent societal economic and political matters effective interventions lose political attraction in cases when the intervention opportunity period is long e g during a multi year drought instead of a major 2 day flood event the implementation of adaptive measures is likely but they will still be based on a reactive mode frequent extremes also result in the extension of the opportunity window refreshing of public memory and persistence of the urgency level leading to useful interventions e g the frequency of major flood events is recognized as one of the main drivers of advancements in flood management by the dutch achieving resilience through proactive mitigation and adaptation actions independent of extreme events requires stimulating the societal sense of importance and urgency of water this can be done through education raising awareness close interactions with the society public outreach and citizen engagement hjorth and madani 2014 a water informed society has less dependency on reactive reforms and is not in need of extreme events to improve the efficiency of its water management system such a society assigns a higher priority to water questions the past water actions and future water plans of its leaders and reduces the political cost of interventions in the water sector in turn forcing its policy makers to take meaningful water actions 6 final remarks building resilient human natural system of systems and addressing the water bankruptcy problems around the world requires reactive and proactive implementation of a portfolio of mitigation and adaptation solutions yet water does not have a high priority in public policy agenda in the absence of societal and political sense of urgency about water as a result the existing water management paradigms mainly promote reactive mitigation solutions within the boundaries of water resource systems as opposed to proactive adaptation solutions that have a larger impact domain in complex human natural system of systems whether natural or man made a crisis extreme event or disaster can create invaluable opportunities to improve the resilience of coupled human natural system of systems as long as the system under control does not completely collapse extreme events can create a sense of urgency about water and pave the way for the implementation of solutions that are politically and economically daunting otherwise nevertheless extreme event dependent interventions are mostly of reactive and mitigation types in addition the risk of the complete collapse of the system or socio natural regime changes as in the cases of aral sea or lake urmia desiccation or the drought relevant security crisis and mass migration in syria makes this type of interventions highly unreliable and risky proactive development of resilient human natural systems can be pursued by promotion and maintenance of the public and political sense of urgency a water informed society assigns a high priority to water issues rewards meaningful water related interventions and is harder to manipulate by politics see a real world experience reported in madani 2018 2019 and stone 2018 this is of particular importance for academicians who are institutionally incentivized to and normally take more pride in communicating their findings to the policy makers rather than the general public this is due to the overlooked power of public opinion and its role in changing the behavior of politicians academics and experts need to believe in the fact that the common narrative of the society about the issues that matter the most and the general public s serious expression of concern about the issues that they find urgent and important can result in interventions and reforms even in autocracies declaration of competing interest the author declares no conflict of interest acknowledgement i am grateful for the henry hart rice senior fellowship of the whitney and betty macmillan center for international and area studies at yale university 
6345,problems have a high rank in decision making when they are both urgent and important accordingly water has not earned the attention it deserves in public policy agenda because under normal circumstances it is not viewed as an urgent matter in the eyes of the public and politicians by creating a sense of urgency extreme events such as droughts floods conflicts and migrations can create opportunities for implementing some essential policy reforms that would be politically costly otherwise so despite their high short term costs extreme natural and societal events have the potential to increase the resilience of water systems in the long run it is argued here that the societal and political sense of urgency about water must be promoted through public outreach and information dissemination otherwise for useful reforms and long term improvements we will rely on costly and risky extreme events that sometimes have the potential to fully collapse the human natural system of systems keywords extreme events resilience water management environmental policy politics 1 addressing water bankruptcy the global water system is bankrupt with water consumption already exceeding the accessible renewable water leading to the overdraft of non renewable water resources and ecosystem damages in many parts of the world addressing water bankruptcy requires investment in both mitigation and adaptation the former normally involves efforts that seek to increase the volume of accessible water or cutting demand through technologic hard and sometimes policy soft solutions within the boundaries of water systems the latter on the other hand involves efforts that are of soft nature and typically out of the authority of water resource managers this type of policy and planning efforts appreciate the nexus of water systems with other systems such as food energy economy society and politics example mitigation measures include water storage and diversion desalination wastewater recycling water conservation technology invention developing drought resistant crops improving irrigation efficiency raising water prices and removing subsidies as well as metering and quota enforcement most if not all of these measures have been already proven to be unsustainable when implemented without considering their long term impacts and feedbacks see bahaddin et al 2018 and mirchi et al 2012 for a review of some common long term and unintended consequences of shortsighted water management solutions adaptation solutions however are supposed to be based on a more comprehensive understanding and appreciation of the complexity of human natural system of systems fig 1 adaptation measures do consider the problems of water sector as products of the complex inter related dynamics of a system of systems involving human and nature example adaptation measures include national and regional development plan reforms to make them less water dependant economic diversification and decoupling economic growth or political economy from water introduction of alternative jobs and livelihoods to farming increased water allocation to ecosystem revision of food security policies and changing crop patterns altering food trade strategies and land use amendments 2 mitigation or adaptation improving the resilience of water systems is realized through boosting their capacity for 1 preparation for 2 absorption of 3 recovering from and 4 adapting to human natural perturbations thus mitigation and adaptation solutions must be co employed in a complementary manner based on a portfolio approach for achieving resilient water systems nevertheless within the existing water and environmental management paradigms the decision makers are mainly concentrated on selective mitigation efforts for recovery in reaction to perturbations and to some extent preparation and absorption proactively based on stationary assumptions decision makers dealing with water systems rarely pursue adaptation strategies this is because they usually suffer from the lack of proper understanding of the complex and non stationary dynamics ristic and madani 2019 of human natural system of systems and are often not authorized to implement changes that involve multiple sectors more importantly effective adaptation solutions have considerable socio economic and political costs in the short run so they are less appealing to the politicians involved in popularity contests that are mainly concerned with maximizing the short term monetary gains of the public rather than investing in efforts and reforms that are unpleasant in the short run but effectively contribute to the long term sustainability of human ecological systems 3 importance versus urgency for a problem to be of top priority in the decision making agenda it should be both urgent and important fig 2 no matter how much we care about water as water users and experts water is currently a non urgent topic from a public policy standpoint even its level of importance to the high level decision makers under normal circumstances is disputed when compared with other issues such as economy employment defence foreign policy energy transportation food health public infrastructure and citizen satisfaction water is indeed a small component of complex human natural system of systems fig 3 a politician with inadequate resources and the goal of remaining popular for maintaining power or getting re elected bruce and madani 2015 is more interested in taking actions in relation to sectors that matter the most to the public during her his limited tenure while citizens generally assign some value to the state of the environment sustainable development and respecting the rights of future generations issues such as economy employment housing health politics and quality of public services infrastructure have higher weights in their utility function thus even if considered to be important rational policy makers do not naturally dedicate much attention efforts and resources to water unless it turns into an urgent issue under special circumstances such as when water shortage results in job losses major economic damages to farmers and even migration e g australia iran and california when water unavailability has potential to create public anger and health risks e g flint and cape town and when an upstream country uses water as a potential weapon to threaten downstream national security and limits the flow of a trans boundary river e g nile mekong tigris euphrates indus and jordan river systems 4 the value of extremes extreme water and societal events such as droughts floods water outage terrorist attacks to water infrastructure water alloction conflicts and water borne disease outbreaks are always expected to occur but their time frequency and magnitude of occurrence are hard to predict accurately they are always costly economically and politically and can sometimes get out of control e g it is believed that droughts functioned as a catalyst to the syrian internal war nevertheless they have the power to turn water into an urgent matter during their time of occurrence and in a limited time window afterwards once the society finds it both urgent and important water earns a high priority in the public policy agenda and a window of opportunity for reactive interventions opens up in this situation the potential political cost of public dissatisfaction with no action business as usual increases while the political cost of policy reforms drops and the economic cost of reactive interventions becomes justifiable for example the 2011 2017 california drought provided an invaluable opportunity window to justify and implement some major reforms that were politically costly otherwise such as the new legislation on regulating and monitoring groundwater in 2014 mitigation measure and the governor s executive order b 29 on a state wide 25 reduction in potable urban water in 2015 adaptation measure as another example the australia s millennium drought justified the implementation of a range of costly both economically and politically reactive mitigation and adaptation measures similarly the socio political fear of day zero and the risk of earning the infamous title of the world s first major city to run out of water justified unprecedented water use restrictions mainly mitigation strategies in cape town in 2018 with lasting impacts on the city s water consumption pattern 5 information and education water problems are developed gradually and are mostly invisible to the general public by the time they are noted by the society and politicians e g under extreme events or after a major ecosystem damage emotional and populist reactive measures and mitigation solutions are more likely as at that time it is usually too late to implement proactive fundamental reforms and adaptation measures once the window of intervention opportunity is closed as a result of public distraction to other important and urgent societal economic and political matters effective interventions lose political attraction in cases when the intervention opportunity period is long e g during a multi year drought instead of a major 2 day flood event the implementation of adaptive measures is likely but they will still be based on a reactive mode frequent extremes also result in the extension of the opportunity window refreshing of public memory and persistence of the urgency level leading to useful interventions e g the frequency of major flood events is recognized as one of the main drivers of advancements in flood management by the dutch achieving resilience through proactive mitigation and adaptation actions independent of extreme events requires stimulating the societal sense of importance and urgency of water this can be done through education raising awareness close interactions with the society public outreach and citizen engagement hjorth and madani 2014 a water informed society has less dependency on reactive reforms and is not in need of extreme events to improve the efficiency of its water management system such a society assigns a higher priority to water questions the past water actions and future water plans of its leaders and reduces the political cost of interventions in the water sector in turn forcing its policy makers to take meaningful water actions 6 final remarks building resilient human natural system of systems and addressing the water bankruptcy problems around the world requires reactive and proactive implementation of a portfolio of mitigation and adaptation solutions yet water does not have a high priority in public policy agenda in the absence of societal and political sense of urgency about water as a result the existing water management paradigms mainly promote reactive mitigation solutions within the boundaries of water resource systems as opposed to proactive adaptation solutions that have a larger impact domain in complex human natural system of systems whether natural or man made a crisis extreme event or disaster can create invaluable opportunities to improve the resilience of coupled human natural system of systems as long as the system under control does not completely collapse extreme events can create a sense of urgency about water and pave the way for the implementation of solutions that are politically and economically daunting otherwise nevertheless extreme event dependent interventions are mostly of reactive and mitigation types in addition the risk of the complete collapse of the system or socio natural regime changes as in the cases of aral sea or lake urmia desiccation or the drought relevant security crisis and mass migration in syria makes this type of interventions highly unreliable and risky proactive development of resilient human natural systems can be pursued by promotion and maintenance of the public and political sense of urgency a water informed society assigns a high priority to water issues rewards meaningful water related interventions and is harder to manipulate by politics see a real world experience reported in madani 2018 2019 and stone 2018 this is of particular importance for academicians who are institutionally incentivized to and normally take more pride in communicating their findings to the policy makers rather than the general public this is due to the overlooked power of public opinion and its role in changing the behavior of politicians academics and experts need to believe in the fact that the common narrative of the society about the issues that matter the most and the general public s serious expression of concern about the issues that they find urgent and important can result in interventions and reforms even in autocracies declaration of competing interest the author declares no conflict of interest acknowledgement i am grateful for the henry hart rice senior fellowship of the whitney and betty macmillan center for international and area studies at yale university 
6346,interactions between surface water sw and groundwater gw have been identified as a major contributing factor to non stationarity in rainfall runoff relationships however because existing rainfall runoff models do not realistically account for these sw gw interactions they fail to robustly simulate runoff during multi year droughts especially in arid and semi arid catchments that are relatively flat therefore this study introduces a linked sw gw modelling approach and tests it under different climatic conditions average dry and wet periods in two heterogeneous semi arid catchments in southeast australia sea the linked sw gw modelling approach includes a fully distributed sw i e rainfall runoff model swatgrid and a three dimensional finite difference gw model modflow the results show that the linked sw gw modelling approach produces highly improved runoff simulations for the study catchments especially during dry conditions these findings demonstrate the importance of accounting for sw gw interactions when conducting rainfall runoff modelling and highlights that failing to do so will result in overestimation of runoff during droughts this is salient given projections for hotter and drier futures in many semi arid regions although the study is focused on sea the insights gained are highly applicable for water managers in any region that experience high hydroclimatic variability or change keywords swatgrid modflow stream aquifer interaction groundwater watershed hydrology climate variability 1 introduction climate variability and associated floods and droughts significantly impacts catchment conditions and water resources madhusoodhanan et al 2016 kiem et al 2016 deb et al 2018 kundzewicz et al 2018 in semi arid regions such as southeast australia sea which has experienced several multi year droughts in the past century verdon kidd and kiem 2009 catchment characteristic changes that occur during multi year droughts e g surface water sw and groundwater gw interaction land use change etc alter eco hydrological processes chiew et al 2014 saft et al 2015 and cause non stationarity in rainfall runoff relationships i e runoff generated per unit rainfall is lower during multi year droughts saft et al 2015 tian et al 2018 deb et al 2019 this introduces uncertainties in hydrological simulations and these uncertainties are exacerbated when rainfall runoff models calibrated to simulate current rainfall runoff relationships are used to project future hydrological conditions especially for regions that are projected to be drier döll and zhang 2010 chiew et al 2014 saft et al 2015 physically process based rainfall runoff models are considered superior to conceptually lumped models when compared for different climatic regimes bhadra et al 2010 ghavidelfar et al 2011 this is because the process based models are capable of considering the temporal changes in vegetation cover during simulation which contributes to non stationarity in rainfall runoff relationships during multi year droughts deb et al 2019 however to avoid model structural complexity existing process based rainfall runoff models e g topmodel swat hspf etc only consider the baseflow quick flow component of gw flow in the models beven et al 2015 also most rainfall runoff models were developed for european catchments and these catchments are typically steeper and contribution of the slow flow component of gw to sw is negligible than what occurs in flat and semi arid catchments winter 1995 käser and hunkeler 2016 vrzel et al 2018 in flat and semi arid catchments sw gw interaction plays a major role tanner and hughes 2015 this is because during multi year droughts the stream aquifer interaction is more likely to cease therefore instead of the aquifer contributing to stream which is dominant during normal rainfall conditions the aquifer takes water from the stream during multi year droughts parsons et al 2008 chiew et al 2014 deb et al 2019 due to the structural limitation of the existing rainfall runoff models this detailed sw gw interaction is not realistically accounted for another important aspect of the existing process based rainfall runoff models is the spatial discretisation of soil map land use map and digital elevation model dem this is because semi distributed rainfall runoff models classify the whole catchment into sub basins or hydrological response units hrus based on the similarities in soil properties and land use and lump the inputs for each sub basin hru arnold and fohrer 2005 this overshadows the spatial heterogeneity of inputs especially rainfall and soil moisture which can be highly variable within a catchment rathjens et al 2015 furthermore water flow chemical from the agricultural field and sediment transport routing in a sub basin hru is done directly through the stream channel in a semi distributed model this may not always be true since flow and transport occur from one landscape location to another prior to entering the stream bosch et al 2010 this along with the spatial heterogeneity of input to models can be eliminated by the application of fully distributed models recent studies compared the fully distributed swatgrid model with lumped and semi distributed models in flat catchments of sea and united states of america respectively and found that fully distributed models outperform the semi distributed and lumped models deb and kiem 2019 pignotti et al 2017 in summary due to consideration of spatial heterogeneity of soil land use dem model inputs and the ability to calculate flow within a sub basin hru fully distributed rainfall runoff models appear to be more robust than lumped and semi distributed models especially in flatter catchments rainfall runoff models implicitly assume that catchment dynamics and associated rainfall runoff relationships will remain similar to that which occurred in the period covered by the data used for calibration and validation andrés doménech et al 2015 this assumption is flawed given catchment characteristics are known to change under prolonged drought conditions saft et al 2015 deb et al 2019 for instance during the millennium drought 1997 to 2009 there was a disproportionate runoff reduction in the sea with rainfall decreases only contributing to 52 66 runoff reduction potter and chiew 2011 several possible reasons for this include sw gw interaction leaf area index lai potential evapotranspiration pet saft et al 2015 ajami et al 2017 deb et al 2019 and influences from large scale climatic processes kiem and verdon kidd 2009 2011 most of these mechanisms are accounted for in rainfall runoff models but sw gw interactions and the temporal changes in lai vegetation cover are not therefore the existing research gap is identifying approaches to account for these two mechanisms in rainfall runoff modelling therefore the novelty of this study is the development of a modelling framework that integrates distributed rainfall runoff modelling with gw modelling to more realistically simulate runoff under different climatic conditions although the study focusses on sea the proposed approach is applicable to all regions and is likely to be particularly useful for catchments that experience high climatic variability and multi year decadal droughts 2 study area two anthropogenically unaltered catchments from sea with contrasting biophysical characteristics e g slope relief area mean elevation etc were considered in this study these catchments were selected based on the findings of saft et al 2015 and deb et al 2018 where non stationarity in rainfall runoff relationships were observed the two catchments were brankeet creek catchment victoria stream gauge located at ancona gauge number 405251 36 97 s 145 79 e and muttama creek catchment new south wales nsw stream gauge located at coolac gauge number 410044 34 93 s 148 16 e hereafter referred as 405251 and 410044 catchments respectively fig 1 brankeet and muttama creeks are the tributaries of goulburn and murrumbidgee river respectively further details on these catchments can be found in deb et al 2018 the hydrological properties of the soil in each catchment were derived from the australian soil database created by western and mckenzie 2004 the lithological information derived from the geosciences society of australia reveals that both of the catchments are dominated by sandstone and volcanic rocks except for the alluvium deposits found adjacent to the river bed also fractured fissured unconfined aquifers are predominant in the catchments 3 data and methods 3 1 data 3 1 1 hydro meteorological data the hydro meteorological data used in this study is shown in table 1 the rainfall data was collected from four rainfall stations and temperature data was derived from one meteorological station for each catchment rainfall data was available for the entire period at catchment 405251 and was missing for 3 of the study period covered in catchment 410044 days where rainfall data was missing were assumed to have zero rainfall this assumption is justified because all the missing data occurred during the world war ii drought period 1941 to 1953 and the probability of rainfall occurrence during droughts is negligible kisaka et al 2015 runoff maximum and minimum temperature data were missing for 5 of the study period missing runoff data on a given day e g 10th december 2003 was infilled by taking the average of runoff that occurred on the same day for all other years that data existed i e 10th december in all other years a similar infilling process was also employed for missing temperature data the gw table dataset in catchment 405251 was available for 23 observation wells for the period 1974 2015 table 1 however for 410044 the gw table dataset was only available for 45 observation wells and for the duration of 1971 2015 since the gw table data was required from 1940 onwards described later a virtual gw table was generated for those 45 wells on a monthly time scale this was done by creating the contour lines of the hydraulic head based on the available observation wells with gw table data recorded at a monthly frequency within the murrumbidgee river catchment muttama creek is a tributary to murrumbidgee river the spatial interpolation of the gw table within the contour lines was done via simple kriging sun et al 2009 xiao et al 2016 this approach is commonly used when gw table data is unavailable within the study catchment but is available at surrounding catchments cho et al 2010 wable et al 2017 abiye et al 2018 both catchments had minimal human intervention and therefore no pumping wells the hydrogeological maps retrieved from local government agencies suggest that local aquifers with low productivity dominate both catchments additionally bedrocks are usually thick often 10 m throughout both catchments 3 1 2 catchment characteristic data catchment characteristic data is shown in table 2 in order to use the same input data for all three models the areal rainfall data throughout each catchment was calculated based on the thiessen polygon approach brassel and reif 1979 pet was calculated using the hargreaves samani equation hargreaves and samani 1985 since this is considered to be the most appropriate approach for arid and semi arid regions moeletsi et al 2013 the dem land use land cover map soil map and the geology map were used directly in the modelling however due to the poor spatial resolution of the lai they were interpolated to the required grid size 900 m using the nearest neighbour method of resampling gonsamo et al 2011 3 2 rainfall runoff and gw models used 3 2 1 swatgrid the swatgrid hydrological model rathjens and oppelt 2012 rathjens et al 2015 was chosen for sw modelling as it has been shown to be the best performing rainfall runoff model under non stationarity in rainfall runoff conditions in sea deb and kiem 2019 swatgrid rathjens et al 2015 is a continuous physically based fully distributed rainfall runoff model it integrates the landscape routing and grid based setup which works in conjunction with the swat model instead of simulating the flows at an hru scale as in swat swatgrid discretises the catchment into user defined grid cells and computes the surface runoff lateral and shallow gw flow for each individual cell the model employs water balance approach to calculate runoff at grid scale eq 1 1 sw t i sw o i 1 t r d a y i q s u r f i e a i w s e e p i q gw i where swt i is soil water content at time t swo is the initial soil water content in mm t represents the simulation period in days rday i is the amount of rainfall on ith day in mm qsurf i represents the surface runoff in mm on the ith day ea i is the amount of pet on ith day in mm wseep i represents the amount of water in mm entering the vadose zone on the ith day and qgw i represents the amount of baseflow in mm on the ith day the model generates the surface runoff through integrating the overland and channel runoff in order to differentiate these two types of runoff a flow separation ratio is used which is based on the topographic index of the catchment eq 2 the topographic index considers topography drainage density channel bed morphology and the soil properties 2 λ i l n a i tan β i k i z i i 1 2 n where i represents the grid number λi is the topographic index ai is the upslope area contributing to per unit contour length in m βi is the slope of the cell in degrees ki is the saturated hydraulic conductivity m day 1 and zi is the soil depth in m for each grid cell unlike swat which uses constant flow separation ratio to generate runoff swatgrid calculates the spatially distributed proportions of the channel and landscape overland flow using the flow separation index which is intrinsically related to the topographic index rathjens et al 2015 swatgrid calculates the surface runoff lateral flow and the shallow gw flow while using the scs cn method kinematic storage model and linear tank storage models respectively for each grid cell the main difference between the swat and swatgrid setup is during the spatial discretisation of dem into hrus in swat and grids in swatgrid in swatgrid the dem was used to identify the flow paths and to define the grid cells this was done while using the landscape analysis tool topographic parameterization topaz garbrecht and martz 2000 and is a pre requisite for swatgrid as swat was developed to divide the whole catchment into small sub basins and to integrate the spatial information given by the dem each grid is defined as a sub basin in swatgrid the outputs are the water balance components runoff pet soil water storage etc in the form of a stack of data frames for each grid cell at the user defined temporal resolution due to the complicated structure of swatgrid model the number of parameters for model calibration can range from 10 to 15 hence to reduce the computational time a sensitivity test was done following the approach by uniyal et al 2015 and then six of the most sensitive parameters were considered in model calibration table s1 of supporting information most of the sensitive model parameters were related to gw and soil moisture content 3 2 2 modflow modflow is a physically based three dimensional finite difference gw flow model that has been widely and successfully used in many global and regional studies harbaugh et al 2000 harbaugh 2005 de graaf et al 2017 gw flow is simulated while using a block centred finite difference approach eq 3 where the head is calculated at the centre of each grid cell considered in modelling the model allows the user to define the grid size and the number of layers either confined or unconfined aquifers 3 δ δ x k xx δ h δ x δ δ y k yy δ h δ y δ δ z k zz δ h δ z w s δ h δ t where x y and z are coordinate axes k is the hydraulic conductivity along the axis h is the hydraulic head w represents gw flux s is the specific storage of the aquifer and t represents time harbaugh 2005 the most recent version of modflow which uses a newtonian based solver nws algorithm was used in this study the nws algorithm allows the cells to dry and re wet again in an unconfined aquifer during simulation which was a major limitation in the previous versions niswonger et al 2011 since the model simulates the gw flow it does not consider several surface processes such as interception flow routing and surface runoff during simulation the model calibration parameters of modflow are hydraulic conductivity in longitudinal vertical and lateral direction and streambed conductance the unit and range of the parameters are given in table s1 of supporting information in addition to the base package of modflow several additional packages are also available for the model to accurately represent the hydro geologic condition the uzf1 package was used to calculate the recharge vadose zone percolation and pet in the model similarly the river package was used to define the stream segments and stream aquifer interaction also the head observation hob package was used to represent the gw table during simulation which was used in model calibration 3 3 sw gw interaction modelling strategy there are three possible approaches to simulate the sw gw interaction at a catchment scale 1 stand alone approach using gw models defining the river in the model set up 2 linked sw gw modelling approach and 3 developing a new model that considers both sw and gw processes cho et al 2010 although the stand alone approach is the simplest it is not applicable in this study due to the limitations associated with gw models not properly considering sw processes that are important in semi arid regions like sea e g interception overland flow etc option 3 is also not feasible due to data constraints and computational limitations that are currently associated with testing and applying such an approach on the other hand while significant effort is required for model set up and simulation the linked sw gw modelling approach provides the flexibility of choosing different models for a given objective e g to simulate sw gw interaction for instance the swat sw model component from swat mod can be exchanged for hec hms sw model without the modification of its source code therefore due to the flexibility and reliability of the existing models the linked sw gw modelling approach is selected for this study fig 2 the linked sw gw modelling approach should be able to represent the two way interactions between the sw and gw in particular the approach should be able to consider the surface aquifer and aquifer stream interactions as both phenomena govern the sw gw interaction sw hydrological processes such as interception topographic wetness index and land use pattern nolan et al 2007 control the spatial variability of recharge rate throughout the catchment this ultimately governs the gw table flux and therefore should be considered in the gw flow simulation this can be achieved by changing the recharge input for the modflow model similarly the discharge from the aquifer to the river network is necessary to be considered in the swatgrid model simulation therefore the linked sw gw modelling approach is applied in this study with the aim being to more realistically simulate flow under non stationary climate and rainfall runoff conditions the linked sw gw modelling approach consists of three major steps 1 virtual simulation of swatgrid to predict daily recharges and saving them as temporal data frames 2 transient state modflow simulation with the updated recharge from the previous step and storing the daily discharge from gw to stream 3 actual swatgrid simulation while considering the outputs of modflow model fig 3 during the transient modflow simulation the recharge input file of modflow rch is updated based on the recharge calculated by swatgrid in the previous step both virtual and actual simulations use the same processes and parameters except the input of gw flux to streamflow for different grid cells is considered in the actual simulation as sw and gw flow rates are different swatgrid was simulated at a daily time step whereas modflow was simulated at a 10 day time step following the recommendations of xu et al 2012 and surinaidu et al 2014 furthermore both swatgrid and modflow allows the user to select the spatial scale grid size at which the models are to be simulated for a smaller grid size of swatgrid compared to modflow the recharge is needed to be spatially lumped for the discrete modflow cells also it results in higher computational time and therefore in order to reduce the complexity a grid size of 900 m is considered to set up both swatgrid sw model and modflow gw model in this study based on the recommendations of beven 1990 and cho et al 2010 this resulted in 181 and 1226 grids including partial grids for the catchment boundaries for catchment 405251 and 410044 respectively see fig s1 in supporting information 3 4 modelling steps three major steps are required to set up the linked sw gw modelling approach 1 calibration of swatgrid with its integrated baseflow calculation stand alone swatgrid 2 steady state modflow calibration 3 runoff simulation using the linked sw gw modelling approach with the calibrated parameters of swatgrid and modflow derived from the previous steps being a fully distributed model the stand alone swatgrid model uses spatially distributed recharge fluxes to calculate the baseflow and lateral gw flow in a catchment the parasol technique of model auto calibration was done in the swat cup package of the model the model was calibrated against daily observed runoff at the catchment outlets i e 405251 and 410044 steady state modflow auto calibration was done while using the external pest program doherty 2015 against the hydraulic head of the observation wells the parameters adjusted for stand alone swatgrid and steady state modflow calibration are provided in table s1 of supporting information in the linked sw gw modelling approach the integrated baseflow and shallow gw flow calculation of the swatgrid model were turned off and the outputs of modflow were used therefore the parameters associated with the shallow gw flow and baseflow were also ignored in the simulation similarly the calculation of the pet in the modflow was also ignored and the output of swatgrid was used in the simulation the initial and boundary conditions used in the stead state modflow calibration were kept the same in the transient state modflow simulation in the linked sw gw modelling approach swatgrid set up involves two main steps generation of the watershed configuration file swatgrid fig and preparing swat input files the watershed configuration file stores the watershed characteristics particularly the watershed boundary flow direction number of upstream grids contributing to any grid flow paths and a map of the channel network these characteristics are obtained by pre processing the raster dataset dem in the topaz tool for a flat topography smaller grid size 1000 m is recommended beven 1990 therefore in this study a grid size of 900 m was used to set up the model this resulted in 136 and 1180 grids for catchment 405251 and 410044 respectively this was followed by the preparation of the remaining input files including the study area location grid size resolution soil type information land use classification baseflow information soil map raster file land use land cover map raster file climate inputs rainfall temperature evapotranspiration and calibration options these input details were stored in the swatgrid inp file after generating all these datasets swat modelling was conducted where swatgrid input files were taken as standard swat input data defining boundary conditions is important for modflow set up the hydrological boundaries are defined based on the information available from well logs dem and geological maps since the rivers in the catchments were perennial constant head boundary conditions were used while setting up the model this is because the contour lines of the gw table were parallel to the catchment boundary at the catchment outlet also both catchments were dominated with fractured aquifers and therefore based on the recommendations of surinaidu et al 2014 and varalakshmi et al 2014 the aquifers were modelled as an equivalent porous medium furthermore a single layer of saturated zone was considered for modflow setup in both catchments since the average gw table was within 30 m from the ground surface for the observed length of gw dataset also increasing the number of aquifers will increase inefficiency since the geology is fractured and computational time during modflow calibration the hydraulic conductivity and streambed conductance were adjusted based on the reference values derived from existing literature doble et al 2009 knowling et al 2015 wood and pierce 2015 3 5 differential split sample test the stand alone swatgrid and steady state modflow calibration and validation were done based on differential split sample test klemes 1986 where the models were calibrated for one climatic period and validated for the other in order to check the robustness of the linked sw gw modelling approach simulations were also done for the same climatic periods these periods were identified based on varying historical rainfall conditions which were chosen as per the recommendations of li et al 2012 this involved calculation of the mean annual rainfall mar for the whole record 1974 2013 and 1941 2015 for catchments 405251 and 410044 respectively for a stable model run i e to avoid parameter instability a simulation period of greater than five years is suggested by beven 2012 two periods of five years each with mar lower and greater than 15 of the mar for the whole record were selected as the dry and wet periods respectively for catchment 405251 additionally two other periods of five years with mar ranging between 5 of the mar for the whole record were selected as average periods for the corresponding catchment note that the five year window was not chosen arbitrarily instead windows ranging from five years to twelve years were considered with five years proving optimal for 405251 where optimal is determined based on closeness to mar for average and mar for those years below above the mar for the whole record as dry wet similarly two periods each of nine years for average dry and wet were selected for the catchment 410044 the periods were termed average1 average2 dry1 dry2 wet1 and wet2 both stand alone swatgrid and steady state modflow were calibrated for the average1 dry1 and wet1 periods and validated for the remaining three i e average2 dry2 and wet2 in turn for both catchments this resulted in a total of nine calibration and validation sets for each catchment and each model fig s2 since steady state condition in gw modelling refers to zero changes in hydraulic head over time the mean value of the observed hydraulic heads for each of the considered periods i e average1 dry1 and wet1 for calibration were used for all the observation wells 23 for catchment 405251 and 45 for 410044 during the steady state modflow calibration similarly the mean hydraulic head was also identified for the validation periods and modflow was validated for steady state condition the linked sw gw modelling approach was also simulated for all the considered periods i e average1 average2 dry1 dry2 wet1 and wet2 note that the converse calibration validation i e calibrated on average2 dry2 and wet2 and validate on average1 dry1 and wet1 was not performed as previous studies suggest that swapping calibration and validation periods leads to minimal useful insights e g coron et al 2012 li et al 2012 3 6 model performance evaluation nash sutcliffe efficiency nse nash and sutcliffe 1970 root mean square error rmse and percentage bias pbias were used to evaluate the linked sw gw modelling approach and stand alone swatgrid simulations whereas pbias and mean absolute error mae were used to evaluate the steady state modflow simulations during calibration and validation periods the performance of swatgrid and the linked sw gw modelling approach was also assessed based on the comparison of flow duration curves fdc during calibration and validation periods these performance metrics are described in detail in the section s1 of the supporting information 4 results 4 1 identification of average dry and wet periods the calculated mar indicates that the larger catchment i e 410044 571 mm is drier than the smaller catchment i e 405251 967 mm fig 4 the variation of mar during dry and wet periods is higher in catchment 410044 compared to catchment 405251 table 3 therefore wider spatial variability in rainfall is likely to contribute in the temporal variability of rainfall in the larger catchment nevertheless the wide variability of the rainfall in both catchments signifies the importance of a rainfall runoff model framework which can realistically capture the spatial and temporal non stationarity in rainfall runoff relationships 4 2 modelling catchment 405251 4 2 1 stand alone swatgrid calibration detailed results of the stand alone swatgrid model simulation are provided in deb and kiem 2019 and therefore are not repeatedly discussed here although the model performance evaluation statistics of the stand alone swatgrid and the linked sw gw modelling approach are given in the first half of tables 5 7 and in figs 5 7 for catchment 405251 4 2 2 steady state modflow calibration table 4 shows the model performance indices of the hydraulic head for model calibration and validation during different periods based on the 23 observation wells the maximum variation in the pbias is observed during wet1 calibration which ranges from 14 4 to 9 8 table 4 on the other hand the maximum variation in the mae is observed for average1 calibration 0 89 2 52 m the best results are obtained for the dry1 calibration case where the pbias and mae range from 4 9 to 8 8 and 1 17 to 1 41 m respectively it can be seen that the model overestimates the hydraulic head during the dry2 validation for all cases of calibration i e average1 dry1 and wet1 calibration periods table 4 nevertheless these results pbias 15 and mae 3 m demonstrate that the steady state modflow reproduces the hydraulic head within a good range of accuracy at the catchment under different climatic periods 4 2 3 transient state simulation by linked sw gw modelling approach fig 5 shows the comparison of runoff simulated by stand alone swatgrid model the linked sw gw modelling approach and the observed runoff during the average1 calibration period and average2 dry2 and wet2 validation periods both stand alone swatgrid and the linked sw gw modelling approach simulates well in accordance to the observed runoff for the calibration and validation periods runoff simulated by the linked sw gw modelling approach shows higher overestimation for the low flows during the dry2 period fig 5 c and g also a noticeable underestimation of the peak flows is also observed for the stand alone swatgrid and the linked sw gw modelling approach simulation for the wet2 period fig 5 d these results are further supported by the model performance statistics provided in table 5 where pbias indicates overestimation during dry2 simulation by the linked sw gw modelling approach 13 12 and underestimation for wet2 simulation by both models pbias 12 74 and 8 41 for the stand alone swatgrid and the linked sw gw modelling approach respectively in general both stand alone swatgrid and the linked sw gw modelling approach simulates the flow in good agreement all three performance criteria are in acceptable range with the observed runoff despite the over and underestimation of the high and low flows fig 6 shows the comparison of stand alone swatgrid and the linked sw gw modelling approach while considering dry1 as calibration period a similar pattern of hydrographs is observed for both stand alone swatgrid and the linked sw gw modelling approach simulations during calibration and validation periods the fdc indicates superior results by the linked sw gw modelling approach especially for the mid range and low flows during the average2 and dry2 validation periods fig 6 f and 7 g the nse ranges from 0 78 to 0 92 and 0 88 to 0 94 for the simulations by stand alone swatgrid and the linked sw gw modelling approach respectively table 6 similarly better rmse is also observed for the linked sw gw modelling approach 0 11 0 36 m3 s 1 compared to stand alone swatgrid model simulation 0 15 0 44 m3 s 1 pbias indicates that stand alone swatgrid underestimates the runoff during dry1 calibration and all validation periods whereas the linked sw gw modelling approach underestimates runoff during the dry1 and average2 simulation periods and overestimates during the dry2 and wet2 simulations table 6 nevertheless both stand alone swatgrid and the linked sw gw modelling approach simulates flow within the acceptable range while considering the three performance evaluation criteria realistic simulations by the stand alone swatgrid and the linked sw gw modelling approach can be seen in the monthly hydrographs and fdc during the wet1 calibration period fig 7 a while in the case of average2 validation overestimation is noted by stand alone swatgrid for the high flows fig 7 b and f the validation of stand alone swatgrid during dry2 period results in an overestimation of the peaks during the low flows similar results are also observed for the linked sw gw approach although a much lesser variation in the magnitude of the peaks is noted fig 7 c and g these results are also supported by the model performance evaluation as presented in table 7 stand alone swatgrid fails to simulate the runoff within an acceptable range nse rmse and pbias when the simulated runoff is compared to the observed runoff during the dry2 validation period nse rmse and pbias calculated from the observed and simulated runoff indicates the linked sw gw modelling approach results in better simulation for all four periods i e wet1 average2 dry2 and wet2 4 3 modelling catchment 410044 4 3 1 stand alone swatgrid calibration similar to the section 4 2 1 detailed results of the stand alone swatgrid model calibration results for catchment 410044 are provided in deb and kiem 2019 comparative results of the stand alone swatgrid model calibration and validation and simulations of linked sw gw interaction are provided in the first half of tables 9 11 and figs 8 10 4 3 2 steady state modflow calibration table 8 shows the model performance indices of the hydraulic head simulated by steady state modflow during calibration and validation during different periods at catchment 410044 the pbias indicates that the hydraulic head is overestimated during the dry2 validation periods for average1 and wet1 calibration 14 2 and 11 2 for dry2 validation for average1 and wet1 calibration period respectively it can be observed that the steady state modflow underestimates positive pbias the hydraulic head for all validation periods during dry1 calibration table 8 mae indicates that higher variation in the simulated and observed hydraulic head persist during the dry2 validation for average1 and wet1 calibration 1 32 and 1 02 m respectively on the other hand the maximum value of mae is observed for the wet2 validation of dry1 calibration this indicates the model results are worse when calibrated for a certain climatic period and validated for the other climate in general steady state modflow reproduces the spatial distribution of hydraulic head in good agreement as pbias 15 and mae 3 m details provided in section s1 of supporting information throughout all considered climatic periods 4 3 3 transient state simulation by the linked sw gw modelling approach fig 8 displays the comparison of mean monthly runoff simulated by stand alone swatgrid and the ds approach during the average1 calibration period and average2 dry2 and wet2 validation periods while comparing the observed runoff both stand alone swatgrid and the linked sw gw modelling approach reproduces the runoff well during the average1 calibration period fig 8 a however the fdc shows that the low flows are overestimated by stand alone swatgrid simulation fig 8 e a relatively better simulation by stand alone swatgrid is noted for the average2 validation period fig 8 b and f also from fig 8 c and g the stand alone swatgrid model fails to realistically simulate the runoff during the dry2 validation period although the linked sw gw modelling approach results in the improvement of runoff simulation fig 8 c and g the fdc indicates an overestimation of the mid range and low flows this is also supported by the pbias calculated 69 81 for the observed and simulated runoff for stand alone swatgrid table 9 in addition to this overestimation is also observed during the wet2 validation period pbias 21 89 for the stand alone swatgrid model on the other hand the performance indices nse rmse and pbias suggest that the linked sw gw modelling approach simulates the runoff within an acceptable range during all four periods considered table 9 fig 9 shows the comparison of stand alone swatgrid and the linked sw gw modelling approach while considering dry1 as calibration period stand alone swatgrid appears to underestimate the peak flows during the dry1 calibration period fig 9 a both stand alone swatgrid and the linked sw gw modelling approach simulates the runoff reasonably well during the average2 and dry2 validation periods furthermore fig 9 d indicates that stand alone swatgrid underestimates the peak flows for all the years 1992 2000 a similar pattern of underestimation is also observed for the linked sw gw modelling approach simulation fig 9 d although the magnitude of variance is lower compared to the stand alone swatgrid simulation table 10 shows the performance statistics of the model simulations during dry1 calibration and average2 dry2 and wet2 validation periods the results indicate superior performance by the linked sw gw modelling approach when compared to stand alone swatgrid nse ranges from 0 39 to 0 87 and 0 71 to 0 91 for the stand alone swatgrid and the linked sw gw modelling approach respectively similarly the range of pbias is observed to be much better in the case of the linked sw gw modelling approach 8 36 to 13 17 when compared to stand alone swatgrid model 30 31 to 99 12 table 10 fig 10 displays the comparison of monthly hydrographs and daily fdc for stand alone swatgrid and the linked sw gw modelling approach during the wet1 calibration period fig 10 a clearly shows that both stand alone swatgrid and the linked sw gw modelling approach over and underestimates the low and high flows respectively during the wet1 calibration period the simulation results of the average2 validation period indicates that stand alone swatgrid overestimates the low and underestimates the peak flows fig 10 b also a general overestimation is observed for the low and high flows in case of the dry2 validation period by the stand alone swatgrid model fig 10 c this is further supported by the fdc generated for the simulated results which shows overestimation for the corresponding periods fig 10 f and g better results for stand alone swatgrid are observed for the wet2 validation period table 11 shows the performance evaluation of the simulation results of stand alone swatgrid and the linked sw gw modelling approach for the wet1 calibration period the results indicate that stand alone swatgrid fails to realistically simulate the runoff during the average2 and dry2 validation periods when calibrated during the wet1 period on the other hand the linked sw gw modelling approach can robustly simulate the runoff during all the four periods considered here i e wet1 average2 dry2 and wet2 the nse ranges between 0 80 and 0 91 and the pbias ranges from 10 12 to 1 66 for the linked sw gw modelling approach table 11 5 discussion the results from sections 4 2 and 4 3 show that stand alone swatgrid model performs better in the smaller catchment 405251 compared to the larger catchment 410044 but the swatgrid model performance varies significantly depending on climate conditions on the other hand the linked sw gw modelling approach performs equally well for both catchments under all three climatic situations i e average dry and wet considered at catchment 405251 the stand alone swatgrid model realistically simulates runoff only during the average1 and dry1 calibration periods satisfactory nse rmse and pbias obtained during both calibration periods and the corresponding average2 dry2 and wet2 validation periods poor model performance occurs when stand alone swatgrid is validated during the dry2 period for a wet1 calibration table 3 a possible reason for this is the transfer of model parameters from wet1 calibration to dry2 validation studies such as li et al 2012 and thirel et al 2015 have identified that model parameters are sensitive to the choice of calibration periods this is because when a model is calibrated for certain climatic conditions model parameters are optimised according to the way the model behaves during the calibration period but these parameters may not be optimal during a validation or application period with different climate conditions another possible explanation could be the poor representation of sw gw interactions by stand alone swatgrid during dry2 validation although the model accounts for the lateral and shallow gw flow through kinematic wave approximation and linear tank storage model respectively it lacks in the simulation of gw table and its interaction with the stream rathjens et al 2015 the linked sw gw modelling approach on the other hand simulates the sw gw interaction and therefore responds to a robust runoff simulation under different climatic periods the overestimation of the low flows at catchment 405251 during the dry2 validation period for average1 calibration by the linked sw gw modelling approach fig 5 g and table 5 can be attributed to the poor lai resolution used in this study due to the resampling approach used for lai temporal vegetation cover changes are poorly represented during the dry2 period this in turn affects the interception major flow generation component in semi arid regions and since tree die off is common during multi year droughts saiki et al 2017 practically more barren lands are generated this can actually result in more rainfall loss through percolation and pet however in the simulation more vegetation cover is used which possibly results in the generation of more lateral flow as plants retain more water in the root zone kim and mohanty 2016 this can possibly result in the generation of more runoff by the rainfall runoff model in the virtual simulation stage during the dry2 period this error is more likely to cascade during the transient state modflow simulation since modflow uses a 10 day time step in the linked sw gw approach thus the linked sw gw modelling approach results in an overestimation of the flow compared to both stand alone swatgrid and observed runoff during model calibration and validation at the smaller catchment 405251 swatgrid shows similar performance indicators i e nse rmse and pbias to the linked sw gw approach as demonstrated by orth et al 2015 this is possibly due to the smaller catchment size 122 km2 and low variability in runoff magnitudes during all calibration and validation periods figs 5 7 another reason is possibly due to the steeper slope in the smaller catchment 405251 within swatgrid flow direction is easier to identify in steeper catchments paul et al 2018 with more accurate representation of flow direction flow routing is improved and therefore swatgrid model performance is good even without the incorporation of gw modelling i e in small steep catchments runoff generation is governed more by rainfall and topography than by sw gw interactions for the larger catchment i e 410044 the stand alone swatgrid model fails to realistically simulate runoff in all calibration and validation periods notably the model fails during dry2 validation for the average1 calibration period table 9 wet2 validation for dry1 calibration table 10 and both average2 and dry2 validation periods for the wet1 calibration period table 11 during dry periods antecedent soil moisture plays a major role in runoff generation grayson and blöschl 2001 therefore the spatial variability of the soil moisture governs the local scale sub basin grid runoff generation within a catchment being a fully distributed model swatgrid can simulate spatiotemporal soil moisture flux however it is limited to the vadose zone during multi year droughts the gw table is highly depleted and the moisture storage is low therefore swatgrid model fails to simulate the soil moisture dynamics beyond the vadose zone which likely leads to the poor model performance especially during the dry2 validation similarly for the dry1 calibration of stand alone swatgrid the model parameters are optimised in a way that falsely represents the wet conditions as mentioned earlier for catchment 405251 moreover the dry1 calibration period also does not contain enough high flows which can force the model to replicate the wet2 conditions gan et al 1997 and therefore the stand alone swatgrid model underestimates the high flows of wet2 validation the poor performance of the stand alone swatgrid during average2 and dry2 validation periods for wet1 calibration at catchment 410044 can be attributed to swatgrid parameters associated with gw although there are four parameters which represent gw and baseflow in swatgrid sol awc available water holding capacity of the soil and gwqmn threshold depth of water in the shallow aquifer required for return flow to occur parameters see table s1 in the supporting information are more likely to be associated with the overestimation of low flows during the validation period cho et al 2010 beven et al 2015 this is because during the wet1 calibration baseflow is generally higher and thus a lower value of water holding capacity sol awc close to the lower limit of suggested value i e 0 and a lower value of threshold depth for return flow gwqmn close to the lower limit of suggested value i e 0 is optimised during calibration see table s7 in the supporting information when these values are transferred for the average2 and dry2 periods the model estimates higher baseflow and ultimately higher runoff since neither parameter is realistic for the dry2 and may not be realistic for the average2 conditions nevertheless this is eliminated by the introduction of three dimensional hydraulic conductivity kxx kyy and kzz see table s1 in the supporting information and streambed conductance ks of modflow during the linked sw gw modelling approach which better represents gw processes and sw gw interactions under different climates there are numerous studies where sw and gw models have been coupled e g van der kamp and hayashi 2009 tian et al 2015 bailey et al 2016 ibrakhimov et al 2018 while these studies have investigated the spatiotemporal dynamics of sw and gw quality under varying catchment management practices spatial pattern of gw discharge to stream network and the temporal sw gw interaction under future climate none has applied the sw gw modelling approach to more realistically simulate runoff in semi arid regions that experience high climatic variability and associated non stationarity in rainfall runoff relationships furthermore the linked sw gw modelling approach proposed here is simple and has the advantage of being flexible both sw and gw models can be chosen by the modeller compared to existing studies where the sw and gw models are fixed although the coupled swat modflow model bailey et al 2016 provides an all inclusive simulation of runoff and sw gw interaction swat is a semi distributed model which performs poorly in semi arid regions alfieri et al 2013 kling et al 2015 therefore in this study the linked sw gw modelling approach where a fully distributed sw model swatgrid is used in conjunction with a gw model modflow to simulate the runoff it is important to note that the objective of this study was not to provide an accurate estimation of spatiotemporal sw gw interactions or gw flow rather to realistically simulate runoff at catchment outlet under non stationary climate and rainfall runoff conditions 6 conclusion during multi year droughts sustainable water resources management requires realistic runoff estimates which as demonstrated here requires sw gw interactions to be considered and accounted for in the rainfall runoff modelling existing studies e g vaze et al 2010 chiew et al 2014 saft et al 2016 have indicated that conceptual rainfall runoff models are unreliable in semi arid catchments where hydroclimatic variability is high because they are unable to realistically capture the non stationarity in rainfall runoff relationships the findings above reveal that even process based fully distributed rainfall runoff models used in isolation can also result in deceptive runoff estimates if sw gw interactions are not realistically incorporated in the rainfall runoff modelling this study shows that these problems can be addressed via a linked sw gw modelling approach the findings also highlight that for catchments which experience high hydroclimatic variability differential split sample test with at least three different climate conditions i e average dry and wet should be standard for rainfall runoff model pre application assessment and selection otherwise runoff will continue to be overestimated during droughts leading to serious social economic and environmental impacts associated with water security e g kiem et al 2016 although the linked sw gw modelling approach presented here is time consuming it appears to be necessary for places like sea where there is significant hydroclimatic variability at the very least a linked sw gw modelling approach does a better job simulating rainfall runoff non stationarity in semi arid than the conceptual lumped rainfall runoff models that have been and continue to be commonly applied in sea this claim is supported by previous studies that suggested a shift towards fully distributed models or linked approaches such as that presented here is required to realistically simulate rainfall runoff non stationarity in semi arid regions e g vaze et al 2010 2011 chiew et al 2014 fowler et al 2016 saft et al 2016 the findings of this study contribute to the aims and priorities of the international association of hydrological sciences decade 2013 2022 panta rehi montanari et al 2013 and are widely applicable for water management under climate variability and change generally rainfall runoff models are calibrated and validated assuming the climate is stationary an assumption that increasingly seems unlikely to be true e g milly et al 2008 kiem and verdon kidd 2011 kiem et al 2016 acknowledgements proloy deb is funded by a university of newcastle international postgraduate research scholarship uniprs and a university of newcastle postgraduate research scholarship central unrsc 50 50 funding for this research was also provided by australian research council linkage grant lp120200494 with further funding and or in kind support also provided by the nsw office of environment and heritage sydney catchment authority hunter water corporation nsw office of water and nsw department of finance and services thanks are also given to dr alison oke bureau of meteorology vic australia and dr stefan kern icdc university of hamburg for providing information about the online data repositories and the lai dataset for the australian continent respectively thanks also to mr olivier rey lescure university of newcastle for providing elevation data and catchment boundary information hydrotsm zambrano bigiarini 2017a and hydrogof zambrano bigiarini 2017b packages of r were adopted and some codes were edited to plot most of the study results declaration of competing interest the authors declare that there is no conflict of interest associated with this manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 05 039 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
6346,interactions between surface water sw and groundwater gw have been identified as a major contributing factor to non stationarity in rainfall runoff relationships however because existing rainfall runoff models do not realistically account for these sw gw interactions they fail to robustly simulate runoff during multi year droughts especially in arid and semi arid catchments that are relatively flat therefore this study introduces a linked sw gw modelling approach and tests it under different climatic conditions average dry and wet periods in two heterogeneous semi arid catchments in southeast australia sea the linked sw gw modelling approach includes a fully distributed sw i e rainfall runoff model swatgrid and a three dimensional finite difference gw model modflow the results show that the linked sw gw modelling approach produces highly improved runoff simulations for the study catchments especially during dry conditions these findings demonstrate the importance of accounting for sw gw interactions when conducting rainfall runoff modelling and highlights that failing to do so will result in overestimation of runoff during droughts this is salient given projections for hotter and drier futures in many semi arid regions although the study is focused on sea the insights gained are highly applicable for water managers in any region that experience high hydroclimatic variability or change keywords swatgrid modflow stream aquifer interaction groundwater watershed hydrology climate variability 1 introduction climate variability and associated floods and droughts significantly impacts catchment conditions and water resources madhusoodhanan et al 2016 kiem et al 2016 deb et al 2018 kundzewicz et al 2018 in semi arid regions such as southeast australia sea which has experienced several multi year droughts in the past century verdon kidd and kiem 2009 catchment characteristic changes that occur during multi year droughts e g surface water sw and groundwater gw interaction land use change etc alter eco hydrological processes chiew et al 2014 saft et al 2015 and cause non stationarity in rainfall runoff relationships i e runoff generated per unit rainfall is lower during multi year droughts saft et al 2015 tian et al 2018 deb et al 2019 this introduces uncertainties in hydrological simulations and these uncertainties are exacerbated when rainfall runoff models calibrated to simulate current rainfall runoff relationships are used to project future hydrological conditions especially for regions that are projected to be drier döll and zhang 2010 chiew et al 2014 saft et al 2015 physically process based rainfall runoff models are considered superior to conceptually lumped models when compared for different climatic regimes bhadra et al 2010 ghavidelfar et al 2011 this is because the process based models are capable of considering the temporal changes in vegetation cover during simulation which contributes to non stationarity in rainfall runoff relationships during multi year droughts deb et al 2019 however to avoid model structural complexity existing process based rainfall runoff models e g topmodel swat hspf etc only consider the baseflow quick flow component of gw flow in the models beven et al 2015 also most rainfall runoff models were developed for european catchments and these catchments are typically steeper and contribution of the slow flow component of gw to sw is negligible than what occurs in flat and semi arid catchments winter 1995 käser and hunkeler 2016 vrzel et al 2018 in flat and semi arid catchments sw gw interaction plays a major role tanner and hughes 2015 this is because during multi year droughts the stream aquifer interaction is more likely to cease therefore instead of the aquifer contributing to stream which is dominant during normal rainfall conditions the aquifer takes water from the stream during multi year droughts parsons et al 2008 chiew et al 2014 deb et al 2019 due to the structural limitation of the existing rainfall runoff models this detailed sw gw interaction is not realistically accounted for another important aspect of the existing process based rainfall runoff models is the spatial discretisation of soil map land use map and digital elevation model dem this is because semi distributed rainfall runoff models classify the whole catchment into sub basins or hydrological response units hrus based on the similarities in soil properties and land use and lump the inputs for each sub basin hru arnold and fohrer 2005 this overshadows the spatial heterogeneity of inputs especially rainfall and soil moisture which can be highly variable within a catchment rathjens et al 2015 furthermore water flow chemical from the agricultural field and sediment transport routing in a sub basin hru is done directly through the stream channel in a semi distributed model this may not always be true since flow and transport occur from one landscape location to another prior to entering the stream bosch et al 2010 this along with the spatial heterogeneity of input to models can be eliminated by the application of fully distributed models recent studies compared the fully distributed swatgrid model with lumped and semi distributed models in flat catchments of sea and united states of america respectively and found that fully distributed models outperform the semi distributed and lumped models deb and kiem 2019 pignotti et al 2017 in summary due to consideration of spatial heterogeneity of soil land use dem model inputs and the ability to calculate flow within a sub basin hru fully distributed rainfall runoff models appear to be more robust than lumped and semi distributed models especially in flatter catchments rainfall runoff models implicitly assume that catchment dynamics and associated rainfall runoff relationships will remain similar to that which occurred in the period covered by the data used for calibration and validation andrés doménech et al 2015 this assumption is flawed given catchment characteristics are known to change under prolonged drought conditions saft et al 2015 deb et al 2019 for instance during the millennium drought 1997 to 2009 there was a disproportionate runoff reduction in the sea with rainfall decreases only contributing to 52 66 runoff reduction potter and chiew 2011 several possible reasons for this include sw gw interaction leaf area index lai potential evapotranspiration pet saft et al 2015 ajami et al 2017 deb et al 2019 and influences from large scale climatic processes kiem and verdon kidd 2009 2011 most of these mechanisms are accounted for in rainfall runoff models but sw gw interactions and the temporal changes in lai vegetation cover are not therefore the existing research gap is identifying approaches to account for these two mechanisms in rainfall runoff modelling therefore the novelty of this study is the development of a modelling framework that integrates distributed rainfall runoff modelling with gw modelling to more realistically simulate runoff under different climatic conditions although the study focusses on sea the proposed approach is applicable to all regions and is likely to be particularly useful for catchments that experience high climatic variability and multi year decadal droughts 2 study area two anthropogenically unaltered catchments from sea with contrasting biophysical characteristics e g slope relief area mean elevation etc were considered in this study these catchments were selected based on the findings of saft et al 2015 and deb et al 2018 where non stationarity in rainfall runoff relationships were observed the two catchments were brankeet creek catchment victoria stream gauge located at ancona gauge number 405251 36 97 s 145 79 e and muttama creek catchment new south wales nsw stream gauge located at coolac gauge number 410044 34 93 s 148 16 e hereafter referred as 405251 and 410044 catchments respectively fig 1 brankeet and muttama creeks are the tributaries of goulburn and murrumbidgee river respectively further details on these catchments can be found in deb et al 2018 the hydrological properties of the soil in each catchment were derived from the australian soil database created by western and mckenzie 2004 the lithological information derived from the geosciences society of australia reveals that both of the catchments are dominated by sandstone and volcanic rocks except for the alluvium deposits found adjacent to the river bed also fractured fissured unconfined aquifers are predominant in the catchments 3 data and methods 3 1 data 3 1 1 hydro meteorological data the hydro meteorological data used in this study is shown in table 1 the rainfall data was collected from four rainfall stations and temperature data was derived from one meteorological station for each catchment rainfall data was available for the entire period at catchment 405251 and was missing for 3 of the study period covered in catchment 410044 days where rainfall data was missing were assumed to have zero rainfall this assumption is justified because all the missing data occurred during the world war ii drought period 1941 to 1953 and the probability of rainfall occurrence during droughts is negligible kisaka et al 2015 runoff maximum and minimum temperature data were missing for 5 of the study period missing runoff data on a given day e g 10th december 2003 was infilled by taking the average of runoff that occurred on the same day for all other years that data existed i e 10th december in all other years a similar infilling process was also employed for missing temperature data the gw table dataset in catchment 405251 was available for 23 observation wells for the period 1974 2015 table 1 however for 410044 the gw table dataset was only available for 45 observation wells and for the duration of 1971 2015 since the gw table data was required from 1940 onwards described later a virtual gw table was generated for those 45 wells on a monthly time scale this was done by creating the contour lines of the hydraulic head based on the available observation wells with gw table data recorded at a monthly frequency within the murrumbidgee river catchment muttama creek is a tributary to murrumbidgee river the spatial interpolation of the gw table within the contour lines was done via simple kriging sun et al 2009 xiao et al 2016 this approach is commonly used when gw table data is unavailable within the study catchment but is available at surrounding catchments cho et al 2010 wable et al 2017 abiye et al 2018 both catchments had minimal human intervention and therefore no pumping wells the hydrogeological maps retrieved from local government agencies suggest that local aquifers with low productivity dominate both catchments additionally bedrocks are usually thick often 10 m throughout both catchments 3 1 2 catchment characteristic data catchment characteristic data is shown in table 2 in order to use the same input data for all three models the areal rainfall data throughout each catchment was calculated based on the thiessen polygon approach brassel and reif 1979 pet was calculated using the hargreaves samani equation hargreaves and samani 1985 since this is considered to be the most appropriate approach for arid and semi arid regions moeletsi et al 2013 the dem land use land cover map soil map and the geology map were used directly in the modelling however due to the poor spatial resolution of the lai they were interpolated to the required grid size 900 m using the nearest neighbour method of resampling gonsamo et al 2011 3 2 rainfall runoff and gw models used 3 2 1 swatgrid the swatgrid hydrological model rathjens and oppelt 2012 rathjens et al 2015 was chosen for sw modelling as it has been shown to be the best performing rainfall runoff model under non stationarity in rainfall runoff conditions in sea deb and kiem 2019 swatgrid rathjens et al 2015 is a continuous physically based fully distributed rainfall runoff model it integrates the landscape routing and grid based setup which works in conjunction with the swat model instead of simulating the flows at an hru scale as in swat swatgrid discretises the catchment into user defined grid cells and computes the surface runoff lateral and shallow gw flow for each individual cell the model employs water balance approach to calculate runoff at grid scale eq 1 1 sw t i sw o i 1 t r d a y i q s u r f i e a i w s e e p i q gw i where swt i is soil water content at time t swo is the initial soil water content in mm t represents the simulation period in days rday i is the amount of rainfall on ith day in mm qsurf i represents the surface runoff in mm on the ith day ea i is the amount of pet on ith day in mm wseep i represents the amount of water in mm entering the vadose zone on the ith day and qgw i represents the amount of baseflow in mm on the ith day the model generates the surface runoff through integrating the overland and channel runoff in order to differentiate these two types of runoff a flow separation ratio is used which is based on the topographic index of the catchment eq 2 the topographic index considers topography drainage density channel bed morphology and the soil properties 2 λ i l n a i tan β i k i z i i 1 2 n where i represents the grid number λi is the topographic index ai is the upslope area contributing to per unit contour length in m βi is the slope of the cell in degrees ki is the saturated hydraulic conductivity m day 1 and zi is the soil depth in m for each grid cell unlike swat which uses constant flow separation ratio to generate runoff swatgrid calculates the spatially distributed proportions of the channel and landscape overland flow using the flow separation index which is intrinsically related to the topographic index rathjens et al 2015 swatgrid calculates the surface runoff lateral flow and the shallow gw flow while using the scs cn method kinematic storage model and linear tank storage models respectively for each grid cell the main difference between the swat and swatgrid setup is during the spatial discretisation of dem into hrus in swat and grids in swatgrid in swatgrid the dem was used to identify the flow paths and to define the grid cells this was done while using the landscape analysis tool topographic parameterization topaz garbrecht and martz 2000 and is a pre requisite for swatgrid as swat was developed to divide the whole catchment into small sub basins and to integrate the spatial information given by the dem each grid is defined as a sub basin in swatgrid the outputs are the water balance components runoff pet soil water storage etc in the form of a stack of data frames for each grid cell at the user defined temporal resolution due to the complicated structure of swatgrid model the number of parameters for model calibration can range from 10 to 15 hence to reduce the computational time a sensitivity test was done following the approach by uniyal et al 2015 and then six of the most sensitive parameters were considered in model calibration table s1 of supporting information most of the sensitive model parameters were related to gw and soil moisture content 3 2 2 modflow modflow is a physically based three dimensional finite difference gw flow model that has been widely and successfully used in many global and regional studies harbaugh et al 2000 harbaugh 2005 de graaf et al 2017 gw flow is simulated while using a block centred finite difference approach eq 3 where the head is calculated at the centre of each grid cell considered in modelling the model allows the user to define the grid size and the number of layers either confined or unconfined aquifers 3 δ δ x k xx δ h δ x δ δ y k yy δ h δ y δ δ z k zz δ h δ z w s δ h δ t where x y and z are coordinate axes k is the hydraulic conductivity along the axis h is the hydraulic head w represents gw flux s is the specific storage of the aquifer and t represents time harbaugh 2005 the most recent version of modflow which uses a newtonian based solver nws algorithm was used in this study the nws algorithm allows the cells to dry and re wet again in an unconfined aquifer during simulation which was a major limitation in the previous versions niswonger et al 2011 since the model simulates the gw flow it does not consider several surface processes such as interception flow routing and surface runoff during simulation the model calibration parameters of modflow are hydraulic conductivity in longitudinal vertical and lateral direction and streambed conductance the unit and range of the parameters are given in table s1 of supporting information in addition to the base package of modflow several additional packages are also available for the model to accurately represent the hydro geologic condition the uzf1 package was used to calculate the recharge vadose zone percolation and pet in the model similarly the river package was used to define the stream segments and stream aquifer interaction also the head observation hob package was used to represent the gw table during simulation which was used in model calibration 3 3 sw gw interaction modelling strategy there are three possible approaches to simulate the sw gw interaction at a catchment scale 1 stand alone approach using gw models defining the river in the model set up 2 linked sw gw modelling approach and 3 developing a new model that considers both sw and gw processes cho et al 2010 although the stand alone approach is the simplest it is not applicable in this study due to the limitations associated with gw models not properly considering sw processes that are important in semi arid regions like sea e g interception overland flow etc option 3 is also not feasible due to data constraints and computational limitations that are currently associated with testing and applying such an approach on the other hand while significant effort is required for model set up and simulation the linked sw gw modelling approach provides the flexibility of choosing different models for a given objective e g to simulate sw gw interaction for instance the swat sw model component from swat mod can be exchanged for hec hms sw model without the modification of its source code therefore due to the flexibility and reliability of the existing models the linked sw gw modelling approach is selected for this study fig 2 the linked sw gw modelling approach should be able to represent the two way interactions between the sw and gw in particular the approach should be able to consider the surface aquifer and aquifer stream interactions as both phenomena govern the sw gw interaction sw hydrological processes such as interception topographic wetness index and land use pattern nolan et al 2007 control the spatial variability of recharge rate throughout the catchment this ultimately governs the gw table flux and therefore should be considered in the gw flow simulation this can be achieved by changing the recharge input for the modflow model similarly the discharge from the aquifer to the river network is necessary to be considered in the swatgrid model simulation therefore the linked sw gw modelling approach is applied in this study with the aim being to more realistically simulate flow under non stationary climate and rainfall runoff conditions the linked sw gw modelling approach consists of three major steps 1 virtual simulation of swatgrid to predict daily recharges and saving them as temporal data frames 2 transient state modflow simulation with the updated recharge from the previous step and storing the daily discharge from gw to stream 3 actual swatgrid simulation while considering the outputs of modflow model fig 3 during the transient modflow simulation the recharge input file of modflow rch is updated based on the recharge calculated by swatgrid in the previous step both virtual and actual simulations use the same processes and parameters except the input of gw flux to streamflow for different grid cells is considered in the actual simulation as sw and gw flow rates are different swatgrid was simulated at a daily time step whereas modflow was simulated at a 10 day time step following the recommendations of xu et al 2012 and surinaidu et al 2014 furthermore both swatgrid and modflow allows the user to select the spatial scale grid size at which the models are to be simulated for a smaller grid size of swatgrid compared to modflow the recharge is needed to be spatially lumped for the discrete modflow cells also it results in higher computational time and therefore in order to reduce the complexity a grid size of 900 m is considered to set up both swatgrid sw model and modflow gw model in this study based on the recommendations of beven 1990 and cho et al 2010 this resulted in 181 and 1226 grids including partial grids for the catchment boundaries for catchment 405251 and 410044 respectively see fig s1 in supporting information 3 4 modelling steps three major steps are required to set up the linked sw gw modelling approach 1 calibration of swatgrid with its integrated baseflow calculation stand alone swatgrid 2 steady state modflow calibration 3 runoff simulation using the linked sw gw modelling approach with the calibrated parameters of swatgrid and modflow derived from the previous steps being a fully distributed model the stand alone swatgrid model uses spatially distributed recharge fluxes to calculate the baseflow and lateral gw flow in a catchment the parasol technique of model auto calibration was done in the swat cup package of the model the model was calibrated against daily observed runoff at the catchment outlets i e 405251 and 410044 steady state modflow auto calibration was done while using the external pest program doherty 2015 against the hydraulic head of the observation wells the parameters adjusted for stand alone swatgrid and steady state modflow calibration are provided in table s1 of supporting information in the linked sw gw modelling approach the integrated baseflow and shallow gw flow calculation of the swatgrid model were turned off and the outputs of modflow were used therefore the parameters associated with the shallow gw flow and baseflow were also ignored in the simulation similarly the calculation of the pet in the modflow was also ignored and the output of swatgrid was used in the simulation the initial and boundary conditions used in the stead state modflow calibration were kept the same in the transient state modflow simulation in the linked sw gw modelling approach swatgrid set up involves two main steps generation of the watershed configuration file swatgrid fig and preparing swat input files the watershed configuration file stores the watershed characteristics particularly the watershed boundary flow direction number of upstream grids contributing to any grid flow paths and a map of the channel network these characteristics are obtained by pre processing the raster dataset dem in the topaz tool for a flat topography smaller grid size 1000 m is recommended beven 1990 therefore in this study a grid size of 900 m was used to set up the model this resulted in 136 and 1180 grids for catchment 405251 and 410044 respectively this was followed by the preparation of the remaining input files including the study area location grid size resolution soil type information land use classification baseflow information soil map raster file land use land cover map raster file climate inputs rainfall temperature evapotranspiration and calibration options these input details were stored in the swatgrid inp file after generating all these datasets swat modelling was conducted where swatgrid input files were taken as standard swat input data defining boundary conditions is important for modflow set up the hydrological boundaries are defined based on the information available from well logs dem and geological maps since the rivers in the catchments were perennial constant head boundary conditions were used while setting up the model this is because the contour lines of the gw table were parallel to the catchment boundary at the catchment outlet also both catchments were dominated with fractured aquifers and therefore based on the recommendations of surinaidu et al 2014 and varalakshmi et al 2014 the aquifers were modelled as an equivalent porous medium furthermore a single layer of saturated zone was considered for modflow setup in both catchments since the average gw table was within 30 m from the ground surface for the observed length of gw dataset also increasing the number of aquifers will increase inefficiency since the geology is fractured and computational time during modflow calibration the hydraulic conductivity and streambed conductance were adjusted based on the reference values derived from existing literature doble et al 2009 knowling et al 2015 wood and pierce 2015 3 5 differential split sample test the stand alone swatgrid and steady state modflow calibration and validation were done based on differential split sample test klemes 1986 where the models were calibrated for one climatic period and validated for the other in order to check the robustness of the linked sw gw modelling approach simulations were also done for the same climatic periods these periods were identified based on varying historical rainfall conditions which were chosen as per the recommendations of li et al 2012 this involved calculation of the mean annual rainfall mar for the whole record 1974 2013 and 1941 2015 for catchments 405251 and 410044 respectively for a stable model run i e to avoid parameter instability a simulation period of greater than five years is suggested by beven 2012 two periods of five years each with mar lower and greater than 15 of the mar for the whole record were selected as the dry and wet periods respectively for catchment 405251 additionally two other periods of five years with mar ranging between 5 of the mar for the whole record were selected as average periods for the corresponding catchment note that the five year window was not chosen arbitrarily instead windows ranging from five years to twelve years were considered with five years proving optimal for 405251 where optimal is determined based on closeness to mar for average and mar for those years below above the mar for the whole record as dry wet similarly two periods each of nine years for average dry and wet were selected for the catchment 410044 the periods were termed average1 average2 dry1 dry2 wet1 and wet2 both stand alone swatgrid and steady state modflow were calibrated for the average1 dry1 and wet1 periods and validated for the remaining three i e average2 dry2 and wet2 in turn for both catchments this resulted in a total of nine calibration and validation sets for each catchment and each model fig s2 since steady state condition in gw modelling refers to zero changes in hydraulic head over time the mean value of the observed hydraulic heads for each of the considered periods i e average1 dry1 and wet1 for calibration were used for all the observation wells 23 for catchment 405251 and 45 for 410044 during the steady state modflow calibration similarly the mean hydraulic head was also identified for the validation periods and modflow was validated for steady state condition the linked sw gw modelling approach was also simulated for all the considered periods i e average1 average2 dry1 dry2 wet1 and wet2 note that the converse calibration validation i e calibrated on average2 dry2 and wet2 and validate on average1 dry1 and wet1 was not performed as previous studies suggest that swapping calibration and validation periods leads to minimal useful insights e g coron et al 2012 li et al 2012 3 6 model performance evaluation nash sutcliffe efficiency nse nash and sutcliffe 1970 root mean square error rmse and percentage bias pbias were used to evaluate the linked sw gw modelling approach and stand alone swatgrid simulations whereas pbias and mean absolute error mae were used to evaluate the steady state modflow simulations during calibration and validation periods the performance of swatgrid and the linked sw gw modelling approach was also assessed based on the comparison of flow duration curves fdc during calibration and validation periods these performance metrics are described in detail in the section s1 of the supporting information 4 results 4 1 identification of average dry and wet periods the calculated mar indicates that the larger catchment i e 410044 571 mm is drier than the smaller catchment i e 405251 967 mm fig 4 the variation of mar during dry and wet periods is higher in catchment 410044 compared to catchment 405251 table 3 therefore wider spatial variability in rainfall is likely to contribute in the temporal variability of rainfall in the larger catchment nevertheless the wide variability of the rainfall in both catchments signifies the importance of a rainfall runoff model framework which can realistically capture the spatial and temporal non stationarity in rainfall runoff relationships 4 2 modelling catchment 405251 4 2 1 stand alone swatgrid calibration detailed results of the stand alone swatgrid model simulation are provided in deb and kiem 2019 and therefore are not repeatedly discussed here although the model performance evaluation statistics of the stand alone swatgrid and the linked sw gw modelling approach are given in the first half of tables 5 7 and in figs 5 7 for catchment 405251 4 2 2 steady state modflow calibration table 4 shows the model performance indices of the hydraulic head for model calibration and validation during different periods based on the 23 observation wells the maximum variation in the pbias is observed during wet1 calibration which ranges from 14 4 to 9 8 table 4 on the other hand the maximum variation in the mae is observed for average1 calibration 0 89 2 52 m the best results are obtained for the dry1 calibration case where the pbias and mae range from 4 9 to 8 8 and 1 17 to 1 41 m respectively it can be seen that the model overestimates the hydraulic head during the dry2 validation for all cases of calibration i e average1 dry1 and wet1 calibration periods table 4 nevertheless these results pbias 15 and mae 3 m demonstrate that the steady state modflow reproduces the hydraulic head within a good range of accuracy at the catchment under different climatic periods 4 2 3 transient state simulation by linked sw gw modelling approach fig 5 shows the comparison of runoff simulated by stand alone swatgrid model the linked sw gw modelling approach and the observed runoff during the average1 calibration period and average2 dry2 and wet2 validation periods both stand alone swatgrid and the linked sw gw modelling approach simulates well in accordance to the observed runoff for the calibration and validation periods runoff simulated by the linked sw gw modelling approach shows higher overestimation for the low flows during the dry2 period fig 5 c and g also a noticeable underestimation of the peak flows is also observed for the stand alone swatgrid and the linked sw gw modelling approach simulation for the wet2 period fig 5 d these results are further supported by the model performance statistics provided in table 5 where pbias indicates overestimation during dry2 simulation by the linked sw gw modelling approach 13 12 and underestimation for wet2 simulation by both models pbias 12 74 and 8 41 for the stand alone swatgrid and the linked sw gw modelling approach respectively in general both stand alone swatgrid and the linked sw gw modelling approach simulates the flow in good agreement all three performance criteria are in acceptable range with the observed runoff despite the over and underestimation of the high and low flows fig 6 shows the comparison of stand alone swatgrid and the linked sw gw modelling approach while considering dry1 as calibration period a similar pattern of hydrographs is observed for both stand alone swatgrid and the linked sw gw modelling approach simulations during calibration and validation periods the fdc indicates superior results by the linked sw gw modelling approach especially for the mid range and low flows during the average2 and dry2 validation periods fig 6 f and 7 g the nse ranges from 0 78 to 0 92 and 0 88 to 0 94 for the simulations by stand alone swatgrid and the linked sw gw modelling approach respectively table 6 similarly better rmse is also observed for the linked sw gw modelling approach 0 11 0 36 m3 s 1 compared to stand alone swatgrid model simulation 0 15 0 44 m3 s 1 pbias indicates that stand alone swatgrid underestimates the runoff during dry1 calibration and all validation periods whereas the linked sw gw modelling approach underestimates runoff during the dry1 and average2 simulation periods and overestimates during the dry2 and wet2 simulations table 6 nevertheless both stand alone swatgrid and the linked sw gw modelling approach simulates flow within the acceptable range while considering the three performance evaluation criteria realistic simulations by the stand alone swatgrid and the linked sw gw modelling approach can be seen in the monthly hydrographs and fdc during the wet1 calibration period fig 7 a while in the case of average2 validation overestimation is noted by stand alone swatgrid for the high flows fig 7 b and f the validation of stand alone swatgrid during dry2 period results in an overestimation of the peaks during the low flows similar results are also observed for the linked sw gw approach although a much lesser variation in the magnitude of the peaks is noted fig 7 c and g these results are also supported by the model performance evaluation as presented in table 7 stand alone swatgrid fails to simulate the runoff within an acceptable range nse rmse and pbias when the simulated runoff is compared to the observed runoff during the dry2 validation period nse rmse and pbias calculated from the observed and simulated runoff indicates the linked sw gw modelling approach results in better simulation for all four periods i e wet1 average2 dry2 and wet2 4 3 modelling catchment 410044 4 3 1 stand alone swatgrid calibration similar to the section 4 2 1 detailed results of the stand alone swatgrid model calibration results for catchment 410044 are provided in deb and kiem 2019 comparative results of the stand alone swatgrid model calibration and validation and simulations of linked sw gw interaction are provided in the first half of tables 9 11 and figs 8 10 4 3 2 steady state modflow calibration table 8 shows the model performance indices of the hydraulic head simulated by steady state modflow during calibration and validation during different periods at catchment 410044 the pbias indicates that the hydraulic head is overestimated during the dry2 validation periods for average1 and wet1 calibration 14 2 and 11 2 for dry2 validation for average1 and wet1 calibration period respectively it can be observed that the steady state modflow underestimates positive pbias the hydraulic head for all validation periods during dry1 calibration table 8 mae indicates that higher variation in the simulated and observed hydraulic head persist during the dry2 validation for average1 and wet1 calibration 1 32 and 1 02 m respectively on the other hand the maximum value of mae is observed for the wet2 validation of dry1 calibration this indicates the model results are worse when calibrated for a certain climatic period and validated for the other climate in general steady state modflow reproduces the spatial distribution of hydraulic head in good agreement as pbias 15 and mae 3 m details provided in section s1 of supporting information throughout all considered climatic periods 4 3 3 transient state simulation by the linked sw gw modelling approach fig 8 displays the comparison of mean monthly runoff simulated by stand alone swatgrid and the ds approach during the average1 calibration period and average2 dry2 and wet2 validation periods while comparing the observed runoff both stand alone swatgrid and the linked sw gw modelling approach reproduces the runoff well during the average1 calibration period fig 8 a however the fdc shows that the low flows are overestimated by stand alone swatgrid simulation fig 8 e a relatively better simulation by stand alone swatgrid is noted for the average2 validation period fig 8 b and f also from fig 8 c and g the stand alone swatgrid model fails to realistically simulate the runoff during the dry2 validation period although the linked sw gw modelling approach results in the improvement of runoff simulation fig 8 c and g the fdc indicates an overestimation of the mid range and low flows this is also supported by the pbias calculated 69 81 for the observed and simulated runoff for stand alone swatgrid table 9 in addition to this overestimation is also observed during the wet2 validation period pbias 21 89 for the stand alone swatgrid model on the other hand the performance indices nse rmse and pbias suggest that the linked sw gw modelling approach simulates the runoff within an acceptable range during all four periods considered table 9 fig 9 shows the comparison of stand alone swatgrid and the linked sw gw modelling approach while considering dry1 as calibration period stand alone swatgrid appears to underestimate the peak flows during the dry1 calibration period fig 9 a both stand alone swatgrid and the linked sw gw modelling approach simulates the runoff reasonably well during the average2 and dry2 validation periods furthermore fig 9 d indicates that stand alone swatgrid underestimates the peak flows for all the years 1992 2000 a similar pattern of underestimation is also observed for the linked sw gw modelling approach simulation fig 9 d although the magnitude of variance is lower compared to the stand alone swatgrid simulation table 10 shows the performance statistics of the model simulations during dry1 calibration and average2 dry2 and wet2 validation periods the results indicate superior performance by the linked sw gw modelling approach when compared to stand alone swatgrid nse ranges from 0 39 to 0 87 and 0 71 to 0 91 for the stand alone swatgrid and the linked sw gw modelling approach respectively similarly the range of pbias is observed to be much better in the case of the linked sw gw modelling approach 8 36 to 13 17 when compared to stand alone swatgrid model 30 31 to 99 12 table 10 fig 10 displays the comparison of monthly hydrographs and daily fdc for stand alone swatgrid and the linked sw gw modelling approach during the wet1 calibration period fig 10 a clearly shows that both stand alone swatgrid and the linked sw gw modelling approach over and underestimates the low and high flows respectively during the wet1 calibration period the simulation results of the average2 validation period indicates that stand alone swatgrid overestimates the low and underestimates the peak flows fig 10 b also a general overestimation is observed for the low and high flows in case of the dry2 validation period by the stand alone swatgrid model fig 10 c this is further supported by the fdc generated for the simulated results which shows overestimation for the corresponding periods fig 10 f and g better results for stand alone swatgrid are observed for the wet2 validation period table 11 shows the performance evaluation of the simulation results of stand alone swatgrid and the linked sw gw modelling approach for the wet1 calibration period the results indicate that stand alone swatgrid fails to realistically simulate the runoff during the average2 and dry2 validation periods when calibrated during the wet1 period on the other hand the linked sw gw modelling approach can robustly simulate the runoff during all the four periods considered here i e wet1 average2 dry2 and wet2 the nse ranges between 0 80 and 0 91 and the pbias ranges from 10 12 to 1 66 for the linked sw gw modelling approach table 11 5 discussion the results from sections 4 2 and 4 3 show that stand alone swatgrid model performs better in the smaller catchment 405251 compared to the larger catchment 410044 but the swatgrid model performance varies significantly depending on climate conditions on the other hand the linked sw gw modelling approach performs equally well for both catchments under all three climatic situations i e average dry and wet considered at catchment 405251 the stand alone swatgrid model realistically simulates runoff only during the average1 and dry1 calibration periods satisfactory nse rmse and pbias obtained during both calibration periods and the corresponding average2 dry2 and wet2 validation periods poor model performance occurs when stand alone swatgrid is validated during the dry2 period for a wet1 calibration table 3 a possible reason for this is the transfer of model parameters from wet1 calibration to dry2 validation studies such as li et al 2012 and thirel et al 2015 have identified that model parameters are sensitive to the choice of calibration periods this is because when a model is calibrated for certain climatic conditions model parameters are optimised according to the way the model behaves during the calibration period but these parameters may not be optimal during a validation or application period with different climate conditions another possible explanation could be the poor representation of sw gw interactions by stand alone swatgrid during dry2 validation although the model accounts for the lateral and shallow gw flow through kinematic wave approximation and linear tank storage model respectively it lacks in the simulation of gw table and its interaction with the stream rathjens et al 2015 the linked sw gw modelling approach on the other hand simulates the sw gw interaction and therefore responds to a robust runoff simulation under different climatic periods the overestimation of the low flows at catchment 405251 during the dry2 validation period for average1 calibration by the linked sw gw modelling approach fig 5 g and table 5 can be attributed to the poor lai resolution used in this study due to the resampling approach used for lai temporal vegetation cover changes are poorly represented during the dry2 period this in turn affects the interception major flow generation component in semi arid regions and since tree die off is common during multi year droughts saiki et al 2017 practically more barren lands are generated this can actually result in more rainfall loss through percolation and pet however in the simulation more vegetation cover is used which possibly results in the generation of more lateral flow as plants retain more water in the root zone kim and mohanty 2016 this can possibly result in the generation of more runoff by the rainfall runoff model in the virtual simulation stage during the dry2 period this error is more likely to cascade during the transient state modflow simulation since modflow uses a 10 day time step in the linked sw gw approach thus the linked sw gw modelling approach results in an overestimation of the flow compared to both stand alone swatgrid and observed runoff during model calibration and validation at the smaller catchment 405251 swatgrid shows similar performance indicators i e nse rmse and pbias to the linked sw gw approach as demonstrated by orth et al 2015 this is possibly due to the smaller catchment size 122 km2 and low variability in runoff magnitudes during all calibration and validation periods figs 5 7 another reason is possibly due to the steeper slope in the smaller catchment 405251 within swatgrid flow direction is easier to identify in steeper catchments paul et al 2018 with more accurate representation of flow direction flow routing is improved and therefore swatgrid model performance is good even without the incorporation of gw modelling i e in small steep catchments runoff generation is governed more by rainfall and topography than by sw gw interactions for the larger catchment i e 410044 the stand alone swatgrid model fails to realistically simulate runoff in all calibration and validation periods notably the model fails during dry2 validation for the average1 calibration period table 9 wet2 validation for dry1 calibration table 10 and both average2 and dry2 validation periods for the wet1 calibration period table 11 during dry periods antecedent soil moisture plays a major role in runoff generation grayson and blöschl 2001 therefore the spatial variability of the soil moisture governs the local scale sub basin grid runoff generation within a catchment being a fully distributed model swatgrid can simulate spatiotemporal soil moisture flux however it is limited to the vadose zone during multi year droughts the gw table is highly depleted and the moisture storage is low therefore swatgrid model fails to simulate the soil moisture dynamics beyond the vadose zone which likely leads to the poor model performance especially during the dry2 validation similarly for the dry1 calibration of stand alone swatgrid the model parameters are optimised in a way that falsely represents the wet conditions as mentioned earlier for catchment 405251 moreover the dry1 calibration period also does not contain enough high flows which can force the model to replicate the wet2 conditions gan et al 1997 and therefore the stand alone swatgrid model underestimates the high flows of wet2 validation the poor performance of the stand alone swatgrid during average2 and dry2 validation periods for wet1 calibration at catchment 410044 can be attributed to swatgrid parameters associated with gw although there are four parameters which represent gw and baseflow in swatgrid sol awc available water holding capacity of the soil and gwqmn threshold depth of water in the shallow aquifer required for return flow to occur parameters see table s1 in the supporting information are more likely to be associated with the overestimation of low flows during the validation period cho et al 2010 beven et al 2015 this is because during the wet1 calibration baseflow is generally higher and thus a lower value of water holding capacity sol awc close to the lower limit of suggested value i e 0 and a lower value of threshold depth for return flow gwqmn close to the lower limit of suggested value i e 0 is optimised during calibration see table s7 in the supporting information when these values are transferred for the average2 and dry2 periods the model estimates higher baseflow and ultimately higher runoff since neither parameter is realistic for the dry2 and may not be realistic for the average2 conditions nevertheless this is eliminated by the introduction of three dimensional hydraulic conductivity kxx kyy and kzz see table s1 in the supporting information and streambed conductance ks of modflow during the linked sw gw modelling approach which better represents gw processes and sw gw interactions under different climates there are numerous studies where sw and gw models have been coupled e g van der kamp and hayashi 2009 tian et al 2015 bailey et al 2016 ibrakhimov et al 2018 while these studies have investigated the spatiotemporal dynamics of sw and gw quality under varying catchment management practices spatial pattern of gw discharge to stream network and the temporal sw gw interaction under future climate none has applied the sw gw modelling approach to more realistically simulate runoff in semi arid regions that experience high climatic variability and associated non stationarity in rainfall runoff relationships furthermore the linked sw gw modelling approach proposed here is simple and has the advantage of being flexible both sw and gw models can be chosen by the modeller compared to existing studies where the sw and gw models are fixed although the coupled swat modflow model bailey et al 2016 provides an all inclusive simulation of runoff and sw gw interaction swat is a semi distributed model which performs poorly in semi arid regions alfieri et al 2013 kling et al 2015 therefore in this study the linked sw gw modelling approach where a fully distributed sw model swatgrid is used in conjunction with a gw model modflow to simulate the runoff it is important to note that the objective of this study was not to provide an accurate estimation of spatiotemporal sw gw interactions or gw flow rather to realistically simulate runoff at catchment outlet under non stationary climate and rainfall runoff conditions 6 conclusion during multi year droughts sustainable water resources management requires realistic runoff estimates which as demonstrated here requires sw gw interactions to be considered and accounted for in the rainfall runoff modelling existing studies e g vaze et al 2010 chiew et al 2014 saft et al 2016 have indicated that conceptual rainfall runoff models are unreliable in semi arid catchments where hydroclimatic variability is high because they are unable to realistically capture the non stationarity in rainfall runoff relationships the findings above reveal that even process based fully distributed rainfall runoff models used in isolation can also result in deceptive runoff estimates if sw gw interactions are not realistically incorporated in the rainfall runoff modelling this study shows that these problems can be addressed via a linked sw gw modelling approach the findings also highlight that for catchments which experience high hydroclimatic variability differential split sample test with at least three different climate conditions i e average dry and wet should be standard for rainfall runoff model pre application assessment and selection otherwise runoff will continue to be overestimated during droughts leading to serious social economic and environmental impacts associated with water security e g kiem et al 2016 although the linked sw gw modelling approach presented here is time consuming it appears to be necessary for places like sea where there is significant hydroclimatic variability at the very least a linked sw gw modelling approach does a better job simulating rainfall runoff non stationarity in semi arid than the conceptual lumped rainfall runoff models that have been and continue to be commonly applied in sea this claim is supported by previous studies that suggested a shift towards fully distributed models or linked approaches such as that presented here is required to realistically simulate rainfall runoff non stationarity in semi arid regions e g vaze et al 2010 2011 chiew et al 2014 fowler et al 2016 saft et al 2016 the findings of this study contribute to the aims and priorities of the international association of hydrological sciences decade 2013 2022 panta rehi montanari et al 2013 and are widely applicable for water management under climate variability and change generally rainfall runoff models are calibrated and validated assuming the climate is stationary an assumption that increasingly seems unlikely to be true e g milly et al 2008 kiem and verdon kidd 2011 kiem et al 2016 acknowledgements proloy deb is funded by a university of newcastle international postgraduate research scholarship uniprs and a university of newcastle postgraduate research scholarship central unrsc 50 50 funding for this research was also provided by australian research council linkage grant lp120200494 with further funding and or in kind support also provided by the nsw office of environment and heritage sydney catchment authority hunter water corporation nsw office of water and nsw department of finance and services thanks are also given to dr alison oke bureau of meteorology vic australia and dr stefan kern icdc university of hamburg for providing information about the online data repositories and the lai dataset for the australian continent respectively thanks also to mr olivier rey lescure university of newcastle for providing elevation data and catchment boundary information hydrotsm zambrano bigiarini 2017a and hydrogof zambrano bigiarini 2017b packages of r were adopted and some codes were edited to plot most of the study results declaration of competing interest the authors declare that there is no conflict of interest associated with this manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 05 039 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 
6347,the satisfactory separation of baseflow from the other components of streamflow has long been a desirable but elusive goal in the search for consistent and automated baseflow separation techniques direct applicability to physical processes has been increasingly neglected by way of contrast this paper presents a continuous baseflow separation method that emphasises the physical relevance of the flow components and demonstrates its performance the proposed method combines the principle of an exponential master baseflow recession with a compatible smoothing function to link the segments of the master recession two calibrated parameters facilitate a good fit to a range of streamflow behaviours keywords streamflow baseflow hydrograph separation 1 introduction baseflow in streams has long intrigued hydrologists on the one hand baseflow appears to be a real phenomenon with distinctive and recognisable features and a plausible physical explanation on the other hand it has proved very difficult to define baseflow precisely or to separate it reliably from other components of streamflow hewlett and hibbert 1967 appleby 1970 nathan and mcmahon 1990 clearly however the consistent and preferably automated separation of baseflow from total flow remains a desirable goal at broader spatial and temporal scales baseflow behaviour provides information on groundwater status seasonal low flows and instream ecology at finer scales subtraction of baseflow from total flow can assist with the analysis of short term runoff behaviour this paper presents a continuous baseflow separation technique that retains good physical relevance of the separated flow components and shows many of the commonly accepted baseflow features summarised by murphy et al 2009 first is a brief overview of baseflow fundamentals and current baseflow separation techniques more comprehensive reviews of the field include those of hall 1968 tallaksen 1995 brodie and hostetler 2005 and murphy et al 2009 1 1 baseflow streamflow following a rainfall event is commonly thought of as comprising three components quickflow interflow and baseflow barnes 1939 nathan and mcmahon 1990 tallaksen 1995 terminology definitions and even the number of components recognised vary to some extent between sources hewlett and hibbert 1967 murphy et al 2009 but baseflow is always the slowest responding and longest lasting component of streamflow the faster components of streamflow can be associated with a single rainfall event but baseflow cannot hewlett and hibbert 1967 baseflow has been described as flow from groundwater aquifers hewlett and hibbert 1967 murphy et al 2009 or as flow from groundwater storage or other delayed sources hall 1968 tallaksen 1995 nathan and mcmahon 1990 visualise a streamflow recession made up of several exponential decay components terms with lower recession constants and hence faster decay disappear soonest until finally only the component with the highest recession constant survives this they call baseflow combining these descriptions we can say that baseflow is the slowest decaying longest lasting component of streamflow it is usually associated with groundwater processes and cannot be attributed to a single rainfall event for more detailed analysis of baseflow it is convenient to distinguish between the relatively smooth recession phase during periods of little or no rain and the more complex recharge phase during significant rainfall events the two phases are treated separately below 1 2 baseflow recession the most recognisable phase of baseflow and the most amenable to quantitative analysis is the relatively smooth recession observed during extended periods of little or no rain the exponential decay equation of boussinesq 1877 is widely used to describe this phase of baseflow hall 1968 nathan and mcmahon 1990 tallaksen 1995 1 b t b 0 k t where bt is baseflow at time t b0 is initial baseflow at time zero and k is the recession constant boussinesq 1904 subsequently introduced further solutions based on his aquifer analysis and demonstrated that more complex non linear recessions could be described by the superposition of linear exponential terms hall 1968 the simplest superimposed form is obtained by including a constant in eq 1 to give the ice melt exponential of toebes and strang 1964 2 b t b 0 c k t c where c is a constant see also hall 1968 tallaksen 1995 with c positive it simulates a constant flow such as melt from permanent ice fields added to the exponentially receding flow with c negative it allows modelling of ephemeral streams by assuming that an exponential decay component greater than zero is still notionally present but includes some unmeasured hyporheic flow some variation in the recession rate between events at a given site is often observed this may be caused by variation in the initial distribution of water in the catchment s aquifers or by seasonal changes in evapotranspiration losses tallaksen 1995 there is hence a need to find an average curve that best fits the individual recessions at a site this is often called the master recession curve many methods have been used to estimate the master recession curve brodie and hostetler 2005 briefly describe twelve different approaches while nathan and mcmahon 1990 consider two common methods in greater detail simple decay functions such as eqs 1 and 2 assume an idealised catchment with exponential decay components combining close to the measuring point this assumption may be confounded by both artificial and natural effects including upstream flow regulation diversions and return flows pipe leakage and over watering in urban areas storage in natural lakes or wetlands and flow routing in long channels between source and measurement hall 1968 murphy et al 2009 small smooth extraneous effects may have little adverse effect on site calibration but large step changes are likely to disrupt any form of baseflow recession analysis unless they can be accounted for and removed beforehand 1 3 baseflow during an event baseflow is more difficult to define or measure during a rainfall event when groundwater is being recharged and the total hydrograph is dominated by the faster components of runoff many early approaches involved simple graphical separation of the hydrograph and carried an implicit assumption that the increase in flow during an event was just part of the event rainfall running off the catchment the common term direct runoff for the quickflow component reflects this assumption the extensive use of stable isotope tracers since the late 1960s to identify the components of a hydrograph has shown that the reality is considerably more complex the contribution of old water i e groundwater to event runoff is typically both larger and faster than previously expected hewlett and hibbert 1967 chapman and maxwell 1996 klaus and mcdonnell 2013 which implies the rapid displacement of stored water by new rain we can still say that the runoff event is a result of the rainfall event but we cannot say it is all the same water nevertheless there remains a need to separate the resulting runoff event into quickflow and baseflow components detailed tracer information will usually be unavailable and more qualitative methods have often been used summarising the more descriptive approach of papers such as nathan and mcmahon 1990 brodie and hostetler 2005 and murphy et al 2009 gives the following characteristic features of baseflow through the course of a runoff event 1 low flow conditions prior to the start of a runoff event typically consist entirely of baseflow 2 the baseflow recession will continue for a time after the rise of the total hydrograph 3 baseflow will peak after the total hydrograph peak due to the storage routing effect of the sub surface stores 4 the baseflow recession will most likely follow an exponential decay function 5 the baseflow hydrograph will rejoin the total hydrograph as quickflow ceases points 1 and 5 reflect the concept of faster event flows superimposed on longer lasting baseflow the idea behind point 2 is that rising stream levels during a runoff event suppress groundwater flow to the stream by reducing the hydraulic gradient until groundwater levels also rise or stream levels decrease again however there are two schools of thought on this to the extent that nathan and mcmahon 1990 divide their discussion of baseflow separation techniques into two groups those that follow this rule and those that do not point 3 supports the concept of baseflow as an attenuated slow moving component of streamflow point 4 adopts the pragmatic view that exponential decay is a good approximation to most situations even when not rigorously exact they are useful guidelines but baseflow separation during a runoff event is clearly less rigorous than during recession which places limits on the accuracy and scope of event based analysis 1 4 continuous baseflow separation many methods for continuous separation of baseflow have been proposed and are described in reviews by nathan and mcmahon 1990 brodie and hostetler 2005 and murphy et al 2009 among others they vary greatly in their degree of objectivity and ease of automation sloto and crouse 1996 describe an automated implementation of the fixed interval sliding interval and local minimum methods of baseflow separation while rutledge 1998 and piggott et al 2005 present different versions of the local minimum method these three methods are all automated versions of older graphical techniques they provide a predictable response which is consistent between users and compatible with older manual methods but they are not based on the underlying physical processes in the interests of consistency and automation there has been a strong trend towards the use of digital methods the first of these appears to be the recursive digital filter of lyne and hollick 1979 in which 3 q n kq n 1 t n t n 1 1 k 2 4 b n t n q n where qn is the filtered quickflow at time n bn is the filtered baseflow at time n tn is the original total flow at time n and k is the filter parameter the output from the filter is constrained so that the separated baseflow is not negative or greater than the original streamflow following the initial forward pass a reverse pass is applied to the separated baseflow to nullify any phase distortion i e to reduce lag then the same procedure is repeated for further separation lyne and hollick 1979 a fixed value of k 0 925 for daily data from all catchments has been proposed nathan and mcmahon 1990 murphy et al 2009 the expression derives from the field of signal analysis lyne and hollick 1979 where it is used as a frequency filter its application to streamflow assumes that the filtering of low frequency baseflow from high frequency quickflow is analogous to the analysis of other high frequency signals murphy et al 2009 li et al 2014 in its original electronics context the separated low frequency component tends toward the mean of the input waveform at a rate dependent on the filter parameter in its streamflow context the low frequency or baseflow component must tend toward a lower bound rather than the mean the constraints applied to the filter output are intended to adapt the method accordingly the lyne and hollick filter requires no calibration or other subjective user inputs and so is well suited to analysis and comparison of large data sets across many sites on the down side its application by different authors and software packages shows substantial variation in the estimated baseflow fraction of a given streamflow record ladson et al 2013 and there is little direct link to physical catchment processes making it less suitable for detailed single event analysis the step back from physical modelling also makes it harder for the user to visualise the underlying catchment processes and hence to detect data errors or other anomalous behaviour the lyne and hollick filter relies heavily on its applied constraints to give plausible hydrologic results chapman 1991 observed that it implies baseflow is constant when there is no direct runoff so that without constraints it cannot simulate a declining recession many alternative algorithms have been proposed that address this limitation by including a recession component and so provide a more elegant solution when used alone for baseflow separation boughton 1993 jakeman and hornberger 1993 chapman and maxwell 1996 chapman 1999 eckhardt 2005 2 method the baseflow separation method proposed here comprises a single backward pass through the observed data to fit an exponential master baseflow recession curve followed by a single forward pass of the lyne and hollick algorithms to smooth the connection between segments of the master recession the use of the master baseflow recession curve ensures that the commonly accepted features of baseflow are preserved during periods of recession the smoothing function simulates gradual groundwater recharge during the runoff event 2 1 master recession curve the master recession is fitted using the more versatile exponential form shown in eq 2 as it can model a wider range of streamflow behaviour than eq 1 since baseflow is by its nature a long lasting and slow moving process it is preferable to fit the master recession to a long term continuous record rather than to short extracts or single events given the nature of the process it is more convenient to fit it in a single backwards pass starting from the most recent data rearranging eq 2 and applying it to a single time step so that t 1 gives 5 m n 1 m n c k c where mn is the master recession value on day n k is the recession constant and c is a constant flow added to the exponential decay component the output is constrained so that the separated baseflow is not greater than the original streamflow the master recession should be fitted by eye using the guidelines presented in section 4 2 below 2 2 smoothed recession curve the master recession curve addresses the recession phase of runoff but does not consider the recharge phase physically realistic baseflow can only increase smoothly during a runoff event as the groundwater store is replenished by rainfall sharp peaks in the master recession curve need to be smoothed in a way that reflects the physical constraints of the groundwater store the digital filters discussed in section 1 4 appear to be well suited to this task they all smooth peaks which is exactly what is needed but in this second pass the filter is applied to the master recession curve rather than total flow so the recession component of baseflow is already fully accounted for the best filter to use in this situation is the original lyne and hollick filter the only one which does not itself attempt to simulate the baseflow recession even this simplest form incorporates an exponential decay component in the filtered quickflow as can be seen in the special case where tn tn 1 i e approaching a constant total flow rate and the second term of eq 3 reduces to zero hence this smoothing algorithm exhibits the same degree of physical reality as the baseflow recession itself since both draining and recharge apply to the same groundwater store it is reasonable to try using the same value of k in both steps further strengthening the link between the recession and recharge phases of baseflow 2 3 streamflow data the method is demonstrated on three climatically and hydrologically diverse catchments with good quality flow data all located near melbourne australia the melbourne climate is temperate with warm dry summers and a tendency for maximum rainfall in winter or spring there is a strong gradation in mean annual rainfall across the area from less than 500 mm on the plains to the west to well over 1000 mm in the mountains to the east land conservation council of victoria 1973 little stringybark creek is an urbanising catchment of 4 47 square kilometres on the outer eastern fringe of the city about 40 km from the cbd mean annual rainfall is about 1110 mm and the stream has only occasionally ceased to flow walsh et al 2015 the streamflow record has been processed into daily hourly and six minute time steps mcmahons creek is a forested water supply catchment of 40 0 square kilometres located in mountainous country about 80 km east of melbourne mean annual rainfall is a little over 1000 mm and baseflow is persistent even in dry years hamel and fletcher 2013 kororoit creek is a mainly agricultural catchment of 74 9 square kilometres located in open country about 35 km north west of melbourne mean annual rainfall is about 600 mm and the stream is highly ephemeral with long periods of zero flow recorded in all years duncan et al 2014 3 results the master recession and smoothed baseflow fitted to daily streamflow data from the three test catchments are shown in figs 1 3 for clarity in the baseflow range the highest total flows are not shown the master recession curve eq 5 has a sawtooth shape which steps up quickly during significant rain then recedes smoothly until the next significant rain between events the master recession is a good match to the expected baseflow behaviour at each site the smoothed baseflow curve eqs 3 and 4 using the same value of k as the master recession in each case provides a more satisfactory estimate of expected baseflow behaviour during events the fitted recession parameter differs substantially between the three sites ranging from 0 91 to 0 98 with a daily time step even so visually acceptable baseflow separation can be achieved for each site the smoothed baseflow fully meets four of the five standard baseflow characteristics noted above low flow prior to an event is typically all baseflow the baseflow peak falls after the total hydrograph peak baseflow rejoins the total hydrograph as quickflow ceases and the recession is always an exponential decay function modelled baseflow does not continue to recede under the rising limb of the total hydrograph but baseflow separation methods do not all preserve this characteristic nathan and mcmahon 1990 schwartz 2007 4 discussion the method presented here attempts to retain as much physical relevance as possible in the separated components of streamflow and hence differs from other methods in common use several issues arising from these differences are addressed below 4 1 between catchment variation in recession parameter streamflow monitoring shows that the recession constant varies from one catchment to another it depends on catchment area climate geology and other factors all the same factors that influence streamflow magnitude for daily baseflow data nathan and mcmahon 1990 quote typical recession constant values ranging from 0 93 to 0 995 and this study has fitted values from 0 91 to 0 98 given this known variability to retain a strong link to observed behaviour the recession parameter must be calibrated to the catchment of interest the subjective element introduced in fitting model parameters is a disadvantage for comparative studies across multiple sites but for detailed analysis of individual events at a site calibration to that site becomes an advantage as local conditions can be fitted more exactly schwartz 2007 in practice it is more convenient to fit the recession constant k using the master recession rather than the smoothed baseflow as the underlying behaviour is more clearly visible a consideration of the processes involved together with the master recessions shown in figs 1 3 leads to the following guidelines for optimising the model parameters 4 2 calibration guidelines the master recession should show a step up during significant rain except shortly after a previous event where event runoff is still present since significant rain should recharge groundwater and thus increase baseflow if it does not a steeper recession lower k may be more appropriate the master recession should not lie much below total flow in the absence of rain except shortly after an event where event runoff is still present if it does the modelled baseflow is receding more slowly than the observed flows a steeper recession lower k may be more appropriate the master recession should not cling tightly to total flow in the absence of rain and be continuously held down by the not greater than total flow condition if it does the modelled recession is steeper than that of the observed flows a flatter recession higher k may be more appropriate if zero flows may occur the constant c must be a small negative flow typically a few percent of mean flow at the site if zero flows never occur c may be initially set to zero the constant c should be calibrated using observed flows close to zero setting the filter parameter in the second pass equal to the recession constant in the first pass appears to be satisfactory in each case examined 4 3 effect of time step on recession parameter the recession parameter k depends upon the time step both the reverse pass using eq 5 and the forward pass using eqs 3 and 4 are based on exponential decay 6 b n kb n 1 where bn is the baseflow at time step n and k is the recession parameter if the daily time step is now subdivided into 24 hourly sub steps the recession parameter in each sub step must be the 24th root of the original k to reach the same value at the end of the day hence the daily recession parameter of 0 93 at little stringybark creek becomes 0 9970 at hourly sub steps and 0 99970 at six minute sub steps these appear to be very high recession parameters but an example will show that they are correct baseflow separation using hourly and six minute data at little stringybark creek is shown in figs 4 and 5 using k 0 9970 and k 0 99970 respectively the baseflow traces in figs 4 and 5 are virtually identical they differ a little from the daily baseflow in fig 1 but it is not the separation that has changed the difference lies in the total flows where the minimum flows averaged over a day are a little higher than those at shorter time steps 4 4 initial values at the start of the first backward pass fitting the master recession i e the most recent data point the baseflow is not initially known baseflow assumed too low can increase only slowly along the master recession curve but baseflow assumed too high can be forced down in a single time step by low total flow hence for faster convergence to the correct value the first estimate of baseflow at the end of the flow record is better too high than too low in the absence of any further information initial baseflow should be assumed equal to total flow in the second forward pass the fitted master recession provides an initial baseflow estimate ideally the period of fitted baseflow will extend both before and after the period of interest allowing time for convergence although in practice this will not always be possible 4 5 missing data a similar argument applies to missing data the master recession curve can increase only slowly from low flow values so missing data should not be set to zero either a reasonable approximation of the missing values if possible or linear interpolation as proposed by murphy et al 2009 should be used the baseflow calculated during the missing period should also be treated as missing its only value is to minimise errors in calculated baseflow that extend beyond the missing data period 4 6 multiple passes of the digital filter algorithms multiple passes of the digital filter algorithms are both undesirable and unnecessary in this application and should not be used they are undesirable because the common parameter k unifying the recession and recharge phases is no longer common if is applied more than once to the recharge phase and this element of physical reality is lost they are unnecessary because the separation works satisfactorily in a single pass if the recession parameter is fitted correctly 4 7 interpretation of the digital filter there is one point of potential confusion in the description provided by lyne and hollick 1979 of their recursive digital filter in presenting the constraints on eq 3 they say that the output from a pass of the filter was constrained so that the separated slow flow was not negative or greater than the original streamflow in a physical interpretation separated slow flow not greater than the original streamflow clearly implies that quickflow is not negative that is stated explicitly by some later authors including brodie and hostetler 2005 murphy et al 2009 and ladson et al 2013 but not by lyne and hollick 1979 nevertheless that is what they intended their fig 1 can be reconstructed exactly only by prohibiting negative quickflow the distinction is important because eq 3 uses quickflow not baseflow to generate quickflow in the next time step and a purely algebraic interpretation of the constraints will be incorrect baseflow will appear to be unnaturally high during runoff events and carry a memory of high baseflow from one runoff event to the next for correct operation of the recursive digital filter a further constraint that quickflow is not negative must be added to the list the same constraint applies to the single pass of the filter algorithms used in the method presented here quickflow must not be negative 5 conclusions baseflow may be defined as the slowest decaying longest lasting component of streamflow it is usually associated with groundwater processes and cannot be attributed to a single rainfall event in the search for consistent and automated baseflow separation techniques direct applicability to physical processes has been increasingly neglected by way of contrast this paper presents a continuous baseflow separation method that emphasises the physical relevance of the flow components the new method is simple and provides an intuitively satisfactory representation of baseflow the method comprises a single backward pass through the observed total flow data to fit an exponential master baseflow recession curve followed by a single forward pass of the algorithms underlying the digital filter of lyne and hollick 1979 to smooth the connection between segments of the master recession an additional constraint prohibiting negative quickflow implied but not always stated in previous descriptions must be strictly observed for correct operation of the smoothing algorithms to maximise physical applicability two parameters must be calibrated the need for calibration is a disadvantage for broad scale screening and catchment comparison studies but the closer fit and better physical relevance provide distinct advantages for analysis at specific sites acknowledgements i would like to thank tim fletcher matt burns and the anonymous reviewers for their valuable comments on previous versions of this manuscript declaration of competing interest none this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors 
6347,the satisfactory separation of baseflow from the other components of streamflow has long been a desirable but elusive goal in the search for consistent and automated baseflow separation techniques direct applicability to physical processes has been increasingly neglected by way of contrast this paper presents a continuous baseflow separation method that emphasises the physical relevance of the flow components and demonstrates its performance the proposed method combines the principle of an exponential master baseflow recession with a compatible smoothing function to link the segments of the master recession two calibrated parameters facilitate a good fit to a range of streamflow behaviours keywords streamflow baseflow hydrograph separation 1 introduction baseflow in streams has long intrigued hydrologists on the one hand baseflow appears to be a real phenomenon with distinctive and recognisable features and a plausible physical explanation on the other hand it has proved very difficult to define baseflow precisely or to separate it reliably from other components of streamflow hewlett and hibbert 1967 appleby 1970 nathan and mcmahon 1990 clearly however the consistent and preferably automated separation of baseflow from total flow remains a desirable goal at broader spatial and temporal scales baseflow behaviour provides information on groundwater status seasonal low flows and instream ecology at finer scales subtraction of baseflow from total flow can assist with the analysis of short term runoff behaviour this paper presents a continuous baseflow separation technique that retains good physical relevance of the separated flow components and shows many of the commonly accepted baseflow features summarised by murphy et al 2009 first is a brief overview of baseflow fundamentals and current baseflow separation techniques more comprehensive reviews of the field include those of hall 1968 tallaksen 1995 brodie and hostetler 2005 and murphy et al 2009 1 1 baseflow streamflow following a rainfall event is commonly thought of as comprising three components quickflow interflow and baseflow barnes 1939 nathan and mcmahon 1990 tallaksen 1995 terminology definitions and even the number of components recognised vary to some extent between sources hewlett and hibbert 1967 murphy et al 2009 but baseflow is always the slowest responding and longest lasting component of streamflow the faster components of streamflow can be associated with a single rainfall event but baseflow cannot hewlett and hibbert 1967 baseflow has been described as flow from groundwater aquifers hewlett and hibbert 1967 murphy et al 2009 or as flow from groundwater storage or other delayed sources hall 1968 tallaksen 1995 nathan and mcmahon 1990 visualise a streamflow recession made up of several exponential decay components terms with lower recession constants and hence faster decay disappear soonest until finally only the component with the highest recession constant survives this they call baseflow combining these descriptions we can say that baseflow is the slowest decaying longest lasting component of streamflow it is usually associated with groundwater processes and cannot be attributed to a single rainfall event for more detailed analysis of baseflow it is convenient to distinguish between the relatively smooth recession phase during periods of little or no rain and the more complex recharge phase during significant rainfall events the two phases are treated separately below 1 2 baseflow recession the most recognisable phase of baseflow and the most amenable to quantitative analysis is the relatively smooth recession observed during extended periods of little or no rain the exponential decay equation of boussinesq 1877 is widely used to describe this phase of baseflow hall 1968 nathan and mcmahon 1990 tallaksen 1995 1 b t b 0 k t where bt is baseflow at time t b0 is initial baseflow at time zero and k is the recession constant boussinesq 1904 subsequently introduced further solutions based on his aquifer analysis and demonstrated that more complex non linear recessions could be described by the superposition of linear exponential terms hall 1968 the simplest superimposed form is obtained by including a constant in eq 1 to give the ice melt exponential of toebes and strang 1964 2 b t b 0 c k t c where c is a constant see also hall 1968 tallaksen 1995 with c positive it simulates a constant flow such as melt from permanent ice fields added to the exponentially receding flow with c negative it allows modelling of ephemeral streams by assuming that an exponential decay component greater than zero is still notionally present but includes some unmeasured hyporheic flow some variation in the recession rate between events at a given site is often observed this may be caused by variation in the initial distribution of water in the catchment s aquifers or by seasonal changes in evapotranspiration losses tallaksen 1995 there is hence a need to find an average curve that best fits the individual recessions at a site this is often called the master recession curve many methods have been used to estimate the master recession curve brodie and hostetler 2005 briefly describe twelve different approaches while nathan and mcmahon 1990 consider two common methods in greater detail simple decay functions such as eqs 1 and 2 assume an idealised catchment with exponential decay components combining close to the measuring point this assumption may be confounded by both artificial and natural effects including upstream flow regulation diversions and return flows pipe leakage and over watering in urban areas storage in natural lakes or wetlands and flow routing in long channels between source and measurement hall 1968 murphy et al 2009 small smooth extraneous effects may have little adverse effect on site calibration but large step changes are likely to disrupt any form of baseflow recession analysis unless they can be accounted for and removed beforehand 1 3 baseflow during an event baseflow is more difficult to define or measure during a rainfall event when groundwater is being recharged and the total hydrograph is dominated by the faster components of runoff many early approaches involved simple graphical separation of the hydrograph and carried an implicit assumption that the increase in flow during an event was just part of the event rainfall running off the catchment the common term direct runoff for the quickflow component reflects this assumption the extensive use of stable isotope tracers since the late 1960s to identify the components of a hydrograph has shown that the reality is considerably more complex the contribution of old water i e groundwater to event runoff is typically both larger and faster than previously expected hewlett and hibbert 1967 chapman and maxwell 1996 klaus and mcdonnell 2013 which implies the rapid displacement of stored water by new rain we can still say that the runoff event is a result of the rainfall event but we cannot say it is all the same water nevertheless there remains a need to separate the resulting runoff event into quickflow and baseflow components detailed tracer information will usually be unavailable and more qualitative methods have often been used summarising the more descriptive approach of papers such as nathan and mcmahon 1990 brodie and hostetler 2005 and murphy et al 2009 gives the following characteristic features of baseflow through the course of a runoff event 1 low flow conditions prior to the start of a runoff event typically consist entirely of baseflow 2 the baseflow recession will continue for a time after the rise of the total hydrograph 3 baseflow will peak after the total hydrograph peak due to the storage routing effect of the sub surface stores 4 the baseflow recession will most likely follow an exponential decay function 5 the baseflow hydrograph will rejoin the total hydrograph as quickflow ceases points 1 and 5 reflect the concept of faster event flows superimposed on longer lasting baseflow the idea behind point 2 is that rising stream levels during a runoff event suppress groundwater flow to the stream by reducing the hydraulic gradient until groundwater levels also rise or stream levels decrease again however there are two schools of thought on this to the extent that nathan and mcmahon 1990 divide their discussion of baseflow separation techniques into two groups those that follow this rule and those that do not point 3 supports the concept of baseflow as an attenuated slow moving component of streamflow point 4 adopts the pragmatic view that exponential decay is a good approximation to most situations even when not rigorously exact they are useful guidelines but baseflow separation during a runoff event is clearly less rigorous than during recession which places limits on the accuracy and scope of event based analysis 1 4 continuous baseflow separation many methods for continuous separation of baseflow have been proposed and are described in reviews by nathan and mcmahon 1990 brodie and hostetler 2005 and murphy et al 2009 among others they vary greatly in their degree of objectivity and ease of automation sloto and crouse 1996 describe an automated implementation of the fixed interval sliding interval and local minimum methods of baseflow separation while rutledge 1998 and piggott et al 2005 present different versions of the local minimum method these three methods are all automated versions of older graphical techniques they provide a predictable response which is consistent between users and compatible with older manual methods but they are not based on the underlying physical processes in the interests of consistency and automation there has been a strong trend towards the use of digital methods the first of these appears to be the recursive digital filter of lyne and hollick 1979 in which 3 q n kq n 1 t n t n 1 1 k 2 4 b n t n q n where qn is the filtered quickflow at time n bn is the filtered baseflow at time n tn is the original total flow at time n and k is the filter parameter the output from the filter is constrained so that the separated baseflow is not negative or greater than the original streamflow following the initial forward pass a reverse pass is applied to the separated baseflow to nullify any phase distortion i e to reduce lag then the same procedure is repeated for further separation lyne and hollick 1979 a fixed value of k 0 925 for daily data from all catchments has been proposed nathan and mcmahon 1990 murphy et al 2009 the expression derives from the field of signal analysis lyne and hollick 1979 where it is used as a frequency filter its application to streamflow assumes that the filtering of low frequency baseflow from high frequency quickflow is analogous to the analysis of other high frequency signals murphy et al 2009 li et al 2014 in its original electronics context the separated low frequency component tends toward the mean of the input waveform at a rate dependent on the filter parameter in its streamflow context the low frequency or baseflow component must tend toward a lower bound rather than the mean the constraints applied to the filter output are intended to adapt the method accordingly the lyne and hollick filter requires no calibration or other subjective user inputs and so is well suited to analysis and comparison of large data sets across many sites on the down side its application by different authors and software packages shows substantial variation in the estimated baseflow fraction of a given streamflow record ladson et al 2013 and there is little direct link to physical catchment processes making it less suitable for detailed single event analysis the step back from physical modelling also makes it harder for the user to visualise the underlying catchment processes and hence to detect data errors or other anomalous behaviour the lyne and hollick filter relies heavily on its applied constraints to give plausible hydrologic results chapman 1991 observed that it implies baseflow is constant when there is no direct runoff so that without constraints it cannot simulate a declining recession many alternative algorithms have been proposed that address this limitation by including a recession component and so provide a more elegant solution when used alone for baseflow separation boughton 1993 jakeman and hornberger 1993 chapman and maxwell 1996 chapman 1999 eckhardt 2005 2 method the baseflow separation method proposed here comprises a single backward pass through the observed data to fit an exponential master baseflow recession curve followed by a single forward pass of the lyne and hollick algorithms to smooth the connection between segments of the master recession the use of the master baseflow recession curve ensures that the commonly accepted features of baseflow are preserved during periods of recession the smoothing function simulates gradual groundwater recharge during the runoff event 2 1 master recession curve the master recession is fitted using the more versatile exponential form shown in eq 2 as it can model a wider range of streamflow behaviour than eq 1 since baseflow is by its nature a long lasting and slow moving process it is preferable to fit the master recession to a long term continuous record rather than to short extracts or single events given the nature of the process it is more convenient to fit it in a single backwards pass starting from the most recent data rearranging eq 2 and applying it to a single time step so that t 1 gives 5 m n 1 m n c k c where mn is the master recession value on day n k is the recession constant and c is a constant flow added to the exponential decay component the output is constrained so that the separated baseflow is not greater than the original streamflow the master recession should be fitted by eye using the guidelines presented in section 4 2 below 2 2 smoothed recession curve the master recession curve addresses the recession phase of runoff but does not consider the recharge phase physically realistic baseflow can only increase smoothly during a runoff event as the groundwater store is replenished by rainfall sharp peaks in the master recession curve need to be smoothed in a way that reflects the physical constraints of the groundwater store the digital filters discussed in section 1 4 appear to be well suited to this task they all smooth peaks which is exactly what is needed but in this second pass the filter is applied to the master recession curve rather than total flow so the recession component of baseflow is already fully accounted for the best filter to use in this situation is the original lyne and hollick filter the only one which does not itself attempt to simulate the baseflow recession even this simplest form incorporates an exponential decay component in the filtered quickflow as can be seen in the special case where tn tn 1 i e approaching a constant total flow rate and the second term of eq 3 reduces to zero hence this smoothing algorithm exhibits the same degree of physical reality as the baseflow recession itself since both draining and recharge apply to the same groundwater store it is reasonable to try using the same value of k in both steps further strengthening the link between the recession and recharge phases of baseflow 2 3 streamflow data the method is demonstrated on three climatically and hydrologically diverse catchments with good quality flow data all located near melbourne australia the melbourne climate is temperate with warm dry summers and a tendency for maximum rainfall in winter or spring there is a strong gradation in mean annual rainfall across the area from less than 500 mm on the plains to the west to well over 1000 mm in the mountains to the east land conservation council of victoria 1973 little stringybark creek is an urbanising catchment of 4 47 square kilometres on the outer eastern fringe of the city about 40 km from the cbd mean annual rainfall is about 1110 mm and the stream has only occasionally ceased to flow walsh et al 2015 the streamflow record has been processed into daily hourly and six minute time steps mcmahons creek is a forested water supply catchment of 40 0 square kilometres located in mountainous country about 80 km east of melbourne mean annual rainfall is a little over 1000 mm and baseflow is persistent even in dry years hamel and fletcher 2013 kororoit creek is a mainly agricultural catchment of 74 9 square kilometres located in open country about 35 km north west of melbourne mean annual rainfall is about 600 mm and the stream is highly ephemeral with long periods of zero flow recorded in all years duncan et al 2014 3 results the master recession and smoothed baseflow fitted to daily streamflow data from the three test catchments are shown in figs 1 3 for clarity in the baseflow range the highest total flows are not shown the master recession curve eq 5 has a sawtooth shape which steps up quickly during significant rain then recedes smoothly until the next significant rain between events the master recession is a good match to the expected baseflow behaviour at each site the smoothed baseflow curve eqs 3 and 4 using the same value of k as the master recession in each case provides a more satisfactory estimate of expected baseflow behaviour during events the fitted recession parameter differs substantially between the three sites ranging from 0 91 to 0 98 with a daily time step even so visually acceptable baseflow separation can be achieved for each site the smoothed baseflow fully meets four of the five standard baseflow characteristics noted above low flow prior to an event is typically all baseflow the baseflow peak falls after the total hydrograph peak baseflow rejoins the total hydrograph as quickflow ceases and the recession is always an exponential decay function modelled baseflow does not continue to recede under the rising limb of the total hydrograph but baseflow separation methods do not all preserve this characteristic nathan and mcmahon 1990 schwartz 2007 4 discussion the method presented here attempts to retain as much physical relevance as possible in the separated components of streamflow and hence differs from other methods in common use several issues arising from these differences are addressed below 4 1 between catchment variation in recession parameter streamflow monitoring shows that the recession constant varies from one catchment to another it depends on catchment area climate geology and other factors all the same factors that influence streamflow magnitude for daily baseflow data nathan and mcmahon 1990 quote typical recession constant values ranging from 0 93 to 0 995 and this study has fitted values from 0 91 to 0 98 given this known variability to retain a strong link to observed behaviour the recession parameter must be calibrated to the catchment of interest the subjective element introduced in fitting model parameters is a disadvantage for comparative studies across multiple sites but for detailed analysis of individual events at a site calibration to that site becomes an advantage as local conditions can be fitted more exactly schwartz 2007 in practice it is more convenient to fit the recession constant k using the master recession rather than the smoothed baseflow as the underlying behaviour is more clearly visible a consideration of the processes involved together with the master recessions shown in figs 1 3 leads to the following guidelines for optimising the model parameters 4 2 calibration guidelines the master recession should show a step up during significant rain except shortly after a previous event where event runoff is still present since significant rain should recharge groundwater and thus increase baseflow if it does not a steeper recession lower k may be more appropriate the master recession should not lie much below total flow in the absence of rain except shortly after an event where event runoff is still present if it does the modelled baseflow is receding more slowly than the observed flows a steeper recession lower k may be more appropriate the master recession should not cling tightly to total flow in the absence of rain and be continuously held down by the not greater than total flow condition if it does the modelled recession is steeper than that of the observed flows a flatter recession higher k may be more appropriate if zero flows may occur the constant c must be a small negative flow typically a few percent of mean flow at the site if zero flows never occur c may be initially set to zero the constant c should be calibrated using observed flows close to zero setting the filter parameter in the second pass equal to the recession constant in the first pass appears to be satisfactory in each case examined 4 3 effect of time step on recession parameter the recession parameter k depends upon the time step both the reverse pass using eq 5 and the forward pass using eqs 3 and 4 are based on exponential decay 6 b n kb n 1 where bn is the baseflow at time step n and k is the recession parameter if the daily time step is now subdivided into 24 hourly sub steps the recession parameter in each sub step must be the 24th root of the original k to reach the same value at the end of the day hence the daily recession parameter of 0 93 at little stringybark creek becomes 0 9970 at hourly sub steps and 0 99970 at six minute sub steps these appear to be very high recession parameters but an example will show that they are correct baseflow separation using hourly and six minute data at little stringybark creek is shown in figs 4 and 5 using k 0 9970 and k 0 99970 respectively the baseflow traces in figs 4 and 5 are virtually identical they differ a little from the daily baseflow in fig 1 but it is not the separation that has changed the difference lies in the total flows where the minimum flows averaged over a day are a little higher than those at shorter time steps 4 4 initial values at the start of the first backward pass fitting the master recession i e the most recent data point the baseflow is not initially known baseflow assumed too low can increase only slowly along the master recession curve but baseflow assumed too high can be forced down in a single time step by low total flow hence for faster convergence to the correct value the first estimate of baseflow at the end of the flow record is better too high than too low in the absence of any further information initial baseflow should be assumed equal to total flow in the second forward pass the fitted master recession provides an initial baseflow estimate ideally the period of fitted baseflow will extend both before and after the period of interest allowing time for convergence although in practice this will not always be possible 4 5 missing data a similar argument applies to missing data the master recession curve can increase only slowly from low flow values so missing data should not be set to zero either a reasonable approximation of the missing values if possible or linear interpolation as proposed by murphy et al 2009 should be used the baseflow calculated during the missing period should also be treated as missing its only value is to minimise errors in calculated baseflow that extend beyond the missing data period 4 6 multiple passes of the digital filter algorithms multiple passes of the digital filter algorithms are both undesirable and unnecessary in this application and should not be used they are undesirable because the common parameter k unifying the recession and recharge phases is no longer common if is applied more than once to the recharge phase and this element of physical reality is lost they are unnecessary because the separation works satisfactorily in a single pass if the recession parameter is fitted correctly 4 7 interpretation of the digital filter there is one point of potential confusion in the description provided by lyne and hollick 1979 of their recursive digital filter in presenting the constraints on eq 3 they say that the output from a pass of the filter was constrained so that the separated slow flow was not negative or greater than the original streamflow in a physical interpretation separated slow flow not greater than the original streamflow clearly implies that quickflow is not negative that is stated explicitly by some later authors including brodie and hostetler 2005 murphy et al 2009 and ladson et al 2013 but not by lyne and hollick 1979 nevertheless that is what they intended their fig 1 can be reconstructed exactly only by prohibiting negative quickflow the distinction is important because eq 3 uses quickflow not baseflow to generate quickflow in the next time step and a purely algebraic interpretation of the constraints will be incorrect baseflow will appear to be unnaturally high during runoff events and carry a memory of high baseflow from one runoff event to the next for correct operation of the recursive digital filter a further constraint that quickflow is not negative must be added to the list the same constraint applies to the single pass of the filter algorithms used in the method presented here quickflow must not be negative 5 conclusions baseflow may be defined as the slowest decaying longest lasting component of streamflow it is usually associated with groundwater processes and cannot be attributed to a single rainfall event in the search for consistent and automated baseflow separation techniques direct applicability to physical processes has been increasingly neglected by way of contrast this paper presents a continuous baseflow separation method that emphasises the physical relevance of the flow components the new method is simple and provides an intuitively satisfactory representation of baseflow the method comprises a single backward pass through the observed total flow data to fit an exponential master baseflow recession curve followed by a single forward pass of the algorithms underlying the digital filter of lyne and hollick 1979 to smooth the connection between segments of the master recession an additional constraint prohibiting negative quickflow implied but not always stated in previous descriptions must be strictly observed for correct operation of the smoothing algorithms to maximise physical applicability two parameters must be calibrated the need for calibration is a disadvantage for broad scale screening and catchment comparison studies but the closer fit and better physical relevance provide distinct advantages for analysis at specific sites acknowledgements i would like to thank tim fletcher matt burns and the anonymous reviewers for their valuable comments on previous versions of this manuscript declaration of competing interest none this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors 
6348,the main objective of this research work was to propose and verify a new soft computing approach based on multivariate adaptive regression splines mars and particle swarm optimization pso for spatial prediction of flash flood susceptible areas a high frequency tropical typhoon area located on northwest of vietnam was selected as a case study for this purpose a gis database for the study areas was prepared including 654 flash flood inundations and 12 influencing variables elevation slope curvature toposhade aspect topographic wetness index stream power index stream density normalized difference vegetation index soil type lithology and rainfall which were compiled from various sources the database was used to build and verify the prediction model we assessed the model s performance through various indices including classification accuracy rate area under the curve auc precision and recall we also compared the model s usability with five state of the art machine learning techniques including the backpropagation neural network support vector machine and classification tree the results revealed that the hybrid pso mars model outperformed other benchmark models in all the employed statistical measures we conclude that the proposed model can be particularly suited for flash flood forecasting problems at high frequency tropical typhoon area keywords multivariate adaptive regression splines particle swarm optimization flash flood susceptibility mapping gis 1 introduction floods are considered as the most destructive and frequent natural hazard worldwide that cause huge damage to property and affects millions of people in various countries every year bubeck and thieken 2018 chang et al 2014 peduzzi 2017 ward et al 2017 in 2013 the global flood damage was estimated to be more than 50 billion us dollars wasko and sharma 2017 it is anticipated that the flood damage could be reached 1 trillion us dollars yearly by 2050 due to accelerations of population growth and changes of climates and land cover patterns bubeck and thieken 2018 hartnett and nash 2017 studies of flood are expected to reduce economic losses and flood related facilities bubeck et al 2012 chang et al 2018 2019 therefore studies on flood modeling and prediction aiming to reduce flood damages are urgent tasks floods happen when a normally dry land is inundated by temporary waters bergé nguyen and crétaux 2015 and based on different mechanisms floods can be grouped into subsets including coastal flood river flood sewer flood urban flood and flash flood kundzewicz et al 2014 different from the other flood types the flash flood is a particularly damaging flood type due to fast onset characteristics and high flow velocities especially flash floods with large debris loads can be extremely dangerous for infrastructure and human lives due to their hydro static forces and natural impacts caused by flowing materials jalayer et al 2018 santo et al 2017 modeling and predicting the probability of flash floods play a crucial role in mitigating and managing future of flood hazards that can help authorities in operational settings and for suitable strategic planning bodoque et al 2016 giordano et al 2017 hapuarachchi et al 2011 prior studies have successfully provided various modeling approaches for the flash flood prediction including regression analysis and rainfall runoff simulation carpenter et al 1999 edouard et al 2018 javelle et al 2010 lucía et al 2018 tramblay et al 2010 consequently various robust models and tools have successfully proposed i e to name a few hfps donigan et al 1984 hec ras brunner 1995 1997 hydrotel fortin et al 2001 modflow harbaugh 2005 wetspa liu and de smedt 2005 and swat douglas mankin et al 2010 and mike zhou et al 2012 however long period time series data at monitoring stations are required for building accurate flash flood models yu et al 2018 which are difficult to many areas i e in developing countries to overcome the above limitation a new approach namely on off classification has been considered recently khosravi et al 2018b tehrany et al 2014 tien bui and hoang 2017 literature review shows that machine learning techniques have been widely used in flood studies including support vector machines svm tehrany et al 2015 naive bayes liu et al 2017 neuro fuzzy logic tien bui et al 2016 artificial neural networks nikoo et al 2016 decision trees khosravi et al 2018b tehrany et al 2013 and garp and quest darabi et al 2019 however high accuracy prediction of flash flood susceptible areas is still difficult bui et al 2019a therefore new machine learning ensembles models have been explored i e bayesian ensemble framework tien bui and hoang 2017 neural fuzzy optimized by optimization algorithms hong et al 2018 pso based neural networks ngo et al 2018a hybridization of statistics and machine learning algorithms costache 2019 and fuzzy classification ensembles bui et al 2019b overall prediction accuracy of flash flood susceptibility has been improved significantly with the use of ensembles models this research work aims to expand the body of the flash flood prediction knowledge by proposing a new soft computing ensemble approach based on multivariate adaptive regression splines mars and particle swarm optimization pso named as mars pso for flash flood susceptibility prediction the newly proposed model is established and verified with a case study at lao cai area in the northern region of vietnam a high frequency tropical typhoon area to the best of our knowledge this is the first mars pso is proposed for flash flood modeling and prediction mars friedman 1991b is a powerful machine learning method which can be highly useful for analyzing complex and multivariate phenomena this method is based on a divide and conquer strategy within which the data under analysis are separated into distinctive regions the relationship between variables of interest in this region is inferred by a linear model gholampour et al 2018 goh et al 2018 heddam and kisi 2018 hoang et al 2017 therefore mars is potentially useful for discovering hidden functional relationships of gis data moreover the learning phase of mars requires a proper setting of the two tuning parameters the maximum number of basis functions bfs and the penalty coefficient c based on related studies hoang et al 2018 liao et al 2018 prayogo and susanto 2018 tien bui et al 2017d wang et al 2017 xue 2017 the task of identify parameters of machine learning algorithms can be modeled as optimization problems in continuous domains hence this current work proposes to employ the particle swarm optimization pso as a metaheuristic to optimize the mars model specifically used for flash flood susceptibility prediction the rest of this paper is structured as follows the study area and the gis database are generally described in the second section followed by the third section that reviews the employed machine learning and metaheuristic algorithms the fourth section provides the description of the proposed model for flash flood susceptibility mapping followed by the next section that reports the experimental results concluding remarks on this study are stated in the final section 2 mathematical background of the employed algorithms 2 1 multivariate adaptive regression splines mars first proposed by friedman 1991b mars is a popular machine learning approach for mining a function that describes the relationship between a set of predictors xs and an output variable y this machine learning method does not require any assumptions regarding the distribution of the involved variables thus it is considered to be a non parametric approach for data modeling notably mars is highly useful to be applied in the situation that the mapping function for each sub group of the collected data is different york et al 2006 previous works involving mars implementation show that this machine learning approach can help to construct good predictive models for complex engineering datasets deo et al 2017 goh et al 2018 2017 heddam and kisi 2018 roy and datta 2017 since the related works on flood susceptibility prediction demonstrate that the classification function needed to discriminate flood and non flood areas can be highly complex mars can be potentially useful for generalizing such classification function from the gis database during the learning phase mars essentially dissects the learning space of flash flood influencing variables into smaller regions as illustrated in fig 1 for each sub region mars constructs a linear classification model which provides the best fit to the data subset as can been seen in fig 1 mars establishes a piecewise linear function for representing a global model with a data driven manner hoang et al 2017 due to this distinguished feature mars has been successfully employed in various fields liao et al 2018 moreover it is noted that the learning phase of the final prediction model is achieved via the construction of a set of basis functions bfs friedman 1991b these bfs provide descriptions of the relationship between flash flood conditioning factors and output class of flood non flood state a typical form of a bf is shown in the following formulas friedman 1991b 1 b m x max 0 c x or b m x max 0 x c where bm is a bf x denotes a flash flood susceptibility predictor c represents a threshold parameter discovered during the learning phase the final classification model constructed by mars employed for flash flood susceptibility prediction is compactly stated as follows 2 f x s i g n α 0 m 1 k α m b m x where α 0 α 1 α m represent the weighting coefficients f x is the model output which is 1 for the case of non flood class and 1 for the case of flood class k denotes the number of weighting coefficients 2 2 particle swarm optimization the implementation of the mars classification model necessitates the determination of its hyper parameters including the maximum number of basis functions bfs and the penalty coefficient c hoang et al 2017 because the problem of hyper parameter determination can be transferred as an optimization issue this study relies on the particle swarm optimization pso algorithm for optimizing the performance of mars pso proposed by kennedy and eberhart 1995 is a well known stochastic optimization technique that works by building a flock of birds randomly within a population swarm over the searching space called as a particle the good performance of this metaheuristic approach has been reported by previous studies spanning many fields inti and tandon 2017 tien bui et al 2017b zhang and yang 2017 in this research the parameters of the mars can be transferred to the coordination of each particle in the swarm for optimizing thus the merit of each particle position is measured by our proposed objective function value which is also call as the fitness value the coordination of each particle in the swarm is limited in a defined searching space moreover it is noted that particles in the swarm are identified by both their positions and velocities in each training iteration all particles fly across the searching space to find the best position for each particle the best fitness value next the best position of the swarm is determined by selecting the particle position with the highest merit value finally the best value for the mars parameters is derived which is the coordination of the best position of the swarm supposing the position of the i th particle can be expressed as vector x i vi is its velocity and p is the best positions of its neighbors the velocity of each particle is updated using an equation below 3 v i χ v i φ j 1 k i a j p n b r j x i where χ and φ are coefficients and usually used to 0 7298 and 4 1 respectively ki is neighbors for particle i and nbrj is the i s j th neighbor each neighbor of a particle is weighted using coefficient aj as follows 4 a j b j b j b j u 0 1 j 1 k i where u 0 1 denotes a uniform random number between 0 and 1 3 study site and data used 3 1 general description of the study site the study area is the region of two districts bac ha and bao yen bhby belonging to the northwest mountainous province of lao cai around 263 km from hanoi vietnam it is located between the longitudes 104 10 e and 105 37 e and between the latitudes 22 5 n and 22 40 n covering about 1510 4 km2 fig 2 topography is rugged and variable with hilly mountains gorges and highly dense rivers the altitude is from 38 9 m to 1878 69 m above sea level with the mean is 538 1 m areas with slopes from 10 to 40 account for 85 4 of the total study area whereas approximately 11 5 of the bhby has slope degrees less than 10 and areas with slopes larger than 40 occupy only 3 1 of the total study area administratively bhby is divided into 37 communes and 2 towns with total population is 136 06 thousand people the average population density is 83 people km2 and 96 people km2 for bac ha and bao yen respectively the climate is characterized by subtropical monsoonal with two distinct seasons a rainy season lasts from november to aprilwhereas a dry season is from may to october truong et al 2018 the study area located in a storm center in the world and usually receives heavy and extreme rainfalls every year the average annual rainfall varies from 1400 mm to 1843 7 mm and mainly concentrates in the rainy reason gso 2017 tran 2011 although flash floods and landslides occur every year however the widespread flash floods happened in three days 10 12 in october 2017 were considered the most destructive consequence the highest total rainfall at a measured station was 201 mm 3 2 description of the collected data 3 2 1 flash flood inventory map spatial prediction of areas prone to flash flooding using machine learning requires understanding and learning from events occurred in the past and present borga et al 2011 tien bui and hoang 2017 therefore establishment of flash flood inventory map is a key issue and mandatory task however flash flood is usually characterized both by small temporal and spatial scales that are difficult to observe and map borga et al 2011 therefore collection of flash flood inventories is still the most critical in literature most of published works collected happened flash flood events using handhold gps and field survey which are time consuming and not cost effective i e tehrany et al 2015 and khosravi et al 2018a in this research a flash flood inventory map which was the result of the stated fund project of flash flood b2018 mda 18dt ngo et al 2018b was used accordingly a total of 654 flash flood polygons occurred in the rainfall season of 2017 were identified using sentinel 1 sar synthetic aperture radar imagery change detection techniques then these flood polygons were checked in a series of fieldworks using igeotrans a gps application designed for smartphone tien bui et al 2015b and handhold gps more detailed information on the flash flood inventory map and the change detection techniques can be found in ngo et al 2018a it should be noted that due to the tropical depression 23 w nasa 2017 the strongest storms with multiple days of torrential downpours occurred over the northern vietnam including the study area in october 2017 the highest total rainfall per day was 191 2 mm on october 2 2017 measured at the na chi station near the study area these torrential downpours generated extensive flash flood disasters causing 68 deaths reliefweb 2017 3 2 2 influencing factors modeling of flash flood requires identifying geospatial information on key hydrological properties of the study area therefore determination of influencing variables is an important task in this study a total of 12 influencing variables were selected including elevation slope curvature toposhade aspect topographic wetness index twi stream power index spi stream density normalized difference vegetation index ndvi soil type lithology and rainfall all variables were prepared in a raster format with resolution of 10 m topography which is a major factor of the hydrological process is strongly related to flash flood because steep relief enhances the rapid concentration of water flow destro et al 2018 therefore topographic related factors should be used the digital elevation model dem with spatial resolution of 10 m for the bhby was generated from 1 50 000 scale national topographic maps provided by the ministry of natural resources and environment of vietnam monre tien bui et al 2017a using the dem seven geomorphometric factors elevation slope curvature toposhade aspect twi and spi were derived elevation and slope were selected because the flow of water is driven by the gravity force moving from higher to lower elevations ellabban et al 2014 whereas slope control the speed of surface runoff and in general flash flood prone areas are usually located in flat area and low elevation tehrany et al 2013 curvature is employed because flash flood areas are related to high topographic convergence manfreda et al 2014 in this research the elevation map fig 3 a with eight classes were used whereas ten and seven classes were constructed for the slope map fig 3a and the curvature map fig 3c respectively these classes of the three maps were determined based on the natural break interval method available in arcgis regarding the aspect map fig 3d nine classes were used toposhade and aspect were selected because toposhade is related to the shade and length of hillslopes that may influence convergence of water flowing aryal et al 2003 whereas aspect controls surface water flow directions for this study the toposhade map fig 3g with nine classes was constructed twi and spi are typical hydrological parameters that influence both the flow intensity and water accumulation martınez casasnovas et al 2004 therefore they were selected for flash flood modeling in this research twi beven et al 1984 and spi moore et al 1991 are calculated using equations as follow 5 twi ln a tan β 6 spi a s tan β where a is local upslope area β is local slope and a s is the specific catchment area in this analysis the twi map fig 4 e and the spi map fig 4f with seven classes were used these classes were determined and generated using the natural break interval mention above stream density which is computed by dividing the length of river km over the basin area km2 is an important factor influencing flash flood this is because regions with higher stream density are more likely have a rapid response to rainstorm brody et al 2007 therefore they are more prone to flash flood in this project the stream density map with seven classes was considered the stream network was extracted from the national topographic maps mentioned above ndvi is an indicator reflecting the degree of dense vegetation and it is likely that flash flood is more prone in areas with low vegetation density tehrany et al 2013 therefore ndvi could be used for flash flood analysis in this analysis the ndvi map was computed with eight classes fig 3j using the landsat 8 operational land imagery oli surface reflectance produce 30 m spatial resolution acquired on 20 12 2017 and freely available downloaded at http earthexplorer usgs gov and eq 7 reed et al 1994 below 7 ndvi nir red nir red where nir and red are the surface reflectance of the near infrared band and the red band respectively soils have been widely recognized as an important factor that influence rainfall runoff mechanisms geris et al 2015 whereas lithology structure strongly influences the architecture of the drainage pattern pizzuto 1995 that relates to the development of floodplain therefore soil type and lithology should be included in flash flood modeling for this research the soil type map with 13 categories fig 3k was derived from the national pedology map at scale of 100 000 which was provided by the monre truong et al 2018 the lithology map with 14 classes was compiled from the national geological and mineral resources map vietnam at scale of 50 000 which were also provided by the monre tien bui et al 2017c because flash floods are often associated with high intensity and short rainstorms borga et al 2011 therefore rainfall is a key controlling factor for flash flood modeling for this study area high intensity rainstorms occurred on october 10 11 and 12 in 2017 generated widespread severe flash flood in addition rainfall was lasted during the previous 9 days and the rainfall was ended after october 12 2017 therefore total measured rainfall from 1 to 12 october in 2017 at 16 rainfall stations in and around the study areas were used to generate the rainfall map fig 3l using the inverse distance weighted method tien bui et al 2011 4 proposed hybrid artificial intelligence approach based on pso mars for predicting flash flood susceptibility the overall structure of the proposed hybrid model of mars and pso denoted as mars pso for spatial prediction of flash flood susceptibility is presented in this section of the study the mars pso is a combination of mars as a machine learning approach and pso as a metaheuristic optimization algorithm the prediction model employs mars to establish a classification boundary that assigns the pixel in the map of the study area to either flood or non flood category in the hybrid framework mars is implemented via the built in function of the toolbox developed by jekabsons 2016 additionally pso optimization algorithm has been programmed in matlab by the authors the data used for model training and testing were obtained processed and compiled in the arcgis 10 4 and idrisi selva 16 software packages the overall view of model structure is provided in fig 4 4 1 database establishment as mentioned in section 3 2 1 a total of 654 flash flood polygons which were identified using the sentinel 1 sar change detection method were determined for the study area because the on off classification approach tien bui and hoang 2017 was employed for flash flood modeling in this research therefore an equal proportion of 654 samples at non flood areas of the study area were randomly generated and used for avoiding any potential bias to the model it is noted that the output classes are flood and non flood that are coded as 1 and 1 respectively as a result a total number of data samples in the data set was 1308 it is noted that prior to the model construction phase the whole data set were randomly separated into the training set 70 or 966 samples and the validation set 30 or 414 samples chapi et al 2017 hong et al 2018 khosravi et al 2018b tehrany et al 2015 twelve conditioning factors described in fig 3 were used as the input variables to derive the class output flood and non flood these 12 conditioning factor maps were converted from categorical classes into continuous domains within the range of 0 01 and 0 99 using the approach described in the previous study of tien bui et al 2015a finally a sampling task was performed to extract values of 12 conditioning factors for the samples in both the training set and the validation set respectively 4 2 relative importance of variable the relative importance of a variable is generally defined as the square root of the generalized cross validation gcv of the pso mars model friedman 1991a with all its basis functions removed minus square root of the gcv score of the overall model subsequently the result is normalized so that the relative importance of the most influential factor has a value of 100 friedman 1991a jekabsons 2016 4 3 the objective function of the model construction phase as presented earlier the prediction capability of the mars model is affected by the maximum number of basic functions bfs and the penalty coefficient c hence these two parameters should be meticulously specified in this study the pso optimization was employed to search for appropriate values of bfs and c in order to optimize the classification result of mars accordingly the performance of the mars model used for flood susceptibility assessment is optimized by minimizing the cost function cf described eq 11 it is noted that to compute the cf the original training data set were separated into two groups group 1 80 is used for the construction of the mars model and group 2 20 serves as a data set for model validation purpose the aim of this separation of the training data into the aforementioned groups is to avoid the risk of the overfitting problem in machine learning overfitting easily occurs if the training model excessively learns to capture the irregularity in the training data set accordingly the training result is exceptionally good but the classifier performance when predicting novel data can be very poor hence the utilization of the novel data reserved in the group 2 is particularly for hedge against the risk of overfitting hoang et al 2016 accordingly the following cost function should be minimized to obtain a good set of bfs and c 8 f cf 1 car group 1 car group 2 where cargroup1 and cargroup2 are car values derived from the computed results of the data in the group 1 and group 2 respectively 4 4 the training and validating phases of the pso mars model during the model training phase the pso optimization was employed to minimize the aforementioned cf since the number of decision variables 2 which is not large the maximum number of optimization generations was set to be 100 at the first generation initial values of the searched variables bfs and c are randomly created within the range of lower and upper bounds according to the following equation 9 x i 0 l b r 0 1 ub l b where x i 0 is the searched variable i at the first generation r 0 1 denotes a uniformly distributed random number between 0 and 1 lb and ub represent two vectors of lower and upper bounds for parameters the lower boundaries of bfs and c are set to be 5 and 0 1 respectively the upper boundaries of bfs and c are 50 and 10 respectively during the optimization process the pso population explored a large number of the variables which are mars s hyper parameters at each generation the cf of each set of hyper parameters was calculated using eq 11 the pso algorithm approach discards inferior set of hyper parameters and gradually guide the population towards regions featuring good set of set of hyper parameters based on this mechanism better solutions of bfs and c can be used in the training phase of mars finally when the optimized values of bfs and c have been identified the mars model was re trained with all data samples in the original training dataset to construct the final pso mars prediction model used for flash flood susceptibility prediction this optimized model was then used to compute the flash flood susceptibility for all the pixels in the map of the study area the flash flood susceptibility status can then be transformed to a raster format by a geospatial tool developed by the authors and operated in the arcgis software package 4 5 prediction performance evaluation since the task of flash flood susceptibility prediction in this study is modeled as a two class classification the true positive rate tpr the percentage of the flash flood samples correctly classified the false positive rate fpr the percentage of the non flash flood samples misclassified the false negative rate fnr the percentage of flash flood samples misclassified and the true negative rate tnr the percentage of the non flash flood samples correctly classified can be computed from the model prediction output to measure the predictive capability tien bui et al 2018 these four indices are calculated as follows 10 tpr tp tp f n f p r fp fp t n f n r fn tp f n t n r tn tn f p where tp tn fp and fn are the values of true positive true negative false positive and false negative respectively furthermore it is noted that the outcome of the tp fp and fn can be employed to compute the precision and recall indices using the following equations 11 precision tp tp f p 12 recall tp tp f n in addition the receiver operating characteristic roc curve can be constructed to assess the overall predictive ability of a classifier the establishment of this curve is based on the outcomes of the sensitivity true positivity rate and the specificity false negative rate accordingly the area under the curve auc ranging from 0 5 to 1 is often employed to express the predictive classification capability it is noted that auc values of 0 5 0 6 imply very poor whereas values of 0 6 0 7 indicate poor performance predictors with auc values of 0 7 0 8 have moderate performance while predictors with auc values 0 7 0 8 possess good performance classification models with auc values of 0 8 0 9 demonstrate very good performance hoang and tien bui 2018 peterson et al 2008 besides auc classification accuracy rate car can also be used to express the proportion of correctly classified data instances 5 results and discussion as stated previously a total of 1308 data samples were used to create and verify the performance of the proposed machine learning model used for flash flood spatial modeling the datasets were divided into a training set 70 and a testing set 30 the former dataset was employed in the model construction phase while the latter dataset was used to demonstrate the model generalization capability the performance of the newly constructed pso mars in both training and testing phases is reported in table 1 the model achieved a highly satisfactory outcomes with car 90 and auc 0 9 in detail pso mars obtained a car 93 62 and an auc 0 96 additionally there is a notable balance between the model prediction accuracy in the training and testing phases reflecting that the pso metaheuristic can be helpful to fine tune the mars model used for flood prediction moreover the results of the training and prediction phases of the pso mars model are graphically presented in figs 5 and 6 it could be seen that performance of the model the non flood samples is lower than that of the flood samples this is because the geo environment conditions of the non flood samples are complexly varied in the study area compared to those of the flood samples fig 7 provides the roc curves obtained from the prediction outcomes of the proposed machine learning model the contributions of flash flood influencing factors to the pso mars model are reported in table 2 as can be observed from this table all the factors have contributions to the model among them the slope is the most important factor with its merit score ms 100 followed by elevation ms 50 57 toposhade ms 44 22 aspect ms 35 21 twi ms 25 61 curvature ms 23 05 ndvi ms 20 55 and stream density ms 15 42 in contrast lithology ms 8 26 soil type ms 7 16 spi ms 3 47 and rainfall ms 3 03 have lower contributions to the pso mars model the finding in this study is consistent with literature where most studies found that slope is the most important for flash flooding chapi et al 2017 choubin et al 2019 kazakis et al 2015 razavi termeh et al 2018 because it is the main factor governing the amount of run off and the speed of water flow regarding rainfall this is recognized the most important factor generating floods blöschl et al 2015 garcía ruiz et al 2008 however rainfall had a low contribution to the pso mars model in this research this is because the flood inventories in the study area are mainly located in areas with low precipitation see fig 3i whereas areas with the highest rainfall 164 4 mm fig 3i recoded no flash flood problem in addition the support vector machine svm the backpropagation artificial neural network bpann and classification tree ctree were used in this section of the study as benchmark prediction approaches it is noted that svm bpann and ctree are operated via the matlab s statistics and machine learning toolbox matwork 2017 to implement svm its tuning parameters of the penalty coefficient and the kernel function parameter are automatically selected via an advanced method of bayesian optimization czarnecki et al 2015 matwork 2017 in the cases of bpann and ctree the model hyper parameters that help to attain in the best performance for the testing set were selected the appropriate value of the minimal number of observations per tree leaf was selected to be 2 moreover the suitable number of neuron in the hidden layer was found to be 10 the levenberg marquardt algorithm with the maximum number of training epochs 3000 was employed to train the bpann model the prediction results of the proposed pso mars as well as the benchmark models are summarized in table 3 it is observable that the pso mars yielded the highest predictive accuracy in terms of car 93 62 auc 0 96 precision 0 90 and recall 0 98 the svm model provided the second best method with car 89 80 auc 0 94 precision 0 84 and recall 0 94 followed by bpann car 87 69 and auc 0 92 and ctree car 88 01 and auc 0 90 these results demonstrate that the pso mars is the most appropriate for flood susceptibility prediction in the study area 6 flash flood susceptibility map since the pso mar model was the best suited for the dataset collected in the study area we employed it to calculate the flash flood susceptibility for all the pixels within the study area the predictive results of flash flood susceptibility were then transformed to a raster format for use in arcgis 10 4 the resulting map was visualized by five classes fig 8 ranging from very high 10 high 10 moderate 10 low 15 to very low 55 the four threshold values for separating the five above classes were determined by overlaying all flash flood pixels to the flash flood susceptibility map tien bui and hoang 2017 tien bui et al 2016 and then a threshold curve shown in fig 9 was established finally the four thresholds were derived the results showed that about 10 of the study area was classified into the very high class accounting for 72 17 of the total historical flash flood locations meanwhile both the high class and the moderate classes occupied 10 of the region but accounted for only 15 57 and 6 4 of the flash flood locations respectively table 4 whereas 15 of the district area was observed the low class but it contained 4 36 of the flash flood locations particularly 55 of the study area which is categorized to the very low class consisted of only 1 48 further analysis of flash flood density revealed that there was a possible shapely increase of the of the flash flood density from the very low class to the very high class table 4 these indicated that the proposed pso mar model had very high performance and successfully determined susceptible flash flood areas 7 concluding remarks flash flood susceptibility mapping with high accuracy is a crucial task in land use planning and hazard mitigation mahmoud and gan 2018 this study attempted to establish a hybrid model of mars and pso for predicting flash flood susceptibility at a regional scale we employed the mars as a classification model for recognizing patterns of flood and non flood pso as a metaheuristic was used to fine tune the training phase of the employed classification model a gis data set consisted of 12 conditioning variables of elevation slope curvature toposhade aspect topographic wetness index twi stream power index spi stream density normalized difference vegetation index ndvi soil type lithology and rainfall collected in the study area of the lao cai province northern vietnam the data were used to train and verify the performance of the newly constructed pso mars the results pointed out that the integrated model achieved the highest prediction accuracy compared to those of the svm the bpann and the ctree models our findings demonstrated that the proposed hybrid prediction model can be a promising tool to aid the local authorities in establishing flash flood mitigation measures and land use planning declaration of competing interest the authors declare no conflict of interest acknowledgement this work was supported by the national foundation of science and technology development nafosted vietnam under the project 105 99 2014 25 
6348,the main objective of this research work was to propose and verify a new soft computing approach based on multivariate adaptive regression splines mars and particle swarm optimization pso for spatial prediction of flash flood susceptible areas a high frequency tropical typhoon area located on northwest of vietnam was selected as a case study for this purpose a gis database for the study areas was prepared including 654 flash flood inundations and 12 influencing variables elevation slope curvature toposhade aspect topographic wetness index stream power index stream density normalized difference vegetation index soil type lithology and rainfall which were compiled from various sources the database was used to build and verify the prediction model we assessed the model s performance through various indices including classification accuracy rate area under the curve auc precision and recall we also compared the model s usability with five state of the art machine learning techniques including the backpropagation neural network support vector machine and classification tree the results revealed that the hybrid pso mars model outperformed other benchmark models in all the employed statistical measures we conclude that the proposed model can be particularly suited for flash flood forecasting problems at high frequency tropical typhoon area keywords multivariate adaptive regression splines particle swarm optimization flash flood susceptibility mapping gis 1 introduction floods are considered as the most destructive and frequent natural hazard worldwide that cause huge damage to property and affects millions of people in various countries every year bubeck and thieken 2018 chang et al 2014 peduzzi 2017 ward et al 2017 in 2013 the global flood damage was estimated to be more than 50 billion us dollars wasko and sharma 2017 it is anticipated that the flood damage could be reached 1 trillion us dollars yearly by 2050 due to accelerations of population growth and changes of climates and land cover patterns bubeck and thieken 2018 hartnett and nash 2017 studies of flood are expected to reduce economic losses and flood related facilities bubeck et al 2012 chang et al 2018 2019 therefore studies on flood modeling and prediction aiming to reduce flood damages are urgent tasks floods happen when a normally dry land is inundated by temporary waters bergé nguyen and crétaux 2015 and based on different mechanisms floods can be grouped into subsets including coastal flood river flood sewer flood urban flood and flash flood kundzewicz et al 2014 different from the other flood types the flash flood is a particularly damaging flood type due to fast onset characteristics and high flow velocities especially flash floods with large debris loads can be extremely dangerous for infrastructure and human lives due to their hydro static forces and natural impacts caused by flowing materials jalayer et al 2018 santo et al 2017 modeling and predicting the probability of flash floods play a crucial role in mitigating and managing future of flood hazards that can help authorities in operational settings and for suitable strategic planning bodoque et al 2016 giordano et al 2017 hapuarachchi et al 2011 prior studies have successfully provided various modeling approaches for the flash flood prediction including regression analysis and rainfall runoff simulation carpenter et al 1999 edouard et al 2018 javelle et al 2010 lucía et al 2018 tramblay et al 2010 consequently various robust models and tools have successfully proposed i e to name a few hfps donigan et al 1984 hec ras brunner 1995 1997 hydrotel fortin et al 2001 modflow harbaugh 2005 wetspa liu and de smedt 2005 and swat douglas mankin et al 2010 and mike zhou et al 2012 however long period time series data at monitoring stations are required for building accurate flash flood models yu et al 2018 which are difficult to many areas i e in developing countries to overcome the above limitation a new approach namely on off classification has been considered recently khosravi et al 2018b tehrany et al 2014 tien bui and hoang 2017 literature review shows that machine learning techniques have been widely used in flood studies including support vector machines svm tehrany et al 2015 naive bayes liu et al 2017 neuro fuzzy logic tien bui et al 2016 artificial neural networks nikoo et al 2016 decision trees khosravi et al 2018b tehrany et al 2013 and garp and quest darabi et al 2019 however high accuracy prediction of flash flood susceptible areas is still difficult bui et al 2019a therefore new machine learning ensembles models have been explored i e bayesian ensemble framework tien bui and hoang 2017 neural fuzzy optimized by optimization algorithms hong et al 2018 pso based neural networks ngo et al 2018a hybridization of statistics and machine learning algorithms costache 2019 and fuzzy classification ensembles bui et al 2019b overall prediction accuracy of flash flood susceptibility has been improved significantly with the use of ensembles models this research work aims to expand the body of the flash flood prediction knowledge by proposing a new soft computing ensemble approach based on multivariate adaptive regression splines mars and particle swarm optimization pso named as mars pso for flash flood susceptibility prediction the newly proposed model is established and verified with a case study at lao cai area in the northern region of vietnam a high frequency tropical typhoon area to the best of our knowledge this is the first mars pso is proposed for flash flood modeling and prediction mars friedman 1991b is a powerful machine learning method which can be highly useful for analyzing complex and multivariate phenomena this method is based on a divide and conquer strategy within which the data under analysis are separated into distinctive regions the relationship between variables of interest in this region is inferred by a linear model gholampour et al 2018 goh et al 2018 heddam and kisi 2018 hoang et al 2017 therefore mars is potentially useful for discovering hidden functional relationships of gis data moreover the learning phase of mars requires a proper setting of the two tuning parameters the maximum number of basis functions bfs and the penalty coefficient c based on related studies hoang et al 2018 liao et al 2018 prayogo and susanto 2018 tien bui et al 2017d wang et al 2017 xue 2017 the task of identify parameters of machine learning algorithms can be modeled as optimization problems in continuous domains hence this current work proposes to employ the particle swarm optimization pso as a metaheuristic to optimize the mars model specifically used for flash flood susceptibility prediction the rest of this paper is structured as follows the study area and the gis database are generally described in the second section followed by the third section that reviews the employed machine learning and metaheuristic algorithms the fourth section provides the description of the proposed model for flash flood susceptibility mapping followed by the next section that reports the experimental results concluding remarks on this study are stated in the final section 2 mathematical background of the employed algorithms 2 1 multivariate adaptive regression splines mars first proposed by friedman 1991b mars is a popular machine learning approach for mining a function that describes the relationship between a set of predictors xs and an output variable y this machine learning method does not require any assumptions regarding the distribution of the involved variables thus it is considered to be a non parametric approach for data modeling notably mars is highly useful to be applied in the situation that the mapping function for each sub group of the collected data is different york et al 2006 previous works involving mars implementation show that this machine learning approach can help to construct good predictive models for complex engineering datasets deo et al 2017 goh et al 2018 2017 heddam and kisi 2018 roy and datta 2017 since the related works on flood susceptibility prediction demonstrate that the classification function needed to discriminate flood and non flood areas can be highly complex mars can be potentially useful for generalizing such classification function from the gis database during the learning phase mars essentially dissects the learning space of flash flood influencing variables into smaller regions as illustrated in fig 1 for each sub region mars constructs a linear classification model which provides the best fit to the data subset as can been seen in fig 1 mars establishes a piecewise linear function for representing a global model with a data driven manner hoang et al 2017 due to this distinguished feature mars has been successfully employed in various fields liao et al 2018 moreover it is noted that the learning phase of the final prediction model is achieved via the construction of a set of basis functions bfs friedman 1991b these bfs provide descriptions of the relationship between flash flood conditioning factors and output class of flood non flood state a typical form of a bf is shown in the following formulas friedman 1991b 1 b m x max 0 c x or b m x max 0 x c where bm is a bf x denotes a flash flood susceptibility predictor c represents a threshold parameter discovered during the learning phase the final classification model constructed by mars employed for flash flood susceptibility prediction is compactly stated as follows 2 f x s i g n α 0 m 1 k α m b m x where α 0 α 1 α m represent the weighting coefficients f x is the model output which is 1 for the case of non flood class and 1 for the case of flood class k denotes the number of weighting coefficients 2 2 particle swarm optimization the implementation of the mars classification model necessitates the determination of its hyper parameters including the maximum number of basis functions bfs and the penalty coefficient c hoang et al 2017 because the problem of hyper parameter determination can be transferred as an optimization issue this study relies on the particle swarm optimization pso algorithm for optimizing the performance of mars pso proposed by kennedy and eberhart 1995 is a well known stochastic optimization technique that works by building a flock of birds randomly within a population swarm over the searching space called as a particle the good performance of this metaheuristic approach has been reported by previous studies spanning many fields inti and tandon 2017 tien bui et al 2017b zhang and yang 2017 in this research the parameters of the mars can be transferred to the coordination of each particle in the swarm for optimizing thus the merit of each particle position is measured by our proposed objective function value which is also call as the fitness value the coordination of each particle in the swarm is limited in a defined searching space moreover it is noted that particles in the swarm are identified by both their positions and velocities in each training iteration all particles fly across the searching space to find the best position for each particle the best fitness value next the best position of the swarm is determined by selecting the particle position with the highest merit value finally the best value for the mars parameters is derived which is the coordination of the best position of the swarm supposing the position of the i th particle can be expressed as vector x i vi is its velocity and p is the best positions of its neighbors the velocity of each particle is updated using an equation below 3 v i χ v i φ j 1 k i a j p n b r j x i where χ and φ are coefficients and usually used to 0 7298 and 4 1 respectively ki is neighbors for particle i and nbrj is the i s j th neighbor each neighbor of a particle is weighted using coefficient aj as follows 4 a j b j b j b j u 0 1 j 1 k i where u 0 1 denotes a uniform random number between 0 and 1 3 study site and data used 3 1 general description of the study site the study area is the region of two districts bac ha and bao yen bhby belonging to the northwest mountainous province of lao cai around 263 km from hanoi vietnam it is located between the longitudes 104 10 e and 105 37 e and between the latitudes 22 5 n and 22 40 n covering about 1510 4 km2 fig 2 topography is rugged and variable with hilly mountains gorges and highly dense rivers the altitude is from 38 9 m to 1878 69 m above sea level with the mean is 538 1 m areas with slopes from 10 to 40 account for 85 4 of the total study area whereas approximately 11 5 of the bhby has slope degrees less than 10 and areas with slopes larger than 40 occupy only 3 1 of the total study area administratively bhby is divided into 37 communes and 2 towns with total population is 136 06 thousand people the average population density is 83 people km2 and 96 people km2 for bac ha and bao yen respectively the climate is characterized by subtropical monsoonal with two distinct seasons a rainy season lasts from november to aprilwhereas a dry season is from may to october truong et al 2018 the study area located in a storm center in the world and usually receives heavy and extreme rainfalls every year the average annual rainfall varies from 1400 mm to 1843 7 mm and mainly concentrates in the rainy reason gso 2017 tran 2011 although flash floods and landslides occur every year however the widespread flash floods happened in three days 10 12 in october 2017 were considered the most destructive consequence the highest total rainfall at a measured station was 201 mm 3 2 description of the collected data 3 2 1 flash flood inventory map spatial prediction of areas prone to flash flooding using machine learning requires understanding and learning from events occurred in the past and present borga et al 2011 tien bui and hoang 2017 therefore establishment of flash flood inventory map is a key issue and mandatory task however flash flood is usually characterized both by small temporal and spatial scales that are difficult to observe and map borga et al 2011 therefore collection of flash flood inventories is still the most critical in literature most of published works collected happened flash flood events using handhold gps and field survey which are time consuming and not cost effective i e tehrany et al 2015 and khosravi et al 2018a in this research a flash flood inventory map which was the result of the stated fund project of flash flood b2018 mda 18dt ngo et al 2018b was used accordingly a total of 654 flash flood polygons occurred in the rainfall season of 2017 were identified using sentinel 1 sar synthetic aperture radar imagery change detection techniques then these flood polygons were checked in a series of fieldworks using igeotrans a gps application designed for smartphone tien bui et al 2015b and handhold gps more detailed information on the flash flood inventory map and the change detection techniques can be found in ngo et al 2018a it should be noted that due to the tropical depression 23 w nasa 2017 the strongest storms with multiple days of torrential downpours occurred over the northern vietnam including the study area in october 2017 the highest total rainfall per day was 191 2 mm on october 2 2017 measured at the na chi station near the study area these torrential downpours generated extensive flash flood disasters causing 68 deaths reliefweb 2017 3 2 2 influencing factors modeling of flash flood requires identifying geospatial information on key hydrological properties of the study area therefore determination of influencing variables is an important task in this study a total of 12 influencing variables were selected including elevation slope curvature toposhade aspect topographic wetness index twi stream power index spi stream density normalized difference vegetation index ndvi soil type lithology and rainfall all variables were prepared in a raster format with resolution of 10 m topography which is a major factor of the hydrological process is strongly related to flash flood because steep relief enhances the rapid concentration of water flow destro et al 2018 therefore topographic related factors should be used the digital elevation model dem with spatial resolution of 10 m for the bhby was generated from 1 50 000 scale national topographic maps provided by the ministry of natural resources and environment of vietnam monre tien bui et al 2017a using the dem seven geomorphometric factors elevation slope curvature toposhade aspect twi and spi were derived elevation and slope were selected because the flow of water is driven by the gravity force moving from higher to lower elevations ellabban et al 2014 whereas slope control the speed of surface runoff and in general flash flood prone areas are usually located in flat area and low elevation tehrany et al 2013 curvature is employed because flash flood areas are related to high topographic convergence manfreda et al 2014 in this research the elevation map fig 3 a with eight classes were used whereas ten and seven classes were constructed for the slope map fig 3a and the curvature map fig 3c respectively these classes of the three maps were determined based on the natural break interval method available in arcgis regarding the aspect map fig 3d nine classes were used toposhade and aspect were selected because toposhade is related to the shade and length of hillslopes that may influence convergence of water flowing aryal et al 2003 whereas aspect controls surface water flow directions for this study the toposhade map fig 3g with nine classes was constructed twi and spi are typical hydrological parameters that influence both the flow intensity and water accumulation martınez casasnovas et al 2004 therefore they were selected for flash flood modeling in this research twi beven et al 1984 and spi moore et al 1991 are calculated using equations as follow 5 twi ln a tan β 6 spi a s tan β where a is local upslope area β is local slope and a s is the specific catchment area in this analysis the twi map fig 4 e and the spi map fig 4f with seven classes were used these classes were determined and generated using the natural break interval mention above stream density which is computed by dividing the length of river km over the basin area km2 is an important factor influencing flash flood this is because regions with higher stream density are more likely have a rapid response to rainstorm brody et al 2007 therefore they are more prone to flash flood in this project the stream density map with seven classes was considered the stream network was extracted from the national topographic maps mentioned above ndvi is an indicator reflecting the degree of dense vegetation and it is likely that flash flood is more prone in areas with low vegetation density tehrany et al 2013 therefore ndvi could be used for flash flood analysis in this analysis the ndvi map was computed with eight classes fig 3j using the landsat 8 operational land imagery oli surface reflectance produce 30 m spatial resolution acquired on 20 12 2017 and freely available downloaded at http earthexplorer usgs gov and eq 7 reed et al 1994 below 7 ndvi nir red nir red where nir and red are the surface reflectance of the near infrared band and the red band respectively soils have been widely recognized as an important factor that influence rainfall runoff mechanisms geris et al 2015 whereas lithology structure strongly influences the architecture of the drainage pattern pizzuto 1995 that relates to the development of floodplain therefore soil type and lithology should be included in flash flood modeling for this research the soil type map with 13 categories fig 3k was derived from the national pedology map at scale of 100 000 which was provided by the monre truong et al 2018 the lithology map with 14 classes was compiled from the national geological and mineral resources map vietnam at scale of 50 000 which were also provided by the monre tien bui et al 2017c because flash floods are often associated with high intensity and short rainstorms borga et al 2011 therefore rainfall is a key controlling factor for flash flood modeling for this study area high intensity rainstorms occurred on october 10 11 and 12 in 2017 generated widespread severe flash flood in addition rainfall was lasted during the previous 9 days and the rainfall was ended after october 12 2017 therefore total measured rainfall from 1 to 12 october in 2017 at 16 rainfall stations in and around the study areas were used to generate the rainfall map fig 3l using the inverse distance weighted method tien bui et al 2011 4 proposed hybrid artificial intelligence approach based on pso mars for predicting flash flood susceptibility the overall structure of the proposed hybrid model of mars and pso denoted as mars pso for spatial prediction of flash flood susceptibility is presented in this section of the study the mars pso is a combination of mars as a machine learning approach and pso as a metaheuristic optimization algorithm the prediction model employs mars to establish a classification boundary that assigns the pixel in the map of the study area to either flood or non flood category in the hybrid framework mars is implemented via the built in function of the toolbox developed by jekabsons 2016 additionally pso optimization algorithm has been programmed in matlab by the authors the data used for model training and testing were obtained processed and compiled in the arcgis 10 4 and idrisi selva 16 software packages the overall view of model structure is provided in fig 4 4 1 database establishment as mentioned in section 3 2 1 a total of 654 flash flood polygons which were identified using the sentinel 1 sar change detection method were determined for the study area because the on off classification approach tien bui and hoang 2017 was employed for flash flood modeling in this research therefore an equal proportion of 654 samples at non flood areas of the study area were randomly generated and used for avoiding any potential bias to the model it is noted that the output classes are flood and non flood that are coded as 1 and 1 respectively as a result a total number of data samples in the data set was 1308 it is noted that prior to the model construction phase the whole data set were randomly separated into the training set 70 or 966 samples and the validation set 30 or 414 samples chapi et al 2017 hong et al 2018 khosravi et al 2018b tehrany et al 2015 twelve conditioning factors described in fig 3 were used as the input variables to derive the class output flood and non flood these 12 conditioning factor maps were converted from categorical classes into continuous domains within the range of 0 01 and 0 99 using the approach described in the previous study of tien bui et al 2015a finally a sampling task was performed to extract values of 12 conditioning factors for the samples in both the training set and the validation set respectively 4 2 relative importance of variable the relative importance of a variable is generally defined as the square root of the generalized cross validation gcv of the pso mars model friedman 1991a with all its basis functions removed minus square root of the gcv score of the overall model subsequently the result is normalized so that the relative importance of the most influential factor has a value of 100 friedman 1991a jekabsons 2016 4 3 the objective function of the model construction phase as presented earlier the prediction capability of the mars model is affected by the maximum number of basic functions bfs and the penalty coefficient c hence these two parameters should be meticulously specified in this study the pso optimization was employed to search for appropriate values of bfs and c in order to optimize the classification result of mars accordingly the performance of the mars model used for flood susceptibility assessment is optimized by minimizing the cost function cf described eq 11 it is noted that to compute the cf the original training data set were separated into two groups group 1 80 is used for the construction of the mars model and group 2 20 serves as a data set for model validation purpose the aim of this separation of the training data into the aforementioned groups is to avoid the risk of the overfitting problem in machine learning overfitting easily occurs if the training model excessively learns to capture the irregularity in the training data set accordingly the training result is exceptionally good but the classifier performance when predicting novel data can be very poor hence the utilization of the novel data reserved in the group 2 is particularly for hedge against the risk of overfitting hoang et al 2016 accordingly the following cost function should be minimized to obtain a good set of bfs and c 8 f cf 1 car group 1 car group 2 where cargroup1 and cargroup2 are car values derived from the computed results of the data in the group 1 and group 2 respectively 4 4 the training and validating phases of the pso mars model during the model training phase the pso optimization was employed to minimize the aforementioned cf since the number of decision variables 2 which is not large the maximum number of optimization generations was set to be 100 at the first generation initial values of the searched variables bfs and c are randomly created within the range of lower and upper bounds according to the following equation 9 x i 0 l b r 0 1 ub l b where x i 0 is the searched variable i at the first generation r 0 1 denotes a uniformly distributed random number between 0 and 1 lb and ub represent two vectors of lower and upper bounds for parameters the lower boundaries of bfs and c are set to be 5 and 0 1 respectively the upper boundaries of bfs and c are 50 and 10 respectively during the optimization process the pso population explored a large number of the variables which are mars s hyper parameters at each generation the cf of each set of hyper parameters was calculated using eq 11 the pso algorithm approach discards inferior set of hyper parameters and gradually guide the population towards regions featuring good set of set of hyper parameters based on this mechanism better solutions of bfs and c can be used in the training phase of mars finally when the optimized values of bfs and c have been identified the mars model was re trained with all data samples in the original training dataset to construct the final pso mars prediction model used for flash flood susceptibility prediction this optimized model was then used to compute the flash flood susceptibility for all the pixels in the map of the study area the flash flood susceptibility status can then be transformed to a raster format by a geospatial tool developed by the authors and operated in the arcgis software package 4 5 prediction performance evaluation since the task of flash flood susceptibility prediction in this study is modeled as a two class classification the true positive rate tpr the percentage of the flash flood samples correctly classified the false positive rate fpr the percentage of the non flash flood samples misclassified the false negative rate fnr the percentage of flash flood samples misclassified and the true negative rate tnr the percentage of the non flash flood samples correctly classified can be computed from the model prediction output to measure the predictive capability tien bui et al 2018 these four indices are calculated as follows 10 tpr tp tp f n f p r fp fp t n f n r fn tp f n t n r tn tn f p where tp tn fp and fn are the values of true positive true negative false positive and false negative respectively furthermore it is noted that the outcome of the tp fp and fn can be employed to compute the precision and recall indices using the following equations 11 precision tp tp f p 12 recall tp tp f n in addition the receiver operating characteristic roc curve can be constructed to assess the overall predictive ability of a classifier the establishment of this curve is based on the outcomes of the sensitivity true positivity rate and the specificity false negative rate accordingly the area under the curve auc ranging from 0 5 to 1 is often employed to express the predictive classification capability it is noted that auc values of 0 5 0 6 imply very poor whereas values of 0 6 0 7 indicate poor performance predictors with auc values of 0 7 0 8 have moderate performance while predictors with auc values 0 7 0 8 possess good performance classification models with auc values of 0 8 0 9 demonstrate very good performance hoang and tien bui 2018 peterson et al 2008 besides auc classification accuracy rate car can also be used to express the proportion of correctly classified data instances 5 results and discussion as stated previously a total of 1308 data samples were used to create and verify the performance of the proposed machine learning model used for flash flood spatial modeling the datasets were divided into a training set 70 and a testing set 30 the former dataset was employed in the model construction phase while the latter dataset was used to demonstrate the model generalization capability the performance of the newly constructed pso mars in both training and testing phases is reported in table 1 the model achieved a highly satisfactory outcomes with car 90 and auc 0 9 in detail pso mars obtained a car 93 62 and an auc 0 96 additionally there is a notable balance between the model prediction accuracy in the training and testing phases reflecting that the pso metaheuristic can be helpful to fine tune the mars model used for flood prediction moreover the results of the training and prediction phases of the pso mars model are graphically presented in figs 5 and 6 it could be seen that performance of the model the non flood samples is lower than that of the flood samples this is because the geo environment conditions of the non flood samples are complexly varied in the study area compared to those of the flood samples fig 7 provides the roc curves obtained from the prediction outcomes of the proposed machine learning model the contributions of flash flood influencing factors to the pso mars model are reported in table 2 as can be observed from this table all the factors have contributions to the model among them the slope is the most important factor with its merit score ms 100 followed by elevation ms 50 57 toposhade ms 44 22 aspect ms 35 21 twi ms 25 61 curvature ms 23 05 ndvi ms 20 55 and stream density ms 15 42 in contrast lithology ms 8 26 soil type ms 7 16 spi ms 3 47 and rainfall ms 3 03 have lower contributions to the pso mars model the finding in this study is consistent with literature where most studies found that slope is the most important for flash flooding chapi et al 2017 choubin et al 2019 kazakis et al 2015 razavi termeh et al 2018 because it is the main factor governing the amount of run off and the speed of water flow regarding rainfall this is recognized the most important factor generating floods blöschl et al 2015 garcía ruiz et al 2008 however rainfall had a low contribution to the pso mars model in this research this is because the flood inventories in the study area are mainly located in areas with low precipitation see fig 3i whereas areas with the highest rainfall 164 4 mm fig 3i recoded no flash flood problem in addition the support vector machine svm the backpropagation artificial neural network bpann and classification tree ctree were used in this section of the study as benchmark prediction approaches it is noted that svm bpann and ctree are operated via the matlab s statistics and machine learning toolbox matwork 2017 to implement svm its tuning parameters of the penalty coefficient and the kernel function parameter are automatically selected via an advanced method of bayesian optimization czarnecki et al 2015 matwork 2017 in the cases of bpann and ctree the model hyper parameters that help to attain in the best performance for the testing set were selected the appropriate value of the minimal number of observations per tree leaf was selected to be 2 moreover the suitable number of neuron in the hidden layer was found to be 10 the levenberg marquardt algorithm with the maximum number of training epochs 3000 was employed to train the bpann model the prediction results of the proposed pso mars as well as the benchmark models are summarized in table 3 it is observable that the pso mars yielded the highest predictive accuracy in terms of car 93 62 auc 0 96 precision 0 90 and recall 0 98 the svm model provided the second best method with car 89 80 auc 0 94 precision 0 84 and recall 0 94 followed by bpann car 87 69 and auc 0 92 and ctree car 88 01 and auc 0 90 these results demonstrate that the pso mars is the most appropriate for flood susceptibility prediction in the study area 6 flash flood susceptibility map since the pso mar model was the best suited for the dataset collected in the study area we employed it to calculate the flash flood susceptibility for all the pixels within the study area the predictive results of flash flood susceptibility were then transformed to a raster format for use in arcgis 10 4 the resulting map was visualized by five classes fig 8 ranging from very high 10 high 10 moderate 10 low 15 to very low 55 the four threshold values for separating the five above classes were determined by overlaying all flash flood pixels to the flash flood susceptibility map tien bui and hoang 2017 tien bui et al 2016 and then a threshold curve shown in fig 9 was established finally the four thresholds were derived the results showed that about 10 of the study area was classified into the very high class accounting for 72 17 of the total historical flash flood locations meanwhile both the high class and the moderate classes occupied 10 of the region but accounted for only 15 57 and 6 4 of the flash flood locations respectively table 4 whereas 15 of the district area was observed the low class but it contained 4 36 of the flash flood locations particularly 55 of the study area which is categorized to the very low class consisted of only 1 48 further analysis of flash flood density revealed that there was a possible shapely increase of the of the flash flood density from the very low class to the very high class table 4 these indicated that the proposed pso mar model had very high performance and successfully determined susceptible flash flood areas 7 concluding remarks flash flood susceptibility mapping with high accuracy is a crucial task in land use planning and hazard mitigation mahmoud and gan 2018 this study attempted to establish a hybrid model of mars and pso for predicting flash flood susceptibility at a regional scale we employed the mars as a classification model for recognizing patterns of flood and non flood pso as a metaheuristic was used to fine tune the training phase of the employed classification model a gis data set consisted of 12 conditioning variables of elevation slope curvature toposhade aspect topographic wetness index twi stream power index spi stream density normalized difference vegetation index ndvi soil type lithology and rainfall collected in the study area of the lao cai province northern vietnam the data were used to train and verify the performance of the newly constructed pso mars the results pointed out that the integrated model achieved the highest prediction accuracy compared to those of the svm the bpann and the ctree models our findings demonstrated that the proposed hybrid prediction model can be a promising tool to aid the local authorities in establishing flash flood mitigation measures and land use planning declaration of competing interest the authors declare no conflict of interest acknowledgement this work was supported by the national foundation of science and technology development nafosted vietnam under the project 105 99 2014 25 
6349,pore systems become very complex in heterogeneous reservoirs such as low permeability and tight sandstones for macropores and micropores both exist in such reservoirs although the large pores may control the reservoir quality and rock properties micropores always can affect the geometric and transport properties of the pore systems in this paper thus such an effect is studied comprehensively as such low and high resolution computed tomography ct scanning experiments were carried out on the same low permeability sandstone in order to obtain the low and high resolution digital rock lrdr and hrdr images respectively the impacts of micropores on properties of pore systems were investigated based on digital rock analysis of the lrdr and hrdr images for two samples in this study the micro porosity is defined as the pores and throats which can be covered by the hrdr images but cannot be covered by the lrdr images the results show that there are better connectivity smaller tortuosity and higher heterogeneity for the hrdr image compared to the lrdr image of the same rock the fractal analysis of pore space indicates that the surface of the pore space with micropores becomes rougher moreover we found that the micropore space plays a more significant role in the throats than the pores by comparing the pore and throat size distributions of the lrdr and hrdr images in addition the micropores can lead to a decrease in the average shape factor and smoothness of the boundary of pores and throats it was also found that micro porosity not only increases the average coordination number but also increases the number of isolated pores according to the coordination number distributions finally the results of single and two phase flow simulation show that the absolute permeability and formation factor become larger and smaller respectively for the pore systems with micropores this result reveals that micropores can improve the transportability and connectivity of the pore systems keywords micropores pore systems connectivity multiscale digital rock 1 introduction unconventional oil and gas resources are becoming more popular as conventional oil and gas resources are diminishing such resources account for a large proportion of total hydrocarbon resource favvas et al 2009 tahmasebi et al 2016a yan et al 2018 zou et al 2012 the heterogeneity of unconventional reservoirs however has led to many difficulties in developing such reservoirs this heterogeneity not only exists in the reservoir scale but also in the pore scale desbois et al 2016 prodanović et al 2015 tahmasebi 2018 tahmasebi et al 2015 zhang et al 2016 the heterogeneity of the pore systems usually corresponds to the circumstances where large and very small pores are connected as such the pore systems in heterogeneous porous media may involve several orders of length hemes et al 2015 jiang et al 2013 keller et al 2013 such heterogeneous materials is not limited to rocks other porous media such as construction materials soils and aquifers biological tissues fuel cells and batteries also have this complexity in common burbank et al 2013 de vries et al 2017 guo et al 2010 li et al 2018 tahmasebi and kamrava 2018 in such systems large pores are the main channels for oil and gas flow while micro porosity occupies a small proportion in the pore space but has a significant effect on geometric features and transport properties of pore systems bultreys et al 2016b de vries et al 2017 mehmani et al 2013 prodanović et al 2015 wu et al 2019 recently a tremendous amount of attention is given to the multi scale modeling of the pore systems of heterogeneous porous media to explore the impacts of micro porosity on rock properties mehmani and prodanović 2014 tahmasebi and kamrava 2018 yao et al 2015 there are two ways to model multiscale porous media in the first group called image based superposition method one can superimpose images with different scales and resolutions biswal et al 2009 gerke et al 2015 karsanina et al 2018 okabe and blunt 2007 tahmasebi et al 2016b 2015 yao et al 2015 then the influence of micropores on rock properties can be investigated based on single and multi scale digital rocks okabe and blunt 2007 used x ray computed tomography ct to model a two dimensional 3d digital image representing the large pores and reconstructed another 3d medium encompassing small pores using multiple point geostatistics based on a high resolution two dimensional 2d image afterward they obtained a porous medium containing both small and large pores based on image superposition subsequently the results of permeability with and without micro porosity showed an increase in the permeability when the micropores were included okabe and blunt 2007 yao et al 2015 constructed a porous medium model of vugs representing intergranular mesopores and intragranular micropores based on two 2d thin sections using the monte carlo method a 3d porous medium containing micropores and mesopores was then constructed by overlaying their 3d images compared to each single scale digital rock the multiscale medium containing micropores has better connectivity and flow predictability yao et al 2015 although image based superposition method can be used to model multiscale porous media the size of the finally superposed digital image is always small and the available methods are computationally expensive besides the micropores in their studies are often generated stochastically which might not be very close to the actual pore spaces furthermore another drawback is that it is hardly possible for one single small scale high resolution 2d image which was used in the previous studies to cover most of the micropores in the media as the micropores of heterogeneous porous materials are highly complex an alternative strategy is building multiscale pore networks via integrating multiple single scale pore networks namely network based integration method bauer et al 2011 békri et al 2005 bultreys et al 2015 de vries et al 2017 mehmani and prodanović 2014 tahmasebi and kamrava 2018 the impacts of micropores on pore space characteristics were then studied based on single and multi scale pore networks note that the pore network is the simplified pore geometries with the ideal objects e g sphere tube not the actual pore space thanks to this simplification of pore space this approach is computationally efficient for performing single and multi phase flow simulation on large samples covering a great spatial range jiang et al 2013 scanned a carbonate rock using an x ray ct scanner with three different resolutions high medium and low and then extracted three scale pore networks the integration of these three pore networks finally resulted in a comprehensive pore network containing all pores namely macropores mesopores and micropores pore size distributions and transport properties of different pore systems based on these respective pore networks were computed and compared the comparison results show that micropores and mesopores can only make a slight contribution to the permeability of rocks because most of the large pores were originally connected in their scanned sample it has also been pointed out that the influence of small pores on flow properties depends on the pore characteristics of the actual rock jiang et al 2013 mehmani and prodanović 2014 observed the pore space characteristics of tight reservoirs and constructed a two scale pore network with intergranular macropores and micropores consisting of grain filling and clay filling pores the effects of micropores on pore size distribution permeability and capillary pressure curves were analyzed micro porosity is believed to enhance the permeability of the tight rocks mehmani and prodanović 2014 bultreys et al 2015 considered the micro porosity in heterogeneous rocks as micro links to be connected in parallel with large pores then they established a random pore network model containing micro links to simulate two phase flow the result of the two phase flow shows that the micropores have a vital influence on the transport properties bultreys et al 2015 de vries et al 2017 assumed a large number of micropores as a microscopic aggregate domain when they constructed multiscale pore networks these aggregate domains were stochastically generated and randomly placed into macroscopic pore domain they examined the effects of aggregate parameters notably porosity and permeability on the properties of the dual porosity pore networks it was found that an increase in aggregate porosity causes considerable tailing in the breakthrough curves higher permeability within the aggregates resulted in a change in the transport regime from diffusion dominated to more advection dominated de vries et al 2017 tahmasebi and kamrava 2018 proposed a novel idea on modeling multiscale pore network they used low resolution 3d images from ct scanner to generate macropore network and reconstruct 3d stochastic micro porosity based on the widely available high resolution 2d images from scanning electron microscope sem using a hybrid pattern pixel based simulation hypps then the reconstructed micropore spaces were used to extract the micropore networks afterward the micro networks were implanted into the macro networks according to the location of micropores in the large sample besides they analyzed the impact of micropores with different proportions on pore space characteristics and flow properties of the rock tahmasebi and kamrava 2018 aside from the above mentioned methods peng et al 2014 used the actual ct images to study the effects of the micropores on the rock properties first they obtained two scale pore systems of a rock by providing the high and low resolution images the analysis of the influence of micropores on porosity tortuosity specific surface area and permeability of the pore systems was then conducted their study shows that micropores can increase the specific surface area and reduce the tortuosity however the effect of micropores on flow properties still remains an issue in such a way that the small pores in their study are shown to make no influence on the absolute permeability of the pore space peng et al 2014 other studies reveal that the micropores have a great impact on the transport properties of the pore systems bultreys et al 2015 mehmani and prodanović 2014 tahmasebi and kamrava 2018 wu et al 2019 in addition the effects of micropores on other essential properties of pore systems e g topological and two phase flow parameters were not investigated in their study based on the above summary of the previous studies several issues still have remained to be addressed first the micro pores networks are stochastically generated and randomly inserted into the macro pores network second these micro pores networks can be rescaled into the various networks with different sizes while the micropores might vary at different locations of the heterogeneous rocks moreover fewer studies analyzed the role of micro porosity namely pore or throat in the pore systems in this paper thus the effect of micropores on the geometric topological and fractal characteristics and transport properties i e single and two phase flow of pore systems for two heterogeneous rocks are comprehensively studied using various experimental results such as thin section sem and x ray ct scanning herein the 3d low and high resolution digital rock images are used directly without implementing any stochastic modeling for generating the pore networks note that the micropores in this study is defined for the pores and throats whose sizes are smaller than the low resolution sub resolution and larger than the high resolution of ct scanning more importantly the effect of the micropores on the whole pore space are also analyzed which is useful for understanding the importance of the micro porosity this paper is organized as follows first the experimental settings of thin section sem and x ray ct will be briefly introduced then the effects of micropores on the geometric topological and transport properties of pore systems will be analyzed in detail finally the findings and limits of this study will be summarized 2 experimental settings the two examined samples s1 and s2 are low permeability lacustrine turbidite sandstones from es3 reservoir of the shahejie formation dongying depression bohai bay basin china the thin section sem x ray ct tests were all performed on the two samples to analyze the characteristics of their pore systems and investigate the effect of micropores on rock properties specifically the thin section and sem tests were designed to display the features of 2d pore systems of the samples x ray scanning was conducted to exhibit the characteristics of 3d pore systems and analyze the impacts of micropores on the geometric topological and fractal characteristics and transport properties of pore systems for low permeability porous media 2 1 thin section thin section test is a universal and easily available optical microscope technique for studying the features of minerals and pore space of rocks which is widely used in the geology field bultreys et al 2016a nelson 2009 in terms of experimental procedure of thin section the sample first was cut and polished to a thin section with the thickness of 0 03 mm and then the small thin section was filled with the blue epoxy to further highlight the pore space in the rock the features of the mineral and pore systems were observed using the zeiss axio vision se 64 with an axio cam mrc5 camera that was used to photograph the observed phenomenon this work was conducted at reservoir geology key laboratory of shandong province qingdao china 2 2 scanning electron microscope sem test can discover the microstructures of a sample at higher resolutions than the thin section nelson 2009 for our study the sem experiment was performed to display the finer features of pore systems than the thin section sem experiment was carried out at state key laboratory of heavy oil china university of petroleum qingdao china the sample was cut milled by high energy argon ion beaming and coated with a conductive carbon film on the sample surface finally the sample was studied using hitachi s s 4800 fe sem machine with edax xm2 60s spectrometer 2 3 x ray computed tomography x ray ct experiment is widely used for performing the digital rock analysis bultreys et al 2016a ramandi et al 2018 tahmasebi et al 2017 wildenschild and sheppard 2013 in our study each sample was scanned twice using low and high resolution ct machine which is shown schematically in fig 1 the experiment was conducted at the center for x ray tomography of ghent university ugct belgium the conducted experiment steps are as follows first two columns with 5 mm diameter were extracted from s1 and s2 cores respectively and imaged using the hector micro ct scanner with a resolution of 4 63 µm and 4 92 µm respectively for obtaining the low resolution digital rock lrdr images subsequently two subplugs with a diameter of 2 mm were extracted from the 5 mm column and scanned with ugct s medusa using the same resolution of 1 49 μm for s1 and s2 in order to acquire the high resolution digital rock hrdr images a detailed description of the hector equipment can be found elsewhere masschaele et al 2013 the high resolution scanner medusa is the re designed version of the first ugct sub micron ct system and allows for a resolution of approximately 0 9 µm masschaele et al 2007 herein the hrdr images can cover the micropores the size that is smaller than low resolution sub resolution while these micropores cannot be covered in the lrdr images ramandi et al 2017 next the effects of micropores on the properties of pore systems for s1 and s2 will be studied based on digital rock analysis of the hrdr and lrdr images 3 results and discussion 3 1 characteristics of pore space from 2d images the thin sections and sem images are mainly used to display the 2d features of the grains and pore space of the examined two samples the 2d images of s1 are shown in fig 2 as can be seen the existing minerals in the sample are mainly quartz feldspar a few clay minerals calcite and carbonate the images shown in fig 2 a and b demonstrate that the surface of quartz is relatively clean while feldspar appears to be disordered and opaque for the chemical reaction this phenomenon occurs between feldspar and the fluids in the pore space yuan et al 2019 owing to the dissolution of minerals plenty of tiny pores can be generated around the feldspar even with few large pores mehmani and prodanović 2014 sem images on the other hand can provide a vibrant morphology of small pores compared to the optical analysis of thin sections with the aid of a high resolution sem it can be easily visible that there are some pores with a diameter of less than 5 µm in the minerals e g illite shown in fig 2 c and d these 2d images with different resolutions exhibit the morphology and distribution characteristics of various pores i e large and tiny pores these tiny pores not limited to micropores exist in different forms such as pore filling and grain filling mehmani and prodanović 2014 tahmasebi and kamrava 2018 it can be observed from figs 3 and 2 that s2 has similar pore structure characteristics as in s1 intragranular and intergranular pores both exist in two samples both of their pore systems contain large and tiny pores the size of these pores varies across multiple spatial scales which indicates that the pore systems of s1 and s2 are complex and heterogeneous 3 2 geometric properties of 3d pore systems the effects of micropores on geometric topological fractal and transport properties of the pore systems are analyzed mainly based on digital rock analysis of two ct images at low and high resolutions from the same regions in order to find the same region of two sets of ct data of the sample we need to register these two ct images as they are with different resolutions various techniques for registering 2d 3d images have been proposed latham et al 2008 maintz and viergever 1998 ramandi et al 2016a 2017 zitová and flusser 2003 in this study we registered the hrdr and lrdr images of the same rock using register images algorithm based on normalized mutual information in avizo software studholme et al 1999 made a detailed introduction about image registration based on normalized mutual information studholme et al 1999 the registered images of s1 and s2 are manifested in fig 4 afterward the median filter was performed to remove the noises of these ct images then we segmented the ct images into pore space and solid with the watershed algorithm based on the gray intensity of every voxel singh et al 2017 subsequently the opening algorithm as a commonly used workflow of morphological removal of small objects was conducted to remove small items from these images finally the pore spaces are separated into individual pores as shown in fig 4 in terms of digital rock analysis another important step is to choose the representative elementary volume rev of one sample therefore various subsamples with different sizes were extracted from the whole images of lrdr and hrdr of s1 and s2 and their porosity were calculated the results are presented in fig 5 rev can be determined when the porosity is almost stable as can be seen the porosity tends to remain stable when the selected volume is greater than 1 6 109 μm3 and 1 7 109 μm3 for s1 and s2 respectively therefore the images with the size of 1 967 109 μm3 and 1 968 109 μm3 are selected as the revs of lrdr and hrdr of s1 respectively regarding s2 the subsamples with the size of 1 964 109 μm3 and 1 957 109 μm3 are extracted as the revs of lrdr and hrdr of s2 respectively the images in the last two columns of fig 4 are some slices of revs of s1 and s2 it can be seen that there are some unresolved microstructures urm including micropores in fig 4 b and h but these microstructures can be resolved in the hrdr images it should be noted that the grayscale intensity of micro porosity region is lower than that of particles and higher than of pores which is due to i smearing of the x ray attenuation and ii partial volume effects ketcham 2005 ketcham and carlson 2001 ramandi et al 2017 weerakone and wong 2006 after determining the revs of lrdr and hrdr of s1 and s2 we can start to study the influence of micropores on geometric topological and transport characteristics of pore systems firstly the effect of micropores on the porosity and pore spatial distributions of the rocks is investigated as above mentioned we can easily obtain the total pore spatial distribution of each image displayed in fig 6 a d g and j then we applied the connectivity algorithm in image processing to get the connected pore space fig 6 the isolated pore space can be acquired after connected pore space was subtracted from all pore space meanwhile we also calculated the total porosity connected porosity and isolated porosity of every image table 1 via calculating the proportion of corresponding pore space in the volume of the rev herein the connected pore space e g effective pore space represents the interconnected pore volume in a rock that makes a contribution to fluid flow or permeability in this rock kelly et al 2016 verri et al 2017 the connectivity of pore space is the ratio of connected pore volume to total pore volume the larger the connectivity of pore space in a rock the larger contribution it makes to the permeability for the same sample s1 or s2 the proportion of isolated pores in the hrdr image is less than that in the lrdr image numerically speaking the porosity of the hrdr s1 image increases by 2 76 the porosity of the isolated space decreases by 1 79 and the connectivity of the pore system increases by 0 19 with respect to s2 the connectivity of pore space rises by 0 11 which reveals that the presence of micropores can improve the connectivity of pore systems for s1 and s2 in addition the centroid path tortuosity of the pore space is analyzed to characterize the geometric complexity and also to describe diffusion in porous media which can be obtained using the tortuosity algorithm in avizo software it can be shown from table 1 that the tortuosity of the pore space from hrdr becomes smaller than that of lrdr for both s1 and s2 samples indeed micropores could connect the original large pores in the rock which indicates the fluid can flow more easily in the pore space of hrdr the pore networks of lrdr and hrdr images of s1 and s2 demonstrated in figs 7 and 8 respectively were extracted using the improved medial axis method raeini et al 2017 the pore radius throat radius pore shape factor and throat shape factor distributions of these four images are computed and the results are shown in figs 7 and 8 as can be seen the hrdr image of s1 represents a large proportion of micropores in its pore and throat distributions which are not represented in the lrdr image a similar phenomenon also occurs in the aperture size distributions of s2 in addition the proportion of micropores for throats 37 75 is greater than the pores 10 04 for hrdr of s1 the proportion of micropores in the throats 36 32 and pores 11 98 for hrdr of s2 implies that the micropores leave a more visible effect in the throats in the pore network besides the comparison of the average pore throat radius of the lrdr and hrdr for one of the samples table 1 indicates that the presence of microstructures makes aperture size of pore system smaller which can be due to the fact that the average pore throat radius of hrdr is smaller than that of lrdr the difference in pore throat size between lrdr and hrdr can be because of the following reasons i the increase of small pores in hrdr image leads to the decrease of the aperture size of pore system ii the microstructures can be resolved in hrdr which will result in dividing the large pores throats in lrdr into smaller pores throats in hrdr see figs 9 and 4 as such the pore throat size of hrdr is smaller than that of lrdr regardless of s1 or s2 thus the difference of pore throat size between lrdr and hrdr will cause the difference in transport properties between lrdr and hrdr regarding the pore and throat shape factor distributions of the same sample figs 7 and 8 and the average pore and throat shape factors in table 1 the pore and throat shape factors of hrlr become smaller than those of lrdr which reveals that the pores and throats become rougher the next measure used in this study for quantifying the difference of the heterogeneity of the pore space in the lrdr and hrdr of the same rock is the porosity of each layer of these two images in the vertical direction the results are shown in fig 10 to reflect the variation degree of the porosity in each layer of lrdr and hrdr of the same sample we used the standard deviation of porosity variation in each layer to quantify the variation the larger the standard deviation the more greatly the porosity varies and the more heterogeneous the rock is concerning s1 the standard deviation of the porosity change for the hrdr image 2 17 is larger than that of lrdr 1 70 for s2 the standard deviation of hrdr 1 39 is also larger than that of lrdr 1 03 therefore the hrdr image of the same sample is more heterogeneous than the lrdr one the fractal dimension is another quantifier used in this paper by which one can describe the smoothness of the surface of geometry the smaller the fractal dimension the smoother the surface of the geometry is the variations of the fractal dimension of each layer from lrdr and hrdr images of two rocks were calculated using the fractal dimension algorithm wu et al 2019 the results are shown in fig 11 the fractal dimensions of the 3d pore space of the four images are also reported in table 1 as can be seen the fractal dimension in the hrdr image for the same rock is larger than that of lrdr for both the 2d and 3d pore space this explains that the increase in micro porosity makes the pore space rougher which indicates that the presence of micropores makes the pore space less rounded coincidentally this conclusion is in agreement with the results of the pore throat shape factor analysis above it should be noted that the fractal dimension indicates the smoothness of the surface of the pore space rather than the heterogeneity of the pore space mandelbrot and wheeler 1983 3 3 topological properties of 3d pore systems the topological descriptors of pore structures generally consist of coordination number volumetric euler number and two point connectivity function the coordination number was computed using the improved medial axis method raeini et al 2017 the coordination number distributions of s1 and s2 are shown in fig 12 it is noticeable that the frequency of coordination number from 1 to 5 in the lrdr image of s1 is larger than that of hrdr with regard to s2 the frequency of coordination number from 2 to 5 in the hrdr image is smaller than the lrdr one besides we calculated the average coordination number of those with less than 1 and more than 5 for the four images the results are shown in table 2 it can be noticed that the average coordination number of hrdr is larger than that of lrdr for both s1 and s2 which reveals that some micropores are connected to the other pores when they are added to the pore space moreover the proportion of coordination number less than 1 in the lrdr image of the same sample is smaller than that of hrdr this indicates that the presence of micro porosity leads to an increase in the number of isolated pores note that the increase in the number of isolated pores does not correspond to the increase in the volume of isolated pore space i e isolated porosity although the number of isolated pores rises these isolated pores only have very small pore volumes see fig 6 hence the volume proportion of isolated pore space decreases when the micropores are added into original pore space on the other hand the ratio of coordination numbers more than 5 in the hrdr image of the same rock also becomes higher than that of lrdr showing that some of the micropores act as throat in the pore systems therefore the micropores can turn into both pores and throats in the pore systems the two point correlation function tpcf is a mathematical function through which one can quantify the probability of two points in the rock with distance d that both fall into a certain phase pore space or particle the definition of the tpcf is 1 f x x d i x i x d where d is the distance between the points i x is an indicator function if i x 1 meaning x is located in the void space i x i x d can be interpreted as the probability that both two points are pores tahmasebi and sahimi 2012 wu et al 2018 yeong and torquato 1998 the tpcfs of the lrdr and hrdr images of two samples are obtained and the results are displayed in fig 13 as can be seen the tpcf of hrdr of the same sample is higher than that of the lrdr which indicates that the pore spaces in the hrdr image have a stronger correlation if the micropores are implanted into the original pore space in other words the connectivity of the pore space of hrdr has improved after adding the micropores tahmasebi and kamrava 2018 the volumetric euler number ven was introduced by vogel and roth to characterize the connectivity of the pore space vogel and roth 2001 it is defined as 2 χ v χ v where χ is the euler number of a porous medium with volume v the euler number is defined as χ v e f n 3 where v e f and n represent the number of vertices edges faces and tetrahedra of one geometry respectively jiang 2008 wu et al 2019 ven is an important topological descriptor of pore space vogel 2008 vogel and roth 2001 wu et al 2019 increasing positive values indicate decreasing connectivity of the structure and decreasing negative values indicate increasing connectivity ven is a function of the pore diameter to obtain the ven of a pore system one can use an opening operator with one structuring element of size d to remove all pores whose diameter is less than d vogel 2008 which results in the pores of the diameters larger than d in the image herein the size d of the structuring element in opening operation represents the minimum pore diameter in the pore system jiang 2008 vogel 2008 by increasing the size d of structuring element the ven can be obtained in fact the ven curve indicates the connectivity of pore systems when the pores with the minimum pore diameter d are inserted into the pore space more detail interpretation of ven can be found in jiang 2008 and vogel 2008 we calculated the ven for the lrdr and hrdr images of s1 and s2 and the results are shown in fig 14 in terms of the ven of hrdr the pore diameter is about 2 98 µm and 3 00 µm when the ven curve reaches the peak for s1 and s2 respectively the ven decreases as pore diameter decreases from 2 98 µm to 1 49 µm and from 3 00 µm to 1 49 µm for s1 and s2 respectively in other words the connectivity of pore systems is enhanced when pores with the size of less than 2 98 µm and 3 00 µm are implanted into s1 and s2 respectively jiang 2008 vogel 2008 thus the micro porosity has a great contribution to the connectivity of the pore systems as a summary of this part the presence of micropores has an important influence on the topological properties of pore space when micropores are added into the pore space the connectivity of the pore systems increases 3 4 transport properties of the pore systems there are two ways to simulate single and two phase flow in porous media namely direct method and pore network method blunt et al 2013 meakin and tartakovsky 2009 tahmasebi and kamrava 2018 xiong et al 2016 although the former approaches such as computational fluid dynamics lattice boltzmann monte carlo methods have been successful in simulating the single phase and even multi phase flow for various porous materials blunt 2001 bultreys et al 2016a fagbemi et al 2018 meakin and tartakovsky 2009 mirabolghasemi et al 2015 ramandi et al 2016b they always require considerable computer resources and long computation time especially they can be computationally demanding when the multi phase flow is simulated or the pore systems are heterogeneous in terms of the latter method pore network modeling it is computationally efficient which can perform computations on large samples and cover a larger spatial range aghaei and piri 2015 blunt et al 2013 raeesi and piri 2009 tahmasebi and kamrava 2018 thus we used the latter to simulate single and two phase flow when it comes to two phase brine and oil flow simulation using pore network approach valvatne and blunt 2004 all the elements in the pore network was first saturated with brine subsequently the primary oil flooding drainage was simulated at the end of the process the wettability will be changed the water flooding imbibition simulation was then performed the initial contact angle is set between 40 and 60 the altered contact angle is set between 90 and 110 during the simulation the interfacial tension is set to be 30 mn m the viscosity of water and oil are taken to be 1 05 cp and 1 39 cp respectively the density of brine and oil is 1000 kg m3 and 900 kg m3 respectively besides the simulation requires the assumptions below 1 the flow is not compressible and 2 viscous pressure drops in the processes are inconsiderable tahmasebi and kamrava 2018 valvatne and blunt 2004 mathematically speaking when the pore network is saturated a single phase p the absolute permeability k ap of the pore network can be obtained from darcy s law 4 k ap μ p q tsp l a φ il φ ol where μ p is the viscosity of the phase p q tsp is the total flow rate in the single phase flow condition under the potential drop between inlet and outlet φ il φ ol across the length l with a being the cross sectional area of the model valvatne and blunt 2004 on the other hand the relative permeability k rp of phase p can be calculated using 5 k rp q tmp q tsp where q tmp is the total flow rate of phase p brine or oil when brine and oil together flow the network the total flow rate can be obtained by solving the mass conservation of each pore i 6 j q p i j 0 where j runs over all the throats connected with pore i the flow rate q p between two pores i and k can be got using 7 q p i j g p i j l ij φ p i φ p j where g p is the fluid conductance l is the length of the pore centers and φ p p ρ p g h is the potential of phase p valvatne and blunt 2004 at last a set of linear equations can be acquired for all the pores and throats the formation factor is the electrical analogy to absolute permeability because the flow of electrical current is similar to fluid flow the formation factor f can be acquired using archie s formulas 8 f r o r w where r w is water resistivity 1 2 ω m in this study and r o is the computed resistivity of pore network when the network is saturated with water the resistivity of the pore network r o can be acquired from ohm s law 9 r o a δ v li ts where i ts is the electrical total current when one single phase flows through the model with the length l and cross sectional area a under the imposed voltage drop δ v valvatne 2004 as a result the absolute permeability and formation factors of two samples were calculated in table 3 and the relative permeability functions and capillary pressure functions were got in figs 15 and 16 as can be seen from table 3 the absolute permeability of hrdr for the same rock is larger than that of lrdr and the formation factor of hrdr is smaller than lrdr one which points out that the transportability of pore system of hrdr is better compared with lrdr for the same sample therefore the connectivity of the pore system is improved when micropores are added into the rock in terms of two phase flow the relative permeability of hrdr has shifted to the left compared to those of lrdr figs 15 and 16 which is due to the micropores as they have a greater effect on the permeability of non wetting phase than the permeability of wetting phase the variation of relative permeability was also found in other studies bultreys et al 2015 mehmani and prodanović 2014 on the other hand the capillary pressure curves represent larger values for the hrdr image containing the microstructures which is due to that the pore throat size of hrdr is smaller than that of lrdr for the same sample figs 7 and 8 the difference in pore throat size between hrdr and lrdr are explained in figs 9 and 4 the microstructures can be resolved in hrdr which results in dividing the large pores throats in lrdr into smaller pores throats in hrdr as such the aperture size of hrdr tends to be smaller figs 7 and 8 thus the capillary pressure value of hrdr is larger than that of lrdr regardless of the utilized samples bultreys et al 2015 mehmani and prodanović 2014 4 conclusions the effects of micro porosity on the geometric topological and transport properties of pore systems for two low permeability sandstones were studied the low and high resolution 2d images from the thin section and sem experiments all displayed the presence of micropores and the features of 2d pore systems the impacts of micropores on the geometric and topological properties and single and two phase characteristics of the pore systems were analyzed based on the digital images of low and high resolution ct tests of two samples it was observed that micro porosity can increase the connectivity of the pore space and make the surface of the pore space rougher the pore network analysis of lrdr and hrdr revealed that micropores have a significant impact on pore and throat distributions especially the throat since most micropores primarily act as throats besides micro porosity causes an increase of permeability as the absolute permeability of the pore space increases and the electrical resistivity decreases after micropores were added into the original pore systems the comparisons of the two phase flow for lrdr and hrdr of the same sample also reveal that the micro porosity has a great influence on the relative permeability functions and capillary pressure curve the studied micropores in this study were only limited to the micrometer scale pores but not involve the nanoscale in the future work we will study the effects of micropores on properties of pore systems for tight reservoirs with the permeability of less than 1 md for such rocks nanopores can play a significant role in the geometric topological and transport properties of the pore systems acknowledgments this work was funded by the fundamental research funds for the central universities 18cx06024a and technology major project p r china 2016zx05054012 2017zx05009001 the first author would like to acknowledge the china scholarship council csc for its financial support for his living expenses at the university of wyoming as a visiting ph d student the constructive comments offered by the anonymous reviewers are greatly acknowledged declaration of competing interest none 
6349,pore systems become very complex in heterogeneous reservoirs such as low permeability and tight sandstones for macropores and micropores both exist in such reservoirs although the large pores may control the reservoir quality and rock properties micropores always can affect the geometric and transport properties of the pore systems in this paper thus such an effect is studied comprehensively as such low and high resolution computed tomography ct scanning experiments were carried out on the same low permeability sandstone in order to obtain the low and high resolution digital rock lrdr and hrdr images respectively the impacts of micropores on properties of pore systems were investigated based on digital rock analysis of the lrdr and hrdr images for two samples in this study the micro porosity is defined as the pores and throats which can be covered by the hrdr images but cannot be covered by the lrdr images the results show that there are better connectivity smaller tortuosity and higher heterogeneity for the hrdr image compared to the lrdr image of the same rock the fractal analysis of pore space indicates that the surface of the pore space with micropores becomes rougher moreover we found that the micropore space plays a more significant role in the throats than the pores by comparing the pore and throat size distributions of the lrdr and hrdr images in addition the micropores can lead to a decrease in the average shape factor and smoothness of the boundary of pores and throats it was also found that micro porosity not only increases the average coordination number but also increases the number of isolated pores according to the coordination number distributions finally the results of single and two phase flow simulation show that the absolute permeability and formation factor become larger and smaller respectively for the pore systems with micropores this result reveals that micropores can improve the transportability and connectivity of the pore systems keywords micropores pore systems connectivity multiscale digital rock 1 introduction unconventional oil and gas resources are becoming more popular as conventional oil and gas resources are diminishing such resources account for a large proportion of total hydrocarbon resource favvas et al 2009 tahmasebi et al 2016a yan et al 2018 zou et al 2012 the heterogeneity of unconventional reservoirs however has led to many difficulties in developing such reservoirs this heterogeneity not only exists in the reservoir scale but also in the pore scale desbois et al 2016 prodanović et al 2015 tahmasebi 2018 tahmasebi et al 2015 zhang et al 2016 the heterogeneity of the pore systems usually corresponds to the circumstances where large and very small pores are connected as such the pore systems in heterogeneous porous media may involve several orders of length hemes et al 2015 jiang et al 2013 keller et al 2013 such heterogeneous materials is not limited to rocks other porous media such as construction materials soils and aquifers biological tissues fuel cells and batteries also have this complexity in common burbank et al 2013 de vries et al 2017 guo et al 2010 li et al 2018 tahmasebi and kamrava 2018 in such systems large pores are the main channels for oil and gas flow while micro porosity occupies a small proportion in the pore space but has a significant effect on geometric features and transport properties of pore systems bultreys et al 2016b de vries et al 2017 mehmani et al 2013 prodanović et al 2015 wu et al 2019 recently a tremendous amount of attention is given to the multi scale modeling of the pore systems of heterogeneous porous media to explore the impacts of micro porosity on rock properties mehmani and prodanović 2014 tahmasebi and kamrava 2018 yao et al 2015 there are two ways to model multiscale porous media in the first group called image based superposition method one can superimpose images with different scales and resolutions biswal et al 2009 gerke et al 2015 karsanina et al 2018 okabe and blunt 2007 tahmasebi et al 2016b 2015 yao et al 2015 then the influence of micropores on rock properties can be investigated based on single and multi scale digital rocks okabe and blunt 2007 used x ray computed tomography ct to model a two dimensional 3d digital image representing the large pores and reconstructed another 3d medium encompassing small pores using multiple point geostatistics based on a high resolution two dimensional 2d image afterward they obtained a porous medium containing both small and large pores based on image superposition subsequently the results of permeability with and without micro porosity showed an increase in the permeability when the micropores were included okabe and blunt 2007 yao et al 2015 constructed a porous medium model of vugs representing intergranular mesopores and intragranular micropores based on two 2d thin sections using the monte carlo method a 3d porous medium containing micropores and mesopores was then constructed by overlaying their 3d images compared to each single scale digital rock the multiscale medium containing micropores has better connectivity and flow predictability yao et al 2015 although image based superposition method can be used to model multiscale porous media the size of the finally superposed digital image is always small and the available methods are computationally expensive besides the micropores in their studies are often generated stochastically which might not be very close to the actual pore spaces furthermore another drawback is that it is hardly possible for one single small scale high resolution 2d image which was used in the previous studies to cover most of the micropores in the media as the micropores of heterogeneous porous materials are highly complex an alternative strategy is building multiscale pore networks via integrating multiple single scale pore networks namely network based integration method bauer et al 2011 békri et al 2005 bultreys et al 2015 de vries et al 2017 mehmani and prodanović 2014 tahmasebi and kamrava 2018 the impacts of micropores on pore space characteristics were then studied based on single and multi scale pore networks note that the pore network is the simplified pore geometries with the ideal objects e g sphere tube not the actual pore space thanks to this simplification of pore space this approach is computationally efficient for performing single and multi phase flow simulation on large samples covering a great spatial range jiang et al 2013 scanned a carbonate rock using an x ray ct scanner with three different resolutions high medium and low and then extracted three scale pore networks the integration of these three pore networks finally resulted in a comprehensive pore network containing all pores namely macropores mesopores and micropores pore size distributions and transport properties of different pore systems based on these respective pore networks were computed and compared the comparison results show that micropores and mesopores can only make a slight contribution to the permeability of rocks because most of the large pores were originally connected in their scanned sample it has also been pointed out that the influence of small pores on flow properties depends on the pore characteristics of the actual rock jiang et al 2013 mehmani and prodanović 2014 observed the pore space characteristics of tight reservoirs and constructed a two scale pore network with intergranular macropores and micropores consisting of grain filling and clay filling pores the effects of micropores on pore size distribution permeability and capillary pressure curves were analyzed micro porosity is believed to enhance the permeability of the tight rocks mehmani and prodanović 2014 bultreys et al 2015 considered the micro porosity in heterogeneous rocks as micro links to be connected in parallel with large pores then they established a random pore network model containing micro links to simulate two phase flow the result of the two phase flow shows that the micropores have a vital influence on the transport properties bultreys et al 2015 de vries et al 2017 assumed a large number of micropores as a microscopic aggregate domain when they constructed multiscale pore networks these aggregate domains were stochastically generated and randomly placed into macroscopic pore domain they examined the effects of aggregate parameters notably porosity and permeability on the properties of the dual porosity pore networks it was found that an increase in aggregate porosity causes considerable tailing in the breakthrough curves higher permeability within the aggregates resulted in a change in the transport regime from diffusion dominated to more advection dominated de vries et al 2017 tahmasebi and kamrava 2018 proposed a novel idea on modeling multiscale pore network they used low resolution 3d images from ct scanner to generate macropore network and reconstruct 3d stochastic micro porosity based on the widely available high resolution 2d images from scanning electron microscope sem using a hybrid pattern pixel based simulation hypps then the reconstructed micropore spaces were used to extract the micropore networks afterward the micro networks were implanted into the macro networks according to the location of micropores in the large sample besides they analyzed the impact of micropores with different proportions on pore space characteristics and flow properties of the rock tahmasebi and kamrava 2018 aside from the above mentioned methods peng et al 2014 used the actual ct images to study the effects of the micropores on the rock properties first they obtained two scale pore systems of a rock by providing the high and low resolution images the analysis of the influence of micropores on porosity tortuosity specific surface area and permeability of the pore systems was then conducted their study shows that micropores can increase the specific surface area and reduce the tortuosity however the effect of micropores on flow properties still remains an issue in such a way that the small pores in their study are shown to make no influence on the absolute permeability of the pore space peng et al 2014 other studies reveal that the micropores have a great impact on the transport properties of the pore systems bultreys et al 2015 mehmani and prodanović 2014 tahmasebi and kamrava 2018 wu et al 2019 in addition the effects of micropores on other essential properties of pore systems e g topological and two phase flow parameters were not investigated in their study based on the above summary of the previous studies several issues still have remained to be addressed first the micro pores networks are stochastically generated and randomly inserted into the macro pores network second these micro pores networks can be rescaled into the various networks with different sizes while the micropores might vary at different locations of the heterogeneous rocks moreover fewer studies analyzed the role of micro porosity namely pore or throat in the pore systems in this paper thus the effect of micropores on the geometric topological and fractal characteristics and transport properties i e single and two phase flow of pore systems for two heterogeneous rocks are comprehensively studied using various experimental results such as thin section sem and x ray ct scanning herein the 3d low and high resolution digital rock images are used directly without implementing any stochastic modeling for generating the pore networks note that the micropores in this study is defined for the pores and throats whose sizes are smaller than the low resolution sub resolution and larger than the high resolution of ct scanning more importantly the effect of the micropores on the whole pore space are also analyzed which is useful for understanding the importance of the micro porosity this paper is organized as follows first the experimental settings of thin section sem and x ray ct will be briefly introduced then the effects of micropores on the geometric topological and transport properties of pore systems will be analyzed in detail finally the findings and limits of this study will be summarized 2 experimental settings the two examined samples s1 and s2 are low permeability lacustrine turbidite sandstones from es3 reservoir of the shahejie formation dongying depression bohai bay basin china the thin section sem x ray ct tests were all performed on the two samples to analyze the characteristics of their pore systems and investigate the effect of micropores on rock properties specifically the thin section and sem tests were designed to display the features of 2d pore systems of the samples x ray scanning was conducted to exhibit the characteristics of 3d pore systems and analyze the impacts of micropores on the geometric topological and fractal characteristics and transport properties of pore systems for low permeability porous media 2 1 thin section thin section test is a universal and easily available optical microscope technique for studying the features of minerals and pore space of rocks which is widely used in the geology field bultreys et al 2016a nelson 2009 in terms of experimental procedure of thin section the sample first was cut and polished to a thin section with the thickness of 0 03 mm and then the small thin section was filled with the blue epoxy to further highlight the pore space in the rock the features of the mineral and pore systems were observed using the zeiss axio vision se 64 with an axio cam mrc5 camera that was used to photograph the observed phenomenon this work was conducted at reservoir geology key laboratory of shandong province qingdao china 2 2 scanning electron microscope sem test can discover the microstructures of a sample at higher resolutions than the thin section nelson 2009 for our study the sem experiment was performed to display the finer features of pore systems than the thin section sem experiment was carried out at state key laboratory of heavy oil china university of petroleum qingdao china the sample was cut milled by high energy argon ion beaming and coated with a conductive carbon film on the sample surface finally the sample was studied using hitachi s s 4800 fe sem machine with edax xm2 60s spectrometer 2 3 x ray computed tomography x ray ct experiment is widely used for performing the digital rock analysis bultreys et al 2016a ramandi et al 2018 tahmasebi et al 2017 wildenschild and sheppard 2013 in our study each sample was scanned twice using low and high resolution ct machine which is shown schematically in fig 1 the experiment was conducted at the center for x ray tomography of ghent university ugct belgium the conducted experiment steps are as follows first two columns with 5 mm diameter were extracted from s1 and s2 cores respectively and imaged using the hector micro ct scanner with a resolution of 4 63 µm and 4 92 µm respectively for obtaining the low resolution digital rock lrdr images subsequently two subplugs with a diameter of 2 mm were extracted from the 5 mm column and scanned with ugct s medusa using the same resolution of 1 49 μm for s1 and s2 in order to acquire the high resolution digital rock hrdr images a detailed description of the hector equipment can be found elsewhere masschaele et al 2013 the high resolution scanner medusa is the re designed version of the first ugct sub micron ct system and allows for a resolution of approximately 0 9 µm masschaele et al 2007 herein the hrdr images can cover the micropores the size that is smaller than low resolution sub resolution while these micropores cannot be covered in the lrdr images ramandi et al 2017 next the effects of micropores on the properties of pore systems for s1 and s2 will be studied based on digital rock analysis of the hrdr and lrdr images 3 results and discussion 3 1 characteristics of pore space from 2d images the thin sections and sem images are mainly used to display the 2d features of the grains and pore space of the examined two samples the 2d images of s1 are shown in fig 2 as can be seen the existing minerals in the sample are mainly quartz feldspar a few clay minerals calcite and carbonate the images shown in fig 2 a and b demonstrate that the surface of quartz is relatively clean while feldspar appears to be disordered and opaque for the chemical reaction this phenomenon occurs between feldspar and the fluids in the pore space yuan et al 2019 owing to the dissolution of minerals plenty of tiny pores can be generated around the feldspar even with few large pores mehmani and prodanović 2014 sem images on the other hand can provide a vibrant morphology of small pores compared to the optical analysis of thin sections with the aid of a high resolution sem it can be easily visible that there are some pores with a diameter of less than 5 µm in the minerals e g illite shown in fig 2 c and d these 2d images with different resolutions exhibit the morphology and distribution characteristics of various pores i e large and tiny pores these tiny pores not limited to micropores exist in different forms such as pore filling and grain filling mehmani and prodanović 2014 tahmasebi and kamrava 2018 it can be observed from figs 3 and 2 that s2 has similar pore structure characteristics as in s1 intragranular and intergranular pores both exist in two samples both of their pore systems contain large and tiny pores the size of these pores varies across multiple spatial scales which indicates that the pore systems of s1 and s2 are complex and heterogeneous 3 2 geometric properties of 3d pore systems the effects of micropores on geometric topological fractal and transport properties of the pore systems are analyzed mainly based on digital rock analysis of two ct images at low and high resolutions from the same regions in order to find the same region of two sets of ct data of the sample we need to register these two ct images as they are with different resolutions various techniques for registering 2d 3d images have been proposed latham et al 2008 maintz and viergever 1998 ramandi et al 2016a 2017 zitová and flusser 2003 in this study we registered the hrdr and lrdr images of the same rock using register images algorithm based on normalized mutual information in avizo software studholme et al 1999 made a detailed introduction about image registration based on normalized mutual information studholme et al 1999 the registered images of s1 and s2 are manifested in fig 4 afterward the median filter was performed to remove the noises of these ct images then we segmented the ct images into pore space and solid with the watershed algorithm based on the gray intensity of every voxel singh et al 2017 subsequently the opening algorithm as a commonly used workflow of morphological removal of small objects was conducted to remove small items from these images finally the pore spaces are separated into individual pores as shown in fig 4 in terms of digital rock analysis another important step is to choose the representative elementary volume rev of one sample therefore various subsamples with different sizes were extracted from the whole images of lrdr and hrdr of s1 and s2 and their porosity were calculated the results are presented in fig 5 rev can be determined when the porosity is almost stable as can be seen the porosity tends to remain stable when the selected volume is greater than 1 6 109 μm3 and 1 7 109 μm3 for s1 and s2 respectively therefore the images with the size of 1 967 109 μm3 and 1 968 109 μm3 are selected as the revs of lrdr and hrdr of s1 respectively regarding s2 the subsamples with the size of 1 964 109 μm3 and 1 957 109 μm3 are extracted as the revs of lrdr and hrdr of s2 respectively the images in the last two columns of fig 4 are some slices of revs of s1 and s2 it can be seen that there are some unresolved microstructures urm including micropores in fig 4 b and h but these microstructures can be resolved in the hrdr images it should be noted that the grayscale intensity of micro porosity region is lower than that of particles and higher than of pores which is due to i smearing of the x ray attenuation and ii partial volume effects ketcham 2005 ketcham and carlson 2001 ramandi et al 2017 weerakone and wong 2006 after determining the revs of lrdr and hrdr of s1 and s2 we can start to study the influence of micropores on geometric topological and transport characteristics of pore systems firstly the effect of micropores on the porosity and pore spatial distributions of the rocks is investigated as above mentioned we can easily obtain the total pore spatial distribution of each image displayed in fig 6 a d g and j then we applied the connectivity algorithm in image processing to get the connected pore space fig 6 the isolated pore space can be acquired after connected pore space was subtracted from all pore space meanwhile we also calculated the total porosity connected porosity and isolated porosity of every image table 1 via calculating the proportion of corresponding pore space in the volume of the rev herein the connected pore space e g effective pore space represents the interconnected pore volume in a rock that makes a contribution to fluid flow or permeability in this rock kelly et al 2016 verri et al 2017 the connectivity of pore space is the ratio of connected pore volume to total pore volume the larger the connectivity of pore space in a rock the larger contribution it makes to the permeability for the same sample s1 or s2 the proportion of isolated pores in the hrdr image is less than that in the lrdr image numerically speaking the porosity of the hrdr s1 image increases by 2 76 the porosity of the isolated space decreases by 1 79 and the connectivity of the pore system increases by 0 19 with respect to s2 the connectivity of pore space rises by 0 11 which reveals that the presence of micropores can improve the connectivity of pore systems for s1 and s2 in addition the centroid path tortuosity of the pore space is analyzed to characterize the geometric complexity and also to describe diffusion in porous media which can be obtained using the tortuosity algorithm in avizo software it can be shown from table 1 that the tortuosity of the pore space from hrdr becomes smaller than that of lrdr for both s1 and s2 samples indeed micropores could connect the original large pores in the rock which indicates the fluid can flow more easily in the pore space of hrdr the pore networks of lrdr and hrdr images of s1 and s2 demonstrated in figs 7 and 8 respectively were extracted using the improved medial axis method raeini et al 2017 the pore radius throat radius pore shape factor and throat shape factor distributions of these four images are computed and the results are shown in figs 7 and 8 as can be seen the hrdr image of s1 represents a large proportion of micropores in its pore and throat distributions which are not represented in the lrdr image a similar phenomenon also occurs in the aperture size distributions of s2 in addition the proportion of micropores for throats 37 75 is greater than the pores 10 04 for hrdr of s1 the proportion of micropores in the throats 36 32 and pores 11 98 for hrdr of s2 implies that the micropores leave a more visible effect in the throats in the pore network besides the comparison of the average pore throat radius of the lrdr and hrdr for one of the samples table 1 indicates that the presence of microstructures makes aperture size of pore system smaller which can be due to the fact that the average pore throat radius of hrdr is smaller than that of lrdr the difference in pore throat size between lrdr and hrdr can be because of the following reasons i the increase of small pores in hrdr image leads to the decrease of the aperture size of pore system ii the microstructures can be resolved in hrdr which will result in dividing the large pores throats in lrdr into smaller pores throats in hrdr see figs 9 and 4 as such the pore throat size of hrdr is smaller than that of lrdr regardless of s1 or s2 thus the difference of pore throat size between lrdr and hrdr will cause the difference in transport properties between lrdr and hrdr regarding the pore and throat shape factor distributions of the same sample figs 7 and 8 and the average pore and throat shape factors in table 1 the pore and throat shape factors of hrlr become smaller than those of lrdr which reveals that the pores and throats become rougher the next measure used in this study for quantifying the difference of the heterogeneity of the pore space in the lrdr and hrdr of the same rock is the porosity of each layer of these two images in the vertical direction the results are shown in fig 10 to reflect the variation degree of the porosity in each layer of lrdr and hrdr of the same sample we used the standard deviation of porosity variation in each layer to quantify the variation the larger the standard deviation the more greatly the porosity varies and the more heterogeneous the rock is concerning s1 the standard deviation of the porosity change for the hrdr image 2 17 is larger than that of lrdr 1 70 for s2 the standard deviation of hrdr 1 39 is also larger than that of lrdr 1 03 therefore the hrdr image of the same sample is more heterogeneous than the lrdr one the fractal dimension is another quantifier used in this paper by which one can describe the smoothness of the surface of geometry the smaller the fractal dimension the smoother the surface of the geometry is the variations of the fractal dimension of each layer from lrdr and hrdr images of two rocks were calculated using the fractal dimension algorithm wu et al 2019 the results are shown in fig 11 the fractal dimensions of the 3d pore space of the four images are also reported in table 1 as can be seen the fractal dimension in the hrdr image for the same rock is larger than that of lrdr for both the 2d and 3d pore space this explains that the increase in micro porosity makes the pore space rougher which indicates that the presence of micropores makes the pore space less rounded coincidentally this conclusion is in agreement with the results of the pore throat shape factor analysis above it should be noted that the fractal dimension indicates the smoothness of the surface of the pore space rather than the heterogeneity of the pore space mandelbrot and wheeler 1983 3 3 topological properties of 3d pore systems the topological descriptors of pore structures generally consist of coordination number volumetric euler number and two point connectivity function the coordination number was computed using the improved medial axis method raeini et al 2017 the coordination number distributions of s1 and s2 are shown in fig 12 it is noticeable that the frequency of coordination number from 1 to 5 in the lrdr image of s1 is larger than that of hrdr with regard to s2 the frequency of coordination number from 2 to 5 in the hrdr image is smaller than the lrdr one besides we calculated the average coordination number of those with less than 1 and more than 5 for the four images the results are shown in table 2 it can be noticed that the average coordination number of hrdr is larger than that of lrdr for both s1 and s2 which reveals that some micropores are connected to the other pores when they are added to the pore space moreover the proportion of coordination number less than 1 in the lrdr image of the same sample is smaller than that of hrdr this indicates that the presence of micro porosity leads to an increase in the number of isolated pores note that the increase in the number of isolated pores does not correspond to the increase in the volume of isolated pore space i e isolated porosity although the number of isolated pores rises these isolated pores only have very small pore volumes see fig 6 hence the volume proportion of isolated pore space decreases when the micropores are added into original pore space on the other hand the ratio of coordination numbers more than 5 in the hrdr image of the same rock also becomes higher than that of lrdr showing that some of the micropores act as throat in the pore systems therefore the micropores can turn into both pores and throats in the pore systems the two point correlation function tpcf is a mathematical function through which one can quantify the probability of two points in the rock with distance d that both fall into a certain phase pore space or particle the definition of the tpcf is 1 f x x d i x i x d where d is the distance between the points i x is an indicator function if i x 1 meaning x is located in the void space i x i x d can be interpreted as the probability that both two points are pores tahmasebi and sahimi 2012 wu et al 2018 yeong and torquato 1998 the tpcfs of the lrdr and hrdr images of two samples are obtained and the results are displayed in fig 13 as can be seen the tpcf of hrdr of the same sample is higher than that of the lrdr which indicates that the pore spaces in the hrdr image have a stronger correlation if the micropores are implanted into the original pore space in other words the connectivity of the pore space of hrdr has improved after adding the micropores tahmasebi and kamrava 2018 the volumetric euler number ven was introduced by vogel and roth to characterize the connectivity of the pore space vogel and roth 2001 it is defined as 2 χ v χ v where χ is the euler number of a porous medium with volume v the euler number is defined as χ v e f n 3 where v e f and n represent the number of vertices edges faces and tetrahedra of one geometry respectively jiang 2008 wu et al 2019 ven is an important topological descriptor of pore space vogel 2008 vogel and roth 2001 wu et al 2019 increasing positive values indicate decreasing connectivity of the structure and decreasing negative values indicate increasing connectivity ven is a function of the pore diameter to obtain the ven of a pore system one can use an opening operator with one structuring element of size d to remove all pores whose diameter is less than d vogel 2008 which results in the pores of the diameters larger than d in the image herein the size d of the structuring element in opening operation represents the minimum pore diameter in the pore system jiang 2008 vogel 2008 by increasing the size d of structuring element the ven can be obtained in fact the ven curve indicates the connectivity of pore systems when the pores with the minimum pore diameter d are inserted into the pore space more detail interpretation of ven can be found in jiang 2008 and vogel 2008 we calculated the ven for the lrdr and hrdr images of s1 and s2 and the results are shown in fig 14 in terms of the ven of hrdr the pore diameter is about 2 98 µm and 3 00 µm when the ven curve reaches the peak for s1 and s2 respectively the ven decreases as pore diameter decreases from 2 98 µm to 1 49 µm and from 3 00 µm to 1 49 µm for s1 and s2 respectively in other words the connectivity of pore systems is enhanced when pores with the size of less than 2 98 µm and 3 00 µm are implanted into s1 and s2 respectively jiang 2008 vogel 2008 thus the micro porosity has a great contribution to the connectivity of the pore systems as a summary of this part the presence of micropores has an important influence on the topological properties of pore space when micropores are added into the pore space the connectivity of the pore systems increases 3 4 transport properties of the pore systems there are two ways to simulate single and two phase flow in porous media namely direct method and pore network method blunt et al 2013 meakin and tartakovsky 2009 tahmasebi and kamrava 2018 xiong et al 2016 although the former approaches such as computational fluid dynamics lattice boltzmann monte carlo methods have been successful in simulating the single phase and even multi phase flow for various porous materials blunt 2001 bultreys et al 2016a fagbemi et al 2018 meakin and tartakovsky 2009 mirabolghasemi et al 2015 ramandi et al 2016b they always require considerable computer resources and long computation time especially they can be computationally demanding when the multi phase flow is simulated or the pore systems are heterogeneous in terms of the latter method pore network modeling it is computationally efficient which can perform computations on large samples and cover a larger spatial range aghaei and piri 2015 blunt et al 2013 raeesi and piri 2009 tahmasebi and kamrava 2018 thus we used the latter to simulate single and two phase flow when it comes to two phase brine and oil flow simulation using pore network approach valvatne and blunt 2004 all the elements in the pore network was first saturated with brine subsequently the primary oil flooding drainage was simulated at the end of the process the wettability will be changed the water flooding imbibition simulation was then performed the initial contact angle is set between 40 and 60 the altered contact angle is set between 90 and 110 during the simulation the interfacial tension is set to be 30 mn m the viscosity of water and oil are taken to be 1 05 cp and 1 39 cp respectively the density of brine and oil is 1000 kg m3 and 900 kg m3 respectively besides the simulation requires the assumptions below 1 the flow is not compressible and 2 viscous pressure drops in the processes are inconsiderable tahmasebi and kamrava 2018 valvatne and blunt 2004 mathematically speaking when the pore network is saturated a single phase p the absolute permeability k ap of the pore network can be obtained from darcy s law 4 k ap μ p q tsp l a φ il φ ol where μ p is the viscosity of the phase p q tsp is the total flow rate in the single phase flow condition under the potential drop between inlet and outlet φ il φ ol across the length l with a being the cross sectional area of the model valvatne and blunt 2004 on the other hand the relative permeability k rp of phase p can be calculated using 5 k rp q tmp q tsp where q tmp is the total flow rate of phase p brine or oil when brine and oil together flow the network the total flow rate can be obtained by solving the mass conservation of each pore i 6 j q p i j 0 where j runs over all the throats connected with pore i the flow rate q p between two pores i and k can be got using 7 q p i j g p i j l ij φ p i φ p j where g p is the fluid conductance l is the length of the pore centers and φ p p ρ p g h is the potential of phase p valvatne and blunt 2004 at last a set of linear equations can be acquired for all the pores and throats the formation factor is the electrical analogy to absolute permeability because the flow of electrical current is similar to fluid flow the formation factor f can be acquired using archie s formulas 8 f r o r w where r w is water resistivity 1 2 ω m in this study and r o is the computed resistivity of pore network when the network is saturated with water the resistivity of the pore network r o can be acquired from ohm s law 9 r o a δ v li ts where i ts is the electrical total current when one single phase flows through the model with the length l and cross sectional area a under the imposed voltage drop δ v valvatne 2004 as a result the absolute permeability and formation factors of two samples were calculated in table 3 and the relative permeability functions and capillary pressure functions were got in figs 15 and 16 as can be seen from table 3 the absolute permeability of hrdr for the same rock is larger than that of lrdr and the formation factor of hrdr is smaller than lrdr one which points out that the transportability of pore system of hrdr is better compared with lrdr for the same sample therefore the connectivity of the pore system is improved when micropores are added into the rock in terms of two phase flow the relative permeability of hrdr has shifted to the left compared to those of lrdr figs 15 and 16 which is due to the micropores as they have a greater effect on the permeability of non wetting phase than the permeability of wetting phase the variation of relative permeability was also found in other studies bultreys et al 2015 mehmani and prodanović 2014 on the other hand the capillary pressure curves represent larger values for the hrdr image containing the microstructures which is due to that the pore throat size of hrdr is smaller than that of lrdr for the same sample figs 7 and 8 the difference in pore throat size between hrdr and lrdr are explained in figs 9 and 4 the microstructures can be resolved in hrdr which results in dividing the large pores throats in lrdr into smaller pores throats in hrdr as such the aperture size of hrdr tends to be smaller figs 7 and 8 thus the capillary pressure value of hrdr is larger than that of lrdr regardless of the utilized samples bultreys et al 2015 mehmani and prodanović 2014 4 conclusions the effects of micro porosity on the geometric topological and transport properties of pore systems for two low permeability sandstones were studied the low and high resolution 2d images from the thin section and sem experiments all displayed the presence of micropores and the features of 2d pore systems the impacts of micropores on the geometric and topological properties and single and two phase characteristics of the pore systems were analyzed based on the digital images of low and high resolution ct tests of two samples it was observed that micro porosity can increase the connectivity of the pore space and make the surface of the pore space rougher the pore network analysis of lrdr and hrdr revealed that micropores have a significant impact on pore and throat distributions especially the throat since most micropores primarily act as throats besides micro porosity causes an increase of permeability as the absolute permeability of the pore space increases and the electrical resistivity decreases after micropores were added into the original pore systems the comparisons of the two phase flow for lrdr and hrdr of the same sample also reveal that the micro porosity has a great influence on the relative permeability functions and capillary pressure curve the studied micropores in this study were only limited to the micrometer scale pores but not involve the nanoscale in the future work we will study the effects of micropores on properties of pore systems for tight reservoirs with the permeability of less than 1 md for such rocks nanopores can play a significant role in the geometric topological and transport properties of the pore systems acknowledgments this work was funded by the fundamental research funds for the central universities 18cx06024a and technology major project p r china 2016zx05054012 2017zx05009001 the first author would like to acknowledge the china scholarship council csc for its financial support for his living expenses at the university of wyoming as a visiting ph d student the constructive comments offered by the anonymous reviewers are greatly acknowledged declaration of competing interest none 
