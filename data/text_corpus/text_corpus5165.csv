index,text
25825,watershed system models are important tools for understanding complex watershed systems and integrated river basin management however there are very few models that can represent the coevolution of water ecology and socioeconomic system at the river basin scale in this study a watershed system model was developed using the case of the heihe river basin hrb a typical endorheic river basin in northwest china the model is mainly composed of an integrated ecohydrological model a socioeconomic model and two interface models it has been embedded into a decision support system using the surrogate modeling technique the watershed system model proved to be reliable in simulating multiple eco hydrological processes and showed good abilities in exploring the trajectories and interactions of water ecology and socioeconomy this study advances our understanding of the water land air plant human nexus at the watershed scale and has great implications for sustainable developments in endorheic river basins keywords watershed system model human nature system decision support system water resource management heihe river basin endorheic river basin 1 introduction watersheds are the basic unit of earth s land surface system and in most cases are characterized by complex natural human interactions numerical modeling is one of the fundamental methodologies used to study watershed scale earth systems over the last few decades countless numerical models have been proposed to simulate different elements within a watershed including surface water groundwater snow frozen ground land use cover water quality crop growth and socioeconomic behaviors liang et al 1994 wigmosta et al 1994 yang 1998 stöckle et al 2003 harbaugh 2005 schulla and jasper 2007 verburg and overmars 2009 luckmann et al 2014 hu et al 2018 fu et al 2020 yuan et al 2021 a watershed is a complex system with hierarchical structures and whole functions and is composed of a water resource system an ecosystem and a socioeconomic system cheng et al 2014 however most numerical models belong to the category of single disciplinary models and conventionally simulate natural and human processes separately by taking the other as an exogenous variable they are typically unable to model the dynamic feedbacks between the natural and socioeconomic dimensions of a watershed moreover numerical models typically designed for specific purposes or domains can rarely be applied to an entire watershed that has distinct natural and human characteristics over different sections the deficiencies of the existing models together with the increasing influence of human activities in the anthropocene era urgently call for the development of watershed system models to produce a holistic simulation of the water land air plant human nexus at the watershed scale sivapalan et al 2014 cheng and li 2015 inam et al 2017 kuil et al 2018 lu et al 2018 li and xie 2019 watershed system models are essential if we are to better understand complex watershed systems and support integrated river basin management cai et al 2015 li et al 2018b more importantly the development of watershed system model embraces the philosophy of the future earth program launched by the international science association icsu liverman et al 2013 griggs et al 2014 and will contribute to solving the last category of the twenty three unsolved problems i e interfaces with society recently identified by the hydrology community blöschl et al 2019 earth system models esms are essential tools for understanding large scale environmental changes and interactions within and among all relevant aspects of the earth system including the atmosphere land oceans and cryosphere esms have gained remarkable advances in the past few decades and continue to move toward fan et al 2019 a watershed is actually a basin scale earth system and therefore watershed system models can learn greatly from esms meanwhile watershed system models can offer some advantages over esms for instance watershed system models can give detailed considerations of human activities i e water diversion and allocation agricultural water management and water policy and their interactions with the natural system which is a difficult task to complete with an esm clark et al 2015 fan et al 2019 nevertheless there are grand challenges for the development of a watershed system model li et al 2018b first the natural and human system models differ significantly in describing the spatial relationships of the modeling units and they typically have quite different spatiotemporal resolutions wada et al 2017 the ecohydrological model usually describes the study domain in a distributed manner while the socioeconomic model describes it in a lumped approach furthermore the integration of various components of the human and natural system models potentially increases the computational burden considerably hence watershed system models typically require extreme computer processing and storage capacity which constrains their incorporation into decision support systems dsss finally the development of a watershed system model is essentially a transdisciplinary issue that can be accomplished only through a strong collaboration among many researchers in diverse scientific communities by taking advantage of the state of the art advances in ecohydrology hydro economy eco economy and water resource economics endorheic basins which refer to hydrologically landlocked areas are widely distributed in arid and semiarid regions of the world wang et al 2018a covering approximately one fifth of the earth s land surface in the last few decades many endorheic basins such as the aral sea basin micklin 1988 lake urmia stone 2015 lake chad alfa et al 2008 shiyang river basin wang et al 2002 huo et al 2008 and heihe river basin hrb cheng et al 2014 tell a similar story i e the overexploitation of water resources has seriously deteriorated the watershed ecosystem the essence behind the story lies in the irrational water allocations between human and natural systems in view of this how to harmonize human and ecological water uses has become one of the critical issues that needs to be addressed by managers and researchers however this intractable and complex issue involves many aspects such as the hydrology economy ecosystem institution and water resource management which necessitates a step forward to represent both the human and natural aspects of a watershed with a sophisticated model li et al 2018b the hrb is a typical endorheic basin in the arid region of northwestern china the basin has received considerable attention from researchers in both china and other countries due to its distinct alpine oasis desert landscapes li et al 2016 2018a and fierce water use competition between humans and ecology cheng et al 2014 the upstream area is located in the qilian mountains on the northeastern tibetan plateau with relatively little human interference but important cryospheric processes such as snow accumulation and melt permafrost degradation and glacier retreat chen et al 2018 che et al 2019 the mid and downstream areas however are located in arid regions with flat terrains intensive irrigated agriculture and frequent surface water groundwater exchanges tian et al 2015b in recent years two watershed scale ecohydrological observation programs i e the watershed allied telemetry experimental research water li et al 2009 and the heihe watershed allied telemetry experimental research hiwater li et al 2013 2017a and many modeling works have been carried out in the hrb gao et al 2008 2016 zhou et al 2012 wang et al 2013 tian et al 2015a 2015b 2018b yao et al 2015 qin et al 2016 cong et al 2017 guo et al 2018 hu et al 2018 sun et al 2018b which have substantially improved our understanding of the basin s ecohydrological processes nevertheless an integrated watershed system model that can represent the water ecosystem economy system of the entire hrb is still lacking leading to some of the critical issues remain to be resolved i there are significant differences regarding the ecohydrological processes in the different sections of the hrb how can the ecohydrological models of the different sections be integrated for the entire basin meanwhile how can the integrated ecohydrological model be further coupled with the socioeconomic system model ii what are the distinct characteristics of the newly developed watershed system model what are the advantages of the watershed system model over the existing single discipline models iii can the watershed system model be used within the framework of dss to better support watershed management and sustainable development to address these questions this study proposed and developed a watershed system model to represent the integrated water ecosystem economy system by combining the existing knowledge and techniques with a case study of the hrb the work was conducted under the major research plan of the national natural science foundation of china nsfc i e integrated research on the ecohydrological process of the heihe river basin referred to as the heihe plan this plan was carried out in 2010 with the primary goals of revealing the ecohydrological regimes at multiple scales improving the understanding and predictability of the evolution of the water ecosystem economy system and providing scientific support for the sustainable development of inland river basins li et al 2013 the rest of this paper is organized as follows the framework of the watershed system model is briefly described in section 2 in section 3 the coupling mechanisms of different components of the watershed system model are presented the validation and applications of the watershed system model are presented in section 4 finally section 5 contains some concluding remarks and our prospects for future work 2 framework of the watershed system model 2 1 aims of the watershed system model integrating the water ecosystem and socioeconomic systems fig 1 shows the evolution of the model related studies in the hrb three different stages could be identified after 2000 in the first stage i e the years from 2000 to 2010 various hydrological models such as swat vic hbv prms and dhsvm have been applied in the hrb the objectives of the related studies mainly included two aspects at this stage one was the verification and evaluation of the existing hydrological models and the other was the improvement of the understanding of the changes in hydrology and water resources in the hrb after the preliminary studies during the first stage researchers found that some of the special ecohydrological processes such as the cryospheric processes of snow glaciers and frozen ground the frequent interactions of groundwater and surface water in the plain areas of the hrb and the strong dependence of vegetation on groundwater resources could not be well represented by the existing models after 2010 the watershed model related studies transitioned into the second stage and many efforts have been made to revise or integrate the existing models to enhance the modeling of the special ecohydrological processes in the hrb and to improve the comprehensive simulations of the watershed model at the latest stage i e 2015 to present researchers in different disciplinaries have attempted to work together for the development of the integrated model stimulated by the major research plan i e the heihe plan two integrated ecohydrological models i e the geomorphology based ecohydrological model gbehm and the hydrological ecological integrated watershed scale flow heiflow model were developed during this stage building on the rich modeling experience and knowledge accumulated in the three stages we proposed the watershed system model with two primary goals one is to improve the scientific understanding of the water land air plant human nexus by integrating the water ecologic and socioeconomic systems the other is to serve river basin management by supporting the development of a dss using the watershed system model as the backbone 2 2 overarching structure of the watershed system model of the hrb the framework of the watershed system model designed for the hrb is shown in fig 2 an ecohydrological model and an economic system model were bidirectionally coupled through two interface models i e the land use and water resource models within the framework of the watershed system model the ecohydrological and economic models as well as the interface models interact with each other directly or indirectly through exchange variables such as flow and groundwater level water allocation and land use types as depicted along the arrows of fig 2 because of the differences in the model structure spatiotemporal resolutions and programming languages of the four main components both offline and online integration strategies were employed in this study the offline strategy refers to a loose coupling scheme through the exchange of input output files while the online strategy refers to a tight coupling approach at the source code level details about the coupling schemes are presented in section 3 the ecohydrological model is composed of the gbehm and heiflow models the gbehm model is designed for the mountain cryosphere of the hrb it inherits all of the functions of the geomorphology based hydrological model gbhm yang et al 2004 and enhances the representations of the cryospheric processes of snow glaciers and frozen ground gao et al 2018 the heiflow model however is designed for the oasis desert plains of the hrb tian et al 2015a 2015b 2018b han et al 2021 it is a fully coupled surface and groundwater model that can explicitly simulate ecological processes e g vegetation dynamics and crop growth and agricultural water management the water economic model wem is an economic system model designed for the entire hrb and it is developed mainly based on the input output table it is an indispensable component of the watershed system model and plays a critical role in determining the water allocations and the land use structure li et al 2018c the economic model was also coupled with the abm to account for the social dimension of the watershed and the interactions between macro economic and micro economic behaviors du et al 2020 the production consumption and accumulation economic behaviors of peasant households in the abm are the key components of the wem making it a bottom up approach in addition two interface models i e the water resources model tian et al 2015a 2018a and the land use model were included in the watershed system model they mainly play a role in bridging the ecohydrological and economic system models three different irrigation modules were developed within the water resources model to describe the agricultural water management activities one module distributes diverted water from rivers to farmlands and the other allocates pumped groundwater to farmlands tian et al 2015a the additional module simulates the demand based diversion and pumping rates tian et al 2018a the performance of the economy in the economic system model drives the changes in land use cover and the simulations of land use changes are passed to the ecohydrological model the critical feedback of the ecohydrological model to the socioeconomic model is the water allocation in the water resources model 2 3 evolution of the watershed system model the watershed system model of the hrb has evolved from many existing models as plotted in fig 3 the rooted models of the watershed system model include the u s geological survey precipitation runoff modeling system prms the modular ground water flow model modflow and the gbhm we developed and grafted many models modules to better represent the special ecohydrological processes within the hrb the newly developed modules models marked with yellow colors include the crop growth model the desert vegetation growth model and the physically based snow module snow while the grafting modules models marked with green colors include the generic vegetation model revised from the environmental policy integrated climate epic model the soil freezing and thawing process module from the simultaneous heat and water shaw model and the simple biosphere model sib2 the generic vegetation model and the crop growth and desert vegetation models were coupled with the gsflow model which integrates prms and modflow leading to the generation of heiflow these efforts were mainly devoted to better represent the ecological processes of distinct landscapes in the middle and downstream areas of the hrb meanwhile the sib2 and shaw models and the snow module were coupled with the gehm for a better simulation of the cryospherical processes in the upstream area of the hrb leading to the generation of the gbehm model the heilow and gbehm models were coupled to generate an integrated ecohydrological model for the entire hrb meanwhile the microbehavior based abm and the macroeconomic based wem which was developed based on the computable general equilibrium cge and the input output model were integrated to generate a socioeconomic model for the hrb the ecohydrological model was further coupled with the socioeconomic model through two interface modules i e the land use and water resource models finally leading to the generation of the watershed system model in the hrb 2 3 1 gbehm an ecohydrological model with cryosphere hydrological processes for the mountainous area of the hrb the gbehm model yang et al 2015 as shown in fig 4 is an updated version of the geomorphology based hydrological model i e gbhm that was developed by yang et al 2004 compared with the gbhm the major enhancements of the gbehm include the following i a grid system scheme with a spatial resolution of 1 km 1 km to discretize the catchment ii the evapotranspiration et estimation from the penman monteith equation has been replaced by a simple biosphere model used in the simple biosphere model sib2 sellers et al 1986 1996 yang et al 2015 gao et al 2016 iii the vertical soil column in the gbehm could be extended deeply to approximately 50 m so that it could simulate the hydrological process of groundwater particularly in the permafrost region yang et al 2015 gao et al 2018 iv the vegetation dynamics were coupled with the hillslope hydrological processes gao et al 2016 and finally v it has the full functions of modeling cryosphere hydrological processes including glacier ablation li et al 2012 snow accumulation and melting li et al 2019a and soil freezing and thawing zhang et al 2013 gao et al 2018 the gbehm model has been successfully applied to study ecohydrological and cryospheric processes zhang et al 2013 2018 as well as their responses to climate change in the past and future qin et al 2017 zhang et al 2017 gao et al 2018 wang et al 2018b 2 3 2 heiflow a surface water groundwater interactional model with intensive agriculture over the oasis desert area of the hrb the heiflow model as shown in fig 5 has been developed for the mid and downstream areas of the hrb by integrating the 2d surface flow 3d groundwater and ecology models and by coupling different vegetation modules and the water management module tian et al 2015b 2018a 2018b yao et al 2015 2017 sun et al 2018b zheng et al 2020 han et al 2021 the heiflow model version 2 0 tian et al 2018b was evolved from the well known gsflow model and it can simulate all the major hydrological processes within and among three different regions including the areas from the top of a plant canopy to the soil zone base the subsurface zone beneath the base of the soil zone and the areas of streams and lakes markstrom et al 2008 compared with gsflow heiflow has the following distinct features i it improves the soil water simulation by introducing the sub grid structure of land cover multilayer soil water simulation and accurate spatial coverage of irrigation within the hrus han et al 2021 ii it can have time variant model parameters values and therefore is able to accept multiperiod land use data as the model inputs tian et al 2018b iii it includes a water resource allocation wra module to emulate high resolution irrigation activities and represent water management policies zheng et al 2020 and it also couples an agent based model to simulate farmers decision making on water use influenced by collective water management policies du et al 2020 and iv it couples multiple ecological modules that can simulate growth of various vegetation types e g grass crops desert vegetation and populus euphratica li et al 2017b sun et al 2018a han et al 2021 hence heiflow has a good capability of capturing the co evolutions and trade offs among ecology surface water and groundwater heiflow has been successfully used to simulate the ecohydrological processes dominated by the complex interactions between surface water and groundwater and water resource allocation several cases will be presented in section 4 2 3 3 wem social economic model over the hrb a wem for the entire hrb focusing on the interactions between water resources and economic elements has been developed based on the input output table that embeds water land resource factors wu et al 2017 li et al 2018c the wem mainly has three modules i e the production consumption and market equilibrium modules fig 6 water resources are integrated with capital and labor a production factor allocated in the economic model through market mechanisms such as water price adjustments and water rights transfers the incomes of various industrial sectors will change with time and they could exert an indirect impact on expenditures such as consumption investment imports and exports the wem is a highly efficient tool for water resource management and policy decision support water resources can be integrated into the social accounting matrix by the conversion of a physical object to a value the changes in water demands can be effectively simulated under urbanization and industrial transformation scenarios moreover the effects of water market allocation on industrial development can be investigated additionally the social accounting matrix sam which is an extended input output table that adds the factors for production and institutional sectors households firms and government and illustrates the links between the production sectors and all entities in the economy has been embedded in the wem the water embedded sam model was applied to explore the economic structure feedback mechanism and water flows among different sectors zhou et al 2017 it has also been used to simulate the chain effects among different sectors under different agricultural water price scenarios wu et al 2015 it takes what is referred to as a bottom up approach to analyze the agricultural economy therefore an abm was used to describe the agricultural economic behaviors in production and consumption activities the wem takes into account taxes regulations and government legislation it determines the course and nature of the economy looking at the economy as a whole the wem includes the economic behaviors of all sectors however the abm describes the economic behavior of the agricultural sector irrigation agriculture is the largest user of water in heihe accounting for nearly 90 of the total water use therefore the abm is integrated into the wem the wem runs with endogenous prices in addition to quantities which feeds back farmer behavior in the abm to analyze the economic impacts of water shortages and water trading 3 coupling the natural system model with the socioeconomic models the natural system model i e the ecohydrological model was coupled with the socioeconomic system model via two interface models i e the land use and water resource models at various spatiotemporal scales i e county and grid annually and daily by using the surrogate modeling technique in the first step the gbehm and heiflow models were loosely coupled to form an integrated ecohydrological model to simulate the natural processes of the entire hrb the coupling was implemented through an offline file transfer approach the stream flows at the outlets of the sub watersheds in the upstream area of the hrb were first simulated by gbhem and then transferred to heiflow as the input boundary inflows in the second step the integrated ecohydrological model was coupled with the wem at the annual temporal scale and it was tightly coupled with the abm based agricultural economic model at the daily scale the main challenge of coupling the natural system model with the economic model lies in the heavy computational burdens we found that computational expenses would increase exponentially when the economic and natural system models were integrated to address this issue we realized the coupling process through a surrogate modeling technique surrogate modeling refers to the replacement of a complex physically based model with the data driven relationship between multiple explanatory variables and the model outputs razavi et al 2012 wu et al 2016 this approach could considerably improve the computational efficiency of the watershed system model without sacrificing the simulation accuracy more specifically the coupling of the ecohydrological model with the socioeconomic model was implemented as plotted in fig 7 the simulations of the land use model i e the proportions of different land use types were transferred into the ecohydrological surrogate model which simulated the total available water resources to the socioeconomic surrogate model in turn the socioeconomic surrogate model feeds the water demands of different sectors under different climate change scenarios and economic development scenarios to the ecohydrological surrogate model and feeds the land use demands to the land use model based on the surrogate modeling technique the ecological hydrological and socioeconomic models were coupled together which eventually gave birth to the watershed system model the ecohydrological model was coupled with the wem at the annual and administrative regional scales and it was also coupled with the abm at the daily and irrigation district scales the input output embedded land and water resources served as the intermediaries between the ecohydrological model and the economic model the abm was used to simulate farmers water use decisions regarding the use of groundwater and surface water for irrigation du et al 2020 the farmers water use i e surface water diversion and groundwater pumping and agricultural economic value were the primary exchanges between the wem and abm 4 validation and application of the model 4 1 validation of the model the streamflow simulations of the watershed system model were verified against the streamflow observations at different hydrological stations i e yingluo gorge qilian zhamashike zhengyi gorge and langxinshan among them yingluo gorge and zhengyi gorge are the outlets of the upstream and midstream areas of the hrb respectively as shown in fig 8 meanwhile the groundwater level simulations were compared with the borehole observations in addition the pixel scale et upscaled from the multisite measurements liu et al 2016 2018 was used to further crosscheck the simulations of the watershed system model as shown in fig 8 the monthly streamflow simulations match very well with the observations at the gauges in different sections of the hrb the values of the kling gupta efficiency kge gupta et al 2009 approach 0 87 0 77 0 82 0 93 and 0 94 at the qilian zhamashike yingluo gorge zhengyi gorge and langxinshan stations respectively meanwhile the mean annual groundwater level simulations show a very close correlation with the observations as indicated by the high coefficient of determination r2 0 99 in terms of the et simulations they are very comparable to the upscaled observations as presented in fig 9 the r2 values are 0 86 0 76 and 0 74 in the upstream midstream and downstream areas of the hrb respectively the rmse and the mean absolute percent error mape are 0 7 mm day and 19 1 1 2 mm day and 21 9 and 1 8 mm day and 25 9 respectively the precision of the et simulations tends to increase from the upstream area to the downstream area of the hrb overall these results confirm that the model has a good ability to reconstruct the key hydrological components in the hrb and it could be a reliable tool for various purposes i e the long term hydrological modeling and water balance analyses 4 2 hydrological cycle in the hrb the watershed system model was used to close the water balance of the hrb at multiple scales we used the watershed system model to quantify the basin scale water balance for the 2001 2012 period the water balance of the hrb can be expressed as in eq 1 1 p e t δ s w δ g w δ r δ c ε where p is the precipitation et is the evapotranspiration δsw δgw δr and δc represent the storage changes in soil water groundwater lake reservoir and cryospheric water respectively and ε is the mass balance error the hydrological cycle and the water balance for the hrb are shown in fig 10 the hrb receives approximately 15 68 109 m3 yr 1 or 134 70 mm yr 1 of precipitation and releases or consumes approximately 15 51 109 m3 yr 1 or 133 25 mm yr 1 of water through et the soil water storage shows a decreasing trend with a decrease of 0 06 109 m3 yr 1 or 0 48 mm yr 1 while the groundwater storage including the water in the unsaturated zone and the lake and reservoir water storage show upward trends with increments of 0 07 109 m3 yr 1 or 0 59 mm yr 1 and 0 01 109 m3 yr 1 or 0 06 mm yr 1 respectively the increase in lake and reservoir water storage is partially due to the increasing inflows to downstream terminal lakes induced by the ecological water diversion project ewdp implemented in 2000 cheng et al 2014 and is partially due to the increasing precipitation in the upstream area zhang et al 2015 although groundwater storage shows an increasing trend at the basin scale it decreases obviously with a magnitude of 0 14 109 m3 yr 1 or 10 67 mm yr 1 in the midstream area of the hrb mainly due to the increasing groundwater withdrawal from irrigating expanded farmlands the decreasing groundwater storage in the midstream area is offset by the increasing trends in the other sections of the hrb leading to an upward trend as a whole at the basin scale the cryospheric water storage exhibited a downward trend with a magnitude of 0 02 109 m3 yr 1 or 1 01 mm yr 1 over the upstream area of the hrb or 0 13 mm yr 1 over the entire hrb which can be explained by the warming climate in the upstream area of the hrb snowmelt runoff accounts for approximately 15 6 of the discharge at the outlet of the upstream area in particular it contributed considerably to the spring streamflow which approach approximately 50 li et al 2019a the meltwater of underground ice over the permafrost region accounts for approximately 6 of the total streamflow at the outlet of the upstream area of the hrb li et al 2019b while glacier meltwater accounts for less than 5 gao et al 2018 li et al 2018a precipitation is relatively scarce in spring during which however the water demands of irrigated agriculture are increasing in the midstream area of the hrb the irrigation demand deficit is likely to be exacerbated by decreasing cryospheric water storage during the early crop growth stage more details about the water budgets for the upstream midstream and downstream areas of the hrb and those for different landscapes river channel sections and irrigation districts are available in our previous study li et al 2018a fig 11 shows the variations in the water cycle components in the hrb for the 2001 2012 period the mountainous runoff increases with a magnitude of 0 073 109 m3 yr 1 however at the same time both irrigation water uses and et present increasing trends in the middle and downstream areas of the hrb this leads to downward trends in groundwater levels with magnitudes of 0 284 m yr 1 and 0 025 m yr 1 in the middle and downstream areas of the hrb respectively these results indicate that the increasing water demand of agricultural development in the middle and downstream areas was met simultaneously by the increasing water availability from the mountainous region of the hrb and the overexploitation of groundwater the delicate water balance might be easily broken with decreasing water resources from the upstream area of the hrb and agricultural expansions in the future 4 3 long term hydrological modeling past simulation and future prediction long term hydrological modeling will provide valuable information for water resource management in this study we conducted hydrological modeling in the hrb for a long term period of 60 years 2001 2060 by using the watershed system model the climate data for the period 2016 2060 which were dynamically downscaled from the outputs of the ec earth earth system model ec earth hazeleger et al 2010 under the ipcc rcp 4 5 scenarios by using a high resolution regional climate model xiong and yan 2013 together with past meteorological observations were used to drive the watershed system model the model settings and parameters were kept constant for the past and future simulation periods fig 12 a shows the variations and trends in streamflows at the yingluo gorge zhengyi gorge and langxinshan stations the streamflows present obvious increasing trends at all the stations for the 2001 2016 period while they show downward trends over the remaining period 2017 2060 the streamflow of the yingluo gorge station shows the largest magnitude of trends which are 4 1 107 and 1 4 107 m3 year respectively for the 2001 2016 and 2017 2060 periods followed by the zhengyi gorge and langxinshan stations the water storage of the terminal lake sogo nuur increases more than five times from 2001 to 2016 while it exhibits a decreasing trend from 2017 to 2060 these results indicate that the water availability in the hrb tends to decrease in the future which will possibly aggravate the water use conflicts between humans and ecosystems it is critical to take adaptive measures such as strict constraints on farmland expansion and groundwater pumping to ensure sustainable development among agriculture groundwater and ecosystems 4 4 quantifying the socioeconomic water use water is the most precious resource in arid semiarid regions for sustaining the eco agro economic systems of oases hence the most critical aspect of water management in the hrb is how to improve water use efficiency and water productivity the wem was used to represent the mutual feedbacks between economic systems and ecohydrological processes based on the wem the water availability as well as the economic development scenarios for the hrb were determined fig 13 shows the water use in the water economy society integrated system of the hrb for 2012 the agricultural sector is the largest water consumer in each county of the hrb the water consumption of the secondary and tertiary industries is less than that of agricultural production the results reveal that the total water use in the socioeconomic system is approximately 4505 million m³ including 4460 million m³ of direct production water and 45 million m³ of direct domestic water regarding the consumption of real water and virtual water the economic system consumes 5520 million m³ while the social system consumes 4460 million m³ including almost 2973 million m³ of surface water and 1532 million m³ of underground water when all the counties are considered the sectors with the highest virtual water import and export are the food manufacturing and tobacco processing industries in jiayuguan county with the values of 73 57 and 119 33 million m3 respectively while the sector with the lowest virtual water import and export for all counties is the textile industry with the values of 1 44 and 0 20 million m3 respectively the sectors mainly responsible for virtual water import are the chemical industry accommodation and catering the food manufacturing and tobacco processing industries and the metal smelting and rolling processing industries the virtual water import leads to an increase of water availability and it might be an effective way to alleviate regional water stress in contrast the export of virtual water leads to an increase of water consumption which contributes to water stress at local scales the socioeconomic feedback on the water uses of the different industrial sectors was simulated with the wem in total we designed three scenarios regarding the upgradation of the industry structure with the assumptions that the technical progress rates of agriculture industry and service would increase by 5 i e scenarios i ii and iii respectively we found that the usages of surface water and groundwater would decrease under scenario i while they would not exhibit an obvious change under the other scenarios scenario iii would significantly promote the development of agriculture and industry hence the local government should prioritize technical progress in the service sector a modern service industry with a low water consumption should be encouraged and the market competition mechanism needs to be introduced to the higher water consuming service industry to increase the water use efficiency 4 5 experiments on the applications of the watershed system model to critical water resource management issues the watershed system model provides a reliable tool to investigate the ecohydrological impacts of various water management scenarios currently three groups of model experiments regarding water allocation ecological de farming and reservoir operation have been carried out in the hrb by using the watershed system model 1 a trade off relationship among water ecosystems and agriculture in the water allocation experiments three different water use reduction strategies i e reductions in diversions only reductions in groundwater pumping only and proportional reductions in both surface water diversions and groundwater pumping were implemented for the validated watershed system model sun et al 2018b the magnitudes of the reductions were proposed based on the historical gaps between the actual outflows and the goals of the ewdp implemented in 2000 the modeling results of different scenarios were compared with the benchmark which represents the real water use condition in the hrb the results indicated that direct reductions in groundwater extractions could restrain the decreasing groundwater storage whereas they could not induce an apparent increase in the discharge to the downstream area of the hrb consequently the measure could not meet the goal of the ewdp approximately 10 108 m3 yr 1 for a normal hydrological year however the reduction in surface water diversion could meet the water diversion goal while it could not alleviate the significant downward trend of groundwater storage a direct reduction in irrigation demands would benefit groundwater storage or ecosystems but it would be harmful to agriculture overall these results highlighted that the water ecosystem and agriculture are closely interlinked with a prominent tradeoff relationship among the different sections sun et al 2018b the water allocation experiment demonstrated the ability of the watershed system model to support water resource allocation and management 2 defarming policies will alleviate water conflicts between humans and ecosystems the farmland area increased substantially in the midstream area during the past decade which led to a series of ecological problems such as the death of ecological forests the shrinkage of wetlands and the generation of groundwater funnels hu et al 2015 ecological defarming experiments were carried out to study the responses of the entire surface and groundwater system to various ecological defarming scenarios of which the newly developed farmland of the midstream area of the hrb in 2011 was assumed to be returned to the status in 2000 and 2007 respectively while the other land types were kept constant the hydrological simulations of the watershed system model parameterized with different land use maps were compared to evaluate the influence of defarming practices we found that et would decrease by 0 73 7 55 mm yr 1 while the streamflow and groundwater level would increase by 0 19 0 90 109 m3 yr 1 and 67 73 270 91 mm yr 1 respectively in the midstream area of the hrb meanwhile the et and groundwater level would increase by 0 25 1 31 mm yr 1 and 1 43 7 68 mm yr 1 respectively indicating that the ecosystem would be further improved with the defarming policy the proposed defarming practice may be a promising strategy for balancing the agriculture water ecosystem nexus in the hrb the ecological defarming experiment indicates that the watershed system model would help to make scientific based land management policies 3 considerable ecohydrological impacts of the newly constructed large reservoir the huangzangsi reservoir located in the upstream area of the hrb is currently under construction and is expected to be accomplished in 2022 reservoir operation experiments were performed to investigate the ecohydrological impacts of different reservoir operational strategies the different reservoir operations were designed to release the water for ecological flow purposes with different durations and discharge rates but the same total volume the watershed system model was run with the different reservoir operation strategies and the results were compared with each other tian et al 2018a the results indicated that the water allocation goals of the ewdp could be approached through reservoir operation and groundwater storage could be recovered significantly in the downstream area of the hrb nevertheless the assurance rate of agricultural water uses and groundwater storage would decrease in the midstream area of the hrb which might have adverse effects on wetland ecosystems further analyses implied that the operational strategies characterized by smaller water releases with longer durations were more beneficial to achieve the water allocation goals of the ewdp and to increase groundwater recharges in the midstream area of the hrb the reservoir operation experiment implied that the watershed system model could enhance the evaluation of influences of the large water conservancy facility from a watershed scale perspective 4 6 water resource sustainability dss based on the watershed system model one of the ultimate goals of the watershed system model in the hrb was to serve river basin management by supporting the development of a scientific model based dss that could be used for sustainable development assessments ge et al 2013 2018 a river basin sustainable development decision support system risdss that integrates the sustainable development goals of the united nations un sdgs and the local watershed features was developed to address the co developments of the water ecological and socioeconomic systems fig 14 in the risdss we utilized the watershed system model to simulate ecohydrological processes under the interference of human activities including irrigation expending farmland gdp and water productivity and to determine the states of key natural and socioeconomic elements in the future this watershed system model could provide more than 20 output variables such as the gdp population farmland area water price and agricultural water demand for the 10 counties in the hrb at the annual scale these variables are the major parameters used to quantify the indicators of watershed scale sdgs and are closely related to the co development of the ecohydrological and socioeconomic pathways we employed the surrogate modeling technique based on the latin hypercube sampling and support vector machine methods to reduce the dimensionality of the ecohydrological model while maintaining the simulation and prediction accuracy the risdss was applied to project 2160 pathways in the hrb and to analyze the impacts of three major driving forces including precipitation technological level and ecological water flow on the sustainability of this basin in addition we integrated various statistical models into the risdss to quantify the population growth urbanization progress and changes in the forest and grassland areas under the scenarios of a changing climate population and urbanization progress the coupling of these statistical models with the watershed system model could help to output some key variables that cannot be obtained by the two kinds of models for example gdp per capita in addition on the basis of the disaggregated un sdgs and the chosen driving forces ruled by shared socioeconomic pathways ssps we employed an urbanization model and a population development environment pde model together with the simulations of the regional integrated environmental model riems 2 0 to quantify the changes and ranges of the driving forces under future scenarios after the assignment of different scenario parameters the watershed system model could project diverse ecohydrological and socioeconomic pathways then the sustainability assessment model could be used to investigate the sustainability of these pathways by regulating the driving forces accordingly we will identify the key factors dominating the sustainability of river basin development and determine the tipping point of water stress by analyzing the relationships among the changes in the different pathways their sustainability and the driving forces 5 summary and prospects we developed a watershed system model for the hrb a typical endorheic river basin in northwest china via the collective efforts of various research groups in different disciplinaries the watershed system model represents the natural systems of the hrb by using an integrated ecohydrological model and describes the socioeconomic system by using a socioeconomic model integrated by the macroeconomic based wem and the abm meanwhile it simulates the interactions between the natural and socioeconomic systems by coupling the ecohydrological model with the socioeconomic model through two interface models i e the water resources model and the land use model the coupling was implemented at various spatiotemporal scales by using a surrogate modeling technique the watershed system model was evaluated against multiple ground based observations including streamflow groundwater level and et the results indicate that it achieved good performance in the hrb the kge was greater than 0 80 for the streamflow simulations at most of the hydrological stations and the r2 was greater than 0 7 for the et simulations and was closer to 1 for the groundwater level simulations the watershed system model was further demonstrated to have good capacities in i closing the water balances at multiple spatial scales ranging from landscapes districts and subbasins to the entire river basin ii analyzing and forecasting the water use efficiency and water productivity of the socioeconomic sector or system iii simulating and projecting the long term hydrological regimes iv understanding the ecohydrological responses to some critical water management measures and v supporting the development of the scientifically based dss the watershed system model is an earth system model at the watershed scale the successful development of the watershed system model in the hrb could promote a paradigm that shifts from single disciplinary research methods to interdisciplinary and integrated methods in watershed science the coupling of hydrology ecology and socioeconomy within the watershed system model not only enhances the understanding of the phenomenon that arises from the coevolution and two way feedbacks between the human and natural systems but also helps to improve the management and regulation capacities of the hrb moreover the watershed system model provides a robust tool for the realization of the un sdgs the methodology and findings of this study could provide a valuable reference for other endorheic river basins around the world with similar characteristics to the hrb as shown in fig 15 our desired aim was to develop a watershed system model that could represent the coevolution of natural and human systems that include the water land air plant human nexus li et al 2018b li and xie 2019 nevertheless in this study we mainly focused on the interactions of water ecosystem and socioeconomic system there remain some issues and challenges open for further investigations first the natural system model needs to be improved in the future the two way coupling of the ecohydrological model and the regional climatic model was not realized in our watershed system model which limits its capacity to capture the feedbacks between ecohydrology and climate the significant interactions among intensive irrigation ecohydrological processes and regional circulation patterns e g moisture recycling need to be simulated by the desired watershed system model moreover some other key natural processes of the watershed system such as the biogeochemical cycles and vegetation succession are proposed to be represented within the desired watershed system model second social processes such as the water resource management institution and behavioral characteristics of water users which are typically underrepresented in esms need to be further enhanced within the framework of the watershed system model to better account for the interactions among water users hydrology managers and policy makers these processes will be more deeply coupled with the water systems across multiple scales sivapalan and blöschl 2015 sectors and agents as emphasized by the new science of socio hydrology sivapalan et al 2012 to improve the watershed system model s power in explaining and predicting various water sustainability problems such as the efficiency paradoxes and the emergent phenomena sivapalan et al 2014 finally issues such as how to efficiently constrain and assess the uncertainties and complexities of the watershed system model li 2014 koo et al 2020 how to better use the increasingly available remote sensing products artificial intelligence and big data deluge within the watershed system model and how to balance the model s complexities robustness and efficiency are still open for further explorations in the future we will attempt to digest a number of new concepts e g anthropocene tipping elements and planetary boundaries framework technologies e g deep learning big data and high speed computing innovative open web based frameworks e g the opengms platform chen et al 2019 chen et al 2020 to achieve a deeper integration of natural processes with human dynamics that go beyond the economic models steffen et al 2020 software and data availability codes of the watershed system model can be downloaded from https github com heiheproject wsm and the model s meta information and web service can be accessed at https geomodeling njnu edu cn modelitem wsm readers interested in the major components of the watershed system model including heiflow gbehm and wem models can contact the authors dr yi zheng zhengy sustech edu cn dr dawen yang yangdw tsinghua edu cn and dr feng wu wufeng igsnrr ac cn the source code of gbehm can be accessed via https github com gb03 gbehm and the meta information and web service of gbehm with an improved snow module can be accessed via https geomodeling njnu edu cn computablemodel gbehm snow the heiflow model with an improved water allocation module can be downloaded at https github com deephydro wra the datasets used to setup parameterize and validate the watershed system model including data on climate land use cover soil dem irrigation districts irrigation water diversions and withdrawals vegetation streamflow and groundwater level are partly available from the national tibetan plateau data center https data tpdc ac cn en special heihe and partly from the local water resources authorities http slt gansu gov cn and http www zhangye gov cn swj data supporting the results of this study can be provided upon request by contacting the corresponding authors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the strategic priority research program of the chinese academy of sciences grant no xda20100104 and the national natural science foundation of china grant no 91425303 and 41988101 appendix a abbreviations and acronyms hrb heihe river basin dss decision support system wem water economic model dvsim desert vegetation simulation model gehm general eco hydrological model abm agent based model gsflow groundwater and surface water flow modflow modular ground water flow model prms precipitation runoff modeling system gbhm geomorphology based hydrological model gbehm geomorphology based eco hydrological model heiflow hydrological ecological integrated watershed scale flow model heihe plan integrated study of the eco hydrological processes of the heihe river basin ridss river basin sustainable development decision support system un sdgs sustainable development goals of united nation ewdp ecological water diversion project 
25825,watershed system models are important tools for understanding complex watershed systems and integrated river basin management however there are very few models that can represent the coevolution of water ecology and socioeconomic system at the river basin scale in this study a watershed system model was developed using the case of the heihe river basin hrb a typical endorheic river basin in northwest china the model is mainly composed of an integrated ecohydrological model a socioeconomic model and two interface models it has been embedded into a decision support system using the surrogate modeling technique the watershed system model proved to be reliable in simulating multiple eco hydrological processes and showed good abilities in exploring the trajectories and interactions of water ecology and socioeconomy this study advances our understanding of the water land air plant human nexus at the watershed scale and has great implications for sustainable developments in endorheic river basins keywords watershed system model human nature system decision support system water resource management heihe river basin endorheic river basin 1 introduction watersheds are the basic unit of earth s land surface system and in most cases are characterized by complex natural human interactions numerical modeling is one of the fundamental methodologies used to study watershed scale earth systems over the last few decades countless numerical models have been proposed to simulate different elements within a watershed including surface water groundwater snow frozen ground land use cover water quality crop growth and socioeconomic behaviors liang et al 1994 wigmosta et al 1994 yang 1998 stöckle et al 2003 harbaugh 2005 schulla and jasper 2007 verburg and overmars 2009 luckmann et al 2014 hu et al 2018 fu et al 2020 yuan et al 2021 a watershed is a complex system with hierarchical structures and whole functions and is composed of a water resource system an ecosystem and a socioeconomic system cheng et al 2014 however most numerical models belong to the category of single disciplinary models and conventionally simulate natural and human processes separately by taking the other as an exogenous variable they are typically unable to model the dynamic feedbacks between the natural and socioeconomic dimensions of a watershed moreover numerical models typically designed for specific purposes or domains can rarely be applied to an entire watershed that has distinct natural and human characteristics over different sections the deficiencies of the existing models together with the increasing influence of human activities in the anthropocene era urgently call for the development of watershed system models to produce a holistic simulation of the water land air plant human nexus at the watershed scale sivapalan et al 2014 cheng and li 2015 inam et al 2017 kuil et al 2018 lu et al 2018 li and xie 2019 watershed system models are essential if we are to better understand complex watershed systems and support integrated river basin management cai et al 2015 li et al 2018b more importantly the development of watershed system model embraces the philosophy of the future earth program launched by the international science association icsu liverman et al 2013 griggs et al 2014 and will contribute to solving the last category of the twenty three unsolved problems i e interfaces with society recently identified by the hydrology community blöschl et al 2019 earth system models esms are essential tools for understanding large scale environmental changes and interactions within and among all relevant aspects of the earth system including the atmosphere land oceans and cryosphere esms have gained remarkable advances in the past few decades and continue to move toward fan et al 2019 a watershed is actually a basin scale earth system and therefore watershed system models can learn greatly from esms meanwhile watershed system models can offer some advantages over esms for instance watershed system models can give detailed considerations of human activities i e water diversion and allocation agricultural water management and water policy and their interactions with the natural system which is a difficult task to complete with an esm clark et al 2015 fan et al 2019 nevertheless there are grand challenges for the development of a watershed system model li et al 2018b first the natural and human system models differ significantly in describing the spatial relationships of the modeling units and they typically have quite different spatiotemporal resolutions wada et al 2017 the ecohydrological model usually describes the study domain in a distributed manner while the socioeconomic model describes it in a lumped approach furthermore the integration of various components of the human and natural system models potentially increases the computational burden considerably hence watershed system models typically require extreme computer processing and storage capacity which constrains their incorporation into decision support systems dsss finally the development of a watershed system model is essentially a transdisciplinary issue that can be accomplished only through a strong collaboration among many researchers in diverse scientific communities by taking advantage of the state of the art advances in ecohydrology hydro economy eco economy and water resource economics endorheic basins which refer to hydrologically landlocked areas are widely distributed in arid and semiarid regions of the world wang et al 2018a covering approximately one fifth of the earth s land surface in the last few decades many endorheic basins such as the aral sea basin micklin 1988 lake urmia stone 2015 lake chad alfa et al 2008 shiyang river basin wang et al 2002 huo et al 2008 and heihe river basin hrb cheng et al 2014 tell a similar story i e the overexploitation of water resources has seriously deteriorated the watershed ecosystem the essence behind the story lies in the irrational water allocations between human and natural systems in view of this how to harmonize human and ecological water uses has become one of the critical issues that needs to be addressed by managers and researchers however this intractable and complex issue involves many aspects such as the hydrology economy ecosystem institution and water resource management which necessitates a step forward to represent both the human and natural aspects of a watershed with a sophisticated model li et al 2018b the hrb is a typical endorheic basin in the arid region of northwestern china the basin has received considerable attention from researchers in both china and other countries due to its distinct alpine oasis desert landscapes li et al 2016 2018a and fierce water use competition between humans and ecology cheng et al 2014 the upstream area is located in the qilian mountains on the northeastern tibetan plateau with relatively little human interference but important cryospheric processes such as snow accumulation and melt permafrost degradation and glacier retreat chen et al 2018 che et al 2019 the mid and downstream areas however are located in arid regions with flat terrains intensive irrigated agriculture and frequent surface water groundwater exchanges tian et al 2015b in recent years two watershed scale ecohydrological observation programs i e the watershed allied telemetry experimental research water li et al 2009 and the heihe watershed allied telemetry experimental research hiwater li et al 2013 2017a and many modeling works have been carried out in the hrb gao et al 2008 2016 zhou et al 2012 wang et al 2013 tian et al 2015a 2015b 2018b yao et al 2015 qin et al 2016 cong et al 2017 guo et al 2018 hu et al 2018 sun et al 2018b which have substantially improved our understanding of the basin s ecohydrological processes nevertheless an integrated watershed system model that can represent the water ecosystem economy system of the entire hrb is still lacking leading to some of the critical issues remain to be resolved i there are significant differences regarding the ecohydrological processes in the different sections of the hrb how can the ecohydrological models of the different sections be integrated for the entire basin meanwhile how can the integrated ecohydrological model be further coupled with the socioeconomic system model ii what are the distinct characteristics of the newly developed watershed system model what are the advantages of the watershed system model over the existing single discipline models iii can the watershed system model be used within the framework of dss to better support watershed management and sustainable development to address these questions this study proposed and developed a watershed system model to represent the integrated water ecosystem economy system by combining the existing knowledge and techniques with a case study of the hrb the work was conducted under the major research plan of the national natural science foundation of china nsfc i e integrated research on the ecohydrological process of the heihe river basin referred to as the heihe plan this plan was carried out in 2010 with the primary goals of revealing the ecohydrological regimes at multiple scales improving the understanding and predictability of the evolution of the water ecosystem economy system and providing scientific support for the sustainable development of inland river basins li et al 2013 the rest of this paper is organized as follows the framework of the watershed system model is briefly described in section 2 in section 3 the coupling mechanisms of different components of the watershed system model are presented the validation and applications of the watershed system model are presented in section 4 finally section 5 contains some concluding remarks and our prospects for future work 2 framework of the watershed system model 2 1 aims of the watershed system model integrating the water ecosystem and socioeconomic systems fig 1 shows the evolution of the model related studies in the hrb three different stages could be identified after 2000 in the first stage i e the years from 2000 to 2010 various hydrological models such as swat vic hbv prms and dhsvm have been applied in the hrb the objectives of the related studies mainly included two aspects at this stage one was the verification and evaluation of the existing hydrological models and the other was the improvement of the understanding of the changes in hydrology and water resources in the hrb after the preliminary studies during the first stage researchers found that some of the special ecohydrological processes such as the cryospheric processes of snow glaciers and frozen ground the frequent interactions of groundwater and surface water in the plain areas of the hrb and the strong dependence of vegetation on groundwater resources could not be well represented by the existing models after 2010 the watershed model related studies transitioned into the second stage and many efforts have been made to revise or integrate the existing models to enhance the modeling of the special ecohydrological processes in the hrb and to improve the comprehensive simulations of the watershed model at the latest stage i e 2015 to present researchers in different disciplinaries have attempted to work together for the development of the integrated model stimulated by the major research plan i e the heihe plan two integrated ecohydrological models i e the geomorphology based ecohydrological model gbehm and the hydrological ecological integrated watershed scale flow heiflow model were developed during this stage building on the rich modeling experience and knowledge accumulated in the three stages we proposed the watershed system model with two primary goals one is to improve the scientific understanding of the water land air plant human nexus by integrating the water ecologic and socioeconomic systems the other is to serve river basin management by supporting the development of a dss using the watershed system model as the backbone 2 2 overarching structure of the watershed system model of the hrb the framework of the watershed system model designed for the hrb is shown in fig 2 an ecohydrological model and an economic system model were bidirectionally coupled through two interface models i e the land use and water resource models within the framework of the watershed system model the ecohydrological and economic models as well as the interface models interact with each other directly or indirectly through exchange variables such as flow and groundwater level water allocation and land use types as depicted along the arrows of fig 2 because of the differences in the model structure spatiotemporal resolutions and programming languages of the four main components both offline and online integration strategies were employed in this study the offline strategy refers to a loose coupling scheme through the exchange of input output files while the online strategy refers to a tight coupling approach at the source code level details about the coupling schemes are presented in section 3 the ecohydrological model is composed of the gbehm and heiflow models the gbehm model is designed for the mountain cryosphere of the hrb it inherits all of the functions of the geomorphology based hydrological model gbhm yang et al 2004 and enhances the representations of the cryospheric processes of snow glaciers and frozen ground gao et al 2018 the heiflow model however is designed for the oasis desert plains of the hrb tian et al 2015a 2015b 2018b han et al 2021 it is a fully coupled surface and groundwater model that can explicitly simulate ecological processes e g vegetation dynamics and crop growth and agricultural water management the water economic model wem is an economic system model designed for the entire hrb and it is developed mainly based on the input output table it is an indispensable component of the watershed system model and plays a critical role in determining the water allocations and the land use structure li et al 2018c the economic model was also coupled with the abm to account for the social dimension of the watershed and the interactions between macro economic and micro economic behaviors du et al 2020 the production consumption and accumulation economic behaviors of peasant households in the abm are the key components of the wem making it a bottom up approach in addition two interface models i e the water resources model tian et al 2015a 2018a and the land use model were included in the watershed system model they mainly play a role in bridging the ecohydrological and economic system models three different irrigation modules were developed within the water resources model to describe the agricultural water management activities one module distributes diverted water from rivers to farmlands and the other allocates pumped groundwater to farmlands tian et al 2015a the additional module simulates the demand based diversion and pumping rates tian et al 2018a the performance of the economy in the economic system model drives the changes in land use cover and the simulations of land use changes are passed to the ecohydrological model the critical feedback of the ecohydrological model to the socioeconomic model is the water allocation in the water resources model 2 3 evolution of the watershed system model the watershed system model of the hrb has evolved from many existing models as plotted in fig 3 the rooted models of the watershed system model include the u s geological survey precipitation runoff modeling system prms the modular ground water flow model modflow and the gbhm we developed and grafted many models modules to better represent the special ecohydrological processes within the hrb the newly developed modules models marked with yellow colors include the crop growth model the desert vegetation growth model and the physically based snow module snow while the grafting modules models marked with green colors include the generic vegetation model revised from the environmental policy integrated climate epic model the soil freezing and thawing process module from the simultaneous heat and water shaw model and the simple biosphere model sib2 the generic vegetation model and the crop growth and desert vegetation models were coupled with the gsflow model which integrates prms and modflow leading to the generation of heiflow these efforts were mainly devoted to better represent the ecological processes of distinct landscapes in the middle and downstream areas of the hrb meanwhile the sib2 and shaw models and the snow module were coupled with the gehm for a better simulation of the cryospherical processes in the upstream area of the hrb leading to the generation of the gbehm model the heilow and gbehm models were coupled to generate an integrated ecohydrological model for the entire hrb meanwhile the microbehavior based abm and the macroeconomic based wem which was developed based on the computable general equilibrium cge and the input output model were integrated to generate a socioeconomic model for the hrb the ecohydrological model was further coupled with the socioeconomic model through two interface modules i e the land use and water resource models finally leading to the generation of the watershed system model in the hrb 2 3 1 gbehm an ecohydrological model with cryosphere hydrological processes for the mountainous area of the hrb the gbehm model yang et al 2015 as shown in fig 4 is an updated version of the geomorphology based hydrological model i e gbhm that was developed by yang et al 2004 compared with the gbhm the major enhancements of the gbehm include the following i a grid system scheme with a spatial resolution of 1 km 1 km to discretize the catchment ii the evapotranspiration et estimation from the penman monteith equation has been replaced by a simple biosphere model used in the simple biosphere model sib2 sellers et al 1986 1996 yang et al 2015 gao et al 2016 iii the vertical soil column in the gbehm could be extended deeply to approximately 50 m so that it could simulate the hydrological process of groundwater particularly in the permafrost region yang et al 2015 gao et al 2018 iv the vegetation dynamics were coupled with the hillslope hydrological processes gao et al 2016 and finally v it has the full functions of modeling cryosphere hydrological processes including glacier ablation li et al 2012 snow accumulation and melting li et al 2019a and soil freezing and thawing zhang et al 2013 gao et al 2018 the gbehm model has been successfully applied to study ecohydrological and cryospheric processes zhang et al 2013 2018 as well as their responses to climate change in the past and future qin et al 2017 zhang et al 2017 gao et al 2018 wang et al 2018b 2 3 2 heiflow a surface water groundwater interactional model with intensive agriculture over the oasis desert area of the hrb the heiflow model as shown in fig 5 has been developed for the mid and downstream areas of the hrb by integrating the 2d surface flow 3d groundwater and ecology models and by coupling different vegetation modules and the water management module tian et al 2015b 2018a 2018b yao et al 2015 2017 sun et al 2018b zheng et al 2020 han et al 2021 the heiflow model version 2 0 tian et al 2018b was evolved from the well known gsflow model and it can simulate all the major hydrological processes within and among three different regions including the areas from the top of a plant canopy to the soil zone base the subsurface zone beneath the base of the soil zone and the areas of streams and lakes markstrom et al 2008 compared with gsflow heiflow has the following distinct features i it improves the soil water simulation by introducing the sub grid structure of land cover multilayer soil water simulation and accurate spatial coverage of irrigation within the hrus han et al 2021 ii it can have time variant model parameters values and therefore is able to accept multiperiod land use data as the model inputs tian et al 2018b iii it includes a water resource allocation wra module to emulate high resolution irrigation activities and represent water management policies zheng et al 2020 and it also couples an agent based model to simulate farmers decision making on water use influenced by collective water management policies du et al 2020 and iv it couples multiple ecological modules that can simulate growth of various vegetation types e g grass crops desert vegetation and populus euphratica li et al 2017b sun et al 2018a han et al 2021 hence heiflow has a good capability of capturing the co evolutions and trade offs among ecology surface water and groundwater heiflow has been successfully used to simulate the ecohydrological processes dominated by the complex interactions between surface water and groundwater and water resource allocation several cases will be presented in section 4 2 3 3 wem social economic model over the hrb a wem for the entire hrb focusing on the interactions between water resources and economic elements has been developed based on the input output table that embeds water land resource factors wu et al 2017 li et al 2018c the wem mainly has three modules i e the production consumption and market equilibrium modules fig 6 water resources are integrated with capital and labor a production factor allocated in the economic model through market mechanisms such as water price adjustments and water rights transfers the incomes of various industrial sectors will change with time and they could exert an indirect impact on expenditures such as consumption investment imports and exports the wem is a highly efficient tool for water resource management and policy decision support water resources can be integrated into the social accounting matrix by the conversion of a physical object to a value the changes in water demands can be effectively simulated under urbanization and industrial transformation scenarios moreover the effects of water market allocation on industrial development can be investigated additionally the social accounting matrix sam which is an extended input output table that adds the factors for production and institutional sectors households firms and government and illustrates the links between the production sectors and all entities in the economy has been embedded in the wem the water embedded sam model was applied to explore the economic structure feedback mechanism and water flows among different sectors zhou et al 2017 it has also been used to simulate the chain effects among different sectors under different agricultural water price scenarios wu et al 2015 it takes what is referred to as a bottom up approach to analyze the agricultural economy therefore an abm was used to describe the agricultural economic behaviors in production and consumption activities the wem takes into account taxes regulations and government legislation it determines the course and nature of the economy looking at the economy as a whole the wem includes the economic behaviors of all sectors however the abm describes the economic behavior of the agricultural sector irrigation agriculture is the largest user of water in heihe accounting for nearly 90 of the total water use therefore the abm is integrated into the wem the wem runs with endogenous prices in addition to quantities which feeds back farmer behavior in the abm to analyze the economic impacts of water shortages and water trading 3 coupling the natural system model with the socioeconomic models the natural system model i e the ecohydrological model was coupled with the socioeconomic system model via two interface models i e the land use and water resource models at various spatiotemporal scales i e county and grid annually and daily by using the surrogate modeling technique in the first step the gbehm and heiflow models were loosely coupled to form an integrated ecohydrological model to simulate the natural processes of the entire hrb the coupling was implemented through an offline file transfer approach the stream flows at the outlets of the sub watersheds in the upstream area of the hrb were first simulated by gbhem and then transferred to heiflow as the input boundary inflows in the second step the integrated ecohydrological model was coupled with the wem at the annual temporal scale and it was tightly coupled with the abm based agricultural economic model at the daily scale the main challenge of coupling the natural system model with the economic model lies in the heavy computational burdens we found that computational expenses would increase exponentially when the economic and natural system models were integrated to address this issue we realized the coupling process through a surrogate modeling technique surrogate modeling refers to the replacement of a complex physically based model with the data driven relationship between multiple explanatory variables and the model outputs razavi et al 2012 wu et al 2016 this approach could considerably improve the computational efficiency of the watershed system model without sacrificing the simulation accuracy more specifically the coupling of the ecohydrological model with the socioeconomic model was implemented as plotted in fig 7 the simulations of the land use model i e the proportions of different land use types were transferred into the ecohydrological surrogate model which simulated the total available water resources to the socioeconomic surrogate model in turn the socioeconomic surrogate model feeds the water demands of different sectors under different climate change scenarios and economic development scenarios to the ecohydrological surrogate model and feeds the land use demands to the land use model based on the surrogate modeling technique the ecological hydrological and socioeconomic models were coupled together which eventually gave birth to the watershed system model the ecohydrological model was coupled with the wem at the annual and administrative regional scales and it was also coupled with the abm at the daily and irrigation district scales the input output embedded land and water resources served as the intermediaries between the ecohydrological model and the economic model the abm was used to simulate farmers water use decisions regarding the use of groundwater and surface water for irrigation du et al 2020 the farmers water use i e surface water diversion and groundwater pumping and agricultural economic value were the primary exchanges between the wem and abm 4 validation and application of the model 4 1 validation of the model the streamflow simulations of the watershed system model were verified against the streamflow observations at different hydrological stations i e yingluo gorge qilian zhamashike zhengyi gorge and langxinshan among them yingluo gorge and zhengyi gorge are the outlets of the upstream and midstream areas of the hrb respectively as shown in fig 8 meanwhile the groundwater level simulations were compared with the borehole observations in addition the pixel scale et upscaled from the multisite measurements liu et al 2016 2018 was used to further crosscheck the simulations of the watershed system model as shown in fig 8 the monthly streamflow simulations match very well with the observations at the gauges in different sections of the hrb the values of the kling gupta efficiency kge gupta et al 2009 approach 0 87 0 77 0 82 0 93 and 0 94 at the qilian zhamashike yingluo gorge zhengyi gorge and langxinshan stations respectively meanwhile the mean annual groundwater level simulations show a very close correlation with the observations as indicated by the high coefficient of determination r2 0 99 in terms of the et simulations they are very comparable to the upscaled observations as presented in fig 9 the r2 values are 0 86 0 76 and 0 74 in the upstream midstream and downstream areas of the hrb respectively the rmse and the mean absolute percent error mape are 0 7 mm day and 19 1 1 2 mm day and 21 9 and 1 8 mm day and 25 9 respectively the precision of the et simulations tends to increase from the upstream area to the downstream area of the hrb overall these results confirm that the model has a good ability to reconstruct the key hydrological components in the hrb and it could be a reliable tool for various purposes i e the long term hydrological modeling and water balance analyses 4 2 hydrological cycle in the hrb the watershed system model was used to close the water balance of the hrb at multiple scales we used the watershed system model to quantify the basin scale water balance for the 2001 2012 period the water balance of the hrb can be expressed as in eq 1 1 p e t δ s w δ g w δ r δ c ε where p is the precipitation et is the evapotranspiration δsw δgw δr and δc represent the storage changes in soil water groundwater lake reservoir and cryospheric water respectively and ε is the mass balance error the hydrological cycle and the water balance for the hrb are shown in fig 10 the hrb receives approximately 15 68 109 m3 yr 1 or 134 70 mm yr 1 of precipitation and releases or consumes approximately 15 51 109 m3 yr 1 or 133 25 mm yr 1 of water through et the soil water storage shows a decreasing trend with a decrease of 0 06 109 m3 yr 1 or 0 48 mm yr 1 while the groundwater storage including the water in the unsaturated zone and the lake and reservoir water storage show upward trends with increments of 0 07 109 m3 yr 1 or 0 59 mm yr 1 and 0 01 109 m3 yr 1 or 0 06 mm yr 1 respectively the increase in lake and reservoir water storage is partially due to the increasing inflows to downstream terminal lakes induced by the ecological water diversion project ewdp implemented in 2000 cheng et al 2014 and is partially due to the increasing precipitation in the upstream area zhang et al 2015 although groundwater storage shows an increasing trend at the basin scale it decreases obviously with a magnitude of 0 14 109 m3 yr 1 or 10 67 mm yr 1 in the midstream area of the hrb mainly due to the increasing groundwater withdrawal from irrigating expanded farmlands the decreasing groundwater storage in the midstream area is offset by the increasing trends in the other sections of the hrb leading to an upward trend as a whole at the basin scale the cryospheric water storage exhibited a downward trend with a magnitude of 0 02 109 m3 yr 1 or 1 01 mm yr 1 over the upstream area of the hrb or 0 13 mm yr 1 over the entire hrb which can be explained by the warming climate in the upstream area of the hrb snowmelt runoff accounts for approximately 15 6 of the discharge at the outlet of the upstream area in particular it contributed considerably to the spring streamflow which approach approximately 50 li et al 2019a the meltwater of underground ice over the permafrost region accounts for approximately 6 of the total streamflow at the outlet of the upstream area of the hrb li et al 2019b while glacier meltwater accounts for less than 5 gao et al 2018 li et al 2018a precipitation is relatively scarce in spring during which however the water demands of irrigated agriculture are increasing in the midstream area of the hrb the irrigation demand deficit is likely to be exacerbated by decreasing cryospheric water storage during the early crop growth stage more details about the water budgets for the upstream midstream and downstream areas of the hrb and those for different landscapes river channel sections and irrigation districts are available in our previous study li et al 2018a fig 11 shows the variations in the water cycle components in the hrb for the 2001 2012 period the mountainous runoff increases with a magnitude of 0 073 109 m3 yr 1 however at the same time both irrigation water uses and et present increasing trends in the middle and downstream areas of the hrb this leads to downward trends in groundwater levels with magnitudes of 0 284 m yr 1 and 0 025 m yr 1 in the middle and downstream areas of the hrb respectively these results indicate that the increasing water demand of agricultural development in the middle and downstream areas was met simultaneously by the increasing water availability from the mountainous region of the hrb and the overexploitation of groundwater the delicate water balance might be easily broken with decreasing water resources from the upstream area of the hrb and agricultural expansions in the future 4 3 long term hydrological modeling past simulation and future prediction long term hydrological modeling will provide valuable information for water resource management in this study we conducted hydrological modeling in the hrb for a long term period of 60 years 2001 2060 by using the watershed system model the climate data for the period 2016 2060 which were dynamically downscaled from the outputs of the ec earth earth system model ec earth hazeleger et al 2010 under the ipcc rcp 4 5 scenarios by using a high resolution regional climate model xiong and yan 2013 together with past meteorological observations were used to drive the watershed system model the model settings and parameters were kept constant for the past and future simulation periods fig 12 a shows the variations and trends in streamflows at the yingluo gorge zhengyi gorge and langxinshan stations the streamflows present obvious increasing trends at all the stations for the 2001 2016 period while they show downward trends over the remaining period 2017 2060 the streamflow of the yingluo gorge station shows the largest magnitude of trends which are 4 1 107 and 1 4 107 m3 year respectively for the 2001 2016 and 2017 2060 periods followed by the zhengyi gorge and langxinshan stations the water storage of the terminal lake sogo nuur increases more than five times from 2001 to 2016 while it exhibits a decreasing trend from 2017 to 2060 these results indicate that the water availability in the hrb tends to decrease in the future which will possibly aggravate the water use conflicts between humans and ecosystems it is critical to take adaptive measures such as strict constraints on farmland expansion and groundwater pumping to ensure sustainable development among agriculture groundwater and ecosystems 4 4 quantifying the socioeconomic water use water is the most precious resource in arid semiarid regions for sustaining the eco agro economic systems of oases hence the most critical aspect of water management in the hrb is how to improve water use efficiency and water productivity the wem was used to represent the mutual feedbacks between economic systems and ecohydrological processes based on the wem the water availability as well as the economic development scenarios for the hrb were determined fig 13 shows the water use in the water economy society integrated system of the hrb for 2012 the agricultural sector is the largest water consumer in each county of the hrb the water consumption of the secondary and tertiary industries is less than that of agricultural production the results reveal that the total water use in the socioeconomic system is approximately 4505 million m³ including 4460 million m³ of direct production water and 45 million m³ of direct domestic water regarding the consumption of real water and virtual water the economic system consumes 5520 million m³ while the social system consumes 4460 million m³ including almost 2973 million m³ of surface water and 1532 million m³ of underground water when all the counties are considered the sectors with the highest virtual water import and export are the food manufacturing and tobacco processing industries in jiayuguan county with the values of 73 57 and 119 33 million m3 respectively while the sector with the lowest virtual water import and export for all counties is the textile industry with the values of 1 44 and 0 20 million m3 respectively the sectors mainly responsible for virtual water import are the chemical industry accommodation and catering the food manufacturing and tobacco processing industries and the metal smelting and rolling processing industries the virtual water import leads to an increase of water availability and it might be an effective way to alleviate regional water stress in contrast the export of virtual water leads to an increase of water consumption which contributes to water stress at local scales the socioeconomic feedback on the water uses of the different industrial sectors was simulated with the wem in total we designed three scenarios regarding the upgradation of the industry structure with the assumptions that the technical progress rates of agriculture industry and service would increase by 5 i e scenarios i ii and iii respectively we found that the usages of surface water and groundwater would decrease under scenario i while they would not exhibit an obvious change under the other scenarios scenario iii would significantly promote the development of agriculture and industry hence the local government should prioritize technical progress in the service sector a modern service industry with a low water consumption should be encouraged and the market competition mechanism needs to be introduced to the higher water consuming service industry to increase the water use efficiency 4 5 experiments on the applications of the watershed system model to critical water resource management issues the watershed system model provides a reliable tool to investigate the ecohydrological impacts of various water management scenarios currently three groups of model experiments regarding water allocation ecological de farming and reservoir operation have been carried out in the hrb by using the watershed system model 1 a trade off relationship among water ecosystems and agriculture in the water allocation experiments three different water use reduction strategies i e reductions in diversions only reductions in groundwater pumping only and proportional reductions in both surface water diversions and groundwater pumping were implemented for the validated watershed system model sun et al 2018b the magnitudes of the reductions were proposed based on the historical gaps between the actual outflows and the goals of the ewdp implemented in 2000 the modeling results of different scenarios were compared with the benchmark which represents the real water use condition in the hrb the results indicated that direct reductions in groundwater extractions could restrain the decreasing groundwater storage whereas they could not induce an apparent increase in the discharge to the downstream area of the hrb consequently the measure could not meet the goal of the ewdp approximately 10 108 m3 yr 1 for a normal hydrological year however the reduction in surface water diversion could meet the water diversion goal while it could not alleviate the significant downward trend of groundwater storage a direct reduction in irrigation demands would benefit groundwater storage or ecosystems but it would be harmful to agriculture overall these results highlighted that the water ecosystem and agriculture are closely interlinked with a prominent tradeoff relationship among the different sections sun et al 2018b the water allocation experiment demonstrated the ability of the watershed system model to support water resource allocation and management 2 defarming policies will alleviate water conflicts between humans and ecosystems the farmland area increased substantially in the midstream area during the past decade which led to a series of ecological problems such as the death of ecological forests the shrinkage of wetlands and the generation of groundwater funnels hu et al 2015 ecological defarming experiments were carried out to study the responses of the entire surface and groundwater system to various ecological defarming scenarios of which the newly developed farmland of the midstream area of the hrb in 2011 was assumed to be returned to the status in 2000 and 2007 respectively while the other land types were kept constant the hydrological simulations of the watershed system model parameterized with different land use maps were compared to evaluate the influence of defarming practices we found that et would decrease by 0 73 7 55 mm yr 1 while the streamflow and groundwater level would increase by 0 19 0 90 109 m3 yr 1 and 67 73 270 91 mm yr 1 respectively in the midstream area of the hrb meanwhile the et and groundwater level would increase by 0 25 1 31 mm yr 1 and 1 43 7 68 mm yr 1 respectively indicating that the ecosystem would be further improved with the defarming policy the proposed defarming practice may be a promising strategy for balancing the agriculture water ecosystem nexus in the hrb the ecological defarming experiment indicates that the watershed system model would help to make scientific based land management policies 3 considerable ecohydrological impacts of the newly constructed large reservoir the huangzangsi reservoir located in the upstream area of the hrb is currently under construction and is expected to be accomplished in 2022 reservoir operation experiments were performed to investigate the ecohydrological impacts of different reservoir operational strategies the different reservoir operations were designed to release the water for ecological flow purposes with different durations and discharge rates but the same total volume the watershed system model was run with the different reservoir operation strategies and the results were compared with each other tian et al 2018a the results indicated that the water allocation goals of the ewdp could be approached through reservoir operation and groundwater storage could be recovered significantly in the downstream area of the hrb nevertheless the assurance rate of agricultural water uses and groundwater storage would decrease in the midstream area of the hrb which might have adverse effects on wetland ecosystems further analyses implied that the operational strategies characterized by smaller water releases with longer durations were more beneficial to achieve the water allocation goals of the ewdp and to increase groundwater recharges in the midstream area of the hrb the reservoir operation experiment implied that the watershed system model could enhance the evaluation of influences of the large water conservancy facility from a watershed scale perspective 4 6 water resource sustainability dss based on the watershed system model one of the ultimate goals of the watershed system model in the hrb was to serve river basin management by supporting the development of a scientific model based dss that could be used for sustainable development assessments ge et al 2013 2018 a river basin sustainable development decision support system risdss that integrates the sustainable development goals of the united nations un sdgs and the local watershed features was developed to address the co developments of the water ecological and socioeconomic systems fig 14 in the risdss we utilized the watershed system model to simulate ecohydrological processes under the interference of human activities including irrigation expending farmland gdp and water productivity and to determine the states of key natural and socioeconomic elements in the future this watershed system model could provide more than 20 output variables such as the gdp population farmland area water price and agricultural water demand for the 10 counties in the hrb at the annual scale these variables are the major parameters used to quantify the indicators of watershed scale sdgs and are closely related to the co development of the ecohydrological and socioeconomic pathways we employed the surrogate modeling technique based on the latin hypercube sampling and support vector machine methods to reduce the dimensionality of the ecohydrological model while maintaining the simulation and prediction accuracy the risdss was applied to project 2160 pathways in the hrb and to analyze the impacts of three major driving forces including precipitation technological level and ecological water flow on the sustainability of this basin in addition we integrated various statistical models into the risdss to quantify the population growth urbanization progress and changes in the forest and grassland areas under the scenarios of a changing climate population and urbanization progress the coupling of these statistical models with the watershed system model could help to output some key variables that cannot be obtained by the two kinds of models for example gdp per capita in addition on the basis of the disaggregated un sdgs and the chosen driving forces ruled by shared socioeconomic pathways ssps we employed an urbanization model and a population development environment pde model together with the simulations of the regional integrated environmental model riems 2 0 to quantify the changes and ranges of the driving forces under future scenarios after the assignment of different scenario parameters the watershed system model could project diverse ecohydrological and socioeconomic pathways then the sustainability assessment model could be used to investigate the sustainability of these pathways by regulating the driving forces accordingly we will identify the key factors dominating the sustainability of river basin development and determine the tipping point of water stress by analyzing the relationships among the changes in the different pathways their sustainability and the driving forces 5 summary and prospects we developed a watershed system model for the hrb a typical endorheic river basin in northwest china via the collective efforts of various research groups in different disciplinaries the watershed system model represents the natural systems of the hrb by using an integrated ecohydrological model and describes the socioeconomic system by using a socioeconomic model integrated by the macroeconomic based wem and the abm meanwhile it simulates the interactions between the natural and socioeconomic systems by coupling the ecohydrological model with the socioeconomic model through two interface models i e the water resources model and the land use model the coupling was implemented at various spatiotemporal scales by using a surrogate modeling technique the watershed system model was evaluated against multiple ground based observations including streamflow groundwater level and et the results indicate that it achieved good performance in the hrb the kge was greater than 0 80 for the streamflow simulations at most of the hydrological stations and the r2 was greater than 0 7 for the et simulations and was closer to 1 for the groundwater level simulations the watershed system model was further demonstrated to have good capacities in i closing the water balances at multiple spatial scales ranging from landscapes districts and subbasins to the entire river basin ii analyzing and forecasting the water use efficiency and water productivity of the socioeconomic sector or system iii simulating and projecting the long term hydrological regimes iv understanding the ecohydrological responses to some critical water management measures and v supporting the development of the scientifically based dss the watershed system model is an earth system model at the watershed scale the successful development of the watershed system model in the hrb could promote a paradigm that shifts from single disciplinary research methods to interdisciplinary and integrated methods in watershed science the coupling of hydrology ecology and socioeconomy within the watershed system model not only enhances the understanding of the phenomenon that arises from the coevolution and two way feedbacks between the human and natural systems but also helps to improve the management and regulation capacities of the hrb moreover the watershed system model provides a robust tool for the realization of the un sdgs the methodology and findings of this study could provide a valuable reference for other endorheic river basins around the world with similar characteristics to the hrb as shown in fig 15 our desired aim was to develop a watershed system model that could represent the coevolution of natural and human systems that include the water land air plant human nexus li et al 2018b li and xie 2019 nevertheless in this study we mainly focused on the interactions of water ecosystem and socioeconomic system there remain some issues and challenges open for further investigations first the natural system model needs to be improved in the future the two way coupling of the ecohydrological model and the regional climatic model was not realized in our watershed system model which limits its capacity to capture the feedbacks between ecohydrology and climate the significant interactions among intensive irrigation ecohydrological processes and regional circulation patterns e g moisture recycling need to be simulated by the desired watershed system model moreover some other key natural processes of the watershed system such as the biogeochemical cycles and vegetation succession are proposed to be represented within the desired watershed system model second social processes such as the water resource management institution and behavioral characteristics of water users which are typically underrepresented in esms need to be further enhanced within the framework of the watershed system model to better account for the interactions among water users hydrology managers and policy makers these processes will be more deeply coupled with the water systems across multiple scales sivapalan and blöschl 2015 sectors and agents as emphasized by the new science of socio hydrology sivapalan et al 2012 to improve the watershed system model s power in explaining and predicting various water sustainability problems such as the efficiency paradoxes and the emergent phenomena sivapalan et al 2014 finally issues such as how to efficiently constrain and assess the uncertainties and complexities of the watershed system model li 2014 koo et al 2020 how to better use the increasingly available remote sensing products artificial intelligence and big data deluge within the watershed system model and how to balance the model s complexities robustness and efficiency are still open for further explorations in the future we will attempt to digest a number of new concepts e g anthropocene tipping elements and planetary boundaries framework technologies e g deep learning big data and high speed computing innovative open web based frameworks e g the opengms platform chen et al 2019 chen et al 2020 to achieve a deeper integration of natural processes with human dynamics that go beyond the economic models steffen et al 2020 software and data availability codes of the watershed system model can be downloaded from https github com heiheproject wsm and the model s meta information and web service can be accessed at https geomodeling njnu edu cn modelitem wsm readers interested in the major components of the watershed system model including heiflow gbehm and wem models can contact the authors dr yi zheng zhengy sustech edu cn dr dawen yang yangdw tsinghua edu cn and dr feng wu wufeng igsnrr ac cn the source code of gbehm can be accessed via https github com gb03 gbehm and the meta information and web service of gbehm with an improved snow module can be accessed via https geomodeling njnu edu cn computablemodel gbehm snow the heiflow model with an improved water allocation module can be downloaded at https github com deephydro wra the datasets used to setup parameterize and validate the watershed system model including data on climate land use cover soil dem irrigation districts irrigation water diversions and withdrawals vegetation streamflow and groundwater level are partly available from the national tibetan plateau data center https data tpdc ac cn en special heihe and partly from the local water resources authorities http slt gansu gov cn and http www zhangye gov cn swj data supporting the results of this study can be provided upon request by contacting the corresponding authors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work is supported by the strategic priority research program of the chinese academy of sciences grant no xda20100104 and the national natural science foundation of china grant no 91425303 and 41988101 appendix a abbreviations and acronyms hrb heihe river basin dss decision support system wem water economic model dvsim desert vegetation simulation model gehm general eco hydrological model abm agent based model gsflow groundwater and surface water flow modflow modular ground water flow model prms precipitation runoff modeling system gbhm geomorphology based hydrological model gbehm geomorphology based eco hydrological model heiflow hydrological ecological integrated watershed scale flow model heihe plan integrated study of the eco hydrological processes of the heihe river basin ridss river basin sustainable development decision support system un sdgs sustainable development goals of united nation ewdp ecological water diversion project 
25826,this study employs a distributed eco hydrological landslide model the tribs veggie landslide to evaluate the influence of terrain resolution on the hydro geomorphological processes involved in slope stability analysis the model implements a triangulated irregular network tin to describe the topography starting from a grid dem five grid dem resolutions of the case study basin i e 10 20 30 and 70 m are used to derive the corresponding tins the results show that using irregular meshes reduces the loss of accuracy with coarser resolutions in the derived slope distribution in comparison to slope distributions estimated from the original grid based dem from a hydrological perspective the impact of resolution on soil moisture patterns and on slope stability is significant mostly when lateral water exchanges are allowed the degrading of resolution leads to a reduction of the predicted unstable areas with respect to the highest resolution case from about 15 20 m to more than 40 70 m keywords hydrologic modeling landslides numerical modeling digital elevation models slope stability analysis 1 introduction physically based modeling is one of the approaches used to assess the vulnerability of natural basins to hillslope instability induced by extreme or prolonged precipitation the increasing trend of weather related disasters hoeppe 2016 motivates the continuing interest in more reliable tools for prediction and analysis of precipitation induced landslide events one of the issues extensively discussed in landscape modeling is the use of the appropriate grid digital elevation model dem resolution specifically the question is whether adopting the finest available grid dem hereinafter simply dem resolution is a justified choice not only in terms of computational requirements but also in terms of effective improvement of the model capability in predicting determining the initiation of landslides cavazzi et al 2013 fuchs et al 2014 the dem is used to extract morphological secondary attributes such as slope aspect flow path upstream contributing area etc lack of accuracy in the primary attribute i e elevation would be propagated on the extracted morphological information wu et al 2007 vaze et al 2010 yang et al 2014 in landslide modeling the local slope angle is the variable which most influences the calculation of the terrain stability in both direct and indirect ways hydrological stability approaches are based on the integration of distributed hydrological models with the simple infinite slope model montgomery and dietrich 1994 iverson 2000 claessens et al 2005 rosso et al 2006 arnone et al 2011 lepore et al 2013 the landslide stability model computes the equilibrium of forces on a shallow soil prism gravity acts to initiate a slide as a function of the slope angle and the total wight of the soil including water friction resists sliding and it is affected by soil moisture the steeper the slope the greater the component favoring slide initiation direct effect catchment slope distribution also controls many of the hydrological terrain based processes such as the surface flow paths and the lateral redistribution of subsurface flows which ultimately determine the local soil moisture the duration of the transient regime after an event and thus the soil water pressures that impact the forces equilibrium although high resolution digital terrain data allows a more realistic representation of topography and consequently a better analysis of hillslope and valley morphology which are very important in the recognition of the topographic signature of valley incision by debris flows and landslides tarolli and dalla fontana 2009 a high resolution dem does not always imply a better performance in modelling the processes that lead to landslides several studies have explored how the grid cell size of the input topography data may influence rainfall induced landslides some studies focus on landslide susceptibility chang et al 1991 lee et al 2010 grohmann et al 2015 arnone et al 2016a cama et al 2016 and others explore the impact of resolution on results from physically based models zhang and montgomery 1994 tarolli and tarboton 2006 claessens et al 2005 de sy et al 2013 keijsers et al 2011 fuchs et al 2014 penna et al 2014 mahaigam and olsen 2015 viet et al 2016 most of the results of these studies agree that the coarser resolutions tend to smooth the terrain description i e local slope angle decreases thus reducing the number of unstable areas specifically keijsers et al 2011 used the lapsus ls claessens et al 2005 model and found that coarser resolutions reduced the ability to predict probability of failure at a particular location yet stable areas were predicted correctly however many others concluded that the finest available resolution does not necessarily lead to better model performance arnone et al 2016b fuchs et al 2014 since modelling a physical process such as landslides may depend on scales not detected with very high resolutions tarolli and tarboton 2006 penna et al 2014 at finer resolutions the local surface topography is less representative of the process governing the landslide initiation and hence impacts the average size of the landslides freer et al 2002 tarolli and tarboton 2006 the availability of very high resolutions dems up to 1 m yang et al 2014 noto et al 2017 francipane et al 2020 resulting from the use of lidar begs the question of their value in landslide mapping wang et al 2013 fuchs et al 2014 ciampalini et al 2016 fuchs et al 2014 found an improvement of 3 in determining slope instability by using 10 m resolution but they stated that such an improvement can have a small impact in applications where for example the soil terrain properties are poorly described and there is a lack of other data all studies mentioned so far make use of hydrological landslide models that are grid based i e they require a grid dem to describe topography another class of hydrological and geomorphologic models uses triangulated irregular networks tins e g child by tucker et al 1999 tribs by ivanov et al 2004 tribs erosion by francipane et al 2012 chm by marsh et al 2020 which make it possible to represent more efficiently the topography by increasing the number of nodes only where morphology is complex tin meshes can be built directly from measured elevation points but are more commonly derived from readily available grid dems although the quality of simulations directly depends on the tin mesh the quality of the tin discretization depends on the original dem this study evaluates the influence of the dem resolution on the slope stability analysis by using a distributed eco hydrological landslide model which uses tins derived from a dem to describe the topography most hydrological landslide models in the literature are grid based and not much is written about the dependence of tin based models on terrain resolution we use the tribs veggie landslide triangulated irregular network tin based real time integrated basin simulator vegetation generator for interactive evolution lepore et al 2013 which is capable of representing vegetation dynamics and rainfall triggered landslides while simulating soil moisture evolution on the hillslope the study addresses questions regarding the impact of the original dem resolution on the landslide modeling for given dem tin conversion algorithm some of the questions are how significant is the influence of the grid resolution on the estimation of slope distribution how do the resolution impact terrain driven hydrological processes such as lateral redistribution and then the landslide occurrence how does the use of coarse resolutions modify the amount of the predicted total failure area the study area is the mameyes basin which is located in the luquillo experimental forest puerto rico where numerous slope stability analyses have been carried out with the same model lepore et al 2013 dialynas et al 2016 arnone et al 2016b the impact of the original dem resolution on tribs veggie landslide output is studied using different resampled dems at 20 30 50 and 70 m resolution from the available 10 m dem to obtain the triangulated irregular network required by the model 2 methods 2 1 tribs veggie landslide model the tribs veggie landslide model lepore et al 2013 couples the eco hydrological model tribs veggie ivanov et al 2008 and the infinite slope analysis in order to compute the factor of safety fs of a slope as a response to the soil moisture dynamics the hydrological component of the model reproduces essential hydrologic processes over the complex topography of a river basin e g infiltration evapotranspiration interception lateral redistribution and soil moisture dynamics it considers spatial variability in precipitation fields and the land surface and computes the corresponding soil moisture dynamics the role of topography in lateral soil moisture redistribution is emphasized by taking into account the effects of heterogeneous and anisotropic soil topography is described by means of a multiple resolution approach based on a tin which offers a flexible computational structure that reduces the number of computational elements without a significant loss of information vivoni et al 2004 and hence increasing the computational performance of the model the vegetation module simulates the biophysical energy processes e g transpiration biophysical hydrologic processes e g vegetation dependent unsaturated soil moisture and biochemical processes e g photosynthesis and plant respiration in addition to the soil moisture in the unsaturated zone and water table dynamics the stability model accounts also for the soil water characteristic curve and the saturated shear strength parameters cohesion and friction angle to assess fs the implemented equation is the following eq 1 f s t c γ s z n s i n α t a n φ t a n α γ w ψ b γ s z n θ t θ r θ s θ r 1 1 λ t a n φ s i n α where fs t is the time dependent factor of safety hereinafter simply fs c is the effective soil cohesion γ s is the total unit weight of soil which varies with soil moisture γ w is the water unit weight z n is the soil depth along the normal direction to the slope α and φ are the slope and the soil friction angle respectively ψ b is the air entry bubbling pressure assumed negative λ is the pore size distribution index θ t is the time dependent volumetric water content hereinafter simply θ θ r and θ s are the residual and saturated soil moisture contents respectively ψ b and λ are the parameters of the brooks and corey formulation 1964 which relate hydraulic conductivity and soil water potential to soil moisture sivandran and bras 2012 under the condition in which soil is full of water down to the considered soil depth eq 1 reduces to the saturated conditions formulation arnone et al 2016a the final products of the module are dynamic maps of instability areas as well as dynamic fs depth profiles at selected areas which depend on soil moisture dynamics more information about the formulation used in the slope stability model can be found in lepore et al 2013 and arnone et al 2016b while for more details about tribs veggie the reader can refer to ivanov et al 2008 2 2 terrain analysis algorithms the most common methods to represent terrain data are dems and triangulated irregular networks which can be easily incorporated into geographical information systems gis and are increasingly used as data input for hydrological hydraulic and morphological models goodrich et al 1991 kumler 1994 mita et al 2001 tucker et al 2001 ivanov et al 2004a b tins are used since they make possible the representation of very complex topography in a very efficient way areas of uniform terrain can be represented with few triangular elements while complex areas can be represented with increased details by using more triangular elements goodrich et al 1991 tins are extraordinarily flexible and resilient in the representation of terrain in order to build an appropriate tin it is very important to decide how to pick the sample points from the original dataset and or how to triangulate them one of the most important and used triangulation methods is the delaunay triangulation dt watson and philip 1984 tsai 1993 it is the dual graph of the voronoi diagram also called thiessen polygons which subdivides the space into a set of convex polygons whose boundaries are the perpendicular bisectors between adjacent data points the dual relationship between dt and its voronoi diagram provides a direct solution to the nearest neighbor problem for a set of points in such a way that each triangle vertex is connected to its nearest neighbors the algorithm used in this work to convert a dem into a tin is the one implemented within the tin index analysis package vivoni et al 2004 tiap http vivoni asu edu tribs tinindex html which allows the user to obtain a hydrologically significant tin from a high resolution dem e g lidar suitable for models such as tribs veggie landslide the package can derive a tin from a dem by means of two different target methods the tin index method which is based on the idea of hydrologic similarity and the tin terrain or slope criteria method which is instead based on the topographic relevance of dem points in describing the terrain the terrain based approach uses a higher resolution for rugged terrain areas while flatter areas have a lower resolution for the sampling of dem points the package provides three different point selection methods proximal distance pd very important points vip and latticetin lt the lt sampling method lee 1991 is used here because it preserves the catchment slope distribution in a robust and more accurate manner than the others e g vivoni et al 2004 starting from a dem this method retains all those points that are required for maintaining a surface within a specified elevation tolerance that reflects the maximum allowable difference in elevation between the input grid and the surface created from the output tin the generation of an appropriate terrain model for hydrological purposes should ensure that the tin conforms to the watershed boundary and the watershed stream network the created tin mesh thus allows for flow and transport from a node to another along triangle edges using a finite difference approach hydrologic processes e g infiltration evaporation groundwater table elevation are computed on the voronoi polygon associated with each node slope is calculated based on the tin along each triangle edge a slope value is assigned to a voronoi polygon along the steepest of the spokes connected to the voronoi node the slope is used to define the drainage flow path originating from each computational node braun and sambridge 1997 tucker et al 1999 vivoni et al 2004 3 study case 3 1 basin description the mameyes basin is within the luquillo experimental forest lef in the northeast of the island of puerto rico usa it has an area of 16 7 km2 with an elevation ranging between 104 2 and 1046 m a s l fig 1 a about 30 of the basin has a slope greater than 25 deg fig 1a the basin is one of the wettest basins in puerto rico and is characterized by a high variability in rainfall and air temperature throughout the basin the mean annual precipitation map ranges between 3000 and 5000 mm high percentages of sandy loam and clay loam with lower percentages of clay and silty clay make up the soil of the basin the bedrock is located at a depth of about 8 m or deeper simon et al 1990 and does not affect the shallow slope failure mechanisms vegetation is mainly made of tabonuco forest dacryodes excelsa typically within 150 and 600 m of elevation colorado forest cyrilla racemiflora within 600 and 900 m of elevation and dwarf cloud forest above 900 m in addition the palm forest prestoea montana is usually present on steep and poorly drained sites the mameyes basin has been selected as a case study because the availability of data to implement tribs veggie and the large number of landslides which make the basin a good test case for the tribs veggie landslide as an example hurricane maria which hit puerto rico in september 2017 caused about 20 landslides across the basin fig 1a fig 1b shows images of three landslides that occurred along the pr 191 road and observed during a field trip in the rio mameyes basin in 2014 also shown is an old landslide with new vegetation more information about the study area can be found in lepore et al 2013 and arnone et al 2016b 3 2 input data and model parameters the tribs veggie landside model requires meteorological forcing soil distribution data and soil and ecological parameters the used meteorological data and model parameters are those already obtained and calibrated for the mameyes basin in previous studies by lepore et al 2013 and arnone et al 2016b specifically the meteorological data derive from the bisley tower located within the basin lat 18 31 long 65 74 352 m a s l which measures many of the needed input data with an hourly resolution wind speed and direction air temperature cloud cover relative humidity rainfall and incoming shortwave radiation we used the same rainfall forcing as in lepore et al 2013 corresponding to the period between january and november 2008 which includes an important event that occurred in april 2008 specifically we analyzed the results obtained over a time window of 48 h encompassing the event recorded between the 27 and 28 april 2008 with a peak rainfall intensity of about 100 mm h at t t p fig 2 the model operates continuously at the hourly scale as described in lepore et al 2013 soil data were extracted from the soil map retrieved from the usda forest service s international institute of tropical forestry of san juan additionally a calibration procedure of the main hydrological soil parameters was conducted by the authors based on soil moisture time series from may to november 2008 observed at three locations within an area close to the bisley tower values of main hydrologic and soil parameters are reported in table 1 which are constant across the five model configurations which will be introduced in the next section it is important to highlight that landslide model related parameters were not calibrated parameter a r is responsible of the lateral redistribution of soil moisture which has been reported to be significant in the mameyes basin harden and delmas scruggs 2003 a r which is defined as the ratio between saturated hydraulic conductivities in the directions parallel and normal to the slope k s partially controls the lateral subsurface flux transfer a r was varied from 1 to 300 table 1 values used are reported in the model setup section mechanical parameters i e effective soil cohesion c and friction angle φ are reported in table 1 sources lepore et al 2013 simon et al 1990 finally with regard to the topography data calibration of the parameters mentioned was done using the 30 m resolution dem available for the island of puerto rico to derive the tin network this study uses the now available 10 m resolution dem as the core data set for the resolution studies as described in the next section 3 3 model setup resampled dems at resolutions of 20 30 50 and 70 m were obtained from the 10 m dem by applying the nearest neighbor interpolation technique which does not alter any of the values of cells from the input grid and assigns the value of the cell centers on the input grid to the closest cell center on the output grid fig 3 first column indeed others have argued that limited to hydrological applications the nearest neighbor technique leads to the highest accuracy in dem resolution resampling takagi 1998 tan et al 2015 wu et al 2008 the five dems were then used to derive the corresponding hydrologically significant tins mentioned in section 2 2 specifically the combination of slope criteria and lt sampling method was used for each configuration the method retains a number of significant nodes corresponding to the tin to dem ratio ν in order to obtain a reasonable balance between a feasible computational cost and an efficient preservation of topographic characteristics therefore the percentage of retained points with such a choice is the one that guarantees the best hydrographic similarity specifically the aim is to preserve the catchment slope distribution as well as the hydrographic features as the dem resolution decreases the ratio ν required to preserve topographic attributes increases finally from the tin nodes the voronoi polygons are uniquely defined table 2 summarizes the characteristics for each configuration special attention is paid to the spatial distribution of the slope since the slope controls the hydrology and the soil stability and its estimation is affected by dem resolution chang and tsai 1991 claessens et al 2005 grohmann 2015 arnone et al 2016a for the sake of comparison grid based maps of slope are derived from each dem using the planar method of average maximum technique on a 3x3 kernel burrough 1998 implemented within arcmap of esri fig 3 illustrates the five dems first column and the voronoi polygons together with their spatial distributions of slope the figure shows that high resolutions capture more variability in dem elevation the grid based maps of slope second column highlight a considerable smoothing of slopes at lower resolutions e g 50 and 70 m especially in the central and south areas of the watershed where higher slopes orange to red cells are replaced in some cases by gentler slopes blue cells this smoothing is less evident on the voronoi based maps third column according to the voronoi contours it is noteworthy to observe that gentler slope areas of the watershed are represented by large voronoi elements blue polygons while in steeper areas topographic variability is better described by more and smaller voronoi elements orange red polygons the lost in accuracy in the description of topography may lead to a different watershed divide and a slightly smaller watershed area i e 50 and 70 m voronoi mesh however since the analyses will be mostly conducted at a basin scale this will not undermine the results table 3 lists some basic statistics i e minimum maximum mean median and standard deviation of the area and slope of voronoi polygons together with the slope of grid cells for the different resolutions it is observed that the voronoi based maps tend to provide higher maximum slope values this can be the result of the different algorithms used to calculate the slope with dems and voronoi meshes as discussed in section 3 3 and 2 2 respectively indeed the use of an average maximum technique in the grid based map tends to produce a smaller maximum gradient because of smoothing with regard to the voronoi mesh derived from the 70 m dem a greater number and more regular voronoi polygons were created as compared to the 50 m voronoi mesh this is explained by the need to retain more points in order to preserve the elevation description ν ratio in table 2 finally we analyzed the results associated with the two extreme values of coefficient of anisotropy i e a r 1 and a r 300 lepore et al 2013 the selected coefficients of anisotropy are representative of two opposite situations i water lateral redistribution is limited and the wetting front propagates mainly through infiltration in the direction perpendicular to the terrain surface ii there is a strong lateral redistribution mainly driven by gravity 4 results slope stability in the model depends on terrain representation and simulated hydrological processes both dependent on resolution for given mechanical soil properties three variables influence the local failure depth of hypothetical plane of failure slope and soil moisture 4 1 significant lateral redistribution ar 300 case the relation among the above mentioned variables at failure conditions are shown in fig 4 for a r 300 for the five parent dem resolutions and at the time of the storm peak t t p which is representative of rapid changes in hydrological processes across soil depths the panels on the first column report the frequency distribution of the depths of the plane of failure across the basin second and third panels show the scatterplots between the depth of failure and the slope and between the depth of failure and the normalized soil moisture sm or effective saturation at failure respectively finally the panels on the fourth column show the relation between slope and sm elements characterized by different soil types are distinguished by different markers all the scatterplots in fig 4 delineate two clear clusters of points describing different conditions in one case failures occur when the soil is saturated such condition of failure is reached throughout the basin failure due to saturation occurs for all types of soil and mostly at shallow layers i e between 500 mm and 1000 mm as denoted by the frequency distribution of the depths of failure under saturation failures occur at moderate slopes i e within the range of 15 35 deg a second cluster is formed by those polygons that are characterized by a slope greater than 35 deg and fail mostly at depths greater than 1250 mm this only occurs over the sandy loam soil markers where a low degree of saturation is reached in unsaturated soil conditions the role of apparent cohesion due to soil matric suction i e third term of eq 1 can be significant lepore et al 2013 but in sandy loam there is a relatively compared to other fine soils small contribution of the apparent cohesion described by the low absolute value of the air entry bubbling pressure ψb see table 1 thus the elements in sandy loam result in a failure even at unsaturated conditions and at deep failure depths for the given geo mechanical properties as the resolution degrades from top 10 m to bottom 70 m panels the two clusters can still be clearly distinguished with less elements exhibiting slope failures as the resolution degrades and with fewer failing polygons having a very steep slope e g greater than 45deg especially in the 70 m dem derived mesh additionally in contrast to the finest resolutions which show failure surfaces at all depths the coarser resolutions are characterized by shallow failures across the all types of soils and deep layers mostly on the sandy loam soil at unsaturated conditions as previously explained polygons that reach saturation fail mostly at depths of 1000 mm or less the way depth slope and sm at failure are related to each other depends on the main topographical features i e local slope and drainage polygons area which influence the evolution of the hydrological processes and ultimately the slope instability therefore these relations are associated to the accuracy in the description of the topographical features which varies with the five dem derived meshes fig 3 showed that the tin generation algorithm creates an implicit mutual dependence between areas and slopes of voronoi polygons with larger polygons describing gentler slope zones and smaller polygons describing more complex morphologies and hydrological significant areas such as the river networks vivoni et al 2005 an overview of this dependency for the five dem derived meshes is given in fig 5 which shows the bivariate frequency distributions between area and slope of the voronoi polygons the distributions are assessed through the multivariate kernel density estimation mkde simonoff 1996 the red area the red the orange area and the sum of the red orange and yellow areas represents the 25 50 and 75 of the bivariate distribution mass respectively the distribution of the points corresponding to the voronoi polygons derived from the parent 10m dem clearly shows the presence of very steep elements 60 deg that are represented by very small polygons and of a few elements corresponding to very large polygons drawn for zones at moderate slope between nearly flat areas and 20 deg as it is possible to notice from the inset of fig 5a and 75 of generated polygons have an area ranging between 0 and 5000 m2 and a slope lower than 45 deg many of the very small and flat polygons describe the drainage network areas see fig 3 as the resolution of the parent dem decreases the probability mass spreads out towards larger voronoi polygons areas implying an increase in variability moreover the center of the bivariate distribution slightly moves towards higher values of areas and lower values of slope at the lowest resolution fig 5e the variability in voronoi polygons area decreases and slope values are smaller with the absence of values greater than 60 deg thus indicating a pronounced smoothing of the topography moreover it is noteworthy the alignment of some points on the same vertical straight lines fig 5e due to the regular shape of the resulting voronoi polygons see fig 3 as previously mentioned this result reflects the inability of tiap to generate from a too coarse dem a suitable irregular mesh that appropriately represents the topography of the basin the slope area dependence of voronoi polygons directly affects the spatial distribution of the modeled failures the steepest areas of the basin which are those most prone to fail are represented by very small polygons only in the fine resolutions the maps of the landslides at t t p and for a r 300 for the all meshes generated are shown in fig 6 the north western part of the basin is the area that exhibits greater occurrence of slope failures it can be observed that the amount of such failures i e black voronoi polygons gradually decreases as the resolution decreases additionally polygons that fail colored black are smaller in the 10 m resolution mesh the number position and dimension of failing polygons across different resolutions is related to the different slope area dependence depicted in fig 5 failures in the 10 m resolution mesh originate mainly from small voronoi elements associated to the highest slopes fig 5a whereas the failures at the lowest resolution are associated to fewer and larger polygons characterized by slope higher than 35 fig 5e mainly in sandy loam the resulting percentage of total area at failure is reported in fig 7 a specifically the inset histogram reports the percentage of total area at failure as a function of original dem size the main histogram depicts the relative total failure areas as a percent of the 10 m case here taken as reference the main histogram shows that there is a clear reduction in percentage of total failure area as the parent dem resolution is degraded the simulation carried out using the 10 m dem predicted that more than 7 of basin area is unstable the simulations based on 20 m and 30 m dems predicted about 6 of the basin as unstable around 80 of the 10 m dem results finally when 50 m and 70 m dem resolutions are used only about 3 of the basin area is classified as unstable 40 of the 10 m dem this means that adopting a 50 m or 70 m dem derived resolution mesh leads to an underestimation of failure area of about 60 with respect to the highest resolution 10 m considered as the more realistic scenario in terms of angle of failure fig 7b the median varies considerably across the resolutions within the range 28 40 deg whereas the variability is similar across all resolutions except for the coarsest resolution dem where it is somewhat smaller as previously mentioned besides the direct impact of slope on the triggering mechanisms of a landslide the slope and the accuracy in its representation also have an indirect influence given that some of the hydrological processes that influence the soil moisture pattern are gravity driven fig 4 illustrates a decrease in the occurrence of moderate depths of failure i e around 1250 mm as the resolutions degrades especially at the 70 m dem derived mesh in this case apart from the unstable areas characterized by a sandy loam soil type which mostly fail for morphological and geo mechanical reasons since the soil is unsaturated the rest of areas with slope greater than a certain value 15 deg become unstable because they reach saturation down to a certain critical depth specifically the gentler the slope the deeper the location of the depth of failure however in the case of coarser resolutions and particularly the 70 m parent dem very few elements fail because of saturation at depths greater than 1500 m fig 4 for the sake of process understanding fig 8 shows for all polygons the evolution of the soil moisture with depth for the coarsest 70 m and finest 10 m resolutions reporting the scatterplot of slope vs soil moisture across the two soil types i e clay loam and sandy loam where most of the failures occur fig 4 for t t p a r 300 and at three soil depths i e 500 mm fig 8a 1000 mm fig 8b and 2000 mm fig 8c at a depth of 500 mm fig 8a for the 70 m resolution red marks almost the entire basin is quasi saturated sm 0 9 whereas for the 10 m resolution black marks there is a greater number of voronoi polygons that are not as saturated sm 0 9 especially at the steepest areas slope 60 deg this condition explains why at this time failures occur mainly at shallow depths in the case of 70 m resolution see fig 4 moving from 500 mm fig 8a to 1000 mm fig 8b and to 2000 mm fig 8c it is possible to discern the movement of the front of infiltration in both resolutions indeed the cloud of points moves from saturation at the top of the soil column fig 8a to drier values at deeper soil horizons fig 8b and c where the front of infiltration has not yet reached especially in the 70 m resolution case in fact except for a single polygon there are no saturated areas steeper than 20 deg thus explaining the absence of failures due to saturation at depths deeper than 1250 mm see fig 4 analysis of the same plots not reported here right before and after t p confirmed such a movement of the moisture front in this case redistribution occurs and soil moisture spatial patterns are mainly controlled by topography 4 2 limited lateral redistribution ar 1 case when lateral redistribution of soil moisture is limited such as in the case of anisotropy ratio a r 1 the wetting front follows a considerably different path as widely discussed in lepore et al 2013 since the lateral exchanges are attenuated the front of infiltration is mainly along the direction perpendicular to the soil surface lepore et al 2013 indeed the above discussed scatterplots are significantly different for the case of a r 1 as shown in fig 9 for both the finest and coarsest resolutions and for the same two soil types of fig 8 specifically down to 500 mm fig 9a the basin is mostly saturated regardless the soil type and the slope except that for the very steep areas i e slope 60 deg at larger depths fig 9b and c it is possible to clearly distinguish the behavior of the two soil types which are characterized by different water retention properties see table 1 specifically at the depth of 1000 mm fig 9b sm depends on slope following a nearly monotonic relationship in this case the local slope controls the propagation of vertical fluxes downwards the soil column within a single voronoi element together with the hydraulic conductivity properties at the depth of 2000 mm sm mostly depends on soil type fig 9c likely because the wetting front has not yet reached these deeper horizons in this case the changes in the slope representation with different meshes have less impact on the spatial soil moisture dynamics this is likely because fluxes across contiguous polygons are minimized and the slope of a voronoi element may not directly control the moisture dynamics of neighboring cells fig 10 shows the results relative to the elements that fail for the finest 10 m and coarsest 70 m cases for t t p and a r 1 as for the a r 300 case two clusters of points can be distinguished i failures are triggered by the reaching the soil saturation and occur at very shallow horizons and moderate slopes this happens mainly in the clay loam soil and is more emphasized when the coarsest resolution is used ii failures mainly occur in areas with critical slope greater than 35 deg and a degree of saturation greater than 0 5 this situation occurs mainly in the sandy loam soil and is attenuated in the 70 m dem derived mesh because of its smoothed topography as discussed before with respect to the high anisotropy case the greatest percentage of landslides is very shallow and thus attributable to the soil that reaches the saturation in fact the elimination of lateral redistribution of moisture as previously discussed leads to locally higher soil moisture the percentage of total areas at failure and slope at failure for the case a r 1 is reported in fig 11 the results show a percentage of failure area ranging from 20 for the case based on the 10 m original resolution to 10 for the 70 m original resolution fig 11a the higher percentage of failure area as compared with a r 300 fig 7a demonstrates that for given morphological features and rainfall trigger the impacts of the hydrological processes in this case the lateral redistribution in reducing the soil saturation may be significant for the stability of the slope the choice of a r 1 reduces the sensitivity of the predicted area of failure across resolutions the use of 50 m and 70 m resolutions predicted 70 and 60 of the failure area of the 10 m case respectively versus 40 for the a r 300 case finally the median values of slope at failure together with their variability exhibits a slight decreasing trend as the resolution degrades fig 11b this trend reflects the smoothing effect of the coarser resolutions on slope as highlighted in figs 3 and 5 the differences observed between the two cases with a r 300 and a r 1 point out that when the lateral redistribution is limited i e a r 1 land slope is more important than the impacts of soil moisture hydrology on the land failure mechanisms 5 summary and discussion the effects of the original dem size on the slope stability modeling have been explored by analyzing variables and processes that directly i e slope and indirectly i e soil moisture dynamics are involved in triggering failures in contrast to other efforts a distributed eco hydrological landslide model based on an irregular mesh that is better suited to describe the topography was used a 10 m resolution dem available for the study area was resampled to the resolutions of 20 30 50 and 70 m in order to derive the corresponding hydrologically significant tins vivoni et al 2004 slope is a terrain attribute derived from the dem that directly influences the equilibrium of forces controlling the stability analysis the steeper the slope the greater are the forces that lead to the soil movement conversely for given geo mechanical properties of the soil areas can be unconditionally stable montgomery and dietrich 1994 arnone et al 2011 below a certain value of slope the comparison with the grid derived slope showed that the use of a triangulated mesh reduces the smoothing effect due to the use of coarse resolution grids chung and tsai 1991 zhang and montgomery 1994 claessens et al 2005 with meshes as coarse as 30 m in resolution the slope distribution is well preserved especially in the range of slope values most critical for landslide modeling i e slope greater than 25 deg a smoothing effect of the very steep slope values was observed only for the meshes derived from the 50 m and 70 m dem resolutions figs 3 and 5 the bivariate slope area distributions of voronoi polygons vary significantly among the five dem derived meshes fig 5 specifically as the resolution of the parent dem decreases the average area of the voronoi polygons increases while the average slope value decreases resulting in a smoothing effect of the topography because some of the modeled hydrological processes such as convergence of fluxes and lateral redistribution are directly controlled by the local slope and the convergence areas the variations in the bivariate slope area distribution fig 5 are closely connected to the observed changes in the simulated hydrological behavior the voronoi mesh derived from the 70 m resolution dem constitutes an exception in the slope area distribution with points aligned on the same vertical straight lines see fig 5 these are mainly due to the excessive number of retained points from the original dem that led to the creation of several similar voronoi polygons the result thus confirms the inability of generating from a too coarse dem a suitable irregular mesh able to coherently represent the basin morphology vivoni et al 2005 other than the shape of the watershed fig 3 the polygons slope area correlation arises only when irregular meshes are used and thus this type of analysis is missing in work that is grid based tarolli and tarboton 2006 claessens et al 2005 penna et al 2014 the combination of terrain description and simulated soil moisture dynamics determines the conditions of slope stability for each mesh resolution specifically we analyzed the dynamics at the time of the storm peak representative of a time when the evolution of the hydrological processes is fast the results can be summarized as follows the smoothing effect of resolution on the description of topography leads to a reduction of the number of unstable polygons fs 1 especially when a 70 m dem resolution is used failure due to saturation occurs at shallower layers as result of reaching saturation state rapidly regardless of the resolution as also found out by viet et al 2016 at the analyzed time of the simulation shallow depths of failure are more frequent in the coarse resolution cases and particularly failures at the intermediate depths 1250 mm are less frequent in the 70 m grid size dem compared to the 10 m case this is because the combination of soil wetness and slope does not lead to fs values below the critical threshold for example in some cases the smoothing effect of the topography in the coarse resolution may lead to a high degree of saturation within the shallow horizons that reach the critical failure conditions in other cases at equal condition of saturation the smoothing effect may reduce the local slope which then result to be not critical the conditionally stable areas i e those at intermediate slope 15 deg see fig 4 are the ones affected by the changes in the resolution fig 4 the spatial distribution of simulated landslide locations fs 1 highlights the commonality across resolutions of areas of the basin most prone to instabilities however the 10 m case results in more elements and larger areas at failure fig 6 the quantitative analyses of failures confirm the decreasing trend in areas of failure as the resolution of the parent dem decreases this is particularly significant with the coarsest resolutions i e 50 and 70 m as shown by the relative assessment fig 7 the results agree with most of the previous studies especially in highlighting that the changes are not necessarily linear with a loss of resolution and that some degradation of resolution may be an acceptable compromise between the loss of accuracy in terrain description and the goodness of results fuchs et al 2014 penna et al 2014 tarolli and tarboton 2006 dialynas 2017 all the mechanisms that relate grid size dem with the simulated hydrological processes e g mainly the sm lateral redistribution are strongly smoothed if the anisotropy ratio a r is equal to 1 since in this case this parameter limits the gravity driven process in the form of lateral exchanges lepore et al 2013 the front of infiltration mainly develops along the direction perpendicular to the soil surface fig 9 for the specific case analyzed in this study and for anisotropy ratio a r 1 the changes in the soil moisture pattern leads to more voronoi polygons resulting in a failure due to the higher degree of saturation of soil especially at shallow soil horizons in the case of a r of 1 the landsliding process is dominated by the nature of infiltration and development of soil moisture fronts in each voronoi polygon and hence less dependent on the impact of lower resolution on the smoothing of the topography 6 conclusions this study evaluated the hydro geomorphological influences of dem resolution on the slope stability analysis by using a distributed eco hydrological landslide model that uses a triangulated irregular network tin to describe the topography the model has been applied to the mameyes basin puerto rico where numerous landslide analyses have been carried out in the past lepore et al 2013 arnone et al 2016b the results demonstrated that the use of a tin based hydrological landslide model can reduce the loss of accuracy in the derived slope distribution for coarse resolutions significant changes in the prediction of areas in failure result only when a very coarse dem is used to derive the corresponding voroni mesh and when the lateral redistribution of water controlled by the anisotropy coefficient is considerable however if the computational costs of the finest dem resolution are prohibitive the use of a slightly coarser resolution may be a good compromise to still identify the zones highly susceptible to landslides future efforts can investigate how products of very high resolution e g 1 m could enhance the modeling of landslides in the luquillo experimental forest by focusing on landslide phenomena in the road cut slopes declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements and data availability map of soil is available from the soil survey of caribbean national forest and luquillo experimental forest commonwealth of puerto rico at the usda forest service website www nrcs usda gov all data and calibrated parameters can be obtained from dr e arnone elisa arnone uniud it the work of dr dialynas while at the georgia institute of technology and the collaboration with drs arnone and noto by dr bras research group has been supported by the national science foundation luquillo critical zone observatory award ear1331841 r l bras acknowledges the support of the k harrison brown family chair at georgia tech 
25826,this study employs a distributed eco hydrological landslide model the tribs veggie landslide to evaluate the influence of terrain resolution on the hydro geomorphological processes involved in slope stability analysis the model implements a triangulated irregular network tin to describe the topography starting from a grid dem five grid dem resolutions of the case study basin i e 10 20 30 and 70 m are used to derive the corresponding tins the results show that using irregular meshes reduces the loss of accuracy with coarser resolutions in the derived slope distribution in comparison to slope distributions estimated from the original grid based dem from a hydrological perspective the impact of resolution on soil moisture patterns and on slope stability is significant mostly when lateral water exchanges are allowed the degrading of resolution leads to a reduction of the predicted unstable areas with respect to the highest resolution case from about 15 20 m to more than 40 70 m keywords hydrologic modeling landslides numerical modeling digital elevation models slope stability analysis 1 introduction physically based modeling is one of the approaches used to assess the vulnerability of natural basins to hillslope instability induced by extreme or prolonged precipitation the increasing trend of weather related disasters hoeppe 2016 motivates the continuing interest in more reliable tools for prediction and analysis of precipitation induced landslide events one of the issues extensively discussed in landscape modeling is the use of the appropriate grid digital elevation model dem resolution specifically the question is whether adopting the finest available grid dem hereinafter simply dem resolution is a justified choice not only in terms of computational requirements but also in terms of effective improvement of the model capability in predicting determining the initiation of landslides cavazzi et al 2013 fuchs et al 2014 the dem is used to extract morphological secondary attributes such as slope aspect flow path upstream contributing area etc lack of accuracy in the primary attribute i e elevation would be propagated on the extracted morphological information wu et al 2007 vaze et al 2010 yang et al 2014 in landslide modeling the local slope angle is the variable which most influences the calculation of the terrain stability in both direct and indirect ways hydrological stability approaches are based on the integration of distributed hydrological models with the simple infinite slope model montgomery and dietrich 1994 iverson 2000 claessens et al 2005 rosso et al 2006 arnone et al 2011 lepore et al 2013 the landslide stability model computes the equilibrium of forces on a shallow soil prism gravity acts to initiate a slide as a function of the slope angle and the total wight of the soil including water friction resists sliding and it is affected by soil moisture the steeper the slope the greater the component favoring slide initiation direct effect catchment slope distribution also controls many of the hydrological terrain based processes such as the surface flow paths and the lateral redistribution of subsurface flows which ultimately determine the local soil moisture the duration of the transient regime after an event and thus the soil water pressures that impact the forces equilibrium although high resolution digital terrain data allows a more realistic representation of topography and consequently a better analysis of hillslope and valley morphology which are very important in the recognition of the topographic signature of valley incision by debris flows and landslides tarolli and dalla fontana 2009 a high resolution dem does not always imply a better performance in modelling the processes that lead to landslides several studies have explored how the grid cell size of the input topography data may influence rainfall induced landslides some studies focus on landslide susceptibility chang et al 1991 lee et al 2010 grohmann et al 2015 arnone et al 2016a cama et al 2016 and others explore the impact of resolution on results from physically based models zhang and montgomery 1994 tarolli and tarboton 2006 claessens et al 2005 de sy et al 2013 keijsers et al 2011 fuchs et al 2014 penna et al 2014 mahaigam and olsen 2015 viet et al 2016 most of the results of these studies agree that the coarser resolutions tend to smooth the terrain description i e local slope angle decreases thus reducing the number of unstable areas specifically keijsers et al 2011 used the lapsus ls claessens et al 2005 model and found that coarser resolutions reduced the ability to predict probability of failure at a particular location yet stable areas were predicted correctly however many others concluded that the finest available resolution does not necessarily lead to better model performance arnone et al 2016b fuchs et al 2014 since modelling a physical process such as landslides may depend on scales not detected with very high resolutions tarolli and tarboton 2006 penna et al 2014 at finer resolutions the local surface topography is less representative of the process governing the landslide initiation and hence impacts the average size of the landslides freer et al 2002 tarolli and tarboton 2006 the availability of very high resolutions dems up to 1 m yang et al 2014 noto et al 2017 francipane et al 2020 resulting from the use of lidar begs the question of their value in landslide mapping wang et al 2013 fuchs et al 2014 ciampalini et al 2016 fuchs et al 2014 found an improvement of 3 in determining slope instability by using 10 m resolution but they stated that such an improvement can have a small impact in applications where for example the soil terrain properties are poorly described and there is a lack of other data all studies mentioned so far make use of hydrological landslide models that are grid based i e they require a grid dem to describe topography another class of hydrological and geomorphologic models uses triangulated irregular networks tins e g child by tucker et al 1999 tribs by ivanov et al 2004 tribs erosion by francipane et al 2012 chm by marsh et al 2020 which make it possible to represent more efficiently the topography by increasing the number of nodes only where morphology is complex tin meshes can be built directly from measured elevation points but are more commonly derived from readily available grid dems although the quality of simulations directly depends on the tin mesh the quality of the tin discretization depends on the original dem this study evaluates the influence of the dem resolution on the slope stability analysis by using a distributed eco hydrological landslide model which uses tins derived from a dem to describe the topography most hydrological landslide models in the literature are grid based and not much is written about the dependence of tin based models on terrain resolution we use the tribs veggie landslide triangulated irregular network tin based real time integrated basin simulator vegetation generator for interactive evolution lepore et al 2013 which is capable of representing vegetation dynamics and rainfall triggered landslides while simulating soil moisture evolution on the hillslope the study addresses questions regarding the impact of the original dem resolution on the landslide modeling for given dem tin conversion algorithm some of the questions are how significant is the influence of the grid resolution on the estimation of slope distribution how do the resolution impact terrain driven hydrological processes such as lateral redistribution and then the landslide occurrence how does the use of coarse resolutions modify the amount of the predicted total failure area the study area is the mameyes basin which is located in the luquillo experimental forest puerto rico where numerous slope stability analyses have been carried out with the same model lepore et al 2013 dialynas et al 2016 arnone et al 2016b the impact of the original dem resolution on tribs veggie landslide output is studied using different resampled dems at 20 30 50 and 70 m resolution from the available 10 m dem to obtain the triangulated irregular network required by the model 2 methods 2 1 tribs veggie landslide model the tribs veggie landslide model lepore et al 2013 couples the eco hydrological model tribs veggie ivanov et al 2008 and the infinite slope analysis in order to compute the factor of safety fs of a slope as a response to the soil moisture dynamics the hydrological component of the model reproduces essential hydrologic processes over the complex topography of a river basin e g infiltration evapotranspiration interception lateral redistribution and soil moisture dynamics it considers spatial variability in precipitation fields and the land surface and computes the corresponding soil moisture dynamics the role of topography in lateral soil moisture redistribution is emphasized by taking into account the effects of heterogeneous and anisotropic soil topography is described by means of a multiple resolution approach based on a tin which offers a flexible computational structure that reduces the number of computational elements without a significant loss of information vivoni et al 2004 and hence increasing the computational performance of the model the vegetation module simulates the biophysical energy processes e g transpiration biophysical hydrologic processes e g vegetation dependent unsaturated soil moisture and biochemical processes e g photosynthesis and plant respiration in addition to the soil moisture in the unsaturated zone and water table dynamics the stability model accounts also for the soil water characteristic curve and the saturated shear strength parameters cohesion and friction angle to assess fs the implemented equation is the following eq 1 f s t c γ s z n s i n α t a n φ t a n α γ w ψ b γ s z n θ t θ r θ s θ r 1 1 λ t a n φ s i n α where fs t is the time dependent factor of safety hereinafter simply fs c is the effective soil cohesion γ s is the total unit weight of soil which varies with soil moisture γ w is the water unit weight z n is the soil depth along the normal direction to the slope α and φ are the slope and the soil friction angle respectively ψ b is the air entry bubbling pressure assumed negative λ is the pore size distribution index θ t is the time dependent volumetric water content hereinafter simply θ θ r and θ s are the residual and saturated soil moisture contents respectively ψ b and λ are the parameters of the brooks and corey formulation 1964 which relate hydraulic conductivity and soil water potential to soil moisture sivandran and bras 2012 under the condition in which soil is full of water down to the considered soil depth eq 1 reduces to the saturated conditions formulation arnone et al 2016a the final products of the module are dynamic maps of instability areas as well as dynamic fs depth profiles at selected areas which depend on soil moisture dynamics more information about the formulation used in the slope stability model can be found in lepore et al 2013 and arnone et al 2016b while for more details about tribs veggie the reader can refer to ivanov et al 2008 2 2 terrain analysis algorithms the most common methods to represent terrain data are dems and triangulated irregular networks which can be easily incorporated into geographical information systems gis and are increasingly used as data input for hydrological hydraulic and morphological models goodrich et al 1991 kumler 1994 mita et al 2001 tucker et al 2001 ivanov et al 2004a b tins are used since they make possible the representation of very complex topography in a very efficient way areas of uniform terrain can be represented with few triangular elements while complex areas can be represented with increased details by using more triangular elements goodrich et al 1991 tins are extraordinarily flexible and resilient in the representation of terrain in order to build an appropriate tin it is very important to decide how to pick the sample points from the original dataset and or how to triangulate them one of the most important and used triangulation methods is the delaunay triangulation dt watson and philip 1984 tsai 1993 it is the dual graph of the voronoi diagram also called thiessen polygons which subdivides the space into a set of convex polygons whose boundaries are the perpendicular bisectors between adjacent data points the dual relationship between dt and its voronoi diagram provides a direct solution to the nearest neighbor problem for a set of points in such a way that each triangle vertex is connected to its nearest neighbors the algorithm used in this work to convert a dem into a tin is the one implemented within the tin index analysis package vivoni et al 2004 tiap http vivoni asu edu tribs tinindex html which allows the user to obtain a hydrologically significant tin from a high resolution dem e g lidar suitable for models such as tribs veggie landslide the package can derive a tin from a dem by means of two different target methods the tin index method which is based on the idea of hydrologic similarity and the tin terrain or slope criteria method which is instead based on the topographic relevance of dem points in describing the terrain the terrain based approach uses a higher resolution for rugged terrain areas while flatter areas have a lower resolution for the sampling of dem points the package provides three different point selection methods proximal distance pd very important points vip and latticetin lt the lt sampling method lee 1991 is used here because it preserves the catchment slope distribution in a robust and more accurate manner than the others e g vivoni et al 2004 starting from a dem this method retains all those points that are required for maintaining a surface within a specified elevation tolerance that reflects the maximum allowable difference in elevation between the input grid and the surface created from the output tin the generation of an appropriate terrain model for hydrological purposes should ensure that the tin conforms to the watershed boundary and the watershed stream network the created tin mesh thus allows for flow and transport from a node to another along triangle edges using a finite difference approach hydrologic processes e g infiltration evaporation groundwater table elevation are computed on the voronoi polygon associated with each node slope is calculated based on the tin along each triangle edge a slope value is assigned to a voronoi polygon along the steepest of the spokes connected to the voronoi node the slope is used to define the drainage flow path originating from each computational node braun and sambridge 1997 tucker et al 1999 vivoni et al 2004 3 study case 3 1 basin description the mameyes basin is within the luquillo experimental forest lef in the northeast of the island of puerto rico usa it has an area of 16 7 km2 with an elevation ranging between 104 2 and 1046 m a s l fig 1 a about 30 of the basin has a slope greater than 25 deg fig 1a the basin is one of the wettest basins in puerto rico and is characterized by a high variability in rainfall and air temperature throughout the basin the mean annual precipitation map ranges between 3000 and 5000 mm high percentages of sandy loam and clay loam with lower percentages of clay and silty clay make up the soil of the basin the bedrock is located at a depth of about 8 m or deeper simon et al 1990 and does not affect the shallow slope failure mechanisms vegetation is mainly made of tabonuco forest dacryodes excelsa typically within 150 and 600 m of elevation colorado forest cyrilla racemiflora within 600 and 900 m of elevation and dwarf cloud forest above 900 m in addition the palm forest prestoea montana is usually present on steep and poorly drained sites the mameyes basin has been selected as a case study because the availability of data to implement tribs veggie and the large number of landslides which make the basin a good test case for the tribs veggie landslide as an example hurricane maria which hit puerto rico in september 2017 caused about 20 landslides across the basin fig 1a fig 1b shows images of three landslides that occurred along the pr 191 road and observed during a field trip in the rio mameyes basin in 2014 also shown is an old landslide with new vegetation more information about the study area can be found in lepore et al 2013 and arnone et al 2016b 3 2 input data and model parameters the tribs veggie landside model requires meteorological forcing soil distribution data and soil and ecological parameters the used meteorological data and model parameters are those already obtained and calibrated for the mameyes basin in previous studies by lepore et al 2013 and arnone et al 2016b specifically the meteorological data derive from the bisley tower located within the basin lat 18 31 long 65 74 352 m a s l which measures many of the needed input data with an hourly resolution wind speed and direction air temperature cloud cover relative humidity rainfall and incoming shortwave radiation we used the same rainfall forcing as in lepore et al 2013 corresponding to the period between january and november 2008 which includes an important event that occurred in april 2008 specifically we analyzed the results obtained over a time window of 48 h encompassing the event recorded between the 27 and 28 april 2008 with a peak rainfall intensity of about 100 mm h at t t p fig 2 the model operates continuously at the hourly scale as described in lepore et al 2013 soil data were extracted from the soil map retrieved from the usda forest service s international institute of tropical forestry of san juan additionally a calibration procedure of the main hydrological soil parameters was conducted by the authors based on soil moisture time series from may to november 2008 observed at three locations within an area close to the bisley tower values of main hydrologic and soil parameters are reported in table 1 which are constant across the five model configurations which will be introduced in the next section it is important to highlight that landslide model related parameters were not calibrated parameter a r is responsible of the lateral redistribution of soil moisture which has been reported to be significant in the mameyes basin harden and delmas scruggs 2003 a r which is defined as the ratio between saturated hydraulic conductivities in the directions parallel and normal to the slope k s partially controls the lateral subsurface flux transfer a r was varied from 1 to 300 table 1 values used are reported in the model setup section mechanical parameters i e effective soil cohesion c and friction angle φ are reported in table 1 sources lepore et al 2013 simon et al 1990 finally with regard to the topography data calibration of the parameters mentioned was done using the 30 m resolution dem available for the island of puerto rico to derive the tin network this study uses the now available 10 m resolution dem as the core data set for the resolution studies as described in the next section 3 3 model setup resampled dems at resolutions of 20 30 50 and 70 m were obtained from the 10 m dem by applying the nearest neighbor interpolation technique which does not alter any of the values of cells from the input grid and assigns the value of the cell centers on the input grid to the closest cell center on the output grid fig 3 first column indeed others have argued that limited to hydrological applications the nearest neighbor technique leads to the highest accuracy in dem resolution resampling takagi 1998 tan et al 2015 wu et al 2008 the five dems were then used to derive the corresponding hydrologically significant tins mentioned in section 2 2 specifically the combination of slope criteria and lt sampling method was used for each configuration the method retains a number of significant nodes corresponding to the tin to dem ratio ν in order to obtain a reasonable balance between a feasible computational cost and an efficient preservation of topographic characteristics therefore the percentage of retained points with such a choice is the one that guarantees the best hydrographic similarity specifically the aim is to preserve the catchment slope distribution as well as the hydrographic features as the dem resolution decreases the ratio ν required to preserve topographic attributes increases finally from the tin nodes the voronoi polygons are uniquely defined table 2 summarizes the characteristics for each configuration special attention is paid to the spatial distribution of the slope since the slope controls the hydrology and the soil stability and its estimation is affected by dem resolution chang and tsai 1991 claessens et al 2005 grohmann 2015 arnone et al 2016a for the sake of comparison grid based maps of slope are derived from each dem using the planar method of average maximum technique on a 3x3 kernel burrough 1998 implemented within arcmap of esri fig 3 illustrates the five dems first column and the voronoi polygons together with their spatial distributions of slope the figure shows that high resolutions capture more variability in dem elevation the grid based maps of slope second column highlight a considerable smoothing of slopes at lower resolutions e g 50 and 70 m especially in the central and south areas of the watershed where higher slopes orange to red cells are replaced in some cases by gentler slopes blue cells this smoothing is less evident on the voronoi based maps third column according to the voronoi contours it is noteworthy to observe that gentler slope areas of the watershed are represented by large voronoi elements blue polygons while in steeper areas topographic variability is better described by more and smaller voronoi elements orange red polygons the lost in accuracy in the description of topography may lead to a different watershed divide and a slightly smaller watershed area i e 50 and 70 m voronoi mesh however since the analyses will be mostly conducted at a basin scale this will not undermine the results table 3 lists some basic statistics i e minimum maximum mean median and standard deviation of the area and slope of voronoi polygons together with the slope of grid cells for the different resolutions it is observed that the voronoi based maps tend to provide higher maximum slope values this can be the result of the different algorithms used to calculate the slope with dems and voronoi meshes as discussed in section 3 3 and 2 2 respectively indeed the use of an average maximum technique in the grid based map tends to produce a smaller maximum gradient because of smoothing with regard to the voronoi mesh derived from the 70 m dem a greater number and more regular voronoi polygons were created as compared to the 50 m voronoi mesh this is explained by the need to retain more points in order to preserve the elevation description ν ratio in table 2 finally we analyzed the results associated with the two extreme values of coefficient of anisotropy i e a r 1 and a r 300 lepore et al 2013 the selected coefficients of anisotropy are representative of two opposite situations i water lateral redistribution is limited and the wetting front propagates mainly through infiltration in the direction perpendicular to the terrain surface ii there is a strong lateral redistribution mainly driven by gravity 4 results slope stability in the model depends on terrain representation and simulated hydrological processes both dependent on resolution for given mechanical soil properties three variables influence the local failure depth of hypothetical plane of failure slope and soil moisture 4 1 significant lateral redistribution ar 300 case the relation among the above mentioned variables at failure conditions are shown in fig 4 for a r 300 for the five parent dem resolutions and at the time of the storm peak t t p which is representative of rapid changes in hydrological processes across soil depths the panels on the first column report the frequency distribution of the depths of the plane of failure across the basin second and third panels show the scatterplots between the depth of failure and the slope and between the depth of failure and the normalized soil moisture sm or effective saturation at failure respectively finally the panels on the fourth column show the relation between slope and sm elements characterized by different soil types are distinguished by different markers all the scatterplots in fig 4 delineate two clear clusters of points describing different conditions in one case failures occur when the soil is saturated such condition of failure is reached throughout the basin failure due to saturation occurs for all types of soil and mostly at shallow layers i e between 500 mm and 1000 mm as denoted by the frequency distribution of the depths of failure under saturation failures occur at moderate slopes i e within the range of 15 35 deg a second cluster is formed by those polygons that are characterized by a slope greater than 35 deg and fail mostly at depths greater than 1250 mm this only occurs over the sandy loam soil markers where a low degree of saturation is reached in unsaturated soil conditions the role of apparent cohesion due to soil matric suction i e third term of eq 1 can be significant lepore et al 2013 but in sandy loam there is a relatively compared to other fine soils small contribution of the apparent cohesion described by the low absolute value of the air entry bubbling pressure ψb see table 1 thus the elements in sandy loam result in a failure even at unsaturated conditions and at deep failure depths for the given geo mechanical properties as the resolution degrades from top 10 m to bottom 70 m panels the two clusters can still be clearly distinguished with less elements exhibiting slope failures as the resolution degrades and with fewer failing polygons having a very steep slope e g greater than 45deg especially in the 70 m dem derived mesh additionally in contrast to the finest resolutions which show failure surfaces at all depths the coarser resolutions are characterized by shallow failures across the all types of soils and deep layers mostly on the sandy loam soil at unsaturated conditions as previously explained polygons that reach saturation fail mostly at depths of 1000 mm or less the way depth slope and sm at failure are related to each other depends on the main topographical features i e local slope and drainage polygons area which influence the evolution of the hydrological processes and ultimately the slope instability therefore these relations are associated to the accuracy in the description of the topographical features which varies with the five dem derived meshes fig 3 showed that the tin generation algorithm creates an implicit mutual dependence between areas and slopes of voronoi polygons with larger polygons describing gentler slope zones and smaller polygons describing more complex morphologies and hydrological significant areas such as the river networks vivoni et al 2005 an overview of this dependency for the five dem derived meshes is given in fig 5 which shows the bivariate frequency distributions between area and slope of the voronoi polygons the distributions are assessed through the multivariate kernel density estimation mkde simonoff 1996 the red area the red the orange area and the sum of the red orange and yellow areas represents the 25 50 and 75 of the bivariate distribution mass respectively the distribution of the points corresponding to the voronoi polygons derived from the parent 10m dem clearly shows the presence of very steep elements 60 deg that are represented by very small polygons and of a few elements corresponding to very large polygons drawn for zones at moderate slope between nearly flat areas and 20 deg as it is possible to notice from the inset of fig 5a and 75 of generated polygons have an area ranging between 0 and 5000 m2 and a slope lower than 45 deg many of the very small and flat polygons describe the drainage network areas see fig 3 as the resolution of the parent dem decreases the probability mass spreads out towards larger voronoi polygons areas implying an increase in variability moreover the center of the bivariate distribution slightly moves towards higher values of areas and lower values of slope at the lowest resolution fig 5e the variability in voronoi polygons area decreases and slope values are smaller with the absence of values greater than 60 deg thus indicating a pronounced smoothing of the topography moreover it is noteworthy the alignment of some points on the same vertical straight lines fig 5e due to the regular shape of the resulting voronoi polygons see fig 3 as previously mentioned this result reflects the inability of tiap to generate from a too coarse dem a suitable irregular mesh that appropriately represents the topography of the basin the slope area dependence of voronoi polygons directly affects the spatial distribution of the modeled failures the steepest areas of the basin which are those most prone to fail are represented by very small polygons only in the fine resolutions the maps of the landslides at t t p and for a r 300 for the all meshes generated are shown in fig 6 the north western part of the basin is the area that exhibits greater occurrence of slope failures it can be observed that the amount of such failures i e black voronoi polygons gradually decreases as the resolution decreases additionally polygons that fail colored black are smaller in the 10 m resolution mesh the number position and dimension of failing polygons across different resolutions is related to the different slope area dependence depicted in fig 5 failures in the 10 m resolution mesh originate mainly from small voronoi elements associated to the highest slopes fig 5a whereas the failures at the lowest resolution are associated to fewer and larger polygons characterized by slope higher than 35 fig 5e mainly in sandy loam the resulting percentage of total area at failure is reported in fig 7 a specifically the inset histogram reports the percentage of total area at failure as a function of original dem size the main histogram depicts the relative total failure areas as a percent of the 10 m case here taken as reference the main histogram shows that there is a clear reduction in percentage of total failure area as the parent dem resolution is degraded the simulation carried out using the 10 m dem predicted that more than 7 of basin area is unstable the simulations based on 20 m and 30 m dems predicted about 6 of the basin as unstable around 80 of the 10 m dem results finally when 50 m and 70 m dem resolutions are used only about 3 of the basin area is classified as unstable 40 of the 10 m dem this means that adopting a 50 m or 70 m dem derived resolution mesh leads to an underestimation of failure area of about 60 with respect to the highest resolution 10 m considered as the more realistic scenario in terms of angle of failure fig 7b the median varies considerably across the resolutions within the range 28 40 deg whereas the variability is similar across all resolutions except for the coarsest resolution dem where it is somewhat smaller as previously mentioned besides the direct impact of slope on the triggering mechanisms of a landslide the slope and the accuracy in its representation also have an indirect influence given that some of the hydrological processes that influence the soil moisture pattern are gravity driven fig 4 illustrates a decrease in the occurrence of moderate depths of failure i e around 1250 mm as the resolutions degrades especially at the 70 m dem derived mesh in this case apart from the unstable areas characterized by a sandy loam soil type which mostly fail for morphological and geo mechanical reasons since the soil is unsaturated the rest of areas with slope greater than a certain value 15 deg become unstable because they reach saturation down to a certain critical depth specifically the gentler the slope the deeper the location of the depth of failure however in the case of coarser resolutions and particularly the 70 m parent dem very few elements fail because of saturation at depths greater than 1500 m fig 4 for the sake of process understanding fig 8 shows for all polygons the evolution of the soil moisture with depth for the coarsest 70 m and finest 10 m resolutions reporting the scatterplot of slope vs soil moisture across the two soil types i e clay loam and sandy loam where most of the failures occur fig 4 for t t p a r 300 and at three soil depths i e 500 mm fig 8a 1000 mm fig 8b and 2000 mm fig 8c at a depth of 500 mm fig 8a for the 70 m resolution red marks almost the entire basin is quasi saturated sm 0 9 whereas for the 10 m resolution black marks there is a greater number of voronoi polygons that are not as saturated sm 0 9 especially at the steepest areas slope 60 deg this condition explains why at this time failures occur mainly at shallow depths in the case of 70 m resolution see fig 4 moving from 500 mm fig 8a to 1000 mm fig 8b and to 2000 mm fig 8c it is possible to discern the movement of the front of infiltration in both resolutions indeed the cloud of points moves from saturation at the top of the soil column fig 8a to drier values at deeper soil horizons fig 8b and c where the front of infiltration has not yet reached especially in the 70 m resolution case in fact except for a single polygon there are no saturated areas steeper than 20 deg thus explaining the absence of failures due to saturation at depths deeper than 1250 mm see fig 4 analysis of the same plots not reported here right before and after t p confirmed such a movement of the moisture front in this case redistribution occurs and soil moisture spatial patterns are mainly controlled by topography 4 2 limited lateral redistribution ar 1 case when lateral redistribution of soil moisture is limited such as in the case of anisotropy ratio a r 1 the wetting front follows a considerably different path as widely discussed in lepore et al 2013 since the lateral exchanges are attenuated the front of infiltration is mainly along the direction perpendicular to the soil surface lepore et al 2013 indeed the above discussed scatterplots are significantly different for the case of a r 1 as shown in fig 9 for both the finest and coarsest resolutions and for the same two soil types of fig 8 specifically down to 500 mm fig 9a the basin is mostly saturated regardless the soil type and the slope except that for the very steep areas i e slope 60 deg at larger depths fig 9b and c it is possible to clearly distinguish the behavior of the two soil types which are characterized by different water retention properties see table 1 specifically at the depth of 1000 mm fig 9b sm depends on slope following a nearly monotonic relationship in this case the local slope controls the propagation of vertical fluxes downwards the soil column within a single voronoi element together with the hydraulic conductivity properties at the depth of 2000 mm sm mostly depends on soil type fig 9c likely because the wetting front has not yet reached these deeper horizons in this case the changes in the slope representation with different meshes have less impact on the spatial soil moisture dynamics this is likely because fluxes across contiguous polygons are minimized and the slope of a voronoi element may not directly control the moisture dynamics of neighboring cells fig 10 shows the results relative to the elements that fail for the finest 10 m and coarsest 70 m cases for t t p and a r 1 as for the a r 300 case two clusters of points can be distinguished i failures are triggered by the reaching the soil saturation and occur at very shallow horizons and moderate slopes this happens mainly in the clay loam soil and is more emphasized when the coarsest resolution is used ii failures mainly occur in areas with critical slope greater than 35 deg and a degree of saturation greater than 0 5 this situation occurs mainly in the sandy loam soil and is attenuated in the 70 m dem derived mesh because of its smoothed topography as discussed before with respect to the high anisotropy case the greatest percentage of landslides is very shallow and thus attributable to the soil that reaches the saturation in fact the elimination of lateral redistribution of moisture as previously discussed leads to locally higher soil moisture the percentage of total areas at failure and slope at failure for the case a r 1 is reported in fig 11 the results show a percentage of failure area ranging from 20 for the case based on the 10 m original resolution to 10 for the 70 m original resolution fig 11a the higher percentage of failure area as compared with a r 300 fig 7a demonstrates that for given morphological features and rainfall trigger the impacts of the hydrological processes in this case the lateral redistribution in reducing the soil saturation may be significant for the stability of the slope the choice of a r 1 reduces the sensitivity of the predicted area of failure across resolutions the use of 50 m and 70 m resolutions predicted 70 and 60 of the failure area of the 10 m case respectively versus 40 for the a r 300 case finally the median values of slope at failure together with their variability exhibits a slight decreasing trend as the resolution degrades fig 11b this trend reflects the smoothing effect of the coarser resolutions on slope as highlighted in figs 3 and 5 the differences observed between the two cases with a r 300 and a r 1 point out that when the lateral redistribution is limited i e a r 1 land slope is more important than the impacts of soil moisture hydrology on the land failure mechanisms 5 summary and discussion the effects of the original dem size on the slope stability modeling have been explored by analyzing variables and processes that directly i e slope and indirectly i e soil moisture dynamics are involved in triggering failures in contrast to other efforts a distributed eco hydrological landslide model based on an irregular mesh that is better suited to describe the topography was used a 10 m resolution dem available for the study area was resampled to the resolutions of 20 30 50 and 70 m in order to derive the corresponding hydrologically significant tins vivoni et al 2004 slope is a terrain attribute derived from the dem that directly influences the equilibrium of forces controlling the stability analysis the steeper the slope the greater are the forces that lead to the soil movement conversely for given geo mechanical properties of the soil areas can be unconditionally stable montgomery and dietrich 1994 arnone et al 2011 below a certain value of slope the comparison with the grid derived slope showed that the use of a triangulated mesh reduces the smoothing effect due to the use of coarse resolution grids chung and tsai 1991 zhang and montgomery 1994 claessens et al 2005 with meshes as coarse as 30 m in resolution the slope distribution is well preserved especially in the range of slope values most critical for landslide modeling i e slope greater than 25 deg a smoothing effect of the very steep slope values was observed only for the meshes derived from the 50 m and 70 m dem resolutions figs 3 and 5 the bivariate slope area distributions of voronoi polygons vary significantly among the five dem derived meshes fig 5 specifically as the resolution of the parent dem decreases the average area of the voronoi polygons increases while the average slope value decreases resulting in a smoothing effect of the topography because some of the modeled hydrological processes such as convergence of fluxes and lateral redistribution are directly controlled by the local slope and the convergence areas the variations in the bivariate slope area distribution fig 5 are closely connected to the observed changes in the simulated hydrological behavior the voronoi mesh derived from the 70 m resolution dem constitutes an exception in the slope area distribution with points aligned on the same vertical straight lines see fig 5 these are mainly due to the excessive number of retained points from the original dem that led to the creation of several similar voronoi polygons the result thus confirms the inability of generating from a too coarse dem a suitable irregular mesh able to coherently represent the basin morphology vivoni et al 2005 other than the shape of the watershed fig 3 the polygons slope area correlation arises only when irregular meshes are used and thus this type of analysis is missing in work that is grid based tarolli and tarboton 2006 claessens et al 2005 penna et al 2014 the combination of terrain description and simulated soil moisture dynamics determines the conditions of slope stability for each mesh resolution specifically we analyzed the dynamics at the time of the storm peak representative of a time when the evolution of the hydrological processes is fast the results can be summarized as follows the smoothing effect of resolution on the description of topography leads to a reduction of the number of unstable polygons fs 1 especially when a 70 m dem resolution is used failure due to saturation occurs at shallower layers as result of reaching saturation state rapidly regardless of the resolution as also found out by viet et al 2016 at the analyzed time of the simulation shallow depths of failure are more frequent in the coarse resolution cases and particularly failures at the intermediate depths 1250 mm are less frequent in the 70 m grid size dem compared to the 10 m case this is because the combination of soil wetness and slope does not lead to fs values below the critical threshold for example in some cases the smoothing effect of the topography in the coarse resolution may lead to a high degree of saturation within the shallow horizons that reach the critical failure conditions in other cases at equal condition of saturation the smoothing effect may reduce the local slope which then result to be not critical the conditionally stable areas i e those at intermediate slope 15 deg see fig 4 are the ones affected by the changes in the resolution fig 4 the spatial distribution of simulated landslide locations fs 1 highlights the commonality across resolutions of areas of the basin most prone to instabilities however the 10 m case results in more elements and larger areas at failure fig 6 the quantitative analyses of failures confirm the decreasing trend in areas of failure as the resolution of the parent dem decreases this is particularly significant with the coarsest resolutions i e 50 and 70 m as shown by the relative assessment fig 7 the results agree with most of the previous studies especially in highlighting that the changes are not necessarily linear with a loss of resolution and that some degradation of resolution may be an acceptable compromise between the loss of accuracy in terrain description and the goodness of results fuchs et al 2014 penna et al 2014 tarolli and tarboton 2006 dialynas 2017 all the mechanisms that relate grid size dem with the simulated hydrological processes e g mainly the sm lateral redistribution are strongly smoothed if the anisotropy ratio a r is equal to 1 since in this case this parameter limits the gravity driven process in the form of lateral exchanges lepore et al 2013 the front of infiltration mainly develops along the direction perpendicular to the soil surface fig 9 for the specific case analyzed in this study and for anisotropy ratio a r 1 the changes in the soil moisture pattern leads to more voronoi polygons resulting in a failure due to the higher degree of saturation of soil especially at shallow soil horizons in the case of a r of 1 the landsliding process is dominated by the nature of infiltration and development of soil moisture fronts in each voronoi polygon and hence less dependent on the impact of lower resolution on the smoothing of the topography 6 conclusions this study evaluated the hydro geomorphological influences of dem resolution on the slope stability analysis by using a distributed eco hydrological landslide model that uses a triangulated irregular network tin to describe the topography the model has been applied to the mameyes basin puerto rico where numerous landslide analyses have been carried out in the past lepore et al 2013 arnone et al 2016b the results demonstrated that the use of a tin based hydrological landslide model can reduce the loss of accuracy in the derived slope distribution for coarse resolutions significant changes in the prediction of areas in failure result only when a very coarse dem is used to derive the corresponding voroni mesh and when the lateral redistribution of water controlled by the anisotropy coefficient is considerable however if the computational costs of the finest dem resolution are prohibitive the use of a slightly coarser resolution may be a good compromise to still identify the zones highly susceptible to landslides future efforts can investigate how products of very high resolution e g 1 m could enhance the modeling of landslides in the luquillo experimental forest by focusing on landslide phenomena in the road cut slopes declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements and data availability map of soil is available from the soil survey of caribbean national forest and luquillo experimental forest commonwealth of puerto rico at the usda forest service website www nrcs usda gov all data and calibrated parameters can be obtained from dr e arnone elisa arnone uniud it the work of dr dialynas while at the georgia institute of technology and the collaboration with drs arnone and noto by dr bras research group has been supported by the national science foundation luquillo critical zone observatory award ear1331841 r l bras acknowledges the support of the k harrison brown family chair at georgia tech 
25827,climate change adaptation f yes university climate change adaptation m yes consultant climate change adaptation f yes ngo climate change adaptation m yes ngo energy m no ngo land use f no table 2 list of pre defined concepts table 2 concept name description source c1 import of food amount and type of food that is imported in kenya workshop c2 regional collaboration on tci the degree of collaboration in east african boarder regions to share information workshop c3 policy implementation the degree in which policy is transformed in to tangible actions workshop c4 land use change in kenya subsequently land and water use identified as the focal issue the amount of land and water used workshop c5 knowledge management systems the degree of access to information platforms and international sharing of data information workshop c6 rapid population growth the degree of population growth in kenya workshop c7 access to tci relevant data the degree of access to data regarding transnational climate impacts workshop c8 importing energy the amount of energy imported workshop c9 climate finance the amount and access to climate finance workshop c10 urbanisation and cultural change the increase of rural to urban migration and decline of rural traditions knowledge workshop c11 national infrastructure infrastructure that is vulnerable to climate change especially flooding e g power dams roads workshop c12 new economic perspective circular economy businesses workshop c13 tourism in kenya wildlife migration extinction and the effect of tourism workshop c14 supply chain risk management an integrated and sustainable value chain of products workshop c15 insecurity and terrorism the decline of adaptive capacity due to the fear of terrorism workshop c16 healthcare access to healthcare and emerging terminal illnesses workshop c17 technology transfer research and development of technologies to reduce vulnerabilities workshop c18 extreme poverty proportion of people in extreme poverty workshop c19 shared natural resources water availability and the quality of water land workshop c20 income per capita see schweizer and o neill 2014 literature c21 quality of governance see schweizer and o neill 2014 literature c22 water scarcity see schweizer and o neill 2014 literature c23 proportion of population on coasts see schweizer and o neill 2014 literature c24 innovation capacity see schweizer and o neill 2014 literature c25 urbanization subsequently merged with c10 see schweizer and o neill 2014 literature c26 educational attainment see schweizer and o neill 2014 literature c27 agricultural productivity see schweizer and o neill 2014 literature table 3 ambiguity in relationships with a summarised matrix of up to 70 agreement aba 7 in which relationships between 15 concepts see table 2 and three drivers are displayed s indicates strong relationships m indicates medium strength relationships and w indicates weak relations o represents relationships that were not defined in the individual fcms yellow boxes indicate single stakeholder relationships dark shade positive and light shade negative table 3 table 4 overview of the verification step of the aba 10 fcm relationships are represented as concept concept table 4 relationship names combining individual fcms verification step fcm value c21 c4 quality of governance land and water use mentioned by six stakeholders 3 strong negative2 strong positive1 medium negative it is assumed that a good quality of governance strongly decreases the amount of land and water that is used and increases sustainable land and water use this is because it is expected that policies will guide kenyans to use less land and water or more sustainable land and water use 0 9 c6 c4 rapid population growth land and water use mentioned by nine stakeholders 5 strong positive3 medium positive1 neither positive nor negative it is assumed that a larger population will use more land and water primarily for food production as most kenyans rely on agriculture this was identified as a strong relationship rapid population growth is also presumed to result in more subdivision of land because family land will be split among the children these smaller allocations are in some cases not enough to provide for the family therefore people will look elsewhere for more land and or water 0 8 c19 c4 shared natural resources land and water use mentioned by five stakeholders 4 medium positive1 strong positive the quality of shared natural resources influences the amount of land and water that is or can be used low quality means less available land and water with sufficient quality to be used some transboundary rivers lakes dry up or drop their water table due to the presumed over exploitation of neighbouring regions another example is the water quality of lake victoria which results in forced changes of land and water use practices 0 6 c4 c19 land and water use shared natural resources mentioned by three stakeholders 1 medium negative1 medium positive1 strong negative the more land and water is used the less the state quality of shared natural resources will be this is because it is assumed that kenyans expand their agricultural or pastoral practices to transboundary areas an example is the forced migration of pastoral groups in the northern part of kenya resulting in more land and water use of shared natural resources such as water and grassland which is assumed to result in the degradation of these resources mainly due to overexploitation moreover deforestation for agricultural practices is a common practice in kenya which also influences the shared use of natural resources such as national parks bordering neighbouring regions the more sustainable land and water use is the higher the quality of the resource 0 4 c21 c19 quality of governance shared natural resources mentioned by two stakeholders1 medium positive1 weak positive it is assumed that government enforcement and legislation will increase the management of protected areas which can increase the quality of shared natural resources 0 3 c6 c19 rapid population growth shared natural resources mentioned by one stakeholder1 medium positive the stakeholder stated that with more people more resources will be used leading to the deterioration of natural resources 0 1 c19 c6 shared natural resources rapid population growth mentioned by one stakeholder1 strong positive the stakeholder stated that with a better state of shared natural resources more food can be produced and a better state of health will be reached which causes population growth 0 1 table 5 fuzzy cognitive model fcm properties of individual fcms averages median and sum abbreviations nd nc nr and d represent the number of drivers concepts relationships and density respectively table 5 fcm properties nd nc nr d fcm1 3 16 31 0 12 fcm2 6 10 23 0 23 fcm3 2 16 33 0 13 fcm4 5 15 33 0 15 fcm5 4 14 30 0 15 fcm6 1 11 27 0 22 fcm7 9 18 32 0 10 fcm8 2 8 12 0 19 fcm9 6 15 48 0 21 fcm10 4 15 32 0 14 average individual fcms 4 14 30 0 17 median individual fcms 4 15 32 0 15 common aggregation 0 26 176 0 26 aba 10 aggregation 2 4 5 0 31 aba 9 aggregation 2 8 19 0 30 aba 8 aggregation 2 11 33 0 27 aba 7 aggregation 3 15 45 0 22 table 6 fuzzy cognitive map fcm properties step 1 3 of the ambiguity based aggregation aba calibration abbreviations nd nc nr and d represent the number of drivers concepts relationships and density respectively table 6 agreement rank aba calibration step nd nc nr d aba 10 step 1 1 4 7 0 44 step 2 2 4 5 0 31 step 3 2 4 5 0 31 aba 9 step 1 1 8 28 0 44 step 2 2 8 19 0 30 step 3 2 8 19 0 30 aba 8 step 1 1 11 58 0 50 step 2 2 11 33 0 27 step 3 2 11 33 0 27 aba 7 step 1 0 15 94 0 42 step 2 0 15 49 0 22 step 3 3 15 45 0 22 box 1 matrix iterations in fcm box 1 formula ai ai 1 e in which ai is the new state vector after each iteration i a1 is the initial state vector for the iterations usually set based on the drivers and e represents the matrix of all relationships to use the example of figure 6 state vector a1 1 0 1 matrix e ai a1 e 1 0 1 1 1 5 1 the new state vector is 1 1 5 1 this process can be repeated until the fcm reaches a stable state ambiguity in social ecological system understanding advancing modelling of stakeholder perceptions of climate change adaptation in kenya charlotte esmeralda de jong a c kasper kok b a soil geography and landscape group wageningen university research p o gox 47 6700aa wageningen the netherlands soil geography and landscape group wageningen university research p o gox 47 wageningen 6700aa the netherlands 1 soil geography and landscape group wageningen university research p o box 47 6700aa wageningen the netherlands b environmental systems analysis broup wageningen university research p o box 47 6700aa wageningen the netherlands environmental systems analysis broup wageningen university research p o box 47 wageningen 6700aa the netherlands 2 environmental systems analysis group wageningen university research p o box 47 6700aa wageningen the netherlands c noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 9701 da groningen the netherlands noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 groningen 9701 da the netherlands noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 9701 da groningen the netherlands corresponding author climate change adaptation requires understanding of complex social ecological systems sess one source of uncertainty in complex sess is ambiguity defined as the range and variety of existing perceptions in and of an ses which are considered equally valid resulting in a lack of a unique or single system understanding current modelling practices that acknowledge the presence of ambiguity in sess focus on finding consensus with stakeholders however advanced methods for explicitly representing and aggregating ambiguity in sess are underdeveloped moreover understanding the influences of ambiguity on ses representation is limited this paper demonstrates the presence and range of ambiguities in endogenous and exogenous system drivers and internal relationships based on individual fuzzy cognitive maps derived from stakeholder perceptions of climate change adaptation in kenya and introduces an ambiguity based modelling process our results indicate that acknowledging ambiguity fundamentally changes ses representation and more advanced methods are required keywords ambiguity social ecological systems fuzzy cognitive maps climate change adaptation participatory modelling abbreviations aba ambiguity based aggregation 1 introduction referred to by popular media as the biggest threat facing humanity 1 1 https www nytimes com 2018 03 29 climate united nations climate change html future climate change is recognised as being hazardous for human and natural systems ipcc 2014 adapting to climate change is a complex issue because of the numerous interactions between the human and natural systems pahl wostl 2007 a leading concept in adaptive complex systems thinking is the notion of the social ecological system ses audouin et al 2013 berkes and folke 1998 biggs et al 2015 preise et al 2018 in a ses human and natural systems are inherently intertwined human systems include elements such as values decisions and perceptions and natural systems relate to biophysical elements including the ecological and hydrological cycles interactions are the result of any behaviour within or between the human and natural systems that reinforce or modify ses dynamics berkes and folke 1998 many different approaches methods and tools have been successfully applied to improve ses understanding e g binder et al 2013 levin et al 2013 liu et al 2007 ostrom 2009 often involving modelling aimed at predicting exploring communicating and learning brugnach and pahl wostl 2008 common modelling approaches include system dynamics models bayesian networks coupled component models agent based models and knowledge based models kelly et al 2013 recently eight major challenges for ses modelling were identified by elsawah et al 2020 including bridging epistemologies dealing with uncertainties and integrating the human dimension which form the broad focus of this research first the challenge of bridging epistemologies emerges because scientists disagree on how to represent a system due to fundamental paradigmatic differences between the social and environmental sciences second the challenge of dealing with uncertainties emerges because of the disagreement between what is considered structural uncertainty i e model context and model purpose and model uncertainty i e data and parameters third integrating the human dimension in ses models remains challenging due to a lack of understanding about specific social systems and disagreement on the approaches to generalise social behaviour such a lack of understanding is compounded by limited research funding in this area as well as privacy issues associated with the use of big data to study social behaviour patterns here we argue that these three challenges are connected by one common theme the presence of ambiguity within and about sess and the absence of mutually acceptable and replicable approaches to address ambiguity in current modelling practices ambiguity is a type of uncertainty caused by the presence of multiple knowledge frames both about and within sess where there is not a unique and complete understanding of the system to be managed brugnach et al 2008 multiple knowledge frames are considered equally valid and have an impact on for example how a problem is defined dewulf et al 2005 here we define ambiguity in sess as the range and variety of existing perceptions in and of an ses which are equally valid and which result in a lack of unique or single system understanding ambiguity in sess is currently addressed in models through participatory modelling pm which aims to generate multiple perceptions of ses system dynamics voinov et al 2016 for example some modelling approaches specifically seek to integrate the opinions and values of scientists and stakeholders tuler et al 2017 voinov and gaddis 2017 an advantage of pm is that it can facilitate understanding of the underlying beliefs and values of stakeholders about their environment paolisso and tombley 2017 with a broad aspiration to improve standardised reporting and reproducible methods gray et al 2018 therefore we regard participatory modelling as an important example of how ambiguity is currently recognised and at least partially accounted for in ses modelling group modelling workshops are a novel pm method for addressing ambiguity in which stakeholders are facilitated towards a common understanding of an ses e g diniz et al 2015 henriksen et al 2012 simon and etienne 2010 van der sluis et al 2019 an advantage of group modelling is that ambiguity is addressed by facilitating the decision space in a way that supports collaboration however it is questionable whether group modelling results in a common understanding because represented knowledge is dependent on group power dynamics gray et al 2014 turnhout et al 2020 alternative methods address this issue by collecting and aggregating individual perceptions of stakeholders into one model e g solana gutiérrez et al 2017 lavin et al 2018 mehryar et al 2019 while this approach increases the understanding of individual ses system dynamics gray et al 2014 when aggregated heterogeneity in stakeholder perceptions is lost mehryar et al 2019 occasionally studies have combined group modelling workshops and the collection of individual and or aggregated perceptions e g salliou et al 2017 if the goal of pm is to model how stakeholders perceive their ses it is crucial to explicitly address the diversity of perceptions and thereby inherent ambiguity most models derived using pm aim to develop a consensus system by aggregating perspectives assuming that each stakeholder has limited knowledge of the entire system therefore models that represent ambiguity are underdeveloped brugnach and ingram 2012 we argue that explicitly representing ambiguity fundamentally changes the way we understand and represent complex sess additionally increasing transparency in the ambiguity of models is necessary to advance the field of pm and complex ses representation identifying how one system can be modelled whilst also explicitly representing multiple knowledge frames i e ambiguity is therefore a key research challenge fuzzy cognitive maps fcms are commonly used for pm based group model building and or eliciting individual perspectives in environmental sciences fcms are used in a participatory setting to bridge the knowledge gap between stakeholders and scientists mallampalli et al 2016 van vliet 2010 qualitative and quantitative modelling kok 2009 van vliet et al 2017 and policy and practice solana guitiérrez et al 2017 moreover fcms are used to understand stakeholder perspectives on concepts driving relationships and feedback loops within a system diniz et al 2015 özesmi and özesmi 2004 current fcm practices concentrate on finding consensus by group modelling or aggregating individual fcms aggregation practices aim to find similarities in the internal fcm structure using for example mathematical simulations özesmi and özesmi 2004 whereas fcms that represent multiple perspectives could be more beneficial when diversity and ambiguity are openly considered van vliet et al 2010 aggregating individual fcms can aid the capture of complexity because individual fcms tend to contain few or no feedback loops levy et al 2018 however while particularly accounting for ambiguity advanced and mature fcm aggregation methods remain underdeveloped to address these limitations the main objectives of this study are to 1 explicitly represent ambiguity in complex sess using fcms 2 advance the aggregation process of fcms while explicitly representing ambiguity and 3 understand the influence of fcm aggregation on ses representation 2 background 2 1 ambiguity in sess ambiguity as a type of uncertainty described by brugnach et al 2008 can be approached using two broad strategies first a generalised correct representation can be sought using epistemic strategies or alternatively ambiguity is accepted as an inherent structural uncertainty that is addressed via ontological strategies through these approaches epistemic strategies involve the negotiation of a mutually acceptable frame and ontological strategies relate to working with different frames respectively both approaches assume that a unique system exists in practice the combination of these two approaches is used to simulate the heterogeneity of perceptions by for example splitting stakeholders into different actor groups mehryar et al 2019 ambiguity in sess can result from multiple system characteristics such as poorly defined system boundaries or multi scale interactions cash et al 2006 the treatment of system entities or structures kelly et al 2013 and the types of data employed elsawah et al 2020 in the case of the treatment of system entities or structures the entities of system dynamics encompass both endogenous drivers concepts and exogenous drivers drivers as well as their interrelationships ambiguity in concepts appears when decisions are made about whether or not a certain element is included in the system representation ambiguity in drivers appears when decisions are made about the driving capacity of specific elements and ambiguity in relationships appears when decision are made about the existence influence and direction of these relationships all of these system entities determine the representation and understanding of a system ambiguity is mainly addressed through the collection of data for multiple knowledge frames for example brugnach and ingram 2012 provide recommendations for dealing with ambiguity at the stakeholder facilitation stage including facilitating recognition of interdependencies building relationships and creating a decision space that supports collaboration therefore excellent facilitation and careful stakeholder interaction are crucial for addressing ambiguity additionally following bremer and meisch 2017 who performed a comprehensive literature study on participation or co production in climate change research eight lenses of participation that bridge two fundamental usages of participation first participation is seen as a method to reach a common normative goal second descriptive participation focusses on how science and society shape each other and how this influences both this framing does not however address methodologies aimed at processing multiple knowledge frames toward a posteriori models 2 2 fuzzy cognitive maps a fcm is a graphical presentation of a combination of endogenous drivers concepts of a system and exogenous drivers drivers kok 2009 kosko 1986 jetter and kok 2014 drivers are activated during each iteration step by the state vector and are usually pure drivers indicating concepts that do not have any incoming relationships from the system the visualisation of fcms takes the form of a fcm fig 1 left an adjacency matrix box 1 and a dynamic output fig 1 right as a result of the final state of concepts from the iterations the dynamic output can diverge converge be cyclic or be stable depending on the matrix only stable outputs are interpretable without a threshold or clipper function fcms usually have a focal issue concept around which the system is built jetter and kok 2014 the aggregation of individual fcms is frequently performed using matrix algebra e g singh 2011 solana gutiérrez et al 2017 mehryar et al 2019 in which numerical values are first assigned to the relationships of individual fcms and then combined by taking the average or median values this can be based on either individual relationships or groups of relationships see aminpour et al 2020 some alternative methods aggregate individual fcms using atlas ti coding to determine the value of relationships see rahimi et al 2018 usually all the aforementioned relationships are included in the final aggregated fcm averaging solves the problem of conflicting relationships when one stakeholder indicates a strong negative relationship and another has a weak positive relationship nevertheless this can result in an aggregated fcm with a majority of medium relationships as a result averaging can cause relationships to cancel each other out for instance 0 8 and 0 8 will be 0 which results in the appearance that there is no relationship ozesmi 2006 as such the logic and reasoning of individual fcms are lost and relationships derived from individual stakeholders i e single stakeholder relationships can have a large influence on the total system fcms are frequently analysed using fcm indices özesmi and özesmi 2018 özesmi and özesmi 2004 to explore individual concepts and relationships or the overall fcm one example is indegree which is used to determine the sum of weights of incoming relationships that influence a certain concept indices used to analyse overall fcms include the number of concepts and density which is a measure of complexity calculated as the actual number of relationships divided by the total maximum number of relationships in a fcm 2 3 project background the senses 2 2 http senses project org https climatescenarios org http www jpi climate eu era4cs http www jpi climate eu home project 2017 2020 was part of the european research area for climate services era4cs with partners from the netherlands germany sweden and austria the senses project aimed to make scenario information accessible to users in interactive transparent and comprehensible ways that help to convert scenario data into user specific scenario knowledge the overall project objective of senses was to develop a toolkit in which scenarios are communicated and tailored to specific user groups and stakeholders by integrating climate change scenario information participatory methods and visualisation tools the project incorporated regional case studies in the netherlands and kenya the kenyan case study focussed on integrating the indirect impacts of climate change so called transnational climate impacts tci hedlund et al 2018 into climate change adaptation scenarios for kenya in the global south in particular climate change can lead to increased vulnerability and the deterioration of natural resources as such kenya has been classified as a water scarce country falkenmark 1989 and prolonged droughts and extreme precipitation events have already led to severe impacts across society which will presumably aggravated by climate change in the future nccap2018 2022 therefore societal adaptation to climate change is urgently required the impacts of climate change span borders sectors and actors including agriculture water energy tourism wildlife and health and the national government civil society and youth nccap2018 2022 agriculture in kenya which is mostly rain fed is the largest contributor to the economy and is increasingly affected by water scarcity leading to economic losses nwmp 2013 therefore land and water use are strongly related the involvement of multiple actors and sectors with multiple knowledge frames and the fact that climate change can have severe impacts on land and water use suggests that climate change adaptation in kenya requires deeper ses understanding 3 stakeholder engagement and methodology 3 1 stakeholder engagement our stakeholder engagement adopted a mixed method approach consisting of the following three elements 1 performing a stakeholder analysis 2 determining fcm concepts and 3 eliciting individual fcms the stakeholder analysis was based on the grey literature fcm concepts were derived during a stakeholder workshop and individual fcms were elicited during the stakeholder interviews 3 1 1 stakeholder analysis the stakeholder analysis utilised an analytical categorisation top down and a stakeholder led categorisation bottom up of sectors and actors reed et al 2009 the analytical categorisation was based on national policy documents with the government of kenya proposing several stakeholder lists via their climate adaptation policy documents knap2015 2030 nccap2018 2022 in this context actors were defined as having an influence on climate change adaptation or being influenced by climate change adaptation furthermore the policy documents indicated several sectors involved in climate change adaptation nccap2018 2022 a stakeholder analysis by ngigi et al 2011 identified actors and sectors in kenya and ranked the formal influence of stakeholders on smallholder farmers here actors who have large to moderate influence i e non governmental organisations ngos and ministries and sectors that are primarily involved in climate change adaptation environment water and agriculture were selected 3 1 2 defining concepts in a stakeholder workshop we used the output of a stakeholder workshop brainstorming session to define a list of concepts for the fcms and the focal issues of the fcm the objective of the workshop as part of the overall kenyan case study was to create a skeleton or base for future scenarios as tools to explore future transnational climate impacts for kenya in the brainstorming session participants were invited to contribute ideas on the concepts of transnational climate impacts for kenya global challenges for adaptation from earlier research schweizer and o neill 2014 were posted on the wall of the workshop room for inspiration additionally the big four agenda from kenya vision2030 3 3 the big four agenda from the kenya vision 2030 includes the four main governmental focus points of 1 food security 2 affordable housing 3 manufacturing and 4 affordable healthcare for all was provided to highlight issues currently addressed by the national government the focus question of the brainstorm session was what are the most important drivers for understanding kenya s vulnerability to future transnational climate risks which was framed as challenges for climate change adaptation within and outside of kenya for the first round of brainstorming each participant presented two concept ideas which were written down on post it notes participants could then choose to present one or two additional ideas all individuals ideas were then presented to the group collected on the wall and grouped into named clusters by the senses facilitation team at the beginning of the next session the workshop lead facilitator verified that the participants agreed on the clusters the concepts were subsequently labelled to determine their importance and uncertainty each participant received five red voting stickers to indicate the uncertainty of a concept and five green voting stickers to indicate the importance of a concept this exercise began the development part of the workshop but it served to determine the focal issue of the fcm finally the concepts derived from the stakeholders and the concepts provided by schweizer and o neill 2014 were combined to generate a comprehensive list of concepts 3 1 3 eliciting fcms via interviews interviews were conducted to further explore stakeholder perspectives on relationships between the pre defined concepts derived from the workshop during the interviews individual fcms were created to connect the concepts which were printed out to enable the stakeholders to indicate those that were most relevant from their own personal perspective the purpose of the interview was explained to each participant and a fcm was shown to visualise the goal of the interview the participants were assured that no direct quotes would be used and permission was sought for the interview to be recorded for verification purposes subsequently following some introductory questions the stakeholders were invited to share their views on climate change effects in kenya to stimulate conceptual and relational thinking each stakeholder then constructed their individual fcm placing the focal issue in the centre concepts were then added to the map based on the following questions 1 which concepts have a direct relationship with the focal issue 2 which concepts are directly influenced by the focal issue this provided the first outline of the individual s fcm after which the following questions were used to systematically discuss positive and or negative relationships between each concept 3 do you think concept c1 influences concept c2 yes no if so why 4 if concept c1 increases then will concept c2 increase yes no if so why finally the stakeholders had the opportunity of adding concepts and defining the relative strength of their relationships based on the following questions 5 do you think that there are crucial concepts which are missing 6 if concept c1 increases how strongly does concept c2 increase if x doubles will z double too 7 in relative terms will the relationship a be stronger than relationship b yes no if so why 3 2 methodology the analysis methodology consisted of three elements organised around the three objectives first ambiguity was elucidated based on the individual fcms second a combined fcm was constructed using an ambiguity based aggregation aba process third the effects of the aba process on the fcm indices were determined and compared with the indices of the common aggregation method 3 2 1 elucidating ambiguity three important steps were considered to explicitly represent ambiguity using fcms the first step involved ranking the concepts the second step involved ranking the drivers and the third step involved summarising the individual matrices in step 1 the predefined concepts were ranked according to how often they were included in all of the individual fcms for example a rank score of 10 indicated agreement between 100 of the stakeholders a rank score of 9 indicated 90 agreement and so on this approach elucidated the ambiguity regarding the inclusion of concepts in the overall ses representation step 2 involved ranking the drivers of the individual fcms the agreement on the system drivers was tested by counting how often a concept was considered to be a driver defined as those concepts having no incoming relationships in the individual fcms the driver ranks were then coupled to the concept ranks so that each rank indicated the number of concepts and drivers i e rank 10 with x concepts and x drivers furthermore with the intention of limiting the number of drivers in the ses representation only those were used as concepts in more than 30 of the individual fcms were included this elucidated the ambiguity regarding the inclusion of drivers in the overall ses representation in step 3 the individual matrices representing the individual fcms were combined into one matrix the relationships in the matrix were summarised as indicated in the individual fcms i e strong medium and weak and positive and negative without quantifying the relationships this elucidated the ambiguity in the system relationships and summarised the perceptions of the presence strength direction and influence positive negative of the relationships in the overall ses representation 3 2 2 ambiguity based aggregation aba the aba process fig 2 was based on the notion of a core agreement where we aimed to include part of the fcm characteristics concepts and drivers that were found to have the largest degree of agreement accordingly the starting point of the aba were the concepts with the highest rank subsequently the corresponding drivers with the highest ranking were designated and all relationships between the concepts and drivers were then included the aba process adopted three common modelling procedures verification calibration and sensitivity analysis as presented by aral 2010 where verification is a demonstration that the modelling formalism is correct calibration is the adjustment of parameters of the mathematical model such that the model agreement is maximized with respect to the observation data we have on the modelled system and a sensitivity analysis is a simulation through which the modeler evaluates the response of the model to changes in input parameters or boundary condition of the model aral 2010 p 45 48 the three modelling procedures were modified to fit the requirements for fcm development the modified verification step aimed to interpret the relationships between the concepts according to the collective logic of the stakeholders and quantify them accordingly following la mere et al 2020 verification was performed by comparing the summarised matrix of the directly elicited individual fcms with the transcribed interviews first as described by jetter and kok 2014 the direction of the relationship i e positive or negative was determined second the relative strength strong medium or weak was determined and third the actual numerical integer was assigned strong relationships received a value between 0 9 and 0 7 medium relationships received a value between 0 6 and 0 4 and weak relationships received a value of 0 3 or 0 2 in each case the final relationship value depended on a relative comparison with other relationships according to interview question 7 see section 3 1 relationships identified by only one stakeholder receive a value of 0 1 thereby moderating the influence of single stakeholder relationships in the dynamic output of the overall system representation all of these verification steps and considerations were summarised in a table for the core system which provided an overview of the core assumptions of the total aba fcm the subsequent calibration step aimed to generate an interpretable stable dynamic fcm output for this we used microsoft excel to run 45 iterations and analyse the dynamic output by visualising a graph of the iteration and corresponding state values of the concepts single stakeholder relationships strongly influenced the dynamic output despite their low values therefore all single stakeholder relationships were removed additionally all relationships between the concepts and drivers were removed because of their disproportionate effect on the dynamic output these modifications generated a stable and calibrated dynamic fcm output a sensitivity analysis was then used to examine the behaviour of the system based on the one factor at a time with δ0 1 approach ten broeke et al 2016 this generated an understanding of the influence of the final relationship weights on the overall system next all the relationship values were set to medium relationships value of 0 5 and similarly the state vector was halved 0 5 to examine the influence of this boundary condition on the dynamic output using the calibrated output and behavioural understanding of the core fcm the concepts and drivers with the second highest ranks 9 were added aba 9 this process was then repeated until a desired aggregated system representation with a corresponding range of ambiguity was reached the repetition of the process can be modified regarding the objective of the fcm for example if the aim is to understand the core of an agreement repetition can be limited if the aim is to create a holistic view of stakeholder perceptions repetition can be maximized 3 2 3 comparing fcm indices fcm system representation can be analysed in several ways levy et al 2018 özesemi and özesemi 2004 özesemi and özesemi 2004 proposed a number of indices including the number of drivers nd number of concepts nc number of relationships nr and density d which is defined as nr nc 2 these fcm indices were calculated for the individual fcms as well as the aggregated fcm using standard aggregation methods see section 2 2 to understand how fcm indices were altered by the aggregation the average and median indices of the aggregated fcm were calculated and compared to the average and median values of the individual fcms finally to examine how the fcm indices were altered by the aba process they were calculated for the three calibration steps of each aba rank and compared with the individual and standard aggregated values 4 results 4 1 stakeholder engagement 4 1 1 stakeholder participation the stakeholder workshop facilitated by the swedish kenyan partners of the project was organised on the 10th of january 2019 in nairobi to ensure consistency between the interviewees and workshop participants stakeholders to be interviewed were first approached during the workshop the list of stakeholders was expanded by adding missing actors from the workshop and asking the participants for additional names a total of 11 stakeholders were interviewed in nairobi during ten one and a half hour interviews in january and february 2019 which provided ten individual fcms with a gender distribution of 55 female and 45 male a workshop interview consistency of 36 64 no yes and a mix of private and public actors within climate change affected sectors we were able to capture a representative sample of stakeholder perceptions table 1 4 1 2 list of concepts the workshop brainstorm session resulted in 19 concepts in which land and water use c4 was prioritised the concept list was completed with the addition of eight concepts listed by schweizer and o neill 2014 giving 27 concepts considered a challenge for climate change adaptation in kenya see table 2 4 1 3 individual fcms an example of an individual fcm is shown in fig 3 in general stakeholders found it difficult to define relatively stronger and weaker relationships and two stakeholders refused to do so some of the relationships were therefore only defined in terms of their direction 4 2 ambiguity in fcm concepts drivers and relationships considerable ambiguity was revealed in the fcm concepts drivers and relationships fig 4 of the 27 pre defined concepts all except c14 supply chain risk management were included in the individual fcms overall four concepts were mentioned by every stakeholder indicating that 15 of the fcm concepts were mutually agreed upon these four concepts were c4 land and water use identified as the focal issue c6 rapid population growth c19 shared natural resources and c21 quality of governance there was no mutual agreement among drivers however with a total of 19 identified as those concepts having no incoming relationships in the individual fcms the highest rank score was an agreement of 50 for drivers c6 and c21 based on a constraint of at least 30 agreement the following five drivers remained c6 rapid population growth c9 climate finance c11 national infrastructure c20 income per capita and c21 quality of governance two of the constrained drivers c6 and c21 correspond to the four concepts of mutual agreement ambiguity in the fcms was also strong in the identified concept relationships with no single relationship included in all cases however relationship between c6 rapid population growth and c4 land and water use was identified in 90 of the individual fcms the strength and influence positive negative of the relationships also varied and in some cases relationships were undefined by the stakeholders indicating uncertainty about their relative strengths table 3 displays the aba 7 matrix and its corresponding concepts drivers and relationships indicating a 70 agreement on the concepts a fully summarised matrix is provided in the supplementary materials 4 3 ambiguity based aggregated fcm for brevity here we show the verification step and the calibration step of the aba approach in detail which accurately demonstrate the overall process using the verification step of aba 10 and the calibration step of aba 7 the sensitivity analysis of the aba 7 fcm is also described for illustration aba 10 fig 5 included four concepts c4 c6 c19 and c21 of which two were drivers c6 and c21 between the concepts and drivers seven relationships were defined of which two were single stakeholder relationships and therefore has not yet been removed the verification step in which the relationships were quantified for aba 10 is shown in table 4 the differences in the strength and influence positive negative of the relationships occurred due to different interpretations of the concepts for instance as the focal issue c4 was interpreted as the amount of land and water use as well as sustainably managed land and water use moreover shared natural resources were interpreted as physical areas around the borders of kenya by some stakeholders while others implied the inclusion of all shared resources within kenya such as national parks using the aba 7 fcm matrix to illustrate the calibration steps 15 concepts were included of which three were drivers connected by 94 relationships starting with all relationships calibration step 1 the dynamic output was unstable fig 6 the end state of the concepts increased exponentially between 20 and 30 iterations as a next step calibration step 2 all single stakeholder relationships were removed from the matrix this produced very similar results with the same concepts showing positive and exponentially increasing values in calibration step 3 the additional removal of relationships on drivers led to a stable set of concept values fig 7 this shows that when calibrating a fcm removing influences on drivers is crucial as is common in dynamic fcm outputs the focal issue c4 is pushed to the highest end state the second highest end state was c10 urbanisation and cultural change followed by c27 agricultural productivity in addition one concept c18 extreme poverty was identified as having a strong negative value this indicates that the three drivers of rapid population growth income per capita and quality of governance c6 c20 and c21 increased the amount of land and water use enhanced urbanisation and cultural change increased agricultural productivity and reduced extreme poverty the fcm is sensitive to strong relationships the δ0 1 change making strong relationships stronger yields an explosive system that does not stabilise other value changes cause minor changes in the shape and end states of the concepts when weakening the relationships by 0 1 the ranked order of land and water use urbanisation and cultural change was altered but no other considerable end state shifts occur a reconstruction of the aba 7 fcm fig 8 shows a strong feedback loop between land and water use water scarcity agricultural productivity and back to land and water use as a driver rapid population growth enforces agricultural productivity and land and water use making this loop even stronger 4 4 influence of aggregation on fcm indices there was a wide range of drivers concepts and relationships in the individual fcms see table 5 the number of drivers ranged from one to nine the number of included concepts varied from eight to 18 and the number of relationships varied between 12 and 48 importantly the index values of the common aggregation method differ from those of the individual fcms table 5 the common aggregation method produced a fcm without any drivers and with a considerably higher density value mainly because of the high number of relationships although outside of the scope of this paper it is worth noting that the dynamic behaviours of the aggregated fcms were consequently also very different similar to commonly used aggregation methods the aba method also influenced the fcm properties table 6 with highest the density values in each agreement rank with all relationships e g for aba 10 step 1 had the highest density and for aba 7 step 1 had the highest density importantly the density values of almost all the steps were higher than those obtained from the common aggregation method largely due to the low number of concepts and the relatively high number of relationships the two subsequent calibration steps significantly reduced the number of relationships and reintroduced drivers this indicates that the calibrated aba 7 included three drivers 15 concepts and 45 relationships corresponding to a density of 0 22 these properties are closer to the average and median properties of the individual fcms than the values obtained using the common aggregated method the calibration steps were therefore crucial for not only providing a stable dynamic fcm output but also to change the fcm properties based on tables 5 and 6 the properties of the common fcm aggregation method do not correspond with the properties of the individual fcms for example the disappearance of drivers and the high number of concepts and relationships are substantially different from individual perceptions in comparison after calibration the aba 7 properties correspond to the average and median fcm properties and provide a more similar aggregated model compared to stakeholder perceptions this indicates that an aba process can produce a stable output with fcm indices similar to individual fcms while at the same time elucidating and aggregating multiple perspectives 5 discussion and conclusions given that fcms display a substantial amount of ambiguity our aba approach provides transparent steps for aggregating multiple fcms the fcm aggregation method applied substantially influences fcm indices and therefore ses representation nevertheless explicitly representing ambiguity in complex sess using fcms while advancing the aggregation process and understanding its influence on ses representation does not come without some shortcomings which we discuss in the following section in context of our original objectives 5 1 explicitly represent ambiguity in complex sess with fcms grey et al 2014 discussed multiple options for collecting data to build a fcm in this study we focussed on consensus building and scope setting by framing fcm concepts during a stakeholder workshop this provided predefined concepts that served as inputs for the subsequent interviews the main advantages of using predefined concepts for fcm co production include 1 a collaborative understanding of concepts 2 achieving a focussed discussion on relationships instead of concepts during interviews 3 increased comparability of individual fcms and 4 minimised time requirements of individual stakeholders thus limiting stakeholder fatigue however stakeholders re interpreted the identified concepts differently resulting in partially conflicting interpretations as described by jetter and kok 2014 differences in the meaning of concepts are common even after a plenary participatory discussion limiting conflicting interpretations of concepts could be facilitated during the interviews by briefly explaining the concepts before discussing the relationships between them for example although this brings the focus back on the concepts and limits stakeholders freedom of thought as every fcm displays an individual narrative of logic between concepts we aimed to record this narrative rather than forcing one meaning upon them prior to the interview as this might lead to stakeholders repeating what we told them rather than voicing their own opinions in our view this ex ante validation limits stakeholder input when research is specifically aimed at comparing relationships in individual fcms an increased consensus view among stakeholders could increase comparability while explicitly representing ambiguity we quantified three types of ambiguity in the studied sess the first type concerns the presence of concepts the second the presence and driving capacity of concepts and the third the presence direction influence and strength of relationships between the concepts elucidating ambiguity in the first two types has been realised by assessing similarities and differences in individual fcms and demonstrates that multiple knowledge frames have a large range of ambiguities importantly there might be additional types of ambiguity and more exploration is needed to quantify other potential sources including the importance of concepts and relationships the probability of relationships the dynamics of the system and emerging properties nevertheless our research clearly demonstrates that the range of ambiguities in complex sess is already extensive furthermore it is evident that dealing with ambiguity is essential when attempting to understand sess in a participatory setting owing to its strong influence on the represented system 5 2 ambiguity based aggregation the aba process involves verification calibration and sensitivity analysis these three steps create a stable fcm with a coinciding range of ambiguities by adding concepts according to their agreement rank a fcm can be constructed with a transparent and flexible method that accounts for the degree of common understanding among all stakeholders a central matter in fcm aggregation remains the translation of the linguistic valuation of relationships strong weak to numerical integers as presented the most commonly used method for quantifying relationships is to calculate an average value this has the advantages of being straightforward reproducible and does not require value judgments from the researchers it also solves the problem of reproducing conflicting relationships when for example one stakeholder indicates a strong negative relationship and another stakeholder indicates a weak positive relationship nevertheless the resulting aggregated fcms are likely to have a majority of medium relationships that did not exist in the original individual fcms and furthermore relationship scores might cancel each other out özesmi 2006 therefore we argue that averaging should not be used because the advantages do not outweigh the disadvantages we adopted extra verification step therefore to quantify the relationships between concepts and drivers providing the possibility of incorporating logic and reasoning back into the aggregated fcm we strongly argue that such a verification step enhances fcm aggregation and this process should not be simplified by mathematical configurations if stakeholder perceptions and ambiguity in sess are to be fully understood although the proposed verification step still contains a subjective modelling choice this choice is transparent and structured which enhances reproducibility the calibration step yielded a stable fcm output in this study however this will not always be the case for example when an individual fcm contains a large number of relationships especially feedback loops and is highly complex the applied calibration method will not suffice however in practice fcms developed from individual pm activities do not typically have large density values therefore we hypothesise that the calibration steps proposed here will be useful for most fcms derived through pm while the proposed aba methodology provides a more systemic way to represent ambiguity an additional validation step would be advantageous as indicated by earlier research kok et al 2011 the validation of stakeholder perceptions is an iterative process here more practical reasons e g budget time etc prevented us from including a validation step therefore we do not claim that our methodology results in a correct representation of stakeholder perceptions but primarily serves as an example of a method to explicitly account for ambiguity offering an ontological approach for capturing the range of stakeholder ambiguities in aggregated models 5 3 influence of fcm aggregation on ses representation recognising and addressing ambiguity is essential as the manner by which we address it or not can fundamentally change the way we represent aggregated fcms often leads to fcms that have radically different properties to any of the individual fcms used to construct it this is demonstrated by the large differences in the fcm indices of the common aggregation and aba methods although sometimes the whole can be more than the sum of the parts this is not desirable in this instance in our work we provided all identified concepts as inputs thereby aiming for a description of the entire system from each stakeholder in this case it is desirable to maintain the properties that individual stakeholders attach to the system in the final product in more general terms we argue that it should always be an aim to maintain stakeholder views on system functioning to best represent the collective views of a stakeholder group fcm indices are typically used to identify the characteristics of a fcm in addition to those used in this study a range of additional properties have been suggested including centrality indegree outdegree complexity hierarchy number of transmitters and number of receivers grey et al 2014 özesmi and özesmi 2004 here we purposefully avoided using more complicated indices as these are highly correlated with the counting of concepts and relationships and illustrate the ambiguities in other aspects of ses characteristics other studies e g lavin et al 2018 have also used indices to determine whether individuals share a paradigm and categorise individual fcms into groups although an interesting approach there is no documented evidence that fcm properties are indicative of the logic of the underlying system we argue that fcm properties are useful for comparing fcms and matrices but they cannot be used to make conclusions about stakeholder understanding and reasoning in an ses 5 4 modelling with ambiguity our research focussed on identifying how a complex ses can be modelled with fcms while explicitly elucidating ambiguity we used a mix of ontological and epistemic strategies by first identifying a range of ambiguities followed by reconstructing one fcm in line with the participatory paradigm heron and reason 1997 it is assumed that reality is co created by an objective and subjective set of experiences however the aggregation stage of the research adopts a more positivist paradigm assuming that a consistent part of perceptions on which stakeholders agree exist and can be modelled modelling multiple perceptions remains a careful balancing act but can provide insights into similar stakeholder paradigms nevertheless a model is merely a tool to enable understanding of what is being modelled using a mixed paradigmatic approach as we did emphasises the diversity of multiple perspectives while providing one model a deep understanding of sess therefore requires new methods to structure and quantify the range of ambiguities from different perspectives the strength of individual pms might not lie in the model that is created but in the systematic understanding of the paradigms of the stakeholders involved if a model shares a paradigm with the user it may improve the uptake of the model in particular if pm is focussed on decision support identifying these paradigms can advance the understanding of how society and science shape each other more studies and elaborate methods are needed to understand what we model why we model it where we simplify a model and which choices are made during this process methods remain in their infancy but have already demonstrated the importance of ambiguity and therefore the importance of transparent and flexible methods to account for it funding this research was funded by the dutch partners of the senses project nwo grant number 438 17 810 the project runs from 2017 to 2020 the project senses is part of the european research area for climate services era4cs an era net initiated by jpi climate it is fully funded by bmbf de bmwfw at nwo nl formas se with co funding by the european union grant 690462 era4cs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the stockholm and africa office of sei for their workshop preparations and help in the stakeholder analysis we would also like to thank the senses project for partly funding this research special thanks to all workshop participants and stakeholders who were willing to draw their fcms during the follow up interviews appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105054 policy documents ipcc 2014 intergovernmental panel on climate change 2014 adaptation planning and implementation in climate change 2014 impacts adaptation and vulnerability part a global and sectoral aspects working group ii contribution to the ipcc fifth assessment report pp 869 898 cambridge cambridge university press https doi org 10 1017 cbo9781107415379 020 knap2015 2030 kenya national adaptation plan 2015 2030 government of kenya ministry of environment and natural resources 2016 nccap2018 2022 national climate change action plan 2018 2022 2018 draft for discussion version 3 10th june 2018 ministry of environment and forestry climate change directorate nwmp 2013 national water master plan 2030 government of kenya ministry of environment water and natural resources water resources management authority 2013 internet the biggest threat facing humanity new york times 2018 rechecked on 17 8 2020 from https www nytimes com 2018 03 29 climate united nations climate change html ngigi et al 2011 marther ngigi barrack okoba noora aberman and regina birner 2011 a stakeholder map for climate change adaptation in kenya s agricultural sector retrieved on 23 01 2019 from http womenandclimate ifpri info files 2012 02 kenya net map final pdf 
25827,climate change adaptation f yes university climate change adaptation m yes consultant climate change adaptation f yes ngo climate change adaptation m yes ngo energy m no ngo land use f no table 2 list of pre defined concepts table 2 concept name description source c1 import of food amount and type of food that is imported in kenya workshop c2 regional collaboration on tci the degree of collaboration in east african boarder regions to share information workshop c3 policy implementation the degree in which policy is transformed in to tangible actions workshop c4 land use change in kenya subsequently land and water use identified as the focal issue the amount of land and water used workshop c5 knowledge management systems the degree of access to information platforms and international sharing of data information workshop c6 rapid population growth the degree of population growth in kenya workshop c7 access to tci relevant data the degree of access to data regarding transnational climate impacts workshop c8 importing energy the amount of energy imported workshop c9 climate finance the amount and access to climate finance workshop c10 urbanisation and cultural change the increase of rural to urban migration and decline of rural traditions knowledge workshop c11 national infrastructure infrastructure that is vulnerable to climate change especially flooding e g power dams roads workshop c12 new economic perspective circular economy businesses workshop c13 tourism in kenya wildlife migration extinction and the effect of tourism workshop c14 supply chain risk management an integrated and sustainable value chain of products workshop c15 insecurity and terrorism the decline of adaptive capacity due to the fear of terrorism workshop c16 healthcare access to healthcare and emerging terminal illnesses workshop c17 technology transfer research and development of technologies to reduce vulnerabilities workshop c18 extreme poverty proportion of people in extreme poverty workshop c19 shared natural resources water availability and the quality of water land workshop c20 income per capita see schweizer and o neill 2014 literature c21 quality of governance see schweizer and o neill 2014 literature c22 water scarcity see schweizer and o neill 2014 literature c23 proportion of population on coasts see schweizer and o neill 2014 literature c24 innovation capacity see schweizer and o neill 2014 literature c25 urbanization subsequently merged with c10 see schweizer and o neill 2014 literature c26 educational attainment see schweizer and o neill 2014 literature c27 agricultural productivity see schweizer and o neill 2014 literature table 3 ambiguity in relationships with a summarised matrix of up to 70 agreement aba 7 in which relationships between 15 concepts see table 2 and three drivers are displayed s indicates strong relationships m indicates medium strength relationships and w indicates weak relations o represents relationships that were not defined in the individual fcms yellow boxes indicate single stakeholder relationships dark shade positive and light shade negative table 3 table 4 overview of the verification step of the aba 10 fcm relationships are represented as concept concept table 4 relationship names combining individual fcms verification step fcm value c21 c4 quality of governance land and water use mentioned by six stakeholders 3 strong negative2 strong positive1 medium negative it is assumed that a good quality of governance strongly decreases the amount of land and water that is used and increases sustainable land and water use this is because it is expected that policies will guide kenyans to use less land and water or more sustainable land and water use 0 9 c6 c4 rapid population growth land and water use mentioned by nine stakeholders 5 strong positive3 medium positive1 neither positive nor negative it is assumed that a larger population will use more land and water primarily for food production as most kenyans rely on agriculture this was identified as a strong relationship rapid population growth is also presumed to result in more subdivision of land because family land will be split among the children these smaller allocations are in some cases not enough to provide for the family therefore people will look elsewhere for more land and or water 0 8 c19 c4 shared natural resources land and water use mentioned by five stakeholders 4 medium positive1 strong positive the quality of shared natural resources influences the amount of land and water that is or can be used low quality means less available land and water with sufficient quality to be used some transboundary rivers lakes dry up or drop their water table due to the presumed over exploitation of neighbouring regions another example is the water quality of lake victoria which results in forced changes of land and water use practices 0 6 c4 c19 land and water use shared natural resources mentioned by three stakeholders 1 medium negative1 medium positive1 strong negative the more land and water is used the less the state quality of shared natural resources will be this is because it is assumed that kenyans expand their agricultural or pastoral practices to transboundary areas an example is the forced migration of pastoral groups in the northern part of kenya resulting in more land and water use of shared natural resources such as water and grassland which is assumed to result in the degradation of these resources mainly due to overexploitation moreover deforestation for agricultural practices is a common practice in kenya which also influences the shared use of natural resources such as national parks bordering neighbouring regions the more sustainable land and water use is the higher the quality of the resource 0 4 c21 c19 quality of governance shared natural resources mentioned by two stakeholders1 medium positive1 weak positive it is assumed that government enforcement and legislation will increase the management of protected areas which can increase the quality of shared natural resources 0 3 c6 c19 rapid population growth shared natural resources mentioned by one stakeholder1 medium positive the stakeholder stated that with more people more resources will be used leading to the deterioration of natural resources 0 1 c19 c6 shared natural resources rapid population growth mentioned by one stakeholder1 strong positive the stakeholder stated that with a better state of shared natural resources more food can be produced and a better state of health will be reached which causes population growth 0 1 table 5 fuzzy cognitive model fcm properties of individual fcms averages median and sum abbreviations nd nc nr and d represent the number of drivers concepts relationships and density respectively table 5 fcm properties nd nc nr d fcm1 3 16 31 0 12 fcm2 6 10 23 0 23 fcm3 2 16 33 0 13 fcm4 5 15 33 0 15 fcm5 4 14 30 0 15 fcm6 1 11 27 0 22 fcm7 9 18 32 0 10 fcm8 2 8 12 0 19 fcm9 6 15 48 0 21 fcm10 4 15 32 0 14 average individual fcms 4 14 30 0 17 median individual fcms 4 15 32 0 15 common aggregation 0 26 176 0 26 aba 10 aggregation 2 4 5 0 31 aba 9 aggregation 2 8 19 0 30 aba 8 aggregation 2 11 33 0 27 aba 7 aggregation 3 15 45 0 22 table 6 fuzzy cognitive map fcm properties step 1 3 of the ambiguity based aggregation aba calibration abbreviations nd nc nr and d represent the number of drivers concepts relationships and density respectively table 6 agreement rank aba calibration step nd nc nr d aba 10 step 1 1 4 7 0 44 step 2 2 4 5 0 31 step 3 2 4 5 0 31 aba 9 step 1 1 8 28 0 44 step 2 2 8 19 0 30 step 3 2 8 19 0 30 aba 8 step 1 1 11 58 0 50 step 2 2 11 33 0 27 step 3 2 11 33 0 27 aba 7 step 1 0 15 94 0 42 step 2 0 15 49 0 22 step 3 3 15 45 0 22 box 1 matrix iterations in fcm box 1 formula ai ai 1 e in which ai is the new state vector after each iteration i a1 is the initial state vector for the iterations usually set based on the drivers and e represents the matrix of all relationships to use the example of figure 6 state vector a1 1 0 1 matrix e ai a1 e 1 0 1 1 1 5 1 the new state vector is 1 1 5 1 this process can be repeated until the fcm reaches a stable state ambiguity in social ecological system understanding advancing modelling of stakeholder perceptions of climate change adaptation in kenya charlotte esmeralda de jong a c kasper kok b a soil geography and landscape group wageningen university research p o gox 47 6700aa wageningen the netherlands soil geography and landscape group wageningen university research p o gox 47 wageningen 6700aa the netherlands 1 soil geography and landscape group wageningen university research p o box 47 6700aa wageningen the netherlands b environmental systems analysis broup wageningen university research p o box 47 6700aa wageningen the netherlands environmental systems analysis broup wageningen university research p o box 47 wageningen 6700aa the netherlands 2 environmental systems analysis group wageningen university research p o box 47 6700aa wageningen the netherlands c noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 9701 da groningen the netherlands noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 groningen 9701 da the netherlands noorderruimte institute of future environments hanze university of applied sciences zernikeplein 7 p o box 3037 9701 da groningen the netherlands corresponding author climate change adaptation requires understanding of complex social ecological systems sess one source of uncertainty in complex sess is ambiguity defined as the range and variety of existing perceptions in and of an ses which are considered equally valid resulting in a lack of a unique or single system understanding current modelling practices that acknowledge the presence of ambiguity in sess focus on finding consensus with stakeholders however advanced methods for explicitly representing and aggregating ambiguity in sess are underdeveloped moreover understanding the influences of ambiguity on ses representation is limited this paper demonstrates the presence and range of ambiguities in endogenous and exogenous system drivers and internal relationships based on individual fuzzy cognitive maps derived from stakeholder perceptions of climate change adaptation in kenya and introduces an ambiguity based modelling process our results indicate that acknowledging ambiguity fundamentally changes ses representation and more advanced methods are required keywords ambiguity social ecological systems fuzzy cognitive maps climate change adaptation participatory modelling abbreviations aba ambiguity based aggregation 1 introduction referred to by popular media as the biggest threat facing humanity 1 1 https www nytimes com 2018 03 29 climate united nations climate change html future climate change is recognised as being hazardous for human and natural systems ipcc 2014 adapting to climate change is a complex issue because of the numerous interactions between the human and natural systems pahl wostl 2007 a leading concept in adaptive complex systems thinking is the notion of the social ecological system ses audouin et al 2013 berkes and folke 1998 biggs et al 2015 preise et al 2018 in a ses human and natural systems are inherently intertwined human systems include elements such as values decisions and perceptions and natural systems relate to biophysical elements including the ecological and hydrological cycles interactions are the result of any behaviour within or between the human and natural systems that reinforce or modify ses dynamics berkes and folke 1998 many different approaches methods and tools have been successfully applied to improve ses understanding e g binder et al 2013 levin et al 2013 liu et al 2007 ostrom 2009 often involving modelling aimed at predicting exploring communicating and learning brugnach and pahl wostl 2008 common modelling approaches include system dynamics models bayesian networks coupled component models agent based models and knowledge based models kelly et al 2013 recently eight major challenges for ses modelling were identified by elsawah et al 2020 including bridging epistemologies dealing with uncertainties and integrating the human dimension which form the broad focus of this research first the challenge of bridging epistemologies emerges because scientists disagree on how to represent a system due to fundamental paradigmatic differences between the social and environmental sciences second the challenge of dealing with uncertainties emerges because of the disagreement between what is considered structural uncertainty i e model context and model purpose and model uncertainty i e data and parameters third integrating the human dimension in ses models remains challenging due to a lack of understanding about specific social systems and disagreement on the approaches to generalise social behaviour such a lack of understanding is compounded by limited research funding in this area as well as privacy issues associated with the use of big data to study social behaviour patterns here we argue that these three challenges are connected by one common theme the presence of ambiguity within and about sess and the absence of mutually acceptable and replicable approaches to address ambiguity in current modelling practices ambiguity is a type of uncertainty caused by the presence of multiple knowledge frames both about and within sess where there is not a unique and complete understanding of the system to be managed brugnach et al 2008 multiple knowledge frames are considered equally valid and have an impact on for example how a problem is defined dewulf et al 2005 here we define ambiguity in sess as the range and variety of existing perceptions in and of an ses which are equally valid and which result in a lack of unique or single system understanding ambiguity in sess is currently addressed in models through participatory modelling pm which aims to generate multiple perceptions of ses system dynamics voinov et al 2016 for example some modelling approaches specifically seek to integrate the opinions and values of scientists and stakeholders tuler et al 2017 voinov and gaddis 2017 an advantage of pm is that it can facilitate understanding of the underlying beliefs and values of stakeholders about their environment paolisso and tombley 2017 with a broad aspiration to improve standardised reporting and reproducible methods gray et al 2018 therefore we regard participatory modelling as an important example of how ambiguity is currently recognised and at least partially accounted for in ses modelling group modelling workshops are a novel pm method for addressing ambiguity in which stakeholders are facilitated towards a common understanding of an ses e g diniz et al 2015 henriksen et al 2012 simon and etienne 2010 van der sluis et al 2019 an advantage of group modelling is that ambiguity is addressed by facilitating the decision space in a way that supports collaboration however it is questionable whether group modelling results in a common understanding because represented knowledge is dependent on group power dynamics gray et al 2014 turnhout et al 2020 alternative methods address this issue by collecting and aggregating individual perceptions of stakeholders into one model e g solana gutiérrez et al 2017 lavin et al 2018 mehryar et al 2019 while this approach increases the understanding of individual ses system dynamics gray et al 2014 when aggregated heterogeneity in stakeholder perceptions is lost mehryar et al 2019 occasionally studies have combined group modelling workshops and the collection of individual and or aggregated perceptions e g salliou et al 2017 if the goal of pm is to model how stakeholders perceive their ses it is crucial to explicitly address the diversity of perceptions and thereby inherent ambiguity most models derived using pm aim to develop a consensus system by aggregating perspectives assuming that each stakeholder has limited knowledge of the entire system therefore models that represent ambiguity are underdeveloped brugnach and ingram 2012 we argue that explicitly representing ambiguity fundamentally changes the way we understand and represent complex sess additionally increasing transparency in the ambiguity of models is necessary to advance the field of pm and complex ses representation identifying how one system can be modelled whilst also explicitly representing multiple knowledge frames i e ambiguity is therefore a key research challenge fuzzy cognitive maps fcms are commonly used for pm based group model building and or eliciting individual perspectives in environmental sciences fcms are used in a participatory setting to bridge the knowledge gap between stakeholders and scientists mallampalli et al 2016 van vliet 2010 qualitative and quantitative modelling kok 2009 van vliet et al 2017 and policy and practice solana guitiérrez et al 2017 moreover fcms are used to understand stakeholder perspectives on concepts driving relationships and feedback loops within a system diniz et al 2015 özesmi and özesmi 2004 current fcm practices concentrate on finding consensus by group modelling or aggregating individual fcms aggregation practices aim to find similarities in the internal fcm structure using for example mathematical simulations özesmi and özesmi 2004 whereas fcms that represent multiple perspectives could be more beneficial when diversity and ambiguity are openly considered van vliet et al 2010 aggregating individual fcms can aid the capture of complexity because individual fcms tend to contain few or no feedback loops levy et al 2018 however while particularly accounting for ambiguity advanced and mature fcm aggregation methods remain underdeveloped to address these limitations the main objectives of this study are to 1 explicitly represent ambiguity in complex sess using fcms 2 advance the aggregation process of fcms while explicitly representing ambiguity and 3 understand the influence of fcm aggregation on ses representation 2 background 2 1 ambiguity in sess ambiguity as a type of uncertainty described by brugnach et al 2008 can be approached using two broad strategies first a generalised correct representation can be sought using epistemic strategies or alternatively ambiguity is accepted as an inherent structural uncertainty that is addressed via ontological strategies through these approaches epistemic strategies involve the negotiation of a mutually acceptable frame and ontological strategies relate to working with different frames respectively both approaches assume that a unique system exists in practice the combination of these two approaches is used to simulate the heterogeneity of perceptions by for example splitting stakeholders into different actor groups mehryar et al 2019 ambiguity in sess can result from multiple system characteristics such as poorly defined system boundaries or multi scale interactions cash et al 2006 the treatment of system entities or structures kelly et al 2013 and the types of data employed elsawah et al 2020 in the case of the treatment of system entities or structures the entities of system dynamics encompass both endogenous drivers concepts and exogenous drivers drivers as well as their interrelationships ambiguity in concepts appears when decisions are made about whether or not a certain element is included in the system representation ambiguity in drivers appears when decisions are made about the driving capacity of specific elements and ambiguity in relationships appears when decision are made about the existence influence and direction of these relationships all of these system entities determine the representation and understanding of a system ambiguity is mainly addressed through the collection of data for multiple knowledge frames for example brugnach and ingram 2012 provide recommendations for dealing with ambiguity at the stakeholder facilitation stage including facilitating recognition of interdependencies building relationships and creating a decision space that supports collaboration therefore excellent facilitation and careful stakeholder interaction are crucial for addressing ambiguity additionally following bremer and meisch 2017 who performed a comprehensive literature study on participation or co production in climate change research eight lenses of participation that bridge two fundamental usages of participation first participation is seen as a method to reach a common normative goal second descriptive participation focusses on how science and society shape each other and how this influences both this framing does not however address methodologies aimed at processing multiple knowledge frames toward a posteriori models 2 2 fuzzy cognitive maps a fcm is a graphical presentation of a combination of endogenous drivers concepts of a system and exogenous drivers drivers kok 2009 kosko 1986 jetter and kok 2014 drivers are activated during each iteration step by the state vector and are usually pure drivers indicating concepts that do not have any incoming relationships from the system the visualisation of fcms takes the form of a fcm fig 1 left an adjacency matrix box 1 and a dynamic output fig 1 right as a result of the final state of concepts from the iterations the dynamic output can diverge converge be cyclic or be stable depending on the matrix only stable outputs are interpretable without a threshold or clipper function fcms usually have a focal issue concept around which the system is built jetter and kok 2014 the aggregation of individual fcms is frequently performed using matrix algebra e g singh 2011 solana gutiérrez et al 2017 mehryar et al 2019 in which numerical values are first assigned to the relationships of individual fcms and then combined by taking the average or median values this can be based on either individual relationships or groups of relationships see aminpour et al 2020 some alternative methods aggregate individual fcms using atlas ti coding to determine the value of relationships see rahimi et al 2018 usually all the aforementioned relationships are included in the final aggregated fcm averaging solves the problem of conflicting relationships when one stakeholder indicates a strong negative relationship and another has a weak positive relationship nevertheless this can result in an aggregated fcm with a majority of medium relationships as a result averaging can cause relationships to cancel each other out for instance 0 8 and 0 8 will be 0 which results in the appearance that there is no relationship ozesmi 2006 as such the logic and reasoning of individual fcms are lost and relationships derived from individual stakeholders i e single stakeholder relationships can have a large influence on the total system fcms are frequently analysed using fcm indices özesmi and özesmi 2018 özesmi and özesmi 2004 to explore individual concepts and relationships or the overall fcm one example is indegree which is used to determine the sum of weights of incoming relationships that influence a certain concept indices used to analyse overall fcms include the number of concepts and density which is a measure of complexity calculated as the actual number of relationships divided by the total maximum number of relationships in a fcm 2 3 project background the senses 2 2 http senses project org https climatescenarios org http www jpi climate eu era4cs http www jpi climate eu home project 2017 2020 was part of the european research area for climate services era4cs with partners from the netherlands germany sweden and austria the senses project aimed to make scenario information accessible to users in interactive transparent and comprehensible ways that help to convert scenario data into user specific scenario knowledge the overall project objective of senses was to develop a toolkit in which scenarios are communicated and tailored to specific user groups and stakeholders by integrating climate change scenario information participatory methods and visualisation tools the project incorporated regional case studies in the netherlands and kenya the kenyan case study focussed on integrating the indirect impacts of climate change so called transnational climate impacts tci hedlund et al 2018 into climate change adaptation scenarios for kenya in the global south in particular climate change can lead to increased vulnerability and the deterioration of natural resources as such kenya has been classified as a water scarce country falkenmark 1989 and prolonged droughts and extreme precipitation events have already led to severe impacts across society which will presumably aggravated by climate change in the future nccap2018 2022 therefore societal adaptation to climate change is urgently required the impacts of climate change span borders sectors and actors including agriculture water energy tourism wildlife and health and the national government civil society and youth nccap2018 2022 agriculture in kenya which is mostly rain fed is the largest contributor to the economy and is increasingly affected by water scarcity leading to economic losses nwmp 2013 therefore land and water use are strongly related the involvement of multiple actors and sectors with multiple knowledge frames and the fact that climate change can have severe impacts on land and water use suggests that climate change adaptation in kenya requires deeper ses understanding 3 stakeholder engagement and methodology 3 1 stakeholder engagement our stakeholder engagement adopted a mixed method approach consisting of the following three elements 1 performing a stakeholder analysis 2 determining fcm concepts and 3 eliciting individual fcms the stakeholder analysis was based on the grey literature fcm concepts were derived during a stakeholder workshop and individual fcms were elicited during the stakeholder interviews 3 1 1 stakeholder analysis the stakeholder analysis utilised an analytical categorisation top down and a stakeholder led categorisation bottom up of sectors and actors reed et al 2009 the analytical categorisation was based on national policy documents with the government of kenya proposing several stakeholder lists via their climate adaptation policy documents knap2015 2030 nccap2018 2022 in this context actors were defined as having an influence on climate change adaptation or being influenced by climate change adaptation furthermore the policy documents indicated several sectors involved in climate change adaptation nccap2018 2022 a stakeholder analysis by ngigi et al 2011 identified actors and sectors in kenya and ranked the formal influence of stakeholders on smallholder farmers here actors who have large to moderate influence i e non governmental organisations ngos and ministries and sectors that are primarily involved in climate change adaptation environment water and agriculture were selected 3 1 2 defining concepts in a stakeholder workshop we used the output of a stakeholder workshop brainstorming session to define a list of concepts for the fcms and the focal issues of the fcm the objective of the workshop as part of the overall kenyan case study was to create a skeleton or base for future scenarios as tools to explore future transnational climate impacts for kenya in the brainstorming session participants were invited to contribute ideas on the concepts of transnational climate impacts for kenya global challenges for adaptation from earlier research schweizer and o neill 2014 were posted on the wall of the workshop room for inspiration additionally the big four agenda from kenya vision2030 3 3 the big four agenda from the kenya vision 2030 includes the four main governmental focus points of 1 food security 2 affordable housing 3 manufacturing and 4 affordable healthcare for all was provided to highlight issues currently addressed by the national government the focus question of the brainstorm session was what are the most important drivers for understanding kenya s vulnerability to future transnational climate risks which was framed as challenges for climate change adaptation within and outside of kenya for the first round of brainstorming each participant presented two concept ideas which were written down on post it notes participants could then choose to present one or two additional ideas all individuals ideas were then presented to the group collected on the wall and grouped into named clusters by the senses facilitation team at the beginning of the next session the workshop lead facilitator verified that the participants agreed on the clusters the concepts were subsequently labelled to determine their importance and uncertainty each participant received five red voting stickers to indicate the uncertainty of a concept and five green voting stickers to indicate the importance of a concept this exercise began the development part of the workshop but it served to determine the focal issue of the fcm finally the concepts derived from the stakeholders and the concepts provided by schweizer and o neill 2014 were combined to generate a comprehensive list of concepts 3 1 3 eliciting fcms via interviews interviews were conducted to further explore stakeholder perspectives on relationships between the pre defined concepts derived from the workshop during the interviews individual fcms were created to connect the concepts which were printed out to enable the stakeholders to indicate those that were most relevant from their own personal perspective the purpose of the interview was explained to each participant and a fcm was shown to visualise the goal of the interview the participants were assured that no direct quotes would be used and permission was sought for the interview to be recorded for verification purposes subsequently following some introductory questions the stakeholders were invited to share their views on climate change effects in kenya to stimulate conceptual and relational thinking each stakeholder then constructed their individual fcm placing the focal issue in the centre concepts were then added to the map based on the following questions 1 which concepts have a direct relationship with the focal issue 2 which concepts are directly influenced by the focal issue this provided the first outline of the individual s fcm after which the following questions were used to systematically discuss positive and or negative relationships between each concept 3 do you think concept c1 influences concept c2 yes no if so why 4 if concept c1 increases then will concept c2 increase yes no if so why finally the stakeholders had the opportunity of adding concepts and defining the relative strength of their relationships based on the following questions 5 do you think that there are crucial concepts which are missing 6 if concept c1 increases how strongly does concept c2 increase if x doubles will z double too 7 in relative terms will the relationship a be stronger than relationship b yes no if so why 3 2 methodology the analysis methodology consisted of three elements organised around the three objectives first ambiguity was elucidated based on the individual fcms second a combined fcm was constructed using an ambiguity based aggregation aba process third the effects of the aba process on the fcm indices were determined and compared with the indices of the common aggregation method 3 2 1 elucidating ambiguity three important steps were considered to explicitly represent ambiguity using fcms the first step involved ranking the concepts the second step involved ranking the drivers and the third step involved summarising the individual matrices in step 1 the predefined concepts were ranked according to how often they were included in all of the individual fcms for example a rank score of 10 indicated agreement between 100 of the stakeholders a rank score of 9 indicated 90 agreement and so on this approach elucidated the ambiguity regarding the inclusion of concepts in the overall ses representation step 2 involved ranking the drivers of the individual fcms the agreement on the system drivers was tested by counting how often a concept was considered to be a driver defined as those concepts having no incoming relationships in the individual fcms the driver ranks were then coupled to the concept ranks so that each rank indicated the number of concepts and drivers i e rank 10 with x concepts and x drivers furthermore with the intention of limiting the number of drivers in the ses representation only those were used as concepts in more than 30 of the individual fcms were included this elucidated the ambiguity regarding the inclusion of drivers in the overall ses representation in step 3 the individual matrices representing the individual fcms were combined into one matrix the relationships in the matrix were summarised as indicated in the individual fcms i e strong medium and weak and positive and negative without quantifying the relationships this elucidated the ambiguity in the system relationships and summarised the perceptions of the presence strength direction and influence positive negative of the relationships in the overall ses representation 3 2 2 ambiguity based aggregation aba the aba process fig 2 was based on the notion of a core agreement where we aimed to include part of the fcm characteristics concepts and drivers that were found to have the largest degree of agreement accordingly the starting point of the aba were the concepts with the highest rank subsequently the corresponding drivers with the highest ranking were designated and all relationships between the concepts and drivers were then included the aba process adopted three common modelling procedures verification calibration and sensitivity analysis as presented by aral 2010 where verification is a demonstration that the modelling formalism is correct calibration is the adjustment of parameters of the mathematical model such that the model agreement is maximized with respect to the observation data we have on the modelled system and a sensitivity analysis is a simulation through which the modeler evaluates the response of the model to changes in input parameters or boundary condition of the model aral 2010 p 45 48 the three modelling procedures were modified to fit the requirements for fcm development the modified verification step aimed to interpret the relationships between the concepts according to the collective logic of the stakeholders and quantify them accordingly following la mere et al 2020 verification was performed by comparing the summarised matrix of the directly elicited individual fcms with the transcribed interviews first as described by jetter and kok 2014 the direction of the relationship i e positive or negative was determined second the relative strength strong medium or weak was determined and third the actual numerical integer was assigned strong relationships received a value between 0 9 and 0 7 medium relationships received a value between 0 6 and 0 4 and weak relationships received a value of 0 3 or 0 2 in each case the final relationship value depended on a relative comparison with other relationships according to interview question 7 see section 3 1 relationships identified by only one stakeholder receive a value of 0 1 thereby moderating the influence of single stakeholder relationships in the dynamic output of the overall system representation all of these verification steps and considerations were summarised in a table for the core system which provided an overview of the core assumptions of the total aba fcm the subsequent calibration step aimed to generate an interpretable stable dynamic fcm output for this we used microsoft excel to run 45 iterations and analyse the dynamic output by visualising a graph of the iteration and corresponding state values of the concepts single stakeholder relationships strongly influenced the dynamic output despite their low values therefore all single stakeholder relationships were removed additionally all relationships between the concepts and drivers were removed because of their disproportionate effect on the dynamic output these modifications generated a stable and calibrated dynamic fcm output a sensitivity analysis was then used to examine the behaviour of the system based on the one factor at a time with δ0 1 approach ten broeke et al 2016 this generated an understanding of the influence of the final relationship weights on the overall system next all the relationship values were set to medium relationships value of 0 5 and similarly the state vector was halved 0 5 to examine the influence of this boundary condition on the dynamic output using the calibrated output and behavioural understanding of the core fcm the concepts and drivers with the second highest ranks 9 were added aba 9 this process was then repeated until a desired aggregated system representation with a corresponding range of ambiguity was reached the repetition of the process can be modified regarding the objective of the fcm for example if the aim is to understand the core of an agreement repetition can be limited if the aim is to create a holistic view of stakeholder perceptions repetition can be maximized 3 2 3 comparing fcm indices fcm system representation can be analysed in several ways levy et al 2018 özesemi and özesemi 2004 özesemi and özesemi 2004 proposed a number of indices including the number of drivers nd number of concepts nc number of relationships nr and density d which is defined as nr nc 2 these fcm indices were calculated for the individual fcms as well as the aggregated fcm using standard aggregation methods see section 2 2 to understand how fcm indices were altered by the aggregation the average and median indices of the aggregated fcm were calculated and compared to the average and median values of the individual fcms finally to examine how the fcm indices were altered by the aba process they were calculated for the three calibration steps of each aba rank and compared with the individual and standard aggregated values 4 results 4 1 stakeholder engagement 4 1 1 stakeholder participation the stakeholder workshop facilitated by the swedish kenyan partners of the project was organised on the 10th of january 2019 in nairobi to ensure consistency between the interviewees and workshop participants stakeholders to be interviewed were first approached during the workshop the list of stakeholders was expanded by adding missing actors from the workshop and asking the participants for additional names a total of 11 stakeholders were interviewed in nairobi during ten one and a half hour interviews in january and february 2019 which provided ten individual fcms with a gender distribution of 55 female and 45 male a workshop interview consistency of 36 64 no yes and a mix of private and public actors within climate change affected sectors we were able to capture a representative sample of stakeholder perceptions table 1 4 1 2 list of concepts the workshop brainstorm session resulted in 19 concepts in which land and water use c4 was prioritised the concept list was completed with the addition of eight concepts listed by schweizer and o neill 2014 giving 27 concepts considered a challenge for climate change adaptation in kenya see table 2 4 1 3 individual fcms an example of an individual fcm is shown in fig 3 in general stakeholders found it difficult to define relatively stronger and weaker relationships and two stakeholders refused to do so some of the relationships were therefore only defined in terms of their direction 4 2 ambiguity in fcm concepts drivers and relationships considerable ambiguity was revealed in the fcm concepts drivers and relationships fig 4 of the 27 pre defined concepts all except c14 supply chain risk management were included in the individual fcms overall four concepts were mentioned by every stakeholder indicating that 15 of the fcm concepts were mutually agreed upon these four concepts were c4 land and water use identified as the focal issue c6 rapid population growth c19 shared natural resources and c21 quality of governance there was no mutual agreement among drivers however with a total of 19 identified as those concepts having no incoming relationships in the individual fcms the highest rank score was an agreement of 50 for drivers c6 and c21 based on a constraint of at least 30 agreement the following five drivers remained c6 rapid population growth c9 climate finance c11 national infrastructure c20 income per capita and c21 quality of governance two of the constrained drivers c6 and c21 correspond to the four concepts of mutual agreement ambiguity in the fcms was also strong in the identified concept relationships with no single relationship included in all cases however relationship between c6 rapid population growth and c4 land and water use was identified in 90 of the individual fcms the strength and influence positive negative of the relationships also varied and in some cases relationships were undefined by the stakeholders indicating uncertainty about their relative strengths table 3 displays the aba 7 matrix and its corresponding concepts drivers and relationships indicating a 70 agreement on the concepts a fully summarised matrix is provided in the supplementary materials 4 3 ambiguity based aggregated fcm for brevity here we show the verification step and the calibration step of the aba approach in detail which accurately demonstrate the overall process using the verification step of aba 10 and the calibration step of aba 7 the sensitivity analysis of the aba 7 fcm is also described for illustration aba 10 fig 5 included four concepts c4 c6 c19 and c21 of which two were drivers c6 and c21 between the concepts and drivers seven relationships were defined of which two were single stakeholder relationships and therefore has not yet been removed the verification step in which the relationships were quantified for aba 10 is shown in table 4 the differences in the strength and influence positive negative of the relationships occurred due to different interpretations of the concepts for instance as the focal issue c4 was interpreted as the amount of land and water use as well as sustainably managed land and water use moreover shared natural resources were interpreted as physical areas around the borders of kenya by some stakeholders while others implied the inclusion of all shared resources within kenya such as national parks using the aba 7 fcm matrix to illustrate the calibration steps 15 concepts were included of which three were drivers connected by 94 relationships starting with all relationships calibration step 1 the dynamic output was unstable fig 6 the end state of the concepts increased exponentially between 20 and 30 iterations as a next step calibration step 2 all single stakeholder relationships were removed from the matrix this produced very similar results with the same concepts showing positive and exponentially increasing values in calibration step 3 the additional removal of relationships on drivers led to a stable set of concept values fig 7 this shows that when calibrating a fcm removing influences on drivers is crucial as is common in dynamic fcm outputs the focal issue c4 is pushed to the highest end state the second highest end state was c10 urbanisation and cultural change followed by c27 agricultural productivity in addition one concept c18 extreme poverty was identified as having a strong negative value this indicates that the three drivers of rapid population growth income per capita and quality of governance c6 c20 and c21 increased the amount of land and water use enhanced urbanisation and cultural change increased agricultural productivity and reduced extreme poverty the fcm is sensitive to strong relationships the δ0 1 change making strong relationships stronger yields an explosive system that does not stabilise other value changes cause minor changes in the shape and end states of the concepts when weakening the relationships by 0 1 the ranked order of land and water use urbanisation and cultural change was altered but no other considerable end state shifts occur a reconstruction of the aba 7 fcm fig 8 shows a strong feedback loop between land and water use water scarcity agricultural productivity and back to land and water use as a driver rapid population growth enforces agricultural productivity and land and water use making this loop even stronger 4 4 influence of aggregation on fcm indices there was a wide range of drivers concepts and relationships in the individual fcms see table 5 the number of drivers ranged from one to nine the number of included concepts varied from eight to 18 and the number of relationships varied between 12 and 48 importantly the index values of the common aggregation method differ from those of the individual fcms table 5 the common aggregation method produced a fcm without any drivers and with a considerably higher density value mainly because of the high number of relationships although outside of the scope of this paper it is worth noting that the dynamic behaviours of the aggregated fcms were consequently also very different similar to commonly used aggregation methods the aba method also influenced the fcm properties table 6 with highest the density values in each agreement rank with all relationships e g for aba 10 step 1 had the highest density and for aba 7 step 1 had the highest density importantly the density values of almost all the steps were higher than those obtained from the common aggregation method largely due to the low number of concepts and the relatively high number of relationships the two subsequent calibration steps significantly reduced the number of relationships and reintroduced drivers this indicates that the calibrated aba 7 included three drivers 15 concepts and 45 relationships corresponding to a density of 0 22 these properties are closer to the average and median properties of the individual fcms than the values obtained using the common aggregated method the calibration steps were therefore crucial for not only providing a stable dynamic fcm output but also to change the fcm properties based on tables 5 and 6 the properties of the common fcm aggregation method do not correspond with the properties of the individual fcms for example the disappearance of drivers and the high number of concepts and relationships are substantially different from individual perceptions in comparison after calibration the aba 7 properties correspond to the average and median fcm properties and provide a more similar aggregated model compared to stakeholder perceptions this indicates that an aba process can produce a stable output with fcm indices similar to individual fcms while at the same time elucidating and aggregating multiple perspectives 5 discussion and conclusions given that fcms display a substantial amount of ambiguity our aba approach provides transparent steps for aggregating multiple fcms the fcm aggregation method applied substantially influences fcm indices and therefore ses representation nevertheless explicitly representing ambiguity in complex sess using fcms while advancing the aggregation process and understanding its influence on ses representation does not come without some shortcomings which we discuss in the following section in context of our original objectives 5 1 explicitly represent ambiguity in complex sess with fcms grey et al 2014 discussed multiple options for collecting data to build a fcm in this study we focussed on consensus building and scope setting by framing fcm concepts during a stakeholder workshop this provided predefined concepts that served as inputs for the subsequent interviews the main advantages of using predefined concepts for fcm co production include 1 a collaborative understanding of concepts 2 achieving a focussed discussion on relationships instead of concepts during interviews 3 increased comparability of individual fcms and 4 minimised time requirements of individual stakeholders thus limiting stakeholder fatigue however stakeholders re interpreted the identified concepts differently resulting in partially conflicting interpretations as described by jetter and kok 2014 differences in the meaning of concepts are common even after a plenary participatory discussion limiting conflicting interpretations of concepts could be facilitated during the interviews by briefly explaining the concepts before discussing the relationships between them for example although this brings the focus back on the concepts and limits stakeholders freedom of thought as every fcm displays an individual narrative of logic between concepts we aimed to record this narrative rather than forcing one meaning upon them prior to the interview as this might lead to stakeholders repeating what we told them rather than voicing their own opinions in our view this ex ante validation limits stakeholder input when research is specifically aimed at comparing relationships in individual fcms an increased consensus view among stakeholders could increase comparability while explicitly representing ambiguity we quantified three types of ambiguity in the studied sess the first type concerns the presence of concepts the second the presence and driving capacity of concepts and the third the presence direction influence and strength of relationships between the concepts elucidating ambiguity in the first two types has been realised by assessing similarities and differences in individual fcms and demonstrates that multiple knowledge frames have a large range of ambiguities importantly there might be additional types of ambiguity and more exploration is needed to quantify other potential sources including the importance of concepts and relationships the probability of relationships the dynamics of the system and emerging properties nevertheless our research clearly demonstrates that the range of ambiguities in complex sess is already extensive furthermore it is evident that dealing with ambiguity is essential when attempting to understand sess in a participatory setting owing to its strong influence on the represented system 5 2 ambiguity based aggregation the aba process involves verification calibration and sensitivity analysis these three steps create a stable fcm with a coinciding range of ambiguities by adding concepts according to their agreement rank a fcm can be constructed with a transparent and flexible method that accounts for the degree of common understanding among all stakeholders a central matter in fcm aggregation remains the translation of the linguistic valuation of relationships strong weak to numerical integers as presented the most commonly used method for quantifying relationships is to calculate an average value this has the advantages of being straightforward reproducible and does not require value judgments from the researchers it also solves the problem of reproducing conflicting relationships when for example one stakeholder indicates a strong negative relationship and another stakeholder indicates a weak positive relationship nevertheless the resulting aggregated fcms are likely to have a majority of medium relationships that did not exist in the original individual fcms and furthermore relationship scores might cancel each other out özesmi 2006 therefore we argue that averaging should not be used because the advantages do not outweigh the disadvantages we adopted extra verification step therefore to quantify the relationships between concepts and drivers providing the possibility of incorporating logic and reasoning back into the aggregated fcm we strongly argue that such a verification step enhances fcm aggregation and this process should not be simplified by mathematical configurations if stakeholder perceptions and ambiguity in sess are to be fully understood although the proposed verification step still contains a subjective modelling choice this choice is transparent and structured which enhances reproducibility the calibration step yielded a stable fcm output in this study however this will not always be the case for example when an individual fcm contains a large number of relationships especially feedback loops and is highly complex the applied calibration method will not suffice however in practice fcms developed from individual pm activities do not typically have large density values therefore we hypothesise that the calibration steps proposed here will be useful for most fcms derived through pm while the proposed aba methodology provides a more systemic way to represent ambiguity an additional validation step would be advantageous as indicated by earlier research kok et al 2011 the validation of stakeholder perceptions is an iterative process here more practical reasons e g budget time etc prevented us from including a validation step therefore we do not claim that our methodology results in a correct representation of stakeholder perceptions but primarily serves as an example of a method to explicitly account for ambiguity offering an ontological approach for capturing the range of stakeholder ambiguities in aggregated models 5 3 influence of fcm aggregation on ses representation recognising and addressing ambiguity is essential as the manner by which we address it or not can fundamentally change the way we represent aggregated fcms often leads to fcms that have radically different properties to any of the individual fcms used to construct it this is demonstrated by the large differences in the fcm indices of the common aggregation and aba methods although sometimes the whole can be more than the sum of the parts this is not desirable in this instance in our work we provided all identified concepts as inputs thereby aiming for a description of the entire system from each stakeholder in this case it is desirable to maintain the properties that individual stakeholders attach to the system in the final product in more general terms we argue that it should always be an aim to maintain stakeholder views on system functioning to best represent the collective views of a stakeholder group fcm indices are typically used to identify the characteristics of a fcm in addition to those used in this study a range of additional properties have been suggested including centrality indegree outdegree complexity hierarchy number of transmitters and number of receivers grey et al 2014 özesmi and özesmi 2004 here we purposefully avoided using more complicated indices as these are highly correlated with the counting of concepts and relationships and illustrate the ambiguities in other aspects of ses characteristics other studies e g lavin et al 2018 have also used indices to determine whether individuals share a paradigm and categorise individual fcms into groups although an interesting approach there is no documented evidence that fcm properties are indicative of the logic of the underlying system we argue that fcm properties are useful for comparing fcms and matrices but they cannot be used to make conclusions about stakeholder understanding and reasoning in an ses 5 4 modelling with ambiguity our research focussed on identifying how a complex ses can be modelled with fcms while explicitly elucidating ambiguity we used a mix of ontological and epistemic strategies by first identifying a range of ambiguities followed by reconstructing one fcm in line with the participatory paradigm heron and reason 1997 it is assumed that reality is co created by an objective and subjective set of experiences however the aggregation stage of the research adopts a more positivist paradigm assuming that a consistent part of perceptions on which stakeholders agree exist and can be modelled modelling multiple perceptions remains a careful balancing act but can provide insights into similar stakeholder paradigms nevertheless a model is merely a tool to enable understanding of what is being modelled using a mixed paradigmatic approach as we did emphasises the diversity of multiple perspectives while providing one model a deep understanding of sess therefore requires new methods to structure and quantify the range of ambiguities from different perspectives the strength of individual pms might not lie in the model that is created but in the systematic understanding of the paradigms of the stakeholders involved if a model shares a paradigm with the user it may improve the uptake of the model in particular if pm is focussed on decision support identifying these paradigms can advance the understanding of how society and science shape each other more studies and elaborate methods are needed to understand what we model why we model it where we simplify a model and which choices are made during this process methods remain in their infancy but have already demonstrated the importance of ambiguity and therefore the importance of transparent and flexible methods to account for it funding this research was funded by the dutch partners of the senses project nwo grant number 438 17 810 the project runs from 2017 to 2020 the project senses is part of the european research area for climate services era4cs an era net initiated by jpi climate it is fully funded by bmbf de bmwfw at nwo nl formas se with co funding by the european union grant 690462 era4cs declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank the stockholm and africa office of sei for their workshop preparations and help in the stakeholder analysis we would also like to thank the senses project for partly funding this research special thanks to all workshop participants and stakeholders who were willing to draw their fcms during the follow up interviews appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105054 policy documents ipcc 2014 intergovernmental panel on climate change 2014 adaptation planning and implementation in climate change 2014 impacts adaptation and vulnerability part a global and sectoral aspects working group ii contribution to the ipcc fifth assessment report pp 869 898 cambridge cambridge university press https doi org 10 1017 cbo9781107415379 020 knap2015 2030 kenya national adaptation plan 2015 2030 government of kenya ministry of environment and natural resources 2016 nccap2018 2022 national climate change action plan 2018 2022 2018 draft for discussion version 3 10th june 2018 ministry of environment and forestry climate change directorate nwmp 2013 national water master plan 2030 government of kenya ministry of environment water and natural resources water resources management authority 2013 internet the biggest threat facing humanity new york times 2018 rechecked on 17 8 2020 from https www nytimes com 2018 03 29 climate united nations climate change html ngigi et al 2011 marther ngigi barrack okoba noora aberman and regina birner 2011 a stakeholder map for climate change adaptation in kenya s agricultural sector retrieved on 23 01 2019 from http womenandclimate ifpri info files 2012 02 kenya net map final pdf 
25828,the complexity associated with water quality models wqms has increased owing to the introduction of numerous physical and biological mechanisms in the models sensitivity analysis sa is conducted to identify influential parameters in these mechanisms however enormous computational power and time are required to obtain numerical solutions from thousands of model simulations therefore a cloud based toolbox is developed for performing sa of wqms by implementing a cloud computing system using grab sampling data and hyperspectral images hsi of waterbodies cloud computing can provide high performance computation by adjusting the scale of the computational power according to user preference the developed toolbox with the cloud system can reduce the computation time for sa by approximately 20 times compared to that of a desktop computer keywords cloud based toolbox cloud computing system water quality model sensitivity analysis hyperspectral imaging data 1 introduction harmful algal blooms habs are the severe proliferation of cyanobacteria in aquatic ecosystems habs cause water quality degradation and have serious impacts on human health aquatic ecosystems and the economy anderson et al 2012 gao et al 2003 o neil et al 2012 in south korea severe water quality degradation has occurred in four major rivers e g han nakdong geum and yeongsan rivers due to excessive eutrophication and algal biomass by artificial weir construction bae and seo 2018 lah et al 2015 lee et al 2019 to better understand the trends and causes of habs the numerical modeling approach has been widely applied pyo et al 2019b zou et al 2006 the modeling approach can be useful in organizing an effective watershed and water quality management system at limited cost and labor baek et al 2015 perez pedini et al 2005 over the years various water quality models wqms have been developed such as the environmental fluid dynamics code efdc hamrick 1992 water quality analysis simulation program wasp ambrose et al 1993 and the ce qual w2 cole and buchak 1995 these models have been successfully implemented in simulating spatiotemporal variations of water quality variables in different waterbodies abbaspour et al 2007 mbuh et al 2018 sadeghian et al 2018 however wqms have become more complex and highly uncertain because a number of model parameters are involved in the biological and physical mechanisms of the water quality variables lindenschmidt 2006 park et al 1995 snowling and kramer 2001 for example there are more than 100 parameters in the water quality module of the efdc model and more than 50 water quality parameters in the wasp model ambrose et al 1993 park et al 1995 yi et al 2016 this causes longer simulation times for model calibration and validation owing to the increase in the number of calculations in the past decades sensitivity analysis sa has been introduced as an efficient way to identify influential model parameters yi et al 2016 ziliani et al 2013 and herman et al 2013 suggested that as a first step sa should be used for model evaluation and calibration to reduce the dimensionality of the parameter space thereby helping to understand the relationship between parameters it implies that complex modeling without sa would be an ineffective exercise since no stakeholder or decision maker could make any use of it with increasing model complexity the computational burden issue has become a concern in sa ercan et al 2014 humphrey et al 2012 rouholahnejad et al 2012 cloud computing has been proposed as a solution for the need of massive computational power ercan et al 2014 glenis et al 2013 li et al 2013 cloud computing delivers high performance computing including storage memory and cpu gpu in addition it is flexible in scaling computational power up or down depending on the preference of the user thereby saving substantial computational costs o donncha et al 2016a bürger et al 2012 integrated cloud computing and hydrological models to simulate a hydrological model in real time o donncha et al 2016b investigated the performance of the efdc model using cloud computing with message passing interface mpi and open multi processing openmp arango et al 2014 developed a new version of agent swarm optimization with a cloud service to conduct a scenario analysis in this study we described a new cloud based toolbox developed to conduct sa of a wqm our toolbox can reduce the total time required to perform the sa resulting in reduced computational operation and analysis efforts it thus has demonstrated it useful for identifying key parameters of wqms and especially for improving our understanding of the mechanisms of algal blooms additionally point data from grab sampling and area monitoring data from hyperspectral imaging hsi were applied to explore the dependency of the sa on the different data sources specifically hsi was used to quantify the spatial distribution of habs and water quality whereas grab sampling was used for point based monitoring for the present study we have conducted a sa of the efdc model which can simulate multiple algal groups and hydraulic artificial structures this model has also been verified in previous studies jia et al 2018 kim et al 2017 loos et al 2020 wu and xu 2011 in this regard the specific objectives of this study were 1 to test a freshly developed a cloud based toolbox to perform sa 2 to quantify the sensitivity of the parameters related to algal mechanisms and 3 to identify the potential effect of different algal observation methods such as grab and hsi based sampling on the sa results 2 methods 2 1 study design in the field of environmental modeling sa is an effective tool to identify the most influential parameters of a model and allows calibration at a reasonable computational cost thereby enabling the reduction of errors between observations and modeling results borgonovo et al 2012 iooss and lemaître 2015 king and perera 2013 pianosi et al 2016 saltelli et al 2000 sa can be categorized into local sensitivity analysis lsa and global sensitivity analysis gsa gsa aims to investigate the influence of parameters over an entire set of parameters while lsa focuses on the effects a single parameter change has on the output van griensven et al 2006 demonstrated that lsa is limited with regard to understanding wqm mechanisms because the model output might not be linearly related to the input parameters based on this background we selected gsa to measure the influence of parameters on wqms in this study the elementary effect test eet based on the latin hypercube one factor at a time lh oat method was adopted for the gsa saltelli et al 2008 van griensven and meixner 2003 the efdc nier model was applied to simulate the hydrodynamics eutrophication water quality and sediment transport in waterbodies pyo et al 2019a however this model requires hundreds of parameters resulting in long simulation times owing to a very high number of calculations therefore our study utilized cloud computing that can provide high performance computation by adjusting the scale of the computational power according to user preference fig 1 shows an overview of the procedures of this study a monitoring based on grab and hsi sampling b wqms setup and c sa based on eet with lh oat grab and hsi sampling were conducted to obtain chl a observation data fig 1a in the model setup fig 1b we prepared bathymetry water elevation and water quality data for the initial and boundary conditions this information was assigned to the efdc nier model in the sa fig 1c we estimated the parameter sensitivity using the eet and lh oat methods to explore the data dependency of the sa we compared the sensitivity to grab and hsi based sampling 2 2 efdc nier the efdc model is a three dimensional model for simulating hydrodynamics eutrophication water quality sediment transport and toxics in rivers estuaries and lakes hamrick 1992 it numerically solves partial differential equations using the finite difference method on a curvilinear grid for a single grid cell the model solves the continuity and momentum equations for the hydrodynamic component and then the advection dispersion equation for the water quality variables the mass balance equation for the efdc model eq s1 and kinetic equations for algae eqs s2 s6 are described in appendix a of the supplementary material a detailed explanation of the efdc model can be found in tetratech 2002 the national institute of environmental research of south korea nier upgraded the efdc model referred to as efdc nier by adding simulations of artificial weirs and multiple algal groups in the hydrodynamic and water quality modules respectively the weir module can effectively simulate the operations of artificial hydraulic structures including fixed weirs movable weirs and multifunctional weirs shin et al 2017 in addition the efdc nier model allows the simulation of phytoplankton functional groups pfgs in the water quality module these functional groups were classified based on the physiological and ecological characteristics of specific phytoplankton the major characteristics of the nine pfgs are summarized in the supplementary material table s1 reynolds 1980 2006 reynolds et al 2002 in this study five groups codons m d p x2 and c were selected as target pfgs for conducting the sa as they showed a high relative abundance of chlorophyll a chl a in the weir reaches of the four major rivers of south korea nier 2017 codon m is represented by microcystis spp while codons d and c include species of the diatom class codon p is a species of both diatom class and green algae spp and codon x2 contains green algae and other algal species fifty parameters of the efdc nier model were selected for sa in our study a list and the ranges of the input parameters were determined from previous literature and domestic case studies table s2 jia et al 2018 jiang et al 2018 pak et al 2016 reynolds 2006 shin et al 2017 yi et al 2016 2 3 grab and hsi based sampling the hsi data can identify spatial and spectral information of water quality while grab sampling is a traditional method to obtain data in the observation points pyo et al 2019a this study identified the influential parameters related to chl a by comparing grab and hsi observations chl a is an essential element for most photosynthetic organisms that provoke habs raven et al 2005 and has been verified as an indicator of habs tian et al 2017 zhao et al 2016 fig 2 illustrates the model error calculation for sa using different sources of observation data grab and hsi based sampling fig 2a shows the process used to determine the model error using observations from grab based sampling the model output of the grid cell corresponding to the location of the observation was used the observed concentration was then compared with the chl a concentration of the efdc grid cell based on hsi based sampling the chl a map created from the hsi data was superimposed onto the efdc grid as shown in fig 2b approximately 3000 5000 pixels in the chl a map were clipped to each corresponding grid cell of the efdc we further generated a histogram of the clipped pixels of the chl a map and its mode was adopted to calculate the error with the corresponding chl a concentration of the efdc grid cell the mode is the most frequent value in a set of data values gujarati et al 2012 a detailed description of hsi data processing from the raw image to the chl a map is provided in appendix b of the supplementary material grab sampling and hsi based observation data were incorporated to evaluate the model error for the sa the model simulation error was calculated using the mean absolute error mae the mae function is defined as follows 1 mae 1 n i 1 n o i e i o i where n is the number of observed data points i is the iteration number and e i and o i are the ith values of the estimated and observed chl a concentrations mg m 3 respectively in this study e i is the chl a concentration from the efdc model and o i is the observed chl a concentration obtained from grab sampling and hsi based observations 2 4 sensitivity analysis of the efdc sae toolbox the sensitivity analysis of the efdc sae toolbox was developed using matlab r2019b software the mathworks inc natick ma usa fig s1 to perform sa of the efdc model parameters the sae tool adopted lh oat sampling eet method and cloud system fig 3 shows a schematic diagram of the sa using cloud computing this process consisted of six steps 1 generating the model set by lh oat sampling 2 dividing the entire model set into subsets 3 transferring the model subset to each instance in the cloud system 4 executing multiple model subsets 5 transferring simulation results to a local computer and 6 conducting sa the model parameter sets are generated by lh oat sampling and written in the efdc nier model thus n p 1 models are generated n and p are the number of interval and model parameters respectively fig 3a when the number of subsets x is determined the model set is divided into subsets fig 3b these subsets were then transferred to each instance in the cloud system fig 3c each instance ran the model with subsets the number of subsets in each instance was calculated by n p 1 i i is the number of instances fig 3d the instance can be regarded as virtual computing environments in the cloud system and the user can define the number of multiple executions for model running multiple executions can be defined as the number of models running at one time y the model results for each instance were transferred to a local computer fig 3e and sa was then conducted fig 3f this study used the amazon web service aws ec 2 c5n 18xlarge instance with an intel xeon platinum 8000 processor at a frequency of 3 4 ghz that uses 72 virtual cpus vcpus and 192 gb of memory 2 4 1 latin hypercube one factor at a time lh oat the one factor at a time oat design changes only one parameter at a time while the other parameters are fixed morris 1991 saltelli et al 2008 lh oat is a method in which the latin hypercube lh sampling is combined with the oat design by taking lh samples as initial points for the oat design van griensven et al 2006 although the oat method is an lsa the lh oat method is regarded as a gsa nossent and bauwens 2012 xu et al 2016 this method can cover the entire range of parameters with fewer sets of model parameters compared to morris oat design thereby reducing the computational cost holvoet et al 2005 van griensven et al 2006 xu et al 2016 lh is a stratified sampling technique based on the monte carlo method mckay 1988 this method divides the parameter values into small groups with a specific interval after which the divided values are randomly selected for each parameter the lh sampling can then generate a unique set of model parameters for each simulation this study used a uniform distribution for parameter sampling dividing the range of each parameter into n equal intervals qiang et al 2010 the oat procedure was repeated until the same number of model parameters was reached p after implementing lh oat the total number of parameter sets becomes n p 1 thereby requiring a total of n p 1 model runs in this study the lh oat sampling generated 5 100 parameter sets n p 1 based on 50 parameters p with 100 intervals n and a radial design pianosi et al 2016 ruano et al 2012 the sample size is a critical factor for gsa noacco et al 2019 sarrazin et al 2016 this is because the sample size determines the robustness and computational cost of a gsa when sampling is properly applied to ensure the entire coverage of the parameter space gsa can handle nonlinearity non additivity and non monotonicity nossent and bauwens 2012 2 4 2 elementary effect test eet in this study the eet method with lh oat was selected to conduct the gsa morris 1991 nossent and bauwens 2012 saltelli et al 2008 xu et al 2016 this method is the most commonly used gsa method owing to its simplicity and effectiveness campolongo et al 2007 because the eet method requires fewer iterations to implement sa than other methods e g the sobol and fast methods it can effectively reduce computational demands herman et al 2013 the eet method is a reliable and efficient technique for identifying and ranking influential parameters as has been verified in previous studies campolongo et al 2007 king and perera 2013 morris 1991 the elementary effect ee quantifies the influence of input parameter variations depending on the model output jia et al 2018 morris 1991 the ee was calculated using eq 2 2 e e i f x 1 x i δ i x k f x 1 x i x k δ i where ee i is the elementary effect of the ith input parameter f is the mae between the simulation and observation x 1 x k are the model input parameters and δ i is the difference between the parameter values the mean and standard deviation of ees were used to measure the global sensitivity of the model parameters the mean of ees assesses the overall importance of an input parameter to the model output while the standard deviation of ees describes the effect of a certain parameter on the other parameters morris 1991 this study utilized the safe toolbox to implement sa pianosi et al 2015 3 case study 3 1 site description the yeongsan river is one of the four major rivers in south korea this river has a catchment area of 3 371 km2 and a total length of 115 km fig 4 the seungchon and juksan weirs were constructed along the mainstream of the yeongsan river to secure the water supply and restore the river ecosystem jun and kim 2011 lee et al 2019 grab sampling and hsi based observations were implemented to investigate the algal blooms at the weirs in 2018 there are three chl a observation stations gwangsan yeongsanpo and juksan henceforth denoted as gs ysp and js respectively fig 4 from the grab sampling the means of the chl a concentrations were observed as 44 90 mg m 3 79 60 mg m 3 and 58 73 mg m 3 at gs ysp and js respectively table 1 from the hsi based observations the means of chl a were 36 49 mg m 3 35 29 mg m 3 and 36 78 mg m 3 respectively the observed chl a data from october to november 2018 were utilized for the sa to correspond with the sampling events of the grab and hsi based observations table 1 3 2 model setup the efdc nier model was built to include the seungchon and juksan weirs as shown in fig 4 a total of 1 225 grid cells with five vertical layers were generated by following a boundary fit curvilinear grid initial boundary and meteorological conditions were assigned for the model setup the water elevation and water quality data of the initial and boundary conditions were obtained from my water http www water or kr and the water environmental information system http water nier go kr in south korea respectively in addition the weather data were collected from the korea meteorological administration kma https www weather go kr the water elevation of the model was calibrated using the observed elevation data of the gs and js stations in 2018 fig s2 the calibration results showed reasonable accuracy with mae values of 0 17 m and 0 12 m at gs and js respectively sa was then performed by comparing the chl a data of the observation stations with the corresponding efdc nier model outputs 3 3 sensitivity analysis 3 3 1 grab sampling fig 5 shows the results of the sa based on the chl a concentrations from the grab sampling the sensitivity ranks of the model parameters are sorted in descending order of the means of ee values in this study the mean ees indicate the overall importance of an input parameter to chl a concentrations from the efdc nier model the standard deviation of ees describes the effect of a certain parameter on the other parameters at gs pmm was the most sensitive parameter fig 5a this is because the parameter is affected by the algal growth ratio that dominated algal biomass dynamics yi et al 2016 also suggested that the algal growth ratio is the most sensitive parameters for algal biomass dynamics in addition pmm yielded a high standard deviation of ees indicating that the parameter interacted significantly with the other parameters morris 1991 table 2 tmd2 was the second most sensitive parameter owing to its relationship with temperature which was significant to algal production eqs s3 and s6 in our case the range of water temperature that can promote diatom growth from october to november was observed to be between 10 12 c and 22 00 c gamier et al 1995 thus tmd2 may accelerate the growth rate of diatoms during this period the third most sensitive parameter at gs is ancc which accounts for the contributions of algal biomass dynamics to the return of nitrogen a sufficient nitrogen supply is a fundamental nutrient requirement for diatom dynamics gilpin et al 2004 according to mallin et al 2009 chemical and manure fertilizers are major sources of nitrogen subject to surface runoff in rural areas these nitrogen sources can be washed into the aquatic environment which can consequently cause eutrophication hart et al 2004 vadas et al 2007 the gs station was surrounded by rural areas hence ancc showed high sensitivity lim et al 2019 tmd2 and pmm were also the most sensitive parameters at ysp fig 5b in addition cpprm3 showed a high sensitivity rank which implies that the effects of algal biomass on the return of phosphorus are significant at ysp table 2 algal growth in freshwater can be governed by the availability of phosphorus dabrowski et al 2009 hecky and kilham 1988 specifically the algal phosphorus to carbon p c ratio is positively related to the ambient dissolved phosphate concentration cerco and cole 1993 yi et al 2016 also revealed that the parameter regarding the p c ratio was influential to chl a phosphorus sources namely livestock wastewater treatment plants manure treatment plants and livestock farms were closely located near the ysp station cooper et al 2002 jung et al 2013 these sources can supply sufficient phosphorus loading to ysp jung et al 2013 ma et al 2011 hence chl a concentrations in the ysp varied depending on the ambient phosphorus concentration at js pmm and tmd2 were ranked first and third in the sensitivity ranks fig 5c respectively the second most sensitive parameter was wqrm which is related to the sinking velocity of cyanobacteria the settling velocity is governed by the stokes equation as described in the study of guven and howard 2006 in particular microcystis a genus of cyanobacteria can move vertically by regulating their buoyancy the microcystis radius is one of the key determining factors of its settling velocity visser et al 1997 the average of the model flow velocities at gs ysp and js were observed as 0 22 m s 1 0 07 m s 1 and 0 05 m s 1 respectively microcystis can grow well by regulating its buoyancy when the flow is slow however it would be difficult for microcystis to move vertically when the flow is fast because they can be easily swept away thus the lower flow velocity at js contributed to the high sensitivity result for wqrm overall six parameters were identified as the common sensitive parameters from the grab based sa results table 2 these parameters were related to algal kinetics i e pmm pmd and pmc temperature i e tmd2 and ktgd2 and nutrients i e cpprm3 they are also the primary factors in calculating algal growth p x which is one of the terms used in the calculation of algal biomass b x in eq s2 eq s3 shows that p x is affected by nutrients light intensity and temperature this result showed that temperature was not the only key determining factor for algal growth maranon et al 2018 singh and singh 2015 but also phosphorus and nitrogen which play significant roles as food supplies for algae giannuzzi 2018 specifically pmm and tmd2 had the highest sensitivity between the three observation point parameters implying that these could be considered as the preferential parameters for the calibration of the efdc nier model meanwhile cpprm3 and wqrm showed different sensitivities at the observation points depending on the flow velocity and or their distance from the point sources 3 3 2 hsi based observations fig 6 shows the results of the sa with chl a concentrations from the hsi based observations at gs both cpprm3 and tmd2 were the most sensitive parameters fig 6a the sensitivity results of these parameters are similar to the grab based sa results the third most sensitive parameter at gs was ktgd1 a temperature related parameter affecting diatom production eqs s3 and s6 ancc was the fourth most sensitive parameter table 3 this adds to the assumption that phosphorus and nitrogen are significant for algal growth because the sensitive parameters i e cpprm3 and ancc were mainly related to nutrients previous studies have demonstrated that phosphorus and nitrogen are the primary limiting nutrients and their ratios largely influence algal growth fried et al 2003 mostert and grobbelaar 1987 at ysp tmd2 was the most sensitive parameter from the hsi based sa fig 6b the diatom biomass was highly influenced by temperature related parameters this parameter strongly interacted with others based on the high standard deviation of ee in addition pmd was the second most sensitive parameter revealing that the parameter for diatom growth was important at ysp tmd2 also showed the highest sensitivity at js followed by pmm and cpprm3 fig 6c in the hsi based sa results wqrm was less sensitive than the grab based sa results figs 5c and 6c this is because the hsi events were conducted under moderate wind speed and cloudless weather conditions therefore there was less variability in the temperature values this may result in less sensitivity of wqrm because the velocity of the vertical movement was largely affected by the temperature guven and howard 2006 overall the hsi based sa results showed that tmd2 is a common sensitive parameter the nutrient parameters i e cpprm3 and ancc and algal kinetic parameters i e pmd and pmm should also be considered in the calibration of algal concentrations in addition we produced convergence plots against the number of model evaluations at each observation point fig s3 these plots show the variation of sensitivity ranks with the number of iterations pianosi et al 2015 sarrazin et al 2016 most parameters stabilized at 5 100 model evaluations as shown in fig s3 therefore our model simulations can provide robust eet results for this study 3 4 evaluation of sae toolbox performance fig 7 shows a comparison of the simulation time of a desktop computer pc and a cloud system we calculated the total simulation time by multiplying the average simulation time for 10 cycles of multiple executions by the total number of iterations for example with an average simulation time of 2 h if the number of cycles is 10 and the number of executions is 20 the total number of iterations will be 200 i e no cycle no executions resulting in a total simulation time of 400 h i e no iterations average simulation time total simulation times decreased with an increase in the number of executions and the cloud system required a shorter simulation time than pc fig 7a the maximum number of executions was 50 and 100 for the pc and cloud systems respectively this difference was due to the higher computing capacity of the cloud system i e 72 intel xeon platinum 8000 processor and 192 gb memory compared to pc i e two intel xeon cpu e5 2680 v3 and 128 gb memory in the case of one execution the total time was 669 and 57 days for the pc and cloud systems respectively the pc using 50 executions required 35 days while the cloud system using 50 executions required 2 days of simulation time this indicates that the cloud system can save approximately 20 times the simulation time for sa compared to the pc fig 7b shows the simulation time ratio of the cloud system and pc for different executions the ratio reached a factor of 20 as the number of executions increased to 50 in addition we compared the simulation time depending on the number of cores two four and eight fig 7c the total simulation time decreased with an increase in the number of cores and executions after the number of executions exceeded that of the cores the total simulation time could not be decreased over the number of executions the main advantages of cloud based computing are the scalability and flexibility of computing power thereby ensuring an effective use of resources and allowing to save considerable computational cost in cloud systems the user can specify the computational specifications e g cpu and gpu and operating system os e g linux and windows kan et al 2018 therefore our system can reduce the simulation time for sa enabling to feasibly cope with complex models numerous studies have conducted model simulations using cloud systems yi et al 2016 performed a sa of the efdc model and the simulation time required was 75 days for 6 600 model iterations alarcon et al 2014 coupled mpi implementation and the efdc model which resulted in an 8 53 fold speedup of the simulation o donncha et al 2016b achieved a 16 fold speedup using mpi hybrid mpi and openmp implementation in addition cloud systems are not restricted to the storage constraint and the data in the cloud can be accessed anywhere thus it is feasible to manage and share simulation results through the internet sa is an essential procedure for model development application and calibration borgonovo et al 2012 king and perera 2013 lenhart et al 2002 saltelli et al 2000 it has been used to determine key model mechanisms and reduce the computational burden jiang et al 2018 lenhart et al 2002 saltelli et al 2008 van griensven et al 2006 zhan et al 2013 demonstrated that sa is an alternative method for understanding the interaction between parameters holvoet et al 2005 calibrated the swat model using the influenced parameters that were selected based on the lh oat herman et al 2013 reported that sa brings with it a computational burden owing to thousands of iterations our study tackled the challenge regarding computational power by developing a toolbox based on clouds this approach allowed to reduce the computation time of sa by approximately a factor of 20 compared with the computation time using a pc the total simulation time using a pc was 837 h while that using the cloud system was 43 h furthermore the developed toolbox can be applied to other numerical models e g ocean models and watershed models and data assimilation for example in the past decades the data assimilation approach has been proposed for improving model predictions and reducing prediction uncertainty by handling state variables model parameters and model conditions however this approach requires thousands of model iterations cho et al 2020 the toolbox developed in this study can be applied to solve this practical issue of data assimilation 4 conclusion in this study we developed a cloud based toolbox for conducting sa of the efdc nier model this toolbox adopts the eet method with lh oat in addition this study utilized grab sampling and hsi based observations of a dataset of the yeongsan river south korea to identify the influential parameters the major findings of this study are as follows 1 the sa toolbox we have developed and deployed on a cloud computing system demonstrated friendly and effective 2 it succeeded in identifying the common pmm and tmd2 parameters as the most sensitive one in grab based sa 3 the cloud implementation allowed to reduce the computation time for the sa compared to that of a pc in our application the total simulation time using a pc was 837 h whereas that using the cloud system was 43 h this study demonstrates that the cloud based toolbox can reduce the computation time for conducting sa when used with massive wqm simulations the benefit of sa is the identification of influential parameters in the calibration process the computational power can be reduced by selecting the influenced parameters holvoet et al 2005 in addition sa can be useful for understanding the model mechanisms by analyzing the relationship between the parameters the advantage of our toolbox is that it is capable of simulating a sophisticated model that requires massive computational power e g scenario analysis model calibration and data assimilation that is through the cloud system the developed toolbox can be used at high computational power and sufficient storage it can be utilized as a practical computational method for water quality modeling by providing effective model parameter information and allows users to perform sa of complex wqms more conveniently and effectively on cloud computing resulting in reduced operational and labor costs software availability program name sensitivity analysis of the efdc sae developers ulsan national institute of science and technology unist national institute of environmental research nier geosystem research corporation contact address school of urban and environmental engineering ulsan national institute of science and technology unist gil 50 ulsan 689 798 republic of korea e mail khcho unist ac kr year first available 2020 program language matlab software required ms windows software development matlab 2019b software availability contact the authors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by a grant from the national institute of environment research nier funded by the ministry of environment moe of the republic of korea nier 2019 04 02 037 this work was supported by the korea environment industry technology institute keiti through the chemical accident prevention technology development project funded by the korea ministry of environment moe no 2016001970001 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105068 
25828,the complexity associated with water quality models wqms has increased owing to the introduction of numerous physical and biological mechanisms in the models sensitivity analysis sa is conducted to identify influential parameters in these mechanisms however enormous computational power and time are required to obtain numerical solutions from thousands of model simulations therefore a cloud based toolbox is developed for performing sa of wqms by implementing a cloud computing system using grab sampling data and hyperspectral images hsi of waterbodies cloud computing can provide high performance computation by adjusting the scale of the computational power according to user preference the developed toolbox with the cloud system can reduce the computation time for sa by approximately 20 times compared to that of a desktop computer keywords cloud based toolbox cloud computing system water quality model sensitivity analysis hyperspectral imaging data 1 introduction harmful algal blooms habs are the severe proliferation of cyanobacteria in aquatic ecosystems habs cause water quality degradation and have serious impacts on human health aquatic ecosystems and the economy anderson et al 2012 gao et al 2003 o neil et al 2012 in south korea severe water quality degradation has occurred in four major rivers e g han nakdong geum and yeongsan rivers due to excessive eutrophication and algal biomass by artificial weir construction bae and seo 2018 lah et al 2015 lee et al 2019 to better understand the trends and causes of habs the numerical modeling approach has been widely applied pyo et al 2019b zou et al 2006 the modeling approach can be useful in organizing an effective watershed and water quality management system at limited cost and labor baek et al 2015 perez pedini et al 2005 over the years various water quality models wqms have been developed such as the environmental fluid dynamics code efdc hamrick 1992 water quality analysis simulation program wasp ambrose et al 1993 and the ce qual w2 cole and buchak 1995 these models have been successfully implemented in simulating spatiotemporal variations of water quality variables in different waterbodies abbaspour et al 2007 mbuh et al 2018 sadeghian et al 2018 however wqms have become more complex and highly uncertain because a number of model parameters are involved in the biological and physical mechanisms of the water quality variables lindenschmidt 2006 park et al 1995 snowling and kramer 2001 for example there are more than 100 parameters in the water quality module of the efdc model and more than 50 water quality parameters in the wasp model ambrose et al 1993 park et al 1995 yi et al 2016 this causes longer simulation times for model calibration and validation owing to the increase in the number of calculations in the past decades sensitivity analysis sa has been introduced as an efficient way to identify influential model parameters yi et al 2016 ziliani et al 2013 and herman et al 2013 suggested that as a first step sa should be used for model evaluation and calibration to reduce the dimensionality of the parameter space thereby helping to understand the relationship between parameters it implies that complex modeling without sa would be an ineffective exercise since no stakeholder or decision maker could make any use of it with increasing model complexity the computational burden issue has become a concern in sa ercan et al 2014 humphrey et al 2012 rouholahnejad et al 2012 cloud computing has been proposed as a solution for the need of massive computational power ercan et al 2014 glenis et al 2013 li et al 2013 cloud computing delivers high performance computing including storage memory and cpu gpu in addition it is flexible in scaling computational power up or down depending on the preference of the user thereby saving substantial computational costs o donncha et al 2016a bürger et al 2012 integrated cloud computing and hydrological models to simulate a hydrological model in real time o donncha et al 2016b investigated the performance of the efdc model using cloud computing with message passing interface mpi and open multi processing openmp arango et al 2014 developed a new version of agent swarm optimization with a cloud service to conduct a scenario analysis in this study we described a new cloud based toolbox developed to conduct sa of a wqm our toolbox can reduce the total time required to perform the sa resulting in reduced computational operation and analysis efforts it thus has demonstrated it useful for identifying key parameters of wqms and especially for improving our understanding of the mechanisms of algal blooms additionally point data from grab sampling and area monitoring data from hyperspectral imaging hsi were applied to explore the dependency of the sa on the different data sources specifically hsi was used to quantify the spatial distribution of habs and water quality whereas grab sampling was used for point based monitoring for the present study we have conducted a sa of the efdc model which can simulate multiple algal groups and hydraulic artificial structures this model has also been verified in previous studies jia et al 2018 kim et al 2017 loos et al 2020 wu and xu 2011 in this regard the specific objectives of this study were 1 to test a freshly developed a cloud based toolbox to perform sa 2 to quantify the sensitivity of the parameters related to algal mechanisms and 3 to identify the potential effect of different algal observation methods such as grab and hsi based sampling on the sa results 2 methods 2 1 study design in the field of environmental modeling sa is an effective tool to identify the most influential parameters of a model and allows calibration at a reasonable computational cost thereby enabling the reduction of errors between observations and modeling results borgonovo et al 2012 iooss and lemaître 2015 king and perera 2013 pianosi et al 2016 saltelli et al 2000 sa can be categorized into local sensitivity analysis lsa and global sensitivity analysis gsa gsa aims to investigate the influence of parameters over an entire set of parameters while lsa focuses on the effects a single parameter change has on the output van griensven et al 2006 demonstrated that lsa is limited with regard to understanding wqm mechanisms because the model output might not be linearly related to the input parameters based on this background we selected gsa to measure the influence of parameters on wqms in this study the elementary effect test eet based on the latin hypercube one factor at a time lh oat method was adopted for the gsa saltelli et al 2008 van griensven and meixner 2003 the efdc nier model was applied to simulate the hydrodynamics eutrophication water quality and sediment transport in waterbodies pyo et al 2019a however this model requires hundreds of parameters resulting in long simulation times owing to a very high number of calculations therefore our study utilized cloud computing that can provide high performance computation by adjusting the scale of the computational power according to user preference fig 1 shows an overview of the procedures of this study a monitoring based on grab and hsi sampling b wqms setup and c sa based on eet with lh oat grab and hsi sampling were conducted to obtain chl a observation data fig 1a in the model setup fig 1b we prepared bathymetry water elevation and water quality data for the initial and boundary conditions this information was assigned to the efdc nier model in the sa fig 1c we estimated the parameter sensitivity using the eet and lh oat methods to explore the data dependency of the sa we compared the sensitivity to grab and hsi based sampling 2 2 efdc nier the efdc model is a three dimensional model for simulating hydrodynamics eutrophication water quality sediment transport and toxics in rivers estuaries and lakes hamrick 1992 it numerically solves partial differential equations using the finite difference method on a curvilinear grid for a single grid cell the model solves the continuity and momentum equations for the hydrodynamic component and then the advection dispersion equation for the water quality variables the mass balance equation for the efdc model eq s1 and kinetic equations for algae eqs s2 s6 are described in appendix a of the supplementary material a detailed explanation of the efdc model can be found in tetratech 2002 the national institute of environmental research of south korea nier upgraded the efdc model referred to as efdc nier by adding simulations of artificial weirs and multiple algal groups in the hydrodynamic and water quality modules respectively the weir module can effectively simulate the operations of artificial hydraulic structures including fixed weirs movable weirs and multifunctional weirs shin et al 2017 in addition the efdc nier model allows the simulation of phytoplankton functional groups pfgs in the water quality module these functional groups were classified based on the physiological and ecological characteristics of specific phytoplankton the major characteristics of the nine pfgs are summarized in the supplementary material table s1 reynolds 1980 2006 reynolds et al 2002 in this study five groups codons m d p x2 and c were selected as target pfgs for conducting the sa as they showed a high relative abundance of chlorophyll a chl a in the weir reaches of the four major rivers of south korea nier 2017 codon m is represented by microcystis spp while codons d and c include species of the diatom class codon p is a species of both diatom class and green algae spp and codon x2 contains green algae and other algal species fifty parameters of the efdc nier model were selected for sa in our study a list and the ranges of the input parameters were determined from previous literature and domestic case studies table s2 jia et al 2018 jiang et al 2018 pak et al 2016 reynolds 2006 shin et al 2017 yi et al 2016 2 3 grab and hsi based sampling the hsi data can identify spatial and spectral information of water quality while grab sampling is a traditional method to obtain data in the observation points pyo et al 2019a this study identified the influential parameters related to chl a by comparing grab and hsi observations chl a is an essential element for most photosynthetic organisms that provoke habs raven et al 2005 and has been verified as an indicator of habs tian et al 2017 zhao et al 2016 fig 2 illustrates the model error calculation for sa using different sources of observation data grab and hsi based sampling fig 2a shows the process used to determine the model error using observations from grab based sampling the model output of the grid cell corresponding to the location of the observation was used the observed concentration was then compared with the chl a concentration of the efdc grid cell based on hsi based sampling the chl a map created from the hsi data was superimposed onto the efdc grid as shown in fig 2b approximately 3000 5000 pixels in the chl a map were clipped to each corresponding grid cell of the efdc we further generated a histogram of the clipped pixels of the chl a map and its mode was adopted to calculate the error with the corresponding chl a concentration of the efdc grid cell the mode is the most frequent value in a set of data values gujarati et al 2012 a detailed description of hsi data processing from the raw image to the chl a map is provided in appendix b of the supplementary material grab sampling and hsi based observation data were incorporated to evaluate the model error for the sa the model simulation error was calculated using the mean absolute error mae the mae function is defined as follows 1 mae 1 n i 1 n o i e i o i where n is the number of observed data points i is the iteration number and e i and o i are the ith values of the estimated and observed chl a concentrations mg m 3 respectively in this study e i is the chl a concentration from the efdc model and o i is the observed chl a concentration obtained from grab sampling and hsi based observations 2 4 sensitivity analysis of the efdc sae toolbox the sensitivity analysis of the efdc sae toolbox was developed using matlab r2019b software the mathworks inc natick ma usa fig s1 to perform sa of the efdc model parameters the sae tool adopted lh oat sampling eet method and cloud system fig 3 shows a schematic diagram of the sa using cloud computing this process consisted of six steps 1 generating the model set by lh oat sampling 2 dividing the entire model set into subsets 3 transferring the model subset to each instance in the cloud system 4 executing multiple model subsets 5 transferring simulation results to a local computer and 6 conducting sa the model parameter sets are generated by lh oat sampling and written in the efdc nier model thus n p 1 models are generated n and p are the number of interval and model parameters respectively fig 3a when the number of subsets x is determined the model set is divided into subsets fig 3b these subsets were then transferred to each instance in the cloud system fig 3c each instance ran the model with subsets the number of subsets in each instance was calculated by n p 1 i i is the number of instances fig 3d the instance can be regarded as virtual computing environments in the cloud system and the user can define the number of multiple executions for model running multiple executions can be defined as the number of models running at one time y the model results for each instance were transferred to a local computer fig 3e and sa was then conducted fig 3f this study used the amazon web service aws ec 2 c5n 18xlarge instance with an intel xeon platinum 8000 processor at a frequency of 3 4 ghz that uses 72 virtual cpus vcpus and 192 gb of memory 2 4 1 latin hypercube one factor at a time lh oat the one factor at a time oat design changes only one parameter at a time while the other parameters are fixed morris 1991 saltelli et al 2008 lh oat is a method in which the latin hypercube lh sampling is combined with the oat design by taking lh samples as initial points for the oat design van griensven et al 2006 although the oat method is an lsa the lh oat method is regarded as a gsa nossent and bauwens 2012 xu et al 2016 this method can cover the entire range of parameters with fewer sets of model parameters compared to morris oat design thereby reducing the computational cost holvoet et al 2005 van griensven et al 2006 xu et al 2016 lh is a stratified sampling technique based on the monte carlo method mckay 1988 this method divides the parameter values into small groups with a specific interval after which the divided values are randomly selected for each parameter the lh sampling can then generate a unique set of model parameters for each simulation this study used a uniform distribution for parameter sampling dividing the range of each parameter into n equal intervals qiang et al 2010 the oat procedure was repeated until the same number of model parameters was reached p after implementing lh oat the total number of parameter sets becomes n p 1 thereby requiring a total of n p 1 model runs in this study the lh oat sampling generated 5 100 parameter sets n p 1 based on 50 parameters p with 100 intervals n and a radial design pianosi et al 2016 ruano et al 2012 the sample size is a critical factor for gsa noacco et al 2019 sarrazin et al 2016 this is because the sample size determines the robustness and computational cost of a gsa when sampling is properly applied to ensure the entire coverage of the parameter space gsa can handle nonlinearity non additivity and non monotonicity nossent and bauwens 2012 2 4 2 elementary effect test eet in this study the eet method with lh oat was selected to conduct the gsa morris 1991 nossent and bauwens 2012 saltelli et al 2008 xu et al 2016 this method is the most commonly used gsa method owing to its simplicity and effectiveness campolongo et al 2007 because the eet method requires fewer iterations to implement sa than other methods e g the sobol and fast methods it can effectively reduce computational demands herman et al 2013 the eet method is a reliable and efficient technique for identifying and ranking influential parameters as has been verified in previous studies campolongo et al 2007 king and perera 2013 morris 1991 the elementary effect ee quantifies the influence of input parameter variations depending on the model output jia et al 2018 morris 1991 the ee was calculated using eq 2 2 e e i f x 1 x i δ i x k f x 1 x i x k δ i where ee i is the elementary effect of the ith input parameter f is the mae between the simulation and observation x 1 x k are the model input parameters and δ i is the difference between the parameter values the mean and standard deviation of ees were used to measure the global sensitivity of the model parameters the mean of ees assesses the overall importance of an input parameter to the model output while the standard deviation of ees describes the effect of a certain parameter on the other parameters morris 1991 this study utilized the safe toolbox to implement sa pianosi et al 2015 3 case study 3 1 site description the yeongsan river is one of the four major rivers in south korea this river has a catchment area of 3 371 km2 and a total length of 115 km fig 4 the seungchon and juksan weirs were constructed along the mainstream of the yeongsan river to secure the water supply and restore the river ecosystem jun and kim 2011 lee et al 2019 grab sampling and hsi based observations were implemented to investigate the algal blooms at the weirs in 2018 there are three chl a observation stations gwangsan yeongsanpo and juksan henceforth denoted as gs ysp and js respectively fig 4 from the grab sampling the means of the chl a concentrations were observed as 44 90 mg m 3 79 60 mg m 3 and 58 73 mg m 3 at gs ysp and js respectively table 1 from the hsi based observations the means of chl a were 36 49 mg m 3 35 29 mg m 3 and 36 78 mg m 3 respectively the observed chl a data from october to november 2018 were utilized for the sa to correspond with the sampling events of the grab and hsi based observations table 1 3 2 model setup the efdc nier model was built to include the seungchon and juksan weirs as shown in fig 4 a total of 1 225 grid cells with five vertical layers were generated by following a boundary fit curvilinear grid initial boundary and meteorological conditions were assigned for the model setup the water elevation and water quality data of the initial and boundary conditions were obtained from my water http www water or kr and the water environmental information system http water nier go kr in south korea respectively in addition the weather data were collected from the korea meteorological administration kma https www weather go kr the water elevation of the model was calibrated using the observed elevation data of the gs and js stations in 2018 fig s2 the calibration results showed reasonable accuracy with mae values of 0 17 m and 0 12 m at gs and js respectively sa was then performed by comparing the chl a data of the observation stations with the corresponding efdc nier model outputs 3 3 sensitivity analysis 3 3 1 grab sampling fig 5 shows the results of the sa based on the chl a concentrations from the grab sampling the sensitivity ranks of the model parameters are sorted in descending order of the means of ee values in this study the mean ees indicate the overall importance of an input parameter to chl a concentrations from the efdc nier model the standard deviation of ees describes the effect of a certain parameter on the other parameters at gs pmm was the most sensitive parameter fig 5a this is because the parameter is affected by the algal growth ratio that dominated algal biomass dynamics yi et al 2016 also suggested that the algal growth ratio is the most sensitive parameters for algal biomass dynamics in addition pmm yielded a high standard deviation of ees indicating that the parameter interacted significantly with the other parameters morris 1991 table 2 tmd2 was the second most sensitive parameter owing to its relationship with temperature which was significant to algal production eqs s3 and s6 in our case the range of water temperature that can promote diatom growth from october to november was observed to be between 10 12 c and 22 00 c gamier et al 1995 thus tmd2 may accelerate the growth rate of diatoms during this period the third most sensitive parameter at gs is ancc which accounts for the contributions of algal biomass dynamics to the return of nitrogen a sufficient nitrogen supply is a fundamental nutrient requirement for diatom dynamics gilpin et al 2004 according to mallin et al 2009 chemical and manure fertilizers are major sources of nitrogen subject to surface runoff in rural areas these nitrogen sources can be washed into the aquatic environment which can consequently cause eutrophication hart et al 2004 vadas et al 2007 the gs station was surrounded by rural areas hence ancc showed high sensitivity lim et al 2019 tmd2 and pmm were also the most sensitive parameters at ysp fig 5b in addition cpprm3 showed a high sensitivity rank which implies that the effects of algal biomass on the return of phosphorus are significant at ysp table 2 algal growth in freshwater can be governed by the availability of phosphorus dabrowski et al 2009 hecky and kilham 1988 specifically the algal phosphorus to carbon p c ratio is positively related to the ambient dissolved phosphate concentration cerco and cole 1993 yi et al 2016 also revealed that the parameter regarding the p c ratio was influential to chl a phosphorus sources namely livestock wastewater treatment plants manure treatment plants and livestock farms were closely located near the ysp station cooper et al 2002 jung et al 2013 these sources can supply sufficient phosphorus loading to ysp jung et al 2013 ma et al 2011 hence chl a concentrations in the ysp varied depending on the ambient phosphorus concentration at js pmm and tmd2 were ranked first and third in the sensitivity ranks fig 5c respectively the second most sensitive parameter was wqrm which is related to the sinking velocity of cyanobacteria the settling velocity is governed by the stokes equation as described in the study of guven and howard 2006 in particular microcystis a genus of cyanobacteria can move vertically by regulating their buoyancy the microcystis radius is one of the key determining factors of its settling velocity visser et al 1997 the average of the model flow velocities at gs ysp and js were observed as 0 22 m s 1 0 07 m s 1 and 0 05 m s 1 respectively microcystis can grow well by regulating its buoyancy when the flow is slow however it would be difficult for microcystis to move vertically when the flow is fast because they can be easily swept away thus the lower flow velocity at js contributed to the high sensitivity result for wqrm overall six parameters were identified as the common sensitive parameters from the grab based sa results table 2 these parameters were related to algal kinetics i e pmm pmd and pmc temperature i e tmd2 and ktgd2 and nutrients i e cpprm3 they are also the primary factors in calculating algal growth p x which is one of the terms used in the calculation of algal biomass b x in eq s2 eq s3 shows that p x is affected by nutrients light intensity and temperature this result showed that temperature was not the only key determining factor for algal growth maranon et al 2018 singh and singh 2015 but also phosphorus and nitrogen which play significant roles as food supplies for algae giannuzzi 2018 specifically pmm and tmd2 had the highest sensitivity between the three observation point parameters implying that these could be considered as the preferential parameters for the calibration of the efdc nier model meanwhile cpprm3 and wqrm showed different sensitivities at the observation points depending on the flow velocity and or their distance from the point sources 3 3 2 hsi based observations fig 6 shows the results of the sa with chl a concentrations from the hsi based observations at gs both cpprm3 and tmd2 were the most sensitive parameters fig 6a the sensitivity results of these parameters are similar to the grab based sa results the third most sensitive parameter at gs was ktgd1 a temperature related parameter affecting diatom production eqs s3 and s6 ancc was the fourth most sensitive parameter table 3 this adds to the assumption that phosphorus and nitrogen are significant for algal growth because the sensitive parameters i e cpprm3 and ancc were mainly related to nutrients previous studies have demonstrated that phosphorus and nitrogen are the primary limiting nutrients and their ratios largely influence algal growth fried et al 2003 mostert and grobbelaar 1987 at ysp tmd2 was the most sensitive parameter from the hsi based sa fig 6b the diatom biomass was highly influenced by temperature related parameters this parameter strongly interacted with others based on the high standard deviation of ee in addition pmd was the second most sensitive parameter revealing that the parameter for diatom growth was important at ysp tmd2 also showed the highest sensitivity at js followed by pmm and cpprm3 fig 6c in the hsi based sa results wqrm was less sensitive than the grab based sa results figs 5c and 6c this is because the hsi events were conducted under moderate wind speed and cloudless weather conditions therefore there was less variability in the temperature values this may result in less sensitivity of wqrm because the velocity of the vertical movement was largely affected by the temperature guven and howard 2006 overall the hsi based sa results showed that tmd2 is a common sensitive parameter the nutrient parameters i e cpprm3 and ancc and algal kinetic parameters i e pmd and pmm should also be considered in the calibration of algal concentrations in addition we produced convergence plots against the number of model evaluations at each observation point fig s3 these plots show the variation of sensitivity ranks with the number of iterations pianosi et al 2015 sarrazin et al 2016 most parameters stabilized at 5 100 model evaluations as shown in fig s3 therefore our model simulations can provide robust eet results for this study 3 4 evaluation of sae toolbox performance fig 7 shows a comparison of the simulation time of a desktop computer pc and a cloud system we calculated the total simulation time by multiplying the average simulation time for 10 cycles of multiple executions by the total number of iterations for example with an average simulation time of 2 h if the number of cycles is 10 and the number of executions is 20 the total number of iterations will be 200 i e no cycle no executions resulting in a total simulation time of 400 h i e no iterations average simulation time total simulation times decreased with an increase in the number of executions and the cloud system required a shorter simulation time than pc fig 7a the maximum number of executions was 50 and 100 for the pc and cloud systems respectively this difference was due to the higher computing capacity of the cloud system i e 72 intel xeon platinum 8000 processor and 192 gb memory compared to pc i e two intel xeon cpu e5 2680 v3 and 128 gb memory in the case of one execution the total time was 669 and 57 days for the pc and cloud systems respectively the pc using 50 executions required 35 days while the cloud system using 50 executions required 2 days of simulation time this indicates that the cloud system can save approximately 20 times the simulation time for sa compared to the pc fig 7b shows the simulation time ratio of the cloud system and pc for different executions the ratio reached a factor of 20 as the number of executions increased to 50 in addition we compared the simulation time depending on the number of cores two four and eight fig 7c the total simulation time decreased with an increase in the number of cores and executions after the number of executions exceeded that of the cores the total simulation time could not be decreased over the number of executions the main advantages of cloud based computing are the scalability and flexibility of computing power thereby ensuring an effective use of resources and allowing to save considerable computational cost in cloud systems the user can specify the computational specifications e g cpu and gpu and operating system os e g linux and windows kan et al 2018 therefore our system can reduce the simulation time for sa enabling to feasibly cope with complex models numerous studies have conducted model simulations using cloud systems yi et al 2016 performed a sa of the efdc model and the simulation time required was 75 days for 6 600 model iterations alarcon et al 2014 coupled mpi implementation and the efdc model which resulted in an 8 53 fold speedup of the simulation o donncha et al 2016b achieved a 16 fold speedup using mpi hybrid mpi and openmp implementation in addition cloud systems are not restricted to the storage constraint and the data in the cloud can be accessed anywhere thus it is feasible to manage and share simulation results through the internet sa is an essential procedure for model development application and calibration borgonovo et al 2012 king and perera 2013 lenhart et al 2002 saltelli et al 2000 it has been used to determine key model mechanisms and reduce the computational burden jiang et al 2018 lenhart et al 2002 saltelli et al 2008 van griensven et al 2006 zhan et al 2013 demonstrated that sa is an alternative method for understanding the interaction between parameters holvoet et al 2005 calibrated the swat model using the influenced parameters that were selected based on the lh oat herman et al 2013 reported that sa brings with it a computational burden owing to thousands of iterations our study tackled the challenge regarding computational power by developing a toolbox based on clouds this approach allowed to reduce the computation time of sa by approximately a factor of 20 compared with the computation time using a pc the total simulation time using a pc was 837 h while that using the cloud system was 43 h furthermore the developed toolbox can be applied to other numerical models e g ocean models and watershed models and data assimilation for example in the past decades the data assimilation approach has been proposed for improving model predictions and reducing prediction uncertainty by handling state variables model parameters and model conditions however this approach requires thousands of model iterations cho et al 2020 the toolbox developed in this study can be applied to solve this practical issue of data assimilation 4 conclusion in this study we developed a cloud based toolbox for conducting sa of the efdc nier model this toolbox adopts the eet method with lh oat in addition this study utilized grab sampling and hsi based observations of a dataset of the yeongsan river south korea to identify the influential parameters the major findings of this study are as follows 1 the sa toolbox we have developed and deployed on a cloud computing system demonstrated friendly and effective 2 it succeeded in identifying the common pmm and tmd2 parameters as the most sensitive one in grab based sa 3 the cloud implementation allowed to reduce the computation time for the sa compared to that of a pc in our application the total simulation time using a pc was 837 h whereas that using the cloud system was 43 h this study demonstrates that the cloud based toolbox can reduce the computation time for conducting sa when used with massive wqm simulations the benefit of sa is the identification of influential parameters in the calibration process the computational power can be reduced by selecting the influenced parameters holvoet et al 2005 in addition sa can be useful for understanding the model mechanisms by analyzing the relationship between the parameters the advantage of our toolbox is that it is capable of simulating a sophisticated model that requires massive computational power e g scenario analysis model calibration and data assimilation that is through the cloud system the developed toolbox can be used at high computational power and sufficient storage it can be utilized as a practical computational method for water quality modeling by providing effective model parameter information and allows users to perform sa of complex wqms more conveniently and effectively on cloud computing resulting in reduced operational and labor costs software availability program name sensitivity analysis of the efdc sae developers ulsan national institute of science and technology unist national institute of environmental research nier geosystem research corporation contact address school of urban and environmental engineering ulsan national institute of science and technology unist gil 50 ulsan 689 798 republic of korea e mail khcho unist ac kr year first available 2020 program language matlab software required ms windows software development matlab 2019b software availability contact the authors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by a grant from the national institute of environment research nier funded by the ministry of environment moe of the republic of korea nier 2019 04 02 037 this work was supported by the korea environment industry technology institute keiti through the chemical accident prevention technology development project funded by the korea ministry of environment moe no 2016001970001 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105068 
25829,multi objective spatial optimization problems require spatial data input that can contain uncertainties via the validation of constraints and the computation of objective values this uncertainty propagates to the pareto fronts here we develop a method to quantify the uncertainty in pareto fronts by finding the extreme lower and upper bound of the range of optimal values in the objective space i e the pareto interval the method is demonstrated on a land use allocation problem with initial land use for objectives and constraints and soil fertility for one objective as uncertain input data pareto intervals resulting from uncertain land use data were wide and irregularly shaped whereas the ones from uncertain soil data were narrow and regularly shaped furthermore in some objective space regions optimal land use patterns remained relatively stable under uncertainty while elsewhere they were clouded this information can be used to select solutions robust to spatial input data uncertainty graphical abstract image 1 keywords spatial optimization land use allocation uncertain spatial data uncertain pareto fronts seeding 1 introduction spatial optimization covers a range of approaches to find configurations of space that are optimal given one or more decision variables one or more objectives and one or more constraints cao 2018 most spatial optimization problems involve multiple conflicting objectives such as minimizing production costs while minimizing green house gas emissions verstegen et al 2017 or minimizing the travel time to hospitals while minimizing the costs involved in building new hospitals luo et al 2017 in such cases the spatial optimization does not result in a single optimal spatial configuration but instead in a set of spatial configurations called the non dominated solutions these configurations can all be considered optimal but represent trade offs between the conflicting objectives e g high crop yield with high water usage or the other way around when plotted in the objective space i e plotting the values of the objective functions for these non dominated solutions they together form the pareto front the spatial input data to an optimization problem may be uncertain the sources of uncertainty are diverse the data can contain errors vagueness or ambiguity fisher et al 2006 these uncertainties lead to arbitrarity in whether or not a solution is non dominated for two reasons firstly the validation of the feasibility of solutions with the defined constraints may become uncertain secondly the computed objective values become uncertain as such the uncertainties from spatial input data propagate to the output of the optimization the pareto fronts objective space and the corresponding optimal spatial configurations solution space a quantification of the uncertainty in these two output dimensions would serve decision makers to assess the likelihood that their objectives are met for a point on the pareto front as well as how the optimal spatial configuration may vary at this point autuori et al 2016 wide ranges in the pareto fronts with low similarity in the optimal spatial configurations could serve as a warning while narrow ranges and high similarity in the spatial configurations bring confidence in the selection process for decision makers the question arises how the desired information of uncertainty in the optimization results can be obtained a method to analyze the propagation of uncertainties and errors from model inputs to model outputs is monte carlo simulation heuvelink 1998 in monte carlo simulation samples are randomly drawn from probability distributions of the input variables and for each sample the model is run to obtain an estimate of the uncertainty in the model output anderson 1976 monte carlo simulation can be applied to analyze the uncertainty in optimization outputs for example villa et al 2013 evaluate the objectives in a non spatial optimization with uncertain data with a monte carlo simulation to approximate lower and upper bounds of the uncertain pareto fronts here the monte carlo is implemented within the optimization i e interior sampling however when the constraint data are uncertain the lower and upper bounds can be hard or impossible to estimate homem de mello and bayraksan 2014 because the feasible regions in objective space become non convex ahmed and shapiro 2008 an exterior sampling method shapiro 2003 can be used to simulate both uncertain objective and constraint data where one sample is generated before the optimization starts and the optimization is performed with this samples by repeating the sampling and the optimization execution the probability distributions of the optimization outputs can be derived a limitation of the exterior sampling method is the high computational effort as it typically requires a high number of optimization executions and in multi objective spatial optimization the computational effort of one execution is often high uncertainty assessment in pareto fronts from multi objective spatial optimizations with a sampling procedure of uncertain constraint and objective evaluation data has not been researched yet possibly because of this high computational effort we aim to overcome this research gap with a method in which we first assess the uncertainty in computationally cheaper single objective evaluations and then use that information to produce pareto fronts of the multi objective optimization problem hereto we adapt an approach proposed by guariso and sangiorgio 2020 who solved single objective optima first and used those solutions as elite members in a multi objective optimization given that the single objective optimal solutions of the multi objective problem can be derived with a much lower computational effort we can cost effectively apply the exterior sampling method on the single objective optima to compute the uncertainty in the single points at the outer ends of the pareto fronts to extend the available information from the single objectives to the uncertainty in the pareto front we execute the multi objective optimization including the single objective optima with a method called seeding friedrich and wagner 2015 seeding entails that a part of the random initial solutions of the optimization is replaced by better solutions in our case the single objective optima in our proposed approach we seed the two samples from the uncertain input data that lead to the lower and upper bound extremes of the single objectives consecutively the resulting two pareto fronts are estimations of the lower and upper extremes of attainable pareto fronts in the objective space i e a pareto interval the total number of optimization executions is thus limited to the number objectives multiplied by two we use a multi objective land use allocation as a case study for the uncertainty assessment of multi objective spatial optimizations the following research questions are answered in this work 1 what is the effect of seeding single objective optima into the initial set of solutions on the multi objective land use allocation optimization 2 what is the effect of uncertain spatial input data on the width and shape of the pareto interval 3 what is effect of uncertain spatial input data on the optimal spatial configurations 2 methods 2 1 overview in this work we extend an existing multi objective land use allocation optimization under four objectives strauch et al 2019 with input data containing quantified uncertainties and methods to propagate this uncertainty to the objective and solution space fig 1 the first step is to construct the probability distributions of the spatial input data and then draw samples from these distributions section 2 3 fig 1a the second step is to use the two input data samples resulting in the lower and upper bound of the single objectives as input data for the multi objective spatial optimization furthermore the single objective optimal solutions are seeded into the first population of the optimization section 2 4 1 fig 1b finally the effect of uncertainty in the spatial input data on the width and shape of the pareto interval fig 1c and the similarity of solutions in the solution space is quantified and visualized section 2 4 2 2 2 optimization problem and algorithm in this study we build upon an existing land use allocation optimization comola that optimizes a land use raster under four objectives optionally under constraints strauch et al 2019 the optimization uses a multi objective genetic algorithm called non dominated sorting genetic algorithm ii nsga ii deb et al 2002 genetic algorithms mimic the natural competition within a population consisting of individuals by means of reproduction crossover and mutation of the individuals holland 1984 the decision variable of the optimization is the land use type of each grid cell where the possible land use types are pasture forest urban and cropland 1 5 representing five different levels of agricultural productivity to be in line with comola we use a synthetic initial land use raster of 10x10 cells the representation of an individual in the nsga ii is an array with land use patches fig 2 herein a patch is a set of contiguous cells with the same land use type each patch is assigned an identifier id two types of constraints are used land use transition constraints and area proportion constraints the land use transition constraints are urban areas can neither be extended nor removed forest can only be converted to pasture and pasture cannot be converted all other conversions are allowed the area proportion constraint was set to permitted ranges of 10 25 for forest and of 10 30 for pasture all other land use types have no area proportion constraints the four objectives are the maximization of forest species richness habitat heterogeneity water yield and crop yield they are explained below and their equations can be found in appendix a the species richness sr objective function bases on empirical relationships between habitat area and species richness from macarthur and wilson 1967 the number of grid cells of land use forest defines the objective value and the objective value is the sum of 5 times the forest area to the power of 0 2 an optimal valid solution for this objective is a map where the maximum area constraint of 25 forest is reached the worst solution has the minimum permitted area of 10 forest the habitat heterogeneity hh is the sum over edges between different land use types i e between patches edges have different weights a higher land use intensity leads to a lower habitat heterogeneity edges with forest pasture and cropland 1 have the lowest intensity and get a weight of 1 edges with cropland 2 5 have corresponding intensity weights of 2 5 edges with urban are ignored and therefore do not contribute to a higher habitat heterogeneity the optimal valid solution for this objective has the highest possible number of edges between forest pasture and cropland 1 obtainable under the maximum area constraints of 25 forest and 30 pasture the worst solution has 10 forest 10 pasture and 80 urban in three large patches the water yield wy objective function is based on the relative differences in evapotranspiration rates between land use types the total water yield is computed by summing all land use areas divided by the land use specific evapotranspiration rate the evapotranspiration rates are in increasing order cropland 1 0 900 cropland 2 0 925 cropland 3 0 950 pasture 0 960 cropland 4 0 975 cropland 5 1 00 forest 1 14 the optimal valid solution for this objective is found when the minimum area constraint of 10 forest and pasture are reached and the other 80 of the study area is cropland 1 the worst solution is composed by 25 forest 30 pasture and 45 cropland 5 crop yield cy is the sum of all logarithmic products of cropland intensity and soil fertility over all cells it is the only objective function for which a second spatial input data set is required a soil fertility map with values ranging from 0 1 to 1 the optimal valid solution for this objective is found when all permitted land use is transitioned into cropland 5 on the cells with the highest soil fertility value while the transition constraints are not violated 10 forest 10 pasture 80 cropland 5 the worst solution has no cropland at all 2 3 quantify uncertainty in input data and create samples and seeds 2 3 1 uncertainty in data for constraints the synthetic input land use map in comola strauch et al 2019 is the reference input land use map in this work given that no information about its accuracy is available we use overall land use class errors to construct the uncertainty in this map as explained in the following a measure to quantify uncertainty in land use classifications are confusion matrices fang et al 2006 confusion matrices indicate for every class how often a class was correctly classified as such how often a class was incorrectly assigned to another class commission error and how often a class was not classified as such omission error foody 2002 we assign omission errors to every cell as the probability to be reclassified on the basis of the land use type in the reference input land use map if the classification accuracy of land use a is high then the reclassification probability is low but if land use a was often incorrectly classified as land use b then the probability of reclassifying a cell of class b to a is accordingly high the confusion matrix of land cover data from globcover bicheron et al 2008 is used to derive the reclassification probabilities table 1 the optimization handles land use instead of land cover data which makes a mapping between land cover and land use classes necessary the mapping is displayed in appendix c table a1 the probabilities were computed by dividing the number of classifications by the row sum the reclassification of the grid cells on the basis the omission errors does not only influence the land use map but may also affect the patch id map fig 2 this happens when a cell in a patch is transitioned while the other cells in the patch are not or are transitioned to another land use type if the patch id map changes the array length changes accordingly 2 3 2 uncertainty in data for objective evaluations besides land use as an input for the objective evaluations see previous section for uncertainty estimation the objective crop yield is computed with additional spatial data a soil fertility map soil fertility or soil quality maps are typically derived by interpolating field samples point data of the physical chemical and biological properties of the soil klimkowicz pawlas et al 2019 soil quality estimations from interpolating points are uncertain and the spatial uncertainty depends on the spatial arrangement of samples hunsaker et al 2013 we simulate the uncertainty by synthetically positioning field samples on the original soil fertility map of comola and interpolating between them fig 3 a the geostatistical interpolation method kriging is used for interpolating the samples ismaili et al 2014 on a resolution 50 times finer than the original raster along with the expected values fig 3b kriging generates estimated variance map fig 3c wackernagel 1995 lastly we derive the average variance for each cell of the 10x10 cell extent of the study area fig 3d to obtain a sample of the soil fertility map we draw independent values for each cell from a gaussian distribution with the mean value from the reference soil fertility map and the standard deviation according to the variance map from the kriging its square root values above 1 are set to 1 and values below 0 are set to 0 to maintain the original value scale 2 3 3 sampling and seeding procedure in total 1000 samples are realized from the uncertain land use data section 2 3 1 and 1000 samples are realized from the uncertain soil fertility data section 2 3 1 the number 1000 was selected by iteratively assessing the maximum single objective values of the samples the optimal single objective value did not longer increase for any of the objectives after 410 iterations appendix b fig a1 that indicates that 1000 samples suffices to estimate the single objective extreme optimal solutions we compute the single objective optima for all samples hereto we use knowledge about the objective functions to compute the single objective optima deterministically the optimal land use configurations for every objective are derived by replacing land uses with the optimal land use per objective while meeting the area and transition constraints see section 2 2 the first step of the exterior sampling method is finished with the detection of the samples leading to the extreme lower and upper bounds of the single objectives the next step the execution of the optimization with the extreme lower and upper bound samples as spatial data inputs in addition for each execution of the optimization the four optimal single objective optimal solutions belonging to these inputs are seeded into the initial population of the multi objective genetic algorithm following the method of guariso and sangiorgio 2020 2 4 uncertainty assessment of pareto fronts from extreme samples 2 4 1 experimental design we execute the experiments with following different input data 1 with the reference data from strauch et al 2019 without quantified uncertainty and excluding the seeding procedure 2 with the reference data from strauch et al 2019 without quantified uncertainty and including the seeding procedure this experiment is meant to demonstrate the effect of the seeding only 3 ith the eight extreme lower and upper bound samples of the uncertain land use data and the original soil data and including the seeding procedure therefore the reference soil fertility map of comola and eight different land use maps are used as data input in eight optimizations this experiment is meant to demonstrate the effect of uncertainty in the initial land use data on the objective and solution space 4 with the extreme lower and upper bound samples of the soil data for objective crop yield and the original land use data and including the seeding procedure that means two different soil fertility maps and the reference land use map of comola are used as data inputs in two optimizations this experiment is meant to demonstrate the effect of uncertainty in the soil fertility data on the objective and solution space 5 with the extreme lower and upper bound samples of the combined uncertain soil and land use data for objective crop yield and including the seeding procedure each land use data sample is combined with each soil data sample two different soil fertility maps and two different land use map that lead to the extreme lower and upper bound crop yield values are used as data inputs in two optimizations this experiment is meant to demonstrate the effect of uncertainty in the initial land use data and soil fertility data together on the objective and solution space in total 13 different optimizations are executed each of these optimizations is executed 10 times to account for the stochasticity in nsga ii in line with comola we use a population size of 300 over 300 generations a crossover rate of 0 9 and a mutation rate of 1 divided by the number of spatial units of the individual which is the number of patches runs are performed in parallel on a high performance linux cluster megware cluster with 15 120 cores 412 nodes and intel xeon gold 6140 18c 2 30 ghz processors 2 4 2 quantification and visualization of uncertainty in the pareto fronts the resulting pareto front from each optimization has four dimensions as four objectives are optimized we use a scatter plot matrix which illustrates the position of the objective values in a 2d scatter plot for each combination of objectives ibrahim et al 2016 in the plots we show the lower bound front the upper bound front and the pareto front from reference data reference front to illustrate the pareto interval resulting from the uncertain data we plot convex hulls between the three fig 4 a the plot s axes are normalized to the range from 0 to 1 to show the relative influence of the uncertainty for each objective herein where 0 is the worst objective value and 1 is the best objective value of the reference pareto front for quantifying and visualizing the difference between the resulting spatial configurations of the non dominated solutions the kappa statistic is used as a metric of similarity between the land use maps kappa has a range from 1 all cell values differ to 1 all cells values cohere monserud and leemans 1992 for each non dominated solution obtained from the optimization without quantified uncertainty fig 4a black point the closest non dominated solution in the objective space is selected from each of the two pareto fronts obtained with the extreme lower and upper bound samples respectively figs 4a 5 6 red and green point for the two pairs the kappa statistic is calculated and averaged over the pairs fig 4b the non dominated solutions from the optimization without quantified uncertainty are then colored according these average kappa values to visualize the level of agreement in spatial configuration the solution space for each part of the pareto front 3 results and discussion 3 1 reference data input with and without seeding the experiments 1 and 2 sec 2 4 1 are compared to assess the effect of the seeding the pareto front of habitat heterogeneity against crop yield obtained with the seeding procedure has a wider spread of solutions in the objective space than the pareto front obtained without seeding fig 5 furthermore the optimal solutions of the optimization with seeding dominate the optimal solutions obtained without seeding after 300 generations fig 5 the extreme values are 7 better for habitat heterogeneity and 10 better for crop yield for the other two objectives not shown in fig 5 the improvements 9 water yield or the same optimal objective values were obtained species richness finally the optimization with seeding leads to faster conversion this is for example illustrated by the fact that the pareto front obtained with seeding in the 200th generation already dominates the pareto front in the 300th generation without seeding for a crop yield of 85 fig 5 it can be concluded that the seeding has positive effects on the quality of solutions in the pareto fronts as was also concluded by friedrich and wagner 2015 for a non spatial optimization the high quality of the pareto front after 200 generations is in line with their finding that seeding lowers the computational demand of an optimization our observation of the wider spread of solutions in the objective space also support the finding from guariso and sangiorgio 2020 that injecting single objective optimal solutions as seeds into the initial population leads to a better covered objective space in sum our results support the application of the seeding for uncertainty analysis in the pareto fronts 3 2 probability distributions of the sampled single objective optima the probability distributions of the optimal single objective values fig 6 a d of habitat heterogeneity fig 6a water yield fig 6c and crop yield fig 6d from the samples of the uncertain land use data resemble normal distributions the optimal objective values of habitat heterogeneity and water yield from the reference land use data are close to the mean of the probability distributions so roughly half of the samples lead to better objective values and the other half to worse objective values in contrast 97 objective values of crop yield from the samples are worse than the objective value from the reference data the unbalance is caused by the misclassification probabilities in the confusion matrix on average the land use types contributing to the objective crop yield cropland 1 5 were more frequently wrongly classified as such than land use types not contributing to the objective crop yield especially cropland 1 2 and 3 table 1 as a consequence fewer cropland cells than non cropland cells are expected in the samples because they are more often reclassified to forest pasture and urban than vice versa the objective values for species richness are in contrast to those of other objectives not uncertain this is directly linked to the maximum allowed amount of land use type forest the optimal species richness for a land use map with 25 forest cells is 9 51 and this 25 can not be exceeded due to the predefined area constraints the reason for no values below 9 51 is again related to the confusion matrix table 1 the species richness can only be lower if more than 75 of all cells were reclassified to land use types that cannot be converted to forest defined in transition constraints the only land use types that cannot be converted to forest are pasture and urban samples with more than 75 of either pasture or urban are theoretically possible but highly unlikely given the probabilities in the confusion matrix the distribution of crop yield values with the reference land use data but with the uncertain soil data fig 6e is with a range 4 70 narrower than the distribution from uncertain land use data with a range of 45 3 most samples are equal or close to the crop yield objective value obtained with the original soil data without quantified uncertainty the combined uncertain data for the objective crop yield result in the widest range of 52 4 the combination of 1000 uncertain land use and soil data samples also results in a smoother frequency distribution the reason for the smoother distribution is the higher sample size of 1 million 1000 1000 combinations the ranges indicate that the uncertain land use data have a higher impact on the objective value crop yield than the uncertain soil data this is because a reclassification from cropland to non cropland reduces the crop yield to zero on the other hand the errors in the soil fertility map are likely to still allow crop production even when the soil fertility is reduced in a comparison of set ups with different strengths of the constraints strauch et al 2019 found that constraints limited the attainable optimal solutions for example higher area constraints lead to a narrower pareto front in our case the area constraints remain the same but the strength of the transition constraints varies with every sample because the amount and position of cells that underlay the transition constraints differ our results show that uncertain spatial input data affects the objective space limitation in land use allocation optimizations when transition constraints are defined the objective space limitations are not only affected by the definition of what land use types underlay transition constraints but also by the quantified uncertainty in the land use data inputs furthermore the probability distribution of the optimal single objective solutions for the objective species richness lead to the conclusion that a strong constraint can cancel out the effect of other sources of uncertainty 3 3 uncertainty in the objective space the third experiment with the extreme lower and upper extreme samples of uncertain land use data sec 2 4 1 resulted in pareto intervals with diverse shapes rotations and areas those geometric properties of the pareto intervals allow to assess both information about the trade offs between objectives and the uncertainty they could be categorized into 1 non conflicting objectives pareto fronts containing one single point become horizontal or vertical lines when one objective is uncertain or rectangular pareto intervals when both are uncertain but this situation is not observed in our results 2 conflicting objectives non horizontal and non vertical pareto fronts become non horizontal and non vertical pareto intervals the two objectives habitat heterogeneity and species richness represent category 1 non conflicting objectives the synergy between the objectives is explained by the common property that maximum number of forest cells is optimal with uncertain spatial input data the species richness remains constant over the experiments while the habitat heterogeneity varies fig 7 row 2 column 1 it was possible in all cases to produce a solution with a maximum habitat heterogeneity that also has the maximum allowed 25 forest cells and thus maximum species richness all other objective pairs fall into the second category conflicting objectives with uncertain spatial input data the lines become intervals where the width of the interval increases with the uncertainty the angle of the pareto fronts with conflicting objectives how much the values of one objective decrease with a certain increase in another objective i e the trade off between the two objectives the area of the pareto interval is therefore affected by the uncertainty in the objective values and the trade off in some cases the angles of the pareto fronts i e the trade offs between the objectives remain equal regardless of the uncertain input data e g for the pairs water yield habitat heterogeneity fig 7 row 3 column 1 and crop yield habitat heterogeneity fig 7 row 4 column 1 here all extreme lower and upper bound samples resulted in similarly shaped pareto fronts where mainly the positions of the fronts change for other objective pairs the trade offs change because of the uncertainty in the spatial input data e g for the objective pair water yield species richness fig 7 row 3 column 2 the pareto fronts obtained with the lower and upper extreme samples consist of two optima while the reference pareto front consists of eight optima the reason for the different number of feasible optimal solutions in the pareto fronts is the different number of transition constrained cells in the uncertain land use data the more transition constrained cells exist the lower the possible number of optimal land use allocations the fourth experiment with uncertain soil data only sec 2 4 1 results in pareto intervals with a width of only 7 1 in the x dimension and 5 5 in the y dimension of the pareto intervals from uncertain land use data only averaged over all three objective pairs in row 4 in fig 7 in the objective pair crop yield habitat heterogeneity and crop yield water yield fig 7 row 4 column 1 the pareto intervals constantly enclose the reference pareto fronts over the whole range of the objective space in line with the assessment of uncertain objective evaluation data by bassi et al 2018 only in the objective pair crop yield species richness fig 7 row 4 column 2 a small part of the reference pareto front is not enclosed by the pareto interval we believe that this is an artifact of the stochasticity in the optimization algorithm the pareto intervals from the fifth experiment with the combined uncertain data inputs sec 2 4 1 are displayed in the last row of fig 7 for the objective pair water yield crop yield fig 7 row 4 column 3 the pareto interval has a similar shape and the interval is 2 wider than the pareto interval from the uncertain land use data only in the objective pair species richness crop yield fig 7 row 4 column 2 the combined uncertain data inputs lead to a 24 wider range between the extreme points compared to pareto interval from the uncertain land use data only the objective pair habitat heterogeneity crop yield fig 7 row 4 column 1 resulted in a pareto interval with a range that increases with increasing crop yield values the cone shape can be explained by the increasing influence of soil fertility and thus its uncertainty with an increasing crop production on the other side of the pareto front low crop yield a high amount of forest and pasture is present because these land uses improve habitat heterogeneity these land use types can not be converted into cropland which diminishes the effect of the soil fertility on the pareto front in our results not all shapes of the pareto fronts from uncertain land use and combined uncertain land use and soil data resemble each other which is in contrast with the findings about uncertain objective evaluation data by bassi et al 2018 this is caused by non convex feasible objective space homem de mello and bayraksan 2014 that is introduced by the uncertain land use maps in combination with the land use transition constraints the selected maps in fig 8 highlighted in fig 7 illustrate the reason for the non convex feasible space one common factor that determines the interval between the pareto fronts is the number of urban cells because urban cells do not contribute to any of the objectives and can not be transformed into another land use so more urban cells lead to worse objective values e g the three examples from the upper bound pareto fronts green in fig 8 have a low amount of urban land with 5 3 and 4 while the lower bound pareto front red all have 15 urban land the reason for the different number of cells in the upper bound pareto fronts is that not only the amount of land use is of importance but also the location the uncertainty in the uncertain land use data led to samples in which both the amount and the location of cells benefiting the objective limit the feasible objective space leading to the non convex feasible objective space under uncertainty the uncertainty in the amount and location of urban cells is thus a strong determinant of output uncertainty validating urban areas can therefore help to reduce uncertainty in all pairwise pareto fronts ancillary data can be used to increase the accuracy of 75 in urban area classifications table 1 for example existing maps defining the outlines of urban areas corbane et al 2021 3 4 uncertainty in the solution space the average kappa values as well as the variation in kappa values differ per objective pair fig 7 all pareto fronts containing habitat heterogeneity have relatively low kappa values fig 7 in addition the solutions with a higher habitat heterogeneity have increasingly low kappa values this is because habitat heterogeneity is computed by summing up heterogeneous land use edges independent of the specific land use type while the kappa statistic compares the land use type in the cells for example if kappa was computed between a land use map and the transposed version of this map the kappa value would likely be low but the habitat heterogeneity would remain the same as only the number of edges counts in the pareto front between species richness and water yield all kappa values are similar with a range of only 0 08 while the kappa values of the pareto fronts between species richness and crop yield and water yield and crop yield have ranges of 0 21 and 0 3 respectively high kappa values indicate a high robustness in the solution space fig 9 the solutions with a high kappa fig 9 upper row have more spatial characteristics in common between the uncertain solutions than the ones with a low kappa fig 9 upper row for example in the high kappa spatial configurations the north and east are dominated by cropland 1 with few patches of forest or pasture while the south and east contain more forest the spatial configurations with a low kappa value fig 9 upper row have fewer characteristics in common even though the objective values vary less than 0 5 this variation in the solution space is crucial for decision makers as land use is their decision variable input data uncertainty becomes most problematic when it causes unclarity in the characteristics of the optimal spatial configuration for the selected point at the pareto front the solution space uncertainty computed here can serve as an incentive to select a different more robust compromise solution 3 5 limitations and future work we were able to approximate the uncertainty in the pareto fronts with highly reduced computational effort compared to a full monte carlo a full monte carlo with the selected sample size of 1000 would require 1000 executions of the optimization the computational effort was reduced by 98 7 to 13 executions the additional computation time to compute the objective value is only 10 of a single optimization execution time the main limitation of our work is that the distribution and shape of pareto fronts between the two extremes remain unknown hereby we miss information about how uncertain land use data that affects the land use transition constraints may lead to irregular infeasible regions homem de mello and bayraksan 2014 that missing information is the trade off between the highly reduced computation time and available information about the propagation of input data uncertainty another trade off from not performing an optimization for all samples is that there is no guarantee that the data samples resulting in the extreme single objective values lead to the widest pareto interval it is possible that other samples result in more extreme pareto front sections in the center i e away from the single objective optima moreover the amount of uncertainty in our case study was based on empirical data but fixed we did not investigate the effect of varying amounts of uncertainty in the spatial input data on the pareto fronts in future work this may be assessed for example by means of a sensitivity analysis furthermore our visualization of uncertainty in the pareto fronts is shown in separate scatter plots in a matrix containing all pairwise pareto fronts as such the uncertainty distribution over the whole objective space is not directly observable part of possible future work is incorporating both the extreme intervals and the similarity metric with all objectives in one single visualization for example with the multi objective visualization method of 3d radvis ibrahim et al 2016 yet it should then be tested whether this amount of information in one plot is still understandable senaratne et al 2012 lastly a real world case study of a spatial optimization is important future work such application will also allow comparing the propagation of uncertainty from different data sources to the optimization outputs 4 conclusion in this work we used seeding of optimal solutions in combination with an exterior sampling method to estimate the propagation of uncertainty from spatial input data to the results of a multi objective spatial optimization this approach allowed to reduce the computation time by 98 7 compared to a full monte carlo the approach was demonstrated on a land use allocation optimization with uncertain constraint and objective evaluation data our first research question was what is the effect of seeding single objective optima into the initial set of solutions on the multi objective land use allocation optimization the optimization with the seeding procedure resulted in pareto fronts with 6 25 better objective values averaged over all four objectives compared to the optimization without seeding furthermore the optimization with seeding produced solutions with the same quality in shorter time after 200 generations the pareto front from the optimization with seeding dominated the pareto front without the seeding procedure after 300 generations our second research question was what is the effect of uncertain spatial input data on the width and shape of the pareto interval we found two types of shapes 1 a horizontal or vertical line which was obtained between two non conflicting objective of which one was affected by the uncertainty in input data and 2 a non horizontal and non vertical pareto intervals which was obtained between two conflicting objective of which at least one was affected by the uncertainty in input data in our case study the uncertain initial land use data had by far the highest effect on the width and shape of the pareto intervals the uncertain soil fertility data led to ranges in the pareto intervals that were 6 of the ranges from uncertain land use data in the two objective pairs affected by both inputs the combined pareto intervals were 2 and 24 wider compared to the pareto intervals from uncertain land use data only furthermore in line with previous research on uncertainty in non spatial optimizations we found that uncertain soil fertility data used for computing objective values resulted in regular pareto intervals while uncertain land use data that affects the transition constraints resulted in irregular pareto intervals our third research question was what is the effect of uncertain spatial input data on the optimal spatial configurations given that the number and location of urban cells in the input land use map affected the ranges of all pairwise pareto fronts we conclude that increasing the classification accuracy of urban land is an option to reduce uncertainty for example by using auxiliary data furthermore trends of the kappa values could be observed within the single pareto fronts the pareto front of the objective pair species richness and water yield had comparatively high kappa values whereas the pareto fronts containing habitat heterogeneity had comparatively low kappa values respective to the other objective pairs the solution space uncertainty computed here can serve as an incentive to select compromise solutions that are robust to uncertainty in the spatial input data software and data availability the dataset sampling procedure of land use and soil fertility map under uncertainty is available at hildemann 2021b the dataset contains the input data the python code and the output data along with a description and steps to reproduce developer m hildemann first author see contact details at first page year first available 2021 running the sampling procedure requires python version 3 8 with numpy 1 20 1 pandas 1 2 3 plotting requires seaborn 0 11 1 scipy 1 6 2 and matplotlib 3 3 4 the software is free the dataset algorithm for constrained multi objective land use allocation optimization under uncertainty is available at hildemann 2021a the dataset contains a description the program files and the steps to reproduce we reused and extended the python software comola developed by strauch et al 2019 which is available at https github com michstrauch comola we included a seeding procedure and adapted the program for the uncertainty propagation analysis developer m hildemann first author see contact details at first page year first available 2021 the optimization was executed on a megware cluster with 15 120 cores 412 nodes and intel xeon gold 6140 18c 2 30 ghz processors with the freely available python 3 7 2 software in a linux environment with the modules numpy 1 19 1 pandas 1 2 3 and pickle 12 1 credit authorship contribution statement moritz hildemann conceptualization methodology software judith a verstegen conceptualization writing review editing supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a objective functions 1 s r 5 a f 0 2 where a f area of forest 2 h h i 1 5 h h e i e i i where e number of edges i edge intensity 3 w y c 1 7 w y a c a k c k c where k c evaporation rate a k c area of land use with evatransporation rate k c 4 c y i 1 i c y i l o g p i 1 f i where p i crop production intensity f soil fertility appendix b progression of objective values in monte carlo simulation fig a1 progression of best achieved objective values normalized in the sampling process of the uncertain land use data fig a1 appendix c mapping between land cover and land use in general land covers dominated by cropland or vegetation is assumed to be used as cropland forest dominated land covers are mapped to the land use forest shrubland and grassland dominated land cover are mapped to pasture and artificial surfaces and bare areas as urban area 19 land covers are mapped to 7 land uses therefore some closes of the original confusion matrix from globcover bicheron et al 2008 are aggregated for example globcover land cover classes 40 110 correspond to the land use forest after the class aggregation in mapping land covers to land uses it is not a misclassification if e g land cover class 40 was classified as land cover class 100 it counts as an error if a land use forest land cover classes 40 100 was misclassified as urban land cover classes 190 200 or one of the other land uses table a1 mapping land cover to land use classes table a1 gc class gc label land use label id 11 post flooding or irrigated croplands cropland intensity 5 5 14 rainfed croplands cropland intensity 4 4 20 mosaic cropland 50 70 vegetation grassland shrubland forest 20 50 cropland intensity 3 3 20 mosaic cropland 50 70 vegetation grassland shrubland forest 20 50 cropland intensity 2 2 30 mosaic vegetation grassland shrubland forest 50 70 cropland 20 50 cropland intensity 1 1 30 natural and semi natural primarily terrestrial vegetation cultivated and managed terrestrial areas cropland intensity 1 1 40 closed to open 15 broadleaved evergreen and or semi deciduous forest 5 m forest 6 50 closed 40 broadleaved deciduous forest 5 m forest 6 60 open 15 40 broadleaved deciduous forest 5 m forest 6 70 closed 40 needle leaved evergreen forest 5 m forest 6 90 open 15 40 needle leaved deciduous or evergreen forest 5 m forest 6 100 closed to open 15 mixed broadleaved and needle leaved forest 5 m forest 6 110 mosaic forest shrubland 50 70 grassland 20 50 pasture 7 120 mosaic grassland 50 70 forest shrubland 20 50 pasture 7 130 closed to open 15 shrubland 5 m pasture 7 140 closed to open 15 grassland pasture 7 150 sparse 15 vegetation woody vegetation shrubs grassland pasture 7 190 artificial surfaces and associated areas urban areas 50 urban area 8 200 bare areas urban area 8 
25829,multi objective spatial optimization problems require spatial data input that can contain uncertainties via the validation of constraints and the computation of objective values this uncertainty propagates to the pareto fronts here we develop a method to quantify the uncertainty in pareto fronts by finding the extreme lower and upper bound of the range of optimal values in the objective space i e the pareto interval the method is demonstrated on a land use allocation problem with initial land use for objectives and constraints and soil fertility for one objective as uncertain input data pareto intervals resulting from uncertain land use data were wide and irregularly shaped whereas the ones from uncertain soil data were narrow and regularly shaped furthermore in some objective space regions optimal land use patterns remained relatively stable under uncertainty while elsewhere they were clouded this information can be used to select solutions robust to spatial input data uncertainty graphical abstract image 1 keywords spatial optimization land use allocation uncertain spatial data uncertain pareto fronts seeding 1 introduction spatial optimization covers a range of approaches to find configurations of space that are optimal given one or more decision variables one or more objectives and one or more constraints cao 2018 most spatial optimization problems involve multiple conflicting objectives such as minimizing production costs while minimizing green house gas emissions verstegen et al 2017 or minimizing the travel time to hospitals while minimizing the costs involved in building new hospitals luo et al 2017 in such cases the spatial optimization does not result in a single optimal spatial configuration but instead in a set of spatial configurations called the non dominated solutions these configurations can all be considered optimal but represent trade offs between the conflicting objectives e g high crop yield with high water usage or the other way around when plotted in the objective space i e plotting the values of the objective functions for these non dominated solutions they together form the pareto front the spatial input data to an optimization problem may be uncertain the sources of uncertainty are diverse the data can contain errors vagueness or ambiguity fisher et al 2006 these uncertainties lead to arbitrarity in whether or not a solution is non dominated for two reasons firstly the validation of the feasibility of solutions with the defined constraints may become uncertain secondly the computed objective values become uncertain as such the uncertainties from spatial input data propagate to the output of the optimization the pareto fronts objective space and the corresponding optimal spatial configurations solution space a quantification of the uncertainty in these two output dimensions would serve decision makers to assess the likelihood that their objectives are met for a point on the pareto front as well as how the optimal spatial configuration may vary at this point autuori et al 2016 wide ranges in the pareto fronts with low similarity in the optimal spatial configurations could serve as a warning while narrow ranges and high similarity in the spatial configurations bring confidence in the selection process for decision makers the question arises how the desired information of uncertainty in the optimization results can be obtained a method to analyze the propagation of uncertainties and errors from model inputs to model outputs is monte carlo simulation heuvelink 1998 in monte carlo simulation samples are randomly drawn from probability distributions of the input variables and for each sample the model is run to obtain an estimate of the uncertainty in the model output anderson 1976 monte carlo simulation can be applied to analyze the uncertainty in optimization outputs for example villa et al 2013 evaluate the objectives in a non spatial optimization with uncertain data with a monte carlo simulation to approximate lower and upper bounds of the uncertain pareto fronts here the monte carlo is implemented within the optimization i e interior sampling however when the constraint data are uncertain the lower and upper bounds can be hard or impossible to estimate homem de mello and bayraksan 2014 because the feasible regions in objective space become non convex ahmed and shapiro 2008 an exterior sampling method shapiro 2003 can be used to simulate both uncertain objective and constraint data where one sample is generated before the optimization starts and the optimization is performed with this samples by repeating the sampling and the optimization execution the probability distributions of the optimization outputs can be derived a limitation of the exterior sampling method is the high computational effort as it typically requires a high number of optimization executions and in multi objective spatial optimization the computational effort of one execution is often high uncertainty assessment in pareto fronts from multi objective spatial optimizations with a sampling procedure of uncertain constraint and objective evaluation data has not been researched yet possibly because of this high computational effort we aim to overcome this research gap with a method in which we first assess the uncertainty in computationally cheaper single objective evaluations and then use that information to produce pareto fronts of the multi objective optimization problem hereto we adapt an approach proposed by guariso and sangiorgio 2020 who solved single objective optima first and used those solutions as elite members in a multi objective optimization given that the single objective optimal solutions of the multi objective problem can be derived with a much lower computational effort we can cost effectively apply the exterior sampling method on the single objective optima to compute the uncertainty in the single points at the outer ends of the pareto fronts to extend the available information from the single objectives to the uncertainty in the pareto front we execute the multi objective optimization including the single objective optima with a method called seeding friedrich and wagner 2015 seeding entails that a part of the random initial solutions of the optimization is replaced by better solutions in our case the single objective optima in our proposed approach we seed the two samples from the uncertain input data that lead to the lower and upper bound extremes of the single objectives consecutively the resulting two pareto fronts are estimations of the lower and upper extremes of attainable pareto fronts in the objective space i e a pareto interval the total number of optimization executions is thus limited to the number objectives multiplied by two we use a multi objective land use allocation as a case study for the uncertainty assessment of multi objective spatial optimizations the following research questions are answered in this work 1 what is the effect of seeding single objective optima into the initial set of solutions on the multi objective land use allocation optimization 2 what is the effect of uncertain spatial input data on the width and shape of the pareto interval 3 what is effect of uncertain spatial input data on the optimal spatial configurations 2 methods 2 1 overview in this work we extend an existing multi objective land use allocation optimization under four objectives strauch et al 2019 with input data containing quantified uncertainties and methods to propagate this uncertainty to the objective and solution space fig 1 the first step is to construct the probability distributions of the spatial input data and then draw samples from these distributions section 2 3 fig 1a the second step is to use the two input data samples resulting in the lower and upper bound of the single objectives as input data for the multi objective spatial optimization furthermore the single objective optimal solutions are seeded into the first population of the optimization section 2 4 1 fig 1b finally the effect of uncertainty in the spatial input data on the width and shape of the pareto interval fig 1c and the similarity of solutions in the solution space is quantified and visualized section 2 4 2 2 2 optimization problem and algorithm in this study we build upon an existing land use allocation optimization comola that optimizes a land use raster under four objectives optionally under constraints strauch et al 2019 the optimization uses a multi objective genetic algorithm called non dominated sorting genetic algorithm ii nsga ii deb et al 2002 genetic algorithms mimic the natural competition within a population consisting of individuals by means of reproduction crossover and mutation of the individuals holland 1984 the decision variable of the optimization is the land use type of each grid cell where the possible land use types are pasture forest urban and cropland 1 5 representing five different levels of agricultural productivity to be in line with comola we use a synthetic initial land use raster of 10x10 cells the representation of an individual in the nsga ii is an array with land use patches fig 2 herein a patch is a set of contiguous cells with the same land use type each patch is assigned an identifier id two types of constraints are used land use transition constraints and area proportion constraints the land use transition constraints are urban areas can neither be extended nor removed forest can only be converted to pasture and pasture cannot be converted all other conversions are allowed the area proportion constraint was set to permitted ranges of 10 25 for forest and of 10 30 for pasture all other land use types have no area proportion constraints the four objectives are the maximization of forest species richness habitat heterogeneity water yield and crop yield they are explained below and their equations can be found in appendix a the species richness sr objective function bases on empirical relationships between habitat area and species richness from macarthur and wilson 1967 the number of grid cells of land use forest defines the objective value and the objective value is the sum of 5 times the forest area to the power of 0 2 an optimal valid solution for this objective is a map where the maximum area constraint of 25 forest is reached the worst solution has the minimum permitted area of 10 forest the habitat heterogeneity hh is the sum over edges between different land use types i e between patches edges have different weights a higher land use intensity leads to a lower habitat heterogeneity edges with forest pasture and cropland 1 have the lowest intensity and get a weight of 1 edges with cropland 2 5 have corresponding intensity weights of 2 5 edges with urban are ignored and therefore do not contribute to a higher habitat heterogeneity the optimal valid solution for this objective has the highest possible number of edges between forest pasture and cropland 1 obtainable under the maximum area constraints of 25 forest and 30 pasture the worst solution has 10 forest 10 pasture and 80 urban in three large patches the water yield wy objective function is based on the relative differences in evapotranspiration rates between land use types the total water yield is computed by summing all land use areas divided by the land use specific evapotranspiration rate the evapotranspiration rates are in increasing order cropland 1 0 900 cropland 2 0 925 cropland 3 0 950 pasture 0 960 cropland 4 0 975 cropland 5 1 00 forest 1 14 the optimal valid solution for this objective is found when the minimum area constraint of 10 forest and pasture are reached and the other 80 of the study area is cropland 1 the worst solution is composed by 25 forest 30 pasture and 45 cropland 5 crop yield cy is the sum of all logarithmic products of cropland intensity and soil fertility over all cells it is the only objective function for which a second spatial input data set is required a soil fertility map with values ranging from 0 1 to 1 the optimal valid solution for this objective is found when all permitted land use is transitioned into cropland 5 on the cells with the highest soil fertility value while the transition constraints are not violated 10 forest 10 pasture 80 cropland 5 the worst solution has no cropland at all 2 3 quantify uncertainty in input data and create samples and seeds 2 3 1 uncertainty in data for constraints the synthetic input land use map in comola strauch et al 2019 is the reference input land use map in this work given that no information about its accuracy is available we use overall land use class errors to construct the uncertainty in this map as explained in the following a measure to quantify uncertainty in land use classifications are confusion matrices fang et al 2006 confusion matrices indicate for every class how often a class was correctly classified as such how often a class was incorrectly assigned to another class commission error and how often a class was not classified as such omission error foody 2002 we assign omission errors to every cell as the probability to be reclassified on the basis of the land use type in the reference input land use map if the classification accuracy of land use a is high then the reclassification probability is low but if land use a was often incorrectly classified as land use b then the probability of reclassifying a cell of class b to a is accordingly high the confusion matrix of land cover data from globcover bicheron et al 2008 is used to derive the reclassification probabilities table 1 the optimization handles land use instead of land cover data which makes a mapping between land cover and land use classes necessary the mapping is displayed in appendix c table a1 the probabilities were computed by dividing the number of classifications by the row sum the reclassification of the grid cells on the basis the omission errors does not only influence the land use map but may also affect the patch id map fig 2 this happens when a cell in a patch is transitioned while the other cells in the patch are not or are transitioned to another land use type if the patch id map changes the array length changes accordingly 2 3 2 uncertainty in data for objective evaluations besides land use as an input for the objective evaluations see previous section for uncertainty estimation the objective crop yield is computed with additional spatial data a soil fertility map soil fertility or soil quality maps are typically derived by interpolating field samples point data of the physical chemical and biological properties of the soil klimkowicz pawlas et al 2019 soil quality estimations from interpolating points are uncertain and the spatial uncertainty depends on the spatial arrangement of samples hunsaker et al 2013 we simulate the uncertainty by synthetically positioning field samples on the original soil fertility map of comola and interpolating between them fig 3 a the geostatistical interpolation method kriging is used for interpolating the samples ismaili et al 2014 on a resolution 50 times finer than the original raster along with the expected values fig 3b kriging generates estimated variance map fig 3c wackernagel 1995 lastly we derive the average variance for each cell of the 10x10 cell extent of the study area fig 3d to obtain a sample of the soil fertility map we draw independent values for each cell from a gaussian distribution with the mean value from the reference soil fertility map and the standard deviation according to the variance map from the kriging its square root values above 1 are set to 1 and values below 0 are set to 0 to maintain the original value scale 2 3 3 sampling and seeding procedure in total 1000 samples are realized from the uncertain land use data section 2 3 1 and 1000 samples are realized from the uncertain soil fertility data section 2 3 1 the number 1000 was selected by iteratively assessing the maximum single objective values of the samples the optimal single objective value did not longer increase for any of the objectives after 410 iterations appendix b fig a1 that indicates that 1000 samples suffices to estimate the single objective extreme optimal solutions we compute the single objective optima for all samples hereto we use knowledge about the objective functions to compute the single objective optima deterministically the optimal land use configurations for every objective are derived by replacing land uses with the optimal land use per objective while meeting the area and transition constraints see section 2 2 the first step of the exterior sampling method is finished with the detection of the samples leading to the extreme lower and upper bounds of the single objectives the next step the execution of the optimization with the extreme lower and upper bound samples as spatial data inputs in addition for each execution of the optimization the four optimal single objective optimal solutions belonging to these inputs are seeded into the initial population of the multi objective genetic algorithm following the method of guariso and sangiorgio 2020 2 4 uncertainty assessment of pareto fronts from extreme samples 2 4 1 experimental design we execute the experiments with following different input data 1 with the reference data from strauch et al 2019 without quantified uncertainty and excluding the seeding procedure 2 with the reference data from strauch et al 2019 without quantified uncertainty and including the seeding procedure this experiment is meant to demonstrate the effect of the seeding only 3 ith the eight extreme lower and upper bound samples of the uncertain land use data and the original soil data and including the seeding procedure therefore the reference soil fertility map of comola and eight different land use maps are used as data input in eight optimizations this experiment is meant to demonstrate the effect of uncertainty in the initial land use data on the objective and solution space 4 with the extreme lower and upper bound samples of the soil data for objective crop yield and the original land use data and including the seeding procedure that means two different soil fertility maps and the reference land use map of comola are used as data inputs in two optimizations this experiment is meant to demonstrate the effect of uncertainty in the soil fertility data on the objective and solution space 5 with the extreme lower and upper bound samples of the combined uncertain soil and land use data for objective crop yield and including the seeding procedure each land use data sample is combined with each soil data sample two different soil fertility maps and two different land use map that lead to the extreme lower and upper bound crop yield values are used as data inputs in two optimizations this experiment is meant to demonstrate the effect of uncertainty in the initial land use data and soil fertility data together on the objective and solution space in total 13 different optimizations are executed each of these optimizations is executed 10 times to account for the stochasticity in nsga ii in line with comola we use a population size of 300 over 300 generations a crossover rate of 0 9 and a mutation rate of 1 divided by the number of spatial units of the individual which is the number of patches runs are performed in parallel on a high performance linux cluster megware cluster with 15 120 cores 412 nodes and intel xeon gold 6140 18c 2 30 ghz processors 2 4 2 quantification and visualization of uncertainty in the pareto fronts the resulting pareto front from each optimization has four dimensions as four objectives are optimized we use a scatter plot matrix which illustrates the position of the objective values in a 2d scatter plot for each combination of objectives ibrahim et al 2016 in the plots we show the lower bound front the upper bound front and the pareto front from reference data reference front to illustrate the pareto interval resulting from the uncertain data we plot convex hulls between the three fig 4 a the plot s axes are normalized to the range from 0 to 1 to show the relative influence of the uncertainty for each objective herein where 0 is the worst objective value and 1 is the best objective value of the reference pareto front for quantifying and visualizing the difference between the resulting spatial configurations of the non dominated solutions the kappa statistic is used as a metric of similarity between the land use maps kappa has a range from 1 all cell values differ to 1 all cells values cohere monserud and leemans 1992 for each non dominated solution obtained from the optimization without quantified uncertainty fig 4a black point the closest non dominated solution in the objective space is selected from each of the two pareto fronts obtained with the extreme lower and upper bound samples respectively figs 4a 5 6 red and green point for the two pairs the kappa statistic is calculated and averaged over the pairs fig 4b the non dominated solutions from the optimization without quantified uncertainty are then colored according these average kappa values to visualize the level of agreement in spatial configuration the solution space for each part of the pareto front 3 results and discussion 3 1 reference data input with and without seeding the experiments 1 and 2 sec 2 4 1 are compared to assess the effect of the seeding the pareto front of habitat heterogeneity against crop yield obtained with the seeding procedure has a wider spread of solutions in the objective space than the pareto front obtained without seeding fig 5 furthermore the optimal solutions of the optimization with seeding dominate the optimal solutions obtained without seeding after 300 generations fig 5 the extreme values are 7 better for habitat heterogeneity and 10 better for crop yield for the other two objectives not shown in fig 5 the improvements 9 water yield or the same optimal objective values were obtained species richness finally the optimization with seeding leads to faster conversion this is for example illustrated by the fact that the pareto front obtained with seeding in the 200th generation already dominates the pareto front in the 300th generation without seeding for a crop yield of 85 fig 5 it can be concluded that the seeding has positive effects on the quality of solutions in the pareto fronts as was also concluded by friedrich and wagner 2015 for a non spatial optimization the high quality of the pareto front after 200 generations is in line with their finding that seeding lowers the computational demand of an optimization our observation of the wider spread of solutions in the objective space also support the finding from guariso and sangiorgio 2020 that injecting single objective optimal solutions as seeds into the initial population leads to a better covered objective space in sum our results support the application of the seeding for uncertainty analysis in the pareto fronts 3 2 probability distributions of the sampled single objective optima the probability distributions of the optimal single objective values fig 6 a d of habitat heterogeneity fig 6a water yield fig 6c and crop yield fig 6d from the samples of the uncertain land use data resemble normal distributions the optimal objective values of habitat heterogeneity and water yield from the reference land use data are close to the mean of the probability distributions so roughly half of the samples lead to better objective values and the other half to worse objective values in contrast 97 objective values of crop yield from the samples are worse than the objective value from the reference data the unbalance is caused by the misclassification probabilities in the confusion matrix on average the land use types contributing to the objective crop yield cropland 1 5 were more frequently wrongly classified as such than land use types not contributing to the objective crop yield especially cropland 1 2 and 3 table 1 as a consequence fewer cropland cells than non cropland cells are expected in the samples because they are more often reclassified to forest pasture and urban than vice versa the objective values for species richness are in contrast to those of other objectives not uncertain this is directly linked to the maximum allowed amount of land use type forest the optimal species richness for a land use map with 25 forest cells is 9 51 and this 25 can not be exceeded due to the predefined area constraints the reason for no values below 9 51 is again related to the confusion matrix table 1 the species richness can only be lower if more than 75 of all cells were reclassified to land use types that cannot be converted to forest defined in transition constraints the only land use types that cannot be converted to forest are pasture and urban samples with more than 75 of either pasture or urban are theoretically possible but highly unlikely given the probabilities in the confusion matrix the distribution of crop yield values with the reference land use data but with the uncertain soil data fig 6e is with a range 4 70 narrower than the distribution from uncertain land use data with a range of 45 3 most samples are equal or close to the crop yield objective value obtained with the original soil data without quantified uncertainty the combined uncertain data for the objective crop yield result in the widest range of 52 4 the combination of 1000 uncertain land use and soil data samples also results in a smoother frequency distribution the reason for the smoother distribution is the higher sample size of 1 million 1000 1000 combinations the ranges indicate that the uncertain land use data have a higher impact on the objective value crop yield than the uncertain soil data this is because a reclassification from cropland to non cropland reduces the crop yield to zero on the other hand the errors in the soil fertility map are likely to still allow crop production even when the soil fertility is reduced in a comparison of set ups with different strengths of the constraints strauch et al 2019 found that constraints limited the attainable optimal solutions for example higher area constraints lead to a narrower pareto front in our case the area constraints remain the same but the strength of the transition constraints varies with every sample because the amount and position of cells that underlay the transition constraints differ our results show that uncertain spatial input data affects the objective space limitation in land use allocation optimizations when transition constraints are defined the objective space limitations are not only affected by the definition of what land use types underlay transition constraints but also by the quantified uncertainty in the land use data inputs furthermore the probability distribution of the optimal single objective solutions for the objective species richness lead to the conclusion that a strong constraint can cancel out the effect of other sources of uncertainty 3 3 uncertainty in the objective space the third experiment with the extreme lower and upper extreme samples of uncertain land use data sec 2 4 1 resulted in pareto intervals with diverse shapes rotations and areas those geometric properties of the pareto intervals allow to assess both information about the trade offs between objectives and the uncertainty they could be categorized into 1 non conflicting objectives pareto fronts containing one single point become horizontal or vertical lines when one objective is uncertain or rectangular pareto intervals when both are uncertain but this situation is not observed in our results 2 conflicting objectives non horizontal and non vertical pareto fronts become non horizontal and non vertical pareto intervals the two objectives habitat heterogeneity and species richness represent category 1 non conflicting objectives the synergy between the objectives is explained by the common property that maximum number of forest cells is optimal with uncertain spatial input data the species richness remains constant over the experiments while the habitat heterogeneity varies fig 7 row 2 column 1 it was possible in all cases to produce a solution with a maximum habitat heterogeneity that also has the maximum allowed 25 forest cells and thus maximum species richness all other objective pairs fall into the second category conflicting objectives with uncertain spatial input data the lines become intervals where the width of the interval increases with the uncertainty the angle of the pareto fronts with conflicting objectives how much the values of one objective decrease with a certain increase in another objective i e the trade off between the two objectives the area of the pareto interval is therefore affected by the uncertainty in the objective values and the trade off in some cases the angles of the pareto fronts i e the trade offs between the objectives remain equal regardless of the uncertain input data e g for the pairs water yield habitat heterogeneity fig 7 row 3 column 1 and crop yield habitat heterogeneity fig 7 row 4 column 1 here all extreme lower and upper bound samples resulted in similarly shaped pareto fronts where mainly the positions of the fronts change for other objective pairs the trade offs change because of the uncertainty in the spatial input data e g for the objective pair water yield species richness fig 7 row 3 column 2 the pareto fronts obtained with the lower and upper extreme samples consist of two optima while the reference pareto front consists of eight optima the reason for the different number of feasible optimal solutions in the pareto fronts is the different number of transition constrained cells in the uncertain land use data the more transition constrained cells exist the lower the possible number of optimal land use allocations the fourth experiment with uncertain soil data only sec 2 4 1 results in pareto intervals with a width of only 7 1 in the x dimension and 5 5 in the y dimension of the pareto intervals from uncertain land use data only averaged over all three objective pairs in row 4 in fig 7 in the objective pair crop yield habitat heterogeneity and crop yield water yield fig 7 row 4 column 1 the pareto intervals constantly enclose the reference pareto fronts over the whole range of the objective space in line with the assessment of uncertain objective evaluation data by bassi et al 2018 only in the objective pair crop yield species richness fig 7 row 4 column 2 a small part of the reference pareto front is not enclosed by the pareto interval we believe that this is an artifact of the stochasticity in the optimization algorithm the pareto intervals from the fifth experiment with the combined uncertain data inputs sec 2 4 1 are displayed in the last row of fig 7 for the objective pair water yield crop yield fig 7 row 4 column 3 the pareto interval has a similar shape and the interval is 2 wider than the pareto interval from the uncertain land use data only in the objective pair species richness crop yield fig 7 row 4 column 2 the combined uncertain data inputs lead to a 24 wider range between the extreme points compared to pareto interval from the uncertain land use data only the objective pair habitat heterogeneity crop yield fig 7 row 4 column 1 resulted in a pareto interval with a range that increases with increasing crop yield values the cone shape can be explained by the increasing influence of soil fertility and thus its uncertainty with an increasing crop production on the other side of the pareto front low crop yield a high amount of forest and pasture is present because these land uses improve habitat heterogeneity these land use types can not be converted into cropland which diminishes the effect of the soil fertility on the pareto front in our results not all shapes of the pareto fronts from uncertain land use and combined uncertain land use and soil data resemble each other which is in contrast with the findings about uncertain objective evaluation data by bassi et al 2018 this is caused by non convex feasible objective space homem de mello and bayraksan 2014 that is introduced by the uncertain land use maps in combination with the land use transition constraints the selected maps in fig 8 highlighted in fig 7 illustrate the reason for the non convex feasible space one common factor that determines the interval between the pareto fronts is the number of urban cells because urban cells do not contribute to any of the objectives and can not be transformed into another land use so more urban cells lead to worse objective values e g the three examples from the upper bound pareto fronts green in fig 8 have a low amount of urban land with 5 3 and 4 while the lower bound pareto front red all have 15 urban land the reason for the different number of cells in the upper bound pareto fronts is that not only the amount of land use is of importance but also the location the uncertainty in the uncertain land use data led to samples in which both the amount and the location of cells benefiting the objective limit the feasible objective space leading to the non convex feasible objective space under uncertainty the uncertainty in the amount and location of urban cells is thus a strong determinant of output uncertainty validating urban areas can therefore help to reduce uncertainty in all pairwise pareto fronts ancillary data can be used to increase the accuracy of 75 in urban area classifications table 1 for example existing maps defining the outlines of urban areas corbane et al 2021 3 4 uncertainty in the solution space the average kappa values as well as the variation in kappa values differ per objective pair fig 7 all pareto fronts containing habitat heterogeneity have relatively low kappa values fig 7 in addition the solutions with a higher habitat heterogeneity have increasingly low kappa values this is because habitat heterogeneity is computed by summing up heterogeneous land use edges independent of the specific land use type while the kappa statistic compares the land use type in the cells for example if kappa was computed between a land use map and the transposed version of this map the kappa value would likely be low but the habitat heterogeneity would remain the same as only the number of edges counts in the pareto front between species richness and water yield all kappa values are similar with a range of only 0 08 while the kappa values of the pareto fronts between species richness and crop yield and water yield and crop yield have ranges of 0 21 and 0 3 respectively high kappa values indicate a high robustness in the solution space fig 9 the solutions with a high kappa fig 9 upper row have more spatial characteristics in common between the uncertain solutions than the ones with a low kappa fig 9 upper row for example in the high kappa spatial configurations the north and east are dominated by cropland 1 with few patches of forest or pasture while the south and east contain more forest the spatial configurations with a low kappa value fig 9 upper row have fewer characteristics in common even though the objective values vary less than 0 5 this variation in the solution space is crucial for decision makers as land use is their decision variable input data uncertainty becomes most problematic when it causes unclarity in the characteristics of the optimal spatial configuration for the selected point at the pareto front the solution space uncertainty computed here can serve as an incentive to select a different more robust compromise solution 3 5 limitations and future work we were able to approximate the uncertainty in the pareto fronts with highly reduced computational effort compared to a full monte carlo a full monte carlo with the selected sample size of 1000 would require 1000 executions of the optimization the computational effort was reduced by 98 7 to 13 executions the additional computation time to compute the objective value is only 10 of a single optimization execution time the main limitation of our work is that the distribution and shape of pareto fronts between the two extremes remain unknown hereby we miss information about how uncertain land use data that affects the land use transition constraints may lead to irregular infeasible regions homem de mello and bayraksan 2014 that missing information is the trade off between the highly reduced computation time and available information about the propagation of input data uncertainty another trade off from not performing an optimization for all samples is that there is no guarantee that the data samples resulting in the extreme single objective values lead to the widest pareto interval it is possible that other samples result in more extreme pareto front sections in the center i e away from the single objective optima moreover the amount of uncertainty in our case study was based on empirical data but fixed we did not investigate the effect of varying amounts of uncertainty in the spatial input data on the pareto fronts in future work this may be assessed for example by means of a sensitivity analysis furthermore our visualization of uncertainty in the pareto fronts is shown in separate scatter plots in a matrix containing all pairwise pareto fronts as such the uncertainty distribution over the whole objective space is not directly observable part of possible future work is incorporating both the extreme intervals and the similarity metric with all objectives in one single visualization for example with the multi objective visualization method of 3d radvis ibrahim et al 2016 yet it should then be tested whether this amount of information in one plot is still understandable senaratne et al 2012 lastly a real world case study of a spatial optimization is important future work such application will also allow comparing the propagation of uncertainty from different data sources to the optimization outputs 4 conclusion in this work we used seeding of optimal solutions in combination with an exterior sampling method to estimate the propagation of uncertainty from spatial input data to the results of a multi objective spatial optimization this approach allowed to reduce the computation time by 98 7 compared to a full monte carlo the approach was demonstrated on a land use allocation optimization with uncertain constraint and objective evaluation data our first research question was what is the effect of seeding single objective optima into the initial set of solutions on the multi objective land use allocation optimization the optimization with the seeding procedure resulted in pareto fronts with 6 25 better objective values averaged over all four objectives compared to the optimization without seeding furthermore the optimization with seeding produced solutions with the same quality in shorter time after 200 generations the pareto front from the optimization with seeding dominated the pareto front without the seeding procedure after 300 generations our second research question was what is the effect of uncertain spatial input data on the width and shape of the pareto interval we found two types of shapes 1 a horizontal or vertical line which was obtained between two non conflicting objective of which one was affected by the uncertainty in input data and 2 a non horizontal and non vertical pareto intervals which was obtained between two conflicting objective of which at least one was affected by the uncertainty in input data in our case study the uncertain initial land use data had by far the highest effect on the width and shape of the pareto intervals the uncertain soil fertility data led to ranges in the pareto intervals that were 6 of the ranges from uncertain land use data in the two objective pairs affected by both inputs the combined pareto intervals were 2 and 24 wider compared to the pareto intervals from uncertain land use data only furthermore in line with previous research on uncertainty in non spatial optimizations we found that uncertain soil fertility data used for computing objective values resulted in regular pareto intervals while uncertain land use data that affects the transition constraints resulted in irregular pareto intervals our third research question was what is the effect of uncertain spatial input data on the optimal spatial configurations given that the number and location of urban cells in the input land use map affected the ranges of all pairwise pareto fronts we conclude that increasing the classification accuracy of urban land is an option to reduce uncertainty for example by using auxiliary data furthermore trends of the kappa values could be observed within the single pareto fronts the pareto front of the objective pair species richness and water yield had comparatively high kappa values whereas the pareto fronts containing habitat heterogeneity had comparatively low kappa values respective to the other objective pairs the solution space uncertainty computed here can serve as an incentive to select compromise solutions that are robust to uncertainty in the spatial input data software and data availability the dataset sampling procedure of land use and soil fertility map under uncertainty is available at hildemann 2021b the dataset contains the input data the python code and the output data along with a description and steps to reproduce developer m hildemann first author see contact details at first page year first available 2021 running the sampling procedure requires python version 3 8 with numpy 1 20 1 pandas 1 2 3 plotting requires seaborn 0 11 1 scipy 1 6 2 and matplotlib 3 3 4 the software is free the dataset algorithm for constrained multi objective land use allocation optimization under uncertainty is available at hildemann 2021a the dataset contains a description the program files and the steps to reproduce we reused and extended the python software comola developed by strauch et al 2019 which is available at https github com michstrauch comola we included a seeding procedure and adapted the program for the uncertainty propagation analysis developer m hildemann first author see contact details at first page year first available 2021 the optimization was executed on a megware cluster with 15 120 cores 412 nodes and intel xeon gold 6140 18c 2 30 ghz processors with the freely available python 3 7 2 software in a linux environment with the modules numpy 1 19 1 pandas 1 2 3 and pickle 12 1 credit authorship contribution statement moritz hildemann conceptualization methodology software judith a verstegen conceptualization writing review editing supervision validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a objective functions 1 s r 5 a f 0 2 where a f area of forest 2 h h i 1 5 h h e i e i i where e number of edges i edge intensity 3 w y c 1 7 w y a c a k c k c where k c evaporation rate a k c area of land use with evatransporation rate k c 4 c y i 1 i c y i l o g p i 1 f i where p i crop production intensity f soil fertility appendix b progression of objective values in monte carlo simulation fig a1 progression of best achieved objective values normalized in the sampling process of the uncertain land use data fig a1 appendix c mapping between land cover and land use in general land covers dominated by cropland or vegetation is assumed to be used as cropland forest dominated land covers are mapped to the land use forest shrubland and grassland dominated land cover are mapped to pasture and artificial surfaces and bare areas as urban area 19 land covers are mapped to 7 land uses therefore some closes of the original confusion matrix from globcover bicheron et al 2008 are aggregated for example globcover land cover classes 40 110 correspond to the land use forest after the class aggregation in mapping land covers to land uses it is not a misclassification if e g land cover class 40 was classified as land cover class 100 it counts as an error if a land use forest land cover classes 40 100 was misclassified as urban land cover classes 190 200 or one of the other land uses table a1 mapping land cover to land use classes table a1 gc class gc label land use label id 11 post flooding or irrigated croplands cropland intensity 5 5 14 rainfed croplands cropland intensity 4 4 20 mosaic cropland 50 70 vegetation grassland shrubland forest 20 50 cropland intensity 3 3 20 mosaic cropland 50 70 vegetation grassland shrubland forest 20 50 cropland intensity 2 2 30 mosaic vegetation grassland shrubland forest 50 70 cropland 20 50 cropland intensity 1 1 30 natural and semi natural primarily terrestrial vegetation cultivated and managed terrestrial areas cropland intensity 1 1 40 closed to open 15 broadleaved evergreen and or semi deciduous forest 5 m forest 6 50 closed 40 broadleaved deciduous forest 5 m forest 6 60 open 15 40 broadleaved deciduous forest 5 m forest 6 70 closed 40 needle leaved evergreen forest 5 m forest 6 90 open 15 40 needle leaved deciduous or evergreen forest 5 m forest 6 100 closed to open 15 mixed broadleaved and needle leaved forest 5 m forest 6 110 mosaic forest shrubland 50 70 grassland 20 50 pasture 7 120 mosaic grassland 50 70 forest shrubland 20 50 pasture 7 130 closed to open 15 shrubland 5 m pasture 7 140 closed to open 15 grassland pasture 7 150 sparse 15 vegetation woody vegetation shrubs grassland pasture 7 190 artificial surfaces and associated areas urban areas 50 urban area 8 200 bare areas urban area 8 
