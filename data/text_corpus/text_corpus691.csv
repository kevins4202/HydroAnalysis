index,text
3455,when modelling heat transport in hydrogeological systems a standard assumption is local thermal equilibrium lte which implies that the porous medium temperature at the interface between the solid and fluid instantaneously reaches equilibrium few studies have investigated the validity of the lte assumption and its violation also known as local thermal non equilibrium ltne as well as its impact on the accuracy of heat transport models while the theoretical conditions under which ltne occurs in natural groundwater flow have recently been revealed these have not yet been experimentally verified we examined the applicability of the lte assumption by conducting systematic laboratory experiments using eight distinct flow velocities reynolds number re 0 37 through sand 0 76 mm grain size injecting both heat and solute as tracers and observing the response at multiple points downstream theoretical heat transport parameters were calculated from solute tracer experiments by applying a retardation factor and the results were subsequently compared to the actual parameters estimated from heat tracing our experimental results confirm that the lte assumption can be violated under natural groundwater flow conditions and that ltne impacts thermal dispersion coefficients more significantly than thermal front velocities the largest differences between the predicted and estimated thermal transport parameters were 112 and 13 for the dispersion coefficients and velocities respectively our results demonstrate that ltne effects need to be considered in heat transport modelling especially when analyzing thermal dispersion coefficients keywords heat and solute tracer experiments heat transport modelling local thermal non equilibrium retardation factor 1 introduction using heat as a tracer has become an essential tool for the exploration of the shallow subsurface anderson 2005 kurylyk and irvine 2019 rau et al 2014 it can be used to interpret groundwater surface water interactions from vertical temperature depth profiles irvine et al 2017 ren et al 2018 to evaluate the thermal groundwater response to surface warming reiter 2006 taniguchi et al 1999 taniguchi et al 2003 taylor and stefan 2009 uchida et al 2003 and to characterize the hydraulic and thermal subsurface properties deming et al 1992 doro et al 2015 keys and brown 1978 mccallum et al 2012 park et al 2015 saar 2011 wagner et al 2014 when using aquifers as a source of water or thermal energy it has been demonstrated that heat tracing is a cost effective approach to quantify hydrogeological properties e g hydraulic conductivity and groundwater flow velocity as well as properties related to heat transport e g thermal diffusivity and thermal dispersion coefficient bense et al 2016 doro et al 2015 irvine et al 2017 kurylyk and irvine 2019 saar 2011 as heat tracing has become a popular tool used by the hydrogeological community much effort has been devoted to deepening our understanding of heat transport processes some studies have compared the behavior of heat transport with that of a conservative solute tracer bandai et al 2017 irvine et al 2015 lu et al 2019 ma et al 2012 rau et al 2012a sarris et al 2018 vandenbohede et al 2009 unlike a solute tracer heat can propagate through the solid and can be exchanged between the solid and fluid the concept of retardation can be used to compare heat and solute tracers bodvarsson 1972 irvine et al 2015 compared solute and heat transport for characterizing a heterogeneous aquifer and found that heat can provide a better estimate of the mean background flow velocity whereas solute transport is affected by the variance of the background flow velocity in addition few investigations have focused on the prediction of solute transport using information derived from heat transport based on the similarity of the governing equations bons et al 2013 gossler et al 2019 lu et al 2019 compared two different tracers in three different porous materials and their results indicated that heat dispersion can be used to approximate solute dispersion most research in natural systems assumes instantaneous temperature equilibrium in the representative elementary volume rev ignoring the effects arising from the heat exchange between the solid and neighboring fluid this assumption is also known as local thermal equilibrium lte and it allows a single transport equation instead of two energy balance equations which reduces the computational cost required for interpreting heat transport lte also enables the prediction of the transport parameters for heat transport from the corresponding parameters derived from solute transport and vice versa banks 2012 bons et al 2013 gossler et al 2019 in the definition of the lte assumption instant thermal equilibrium is related to the time required to reach thermal equilibrium this is controlled by factors such as flow velocity porosity volume to equilibrate solid fluid thermal conductivity ratio heat transfer coefficient and temperature difference between the heat sources alazmi and vafai 2000 alomar 2019 carbonell and whitaker 1984 gelet et al 2013 gossler et al 2020 kaviany 2012 kunii and smith 1961 minkowycz et al 1999 nield et al 2002 in other words if the time to equilibrate is long enough to affect heat transport the lte assumption may be inadequate resulting in what is referred to as local thermal non equilibrium ltne conditions ltne has been investigated mainly in the field of mechanical engineering where a typical scenario is to model flow into a parallel plate channel filled with a saturated porous medium haji sheikh and minkowycz 2008 lee and vafai 1999 minkowycz et al 1999 nield et al 2002 nozad et al 1985 shivakumara et al 2011 vadasz 2007 however such models and results cannot be directly transferred to hydrogeological systems because of the difference in boundary conditions or variables that are not representative for example nield et al 2002 studied the ltne in a forced convection problem in the context of industrial examples such as nuclear reactors and solar energy storage systems they used parallel plates as wall boundaries and applied the thickness of the porous channel in the definition of several dimensionless variables in geological systems such dimensionless variables cannot be defined in addition since the majority of research has focused on the factors that affect ltne there is a lack of explanation of the mechanism that could explain the model results therefore custom designed ltne studies representative of hydrogeological systems need to be conducted to explain the experimental or numerical results research into the ltne has progressed in the context of hydrogeological systems bandai et al 2017 gelet et al 2013 hamidi et al 2019 heinze and blöcher 2019 gossler et al 2019 gossler et al 2020 lu and xiang 2012 metzger et al 2004 rees et al 2008 rees 2010 roshan et al 2014 nouri borujerdi et al 2007 sarmasti and mazaheri 2017 for instance hamidi et al 2019 used a numerical model to simulate a deep geothermal system and revealed that hydraulic heterogeneity can enhance the disequilibrium between solid and fluid temperatures their results support the hypothesis that the rev can control the time for thermal equilibrium carbonell and whitaker 1984 kaviany 2012 roshan et al 2014 found that ltne could occur at low re values 0 01 they suggested that the velocity and heat exchange act in opposition and that this can cause thermal disequilibrium at low velocities on the other hand gossler et al 2020 used a two equation numerical model to predict the occurrence of ltne at seepage velocity 1 6 m d gossler et al 2020 also revealed a velocity variance at low velocities in porous materials with large particle sizes but they interpreted this as originating from differing boundary conditions when using lte and ltne models for example they found that the different interpretations at low flow velocities may result from different definitions of the nusselt correlation required to calculate the heat transfer coefficient between the phases the reported results cannot simply be combined because of the differences in modelling conditions such as porous materials velocity range and nusselt correlation so far in the context of thermogeological systems only few studies considered the effects of ltne on heat transport interpretations bandai et al 2017 heinze and blöcher 2019 gossler et al 2019 gossler et al 2020 metzger et al 2004 roshan et al 2014 with the experimental evidence of ltne lacking in particular the objective of this study is to experimentally verify the validity of the lte assumption and to investigate the potential effects of the ltne on heat transport interpretation we conducted laboratory experiments using solute and heat tracers applied at a range of distinct background flow velocities in water saturated and natural porous media we provide evidence for ltne conditions occurring under natural groundwater flow conditions and demonstrate that these effects must be considered when evaluating heat transport in hydrogeological settings 2 material and methods 2 1 description of the laboratory experimental system comprehensive laboratory experiments were conducted to investigate the lte during heat transport in natural materials fig 1 a shows the laboratory experimental setup which consists of a sand tank with dimensions of 1 3 m 0 6 m 0 8 m l w h fluid electric conductivity ec and temperature sensors connected to a data acquisition daq system the experimental setup was designed for a previous study to investigate the dispersion velocity relationship in saturated porous media and it was used to examine the effect of injected water and thermal dispersivity ratio during heat transport park et al 2018 park and lee 2021 in this work the same laboratory experimental system was used to verify the validity of the lte assumption by comparing the transport parameters of the solute and heat first solute transport experiments were performed at a range of darcy fluxes and analyzed with an analytical solution to the advective dispersive transport of the solute hunt 1978 rau et al 2012a to estimate the seepage velocity and hydrodynamic dispersion of solute then the heat transport experiments under various flow conditions conducted by park and lee 2021 were re interpreted analytically and the tracer front velocity and dispersion coefficients of heat were compared with those of the solute for the same flow velocities at that time the thermal properties of used sand table 1 obtained from the heat tracer experiments under the no flow condition conducted by park and lee 2021 were re used detailed procedures to evaluate the thermal properties are explained in park 2019 as shown in fig 1a the sand tank was composed of three chambers the water levels in two chambers on both sides can be adjusted and maintained to create a static hydraulic gradient between the chambers the middle chamber was filled with sand and served as a water saturated porous medium representative of a shallow aquifer before each transport experiment the water level in the left chamber was kept higher than on the right side for several hours ensuring that the residual tracer was removed from the material the hydraulic and physical properties of the sand were estimated in a previous study park and lee 2021 and were used to constrain the flow and transport description the uniformity cu and mean grain size d50 are 1 50 and 0 76 mm indicative of a homogeneous coarse sand friedman and sanders 1978 the porosity of the sand n was determined to be 0 374 0 0043 which are the average value and standard deviation of 51 measurements owing to the ideal properties of the sand for transport purposes we did not distinguish between the total porosity and effective porosity hydraulic conductivity was estimated to be 3 23 10 3 m s which falls within the permeability range of clean sand or gravel freeze and cherry 1979 2 2 solute and heat transport experiments by adjusting the hydraulic heads in both side chambers solute transport experiments were performed at 18 different darcy fluxes between 8 91 and 36 53 m d within the linear laminar flow regime reynolds number re 0 37 sodium chloride nacl 99 5 junsei chemical japan solution was used in the experiments as a conservative solute tracer according to schincariol and schwartz 1990 a density difference between water and nacl solutions upwards 1000 mg l can cause gravitational instability which can confound the interpretation of the dispersive solute transport to avoid this we used a 500 mg l nacl solution as a test we injected the solution into a well for 1 min at a rate of 50 ml min using a peristaltic pump minipuls 3 gilson usa the injected solution flowed uniformly through the screened interval 29 31 cm in height of the injection well into the saturated sand as shown in fig 1 ec as a proxy for changes in solute concentration was measured using four microelectrodes microelectrodes usa installed along the flow path ec measurements were recorded at 1 s intervals on a laptop computer through a daq system which consisted of four conductivity isopods ep357 edaq australia and podvu software edaq australia each solute transport experiment was continued until the values observed at the ec sensor placed farthest from the injection point l29 returned to the initial ec values after each experiment the middle chamber was flushed out by maintaining the flow to remove any residual nacl solution to validate the lte assumption and investigate its impacts on heat transport processes in a saturated porous medium this study reanalyzed the temperature time series data acquired during previous work park and lee 2021 the heat transport experiments were conducted by park and lee 2021 in two steps first experiments using an electrical resistor 7 mm diameter resistance of 47 ω and power rating of 5 w as a continuous point heat source were conducted five times under no flow conditions to estimate the bulk thermal diffusivity of the water saturated sand second resistor heating experiments were performed at 34 different darcy fluxes between 8 13 and 36 75 m d to quantify the relationship between thermal dispersion coefficients and thermal front velocities during the experiments constant power of 3 685 4 517 w was applied to the electrical resistor by a laboratory dc power supply ac input 220 v dc output 0 30 v because the temperature inside the middle chamber became uneven after each experiment the water was kept flowing for several hours to attain thermal equilibrium as shown in fig 1 temperature time series data from heat transport experiments were monitored by a daq system consisting of temperature sensors pt100 hayashi denko japan analog input modules ni 9217 national instruments usa a compact daq chassis cdaq 9178 national instruments usa and daq software daqmx and labview 2015 see park 2019 a total of 29 resistance temperature detectors rtds were installed at distinct locations downstream from the heat source within the saturated sand the rtds are 3 2 mm in diameter and 20 mm long and have the response time of 2 s to 63 of temperature shift from 0 to 100 c tstec 2021 they measured the temperature change at 0 1 s intervals during each experiment in this study the temperature time series data from the four observation points l15 l20 l25 and l29 fig 1b were used to compare the transport parameters of heat with those estimated from solute transport experiments because it was difficult to detect nacl concentrations in off center locations l12 and l19 we calculated the time for a 63 response to heating for the worst case experimental conditions fastest flow as approx 31 s this is 16 times slower than the sensors response time and demonstrates that the temperature responses were not influenced by the measurement system 2 3 analytical modeling of solute transport the advective dispersive transport of solute in a porous medium is described by a differential transport equation dte as follows de marsily 1986 1 c t d s 2 c v s c where c is the concentration of the solute kg m3 t is the time s and vs is the solute front or seepage or interstitial velocity m s the solute dispersion coefficient ds m2 s consists of diffusion and hydromechanical dispersion terms as follows de marsily 1986 2 d l t s d 0 s α l t v s where d0 s is the molecular diffusion coefficient of the solute in free water m2 s α is the solute dispersivity m and the subscripts l and t represent the longitudinal and transverse directions respectively the relative contributions of diffusive and advective solute transport can be quantified using the solute péclet number de marsily 1986 3 pe s vl d 0 s where v is the linear average velocity m s and l is the characteristic length of the fluid flow m for which the mean grain size d50 of a porous medium can be used de marsily 1986 in this study a molecular diffusion coefficient of 1 47 10 9 m2 s was used for sodium chloride to calculate the solute péclet number vitagliano and lyons 1956 for a continuous source at the origin within an infinite medium with a uniform flow along the x direction the solution of the dte in equation 1 with the initial condition of c x y z t 0 0 for x y z and boundary conditions of lim x y z c x y z t 0 and w 0 0 0 t 0 m is as follows hunt 1978 4 c x y z t m 8 π n e r d t s exp x v s 2 d l s exp r v s 2 d l s e r f c r v s t 2 d l s t exp r v s 2 d l s e r f c r v s t 2 d l s t here m is the mass flow rate kg s ne is the effective porosity and r is the spherical radius m defined by 5 r x 2 d l s d t s y 2 z 2 where x y and z m are cartesian coordinates equation 4 describes the change in concentration over time and at a distance from a continuous source however the microelectrodes installed along the flow direction measure the variation in fluid ec instead of concentration because the ec sensors are sensitive to pressure changes resulting from hydraulic control it is not possible to calibrate the sensors after the experimental setup rau et al 2012a however the time series data observed during the solute transport experiments can be used to indicate the relative solute concentration changes at the monitoring points for this reason the analytical model of equation 4 was normalized with respect to the steady state concentrations as follows rau et al 2012a 6 c n r t 1 2 e r f c r v s t 2 d l s t exp r v s d l s e r f c r v s t 2 d l s t where cn is the normalized concentration ranging between 0 and 1 for steady state flow along the x direction the solute velocity can also be calculated from the solute breakthrough curves as follows kreft and zuber 1978 7 v s x t 50 where t50 is the time when the concentration reaches 50 of the steady state concentration see fig 2 b this method is known as a method of moments mom and is regarded as robust because it is not governed by any physical transport model yu et al 1999 rau et al 2012a mathematically equation 7 represents the result for a delta input cn 0 t δ t however in the solute transport experiments a sodium chloride solution was injected for a finite duration of 1 min fig 2a therefore equation 7 was modified to consider the finite pulse input cn 0 0 t t0 1 as follows yu et al 1999 8 v mom s x t 50 t 0 2 2 4 analytical modeling of heat transport heat transport differs from solute transport in that thermal energy can propagate through both the fluid and solid phases the mathematical formulation of this problem requires two separate equations that are coupled together using a heat transfer coefficient an approach referred to as ltne kaviany 2012 since it is difficult to estimate the heat transfer coefficient especially for natural systems gandomkar and gray 2018 the theory is simplified by assuming that liquid and solid are one continuum with averaged thermal properties this is referred to as lte and it is generally used for heat transport in natural systems e g gossler et al 2020 under the lte assumption advective dispersive transport of heat in a saturated porous medium can be described by a three dimensional differential equation as follows de marsily 1986 9 t t d t 2 t v t t where t is the temperature c and vt is the thermal front velocity m s similar to the solute dispersion coefficient the thermal dispersion coefficient dt m2 s is also composed of thermal diffusion and hydromechanical thermal dispersion terms as follows rau et al 2012b 10 d l t t λ ρ c β l t v t m where λ is the bulk thermal conductivity w m k ρc is the bulk volumetric heat capacity j m3 k β is the thermal dispersivity and m is the coefficient describing the relationship between the thermal front velocity and thermal dispersion coefficient note that this is nonlinear because heat diffusion is much faster than solute diffusion leading to a different transport regime rau et al 2012a thermal diffusion comprises the bulk thermal conductivity defined as woodside and messmer 1961 11 λ λ f n e λ s 1 n e and the bulk volumetric heat capacity is defined as follows buntebarth and schopper 1998 12 ρ c n e ρ f c f 1 n e ρ s c s where the subscripts f and s indicate the fluid and solid phases respectively analogous to solute transport the relative dominance between conduction and mechanical dispersion can be evaluated by the thermal péclet number as follows de marsily 1986 13 pe t ρ f c f q l λ the heat transport equation in equation 9 was solved for an infinite aquifer under a uniform flow in the x direction by carslaw and jaeger 1959 with the initial condition of t x y z t 0 t0 and boundary conditions of lim x y z t x y z t t 0 and w 0 0 0 t 0 q the analytical solution is given in a modified form as follows rau et al 2012a 14 t x y z t t 0 q 8 π d t t ρ c r exp x v t 2 d l t exp r v t 2 d l t e r f c r v t t 2 d l t t exp r v t 2 d l t e r f c r v t t 2 d l t t 15 r x 2 d l t d t t y 2 z 2 equation 14 is known as a moving continuous point source mcps model which was used to analyze the heat transport experiments conducted at various flow velocities similar to the solute front velocity the thermal front velocity can also be calculated from the thermal breakthrough curve as follows 16 v 50 t x t 50 where t50 is the time s when the temperature reaches 50 of the steady state value however it should be noted that thermal and solute front velocities differ even under the same flow conditions because heat diffuses through solids whereas solute does not de marsily 1986 2 5 parameter estimation as shown in fig 2b the ec time series data for the finite pulse input were integrated and normalized into breakthrough curves btcs the solute front velocities vfit s and solute dispersion coefficients dfit s were estimated by fitting the solute forward model sfm in equation 6 to the btcs analogously heat transport experiments conducted at various flow velocities were interpreted using the mcps model in equation 14 the thermal front velocities vfit t and thermal dispersion coefficients dfit t were estimated by matching the model to the measurements based on the estimated bulk thermal properties listed in table 1 in this study curve fitting between the observed data and analytical models was performed using a nonlinear least squares function in matlab the goodness of fit was quantified using the root mean square error rmse and coefficient of determination r2 2 6 comparison of solute and heat transports in our study we are unable to apply the ltne model because estimating the heat transfer coefficient for ltne requires separate measurement of the temperature in both the liquid and solid phases which is infeasible for the grain sizes we used in our work further it has been shown that the ltne formulation reduces to that used for solute transport equation 1 if both the heat transfer into and through the solid phase are muted whitaker 1991 consequently if ltne is present within a system there must be a difference between the properties derived using solute and lte heat transport theories if the lte condition is valid the velocity and dispersion coefficient of the solute can be related to those of heat by a thermal retardation factor respectively the thermal retardation factor is defined by the ratio of thermal and hydraulic travel times banks 2012 theoretically under the lte assumption the travel time ratio becomes equal to the ratio of the volumetric heat capacity of the aquifer and the water the theoretical apparent thermal retardation factor rapp is defined in this study as follows bodvarsson 1972 gossler et al 2019 17 r app ρ c n e ρ f c f the thermal retardation factor defined as the travel time ratio can also be converted into the ratio of the seepage and thermal front velocities because the velocity is defined as the distance divided by the travel time as a result the effective thermal retardation factor reff represented by the velocity ratio is defined in this study as follows gossler et al 2019 18 r eff v s v t therefore the lte assumption can be verified by comparing two thermal retardation factors equations 17 and 18 because the theoretical rapp should be equal to the experimental reff under the lte assumption in the case of dispersion coefficients bons et al 2013 developed a unified expression for both solute and thermal transport they created a new concept the critical péclet number pec to explain the tracer behaviors through the various pore channels using a statistical approach pec was determined by the critical velocity which was calculated by capturing the location of each particle and by counting the number of particles that are dominantly moved by advection or diffusion the physical meaning of pec is the péclet number when the particle is equally distributed into advective and diffusive channels with this concept the relationship between two dispersion coefficients in the longitudinal direction was proposed using the theoretical thermal retardation factor under lte bons et al 2013 and it was slightly modified as follows due to the different definitions of the theoretical retardation factor 19 d l s t 1 r app d 0 s r app 1 d 0 f s t β l s t r app d 0 s t pe s t pe s t pe c s t 1 pe s t pe c s t where the superscripts s and t indicate the solute and heat and the subscripts s and f indicate the solid and fluid respectively d0 is the diffusivity m2 s and βl is a coefficient related to the geometry of the system defined as the coefficient of the relationship between the mechanical dispersion coefficient in the longitudinal direction and velocity v multiplied by the characteristic length l pet described in equation 19 was defined differently from equation 13 in this study using thermal diffusivity for the bulk volume as follows bons et al 2013 20 pe t vl d 0 t further information about this model can be found in bons et al 2013 in this study the validity of the lte assumption was investigated by confirming whether both solute and thermal dispersion coefficients estimated in section 2 2 satisfy equation 19 to fit equation 19 to the normalized solute dispersion coefficient it can be rewritten as follows 21 d norm s d l s d o s 1 β l s pe s pe s pe c s 1 pe s pe c s the normalized solute dispersion coefficients were fitted to the model equation 21 in the direction of minimizing the sum of squared residuals by changing two unknown parameters βl s and pec s the fitting was performed using a nonlinear routine implemented in matlab the fitted model for the solute dispersion coefficient was applied to the thermal dispersion coefficient to check whether the thermal dispersion coefficients showed good agreement with the model 3 results 3 1 solute transport fig 2b shows the observed and modeled normalized concentration time series at three monitoring points at a darcy flux of 14 60 m d the best fit models successfully reproduced the measurements with r2 0 9996 and rmse 0 0090 from this scenario the solute front velocities and solute dispersion coefficients for all experiments were determined to be in the range of 20 10 to 81 22 m d and 5 17 10 7 to 2 67 10 6 m2 s respectively because the vs would be further used to calculate the effective retardation factor and thereby test the lte assumption it was also estimated by another method the solute velocities evaluated using finite pulse mom ranged from 19 60 to 76 03 m d the results show good agreement between the two methods as evidenced by an r2 value of 0 974 fig 3 fig 4 shows the relationship between the solute front velocities and the solute dispersion coefficients estimated by the sfm a regression analysis indicated that the solute dispersion coefficients increased linearly with solute front velocities r2 0 979 pes corresponding to the flow velocities in this study were in the range of 142 to 583 according to de marsily 1986 this complies with a transport regime in which hydromechanical dispersion is the dominant transport mechanism in this regime a linear relationship between the flow velocity and dispersion coefficient is generally accepted 3 2 heat transport to estimate the thermal front velocities and thermal dispersion coefficients heat transport breakthrough curves for discrete darcy fluxes between 8 13 and 36 75 m d were analyzed using the mcps model described in equation 14 fig 5 shows the measured and modeled temperatures at four monitoring points for a darcy flux of 10 44 m d the best fit mcps models successfully reproduced the observations with r2 0 9969 and rmse 0 0040 k from the best fit models the thermal front velocities and thermal dispersion coefficients were determined to be 7 82 36 71 m d and 6 63 10 7 2 05 10 6 m2 s respectively because vt is used to calculate the effective retardation factor and thereby validate the lte assumption it was independently estimated from the normalized temperature breakthrough curves the thermal velocities of v50 t were in the range of 9 46 to 37 94 m d which is in good agreement with those estimated by the mcps model fig 6 fig 7 shows the relationship between the thermal front velocities and thermal dispersion coefficients estimated by the mcps model a regression analysis of the relationship indicates that the thermal dispersion coefficients increase exponentially with the thermal front velocities m 2 in equation 10 the pet calculated using equation 13 for the heat transport experiments in this study was in the range of 0 2 pet 0 8 this corresponds to the transition regime 0 5 pet 2 5 where diffusion and hydromechanical thermal dispersion compete for which it has been shown that the dispersion velocity relationship can be approximated by a square law rau et al 2012a 4 discussion 4 1 using tracer derived velocities to test for the lte assumption under the lte assumption the tracer front velocities of the solute and heat can be compared using two retardation factors that is the experimental reff equation 18 derived from the solute and heat front velocities should be equal to the theoretical rapp equation 17 as calculated from the volumetric heat capacities and porosity the theoretical rapp of this study ranges from 1 76 to 1 83 fig 8 which is narrow compared to the possible range 1 58 3 78 for saturated sand calculated from the literature stauffer et al 2013 fetter 2001 it should be noted that the source locations for the solute and heat transport experiments differed which led to longer transport distances for the solute compared to heat at the same observation points for this reason the velocities between observation points hereafter termed interval velocity need to be analyzed from the travel time information e g t50 of normalized data and sensor locations the experimental reff was computed using the interval velocity for the longest distance from l15 to l29 see fig 1 and they were in the range of 1 77 to 2 05 fig 8 as depicted in fig 8 at darcy fluxes lower than 20 m d the experimental reff agreed with the theoretical rapp with a difference of 5 at higher darcy fluxes reff deviates from rapp by up to 13 these deviations cannot be explained only by the spatial heterogeneity of the thermal properties table 1 because the differences between the two retardation factors increase with increasing flow velocity fig 8 as demonstrated by gossler et al 2019 the thermal velocities calculated from the normalized temperature of 0 5 are mainly affected by advection therefore a possible explanation for the deviations of reff from rapp could be the occurrence of non uniform flow rau et al 2012b found in their controlled sinusoidal heating experiments that even in the sub meter scale experiments performed with relatively homogeneous coarse sand cu 1 68 and d50 2 mm under a transition transport regime pet 0 7 a non uniform flow field can occur and affect the propagation of the thermal front using the heat transport data used here park and lee 2021 conducted a detailed analysis of the dispersion velocity relationship and observed that the discrepancy among thermal velocities increased with increasing flow velocity even at a single observation point this result indicates that the velocity field may not be homogeneous even in small scale experiments 0 25 m with homogeneous natural materials cu 1 50 which is consistent with previous findings park et al 2018 rau et al 2012b as the background flow velocity increases the difference between the heat derived seepage velocity and solute front velocity increases and becomes larger than the scatter in their relationship see fig s1 this cannot be explained only by the occurrence of a non uniform flow field another possible explanation for the increase in the deviation between reff and rapp could be the influence of the ltne according to zhang et al 2009 ltne conditions may occur with an increase in the background flow velocity and particle size of a porous medium recently gossler et al 2020 performed a 1d numerical study of advective dispersive heat transport in natural porous aquifers and presented the discrete lower limits of the lte assumption in terms of groundwater flow velocity vs 1 6 m d or grain size d50 7 mm heat transport experiments of this study were conducted at higher flow velocities 21 7 m d vs 98 3 m d than those of gossler et al 2020 vs 50 m d but the saturated sand used here had a smaller particle size d50 0 76 mm despite the smaller mean grain size the ltne effects on the velocity estimates occurred in our study this result may be related to the representative elementary volume rev because the concept of rev is used to define and measure the average properties of the volume of interest de marsily 1986 the size of the rev can be larger in a heterogeneous medium than in a homogeneous medium bear 1972 therefore the spatial heterogeneity of the thermal properties in table 1 can increase the size of the rev for the saturated sand leading to an increase in the particle size for a homogeneous numerical model for this reason we interpret that our heat transport experiments conducted at high background flow velocities using saturated sand with a small particle diameter illustrate the effects on the thermal front velocity caused by ltne the discrepancy between the theoretical rapp and experimental reff results could be caused by the ltne but other possible factors inherent in experimental conditions must first be excluded this means that the difference between the retardation factors does not necessarily indicate the effect of the ltne on heat transport the heterogeneity of physical properties is a general problem under real world conditions because most models assume homogeneous properties the heterogeneous properties of hydraulic and thermal parameters can cause errors in transport parameter estimation for example the existence of a distinction between high and low permeability can lead to large errors for the velocity estimates especially at low flow velocities schornberg et al 2010 the discrepancy between rapp and reff can be attributed to the errors in the slow velocity estimates this means that the difference between rapp and reff could be large even at low velocities considering that the velocity difference in this study was 13 it would be difficult to verify the lte assumption under more heterogeneous field conditions using the tracer front velocities 4 2 using tracer derived dispersion coefficients to verify the lte assumption bons et al 2013 developed a universal dispersion model that enables a direct comparison of the solute and thermal dispersion coefficients which was introduced in equation 19 because the dispersion model was validated over a wide range of transport regimes up to pe 106 in bons et al 2013 it is fully applicable to transport experiments conducted in our study 10 1 pe 103 the pet defined in equation 20 was used in bons et al 2013 we note that these pet values are presented in fig 9 whereas the pet values calculated using equation 13 are presented in fig 7 when assuming lte the dispersion coefficients of both the solute and heat should lie on a single curve predicted by the dispersion model consequently a discrepancy between the thermal dispersion coefficients predicted from solute transport and those estimated from the heat transport experiments indicates the existence of ltne fig 9a shows the solute and thermal dispersion coefficients estimated by the transport experiments and the corresponding dispersion model with respect to pe the dispersion model matches the solute dispersion coefficients estimated from the solute breakthrough curves fig 9a the normalized dispersion coefficients predicted by the dispersion model dnorm model were compared with the normalized thermal dispersion coefficients estimated by the analytical solution dnorm fit t at three monitoring points l15 l20 and l25 estimates from monitoring point l29 were excluded from the comparison owing to the large data scatter see fig 7 as shown in fig 9a the estimated thermal dispersion coefficients increasingly deviate from the prediction of the dispersion model with increasing flow velocity this result indicates that the bons et al 2013 dispersion model is no longer valid and its underlying assumptions are violated therefore thermal dispersion coefficients cannot be predicted from solute transport experiments and vice versa gossler et al 2020 quantified the degree of ltne using three different metrics one of these is the ratio of thermal dispersion coefficients estimated from the temperature breakthrough curve generated by the lte and ltne models method 1 in gossler et al 2020 we evaluated the degree of ltne based on the ratio of thermal dispersion coefficients predicted by the solute tracer dnorm model in this study and estimated using a heat tracer dnorm fit t in this study as shown in fig 9b for pe 0 9 the ratios of thermal dispersion coefficients at monitoring points l20 and l25 exceeded 1 5 the upper limit of quasi lte which is defined by considering the uncertainty in thermal dispersion estimates as up to 50 gossler et al 2020 the maximum ratio was 2 12 at l25 as shown in fig 9b the spatial difference between l15 and l25 was 21 on average at the lowest pe the spatial differences originate from the process of normalizing the thermal dispersion coefficients which could be due to heterogeneity in the thermal properties table 1 or thermal front velocity differences however the increasing discrepancy between dnorm model and dnorm fit along with the increase in flow velocity cannot be explained by spatial heterogeneity other possible explanations could be small scale non uniform flows or ltne it is well known that non uniform flow conditions affect solute transport more than heat transport irvine et al 2015 the spatial difference of the normalized solute dispersion coefficient solely caused by mechanical dispersion did not show any trend with the solute velocity and had an average of 7 9 for all velocities this means that non uniform flow can be ruled out as an influence because it cannot explain the differences between dnorm model and dnorm fit therefore we conclude that ltne contributes to the inconsistency between the dispersion results derived from modelling and experimentation bandai et al 2017 compared the dispersion coefficients of solute and heat tracers for three porous media with differently sized glass beads mean grain sizes of 0 41 1 10 and 4 94 mm they found that unlike solute dispersion the thermal dispersion increased when the particle size decreased and hypothesized that this was caused by the ltne effects the same was reported by lu et al 2019 for sand silt loam and sandy clayey loam in addition as emphasized by gossler et al 2020 the discrepancy between dnorm model and dfit t was up to 112 which was larger than that between rapp and reff maximum 13 found in our study surprisingly in our results we found an onset of ltne for much smaller particles but at much higher velocities compared to the limits derived by gossler et al 2020 since our experimental velocities exceeded those considered by gossler et al 2020 this could be due to the relationship between velocity and particle size for ltne fig 7 in gossler et al 2020 alternatively this could be caused by our experimental conditions not reflecting the broad nusselt correlation derived in gossler et al 2020 from a few experiments a different nusselt correlation would lead to a difference in the heat transfer coefficient and alter their limits for the onset of ltne the latter explanation is more likely and demonstrates that more experimental research is required to quantify the heat transfer coefficients for natural materials and flow conditions 4 3 implications for heat transport modelling in natural sediments field conditions are generally more complicated due to the pervasive presence of heterogeneity irvine et al 2015 zech et al 2016 zhu and yeh 2005 as mentioned by rau et al 2014 an appropriate rev needs to be defined if the heat transport is simplified by volume averaging in a heterogeneous medium the time for thermal equilibrium between a solid and its neighboring fluid can be increased because of the larger rev rau et al 2014 carbonell and whitaker 1984 however there is no clear guidance on how to define an rev that ensures a valid lte assumption for natural sediments in the literature consideration of the effects of ltne on heat transport in field experiments is an open research question with significant implications several variables have been suggested in the literature to assess the validity of the lte assumption for heat transport in a porous medium such as the effective fluid prandtl number local nusselt number sparrow number biot number and darcy number kim and jang 2002 lee and vafai 1999 minkowycz et al 1999 nield et al 2002 unfortunately these criteria cannot be directly applied to hydrogeological systems because of the differences in boundary conditions or dimensionless variables that are unknown in natural systems to overcome such limitations gossler et al 2020 defined lower limits for groundwater flow velocity and particle size which ensure that lte is provided using theoretical analyses however our study illustrated that ltne could occur for smaller particle sizes than predicted by gossler et al 2020 but at flow velocities that exceed their considerations our experimental results show that higher flow velocities could violate lte assumptions for smaller grain sizes than theoretically predicted suggesting an interdependency between the previously defined limits for grain size and flow velocity further since our results are experimental there could be a discrepancy between theory and physical reality consequently more experimental studies are needed to elucidate the validity of lte for heat transport in natural sediments in this study the ltne impact on the thermal front velocity estimates was not noticeable when the advective transport velocities were evaluated using heat and solute tracers this verifies the theoretical findings of gossler et al 2019 and gossler et al 2020 based on these results it is expected that any ltne impacts on the flow velocity estimates conducted in previous studies that interpreted temperature breakthrough curves and assumed lte conditions seemed to be negligible in contrast the impact of ltne on the estimated thermal dispersion coefficients was noticeable in our experiments as has also been predicted theoretically by gossler et al 2020 albeit for lower grain sizes and higher velocities knowledge of mechanical thermal dispersion has been demonstrated to be important when modelling thermal plumes in natural systems lo russo and civita 2009 park et al 2018 sauty et al 1982 it is common to either interchange heat and solute dispersion or infer one from the other because ltne can affect dispersion estimates such inference can lead to erroneous results overall our results demonstrate that ltne effects need to be considered when accurate heat transport modelling is required further experiments are necessary to determine accurate physical limits for lte and to investigate the impact of natural system characteristics on the onset of ltne heat transport 5 conclusions we conducted systematic laboratory experiments using solute and heat tracers to test and verify the common assumption of local thermal equilibrium lte heat transport in porous materials under natural flow conditions previous numerical investigations have predicted that local thermal non equilibrium ltne should not occur for grain sizes smaller than 7 mm or flow velocities slower than 1 6 m d surprisingly we found an increasing occurrence of local thermal non equilibrium ltne for heat transport through uniform sand with a grain size of 0 76 mm and flow velocities 20 m d in agreement with previous research we confirmed that the estimated flow velocity remained unaffected whereas thermal dispersion was influenced by the presence of ltne we provide the first experimental evidence for ltne effects during heat transport in natural sediments and show that ltne impacts can occur as has been predicted in previous studies however our experiments indicate smaller particles and higher velocity limits for the onset of ltne compared to those predicted in the literature we hypothesize that this may be caused by different heat transfer coefficients between fluid and solids in our experiment compared to the generic conditions derived from limited experimental data in previous work our work shows that ltne effects may need to be considered when assessing the impact of thermal dispersion on heat transport in natural hydrogeologic systems for example when modelling the spatial and temporal evolution of temperature plumes further research is required to test different material sizes and flow velocities so that more accurate and robust limits for lte heat transport under natural conditions can be defined credit authorship contribution statement ji young baek methodology validation formal analysis investigation resources data curation writing original draft writing review editing visualization byeong hak park conceptualization methodology validation investigation resources data curation writing original draft writing review editing visualization gabriel c rau resources writing review editing visualization kang kun lee resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national research foundation of korea nrf grant funded by the ministry of science and ict msit of the south korean government grant number 2017r1a2b3002119 this work was also supported by the institute for korea spent nuclear fuel iksnf and the national research foundation of korea nrf grant funded by the korean government ministry of science and ict msit grant number 2021m2e1a1085200 the authors appreciate the insightful and constructive comments made by anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127589 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3455,when modelling heat transport in hydrogeological systems a standard assumption is local thermal equilibrium lte which implies that the porous medium temperature at the interface between the solid and fluid instantaneously reaches equilibrium few studies have investigated the validity of the lte assumption and its violation also known as local thermal non equilibrium ltne as well as its impact on the accuracy of heat transport models while the theoretical conditions under which ltne occurs in natural groundwater flow have recently been revealed these have not yet been experimentally verified we examined the applicability of the lte assumption by conducting systematic laboratory experiments using eight distinct flow velocities reynolds number re 0 37 through sand 0 76 mm grain size injecting both heat and solute as tracers and observing the response at multiple points downstream theoretical heat transport parameters were calculated from solute tracer experiments by applying a retardation factor and the results were subsequently compared to the actual parameters estimated from heat tracing our experimental results confirm that the lte assumption can be violated under natural groundwater flow conditions and that ltne impacts thermal dispersion coefficients more significantly than thermal front velocities the largest differences between the predicted and estimated thermal transport parameters were 112 and 13 for the dispersion coefficients and velocities respectively our results demonstrate that ltne effects need to be considered in heat transport modelling especially when analyzing thermal dispersion coefficients keywords heat and solute tracer experiments heat transport modelling local thermal non equilibrium retardation factor 1 introduction using heat as a tracer has become an essential tool for the exploration of the shallow subsurface anderson 2005 kurylyk and irvine 2019 rau et al 2014 it can be used to interpret groundwater surface water interactions from vertical temperature depth profiles irvine et al 2017 ren et al 2018 to evaluate the thermal groundwater response to surface warming reiter 2006 taniguchi et al 1999 taniguchi et al 2003 taylor and stefan 2009 uchida et al 2003 and to characterize the hydraulic and thermal subsurface properties deming et al 1992 doro et al 2015 keys and brown 1978 mccallum et al 2012 park et al 2015 saar 2011 wagner et al 2014 when using aquifers as a source of water or thermal energy it has been demonstrated that heat tracing is a cost effective approach to quantify hydrogeological properties e g hydraulic conductivity and groundwater flow velocity as well as properties related to heat transport e g thermal diffusivity and thermal dispersion coefficient bense et al 2016 doro et al 2015 irvine et al 2017 kurylyk and irvine 2019 saar 2011 as heat tracing has become a popular tool used by the hydrogeological community much effort has been devoted to deepening our understanding of heat transport processes some studies have compared the behavior of heat transport with that of a conservative solute tracer bandai et al 2017 irvine et al 2015 lu et al 2019 ma et al 2012 rau et al 2012a sarris et al 2018 vandenbohede et al 2009 unlike a solute tracer heat can propagate through the solid and can be exchanged between the solid and fluid the concept of retardation can be used to compare heat and solute tracers bodvarsson 1972 irvine et al 2015 compared solute and heat transport for characterizing a heterogeneous aquifer and found that heat can provide a better estimate of the mean background flow velocity whereas solute transport is affected by the variance of the background flow velocity in addition few investigations have focused on the prediction of solute transport using information derived from heat transport based on the similarity of the governing equations bons et al 2013 gossler et al 2019 lu et al 2019 compared two different tracers in three different porous materials and their results indicated that heat dispersion can be used to approximate solute dispersion most research in natural systems assumes instantaneous temperature equilibrium in the representative elementary volume rev ignoring the effects arising from the heat exchange between the solid and neighboring fluid this assumption is also known as local thermal equilibrium lte and it allows a single transport equation instead of two energy balance equations which reduces the computational cost required for interpreting heat transport lte also enables the prediction of the transport parameters for heat transport from the corresponding parameters derived from solute transport and vice versa banks 2012 bons et al 2013 gossler et al 2019 in the definition of the lte assumption instant thermal equilibrium is related to the time required to reach thermal equilibrium this is controlled by factors such as flow velocity porosity volume to equilibrate solid fluid thermal conductivity ratio heat transfer coefficient and temperature difference between the heat sources alazmi and vafai 2000 alomar 2019 carbonell and whitaker 1984 gelet et al 2013 gossler et al 2020 kaviany 2012 kunii and smith 1961 minkowycz et al 1999 nield et al 2002 in other words if the time to equilibrate is long enough to affect heat transport the lte assumption may be inadequate resulting in what is referred to as local thermal non equilibrium ltne conditions ltne has been investigated mainly in the field of mechanical engineering where a typical scenario is to model flow into a parallel plate channel filled with a saturated porous medium haji sheikh and minkowycz 2008 lee and vafai 1999 minkowycz et al 1999 nield et al 2002 nozad et al 1985 shivakumara et al 2011 vadasz 2007 however such models and results cannot be directly transferred to hydrogeological systems because of the difference in boundary conditions or variables that are not representative for example nield et al 2002 studied the ltne in a forced convection problem in the context of industrial examples such as nuclear reactors and solar energy storage systems they used parallel plates as wall boundaries and applied the thickness of the porous channel in the definition of several dimensionless variables in geological systems such dimensionless variables cannot be defined in addition since the majority of research has focused on the factors that affect ltne there is a lack of explanation of the mechanism that could explain the model results therefore custom designed ltne studies representative of hydrogeological systems need to be conducted to explain the experimental or numerical results research into the ltne has progressed in the context of hydrogeological systems bandai et al 2017 gelet et al 2013 hamidi et al 2019 heinze and blöcher 2019 gossler et al 2019 gossler et al 2020 lu and xiang 2012 metzger et al 2004 rees et al 2008 rees 2010 roshan et al 2014 nouri borujerdi et al 2007 sarmasti and mazaheri 2017 for instance hamidi et al 2019 used a numerical model to simulate a deep geothermal system and revealed that hydraulic heterogeneity can enhance the disequilibrium between solid and fluid temperatures their results support the hypothesis that the rev can control the time for thermal equilibrium carbonell and whitaker 1984 kaviany 2012 roshan et al 2014 found that ltne could occur at low re values 0 01 they suggested that the velocity and heat exchange act in opposition and that this can cause thermal disequilibrium at low velocities on the other hand gossler et al 2020 used a two equation numerical model to predict the occurrence of ltne at seepage velocity 1 6 m d gossler et al 2020 also revealed a velocity variance at low velocities in porous materials with large particle sizes but they interpreted this as originating from differing boundary conditions when using lte and ltne models for example they found that the different interpretations at low flow velocities may result from different definitions of the nusselt correlation required to calculate the heat transfer coefficient between the phases the reported results cannot simply be combined because of the differences in modelling conditions such as porous materials velocity range and nusselt correlation so far in the context of thermogeological systems only few studies considered the effects of ltne on heat transport interpretations bandai et al 2017 heinze and blöcher 2019 gossler et al 2019 gossler et al 2020 metzger et al 2004 roshan et al 2014 with the experimental evidence of ltne lacking in particular the objective of this study is to experimentally verify the validity of the lte assumption and to investigate the potential effects of the ltne on heat transport interpretation we conducted laboratory experiments using solute and heat tracers applied at a range of distinct background flow velocities in water saturated and natural porous media we provide evidence for ltne conditions occurring under natural groundwater flow conditions and demonstrate that these effects must be considered when evaluating heat transport in hydrogeological settings 2 material and methods 2 1 description of the laboratory experimental system comprehensive laboratory experiments were conducted to investigate the lte during heat transport in natural materials fig 1 a shows the laboratory experimental setup which consists of a sand tank with dimensions of 1 3 m 0 6 m 0 8 m l w h fluid electric conductivity ec and temperature sensors connected to a data acquisition daq system the experimental setup was designed for a previous study to investigate the dispersion velocity relationship in saturated porous media and it was used to examine the effect of injected water and thermal dispersivity ratio during heat transport park et al 2018 park and lee 2021 in this work the same laboratory experimental system was used to verify the validity of the lte assumption by comparing the transport parameters of the solute and heat first solute transport experiments were performed at a range of darcy fluxes and analyzed with an analytical solution to the advective dispersive transport of the solute hunt 1978 rau et al 2012a to estimate the seepage velocity and hydrodynamic dispersion of solute then the heat transport experiments under various flow conditions conducted by park and lee 2021 were re interpreted analytically and the tracer front velocity and dispersion coefficients of heat were compared with those of the solute for the same flow velocities at that time the thermal properties of used sand table 1 obtained from the heat tracer experiments under the no flow condition conducted by park and lee 2021 were re used detailed procedures to evaluate the thermal properties are explained in park 2019 as shown in fig 1a the sand tank was composed of three chambers the water levels in two chambers on both sides can be adjusted and maintained to create a static hydraulic gradient between the chambers the middle chamber was filled with sand and served as a water saturated porous medium representative of a shallow aquifer before each transport experiment the water level in the left chamber was kept higher than on the right side for several hours ensuring that the residual tracer was removed from the material the hydraulic and physical properties of the sand were estimated in a previous study park and lee 2021 and were used to constrain the flow and transport description the uniformity cu and mean grain size d50 are 1 50 and 0 76 mm indicative of a homogeneous coarse sand friedman and sanders 1978 the porosity of the sand n was determined to be 0 374 0 0043 which are the average value and standard deviation of 51 measurements owing to the ideal properties of the sand for transport purposes we did not distinguish between the total porosity and effective porosity hydraulic conductivity was estimated to be 3 23 10 3 m s which falls within the permeability range of clean sand or gravel freeze and cherry 1979 2 2 solute and heat transport experiments by adjusting the hydraulic heads in both side chambers solute transport experiments were performed at 18 different darcy fluxes between 8 91 and 36 53 m d within the linear laminar flow regime reynolds number re 0 37 sodium chloride nacl 99 5 junsei chemical japan solution was used in the experiments as a conservative solute tracer according to schincariol and schwartz 1990 a density difference between water and nacl solutions upwards 1000 mg l can cause gravitational instability which can confound the interpretation of the dispersive solute transport to avoid this we used a 500 mg l nacl solution as a test we injected the solution into a well for 1 min at a rate of 50 ml min using a peristaltic pump minipuls 3 gilson usa the injected solution flowed uniformly through the screened interval 29 31 cm in height of the injection well into the saturated sand as shown in fig 1 ec as a proxy for changes in solute concentration was measured using four microelectrodes microelectrodes usa installed along the flow path ec measurements were recorded at 1 s intervals on a laptop computer through a daq system which consisted of four conductivity isopods ep357 edaq australia and podvu software edaq australia each solute transport experiment was continued until the values observed at the ec sensor placed farthest from the injection point l29 returned to the initial ec values after each experiment the middle chamber was flushed out by maintaining the flow to remove any residual nacl solution to validate the lte assumption and investigate its impacts on heat transport processes in a saturated porous medium this study reanalyzed the temperature time series data acquired during previous work park and lee 2021 the heat transport experiments were conducted by park and lee 2021 in two steps first experiments using an electrical resistor 7 mm diameter resistance of 47 ω and power rating of 5 w as a continuous point heat source were conducted five times under no flow conditions to estimate the bulk thermal diffusivity of the water saturated sand second resistor heating experiments were performed at 34 different darcy fluxes between 8 13 and 36 75 m d to quantify the relationship between thermal dispersion coefficients and thermal front velocities during the experiments constant power of 3 685 4 517 w was applied to the electrical resistor by a laboratory dc power supply ac input 220 v dc output 0 30 v because the temperature inside the middle chamber became uneven after each experiment the water was kept flowing for several hours to attain thermal equilibrium as shown in fig 1 temperature time series data from heat transport experiments were monitored by a daq system consisting of temperature sensors pt100 hayashi denko japan analog input modules ni 9217 national instruments usa a compact daq chassis cdaq 9178 national instruments usa and daq software daqmx and labview 2015 see park 2019 a total of 29 resistance temperature detectors rtds were installed at distinct locations downstream from the heat source within the saturated sand the rtds are 3 2 mm in diameter and 20 mm long and have the response time of 2 s to 63 of temperature shift from 0 to 100 c tstec 2021 they measured the temperature change at 0 1 s intervals during each experiment in this study the temperature time series data from the four observation points l15 l20 l25 and l29 fig 1b were used to compare the transport parameters of heat with those estimated from solute transport experiments because it was difficult to detect nacl concentrations in off center locations l12 and l19 we calculated the time for a 63 response to heating for the worst case experimental conditions fastest flow as approx 31 s this is 16 times slower than the sensors response time and demonstrates that the temperature responses were not influenced by the measurement system 2 3 analytical modeling of solute transport the advective dispersive transport of solute in a porous medium is described by a differential transport equation dte as follows de marsily 1986 1 c t d s 2 c v s c where c is the concentration of the solute kg m3 t is the time s and vs is the solute front or seepage or interstitial velocity m s the solute dispersion coefficient ds m2 s consists of diffusion and hydromechanical dispersion terms as follows de marsily 1986 2 d l t s d 0 s α l t v s where d0 s is the molecular diffusion coefficient of the solute in free water m2 s α is the solute dispersivity m and the subscripts l and t represent the longitudinal and transverse directions respectively the relative contributions of diffusive and advective solute transport can be quantified using the solute péclet number de marsily 1986 3 pe s vl d 0 s where v is the linear average velocity m s and l is the characteristic length of the fluid flow m for which the mean grain size d50 of a porous medium can be used de marsily 1986 in this study a molecular diffusion coefficient of 1 47 10 9 m2 s was used for sodium chloride to calculate the solute péclet number vitagliano and lyons 1956 for a continuous source at the origin within an infinite medium with a uniform flow along the x direction the solution of the dte in equation 1 with the initial condition of c x y z t 0 0 for x y z and boundary conditions of lim x y z c x y z t 0 and w 0 0 0 t 0 m is as follows hunt 1978 4 c x y z t m 8 π n e r d t s exp x v s 2 d l s exp r v s 2 d l s e r f c r v s t 2 d l s t exp r v s 2 d l s e r f c r v s t 2 d l s t here m is the mass flow rate kg s ne is the effective porosity and r is the spherical radius m defined by 5 r x 2 d l s d t s y 2 z 2 where x y and z m are cartesian coordinates equation 4 describes the change in concentration over time and at a distance from a continuous source however the microelectrodes installed along the flow direction measure the variation in fluid ec instead of concentration because the ec sensors are sensitive to pressure changes resulting from hydraulic control it is not possible to calibrate the sensors after the experimental setup rau et al 2012a however the time series data observed during the solute transport experiments can be used to indicate the relative solute concentration changes at the monitoring points for this reason the analytical model of equation 4 was normalized with respect to the steady state concentrations as follows rau et al 2012a 6 c n r t 1 2 e r f c r v s t 2 d l s t exp r v s d l s e r f c r v s t 2 d l s t where cn is the normalized concentration ranging between 0 and 1 for steady state flow along the x direction the solute velocity can also be calculated from the solute breakthrough curves as follows kreft and zuber 1978 7 v s x t 50 where t50 is the time when the concentration reaches 50 of the steady state concentration see fig 2 b this method is known as a method of moments mom and is regarded as robust because it is not governed by any physical transport model yu et al 1999 rau et al 2012a mathematically equation 7 represents the result for a delta input cn 0 t δ t however in the solute transport experiments a sodium chloride solution was injected for a finite duration of 1 min fig 2a therefore equation 7 was modified to consider the finite pulse input cn 0 0 t t0 1 as follows yu et al 1999 8 v mom s x t 50 t 0 2 2 4 analytical modeling of heat transport heat transport differs from solute transport in that thermal energy can propagate through both the fluid and solid phases the mathematical formulation of this problem requires two separate equations that are coupled together using a heat transfer coefficient an approach referred to as ltne kaviany 2012 since it is difficult to estimate the heat transfer coefficient especially for natural systems gandomkar and gray 2018 the theory is simplified by assuming that liquid and solid are one continuum with averaged thermal properties this is referred to as lte and it is generally used for heat transport in natural systems e g gossler et al 2020 under the lte assumption advective dispersive transport of heat in a saturated porous medium can be described by a three dimensional differential equation as follows de marsily 1986 9 t t d t 2 t v t t where t is the temperature c and vt is the thermal front velocity m s similar to the solute dispersion coefficient the thermal dispersion coefficient dt m2 s is also composed of thermal diffusion and hydromechanical thermal dispersion terms as follows rau et al 2012b 10 d l t t λ ρ c β l t v t m where λ is the bulk thermal conductivity w m k ρc is the bulk volumetric heat capacity j m3 k β is the thermal dispersivity and m is the coefficient describing the relationship between the thermal front velocity and thermal dispersion coefficient note that this is nonlinear because heat diffusion is much faster than solute diffusion leading to a different transport regime rau et al 2012a thermal diffusion comprises the bulk thermal conductivity defined as woodside and messmer 1961 11 λ λ f n e λ s 1 n e and the bulk volumetric heat capacity is defined as follows buntebarth and schopper 1998 12 ρ c n e ρ f c f 1 n e ρ s c s where the subscripts f and s indicate the fluid and solid phases respectively analogous to solute transport the relative dominance between conduction and mechanical dispersion can be evaluated by the thermal péclet number as follows de marsily 1986 13 pe t ρ f c f q l λ the heat transport equation in equation 9 was solved for an infinite aquifer under a uniform flow in the x direction by carslaw and jaeger 1959 with the initial condition of t x y z t 0 t0 and boundary conditions of lim x y z t x y z t t 0 and w 0 0 0 t 0 q the analytical solution is given in a modified form as follows rau et al 2012a 14 t x y z t t 0 q 8 π d t t ρ c r exp x v t 2 d l t exp r v t 2 d l t e r f c r v t t 2 d l t t exp r v t 2 d l t e r f c r v t t 2 d l t t 15 r x 2 d l t d t t y 2 z 2 equation 14 is known as a moving continuous point source mcps model which was used to analyze the heat transport experiments conducted at various flow velocities similar to the solute front velocity the thermal front velocity can also be calculated from the thermal breakthrough curve as follows 16 v 50 t x t 50 where t50 is the time s when the temperature reaches 50 of the steady state value however it should be noted that thermal and solute front velocities differ even under the same flow conditions because heat diffuses through solids whereas solute does not de marsily 1986 2 5 parameter estimation as shown in fig 2b the ec time series data for the finite pulse input were integrated and normalized into breakthrough curves btcs the solute front velocities vfit s and solute dispersion coefficients dfit s were estimated by fitting the solute forward model sfm in equation 6 to the btcs analogously heat transport experiments conducted at various flow velocities were interpreted using the mcps model in equation 14 the thermal front velocities vfit t and thermal dispersion coefficients dfit t were estimated by matching the model to the measurements based on the estimated bulk thermal properties listed in table 1 in this study curve fitting between the observed data and analytical models was performed using a nonlinear least squares function in matlab the goodness of fit was quantified using the root mean square error rmse and coefficient of determination r2 2 6 comparison of solute and heat transports in our study we are unable to apply the ltne model because estimating the heat transfer coefficient for ltne requires separate measurement of the temperature in both the liquid and solid phases which is infeasible for the grain sizes we used in our work further it has been shown that the ltne formulation reduces to that used for solute transport equation 1 if both the heat transfer into and through the solid phase are muted whitaker 1991 consequently if ltne is present within a system there must be a difference between the properties derived using solute and lte heat transport theories if the lte condition is valid the velocity and dispersion coefficient of the solute can be related to those of heat by a thermal retardation factor respectively the thermal retardation factor is defined by the ratio of thermal and hydraulic travel times banks 2012 theoretically under the lte assumption the travel time ratio becomes equal to the ratio of the volumetric heat capacity of the aquifer and the water the theoretical apparent thermal retardation factor rapp is defined in this study as follows bodvarsson 1972 gossler et al 2019 17 r app ρ c n e ρ f c f the thermal retardation factor defined as the travel time ratio can also be converted into the ratio of the seepage and thermal front velocities because the velocity is defined as the distance divided by the travel time as a result the effective thermal retardation factor reff represented by the velocity ratio is defined in this study as follows gossler et al 2019 18 r eff v s v t therefore the lte assumption can be verified by comparing two thermal retardation factors equations 17 and 18 because the theoretical rapp should be equal to the experimental reff under the lte assumption in the case of dispersion coefficients bons et al 2013 developed a unified expression for both solute and thermal transport they created a new concept the critical péclet number pec to explain the tracer behaviors through the various pore channels using a statistical approach pec was determined by the critical velocity which was calculated by capturing the location of each particle and by counting the number of particles that are dominantly moved by advection or diffusion the physical meaning of pec is the péclet number when the particle is equally distributed into advective and diffusive channels with this concept the relationship between two dispersion coefficients in the longitudinal direction was proposed using the theoretical thermal retardation factor under lte bons et al 2013 and it was slightly modified as follows due to the different definitions of the theoretical retardation factor 19 d l s t 1 r app d 0 s r app 1 d 0 f s t β l s t r app d 0 s t pe s t pe s t pe c s t 1 pe s t pe c s t where the superscripts s and t indicate the solute and heat and the subscripts s and f indicate the solid and fluid respectively d0 is the diffusivity m2 s and βl is a coefficient related to the geometry of the system defined as the coefficient of the relationship between the mechanical dispersion coefficient in the longitudinal direction and velocity v multiplied by the characteristic length l pet described in equation 19 was defined differently from equation 13 in this study using thermal diffusivity for the bulk volume as follows bons et al 2013 20 pe t vl d 0 t further information about this model can be found in bons et al 2013 in this study the validity of the lte assumption was investigated by confirming whether both solute and thermal dispersion coefficients estimated in section 2 2 satisfy equation 19 to fit equation 19 to the normalized solute dispersion coefficient it can be rewritten as follows 21 d norm s d l s d o s 1 β l s pe s pe s pe c s 1 pe s pe c s the normalized solute dispersion coefficients were fitted to the model equation 21 in the direction of minimizing the sum of squared residuals by changing two unknown parameters βl s and pec s the fitting was performed using a nonlinear routine implemented in matlab the fitted model for the solute dispersion coefficient was applied to the thermal dispersion coefficient to check whether the thermal dispersion coefficients showed good agreement with the model 3 results 3 1 solute transport fig 2b shows the observed and modeled normalized concentration time series at three monitoring points at a darcy flux of 14 60 m d the best fit models successfully reproduced the measurements with r2 0 9996 and rmse 0 0090 from this scenario the solute front velocities and solute dispersion coefficients for all experiments were determined to be in the range of 20 10 to 81 22 m d and 5 17 10 7 to 2 67 10 6 m2 s respectively because the vs would be further used to calculate the effective retardation factor and thereby test the lte assumption it was also estimated by another method the solute velocities evaluated using finite pulse mom ranged from 19 60 to 76 03 m d the results show good agreement between the two methods as evidenced by an r2 value of 0 974 fig 3 fig 4 shows the relationship between the solute front velocities and the solute dispersion coefficients estimated by the sfm a regression analysis indicated that the solute dispersion coefficients increased linearly with solute front velocities r2 0 979 pes corresponding to the flow velocities in this study were in the range of 142 to 583 according to de marsily 1986 this complies with a transport regime in which hydromechanical dispersion is the dominant transport mechanism in this regime a linear relationship between the flow velocity and dispersion coefficient is generally accepted 3 2 heat transport to estimate the thermal front velocities and thermal dispersion coefficients heat transport breakthrough curves for discrete darcy fluxes between 8 13 and 36 75 m d were analyzed using the mcps model described in equation 14 fig 5 shows the measured and modeled temperatures at four monitoring points for a darcy flux of 10 44 m d the best fit mcps models successfully reproduced the observations with r2 0 9969 and rmse 0 0040 k from the best fit models the thermal front velocities and thermal dispersion coefficients were determined to be 7 82 36 71 m d and 6 63 10 7 2 05 10 6 m2 s respectively because vt is used to calculate the effective retardation factor and thereby validate the lte assumption it was independently estimated from the normalized temperature breakthrough curves the thermal velocities of v50 t were in the range of 9 46 to 37 94 m d which is in good agreement with those estimated by the mcps model fig 6 fig 7 shows the relationship between the thermal front velocities and thermal dispersion coefficients estimated by the mcps model a regression analysis of the relationship indicates that the thermal dispersion coefficients increase exponentially with the thermal front velocities m 2 in equation 10 the pet calculated using equation 13 for the heat transport experiments in this study was in the range of 0 2 pet 0 8 this corresponds to the transition regime 0 5 pet 2 5 where diffusion and hydromechanical thermal dispersion compete for which it has been shown that the dispersion velocity relationship can be approximated by a square law rau et al 2012a 4 discussion 4 1 using tracer derived velocities to test for the lte assumption under the lte assumption the tracer front velocities of the solute and heat can be compared using two retardation factors that is the experimental reff equation 18 derived from the solute and heat front velocities should be equal to the theoretical rapp equation 17 as calculated from the volumetric heat capacities and porosity the theoretical rapp of this study ranges from 1 76 to 1 83 fig 8 which is narrow compared to the possible range 1 58 3 78 for saturated sand calculated from the literature stauffer et al 2013 fetter 2001 it should be noted that the source locations for the solute and heat transport experiments differed which led to longer transport distances for the solute compared to heat at the same observation points for this reason the velocities between observation points hereafter termed interval velocity need to be analyzed from the travel time information e g t50 of normalized data and sensor locations the experimental reff was computed using the interval velocity for the longest distance from l15 to l29 see fig 1 and they were in the range of 1 77 to 2 05 fig 8 as depicted in fig 8 at darcy fluxes lower than 20 m d the experimental reff agreed with the theoretical rapp with a difference of 5 at higher darcy fluxes reff deviates from rapp by up to 13 these deviations cannot be explained only by the spatial heterogeneity of the thermal properties table 1 because the differences between the two retardation factors increase with increasing flow velocity fig 8 as demonstrated by gossler et al 2019 the thermal velocities calculated from the normalized temperature of 0 5 are mainly affected by advection therefore a possible explanation for the deviations of reff from rapp could be the occurrence of non uniform flow rau et al 2012b found in their controlled sinusoidal heating experiments that even in the sub meter scale experiments performed with relatively homogeneous coarse sand cu 1 68 and d50 2 mm under a transition transport regime pet 0 7 a non uniform flow field can occur and affect the propagation of the thermal front using the heat transport data used here park and lee 2021 conducted a detailed analysis of the dispersion velocity relationship and observed that the discrepancy among thermal velocities increased with increasing flow velocity even at a single observation point this result indicates that the velocity field may not be homogeneous even in small scale experiments 0 25 m with homogeneous natural materials cu 1 50 which is consistent with previous findings park et al 2018 rau et al 2012b as the background flow velocity increases the difference between the heat derived seepage velocity and solute front velocity increases and becomes larger than the scatter in their relationship see fig s1 this cannot be explained only by the occurrence of a non uniform flow field another possible explanation for the increase in the deviation between reff and rapp could be the influence of the ltne according to zhang et al 2009 ltne conditions may occur with an increase in the background flow velocity and particle size of a porous medium recently gossler et al 2020 performed a 1d numerical study of advective dispersive heat transport in natural porous aquifers and presented the discrete lower limits of the lte assumption in terms of groundwater flow velocity vs 1 6 m d or grain size d50 7 mm heat transport experiments of this study were conducted at higher flow velocities 21 7 m d vs 98 3 m d than those of gossler et al 2020 vs 50 m d but the saturated sand used here had a smaller particle size d50 0 76 mm despite the smaller mean grain size the ltne effects on the velocity estimates occurred in our study this result may be related to the representative elementary volume rev because the concept of rev is used to define and measure the average properties of the volume of interest de marsily 1986 the size of the rev can be larger in a heterogeneous medium than in a homogeneous medium bear 1972 therefore the spatial heterogeneity of the thermal properties in table 1 can increase the size of the rev for the saturated sand leading to an increase in the particle size for a homogeneous numerical model for this reason we interpret that our heat transport experiments conducted at high background flow velocities using saturated sand with a small particle diameter illustrate the effects on the thermal front velocity caused by ltne the discrepancy between the theoretical rapp and experimental reff results could be caused by the ltne but other possible factors inherent in experimental conditions must first be excluded this means that the difference between the retardation factors does not necessarily indicate the effect of the ltne on heat transport the heterogeneity of physical properties is a general problem under real world conditions because most models assume homogeneous properties the heterogeneous properties of hydraulic and thermal parameters can cause errors in transport parameter estimation for example the existence of a distinction between high and low permeability can lead to large errors for the velocity estimates especially at low flow velocities schornberg et al 2010 the discrepancy between rapp and reff can be attributed to the errors in the slow velocity estimates this means that the difference between rapp and reff could be large even at low velocities considering that the velocity difference in this study was 13 it would be difficult to verify the lte assumption under more heterogeneous field conditions using the tracer front velocities 4 2 using tracer derived dispersion coefficients to verify the lte assumption bons et al 2013 developed a universal dispersion model that enables a direct comparison of the solute and thermal dispersion coefficients which was introduced in equation 19 because the dispersion model was validated over a wide range of transport regimes up to pe 106 in bons et al 2013 it is fully applicable to transport experiments conducted in our study 10 1 pe 103 the pet defined in equation 20 was used in bons et al 2013 we note that these pet values are presented in fig 9 whereas the pet values calculated using equation 13 are presented in fig 7 when assuming lte the dispersion coefficients of both the solute and heat should lie on a single curve predicted by the dispersion model consequently a discrepancy between the thermal dispersion coefficients predicted from solute transport and those estimated from the heat transport experiments indicates the existence of ltne fig 9a shows the solute and thermal dispersion coefficients estimated by the transport experiments and the corresponding dispersion model with respect to pe the dispersion model matches the solute dispersion coefficients estimated from the solute breakthrough curves fig 9a the normalized dispersion coefficients predicted by the dispersion model dnorm model were compared with the normalized thermal dispersion coefficients estimated by the analytical solution dnorm fit t at three monitoring points l15 l20 and l25 estimates from monitoring point l29 were excluded from the comparison owing to the large data scatter see fig 7 as shown in fig 9a the estimated thermal dispersion coefficients increasingly deviate from the prediction of the dispersion model with increasing flow velocity this result indicates that the bons et al 2013 dispersion model is no longer valid and its underlying assumptions are violated therefore thermal dispersion coefficients cannot be predicted from solute transport experiments and vice versa gossler et al 2020 quantified the degree of ltne using three different metrics one of these is the ratio of thermal dispersion coefficients estimated from the temperature breakthrough curve generated by the lte and ltne models method 1 in gossler et al 2020 we evaluated the degree of ltne based on the ratio of thermal dispersion coefficients predicted by the solute tracer dnorm model in this study and estimated using a heat tracer dnorm fit t in this study as shown in fig 9b for pe 0 9 the ratios of thermal dispersion coefficients at monitoring points l20 and l25 exceeded 1 5 the upper limit of quasi lte which is defined by considering the uncertainty in thermal dispersion estimates as up to 50 gossler et al 2020 the maximum ratio was 2 12 at l25 as shown in fig 9b the spatial difference between l15 and l25 was 21 on average at the lowest pe the spatial differences originate from the process of normalizing the thermal dispersion coefficients which could be due to heterogeneity in the thermal properties table 1 or thermal front velocity differences however the increasing discrepancy between dnorm model and dnorm fit along with the increase in flow velocity cannot be explained by spatial heterogeneity other possible explanations could be small scale non uniform flows or ltne it is well known that non uniform flow conditions affect solute transport more than heat transport irvine et al 2015 the spatial difference of the normalized solute dispersion coefficient solely caused by mechanical dispersion did not show any trend with the solute velocity and had an average of 7 9 for all velocities this means that non uniform flow can be ruled out as an influence because it cannot explain the differences between dnorm model and dnorm fit therefore we conclude that ltne contributes to the inconsistency between the dispersion results derived from modelling and experimentation bandai et al 2017 compared the dispersion coefficients of solute and heat tracers for three porous media with differently sized glass beads mean grain sizes of 0 41 1 10 and 4 94 mm they found that unlike solute dispersion the thermal dispersion increased when the particle size decreased and hypothesized that this was caused by the ltne effects the same was reported by lu et al 2019 for sand silt loam and sandy clayey loam in addition as emphasized by gossler et al 2020 the discrepancy between dnorm model and dfit t was up to 112 which was larger than that between rapp and reff maximum 13 found in our study surprisingly in our results we found an onset of ltne for much smaller particles but at much higher velocities compared to the limits derived by gossler et al 2020 since our experimental velocities exceeded those considered by gossler et al 2020 this could be due to the relationship between velocity and particle size for ltne fig 7 in gossler et al 2020 alternatively this could be caused by our experimental conditions not reflecting the broad nusselt correlation derived in gossler et al 2020 from a few experiments a different nusselt correlation would lead to a difference in the heat transfer coefficient and alter their limits for the onset of ltne the latter explanation is more likely and demonstrates that more experimental research is required to quantify the heat transfer coefficients for natural materials and flow conditions 4 3 implications for heat transport modelling in natural sediments field conditions are generally more complicated due to the pervasive presence of heterogeneity irvine et al 2015 zech et al 2016 zhu and yeh 2005 as mentioned by rau et al 2014 an appropriate rev needs to be defined if the heat transport is simplified by volume averaging in a heterogeneous medium the time for thermal equilibrium between a solid and its neighboring fluid can be increased because of the larger rev rau et al 2014 carbonell and whitaker 1984 however there is no clear guidance on how to define an rev that ensures a valid lte assumption for natural sediments in the literature consideration of the effects of ltne on heat transport in field experiments is an open research question with significant implications several variables have been suggested in the literature to assess the validity of the lte assumption for heat transport in a porous medium such as the effective fluid prandtl number local nusselt number sparrow number biot number and darcy number kim and jang 2002 lee and vafai 1999 minkowycz et al 1999 nield et al 2002 unfortunately these criteria cannot be directly applied to hydrogeological systems because of the differences in boundary conditions or dimensionless variables that are unknown in natural systems to overcome such limitations gossler et al 2020 defined lower limits for groundwater flow velocity and particle size which ensure that lte is provided using theoretical analyses however our study illustrated that ltne could occur for smaller particle sizes than predicted by gossler et al 2020 but at flow velocities that exceed their considerations our experimental results show that higher flow velocities could violate lte assumptions for smaller grain sizes than theoretically predicted suggesting an interdependency between the previously defined limits for grain size and flow velocity further since our results are experimental there could be a discrepancy between theory and physical reality consequently more experimental studies are needed to elucidate the validity of lte for heat transport in natural sediments in this study the ltne impact on the thermal front velocity estimates was not noticeable when the advective transport velocities were evaluated using heat and solute tracers this verifies the theoretical findings of gossler et al 2019 and gossler et al 2020 based on these results it is expected that any ltne impacts on the flow velocity estimates conducted in previous studies that interpreted temperature breakthrough curves and assumed lte conditions seemed to be negligible in contrast the impact of ltne on the estimated thermal dispersion coefficients was noticeable in our experiments as has also been predicted theoretically by gossler et al 2020 albeit for lower grain sizes and higher velocities knowledge of mechanical thermal dispersion has been demonstrated to be important when modelling thermal plumes in natural systems lo russo and civita 2009 park et al 2018 sauty et al 1982 it is common to either interchange heat and solute dispersion or infer one from the other because ltne can affect dispersion estimates such inference can lead to erroneous results overall our results demonstrate that ltne effects need to be considered when accurate heat transport modelling is required further experiments are necessary to determine accurate physical limits for lte and to investigate the impact of natural system characteristics on the onset of ltne heat transport 5 conclusions we conducted systematic laboratory experiments using solute and heat tracers to test and verify the common assumption of local thermal equilibrium lte heat transport in porous materials under natural flow conditions previous numerical investigations have predicted that local thermal non equilibrium ltne should not occur for grain sizes smaller than 7 mm or flow velocities slower than 1 6 m d surprisingly we found an increasing occurrence of local thermal non equilibrium ltne for heat transport through uniform sand with a grain size of 0 76 mm and flow velocities 20 m d in agreement with previous research we confirmed that the estimated flow velocity remained unaffected whereas thermal dispersion was influenced by the presence of ltne we provide the first experimental evidence for ltne effects during heat transport in natural sediments and show that ltne impacts can occur as has been predicted in previous studies however our experiments indicate smaller particles and higher velocity limits for the onset of ltne compared to those predicted in the literature we hypothesize that this may be caused by different heat transfer coefficients between fluid and solids in our experiment compared to the generic conditions derived from limited experimental data in previous work our work shows that ltne effects may need to be considered when assessing the impact of thermal dispersion on heat transport in natural hydrogeologic systems for example when modelling the spatial and temporal evolution of temperature plumes further research is required to test different material sizes and flow velocities so that more accurate and robust limits for lte heat transport under natural conditions can be defined credit authorship contribution statement ji young baek methodology validation formal analysis investigation resources data curation writing original draft writing review editing visualization byeong hak park conceptualization methodology validation investigation resources data curation writing original draft writing review editing visualization gabriel c rau resources writing review editing visualization kang kun lee resources writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national research foundation of korea nrf grant funded by the ministry of science and ict msit of the south korean government grant number 2017r1a2b3002119 this work was also supported by the institute for korea spent nuclear fuel iksnf and the national research foundation of korea nrf grant funded by the korean government ministry of science and ict msit grant number 2021m2e1a1085200 the authors appreciate the insightful and constructive comments made by anonymous reviewers appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127589 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3456,the gravity recovery and climate experiment grace provided an entirely new way to measure mass changes on the earth at unprecedented accuracy and resolution however the delayed launch of the grace follow on fo mission led to an approximately 1 year gap between grace and grace fo data breaking the continuity of observation and hampering data analysis efforts have been made to bridge this gap for the major river basins but little has been done on ice sheets to address this limitation we evaluated multiple linear regression mlr a back propagation neural network bpnn and a deep belief network dbn to fill the data gap in greenland and its six sub regions we employed these methods to establish the relationships between precipitation runoff evapotranspiration and ice discharge and grace estimated ice mass changes a sliding window testing method shows that the bpnn outperformed the two other methods with a root mean square rms error of 1 5 cm in the metrics for the equivalent water height for the whole of greenland and 1 5 3 6 cm 2 5 cm in average for the six sub regions this accuracy is rather high given an uncertainty of 2 cm in grace estimates but higher for the whole of greenland than in the sub regions this difference was caused by mass leakage error between adjacent sub regions in the grace observations and can be mitigated by merging these sub regions the bpnn predicted ice mass changes agree with the grace estimates for long term and seasonal signals but are less accurate and precise for interannual signals based on the grace observations and the bpnn predicted values we re estimated the ice mass change in greenland finding that ice loss on greenland decelerated after mid 2012 primarily due to deceleration in sw se and ne regions keywords greenland grace ice mass balance gap filling artificial neural network 1 introduction the gravity recovery and climate experiment grace twin satellites have been observing the earth s time varying gravity filed since their launch in march 2002 tapley et al 2004 the time varying gravity observations have been successfully interpreted as change in the mass of the earth thus permitting the monitoring of changes in terrestrial water storage tws ice sheet and glacier mass sea level and ocean bottom pressure as well as increasing the understanding of climate change tapley et al 2019 however grace stopped service in october 2017 during its operation from march 2002 to october 2017 grace has revolutionized the way of monitoring tws change and ice mass balance and expanded our views on the complex interactions and transitions involved in the regional and continental hydroclimatic phenomena and human activities tapley et al 2004 sun et al 2021 a successor to the grace mission the grace follow on fo mission was launched in may 2018 to continue observing the global tws change and ice sheet and glacier mass balance the continuity of the mass balance record across the grace grace fo missions has been examined and demonstrated in greenland and antarctica velicogna et al 2020 and in world s glaciers and ice caps ciracì et al 2020 landerer et al 2020 compared the grace grace fo observations to independent mass change estimates and found no intermission biases between grace and grace fo however the delayed launch of the grace fo mission caused an approximately 1 year data gap between grace and grace fo breaking the continuity of observations and influencing the study of short term changes in tws and ice mass balance this gap may introduce biases in analysis of grace based mass products therefore filling the gap between grace and grace fo is necessary to maintain data continuity and facilitate data analysis this is especially necessary in the cases of the greenland and the antarctic ice sheets since they lose hundreds of gigatonnes of ice mass per year and a change in the ice loss trend occurred around the time of the data gap zhang et al 2021 for antarctic ice sheet greenland ice sheet will be demonstrated later if this gap is not filled properly on ice sheets we will not know exactly when the change happened and why the european space agency s swarm measurements can bridge the gravity data gap between grace and grace fo lück et al 2018 forootan et al 2020 teixeira da encarnação et al 2020 richter et al 2021 zhang et al 2021 but the swarm data only contains sufficient information to reconstruct low degree signals for instance below degree 12 teixeira da encarnação et al 2020 iterative singular spectrum analysis ssa kondrashov ghil 2006 can fill the data gap at the global scale wang et al 2021 yi and sneeuw 2021 however this method in essence interpolates the missing observations by taking advantage of the temporal correlation of the grace grace fo data and does not add new information velicogna et al 2020 filled the data gap between grace and grace fo in greenland and antarctica by adjusting the trend offsets between grace and mass budget method mbm estimated ice mass changes however this method only considers the trend differences between grace and mbm estimated ice mass changes and does not correct the differences in high frequency signals long et al 2014 used artificial neural network ann models tohindcast grace like tws anomalies in yun gui plateau since then ann models have been widely used to reconstruct tws change with hydroclimatic variables as input sun et al 2019 2021 li et al 2020 sahour et al 2020 sun et al 2020 some of these attempts obtained impressive results but their models and input variables are not suitable for reconstructing mass change over ice sheets since few methods have been proposed particularly for bridging grace grace fo gap over ice sheets we evaluated a statistical method multiple linear regression a machine learning method back propagation neural network and a deep learning method deep belief network to reconstruct the grace like ice mass changes from precipitation p evapotranspiration e runoff r and ice discharge d in greenland in contrast to velicogna et al 2020 and yi and sneeuw 2021 we establish more complex relationship between grace data and other independent data thereby fully taking advantage of the information imbedded in the independent data through this exercise we provide a qualified candidate method for filling the data gap between grace and grace fo over ice sheets 2 data 2 1 csr grace grace fo mascon rl06m data since there are so many grace based ice mass change products and different delineations of drainage basins in greenland it is not practical to fill data gap for each of the grace product and drainage delineation combination although the gap filling methods proposed later are applicable to any grace based ice mass change product the grace grace fo mascon rl06m v02 solutions save 2020 from the center for space research csr were used to validate the feasibility of the each proposed method in this dataset grace and grace fo mascons were estimated with the same standards as the csr rl06 spherical harmonic solutions using grace level 1 observations compared to the rl05 solutions save et al 2016 rl06 mascon solutions use a newly defined grid in which the hexagonal tiles that span across the coastline are split into two tiles along the coastline to minimize the leakage between land and ocean signals in addition the rl06 mascon solutions are released as 1 4 degree instead of 1 2 in rl05 which benefits the representation of coastlines the ellipsoidal correction for csr rl06 mass anomaly grid representation was applied as described by ditmar 2018 this correction was applied separately for land and ocean to prevent any leakage of the land signal correction into the ocean the c20 coefficients were replaced with those from satellite laser ranging slr for grace and grace fo and the c30 coefficients were replaced with those from slr for grace fo only loomis et al 2019 the degree 1 coefficients geocenter motion corrections were applied using the estimates in tn 13a sun et al 2016 the glacial isostatic adjustment was corrected using the ice6g d model peltier et al 2018 we followed save et al 2016 to extend the coastlines of greenland by 120 km into the ocean to take into account the land ocean mass leakage based on the new boundaries and the delimitation of drainage basins by rignot et al 2011 we divided greenland into six sub regions no north nw northwest cw central west sw southwest ne northeast and se southeast as shown in fig 1 we used the csr mascon rl06 solutions to estimate the ice mass change of greenland and its six sub regions we therefore obtained seven mass change time series each having a data gap between june 2017 and may 2018 in the following we will bridge this data gap between grace and grace fo estimated ice mass changes for the seven regions 2 2 ice mass balance data in greenland the ice mass balance can also be estimated by mbm 1 dm p e r d where dm is the ice mass change and the result of p e r is surface mass balance smb therefore the mbm may be used to bridge the data gap between grace and grace fo over greenland although the mbm can yield monthly estimates of ice mass change at the basin scale we cannot directly use these estimates to fill the data gap since there are biases between the mbm and the grace fo estimated ice mass changes a potential solution to this problem is adjusting the mass balance components p e r and d to match the grace estimated ice mass changes therefore we used p e and r from the mar model version 3 11 5 fettweis et al 2017 updated in 2021 and d from mankoff et al 2020 as the forcing variables to reconstruct grace like ice mass changes the mar data are the monthly increments provided at 10 10 km grids over the entire greenland ice sheet peripheral glaciers ice caps and tundra areas we integrated the monthly p e and r at each grid point and then summed the values of all points within each of the seven regions to obtain the accumulated p e and r of that region mankoff et al 2020 provided a new dataset for greenland ice sheet solid ice discharge from 1986 to march 2020 to produce this dataset ice velocity ice thickness and the position of the discharge gates were needed ice velocity data from sentinel 1a and 1b derived by promice measures 0478 joughin et al 2010 joughin et al 2015 updated in 2018 measures 0646 howat 2017 and mouginot et al 2018a 2018b were used to estimate ice thickness surface elevation from greenland ice mapping project gimp howat et al 2014 2017 adjusted through time with surface elevation change from khan et al 2016 and bed elevation from bedmachine v3 replaced by millan et al 2018 were used this dataset includes all discharging ice that flows faster than 100 m yr and was generated through an automatic and adaptable method the discharge gates were positioned near the present year termini based on the surface speed and an ice mask the total ice discharge from mankoff et al 2020 was estimated to be 10 less than that of mouginot et al 2019 and enderlin et al 2014 and similar to that of king et al 2018 in this study the accumulated p e and r from the mar model and d from mankoff et al 2020 were used to estimate ice mass balance and fill the data gap for the seven regions 3 methodology the basic idea behind using p e r and d to reconstruct the missing grace like ice mass estimates is to establish the relationships that adjust p e r and d to best match grace grace fo estimated ice mass changes multiple linear regression mlr back propagation neural network bpnn and deep belief network dbn methods were employed to build these relationships 3 1 multiple linear regression the mlr method is a simple statistical technique that models the linear relationship between dependent variable and independent variables and used to explore the links between key variables in hydrology and climate sciences seidou et al 2007 its formula is expressed as in eq 2 2 dm t a 0 a 1 p t a 2 e t a 3 r t a 4 d t where m is the dependent variable which is the grace grace fo estimated ice mass change at time t p e r and d are the independent variables and a 0 a 1 a 2 a 3 a 4 are the coefficients to be estimated we interpolated p e r and d to the sampling time of the grace observations and fed all the available m p e r and d data into eq 2 to solve for the coefficients using a least square method for each of the seven regions when the coefficients were optimally determined we used eq 2 and p e r and d data to predict m between grace and grace fo and thus filled the data gap 3 2 back propagation neural network the bpnn employs a gradient descent method to minimize the differences between the network output and the target output hecht nielsen 1992 because of its strong nonlinear fitting ability it has become one of the most commonly used machine learning methods we used a classic bpnn model that contains an input layer a hidden layer and an output layer the structure is shown in fig 2 the number of neurons in the input and output layers were equal to the number of sample pairs the number of neurons in the hidden layer should be optimized each neuron in the input layer contains p e r and d for a certain time the corresponding neuron in the output layer contains grace grace fo estimated ice mass change in any bpnn each neuron in one layer is directly connected to the neurons of the subsequent layer with an activation function a sigmoid function was employed as the activation function between the input and hidden layers and the linear function is used as the activation function between the hidden and output layers when training the network we used the the nguyen widrow method nguyen and widrow 1990 to initialize the weights and biases of the network and employed the levenberg marquardt l m algorithm levenberg 1944 marquardt 1963 to iteratively adjust the weights and biases until the model obtained the minimal mean square error we used the l m algorithm since it has fast convergence speed as well as the high precision in moderate sized bpnn training mukherjee and routroy 2012 the maximum number of iterations was set to 1000 the performance goal was set to 0 00 the minimum performance gradient is set to 1 0 10 7 the bpnn however does not guarantee a global optimal mukherjee and routroy 2012 thus to avoid local optima in the model training we used random weights for the neurons and repeated the training process 50 times taking the average training result after removing outliers as the final training result we used a posteriori way to determine the optimal number of neurons in the hidden layer that is based on the testing root mean square rms error fig s1 of the supplementary material sm shows the testing rms error versus the number of nodes in the hidden layer in greenland and the six sub regions in which the number of nodes that corresponds to the smallest rms is taken as the optimal number of nodes in the hidden layer 3 3 deep belief network as a classic deep learning neural network dbn stacks several restricted boltzmann machines rbms and ends with a back propagation bp layer hinton et al 2006 each rbm is composed of a visible layer and a hidden layer which are bidirectionally linked the hidden layer in the prior rbm serves as the visible layer in the next rbm connections exist between rbms but do not between units within layers a dbn structure with two rbms was used in this study as shown in fig 3 when training this dbn we trained the rbms layer by layer without supervision using the contrastive divergence algorithm hinton salakhutdinov 2006 to obtain the approximate weight to initialize the multi layer neural network the dbn worked as a feed forward neural network and the supervised bp algorithm was used to fine tune the weights of each layer to yield the final dbn model the neuron numbers in the visible and output layers are the same to the number of the sample pairs the neuron numbers in the two hidden layers were optimized and set in the same way for simplicity we used the same method as in the case of the bpnn model to determine the number of nodes for the two hidden layers fig s2 of the sm illustrates the testing rms error versus the number of nodes in the hidden layers for greenland and the six sub regions in which the number of nodes corresponding to the smallest rms was taken as the optimal number of nodes for the hidden layers 3 4 model performance testing since the main purpose of this study was to fill the approximately 1 year data gap between grace and grace fo a conventional testing method like k fold cross validation was not suitable in this case as it randomly divides the samples into training and testing sets some researchers used the first several years of grace data for training and the remaining years for testing li et al 2020 sun et al 2020 when reconstructing the tws changes but this method is not ideal since more data could have been involved in modeling and testing to fully take advantage of all the grace grace fo data we separated the whole process into modeling and testing processes in the modeling process all data were used to train the three models without testing in the testing process a sliding window testing swt method was employed to estimate the model performance in each swt run one year of data in the window was removed for testing and the remaining data were used to train the model which was then used to predict data in the removed year we obtained a time series of predicted data by sliding the window removing one year starting from the first year to the last year and repeating the process for all the years by comparing the predicted data to the original grace time series we estimated the model performance quantitatively by bias standard deviation std rms and correlation coefficient cc to eliminate the influence of long term trends on the cc calculations the ccs hereafter were calculated based on the detrended time series since the testing process uses one less year of data to train the model than the modeling process it tends to give a conservative estimate of the model performance 4 results 4 1 reconstruction accuracy table 1 exhibits the training and testing accuracy results for the three methods in the seven regions the bpnn method obtains the smallest training and testing rms among the three methods indicating the bpnn method outperforms the two other methods note that the dbn method obtains nearly identical rms results to the bpnn method and both the dbn method and the bpnn method are apparently better than the mlr method since the dbn method is more complex than the bpnn method we prefer the bpnn method and will focus our analysis on the bpnn results hereafter among the six sub regions the bpnn method has biases ranging from 0 5 cm sw to 0 2 cm ne with a mean bias of 0 1 cm and rmss from 1 5 cm no to 3 6 cm se with a mean rms of 2 5 cm the relatively weak reconstruction accuracy occurred in the sw 3 4 cm in terms of rms and se 3 6 cm this was where more than 100 gt of ice was lost each year the bpnn method obtained a reconstruction accuracy of 1 5 cm for the whole of greenland which is not only the best performance among the seven regions but also superior to the mean performance for the six sub regions this suggests that the data gap can be better reconstructed for the whole of greenland than in sub regions fig 4 shows the comparisons among the original grace estimated ice mass changes the predicted time series from the testing process and the final fitted time series from the modeling process overall both the predicted and fitted ice mass changes agree with the grace estimated ice mass changes which together with the information in table 1 adds confidence to the gap filling for june 2017 and may 2018 however in the ne rms 18 5 gt the agreement between grace estimated and bpnn reconstructed mass changes is actually not as good as in other regions given that ne lost only 17 0 gt ice mass per year this may be due to the gentle mass change in ne that caused grace to have low signal to noise ratio in that region as suggested by the irregular fluctuations in fig 4c despite limitations in sub regions the bpnn method still outperforms the existing methods wang et al 2021 and yi and sneeuw 2021 used the ssa based methods to fill the gap at the global scale and discussed the reconstruction accuracy in greenland yi sneeuw 2021 used the iterative ssa but did not present accuracy information comparable to this study wang et al 2021 used an improved ssa and claimed their method was better than the iterative ssa although wang et al 2021 used only 11 months of data in the middle of the time series to validate the reconstruction accuracy their results were still not as accurate as those we report rms 1 9 cm vs 1 5 cm in greenland in addition ssa based methods cannot guarantee interpolation accuracy near the ends of the time series as the ssa is strongly influenced by the edge effect 4 2 compare with mass budget method since the mbm can also estimate ice mass balance we compared the bpnn reconstructed ice mass changes to the mbm estimates table 2 shows the differences between grace estimated mass changes and the mbm estimates for the seven regions this table illustrates noteworthy biases between grace and mbm estimated mass changes in all the seven regions with biases grace mbm ranging from 11 7 cm cw to 1 2 cm ne this implies that grace underestimated the mass change relative to the mbm method the rms of the differences ranges from 2 9 cm ne to 41 5 cm cw with an average value of 17 0 cm the largest disagreement appears in the cw and sw regions the average bias and rms of the six sub regions were 6 2 cm and 17 0 cm while the bias and rms for the whole of greenland is 6 1 cm and 8 5 cm this indicates that grace and mbm estimated mass changes agree better for the whole of greenland than in the sub regions similar to the case of the reconstructed mass changes fig 5 presents the comparisons between mass change estimates from grace and mbm it intuitively demonstrates that grace estimated mass changes have smaller rates in the no nw cw and greenland larger rates in the sw and close rates in the ne and se than the mbm estimated rates velicogna et al 2020 attributed these trend offsets to the uncertainties in the gia correction in the grace data and uncertainties in absolute ice discharge and smb rate deviations cause great differences between the two data sets which explains why we cannot directly use the mbm estimates to fill the grace data gap comparing table 1 to table 2 and fig 4 to fig 5 we can observe that the bpnn reconstructed ice mass changes agree much better with the grace estimated mass changes than the mbm estimated mass changes 5 discussion 5 1 reconstruction uncertainties it is easily observed in fig 4 that the long term trends are well reconstructed in the predicted time series which means the reconstruction uncertainties mainly lie in the short term variations the lomb scargle periodogram lsp was employed to further investigate the uncertainties the lsp lomb 1976 scargle 1998 detects and characterizes periodicity in unevenly sampled time series and used in many fields vanderplas 2018 we applied the lsp to the differences between the detrended grace estimated ice mass changes simply called g hereafter and the detrended bpnn reconstructed ice mass changes r hereafter for comparative purposes we also applied the lsp to the differences between the detrended grace estimated and the detrended mbm estimated ice mass changes m hereafter fig 6 shows the differences g r and g m in the left panels and the lsp results in the right panels for the seven regions note that the power of g m and g r was normalized by their largest power for the less than eight year periods which means the power can be compared within the same data but cannot be compared between g m and g r despite the trend differences are eliminated the reconstructed mass changes still have much smaller rms values than the mbm estimated values for the seven regions i e 2 5 vs 1 5 cm in no 3 0 vs 2 1 cm in nw 2 6 vs 2 2 cm in ne 3 7 vs 2 1 cm in cw 7 0 vs 3 4 cm in nw 6 1 vs 3 6 cm in se and 3 1 vs 1 5 cm in greenland this implies that merely correcting the trend offsets in mbm estimated mass changes cannot fully restore the grace like ice mass changes in addition g m has a dominant power at the annual scale and strong power at the interannual and semi annual scales indicating that the largest difference between g and m lies in annual variations besides the long term trends different from the g m the g r exhibits a low power at the annual scale for the seven regions implying the bpnn method effectively restored the annual variations from p e r and d the g r however has relatively large power at the semi annual except for cw and inter annual scales especially at the inter annual scale by comparing the periodograms for g r and g m we conclude that the bpnn method effectively reconstructed the annual signals as well as the linear trends but did not perform as well in semi annual and interannual signals since the irregular interannual ice mass change is violent in greenland and difficult to model we infer that the relationship between g and m is inconstant at the interannual scale which hinders the ability of bpnn to reconstruct the grace like ice mass change from p e r and d fig 6 also shows that the six sub regions have relatively larger reconstruction uncertainties than the whole of greenland especially since the sw and se have a reconstruction accuracy of only 3 4 cm and 3 6 cm since the grace like ice mass changes were reconstructed from smb and d the deviations in smb and d will cause uncertainties fig 6e and 6f demonstrate that the values of g m fluctuated significantly in sw and se regions indicating the mbm estimated mass changes did not agree well with the grace estimated values and the disagreement changed randomly over time and led to relatively poorer reconstruction accuracy in the sw and se regions in other regions where the values of g m had gentle variations the reconstruction accuracy was much better we also observed that when the g m tended to be positive in the sw it would tend to be negative in the se when we merged the two sub regions and recalculated the g m and g r we obtained the results displayed in fig 7 this graph shows that g m had much gentler variations in the sw se than in the sw or the se and that the difference between g and m decreased to 4 4 cm and the reconstructed accuracy was improved to 2 4 cm much better than 3 4 cm in the sw and 3 6 cm in the se this phenomenon motivated us to attribute the uncertainties to a mass leakage error between sub regions this conclusion is reinforced in table 1 where the mean reconstruction accuracy of the six sub regions was poorer than the whole of greenland fig 5 indicates that the grace estimated mass change has a smaller rate than the mbm estimated mass change in the cw region whereas there is a larger rate in the sw region since more than half of ice mass of greenland losses are from the cw sw and se every year it is reasonable to infer that non negligible mass leakage exists among cw sw and se in the grace observations if this inference is correct then the reconstruction accuracy would be improved by merging sub regions to verify this inference we tested the reconstruction accuracy of merged regions and compared the mbm estimated mass changes to the grace estimated values as presented in table 3 this table clearly shows that the reconstruction accuracy of the bpnn method was improved when more regions were merged the reconstruction accuracy was poorest in the se 3 6 cm and sw 3 4 cm but sharply increased to 2 4 cm when the sw and se regions were merged the reconstruction accuracy was further improved when cw and nw were also merged merging the ne region did not improve reconstruction accuracy which was because the ne and its neighboring regions lost only a little mass the differences between the grace estimated mass changes and the mbm estimated values also became smaller when more regions were merged these findings indicate that mass leakage between sub regions caused uncertainties in reconstructing grace like ice mass changes and enlarged the differences between grace and mbm estimated ice mass changes in the sub regions 5 2 new ice loss trends we re estimated the ice loss rate in the six sub regions and greenland based on the filled grace data to get the state of the art knowledge of the ice loss in greenland we used a constant a linear trend a quadratic term and four seasonal terms to fit the grace estimated ice mass changes and resolved the coefficients using the least square method since we considered acceleration the velocities mentioned hereafter refer to temporal mean velocities fig 8 shows the ice mass change time series and their quadratic fittings since the ice mass change exhibited clearly different trends before and after 2012 5 we solved velocities and accelerations separately for 2002 4 2012 5 2012 5 2020 4 and 2002 4 2020 4 as displayed in fig 8 and table 4 overall greenland and all its six sub regions demonstrated decelerated ice loss in 2012 5 2020 4 in contrast to 2002 4 2012 5 this was especially significant in the se sw and ne regions the se region had an ice mass change rate of 89 4 7 9 gt yr with an acceleration of 0 3 1 1 gt yr2 before 2012 5 but the velocity sharply dropped to 45 5 5 8 gt yr after 2012 5 although its acceleration increased to 6 5 1 0 gt yr2 which makes se the most decelerated region the second most decelerated region is the sw where the velocity decreased from 48 7 4 4 gt yr to 36 1 7 3 gt yr and the acceleration dropped from 10 6 0 6 gt yr2 to 3 5 1 3 gt yr2 the ne region showed an apparently decreasing trend 22 0 4 4 gt yr before 2012 5 but this trend almost disappeared after 2012 5 and assumed a stable state the nw and cw kept nearly the same ice mass loss velocity before and after 2012 5 but the ice loss acceleration decreased sharply after 2012 5 which implies the acceleration trend was gone only the no region retained both a stable velocity and acceleration in the whole 2002 4 2020 4 time frame as for the whole of greenland it had a velocity of 266 5 10 3 gt yr and an acceleration of 24 4 1 5 gt yr2 before 2012 5 but after 2012 5 the velocity and acceleration became 197 6 25 8 gt yr and 16 4 4 4 gt yr2 respectively suggesting a clear change in trend many scientists have reported a sharp acceleration of ice loss in greenland before 2013 e g 30 11 gt yr2 for 2002 2009 velicogna 2009 21 9 1 gt yr2 for 1992 2009 rignot et al 2011 25 9 gt yr2 for 2003 2012 wouters et al 2013 and 27 7 4 4 gt yr2 for 2003 2013 bevis et al 2019 compared to these acceleration estimates the trend change after 2012 5 was even more impressive when looking at the whole period 2002 4 2020 4 we observe that greenland and its six sub regions had very small accelerations 0 5 4 1 gt yr2 and that many strong negative accelerations before 2012 5 became positive this indicates that the ice mass loss in greenland decreased in recent years although record ice loss was observed in 2019 sasgen et al 2020 velicogna et al 2020 we infer that short term acceleration may be caused by interannual variations and may not persist zhang et al 2020 pointed out that the conventional methods that neglect the interannual variations overestimated the ice loss acceleration and provided a possible acceleration range 7 5 5 3 gt yr2 based on different ice mass change models the positive accelerations in table 4 partly verify the correctness of the theory in zhang et al 2020 therefore we suggest treating short term accelerations as interannual variations according to zhang et al 2020 we can estimate robust velocities and accelerations from more than 20 years of observations therefore the velocities and accelerations estimated from the 2002 4 2020 4 observations are more reliable than the previous results in addition to the trend change observed in 2012 5 the continuous mass change in fig 8 also suggests another trend change happened just in the gap the ice loss rate was apparently smaller in 2012 5 2016 than in 2018 2020 in the no ne cw sw and se regions and greenland as a whole we can easily observe from the continuous data that this trend change happened in 2017 this provides the basic temporal information for further investigating the reason for this change without this gap filled data the exact time of this change will be hard to determine furthermore the continuous data enables principal component analysis pca that requires equally spaced data by applying the pca based methods to the continuous mass change data we can analyze the spatiotemporal patterns of change at different spatiotemporal scales to illustrate the influence of the gap on the trend estimates we compare the trend estimates for 2012 5 2020 4 before and after filling the gap the trend estimates after gap filling are shown in table 4 while the estimates before are shown in table 5 the mean absolute difference between the velocity estimates for the seven regions is 1 4 gt yr and the largest difference is 2 9 gt yr that happened in the whole of greenland the mean absolute difference between the acceleration estimates for the seven regions is 0 6 gt yr2 and the largest difference is 0 8 gt yr2 that happened in the nw these differences are not large which suggests this gap has limited influence on the long term trend estimates 6 conclusions we applied mlr bpnn and dbn to fill the data gap between grace and grace fo using precipitation evapotranspiration runoff and ice discharge in greenland and its six sub regions among the three methods bpnn performs the best with testing biases ranging from 0 5 to 0 2 cm and rms from 1 5 to 3 6 cm but relatively low accuracy was observed in the sw and se regions the bpnn obtained better reconstruction accuracy for the whole of greenland bias 0 1 cm rms 1 5 cm than in the sub regions we found that the bpnn method better reconstructed the long term and annual variations than the interannual variations and that mass leakage between sub regions affected the reconstruction accuracy overall the bpnn reconstructed ice mass changes agree much better with the grace estimates than the mass budget method estimated values based on the filled grace data we re estimated the ice mass change trend in greenland it exhibits that ice mass loss decelerated after 2012 5 especially in the se sw and ne regions ice mass change in greenland is estimated to be 270 1 11 5 gt yr with an acceleration of 3 4 0 9 gt yr2 for 2002 4 2020 4 these findings suggest that ice mass change in greenland entered a new period featuring decelerated ice loss this study provides continuous grace based ice mass change estimates that bridge the gap between grace and grace fo which will be useful in analyzing ice mass change signals investigating short term ice response to climate change and validating ice change estimates using different techniques credit authorship contribution statement bao zhang conceptualization methodology formal analysis investigation validation funding acquisition writing review editing yibin yao conceptualization yulin he methodology software validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we thank the center for space research at the university of texas austin for providing the csr rl06 grace grace fo mascon products the used mascon data are downloaded from http www2 csr utexas edu grace we also thank dr xavier fettweis for providing mar smb data and dr ken mankoff for providing ice discharge data the mar data can be obtained by contacting dr xavier fettweis xavier fettweis uliege be the gap filled ice mass change estimates for greenland and its six sub regions are available upon request to bao zhang sggzb whu edu cn the solid ice discharge data is available at https dataverse01 geus dk dataset xhtml persistentid doi 10 22008 promice data ice discharge d v02 funding sources this work was jointly supported by the national natural science foundation of china grant number 42074035 the natural science foundation of hubei province china grant number 2021cfb319 and the fundamental research funds for the central universities of china grant number 2042020kf0009 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127614 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3456,the gravity recovery and climate experiment grace provided an entirely new way to measure mass changes on the earth at unprecedented accuracy and resolution however the delayed launch of the grace follow on fo mission led to an approximately 1 year gap between grace and grace fo data breaking the continuity of observation and hampering data analysis efforts have been made to bridge this gap for the major river basins but little has been done on ice sheets to address this limitation we evaluated multiple linear regression mlr a back propagation neural network bpnn and a deep belief network dbn to fill the data gap in greenland and its six sub regions we employed these methods to establish the relationships between precipitation runoff evapotranspiration and ice discharge and grace estimated ice mass changes a sliding window testing method shows that the bpnn outperformed the two other methods with a root mean square rms error of 1 5 cm in the metrics for the equivalent water height for the whole of greenland and 1 5 3 6 cm 2 5 cm in average for the six sub regions this accuracy is rather high given an uncertainty of 2 cm in grace estimates but higher for the whole of greenland than in the sub regions this difference was caused by mass leakage error between adjacent sub regions in the grace observations and can be mitigated by merging these sub regions the bpnn predicted ice mass changes agree with the grace estimates for long term and seasonal signals but are less accurate and precise for interannual signals based on the grace observations and the bpnn predicted values we re estimated the ice mass change in greenland finding that ice loss on greenland decelerated after mid 2012 primarily due to deceleration in sw se and ne regions keywords greenland grace ice mass balance gap filling artificial neural network 1 introduction the gravity recovery and climate experiment grace twin satellites have been observing the earth s time varying gravity filed since their launch in march 2002 tapley et al 2004 the time varying gravity observations have been successfully interpreted as change in the mass of the earth thus permitting the monitoring of changes in terrestrial water storage tws ice sheet and glacier mass sea level and ocean bottom pressure as well as increasing the understanding of climate change tapley et al 2019 however grace stopped service in october 2017 during its operation from march 2002 to october 2017 grace has revolutionized the way of monitoring tws change and ice mass balance and expanded our views on the complex interactions and transitions involved in the regional and continental hydroclimatic phenomena and human activities tapley et al 2004 sun et al 2021 a successor to the grace mission the grace follow on fo mission was launched in may 2018 to continue observing the global tws change and ice sheet and glacier mass balance the continuity of the mass balance record across the grace grace fo missions has been examined and demonstrated in greenland and antarctica velicogna et al 2020 and in world s glaciers and ice caps ciracì et al 2020 landerer et al 2020 compared the grace grace fo observations to independent mass change estimates and found no intermission biases between grace and grace fo however the delayed launch of the grace fo mission caused an approximately 1 year data gap between grace and grace fo breaking the continuity of observations and influencing the study of short term changes in tws and ice mass balance this gap may introduce biases in analysis of grace based mass products therefore filling the gap between grace and grace fo is necessary to maintain data continuity and facilitate data analysis this is especially necessary in the cases of the greenland and the antarctic ice sheets since they lose hundreds of gigatonnes of ice mass per year and a change in the ice loss trend occurred around the time of the data gap zhang et al 2021 for antarctic ice sheet greenland ice sheet will be demonstrated later if this gap is not filled properly on ice sheets we will not know exactly when the change happened and why the european space agency s swarm measurements can bridge the gravity data gap between grace and grace fo lück et al 2018 forootan et al 2020 teixeira da encarnação et al 2020 richter et al 2021 zhang et al 2021 but the swarm data only contains sufficient information to reconstruct low degree signals for instance below degree 12 teixeira da encarnação et al 2020 iterative singular spectrum analysis ssa kondrashov ghil 2006 can fill the data gap at the global scale wang et al 2021 yi and sneeuw 2021 however this method in essence interpolates the missing observations by taking advantage of the temporal correlation of the grace grace fo data and does not add new information velicogna et al 2020 filled the data gap between grace and grace fo in greenland and antarctica by adjusting the trend offsets between grace and mass budget method mbm estimated ice mass changes however this method only considers the trend differences between grace and mbm estimated ice mass changes and does not correct the differences in high frequency signals long et al 2014 used artificial neural network ann models tohindcast grace like tws anomalies in yun gui plateau since then ann models have been widely used to reconstruct tws change with hydroclimatic variables as input sun et al 2019 2021 li et al 2020 sahour et al 2020 sun et al 2020 some of these attempts obtained impressive results but their models and input variables are not suitable for reconstructing mass change over ice sheets since few methods have been proposed particularly for bridging grace grace fo gap over ice sheets we evaluated a statistical method multiple linear regression a machine learning method back propagation neural network and a deep learning method deep belief network to reconstruct the grace like ice mass changes from precipitation p evapotranspiration e runoff r and ice discharge d in greenland in contrast to velicogna et al 2020 and yi and sneeuw 2021 we establish more complex relationship between grace data and other independent data thereby fully taking advantage of the information imbedded in the independent data through this exercise we provide a qualified candidate method for filling the data gap between grace and grace fo over ice sheets 2 data 2 1 csr grace grace fo mascon rl06m data since there are so many grace based ice mass change products and different delineations of drainage basins in greenland it is not practical to fill data gap for each of the grace product and drainage delineation combination although the gap filling methods proposed later are applicable to any grace based ice mass change product the grace grace fo mascon rl06m v02 solutions save 2020 from the center for space research csr were used to validate the feasibility of the each proposed method in this dataset grace and grace fo mascons were estimated with the same standards as the csr rl06 spherical harmonic solutions using grace level 1 observations compared to the rl05 solutions save et al 2016 rl06 mascon solutions use a newly defined grid in which the hexagonal tiles that span across the coastline are split into two tiles along the coastline to minimize the leakage between land and ocean signals in addition the rl06 mascon solutions are released as 1 4 degree instead of 1 2 in rl05 which benefits the representation of coastlines the ellipsoidal correction for csr rl06 mass anomaly grid representation was applied as described by ditmar 2018 this correction was applied separately for land and ocean to prevent any leakage of the land signal correction into the ocean the c20 coefficients were replaced with those from satellite laser ranging slr for grace and grace fo and the c30 coefficients were replaced with those from slr for grace fo only loomis et al 2019 the degree 1 coefficients geocenter motion corrections were applied using the estimates in tn 13a sun et al 2016 the glacial isostatic adjustment was corrected using the ice6g d model peltier et al 2018 we followed save et al 2016 to extend the coastlines of greenland by 120 km into the ocean to take into account the land ocean mass leakage based on the new boundaries and the delimitation of drainage basins by rignot et al 2011 we divided greenland into six sub regions no north nw northwest cw central west sw southwest ne northeast and se southeast as shown in fig 1 we used the csr mascon rl06 solutions to estimate the ice mass change of greenland and its six sub regions we therefore obtained seven mass change time series each having a data gap between june 2017 and may 2018 in the following we will bridge this data gap between grace and grace fo estimated ice mass changes for the seven regions 2 2 ice mass balance data in greenland the ice mass balance can also be estimated by mbm 1 dm p e r d where dm is the ice mass change and the result of p e r is surface mass balance smb therefore the mbm may be used to bridge the data gap between grace and grace fo over greenland although the mbm can yield monthly estimates of ice mass change at the basin scale we cannot directly use these estimates to fill the data gap since there are biases between the mbm and the grace fo estimated ice mass changes a potential solution to this problem is adjusting the mass balance components p e r and d to match the grace estimated ice mass changes therefore we used p e and r from the mar model version 3 11 5 fettweis et al 2017 updated in 2021 and d from mankoff et al 2020 as the forcing variables to reconstruct grace like ice mass changes the mar data are the monthly increments provided at 10 10 km grids over the entire greenland ice sheet peripheral glaciers ice caps and tundra areas we integrated the monthly p e and r at each grid point and then summed the values of all points within each of the seven regions to obtain the accumulated p e and r of that region mankoff et al 2020 provided a new dataset for greenland ice sheet solid ice discharge from 1986 to march 2020 to produce this dataset ice velocity ice thickness and the position of the discharge gates were needed ice velocity data from sentinel 1a and 1b derived by promice measures 0478 joughin et al 2010 joughin et al 2015 updated in 2018 measures 0646 howat 2017 and mouginot et al 2018a 2018b were used to estimate ice thickness surface elevation from greenland ice mapping project gimp howat et al 2014 2017 adjusted through time with surface elevation change from khan et al 2016 and bed elevation from bedmachine v3 replaced by millan et al 2018 were used this dataset includes all discharging ice that flows faster than 100 m yr and was generated through an automatic and adaptable method the discharge gates were positioned near the present year termini based on the surface speed and an ice mask the total ice discharge from mankoff et al 2020 was estimated to be 10 less than that of mouginot et al 2019 and enderlin et al 2014 and similar to that of king et al 2018 in this study the accumulated p e and r from the mar model and d from mankoff et al 2020 were used to estimate ice mass balance and fill the data gap for the seven regions 3 methodology the basic idea behind using p e r and d to reconstruct the missing grace like ice mass estimates is to establish the relationships that adjust p e r and d to best match grace grace fo estimated ice mass changes multiple linear regression mlr back propagation neural network bpnn and deep belief network dbn methods were employed to build these relationships 3 1 multiple linear regression the mlr method is a simple statistical technique that models the linear relationship between dependent variable and independent variables and used to explore the links between key variables in hydrology and climate sciences seidou et al 2007 its formula is expressed as in eq 2 2 dm t a 0 a 1 p t a 2 e t a 3 r t a 4 d t where m is the dependent variable which is the grace grace fo estimated ice mass change at time t p e r and d are the independent variables and a 0 a 1 a 2 a 3 a 4 are the coefficients to be estimated we interpolated p e r and d to the sampling time of the grace observations and fed all the available m p e r and d data into eq 2 to solve for the coefficients using a least square method for each of the seven regions when the coefficients were optimally determined we used eq 2 and p e r and d data to predict m between grace and grace fo and thus filled the data gap 3 2 back propagation neural network the bpnn employs a gradient descent method to minimize the differences between the network output and the target output hecht nielsen 1992 because of its strong nonlinear fitting ability it has become one of the most commonly used machine learning methods we used a classic bpnn model that contains an input layer a hidden layer and an output layer the structure is shown in fig 2 the number of neurons in the input and output layers were equal to the number of sample pairs the number of neurons in the hidden layer should be optimized each neuron in the input layer contains p e r and d for a certain time the corresponding neuron in the output layer contains grace grace fo estimated ice mass change in any bpnn each neuron in one layer is directly connected to the neurons of the subsequent layer with an activation function a sigmoid function was employed as the activation function between the input and hidden layers and the linear function is used as the activation function between the hidden and output layers when training the network we used the the nguyen widrow method nguyen and widrow 1990 to initialize the weights and biases of the network and employed the levenberg marquardt l m algorithm levenberg 1944 marquardt 1963 to iteratively adjust the weights and biases until the model obtained the minimal mean square error we used the l m algorithm since it has fast convergence speed as well as the high precision in moderate sized bpnn training mukherjee and routroy 2012 the maximum number of iterations was set to 1000 the performance goal was set to 0 00 the minimum performance gradient is set to 1 0 10 7 the bpnn however does not guarantee a global optimal mukherjee and routroy 2012 thus to avoid local optima in the model training we used random weights for the neurons and repeated the training process 50 times taking the average training result after removing outliers as the final training result we used a posteriori way to determine the optimal number of neurons in the hidden layer that is based on the testing root mean square rms error fig s1 of the supplementary material sm shows the testing rms error versus the number of nodes in the hidden layer in greenland and the six sub regions in which the number of nodes that corresponds to the smallest rms is taken as the optimal number of nodes in the hidden layer 3 3 deep belief network as a classic deep learning neural network dbn stacks several restricted boltzmann machines rbms and ends with a back propagation bp layer hinton et al 2006 each rbm is composed of a visible layer and a hidden layer which are bidirectionally linked the hidden layer in the prior rbm serves as the visible layer in the next rbm connections exist between rbms but do not between units within layers a dbn structure with two rbms was used in this study as shown in fig 3 when training this dbn we trained the rbms layer by layer without supervision using the contrastive divergence algorithm hinton salakhutdinov 2006 to obtain the approximate weight to initialize the multi layer neural network the dbn worked as a feed forward neural network and the supervised bp algorithm was used to fine tune the weights of each layer to yield the final dbn model the neuron numbers in the visible and output layers are the same to the number of the sample pairs the neuron numbers in the two hidden layers were optimized and set in the same way for simplicity we used the same method as in the case of the bpnn model to determine the number of nodes for the two hidden layers fig s2 of the sm illustrates the testing rms error versus the number of nodes in the hidden layers for greenland and the six sub regions in which the number of nodes corresponding to the smallest rms was taken as the optimal number of nodes for the hidden layers 3 4 model performance testing since the main purpose of this study was to fill the approximately 1 year data gap between grace and grace fo a conventional testing method like k fold cross validation was not suitable in this case as it randomly divides the samples into training and testing sets some researchers used the first several years of grace data for training and the remaining years for testing li et al 2020 sun et al 2020 when reconstructing the tws changes but this method is not ideal since more data could have been involved in modeling and testing to fully take advantage of all the grace grace fo data we separated the whole process into modeling and testing processes in the modeling process all data were used to train the three models without testing in the testing process a sliding window testing swt method was employed to estimate the model performance in each swt run one year of data in the window was removed for testing and the remaining data were used to train the model which was then used to predict data in the removed year we obtained a time series of predicted data by sliding the window removing one year starting from the first year to the last year and repeating the process for all the years by comparing the predicted data to the original grace time series we estimated the model performance quantitatively by bias standard deviation std rms and correlation coefficient cc to eliminate the influence of long term trends on the cc calculations the ccs hereafter were calculated based on the detrended time series since the testing process uses one less year of data to train the model than the modeling process it tends to give a conservative estimate of the model performance 4 results 4 1 reconstruction accuracy table 1 exhibits the training and testing accuracy results for the three methods in the seven regions the bpnn method obtains the smallest training and testing rms among the three methods indicating the bpnn method outperforms the two other methods note that the dbn method obtains nearly identical rms results to the bpnn method and both the dbn method and the bpnn method are apparently better than the mlr method since the dbn method is more complex than the bpnn method we prefer the bpnn method and will focus our analysis on the bpnn results hereafter among the six sub regions the bpnn method has biases ranging from 0 5 cm sw to 0 2 cm ne with a mean bias of 0 1 cm and rmss from 1 5 cm no to 3 6 cm se with a mean rms of 2 5 cm the relatively weak reconstruction accuracy occurred in the sw 3 4 cm in terms of rms and se 3 6 cm this was where more than 100 gt of ice was lost each year the bpnn method obtained a reconstruction accuracy of 1 5 cm for the whole of greenland which is not only the best performance among the seven regions but also superior to the mean performance for the six sub regions this suggests that the data gap can be better reconstructed for the whole of greenland than in sub regions fig 4 shows the comparisons among the original grace estimated ice mass changes the predicted time series from the testing process and the final fitted time series from the modeling process overall both the predicted and fitted ice mass changes agree with the grace estimated ice mass changes which together with the information in table 1 adds confidence to the gap filling for june 2017 and may 2018 however in the ne rms 18 5 gt the agreement between grace estimated and bpnn reconstructed mass changes is actually not as good as in other regions given that ne lost only 17 0 gt ice mass per year this may be due to the gentle mass change in ne that caused grace to have low signal to noise ratio in that region as suggested by the irregular fluctuations in fig 4c despite limitations in sub regions the bpnn method still outperforms the existing methods wang et al 2021 and yi and sneeuw 2021 used the ssa based methods to fill the gap at the global scale and discussed the reconstruction accuracy in greenland yi sneeuw 2021 used the iterative ssa but did not present accuracy information comparable to this study wang et al 2021 used an improved ssa and claimed their method was better than the iterative ssa although wang et al 2021 used only 11 months of data in the middle of the time series to validate the reconstruction accuracy their results were still not as accurate as those we report rms 1 9 cm vs 1 5 cm in greenland in addition ssa based methods cannot guarantee interpolation accuracy near the ends of the time series as the ssa is strongly influenced by the edge effect 4 2 compare with mass budget method since the mbm can also estimate ice mass balance we compared the bpnn reconstructed ice mass changes to the mbm estimates table 2 shows the differences between grace estimated mass changes and the mbm estimates for the seven regions this table illustrates noteworthy biases between grace and mbm estimated mass changes in all the seven regions with biases grace mbm ranging from 11 7 cm cw to 1 2 cm ne this implies that grace underestimated the mass change relative to the mbm method the rms of the differences ranges from 2 9 cm ne to 41 5 cm cw with an average value of 17 0 cm the largest disagreement appears in the cw and sw regions the average bias and rms of the six sub regions were 6 2 cm and 17 0 cm while the bias and rms for the whole of greenland is 6 1 cm and 8 5 cm this indicates that grace and mbm estimated mass changes agree better for the whole of greenland than in the sub regions similar to the case of the reconstructed mass changes fig 5 presents the comparisons between mass change estimates from grace and mbm it intuitively demonstrates that grace estimated mass changes have smaller rates in the no nw cw and greenland larger rates in the sw and close rates in the ne and se than the mbm estimated rates velicogna et al 2020 attributed these trend offsets to the uncertainties in the gia correction in the grace data and uncertainties in absolute ice discharge and smb rate deviations cause great differences between the two data sets which explains why we cannot directly use the mbm estimates to fill the grace data gap comparing table 1 to table 2 and fig 4 to fig 5 we can observe that the bpnn reconstructed ice mass changes agree much better with the grace estimated mass changes than the mbm estimated mass changes 5 discussion 5 1 reconstruction uncertainties it is easily observed in fig 4 that the long term trends are well reconstructed in the predicted time series which means the reconstruction uncertainties mainly lie in the short term variations the lomb scargle periodogram lsp was employed to further investigate the uncertainties the lsp lomb 1976 scargle 1998 detects and characterizes periodicity in unevenly sampled time series and used in many fields vanderplas 2018 we applied the lsp to the differences between the detrended grace estimated ice mass changes simply called g hereafter and the detrended bpnn reconstructed ice mass changes r hereafter for comparative purposes we also applied the lsp to the differences between the detrended grace estimated and the detrended mbm estimated ice mass changes m hereafter fig 6 shows the differences g r and g m in the left panels and the lsp results in the right panels for the seven regions note that the power of g m and g r was normalized by their largest power for the less than eight year periods which means the power can be compared within the same data but cannot be compared between g m and g r despite the trend differences are eliminated the reconstructed mass changes still have much smaller rms values than the mbm estimated values for the seven regions i e 2 5 vs 1 5 cm in no 3 0 vs 2 1 cm in nw 2 6 vs 2 2 cm in ne 3 7 vs 2 1 cm in cw 7 0 vs 3 4 cm in nw 6 1 vs 3 6 cm in se and 3 1 vs 1 5 cm in greenland this implies that merely correcting the trend offsets in mbm estimated mass changes cannot fully restore the grace like ice mass changes in addition g m has a dominant power at the annual scale and strong power at the interannual and semi annual scales indicating that the largest difference between g and m lies in annual variations besides the long term trends different from the g m the g r exhibits a low power at the annual scale for the seven regions implying the bpnn method effectively restored the annual variations from p e r and d the g r however has relatively large power at the semi annual except for cw and inter annual scales especially at the inter annual scale by comparing the periodograms for g r and g m we conclude that the bpnn method effectively reconstructed the annual signals as well as the linear trends but did not perform as well in semi annual and interannual signals since the irregular interannual ice mass change is violent in greenland and difficult to model we infer that the relationship between g and m is inconstant at the interannual scale which hinders the ability of bpnn to reconstruct the grace like ice mass change from p e r and d fig 6 also shows that the six sub regions have relatively larger reconstruction uncertainties than the whole of greenland especially since the sw and se have a reconstruction accuracy of only 3 4 cm and 3 6 cm since the grace like ice mass changes were reconstructed from smb and d the deviations in smb and d will cause uncertainties fig 6e and 6f demonstrate that the values of g m fluctuated significantly in sw and se regions indicating the mbm estimated mass changes did not agree well with the grace estimated values and the disagreement changed randomly over time and led to relatively poorer reconstruction accuracy in the sw and se regions in other regions where the values of g m had gentle variations the reconstruction accuracy was much better we also observed that when the g m tended to be positive in the sw it would tend to be negative in the se when we merged the two sub regions and recalculated the g m and g r we obtained the results displayed in fig 7 this graph shows that g m had much gentler variations in the sw se than in the sw or the se and that the difference between g and m decreased to 4 4 cm and the reconstructed accuracy was improved to 2 4 cm much better than 3 4 cm in the sw and 3 6 cm in the se this phenomenon motivated us to attribute the uncertainties to a mass leakage error between sub regions this conclusion is reinforced in table 1 where the mean reconstruction accuracy of the six sub regions was poorer than the whole of greenland fig 5 indicates that the grace estimated mass change has a smaller rate than the mbm estimated mass change in the cw region whereas there is a larger rate in the sw region since more than half of ice mass of greenland losses are from the cw sw and se every year it is reasonable to infer that non negligible mass leakage exists among cw sw and se in the grace observations if this inference is correct then the reconstruction accuracy would be improved by merging sub regions to verify this inference we tested the reconstruction accuracy of merged regions and compared the mbm estimated mass changes to the grace estimated values as presented in table 3 this table clearly shows that the reconstruction accuracy of the bpnn method was improved when more regions were merged the reconstruction accuracy was poorest in the se 3 6 cm and sw 3 4 cm but sharply increased to 2 4 cm when the sw and se regions were merged the reconstruction accuracy was further improved when cw and nw were also merged merging the ne region did not improve reconstruction accuracy which was because the ne and its neighboring regions lost only a little mass the differences between the grace estimated mass changes and the mbm estimated values also became smaller when more regions were merged these findings indicate that mass leakage between sub regions caused uncertainties in reconstructing grace like ice mass changes and enlarged the differences between grace and mbm estimated ice mass changes in the sub regions 5 2 new ice loss trends we re estimated the ice loss rate in the six sub regions and greenland based on the filled grace data to get the state of the art knowledge of the ice loss in greenland we used a constant a linear trend a quadratic term and four seasonal terms to fit the grace estimated ice mass changes and resolved the coefficients using the least square method since we considered acceleration the velocities mentioned hereafter refer to temporal mean velocities fig 8 shows the ice mass change time series and their quadratic fittings since the ice mass change exhibited clearly different trends before and after 2012 5 we solved velocities and accelerations separately for 2002 4 2012 5 2012 5 2020 4 and 2002 4 2020 4 as displayed in fig 8 and table 4 overall greenland and all its six sub regions demonstrated decelerated ice loss in 2012 5 2020 4 in contrast to 2002 4 2012 5 this was especially significant in the se sw and ne regions the se region had an ice mass change rate of 89 4 7 9 gt yr with an acceleration of 0 3 1 1 gt yr2 before 2012 5 but the velocity sharply dropped to 45 5 5 8 gt yr after 2012 5 although its acceleration increased to 6 5 1 0 gt yr2 which makes se the most decelerated region the second most decelerated region is the sw where the velocity decreased from 48 7 4 4 gt yr to 36 1 7 3 gt yr and the acceleration dropped from 10 6 0 6 gt yr2 to 3 5 1 3 gt yr2 the ne region showed an apparently decreasing trend 22 0 4 4 gt yr before 2012 5 but this trend almost disappeared after 2012 5 and assumed a stable state the nw and cw kept nearly the same ice mass loss velocity before and after 2012 5 but the ice loss acceleration decreased sharply after 2012 5 which implies the acceleration trend was gone only the no region retained both a stable velocity and acceleration in the whole 2002 4 2020 4 time frame as for the whole of greenland it had a velocity of 266 5 10 3 gt yr and an acceleration of 24 4 1 5 gt yr2 before 2012 5 but after 2012 5 the velocity and acceleration became 197 6 25 8 gt yr and 16 4 4 4 gt yr2 respectively suggesting a clear change in trend many scientists have reported a sharp acceleration of ice loss in greenland before 2013 e g 30 11 gt yr2 for 2002 2009 velicogna 2009 21 9 1 gt yr2 for 1992 2009 rignot et al 2011 25 9 gt yr2 for 2003 2012 wouters et al 2013 and 27 7 4 4 gt yr2 for 2003 2013 bevis et al 2019 compared to these acceleration estimates the trend change after 2012 5 was even more impressive when looking at the whole period 2002 4 2020 4 we observe that greenland and its six sub regions had very small accelerations 0 5 4 1 gt yr2 and that many strong negative accelerations before 2012 5 became positive this indicates that the ice mass loss in greenland decreased in recent years although record ice loss was observed in 2019 sasgen et al 2020 velicogna et al 2020 we infer that short term acceleration may be caused by interannual variations and may not persist zhang et al 2020 pointed out that the conventional methods that neglect the interannual variations overestimated the ice loss acceleration and provided a possible acceleration range 7 5 5 3 gt yr2 based on different ice mass change models the positive accelerations in table 4 partly verify the correctness of the theory in zhang et al 2020 therefore we suggest treating short term accelerations as interannual variations according to zhang et al 2020 we can estimate robust velocities and accelerations from more than 20 years of observations therefore the velocities and accelerations estimated from the 2002 4 2020 4 observations are more reliable than the previous results in addition to the trend change observed in 2012 5 the continuous mass change in fig 8 also suggests another trend change happened just in the gap the ice loss rate was apparently smaller in 2012 5 2016 than in 2018 2020 in the no ne cw sw and se regions and greenland as a whole we can easily observe from the continuous data that this trend change happened in 2017 this provides the basic temporal information for further investigating the reason for this change without this gap filled data the exact time of this change will be hard to determine furthermore the continuous data enables principal component analysis pca that requires equally spaced data by applying the pca based methods to the continuous mass change data we can analyze the spatiotemporal patterns of change at different spatiotemporal scales to illustrate the influence of the gap on the trend estimates we compare the trend estimates for 2012 5 2020 4 before and after filling the gap the trend estimates after gap filling are shown in table 4 while the estimates before are shown in table 5 the mean absolute difference between the velocity estimates for the seven regions is 1 4 gt yr and the largest difference is 2 9 gt yr that happened in the whole of greenland the mean absolute difference between the acceleration estimates for the seven regions is 0 6 gt yr2 and the largest difference is 0 8 gt yr2 that happened in the nw these differences are not large which suggests this gap has limited influence on the long term trend estimates 6 conclusions we applied mlr bpnn and dbn to fill the data gap between grace and grace fo using precipitation evapotranspiration runoff and ice discharge in greenland and its six sub regions among the three methods bpnn performs the best with testing biases ranging from 0 5 to 0 2 cm and rms from 1 5 to 3 6 cm but relatively low accuracy was observed in the sw and se regions the bpnn obtained better reconstruction accuracy for the whole of greenland bias 0 1 cm rms 1 5 cm than in the sub regions we found that the bpnn method better reconstructed the long term and annual variations than the interannual variations and that mass leakage between sub regions affected the reconstruction accuracy overall the bpnn reconstructed ice mass changes agree much better with the grace estimates than the mass budget method estimated values based on the filled grace data we re estimated the ice mass change trend in greenland it exhibits that ice mass loss decelerated after 2012 5 especially in the se sw and ne regions ice mass change in greenland is estimated to be 270 1 11 5 gt yr with an acceleration of 3 4 0 9 gt yr2 for 2002 4 2020 4 these findings suggest that ice mass change in greenland entered a new period featuring decelerated ice loss this study provides continuous grace based ice mass change estimates that bridge the gap between grace and grace fo which will be useful in analyzing ice mass change signals investigating short term ice response to climate change and validating ice change estimates using different techniques credit authorship contribution statement bao zhang conceptualization methodology formal analysis investigation validation funding acquisition writing review editing yibin yao conceptualization yulin he methodology software validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we thank the center for space research at the university of texas austin for providing the csr rl06 grace grace fo mascon products the used mascon data are downloaded from http www2 csr utexas edu grace we also thank dr xavier fettweis for providing mar smb data and dr ken mankoff for providing ice discharge data the mar data can be obtained by contacting dr xavier fettweis xavier fettweis uliege be the gap filled ice mass change estimates for greenland and its six sub regions are available upon request to bao zhang sggzb whu edu cn the solid ice discharge data is available at https dataverse01 geus dk dataset xhtml persistentid doi 10 22008 promice data ice discharge d v02 funding sources this work was jointly supported by the national natural science foundation of china grant number 42074035 the natural science foundation of hubei province china grant number 2021cfb319 and the fundamental research funds for the central universities of china grant number 2042020kf0009 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127614 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3457,a comprehensive glacier hydrology model was developed within the cold regions hydrological modelling platform crhm to include modules representing wind flow over complex terrain blowing snow redistribution and sublimation by wind snow redistribution by avalanches solar irradiance to sloping surfaces surface sublimation glacier mass balance and runoff meltwater and streamflow routing the physically based glacier hydrology model created from these modules in crhm was applied to simulate the hydrology of the instrumented glacierized and rapidly deglaciating peyto and athabasca glacier research basins in the canadian rockies without calibration of parameters from streamflow it was tested against observed albedo point and aggregated glacier mass balance and streamflow and found to successfully simulate surface albedo snow redistribution snow and glacier accumulation and ablation mass balance and streamflow discharge both when driven by in situ observations and reanalysis forcing data long term modelling results indicate that the increases in discharge from the 1960s to the present are due to increased glacier ice melt contributions despite declining precipitation and snow melt keywords glacier hydrology energy budget melt mass balance snow redistribution peyto glacier athabasca glacier hydrological modelling 1 introduction changes in alpine snow and glacier hydrology influence both timing and magnitude of streamflow discharge and thus impact the water supply for downstream industrial agricultural hydropower environmental and drinking purposes around the world these changes include the rapid retreat of glaciers arendt et al 2009 berthier 2004 demuth and pietroniro 2003 diolaiuti et al 2011 fujita and nuimura 2011 haeberli et al 2007 kaser et al 2004 naz et al 2014 ohmura 2006 schiefer et al 2007 declining seasonal snowcover at higher elevations fujita and nuimura 2011 ipcc 2007 mote et al 2005 and declining streamflow demuth and pietroniro 2003 immerzeel et al 2010 kienzle et al 2012 rood et al 2008 in particular the influence of glacier snow and ice melt dominates the seasonal pattern of runoff in mid to high latitude mountains more than low latitude high mountains kaser et al 2003 the canadian rockies constitute the headwaters of the major rivers of western canada and northwest us for example the saskatchewan nelson columbia fraser and columbia rivers snow and ice in these mountain headwaters regulate the hydrology of the rivers by acting as a short to long term water storage reservoir lópez moreno et al 2020 but north american mountain glaciers are retreating arendt et al 2002 berthier 2004 berthier et al 2010 comeau et al 2009 debeer et al 2007 demuth and pietroniro 2003 moore and demuth 2001 munro 2000 schiefer et al 2007 thus causing changes to this reservoir function observations suggest that there is a pronounced acceleration in the glacier retreat in the canadian rockies moore et al 2009 which is very noticeable in the case of peyto glacier e g demuth and keller 2006 kehrl et al 2014 changes in north american glacier mass area and shape result in changing contributions to water resources barry 2006 reynolds and young 1997 and these changes in glacier elevation and volume are related to changes in temperature and precipitation tennant and menounos 2013 the other notable change in most glaciers is the rise in their equilibrium line altitudes ela due to warming climate malecki 2015 van pelt and kohler 2015 zemp et al 2015 the ela is the dividing elevation between accumulation and ablation zones on a mountain glacier and so its elevation indexes the glacier mass balance variations in the ela are commonly attributed to changes of winter precipitation and summer air temperature bakke and nesje 2011 therefore there are changes in glacier mass ela and in streamflow it is essential to understand how the decline of alpine snowcover and glacier mass in the mountains is influencing streamflow generation as this can help to predict the availability of future water resources snow and glacier melt models range from complex energy budget models hock and holmgren 2005 klok et al 2002 magnusson et al 2010 michlmayr et al 2008 mott et al 2008 munro 2011a munro 2004 munro and marosz wantuch 2009 naz et al 2014 oerlemans 1991 shea et al 2015 to more simplified degree day models anderson et al 2006 hock 1999 immerzeel et al 2012 most glacier hydrology models use simple conceptual melt models that are based on temperature and precipitation observations and are calibrated from past conditions see hock 2005 for review examples include statistical and temperature index models fujita and nuimura 2011 hannah and gurnell 2001 hock 2003 1999 luo et al 2013 shea and marshall 2007 singh and bengtsson 2005 stahl et al 2008 verbunt et al 2003 these empirical models do not consider the redistribution of snow by wind and avalanches sublimation losses and the full radiation energetics that are critical to the survival of small mountain glaciers déry et al 2010 because high altitude observations of shortwave irradiance are limited empirical techniques that rely upon commonly measured variables such as air temperature have led to the popularity of the temperature index model and its wide use to simulate glacier snow and ice melt hock 2005 these empirical methods are unlikely to be reliable for future conditions as they have been calibrated based on past climates poulin et al 2011 walter et al 2005 however demonstrated that a physically based energy budget melt model does not require more input data than most temperature index methods or what is available on most modern meteorological stations the energy budget snowmelt model ebsm of gray and landine 1988 is an example of such a physically based snow model that only requires precipitation temperature humidity and wind speed information pomeroy et al 2013 showed that shortwave and net radiation can be synthesized from temperature and humidity data to drive energy budget snowmelt and evapotranspiration algorithms for example several relationships have been developed to estimate shortwave shook and pomeroy 2011 and longwave radiation sicart et al 2006 from latitude time of year air temperature and vapour pressure sicart et al 2006 evaluated longwave and shortwave radiation estimates from these methods over mountain wolf creek research basin in yukon territory and prairie saskatchewan sites in canada and found that simulated values were close to measurements moreover reanalysis products are now commonly being used to force hydrological models krogh et al 2015 making application of the energy balance more straightforward than in the past the cold regions hydrological modelling platform crhm pomeroy et al 2007 is a flexible object oriented process based modelling platform that runs on spatially distributed hydrological response units hru at sub daily or sub hourly timesteps hru are landscape units having a common set of parameters and modules and that have some common biogeophysical and drainage characteristics hru are used to distribute meteorological forcing data over the basin and in this application are based on slope aspect elevation and landcover type including glacier coverage crhm simulates several cold region hydrological processes that are important in high mountain environments such as blowing snow redistribution blowing snow sublimation infiltration into frozen soils radiation exchange in complex terrain snow accumulation and ablation as well as the full range of hydrological processes for warm seasons such as evapotranspiration infiltration soil moisture movement groundwater dynamics surface runoff and interflow pomeroy et al 2007 fang et al 2013 the model runs through interactions of the four components observations parameters modules and state variables through calculation of mass and energy budgets on the hru sub basin and basin levels of discretization blowing snow avalanches runoff interflow and groundwater flow can move via various pathways from hru to hru s and streamflow is routed from various sub basins to the basin outlet through these interactions crhm links atmospheric data inputs and hydrological outputs the minimum atmospheric inputs required to force crhm are air temperature humidity wind speed and precipitation either from automatic weather stations or from atmospheric model outputs for the surface level crhm has been successfully applied to many regions ranging from the canadian prairies to high mountains in north and south america ellis et al 2010 fang et al 2010 fang and pomeroy 2007 krogh et al 2015 lv and pomeroy 2019 macdonald et al 2010 2009 rasouli et al 2014 europe lópez moreno et al 2013 africa lópez moreno et al 2020 and asia zhou et al 2014 recent research has coupled basin hydrology modelling with glacier dynamics to assess the impact of glacier retreat on streamflow finger et al 2013 huss 2011 huss et al 2005 immerzeel et al 2012 naz et al 2014 shea et al 2015 however these and other studies have not considered many of the important cold region hydrological processes including the evolution ablation and redistribution of snow snow storage redistribution of snow by wind and gravity and sublimation rates in high latitude alpine mountains are crucial processes to consider when determining meltwater contribution to the basin ayala ramos 2017 bernhardt and schulz 2010 bravo et al 2017 macdonald et al 2010 strasser et al 2008 despite significant advances in the understanding of blowing snow redistribution and sublimation processes déry et al 2010 doorschot et al 2001 essery and pomeroy 2004 liston and elder 2006 macdonald et al 2009 pomeroy and li 2000 they have not yet been included in mountain glacier melt studies in the canadian rockies they have been considered in mass balance and melt studies over icelandic and polar glaciers déry et al 2004 as well as in studies of greenland mernild et al 2008 mernild et al 2007 antarctic bintanja and reijmer 2001 gallée et al 2012 thiery et al 2012 and arctic bintanja 2001 liston and hiemstra 2011 sea ice and ice sheets these studies suggest snow redistribution snow sublimation and other hydrological processes may also contribute to the mass and energy budgets of mountain glaciers in western canada therefore there is a need to develop a glacial melt model that utilizes an energy budget approach physically measurable inputs and a snow redistribution approach that accounts for the complex mass transport present in mountainous regions it is hypothesized that the simulation of water contributions from glacial ablation will be more accurate when snow redistribution by wind and gravity sublimation and surface energy budget energetics are included this study develops and tests a comprehensive physically based and spatially distributed model of glacier snow and ice hydrology at two glacierized research basins in the canadian rockies the crhm glacier model developed within chrm includes redistribution of snow by wind and avalanches an energy budget melt model for snow firn and ice consideration of slope and aspect for radiation distribution and runoff routing 2 study sites and data 2 1 two instrumented partially glacierized alpine basins in the canadian rockies peyto glacier research basin pgrb latitude 51040 n and longitude 116033 w in banff national park and athabasca glacier research basin agrb latitude 52011 n and longitude 117016 w in jasper national park both in alberta canada were considered for testing the crhm glacier model figs 1 and 2 both research sites are part of the canadian rockies hydrological observatory a network of instrumented basins in the mountain headwaters of the saskatchewan and athabasca river basins operated by the university of saskatchewan centre for hydrology pgrb with its outlet at the former streamflow gauging site peyto outlet old fig 1 c covers an area of 22 43 km2 which included 9 9 km2 of glacierized area as of 2016 agrb has a basin area of 29 3 km2 including 16 9 km2 of glacierized area in 2016 peyto glacier in pgrb is a valley outflow glacier of the wapta icefield in the waputik mountains athabasca glacier in agrb is a valley outflow glacier of the columbia icefield streamflow out of pgrb flows east into the mistaya river basin a headwater of the north saskatchewan river and eventually into the hudson bay via the nelson river and that out of agrb flows north through the sunwapta river a headwater of the athabasca river and eventually into the beaufort sea of the arctic ocean via the mackenzie river table 1 provides the general physical characteristics of these two research basins these basins were equipped in 2013 2014 with new automatic weather stations aws on ice and off ice sites the instrumentation and range of parameters measured at these aws are presented in table 2 these glaciers have been losing mass continuously since the mid 1970 s demuth and keller 2006 kehrl et al 2014 tennant and menounos 2013 in the case of peyto glacier a new proglacial lake lake munro formed at the tongue of the glacier and is increasing in size every year peyto creek flowing out of lake munro drains the meltwater from the glacier and discharges to peyto lake which has outflow into the mistaya river the first record of peyto glacier goes back to 1897 photograph by walter d wilcox and it was subject to intermittent scientific investigations in the 1930s 1940s and 1950s significant research over the glacier started in 1965 when it was selected as one of the research sites for the unesco international hydrological decade ihd the scientific scope and instruments used for observations have increased and improved progressively since then munro 2013 as reported by meek 1948 surveys documenting the recession and flow of athabasca glacier began in 1945 2 2 data 2 2 1 topography several digital elevation models dem from different years topographical maps and satellite images were considered for both the basins for pgrb the 1966 dem 10 m resolution was developed from the scanned topographic map of peyto glacier produced from the aerial photographs from august 1966 sedgwick and henoch 1975 the same map was used for considering landcover for 1966 of the basin the 2006 dem 10 m resolution was obtained from airborne lidar measurements demuth and hopkinson 2013 since the aerial photograph didn t cover the whole pgrb the northeastern corner of the basin was mosaiced with the 2014 dem to fill in the missing part the 2014 dem was prepared at a 10 m resolution from aerial photogrammetry of banff national park by geodesy group inc taken during july and september 2014 pgrb landcover maps for 2006 and 2014 were prepared based upon landsat 5 satellite images for 2006 and landsat 8 for 2014 for agrb dems from 1983 canadian digital elevation model cdem 2000 canadian digital surface model cdsm and 2011 all at 20 m horizontal resolution were available landcover maps were generated from landsat 5 and landsat 8 top of atmosphere reflectance images using google earth engine landsat 5 images were used for the years 1984 and 2006 and landsat 8 images were used for 2014 the images acquired for this study were taken between 15th july to 15th september in the respective years with minimum or no cloud cover inside the basin boundaries the dem and landcover data are summarized in table 3 2 2 2 glaciology and hydrology past studies of peyto glacier are well documented in the book peyto glacier one century of science edited by demuth et al 2006 the book also provides details of the mass balance data along with hypsometry of the glacier long term glacier mass balance records are available for peyto glacier from 1965 with a data gap in 1991 1992 glaciological mass balance measurements using ablation stakes and snow pits have been taken continuously since the ihd period mass balance data for the 11 elevation bands are available in several publications demuth and keller 2006 ommanney 1987 young and stanley 1976 though winter bw and summer bs balance records are available until 1994 annual glacier net mass balance bn data are available after 1994 wgms 2020 mass balance data for athabasca glacier were not available for this study pgrb streamflow was gauged during the ihd period and then discontinued in 1977 in the summer of 2013 the university of saskatchewan centre for hydrology established a stream gauging site in the basin about 1 5 km upstream from the site used in the ihd locations of old and new gauges are shown in fig 6 discharge data from the ihd period are available for an 11 year period 1967 1977 and those from the recent period are available for 6 years 2013 2018 discharge data from the outlet of athabasca glacier are available from 1948 to the present with a data gap from 1997 to 2004 historical streamflow discharge data from pgrb and agrb and recent data for agrb were obtained from the environment and climate change canada s water survey of canada 2 2 3 meteorological forcing datasets awss fig 2 were installed at on ice and off glacier sites in agrb and pgrb by the university of saskatchewan centre for hydrology in 2013 2014 archived hourly meteorological observations from the aws at the peyto glacier main station were available from 1987 munro 2011a munro 2011b along with periodical observations made on the ice since 2007 pradhananga et al 2021 precipitation data from the canadian rockies hydrological observatory station above nearby helen lake https research groups usask ca hydrology data php and the three stations bow summit saskatchewan river crossing and lake louise of environment and climate change canada http climate weather gc ca were used to estimate elevational gradients in precipitation following the approach by fang et al 2013 monthly values of temperature lapse rates were obtained from observations at the four aws stations fig 1c at different elevations on pgrb these monthly values of gradients in precipitation and temperature were applied to pgrb and then transferred to agrb preparation of meteorological data to provide continuous datasets suitable for forcing a hydrology model presents several challenges at these sites meteorological data collection from alpine glacier basins is challenged by remoteness difficulty in accessibility severe weather and year round cold conditions and many other difficulties higher winter snow accumulations can bury on ice stations and increasingly rapid summer melt can cause the meteorological station towers or tripods to tilt or fall rapid ice melt means that stations needed to be re installed by drilling 5 m into the ice twice a year therefore the aws located within and near the basin were used to fill in gaps details are in pradhananga et al 2021 for pgrb reanalysis data were used to run the model beyond the observation periods for pgrb the model was also tested with lake louise precipitation data for the model run period 1967 1977 as this was the only proximal station in existence at the time the era global reanalysis datasets era interim dee et al 2011 and era 40 uppala et al 2005 were first bias corrected to a single point at the main aws stations on agrb and pgrb by comparing with the in situ observations at these sites or proximal sites when precipitation was corrected for wind undercatch a quantile mapping technique was used for the bias corrections of air temperature vapour pressure wind speed precipitation incoming shortwave and longwave radiation with parameters individually calibrated for each month from corresponding data periods using the qmap package in r gudmundsson 2016 for agrb era interim data were bias corrected to the athabasca moraine station which had observed data from 2014 to 2019 since there was not any observed data before 2014 for agrb era 40 data were bias corrected using era interim data for the period of 1979 2002 similar to the approach of krogh and pomeroy 2018 for pgrb era interim data were bias corrected to peyto main station observations from 2013 to 2019 except for precipitation data which were taken from the proximal and sheltered bow summit observations era 40 data for pgrb were bias corrected to the archived observation from the station for the common overlap period of 1987 2001 these bias corrected reanalysis datasets and in situ observations over pgrb are published in pradhananga et al 2021 lake louise precipitation data were also bias corrected to bow summit by monthly quantile mapping using these datasets to force crhm has been discussed by krogh et al 2017 and krogh et al 2015 and involves creating continuous hourly fields of temperature humidity wind speed shortwave irradiance and either hourly or daily precipitation these data were distributed to the basin using algorithms and macros in crhm pomeroy et al 2007 crhm s observation module adjusted temperature and precipitation with elevation of each hru based on monthly lapse rates the radiation module distributed global radiation to hrus based on latitude elevation ground slope and azimuth incoming longwave radiation was distributed in crhm based on air temperature humidity and the hru terrain view factor wind speed acceleration and deceleration due to flow over complex terrain was adjusted using the walmsley s parametric boundary layer wind flow module in crhm walmsley et al 1989 details of these modules are provided by fang et al 2013 the model input data files were prepared using several r packages crhmr shook 2016a for pre processing meteorological station forcing data post processing and analysing model outputs mscr shook 2015 for pre processing archived data from environment and climate change canada and reanalysis shook 2016b for pre processing and interpolating atmospheric model reanalysis data 3 crhm glacier glacier snow and ice energy and mass budgets and meltwater routing processes were incorporated into crhm to create crhm glacier a model suitable for alpine glacierized basins these modules are linked in a sequential manner to simulate hydrological processes for a glacierized basin following the flow diagram shown in fig 3 the most relevant modules for an alpine glacier dominated basin are described in the following subsections along with the new glacier module this section also details the development of the distributed physically based numerical model to simulate glacier mass and energy fluxes 3 1 snow redistribution and sublimation many mountain glacier models neglect blowing snow and sublimation despite the prominence of these processes at high altitudes e g naz et al 2014 shea et al 2015 and demonstration of improvements in model performance when these processes are included in alpine simulations fang et al 2013 snow redistribution by both wind and avalanches is important on mountain glaciers due to high wind speeds and steep topography redistribution of snow significantly alters the mass balance and thus melting processes wayand et al 2018 the blowing snow module pomeroy 1989 pomeroy and li 2000 calculates hru snow erosion and deposition as a mass balance of horizontal snow transport via saltation and suspension and in transit sublimation using precipitation wind speed air temperature and relative humidity as well as information on the snowpack horizontal blowing snow redistribution by wind from one hru to another is determined by exposed surface roughness and therefore snow depth and surface characteristics three factors are needed for a blowing snow event to occur wind at a speed greater than the threshold condition an open snow surface with good exposure to wind and supply of erodible snow snow is eroded from wind exposed hrus and deposited as drifts in topographically sheltered or well vegetated hrus the details of the blowing snow model in crhm are provided in pomeroy et al 1993 and application of the model over a mountain region is detailed in macdonald et al 2009 in addition to blowing snow snow is redistributed by gravity in avalanches from higher to lower elevations on steep slopes described by an avalanche module named as sweslope in crhm based on the algorithm developed by bernhardt and schulz 2010 snow slides in an avalanche if the minimum snow holding depth hd and a minimum slope angle sm are exceeded they suggested values of hd and sm are 50 mm w e water equivalent and 25 surface slope respectively for slopes steeper than sm the snow holding depth decreases exponentially a best fit regression line equation 1 was derived from the curve of hd m and sm 0 as developed by bernhardt and schulz 2010 and used in the avalanche module 1 h d 3178 4 s m 2 3 2 energy balance the energy available for snow firn and ice melt qm w m 2 is the sum of fluxes due to radiation turbulence advection and conduction pomeroy et al 1998a pomeroy et al 1998b 2 q m q n q h q e q p q g d u d t where du dt is the change in internal energy of the snow ice qm is the energy available for melt qp is the advection energy from precipitation qg is the heat flux due to conduction qe and qh are turbulent fluxes of latent heat and sensible heat respectively and qn is the net radiation expressed as 3 q n k i n k o u t l i n l o u t 1 α k i n l i n ε σ t s 4 where k i n and k o u t are incoming and outgoing shortwave radiations l i n and l o u t are incoming and outgoing longwave radiations all these energy components have units of w m 2 ts is the surface temperature in kelvin and ε is the emissivity of the surface the available energy for melt qm can be converted to a melt rate m m s 1 as 4 m q m ρ w l f where ρ w is the density of water and l f is the latent heat of water fusion at the freezing temperature energy balance glacier melt modelling in crhm glacier consists of two separate melt algorithms giving distinct calculations for snow and firn ice surfaces the energy and mass balance snowmelt model snobal marks et al 1999 marks et al 1998 is used in modelling snow melt processes it simulates the energy and mass balances of snowpacks in mountains over glacier and non glacier surfaces internal energy exchange is calculated by tracking the cold content in two layers a surface shallow active layer and b lower deep snowpack the model solves for temperature and specific mass kg m 2 which is the product of snow depth and snow density accumulated energy is the energy available after satisfying the cold content and runoff of accumulated melt and liquid content exceeding a specified threshold the turbulent heat fluxes are obtained using an approach adopted from brutsaert 1982 by marks and dozier 1992 details are in marks et al 1998 a single layer daily time step energy budget melt model originally developed by gray and landine 1988 for shallow prairie snowpacks was customized to ice and firn melt by adjusting its albedo routine and assuming glacier ice and firn are isothermal so all internal energy change goes to ice melt or firn melt the radiation module in crhm simulates incoming shortwave global radiation adjusted to slope and aspect similarly in the absence of observations longwave irradiance can be estimated from shortwave transmittance and air temperature using the algorithm proposed by sicart et al 2006 that modified brutsaert s clear sky longwave algorithm for cloudy conditions terrain emission of longwave is also included in the sicart s model the influence of longwave irradiance from surrounding terrain can be significant in mountains plüss and ohmura 1997 the albedo module of snow evolution by verseghy 1991 adopted by essery and etchevers 2004 based on the age depth density and temperature of the snow layer is used to simulate the snow surface albedo 3 3 mass balance crhm glacier simulates the mass balance of snow firn ice water equivalents for glaciers as the following variables snow water equivalent swe mm firn water equivalent fwe mm and ice water equivalent iwe mm the mass balance of a glacier mb mm also referred to as the mass budget is expressed in flux terms as 5 d m b d t d s w e d t d f w e d t d i w e d t where the three terms in the right hand side are expressed as 6 d s w e dt d p snow dt d h i n s n o w dt d h o u t s n o w dt ds snow dt d m s n o w d t 7 d f w e dt v i n s n o w t o f i r n dt d v o u t f i r n t o i c e dt d s f i r n dt d m f i r n dt and 8 d i w e dt d v i n f i r n t o i c e dt d s ice dt d m ice dt swe fwe and iwe are the water equivalents of snow firn and ice respectively mass balances are typically calculated annually but fluxes of swe fwe and iwe need higher spatial and temporal resolution in their determination psnow is the amount of precipitation to the snowpack hin snow and hout snow are horizontal incoming and outgoing mass flows of snow due to blowing snow and avalanches whereas vin snow to firn and vout firn to ice are vertical incoming and outgoing mass flows due to firnification and firn conversion to ice ssnow sfirn sice are the mass losses by sublimation and msnow mfirn and mice are losses by melting from snow firn and ice respectively the units for these variables are mm p hin vin represent input fluxes and hout vout s m represent outputs many models do not consider firn separately e g li et al 2015 naz et al 2014 however firn has properties that are significant to glacier energetics and mass balance the albedo of firn is lower than that of snow but it is higher than that of ice secondly it is important for meltwater routing which is slower in firn than in ice hannah and gurnell 2001 thirdly the model adds the water equivalents of snow firn and ice to simulate changes in glacier surface elevation glacier surface elevation change δe at each time step of the model typically daily can be obtained as 9 δ e δ s w e ρ s δ f w e ρ f δ i w e ρ i ρ w here ρ s ρ f ρ i and ρ w are densities of snow firn ice and water respectively the densities are modelled through densification of multilayer snow pomeroy et al 1998a pomeroy et al 1998b and firn herron and langway 1980 δ s w e δ f w e and δ i w e are changes in water equivalents of snow firn and ice respectively crhm simulates the change in glacier surface elevation by considering snow redistribution and accumulation snow conversion to firn firn conversion to ice and ablation of snow firn and ice firn is snow that has survived at least for one summer melt season anderson and benson 1963 firn densification is calculated in three temporal stages adopted from semi empirical steady state approaches initially the top layer snowpack undergoes densification due to wind redistribution and compression as described by pomeroy et al 1998a pomeroy et al 1998b then firn undergoes densification at a rate that is linearly related to the pressure of overlying snow and firn layers herron and langway 1980 proposed two stages of densification from surface to the zone of pore close off 830 kg m 3 the initial rate of densification is faster and occurs until the density reaches 550 kg m 3 considered the critical density and the latter rate is slower and proceeds from the critical density to 830 kg m 3 from which the firn is considered to have become ice these firn densification stages are modeled in a 10 layer firn system and one ice layer updated annually at the end of summer fig 4 shows the schematic representation of snow firn and ice layers transitioning from winter to summer 3 4 water flow modules crhm assembles hydrological models from a library of physically based hydrological and energy balance process modules the crhm glacier model considers delayed interflow through snow firn ice and subsurface as well as groundwater flow using lag and storage hydrograph translation parameters the concept of linear storage routing has been used in several glacio hydrological studies e g engelhardt et al 2014 hannah and gurnell 2001 huss et al 2008 magnusson et al 2011 oerter et al 1981 jansson et al 2003 de woul et al 2006 proposed variable snow and ice reservoirs whilst keeping the firn reservoir constant they considered snow covered firn to be part of the firn reservoir however if ice was covered by snow they considered a distinctive snow reservoir in their model in crhm glacier meltwater is therefore routed from one hru to the other until it reaches the outlet by means of three storage constants ice firn and snow once the meltwater and rain reach the ground surface the three modules infiltration hillslope and routing estimate their storage and flow through three different strata surface subsurface and groundwater the model considers delayed interflow through snow firn ice and subsurface and groundwater flows using lag and storage parameters which can be determined using values from the literature or estimated using flow timing measurements or by calibration to fit the streamflow hydrograph either the muskingum streamflow routing module chow 1959 or clark s lag and route runoff routing module clark 1945 can be chosen in crhm for routing runoff to streamflow infiltrated water is calculated by a hillslope soil module by fang et al 2013 based on the soil module by leavesley et al 1983 which was progressively modified by dornes et al 2008 for cold regions mountain soils and fang et al 2010 for depressional storage and fang et al 2013 for mountain hillslopes the hillslope soil module deals with depression storage subsurface runoff groundwater recharge and groundwater flows between hrus water moisture loss from unsaturated or saturated non frozen surfaces by evaporation and transpiration is estimated using granger gray s evapotranspiration expression granger and gray 1989 granger and pomeroy 1997 which employs an energy budget and an extension of penman s combination equation using the complementary evaporation hypothesis evaporation from open water bodies is simulated by the energy budget evaporation expression for small water bodies and wetlands developed by priestley and taylor 1972 3 5 hydrological response units hrus the basins were discretized into hru based on slope aspect elevation and landcover including glacier cover the hru are control volumes used to apply meteorological forcing data and are the basis for coupled mass and energy budgets by the process modules google earth engine and arcmap were used to prepare hrus for both basins the steps in the flowchart shown in fig 5 example for pgrb were followed for the two research basins pgrb fig 6 and agrb fig 7 two landcovers 2014 and 1966 in the case of pgrb and 1984 and 2014 in the case of agrb were used since the gauging sites were at different locations during the ihd period and the present time two separate basin maps were prepared for pgrb the catchment area at the new gauging site is about 4 km2 smaller than at the old gauging site except for the 1966 landcover map of pgrb landsat images taken between 15th july to 15th september were considered as this time of year when the seasonal snowpack has melted the pgrb landcover map for 1966 was prepared from the scanned topographic map of 1966 four landcover classes were considered accumulation area firn snow ablation area ice non glacierized area bare and water the following steps were considered whilst preparing hru 1 landcover maps from two periods were prepared from landsat images and a topographic map for agrb 1984 and 2014 and for pgrb 1966 and 2014 were considered 2 dem derivatives slope aspect and elevation bands were created from 2000 dem agrb and 1966 dem pgrb using the arcmap spatial analyst tool 3 slope was reclassified to 3 classes 0 15 15 45 and 45 aspect was reclassified to north and south and elevation was classified in bands at every 100 m the classes were converted to polygons using a raster to polygon tool 4 landcovers from two dates slope aspect and elevation bands were intersected with each other using the union function 5 the created feature had many smaller polygons which were simplified using the eliminate function the smaller polygons with area below 25000 m2 were dissolved to polygon with the largest border it shared with 6 if the polygons fell under bare area on both years 1984 and 2014 for agrb and 1966 and 2014 for pgrb the polygons were merged to adjacent polygons making elevation bands cut at every 200 m 7 all the polygons were carefully analyzed based on topology and merged to one another reducing the number of hru s to 90 for agrb fig 6 and 70 for pgrb peyto old outlet the number of hru s were reduced to 65 for pgrb with peyto new outlet fig 7 8 hru numbering was done based on flow direction patterns where water flows from smaller hru number to higher hru number finally towards the outlets of the basins hru 90 is the outlet of agrb hru 70 is the peyto old outlet and hru 65 is the peyto new outlet the physiographic parameters required by crhm glacier for each hru include the following area latitude average elevation average ground slope average aspect and average terrain view factor tvf except for tvf all parameters were calculated in r for each available dem tvf was obtained in saga gis as a sub product of the sky view factor under the terrain analysis the major landcover of each hru in a year was calculated using zonal statistics with table the majority of landcovers from 1966 and 2014 in the case of pgrb and those from 1984 and 2014 in the case of agrb were calculated by using the raster iterator operator in a model builder of arcgis 10 3 1 3 6 testing model performance model simulations were compared with the available hydrometeorological and glaciological observations at the two basins agrb and pgrb to evaluate the crhm glacier model the model was compared with the in situ measurements of albedo surface accumulation and ablation and streamflow discharge generation incoming and outgoing shortwave radiation measured by aws on glacier ice and moraine provided observed albedo measured daily albedo was obtained as a ratio of the daily amount of outgoing shortwave radiation to the daily amount of incoming shortwave radiation oerlemans and knap 1998 daily observed and simulated albedo values were compared for the four sites for five years or more except peyto glacier lower ice aws which had both incoming and outgoing shortwave radiation measurements during 2007 2008 only modelled surface accumulation and ablation processes over the glacier were compared with surface height changes fig 8 that were measured by sr50 ultrasonic depth sounders at the three ice stations in pgrb the advantage of comparing surface elevation change over comparing water equivalent change is that the former provides an additional comparison of density simulation in the model garen and marks 2005 this process also validates the surface elevation change modelled by the accumulation and ablation process at the surface crhm parameters were set by knowledge and understanding of the basin instead of optimizing to simulate the streamflow hydrograph though parameter calibration is sometimes inevitable it can be reduced with advancements in hydrological science pomeroy et al 2013 ommanney 2002 summarized the studies made by derikx 1975 and collins 1982 who found that the meltwater reaches the outlet of pgrb at a very short time from 2 to 5 h munro 2011a and munro 2013 also considered the runoff delay in pgrb and found it varied from a few hours to half a day given the daily time step of discharge no parameters whatsoever were calibrated in this study the model simulated discharges of the two basins for two different time slices were compared with observations over daily periods for the present 2014 2019 for agrb 2013 2018 for pgrb and past datasets 1967 1977 and 1980 1989 for agrb 1967 1977 for pgrb crhm glacier considered redistribution of accumulated snow by two processes blowing snow and avalanching blowing snow includes the effect of blowing snow transport redistribution and sublimation losses avalanching is dependent upon blowing snow transport to redistribute snow to form deep accumulations in avalanche source areas the effects on model performance of adding blowing snow and avalanching were investigated using model falsification with and without these processes by comparing the model outputs to the observations similarly the test runs were carried out to diagnose the impacts of glacier processes on the model model falsification is straightforward to implement in crhm the blowing snow avalanche and glacier modules in crhm can be turned on and off so that outputs could be compared for example models could be built with and without the blowing snow module first the model was tested for glacier surface elevation changes on peyto glacier at three observational sites second it was tested for streamflow simulations from the two basins agrb for 2014 2019 and pgrb 2013 2018 with forcing meteorological data from bias corrected era interim and in situ observed data the following three model scenarios were considered with a model falsification approach to examine the impacts of glacier and snow redistribution processes on streamflow and glacier surface calculations 1 with both glacier and snow redistribution processes 2 with glacier but without snow redistribution processes 3 with snow redistribution but without glacier processes based on these three experimental scenarios three comparison tests were employed to evaluate the glacier and snow redistribution modules agreement between simulated and observed values was evaluated by using both traditional and non traditional statistical indices nash sutcliffe efficiency nse nash and sutcliffe 1970 mean bias error mbe and the root mean square error rsme were used along with the wang bovik index wbi proposed by wang and bovik 2002 and reformulated by mo et al 2014 for application to hydrometeorological data wbi evaluates the similarities between modelled and observed variables in terms of pattern association and differences in the means and variances mo et al 2014 10 wbi m xy v xy r xy where the three components are defined as 11 m xy 2 x ψ xy y ψ xy x ψ xy 2 y ψ xy 2 12 v xy 2 σ x σ y σ x 2 σ y 2 13 r xy σ xy σ x σ y where ψ xy min xi yi i 1 2 3 n here xi and yi are measured and predicted daily global solar radiation respectively at i day x and y are means σ x and σ y are standard deviations and σ xy is covariance m xy and v xy are the measures of differences in means and variances respectively r xy is the pearson correlation coefficient all statistical analyses were carried out in r r core team 2017 in the rstudio platform rstudio 2017 the code for wbi was provided by paul whitfield university of saskatchewan centre for hydrology and environment and climate change canada and the other codes were used from the r packages hydrogof mauricio 2014 and sirad bojanowski 2016 the analysis results are presented in graphs and tables performance rating based on the values of nse was considered as very good nse 0 65 adequate 0 65 nse 0 54 and satisfactory 0 54 nse 0 50 following dahal et al 2020 4 results and discussion unlike other glacier hydrological models the model parameters in crhm glacier are not calibrated and so there are no calibration and validation periods to compare the model results are presented in the following subsections 4 1 model evaluation the model was tested against observations of meteorological variables albedo mass balance and discharge model performance was evaluated by means of visual as well as statistical interpretations 4 1 1 albedo net shortwave radiation is the most important energy flux for glacier melt munro and young 1982 therefore accurate parameterization and modelling of surface albedo are crucial for computing the energy and mass balance of the glaciers the model was evaluated using recent measurements of surface albedo at four locations two sites in pgrb peyto main and peyto lower ice stations and two sites in agrb athabasca moraine and athabasca ice stations the crhm glacier albedo module was used to simulate albedo on glacier ice and off glacier surfaces over both basins the meteorological forcing data for these tests were from athabasca moraine station for agrb and peyto main station except precipitation data for pgrb precipitation data for pgrb were from bow summit the comparisons were made at daily values with point aws measurements fig 9 and their statistical measures for model performance are presented in table 4 the model captured the variation of albedo on both on ice and off ice sites with wbi higher than 0 85 rmse less than 0 17 and the highest mbe being 0 063 though these point observations do not represent all basin areas they represent both snow accumulation and ablation conditions since a single value of albedo was used for snow free conditions the variation of albedo during ice melt was not represented however transitions of albedo from snow covered to snow free and vice versa were well captured at both on ice and off ice sites fig 9 both glacier and moraine sites presented cycles of snow covered and snow free times with albedo values reaching 0 9 and 0 3 in the case of ice surfaces and 0 15 at moraines the ice exposed periods with lower albedo values were well simulated by the model the modelled albedo decay over the athabasca moraine station was slower than the observed values and mid winter albedo values were overestimated due to wind erosion of snow and exposed boulders and microtopography at this site the albedo of athabasca ice during snow free periods in the recent years 2017 2019 was lower 0 25 than the previous years fig 9a and may be influenced by upwind forest fires bertoncini et al in review 4 1 2 glacier mass balance the surface accumulation and ablation simulations from crhm glacier were tested with the surface mass balance measurements by mass balance stakes and ultrasonic sensors sr50 installed at various points over peyto glacier 4 1 2 1 surface point mass balance fig 10 shows the time series of simulated and observed changes in the elevation of the glacier surface with respect to the sr50 sensors during the recent decade the model was run from october 2010 to september 2019 with meteorological forcing data from both in situ observation at peyto main station air temperature relative humidity wind speed incoming short and long wave radiation and bow summit precipitation and bias corrected era interim the comparisons were limited to the periods when sr50 data were available performance of the model along with meteorological forcing data were evaluated by statistical parameters presented in table 5 all the sites had at least one continuous dataset for two years showing the model s capability to capture accumulation and ablation the best match between simulated and observed surface heights was at the lower ice station and performance diminished with elevation the model accumulated more mass during the two year period than the measured mass balance at the upper ice station mbe 0 26 m with the measured model forcing data from the peyto main however the accumulation was less when the model was forced with era interim data table 5 4 1 2 2 aggregated glacier mass balance model simulated hourly daily mass balance for peyto glacier was converted to seasonal and annual mass balances to compare with the measured values obtained from the ablation stakes fig 6 the simulated seasonal glacier mass balances exclude dragan glacier and other small ice patches in the northeast part of the basin for the period from 1965 to 1995 fig 11 shows that the model did not simulate the aggregated seasonal mass balance as well as it simulated point mass balances as presented in section 4 1 2 1 several factors could have contributed to the reduced performance at the glacier scale firstly none of the model parameters were calibrated to simulate mass balance although there is a practice of calibrating mass balance against in situ observations e g giesen and oerlemans 2012 radić and hock 2011 shannon et al 2019 secondly the model performed less well at the upper ice station compared to the middle ice and lower ice stations fig 10 another reason could be the difference in approaches to obtain the seasonal mass balance the observed values of seasonal mass balance were obtained from a series of transects of ablation stakes distributed over half of the glacier area at lower elevations fig 6 and these values were linearly extrapolated to higher elevation bands as there were not any mass balance stake measurements above 2700 m details are in demuth and keller 2006 the modelled seasonal mass balance was calculated from the hrus distributed over the glacier differences between the mass balance extrapolations and various model distributions of forcing meteorology with elevation could explain why the mass balances simulated at lower elevation bands matched closer to the observations not shown here than did those simulated at higher elevation bands 4 1 3 streamflow model performance metrics for both basins are provided in table 6 and from figs 12 to 15 the performance of the model can be rated as very good with nse equal to 0 71 and 0 77 for agrb for the period 2014 2019 with meteorological forcing data from in situ observation and from era interim respectively the model performance of agrb with era 40 forcing data was also very good for the past records 1967 1977 nse 0 75 and 1980 1989 nse 0 73 the model performance for pgrb was very good with nse equal to 0 68 and 0 67 with meteorological forcing data from in situ observation and from era interim respectively wbi values were 0 86 and 0 87 for agrb and 0 80 for pgrb however pgrb had smaller mbe values 0 06 and 0 01 m3s 1 and lower rmse values 1 19 and 1 2 m3s 1 than agrb mbe 0 28 and 0 11 m3s 1 rmse 1 29 and 1 14 m3s 1 figs 13 15 the model also performed well for the past records with bias corrected era 40 nse values of agrb were 0 75 and 0 73 and wbi were 0 89 and 0 87 for the periods 1967 1977 and 1980 1989 respectively the nse value of pgrb 1967 1977 was 0 61 with the bias corrected era 40 the model was also tested with lake louise precipitation data for pgrb 1967 1977 the model driven by era 40 data provided a better simulation than that driven by era 40 with lake louise precipitation data table 6 generally the model simulated streamflow well with wbi values higher than 0 8 except for pgrb in the past 1967 1977 when the wbi was 0 76 wbi evaluates similarity in modelled and simulated values in terms of not only correlation but also mean and variance mo et al 2014 the model performed better in agrb compared to pgrb moreover the streamflow simulations were better in the present period compared to the past for pgrb this could be due to the uncertain quality of streamflow data at pgrb in the past flow measurement at the peyto outlet during the ihd 1967 1977 was a challenge due to an unstable cross section occasional flash floods and lack of direct discharge measurements during high flows goodison 1972 reported that the discharge records from 1967 were not reliable and he did not use this data for his study the streamflow stage gauge was washed out during a flood in august 1967 occasional flash floods were reported in the stream by ommanney 1987 and johnson and power 1985 however model performance statistics show a good ability to simulate streamflow both in the past and present time periods from the bias corrected reanalysis data for both basins the test runs were also carried out to see the impacts of glacier and snow redistribution processes using a model falsification approach fang et al 2013 the model was run three times first with both glacier and snow redistribution processes the second run was with the glacier but without snow redistribution processes and the third one was with snow redistribution but without the glacier fig 16 compares the observed and simulated streamflow hydrographs for agrb averaged over the model run period of 2014 2019 streamflow simulations without the glacier generated about 50 of the observed flow and indicated the strong influence of glaciation on streamflow the differences between observed and simulated streamflow without the glacier were highest during july august fig 17 compares these simulations with the observed streamflow at the peyto glacier outlet similar to athabasca hydrological simulations without the glacier in pgrb also generated almost half the streamflow compared to the observed streamflow simulations without snow redistribution overestimated streamflow showing the need to include blowing snow transport and sublimation calculations in glacier hydrological simulations the agreement between simulated and observed runoff was closer in pgrb than in agrb this is likely due to the precipitation data used for pgrb this was observed at the bow summit station which is a well sheltered precipitation gauge whereas the precipitation gauge in agrb is at wind blown open site where uncertainty due to wind undercatch corrections is introduced moreover the precipitation and temperature lapse rates were determined from observed precipitation at different elevations at pgrb and these values were transferred to agrb adding uncertainty in the regionalization of these rates 4 2 sources of runoff and changes over time the crhm glacier model was used to determine various spatially integrated mass fluxes and their changes over a period of five decades simulated spatially integrated mass fluxes are shown in fig 18 their values are given in table 7 this shows the importance of glacier firn and ice melt 38 50 to total runoff streamflow discharge though snow melt was still the largest runoff component the contribution of glacier melt increased by 6 7 in the recent decade 2006 2017 compared to the past 1966 1977 total precipitation decreased in both basins however the rainfall ratio increased as did basin flow annual discharge this was caused by an increase in glacier ice melt that was tempered by a decrease in snow melt the combination of increasing rainfall decreasing snow melt increasing ice melt led to increasing basin flow and showed a hydrological regime change under way importantly the increase in rainfall and ice melt more than compensated for decreasing snow melt in their impact on basin flow 5 discussion most mountain glaciers lack on ice weather data clarke et al 2009 the result of crhm glacier over peyto and athabasca glaciers is encouraging in that both off ice station and atmospheric model reanalysis data have very good potential for use in driving glacier hydrological models of mountain glaciers in remote regions the simulated streamflow hydrographs without the glacier generated about half of the total observed flow in both basins the differences in these flow values increased to approximately an order of magnitude larger than modelled flows without the glacier by late summer when ice melt is large and snow melt is depleted these test runs showed that the streamflow from these basins would be reduced dramatically and catastrophically under the current climate with complete deglaciation snow redistribution processes by wind and avalanches reduced streamflow the simulation with the glacier and addition of the redistribution processes reduced the differences between the simulated and observed streamflows and were important to include the shifting importance of glacio hydrological processes from the ihd period to the present is instructive the increase in rainfall and decrease in snowmelt can be attributed to the increasing rainfall ratio and its effects on both rainfall occurrence and snow accumulation and melt the declining snowcover over the glaciers increased the ice exposure and hence the ice melt as there was a greater ice surface exposed to melt energy this is consistent with the rise in the ela that is noticeable from the ihd to present period in photographs of peyto glacier and the authors photographs of athabasca glacier from the 1970 s to present the more negative mass balance and shrinkage of both glaciers is the cause of the 260 mm peyto to 88 mm athabasca increase in streamflow runoff when precipitation has declined by 226 mm peyto and 115 mm athabasca since the 1960 s though the model performed well in most tested metrics there are some limitations that could be improved in future studies crhm glacier was constrained by the forcing of meteorology and the suite of processes that were included in the model several uncertainties in the input data drove the uncertainties in model outputs precipitation is critical for crhm glacier precipitation measurements at the moraine stations in the study basins were not reliable due to very high wind speeds for which available undercatch equations are unreliable therefore precipitation measured at bow summit a small wind sheltered forest clearing outside pgrb was used to evaluate model performance and to bias correct reanalysis data no similar sheltered precipitation gauge was available for agrb the temperature and precipitation lapse rates were set by observations made at different elevations and so errors in these observations propagated into lapse rate estimation another important meteorological variable is shortwave irradiance the model corrects irradiance due to self shading for each hru using slope and aspect to spatially distribute shortwave and longwave irradiance however it does not consider shadowing from surrounding topography consideration of which may improve melt calculations in mountains as shown by marsh et al 2012 and hopkinson et al 2010 in this region moreover there are potential errors in global radiation measurement average global radiation was measured with a kipp and zonen cm 11 pyranometer and a cnr 4 in the main stations snow accumulation and frost on the pyranometer dome certainly occurred at times similarly several processes such as ice flow glacier surges melt of ice cored moraine ice falls ice calving into the downstream glacial lakes evolution of vegetation cover at the lower elevation of the basin and evolution of drainage patterns were not considered in the model and its operation here debris covered ice is becoming more common in canadian mountain glaciers particularly at the terminus currently these areas are not treated distinctively apart from assigning low albedo values the debris cover may alter the surface energy balance due to the low thermal conductivity of debris vincent et al 2016 the model also did not consider short term impacts of meltwater refreezing to form superimposed ice on the glacier naz et al 2014 6 conclusions crhm glacier a new physically based energy budget and mass balance snow redistribution spatially distributed glacier hydrology model was developed and applied to simulate both the glacier mass balance and streamflow of mountain glacierized basins crhm glacier uses coupled mass and energy budgets firnification and snow redistribution by wind and gravity to calculate snow melt firn melt and ice melt separately and it can be used in basins that are glacierized partly glacierized or glacier free including basins undergoing transitional phases from glaciation to deglaciation hydrometeorological streamflow and glaciological observations from the 1960 s to recent times at peyto glacier and new observations at athabasca glacier in the canadian rockies were used to quantify change suggest model development verify model operation and drive models of glacier hydrology change bias corrected reanalysis data and data from off ice stations were used to drive the model and on glacier station observations were used to validate the model when driven with locally measured off ice meteorological data or bias corrected reanalysis data and tested against specialized on ice snow and ice surface height measurements the model was able to simulate both accumulation and ablation of snow and ice quite well the model was also able to simulate albedo and streamflow well without calibration of any parameters from observations model predictions of streamflow improved when processes describing snow redistribution by wind and gravity were included in the model and model falsification showed that hydrological modelling must include a glacier component including firnification in order to successfully simulate the hydrology of glacierized basins the validated model was used to simulate water balance and runoff components of both study basins for two time periods past 1966 1977 and present 2006 2017 there was an increase in streamflow in the more recent period despite a marked decrease in precipitation and snow melt this is due to increased glacier ice melt which has become a larger runoff component during late summer the increase in streamflow despite declining precipitation from these glaciers is a symptom of deglaciation and increased glacier ice melt since the 1960 s and is not sustainable into the future as these glaciers will disappear due to their persistently negative mass balances the physical basis of this model and determination of physically identifiable model parameters from observations can reduce uncertainty in long term simulations especially those for future climates where calibrated parameters may no longer apply author contributions dp and jwp conceptualized the research dp built the model and tested it at the research basins and prepared the manuscript jwp contributed to model and methodology development instrumented the glaciers and contributed to and revised the manuscript credit authorship contribution statement dhiraj pradhananga conceptualization formal analysis investigation software writing original draft john w pomeroy conceptualization data curation funding acquisition software supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors wish to acknowledge the decades of extremely challenging field research at peyto and athabasca glacier basins by dozens of scientists and students meriting special mention are dr d scott munro retired of the university of toronto and michael n demuth retired of natural resources canada whose legacy of research on peyto glacier including meteorological and mass balance observations made this study possible special mention also goes to the prescient scientists of the international hydrological decade who established peyto glacier as a research site including dr gordon young of environment canada and wilfrid laurier university additional data was provided by environment and climate change canada s meteorological service of canada and water survey of canada parks canada and alberta environment and parks tom brown and xing fang of the centre for hydrology supported crhm development and operation parameterization respectively nammy hang kirat of the small earth nepal supported gis map production funding for this study was provided by the canada research chairs canada foundation for innovation natural sciences and engineering research council of canada through its discovery grants and the changing cold regions network alberta innovation and the canada first research excellence fund s global water futures programme special thanks go to the two anonymous reviewers for their careful and critical review of the manuscript and their several insightful comments and constructive suggestions which helped to improve the manuscript 
3457,a comprehensive glacier hydrology model was developed within the cold regions hydrological modelling platform crhm to include modules representing wind flow over complex terrain blowing snow redistribution and sublimation by wind snow redistribution by avalanches solar irradiance to sloping surfaces surface sublimation glacier mass balance and runoff meltwater and streamflow routing the physically based glacier hydrology model created from these modules in crhm was applied to simulate the hydrology of the instrumented glacierized and rapidly deglaciating peyto and athabasca glacier research basins in the canadian rockies without calibration of parameters from streamflow it was tested against observed albedo point and aggregated glacier mass balance and streamflow and found to successfully simulate surface albedo snow redistribution snow and glacier accumulation and ablation mass balance and streamflow discharge both when driven by in situ observations and reanalysis forcing data long term modelling results indicate that the increases in discharge from the 1960s to the present are due to increased glacier ice melt contributions despite declining precipitation and snow melt keywords glacier hydrology energy budget melt mass balance snow redistribution peyto glacier athabasca glacier hydrological modelling 1 introduction changes in alpine snow and glacier hydrology influence both timing and magnitude of streamflow discharge and thus impact the water supply for downstream industrial agricultural hydropower environmental and drinking purposes around the world these changes include the rapid retreat of glaciers arendt et al 2009 berthier 2004 demuth and pietroniro 2003 diolaiuti et al 2011 fujita and nuimura 2011 haeberli et al 2007 kaser et al 2004 naz et al 2014 ohmura 2006 schiefer et al 2007 declining seasonal snowcover at higher elevations fujita and nuimura 2011 ipcc 2007 mote et al 2005 and declining streamflow demuth and pietroniro 2003 immerzeel et al 2010 kienzle et al 2012 rood et al 2008 in particular the influence of glacier snow and ice melt dominates the seasonal pattern of runoff in mid to high latitude mountains more than low latitude high mountains kaser et al 2003 the canadian rockies constitute the headwaters of the major rivers of western canada and northwest us for example the saskatchewan nelson columbia fraser and columbia rivers snow and ice in these mountain headwaters regulate the hydrology of the rivers by acting as a short to long term water storage reservoir lópez moreno et al 2020 but north american mountain glaciers are retreating arendt et al 2002 berthier 2004 berthier et al 2010 comeau et al 2009 debeer et al 2007 demuth and pietroniro 2003 moore and demuth 2001 munro 2000 schiefer et al 2007 thus causing changes to this reservoir function observations suggest that there is a pronounced acceleration in the glacier retreat in the canadian rockies moore et al 2009 which is very noticeable in the case of peyto glacier e g demuth and keller 2006 kehrl et al 2014 changes in north american glacier mass area and shape result in changing contributions to water resources barry 2006 reynolds and young 1997 and these changes in glacier elevation and volume are related to changes in temperature and precipitation tennant and menounos 2013 the other notable change in most glaciers is the rise in their equilibrium line altitudes ela due to warming climate malecki 2015 van pelt and kohler 2015 zemp et al 2015 the ela is the dividing elevation between accumulation and ablation zones on a mountain glacier and so its elevation indexes the glacier mass balance variations in the ela are commonly attributed to changes of winter precipitation and summer air temperature bakke and nesje 2011 therefore there are changes in glacier mass ela and in streamflow it is essential to understand how the decline of alpine snowcover and glacier mass in the mountains is influencing streamflow generation as this can help to predict the availability of future water resources snow and glacier melt models range from complex energy budget models hock and holmgren 2005 klok et al 2002 magnusson et al 2010 michlmayr et al 2008 mott et al 2008 munro 2011a munro 2004 munro and marosz wantuch 2009 naz et al 2014 oerlemans 1991 shea et al 2015 to more simplified degree day models anderson et al 2006 hock 1999 immerzeel et al 2012 most glacier hydrology models use simple conceptual melt models that are based on temperature and precipitation observations and are calibrated from past conditions see hock 2005 for review examples include statistical and temperature index models fujita and nuimura 2011 hannah and gurnell 2001 hock 2003 1999 luo et al 2013 shea and marshall 2007 singh and bengtsson 2005 stahl et al 2008 verbunt et al 2003 these empirical models do not consider the redistribution of snow by wind and avalanches sublimation losses and the full radiation energetics that are critical to the survival of small mountain glaciers déry et al 2010 because high altitude observations of shortwave irradiance are limited empirical techniques that rely upon commonly measured variables such as air temperature have led to the popularity of the temperature index model and its wide use to simulate glacier snow and ice melt hock 2005 these empirical methods are unlikely to be reliable for future conditions as they have been calibrated based on past climates poulin et al 2011 walter et al 2005 however demonstrated that a physically based energy budget melt model does not require more input data than most temperature index methods or what is available on most modern meteorological stations the energy budget snowmelt model ebsm of gray and landine 1988 is an example of such a physically based snow model that only requires precipitation temperature humidity and wind speed information pomeroy et al 2013 showed that shortwave and net radiation can be synthesized from temperature and humidity data to drive energy budget snowmelt and evapotranspiration algorithms for example several relationships have been developed to estimate shortwave shook and pomeroy 2011 and longwave radiation sicart et al 2006 from latitude time of year air temperature and vapour pressure sicart et al 2006 evaluated longwave and shortwave radiation estimates from these methods over mountain wolf creek research basin in yukon territory and prairie saskatchewan sites in canada and found that simulated values were close to measurements moreover reanalysis products are now commonly being used to force hydrological models krogh et al 2015 making application of the energy balance more straightforward than in the past the cold regions hydrological modelling platform crhm pomeroy et al 2007 is a flexible object oriented process based modelling platform that runs on spatially distributed hydrological response units hru at sub daily or sub hourly timesteps hru are landscape units having a common set of parameters and modules and that have some common biogeophysical and drainage characteristics hru are used to distribute meteorological forcing data over the basin and in this application are based on slope aspect elevation and landcover type including glacier coverage crhm simulates several cold region hydrological processes that are important in high mountain environments such as blowing snow redistribution blowing snow sublimation infiltration into frozen soils radiation exchange in complex terrain snow accumulation and ablation as well as the full range of hydrological processes for warm seasons such as evapotranspiration infiltration soil moisture movement groundwater dynamics surface runoff and interflow pomeroy et al 2007 fang et al 2013 the model runs through interactions of the four components observations parameters modules and state variables through calculation of mass and energy budgets on the hru sub basin and basin levels of discretization blowing snow avalanches runoff interflow and groundwater flow can move via various pathways from hru to hru s and streamflow is routed from various sub basins to the basin outlet through these interactions crhm links atmospheric data inputs and hydrological outputs the minimum atmospheric inputs required to force crhm are air temperature humidity wind speed and precipitation either from automatic weather stations or from atmospheric model outputs for the surface level crhm has been successfully applied to many regions ranging from the canadian prairies to high mountains in north and south america ellis et al 2010 fang et al 2010 fang and pomeroy 2007 krogh et al 2015 lv and pomeroy 2019 macdonald et al 2010 2009 rasouli et al 2014 europe lópez moreno et al 2013 africa lópez moreno et al 2020 and asia zhou et al 2014 recent research has coupled basin hydrology modelling with glacier dynamics to assess the impact of glacier retreat on streamflow finger et al 2013 huss 2011 huss et al 2005 immerzeel et al 2012 naz et al 2014 shea et al 2015 however these and other studies have not considered many of the important cold region hydrological processes including the evolution ablation and redistribution of snow snow storage redistribution of snow by wind and gravity and sublimation rates in high latitude alpine mountains are crucial processes to consider when determining meltwater contribution to the basin ayala ramos 2017 bernhardt and schulz 2010 bravo et al 2017 macdonald et al 2010 strasser et al 2008 despite significant advances in the understanding of blowing snow redistribution and sublimation processes déry et al 2010 doorschot et al 2001 essery and pomeroy 2004 liston and elder 2006 macdonald et al 2009 pomeroy and li 2000 they have not yet been included in mountain glacier melt studies in the canadian rockies they have been considered in mass balance and melt studies over icelandic and polar glaciers déry et al 2004 as well as in studies of greenland mernild et al 2008 mernild et al 2007 antarctic bintanja and reijmer 2001 gallée et al 2012 thiery et al 2012 and arctic bintanja 2001 liston and hiemstra 2011 sea ice and ice sheets these studies suggest snow redistribution snow sublimation and other hydrological processes may also contribute to the mass and energy budgets of mountain glaciers in western canada therefore there is a need to develop a glacial melt model that utilizes an energy budget approach physically measurable inputs and a snow redistribution approach that accounts for the complex mass transport present in mountainous regions it is hypothesized that the simulation of water contributions from glacial ablation will be more accurate when snow redistribution by wind and gravity sublimation and surface energy budget energetics are included this study develops and tests a comprehensive physically based and spatially distributed model of glacier snow and ice hydrology at two glacierized research basins in the canadian rockies the crhm glacier model developed within chrm includes redistribution of snow by wind and avalanches an energy budget melt model for snow firn and ice consideration of slope and aspect for radiation distribution and runoff routing 2 study sites and data 2 1 two instrumented partially glacierized alpine basins in the canadian rockies peyto glacier research basin pgrb latitude 51040 n and longitude 116033 w in banff national park and athabasca glacier research basin agrb latitude 52011 n and longitude 117016 w in jasper national park both in alberta canada were considered for testing the crhm glacier model figs 1 and 2 both research sites are part of the canadian rockies hydrological observatory a network of instrumented basins in the mountain headwaters of the saskatchewan and athabasca river basins operated by the university of saskatchewan centre for hydrology pgrb with its outlet at the former streamflow gauging site peyto outlet old fig 1 c covers an area of 22 43 km2 which included 9 9 km2 of glacierized area as of 2016 agrb has a basin area of 29 3 km2 including 16 9 km2 of glacierized area in 2016 peyto glacier in pgrb is a valley outflow glacier of the wapta icefield in the waputik mountains athabasca glacier in agrb is a valley outflow glacier of the columbia icefield streamflow out of pgrb flows east into the mistaya river basin a headwater of the north saskatchewan river and eventually into the hudson bay via the nelson river and that out of agrb flows north through the sunwapta river a headwater of the athabasca river and eventually into the beaufort sea of the arctic ocean via the mackenzie river table 1 provides the general physical characteristics of these two research basins these basins were equipped in 2013 2014 with new automatic weather stations aws on ice and off ice sites the instrumentation and range of parameters measured at these aws are presented in table 2 these glaciers have been losing mass continuously since the mid 1970 s demuth and keller 2006 kehrl et al 2014 tennant and menounos 2013 in the case of peyto glacier a new proglacial lake lake munro formed at the tongue of the glacier and is increasing in size every year peyto creek flowing out of lake munro drains the meltwater from the glacier and discharges to peyto lake which has outflow into the mistaya river the first record of peyto glacier goes back to 1897 photograph by walter d wilcox and it was subject to intermittent scientific investigations in the 1930s 1940s and 1950s significant research over the glacier started in 1965 when it was selected as one of the research sites for the unesco international hydrological decade ihd the scientific scope and instruments used for observations have increased and improved progressively since then munro 2013 as reported by meek 1948 surveys documenting the recession and flow of athabasca glacier began in 1945 2 2 data 2 2 1 topography several digital elevation models dem from different years topographical maps and satellite images were considered for both the basins for pgrb the 1966 dem 10 m resolution was developed from the scanned topographic map of peyto glacier produced from the aerial photographs from august 1966 sedgwick and henoch 1975 the same map was used for considering landcover for 1966 of the basin the 2006 dem 10 m resolution was obtained from airborne lidar measurements demuth and hopkinson 2013 since the aerial photograph didn t cover the whole pgrb the northeastern corner of the basin was mosaiced with the 2014 dem to fill in the missing part the 2014 dem was prepared at a 10 m resolution from aerial photogrammetry of banff national park by geodesy group inc taken during july and september 2014 pgrb landcover maps for 2006 and 2014 were prepared based upon landsat 5 satellite images for 2006 and landsat 8 for 2014 for agrb dems from 1983 canadian digital elevation model cdem 2000 canadian digital surface model cdsm and 2011 all at 20 m horizontal resolution were available landcover maps were generated from landsat 5 and landsat 8 top of atmosphere reflectance images using google earth engine landsat 5 images were used for the years 1984 and 2006 and landsat 8 images were used for 2014 the images acquired for this study were taken between 15th july to 15th september in the respective years with minimum or no cloud cover inside the basin boundaries the dem and landcover data are summarized in table 3 2 2 2 glaciology and hydrology past studies of peyto glacier are well documented in the book peyto glacier one century of science edited by demuth et al 2006 the book also provides details of the mass balance data along with hypsometry of the glacier long term glacier mass balance records are available for peyto glacier from 1965 with a data gap in 1991 1992 glaciological mass balance measurements using ablation stakes and snow pits have been taken continuously since the ihd period mass balance data for the 11 elevation bands are available in several publications demuth and keller 2006 ommanney 1987 young and stanley 1976 though winter bw and summer bs balance records are available until 1994 annual glacier net mass balance bn data are available after 1994 wgms 2020 mass balance data for athabasca glacier were not available for this study pgrb streamflow was gauged during the ihd period and then discontinued in 1977 in the summer of 2013 the university of saskatchewan centre for hydrology established a stream gauging site in the basin about 1 5 km upstream from the site used in the ihd locations of old and new gauges are shown in fig 6 discharge data from the ihd period are available for an 11 year period 1967 1977 and those from the recent period are available for 6 years 2013 2018 discharge data from the outlet of athabasca glacier are available from 1948 to the present with a data gap from 1997 to 2004 historical streamflow discharge data from pgrb and agrb and recent data for agrb were obtained from the environment and climate change canada s water survey of canada 2 2 3 meteorological forcing datasets awss fig 2 were installed at on ice and off glacier sites in agrb and pgrb by the university of saskatchewan centre for hydrology in 2013 2014 archived hourly meteorological observations from the aws at the peyto glacier main station were available from 1987 munro 2011a munro 2011b along with periodical observations made on the ice since 2007 pradhananga et al 2021 precipitation data from the canadian rockies hydrological observatory station above nearby helen lake https research groups usask ca hydrology data php and the three stations bow summit saskatchewan river crossing and lake louise of environment and climate change canada http climate weather gc ca were used to estimate elevational gradients in precipitation following the approach by fang et al 2013 monthly values of temperature lapse rates were obtained from observations at the four aws stations fig 1c at different elevations on pgrb these monthly values of gradients in precipitation and temperature were applied to pgrb and then transferred to agrb preparation of meteorological data to provide continuous datasets suitable for forcing a hydrology model presents several challenges at these sites meteorological data collection from alpine glacier basins is challenged by remoteness difficulty in accessibility severe weather and year round cold conditions and many other difficulties higher winter snow accumulations can bury on ice stations and increasingly rapid summer melt can cause the meteorological station towers or tripods to tilt or fall rapid ice melt means that stations needed to be re installed by drilling 5 m into the ice twice a year therefore the aws located within and near the basin were used to fill in gaps details are in pradhananga et al 2021 for pgrb reanalysis data were used to run the model beyond the observation periods for pgrb the model was also tested with lake louise precipitation data for the model run period 1967 1977 as this was the only proximal station in existence at the time the era global reanalysis datasets era interim dee et al 2011 and era 40 uppala et al 2005 were first bias corrected to a single point at the main aws stations on agrb and pgrb by comparing with the in situ observations at these sites or proximal sites when precipitation was corrected for wind undercatch a quantile mapping technique was used for the bias corrections of air temperature vapour pressure wind speed precipitation incoming shortwave and longwave radiation with parameters individually calibrated for each month from corresponding data periods using the qmap package in r gudmundsson 2016 for agrb era interim data were bias corrected to the athabasca moraine station which had observed data from 2014 to 2019 since there was not any observed data before 2014 for agrb era 40 data were bias corrected using era interim data for the period of 1979 2002 similar to the approach of krogh and pomeroy 2018 for pgrb era interim data were bias corrected to peyto main station observations from 2013 to 2019 except for precipitation data which were taken from the proximal and sheltered bow summit observations era 40 data for pgrb were bias corrected to the archived observation from the station for the common overlap period of 1987 2001 these bias corrected reanalysis datasets and in situ observations over pgrb are published in pradhananga et al 2021 lake louise precipitation data were also bias corrected to bow summit by monthly quantile mapping using these datasets to force crhm has been discussed by krogh et al 2017 and krogh et al 2015 and involves creating continuous hourly fields of temperature humidity wind speed shortwave irradiance and either hourly or daily precipitation these data were distributed to the basin using algorithms and macros in crhm pomeroy et al 2007 crhm s observation module adjusted temperature and precipitation with elevation of each hru based on monthly lapse rates the radiation module distributed global radiation to hrus based on latitude elevation ground slope and azimuth incoming longwave radiation was distributed in crhm based on air temperature humidity and the hru terrain view factor wind speed acceleration and deceleration due to flow over complex terrain was adjusted using the walmsley s parametric boundary layer wind flow module in crhm walmsley et al 1989 details of these modules are provided by fang et al 2013 the model input data files were prepared using several r packages crhmr shook 2016a for pre processing meteorological station forcing data post processing and analysing model outputs mscr shook 2015 for pre processing archived data from environment and climate change canada and reanalysis shook 2016b for pre processing and interpolating atmospheric model reanalysis data 3 crhm glacier glacier snow and ice energy and mass budgets and meltwater routing processes were incorporated into crhm to create crhm glacier a model suitable for alpine glacierized basins these modules are linked in a sequential manner to simulate hydrological processes for a glacierized basin following the flow diagram shown in fig 3 the most relevant modules for an alpine glacier dominated basin are described in the following subsections along with the new glacier module this section also details the development of the distributed physically based numerical model to simulate glacier mass and energy fluxes 3 1 snow redistribution and sublimation many mountain glacier models neglect blowing snow and sublimation despite the prominence of these processes at high altitudes e g naz et al 2014 shea et al 2015 and demonstration of improvements in model performance when these processes are included in alpine simulations fang et al 2013 snow redistribution by both wind and avalanches is important on mountain glaciers due to high wind speeds and steep topography redistribution of snow significantly alters the mass balance and thus melting processes wayand et al 2018 the blowing snow module pomeroy 1989 pomeroy and li 2000 calculates hru snow erosion and deposition as a mass balance of horizontal snow transport via saltation and suspension and in transit sublimation using precipitation wind speed air temperature and relative humidity as well as information on the snowpack horizontal blowing snow redistribution by wind from one hru to another is determined by exposed surface roughness and therefore snow depth and surface characteristics three factors are needed for a blowing snow event to occur wind at a speed greater than the threshold condition an open snow surface with good exposure to wind and supply of erodible snow snow is eroded from wind exposed hrus and deposited as drifts in topographically sheltered or well vegetated hrus the details of the blowing snow model in crhm are provided in pomeroy et al 1993 and application of the model over a mountain region is detailed in macdonald et al 2009 in addition to blowing snow snow is redistributed by gravity in avalanches from higher to lower elevations on steep slopes described by an avalanche module named as sweslope in crhm based on the algorithm developed by bernhardt and schulz 2010 snow slides in an avalanche if the minimum snow holding depth hd and a minimum slope angle sm are exceeded they suggested values of hd and sm are 50 mm w e water equivalent and 25 surface slope respectively for slopes steeper than sm the snow holding depth decreases exponentially a best fit regression line equation 1 was derived from the curve of hd m and sm 0 as developed by bernhardt and schulz 2010 and used in the avalanche module 1 h d 3178 4 s m 2 3 2 energy balance the energy available for snow firn and ice melt qm w m 2 is the sum of fluxes due to radiation turbulence advection and conduction pomeroy et al 1998a pomeroy et al 1998b 2 q m q n q h q e q p q g d u d t where du dt is the change in internal energy of the snow ice qm is the energy available for melt qp is the advection energy from precipitation qg is the heat flux due to conduction qe and qh are turbulent fluxes of latent heat and sensible heat respectively and qn is the net radiation expressed as 3 q n k i n k o u t l i n l o u t 1 α k i n l i n ε σ t s 4 where k i n and k o u t are incoming and outgoing shortwave radiations l i n and l o u t are incoming and outgoing longwave radiations all these energy components have units of w m 2 ts is the surface temperature in kelvin and ε is the emissivity of the surface the available energy for melt qm can be converted to a melt rate m m s 1 as 4 m q m ρ w l f where ρ w is the density of water and l f is the latent heat of water fusion at the freezing temperature energy balance glacier melt modelling in crhm glacier consists of two separate melt algorithms giving distinct calculations for snow and firn ice surfaces the energy and mass balance snowmelt model snobal marks et al 1999 marks et al 1998 is used in modelling snow melt processes it simulates the energy and mass balances of snowpacks in mountains over glacier and non glacier surfaces internal energy exchange is calculated by tracking the cold content in two layers a surface shallow active layer and b lower deep snowpack the model solves for temperature and specific mass kg m 2 which is the product of snow depth and snow density accumulated energy is the energy available after satisfying the cold content and runoff of accumulated melt and liquid content exceeding a specified threshold the turbulent heat fluxes are obtained using an approach adopted from brutsaert 1982 by marks and dozier 1992 details are in marks et al 1998 a single layer daily time step energy budget melt model originally developed by gray and landine 1988 for shallow prairie snowpacks was customized to ice and firn melt by adjusting its albedo routine and assuming glacier ice and firn are isothermal so all internal energy change goes to ice melt or firn melt the radiation module in crhm simulates incoming shortwave global radiation adjusted to slope and aspect similarly in the absence of observations longwave irradiance can be estimated from shortwave transmittance and air temperature using the algorithm proposed by sicart et al 2006 that modified brutsaert s clear sky longwave algorithm for cloudy conditions terrain emission of longwave is also included in the sicart s model the influence of longwave irradiance from surrounding terrain can be significant in mountains plüss and ohmura 1997 the albedo module of snow evolution by verseghy 1991 adopted by essery and etchevers 2004 based on the age depth density and temperature of the snow layer is used to simulate the snow surface albedo 3 3 mass balance crhm glacier simulates the mass balance of snow firn ice water equivalents for glaciers as the following variables snow water equivalent swe mm firn water equivalent fwe mm and ice water equivalent iwe mm the mass balance of a glacier mb mm also referred to as the mass budget is expressed in flux terms as 5 d m b d t d s w e d t d f w e d t d i w e d t where the three terms in the right hand side are expressed as 6 d s w e dt d p snow dt d h i n s n o w dt d h o u t s n o w dt ds snow dt d m s n o w d t 7 d f w e dt v i n s n o w t o f i r n dt d v o u t f i r n t o i c e dt d s f i r n dt d m f i r n dt and 8 d i w e dt d v i n f i r n t o i c e dt d s ice dt d m ice dt swe fwe and iwe are the water equivalents of snow firn and ice respectively mass balances are typically calculated annually but fluxes of swe fwe and iwe need higher spatial and temporal resolution in their determination psnow is the amount of precipitation to the snowpack hin snow and hout snow are horizontal incoming and outgoing mass flows of snow due to blowing snow and avalanches whereas vin snow to firn and vout firn to ice are vertical incoming and outgoing mass flows due to firnification and firn conversion to ice ssnow sfirn sice are the mass losses by sublimation and msnow mfirn and mice are losses by melting from snow firn and ice respectively the units for these variables are mm p hin vin represent input fluxes and hout vout s m represent outputs many models do not consider firn separately e g li et al 2015 naz et al 2014 however firn has properties that are significant to glacier energetics and mass balance the albedo of firn is lower than that of snow but it is higher than that of ice secondly it is important for meltwater routing which is slower in firn than in ice hannah and gurnell 2001 thirdly the model adds the water equivalents of snow firn and ice to simulate changes in glacier surface elevation glacier surface elevation change δe at each time step of the model typically daily can be obtained as 9 δ e δ s w e ρ s δ f w e ρ f δ i w e ρ i ρ w here ρ s ρ f ρ i and ρ w are densities of snow firn ice and water respectively the densities are modelled through densification of multilayer snow pomeroy et al 1998a pomeroy et al 1998b and firn herron and langway 1980 δ s w e δ f w e and δ i w e are changes in water equivalents of snow firn and ice respectively crhm simulates the change in glacier surface elevation by considering snow redistribution and accumulation snow conversion to firn firn conversion to ice and ablation of snow firn and ice firn is snow that has survived at least for one summer melt season anderson and benson 1963 firn densification is calculated in three temporal stages adopted from semi empirical steady state approaches initially the top layer snowpack undergoes densification due to wind redistribution and compression as described by pomeroy et al 1998a pomeroy et al 1998b then firn undergoes densification at a rate that is linearly related to the pressure of overlying snow and firn layers herron and langway 1980 proposed two stages of densification from surface to the zone of pore close off 830 kg m 3 the initial rate of densification is faster and occurs until the density reaches 550 kg m 3 considered the critical density and the latter rate is slower and proceeds from the critical density to 830 kg m 3 from which the firn is considered to have become ice these firn densification stages are modeled in a 10 layer firn system and one ice layer updated annually at the end of summer fig 4 shows the schematic representation of snow firn and ice layers transitioning from winter to summer 3 4 water flow modules crhm assembles hydrological models from a library of physically based hydrological and energy balance process modules the crhm glacier model considers delayed interflow through snow firn ice and subsurface as well as groundwater flow using lag and storage hydrograph translation parameters the concept of linear storage routing has been used in several glacio hydrological studies e g engelhardt et al 2014 hannah and gurnell 2001 huss et al 2008 magnusson et al 2011 oerter et al 1981 jansson et al 2003 de woul et al 2006 proposed variable snow and ice reservoirs whilst keeping the firn reservoir constant they considered snow covered firn to be part of the firn reservoir however if ice was covered by snow they considered a distinctive snow reservoir in their model in crhm glacier meltwater is therefore routed from one hru to the other until it reaches the outlet by means of three storage constants ice firn and snow once the meltwater and rain reach the ground surface the three modules infiltration hillslope and routing estimate their storage and flow through three different strata surface subsurface and groundwater the model considers delayed interflow through snow firn ice and subsurface and groundwater flows using lag and storage parameters which can be determined using values from the literature or estimated using flow timing measurements or by calibration to fit the streamflow hydrograph either the muskingum streamflow routing module chow 1959 or clark s lag and route runoff routing module clark 1945 can be chosen in crhm for routing runoff to streamflow infiltrated water is calculated by a hillslope soil module by fang et al 2013 based on the soil module by leavesley et al 1983 which was progressively modified by dornes et al 2008 for cold regions mountain soils and fang et al 2010 for depressional storage and fang et al 2013 for mountain hillslopes the hillslope soil module deals with depression storage subsurface runoff groundwater recharge and groundwater flows between hrus water moisture loss from unsaturated or saturated non frozen surfaces by evaporation and transpiration is estimated using granger gray s evapotranspiration expression granger and gray 1989 granger and pomeroy 1997 which employs an energy budget and an extension of penman s combination equation using the complementary evaporation hypothesis evaporation from open water bodies is simulated by the energy budget evaporation expression for small water bodies and wetlands developed by priestley and taylor 1972 3 5 hydrological response units hrus the basins were discretized into hru based on slope aspect elevation and landcover including glacier cover the hru are control volumes used to apply meteorological forcing data and are the basis for coupled mass and energy budgets by the process modules google earth engine and arcmap were used to prepare hrus for both basins the steps in the flowchart shown in fig 5 example for pgrb were followed for the two research basins pgrb fig 6 and agrb fig 7 two landcovers 2014 and 1966 in the case of pgrb and 1984 and 2014 in the case of agrb were used since the gauging sites were at different locations during the ihd period and the present time two separate basin maps were prepared for pgrb the catchment area at the new gauging site is about 4 km2 smaller than at the old gauging site except for the 1966 landcover map of pgrb landsat images taken between 15th july to 15th september were considered as this time of year when the seasonal snowpack has melted the pgrb landcover map for 1966 was prepared from the scanned topographic map of 1966 four landcover classes were considered accumulation area firn snow ablation area ice non glacierized area bare and water the following steps were considered whilst preparing hru 1 landcover maps from two periods were prepared from landsat images and a topographic map for agrb 1984 and 2014 and for pgrb 1966 and 2014 were considered 2 dem derivatives slope aspect and elevation bands were created from 2000 dem agrb and 1966 dem pgrb using the arcmap spatial analyst tool 3 slope was reclassified to 3 classes 0 15 15 45 and 45 aspect was reclassified to north and south and elevation was classified in bands at every 100 m the classes were converted to polygons using a raster to polygon tool 4 landcovers from two dates slope aspect and elevation bands were intersected with each other using the union function 5 the created feature had many smaller polygons which were simplified using the eliminate function the smaller polygons with area below 25000 m2 were dissolved to polygon with the largest border it shared with 6 if the polygons fell under bare area on both years 1984 and 2014 for agrb and 1966 and 2014 for pgrb the polygons were merged to adjacent polygons making elevation bands cut at every 200 m 7 all the polygons were carefully analyzed based on topology and merged to one another reducing the number of hru s to 90 for agrb fig 6 and 70 for pgrb peyto old outlet the number of hru s were reduced to 65 for pgrb with peyto new outlet fig 7 8 hru numbering was done based on flow direction patterns where water flows from smaller hru number to higher hru number finally towards the outlets of the basins hru 90 is the outlet of agrb hru 70 is the peyto old outlet and hru 65 is the peyto new outlet the physiographic parameters required by crhm glacier for each hru include the following area latitude average elevation average ground slope average aspect and average terrain view factor tvf except for tvf all parameters were calculated in r for each available dem tvf was obtained in saga gis as a sub product of the sky view factor under the terrain analysis the major landcover of each hru in a year was calculated using zonal statistics with table the majority of landcovers from 1966 and 2014 in the case of pgrb and those from 1984 and 2014 in the case of agrb were calculated by using the raster iterator operator in a model builder of arcgis 10 3 1 3 6 testing model performance model simulations were compared with the available hydrometeorological and glaciological observations at the two basins agrb and pgrb to evaluate the crhm glacier model the model was compared with the in situ measurements of albedo surface accumulation and ablation and streamflow discharge generation incoming and outgoing shortwave radiation measured by aws on glacier ice and moraine provided observed albedo measured daily albedo was obtained as a ratio of the daily amount of outgoing shortwave radiation to the daily amount of incoming shortwave radiation oerlemans and knap 1998 daily observed and simulated albedo values were compared for the four sites for five years or more except peyto glacier lower ice aws which had both incoming and outgoing shortwave radiation measurements during 2007 2008 only modelled surface accumulation and ablation processes over the glacier were compared with surface height changes fig 8 that were measured by sr50 ultrasonic depth sounders at the three ice stations in pgrb the advantage of comparing surface elevation change over comparing water equivalent change is that the former provides an additional comparison of density simulation in the model garen and marks 2005 this process also validates the surface elevation change modelled by the accumulation and ablation process at the surface crhm parameters were set by knowledge and understanding of the basin instead of optimizing to simulate the streamflow hydrograph though parameter calibration is sometimes inevitable it can be reduced with advancements in hydrological science pomeroy et al 2013 ommanney 2002 summarized the studies made by derikx 1975 and collins 1982 who found that the meltwater reaches the outlet of pgrb at a very short time from 2 to 5 h munro 2011a and munro 2013 also considered the runoff delay in pgrb and found it varied from a few hours to half a day given the daily time step of discharge no parameters whatsoever were calibrated in this study the model simulated discharges of the two basins for two different time slices were compared with observations over daily periods for the present 2014 2019 for agrb 2013 2018 for pgrb and past datasets 1967 1977 and 1980 1989 for agrb 1967 1977 for pgrb crhm glacier considered redistribution of accumulated snow by two processes blowing snow and avalanching blowing snow includes the effect of blowing snow transport redistribution and sublimation losses avalanching is dependent upon blowing snow transport to redistribute snow to form deep accumulations in avalanche source areas the effects on model performance of adding blowing snow and avalanching were investigated using model falsification with and without these processes by comparing the model outputs to the observations similarly the test runs were carried out to diagnose the impacts of glacier processes on the model model falsification is straightforward to implement in crhm the blowing snow avalanche and glacier modules in crhm can be turned on and off so that outputs could be compared for example models could be built with and without the blowing snow module first the model was tested for glacier surface elevation changes on peyto glacier at three observational sites second it was tested for streamflow simulations from the two basins agrb for 2014 2019 and pgrb 2013 2018 with forcing meteorological data from bias corrected era interim and in situ observed data the following three model scenarios were considered with a model falsification approach to examine the impacts of glacier and snow redistribution processes on streamflow and glacier surface calculations 1 with both glacier and snow redistribution processes 2 with glacier but without snow redistribution processes 3 with snow redistribution but without glacier processes based on these three experimental scenarios three comparison tests were employed to evaluate the glacier and snow redistribution modules agreement between simulated and observed values was evaluated by using both traditional and non traditional statistical indices nash sutcliffe efficiency nse nash and sutcliffe 1970 mean bias error mbe and the root mean square error rsme were used along with the wang bovik index wbi proposed by wang and bovik 2002 and reformulated by mo et al 2014 for application to hydrometeorological data wbi evaluates the similarities between modelled and observed variables in terms of pattern association and differences in the means and variances mo et al 2014 10 wbi m xy v xy r xy where the three components are defined as 11 m xy 2 x ψ xy y ψ xy x ψ xy 2 y ψ xy 2 12 v xy 2 σ x σ y σ x 2 σ y 2 13 r xy σ xy σ x σ y where ψ xy min xi yi i 1 2 3 n here xi and yi are measured and predicted daily global solar radiation respectively at i day x and y are means σ x and σ y are standard deviations and σ xy is covariance m xy and v xy are the measures of differences in means and variances respectively r xy is the pearson correlation coefficient all statistical analyses were carried out in r r core team 2017 in the rstudio platform rstudio 2017 the code for wbi was provided by paul whitfield university of saskatchewan centre for hydrology and environment and climate change canada and the other codes were used from the r packages hydrogof mauricio 2014 and sirad bojanowski 2016 the analysis results are presented in graphs and tables performance rating based on the values of nse was considered as very good nse 0 65 adequate 0 65 nse 0 54 and satisfactory 0 54 nse 0 50 following dahal et al 2020 4 results and discussion unlike other glacier hydrological models the model parameters in crhm glacier are not calibrated and so there are no calibration and validation periods to compare the model results are presented in the following subsections 4 1 model evaluation the model was tested against observations of meteorological variables albedo mass balance and discharge model performance was evaluated by means of visual as well as statistical interpretations 4 1 1 albedo net shortwave radiation is the most important energy flux for glacier melt munro and young 1982 therefore accurate parameterization and modelling of surface albedo are crucial for computing the energy and mass balance of the glaciers the model was evaluated using recent measurements of surface albedo at four locations two sites in pgrb peyto main and peyto lower ice stations and two sites in agrb athabasca moraine and athabasca ice stations the crhm glacier albedo module was used to simulate albedo on glacier ice and off glacier surfaces over both basins the meteorological forcing data for these tests were from athabasca moraine station for agrb and peyto main station except precipitation data for pgrb precipitation data for pgrb were from bow summit the comparisons were made at daily values with point aws measurements fig 9 and their statistical measures for model performance are presented in table 4 the model captured the variation of albedo on both on ice and off ice sites with wbi higher than 0 85 rmse less than 0 17 and the highest mbe being 0 063 though these point observations do not represent all basin areas they represent both snow accumulation and ablation conditions since a single value of albedo was used for snow free conditions the variation of albedo during ice melt was not represented however transitions of albedo from snow covered to snow free and vice versa were well captured at both on ice and off ice sites fig 9 both glacier and moraine sites presented cycles of snow covered and snow free times with albedo values reaching 0 9 and 0 3 in the case of ice surfaces and 0 15 at moraines the ice exposed periods with lower albedo values were well simulated by the model the modelled albedo decay over the athabasca moraine station was slower than the observed values and mid winter albedo values were overestimated due to wind erosion of snow and exposed boulders and microtopography at this site the albedo of athabasca ice during snow free periods in the recent years 2017 2019 was lower 0 25 than the previous years fig 9a and may be influenced by upwind forest fires bertoncini et al in review 4 1 2 glacier mass balance the surface accumulation and ablation simulations from crhm glacier were tested with the surface mass balance measurements by mass balance stakes and ultrasonic sensors sr50 installed at various points over peyto glacier 4 1 2 1 surface point mass balance fig 10 shows the time series of simulated and observed changes in the elevation of the glacier surface with respect to the sr50 sensors during the recent decade the model was run from october 2010 to september 2019 with meteorological forcing data from both in situ observation at peyto main station air temperature relative humidity wind speed incoming short and long wave radiation and bow summit precipitation and bias corrected era interim the comparisons were limited to the periods when sr50 data were available performance of the model along with meteorological forcing data were evaluated by statistical parameters presented in table 5 all the sites had at least one continuous dataset for two years showing the model s capability to capture accumulation and ablation the best match between simulated and observed surface heights was at the lower ice station and performance diminished with elevation the model accumulated more mass during the two year period than the measured mass balance at the upper ice station mbe 0 26 m with the measured model forcing data from the peyto main however the accumulation was less when the model was forced with era interim data table 5 4 1 2 2 aggregated glacier mass balance model simulated hourly daily mass balance for peyto glacier was converted to seasonal and annual mass balances to compare with the measured values obtained from the ablation stakes fig 6 the simulated seasonal glacier mass balances exclude dragan glacier and other small ice patches in the northeast part of the basin for the period from 1965 to 1995 fig 11 shows that the model did not simulate the aggregated seasonal mass balance as well as it simulated point mass balances as presented in section 4 1 2 1 several factors could have contributed to the reduced performance at the glacier scale firstly none of the model parameters were calibrated to simulate mass balance although there is a practice of calibrating mass balance against in situ observations e g giesen and oerlemans 2012 radić and hock 2011 shannon et al 2019 secondly the model performed less well at the upper ice station compared to the middle ice and lower ice stations fig 10 another reason could be the difference in approaches to obtain the seasonal mass balance the observed values of seasonal mass balance were obtained from a series of transects of ablation stakes distributed over half of the glacier area at lower elevations fig 6 and these values were linearly extrapolated to higher elevation bands as there were not any mass balance stake measurements above 2700 m details are in demuth and keller 2006 the modelled seasonal mass balance was calculated from the hrus distributed over the glacier differences between the mass balance extrapolations and various model distributions of forcing meteorology with elevation could explain why the mass balances simulated at lower elevation bands matched closer to the observations not shown here than did those simulated at higher elevation bands 4 1 3 streamflow model performance metrics for both basins are provided in table 6 and from figs 12 to 15 the performance of the model can be rated as very good with nse equal to 0 71 and 0 77 for agrb for the period 2014 2019 with meteorological forcing data from in situ observation and from era interim respectively the model performance of agrb with era 40 forcing data was also very good for the past records 1967 1977 nse 0 75 and 1980 1989 nse 0 73 the model performance for pgrb was very good with nse equal to 0 68 and 0 67 with meteorological forcing data from in situ observation and from era interim respectively wbi values were 0 86 and 0 87 for agrb and 0 80 for pgrb however pgrb had smaller mbe values 0 06 and 0 01 m3s 1 and lower rmse values 1 19 and 1 2 m3s 1 than agrb mbe 0 28 and 0 11 m3s 1 rmse 1 29 and 1 14 m3s 1 figs 13 15 the model also performed well for the past records with bias corrected era 40 nse values of agrb were 0 75 and 0 73 and wbi were 0 89 and 0 87 for the periods 1967 1977 and 1980 1989 respectively the nse value of pgrb 1967 1977 was 0 61 with the bias corrected era 40 the model was also tested with lake louise precipitation data for pgrb 1967 1977 the model driven by era 40 data provided a better simulation than that driven by era 40 with lake louise precipitation data table 6 generally the model simulated streamflow well with wbi values higher than 0 8 except for pgrb in the past 1967 1977 when the wbi was 0 76 wbi evaluates similarity in modelled and simulated values in terms of not only correlation but also mean and variance mo et al 2014 the model performed better in agrb compared to pgrb moreover the streamflow simulations were better in the present period compared to the past for pgrb this could be due to the uncertain quality of streamflow data at pgrb in the past flow measurement at the peyto outlet during the ihd 1967 1977 was a challenge due to an unstable cross section occasional flash floods and lack of direct discharge measurements during high flows goodison 1972 reported that the discharge records from 1967 were not reliable and he did not use this data for his study the streamflow stage gauge was washed out during a flood in august 1967 occasional flash floods were reported in the stream by ommanney 1987 and johnson and power 1985 however model performance statistics show a good ability to simulate streamflow both in the past and present time periods from the bias corrected reanalysis data for both basins the test runs were also carried out to see the impacts of glacier and snow redistribution processes using a model falsification approach fang et al 2013 the model was run three times first with both glacier and snow redistribution processes the second run was with the glacier but without snow redistribution processes and the third one was with snow redistribution but without the glacier fig 16 compares the observed and simulated streamflow hydrographs for agrb averaged over the model run period of 2014 2019 streamflow simulations without the glacier generated about 50 of the observed flow and indicated the strong influence of glaciation on streamflow the differences between observed and simulated streamflow without the glacier were highest during july august fig 17 compares these simulations with the observed streamflow at the peyto glacier outlet similar to athabasca hydrological simulations without the glacier in pgrb also generated almost half the streamflow compared to the observed streamflow simulations without snow redistribution overestimated streamflow showing the need to include blowing snow transport and sublimation calculations in glacier hydrological simulations the agreement between simulated and observed runoff was closer in pgrb than in agrb this is likely due to the precipitation data used for pgrb this was observed at the bow summit station which is a well sheltered precipitation gauge whereas the precipitation gauge in agrb is at wind blown open site where uncertainty due to wind undercatch corrections is introduced moreover the precipitation and temperature lapse rates were determined from observed precipitation at different elevations at pgrb and these values were transferred to agrb adding uncertainty in the regionalization of these rates 4 2 sources of runoff and changes over time the crhm glacier model was used to determine various spatially integrated mass fluxes and their changes over a period of five decades simulated spatially integrated mass fluxes are shown in fig 18 their values are given in table 7 this shows the importance of glacier firn and ice melt 38 50 to total runoff streamflow discharge though snow melt was still the largest runoff component the contribution of glacier melt increased by 6 7 in the recent decade 2006 2017 compared to the past 1966 1977 total precipitation decreased in both basins however the rainfall ratio increased as did basin flow annual discharge this was caused by an increase in glacier ice melt that was tempered by a decrease in snow melt the combination of increasing rainfall decreasing snow melt increasing ice melt led to increasing basin flow and showed a hydrological regime change under way importantly the increase in rainfall and ice melt more than compensated for decreasing snow melt in their impact on basin flow 5 discussion most mountain glaciers lack on ice weather data clarke et al 2009 the result of crhm glacier over peyto and athabasca glaciers is encouraging in that both off ice station and atmospheric model reanalysis data have very good potential for use in driving glacier hydrological models of mountain glaciers in remote regions the simulated streamflow hydrographs without the glacier generated about half of the total observed flow in both basins the differences in these flow values increased to approximately an order of magnitude larger than modelled flows without the glacier by late summer when ice melt is large and snow melt is depleted these test runs showed that the streamflow from these basins would be reduced dramatically and catastrophically under the current climate with complete deglaciation snow redistribution processes by wind and avalanches reduced streamflow the simulation with the glacier and addition of the redistribution processes reduced the differences between the simulated and observed streamflows and were important to include the shifting importance of glacio hydrological processes from the ihd period to the present is instructive the increase in rainfall and decrease in snowmelt can be attributed to the increasing rainfall ratio and its effects on both rainfall occurrence and snow accumulation and melt the declining snowcover over the glaciers increased the ice exposure and hence the ice melt as there was a greater ice surface exposed to melt energy this is consistent with the rise in the ela that is noticeable from the ihd to present period in photographs of peyto glacier and the authors photographs of athabasca glacier from the 1970 s to present the more negative mass balance and shrinkage of both glaciers is the cause of the 260 mm peyto to 88 mm athabasca increase in streamflow runoff when precipitation has declined by 226 mm peyto and 115 mm athabasca since the 1960 s though the model performed well in most tested metrics there are some limitations that could be improved in future studies crhm glacier was constrained by the forcing of meteorology and the suite of processes that were included in the model several uncertainties in the input data drove the uncertainties in model outputs precipitation is critical for crhm glacier precipitation measurements at the moraine stations in the study basins were not reliable due to very high wind speeds for which available undercatch equations are unreliable therefore precipitation measured at bow summit a small wind sheltered forest clearing outside pgrb was used to evaluate model performance and to bias correct reanalysis data no similar sheltered precipitation gauge was available for agrb the temperature and precipitation lapse rates were set by observations made at different elevations and so errors in these observations propagated into lapse rate estimation another important meteorological variable is shortwave irradiance the model corrects irradiance due to self shading for each hru using slope and aspect to spatially distribute shortwave and longwave irradiance however it does not consider shadowing from surrounding topography consideration of which may improve melt calculations in mountains as shown by marsh et al 2012 and hopkinson et al 2010 in this region moreover there are potential errors in global radiation measurement average global radiation was measured with a kipp and zonen cm 11 pyranometer and a cnr 4 in the main stations snow accumulation and frost on the pyranometer dome certainly occurred at times similarly several processes such as ice flow glacier surges melt of ice cored moraine ice falls ice calving into the downstream glacial lakes evolution of vegetation cover at the lower elevation of the basin and evolution of drainage patterns were not considered in the model and its operation here debris covered ice is becoming more common in canadian mountain glaciers particularly at the terminus currently these areas are not treated distinctively apart from assigning low albedo values the debris cover may alter the surface energy balance due to the low thermal conductivity of debris vincent et al 2016 the model also did not consider short term impacts of meltwater refreezing to form superimposed ice on the glacier naz et al 2014 6 conclusions crhm glacier a new physically based energy budget and mass balance snow redistribution spatially distributed glacier hydrology model was developed and applied to simulate both the glacier mass balance and streamflow of mountain glacierized basins crhm glacier uses coupled mass and energy budgets firnification and snow redistribution by wind and gravity to calculate snow melt firn melt and ice melt separately and it can be used in basins that are glacierized partly glacierized or glacier free including basins undergoing transitional phases from glaciation to deglaciation hydrometeorological streamflow and glaciological observations from the 1960 s to recent times at peyto glacier and new observations at athabasca glacier in the canadian rockies were used to quantify change suggest model development verify model operation and drive models of glacier hydrology change bias corrected reanalysis data and data from off ice stations were used to drive the model and on glacier station observations were used to validate the model when driven with locally measured off ice meteorological data or bias corrected reanalysis data and tested against specialized on ice snow and ice surface height measurements the model was able to simulate both accumulation and ablation of snow and ice quite well the model was also able to simulate albedo and streamflow well without calibration of any parameters from observations model predictions of streamflow improved when processes describing snow redistribution by wind and gravity were included in the model and model falsification showed that hydrological modelling must include a glacier component including firnification in order to successfully simulate the hydrology of glacierized basins the validated model was used to simulate water balance and runoff components of both study basins for two time periods past 1966 1977 and present 2006 2017 there was an increase in streamflow in the more recent period despite a marked decrease in precipitation and snow melt this is due to increased glacier ice melt which has become a larger runoff component during late summer the increase in streamflow despite declining precipitation from these glaciers is a symptom of deglaciation and increased glacier ice melt since the 1960 s and is not sustainable into the future as these glaciers will disappear due to their persistently negative mass balances the physical basis of this model and determination of physically identifiable model parameters from observations can reduce uncertainty in long term simulations especially those for future climates where calibrated parameters may no longer apply author contributions dp and jwp conceptualized the research dp built the model and tested it at the research basins and prepared the manuscript jwp contributed to model and methodology development instrumented the glaciers and contributed to and revised the manuscript credit authorship contribution statement dhiraj pradhananga conceptualization formal analysis investigation software writing original draft john w pomeroy conceptualization data curation funding acquisition software supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors wish to acknowledge the decades of extremely challenging field research at peyto and athabasca glacier basins by dozens of scientists and students meriting special mention are dr d scott munro retired of the university of toronto and michael n demuth retired of natural resources canada whose legacy of research on peyto glacier including meteorological and mass balance observations made this study possible special mention also goes to the prescient scientists of the international hydrological decade who established peyto glacier as a research site including dr gordon young of environment canada and wilfrid laurier university additional data was provided by environment and climate change canada s meteorological service of canada and water survey of canada parks canada and alberta environment and parks tom brown and xing fang of the centre for hydrology supported crhm development and operation parameterization respectively nammy hang kirat of the small earth nepal supported gis map production funding for this study was provided by the canada research chairs canada foundation for innovation natural sciences and engineering research council of canada through its discovery grants and the changing cold regions network alberta innovation and the canada first research excellence fund s global water futures programme special thanks go to the two anonymous reviewers for their careful and critical review of the manuscript and their several insightful comments and constructive suggestions which helped to improve the manuscript 
3458,scale dependent and independent error and performance measures are used to evaluate hydrologic forecasting and simulation models however these single valued measures may not always provide a comprehensive assessment of model performance developed for a specific hydrologic process and application a new frequency based performance measure fbpm that can incorporate application specific information for model evaluation is proposed to address the limitations of existing measures fbpm is derived using a data classification scheme to partition the observed data into several classes and evaluate frequencies of each class s chronologically paired observed and forecasted values a variant of fbpm composite performance measure cpm is also developed to include additional indices that evaluate error variance and other statistical characteristics of the observed and forecasted series several univariate and multivariate data classification schemes are initially evaluated and the best one is selected for use in the measures fbpm and cpm are used to assess the performance of daily streamflow forecasting models developed for the tapi river india using a data driven model tree mt approach the measures are also evaluated using two synthetic datasets representing different model forecast scenarios a comprehensive evaluation of streamflow forecasts using fbpm and cpm with the best data classification scheme i e geometricinterval schemein this work indicates a better and more robust assessment of the forecasting model performance than that from existing error and performance measures the traditional measures such as coefficient of determination index of agreement nash sutcliffe and kling gupta efficiency have overestimated model performances compared to fbpm and cpm on an average by at least 100 the traditional measures have also failed to identify inferior models mainly due to their inflated numerical values compared to those from fbpm and cpm the measures developed in this study allow the user specific definition of classesandassignment of weightstothese classes based on the intended purpose of the hydrologic modeling effort the fbpm and cpm are scale independent informative interpretable andoutlier resistant these measures can be used for visual and or statistical evaluation of the performance ofsingleor multiple hydrologic simulation models keywords frequency based performance measure data classification error and performance measures model evaluation synthetic datasets model tree composite performance measure 1 introduction calibration and validation are two essential tasks that need to be carried out to develop and evaluate hydrologic simulation models evaluation of models during calibration and validation phases using various statistical error and performance measures are documented in several studies asce 1993 chen et al 2017 dawson et al 2007 gupta et al 1998 hwang et al 2012 karran et al 2014 nash and sutcliffe 1970 moriasi et al 2007 2015 shamseldin 1997 simonovic and todini 1994 sorooshian and gupta 1995 teegavarapu and elshorbagy 2005 teegavarapu et al 2017 fu et al 2020 often visual evaluation of the observed and predicted or forecasted values of the hydrologic variables is used to support the model selection and assessment tasks for different applications one of the major limitations of single valued numerical error or performance measures is the lack of a model s ability to characterize the system behavior and predict the magnitudes e g extremes and average values of the variables that are of interest under all hydrologic system specific conditions a robust hydrologic simulation model developed for streamflow prediction is expected to provide accurate forecasts under normal and extreme flow conditions i e floods and droughts in general a single valued performance measure provides the overall performance usually with respect to a benchmark but fails to provide a complete assessment of the model performance across all streamflow regimes 1 1 measures for model performance evaluation forecast verification measures offer several single valued aggregate numerical error and performance or efficiency measures or criteria to evaluate models in general any hydrologic model evaluation is carried out through time and signature domain metrics the time domain evaluation involves error and performance measures which can be broadly classified as scale dependent scale independent percentage based relative based and efficiency measures the scale dependent error measures usually represent the errors in the same or squared unit of the variable in question these include mean error me mean absolute error mae absolute maximum error ame mean squared error mse root mean squared error rmse fourth root of the mean quadrupled error r4ms4e mean squared logarithmic error msle mean squared derivative error msde peak difference pdiff dawson et al 2007 fuzzy mean squared error fmse teegavarapu and elshorbagy 2005 and few others the scale dependent measures such as mse rmse msle and msde are found to weigh more heavily on large errors because of the squared deviations thus rendering them unsuitable for comparison of model performances across different watersheds which represent distinct hydrologic dynamics in terms of streamflow magnitudes and variability althoff and rodrigues 2021 the scale independent measures normalize the error statistic into a non dimensional form for better comparison among different models these measures include fractional standard error fse karran et al 2014 rmse to standard deviation ratio rsr moriasi et al 2015 and inertia root mean squared error irmse dawson et al 2007 the scale dependent measures are influenced by outliers and sensitive to the simulated higher magnitude errors in contrast the scale independent measures are not appropriate for model prediction over a large range relative absolute error rae overcomes the drawbacks associated with the above error measures viz sensitivity to the outliers and difficulty in their interpretation armstrong and collopy 1992 the error measures are also expressed in terms of percentage difference such as mean absolute percentage error mape median absolute percentage error mdape armstrong and collopy 1992 percent error in peak pep dawson et al 2007 and runoff coefficient error rr yilmaz et al 2008 the relative based measures also enable the comparison of a model s performance to that of a benchmark model the mean relative error mre relative absolute error rae relative volume error rve or percentage bias pbias mean absolute relative error mare mean relative absolute error mrae the geometric mean of relative absolute error gmrae armstrong and collopy 1992 dawson et al 2007 are amongst the relative based error measures chen et al 2017 introduced variants of relative accuracy measures such as bounded rae brae mean brae mbrae and unscaled mbrae umbrae which had several advantages over the preceding error measures in terms of being informative resistant to outliers symmetric scale independent and interpretable the percentage based and few relative based measures in some situations result in infinite or undefined numerical metrics error measures relevant to hydrologic model evaluation include nash sutcliffe efficiency nse criterion nash and sutcliffe 1970 garrick et al 1978 kling gupta efficiency kge gupta et al 2009 volumetric efficiency ve criss and winston 2008 persistence index pi kitanidis and bras 1980 relative correlation coefficient rcc hwang et al 2012 probability of detection pod and false alarm rate fa karran et al 2014 and onyutha efficiency onyutha 2021 some of these measures may provide redundant information when used without consideration of their limitations for instance the nse evaluates the squared difference between the observed and forecasted values wherein the larger values are highly overestimated whereas the smaller values are often neglected legates and mccabe 1999 nse is significantly influenced by the outliers time offset and magnitude bias mccuen et al 2006 and adopts a relatively weaker benchmark i e mean streamflows to compare the model performance which is not appropriate for river basins depicting high seasonality althoff and rodrigues 2021 efficiency measures generally used for evaluation of model performance include pearson kendall and spearman correlation coefficients index of agreement ioad willmott 1981and coefficient of determination or r squared statistic r2 teegavarapu et al 2017 the r2 and ioad measures are found to be over sensitive to high extreme values and fail to quantify the model bias onyutha 2021 while log nse is sensitive to low flows althoff and rodrigues 2021 some of these measures are not resistant to outliers while few measures adopt a relatively weaker benchmark clark et al 2021 suggested the adoption of a relatively stricter and purpose specific benchmark for an objective evaluation of the strength and weaknesses of a model complete details of the several statistical error and performance measures along with their advantages and limitations are provided in the appendix table a1 the signature based metrics evaluate specific features termed as signatures of the time series rather than the time series itself kavetski et al 2018 for example in the case of a watershed model evaluation these measures can be used to describe the streamflow characteristics and watershed dynamics the commonly adopted signature domain metrics include flow duration curves the spectral density of runoff base flow index interannual runoff variability rising limb density peak distribution and others yilmaz et al 2008 westerberg et al 2011 kavetski et al 2018 these metrics provide a better interpretation of the underlying processes of the system compared to the time domain measures however the modeler needs to consider multiple signatures to effectively characterize the system behavior since a given signature would reflect only a specific aspect of the watershed response euser et al 2013 therefore these measures cannot provide a comprehensive model evaluation as they are adopted to assess specific characteristics of a hydrologic model 1 2 need for new performance measures a comprehensive assessment refers to the evaluation of model performance by analyzing several characteristic features such as variability errors efficiency distribution similarity etc of observed and simulated values across all streamflow regimes single valued numeric error and performance measures reflect the degree of agreement between observed and simulated values however these measures fail to capture all the features reproduced by a hydrologic model in terms of inadequate utilization of the information content of data model capabilities and uncertainty gupta et al 1998 pachepsky et al 2006 mizukami et al 2019 clark et al 2021 and thus fail to provide a comprehensive assessment of the model performance also the performance metrics can substantially affect the quality of the calibrated model simulations mizukami et al 2019 rathinasamy et al 2014 indicated that the traditional performance measures are insufficient as they only provide an overall perception about the performance of the model by comparing two signals in the time and frequency domains separately the single valued performance measures such as nse and kge provide a relative gradation of model performance but they fail to identify the inherent causes for unsatisfactory model performance which could indicate the modeler for improvement of the model schwemmle et al 2021 furthermore the sensitivity of traditional performance measures towards high flows would dominate the global model performance which often masks its poor performance to simulate other flow regimes zhang et al 2011 pfannerstill et al 2014 visual evaluations of results using scatter and time series plots may help identify the limits of the model skill in accurately reproducing the observed behavior of the system these evaluations are subjective and can depend on the skill of the modeler also these evaluations may not always provide an objective assessment of the model performance across the range of values the model estimates or predictions therefore there is always a need for measures for hydrologic model evaluation that can overcome the limitations of existing error and performance measures several studies gupta et al 1998 legates and mccabe 1999 krause et al 2005 moriasi et al 2015 have recommended a multi objective evaluation of the model involving at least one dimensionless criterion one criterion in the same unit of the target variable a combination of different efficiency criteria and absolute or relative volume error estimation one or more single valued numerical measures are ideally suited for the comparative assessment of multiple models teegavarapu et al 2017 considering the limitations of existing single valued measures time domain metrics and signature domain metrics new frequency based performance measures for assessments of the model performance are developed and evaluated in this study the frequency based performance measures involve the use of time matched observed and forecasted instances in each class interval supplemented with additional indices that evaluate error variance the strength of association and distribution similarity between observed and forecasted values by suitably assigning weights to the classes based on the purpose of modeling the frequency based performance measures can be used for performance evaluation of a single hydrologic model or comparative assessments of multiple models the contents of this manuscript are organized as follows the methodology section discusses the need for partitioning of data for the development and implementation of these measures various data partitioning methods and briefly explains the proposed data partitioning based performance measures developed in this study information on the model tree mt data driven technique case study region data sources and the various datasets adopted in the current investigation is provided next the results and analysis section includes a comparison of various data partitioning methods and application of proposed measures to modeled and synthetic hydrologic datasets general remarks discussing advantages and limitations of the frequency based measures and the conclusions are provided next 2 methodology the methodology adopted for the development of frequency based and composite performance measures for the assessment of model predictions is shown in fig 1 the developed measures in this study are used for the evaluation of a data driven streamflow forecasting model 2 1 need for data partitioning the measures developed in this study will help assess the performance of a model based on a particular range of observed values of the variable of interest above or below a specific numerical threshold which could correspond to high medium and low flow conditions to evaluate the model performance and quantify it across different classes or bins of data of the observed values a data partitioning or classification approach is required a manual or user defined classification method that partitions the data into a specific number of classes can be used alternatively an automatic partitioning method that considers the data characteristics and distribution of the values can also be used the number of partitions and class interval widths can be hydrologic model application specific when the manual method is used 2 2 methods for partitioning of data in this study seven partitioning methods are evaluated for data classification which include i equal interval ii k means clustering iii natural breaks iv geometrical interval v quantile vi interquartile range and vii user defined or problem specific breaks except for the k means clustering method a multivariate approach all other schemes are univariate data classification techniques all the partitioning methods require the number of classes to be specified sturge s formula sturges 1926 doane s formula doane 1976 scott s rule scott 1979 freedman diaconis rule freedman and diaconis 1981 variable bin widths kallenberg et al 1985 and bin width optimization shimazaki and shinomoto 2007 can be used to determine the number of classes based on the bin sizes for robust evaluation it must be ensured that the minimum number of values in each bin must be greater than five in at least 80 of the bins and no bin should have an expected value of less than one mchugh 2013 rolke and gongora 2021 in the equal interval method the attribute values are divided into several classes having equal class width de smith et al 2007 this method is best suited for uniformly distributed data since the equal class widths may result in classes with zero observations in the case of nonuniformly distributed datasets k means clustering attempts to partition a multivariate dataset into k distinct non overlapping clusters so that points within a cluster are as close as possible in the multi dimensional space and as far away as possible from points in other clusters de smith et al 2007 the natural breaks algorithm classifies the data based on natural groupings inherent in the data class breaks are created such that similar values are grouped by maximizing the difference between the classes jenks 1967 de smith et al 2007 in this method the features are divided into classes and the boundaries are marked where relatively significant differences in the data values are noticed the geometric interval classification scheme creates class breaks that conform to a geometric series based on class intervals the intervals are selected such that the number of observations in each successive interval increases or decreases exponentially de smith et al 2007 the algorithm creates geometric intervals by minimizing the sum of squares of the number of elements in each class the quantile method divides the range of possible values into unequal sized intervals so that the number of values in each class is similar de smith et al 2007 generally this classification would not result in empty classes or classes with too few or too many values thereby resulting in equiprobable class intervals the interquartile range method proposed in this study is derived by idealizing the boxplot characteristics this method requires information regarding the distribution of the data a priori in this method the classes are defined based on the division of the interquartile range between 25th and 75th percentiles upper quartile greater than 75th percentile and lower quartile smaller than 25th percentile depending upon the distribution of the data for instance if the data is positively negatively skewed the data values in the lower upper quartile would warrant finer discretization compared to the rest of the values apart from these methods user defined or problem specific class intervals can be used for data partitioning for instance the streamflow data can be classified based on the return periods critical levels of flooding in the channel or based on the environmental flow considerations that are specific to a region 2 3 performance measures two frequency based performance measures proposed and developed in this study are described in the following sections 2 3 1 frequency based performance measure fbpm the frequency based performance measure fbpm uses counts or frequency estimates of observed and forecasted values in all the class intervals bins of the observed data derived using a specific univariate or multivariate data classification scheme the observed data is divided into several class intervals n c of equal or unequal widths using a manual or automatic partitioning method in each class interval i or bin the total number of observations o i and time index matched forecasts f i m i e the total number of only those forecast values that are associated with the same time index as with those of observations are obtained the superscript m refers to a chronological match or time match the ratios of these counts f i m o i are weighted and aggregated across all intervals to obtain the fbpm defined by equation 1 the weight w i associated with each class interval needs to be assigned by the user with a condition of i 1 nc w i 1 the ratio for each interval serves as an assessment of the model performance for the range of observed values specified by the interval 1 fbpm i 1 nc w i f i m o i the fbpm benefits from multiple assessments and quantifications of the model performances in different ranges of the observed variable weights defined by the user considering the model application e g for low flow forecasting or flood forecasting are attached to each of these classes 2 3 1 1 composite performance measure cpm a variant of the fbpm is also developed to include additional indices that evaluate error variance and other statistical characteristics of two different time series observed and forecasted for the development of a composite or aggregated performance measure this variant is referred to as a composite performance measure cpm as defined by equation 2 this approach provides flexibility to the user to incorporate remove additional indices in the purview of cpm based on the purpose of modeling the cpm assesses the agreement between time matched forecasted and observed values therefore each index that comprises the cpm is penalized by multiplying the unweighted fbpm for each class interval to account for the time mismatch between the observed and forecasted values 2 cpm i 1 nc w i g j i i j f i m o i the variable i i j refers to index j obtained using on forecasted and observed time series values within the class interval i the function g j refers to a transformation function for each index j that is used to normalize the i i j values between 0 and 1 for ease in comparison across the classes and indices the normalization process adopted for different indices of cpm is discussed at length in section 2 3 2 2 the weight w i associated with each class interval needs to be assigned by the user with a condition of i 1 nc w i 1 five class based indices i i j j 1 5 are aggregated using equation 2 for cpm computation and they are variance index vi interquartile range index iqri correlation index ci the bounded relative absolute error index braei and the kolmogorov smirnov index ksi these indices are derived using equations 3 7 the ksi uses a ks test statistic value to evaluate the similarity of the two probability distributions based on observed and forecasted values in a class 2 3 1 2 indices of cpm the variance index vi is defined by equation 3 the variables s i f and s i o in equation 3 refer to standard deviation obtained using time matched forecasted and observed data respectively in class interval i 3 i i j vi i j s i f 2 s i o 2 i j 1 the interquartile range index iqri is defined by equation 4 the variables iqr i f and iqr i o in equation 4 refer to interquartile range values obtained using time matched forecasted and observed data respectively in class interval i 4 i i j iqri i j iqr i f iqr i o i j 2 the correlation index ci is defined by equation 5 the variables ρ i f and ρ i o in equation 5 refer to the pearson correlation coefficient obtained using time matched forecasted and observed data respectively in class interval i 5 i i j ci i j ρ i f ρ i o i j 3 the bounded relative absolute error index braei is defined by equation 6 in general the relative errors provide more intuitive results than percentage errors chen et al 2017 the variables v i f and v i o refer to time matched forecasted derived from model simulations and observed values respectively and nm i is the total number of matched values in the interval i on the other hand e i f is the simulated value obtained from a one step naïve model i e x t x t 1 which is generally used as a benchmark to compare the model errors the braei would ensure that the maximum error is one while the minimum error is zero when v s i f v s i o is equal to zero also braei is well suited for intermittent demand data which have many zero valued observations chen et al 2017 to avoid the issue of being undefined braei is defined to be 0 5 for the special case when v s i f v s i o and e s i f v s i o are both equal to zero chen et al 2017 6 i i j braei i j 1 nm i s 1 nm i v s i f v s i o v s i f v s i o e s i f v s i o i j 4 the kolmogorov smirnov index ksi is defined by equation 7 the ksi is derived based on a two sample unpaired kolmogorov smirnov ks test statistic massey 1951 value obtained for each class interval i based on time matched observed and forecasted values as given by equation 7 this statistic evaluates the difference between the cumulative distribution functions cdfs of the observed f i o x and predicted f i f x datasets in each class interval i the test statistic ksi i j is defined as 7 i i j ksi i j max i f i o x f i f x i j 5 2 3 1 3 normalization of the cpm indices the indices i i j of cpm are normalized using a transformation function g j i i j to obtain numerical values within a specific range 0 1 after normalization of the parameters the best ideal and worst values for each parameter would be 1 and 0 respectively the numerical value of fpbm from equation 1 will be in the range 0 1 wherein a time match between the observed and forecasted frequencies will be denoted by 1 the vi and iqri may originally vary in the range 0 for a perfect model performance the value of vi and iqri should be equal to 1 hence the deviations of vi and iqri from 1 on lower and higher sides are penalized while normalizing them for instance the values of vi and iqri lower than one are subtracted from 1 for normalization and the values of vi and iqri greater than one are normalized using the equations 1 v i i j 1 vi i j and 1 i q r i i j 1 iqri i j respectively such that higher deviations from 1 are penalized heavily the ci may show variations within the range 1 1 hence it is normalized by a linear approximation such that 1 1 corresponds to 0 1 for a perfect model ci should be 1 the variations in braei shall be in the range 0 1 thus in the current context braei is normalized by subtracting their values from 1 such that for a perfect model the normalized braei is 1 the ksi values would range between 0 1 wherein the values close to 0 would indicate the acceptance of the null hypothesis i e distributional similarity exists between observed and simulated datasets hence while normalizing the ksi values are subtracted from 1 such that normalized ksi equal to 1 represents a perfect distributional similarity 2 3 2 assignment of weights the fbpm and cpm are derived by assigning user defined weights to the normalized values of these indices for each class interval the fbpm and cpm values vary between 0 and 1 wherein 1 indicates the best model performance also higher weights may be assigned to lower higher class intervals in case the prime focus of the modeling exercise is to accurately forecast low high flow events equal weights may be assigned for an objective comparison of different models the values of fbpm and indices of cpm for each class interval can be graphically represented using a color coded matrix i e heatmap for visual interpretation of the model performance and multi model comparisons 2 3 3 adjustments to class intervals and widths in many situations hydrologic simulation models predict streamflow values that are larger than the maximum observed streamflows or provide negative streamflow values under such circumstances additional class interval s can be included other than those defined based on the observed data additional class interval s shall have the class edges as the maximum minimum observed and maximum minimum predicted streamflows the upper and lower limits of the forecasted streamflows if falling outside the range of observed streamflows can still be evaluated using these additional class interval s this would require the redistribution of weights as per the revised number of class intervals and the erroneous predictions shall be penalized for multi model comparisons if there are no observed and predicted values in the additional class interval s then no penalty is assigned 2 4 model performance assessment numerical thresholds for measures performance assessment based on a numerical threshold value or a range of values of any error measure e g nse pbias r2 and rsr can serve as valuable guidance for model assessment moriasi et al 2007 2015 guidance on model performance evaluation using numerical values of fbpm and cpm with equal weightage to all classes is recommended as follows unsatisfactory or poor fbpm 0 50 o r c p m 0 35 satisfactory or average 0 50 f b p m 0 60 o r 0 35 c p m 0 50 good 0 60 f b p m 0 70 o r 0 50 c p m 0 60 excellent 0 70 f b p m 1 00 o r 0 60 c p m 1 00 since the fbpm is implicitly incorporated in the computation of cpm the value of cpm would always be equal to or lower than that of fbpm also while interpreting the model performance based on fbpm and cpm values the modelers must ensure that the appropriate model is selected for the intended purpose of modeling the model terminologies parameters and objectives are correctly defined appropriate temporal and spatial scales are chosen and the calibration and validation approaches are pertinently formulated and executed moriasi et al 2015 3 application of the measures the fbpm and cpm are tested for the evaluation of streamflow forecasting models the models are data driven and are developed using the model tree mt technique quinlan 1992 witten and frank 2005 approach for one step ahead prediction these models use the information about lagged daily streamflow values at a target site and a site upstream to the target site and moving averaged values at the target site lagged precipitation values and estimated baseflows the baseflow estimations were obtained using a digital filtering algorithm eckhardt 2005 using the web based hydrograph analysis tool what lim et al 2005 3 1 model tree mt approach a model tree mt quinlan 1992 is a data driven hierarchical approach that characterizes and models the relationship between input and output parameters and represents them using linear models the mt divides the input parameter region into several sub regions and formulates a multi variable linear regression model for each sub region quinlan 1992 witten and frank 2005 mt employs segmented linearization to represent a non linear process jothiprakash and kote 2011 the mt based models show an advancement over the classification and regression tree cart models by incorporating linear regression equations in the leaves as compared to the numeric values in the latter rezaie balf et al 2017 the mt approach has been successfully applied for streamflow forecasting applications solomatine and xue 2004 rezaie balf et al 2017 esmaeilzadeh et al 2017 3 2 case study domain the mt based streamflow forecasting model is developed to predict daily streamflows at the ukai dam in the tapi basin india the tapi basin fig 2 with an area of 65 145 km2 in the west central part of india exhibits heterogeneous physiographic and climatic variability sharma et al 2020 the basin is bounded by mountain ranges on three sides and the arabian sea to its west as shown in fig 2 the mean annual temperature across the basin ranges from 20 7 c to 33 0 c whereas the annual rainfall varies between 550 and 1800 mm the region experiences a typical monsoonal climate wherein around 90 of total rainfall is received between june and september referred to as flood season sharma et al 2020 the ukai dam is the largest reservoir in the basin draining an area of 62 225 km2 with a densely populated urban and industrial center city of surat located downstream of this dam near the arabian sea the city was impacted by severe floods in the years 1994 1998 2006 and 2013 mainly due to large releases made from the ukai dam thus developing and evaluating a streamflow forecasting model for the ukai dam would be critical for flood forecasting and reservoir operations the daily inflows to the ukai dam for the period 1975 2013 were obtained from the ukai civil circle ukai government of gujarat india the daily streamflows at gidhade stream gauging station shown in fig 2 upstream of the ukai dam for the concurrent period were collected from the tapi division central water commission cwc government of india the daily rainfall data at forty nine rain gauges located upstream of the ukai dam shown in fig 2 were collected from india meteorological department imd pune india these data were used for the development of a streamflow forecasting model for the ukai dam using the model tree mt technique sharma et al 2021 3 3 mt based forecasting models three mt based models referred to as models a b and c based on different hydrological input variables are chosen to evaluate the applications of the proposed performance measures in evaluating models the models are calibrated and validated using the observed streamflow data at the ukai dam for the period 1975 2013 the models are developed for forecasting monsoon season june to september streamflows into the ukai reservoir the calibration and validation datasets are for the periods 1975 2005 and 2006 2013 respectively since the data length is sufficient to develop and evaluate the model exhaustive cross validation is not performed in model development the daily streamflow at two sites i e the target site and the upstream site lumped rainfall up to the target site computed baseflow values and moving averaged streamflows at the target site are used as inputs to the model the locations of the target site i e ukai dam where the forecasts of streamflows are required and the upstream site i e gidhade are shown in fig 2 the mean areal precipitation is derived using the thiessen polygon approach based on precipitation values from all the rain gauges in the tapi river basin that are located upstream of the ukai dam model a in this model the lagged values of streamflows q t 1 o q t 2 o in time intervals t 1 and t 2 at the target site are used to predict flows q t p in the time interval t the functional relationship specifying model a is given by equation 8 8 q t p f q t 1 o q t 2 o t model b in this model lagged values p t 1 o p t 2 o p t 3 o in time intervals t 1 and t 2 at the target site are used to predict flows q t p in the time interval t the functional relationship specifying model b is given by equation 9 9 q t p f p t 1 o p t 2 o p t 3 o t model c this model uses three types of input variables and they are two lagged values q t 1 o q t 2 o of streamflows at the target site estimated baseflows b q t 1 o bq t 2 o at the target site and streamflows q u t 1 o q u t 2 o at an upstream site in time intervals t 1 and t 2 respectively in addition to these variables moving averaged three and five day streamflows q mv 3 o q mv 5 o at the target site are used to predict flows q t p in the time interval t the functional relationship between these variables and predicted flows in model c is given by equation 10 10 q t p f q t 1 o q t 2 o q u t 1 o q u t 2 o b q t 1 o bq t 2 o q mv 3 o q mv 5 o t the moving averaged flow value q mv m t o for mt intervals is obtained using equation 11 11 q mv m t o l 1 mt q mt t l o mt m t t 1 3 4 test datasets in addition to evaluations of performances of three mt based models i e model a b and c two hypothetical or synthetic datasets consisting of observed and forecasted streamflows are used for assessment the two synthetic datasets developed are 1 real world observed streamflows and forecasted flows derived from modified observed flows and 2 hypothetical forecasted and observed datasets the forecasted values for the first test dataset are derived by modifying the observed streamflows at the ukai dam to demonstrate the applicability of these measures on a range of model evaluation scenarios that are likely to be encountered by the modelers however there is no restriction on the usage of a particular dataset this dataset is hereafter referred to as a synthetic dataset consisting of five scenarios referred to as s1 s2 s3 s4 and s5 the second dataset referred to as hydrotest dataset is obtained from https hydrotest org uk benchmarks html this dataset with four forecast scenarios referred to as h1 h2 h3 and h4 is publicly available for modelers to evaluate different error and performance measures since these two datasets use hypothetical forecasts that are assumed to be generated by forecasting models the scenarios are referred to as models s1 s2 s3 s4 and s5 and models h1 h2 h3 and h4 to be consistent with the notation used for mt based models a b and c in this study in addition hypothetical datasets refer to supplementary material demonstrating exceptional cases with a lower sample size i e 16 and skewed data distribution are evaluated to prove that the proposed measure is outlier resistant and accounts for inconsistencies in data distribution 4 results and analysis the utility of several data classification methods is initially evaluated for partitioning the randomly generated data samples of different probability distributions i e normal and skewed distributions the fbpm and cpm measures are then evaluated using forecasts from different models and datasets described in sections 3 3 and 3 4 improvements in the model forecasts are evaluated when post forecast corrections are used to address erroneous model predictions 4 1 data partitioning approaches the data partitioning methods are applied for deriving class edges corresponding to each class interval for a given dataset for an exhaustive comparison of performances of these methods four randomly generated data samples with 1000 values that characterize different distributions are used data that follows a gaussian distribution is generated with the location μ scale σ skewness γ and kurtosis β2 parameter values of 100 1 0 and 3 respectively another dataset following uniform distribution is generated with observations in the range 97 103 further two skewed distributions viz positively and negatively skewed are generated with μ σ γ and β2 parameters values of 100 1 1 and 3 and 100 1 1 and 3 respectively twelve bins for these datasets derived using sturges s rule were used in the partitioning approaches the corresponding class edges for each bin determined by different partitioning methods are shown in figs 3 5 it can be noted from figs 3 5 that the equal interval classification results in higher frequencies in the central class intervals while the starting and the ending bins have very few values the k means clustering and natural breaks methods attempt to divide the central values having higher frequencies into a greater number of classes however the geometric interval and quantile methods achieve finer discretization in dense data ranges as compared to other methods the quantile method results in equiprobable class intervals i e all the intervals have an almost equal number of data points the interquartile range method requires prior information about the underlying distribution of the data and the data division is user specific in the case of the gaussian distribution higher frequencies are concentrated between the interquartile range i e 25th and 75th percentiles therefore this data range is divided into a greater number of classes i e eight classes in this case while the values greater lower than the upper lower quartiles are divided into two classes each the equal interval classification fig 3 a 4 a and 5 a method performs poorly for skewed datasets compared to the normally distributed datasets in the case of positively negatively skewed datasets the equal interval classification would result in fewer values in higher lower class intervals in the case of skewed datasets higher frequencies are concentrated in the start or end bins hence finer discretization is required in those data ranges the k means fig 3 b 4 b and 5 b and natural breaks fig 3 c 4 c and 5 c methods produce comparatively fewer numbers of classes in those data ranges than geometric interval fig 3 d 4 d and 5 d quantile fig 3 e 4 e and 5 e and interquartile range fig 3 f 4 f and 5 f methods the interquartile range method divides data that is lesser greater than the lower upper quartile in finer classes in the case of a positively negatively skewed dataset the number of divisions required in these data ranges is user specific and problem dependent on the other hand all the methods have shown comparable performance for uniformly distributed data in hydrologic time series analysis positively skewed data e g daily streamflow and rainfall and data with near gaussian distribution such as daily temperature and evaporation are usually encountered the uniformly distributed and negatively skewed datasets are uncommon the geometric interval quantile natural breaks and quantile methods are better suited to classify skewed and normally distributed datasets in real world applications the class edges for the observed streamflows at the ukai dam derived using all the methods considering ten class intervals are derived and are provided in table 1 the class edges corresponding to ten class intervals for synthetic and hydrotest datasets estimated using four methods are provided in table 2 4 2 evaluation of models and test cases the summary statistics of the real world synthetic and hydrotest datasets are provided in table 3 the developed performance measures are applied to analyze the prediction accuracy of test datasets from real world models and synthetic time series the results of the assessment of model accuracy through error and performance indices and the developed performance measures fbpm and cpm are provided in tables 4 and 5 respectively 4 2 1 model tree based forecasting models the mt based streamflow forecasting models are developed to predict one day ahead streamflows at the ukai dam the streamflow data is partitioned into several classes to facilitate the classification of different streamflow regimes the classes 1 3 4 7 and 8 10 represent low moderate and high flow conditions respectively based on geometrical interval classification also the limits of classes 3 and 8 which represent low and high flow thresholds correspond to 33rd and 90th percentile streamflows respectively alternatively the flow conditions can also be defined and associated class intervals be identified such that observed streamflows 10th percentile between 10th 90th percentile and greater than 90th percentile threshold values correspond to low medium and high flow conditions respectively similar to those utilized by united states geological survey usgs https waterdata usgs gov nwis rt the selection of input variables for these data driven models was carried out using autocorrelation partial autocorrelation average mutual information and the false nearest neighbor criterion sharma et al 2021 based on the combination of input variables several candidate models were formulated and analyzed using multiple error and performance indices out of these candidate models three models viz model a model b and model c described in section 3 3 are used to derive forecasts and the performances of these models are evaluated using fbpm and cpm the nse values derived for models a b and c are 0 70 0 58 and 0 94 respectively in the calibration phase however in this experiment the validation data of the models a b and c are analyzed in detail the observed and forecasted streamflows for these models are shown in fig 6 from fig 6 a b model a is noted to overpredict the low and moderate flows while underpredicting the high flows model b is found to consistently underpredict all flow ranges fig 6 c d whereas simulation results from model c show good agreement between observed and simulated streamflows fig 6 e f error and performance measures derived based on models a b and c are provided in table 4 relatively lower values of error measures i e rmse rae mare and mre and higher values of efficiency measures e g r2 nse and kge are noted for model c compared to models a and b model c uses additional information in terms of streamflow at an upstream gauge computed base flow and moving average streamflow as compared to models a and b this additional information has led to an improvement in the forecasts by effectively capturing the variability of the physical processes generating streamflow in the basin however model c is not effective in modeling the low flows the linear regression models generated in the mt approach include a positive constant term which leads to an overestimation of the observations with zero values visual assessment through time series and scatter plots fig 6 e f may specify some of these issues related to the performances of the models however the quantitative evaluations using single valued error and performance measures table 4 do not provide a comprehensive assessment of the models most of the performance measures provided in table 4 suggest the sensitivity of model performances to moderate and high flows while the errors associated with low flows are not highlighted hence there is a need for careful assessment of the prediction models to effectively capture the model performance across all streamflow regimes the fbpm and cpm can help overcome such shortcomings of existing error and performance measures the observed streamflow dataset shows a higher skewness γ 6 3 and variability coefficient of variability 5 14 flow range 0 29 046 m3 s the observed streamflow data follows a positively skewed distribution as shown in fig 4 the class edges derived using different approaches considering ten bins based on sturge s rule are provided in table 1 as indicated earlier the data classification using geometric interval natural breaks quantile and interquartile range approaches are more suited for skewed data however due to the large number of zero observations in the dataset the quantile method fails to assign values to the first class interval refer to table 1 use of natural breaks method resulted in intervals with higher class edges when compared to the geometric interval and interquartile range methods in the current study the user defined approach that classifies the streamflows based on the return periods is also initially assessed the annual maximum streamflow for ukai dam 1975 2013 is fitted with a generalized extreme value gev distribution using the maximum likelihood estimation mle method to obtain distribution specific parameters for deriving streamflow magnitudes corresponding to different return periods however this approach is only suitable to assess the predictive performance of models developed for simulation of peak discharges overall the geometric interval approach resulted in the finer discretization of classes for data range with higher densities compared to other methods the fbpm and cpm are employed to analyze the model performances considering ten class intervals using all classification methods however results derived using geometric interval classification are discussed further based on the geometric interval classification models a and b exhibit poor performance across most class intervals particularly the low and high flow classes as shown in fig 7 a and b on the other hand model c shows better performance in predicting the moderate and high flows as shown in fig 7 c model c is unable to estimate the low flows accurately which is mainly attributed to over estimation by the mt model this shortcoming of model c is not effectively captured by the statistical error and performance indices described in table 4 these indices such as rmse mae r2 and nse indicate better model performance in predicting moderate and high flows which confirm the results of the proposed approach similarly the k means clustering natural breaks and quantile methods have also been used to derive the fbpm and cpm values for these models which are provided in table 5 from table 5 it can be noted that model c outperforms models a and b in terms of higher fbpm scores for all data classification methods considering equal weights to each class interval the fbpm values for models a and b are lower than 0 5 which indicates unsatisfactory model performance whereas model c shows satisfactory model performance i e 0 50 fbpm 0 60 for all data classification schemes overall the cpm values for model c are reportedly lower than the fbpm values however they are within the acceptable range 4 2 2 synthetic datasets in this experiment the observed streamflows q t o at ukai dam that are lower higher than 33rd percentile q33 90th percentile q90 are considered as low high flows whereas the streamflows ranging between q33 and q90 are denoted as moderate flows the observed dataset is synthetically modified to generate five different scenarios of simulated flows these model scenarios are referred to as models s1 s2 s3 s4 and s5 and they are defined as model s1 the daily observed streamflows are lagged by two days and lowered by a factor ranging between 0 95 and 0 99 to derive the simulated streamflows as shown in fig 8 a b model s2 the low flows i e q t o q33 are well predicted within an accuracy between 95 and 99 while the streamflows higher than q33 are lowered by a factor ranging between 0 5 and 0 75 to depict that moderate and high flows are underpredicted as shown in fig 8 c d model s3 the high flows i e q t o q90 are well modeled within an accuracy range of 95 99 while the low and moderate flows are overpredicted by a factor ranging between 1 5 and 2 as shown in fig 8 e f model s4 the moderate flows i e q33 q t o q90 are fairly predicted within an accuracy range of 95 99 while the low and high flows are overpredicted and underpredicted respectively as shown in fig 8 g h model s5 the simulated streamflows are predicted within the range of 95 99 of the observed flows as shown in fig 8 i j the observed streamflows at ukai dam are modified to generate simulated synthetic datasets representing various scenarios viz persistent lagged flow model low flow model high flow model moderate flow model and ideal model the synthetic datasets are positively skewed with lower variability compared to the previous dataset table 3 sturge s rule suggests ten bins to classify the data the geometric interval classification has yielded finer discretization of data with higher densities as compared to other methods the error and performance measures computed and provided in table 4 for these models suggest higher prediction accuracy for model s5 as compared to other models whereas model s1 performs poorly model s4 performs better than models s2 and s3 when error and performance measures are compared fbpm and cpm values for these models are provided in table 5 and are visualized as heatmaps shown in fig 9 it is evident from fig 9 a that model s1 performs poorly in the prediction of streamflows across all class intervals model s2 shows better performance for low flows while underpredicting the moderate and high flows significantly which results in poor performance in those intervals fig 9 b the model s3 shows better accuracy in predicting high flows than low and moderate flows which are overpredicted fig 9 c model s4 performs better in the prediction of moderate flows while low and high flows are not accurately mapped fig 9 d the model s5 results show superior performance across all streamflow classes fig 9 e from table 5 the fbpm and cpm values suggest the superior performance of the model s5 for all methods considering equal weights the fbpm and cpm values for model s4 reflect its better prediction accuracy than models s1 s2 and s3 the model s4 performs exceedingly well for moderate flows i e class intervals 4 7 while the model performance for low flow events is average the model s1 the persistence model is the worst performing model since the lag effect leads to inaccurate time matching the fbpm and cpm values indicate unsatisfactory performance for the models s1 s2 and s3 on the other hand the performance of models s4 and s5 are interpreted as good and excellent respectively the fbpm and cpm effectively characterize the performances of models across all classes and provide an objective comparison of different models the visual assessments through heatmaps are beneficial to identify the model deficiencies i e inability to capture low high flows and enable multi model comparison across various streamflow regimes for instance a heatmap based evaluation may point to a specific hydrological model s poor prediction performance in those class intervals that define flow extremes this reflects the inability of the model to effectively predict the hydrograph peaks which would suggest the modeler re calibrate the model parameters associated with high flow conditions the conventional performance measures do not provide such specific and comprehensive information 4 2 3 hydrotest datasets the hydrotest dataset differs from the synthetic dataset discussed in section 4 2 2 the former dataset is characterized by lower streamflow variability and rather uniform distribution whereas the latter suggests a higher streamflow variability and positively skewed distribution with a considerable number of zero observations the hydrotest benchmark datasets represent four scenarios and they are denoted as models h1 h2 h3 and h4 model h1 this model is referred to as a naïve model wherein the model predicts the observed data from six previous time steps without any change in its magnitudes as shown in fig 10 a b model h2 this model simulates the low flow events better however the high flow events are underpredicted as shown in fig 10 c d model h3 this model is termed as a noisy model in which the observed flows are reasonably well overall but are consistently over or under predicted by 15 as shown in fig 10 e f model h4 this model predicts the high flow events better however the low flow events are not simulated properly as shown in fig 10 g h the hydrotest dataset represents streamflow conditions with low variability skewness and kurtosis but higher persistence evident from lag one autocorrelation table 3 the sample size of the hydrotest data n 160 is also relatively smaller than previous datasets the variations of the observed data produce four different scenarios viz the naïve model persistence model low flow model noisy model irregular fluctuations and high flow model the noisy model as extreme test case is included in the current study to demonstrate the utility of measures developed in this study ten class intervals are used for consistency of analysis even though sturge s rule recommended eleven bins for this dataset all the methods of the classification resulted in almost similar class edges table 2 the error and performance measures table 4 suggest that model h1 results in lower values of rmse mre and msle and higher values of nse and kge whereas the noisy model h3 results in lower me r4ms4e mre msre values compared to other models therefore the error and performance measures can be misleading in evaluating these model performances despite knowing their inherent limitations the data partitioning based measure is applied to hydrotest dataset and their results are shown in table 5 and fig 11 it is evident from fig 11 a that model h1 shows inconsistent performance across all classes wherein the fbpm and cpm reflect lower values across most classes model h2 predicts the low and moderate flow events with perfect accuracy however the high flow events are under predicted fig 11 b model d shows a better prediction of high flow events whereas the low and moderate flows are poorly predicted fig 11 d the proposed approach highlights the erratic characteristics of model c which shows the worst performance fig 11 c whereas the interpretations of the statistical performance indices to assess the model performances are misleading this shows the superiority of the proposed approach in terms of statistical and visual assessment of the model performance the fbpm and cpm values also suggest that model b is the best model amongst the hydrotest datasets while model c is the worst performing model table 5 the performance evaluation criteria suggest that the models h1 h3 and h4 show unsatisfactory performance while model h2 reflects good and excellent performance based on fbpm and cpm values respectively for all data classification schemes from table 5 it can be noted that the classification method chosen may affect the numerical value of the measure that quantifies the model performance and not the model performance itself the class bin range values for different classification methods vary and these partitions in data will determine how many observed and forecasted values fall into these classes as the bin widths are different the number of classes and bin widths class intervals will eventually affect the numerical value of the performance measure but not the general assessment of the model performance 4 2 4 hypothetical dataset with an exceptional case a hypothetical dataset representing an exceptional case which is less likely to be encountered in real world modeling studies of a smaller sample size i e 16 partitioned into two class intervals yielding a highly skewed distribution of data is evaluated in this scenario a fewer number of observed and predicted values in a particular class interval exhibit do not exhibit a perfect time match which is represented as case 1 case 2 and as shown in figs s1 and s2 of the supplementary material the analyses reveal that partitioning the data into fewer i e two class intervals tends to inflate the fbpm value for case 1 fbpm 0 73 and suggests a better model performance as compared to case 2 fbpm 0 22 on the other hand the cpm values for case 1 and 2 are found to be 0 30 and 0 17 respectively which suggests a poor model performance in both cases however the sensitivity of fbpm does not indicate its drawback but rather it points towards inappropriate application of the measure as per sturges s rule the minimum number of bins obtained for the given sample size is five the fbpm values for case 1 and 2 considering ci 5 are found to be 0 33 and 0 13 respectively which indicates a poor model performance thus inappropriate data partitioning i e too few or too large a number of bins would undermine the effectiveness of fbpm in evaluating model performance three additional cases are also generated i e case 3 4 and 5 by introducing outliers in observed and predicted datasets as shown in figures s3 to s5 of the supplementary material the presence of an outlier inflates the values of conventional error and performance measures such as rmse r2 mae nse and others table s1 while the fbpm and cpm measures change minimally table s2 these experiments suggest that fbpm and cpm measures are resistant to outliers and they do not inflate the model performance unlike other performance indices additional details of these experiments are provided in the supplementary material 4 2 5 sensitivity of fbpm and cpm to the number of class intervals the number of bins for data partitioning approaches can be defined using different methods however in this study sturges s rule for estimation of the number of bins based on data sample size is used to assess the sensitivity of fbpm and cpm values to the number of class intervals performances of models a b and c are evaluated considering five ten fifteen and twenty classes the variations in fbpm and cpm values for these model configurations considering geometric interval classification and equal class weights are shown in fig 12 it can be noted from fig 12 the fbpm and cpm values decrease with an increase in the number of class intervals model c shows superior performance for all the class intervals a fewer number of classes may lead to a greater number of data points within these class intervals leading to higher fbpm and cpm values on the other hand the increase in the number of classes sometimes results in fewer observations in certain class intervals which is responsible for lower values of fbpm and cpm the variations in fpbm and cpm values with changes in the number of class intervals do not alter the results of the inter model performance comparisons for instance model b shows poor performance than models a and c irrespective of the number of class intervals increasing the number of class intervals may occasionally lead to empty class intervals i e classes with no data which may affect the model evaluation using fbpm and cpm 4 2 6 sensitivity of fbpm and cpm to assigned weights user defined weights are attached to the class intervals in fbpm and cpm based on the intended purpose of the model application to ascertain the influence of weights on the model performance evaluation a comparison of results of all the models corresponding to ten class intervals derived using the geometric interval method is performed under this investigation four different scenarios are considered initially all the classes are assigned equal weights and thereafter more weights are assigned to low moderate and high flow classes subsequently from fig 13 minor variations in the fbpm and cpm values are evident for a particular model for different weight scenarios however the assigned weights do not change the results of inter model performance comparisons for instance model c shows superior performance for all weightage scenarios as compared to models a and b fig 13 as discussed in section 4 2 2 model s2 predicts low flow with better accuracy hence higher fbpm and cpm values are observed when low flows are given more importance weightage similarly the models s3 and s4 show better performance in the prediction of high and moderate flows respectively thus the importance attached to high and moderate flows for these models results in an improvement in their performance measures the nse value for model s1 is found to be zero however the fbpm and cpm values are not zero the nse 0 indicates a similar model prediction skill as that of the mean flow of the time series however the proposed approach provides an objective assessment of the model performance considering all class ranges and hence the fbpm and cpm values are non zero for model s1 thus the conventional performance measures are unable to assess the deficiencies in the models across all flow ranges whereas fbpm and cpm values provide an objective evaluation of the model performances overall the fbpm and cpm provide flexibility to the user in assigning importance to the flow regimes based on the purpose of modeling for instance the analysis of droughts floods would warrant larger weights being assigned to lower higher classes based on the classification scheme and the number of class intervals adopted 4 3 influence of post forecast corrections model forecasts can be corrected based on information available about hydrological conditions or inherent limitations of the model these post forecast corrections can help in improving erroneous predictions the linear regression model used in the mt based approach has a constant term that results in a forecast of non zero streamflows values as opposed to observed zero values this amplifies the model errors and thereby lowers its predictive performance hence based on the analysis of hydrometeorological processes influencing the streamflow the forecasted value can be corrected to compensate for the limitations of the model forecast corrections are made to simulation results of models a b and c the streamflow observed at ukai dam is influenced by the observed streamflow at an upstream gauge gidhade station and the rainfall between the watershed from gidhade to the ukai dam also the three day moving averaged streamflow q mv 3 o at the ukai dam is additionally considered to make a judgment regarding the post forecast correction therefore based on the values of rainfall p t 1 o observed streamflow at the upstream gauge q u t 1 o and three day moving average flows i e q mv 3 o the predicted streamflow q t p is corrected as q t p using the condition expressed in eq 12 12 if q u t 1 o q mv 3 o a n d p t 1 o 0 t h e n q t p 0 e l s e q t p q t p t the post forecast correction is applied to all the non zero values produced by models a b and c subject to the condition specified in eqn 12 the results from these post forecast corrections show an improvement in the model performance in terms of fbpm and cpm as shown in fig 14 4 4 general remarks comparative evaluations of traditional performance measures such as coefficient of determination r2 index of agreement ioad nash sutcliffe efficiency nse and kling gupta efficiency kge and the fpbm and cpm using results from the twelve models models a c s1 s5 h1 h4 developed in the study are carried out a percentage difference δ based on any traditional performance measure β and fbpm or cpm θ is obtained using equation 13 13 δ β θ θ 100 the r2 ioad nse and kge values on average overestimate the model performance compared to fbpm and cpm by 121 and 284 respectively when twelve models are evaluated in the case of the inferior models a b s1 h1 h3 the r2 ioad nse and kge values overestimate the model performance compared to fbpm and cpm by average 207 and 546 respectively when the best models c s5 and h2 are considered the r2 ioad nse and kge values on averageoverestimate the model performance compared to fbpm and cpm by 15 and 44 respectively the traditional performancemeasures failed to identify the worst performing models the inflation of numerical values from traditional measures i e r2 ioad nse and kge may lead to the inappropriate selection of the best model among a set of competing models the two measures fbpm and cpm developed in this study benefit from dividing the data into several bins class intervals and evaluating the number of observed and predicted values in those partitions an extremely small number of class intervals or observations and predictions in those class intervals and many class intervals with few or no observations and predictions in those intervals will lead to biased and inaccurate performance evaluations when these measures are used since fbpm and cpm are frequency based measures they have similar limitations that plague histograms and statistical goodness of fit hypothesis tests e g chi square goodness of fit test that rely on the use of the appropriate sizes and number of class intervals for accurate assessment of distributions and robust inferences considering these limitations the number of class intervals and sizes of such intervals should be given careful consideration when fbpm and cpm are used for model evaluation for different hydrologic applications accurate assessment of model performance based on numerical values of fbpm and cpm is possible if the parameters such as the number of classes class interval width and weights assigned to each class interval are selected appropriately considering the purpose for which the model is being evaluated modelers can judiciously assign values to these parameters by evaluating the distribution of the observed data adopting the best available guidance in the literature on defining the number of class intervals and selecting equal or best set of unequal class interval widths based on an iterative screening exercise that involves the use of multiple data portioning schemes equal and unequal weights can be assigned to the class intervals the former assignment is simple and objective while the latter is subjective and related to the purpose for which the model is evaluated arbitrary selection of weights should be avoided and rather scientific approaches such as entropy analytical hierarchy process ahp and others may be adopted 5 conclusions a new performance measure frequency based performance measure fbpm that uses a data partitioning approach is developed for the evaluation of hydrologic simulation or forecasting model predictions several new indices are used in conjunction with this measure to devise an additional aggregated measure composite performance measure cpm that evaluates the model performance based on different characteristics of the observed and predicted time series multiple data classification techniques are evaluated to partition the streamflow data for use in the fbpm and cpm performances of multiple model tree based forecasts for a site in the tapi river basin in india and synthetic datasets viz observed and forecasted are assessed using these two measures the geometric interval approach was found to characterize and partition the datasets used in this study better than all the other approaches evaluated the fbpm and cpm provide better assessments of the models performances than single valued performance measures in accurately predicting different streamflow regimes of the tapi river the use of fbpm and cpm for the evaluation of synthetic datasets point to their superiority over the traditional error and performance measures the developed measures allow users to define class intervals and assign weights based on the intended purpose of the modeling and the importance attached to the specific forecasts inaccurate evaluations due to inflated fbpm values are possible when the number of class intervals used is too small to characterize the variability of observed and forecasted values from the models the fbpm and cpm are conceptually simple to derive scale independent resistant to the outlier observations and forecasts informative and can aid in the exhaustive assessment of the performance of a single model or selecting the best among competing models credit authorship contribution statement ramesh s v teegavarapu conceptualization formal analysis methodology writing original draft writing review editing priyank j sharma investigation validation visualization writing review editing prem lal patel data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thank the developers of waikato environmental for knowledge analysis weka software which was used in this study for the development of the forecasting models the authors also acknowledge the data disseminating agencies viz ukai civil circle cwc and imd india for providing the necessary data to svnit surat and the hydrotest website http hydrotest org uk for providing necessary data to conduct the present study the authors are thankful to the anonymous reviewers for their constructive comments and suggestions data availability the observed daily streamflow data for the ukai reservoir and gidhade gauging station are collected from the ukai civil circle ukai and tapi division central water commission cwc surat india respectively the rainfall data of the tapi basin is collected from the india meteorological department imd pune the benchmark test datasets for streamflow are downloaded from the hydrotest website https hydrotest org uk benchmarks html appendix the mathematical formulations of different error and performance measures along with their advantages and limitations are discussed in table a 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127583 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3458,scale dependent and independent error and performance measures are used to evaluate hydrologic forecasting and simulation models however these single valued measures may not always provide a comprehensive assessment of model performance developed for a specific hydrologic process and application a new frequency based performance measure fbpm that can incorporate application specific information for model evaluation is proposed to address the limitations of existing measures fbpm is derived using a data classification scheme to partition the observed data into several classes and evaluate frequencies of each class s chronologically paired observed and forecasted values a variant of fbpm composite performance measure cpm is also developed to include additional indices that evaluate error variance and other statistical characteristics of the observed and forecasted series several univariate and multivariate data classification schemes are initially evaluated and the best one is selected for use in the measures fbpm and cpm are used to assess the performance of daily streamflow forecasting models developed for the tapi river india using a data driven model tree mt approach the measures are also evaluated using two synthetic datasets representing different model forecast scenarios a comprehensive evaluation of streamflow forecasts using fbpm and cpm with the best data classification scheme i e geometricinterval schemein this work indicates a better and more robust assessment of the forecasting model performance than that from existing error and performance measures the traditional measures such as coefficient of determination index of agreement nash sutcliffe and kling gupta efficiency have overestimated model performances compared to fbpm and cpm on an average by at least 100 the traditional measures have also failed to identify inferior models mainly due to their inflated numerical values compared to those from fbpm and cpm the measures developed in this study allow the user specific definition of classesandassignment of weightstothese classes based on the intended purpose of the hydrologic modeling effort the fbpm and cpm are scale independent informative interpretable andoutlier resistant these measures can be used for visual and or statistical evaluation of the performance ofsingleor multiple hydrologic simulation models keywords frequency based performance measure data classification error and performance measures model evaluation synthetic datasets model tree composite performance measure 1 introduction calibration and validation are two essential tasks that need to be carried out to develop and evaluate hydrologic simulation models evaluation of models during calibration and validation phases using various statistical error and performance measures are documented in several studies asce 1993 chen et al 2017 dawson et al 2007 gupta et al 1998 hwang et al 2012 karran et al 2014 nash and sutcliffe 1970 moriasi et al 2007 2015 shamseldin 1997 simonovic and todini 1994 sorooshian and gupta 1995 teegavarapu and elshorbagy 2005 teegavarapu et al 2017 fu et al 2020 often visual evaluation of the observed and predicted or forecasted values of the hydrologic variables is used to support the model selection and assessment tasks for different applications one of the major limitations of single valued numerical error or performance measures is the lack of a model s ability to characterize the system behavior and predict the magnitudes e g extremes and average values of the variables that are of interest under all hydrologic system specific conditions a robust hydrologic simulation model developed for streamflow prediction is expected to provide accurate forecasts under normal and extreme flow conditions i e floods and droughts in general a single valued performance measure provides the overall performance usually with respect to a benchmark but fails to provide a complete assessment of the model performance across all streamflow regimes 1 1 measures for model performance evaluation forecast verification measures offer several single valued aggregate numerical error and performance or efficiency measures or criteria to evaluate models in general any hydrologic model evaluation is carried out through time and signature domain metrics the time domain evaluation involves error and performance measures which can be broadly classified as scale dependent scale independent percentage based relative based and efficiency measures the scale dependent error measures usually represent the errors in the same or squared unit of the variable in question these include mean error me mean absolute error mae absolute maximum error ame mean squared error mse root mean squared error rmse fourth root of the mean quadrupled error r4ms4e mean squared logarithmic error msle mean squared derivative error msde peak difference pdiff dawson et al 2007 fuzzy mean squared error fmse teegavarapu and elshorbagy 2005 and few others the scale dependent measures such as mse rmse msle and msde are found to weigh more heavily on large errors because of the squared deviations thus rendering them unsuitable for comparison of model performances across different watersheds which represent distinct hydrologic dynamics in terms of streamflow magnitudes and variability althoff and rodrigues 2021 the scale independent measures normalize the error statistic into a non dimensional form for better comparison among different models these measures include fractional standard error fse karran et al 2014 rmse to standard deviation ratio rsr moriasi et al 2015 and inertia root mean squared error irmse dawson et al 2007 the scale dependent measures are influenced by outliers and sensitive to the simulated higher magnitude errors in contrast the scale independent measures are not appropriate for model prediction over a large range relative absolute error rae overcomes the drawbacks associated with the above error measures viz sensitivity to the outliers and difficulty in their interpretation armstrong and collopy 1992 the error measures are also expressed in terms of percentage difference such as mean absolute percentage error mape median absolute percentage error mdape armstrong and collopy 1992 percent error in peak pep dawson et al 2007 and runoff coefficient error rr yilmaz et al 2008 the relative based measures also enable the comparison of a model s performance to that of a benchmark model the mean relative error mre relative absolute error rae relative volume error rve or percentage bias pbias mean absolute relative error mare mean relative absolute error mrae the geometric mean of relative absolute error gmrae armstrong and collopy 1992 dawson et al 2007 are amongst the relative based error measures chen et al 2017 introduced variants of relative accuracy measures such as bounded rae brae mean brae mbrae and unscaled mbrae umbrae which had several advantages over the preceding error measures in terms of being informative resistant to outliers symmetric scale independent and interpretable the percentage based and few relative based measures in some situations result in infinite or undefined numerical metrics error measures relevant to hydrologic model evaluation include nash sutcliffe efficiency nse criterion nash and sutcliffe 1970 garrick et al 1978 kling gupta efficiency kge gupta et al 2009 volumetric efficiency ve criss and winston 2008 persistence index pi kitanidis and bras 1980 relative correlation coefficient rcc hwang et al 2012 probability of detection pod and false alarm rate fa karran et al 2014 and onyutha efficiency onyutha 2021 some of these measures may provide redundant information when used without consideration of their limitations for instance the nse evaluates the squared difference between the observed and forecasted values wherein the larger values are highly overestimated whereas the smaller values are often neglected legates and mccabe 1999 nse is significantly influenced by the outliers time offset and magnitude bias mccuen et al 2006 and adopts a relatively weaker benchmark i e mean streamflows to compare the model performance which is not appropriate for river basins depicting high seasonality althoff and rodrigues 2021 efficiency measures generally used for evaluation of model performance include pearson kendall and spearman correlation coefficients index of agreement ioad willmott 1981and coefficient of determination or r squared statistic r2 teegavarapu et al 2017 the r2 and ioad measures are found to be over sensitive to high extreme values and fail to quantify the model bias onyutha 2021 while log nse is sensitive to low flows althoff and rodrigues 2021 some of these measures are not resistant to outliers while few measures adopt a relatively weaker benchmark clark et al 2021 suggested the adoption of a relatively stricter and purpose specific benchmark for an objective evaluation of the strength and weaknesses of a model complete details of the several statistical error and performance measures along with their advantages and limitations are provided in the appendix table a1 the signature based metrics evaluate specific features termed as signatures of the time series rather than the time series itself kavetski et al 2018 for example in the case of a watershed model evaluation these measures can be used to describe the streamflow characteristics and watershed dynamics the commonly adopted signature domain metrics include flow duration curves the spectral density of runoff base flow index interannual runoff variability rising limb density peak distribution and others yilmaz et al 2008 westerberg et al 2011 kavetski et al 2018 these metrics provide a better interpretation of the underlying processes of the system compared to the time domain measures however the modeler needs to consider multiple signatures to effectively characterize the system behavior since a given signature would reflect only a specific aspect of the watershed response euser et al 2013 therefore these measures cannot provide a comprehensive model evaluation as they are adopted to assess specific characteristics of a hydrologic model 1 2 need for new performance measures a comprehensive assessment refers to the evaluation of model performance by analyzing several characteristic features such as variability errors efficiency distribution similarity etc of observed and simulated values across all streamflow regimes single valued numeric error and performance measures reflect the degree of agreement between observed and simulated values however these measures fail to capture all the features reproduced by a hydrologic model in terms of inadequate utilization of the information content of data model capabilities and uncertainty gupta et al 1998 pachepsky et al 2006 mizukami et al 2019 clark et al 2021 and thus fail to provide a comprehensive assessment of the model performance also the performance metrics can substantially affect the quality of the calibrated model simulations mizukami et al 2019 rathinasamy et al 2014 indicated that the traditional performance measures are insufficient as they only provide an overall perception about the performance of the model by comparing two signals in the time and frequency domains separately the single valued performance measures such as nse and kge provide a relative gradation of model performance but they fail to identify the inherent causes for unsatisfactory model performance which could indicate the modeler for improvement of the model schwemmle et al 2021 furthermore the sensitivity of traditional performance measures towards high flows would dominate the global model performance which often masks its poor performance to simulate other flow regimes zhang et al 2011 pfannerstill et al 2014 visual evaluations of results using scatter and time series plots may help identify the limits of the model skill in accurately reproducing the observed behavior of the system these evaluations are subjective and can depend on the skill of the modeler also these evaluations may not always provide an objective assessment of the model performance across the range of values the model estimates or predictions therefore there is always a need for measures for hydrologic model evaluation that can overcome the limitations of existing error and performance measures several studies gupta et al 1998 legates and mccabe 1999 krause et al 2005 moriasi et al 2015 have recommended a multi objective evaluation of the model involving at least one dimensionless criterion one criterion in the same unit of the target variable a combination of different efficiency criteria and absolute or relative volume error estimation one or more single valued numerical measures are ideally suited for the comparative assessment of multiple models teegavarapu et al 2017 considering the limitations of existing single valued measures time domain metrics and signature domain metrics new frequency based performance measures for assessments of the model performance are developed and evaluated in this study the frequency based performance measures involve the use of time matched observed and forecasted instances in each class interval supplemented with additional indices that evaluate error variance the strength of association and distribution similarity between observed and forecasted values by suitably assigning weights to the classes based on the purpose of modeling the frequency based performance measures can be used for performance evaluation of a single hydrologic model or comparative assessments of multiple models the contents of this manuscript are organized as follows the methodology section discusses the need for partitioning of data for the development and implementation of these measures various data partitioning methods and briefly explains the proposed data partitioning based performance measures developed in this study information on the model tree mt data driven technique case study region data sources and the various datasets adopted in the current investigation is provided next the results and analysis section includes a comparison of various data partitioning methods and application of proposed measures to modeled and synthetic hydrologic datasets general remarks discussing advantages and limitations of the frequency based measures and the conclusions are provided next 2 methodology the methodology adopted for the development of frequency based and composite performance measures for the assessment of model predictions is shown in fig 1 the developed measures in this study are used for the evaluation of a data driven streamflow forecasting model 2 1 need for data partitioning the measures developed in this study will help assess the performance of a model based on a particular range of observed values of the variable of interest above or below a specific numerical threshold which could correspond to high medium and low flow conditions to evaluate the model performance and quantify it across different classes or bins of data of the observed values a data partitioning or classification approach is required a manual or user defined classification method that partitions the data into a specific number of classes can be used alternatively an automatic partitioning method that considers the data characteristics and distribution of the values can also be used the number of partitions and class interval widths can be hydrologic model application specific when the manual method is used 2 2 methods for partitioning of data in this study seven partitioning methods are evaluated for data classification which include i equal interval ii k means clustering iii natural breaks iv geometrical interval v quantile vi interquartile range and vii user defined or problem specific breaks except for the k means clustering method a multivariate approach all other schemes are univariate data classification techniques all the partitioning methods require the number of classes to be specified sturge s formula sturges 1926 doane s formula doane 1976 scott s rule scott 1979 freedman diaconis rule freedman and diaconis 1981 variable bin widths kallenberg et al 1985 and bin width optimization shimazaki and shinomoto 2007 can be used to determine the number of classes based on the bin sizes for robust evaluation it must be ensured that the minimum number of values in each bin must be greater than five in at least 80 of the bins and no bin should have an expected value of less than one mchugh 2013 rolke and gongora 2021 in the equal interval method the attribute values are divided into several classes having equal class width de smith et al 2007 this method is best suited for uniformly distributed data since the equal class widths may result in classes with zero observations in the case of nonuniformly distributed datasets k means clustering attempts to partition a multivariate dataset into k distinct non overlapping clusters so that points within a cluster are as close as possible in the multi dimensional space and as far away as possible from points in other clusters de smith et al 2007 the natural breaks algorithm classifies the data based on natural groupings inherent in the data class breaks are created such that similar values are grouped by maximizing the difference between the classes jenks 1967 de smith et al 2007 in this method the features are divided into classes and the boundaries are marked where relatively significant differences in the data values are noticed the geometric interval classification scheme creates class breaks that conform to a geometric series based on class intervals the intervals are selected such that the number of observations in each successive interval increases or decreases exponentially de smith et al 2007 the algorithm creates geometric intervals by minimizing the sum of squares of the number of elements in each class the quantile method divides the range of possible values into unequal sized intervals so that the number of values in each class is similar de smith et al 2007 generally this classification would not result in empty classes or classes with too few or too many values thereby resulting in equiprobable class intervals the interquartile range method proposed in this study is derived by idealizing the boxplot characteristics this method requires information regarding the distribution of the data a priori in this method the classes are defined based on the division of the interquartile range between 25th and 75th percentiles upper quartile greater than 75th percentile and lower quartile smaller than 25th percentile depending upon the distribution of the data for instance if the data is positively negatively skewed the data values in the lower upper quartile would warrant finer discretization compared to the rest of the values apart from these methods user defined or problem specific class intervals can be used for data partitioning for instance the streamflow data can be classified based on the return periods critical levels of flooding in the channel or based on the environmental flow considerations that are specific to a region 2 3 performance measures two frequency based performance measures proposed and developed in this study are described in the following sections 2 3 1 frequency based performance measure fbpm the frequency based performance measure fbpm uses counts or frequency estimates of observed and forecasted values in all the class intervals bins of the observed data derived using a specific univariate or multivariate data classification scheme the observed data is divided into several class intervals n c of equal or unequal widths using a manual or automatic partitioning method in each class interval i or bin the total number of observations o i and time index matched forecasts f i m i e the total number of only those forecast values that are associated with the same time index as with those of observations are obtained the superscript m refers to a chronological match or time match the ratios of these counts f i m o i are weighted and aggregated across all intervals to obtain the fbpm defined by equation 1 the weight w i associated with each class interval needs to be assigned by the user with a condition of i 1 nc w i 1 the ratio for each interval serves as an assessment of the model performance for the range of observed values specified by the interval 1 fbpm i 1 nc w i f i m o i the fbpm benefits from multiple assessments and quantifications of the model performances in different ranges of the observed variable weights defined by the user considering the model application e g for low flow forecasting or flood forecasting are attached to each of these classes 2 3 1 1 composite performance measure cpm a variant of the fbpm is also developed to include additional indices that evaluate error variance and other statistical characteristics of two different time series observed and forecasted for the development of a composite or aggregated performance measure this variant is referred to as a composite performance measure cpm as defined by equation 2 this approach provides flexibility to the user to incorporate remove additional indices in the purview of cpm based on the purpose of modeling the cpm assesses the agreement between time matched forecasted and observed values therefore each index that comprises the cpm is penalized by multiplying the unweighted fbpm for each class interval to account for the time mismatch between the observed and forecasted values 2 cpm i 1 nc w i g j i i j f i m o i the variable i i j refers to index j obtained using on forecasted and observed time series values within the class interval i the function g j refers to a transformation function for each index j that is used to normalize the i i j values between 0 and 1 for ease in comparison across the classes and indices the normalization process adopted for different indices of cpm is discussed at length in section 2 3 2 2 the weight w i associated with each class interval needs to be assigned by the user with a condition of i 1 nc w i 1 five class based indices i i j j 1 5 are aggregated using equation 2 for cpm computation and they are variance index vi interquartile range index iqri correlation index ci the bounded relative absolute error index braei and the kolmogorov smirnov index ksi these indices are derived using equations 3 7 the ksi uses a ks test statistic value to evaluate the similarity of the two probability distributions based on observed and forecasted values in a class 2 3 1 2 indices of cpm the variance index vi is defined by equation 3 the variables s i f and s i o in equation 3 refer to standard deviation obtained using time matched forecasted and observed data respectively in class interval i 3 i i j vi i j s i f 2 s i o 2 i j 1 the interquartile range index iqri is defined by equation 4 the variables iqr i f and iqr i o in equation 4 refer to interquartile range values obtained using time matched forecasted and observed data respectively in class interval i 4 i i j iqri i j iqr i f iqr i o i j 2 the correlation index ci is defined by equation 5 the variables ρ i f and ρ i o in equation 5 refer to the pearson correlation coefficient obtained using time matched forecasted and observed data respectively in class interval i 5 i i j ci i j ρ i f ρ i o i j 3 the bounded relative absolute error index braei is defined by equation 6 in general the relative errors provide more intuitive results than percentage errors chen et al 2017 the variables v i f and v i o refer to time matched forecasted derived from model simulations and observed values respectively and nm i is the total number of matched values in the interval i on the other hand e i f is the simulated value obtained from a one step naïve model i e x t x t 1 which is generally used as a benchmark to compare the model errors the braei would ensure that the maximum error is one while the minimum error is zero when v s i f v s i o is equal to zero also braei is well suited for intermittent demand data which have many zero valued observations chen et al 2017 to avoid the issue of being undefined braei is defined to be 0 5 for the special case when v s i f v s i o and e s i f v s i o are both equal to zero chen et al 2017 6 i i j braei i j 1 nm i s 1 nm i v s i f v s i o v s i f v s i o e s i f v s i o i j 4 the kolmogorov smirnov index ksi is defined by equation 7 the ksi is derived based on a two sample unpaired kolmogorov smirnov ks test statistic massey 1951 value obtained for each class interval i based on time matched observed and forecasted values as given by equation 7 this statistic evaluates the difference between the cumulative distribution functions cdfs of the observed f i o x and predicted f i f x datasets in each class interval i the test statistic ksi i j is defined as 7 i i j ksi i j max i f i o x f i f x i j 5 2 3 1 3 normalization of the cpm indices the indices i i j of cpm are normalized using a transformation function g j i i j to obtain numerical values within a specific range 0 1 after normalization of the parameters the best ideal and worst values for each parameter would be 1 and 0 respectively the numerical value of fpbm from equation 1 will be in the range 0 1 wherein a time match between the observed and forecasted frequencies will be denoted by 1 the vi and iqri may originally vary in the range 0 for a perfect model performance the value of vi and iqri should be equal to 1 hence the deviations of vi and iqri from 1 on lower and higher sides are penalized while normalizing them for instance the values of vi and iqri lower than one are subtracted from 1 for normalization and the values of vi and iqri greater than one are normalized using the equations 1 v i i j 1 vi i j and 1 i q r i i j 1 iqri i j respectively such that higher deviations from 1 are penalized heavily the ci may show variations within the range 1 1 hence it is normalized by a linear approximation such that 1 1 corresponds to 0 1 for a perfect model ci should be 1 the variations in braei shall be in the range 0 1 thus in the current context braei is normalized by subtracting their values from 1 such that for a perfect model the normalized braei is 1 the ksi values would range between 0 1 wherein the values close to 0 would indicate the acceptance of the null hypothesis i e distributional similarity exists between observed and simulated datasets hence while normalizing the ksi values are subtracted from 1 such that normalized ksi equal to 1 represents a perfect distributional similarity 2 3 2 assignment of weights the fbpm and cpm are derived by assigning user defined weights to the normalized values of these indices for each class interval the fbpm and cpm values vary between 0 and 1 wherein 1 indicates the best model performance also higher weights may be assigned to lower higher class intervals in case the prime focus of the modeling exercise is to accurately forecast low high flow events equal weights may be assigned for an objective comparison of different models the values of fbpm and indices of cpm for each class interval can be graphically represented using a color coded matrix i e heatmap for visual interpretation of the model performance and multi model comparisons 2 3 3 adjustments to class intervals and widths in many situations hydrologic simulation models predict streamflow values that are larger than the maximum observed streamflows or provide negative streamflow values under such circumstances additional class interval s can be included other than those defined based on the observed data additional class interval s shall have the class edges as the maximum minimum observed and maximum minimum predicted streamflows the upper and lower limits of the forecasted streamflows if falling outside the range of observed streamflows can still be evaluated using these additional class interval s this would require the redistribution of weights as per the revised number of class intervals and the erroneous predictions shall be penalized for multi model comparisons if there are no observed and predicted values in the additional class interval s then no penalty is assigned 2 4 model performance assessment numerical thresholds for measures performance assessment based on a numerical threshold value or a range of values of any error measure e g nse pbias r2 and rsr can serve as valuable guidance for model assessment moriasi et al 2007 2015 guidance on model performance evaluation using numerical values of fbpm and cpm with equal weightage to all classes is recommended as follows unsatisfactory or poor fbpm 0 50 o r c p m 0 35 satisfactory or average 0 50 f b p m 0 60 o r 0 35 c p m 0 50 good 0 60 f b p m 0 70 o r 0 50 c p m 0 60 excellent 0 70 f b p m 1 00 o r 0 60 c p m 1 00 since the fbpm is implicitly incorporated in the computation of cpm the value of cpm would always be equal to or lower than that of fbpm also while interpreting the model performance based on fbpm and cpm values the modelers must ensure that the appropriate model is selected for the intended purpose of modeling the model terminologies parameters and objectives are correctly defined appropriate temporal and spatial scales are chosen and the calibration and validation approaches are pertinently formulated and executed moriasi et al 2015 3 application of the measures the fbpm and cpm are tested for the evaluation of streamflow forecasting models the models are data driven and are developed using the model tree mt technique quinlan 1992 witten and frank 2005 approach for one step ahead prediction these models use the information about lagged daily streamflow values at a target site and a site upstream to the target site and moving averaged values at the target site lagged precipitation values and estimated baseflows the baseflow estimations were obtained using a digital filtering algorithm eckhardt 2005 using the web based hydrograph analysis tool what lim et al 2005 3 1 model tree mt approach a model tree mt quinlan 1992 is a data driven hierarchical approach that characterizes and models the relationship between input and output parameters and represents them using linear models the mt divides the input parameter region into several sub regions and formulates a multi variable linear regression model for each sub region quinlan 1992 witten and frank 2005 mt employs segmented linearization to represent a non linear process jothiprakash and kote 2011 the mt based models show an advancement over the classification and regression tree cart models by incorporating linear regression equations in the leaves as compared to the numeric values in the latter rezaie balf et al 2017 the mt approach has been successfully applied for streamflow forecasting applications solomatine and xue 2004 rezaie balf et al 2017 esmaeilzadeh et al 2017 3 2 case study domain the mt based streamflow forecasting model is developed to predict daily streamflows at the ukai dam in the tapi basin india the tapi basin fig 2 with an area of 65 145 km2 in the west central part of india exhibits heterogeneous physiographic and climatic variability sharma et al 2020 the basin is bounded by mountain ranges on three sides and the arabian sea to its west as shown in fig 2 the mean annual temperature across the basin ranges from 20 7 c to 33 0 c whereas the annual rainfall varies between 550 and 1800 mm the region experiences a typical monsoonal climate wherein around 90 of total rainfall is received between june and september referred to as flood season sharma et al 2020 the ukai dam is the largest reservoir in the basin draining an area of 62 225 km2 with a densely populated urban and industrial center city of surat located downstream of this dam near the arabian sea the city was impacted by severe floods in the years 1994 1998 2006 and 2013 mainly due to large releases made from the ukai dam thus developing and evaluating a streamflow forecasting model for the ukai dam would be critical for flood forecasting and reservoir operations the daily inflows to the ukai dam for the period 1975 2013 were obtained from the ukai civil circle ukai government of gujarat india the daily streamflows at gidhade stream gauging station shown in fig 2 upstream of the ukai dam for the concurrent period were collected from the tapi division central water commission cwc government of india the daily rainfall data at forty nine rain gauges located upstream of the ukai dam shown in fig 2 were collected from india meteorological department imd pune india these data were used for the development of a streamflow forecasting model for the ukai dam using the model tree mt technique sharma et al 2021 3 3 mt based forecasting models three mt based models referred to as models a b and c based on different hydrological input variables are chosen to evaluate the applications of the proposed performance measures in evaluating models the models are calibrated and validated using the observed streamflow data at the ukai dam for the period 1975 2013 the models are developed for forecasting monsoon season june to september streamflows into the ukai reservoir the calibration and validation datasets are for the periods 1975 2005 and 2006 2013 respectively since the data length is sufficient to develop and evaluate the model exhaustive cross validation is not performed in model development the daily streamflow at two sites i e the target site and the upstream site lumped rainfall up to the target site computed baseflow values and moving averaged streamflows at the target site are used as inputs to the model the locations of the target site i e ukai dam where the forecasts of streamflows are required and the upstream site i e gidhade are shown in fig 2 the mean areal precipitation is derived using the thiessen polygon approach based on precipitation values from all the rain gauges in the tapi river basin that are located upstream of the ukai dam model a in this model the lagged values of streamflows q t 1 o q t 2 o in time intervals t 1 and t 2 at the target site are used to predict flows q t p in the time interval t the functional relationship specifying model a is given by equation 8 8 q t p f q t 1 o q t 2 o t model b in this model lagged values p t 1 o p t 2 o p t 3 o in time intervals t 1 and t 2 at the target site are used to predict flows q t p in the time interval t the functional relationship specifying model b is given by equation 9 9 q t p f p t 1 o p t 2 o p t 3 o t model c this model uses three types of input variables and they are two lagged values q t 1 o q t 2 o of streamflows at the target site estimated baseflows b q t 1 o bq t 2 o at the target site and streamflows q u t 1 o q u t 2 o at an upstream site in time intervals t 1 and t 2 respectively in addition to these variables moving averaged three and five day streamflows q mv 3 o q mv 5 o at the target site are used to predict flows q t p in the time interval t the functional relationship between these variables and predicted flows in model c is given by equation 10 10 q t p f q t 1 o q t 2 o q u t 1 o q u t 2 o b q t 1 o bq t 2 o q mv 3 o q mv 5 o t the moving averaged flow value q mv m t o for mt intervals is obtained using equation 11 11 q mv m t o l 1 mt q mt t l o mt m t t 1 3 4 test datasets in addition to evaluations of performances of three mt based models i e model a b and c two hypothetical or synthetic datasets consisting of observed and forecasted streamflows are used for assessment the two synthetic datasets developed are 1 real world observed streamflows and forecasted flows derived from modified observed flows and 2 hypothetical forecasted and observed datasets the forecasted values for the first test dataset are derived by modifying the observed streamflows at the ukai dam to demonstrate the applicability of these measures on a range of model evaluation scenarios that are likely to be encountered by the modelers however there is no restriction on the usage of a particular dataset this dataset is hereafter referred to as a synthetic dataset consisting of five scenarios referred to as s1 s2 s3 s4 and s5 the second dataset referred to as hydrotest dataset is obtained from https hydrotest org uk benchmarks html this dataset with four forecast scenarios referred to as h1 h2 h3 and h4 is publicly available for modelers to evaluate different error and performance measures since these two datasets use hypothetical forecasts that are assumed to be generated by forecasting models the scenarios are referred to as models s1 s2 s3 s4 and s5 and models h1 h2 h3 and h4 to be consistent with the notation used for mt based models a b and c in this study in addition hypothetical datasets refer to supplementary material demonstrating exceptional cases with a lower sample size i e 16 and skewed data distribution are evaluated to prove that the proposed measure is outlier resistant and accounts for inconsistencies in data distribution 4 results and analysis the utility of several data classification methods is initially evaluated for partitioning the randomly generated data samples of different probability distributions i e normal and skewed distributions the fbpm and cpm measures are then evaluated using forecasts from different models and datasets described in sections 3 3 and 3 4 improvements in the model forecasts are evaluated when post forecast corrections are used to address erroneous model predictions 4 1 data partitioning approaches the data partitioning methods are applied for deriving class edges corresponding to each class interval for a given dataset for an exhaustive comparison of performances of these methods four randomly generated data samples with 1000 values that characterize different distributions are used data that follows a gaussian distribution is generated with the location μ scale σ skewness γ and kurtosis β2 parameter values of 100 1 0 and 3 respectively another dataset following uniform distribution is generated with observations in the range 97 103 further two skewed distributions viz positively and negatively skewed are generated with μ σ γ and β2 parameters values of 100 1 1 and 3 and 100 1 1 and 3 respectively twelve bins for these datasets derived using sturges s rule were used in the partitioning approaches the corresponding class edges for each bin determined by different partitioning methods are shown in figs 3 5 it can be noted from figs 3 5 that the equal interval classification results in higher frequencies in the central class intervals while the starting and the ending bins have very few values the k means clustering and natural breaks methods attempt to divide the central values having higher frequencies into a greater number of classes however the geometric interval and quantile methods achieve finer discretization in dense data ranges as compared to other methods the quantile method results in equiprobable class intervals i e all the intervals have an almost equal number of data points the interquartile range method requires prior information about the underlying distribution of the data and the data division is user specific in the case of the gaussian distribution higher frequencies are concentrated between the interquartile range i e 25th and 75th percentiles therefore this data range is divided into a greater number of classes i e eight classes in this case while the values greater lower than the upper lower quartiles are divided into two classes each the equal interval classification fig 3 a 4 a and 5 a method performs poorly for skewed datasets compared to the normally distributed datasets in the case of positively negatively skewed datasets the equal interval classification would result in fewer values in higher lower class intervals in the case of skewed datasets higher frequencies are concentrated in the start or end bins hence finer discretization is required in those data ranges the k means fig 3 b 4 b and 5 b and natural breaks fig 3 c 4 c and 5 c methods produce comparatively fewer numbers of classes in those data ranges than geometric interval fig 3 d 4 d and 5 d quantile fig 3 e 4 e and 5 e and interquartile range fig 3 f 4 f and 5 f methods the interquartile range method divides data that is lesser greater than the lower upper quartile in finer classes in the case of a positively negatively skewed dataset the number of divisions required in these data ranges is user specific and problem dependent on the other hand all the methods have shown comparable performance for uniformly distributed data in hydrologic time series analysis positively skewed data e g daily streamflow and rainfall and data with near gaussian distribution such as daily temperature and evaporation are usually encountered the uniformly distributed and negatively skewed datasets are uncommon the geometric interval quantile natural breaks and quantile methods are better suited to classify skewed and normally distributed datasets in real world applications the class edges for the observed streamflows at the ukai dam derived using all the methods considering ten class intervals are derived and are provided in table 1 the class edges corresponding to ten class intervals for synthetic and hydrotest datasets estimated using four methods are provided in table 2 4 2 evaluation of models and test cases the summary statistics of the real world synthetic and hydrotest datasets are provided in table 3 the developed performance measures are applied to analyze the prediction accuracy of test datasets from real world models and synthetic time series the results of the assessment of model accuracy through error and performance indices and the developed performance measures fbpm and cpm are provided in tables 4 and 5 respectively 4 2 1 model tree based forecasting models the mt based streamflow forecasting models are developed to predict one day ahead streamflows at the ukai dam the streamflow data is partitioned into several classes to facilitate the classification of different streamflow regimes the classes 1 3 4 7 and 8 10 represent low moderate and high flow conditions respectively based on geometrical interval classification also the limits of classes 3 and 8 which represent low and high flow thresholds correspond to 33rd and 90th percentile streamflows respectively alternatively the flow conditions can also be defined and associated class intervals be identified such that observed streamflows 10th percentile between 10th 90th percentile and greater than 90th percentile threshold values correspond to low medium and high flow conditions respectively similar to those utilized by united states geological survey usgs https waterdata usgs gov nwis rt the selection of input variables for these data driven models was carried out using autocorrelation partial autocorrelation average mutual information and the false nearest neighbor criterion sharma et al 2021 based on the combination of input variables several candidate models were formulated and analyzed using multiple error and performance indices out of these candidate models three models viz model a model b and model c described in section 3 3 are used to derive forecasts and the performances of these models are evaluated using fbpm and cpm the nse values derived for models a b and c are 0 70 0 58 and 0 94 respectively in the calibration phase however in this experiment the validation data of the models a b and c are analyzed in detail the observed and forecasted streamflows for these models are shown in fig 6 from fig 6 a b model a is noted to overpredict the low and moderate flows while underpredicting the high flows model b is found to consistently underpredict all flow ranges fig 6 c d whereas simulation results from model c show good agreement between observed and simulated streamflows fig 6 e f error and performance measures derived based on models a b and c are provided in table 4 relatively lower values of error measures i e rmse rae mare and mre and higher values of efficiency measures e g r2 nse and kge are noted for model c compared to models a and b model c uses additional information in terms of streamflow at an upstream gauge computed base flow and moving average streamflow as compared to models a and b this additional information has led to an improvement in the forecasts by effectively capturing the variability of the physical processes generating streamflow in the basin however model c is not effective in modeling the low flows the linear regression models generated in the mt approach include a positive constant term which leads to an overestimation of the observations with zero values visual assessment through time series and scatter plots fig 6 e f may specify some of these issues related to the performances of the models however the quantitative evaluations using single valued error and performance measures table 4 do not provide a comprehensive assessment of the models most of the performance measures provided in table 4 suggest the sensitivity of model performances to moderate and high flows while the errors associated with low flows are not highlighted hence there is a need for careful assessment of the prediction models to effectively capture the model performance across all streamflow regimes the fbpm and cpm can help overcome such shortcomings of existing error and performance measures the observed streamflow dataset shows a higher skewness γ 6 3 and variability coefficient of variability 5 14 flow range 0 29 046 m3 s the observed streamflow data follows a positively skewed distribution as shown in fig 4 the class edges derived using different approaches considering ten bins based on sturge s rule are provided in table 1 as indicated earlier the data classification using geometric interval natural breaks quantile and interquartile range approaches are more suited for skewed data however due to the large number of zero observations in the dataset the quantile method fails to assign values to the first class interval refer to table 1 use of natural breaks method resulted in intervals with higher class edges when compared to the geometric interval and interquartile range methods in the current study the user defined approach that classifies the streamflows based on the return periods is also initially assessed the annual maximum streamflow for ukai dam 1975 2013 is fitted with a generalized extreme value gev distribution using the maximum likelihood estimation mle method to obtain distribution specific parameters for deriving streamflow magnitudes corresponding to different return periods however this approach is only suitable to assess the predictive performance of models developed for simulation of peak discharges overall the geometric interval approach resulted in the finer discretization of classes for data range with higher densities compared to other methods the fbpm and cpm are employed to analyze the model performances considering ten class intervals using all classification methods however results derived using geometric interval classification are discussed further based on the geometric interval classification models a and b exhibit poor performance across most class intervals particularly the low and high flow classes as shown in fig 7 a and b on the other hand model c shows better performance in predicting the moderate and high flows as shown in fig 7 c model c is unable to estimate the low flows accurately which is mainly attributed to over estimation by the mt model this shortcoming of model c is not effectively captured by the statistical error and performance indices described in table 4 these indices such as rmse mae r2 and nse indicate better model performance in predicting moderate and high flows which confirm the results of the proposed approach similarly the k means clustering natural breaks and quantile methods have also been used to derive the fbpm and cpm values for these models which are provided in table 5 from table 5 it can be noted that model c outperforms models a and b in terms of higher fbpm scores for all data classification methods considering equal weights to each class interval the fbpm values for models a and b are lower than 0 5 which indicates unsatisfactory model performance whereas model c shows satisfactory model performance i e 0 50 fbpm 0 60 for all data classification schemes overall the cpm values for model c are reportedly lower than the fbpm values however they are within the acceptable range 4 2 2 synthetic datasets in this experiment the observed streamflows q t o at ukai dam that are lower higher than 33rd percentile q33 90th percentile q90 are considered as low high flows whereas the streamflows ranging between q33 and q90 are denoted as moderate flows the observed dataset is synthetically modified to generate five different scenarios of simulated flows these model scenarios are referred to as models s1 s2 s3 s4 and s5 and they are defined as model s1 the daily observed streamflows are lagged by two days and lowered by a factor ranging between 0 95 and 0 99 to derive the simulated streamflows as shown in fig 8 a b model s2 the low flows i e q t o q33 are well predicted within an accuracy between 95 and 99 while the streamflows higher than q33 are lowered by a factor ranging between 0 5 and 0 75 to depict that moderate and high flows are underpredicted as shown in fig 8 c d model s3 the high flows i e q t o q90 are well modeled within an accuracy range of 95 99 while the low and moderate flows are overpredicted by a factor ranging between 1 5 and 2 as shown in fig 8 e f model s4 the moderate flows i e q33 q t o q90 are fairly predicted within an accuracy range of 95 99 while the low and high flows are overpredicted and underpredicted respectively as shown in fig 8 g h model s5 the simulated streamflows are predicted within the range of 95 99 of the observed flows as shown in fig 8 i j the observed streamflows at ukai dam are modified to generate simulated synthetic datasets representing various scenarios viz persistent lagged flow model low flow model high flow model moderate flow model and ideal model the synthetic datasets are positively skewed with lower variability compared to the previous dataset table 3 sturge s rule suggests ten bins to classify the data the geometric interval classification has yielded finer discretization of data with higher densities as compared to other methods the error and performance measures computed and provided in table 4 for these models suggest higher prediction accuracy for model s5 as compared to other models whereas model s1 performs poorly model s4 performs better than models s2 and s3 when error and performance measures are compared fbpm and cpm values for these models are provided in table 5 and are visualized as heatmaps shown in fig 9 it is evident from fig 9 a that model s1 performs poorly in the prediction of streamflows across all class intervals model s2 shows better performance for low flows while underpredicting the moderate and high flows significantly which results in poor performance in those intervals fig 9 b the model s3 shows better accuracy in predicting high flows than low and moderate flows which are overpredicted fig 9 c model s4 performs better in the prediction of moderate flows while low and high flows are not accurately mapped fig 9 d the model s5 results show superior performance across all streamflow classes fig 9 e from table 5 the fbpm and cpm values suggest the superior performance of the model s5 for all methods considering equal weights the fbpm and cpm values for model s4 reflect its better prediction accuracy than models s1 s2 and s3 the model s4 performs exceedingly well for moderate flows i e class intervals 4 7 while the model performance for low flow events is average the model s1 the persistence model is the worst performing model since the lag effect leads to inaccurate time matching the fbpm and cpm values indicate unsatisfactory performance for the models s1 s2 and s3 on the other hand the performance of models s4 and s5 are interpreted as good and excellent respectively the fbpm and cpm effectively characterize the performances of models across all classes and provide an objective comparison of different models the visual assessments through heatmaps are beneficial to identify the model deficiencies i e inability to capture low high flows and enable multi model comparison across various streamflow regimes for instance a heatmap based evaluation may point to a specific hydrological model s poor prediction performance in those class intervals that define flow extremes this reflects the inability of the model to effectively predict the hydrograph peaks which would suggest the modeler re calibrate the model parameters associated with high flow conditions the conventional performance measures do not provide such specific and comprehensive information 4 2 3 hydrotest datasets the hydrotest dataset differs from the synthetic dataset discussed in section 4 2 2 the former dataset is characterized by lower streamflow variability and rather uniform distribution whereas the latter suggests a higher streamflow variability and positively skewed distribution with a considerable number of zero observations the hydrotest benchmark datasets represent four scenarios and they are denoted as models h1 h2 h3 and h4 model h1 this model is referred to as a naïve model wherein the model predicts the observed data from six previous time steps without any change in its magnitudes as shown in fig 10 a b model h2 this model simulates the low flow events better however the high flow events are underpredicted as shown in fig 10 c d model h3 this model is termed as a noisy model in which the observed flows are reasonably well overall but are consistently over or under predicted by 15 as shown in fig 10 e f model h4 this model predicts the high flow events better however the low flow events are not simulated properly as shown in fig 10 g h the hydrotest dataset represents streamflow conditions with low variability skewness and kurtosis but higher persistence evident from lag one autocorrelation table 3 the sample size of the hydrotest data n 160 is also relatively smaller than previous datasets the variations of the observed data produce four different scenarios viz the naïve model persistence model low flow model noisy model irregular fluctuations and high flow model the noisy model as extreme test case is included in the current study to demonstrate the utility of measures developed in this study ten class intervals are used for consistency of analysis even though sturge s rule recommended eleven bins for this dataset all the methods of the classification resulted in almost similar class edges table 2 the error and performance measures table 4 suggest that model h1 results in lower values of rmse mre and msle and higher values of nse and kge whereas the noisy model h3 results in lower me r4ms4e mre msre values compared to other models therefore the error and performance measures can be misleading in evaluating these model performances despite knowing their inherent limitations the data partitioning based measure is applied to hydrotest dataset and their results are shown in table 5 and fig 11 it is evident from fig 11 a that model h1 shows inconsistent performance across all classes wherein the fbpm and cpm reflect lower values across most classes model h2 predicts the low and moderate flow events with perfect accuracy however the high flow events are under predicted fig 11 b model d shows a better prediction of high flow events whereas the low and moderate flows are poorly predicted fig 11 d the proposed approach highlights the erratic characteristics of model c which shows the worst performance fig 11 c whereas the interpretations of the statistical performance indices to assess the model performances are misleading this shows the superiority of the proposed approach in terms of statistical and visual assessment of the model performance the fbpm and cpm values also suggest that model b is the best model amongst the hydrotest datasets while model c is the worst performing model table 5 the performance evaluation criteria suggest that the models h1 h3 and h4 show unsatisfactory performance while model h2 reflects good and excellent performance based on fbpm and cpm values respectively for all data classification schemes from table 5 it can be noted that the classification method chosen may affect the numerical value of the measure that quantifies the model performance and not the model performance itself the class bin range values for different classification methods vary and these partitions in data will determine how many observed and forecasted values fall into these classes as the bin widths are different the number of classes and bin widths class intervals will eventually affect the numerical value of the performance measure but not the general assessment of the model performance 4 2 4 hypothetical dataset with an exceptional case a hypothetical dataset representing an exceptional case which is less likely to be encountered in real world modeling studies of a smaller sample size i e 16 partitioned into two class intervals yielding a highly skewed distribution of data is evaluated in this scenario a fewer number of observed and predicted values in a particular class interval exhibit do not exhibit a perfect time match which is represented as case 1 case 2 and as shown in figs s1 and s2 of the supplementary material the analyses reveal that partitioning the data into fewer i e two class intervals tends to inflate the fbpm value for case 1 fbpm 0 73 and suggests a better model performance as compared to case 2 fbpm 0 22 on the other hand the cpm values for case 1 and 2 are found to be 0 30 and 0 17 respectively which suggests a poor model performance in both cases however the sensitivity of fbpm does not indicate its drawback but rather it points towards inappropriate application of the measure as per sturges s rule the minimum number of bins obtained for the given sample size is five the fbpm values for case 1 and 2 considering ci 5 are found to be 0 33 and 0 13 respectively which indicates a poor model performance thus inappropriate data partitioning i e too few or too large a number of bins would undermine the effectiveness of fbpm in evaluating model performance three additional cases are also generated i e case 3 4 and 5 by introducing outliers in observed and predicted datasets as shown in figures s3 to s5 of the supplementary material the presence of an outlier inflates the values of conventional error and performance measures such as rmse r2 mae nse and others table s1 while the fbpm and cpm measures change minimally table s2 these experiments suggest that fbpm and cpm measures are resistant to outliers and they do not inflate the model performance unlike other performance indices additional details of these experiments are provided in the supplementary material 4 2 5 sensitivity of fbpm and cpm to the number of class intervals the number of bins for data partitioning approaches can be defined using different methods however in this study sturges s rule for estimation of the number of bins based on data sample size is used to assess the sensitivity of fbpm and cpm values to the number of class intervals performances of models a b and c are evaluated considering five ten fifteen and twenty classes the variations in fbpm and cpm values for these model configurations considering geometric interval classification and equal class weights are shown in fig 12 it can be noted from fig 12 the fbpm and cpm values decrease with an increase in the number of class intervals model c shows superior performance for all the class intervals a fewer number of classes may lead to a greater number of data points within these class intervals leading to higher fbpm and cpm values on the other hand the increase in the number of classes sometimes results in fewer observations in certain class intervals which is responsible for lower values of fbpm and cpm the variations in fpbm and cpm values with changes in the number of class intervals do not alter the results of the inter model performance comparisons for instance model b shows poor performance than models a and c irrespective of the number of class intervals increasing the number of class intervals may occasionally lead to empty class intervals i e classes with no data which may affect the model evaluation using fbpm and cpm 4 2 6 sensitivity of fbpm and cpm to assigned weights user defined weights are attached to the class intervals in fbpm and cpm based on the intended purpose of the model application to ascertain the influence of weights on the model performance evaluation a comparison of results of all the models corresponding to ten class intervals derived using the geometric interval method is performed under this investigation four different scenarios are considered initially all the classes are assigned equal weights and thereafter more weights are assigned to low moderate and high flow classes subsequently from fig 13 minor variations in the fbpm and cpm values are evident for a particular model for different weight scenarios however the assigned weights do not change the results of inter model performance comparisons for instance model c shows superior performance for all weightage scenarios as compared to models a and b fig 13 as discussed in section 4 2 2 model s2 predicts low flow with better accuracy hence higher fbpm and cpm values are observed when low flows are given more importance weightage similarly the models s3 and s4 show better performance in the prediction of high and moderate flows respectively thus the importance attached to high and moderate flows for these models results in an improvement in their performance measures the nse value for model s1 is found to be zero however the fbpm and cpm values are not zero the nse 0 indicates a similar model prediction skill as that of the mean flow of the time series however the proposed approach provides an objective assessment of the model performance considering all class ranges and hence the fbpm and cpm values are non zero for model s1 thus the conventional performance measures are unable to assess the deficiencies in the models across all flow ranges whereas fbpm and cpm values provide an objective evaluation of the model performances overall the fbpm and cpm provide flexibility to the user in assigning importance to the flow regimes based on the purpose of modeling for instance the analysis of droughts floods would warrant larger weights being assigned to lower higher classes based on the classification scheme and the number of class intervals adopted 4 3 influence of post forecast corrections model forecasts can be corrected based on information available about hydrological conditions or inherent limitations of the model these post forecast corrections can help in improving erroneous predictions the linear regression model used in the mt based approach has a constant term that results in a forecast of non zero streamflows values as opposed to observed zero values this amplifies the model errors and thereby lowers its predictive performance hence based on the analysis of hydrometeorological processes influencing the streamflow the forecasted value can be corrected to compensate for the limitations of the model forecast corrections are made to simulation results of models a b and c the streamflow observed at ukai dam is influenced by the observed streamflow at an upstream gauge gidhade station and the rainfall between the watershed from gidhade to the ukai dam also the three day moving averaged streamflow q mv 3 o at the ukai dam is additionally considered to make a judgment regarding the post forecast correction therefore based on the values of rainfall p t 1 o observed streamflow at the upstream gauge q u t 1 o and three day moving average flows i e q mv 3 o the predicted streamflow q t p is corrected as q t p using the condition expressed in eq 12 12 if q u t 1 o q mv 3 o a n d p t 1 o 0 t h e n q t p 0 e l s e q t p q t p t the post forecast correction is applied to all the non zero values produced by models a b and c subject to the condition specified in eqn 12 the results from these post forecast corrections show an improvement in the model performance in terms of fbpm and cpm as shown in fig 14 4 4 general remarks comparative evaluations of traditional performance measures such as coefficient of determination r2 index of agreement ioad nash sutcliffe efficiency nse and kling gupta efficiency kge and the fpbm and cpm using results from the twelve models models a c s1 s5 h1 h4 developed in the study are carried out a percentage difference δ based on any traditional performance measure β and fbpm or cpm θ is obtained using equation 13 13 δ β θ θ 100 the r2 ioad nse and kge values on average overestimate the model performance compared to fbpm and cpm by 121 and 284 respectively when twelve models are evaluated in the case of the inferior models a b s1 h1 h3 the r2 ioad nse and kge values overestimate the model performance compared to fbpm and cpm by average 207 and 546 respectively when the best models c s5 and h2 are considered the r2 ioad nse and kge values on averageoverestimate the model performance compared to fbpm and cpm by 15 and 44 respectively the traditional performancemeasures failed to identify the worst performing models the inflation of numerical values from traditional measures i e r2 ioad nse and kge may lead to the inappropriate selection of the best model among a set of competing models the two measures fbpm and cpm developed in this study benefit from dividing the data into several bins class intervals and evaluating the number of observed and predicted values in those partitions an extremely small number of class intervals or observations and predictions in those class intervals and many class intervals with few or no observations and predictions in those intervals will lead to biased and inaccurate performance evaluations when these measures are used since fbpm and cpm are frequency based measures they have similar limitations that plague histograms and statistical goodness of fit hypothesis tests e g chi square goodness of fit test that rely on the use of the appropriate sizes and number of class intervals for accurate assessment of distributions and robust inferences considering these limitations the number of class intervals and sizes of such intervals should be given careful consideration when fbpm and cpm are used for model evaluation for different hydrologic applications accurate assessment of model performance based on numerical values of fbpm and cpm is possible if the parameters such as the number of classes class interval width and weights assigned to each class interval are selected appropriately considering the purpose for which the model is being evaluated modelers can judiciously assign values to these parameters by evaluating the distribution of the observed data adopting the best available guidance in the literature on defining the number of class intervals and selecting equal or best set of unequal class interval widths based on an iterative screening exercise that involves the use of multiple data portioning schemes equal and unequal weights can be assigned to the class intervals the former assignment is simple and objective while the latter is subjective and related to the purpose for which the model is evaluated arbitrary selection of weights should be avoided and rather scientific approaches such as entropy analytical hierarchy process ahp and others may be adopted 5 conclusions a new performance measure frequency based performance measure fbpm that uses a data partitioning approach is developed for the evaluation of hydrologic simulation or forecasting model predictions several new indices are used in conjunction with this measure to devise an additional aggregated measure composite performance measure cpm that evaluates the model performance based on different characteristics of the observed and predicted time series multiple data classification techniques are evaluated to partition the streamflow data for use in the fbpm and cpm performances of multiple model tree based forecasts for a site in the tapi river basin in india and synthetic datasets viz observed and forecasted are assessed using these two measures the geometric interval approach was found to characterize and partition the datasets used in this study better than all the other approaches evaluated the fbpm and cpm provide better assessments of the models performances than single valued performance measures in accurately predicting different streamflow regimes of the tapi river the use of fbpm and cpm for the evaluation of synthetic datasets point to their superiority over the traditional error and performance measures the developed measures allow users to define class intervals and assign weights based on the intended purpose of the modeling and the importance attached to the specific forecasts inaccurate evaluations due to inflated fbpm values are possible when the number of class intervals used is too small to characterize the variability of observed and forecasted values from the models the fbpm and cpm are conceptually simple to derive scale independent resistant to the outlier observations and forecasts informative and can aid in the exhaustive assessment of the performance of a single model or selecting the best among competing models credit authorship contribution statement ramesh s v teegavarapu conceptualization formal analysis methodology writing original draft writing review editing priyank j sharma investigation validation visualization writing review editing prem lal patel data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors thank the developers of waikato environmental for knowledge analysis weka software which was used in this study for the development of the forecasting models the authors also acknowledge the data disseminating agencies viz ukai civil circle cwc and imd india for providing the necessary data to svnit surat and the hydrotest website http hydrotest org uk for providing necessary data to conduct the present study the authors are thankful to the anonymous reviewers for their constructive comments and suggestions data availability the observed daily streamflow data for the ukai reservoir and gidhade gauging station are collected from the ukai civil circle ukai and tapi division central water commission cwc surat india respectively the rainfall data of the tapi basin is collected from the india meteorological department imd pune the benchmark test datasets for streamflow are downloaded from the hydrotest website https hydrotest org uk benchmarks html appendix the mathematical formulations of different error and performance measures along with their advantages and limitations are discussed in table a 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 127583 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3459,the composition of suspended particles is a key factor in determining the underwater light field which is of great significance for understanding the variability in the optical properties of water bodies in this study the ratio of the phytoplankton absorption coefficient to the backscattering coefficient at wavelength of 681 nm aph 681 bb 681 was found to be an optimal optical indicator of the ratio of chlorophyll a to the total suspended matter concentration chla tsm a parameter indicating the particulate composition therefore a semianalytical algorithm was proposed to estimate chla tsm from remote sensing reflectance rrs λ at 681 nm and 754 nm on sentinel 3 ocean and land color instrument olci images the validation dataset collected from 11 inland lakes and 3 reservoirs in china and 2 inland lakes in america was used to evaluate the algorithm s performance the evaluation results demonstrated that the proposed algorithm could have favorable performance in inland waters furthermore comparison with two other state of the art algorithms sun 13 and ntd675 showed that this proposed algorithm had higher estimation accuracy with an overall winning rate owr of 60 an unbiased mean absolute percentage error umape reduction from 72 95 to 46 44 a root mean square error rmse decline from 1 42 µg mg to 0 83 µg mg and a normalized root mean square error nrmse decline from 11 36 to 6 62 this algorithm was successfully applied to acquire the chla tsm tempo spatial variation using the olci images of lake taihu from 2016 to 2019 it was found that the algorithm developed based on olci images can be applied to satellite sensors with similar bands such as medium resolution imaging spectrometer meris and sentinel 2 multispectral instrument msi etc as a simple and effective algorithm the proposed algorithm has the potential to monitor changes in chla tsm in inland waters on a global scale keywords optical indicator chla tsm remote sensing reflectance tempo spatial variation band setting 1 introduction total suspended matter tsm see table 1 for abbreviations and definitions is an essential biogeochemical parameter in inland waters that can affect lake material circulation and ecosystems cao et al 2017 volpe et al 2011 williamson and crawford 2011 suspended particles in lakes generally include organic and inorganic suspended matter organic suspended matter osm the primary light absorbing substance in lakes mainly includes phytoplankton bacteria and detritus from biological decomposition liu et al 2019 as the main scattering material inorganic suspended matter ism is mainly composed of mineral particles such as sand silt and clay kratzer et al 2020 the particulate composition i e the proportion of osm and ism was often closely related to particle size refractive index and particulate backscattering ratio loisel et al 2007 whitmire et al 2007 in the case of high ism and low osm in particles sediments tend to resuspension lei et al 2020 ism which is usually tiny carries much more toxic and harmful chemical substances on its surface through adsorption and acts as a carrier to contribute to the migration and transformation of pollutants in the water environment howard 2010 furthermore biochemical degradation of osm causes a large amount of oxygen consumption and deterioration of water quality paerl et al 2011 therefore particulate composition information plays a vital role in the variation in the underwater light field and could be used to indicate the erosion and deposition processes primary biomass production and transportation of nutrients and heavy metals bilotta and brazier 2008 liu et al 2019 in previous studies two types of indicators were widely adopted to characterize particulate composition one type was the percentage of the concentrations of different particulate matter such as the ratio of particulate organic carbon poc to tsm poc tsm woźniak et al 2010 the proportion of poc to the sum of poc and particulate inorganic carbon poc poc pic neukermans et al 2012 and the ratio of chlorophyll a chla to tsm chla tsm sun et al 2017 sun et al 2013 which have been successfully applied to characterize the particulate composition with the continuous development of remote sensing technology cao et al 2017 dall olmo et al 2003 xu et al 2020 researches on the remote sensing estimation of particulate composition in water have been conducted compared with parameters such as poc and pic the optical signals of chla and tsm are stronger and easier to capture by satellite sensors therefore it is appropriate to estimate chla tsm to characterize particulate composition chla tsm representing the proportion of phytoplankton in particulate matter determines the change of refractive index thereby directly affecting the underwater light field sun et al 2013 xue et al 2020 changes in the underwater light field would lead to changes in primary productivity kostadinov et al 2012 sathyendranath et al 2017 furthermore the variations of chla tsm could reflect the process of eutrophication which can be used to indicate the possibility of algal blooms to a certain extent binding et al 2012 xue et al 2020 a simple approach is to derive first the concentrations of different types of particles using a developed algorithm and then the proportion of particulate composition is calculated based on the estimated concentration xue et al 2020 estimated chla and tsm separately based on the semianalytical algorithm and finally obtained the chla tsm inversion results of the middle and lower reaches of the yangtze river and the huaihe river basin however the uncertainty and instability of estimating each component concentration may lead to significant error propagation for deriving the particulate composition lee et al 2010 pahlevan et al 2019 therefore it is an optimal method to directly estimate proxy parameters such as chla tsm to characterize particulate composition normalized trough depth at 675 nm ntd675 was proposed to differentiate organic matter dominated from inorganic matter dominated based on remote sensing reflectance rrs λ sun et al 2012 thereafter due to the significant correlation between chla tsm and ntd675 this index was applied to empirically estimate chla tsm xue et al 2020 sun et al 2013 developed the relationship between chla tsm and rrs λ based on a three band chla estimation algorithm and a near infrared band based tsm estimating algorithm for turbid inland waters denoted as sun 13 due to the applicability of the assumptions of three band chla estimation algorithm and the tsm algorithm in different waters le et al 2009 yu et al 2019 the estimation performance may not be robust under a wide range of chla tsm the other type is to characterize the particulate composition using optical properties the backscattering ratio provided an estimate of the refractive index of particles in the ocean allowing us to distinguish organic matter dominated from inorganic matter dominated particles twardowski et al 2001 the backscattering ratio was negatively correlated with chla tsm in the eastern english channel and southern north sea loisel et al 2007 there was a significant negative correlation between particulate backscattering ratio and the ratio of the phytoplankton absorption coefficient to the particulate attenuation coefficient in the mid atlantic bight where a low ratio was indicative of a relatively low concentration of phytoplankton and a rather significant contribution from inorganic matter boss et al 2004 compared with the percentage of the concentration of two different particles the optical proxy parameters are more directly obtained from rrs λ therefore it is an excellent choice to use optical proxy parameters to characterize the particulate composition however due to the differences in the optical characteristics of ocean and inland waters the above optical proxy parameters might fail in an environment dominated by detrital materials boss et al 2004 satellite data such as sentinel 3 ocean and land color instrument olci moderate resolution imaging spectroradiometer modis medium resolution imaging spectrometer meris visible infrared imaging radiometer suite viirs geostationary ocean color imager goci sentinel 2 multispectral instrument msi and landsat 8 operational land imager oli have been widely used for water quality dynamic monitoring guan et al 2020 huang et al 2015 huang et al 2019 shi et al 2019b warren et al 2019 yu et al 2019 it is an effective way to monitor large medium and small lake environments and reveal the pattern of water quality changes in the entire region by combining various sensors with different spatial resolutions spectral resolutions and temporal resolutions therefore a suitable algorithm is expected to be applicable for more sensors consequently the purpose of this study was to 1 propose a chla tsm semianalytical algorithm that can be widely used to inland waters with broad varying optical properties 2 evaluate the robustness of the proposed algorithm and compare it with two other algorithms using an in situ dataset 3 apply the proposed algorithm to olci images in inland waters and 4 evaluate the algorithm accuracy applied to other satellite sensors 2 data and methods 2 1 in situ datasets two datasets were employed in this study for algorithm development and validation including an in situ dataset of inland lakes in china and the great lakes environmental research laboratory dataset glerl dataset the distribution of the two datasets is presented in fig 1 2 1 1 in situ data of inland waters in china the in situ data of inland lakes in china were collected from 14 water bodies including 11 lakes lake chaohu lake hongze lake taihu lake erhai lake dianchi lake hengshui lake gehu lake shijiu lake nanyi lake hulun and lake gaoyou and 3 reservoirs qiandaohu reservoir gangnan reservoir and huangbizhuang reservoir during each cruise the distance between different sampling points was about 3 km and ensured that the sampling points were far away from the shore during the cruising of these 14 water bodies a total of 1002 rrs λ were gathered using a fieldspec spectroradiometer analytical spectra devices inc usa ranging from 350 nm to 1050 nm with an interval of 1 nm details of measurement and calculation of rrs λ could be found in lei et al 2019 and the surface water was brought back for laboratory analysis in the laboratory chla was extracted with ethanol and then analyzed using a spectrophotometer parsons 1984 tsm ism and osm were measured using the weighing method based on standard protocols apha 1998 the absorption coefficient of phytoplankton aph λ nonalgal particulate matter ad λ and color dissolved organic matter ag λ was also determined with the quantitative filter technique cleveland and weidemann 1993 mitchell et al 2014 the number of samples taken for each water body and the sampling date are listed in table 2 furthermore these 1002 samples were randomly divided into two parts a subset of 668 samples was used to develop an algorithm and the remaining part contained 334 samples for algorithm validation see table 3 2 1 2 glerl dataset the great lakes environmental research laboratory provided the glerl dataset and this project was designed for in situ measurement and continuous real time observation of western lake erie and saginaw bay of lake huron https www glerl noaa gov res habs and hypoxia habsmon html focused on the observation of the size movement and toxicity of harmful algal blooms habs since 2012 from may to october each year physical chemical and biological data have been collected through repeated site sampling once a week before during and after the hab event cooperative institute for great lakes research 2019 the distance between several monitoring sites was greater than 3 km and the distance to the shore was greater than 300 m due to the lack of measured rrs λ the measured chla and tsm were adopted to validate the algorithm finally a total of 112 match up pairs of olci images and in situ measured chla and tsm were selected from the glerl dataset 2 2 satellite images data olci is a watercolor sensor mounted on sentinel 3a and 3b satellites https scihub copernicus eu there are 21 bands in the 400 1020 nm spectral range with a high signal to noise ratio at a spatial resolution of 300 m donlon et al 2012 after removing the images with clouds and sunglint 120 olci images of lake taihu from may 2016 to december 2019 were acquired the management unit of the north seas mathematical model mumm which has been proven to perform well in inland waters bi et al 2018 ruddick et al 2000 xu et al 2020 was applied to perform atmospheric correction on olci images a total of 211 match up pairs of olci derived and in situ measured rrs λ from five lakes and one reservoir lake taihu lake chaohu lake shijiu lake hongze lake hulun huangbizhuang reservoir were used to validate the atmospheric correction accuracy in inland waters the measured remote sensing reflectance at sentinel 3 bands was calculated using the sentinel 3 spectral response functions last the presence of algal blooms also causes uncertainty in estimating results using satellite images xue et al 2019b therefore according to the olci band setting the virtual baseline floating macroalgae height vb fah index which forms a virtual baseline using the green and red bands to identify the algal bloom effectively was adopted to mask the blooming area on olci images xing and hu 2016 the in situ measured rrs λ were used to simulate spectra of meris goci viirs modis msi and oli bands according to their spectral response functions and simulated spectra and in situ measured values were adopted to evaluate the accuracy of the algorithm applied to other satellite sensors additionally taking the olci and sentinel 2 msi images in lake taihu on november 15 2019 as an example the applicability of the algorithm on different sensors was further validated by comparing the spatial distribution of the obtained chla tsm from various sensors 2 3 algorithms for particulate composition retrievals 2 3 1 development of a semianalytical algorithm for particulate composition a significant positive correlation between chla and aph λ was found in some studies bricaud et al 2004 wozniak et al 2011 and a significant positive correlation between tsm and the total backscattering coefficient bb λ was also observed wozniak et al 2018 woźniak et al 2010 therefore theoretically the aph λ bb λ ratio must have a significant correlation with chla tsm consequently the aph λ bb λ ratio was finally used to indicate chla tsm here according to the water radiative transfer theory numerous studies have proven the relationship between rrs λ and inherent optical properties gordon et al 1988 huang et al 2019 lee et al 2002 lee et al 1999 liu et al 2019 as shown in eqs 1 to 3 1 r rs λ r rs λ 0 52 1 7 r rs λ 2 u λ b b λ a λ b b λ 3 u λ g 0 g 0 2 4 g 1 r rs λ 1 2 2 g 1 where rrs λ is the rrs λ just beneath the water surface a λ is the total absorption coefficient of water constituents and pure water bb λ is the total backscattering coefficient g0 0 084 and g1 0 17 which were suggested for inland waters huang et al 2019 lee et al 2002 the ratio of aph λ bb λ needs to be separated by using the reciprocal of u λ shown in eq 4 4 1 u λ 1 a ph λ 1 a d λ 1 a g λ 1 a w λ 1 b b λ 1 b b λ 1 where aph λ1 ad λ1 ag λ1 and aw λ1 are the absorption coefficients of phytoplankton nonalgal particulate matter color dissolved organic matter and pure water at wavelength λ1 respectively λ1 is the first spectral region selected where ag λ1 could be ignored the measured data showed that when λ1 was greater than 650 nm the average value of ag λ1 was 0 011 which can be ignored compared to aph λ1 and ad λ1 therefore the selection range of λ1 was greater than 650 nm to minimize the influence of 1 bb λ in eq 4 a wavelength λ2 where aph λ2 and ag λ2 could be ignored was selected considering the decrease in aph λ rottgers et al 2014 xue et al 2019a λ2 was determined beyond 700 nm the specific formula is shown in eq 5 5 1 u λ 2 a w λ 2 b b λ 2 1 a d λ 2 b b λ 2 to separate aph λ bb λ and minimize the influence of 1 bb λ in eq 4 and eq 5 aw λ2 was multiplied to eq 4 and aw λ1 was multiplied to eq 5 6 a w λ 2 u λ 1 a w λ 2 a ph λ 1 b b λ 1 a w λ 2 a w λ 1 b b λ 1 a w λ 2 1 a d λ 1 b b λ 1 7 a w λ 1 u λ 2 a w λ 1 a w λ 2 b b λ 2 a w λ 1 1 a d λ 2 b b λ 2 then separate aph λ1 bb λ1 by subtracting eq 7 from eq 6 in addition based on the assumption that bb λ1 bb λ2 gitelson et al 2008 liu et al 2018 the following equation can be obtained 8 a ph λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 1 a d λ 1 b b λ 1 a w λ 1 a w λ 2 1 a d λ 2 b b λ 2 a w λ 1 b b λ 2 a w λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 1 a d λ 1 b b λ 1 a w λ 1 a w λ 2 1 a d λ 2 b b λ 2 furthermore taking λ1 and λ2 at 681 nm and 754 nm respectively the value of 1 ad λ1 bb λ1 in eq 8 was in the range of 1 59 0 15 with a coefficient of variation c v of 9 50 and the value of 1 ad λ2 bb λ2 aw λ1 aw λ2 was in the range of 0 24 0 03 with a c v of 11 54 as a result the value of 1 ad λ2 bb λ2 aw λ1 aw λ2 1 ad λ1 bb λ1 was in the range of 1 35 0 14 with a c v of 10 13 therefore this value can be approximated as a constant c therefore it can be found that there is a positive correlation between aph λ1 bb λ1 and 1 u λ1 aw λ1 aw λ2 u λ2 which can be applied to estimate chla tsm the flowchart can be seen in fig 2 9 c h l a t s m a ph λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 2 3 2 other retrieval algorithms for particle composition a semianalytical algorithm sun 13 sun et al 2013 and an empirical algorithm ntd675 sun et al 2012 were used for comparison with the algorithm proposed in this study 2 3 2 1 sun 13 based on radiative transfer theory a three band semianalytical model was developed for estimating chla especially for optically complex turbid waters dall olmo et al 2003 zimba and gitelson 2006 which could be seen in eq 10 10 c h l a 1 r rs λ 1 1 r rs λ 2 r rs λ 3 where rrs λi represents the remote sensing reflectance at wavelength λi in addition in the near infrared band only backscattering coefficients carried the information of the particles therefore tsm bb λ rrs nir this relationship could be considered reasonable sun et al 2010 thus considering that similar nir bands were used in chla and tsm retrievals a band combination could be applied to retrieve the chla tsm ratios in inland waters as shown in eq 11 11 c h l a tsm r rs λ 2 r rs λ 1 r rs λ 1 r rs λ 2 sun 13 algorithm was recalibrated using our data through correlation analysis between the independent variable and the ratio of chla tsm using different band combinations using in situ hyperspectral rrs λ based on correlation analysis λ1 and λ2 of the sun 13 algorithm were determined at 685 nm and 688 nm respectively and the correlation coefficient at these two bands reached a maximum of 0 62 the specific expression is shown in table 4 2 3 2 2 ntd675 ntd675 was initially proposed for distinguishing the proportion of phytoplankton based on the depth of the remote sensing reflectance valley at 675 nm there was a significant correlation between chla tsm and ntd675 therefore because of the relationship between ntd675 and chla tsm ntd675 was also employed to estimate chla tsm xue et al 2020 the specific expression is shown in table 4 2 4 statistical evaluation of algorithm performance to evaluate the performance of each algorithm the slope coefficient of determination r2 unbiased mean absolute percentage error umape root mean square error rmse and normalized root mean square error nrmse were adopted the slope and r2 were calculated based on the linear regression model between the measured and estimated values yu et al 2019 the calculation formulas of umape rmse and nrmse are as follows 12 u m a p e 1 n i 1 n x i y i 0 5 x i y i 100 13 r m s e 1 n i 1 n x i y i 2 14 nrmse 1 n i 1 n x i y i 2 max x i min x i 100 where xi and yi are the in situ measurement and estimation values from rrs λ respectively for the comparison of different algorithms the overall winning rate owr seegers et al 2018 yu et al 2019 was introduced as an index to evaluate the performance difference among the three algorithms the algorithm proposed in this study sun 13 and ntd675 the absolute residuals between the estimated and measured values of each sample using different algorithms were compared and the algorithm with the smallest absolute residual was designated the winner the percentage of each algorithm s winning number in all samples was regarded as the owr of each algorithm when the owr was more prominent it indicated that the estimated value of more samples was close to the measured value demonstrating that the algorithm performed well 3 results 3 1 calibration and validation of the particulate composition model based on olci images to select the optimal band combination to estimate chla tsm the bands within 650 770 nm were randomly combined to calculate the correlation between the variable defined as eq 9 and chla tsm using the calibration dataset n 668 the calculated correlation results between the variable and chla tsm were applied to determine the optimal wavelengths λ1 and λ2 which are illustrated in fig 3 according to the theoretical derivation in section 2 3 1 it can be seen that there was a significantly high correlation between the variable and chla tsm when λ1 was located at a specific wavelength greater than 650 nm and λ2 was located at a specific wavelength greater than 700 nm where the influence of aph λ2 could be ignored in particular when λ1 was between 670 and 685 nm and λ2 was between 720 and 760 nm the correlation coefficient reached above 0 8 therefore considering the band settings of olci images b10 681 nm and b12 754 nm were determined to be λ1 and λ2 respectively the independently developed dataset was utilized to calibrate chla tsm retrieval algorithm coefficients by the least square fitting method as defined as eq 15 the relationship between the two variables is shown in fig 4 this proposed algorithm was denoted as cti 15 c h l a t s m 0 926 1 u 681 a w 681 a w 754 u 754 1 158 r 2 0 72 where aw 681 and aw 754 are the absorption coefficients of water at 681 nm and 754 nm respectively buiteveld et al 1994 the validation dataset n 334 was used to evaluate the performance of cti and the scatterplots of estimated values and measured values are displayed in fig 5 a the estimated chla tsm and in situ measured values were approximately distributed along a 1 1 line showing satisfactory accuracy with an r2 of 0 69 a umape of 47 32 an rmse of 0 83 µg mg and an nrmse of 6 62 furthermore the slope of the linear fitting line between the estimated chla tsm and the measured values was 0 88 which was close to 1 indicating that the estimated value was close to the measured value and that there was no evident overestimation or underestimation to further evaluate cti s performance when applied to real olci images a total of 323 match up pairs of olci derived and in situ measured chla tsm values 211 match up pairs from the in situ data of inland waters in china including lake taihu lake chaohu lake shijiu lake hongze lake hulun huangbizhuang reservoir 112 match up pairs of lake erie and lake huron from the glerl dataset were used to calculate the umape rmse and nrmse the scatterplots of olci derived values and in situ measured values are shown in fig 5b the evaluation results demonstrated that cti showed acceptable accuracy when applied to olci images with a umape of 66 37 an rmse of 1 15 µg mg and an nrmse of 17 40 the r2 and slope of the linear fitting line between the olci derived chla tsm and the measured values were 0 64 and 0 91 respectively which indicated that the olci derived chla tsm exhibited acceptable consistency with the measured value and the points were approximately distributed along the 1 1 line in the glerl dataset cti still showed acceptable stability with r2 0 49 umape 52 79 rmse 1 47 µg mg and nrmse 22 37 especially in lake erie with r2 0 62 umape 45 74 rmse 1 19 µg mg and nrmse 18 83 in conclusion the estimation performance of cti in this study was acceptable for inland waters the sensitivity of cti to rrs λ was also analyzed by adding systematic noise 20 and 10 to the measured rrs 681 and rrs 754 in the validation dataset the scatterplots of the original estimated chla tsm values and estimated chla tsm values after adding errors to rrs 681 and rrs 754 are shown in figs 6 and 7 respectively the analysis results showed that the estimated chla tsm values would lead to 30 uncertainties when rrs λ 10 noise when the noise continued to increase the uncertainties of the estimated values became significant when systematic noise of 20 was introduced into rrs 681 the estimated value deviated from the 1 1 line with a slope of 1 32 an increase of 42 69 in umape an increase of 0 85 µg mg in rmse and an increase of 9 54 in nrmse meanwhile if a systematic error of 20 was introduced into rrs 754 it was found that the estimated value and the original value were still distributed along the 1 1 line with a slope of 0 9 an increase of 24 46 in umape a rise of 0 35 µg mg in rmse and a rise of 3 89 in nrmse by comparing fig 6 with fig 7 as the systematic error varied from 20 to 20 at 10 intervals the magnitude of the change in the estimation result caused by rrs 681 was more significant than that of rrs 754 in conclusion this proposed algorithm was more sensitive to rrs 681 than rrs 754 3 2 estimation accuracy comparison between the proposed algorithm and other algorithms the validation dataset collected from inland waters in china n 334 was used to evaluate the accuracy of the reparameterized algorithms as listed in table 5 and the statistical values of the algorithm evaluation are also drawn in fig 8 a the performance of cti was better than that of sun 13 and ntd675 with the highest r2 the lowest umape rmse and nrmse and a slope close to 1 furthermore compared to sun 13 and ntd675 cti had the highest owr indicating that the estimated value of approximately 60 of the samples was closer to the measured value the scatterplot of estimated chla tsm using three different algorithms and the measured values are illustrated in fig 8b and it can be seen that the points estimated by cti were much closer along a 1 1 line than the other two algorithms in addition the sun 13 algorithm may fail in waters with low tsm concentrations mainly because the assumption of the positive linear correlation between tsm and rrs nir is established for waters with higher tsm luo et al 2018 shen et al 2010 however tsm is more likely to positively correlate with rrs λ in visible bands in waters with low to moderate tsm binding et al 2005 based on yu s study yu et al 2019 the validation dataset in this study was divided into two subgroups based on the tsm concentration to further evaluate algorithm performance i e one subgroup with tsm greater than 50 mg l and another subgroup with tsm 50 mg l the evaluation results showed that in the subgroup with tsm greater than 50 mg l the sun 13 algorithm performed acceptably with an r2 of 0 59 however in the other subset with tsm 50 mg l the estimated value of some samples deviated significantly from the 1 1 line and the estimated values were even negative at some points in contrast cti performed more satisfactorily in both subgroups with all r2 0 6 in general cti had higher accuracy and more stable performance than sun 13 and ntd675 3 3 the application of the algorithm in lake taihu the evaluation of atmospheric correction accuracy must be completed before applying the algorithm to taihu olci images the scatterplots of atmospherically corrected rrs and in situ measured rrs at the two bands used in this study are shown in fig 9 although the mumm method showed a slight underestimation at 681 nm and 754 nm the olci derived rrs λ and in situ measured rrs λ were distributed near the 1 1 line the umapes in the two bands were 30 with rmses 0 008 sr 1 and nrmses 15 5 the results demonstrated that the mumm could be applied in inland waters with acceptable accuracy lake taihu was selected as an experimental area and the cti algorithm was applied to the olci images of lake taihu from 2016 to 2019 to obtain the seasonal variation of chla tsm a previous study sun et al 2012 considered the proportion of phytoplankton in total suspended particles to be high when chla tsm 0 5 µg mg otherwise the proportion of phytoplankton is low medium in addition this criterion was also adopted in this study the spatial distribution of the average chla tsm for the four seasons is illustrated in fig 10 there was notable spatiotemporal variation in chla tsm for lake taihu in general the chla tsm was mainly in the range of 0 5 to 2 µg mg spatially the ratio of chla tsm in meiliang bay zhushan bay and gonghu bay was higher than that in the southern part of lake taihu in all four seasons moreover the highest mean chla tsm 1 7 0 6 µg mg was observed in summer and the lowest was in winter 1 2 0 4 µg mg the proportion of phytoplankton in lake taihu was high in all four seasons 3 4 accuracy assessment of the algorithm applied to other satellite sensors based on in situ data the applicability of cti on six different sensors was meris goci viirs modis msi and oli was fully evaluated here if the sensor has the same band setting as the olci the algorithm can be directly applied using 681 nm and 754 nm such as meris in the absence of these two bands such as goci viirs modis and msi images according to the correlation coefficients calculated in fig 3 the adjacent optimal bands were selected to be replaced and like oli images 865 nm was chosen as λ2 for the only band in the near infrared range the statistical values of the algorithm evaluation are listed in table 6 and scatterplots of the measured and estimated values on the various sensors are shown in fig 11 table 6 shows that cti performed reasonably well when applied to meris goci viirs modis and msi with an r2 of approximately 0 7 rmse 0 9 µg mg umape 50 and nrmse 7 the robust performance of the algorithm on these sensors was mainly because there were similar band settings at the two bands used in the meris goci viirs modis and msi sensors liu et al 2018 as a result the coefficients of the algorithm developed based on olci can be directly applied to these sensors without recalibration however due to the significant difference in band settings between landsat and olci and the coarse spectral resolution of landsat s bands the algorithm performed poorly on landsat 8 4 discussion 4 1 the relationship between particulate composition and optical properties optical properties have always been considered an attractive method to estimate various characteristics of water bodies binding et al 2005 boss et al 2004 in previous studies it was found that there was a significant linear relationship between chla and aph λ and between tsm and bb λ balasubramanian et al 2020 gitelson et al 2008 gitelson et al 2007 similarly the relationships between chla and aph λ and between tsm and bb λ were also validated using our measured data and the results are shown in fig 12 there were high correlations between chla and aph λ and between tsm and bb λ in the wavelength range from 400 nm to 800 nm with correlation coefficients 0 5 for ocean waters aph 443 is generally applied to estimate chla brewin et al 2015 bricaud et al 1998 but for inland waters aph 674 is more often used to estimate chla shi et al 2019a xue et al 2019b in this study there was no significant difference in the correlation between chla and aph 443 and aph 674 and both aph 443 and aph 674 can be used to indicate chla in this study the backscattering coefficients at 560 nm are often used to estimate the tsm xue et al 2019b xue et al 2020 in addition the backscattering coefficients in the red and near infrared bands are also applied to estimate the tsm balasubramanian et al 2020 sun et al 2010 which is similar to the results of this study additionally it can be seen in fig 12 that chla tsm exhibited a much higher correlation with aph λ bb λ at 650 700 nm with a correlation coefficient of approximately 0 7 indicating that aph λ bb λ can be used as an indicator for estimating chla tsm similarly wozniak et al 2010 found a reasonably good relationship between ap 675 bp 675 and poc tsm a proxy parameter for particulate composition in the nearshore marine environment at imperial beach california in addition a high correlation between ap 480 ap 570 and poc tsm was also observed at imperial beach california however no correlation between chla tsm and ap 480 ap 570 was found in this study which indicates that there is a different relationship between chla tsm and the ratio of particulate absorption in inland water compared to ocean water 4 2 the influence of bb λ in the development of the algorithm bb 681 and bb 754 were regarded as approximately equal gons 1999 proposed a semianalytical model for estimating a wide range of chla concentrations with high accuracy in which it assumed that bb λ was independent of wavelength melin et al 2003 also adopted a similar assumption to perform atmospheric correction believing that the value of bb λ was constant at 670 865 nm this assumption has been widely used in the development of remote sensing estimation models for water quality parameters and the models could work with acceptable accuracy dall olmo and gitelson 2005 gilerson et al 2010 gitelson et al 2007 it was assumed that bb λ was wavelength independent so aw λ1 bb λ2 aw λ1 bb λ1 eq 8 was considered to be 0 however bb λ may not be wavelength independent in inland waters especially in eutrophic and highly turbid waters bb λ in the near infrared bands will be higher than that in the red bands balasubramanian et al 2020 jiang et al 2020 resulting in a certain error in the algorithm which may be why some of the samples in the validation dataset deviated from the 1 1 line previous studies lyu et al 2020 xu et al 2021 have shown that bb 754 in inland waters was approximately 0 68 2 1 times that of bb 681 with an average of 0 66 m 1 at 681 nm based on this conclusion such a variation of bb at two bands will result in a maximum error of approximately 12 according to equation 8 in the future it will be necessary to collect measured bb λ data and more water quality data in more inland waters to validate and optimize the proposed algorithm to reduce uncertainties 4 3 evaluation of the algorithm s performance when applied to different actual satellite images since the launch of the first earth observation satellite countries have successively launched many remote sensing satellites with different spectral radiometric temporal and spatial resolutions cao et al 2019 guan et al 2020 seegers et al 2018 shi et al 2019a the collaborative analysis and application of multisource remote sensing satellite data have become one of the current research hotspots in remote sensing fan and liu 2014 guan et al 2020 page et al 2019 pahlevan et al 2019 however transit time sensor viewing angle and waveband settings will affect the radiation consistency between multisource images pahlevan et al 2019 therefore even if the validation results using in situ data showed that cti could be extended to other satellite images the differences between different images are still worthy of discussion when the algorithm was actually applied to satellite images therefore in this study the olci and msi images were taken as an example to discuss the consistency of the results obtained by cti fig 13 shows the spatial distribution of chla tsm in lake taihu obtained from two different satellite images the ratio of chla tsm derived from both sensors had similar spatial distribution characteristics and the ratio values fell in the range of 0 to 2 µg mg the difference in spatial variation may be caused by the different spatial resolutions of olci and msi especially in the area near water blooms the value of chla tsm near the bloom area derived from olci was significantly higher than that derived from sentinel 2 msi compared with the msi image with 20 m resolution the pixels near the bloom on the olci image with 300 m resolution may be affected by the adjacent effect cao et al 2019 feng et al 2012 comparing the variation trend of chla tsm along the transection from the p1 location to the p2 location it can be found that the variation trend along the transection estimated by the two sensors was substantially consistent however there was a slight difference in the estimated value at the position of approximately 1000 pixels from p1 which was also in the high value area of chla tsm this may be because a small algal bloom area on the olci image has not been identified there was a difference of approximately half an hour in the transit time between olci and sentinel 2 msi algal blooms change extremely quickly huang et al 2015 qi et al 2018 and may move or disappear within half an hour which leads to a significant difference in chla tsm in this region the comparison of the estimation results of the two scenes showed that cti has the potential to be used in comprehensive analysis using multisource sensors however radiation consistency first needs to be solved before applying the algorithm to different sensors in the future it may be necessary to consider using relative radiometric correction methods to obtain consistent radiation for large scale long term water quality monitoring 5 conclusions in this study a semianalytical algorithm cti was developed to estimate the particulate composition characterized by the ratio of chla tsm based on olci images this algorithm has been proven to be applied in inland waters with satisfactory performance due to the significant relationship between the ratio of chla tsm and the ratio of aph λ bb λ the ratio of aph 681 bb 681 was finally found to be an optimal optical indicator of chla tsm the evaluation demonstrated that the algorithm could perform well in inland waters in china and western lake erie and saginaw bay of lake huron using olci images with an nrmse of 15 29 an rmse of 1 15 µg mg and a slope of 0 91 finally cti was successfully applied to obtain the temporal and spatial chla tsm distribution in taihu lake this study provided an effective way to monitor the particulate composition in large medium and small inland lakes based on multisource sensors with different scales due to their stable performance on various sensors credit authorship contribution statement jiafeng xu conceptualization methodology writing original draft writing review editing ying zhao data curation investigation writing review editing formal analysis heng lyu conceptualization supervision writing review editing funding acquisition huaiqing liu investigation writing review editing xianzhang dong software writing review editing yunmei li supervision methodology resources kai cao writing review editing jie xu writing review editing yangyang li data curation software validation huaijing wang software validation honglei guo data curation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is financially supported by the national natural science foundation of china grant number 41871234 we are grateful to all the pis scientists and contributors who provided the glerl datasets data we thank the european space agency for providing the olci satellite images our thanks are extended to remote sensing application graduate students from nanjing normal university china for their aid with fieldwork and lab analyses acknowledgement for the data support from yangtze river delta science data center national earth system science data center national science technology infrastructure of china 
3459,the composition of suspended particles is a key factor in determining the underwater light field which is of great significance for understanding the variability in the optical properties of water bodies in this study the ratio of the phytoplankton absorption coefficient to the backscattering coefficient at wavelength of 681 nm aph 681 bb 681 was found to be an optimal optical indicator of the ratio of chlorophyll a to the total suspended matter concentration chla tsm a parameter indicating the particulate composition therefore a semianalytical algorithm was proposed to estimate chla tsm from remote sensing reflectance rrs λ at 681 nm and 754 nm on sentinel 3 ocean and land color instrument olci images the validation dataset collected from 11 inland lakes and 3 reservoirs in china and 2 inland lakes in america was used to evaluate the algorithm s performance the evaluation results demonstrated that the proposed algorithm could have favorable performance in inland waters furthermore comparison with two other state of the art algorithms sun 13 and ntd675 showed that this proposed algorithm had higher estimation accuracy with an overall winning rate owr of 60 an unbiased mean absolute percentage error umape reduction from 72 95 to 46 44 a root mean square error rmse decline from 1 42 µg mg to 0 83 µg mg and a normalized root mean square error nrmse decline from 11 36 to 6 62 this algorithm was successfully applied to acquire the chla tsm tempo spatial variation using the olci images of lake taihu from 2016 to 2019 it was found that the algorithm developed based on olci images can be applied to satellite sensors with similar bands such as medium resolution imaging spectrometer meris and sentinel 2 multispectral instrument msi etc as a simple and effective algorithm the proposed algorithm has the potential to monitor changes in chla tsm in inland waters on a global scale keywords optical indicator chla tsm remote sensing reflectance tempo spatial variation band setting 1 introduction total suspended matter tsm see table 1 for abbreviations and definitions is an essential biogeochemical parameter in inland waters that can affect lake material circulation and ecosystems cao et al 2017 volpe et al 2011 williamson and crawford 2011 suspended particles in lakes generally include organic and inorganic suspended matter organic suspended matter osm the primary light absorbing substance in lakes mainly includes phytoplankton bacteria and detritus from biological decomposition liu et al 2019 as the main scattering material inorganic suspended matter ism is mainly composed of mineral particles such as sand silt and clay kratzer et al 2020 the particulate composition i e the proportion of osm and ism was often closely related to particle size refractive index and particulate backscattering ratio loisel et al 2007 whitmire et al 2007 in the case of high ism and low osm in particles sediments tend to resuspension lei et al 2020 ism which is usually tiny carries much more toxic and harmful chemical substances on its surface through adsorption and acts as a carrier to contribute to the migration and transformation of pollutants in the water environment howard 2010 furthermore biochemical degradation of osm causes a large amount of oxygen consumption and deterioration of water quality paerl et al 2011 therefore particulate composition information plays a vital role in the variation in the underwater light field and could be used to indicate the erosion and deposition processes primary biomass production and transportation of nutrients and heavy metals bilotta and brazier 2008 liu et al 2019 in previous studies two types of indicators were widely adopted to characterize particulate composition one type was the percentage of the concentrations of different particulate matter such as the ratio of particulate organic carbon poc to tsm poc tsm woźniak et al 2010 the proportion of poc to the sum of poc and particulate inorganic carbon poc poc pic neukermans et al 2012 and the ratio of chlorophyll a chla to tsm chla tsm sun et al 2017 sun et al 2013 which have been successfully applied to characterize the particulate composition with the continuous development of remote sensing technology cao et al 2017 dall olmo et al 2003 xu et al 2020 researches on the remote sensing estimation of particulate composition in water have been conducted compared with parameters such as poc and pic the optical signals of chla and tsm are stronger and easier to capture by satellite sensors therefore it is appropriate to estimate chla tsm to characterize particulate composition chla tsm representing the proportion of phytoplankton in particulate matter determines the change of refractive index thereby directly affecting the underwater light field sun et al 2013 xue et al 2020 changes in the underwater light field would lead to changes in primary productivity kostadinov et al 2012 sathyendranath et al 2017 furthermore the variations of chla tsm could reflect the process of eutrophication which can be used to indicate the possibility of algal blooms to a certain extent binding et al 2012 xue et al 2020 a simple approach is to derive first the concentrations of different types of particles using a developed algorithm and then the proportion of particulate composition is calculated based on the estimated concentration xue et al 2020 estimated chla and tsm separately based on the semianalytical algorithm and finally obtained the chla tsm inversion results of the middle and lower reaches of the yangtze river and the huaihe river basin however the uncertainty and instability of estimating each component concentration may lead to significant error propagation for deriving the particulate composition lee et al 2010 pahlevan et al 2019 therefore it is an optimal method to directly estimate proxy parameters such as chla tsm to characterize particulate composition normalized trough depth at 675 nm ntd675 was proposed to differentiate organic matter dominated from inorganic matter dominated based on remote sensing reflectance rrs λ sun et al 2012 thereafter due to the significant correlation between chla tsm and ntd675 this index was applied to empirically estimate chla tsm xue et al 2020 sun et al 2013 developed the relationship between chla tsm and rrs λ based on a three band chla estimation algorithm and a near infrared band based tsm estimating algorithm for turbid inland waters denoted as sun 13 due to the applicability of the assumptions of three band chla estimation algorithm and the tsm algorithm in different waters le et al 2009 yu et al 2019 the estimation performance may not be robust under a wide range of chla tsm the other type is to characterize the particulate composition using optical properties the backscattering ratio provided an estimate of the refractive index of particles in the ocean allowing us to distinguish organic matter dominated from inorganic matter dominated particles twardowski et al 2001 the backscattering ratio was negatively correlated with chla tsm in the eastern english channel and southern north sea loisel et al 2007 there was a significant negative correlation between particulate backscattering ratio and the ratio of the phytoplankton absorption coefficient to the particulate attenuation coefficient in the mid atlantic bight where a low ratio was indicative of a relatively low concentration of phytoplankton and a rather significant contribution from inorganic matter boss et al 2004 compared with the percentage of the concentration of two different particles the optical proxy parameters are more directly obtained from rrs λ therefore it is an excellent choice to use optical proxy parameters to characterize the particulate composition however due to the differences in the optical characteristics of ocean and inland waters the above optical proxy parameters might fail in an environment dominated by detrital materials boss et al 2004 satellite data such as sentinel 3 ocean and land color instrument olci moderate resolution imaging spectroradiometer modis medium resolution imaging spectrometer meris visible infrared imaging radiometer suite viirs geostationary ocean color imager goci sentinel 2 multispectral instrument msi and landsat 8 operational land imager oli have been widely used for water quality dynamic monitoring guan et al 2020 huang et al 2015 huang et al 2019 shi et al 2019b warren et al 2019 yu et al 2019 it is an effective way to monitor large medium and small lake environments and reveal the pattern of water quality changes in the entire region by combining various sensors with different spatial resolutions spectral resolutions and temporal resolutions therefore a suitable algorithm is expected to be applicable for more sensors consequently the purpose of this study was to 1 propose a chla tsm semianalytical algorithm that can be widely used to inland waters with broad varying optical properties 2 evaluate the robustness of the proposed algorithm and compare it with two other algorithms using an in situ dataset 3 apply the proposed algorithm to olci images in inland waters and 4 evaluate the algorithm accuracy applied to other satellite sensors 2 data and methods 2 1 in situ datasets two datasets were employed in this study for algorithm development and validation including an in situ dataset of inland lakes in china and the great lakes environmental research laboratory dataset glerl dataset the distribution of the two datasets is presented in fig 1 2 1 1 in situ data of inland waters in china the in situ data of inland lakes in china were collected from 14 water bodies including 11 lakes lake chaohu lake hongze lake taihu lake erhai lake dianchi lake hengshui lake gehu lake shijiu lake nanyi lake hulun and lake gaoyou and 3 reservoirs qiandaohu reservoir gangnan reservoir and huangbizhuang reservoir during each cruise the distance between different sampling points was about 3 km and ensured that the sampling points were far away from the shore during the cruising of these 14 water bodies a total of 1002 rrs λ were gathered using a fieldspec spectroradiometer analytical spectra devices inc usa ranging from 350 nm to 1050 nm with an interval of 1 nm details of measurement and calculation of rrs λ could be found in lei et al 2019 and the surface water was brought back for laboratory analysis in the laboratory chla was extracted with ethanol and then analyzed using a spectrophotometer parsons 1984 tsm ism and osm were measured using the weighing method based on standard protocols apha 1998 the absorption coefficient of phytoplankton aph λ nonalgal particulate matter ad λ and color dissolved organic matter ag λ was also determined with the quantitative filter technique cleveland and weidemann 1993 mitchell et al 2014 the number of samples taken for each water body and the sampling date are listed in table 2 furthermore these 1002 samples were randomly divided into two parts a subset of 668 samples was used to develop an algorithm and the remaining part contained 334 samples for algorithm validation see table 3 2 1 2 glerl dataset the great lakes environmental research laboratory provided the glerl dataset and this project was designed for in situ measurement and continuous real time observation of western lake erie and saginaw bay of lake huron https www glerl noaa gov res habs and hypoxia habsmon html focused on the observation of the size movement and toxicity of harmful algal blooms habs since 2012 from may to october each year physical chemical and biological data have been collected through repeated site sampling once a week before during and after the hab event cooperative institute for great lakes research 2019 the distance between several monitoring sites was greater than 3 km and the distance to the shore was greater than 300 m due to the lack of measured rrs λ the measured chla and tsm were adopted to validate the algorithm finally a total of 112 match up pairs of olci images and in situ measured chla and tsm were selected from the glerl dataset 2 2 satellite images data olci is a watercolor sensor mounted on sentinel 3a and 3b satellites https scihub copernicus eu there are 21 bands in the 400 1020 nm spectral range with a high signal to noise ratio at a spatial resolution of 300 m donlon et al 2012 after removing the images with clouds and sunglint 120 olci images of lake taihu from may 2016 to december 2019 were acquired the management unit of the north seas mathematical model mumm which has been proven to perform well in inland waters bi et al 2018 ruddick et al 2000 xu et al 2020 was applied to perform atmospheric correction on olci images a total of 211 match up pairs of olci derived and in situ measured rrs λ from five lakes and one reservoir lake taihu lake chaohu lake shijiu lake hongze lake hulun huangbizhuang reservoir were used to validate the atmospheric correction accuracy in inland waters the measured remote sensing reflectance at sentinel 3 bands was calculated using the sentinel 3 spectral response functions last the presence of algal blooms also causes uncertainty in estimating results using satellite images xue et al 2019b therefore according to the olci band setting the virtual baseline floating macroalgae height vb fah index which forms a virtual baseline using the green and red bands to identify the algal bloom effectively was adopted to mask the blooming area on olci images xing and hu 2016 the in situ measured rrs λ were used to simulate spectra of meris goci viirs modis msi and oli bands according to their spectral response functions and simulated spectra and in situ measured values were adopted to evaluate the accuracy of the algorithm applied to other satellite sensors additionally taking the olci and sentinel 2 msi images in lake taihu on november 15 2019 as an example the applicability of the algorithm on different sensors was further validated by comparing the spatial distribution of the obtained chla tsm from various sensors 2 3 algorithms for particulate composition retrievals 2 3 1 development of a semianalytical algorithm for particulate composition a significant positive correlation between chla and aph λ was found in some studies bricaud et al 2004 wozniak et al 2011 and a significant positive correlation between tsm and the total backscattering coefficient bb λ was also observed wozniak et al 2018 woźniak et al 2010 therefore theoretically the aph λ bb λ ratio must have a significant correlation with chla tsm consequently the aph λ bb λ ratio was finally used to indicate chla tsm here according to the water radiative transfer theory numerous studies have proven the relationship between rrs λ and inherent optical properties gordon et al 1988 huang et al 2019 lee et al 2002 lee et al 1999 liu et al 2019 as shown in eqs 1 to 3 1 r rs λ r rs λ 0 52 1 7 r rs λ 2 u λ b b λ a λ b b λ 3 u λ g 0 g 0 2 4 g 1 r rs λ 1 2 2 g 1 where rrs λ is the rrs λ just beneath the water surface a λ is the total absorption coefficient of water constituents and pure water bb λ is the total backscattering coefficient g0 0 084 and g1 0 17 which were suggested for inland waters huang et al 2019 lee et al 2002 the ratio of aph λ bb λ needs to be separated by using the reciprocal of u λ shown in eq 4 4 1 u λ 1 a ph λ 1 a d λ 1 a g λ 1 a w λ 1 b b λ 1 b b λ 1 where aph λ1 ad λ1 ag λ1 and aw λ1 are the absorption coefficients of phytoplankton nonalgal particulate matter color dissolved organic matter and pure water at wavelength λ1 respectively λ1 is the first spectral region selected where ag λ1 could be ignored the measured data showed that when λ1 was greater than 650 nm the average value of ag λ1 was 0 011 which can be ignored compared to aph λ1 and ad λ1 therefore the selection range of λ1 was greater than 650 nm to minimize the influence of 1 bb λ in eq 4 a wavelength λ2 where aph λ2 and ag λ2 could be ignored was selected considering the decrease in aph λ rottgers et al 2014 xue et al 2019a λ2 was determined beyond 700 nm the specific formula is shown in eq 5 5 1 u λ 2 a w λ 2 b b λ 2 1 a d λ 2 b b λ 2 to separate aph λ bb λ and minimize the influence of 1 bb λ in eq 4 and eq 5 aw λ2 was multiplied to eq 4 and aw λ1 was multiplied to eq 5 6 a w λ 2 u λ 1 a w λ 2 a ph λ 1 b b λ 1 a w λ 2 a w λ 1 b b λ 1 a w λ 2 1 a d λ 1 b b λ 1 7 a w λ 1 u λ 2 a w λ 1 a w λ 2 b b λ 2 a w λ 1 1 a d λ 2 b b λ 2 then separate aph λ1 bb λ1 by subtracting eq 7 from eq 6 in addition based on the assumption that bb λ1 bb λ2 gitelson et al 2008 liu et al 2018 the following equation can be obtained 8 a ph λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 1 a d λ 1 b b λ 1 a w λ 1 a w λ 2 1 a d λ 2 b b λ 2 a w λ 1 b b λ 2 a w λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 1 a d λ 1 b b λ 1 a w λ 1 a w λ 2 1 a d λ 2 b b λ 2 furthermore taking λ1 and λ2 at 681 nm and 754 nm respectively the value of 1 ad λ1 bb λ1 in eq 8 was in the range of 1 59 0 15 with a coefficient of variation c v of 9 50 and the value of 1 ad λ2 bb λ2 aw λ1 aw λ2 was in the range of 0 24 0 03 with a c v of 11 54 as a result the value of 1 ad λ2 bb λ2 aw λ1 aw λ2 1 ad λ1 bb λ1 was in the range of 1 35 0 14 with a c v of 10 13 therefore this value can be approximated as a constant c therefore it can be found that there is a positive correlation between aph λ1 bb λ1 and 1 u λ1 aw λ1 aw λ2 u λ2 which can be applied to estimate chla tsm the flowchart can be seen in fig 2 9 c h l a t s m a ph λ 1 b b λ 1 1 u λ 1 a w λ 1 a w λ 2 u λ 2 2 3 2 other retrieval algorithms for particle composition a semianalytical algorithm sun 13 sun et al 2013 and an empirical algorithm ntd675 sun et al 2012 were used for comparison with the algorithm proposed in this study 2 3 2 1 sun 13 based on radiative transfer theory a three band semianalytical model was developed for estimating chla especially for optically complex turbid waters dall olmo et al 2003 zimba and gitelson 2006 which could be seen in eq 10 10 c h l a 1 r rs λ 1 1 r rs λ 2 r rs λ 3 where rrs λi represents the remote sensing reflectance at wavelength λi in addition in the near infrared band only backscattering coefficients carried the information of the particles therefore tsm bb λ rrs nir this relationship could be considered reasonable sun et al 2010 thus considering that similar nir bands were used in chla and tsm retrievals a band combination could be applied to retrieve the chla tsm ratios in inland waters as shown in eq 11 11 c h l a tsm r rs λ 2 r rs λ 1 r rs λ 1 r rs λ 2 sun 13 algorithm was recalibrated using our data through correlation analysis between the independent variable and the ratio of chla tsm using different band combinations using in situ hyperspectral rrs λ based on correlation analysis λ1 and λ2 of the sun 13 algorithm were determined at 685 nm and 688 nm respectively and the correlation coefficient at these two bands reached a maximum of 0 62 the specific expression is shown in table 4 2 3 2 2 ntd675 ntd675 was initially proposed for distinguishing the proportion of phytoplankton based on the depth of the remote sensing reflectance valley at 675 nm there was a significant correlation between chla tsm and ntd675 therefore because of the relationship between ntd675 and chla tsm ntd675 was also employed to estimate chla tsm xue et al 2020 the specific expression is shown in table 4 2 4 statistical evaluation of algorithm performance to evaluate the performance of each algorithm the slope coefficient of determination r2 unbiased mean absolute percentage error umape root mean square error rmse and normalized root mean square error nrmse were adopted the slope and r2 were calculated based on the linear regression model between the measured and estimated values yu et al 2019 the calculation formulas of umape rmse and nrmse are as follows 12 u m a p e 1 n i 1 n x i y i 0 5 x i y i 100 13 r m s e 1 n i 1 n x i y i 2 14 nrmse 1 n i 1 n x i y i 2 max x i min x i 100 where xi and yi are the in situ measurement and estimation values from rrs λ respectively for the comparison of different algorithms the overall winning rate owr seegers et al 2018 yu et al 2019 was introduced as an index to evaluate the performance difference among the three algorithms the algorithm proposed in this study sun 13 and ntd675 the absolute residuals between the estimated and measured values of each sample using different algorithms were compared and the algorithm with the smallest absolute residual was designated the winner the percentage of each algorithm s winning number in all samples was regarded as the owr of each algorithm when the owr was more prominent it indicated that the estimated value of more samples was close to the measured value demonstrating that the algorithm performed well 3 results 3 1 calibration and validation of the particulate composition model based on olci images to select the optimal band combination to estimate chla tsm the bands within 650 770 nm were randomly combined to calculate the correlation between the variable defined as eq 9 and chla tsm using the calibration dataset n 668 the calculated correlation results between the variable and chla tsm were applied to determine the optimal wavelengths λ1 and λ2 which are illustrated in fig 3 according to the theoretical derivation in section 2 3 1 it can be seen that there was a significantly high correlation between the variable and chla tsm when λ1 was located at a specific wavelength greater than 650 nm and λ2 was located at a specific wavelength greater than 700 nm where the influence of aph λ2 could be ignored in particular when λ1 was between 670 and 685 nm and λ2 was between 720 and 760 nm the correlation coefficient reached above 0 8 therefore considering the band settings of olci images b10 681 nm and b12 754 nm were determined to be λ1 and λ2 respectively the independently developed dataset was utilized to calibrate chla tsm retrieval algorithm coefficients by the least square fitting method as defined as eq 15 the relationship between the two variables is shown in fig 4 this proposed algorithm was denoted as cti 15 c h l a t s m 0 926 1 u 681 a w 681 a w 754 u 754 1 158 r 2 0 72 where aw 681 and aw 754 are the absorption coefficients of water at 681 nm and 754 nm respectively buiteveld et al 1994 the validation dataset n 334 was used to evaluate the performance of cti and the scatterplots of estimated values and measured values are displayed in fig 5 a the estimated chla tsm and in situ measured values were approximately distributed along a 1 1 line showing satisfactory accuracy with an r2 of 0 69 a umape of 47 32 an rmse of 0 83 µg mg and an nrmse of 6 62 furthermore the slope of the linear fitting line between the estimated chla tsm and the measured values was 0 88 which was close to 1 indicating that the estimated value was close to the measured value and that there was no evident overestimation or underestimation to further evaluate cti s performance when applied to real olci images a total of 323 match up pairs of olci derived and in situ measured chla tsm values 211 match up pairs from the in situ data of inland waters in china including lake taihu lake chaohu lake shijiu lake hongze lake hulun huangbizhuang reservoir 112 match up pairs of lake erie and lake huron from the glerl dataset were used to calculate the umape rmse and nrmse the scatterplots of olci derived values and in situ measured values are shown in fig 5b the evaluation results demonstrated that cti showed acceptable accuracy when applied to olci images with a umape of 66 37 an rmse of 1 15 µg mg and an nrmse of 17 40 the r2 and slope of the linear fitting line between the olci derived chla tsm and the measured values were 0 64 and 0 91 respectively which indicated that the olci derived chla tsm exhibited acceptable consistency with the measured value and the points were approximately distributed along the 1 1 line in the glerl dataset cti still showed acceptable stability with r2 0 49 umape 52 79 rmse 1 47 µg mg and nrmse 22 37 especially in lake erie with r2 0 62 umape 45 74 rmse 1 19 µg mg and nrmse 18 83 in conclusion the estimation performance of cti in this study was acceptable for inland waters the sensitivity of cti to rrs λ was also analyzed by adding systematic noise 20 and 10 to the measured rrs 681 and rrs 754 in the validation dataset the scatterplots of the original estimated chla tsm values and estimated chla tsm values after adding errors to rrs 681 and rrs 754 are shown in figs 6 and 7 respectively the analysis results showed that the estimated chla tsm values would lead to 30 uncertainties when rrs λ 10 noise when the noise continued to increase the uncertainties of the estimated values became significant when systematic noise of 20 was introduced into rrs 681 the estimated value deviated from the 1 1 line with a slope of 1 32 an increase of 42 69 in umape an increase of 0 85 µg mg in rmse and an increase of 9 54 in nrmse meanwhile if a systematic error of 20 was introduced into rrs 754 it was found that the estimated value and the original value were still distributed along the 1 1 line with a slope of 0 9 an increase of 24 46 in umape a rise of 0 35 µg mg in rmse and a rise of 3 89 in nrmse by comparing fig 6 with fig 7 as the systematic error varied from 20 to 20 at 10 intervals the magnitude of the change in the estimation result caused by rrs 681 was more significant than that of rrs 754 in conclusion this proposed algorithm was more sensitive to rrs 681 than rrs 754 3 2 estimation accuracy comparison between the proposed algorithm and other algorithms the validation dataset collected from inland waters in china n 334 was used to evaluate the accuracy of the reparameterized algorithms as listed in table 5 and the statistical values of the algorithm evaluation are also drawn in fig 8 a the performance of cti was better than that of sun 13 and ntd675 with the highest r2 the lowest umape rmse and nrmse and a slope close to 1 furthermore compared to sun 13 and ntd675 cti had the highest owr indicating that the estimated value of approximately 60 of the samples was closer to the measured value the scatterplot of estimated chla tsm using three different algorithms and the measured values are illustrated in fig 8b and it can be seen that the points estimated by cti were much closer along a 1 1 line than the other two algorithms in addition the sun 13 algorithm may fail in waters with low tsm concentrations mainly because the assumption of the positive linear correlation between tsm and rrs nir is established for waters with higher tsm luo et al 2018 shen et al 2010 however tsm is more likely to positively correlate with rrs λ in visible bands in waters with low to moderate tsm binding et al 2005 based on yu s study yu et al 2019 the validation dataset in this study was divided into two subgroups based on the tsm concentration to further evaluate algorithm performance i e one subgroup with tsm greater than 50 mg l and another subgroup with tsm 50 mg l the evaluation results showed that in the subgroup with tsm greater than 50 mg l the sun 13 algorithm performed acceptably with an r2 of 0 59 however in the other subset with tsm 50 mg l the estimated value of some samples deviated significantly from the 1 1 line and the estimated values were even negative at some points in contrast cti performed more satisfactorily in both subgroups with all r2 0 6 in general cti had higher accuracy and more stable performance than sun 13 and ntd675 3 3 the application of the algorithm in lake taihu the evaluation of atmospheric correction accuracy must be completed before applying the algorithm to taihu olci images the scatterplots of atmospherically corrected rrs and in situ measured rrs at the two bands used in this study are shown in fig 9 although the mumm method showed a slight underestimation at 681 nm and 754 nm the olci derived rrs λ and in situ measured rrs λ were distributed near the 1 1 line the umapes in the two bands were 30 with rmses 0 008 sr 1 and nrmses 15 5 the results demonstrated that the mumm could be applied in inland waters with acceptable accuracy lake taihu was selected as an experimental area and the cti algorithm was applied to the olci images of lake taihu from 2016 to 2019 to obtain the seasonal variation of chla tsm a previous study sun et al 2012 considered the proportion of phytoplankton in total suspended particles to be high when chla tsm 0 5 µg mg otherwise the proportion of phytoplankton is low medium in addition this criterion was also adopted in this study the spatial distribution of the average chla tsm for the four seasons is illustrated in fig 10 there was notable spatiotemporal variation in chla tsm for lake taihu in general the chla tsm was mainly in the range of 0 5 to 2 µg mg spatially the ratio of chla tsm in meiliang bay zhushan bay and gonghu bay was higher than that in the southern part of lake taihu in all four seasons moreover the highest mean chla tsm 1 7 0 6 µg mg was observed in summer and the lowest was in winter 1 2 0 4 µg mg the proportion of phytoplankton in lake taihu was high in all four seasons 3 4 accuracy assessment of the algorithm applied to other satellite sensors based on in situ data the applicability of cti on six different sensors was meris goci viirs modis msi and oli was fully evaluated here if the sensor has the same band setting as the olci the algorithm can be directly applied using 681 nm and 754 nm such as meris in the absence of these two bands such as goci viirs modis and msi images according to the correlation coefficients calculated in fig 3 the adjacent optimal bands were selected to be replaced and like oli images 865 nm was chosen as λ2 for the only band in the near infrared range the statistical values of the algorithm evaluation are listed in table 6 and scatterplots of the measured and estimated values on the various sensors are shown in fig 11 table 6 shows that cti performed reasonably well when applied to meris goci viirs modis and msi with an r2 of approximately 0 7 rmse 0 9 µg mg umape 50 and nrmse 7 the robust performance of the algorithm on these sensors was mainly because there were similar band settings at the two bands used in the meris goci viirs modis and msi sensors liu et al 2018 as a result the coefficients of the algorithm developed based on olci can be directly applied to these sensors without recalibration however due to the significant difference in band settings between landsat and olci and the coarse spectral resolution of landsat s bands the algorithm performed poorly on landsat 8 4 discussion 4 1 the relationship between particulate composition and optical properties optical properties have always been considered an attractive method to estimate various characteristics of water bodies binding et al 2005 boss et al 2004 in previous studies it was found that there was a significant linear relationship between chla and aph λ and between tsm and bb λ balasubramanian et al 2020 gitelson et al 2008 gitelson et al 2007 similarly the relationships between chla and aph λ and between tsm and bb λ were also validated using our measured data and the results are shown in fig 12 there were high correlations between chla and aph λ and between tsm and bb λ in the wavelength range from 400 nm to 800 nm with correlation coefficients 0 5 for ocean waters aph 443 is generally applied to estimate chla brewin et al 2015 bricaud et al 1998 but for inland waters aph 674 is more often used to estimate chla shi et al 2019a xue et al 2019b in this study there was no significant difference in the correlation between chla and aph 443 and aph 674 and both aph 443 and aph 674 can be used to indicate chla in this study the backscattering coefficients at 560 nm are often used to estimate the tsm xue et al 2019b xue et al 2020 in addition the backscattering coefficients in the red and near infrared bands are also applied to estimate the tsm balasubramanian et al 2020 sun et al 2010 which is similar to the results of this study additionally it can be seen in fig 12 that chla tsm exhibited a much higher correlation with aph λ bb λ at 650 700 nm with a correlation coefficient of approximately 0 7 indicating that aph λ bb λ can be used as an indicator for estimating chla tsm similarly wozniak et al 2010 found a reasonably good relationship between ap 675 bp 675 and poc tsm a proxy parameter for particulate composition in the nearshore marine environment at imperial beach california in addition a high correlation between ap 480 ap 570 and poc tsm was also observed at imperial beach california however no correlation between chla tsm and ap 480 ap 570 was found in this study which indicates that there is a different relationship between chla tsm and the ratio of particulate absorption in inland water compared to ocean water 4 2 the influence of bb λ in the development of the algorithm bb 681 and bb 754 were regarded as approximately equal gons 1999 proposed a semianalytical model for estimating a wide range of chla concentrations with high accuracy in which it assumed that bb λ was independent of wavelength melin et al 2003 also adopted a similar assumption to perform atmospheric correction believing that the value of bb λ was constant at 670 865 nm this assumption has been widely used in the development of remote sensing estimation models for water quality parameters and the models could work with acceptable accuracy dall olmo and gitelson 2005 gilerson et al 2010 gitelson et al 2007 it was assumed that bb λ was wavelength independent so aw λ1 bb λ2 aw λ1 bb λ1 eq 8 was considered to be 0 however bb λ may not be wavelength independent in inland waters especially in eutrophic and highly turbid waters bb λ in the near infrared bands will be higher than that in the red bands balasubramanian et al 2020 jiang et al 2020 resulting in a certain error in the algorithm which may be why some of the samples in the validation dataset deviated from the 1 1 line previous studies lyu et al 2020 xu et al 2021 have shown that bb 754 in inland waters was approximately 0 68 2 1 times that of bb 681 with an average of 0 66 m 1 at 681 nm based on this conclusion such a variation of bb at two bands will result in a maximum error of approximately 12 according to equation 8 in the future it will be necessary to collect measured bb λ data and more water quality data in more inland waters to validate and optimize the proposed algorithm to reduce uncertainties 4 3 evaluation of the algorithm s performance when applied to different actual satellite images since the launch of the first earth observation satellite countries have successively launched many remote sensing satellites with different spectral radiometric temporal and spatial resolutions cao et al 2019 guan et al 2020 seegers et al 2018 shi et al 2019a the collaborative analysis and application of multisource remote sensing satellite data have become one of the current research hotspots in remote sensing fan and liu 2014 guan et al 2020 page et al 2019 pahlevan et al 2019 however transit time sensor viewing angle and waveband settings will affect the radiation consistency between multisource images pahlevan et al 2019 therefore even if the validation results using in situ data showed that cti could be extended to other satellite images the differences between different images are still worthy of discussion when the algorithm was actually applied to satellite images therefore in this study the olci and msi images were taken as an example to discuss the consistency of the results obtained by cti fig 13 shows the spatial distribution of chla tsm in lake taihu obtained from two different satellite images the ratio of chla tsm derived from both sensors had similar spatial distribution characteristics and the ratio values fell in the range of 0 to 2 µg mg the difference in spatial variation may be caused by the different spatial resolutions of olci and msi especially in the area near water blooms the value of chla tsm near the bloom area derived from olci was significantly higher than that derived from sentinel 2 msi compared with the msi image with 20 m resolution the pixels near the bloom on the olci image with 300 m resolution may be affected by the adjacent effect cao et al 2019 feng et al 2012 comparing the variation trend of chla tsm along the transection from the p1 location to the p2 location it can be found that the variation trend along the transection estimated by the two sensors was substantially consistent however there was a slight difference in the estimated value at the position of approximately 1000 pixels from p1 which was also in the high value area of chla tsm this may be because a small algal bloom area on the olci image has not been identified there was a difference of approximately half an hour in the transit time between olci and sentinel 2 msi algal blooms change extremely quickly huang et al 2015 qi et al 2018 and may move or disappear within half an hour which leads to a significant difference in chla tsm in this region the comparison of the estimation results of the two scenes showed that cti has the potential to be used in comprehensive analysis using multisource sensors however radiation consistency first needs to be solved before applying the algorithm to different sensors in the future it may be necessary to consider using relative radiometric correction methods to obtain consistent radiation for large scale long term water quality monitoring 5 conclusions in this study a semianalytical algorithm cti was developed to estimate the particulate composition characterized by the ratio of chla tsm based on olci images this algorithm has been proven to be applied in inland waters with satisfactory performance due to the significant relationship between the ratio of chla tsm and the ratio of aph λ bb λ the ratio of aph 681 bb 681 was finally found to be an optimal optical indicator of chla tsm the evaluation demonstrated that the algorithm could perform well in inland waters in china and western lake erie and saginaw bay of lake huron using olci images with an nrmse of 15 29 an rmse of 1 15 µg mg and a slope of 0 91 finally cti was successfully applied to obtain the temporal and spatial chla tsm distribution in taihu lake this study provided an effective way to monitor the particulate composition in large medium and small inland lakes based on multisource sensors with different scales due to their stable performance on various sensors credit authorship contribution statement jiafeng xu conceptualization methodology writing original draft writing review editing ying zhao data curation investigation writing review editing formal analysis heng lyu conceptualization supervision writing review editing funding acquisition huaiqing liu investigation writing review editing xianzhang dong software writing review editing yunmei li supervision methodology resources kai cao writing review editing jie xu writing review editing yangyang li data curation software validation huaijing wang software validation honglei guo data curation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is financially supported by the national natural science foundation of china grant number 41871234 we are grateful to all the pis scientists and contributors who provided the glerl datasets data we thank the european space agency for providing the olci satellite images our thanks are extended to remote sensing application graduate students from nanjing normal university china for their aid with fieldwork and lab analyses acknowledgement for the data support from yangtze river delta science data center national earth system science data center national science technology infrastructure of china 
