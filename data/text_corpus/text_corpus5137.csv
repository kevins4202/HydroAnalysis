index,text
25685,the european spruce bark beetle ips typographus l is the most serious disturbance agent for european forests the complex interactions of many influencing factors need to be integrated into a model based decision support system to reduce the potential loss of forests this paper compares two methodological approaches for spatially explicit prediction of the predisposition for bark beetle infestations the fuzzy analytic hierarchy process and the bayesian belief networks were used in combination with a geographical information system to manage uncertainties using available data resources the two approaches were evaluated to produce robust results for forest practitioners and to support measures to minimize the spread of bark beetles the findings revealed that nearly 32 of the sites investigated in a case study were moderately high or high risk categories it is concluded that bbn is more efficient both methods can easily be used to analyze environmental problems involving complex interactions among various criteria graphical abstract image 1 keywords forest pest management bark beetle outbreak disturbance fuzzy ahp bbn gis 1 introduction bark beetle i typographus l infestations have been steadily increasing over recent decades and insect diseases and climate change are expected to damage about one million hectares of european forest in the near future seidl et al 2014 augustynczik et al 2021 droughts and the general rise in global temperature have triggered insect outbreaks and mortality of the norway spruce species pureswaran et al 2018 jactel et al 2019 as well as impacting the ecology threatening recreational activities and impacting the timber industry kunegel lion and lewis 2020b hlásny et al 2019 in the czech republic the annual loss of norway spruce growing stock through bark beetle attacks is around 3 1 5 4 for the period 2017 2019 hlásny et al 2021 the environmental and ecological pressures i e climatic changes acceleration of bark beetle spread dramatic decline of the norway spruce species and related economic losses are important drivers for adaptive forest management biedermann et al 2019 hlásny et al 2021 forest management requires a rational planning process to reduce the uncertainty involved in choosing between alternatives seidl et al 2017 understanding this complex and dynamic environment and identifying relevant factors can help minimize the risks and uncertainty the use of modern planning methods and low cost access to advanced geospatial technologies in particular can support short and long term strategic forest planning tahri et al 2021 in this context there has been a rapid rise in demand from forest practitioners for support in decision making based on the most recent findings in forest science vacik and lexer 2014 forest managers have to take the essential measures to avoid damage to trees in the future which requires a good understanding of the disturbance regimes the available human and financial resources can then be directed towards protecting the forests with a better chance of protecting the landscape in the future one of the challenges facing forest managers is the early detection of potential disturbance agents and adopting the relevant strategies to overcome them kunegel lion and lewis 2020a various statistical methods predictive models and expert systems have been applied to detect and prevent outbreaks of bark beetle netherer and nopp mayr 2005 pasztor et al 2014 including multi criteria analysis methods machine learning algorithms and remote sensing bright et al 2020 valdez vasquez et al 2020 hollaus and vreugdenhil 2019 radl et al 2018 seidl et al 2016 understanding the inter dependencies of forest disturbance agents and involving different stakeholders in decision making considering spatial and temporal aspects of bark beetle outbreaks is challenging many studies have highlighted the need for an integrated model combining the methodological advantages of different techniques tahri et al 2020 in this context the use of bayesian belief networks bbn and or fuzzy analytic hierarchy process fuzzy ahp techniques has been recently proposed in the fields of environmental and industrial problems ar et al 2020 shao et al 2020 fuzzy ahp and bbn are well known for their strengths in dealing with uncertainties and have proven to be robust in solving complex decision planning problems malczewski and rinner 2015 shao et al 2020 radl et al 2018 studied storm and bark beetle agent disturbances in mountain forests at stand scale applying a bbn including bark beetle damages as a sub model to predict the number of damaged trees it has been evidenced that an understanding of bayesian statistics is required for probabilistic analysis kokolakis 2010 and deterministic analysis is useful in many applications several fuzzy ahp technique studies have proved to be useful in identifying risk areas e g disasters and hazards for management planning yariyan et al 2020 lyu et al 2020 roy and saha 2019 haidara et al 2019 eskandari 2017 these studies indicate that they are reliably accurate when compared to ground truth and could provide a useful framework for other case studies the techniques involve different mathematical theories and require different input data bbn is based on the probabilistic interpretation of certain factors as a directed acyclic graph network process which can provide insight into conditional dependence and independence relations between variables by hypothetical observation pearl 1988 2009 expert knowledge is used in conjunction with empirical data in the graphical model fuzzy ahp is based on pairwise comparisons as a deterministic matrix from expert perception only saaty 1987 emrouznejad and ho 2017 however understanding of the effectiveness of such methods remains limited and no formalized comparison between approaches using fuzzy ahp and bbn combined with gis geographical information system has been carried out our aim is therefore to compare the fuzzy ahp and bbn approaches to identify the probability of a forest stand being infested by ips typographus l to address the issues of intensified tree mortality with bark beetle infestation two model based techniques are proposed for forest practitioners to reduce the uncertainty related to the future management of the forests under changing environmental conditions kjærulff and madsen 2008 we will demonstrate that the fuzzy ahp and bbn approach can be designed to help decision makers in managing ambiguity on different temporal and spatial scales regarding bark beetle outbreaks with this contribution we i introduce a combination of fuzzy ahp and bbn techniques with gis to predict spatially explicit vulnerability to bark beetle infestations and ii compare the characteristics and results of the two methodological approaches for a case study in the czech republic to identify the advantages and drawbacks for each method the fuzzy ahp model is used to estimate the importance of the predisposition criteria for ips typographus l following the procedure described in tahri et al 2017 the structure of the probabilistic network of the bbn is set up comparatively to the fuzzy ahp model following the recommendations of radl et al 2018 a geographical information system is used to map the estimated probability of bark beetle damages for both models based on national scale input data for the czech republic the approach proposed may help stakeholders gain a better understanding of the relevance of a large set of spatially explicit prediction parameters and support the design of prevention measures within a short time frame 2 material and methods 2 1 criteria for assessing predisposition to bark beetle infestation the selection of criteria for evaluating the predisposition of forest stands to bark beetle infestation was based on a literature review and inputs provided through an online panel discussion for the panel discussion online questionnaires were developed with input from forest entomology and forest ecology experts in total eight criteria were considered as important for predicting the predisposition proportion of norway spruce of basal area stand age average years drought categories precipitation mm year mean annual temperature c year solar radiation watt hours m2 altitude meters above sea level and soil type different edaphic factor categories the list of criteria is in line with many studies related to the assessment of forest data and site information as predisposing factors for i typographus l outbreaks e g netherer and nopp mayr 2005 pasztor et al 2014 hlásny et al 2021 a web based survey was designed to derive estimates for the importance of the evaluation criteria in a pairwise comparison matrix feedback provided via the online portal by the researchers involved in the survey was also analyzed the relation of the relevant criteria is shown in the visualization of the bayesian network diagram in fig 1 2 2 bayesian belief networks and gis bbn have been used in many different fields from medical science mclachlan et al 2020 hepler et al 2019 wang et al 1999 to environmental sciences roostaei et al 2021 baldock et al 2019 the latest literature review illustrates the emerging number of tools and practices developed de iuliis et al 2021 zhang and mahadevan 2021 landuyt et al 2015 in our study the causal influence of the identified predisposition variables on the potential i typographus l outbreaks for each stand is defined on a regional scale the aim is to identify whether or not a specific stand can be infested by the various x c child considered as variable a survey was carried out among researchers and senior consultants in the field of forest entomology and forest management planning with the aim of constructing a framework of influence diagrams for the bbn to reduce the burden of a large number of estimates for conditional probability distributions by the experts the elicitations were done in accordance with wisse et al 2008 applying the hugin expert tool the experts were asked to build the network structure and identify the names of variables and their relationships within the overall bark beetle disturbance once the network was constructed the elicitation was accomplished using expert interviews where experts expressed their beliefs using the verbal statements 1 certain 0 9 very probable 0 5 fifty fifty 0 2 not probable 0 1 unlikely 0 impossible this allowed a simple assessment in the conditional probability tables cpt with the experts in face to face interviews the calculation of the conditional probability for each value x k of variable x c was estimated using an elicitation method for bbn as below pa x c is the parent node of the variable x c and a corresponds to the variable assignment which is in our case low 1 moderately low 2 moderately high 3 and high 4 p x c p a x c a k x k p a x c w k i m i n k i m a x k f i d i i m a x k i m i n k where f i 0 1 0 1 were constructed by piecewise linear interpolation function through the points i joint a x c p x c x c a x c i min k min i k x k i joint a i max k max i k x k i joint a i joint a is the individual influence factor for each conditioning variable x k pa x c wisse et al 2008 when pa x c has positive influence on x c the joint influence factor i joint is as follow fleqntruemathmargin0pt i joint a k x k p a x c i k x k r a n k x k 1 k x k p a x c r a n k x k m a x 1 when pa x c has negative influence on x c the joint influence factor i joint is written fleqntruemathmargin0pt i joint a k x k p a x c i k x k r a n k x k m a x r a n k x k k x k p a x c r a n k x k m a x 1 w k representing the weight for each parent x k pa x c is defined as 1 w k 1 2 δ k n x p n p a x c δ n 1 2 δ k n x p n p a x c δ n where δ k and δ k are the highest and the lowest state of x c δ k p x c x c m a x a n e g k p x c x c m a x a n e g δ k p x c x c m i n a n e g p x c x c m i n a n e g k and a neg corresponds to the best combination assignment of parent state nodes for the x c low a n e g k is pa x c assignment where x k is in the most favorable state and all x m pa x c x k are in the least favorable p x c x c m a x a n e g k and p x c x c m i n a n e g k are the most and least favorable for high and low values of x c respectively all the criteria variables represented positive influences except for precipitation and altitude where high parent values pa x c contributed to the low probability child x c the input data for each compartment were converted into raster files and subdivided into four states from 1 to 4 applying the equal interval classification method in arcgis appendix a to support the calculations for this study the cpt algorithm was implemented built and a new cpt program was designed in matlab software to accelerate the computation modeling the results were then incorporated into hugin researcher software see network model in section software and or data availability once the rasters were stacked each raster was linked to a node in the model to propagate the evidence by applying the hugin plugin to the open source qgis fig 2 for each xy geographic location a bayesian network case consists of the input data as evidence for the input node i e linked to a raster layer the bayesian network inserts and propagates the evidence in the model resulting in two bands the probability of a state with maximum probability and the other band is an index of state with maximum probability youtube tutorial link section software and or data availability a scenario based sensitivity analysis of the bbn method was carried out for three different scenarios the aim of this type of sensitivity analysis is to assess the results of the model under specific types of scenario in the first scenario a bark beetle disturbance bbd was considered assuming higher temperatures and old aged forest stands for the two other scenarios mountain forests above 490 m altitude and lowland forests beyond 400 m altitude were considered table 1 the second scenario combined all high state nodes in the mountain forest stand and the third scenario corresponded to the worst case scenario of forests in lowland areas with low precipitation all high state nodes except for low state in terms of altitude and precipitation in addition the entropy was measured to check how far the probability mass was distributed across the states of a random variable cover and thomas kjærulff and madsen 2008 2 3 fuzzy analytical hierarchy process and gis the fuzzy ahp approach is a well known multi attribute decision making approach zadeh 1965 saaty 1987 it enables the expression of weights for each criterion to be calculated on the basis of expert knowledge and it also manages uncertain and imprecise data several steps are involved in applying the fuzzy ahp model in this study the vulnerability of forest areas to ips typographus l was assessed by collecting expert judgments on the importance of the predisposition criteria in a pairwise comparison matrix 1 equal importance 3 moderate importance 5 strongly important 9 very important saaty 1977 the model algorithm constructed has been used previously in other studies haidara et al 2019 tahri et al 2017 an online survey https bpmsg com ahp online calculator was used to retrieve expert knowledge on the importance of the evaluation criteria regarding the predisposing effect for bark beetle infestations and speed up the data collection process the values of the pairwise comparison matrix was extracted afterwards and incorporated in the fuzzy ahp computation modeling the algorithm was implemented in a matlab graphical user interface gui the application can be found in section software and or data availability as in buckley 1985 we noted by a i j k the relative importance of criteria i and criteria j given by the expert k l i j min a i j k m i j k 1 n a i j k n u i j max a i j k for all i j 1 n where l ij m ij and u ij are respectively minimum geometrical mean and maximum values of expert opinions pairwise comparison matrix among k experts derived from ahp online calculator the fuzzy judgment matrix a of experts was built independent of k defined by 2 a a i j 1 1 1 l 12 m 12 u 12 l 1 n m 1 n u 1 n l 21 m 21 u 21 1 1 1 l 2 n m 2 n u 2 n l n 1 m n 1 u n 1 l n 2 m n 2 u n 2 1 1 1 defuzzification of the fuzzy pairwise comparison matrix is given as liou and wang 1992 as follows for i j 3 g α μ a i j μ f α l i j 1 μ f α u i j 0 α μ 1 4 g α μ a i j 1 g α μ a i j 0 α μ 1 i j where α corresponds to an index to define stable or unstable conditions μ is an index of the degree of pessimism of a decision maker for the judgment matrix a while f α l ij and f α u ij are derived from α μ and from equation 3 and 4 as well tahri et al 2017 finally an i typographus l risk map was generated by applying overlay layers in arcgis software applying the geometrical mean values for the evaluation criteria derived by the experts 2 4 validation of methodological approaches two different approaches were taken to validate the robustness of the models i comparison with empirical observations from a field survey ii comparison with a reference map based on documented bark beetle infestations at national level first to assess the accuracy of the fuzzy ahp and bbn maps a survey was complemented by observations both in the field and in situ using google earth images ground truth data were collected between may and august 2019 at several spots in the study area to identify trees infected uninfected by bark beetles the spatial locations of 319 trees at the green attack stage were recorded using an arcgis collector app esri inc redlands ca installed on a mobile phone at the green attack stage trees do not show any sign of discoloration niemann and visintini 2005 so a visual survey of red brown boring dust was carried out to detect traces of beetles entering the bark uninfected trees were observed in situ linking the google earth image to arcgis where uninfected trees were clearly visible in situ by traces of salvage logging or afforestation and validated by an expert in the field points were selected to cross validate the predicted and field results using a confusion matrix second we used a map based on the mean percentage of trees affected by bark beetles between 2017 and 2019 at national level hlásny et al 2021 the majority of the input data for this map were based on statistical reports from the state agencies forest of the czech republic military forests and properties and the czech statistical office the surface area for each class was calculated using arcgis for each region the reference map and the map of infected uninfected trees were used to compare the outcomes for each model fuzzy ahp and bbn risk maps a script was built in rstudio software to compute the spatial differences between the two output raster datasets cell by cell bishop et al 1998 wealands et al 2005 and the fuzzy ahp and bbn maps for the same field area the two continuous raster variables were cropped and the data aggregated then resampled for the exact spatial resolution to ensure coherent correlation stack and linear model functions were also computed to generate a linear regression analysis in rstudio to define the heterogeneity of the fuzzy ahp and bbn models in this case the fuzzy ahp variable was considered as a linear predictor finally a pearson s correlation coefficient was calculated to compare the related differences and similarities between the fuzzy ahp and bbn methods 2 5 study area description and input data an area of around 20 to 30 106 m3 trees has been destroyed by i typographus l calamity in the czech republic out of 480 106 m3 of spruce timber in total between 1990 1997 the czech republic was ravaged by bark beetle outbreaks following a storm in 1990 brought on by several warm dry summers schelhaas et al 2003 over the period 1964 to 1991 over five times the amount of salvage logging 70 106 m3 was carried out than sanitation felling 13 106 m3 when intensity gradually increased modlinger and novotný 2015 within this context a representative study area was selected to include different landscape characteristics to test the approach the selected central bohemian region represents an excellent example of typical forest conditions in the czech republic the study area is situated 35 km south east of the capital prague between 14 41 56 4 longitude and 49 59 20 4 latitude and covers an area of 80 000 ha the area is characterized by four vegetation types with coniferous forest covering 61 followed by 32 mixed forest few areas are covered by broad leaved forest and transitional woodland shrub fig 3 the forests are dominated by norway spruce picea abies l and the stand age varies between 34 and 100 years while the oldest stands are mainly found in the west and the south the elevation in the study area ranges between 409 and 493 m and the average altitude is 430 m climate conditions vary significantly across the seasons and over the year the mean annual temperature is 7 9 c and the average annual precipitation is 686 mm although the southeast of the area often has no rainfall during the growing season a considerable proportion of the area receives high quantity solar irradiation the study area incorporates diverse edaphic conditions the forest site classification indicates acidic stagnic acidic deep loamy soils gleysols peat and organic soils all the geographical criteria information appears in appendix b the input data for the evaluation criteria of the fuzzy ahp and bbn applications are listed in appendix c all raster were resampled to cell size 200 200 m and the output of the spatial raster resolution of the both models were 1 0 54 the share of norway spruce stand age altitude and edaphic factors in the forest stand were collected from czech national forest inventory the survey was carried out between 2011 and 2014 by the forest management institute in the czech republic the point data were interpolated using geostatistical tools in the arcgis software and the ordinary kriging was applied to provide a logical framework for interpolation accuracy which resulted in a reduced mean square error the drought map was extracted as an image from intersucho portal and was digitalized and geo referenced in arcgis the droughts comprised standard classifications abnormally dry moderate drought severe drought and exceptional drought svoboda et al 2002 the solar radiation power per unit area was derived from the digital elevation model dem by applying the spatial analyst tool of arcgis the dem data were imported from nasa earth science data https search earthdata nasa gov 3 results 3 1 fuzzy ahp model 3 1 1 weight calculation and map following the steps in subsection 2 3 and incorporating the excel data for each expert opinion the weights were computed using the defuzzification matrix method in eq 3 and eq 4 according to the fuzzy ahp assessment methodology applied the eigenvalue was 8 60 the consistency ratio was 0 06 therefore the matrix judgments were considered reasonable and acceptable the derived criteria weights are presented in table 2 stand age and share of norway spruce were more relevant than the other criteria for detecting bark beetle outbreak predispositions with weights of 22 and 20 respectively the average temperature of over 8 5 c was considered a very high risk for spruce tree vulnerability also the role of droughts 17 was considered a strong evidence that norway spruce trees can be affected by bark beetles although the elevation above sea level m a s l is often considered to be a key parameter affecting bark beetle infestations in this case study the altitude was considered less important by the experts however there is a strong relation to the average temperature as it follows an altitudinal gradient the solar radiation criterion had the lowest weight with only 3 the different raster layer of the evaluation criteria were combined considering the derived weightings for the fuzzy ahp the resulting map is characterized by four levels of risk low risk moderately low risk moderately high risk and high risk areas prone to bark beetle infestation are indicated in fig 5a with the fuzzy ahp approach 38 of the study area is in the moderately high or high risk category while 25 is low or moderately low 3 1 2 sensitivity analysis of the fuzzy ahp model the sensitivity analysis of the fuzzy ahp criteria weights were assessed following the steps outlined by triantaphyllou and sánchez 1997 to demonstrate how changes in the weighting could change the ranking of the criteria the most sensitive criteria were temperature share of norway spruce and drought appendix table d as any changes to these criteria would influence the criteria ranking stand age solar radiation and soil type showed a lower sensitivity coefficient 3 2 bbn model 3 2 1 network and map based on expert assessments and according to eq 1 in subsection 2 2 table 3 shows each parent node weight w k the results show that predisposition and climate node are major drivers for bark beetle predisposition the weights of the child nodes specify that drought solar radiation and soil type contribute mostly to the parent nodes the results i joint were derived using matlab software all parents had positive influence on predisposition and bark beetle disturbance nodes i joint a low 0 i joint a m low 0 33 i joint a m high 0 66 and i joint a high 1 and one parent had negative influence on climate and site specific stand nodes i joint a low 0 i joint a m low 0 11 i joint a m high 0 44 and i joint a high 1 four polygons were derived from the piecewise linear functions to compute the estimation for each cpt node network following the algorithm by wisse et al 2008 the resulting graphical curves are shown in appendix e following the network structure design and based on the mathematical formula provided in subsection 2 3 one master bbn model for bark beetle infestation was built the matlab cpt automatic computation and network model outcomes are given in section software and or data availability following hugin tool fig 4 shows the bayesian network model for estimated bark beetle predisposition which was linked to qgis to derive a thematic risk map for the various factor categories an example was proposed in table 4 for summer with extreme climatic variables and winter with a high precipitation variable which revealed the maximal high disturbance risk as occurring in the summer season with a probability of 0 66 this result would occur only in extreme cases with high temperature drought and solar radiation variables the risk of bark beetle dropped to only 38 in the winter season as shown in the bbn map fig 5b 10 of the area has a probability risk of between 31 and 41 and around 22 of the area has a moderately low risk around 30 of the study area are classified within the two categories moderately high risk and high risk the most vulnerable sites are found in the central zone of the study area and in a few parts in the north the south and west are considered to be affected by a high probability level as well 3 2 2 sensitivity analysis of bbn model by simulating variations of the input values for share of norway spruce and stand age we computed the minimum current and maximum probability values for each bbd risk state the results are shown in table 5 the entropy was h bbd 1 09 of bbd risk this shows that observation of share of norway spruce variable would produce non significant variations in the posterior belief in states being moderately high moderately low or low a slight variation in the posterior belief was noted for the state of high however stand age showed significant variations in posterior belief for all states except moderately high the findings show that posterior distribution is very robust for variations in input from an investigation of the impact of different subsets of the evidence on each state of the hypothesis variable it is clear that the finding ϵ sa on sa stand age acts in favor of the hypothesis h bbd high on the other hand the evidence ϵ t on t temperature acts slightly against the hypothesis while the normalized likelihood of both evidence ϵ t and ϵ sa is 1 06 which acts slightly in favor of the hypothesis h bbd high the evidence therefore supports the hypothesis that an outbreak disturbance is driven by temperature and stand age in the worst case scenario the evidence ϵ pr precipitation acts against the hypothesis while ϵ sr solar radiation acts in favor of the hypothesis h bbd the model behavior representing a variation of the state for each of the variables observed is reported for scenarios 2 and 3 appendix table f the findings show that posterior distribution is relatively non sensitive to one way variations in individual nodes the distribution of bark beetle probability risk is non sensitive to variations in the precipitation node the most sensitive observation is altitude and soil type in scenario 2 and altitude followed by drought and solar radiation in scenario 3 the parameter sensitivity analysis of the bbd hypothesis shows the belief that bbd is high was 0 47 and the belief that it is low was 0 05 the altitude drought precipitation and solar radiation variables revealed the most sensitivities and were influential of all connected nodes tahri et al 2020 a tornado graph of all the root variables except t and sa is shown in the appendix fig g showing the possible variation of each state of bbd altitude is the variable with the greatest potential impact on the probability distribution of bbd and shows that solar radiation drought and precipitation also have the greatest potential impact on bbd probability distribution 3 3 spatial comparative analysis the two methodological approaches were compared in two steps i summary of the linear regression model and spatial correlation between the two resulting raster layer ii interpretation of the results of the two approaches in comparison with reference data sets appendix table h 3 3 1 comparison of risk maps a summary of the linear regression models resulting from the raster comparison of the fuzzy ahp and bbn outputs is given in table 6 a comparison of the two maps resulted in a reduced standard error coefficient 0 03 the result also reveals that the median was close to zero at 0 002 while the t coefficient values 116 86 45 71 were relatively high and are greatly relative to the standard error which could signify the existence of a relationship the residual standard error was 0 049 fig 6 shows the result of rstudio analysis note the moderate positive relationship between the two raster maps fuzzy ahp and bbn with a correlation coefficient of 0 66 with a confidence interval of 95 spatial correlation analysis of the difference maps is shown in the fig 6 the bbn model was more highly correlated with fuzzy ahp model which also can seem similar by visual observation most dark red color high risk areas are located in the north central and south where old forest cover mainly dominates the small differences observed were seen in the south and south west fig 5 3 3 2 validation of data with ground truth the accuracy assessment between the fuzzy ahp and bbn maps was compared with reference data and a field survey the overall confusion matrix with a confidence interval of 95 gave a result of nearly 87 kappa coefficient 71 for the bbn model while the overall confusion matrix for the fuzzy ahp model was 81 kappa coefficient 56 both models showed appropriate accuracy with the field survey this was also confirmed with the reference map hlásny et al 2021 where the kolin and praha regions were characterized by serious yearly losses of tree stock representing more than 73 of moderately high and highly vulnerable areas for both models appendix table h although the benesov region was more uncertain with both models the surrounding border was shown to be characterized by a high density of norway spruce species ancient forest stands with high temperature and low precipitation after checking the criteria maps which confirms the accuracy of the predicted results the mismatch can probably be explained by the different research scales used in the research the reference map was on the national scale while our own study was based on a regional scale the havlickuv brod location gave a contradictory outcome with the fuzzy ahp technique with climatic parameters assuming a high weighting and dominating the southern area in summary the bbn model gave more accurate prediction than the fuzzy ahp technique 4 discussion to our knowledge this comparative research is among the first examples where a regional bark beetle disturbance mapping was done with a fuzzy ahp and bbn modeling approach in a gis comparing the criteria ranks of both applications indicate that the most relevant criteria in the fuzzy ahp approach were quite similar to those with the bbn approach the parameters contributing to bark beetle disturbance in both models were share of norway spruce followed by temperature precipitation and drought in this study a lower risk was observed for young stands with a small share of norway spruce this interpretation concurs with works published previously stereńczak et al 2020 radl et al 2018 where high risk disturbance sites were characterized by ancient stand age and proportion of norway spruce as a dominant species mezei et al 2014 also demonstrated in their study that forest stand age and proportion of norway spruce are among the parameters that cause spruce mortality this research indicates that the denser the spruce tree cover and the more advanced the age of the forest the more vulnerable the trees are to bark beetle this has also been demonstrated by other studies holeksa et al 2017 hlásny and turčáni 2013 where these parameters were considered as major driving factors for intense damage in the disturbed areas also precipitation drought and temperature were often identified as relevant factors černý et al 2020 marini et al 2017 and many reviews consider climate variables such as temperature and precipitation as the two main drivers leading to mass outbreaks of bark beetle brandl et al 2020 christiansen et al 1987 matthews et al 2018 also perceived a dependence on whether or not a drought had occurred in the region netherer et al 2019 investigated environmental drivers for bark beetle spread in the case of austrian norway spruce stands the authors concluded that the warm temperature and acute disposition of the trees to attack caused by drought stress was likely to increase the risk of bark beetle infestation the results of the work by radl et al 2018 were used to validate the results of this study for comparison purposes the probability level based on four criteria was extracted stand age share of norway spruce drought and soil type the bbn model of this study allows to reproduce similar results table 7 despite the different input models and selected criteria in the austrian and czech cases the overall outcomes of the studies have some similarities older stands and a higher proportion of norway spruce in combination with an extreme drought event seem to contribute to higher probabilities for damages the worst and best scenarios revealed the estimated probability distributions according to the most up to date scientific literature findings on bark beetle disturbance the applied methodological approaches are different in terms of the underlying mathematical theories while fuzzy ahp requires a hierarchical process mode bbn is based on a network process taking into account inter dependencies between variables nevertheless the major advantages and drawbacks of both methods are identified along with the potential trade offs a summary of the differences between the two methods based on literature reviews and the present research experiment is given in table 8 concerning calculations both approaches deal with uncertainty and imprecise data and require more complex systems for this reason the fuzzy ahp matlab gui application is proposed for the non specialist as it provides straightforward guidance for a broad range of decision makers academics ecologists consultants etc to facilitate the decision making process for better understanding of forest issues while using bbn in our study research the cpt matlab program was found to be useful but limited to two or three directed node graphs a new cpt algorithm is needed requiring an additional long process in cases with four or more interconnected nodes on the other hand bbn can support a large number of criteria in the model unlike fuzzy ahp the method has a threshold on the number of criteria that can be incorporated a pairwise comparison questionnaire was carried out in fuzzy ahp applying a free web survey integrated with mobile devices available on the market the online questionnaire offering a user friendly remote tool to involve various experts independently the fuzzy ahp was consequently quicker at collecting expert judgments and avoided conflicting compromises between parties more readily the fundamental limitation of fuzzy ahp is that the required data input is restricted expert judgment only according to the saaty 9 point scale in addition the pairwise comparison questionnaire offers non familiarity among stakeholders tahri et al 2017 although there are no pairwise comparison matrices with the bbn technique its main strength is the ability to acquire probabilistic interdependency between uncertain variables dai et al 2021 based on non homogeneous variables and many different types of input data in one functional model expressing probability beliefs demanded enormous concentration but required a limited number of experts max 2 per case study to retrieve expert perceptions the major weaknesses associated with the bbn method compared to the fuzzy ahp technique are its highly complicated processes it was time consuming to implement and retrieving the input data to convert into conditional probability data was inherently challenging this was also confirmed by the majority of previous studies barton et al 2020 nascimento et al 2019 although the overwhelming relationship between dependence independence probability nodes was problematic one of the key advantages of the bbn method is that it offers meticulous transparency and produces dynamic results li et al 2020 laurila pant et al 2019 and also proves to be more precise at stand and local levels building a sample regional bbn model generates multiple scenarios based on the various knowledge sources höfer et al 2020 which provides an insight into the relationship between the forest components and the output nodes for each scenario the functional model can be applied to other local and or regional forest enterprises by simply changing the input data the spatial bbn represents a trade off between assessing the impact of bark beetle on different ecosystem services and stakeholders knowledge of the effects on forest management practices morris et al 2017 after overlaying and resampling different criteria spatial patterns at regional and local scales were easy to access for both methods and gave closely matching results in compiling thematic maps this research corroborates the work of hlásny et al 2021 where the kolin praha and kutna hora regions were well matched in three models according to the confusion matrix results the bbn model gives better results than the fuzzy ahp model it is argued that the maps produced provide both support for forest management planning to prevent further disturbance and monitoring for efficient strategic decision making an improved understanding of regulated timber harvesting is therefore needed which can be achieved by the introduction of salvage logging management vanická et al 2020 dobor et al 2020 and the reforestation and plantation of trees in the most suitable areas thorn et al 2017 macek et al 2017 nováková and edwards jonášová 2015 the results of ground truth and reference data validations reveal that bbn is more efficient than the fuzzy ahp but it cannot be concluded that bbn is more effective than the other model as either of them may predominate depending on processing time knowledge source and goal priority the bbn technique requires computing capabilities and is time consuming to implement but is more accurate and flexible in forest stands since it takes into account many different types of dataset unlike fuzzy ahp matlab gui is a user friendly tool offering rapid processing and is practical at large spatial and temporal scales most importantly both methods are reproducible for use in other types of case study involving stakeholder insights and future priority research 5 conclusion this research will be of great help for forest managers but also for conducting further field research in this area the results obtained from overlaying raster maps of the spatial multi criteria decision making method and bayesian belief network analyses showed that most locations had a similar level of relevance in the region the current situation is challenging in terms of rethinking spatial planning time available for data collection and the high costs of field research two decision support system methods were selected to detect sites potentially disturbed by bark beetles the work carried out required input of a geo referenced data set several meteorological topographical and forest stand parameters were obtained including the extraction of forest vegetation and use of the national forest inventory database however once the methods and data are provided it is possible to update the input data layer quickly and perform scenario analysis by changing the importance of the evaluation criteria this will allow a more robust and less sensitive prediction of bark beetle infestations in the future the new matlab code was effective for both techniques facilitating accurate computational algorithms and programs the conditional probability table code and the fuzzy ahp matlab user interface tools are both useful for application in other study fields the cpt code greatly speeds up processing time and provides a dynamic output model for each stand depending on seasonal distribution since the fuzzy ahp code can be converted to a simple graphical user interface which no longer requires a fuzzy specialist to compute the model the fixed output weight could be used in forest areas worldwide the results of the comparison show that both applications can easily be used to provide solutions for complex environmental decision making problems the efficiency of fuzzy ahp matlab gui was tested for use as an early warning tool while the bbn approach proved to be effective for dynamic and small scale landscapes software and or data availability the fuzzy ahp matlab gui is freely available via the github link https github com meyem4 foman fa it was developed by haytham tahri haytham tahri gmail com and meryem tahri see co author contact information and launched in 2020 conditional probability tables and i typographus l network model outcomes are provided via the github link https github com meyem4 foman itl bbn hugin expert software is required to run the i typographus l network model this was developed by meryem tahri under the supervision of prof anders l madsen see co author contact information a youtube tutorial on the hugin plugin for qgis mapping produced by prof anders l madsen is provided at https www youtube com watch v zcdftmj5tou declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by grant eva4 0 no cz 02 1 01 0 0 0 0 16 019 0000803 financed by op rde the authors gratefully acknowledge prof dr daniel ames editor in chief and anonymous reviewers for their scientific expertise we would like to thank consultants who participated in our survey in particular thank to dr andrew liebhold from us forest service northern research station appendix a criteria and or node description states parameter criteria variable node description state 1 low risk 2 moderate low risk 3 moderate high risk 4 high risk predisposition share of norway spruce proportion of norway spruce in the stand dense spruce areas result in stronger i typographus l attacks on trees low density moderate density high density very high density drought lack of rainfall drought has significant influence on bark beetle abnormally dry moderate drought severe drought exceptional drought stand age years age of stand the older the forest the higher the risk 50 50 64 64 78 78 climate annual temperature c average yearly air temperature high temperature accelerates tree vulnerability stress 6 3 7 6 7 6 8 0 8 0 8 50 8 50 9 2 solar radiation watt hours m2 solar radiation power per unit area greater propagation attracts i typographus l 322k 864k 864k 956k 956k 1 021k 1 021k 1 191k annual precipitation mm annual precipitation high precipitation reduces risk of i typographus l 706 820 660 706 622 660 550 622 site specific stand altitude m elevation above sea level lower areas have negative impact 526 464 526 400 464 338 400 edaphic category soil type edaphic or ecological gley soil waterlogged soil peats organic soil rich in water soils fertile soils acid soils appendix b raster criteria considered in the application of fuzzy ahp and bbn models in the central bohemian region image 2 appendix c source table for data used parameter institution data origin access format cell size resolution share of norway spruce forest management institute czech national forest inventory 2011 2014 database accdb 200 m stand age years forest management institute czech national forest inventory 2011 2014 database accdb 200 m annual temperature c czech hydrometeorological institute meteorological station http portal chmi cz ascii raster asc 500 m annual precipitation mm czech hydrometeorological institute meteorological station http portal chmi cz ascii raster asc 150 m solar radiation wh m2 nasa aster sensor https search earthdata nasa gov raster digital elevation model 30 m drought intersucho https www intersucho cz pdf map digitalization 500 m altitude m a s l forest management institute czech national forest inventory 2011 2014 database accdb 30 m edaphic categories forest management institute czech national forest inventory 2011 2014 database accdb 200 m appendix d sensitivity analysis results of fuzzy ahp decision making solar radiation share of norway spruce stand age altitude temperature soil type precipitation drought criticality degree of criterion c k 369 1 8 9 95 5 9 1 7 9 74 2 77 3 55 sensitivity coefficient of criterion 1 c k 0 00 0 56 0 10 0 17 0 59 0 10 0 36 0 28 ranking 8 2 7 5 1 6 3 4 appendix e graphical curve outcome examples to derive estimation of cpt distributions image 3 appendix f sensitivity analysis min max analysis of each observed node given the remaining observed nodes scenario 3 scenario 2 min max min max precipitation bark beetle disturbance risk high 0 74 0 75 0 63 0 65 bark beetle disturbance risk moderately high 0 17 0 18 0 2 0 21 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 09 bark beetle disturbance risk low 0 03 0 03 0 06 0 07 soil type bark beetle disturbance risk high 0 73 0 75 0 53 0 63 bark beetle disturbance risk moderately high 0 17 0 18 0 21 0 23 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 13 bark beetle disturbance risk low 0 03 0 03 0 07 0 12 altitude bark beetle disturbance risk high 0 65 0 75 0 63 0 73 bark beetle disturbance risk moderately high 0 17 0 2 0 18 0 2 bark beetle disturbance risk moderately low 0 05 0 08 0 06 0 09 bark beetle disturbance risk low 0 03 0 06 0 03 0 07 drought bark beetle disturbance risk high 0 7 0 75 0 57 0 63 bark beetle disturbance risk moderately high 0 17 0 19 0 21 0 22 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 12 bark beetle disturbance risk low 0 03 0 04 0 07 0 1 stand age bark beetle disturbance risk high 0 72 0 75 0 6 0 63 bark beetle disturbance risk moderately high 0 18 0 17 0 21 0 21 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 1 bark beetle disturbance risk low 0 02 0 03 0 07 0 08 temperature bark beetle disturbance risk high 0 73 0 75 0 52 0 63 bark beetle disturbance risk moderately high 0 17 0 17 0 21 0 22 bark beetle disturbance risk moderately low 0 05 0 05 0 09 0 13 bark beetle disturbance risk low 0 02 0 03 0 07 0 12 solar radiation bark beetle disturbance risk high 0 7 0 75 0 56 0 64 bark beetle disturbance risk moderately high 0 17 0 18 0 2 0 22 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 12 bark beetle disturbance risk low 0 02 0 04 0 07 0 1 share of norway spruce bark beetle disturbance risk high 0 73 0 75 0 61 0 63 bark beetle disturbance risk moderately high 0 17 0 17 0 21 0 21 bark beetle disturbance risk moderately low 0 05 0 05 0 09 0 1 bark beetle disturbance risk low 0 02 0 03 0 07 0 08 appendix g tornado graph of all root variables except temperature and stand age nodes image 4 appendix h comparison with reference map reference data hlásny et al 2021 this study region of trees stock loss yearly categorie of surface area using fuzzy ahp of surface area using bbn kolin 5 7 low risk 0 0 moderately low risk 5 2 moderately high risk 65 24 high risk 30 73 praha vychod 3 5 low risk 0 10 moderately low risk 15 17 moderately high risk 73 32 high risk 12 41 kutna hora 3 5 low risk 48 25 moderately low risk 32 32 moderately high risk 21 24 high risk 0 19 benesov 2 3 low risk 6 8 moderately low risk 35 27 moderately high risk 54 34 high risk 5 32 havlickuv brod 5 7 low risk 48 16 moderately low risk 32 41 moderately high risk 21 34 high risk 0 9 
25685,the european spruce bark beetle ips typographus l is the most serious disturbance agent for european forests the complex interactions of many influencing factors need to be integrated into a model based decision support system to reduce the potential loss of forests this paper compares two methodological approaches for spatially explicit prediction of the predisposition for bark beetle infestations the fuzzy analytic hierarchy process and the bayesian belief networks were used in combination with a geographical information system to manage uncertainties using available data resources the two approaches were evaluated to produce robust results for forest practitioners and to support measures to minimize the spread of bark beetles the findings revealed that nearly 32 of the sites investigated in a case study were moderately high or high risk categories it is concluded that bbn is more efficient both methods can easily be used to analyze environmental problems involving complex interactions among various criteria graphical abstract image 1 keywords forest pest management bark beetle outbreak disturbance fuzzy ahp bbn gis 1 introduction bark beetle i typographus l infestations have been steadily increasing over recent decades and insect diseases and climate change are expected to damage about one million hectares of european forest in the near future seidl et al 2014 augustynczik et al 2021 droughts and the general rise in global temperature have triggered insect outbreaks and mortality of the norway spruce species pureswaran et al 2018 jactel et al 2019 as well as impacting the ecology threatening recreational activities and impacting the timber industry kunegel lion and lewis 2020b hlásny et al 2019 in the czech republic the annual loss of norway spruce growing stock through bark beetle attacks is around 3 1 5 4 for the period 2017 2019 hlásny et al 2021 the environmental and ecological pressures i e climatic changes acceleration of bark beetle spread dramatic decline of the norway spruce species and related economic losses are important drivers for adaptive forest management biedermann et al 2019 hlásny et al 2021 forest management requires a rational planning process to reduce the uncertainty involved in choosing between alternatives seidl et al 2017 understanding this complex and dynamic environment and identifying relevant factors can help minimize the risks and uncertainty the use of modern planning methods and low cost access to advanced geospatial technologies in particular can support short and long term strategic forest planning tahri et al 2021 in this context there has been a rapid rise in demand from forest practitioners for support in decision making based on the most recent findings in forest science vacik and lexer 2014 forest managers have to take the essential measures to avoid damage to trees in the future which requires a good understanding of the disturbance regimes the available human and financial resources can then be directed towards protecting the forests with a better chance of protecting the landscape in the future one of the challenges facing forest managers is the early detection of potential disturbance agents and adopting the relevant strategies to overcome them kunegel lion and lewis 2020a various statistical methods predictive models and expert systems have been applied to detect and prevent outbreaks of bark beetle netherer and nopp mayr 2005 pasztor et al 2014 including multi criteria analysis methods machine learning algorithms and remote sensing bright et al 2020 valdez vasquez et al 2020 hollaus and vreugdenhil 2019 radl et al 2018 seidl et al 2016 understanding the inter dependencies of forest disturbance agents and involving different stakeholders in decision making considering spatial and temporal aspects of bark beetle outbreaks is challenging many studies have highlighted the need for an integrated model combining the methodological advantages of different techniques tahri et al 2020 in this context the use of bayesian belief networks bbn and or fuzzy analytic hierarchy process fuzzy ahp techniques has been recently proposed in the fields of environmental and industrial problems ar et al 2020 shao et al 2020 fuzzy ahp and bbn are well known for their strengths in dealing with uncertainties and have proven to be robust in solving complex decision planning problems malczewski and rinner 2015 shao et al 2020 radl et al 2018 studied storm and bark beetle agent disturbances in mountain forests at stand scale applying a bbn including bark beetle damages as a sub model to predict the number of damaged trees it has been evidenced that an understanding of bayesian statistics is required for probabilistic analysis kokolakis 2010 and deterministic analysis is useful in many applications several fuzzy ahp technique studies have proved to be useful in identifying risk areas e g disasters and hazards for management planning yariyan et al 2020 lyu et al 2020 roy and saha 2019 haidara et al 2019 eskandari 2017 these studies indicate that they are reliably accurate when compared to ground truth and could provide a useful framework for other case studies the techniques involve different mathematical theories and require different input data bbn is based on the probabilistic interpretation of certain factors as a directed acyclic graph network process which can provide insight into conditional dependence and independence relations between variables by hypothetical observation pearl 1988 2009 expert knowledge is used in conjunction with empirical data in the graphical model fuzzy ahp is based on pairwise comparisons as a deterministic matrix from expert perception only saaty 1987 emrouznejad and ho 2017 however understanding of the effectiveness of such methods remains limited and no formalized comparison between approaches using fuzzy ahp and bbn combined with gis geographical information system has been carried out our aim is therefore to compare the fuzzy ahp and bbn approaches to identify the probability of a forest stand being infested by ips typographus l to address the issues of intensified tree mortality with bark beetle infestation two model based techniques are proposed for forest practitioners to reduce the uncertainty related to the future management of the forests under changing environmental conditions kjærulff and madsen 2008 we will demonstrate that the fuzzy ahp and bbn approach can be designed to help decision makers in managing ambiguity on different temporal and spatial scales regarding bark beetle outbreaks with this contribution we i introduce a combination of fuzzy ahp and bbn techniques with gis to predict spatially explicit vulnerability to bark beetle infestations and ii compare the characteristics and results of the two methodological approaches for a case study in the czech republic to identify the advantages and drawbacks for each method the fuzzy ahp model is used to estimate the importance of the predisposition criteria for ips typographus l following the procedure described in tahri et al 2017 the structure of the probabilistic network of the bbn is set up comparatively to the fuzzy ahp model following the recommendations of radl et al 2018 a geographical information system is used to map the estimated probability of bark beetle damages for both models based on national scale input data for the czech republic the approach proposed may help stakeholders gain a better understanding of the relevance of a large set of spatially explicit prediction parameters and support the design of prevention measures within a short time frame 2 material and methods 2 1 criteria for assessing predisposition to bark beetle infestation the selection of criteria for evaluating the predisposition of forest stands to bark beetle infestation was based on a literature review and inputs provided through an online panel discussion for the panel discussion online questionnaires were developed with input from forest entomology and forest ecology experts in total eight criteria were considered as important for predicting the predisposition proportion of norway spruce of basal area stand age average years drought categories precipitation mm year mean annual temperature c year solar radiation watt hours m2 altitude meters above sea level and soil type different edaphic factor categories the list of criteria is in line with many studies related to the assessment of forest data and site information as predisposing factors for i typographus l outbreaks e g netherer and nopp mayr 2005 pasztor et al 2014 hlásny et al 2021 a web based survey was designed to derive estimates for the importance of the evaluation criteria in a pairwise comparison matrix feedback provided via the online portal by the researchers involved in the survey was also analyzed the relation of the relevant criteria is shown in the visualization of the bayesian network diagram in fig 1 2 2 bayesian belief networks and gis bbn have been used in many different fields from medical science mclachlan et al 2020 hepler et al 2019 wang et al 1999 to environmental sciences roostaei et al 2021 baldock et al 2019 the latest literature review illustrates the emerging number of tools and practices developed de iuliis et al 2021 zhang and mahadevan 2021 landuyt et al 2015 in our study the causal influence of the identified predisposition variables on the potential i typographus l outbreaks for each stand is defined on a regional scale the aim is to identify whether or not a specific stand can be infested by the various x c child considered as variable a survey was carried out among researchers and senior consultants in the field of forest entomology and forest management planning with the aim of constructing a framework of influence diagrams for the bbn to reduce the burden of a large number of estimates for conditional probability distributions by the experts the elicitations were done in accordance with wisse et al 2008 applying the hugin expert tool the experts were asked to build the network structure and identify the names of variables and their relationships within the overall bark beetle disturbance once the network was constructed the elicitation was accomplished using expert interviews where experts expressed their beliefs using the verbal statements 1 certain 0 9 very probable 0 5 fifty fifty 0 2 not probable 0 1 unlikely 0 impossible this allowed a simple assessment in the conditional probability tables cpt with the experts in face to face interviews the calculation of the conditional probability for each value x k of variable x c was estimated using an elicitation method for bbn as below pa x c is the parent node of the variable x c and a corresponds to the variable assignment which is in our case low 1 moderately low 2 moderately high 3 and high 4 p x c p a x c a k x k p a x c w k i m i n k i m a x k f i d i i m a x k i m i n k where f i 0 1 0 1 were constructed by piecewise linear interpolation function through the points i joint a x c p x c x c a x c i min k min i k x k i joint a i max k max i k x k i joint a i joint a is the individual influence factor for each conditioning variable x k pa x c wisse et al 2008 when pa x c has positive influence on x c the joint influence factor i joint is as follow fleqntruemathmargin0pt i joint a k x k p a x c i k x k r a n k x k 1 k x k p a x c r a n k x k m a x 1 when pa x c has negative influence on x c the joint influence factor i joint is written fleqntruemathmargin0pt i joint a k x k p a x c i k x k r a n k x k m a x r a n k x k k x k p a x c r a n k x k m a x 1 w k representing the weight for each parent x k pa x c is defined as 1 w k 1 2 δ k n x p n p a x c δ n 1 2 δ k n x p n p a x c δ n where δ k and δ k are the highest and the lowest state of x c δ k p x c x c m a x a n e g k p x c x c m a x a n e g δ k p x c x c m i n a n e g p x c x c m i n a n e g k and a neg corresponds to the best combination assignment of parent state nodes for the x c low a n e g k is pa x c assignment where x k is in the most favorable state and all x m pa x c x k are in the least favorable p x c x c m a x a n e g k and p x c x c m i n a n e g k are the most and least favorable for high and low values of x c respectively all the criteria variables represented positive influences except for precipitation and altitude where high parent values pa x c contributed to the low probability child x c the input data for each compartment were converted into raster files and subdivided into four states from 1 to 4 applying the equal interval classification method in arcgis appendix a to support the calculations for this study the cpt algorithm was implemented built and a new cpt program was designed in matlab software to accelerate the computation modeling the results were then incorporated into hugin researcher software see network model in section software and or data availability once the rasters were stacked each raster was linked to a node in the model to propagate the evidence by applying the hugin plugin to the open source qgis fig 2 for each xy geographic location a bayesian network case consists of the input data as evidence for the input node i e linked to a raster layer the bayesian network inserts and propagates the evidence in the model resulting in two bands the probability of a state with maximum probability and the other band is an index of state with maximum probability youtube tutorial link section software and or data availability a scenario based sensitivity analysis of the bbn method was carried out for three different scenarios the aim of this type of sensitivity analysis is to assess the results of the model under specific types of scenario in the first scenario a bark beetle disturbance bbd was considered assuming higher temperatures and old aged forest stands for the two other scenarios mountain forests above 490 m altitude and lowland forests beyond 400 m altitude were considered table 1 the second scenario combined all high state nodes in the mountain forest stand and the third scenario corresponded to the worst case scenario of forests in lowland areas with low precipitation all high state nodes except for low state in terms of altitude and precipitation in addition the entropy was measured to check how far the probability mass was distributed across the states of a random variable cover and thomas kjærulff and madsen 2008 2 3 fuzzy analytical hierarchy process and gis the fuzzy ahp approach is a well known multi attribute decision making approach zadeh 1965 saaty 1987 it enables the expression of weights for each criterion to be calculated on the basis of expert knowledge and it also manages uncertain and imprecise data several steps are involved in applying the fuzzy ahp model in this study the vulnerability of forest areas to ips typographus l was assessed by collecting expert judgments on the importance of the predisposition criteria in a pairwise comparison matrix 1 equal importance 3 moderate importance 5 strongly important 9 very important saaty 1977 the model algorithm constructed has been used previously in other studies haidara et al 2019 tahri et al 2017 an online survey https bpmsg com ahp online calculator was used to retrieve expert knowledge on the importance of the evaluation criteria regarding the predisposing effect for bark beetle infestations and speed up the data collection process the values of the pairwise comparison matrix was extracted afterwards and incorporated in the fuzzy ahp computation modeling the algorithm was implemented in a matlab graphical user interface gui the application can be found in section software and or data availability as in buckley 1985 we noted by a i j k the relative importance of criteria i and criteria j given by the expert k l i j min a i j k m i j k 1 n a i j k n u i j max a i j k for all i j 1 n where l ij m ij and u ij are respectively minimum geometrical mean and maximum values of expert opinions pairwise comparison matrix among k experts derived from ahp online calculator the fuzzy judgment matrix a of experts was built independent of k defined by 2 a a i j 1 1 1 l 12 m 12 u 12 l 1 n m 1 n u 1 n l 21 m 21 u 21 1 1 1 l 2 n m 2 n u 2 n l n 1 m n 1 u n 1 l n 2 m n 2 u n 2 1 1 1 defuzzification of the fuzzy pairwise comparison matrix is given as liou and wang 1992 as follows for i j 3 g α μ a i j μ f α l i j 1 μ f α u i j 0 α μ 1 4 g α μ a i j 1 g α μ a i j 0 α μ 1 i j where α corresponds to an index to define stable or unstable conditions μ is an index of the degree of pessimism of a decision maker for the judgment matrix a while f α l ij and f α u ij are derived from α μ and from equation 3 and 4 as well tahri et al 2017 finally an i typographus l risk map was generated by applying overlay layers in arcgis software applying the geometrical mean values for the evaluation criteria derived by the experts 2 4 validation of methodological approaches two different approaches were taken to validate the robustness of the models i comparison with empirical observations from a field survey ii comparison with a reference map based on documented bark beetle infestations at national level first to assess the accuracy of the fuzzy ahp and bbn maps a survey was complemented by observations both in the field and in situ using google earth images ground truth data were collected between may and august 2019 at several spots in the study area to identify trees infected uninfected by bark beetles the spatial locations of 319 trees at the green attack stage were recorded using an arcgis collector app esri inc redlands ca installed on a mobile phone at the green attack stage trees do not show any sign of discoloration niemann and visintini 2005 so a visual survey of red brown boring dust was carried out to detect traces of beetles entering the bark uninfected trees were observed in situ linking the google earth image to arcgis where uninfected trees were clearly visible in situ by traces of salvage logging or afforestation and validated by an expert in the field points were selected to cross validate the predicted and field results using a confusion matrix second we used a map based on the mean percentage of trees affected by bark beetles between 2017 and 2019 at national level hlásny et al 2021 the majority of the input data for this map were based on statistical reports from the state agencies forest of the czech republic military forests and properties and the czech statistical office the surface area for each class was calculated using arcgis for each region the reference map and the map of infected uninfected trees were used to compare the outcomes for each model fuzzy ahp and bbn risk maps a script was built in rstudio software to compute the spatial differences between the two output raster datasets cell by cell bishop et al 1998 wealands et al 2005 and the fuzzy ahp and bbn maps for the same field area the two continuous raster variables were cropped and the data aggregated then resampled for the exact spatial resolution to ensure coherent correlation stack and linear model functions were also computed to generate a linear regression analysis in rstudio to define the heterogeneity of the fuzzy ahp and bbn models in this case the fuzzy ahp variable was considered as a linear predictor finally a pearson s correlation coefficient was calculated to compare the related differences and similarities between the fuzzy ahp and bbn methods 2 5 study area description and input data an area of around 20 to 30 106 m3 trees has been destroyed by i typographus l calamity in the czech republic out of 480 106 m3 of spruce timber in total between 1990 1997 the czech republic was ravaged by bark beetle outbreaks following a storm in 1990 brought on by several warm dry summers schelhaas et al 2003 over the period 1964 to 1991 over five times the amount of salvage logging 70 106 m3 was carried out than sanitation felling 13 106 m3 when intensity gradually increased modlinger and novotný 2015 within this context a representative study area was selected to include different landscape characteristics to test the approach the selected central bohemian region represents an excellent example of typical forest conditions in the czech republic the study area is situated 35 km south east of the capital prague between 14 41 56 4 longitude and 49 59 20 4 latitude and covers an area of 80 000 ha the area is characterized by four vegetation types with coniferous forest covering 61 followed by 32 mixed forest few areas are covered by broad leaved forest and transitional woodland shrub fig 3 the forests are dominated by norway spruce picea abies l and the stand age varies between 34 and 100 years while the oldest stands are mainly found in the west and the south the elevation in the study area ranges between 409 and 493 m and the average altitude is 430 m climate conditions vary significantly across the seasons and over the year the mean annual temperature is 7 9 c and the average annual precipitation is 686 mm although the southeast of the area often has no rainfall during the growing season a considerable proportion of the area receives high quantity solar irradiation the study area incorporates diverse edaphic conditions the forest site classification indicates acidic stagnic acidic deep loamy soils gleysols peat and organic soils all the geographical criteria information appears in appendix b the input data for the evaluation criteria of the fuzzy ahp and bbn applications are listed in appendix c all raster were resampled to cell size 200 200 m and the output of the spatial raster resolution of the both models were 1 0 54 the share of norway spruce stand age altitude and edaphic factors in the forest stand were collected from czech national forest inventory the survey was carried out between 2011 and 2014 by the forest management institute in the czech republic the point data were interpolated using geostatistical tools in the arcgis software and the ordinary kriging was applied to provide a logical framework for interpolation accuracy which resulted in a reduced mean square error the drought map was extracted as an image from intersucho portal and was digitalized and geo referenced in arcgis the droughts comprised standard classifications abnormally dry moderate drought severe drought and exceptional drought svoboda et al 2002 the solar radiation power per unit area was derived from the digital elevation model dem by applying the spatial analyst tool of arcgis the dem data were imported from nasa earth science data https search earthdata nasa gov 3 results 3 1 fuzzy ahp model 3 1 1 weight calculation and map following the steps in subsection 2 3 and incorporating the excel data for each expert opinion the weights were computed using the defuzzification matrix method in eq 3 and eq 4 according to the fuzzy ahp assessment methodology applied the eigenvalue was 8 60 the consistency ratio was 0 06 therefore the matrix judgments were considered reasonable and acceptable the derived criteria weights are presented in table 2 stand age and share of norway spruce were more relevant than the other criteria for detecting bark beetle outbreak predispositions with weights of 22 and 20 respectively the average temperature of over 8 5 c was considered a very high risk for spruce tree vulnerability also the role of droughts 17 was considered a strong evidence that norway spruce trees can be affected by bark beetles although the elevation above sea level m a s l is often considered to be a key parameter affecting bark beetle infestations in this case study the altitude was considered less important by the experts however there is a strong relation to the average temperature as it follows an altitudinal gradient the solar radiation criterion had the lowest weight with only 3 the different raster layer of the evaluation criteria were combined considering the derived weightings for the fuzzy ahp the resulting map is characterized by four levels of risk low risk moderately low risk moderately high risk and high risk areas prone to bark beetle infestation are indicated in fig 5a with the fuzzy ahp approach 38 of the study area is in the moderately high or high risk category while 25 is low or moderately low 3 1 2 sensitivity analysis of the fuzzy ahp model the sensitivity analysis of the fuzzy ahp criteria weights were assessed following the steps outlined by triantaphyllou and sánchez 1997 to demonstrate how changes in the weighting could change the ranking of the criteria the most sensitive criteria were temperature share of norway spruce and drought appendix table d as any changes to these criteria would influence the criteria ranking stand age solar radiation and soil type showed a lower sensitivity coefficient 3 2 bbn model 3 2 1 network and map based on expert assessments and according to eq 1 in subsection 2 2 table 3 shows each parent node weight w k the results show that predisposition and climate node are major drivers for bark beetle predisposition the weights of the child nodes specify that drought solar radiation and soil type contribute mostly to the parent nodes the results i joint were derived using matlab software all parents had positive influence on predisposition and bark beetle disturbance nodes i joint a low 0 i joint a m low 0 33 i joint a m high 0 66 and i joint a high 1 and one parent had negative influence on climate and site specific stand nodes i joint a low 0 i joint a m low 0 11 i joint a m high 0 44 and i joint a high 1 four polygons were derived from the piecewise linear functions to compute the estimation for each cpt node network following the algorithm by wisse et al 2008 the resulting graphical curves are shown in appendix e following the network structure design and based on the mathematical formula provided in subsection 2 3 one master bbn model for bark beetle infestation was built the matlab cpt automatic computation and network model outcomes are given in section software and or data availability following hugin tool fig 4 shows the bayesian network model for estimated bark beetle predisposition which was linked to qgis to derive a thematic risk map for the various factor categories an example was proposed in table 4 for summer with extreme climatic variables and winter with a high precipitation variable which revealed the maximal high disturbance risk as occurring in the summer season with a probability of 0 66 this result would occur only in extreme cases with high temperature drought and solar radiation variables the risk of bark beetle dropped to only 38 in the winter season as shown in the bbn map fig 5b 10 of the area has a probability risk of between 31 and 41 and around 22 of the area has a moderately low risk around 30 of the study area are classified within the two categories moderately high risk and high risk the most vulnerable sites are found in the central zone of the study area and in a few parts in the north the south and west are considered to be affected by a high probability level as well 3 2 2 sensitivity analysis of bbn model by simulating variations of the input values for share of norway spruce and stand age we computed the minimum current and maximum probability values for each bbd risk state the results are shown in table 5 the entropy was h bbd 1 09 of bbd risk this shows that observation of share of norway spruce variable would produce non significant variations in the posterior belief in states being moderately high moderately low or low a slight variation in the posterior belief was noted for the state of high however stand age showed significant variations in posterior belief for all states except moderately high the findings show that posterior distribution is very robust for variations in input from an investigation of the impact of different subsets of the evidence on each state of the hypothesis variable it is clear that the finding ϵ sa on sa stand age acts in favor of the hypothesis h bbd high on the other hand the evidence ϵ t on t temperature acts slightly against the hypothesis while the normalized likelihood of both evidence ϵ t and ϵ sa is 1 06 which acts slightly in favor of the hypothesis h bbd high the evidence therefore supports the hypothesis that an outbreak disturbance is driven by temperature and stand age in the worst case scenario the evidence ϵ pr precipitation acts against the hypothesis while ϵ sr solar radiation acts in favor of the hypothesis h bbd the model behavior representing a variation of the state for each of the variables observed is reported for scenarios 2 and 3 appendix table f the findings show that posterior distribution is relatively non sensitive to one way variations in individual nodes the distribution of bark beetle probability risk is non sensitive to variations in the precipitation node the most sensitive observation is altitude and soil type in scenario 2 and altitude followed by drought and solar radiation in scenario 3 the parameter sensitivity analysis of the bbd hypothesis shows the belief that bbd is high was 0 47 and the belief that it is low was 0 05 the altitude drought precipitation and solar radiation variables revealed the most sensitivities and were influential of all connected nodes tahri et al 2020 a tornado graph of all the root variables except t and sa is shown in the appendix fig g showing the possible variation of each state of bbd altitude is the variable with the greatest potential impact on the probability distribution of bbd and shows that solar radiation drought and precipitation also have the greatest potential impact on bbd probability distribution 3 3 spatial comparative analysis the two methodological approaches were compared in two steps i summary of the linear regression model and spatial correlation between the two resulting raster layer ii interpretation of the results of the two approaches in comparison with reference data sets appendix table h 3 3 1 comparison of risk maps a summary of the linear regression models resulting from the raster comparison of the fuzzy ahp and bbn outputs is given in table 6 a comparison of the two maps resulted in a reduced standard error coefficient 0 03 the result also reveals that the median was close to zero at 0 002 while the t coefficient values 116 86 45 71 were relatively high and are greatly relative to the standard error which could signify the existence of a relationship the residual standard error was 0 049 fig 6 shows the result of rstudio analysis note the moderate positive relationship between the two raster maps fuzzy ahp and bbn with a correlation coefficient of 0 66 with a confidence interval of 95 spatial correlation analysis of the difference maps is shown in the fig 6 the bbn model was more highly correlated with fuzzy ahp model which also can seem similar by visual observation most dark red color high risk areas are located in the north central and south where old forest cover mainly dominates the small differences observed were seen in the south and south west fig 5 3 3 2 validation of data with ground truth the accuracy assessment between the fuzzy ahp and bbn maps was compared with reference data and a field survey the overall confusion matrix with a confidence interval of 95 gave a result of nearly 87 kappa coefficient 71 for the bbn model while the overall confusion matrix for the fuzzy ahp model was 81 kappa coefficient 56 both models showed appropriate accuracy with the field survey this was also confirmed with the reference map hlásny et al 2021 where the kolin and praha regions were characterized by serious yearly losses of tree stock representing more than 73 of moderately high and highly vulnerable areas for both models appendix table h although the benesov region was more uncertain with both models the surrounding border was shown to be characterized by a high density of norway spruce species ancient forest stands with high temperature and low precipitation after checking the criteria maps which confirms the accuracy of the predicted results the mismatch can probably be explained by the different research scales used in the research the reference map was on the national scale while our own study was based on a regional scale the havlickuv brod location gave a contradictory outcome with the fuzzy ahp technique with climatic parameters assuming a high weighting and dominating the southern area in summary the bbn model gave more accurate prediction than the fuzzy ahp technique 4 discussion to our knowledge this comparative research is among the first examples where a regional bark beetle disturbance mapping was done with a fuzzy ahp and bbn modeling approach in a gis comparing the criteria ranks of both applications indicate that the most relevant criteria in the fuzzy ahp approach were quite similar to those with the bbn approach the parameters contributing to bark beetle disturbance in both models were share of norway spruce followed by temperature precipitation and drought in this study a lower risk was observed for young stands with a small share of norway spruce this interpretation concurs with works published previously stereńczak et al 2020 radl et al 2018 where high risk disturbance sites were characterized by ancient stand age and proportion of norway spruce as a dominant species mezei et al 2014 also demonstrated in their study that forest stand age and proportion of norway spruce are among the parameters that cause spruce mortality this research indicates that the denser the spruce tree cover and the more advanced the age of the forest the more vulnerable the trees are to bark beetle this has also been demonstrated by other studies holeksa et al 2017 hlásny and turčáni 2013 where these parameters were considered as major driving factors for intense damage in the disturbed areas also precipitation drought and temperature were often identified as relevant factors černý et al 2020 marini et al 2017 and many reviews consider climate variables such as temperature and precipitation as the two main drivers leading to mass outbreaks of bark beetle brandl et al 2020 christiansen et al 1987 matthews et al 2018 also perceived a dependence on whether or not a drought had occurred in the region netherer et al 2019 investigated environmental drivers for bark beetle spread in the case of austrian norway spruce stands the authors concluded that the warm temperature and acute disposition of the trees to attack caused by drought stress was likely to increase the risk of bark beetle infestation the results of the work by radl et al 2018 were used to validate the results of this study for comparison purposes the probability level based on four criteria was extracted stand age share of norway spruce drought and soil type the bbn model of this study allows to reproduce similar results table 7 despite the different input models and selected criteria in the austrian and czech cases the overall outcomes of the studies have some similarities older stands and a higher proportion of norway spruce in combination with an extreme drought event seem to contribute to higher probabilities for damages the worst and best scenarios revealed the estimated probability distributions according to the most up to date scientific literature findings on bark beetle disturbance the applied methodological approaches are different in terms of the underlying mathematical theories while fuzzy ahp requires a hierarchical process mode bbn is based on a network process taking into account inter dependencies between variables nevertheless the major advantages and drawbacks of both methods are identified along with the potential trade offs a summary of the differences between the two methods based on literature reviews and the present research experiment is given in table 8 concerning calculations both approaches deal with uncertainty and imprecise data and require more complex systems for this reason the fuzzy ahp matlab gui application is proposed for the non specialist as it provides straightforward guidance for a broad range of decision makers academics ecologists consultants etc to facilitate the decision making process for better understanding of forest issues while using bbn in our study research the cpt matlab program was found to be useful but limited to two or three directed node graphs a new cpt algorithm is needed requiring an additional long process in cases with four or more interconnected nodes on the other hand bbn can support a large number of criteria in the model unlike fuzzy ahp the method has a threshold on the number of criteria that can be incorporated a pairwise comparison questionnaire was carried out in fuzzy ahp applying a free web survey integrated with mobile devices available on the market the online questionnaire offering a user friendly remote tool to involve various experts independently the fuzzy ahp was consequently quicker at collecting expert judgments and avoided conflicting compromises between parties more readily the fundamental limitation of fuzzy ahp is that the required data input is restricted expert judgment only according to the saaty 9 point scale in addition the pairwise comparison questionnaire offers non familiarity among stakeholders tahri et al 2017 although there are no pairwise comparison matrices with the bbn technique its main strength is the ability to acquire probabilistic interdependency between uncertain variables dai et al 2021 based on non homogeneous variables and many different types of input data in one functional model expressing probability beliefs demanded enormous concentration but required a limited number of experts max 2 per case study to retrieve expert perceptions the major weaknesses associated with the bbn method compared to the fuzzy ahp technique are its highly complicated processes it was time consuming to implement and retrieving the input data to convert into conditional probability data was inherently challenging this was also confirmed by the majority of previous studies barton et al 2020 nascimento et al 2019 although the overwhelming relationship between dependence independence probability nodes was problematic one of the key advantages of the bbn method is that it offers meticulous transparency and produces dynamic results li et al 2020 laurila pant et al 2019 and also proves to be more precise at stand and local levels building a sample regional bbn model generates multiple scenarios based on the various knowledge sources höfer et al 2020 which provides an insight into the relationship between the forest components and the output nodes for each scenario the functional model can be applied to other local and or regional forest enterprises by simply changing the input data the spatial bbn represents a trade off between assessing the impact of bark beetle on different ecosystem services and stakeholders knowledge of the effects on forest management practices morris et al 2017 after overlaying and resampling different criteria spatial patterns at regional and local scales were easy to access for both methods and gave closely matching results in compiling thematic maps this research corroborates the work of hlásny et al 2021 where the kolin praha and kutna hora regions were well matched in three models according to the confusion matrix results the bbn model gives better results than the fuzzy ahp model it is argued that the maps produced provide both support for forest management planning to prevent further disturbance and monitoring for efficient strategic decision making an improved understanding of regulated timber harvesting is therefore needed which can be achieved by the introduction of salvage logging management vanická et al 2020 dobor et al 2020 and the reforestation and plantation of trees in the most suitable areas thorn et al 2017 macek et al 2017 nováková and edwards jonášová 2015 the results of ground truth and reference data validations reveal that bbn is more efficient than the fuzzy ahp but it cannot be concluded that bbn is more effective than the other model as either of them may predominate depending on processing time knowledge source and goal priority the bbn technique requires computing capabilities and is time consuming to implement but is more accurate and flexible in forest stands since it takes into account many different types of dataset unlike fuzzy ahp matlab gui is a user friendly tool offering rapid processing and is practical at large spatial and temporal scales most importantly both methods are reproducible for use in other types of case study involving stakeholder insights and future priority research 5 conclusion this research will be of great help for forest managers but also for conducting further field research in this area the results obtained from overlaying raster maps of the spatial multi criteria decision making method and bayesian belief network analyses showed that most locations had a similar level of relevance in the region the current situation is challenging in terms of rethinking spatial planning time available for data collection and the high costs of field research two decision support system methods were selected to detect sites potentially disturbed by bark beetles the work carried out required input of a geo referenced data set several meteorological topographical and forest stand parameters were obtained including the extraction of forest vegetation and use of the national forest inventory database however once the methods and data are provided it is possible to update the input data layer quickly and perform scenario analysis by changing the importance of the evaluation criteria this will allow a more robust and less sensitive prediction of bark beetle infestations in the future the new matlab code was effective for both techniques facilitating accurate computational algorithms and programs the conditional probability table code and the fuzzy ahp matlab user interface tools are both useful for application in other study fields the cpt code greatly speeds up processing time and provides a dynamic output model for each stand depending on seasonal distribution since the fuzzy ahp code can be converted to a simple graphical user interface which no longer requires a fuzzy specialist to compute the model the fixed output weight could be used in forest areas worldwide the results of the comparison show that both applications can easily be used to provide solutions for complex environmental decision making problems the efficiency of fuzzy ahp matlab gui was tested for use as an early warning tool while the bbn approach proved to be effective for dynamic and small scale landscapes software and or data availability the fuzzy ahp matlab gui is freely available via the github link https github com meyem4 foman fa it was developed by haytham tahri haytham tahri gmail com and meryem tahri see co author contact information and launched in 2020 conditional probability tables and i typographus l network model outcomes are provided via the github link https github com meyem4 foman itl bbn hugin expert software is required to run the i typographus l network model this was developed by meryem tahri under the supervision of prof anders l madsen see co author contact information a youtube tutorial on the hugin plugin for qgis mapping produced by prof anders l madsen is provided at https www youtube com watch v zcdftmj5tou declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by grant eva4 0 no cz 02 1 01 0 0 0 0 16 019 0000803 financed by op rde the authors gratefully acknowledge prof dr daniel ames editor in chief and anonymous reviewers for their scientific expertise we would like to thank consultants who participated in our survey in particular thank to dr andrew liebhold from us forest service northern research station appendix a criteria and or node description states parameter criteria variable node description state 1 low risk 2 moderate low risk 3 moderate high risk 4 high risk predisposition share of norway spruce proportion of norway spruce in the stand dense spruce areas result in stronger i typographus l attacks on trees low density moderate density high density very high density drought lack of rainfall drought has significant influence on bark beetle abnormally dry moderate drought severe drought exceptional drought stand age years age of stand the older the forest the higher the risk 50 50 64 64 78 78 climate annual temperature c average yearly air temperature high temperature accelerates tree vulnerability stress 6 3 7 6 7 6 8 0 8 0 8 50 8 50 9 2 solar radiation watt hours m2 solar radiation power per unit area greater propagation attracts i typographus l 322k 864k 864k 956k 956k 1 021k 1 021k 1 191k annual precipitation mm annual precipitation high precipitation reduces risk of i typographus l 706 820 660 706 622 660 550 622 site specific stand altitude m elevation above sea level lower areas have negative impact 526 464 526 400 464 338 400 edaphic category soil type edaphic or ecological gley soil waterlogged soil peats organic soil rich in water soils fertile soils acid soils appendix b raster criteria considered in the application of fuzzy ahp and bbn models in the central bohemian region image 2 appendix c source table for data used parameter institution data origin access format cell size resolution share of norway spruce forest management institute czech national forest inventory 2011 2014 database accdb 200 m stand age years forest management institute czech national forest inventory 2011 2014 database accdb 200 m annual temperature c czech hydrometeorological institute meteorological station http portal chmi cz ascii raster asc 500 m annual precipitation mm czech hydrometeorological institute meteorological station http portal chmi cz ascii raster asc 150 m solar radiation wh m2 nasa aster sensor https search earthdata nasa gov raster digital elevation model 30 m drought intersucho https www intersucho cz pdf map digitalization 500 m altitude m a s l forest management institute czech national forest inventory 2011 2014 database accdb 30 m edaphic categories forest management institute czech national forest inventory 2011 2014 database accdb 200 m appendix d sensitivity analysis results of fuzzy ahp decision making solar radiation share of norway spruce stand age altitude temperature soil type precipitation drought criticality degree of criterion c k 369 1 8 9 95 5 9 1 7 9 74 2 77 3 55 sensitivity coefficient of criterion 1 c k 0 00 0 56 0 10 0 17 0 59 0 10 0 36 0 28 ranking 8 2 7 5 1 6 3 4 appendix e graphical curve outcome examples to derive estimation of cpt distributions image 3 appendix f sensitivity analysis min max analysis of each observed node given the remaining observed nodes scenario 3 scenario 2 min max min max precipitation bark beetle disturbance risk high 0 74 0 75 0 63 0 65 bark beetle disturbance risk moderately high 0 17 0 18 0 2 0 21 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 09 bark beetle disturbance risk low 0 03 0 03 0 06 0 07 soil type bark beetle disturbance risk high 0 73 0 75 0 53 0 63 bark beetle disturbance risk moderately high 0 17 0 18 0 21 0 23 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 13 bark beetle disturbance risk low 0 03 0 03 0 07 0 12 altitude bark beetle disturbance risk high 0 65 0 75 0 63 0 73 bark beetle disturbance risk moderately high 0 17 0 2 0 18 0 2 bark beetle disturbance risk moderately low 0 05 0 08 0 06 0 09 bark beetle disturbance risk low 0 03 0 06 0 03 0 07 drought bark beetle disturbance risk high 0 7 0 75 0 57 0 63 bark beetle disturbance risk moderately high 0 17 0 19 0 21 0 22 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 12 bark beetle disturbance risk low 0 03 0 04 0 07 0 1 stand age bark beetle disturbance risk high 0 72 0 75 0 6 0 63 bark beetle disturbance risk moderately high 0 18 0 17 0 21 0 21 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 1 bark beetle disturbance risk low 0 02 0 03 0 07 0 08 temperature bark beetle disturbance risk high 0 73 0 75 0 52 0 63 bark beetle disturbance risk moderately high 0 17 0 17 0 21 0 22 bark beetle disturbance risk moderately low 0 05 0 05 0 09 0 13 bark beetle disturbance risk low 0 02 0 03 0 07 0 12 solar radiation bark beetle disturbance risk high 0 7 0 75 0 56 0 64 bark beetle disturbance risk moderately high 0 17 0 18 0 2 0 22 bark beetle disturbance risk moderately low 0 05 0 06 0 09 0 12 bark beetle disturbance risk low 0 02 0 04 0 07 0 1 share of norway spruce bark beetle disturbance risk high 0 73 0 75 0 61 0 63 bark beetle disturbance risk moderately high 0 17 0 17 0 21 0 21 bark beetle disturbance risk moderately low 0 05 0 05 0 09 0 1 bark beetle disturbance risk low 0 02 0 03 0 07 0 08 appendix g tornado graph of all root variables except temperature and stand age nodes image 4 appendix h comparison with reference map reference data hlásny et al 2021 this study region of trees stock loss yearly categorie of surface area using fuzzy ahp of surface area using bbn kolin 5 7 low risk 0 0 moderately low risk 5 2 moderately high risk 65 24 high risk 30 73 praha vychod 3 5 low risk 0 10 moderately low risk 15 17 moderately high risk 73 32 high risk 12 41 kutna hora 3 5 low risk 48 25 moderately low risk 32 32 moderately high risk 21 24 high risk 0 19 benesov 2 3 low risk 6 8 moderately low risk 35 27 moderately high risk 54 34 high risk 5 32 havlickuv brod 5 7 low risk 48 16 moderately low risk 32 41 moderately high risk 21 34 high risk 0 9 
25686,due to the seasonal increase in soil salt accumulation after cessation of monsoon rains the simulation of cropping system performance becomes highly challenging in coastal saline cropping areas rapidly changing groundwater gw dynamics during this period gw depth and salinity drive changes in capillary soil moisture rise soil evaporation and consequent deposition of salts in the crop root zone difficulty in simulating this complex cropping environment makes model based examination of optimal cropping patterns and agronomic management difficult as one season can be very different to the next the performance of crops is also difficult to predict under future climate scenarios in these regions as the impact of both changes in climate and groundwater salinity dynamics on soil status in the crop root zone changes in complex fashion no previous simulation study has sought to combine such dynamic and complex elements in simulating crop performance we calibrated and validated the apsim model for simulating a broad range of experimental treatments in a rice pulse cropping system over two seasons using the example of coastal saline west bengal india this represents a novel evaluation of the apsim model in simulating the complex mechanisms of seasonal soil water and salinity behavior as driven solely by daily climate and a dynamic shallow saline water table together with the associated crop responses the model performed well in simulating the observed soil chloride content cc and soil water content swc with a high coefficient of determination r2 for both calibration and validation datasets cc r2 0 91 and 0 89 swc r2 0 90 and 0 93 respectively and also acceptable rmse values these were well within the bounds of observed experimental error indicating that the model was simulating system behaviour acceptably apsim then successfully simulated the observed crop performance in response to these soil dynamics across 24 unique environmental situations this illustrates that crop performance in such complex environments can be robustly simulated and that models like apsim are a useful tool to translate outputs from other models at different scales for example climate change from general circulation model s gcm s and future changes to groundwater depth and salinity dynamics from regional hydrology models into changes in cropping system performance this positions apsim strongly as a robust research tool for climate change studies on agronomic impacts and adaptations in such regions as well as for development of decision support tools to assist farmers in selecting suitable crops cultivars their sowing times and optimal agronomic management practices for coastal saline zone under prevailing conditions keywords apsim rice grass pea cropping systems salinity shallow water table 1 introduction the coastal saline zone csz of west bengal india consists of 1 4 million ha area spread over 78 blocks of six southern districts of the state sarangi et al 2019 the agricultural development in the coastal saline belt is constrained by various physical chemical and social factors mainuddin et al 2019a mandal et al 2020 ray et al 2020 apart from the homestead upland the crop fields of this region are often classified as medium up medium low and lowlands the latter two are usually inundated by floods and rainwater associated with poor drainage in the kharif rainy season banerjee et al 2018b sarkar et al 2019 the shallow water table depth changes dynamically throughout the year supplementary fig s1 as does the salinity level of the ground water such seasonal variations play a driving role in regulating the surface soil salinity dynamics the upward capillary movement of saline groundwater and deposition of salts in the topsoil layer is a defining process in the winter to summer months brahmachari et al 2017 as a result of this the agriculture of the region is predominantly rainfed and the cropping pattern consists almost totally of mono cropped wet season rice samui et al 2020 mainuddin et al 2019a sarangi et al 2016 2019 in most cases the farmers of the coastal zone follow the traditional cropping systems satisfying their own food security needs without thinking of the cost effectiveness agro ecological suitability and sustainability of the technologies bell et al 2019 mainuddin et al 2019a thus sustainable improvement of existing rice based cropping system productivity in salt affected areas of csz is a major challenge for enhanced sustainability salinity dynamics are amongst the main biophysical factors determining timing in the cropping calendar for this salt affected environment radanielson et al 2018c in the csz cropping in the monsoon season starts after enough freshwater has desalinized the topsoil layers to ensure that wet season rice is not affected by salinity during the rabi season winter the shortage of freshwater and upward capillary movement of soil salinity to the upper layer of soils limits the possibility for second cropping to a very limited area gaydon et al 2021 radanielson et al 2018b the sowing date plays a crucial role in optimising crop production gaydon et al 2021 ghosh and khan 2019 ghosh 2018 radanielson et al 2018b amarasingha et al 2015 rice is one of the few crops for salt affected soils that can be successfully cultivated even though it is considered sensitive to salinity radanielson et al 2018b this is because rice under flooded conditions allows partial desalinization of the soil and reduces the impact of salinity ismail et al 2007 radanielson et al 2018a optimization of the sowing date of rice under different land situations to best utilize residual soil water and escape late season salinity stress in the succeeding pulse crops is one of the important strategies to intensify the existing cropping system of csz due to its quick growth habit high yielding ability and high adoptability under salt and moisture stress conditions dixit et al 2016 ghosh 2018 winter pulse crop grass pea lathyrus sativus l may be suitably fitted as a short duration crop in rice based cropping systems several field experiments for adjudging the effect of different sowing dates and land situation on salt and water dynamics of rice pulse cropping systems have been previously conducted in csz brahmachari et al 2020 sarkar 2021 sarkar et al 2020e 2020a 2020d the agricultural and production systems simulator apsim holzworth et al 2014 is increasingly being used in south asia sa for modelling rice based farming systems and has been successfully parameterized calibrated and validated for a broad range of locations within south asia mohanty et al 2020 khaliq et al 2019 gaydon et al 2017 sarkar et al 2020c cropping system models are particularly valuable when partnered with limited period field experiments in understanding long term climatic risk and its impact on system performance thus a well tested and locally calibrated and validated simulation model may be handy to explore the performance of different management practices within the context of a holistic systems approach for increasing system productivity assessing environmental impacts and evaluating the effects of a changing climate khaliq et al 2019 the combined dynamics of soil salinity and soil water is another matter in which models can be helpful in practice it is expensive to assess the effects of daily dynamics of soil water and salinity and the responses of the associated crops in previous investigations using point scale cropping systems models like apsim groundwater inputs were either static huth et al 2012 paydar et al 2005 or the salinity of the root zone soils was an input parameter itself hochman et al 2007 coastal saline cropping environments represent a much more complex situation with groundwater depths and salinity levels which are highly dynamic during the course of a cropping season apsim had not previously been used to simulate soil dynamics water nutrients and salinity together with associated cropping system performance directly from such inputs of daily climate water table dynamics depth and salinity and specifications of imposed management practices in other words in this research work we simulated the dynamics of the crop soil environment we did not specify it this represents a novel application and one that is essential in simulating future cropping system performance when only projected changes in climate and water table dynamics are available fig 2 we considered adjustments in the rice sowing window for two land situations with a focus on intensification of the existing rice based monocropping systems and also on reducing climate related risk however in conducting this work we combined two years field experimentation with a well tested apsim model to help in long term risk assessment in this paper we describe and evaluate a novel approach to simulate complex soil salinity and moisture dynamics and associated crop responses in a coastal saline environment the novelty lies in that this process is driven solely by daily model inputs of climate maximum and minimum temperatures rainfall and solar radiation highly dynamic water table depth gwt and water table salinity gws and farmers management information the soil salinity and moisture dynamics to which the crops are exposed are not model inputs they are simulated from highly dynamic groundwater inputs we conducted this testing over two different climatic seasons and a range of crop sowing dates to evaluate the adaptability of the apsim model s performance in this challenging environment we began by parameterising the model using measured local soil characteristics before calibrating uncertain input parameters for rice grass pea and soil sub models using detailed first year on farm experimental data before validating the model setup for simulation of the rice grass pea system production and associated soil water and salt chloride dynamics using the second year of field data a range of 6 sowing dates 2 seasons and 2 landscape positions allowed robust testing of model performance under 24 unique regimes of salinity and moisture 2 materials and methods we are providing for the first time an evaluation of the apsim model s ability to simulate soil salinity and moisture dynamics using ground water table inputs gwt and gws in contrast to previous work where soil salinity values were either used as direct inputs or else simulated based solely on irrigation water salinity 2 1 description of the study area to provide a testing base for this new methodology a field experiment was performed during 2016 17 and 2017 18 at a farmer s field in rangabelia village in gosaba block of south 24 parganas district west bengal india situated in 21 920 n latitude and 88 800 e longitude fig 1 the average elevation of the polder island where the experiment was conducted is around 3 5 m 0 5 m above mean sea level the polder is surrounded by vidyadhari and hogol rivers where periodic intrusion of highly saline tidal water occurs from bay of bengal 2 2 climatic conditions the daily maximum and minimum temperature relative humidity rainfall and solar radiation during the experimental period 2016 2019 were recorded using an automatic weather station em50 data collection system decagon inc wa usa situated approximately 50 m from the experimental site the study location has a typical sub tropical climate with monsoon dominant rainfall fig 3 the long term daily climatic data 1986 2018 of the experimental location were collected from regional research station coastal saline zone bidhan chandra krishi viswavidyalaya bckv and icar central soil salinity research institute icar cssri regional research station canning town west bengal the maximum and minimum temperature during the experimental years fluctuated between 18 6 and 37 6 c and 8 6 28 6 c respectively which is following a similar trend to the long term average air temperature data obtained from bckv and icar cssri in general there was a gradual drop in temperature from november to january the average relative humidity during the experimental period ranged between 49 6 and 88 8 the two year average rainfall during the experimental period was recorded 212 mm the average solar radiation of the experimental years was 16 mj m 2 day 1 2 3 physical and chemical characteristics of soils and water the experiments were conducted in two different land situations i viz medium upland and medium lowland having distinct differences in surface water dynamics during the wet season together with different soil physical and chemical characteristics the various physical and chemical parameters of the experimental soils are given in table 1 soil samples were collected before starting the experiment using an 80 cm core sampler and the samples were processed for particle size analysis bulk density and organic carbon content samples were collected in five layers 0 15 15 30 30 50 50 80 and 80 120 cm depth using standard procedures jackson 1969 the pedotransfer function software soil water characteristics version 6 02 74 usda available at http hydrolab arsusda gov soilwater index htm was used to estimate the required apsim soil water holding parameters i e crop lower limit ll assumed to be equal to the 15 bar lower limit mm mm 1 drained upper limit dul and saturated water content sat saxton et al 1986 the electrical conductivity of soil suspensions soil water 1 5 was measured at room temperature 28 c using a direct reading conductivity meter model systronics 363 throughout the experimental period water table depths and groundwater salinity ec from three installed piezometers at the experimental location to 5 48 m depth were monitored at regular intervals 7 days the quality of the groundwater was measured using an aqua cre conductivity meter version 2 0 1 as apsim required daily input data of meteorological variables the weekly measured ground water salinity and water table data was algorithmically converted into daily data using ms excel martinović et al 2016 the graphical representation of the monthly average groundwater table depth and salinity obtained from the weekly measured data during the experimental years is presented in fig 4 depths of surface water across different land situations are presented in supplementary fig s2 a b the seasonal dynamics of soil salinity electrical conductivity and soil water content gravitational were measured periodically 15 day intervals on a depth wise basis 0 15 cm 15 30 cm 30 50 cm 50 80 cm and 80 120 cm bhattacharyya et al 2018 for conversion of measured soil ec soil water 1 5 to the chloride deposition in kgha 1 for comparison with apsim simulated values the following equations were used 1 ecse dsm 1 ec1 5 dsm 1 2 74 3 01 he et al 2013 2 chloride ppm ecse dsm 1 1 8 4 4 35 5 bandyopadhyay et al 2003 3 c h l o r i d e k g h a 1 c h l o r i d e p p m b d g c c d e p t h o f s o i l l a y e r c m 10 where e c s e d s m 1 is the electrical conductivity of soil saturation paste extract dsm 1 e c 1 5 d s m 1 is the electrical conductivity of soil water at 1 5 ratio bd mgm 3 is bulk density of soil layer the depth of soil layers for estimating chloride kg ha 1 were 0 15 cm 15 30 cm 30 50 cm 50 80 cm and 80 120 cm the different conversion equations used in this experiment were successfully used in different field experiments of coastal saline zone of india and bangladesh mainuddin et al 2020 paul et al 2020a 2020b sarkar 2021 2 4 experimental treatments field experiments were conducted in the kharif monsoon june october and rabi winter november april seasons of two consecutive years 2016 17 and 2017 18 two land situations medium upland and medium lowland were used with six dates of rice sowing cv cr1017 at an interval of one week 15th june to 19th july replicated four times the size of each plot was 20 sq m 5 m 4 m and total number of plots was 48 rice seedlings 22 days old were manually transplanted at a spacing of 20 cm 15 cm with 2 seedlings per hill after the rice crops reached physiological maturity grass pea seeds cv bio l 212 were relay sown broadcasted into the standing crop of rice for utilization of the residual soil moisture thinning of grass pea was undertaken once at 28 30 days after sowing to ensure optimum plant population 60 70 plants m 2 plant to plant distance of 4 5 cm was maintained in each row in rice the recommended dose of fertilizer rdf i e 60 30 30 n p2o5 k2o kg ha 1 department of agriculture gowb 2012 was applied through chemical fertilizers like urea for n single super phosphate for p and muriate of potash for k half of the recommended dose of n along with full dose of p2o5 and k2o was applied as basal and the remainder applied in two equal splits at maximum tillering stage and at panicle initiation stage in grass pea the entire recommended dose of fertilizer i e 20 40 20 n p2o5 k2okg ha 1 department of agriculture gowb 2012 was applied at the time of sowing both the crops were grown under fully rainfed conditions in the case of rice ponded water depth varied between 2 and 5 cm during the crop growth water was drained from the rice field seven days before harvesting to control weed populations in rice two hand weedings were performed before each top dressing for grasspea two manual weedings were undertaken one at 30 days after sowing and another at 45 days after sowing need based spraying of triazophos 1 5 ml l 1 of water was performed to control yellow stem borer in rice the rice crop was harvested when 80 grains in each panicle were observed to be mature grass pea was harvested when the pods became ripe but the plants were not dead ripe both the harvested crops were dried threshed cleaned and sundried the general crop establishment management practices cropping history vis à vis other best agronomic managements has been described in sarkar 2021 and sarkar et al 2020e 2 5 experimental observations phenological data for both rice and grass pea were recorded the developmental stages dvs of rice were divided into six distinct growth phases i sowing of seeds ii transplanting iii panicle initiation iv 100 flowering phase v physiological maturity and vi harvest similarly the growing season of grass pea was divided into five phases namely i sowing ii 100 emergence phase iii 100 flowering phase iv physiological maturity and v harvest ten plants for both rice and grass pea were randomly selected from each plot uprooted and cleaned for sampling above ground biomass at different intervals 30 50 70 and 90 days after sowing in rice at 20 and 40 das days after sowing grass pea the uprooted plants were then sun dried oven dried at 70 c for 48 h and then weighed at crop harvest stage yield attributes were recorded for assessment of crop yield banerjee et al 2018a however grain seed and straw stover yield were determined from the net harvested data and converted to t ha 1 at 14 moisture content banerjee et al 2018b 2 6 apsim modelling 2 6 1 soil modules used in the study in the apsim framework different linked sub modules enable the user to simulate different agricultural system situations in simulating rice and grass pea crops in coastal saline environments five soil modules were used i e swim3 surfaceom soiln solute and fertiliser the water balance model employed was the apsim swim3 the latest release in the family of swim soil water infiltration and movement models developed for simulating the water and solute movement within soil profile connolly et al 2002 huth et al 2012 swim3 was used to simulate the daily dynamics of soil salinity and moisture the key apsim swim3 parameters which were calibrated to achieve good fit for measured vs simulated soil moisture content and salinity were those governing soil water movement layer based ks for saturated flow mm day 1 matric potential at dul cm solute dispersivity dis cm2 h 1 cm h 1 and the unit change of osmotic potential felt by the crop per unit change in cl concentration clslos cm3 μg 1 verburg et al 1996 these parameters and the values used in our calibration are detailed in appendix a the surfaceom module simulates the dynamics of the above ground crop residues which are left to decompose on the soil surface balwinder singh et al 2015 gaydon et al 2017 jha et al 2021 the soiln module simulates the transformations of soil c and n within the soil profile including residues that have been incorporated these modules include organic matter decomposition n immobilization urea hydrolysis ammonification nitrification and denitrification processes gaydon et al 2017 balwinder singh et al 2015 jha et al 2021 probert et al 1998 the solute module was used to track the solute balance and movement of chloride ions within the layers of the soil profile holzworth et al 2006 calculating leaching and solute diffusion in association with the swim3 module the fertiliser module was used to specify the application of chemical fertilizer to an apsim system using a schedule spanning multiple years mohanty et al 2020 2 6 2 crop modules parameters specifying phenological development for the apsim oryza rice model gaydon et al 2012a 2012b and the newly developed a prototype apsim grasspea model sarkar et al 2020a sarkar et al 2020d were calibrated using observed seeding flowering and harvest dates for varieties employed in the trials brief details of the apsim grasspea model are in appendix b and a more comprehensive publication on this new module with validation across numerous geographical sites is under development here we have only presented the testing of this module for the current location based on our soil core sampling we estimated rooting depths from evidence of root hairs 40 cm for both grass pea and rice in simulation of each experiment crop varieties were calibrated by varying the apsim crop phenology parameters until the modelled phenology dates matched the observed dates the primary dates of focus were those associated with sowing transplanting maximum tillering panicle initiation flowering and physiological maturity for rice and sowing germination 50 flowing 100 flowering physiological maturity and harvest for grass pea to assess the effect of relay sown grass pea in rice the apsim canopy module was used to arbitrate the light and water competition between two associated crops salinity response for rice apsim oryza is detailed by radanielson et al 2018c and for apsim grasspea via documentation on the apsim plant modelling framework huth et al 2012 in essence the apsim approach is that the presence of salinity cl ions in the soil increases the osmotic potential against which the crop draw soil moisture and thereby increase levels of water stress which the crop experiences no consideration of salt toxicity effects on crops were considered 2 6 3 external inputs daily climatic data including maximum and minimum temperature rainfall and solar radiation were used as inputs to apsim additionally we used measured groundwater table depth and groundwater salinity data as external inputs in each simulation we used apsim manager to read these data from the apsim climate file met file and from these inputs apsim simulated the soil water and chloride dynamics in the crop root zone via the processes of soil evaporation capillary moisture rise and crop uptake fig 2 2 6 4 calibration and validation process the model was parameterized using local soils climate and details of imposed management practices and then calibrated and validated using the 2 years on farm experiments for rice and grass pea the first year s data for each crop were used to calibrate the model particularly the genetic coefficients of each crop variety but also difficult to measure soil parameters such as rooting depths and distributions crop lower limit ll fbiom finert probert et al 1998 saturated hydraulic conductivity ks etc the second year s data were used for validation of those parameter calibrations variables compared during this process were soil moisture soil chloride crop phenological stages grain yields and total dry matter 2 7 statistical analysis for model calibration and validation linear regression was used to compare paired data points for observed and simulated grain and biomass yield for both rice and grass pea as well as soil water and chloride the slope α intercept β and coefficient of determination r2 of the linear regression between simulated and observed values were also determined the model performance using the student s t test of means assuming unequal variance p t and the absolute square root of the mean squared error rmse was also evaluated as rmse i 1 n s i o i 2 n rmse n absolute rmse mean of the observed 100 where si and oi are simulated and observed values respectively and n is the number pairs of data a model reproduces experimental data best when α is 1 β is 0 r2 is 1 p t is larger than 0 05 indicating observed and simulated data are the same at the 95 confidence level and the absolute rmse between simulated and observed values is similar to and ideally less than the standard deviation of experimental measurements for that variable representing the error between treatment replicates or the uncertainty of the observed data good model performance is also indicated when rmsen normalized square root of the mean squared error is similar to the standard errors of measured values and the rmsen is similar to the coefficient of variation of measured values yadav et al 2011 statistical comparisons were conducted for subsets of the overall rice and grass pea dataset to explore the performance of the model in simulating different land situations and sowing dates 2 8 scenario analysis after calibration and validation scenario analyses were performed to assess system behaviour under different hypothetical growing environments historical climate data covering 33 years 1986 2018 was used for these simulations measured ground water table depth gwt and ground water salinity gws data were only available for the experimental period 2016 2018 hence the assumption was made that gwt and gws maintained identical seasonal dynamics in each year thus we used the two year average values for these paraments to produced one set of data used every year in the simulation of the for the whole historical for building up the historical climate file with this assumption we performed four scenario analyses without re setting the soil and other crop parameters i long term performance of rice and grass pea yield under different sowing dates and land situations with natural prevailing conditions ii long term performance of rice and grass pea yield after removal of gws i e all salt in system removed no salinity in the groundwater fresh only iii long term performance of rice and grass pea without any water table gwt in the system indigenous salts still present but without salty water table contribution and iv long term performance of rice and grass pea yield with no gws or gwt components i e no shallow groundwater table at all no salts in the system probability of exceedance 0 1 graphs were used to compare the distribution of yields between different scenarios 3 results 3 1 simulation of soil water and salinity dynamics data on performance of apsim in simulating soil water content and salinity dynamics are presented in table 2 in both medium upland and medium lowland situations there was good agreement between observed and simulated chloride content cc kg ha 1 fig 5 a e fig 6 a e and volumetric soil water content swc cm3 cm 3 fig 7 a e fig 8 a e across different soil layers 0 120 cm the cc in the medium upland soil was notably higher than in the medium lowland soil in both land situations the agreement between observed and simulated chloride content for topsoil layers 0 50 cm was better than deeper soil layers 50 120 cm the correlation coefficient r2 between overall simulated and observed values was high for both calibration and validation datasets r2 0 91 and 0 89 respectively with normalized rmse of 18 9 and 19 1 respectively fig 11 a b the rmse of cc for both calibration and validation datasets were also within the uncertainty of observed values table 2 illustrated by the fact that rmse was of the same quantum as observed standard deviation in contrast to the cc the observed swc in the medium lowland soil was markedly higher than in the medium upland soil the correlation coefficient r2 between simulated and observed values for swc was high for both calibration and validation datasets r2 0 90 and 0 93 respectively with rmse s of 0 024 and 0 022 cm3 cm 3 corresponding to normalized rmse s of 6 53 and 6 18 respectively fig 9 c d table 2 comparing favourably with the observed standard deviations of 0 03 and 0 029 cm3 cm 3 respectively 3 2 phenology durations of different growth phases in both rice and grass pea were significantly influenced by variation in sowing date both apsim oryza and apsim grasspea crop modules successfully simulated phenological developmental variations with sowing date accurately predicting stages of emergence grass pea panicle initiation rice flowering both and physiological maturity both in both land situations supplementary tables s3 and s4 supplementary figs s3 and s4 the different cultivar specific parameters used in the apsim calibration and validation process for both rice and grass pea are presented in supplementary tables s1 and s2 in both experimental seasons the effect of sowing date on duration of growth phases was found to be similar in both medium upland and medium lowland situations the duration of growth for both rice and grass pea decreased with delay in sowing date both rice and grass pea took more time to mature when grown in the medium lowland situation irrespective of sowing date early sown rice 15th june 1st dos was delayed in reaching physiological maturity by 7 and 6 days for 2016 and 7 and 8 days for 2017 under medium upland and medium lowland respectively compared to late sown rice 19th july 6th dos similarly early relay sown grass pea took more time to reachphysiological maturity than the late relay sown grass pea 3 3 grain and biomass yield in both experimental years 2016 17 and 2017 18 there was generally good agreement between simulated and observed grain yield and accumulated biomass over time of both rice and relay sown grasspea in both land situations shown as time series in figs 7 and 8 and supplementary tables s3 s4 the crops sown on early sowing dates produced higher amount grain and biomass yield compared to the delayed sown crops for both calibration and validation sets the grain and biomass yield of rice and grasspea is closely associated to the simulated value supplementary fig s5 a d and fig 10 a d the model s performance for rice in terms of the evaluation parameters calibration and validation was judged to be satisfactory the correlation coefficient r2 was high for both calibration and validation datasets of grain and biomass production grain r2 0 76 and 0 80 biomass r2 0 93 and 0 98 respectively calibration and validation datasets fig 11 a d table 2 the rmse for the grain and biomass yield of rice for the calibration and validation was also within the limit of experimental uncertainty grain rmse 331 sdobs 401 and 193 sdobs 203 biomass rmse 431 sdobs 743 and 465 sdobs 683 respectively calibration and validation datasets and normalized rmse was 6 78 and 3 94 for grain yield and 3 87 and 4 64 for biomass respectively the grass pea model also performed well the r2 between simulated and observed grain and biomass yield of grass pea was high for both the calibration and the validation dataset also grain r2 0 89 and 0 90 biomass r2 0 90 and 0 84 respectively fig 12 a d table 2 with normalized rmse of 9 23 and 7 80 for grain yield and 7 89 and 7 80 for biomass respectively the overall crop performance of grasspea was better in year 2 as compared to year 1 overall grain yield 750 kg ha 1 in 2016 17 and 993 kgha 1in 2018 19 and this year wise variation was well captured by the apsim grasspea model table 2 3 4 scenario analysis both crops rice and grass pea sown on earlier dates produced higher amounts of grain and biomass compared to delayed crops under the prevailing natural saline system and for all other scenarios in the medium lowland situation the grain yield of rice with sowing date over the longer term followed a similar trend to the 2 year experimental values used for model calibration and validation supplementary fig s6a in the medium upland situation however rice crops sown on both the 2nd and 3rd sowing date 28th june were shown to outperform those sown on the 1st sowing date 15th june in the most years fig 13 a in both land positions rice yield was not significantly impacted by salt when the water table gwt was present figs 13b and s6b but was negatively impacted when the gwt was removed from the simulation suggesting water stress mitigating impact of the shallow gwt on the rice crop figs 13c and s6c salt in the system however was shown to have a small impact on rice performance when there was no gwt present for when both salt and gwt were removed from the simulations there was a slight improvement in rice yield for some sowing dates comparing fig 13 c and d s6 c and d over the longer term the grass pea yield with sowing date in the medium upland situation also revealed a slightly different trend to that observed in the 2 year experimental phase with the 3rd sowing date 13th nov outperforming the 1st sowing date 2nd nov in all but some of the higher yielding years and with the 2nd sowing date 7th nov achieving the peak yielding crops in a few seasons s7a as per rice the long term grass pea yield trend with sowing date in the medium lowland situation also reflected the experimental observations fig 14 a with the first sowing date being the best performing one by removing gsw and gwt components from the simulations both individually and together it was observed that grass pea is significantly more positively impacted by the presence of the gwt than negatively by salt in this environment across both land situations however when no water table was present grass pea crops were impacted by salinity to a small degree comparing fig 14 c and d s7 c and d in a similar way to rice therefore but to a greater extent apsim suggests that the shallow dynamic gwt provides grass pea crops with significant mitigation against water stress in this environment 4 discussion the feasibility of the apsim model in simulating the performance of the rice grass pea cropping system and salinity and moisture dynamics for medium upland and lowland condition across a broad range of sowing dates in the coastal saline zone of west bengal india was judged to be highly satisfactory to the best of our knowledge this is first time apsim has been used to simulate the complex daily dynamics of soil water and salinity from direct inputs of water table depth and salinity and the consequent response from the crops prediction of soil salinity and moisture were also acceptable across different land situations as were grain and biomass yield predictions 4 1 simulation of soil water and seasonal salinity dynamics seasonal salt and water dynamics in the root zone soil play a pivotal role in the growth and development of the crops in this region apsim simulated these in response to external inputs of groundwater table depth and salinity capturing all the main features of soil water and salinity dynamics throughout the soil profile in both years under both medium upland and medium lowland conditions table 2 the model is successfully simulating the capillary rise solute transport behaviours leaching of salts within the soil profile in these different growing environments figs 5 6 and figs 7 8 the shallow groundwater table of the csz is changing rapidly as function of infiltration of water from surface layer and soil evaporation mainuddin et al 2019b 2019a 2020 and supplementary fig 1 on the other hand seasonal movement of salts in the soil profile and the availability of moisture to the root zone of the crops largely depends on the rainfall and seasonal dynamics of groundwater table 4 2 simulation of phenology crop modules within the apsim framework successfully simulated phenological developmental variations of both rice and grass pea like most other crop models apsim oryza and apsim grasspea calculate phenological stages based on thermal time accumulation cumulative degree days bouman and van laar 2006 under saline growing ecology the crop phenology largely varies with sowing date affecting temperature and moisture conditions to which the growing crop is exposed and salt stress radanielson et al 2018c longer crop duration with longer grain filling time results in higher degree of effective grain filling and higher potential yield yang et al 2008 salt stress can also accelerate the physiological maturity the crop growth period can be reduced by the stress and therefore the duration of grain filling reduced proportionally radanielson et al 2018a 2018c in this present experiment the rice crops sown on 15th june 1stdate of sowing were delayed in reaching physiological maturity by a week compared with those sown on 19th july on the other hand pulse crops are generally more sensitive to the moisture salinity and temperature stress at different growth stages and production of these leguminous crops can be seriously affected by soil salinity and high temperature hanumantharao et al 2016 meena and lal 2018 the duration of grass pea also decreased with a delay in sowing date due to temperature and moisture stress ghosh and khan 2019 these variations in the phenological events due to different sowing dates were well captured by the apsim grasspea model in this coastal dynamically saline environment 4 3 simulation of biomass and grain yield under saline conditions the model generally captured the effect of the sowing date treatments on grain and biomass yield for both rice and grasspea sowing time is one of the major factors in rice cultivation and indirectly determines soil temperature and weather conditions to which young seedlings and rice plants are exposed during different development stages delay in sowing of rice beyond the optimum sowing window can have negative effect on crop yield balwinder singh et al 2016 pal et al 2017 adjustment of sowing time of the rice crop is undertaken because it ensures the vegetative growth occurs during a period of satisfactory temperatures and high levels of solar radiation farrell et al 2003 in the present experiment early sown rice and relay grass pea 15th june 21st june for rice 2nd november 07th november for grass pea performed better than latter sown crops in terms of grain and biomass yield higher remobilization of resources in the early sown crop which probably was linked to the higher dry matter of the crop thus representing the potential source for dry matter remobilization pal et al 2017 przulj and momcilovic 2001 agro meteorological factors like air temperature solar radiation and seasonal destitution of rainfall also plays a significant role to determine the yield of wet season rice chen et al 2013 huang et al 2019 early sown rice has significant yield advantages for the relay sown pulse crops by better utilization of soil water and alleviating the effect of post monsoon salinity stress kar et al 2012 malik et al 2016 the grain and biomass yield for both the crops is reasonably higher in medium lowland situation than crop sown in medium upland situation may be due to low salinity rinsing and higher soil water pro prolonged growth period apsim oryza and apsim grasspea captured these variations in different land situations for both experimental seasons in some treatments the grass pea model overestimated the biomass production but within the range of experimental uncertainty sowing time of pulse crops plays a critical role in regulating the yield components by altering the availability of moisture heat and salinity stress as well as other abiotic and biotic factors late season salinity stress also seemed to be detrimental to the growth of the pulse crops the most crucial and important stage in the life cycle of species growing in saline environment is the period of seed germination and early development of the seedlings ranganathan and rajalakshmi 2006 the soil salinity in csz of west bengal follows a seasonal salinity dynamics the significant increment in soil salinity is observed from the end of march in csz mainuddin et al 2019b thus delayed sown end of january pulse crops have to face extreme salinity and moisture stress in their early to mid pod development stages thus irrespective of land situations sowing of winter pulses at early dates is always advocated as a preventive measure for escaping the late season salinity as well as moisture stress and this unique phenomenon of the complex coastal saline zone was well captured by both the apsim swim3 and apsim grass pea models 4 4 scenario analysis the four long term 33 year hypothetical scenarios conducted with rice and grass pea natural saline system with and without gws with and without gwt and also the natural system minus both salt and gwt illustrated apsim s capacity to differentiate or disaggregate the key drivers and their significance in simulating cropping system performance in a saline environment different performance was also simulated over the long term between the two land situations with different sowing dates preferred to maximise grain yields this of course would be driven by different hydrological outcomes from different seasons for those two land elevations and whereas we do not have observed data to confirm this simulated finding it does illustrate apsim s capacity to differentiate the impact of climate and land situation on crop performance the scenarios illustrate the value in cropping systems modelling for contextualising observed short term experimental data in the long term perspective for example experiments in the medium lowland situation indicated the 1st sowing date 2nd nov resulted in the best grain yields from grass pea crops but the long term simulation analysis suggested that the 3rd sowing date 13th nov would be better on average in more years over a 33 year climate record this illustrates the value of well tested cropping systems models in contextualising experimental results but of course those models must be responsive to the different relative changes that occur in key driving parameters across the seasons our scenarios also illustrated the power of models like apsim to differentiate disaggregate and gauge the relative influence of driving variables like salt and water table dynamics on crop performance in different complex environments where the relative magnitude of these drivers may not be obvious in this particular environment the impact of salt was shown to be minimal on the crops of focus but still relevant when no water table was present it must be remembered however that our long term scenarios used only the water table and water table salinity data from the 2 years of the experimental record to populate the entire 33 years of the simulation it is quite possible that different real combinations of water table depth and salinity which could occur over that 33 year period could indeed change the relative impact of salinity and water stress on the crops it is clear that movement of saline ground water table gwt plays a pivotal role to regulate the moisture depletion pattern and removal building of salinity with the soil profile mainuddin et al 2019a 2019b the gwt table is one of the key driving factors influencing crop growth and yield and this was illustrated in our scenario analyses movement of shallow freshwater is considered a critical factor for crop production in coastal environments stofberg et al 2017 water use by vegetation is in turn significant to the dynamic nature water table mainuddin et al 2020 in this present study this dynamic nature of water tables and salt in the coastal saline zone was captured sensibly by apsim the water table of csz is following a dynamic seasonal pattern which may change into the future thus for assured supply of soil moisture to the root zone of the plants and minimisation of salinity risk under potential future conditions the selection of appropriate land situation and sowing window is of utmost importance the capability demonstrated through these simulations illustrates the value of complex cropping systems models like apsim to understand the key drivers in such complex environments their relative importance and to develop crop management strategies which maximise outcomes 4 5 key functionality demonstrated apsim is a point scale model and cannot know anything about regional dynamics of groundwater in this work we have shown the model to be capable of successfully simulating complex point scale surface soil dynamics moisture and salinity driven by model inputs of complex water table moisture and salinity dynamics and then subsequently simulating the equally complex crop response to these simulated surface soil dynamics across a range of sowing dates and two environmental positions thus we conclude that apsim is a useful tool to explain and predict future scenarios with changing climate water table and salinity dynamics and the associated effects on cropping system performance this unique feature of apsim can be successfully integrated with other polder level models mainuddin et al 2020 2021 mainuddin and kirby 2021 to facilitate broader or regional scale analysis if apsim is supplied with future water table dynamics climate change projections obtained from hydrological models like modflow feflow etc together with future projected meteorological data we believe our analysis here has demonstrated that apsim is capable of sensibly simulating the resultant surface soil water and salinity dynamics for different cropping systems and managements and the associated crop performance by predicting such dynamic behaviour of soil moisture salinity and crop performance it becomes a useful tool for the research scientist to explore and select suitable crops sowing times and agronomic management practices for the coastal saline zone 4 6 limitations and future development strategy our field experimentation and modelling studies were conducted in a complex coastal saline environment using apsim swim3 there is considerable scope for development of this module such as the introduction of other salts expects chloride like calcium carbonate magnesium sulphate etc as well as boundary layer related problems in the present experiment gwt salinity reached a maximum of 4 ds m 1 in the summer season similarly the shallowest gwt depth was at 50 cm with salinity level 1 ds m 1 on the other hand during initialization of the experiment soil salinity was low 0 2 ds m 1 due to removal of salt from the upper layer via rainfall thus the rainy season rice crop at early stages of growth did not face significant salt stress there is also scope for further development of apsim grass pea model and its testing across diverse climates soil environments and management practices in the south asian region the current prototype module does not simulate grain weathering although it is possible to simulate the number of rainfall events during pod fill using the manager module and use this as a surrogate of weathering damage apsim grass pea is not phosphorus responsive and crop growth is not currently sensitive to waterlogging both these limitations should be addressed in the future to expand the module s applicability 5 conclusions the apsim model was calibrated and validated in the complex cropping environment of the coastal saline zone of sundarbans west bengal india for different sowing dates under a rice grass pea cropping system in different land situations elevations apsim swim3 was used in a novel manner to simulate soil water and salinity dynamics within the crop root zone driven solely by highly dynamic measured inputs of groundwater table depth and salinity level specified farmer management and daily climate this can only be achieved by realistic simulation of soil evaporation capillary rise and solute transport the apsim oryza module and a prototype apsim grasspea module were then shown to perform satisfactorily in responding to these simulated soil dynamics by adequately simulating the observed crop phenology biomass and grain yield this illustrates that crop performance in such complex environments can be robustly simulated and that models like apsim can be useful tools to translate outputs from other models at different scales for example climate change from gcm and future changes to groundwater depth and salinity dynamics from regional hydrological models into changes in cropping system performance from this perspective we have shown apsim to be a robust research tool for climate change studies on agronomic management and adaptations in such regions apsim may also be used for development of decision support tools to assist farmers in selecting suitable crops cultivars their sowing times and optimal agronomic management practices for the coastal saline zone under prevailing and projected conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the study is funded by the australian centre for international agricultural research aciar through the project cropping system intensification in the salt affected coastal zones of bangladesh and west bengal india lwr 2014 073 the farmers of rangabelia village of gosaba island west bengal are also gratefully acknowledged for proving their precious land to conduct the field experiments the authors also thank the bckv csiro and ipni for the financial support to the first author s phd research appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105239 
25686,due to the seasonal increase in soil salt accumulation after cessation of monsoon rains the simulation of cropping system performance becomes highly challenging in coastal saline cropping areas rapidly changing groundwater gw dynamics during this period gw depth and salinity drive changes in capillary soil moisture rise soil evaporation and consequent deposition of salts in the crop root zone difficulty in simulating this complex cropping environment makes model based examination of optimal cropping patterns and agronomic management difficult as one season can be very different to the next the performance of crops is also difficult to predict under future climate scenarios in these regions as the impact of both changes in climate and groundwater salinity dynamics on soil status in the crop root zone changes in complex fashion no previous simulation study has sought to combine such dynamic and complex elements in simulating crop performance we calibrated and validated the apsim model for simulating a broad range of experimental treatments in a rice pulse cropping system over two seasons using the example of coastal saline west bengal india this represents a novel evaluation of the apsim model in simulating the complex mechanisms of seasonal soil water and salinity behavior as driven solely by daily climate and a dynamic shallow saline water table together with the associated crop responses the model performed well in simulating the observed soil chloride content cc and soil water content swc with a high coefficient of determination r2 for both calibration and validation datasets cc r2 0 91 and 0 89 swc r2 0 90 and 0 93 respectively and also acceptable rmse values these were well within the bounds of observed experimental error indicating that the model was simulating system behaviour acceptably apsim then successfully simulated the observed crop performance in response to these soil dynamics across 24 unique environmental situations this illustrates that crop performance in such complex environments can be robustly simulated and that models like apsim are a useful tool to translate outputs from other models at different scales for example climate change from general circulation model s gcm s and future changes to groundwater depth and salinity dynamics from regional hydrology models into changes in cropping system performance this positions apsim strongly as a robust research tool for climate change studies on agronomic impacts and adaptations in such regions as well as for development of decision support tools to assist farmers in selecting suitable crops cultivars their sowing times and optimal agronomic management practices for coastal saline zone under prevailing conditions keywords apsim rice grass pea cropping systems salinity shallow water table 1 introduction the coastal saline zone csz of west bengal india consists of 1 4 million ha area spread over 78 blocks of six southern districts of the state sarangi et al 2019 the agricultural development in the coastal saline belt is constrained by various physical chemical and social factors mainuddin et al 2019a mandal et al 2020 ray et al 2020 apart from the homestead upland the crop fields of this region are often classified as medium up medium low and lowlands the latter two are usually inundated by floods and rainwater associated with poor drainage in the kharif rainy season banerjee et al 2018b sarkar et al 2019 the shallow water table depth changes dynamically throughout the year supplementary fig s1 as does the salinity level of the ground water such seasonal variations play a driving role in regulating the surface soil salinity dynamics the upward capillary movement of saline groundwater and deposition of salts in the topsoil layer is a defining process in the winter to summer months brahmachari et al 2017 as a result of this the agriculture of the region is predominantly rainfed and the cropping pattern consists almost totally of mono cropped wet season rice samui et al 2020 mainuddin et al 2019a sarangi et al 2016 2019 in most cases the farmers of the coastal zone follow the traditional cropping systems satisfying their own food security needs without thinking of the cost effectiveness agro ecological suitability and sustainability of the technologies bell et al 2019 mainuddin et al 2019a thus sustainable improvement of existing rice based cropping system productivity in salt affected areas of csz is a major challenge for enhanced sustainability salinity dynamics are amongst the main biophysical factors determining timing in the cropping calendar for this salt affected environment radanielson et al 2018c in the csz cropping in the monsoon season starts after enough freshwater has desalinized the topsoil layers to ensure that wet season rice is not affected by salinity during the rabi season winter the shortage of freshwater and upward capillary movement of soil salinity to the upper layer of soils limits the possibility for second cropping to a very limited area gaydon et al 2021 radanielson et al 2018b the sowing date plays a crucial role in optimising crop production gaydon et al 2021 ghosh and khan 2019 ghosh 2018 radanielson et al 2018b amarasingha et al 2015 rice is one of the few crops for salt affected soils that can be successfully cultivated even though it is considered sensitive to salinity radanielson et al 2018b this is because rice under flooded conditions allows partial desalinization of the soil and reduces the impact of salinity ismail et al 2007 radanielson et al 2018a optimization of the sowing date of rice under different land situations to best utilize residual soil water and escape late season salinity stress in the succeeding pulse crops is one of the important strategies to intensify the existing cropping system of csz due to its quick growth habit high yielding ability and high adoptability under salt and moisture stress conditions dixit et al 2016 ghosh 2018 winter pulse crop grass pea lathyrus sativus l may be suitably fitted as a short duration crop in rice based cropping systems several field experiments for adjudging the effect of different sowing dates and land situation on salt and water dynamics of rice pulse cropping systems have been previously conducted in csz brahmachari et al 2020 sarkar 2021 sarkar et al 2020e 2020a 2020d the agricultural and production systems simulator apsim holzworth et al 2014 is increasingly being used in south asia sa for modelling rice based farming systems and has been successfully parameterized calibrated and validated for a broad range of locations within south asia mohanty et al 2020 khaliq et al 2019 gaydon et al 2017 sarkar et al 2020c cropping system models are particularly valuable when partnered with limited period field experiments in understanding long term climatic risk and its impact on system performance thus a well tested and locally calibrated and validated simulation model may be handy to explore the performance of different management practices within the context of a holistic systems approach for increasing system productivity assessing environmental impacts and evaluating the effects of a changing climate khaliq et al 2019 the combined dynamics of soil salinity and soil water is another matter in which models can be helpful in practice it is expensive to assess the effects of daily dynamics of soil water and salinity and the responses of the associated crops in previous investigations using point scale cropping systems models like apsim groundwater inputs were either static huth et al 2012 paydar et al 2005 or the salinity of the root zone soils was an input parameter itself hochman et al 2007 coastal saline cropping environments represent a much more complex situation with groundwater depths and salinity levels which are highly dynamic during the course of a cropping season apsim had not previously been used to simulate soil dynamics water nutrients and salinity together with associated cropping system performance directly from such inputs of daily climate water table dynamics depth and salinity and specifications of imposed management practices in other words in this research work we simulated the dynamics of the crop soil environment we did not specify it this represents a novel application and one that is essential in simulating future cropping system performance when only projected changes in climate and water table dynamics are available fig 2 we considered adjustments in the rice sowing window for two land situations with a focus on intensification of the existing rice based monocropping systems and also on reducing climate related risk however in conducting this work we combined two years field experimentation with a well tested apsim model to help in long term risk assessment in this paper we describe and evaluate a novel approach to simulate complex soil salinity and moisture dynamics and associated crop responses in a coastal saline environment the novelty lies in that this process is driven solely by daily model inputs of climate maximum and minimum temperatures rainfall and solar radiation highly dynamic water table depth gwt and water table salinity gws and farmers management information the soil salinity and moisture dynamics to which the crops are exposed are not model inputs they are simulated from highly dynamic groundwater inputs we conducted this testing over two different climatic seasons and a range of crop sowing dates to evaluate the adaptability of the apsim model s performance in this challenging environment we began by parameterising the model using measured local soil characteristics before calibrating uncertain input parameters for rice grass pea and soil sub models using detailed first year on farm experimental data before validating the model setup for simulation of the rice grass pea system production and associated soil water and salt chloride dynamics using the second year of field data a range of 6 sowing dates 2 seasons and 2 landscape positions allowed robust testing of model performance under 24 unique regimes of salinity and moisture 2 materials and methods we are providing for the first time an evaluation of the apsim model s ability to simulate soil salinity and moisture dynamics using ground water table inputs gwt and gws in contrast to previous work where soil salinity values were either used as direct inputs or else simulated based solely on irrigation water salinity 2 1 description of the study area to provide a testing base for this new methodology a field experiment was performed during 2016 17 and 2017 18 at a farmer s field in rangabelia village in gosaba block of south 24 parganas district west bengal india situated in 21 920 n latitude and 88 800 e longitude fig 1 the average elevation of the polder island where the experiment was conducted is around 3 5 m 0 5 m above mean sea level the polder is surrounded by vidyadhari and hogol rivers where periodic intrusion of highly saline tidal water occurs from bay of bengal 2 2 climatic conditions the daily maximum and minimum temperature relative humidity rainfall and solar radiation during the experimental period 2016 2019 were recorded using an automatic weather station em50 data collection system decagon inc wa usa situated approximately 50 m from the experimental site the study location has a typical sub tropical climate with monsoon dominant rainfall fig 3 the long term daily climatic data 1986 2018 of the experimental location were collected from regional research station coastal saline zone bidhan chandra krishi viswavidyalaya bckv and icar central soil salinity research institute icar cssri regional research station canning town west bengal the maximum and minimum temperature during the experimental years fluctuated between 18 6 and 37 6 c and 8 6 28 6 c respectively which is following a similar trend to the long term average air temperature data obtained from bckv and icar cssri in general there was a gradual drop in temperature from november to january the average relative humidity during the experimental period ranged between 49 6 and 88 8 the two year average rainfall during the experimental period was recorded 212 mm the average solar radiation of the experimental years was 16 mj m 2 day 1 2 3 physical and chemical characteristics of soils and water the experiments were conducted in two different land situations i viz medium upland and medium lowland having distinct differences in surface water dynamics during the wet season together with different soil physical and chemical characteristics the various physical and chemical parameters of the experimental soils are given in table 1 soil samples were collected before starting the experiment using an 80 cm core sampler and the samples were processed for particle size analysis bulk density and organic carbon content samples were collected in five layers 0 15 15 30 30 50 50 80 and 80 120 cm depth using standard procedures jackson 1969 the pedotransfer function software soil water characteristics version 6 02 74 usda available at http hydrolab arsusda gov soilwater index htm was used to estimate the required apsim soil water holding parameters i e crop lower limit ll assumed to be equal to the 15 bar lower limit mm mm 1 drained upper limit dul and saturated water content sat saxton et al 1986 the electrical conductivity of soil suspensions soil water 1 5 was measured at room temperature 28 c using a direct reading conductivity meter model systronics 363 throughout the experimental period water table depths and groundwater salinity ec from three installed piezometers at the experimental location to 5 48 m depth were monitored at regular intervals 7 days the quality of the groundwater was measured using an aqua cre conductivity meter version 2 0 1 as apsim required daily input data of meteorological variables the weekly measured ground water salinity and water table data was algorithmically converted into daily data using ms excel martinović et al 2016 the graphical representation of the monthly average groundwater table depth and salinity obtained from the weekly measured data during the experimental years is presented in fig 4 depths of surface water across different land situations are presented in supplementary fig s2 a b the seasonal dynamics of soil salinity electrical conductivity and soil water content gravitational were measured periodically 15 day intervals on a depth wise basis 0 15 cm 15 30 cm 30 50 cm 50 80 cm and 80 120 cm bhattacharyya et al 2018 for conversion of measured soil ec soil water 1 5 to the chloride deposition in kgha 1 for comparison with apsim simulated values the following equations were used 1 ecse dsm 1 ec1 5 dsm 1 2 74 3 01 he et al 2013 2 chloride ppm ecse dsm 1 1 8 4 4 35 5 bandyopadhyay et al 2003 3 c h l o r i d e k g h a 1 c h l o r i d e p p m b d g c c d e p t h o f s o i l l a y e r c m 10 where e c s e d s m 1 is the electrical conductivity of soil saturation paste extract dsm 1 e c 1 5 d s m 1 is the electrical conductivity of soil water at 1 5 ratio bd mgm 3 is bulk density of soil layer the depth of soil layers for estimating chloride kg ha 1 were 0 15 cm 15 30 cm 30 50 cm 50 80 cm and 80 120 cm the different conversion equations used in this experiment were successfully used in different field experiments of coastal saline zone of india and bangladesh mainuddin et al 2020 paul et al 2020a 2020b sarkar 2021 2 4 experimental treatments field experiments were conducted in the kharif monsoon june october and rabi winter november april seasons of two consecutive years 2016 17 and 2017 18 two land situations medium upland and medium lowland were used with six dates of rice sowing cv cr1017 at an interval of one week 15th june to 19th july replicated four times the size of each plot was 20 sq m 5 m 4 m and total number of plots was 48 rice seedlings 22 days old were manually transplanted at a spacing of 20 cm 15 cm with 2 seedlings per hill after the rice crops reached physiological maturity grass pea seeds cv bio l 212 were relay sown broadcasted into the standing crop of rice for utilization of the residual soil moisture thinning of grass pea was undertaken once at 28 30 days after sowing to ensure optimum plant population 60 70 plants m 2 plant to plant distance of 4 5 cm was maintained in each row in rice the recommended dose of fertilizer rdf i e 60 30 30 n p2o5 k2o kg ha 1 department of agriculture gowb 2012 was applied through chemical fertilizers like urea for n single super phosphate for p and muriate of potash for k half of the recommended dose of n along with full dose of p2o5 and k2o was applied as basal and the remainder applied in two equal splits at maximum tillering stage and at panicle initiation stage in grass pea the entire recommended dose of fertilizer i e 20 40 20 n p2o5 k2okg ha 1 department of agriculture gowb 2012 was applied at the time of sowing both the crops were grown under fully rainfed conditions in the case of rice ponded water depth varied between 2 and 5 cm during the crop growth water was drained from the rice field seven days before harvesting to control weed populations in rice two hand weedings were performed before each top dressing for grasspea two manual weedings were undertaken one at 30 days after sowing and another at 45 days after sowing need based spraying of triazophos 1 5 ml l 1 of water was performed to control yellow stem borer in rice the rice crop was harvested when 80 grains in each panicle were observed to be mature grass pea was harvested when the pods became ripe but the plants were not dead ripe both the harvested crops were dried threshed cleaned and sundried the general crop establishment management practices cropping history vis à vis other best agronomic managements has been described in sarkar 2021 and sarkar et al 2020e 2 5 experimental observations phenological data for both rice and grass pea were recorded the developmental stages dvs of rice were divided into six distinct growth phases i sowing of seeds ii transplanting iii panicle initiation iv 100 flowering phase v physiological maturity and vi harvest similarly the growing season of grass pea was divided into five phases namely i sowing ii 100 emergence phase iii 100 flowering phase iv physiological maturity and v harvest ten plants for both rice and grass pea were randomly selected from each plot uprooted and cleaned for sampling above ground biomass at different intervals 30 50 70 and 90 days after sowing in rice at 20 and 40 das days after sowing grass pea the uprooted plants were then sun dried oven dried at 70 c for 48 h and then weighed at crop harvest stage yield attributes were recorded for assessment of crop yield banerjee et al 2018a however grain seed and straw stover yield were determined from the net harvested data and converted to t ha 1 at 14 moisture content banerjee et al 2018b 2 6 apsim modelling 2 6 1 soil modules used in the study in the apsim framework different linked sub modules enable the user to simulate different agricultural system situations in simulating rice and grass pea crops in coastal saline environments five soil modules were used i e swim3 surfaceom soiln solute and fertiliser the water balance model employed was the apsim swim3 the latest release in the family of swim soil water infiltration and movement models developed for simulating the water and solute movement within soil profile connolly et al 2002 huth et al 2012 swim3 was used to simulate the daily dynamics of soil salinity and moisture the key apsim swim3 parameters which were calibrated to achieve good fit for measured vs simulated soil moisture content and salinity were those governing soil water movement layer based ks for saturated flow mm day 1 matric potential at dul cm solute dispersivity dis cm2 h 1 cm h 1 and the unit change of osmotic potential felt by the crop per unit change in cl concentration clslos cm3 μg 1 verburg et al 1996 these parameters and the values used in our calibration are detailed in appendix a the surfaceom module simulates the dynamics of the above ground crop residues which are left to decompose on the soil surface balwinder singh et al 2015 gaydon et al 2017 jha et al 2021 the soiln module simulates the transformations of soil c and n within the soil profile including residues that have been incorporated these modules include organic matter decomposition n immobilization urea hydrolysis ammonification nitrification and denitrification processes gaydon et al 2017 balwinder singh et al 2015 jha et al 2021 probert et al 1998 the solute module was used to track the solute balance and movement of chloride ions within the layers of the soil profile holzworth et al 2006 calculating leaching and solute diffusion in association with the swim3 module the fertiliser module was used to specify the application of chemical fertilizer to an apsim system using a schedule spanning multiple years mohanty et al 2020 2 6 2 crop modules parameters specifying phenological development for the apsim oryza rice model gaydon et al 2012a 2012b and the newly developed a prototype apsim grasspea model sarkar et al 2020a sarkar et al 2020d were calibrated using observed seeding flowering and harvest dates for varieties employed in the trials brief details of the apsim grasspea model are in appendix b and a more comprehensive publication on this new module with validation across numerous geographical sites is under development here we have only presented the testing of this module for the current location based on our soil core sampling we estimated rooting depths from evidence of root hairs 40 cm for both grass pea and rice in simulation of each experiment crop varieties were calibrated by varying the apsim crop phenology parameters until the modelled phenology dates matched the observed dates the primary dates of focus were those associated with sowing transplanting maximum tillering panicle initiation flowering and physiological maturity for rice and sowing germination 50 flowing 100 flowering physiological maturity and harvest for grass pea to assess the effect of relay sown grass pea in rice the apsim canopy module was used to arbitrate the light and water competition between two associated crops salinity response for rice apsim oryza is detailed by radanielson et al 2018c and for apsim grasspea via documentation on the apsim plant modelling framework huth et al 2012 in essence the apsim approach is that the presence of salinity cl ions in the soil increases the osmotic potential against which the crop draw soil moisture and thereby increase levels of water stress which the crop experiences no consideration of salt toxicity effects on crops were considered 2 6 3 external inputs daily climatic data including maximum and minimum temperature rainfall and solar radiation were used as inputs to apsim additionally we used measured groundwater table depth and groundwater salinity data as external inputs in each simulation we used apsim manager to read these data from the apsim climate file met file and from these inputs apsim simulated the soil water and chloride dynamics in the crop root zone via the processes of soil evaporation capillary moisture rise and crop uptake fig 2 2 6 4 calibration and validation process the model was parameterized using local soils climate and details of imposed management practices and then calibrated and validated using the 2 years on farm experiments for rice and grass pea the first year s data for each crop were used to calibrate the model particularly the genetic coefficients of each crop variety but also difficult to measure soil parameters such as rooting depths and distributions crop lower limit ll fbiom finert probert et al 1998 saturated hydraulic conductivity ks etc the second year s data were used for validation of those parameter calibrations variables compared during this process were soil moisture soil chloride crop phenological stages grain yields and total dry matter 2 7 statistical analysis for model calibration and validation linear regression was used to compare paired data points for observed and simulated grain and biomass yield for both rice and grass pea as well as soil water and chloride the slope α intercept β and coefficient of determination r2 of the linear regression between simulated and observed values were also determined the model performance using the student s t test of means assuming unequal variance p t and the absolute square root of the mean squared error rmse was also evaluated as rmse i 1 n s i o i 2 n rmse n absolute rmse mean of the observed 100 where si and oi are simulated and observed values respectively and n is the number pairs of data a model reproduces experimental data best when α is 1 β is 0 r2 is 1 p t is larger than 0 05 indicating observed and simulated data are the same at the 95 confidence level and the absolute rmse between simulated and observed values is similar to and ideally less than the standard deviation of experimental measurements for that variable representing the error between treatment replicates or the uncertainty of the observed data good model performance is also indicated when rmsen normalized square root of the mean squared error is similar to the standard errors of measured values and the rmsen is similar to the coefficient of variation of measured values yadav et al 2011 statistical comparisons were conducted for subsets of the overall rice and grass pea dataset to explore the performance of the model in simulating different land situations and sowing dates 2 8 scenario analysis after calibration and validation scenario analyses were performed to assess system behaviour under different hypothetical growing environments historical climate data covering 33 years 1986 2018 was used for these simulations measured ground water table depth gwt and ground water salinity gws data were only available for the experimental period 2016 2018 hence the assumption was made that gwt and gws maintained identical seasonal dynamics in each year thus we used the two year average values for these paraments to produced one set of data used every year in the simulation of the for the whole historical for building up the historical climate file with this assumption we performed four scenario analyses without re setting the soil and other crop parameters i long term performance of rice and grass pea yield under different sowing dates and land situations with natural prevailing conditions ii long term performance of rice and grass pea yield after removal of gws i e all salt in system removed no salinity in the groundwater fresh only iii long term performance of rice and grass pea without any water table gwt in the system indigenous salts still present but without salty water table contribution and iv long term performance of rice and grass pea yield with no gws or gwt components i e no shallow groundwater table at all no salts in the system probability of exceedance 0 1 graphs were used to compare the distribution of yields between different scenarios 3 results 3 1 simulation of soil water and salinity dynamics data on performance of apsim in simulating soil water content and salinity dynamics are presented in table 2 in both medium upland and medium lowland situations there was good agreement between observed and simulated chloride content cc kg ha 1 fig 5 a e fig 6 a e and volumetric soil water content swc cm3 cm 3 fig 7 a e fig 8 a e across different soil layers 0 120 cm the cc in the medium upland soil was notably higher than in the medium lowland soil in both land situations the agreement between observed and simulated chloride content for topsoil layers 0 50 cm was better than deeper soil layers 50 120 cm the correlation coefficient r2 between overall simulated and observed values was high for both calibration and validation datasets r2 0 91 and 0 89 respectively with normalized rmse of 18 9 and 19 1 respectively fig 11 a b the rmse of cc for both calibration and validation datasets were also within the uncertainty of observed values table 2 illustrated by the fact that rmse was of the same quantum as observed standard deviation in contrast to the cc the observed swc in the medium lowland soil was markedly higher than in the medium upland soil the correlation coefficient r2 between simulated and observed values for swc was high for both calibration and validation datasets r2 0 90 and 0 93 respectively with rmse s of 0 024 and 0 022 cm3 cm 3 corresponding to normalized rmse s of 6 53 and 6 18 respectively fig 9 c d table 2 comparing favourably with the observed standard deviations of 0 03 and 0 029 cm3 cm 3 respectively 3 2 phenology durations of different growth phases in both rice and grass pea were significantly influenced by variation in sowing date both apsim oryza and apsim grasspea crop modules successfully simulated phenological developmental variations with sowing date accurately predicting stages of emergence grass pea panicle initiation rice flowering both and physiological maturity both in both land situations supplementary tables s3 and s4 supplementary figs s3 and s4 the different cultivar specific parameters used in the apsim calibration and validation process for both rice and grass pea are presented in supplementary tables s1 and s2 in both experimental seasons the effect of sowing date on duration of growth phases was found to be similar in both medium upland and medium lowland situations the duration of growth for both rice and grass pea decreased with delay in sowing date both rice and grass pea took more time to mature when grown in the medium lowland situation irrespective of sowing date early sown rice 15th june 1st dos was delayed in reaching physiological maturity by 7 and 6 days for 2016 and 7 and 8 days for 2017 under medium upland and medium lowland respectively compared to late sown rice 19th july 6th dos similarly early relay sown grass pea took more time to reachphysiological maturity than the late relay sown grass pea 3 3 grain and biomass yield in both experimental years 2016 17 and 2017 18 there was generally good agreement between simulated and observed grain yield and accumulated biomass over time of both rice and relay sown grasspea in both land situations shown as time series in figs 7 and 8 and supplementary tables s3 s4 the crops sown on early sowing dates produced higher amount grain and biomass yield compared to the delayed sown crops for both calibration and validation sets the grain and biomass yield of rice and grasspea is closely associated to the simulated value supplementary fig s5 a d and fig 10 a d the model s performance for rice in terms of the evaluation parameters calibration and validation was judged to be satisfactory the correlation coefficient r2 was high for both calibration and validation datasets of grain and biomass production grain r2 0 76 and 0 80 biomass r2 0 93 and 0 98 respectively calibration and validation datasets fig 11 a d table 2 the rmse for the grain and biomass yield of rice for the calibration and validation was also within the limit of experimental uncertainty grain rmse 331 sdobs 401 and 193 sdobs 203 biomass rmse 431 sdobs 743 and 465 sdobs 683 respectively calibration and validation datasets and normalized rmse was 6 78 and 3 94 for grain yield and 3 87 and 4 64 for biomass respectively the grass pea model also performed well the r2 between simulated and observed grain and biomass yield of grass pea was high for both the calibration and the validation dataset also grain r2 0 89 and 0 90 biomass r2 0 90 and 0 84 respectively fig 12 a d table 2 with normalized rmse of 9 23 and 7 80 for grain yield and 7 89 and 7 80 for biomass respectively the overall crop performance of grasspea was better in year 2 as compared to year 1 overall grain yield 750 kg ha 1 in 2016 17 and 993 kgha 1in 2018 19 and this year wise variation was well captured by the apsim grasspea model table 2 3 4 scenario analysis both crops rice and grass pea sown on earlier dates produced higher amounts of grain and biomass compared to delayed crops under the prevailing natural saline system and for all other scenarios in the medium lowland situation the grain yield of rice with sowing date over the longer term followed a similar trend to the 2 year experimental values used for model calibration and validation supplementary fig s6a in the medium upland situation however rice crops sown on both the 2nd and 3rd sowing date 28th june were shown to outperform those sown on the 1st sowing date 15th june in the most years fig 13 a in both land positions rice yield was not significantly impacted by salt when the water table gwt was present figs 13b and s6b but was negatively impacted when the gwt was removed from the simulation suggesting water stress mitigating impact of the shallow gwt on the rice crop figs 13c and s6c salt in the system however was shown to have a small impact on rice performance when there was no gwt present for when both salt and gwt were removed from the simulations there was a slight improvement in rice yield for some sowing dates comparing fig 13 c and d s6 c and d over the longer term the grass pea yield with sowing date in the medium upland situation also revealed a slightly different trend to that observed in the 2 year experimental phase with the 3rd sowing date 13th nov outperforming the 1st sowing date 2nd nov in all but some of the higher yielding years and with the 2nd sowing date 7th nov achieving the peak yielding crops in a few seasons s7a as per rice the long term grass pea yield trend with sowing date in the medium lowland situation also reflected the experimental observations fig 14 a with the first sowing date being the best performing one by removing gsw and gwt components from the simulations both individually and together it was observed that grass pea is significantly more positively impacted by the presence of the gwt than negatively by salt in this environment across both land situations however when no water table was present grass pea crops were impacted by salinity to a small degree comparing fig 14 c and d s7 c and d in a similar way to rice therefore but to a greater extent apsim suggests that the shallow dynamic gwt provides grass pea crops with significant mitigation against water stress in this environment 4 discussion the feasibility of the apsim model in simulating the performance of the rice grass pea cropping system and salinity and moisture dynamics for medium upland and lowland condition across a broad range of sowing dates in the coastal saline zone of west bengal india was judged to be highly satisfactory to the best of our knowledge this is first time apsim has been used to simulate the complex daily dynamics of soil water and salinity from direct inputs of water table depth and salinity and the consequent response from the crops prediction of soil salinity and moisture were also acceptable across different land situations as were grain and biomass yield predictions 4 1 simulation of soil water and seasonal salinity dynamics seasonal salt and water dynamics in the root zone soil play a pivotal role in the growth and development of the crops in this region apsim simulated these in response to external inputs of groundwater table depth and salinity capturing all the main features of soil water and salinity dynamics throughout the soil profile in both years under both medium upland and medium lowland conditions table 2 the model is successfully simulating the capillary rise solute transport behaviours leaching of salts within the soil profile in these different growing environments figs 5 6 and figs 7 8 the shallow groundwater table of the csz is changing rapidly as function of infiltration of water from surface layer and soil evaporation mainuddin et al 2019b 2019a 2020 and supplementary fig 1 on the other hand seasonal movement of salts in the soil profile and the availability of moisture to the root zone of the crops largely depends on the rainfall and seasonal dynamics of groundwater table 4 2 simulation of phenology crop modules within the apsim framework successfully simulated phenological developmental variations of both rice and grass pea like most other crop models apsim oryza and apsim grasspea calculate phenological stages based on thermal time accumulation cumulative degree days bouman and van laar 2006 under saline growing ecology the crop phenology largely varies with sowing date affecting temperature and moisture conditions to which the growing crop is exposed and salt stress radanielson et al 2018c longer crop duration with longer grain filling time results in higher degree of effective grain filling and higher potential yield yang et al 2008 salt stress can also accelerate the physiological maturity the crop growth period can be reduced by the stress and therefore the duration of grain filling reduced proportionally radanielson et al 2018a 2018c in this present experiment the rice crops sown on 15th june 1stdate of sowing were delayed in reaching physiological maturity by a week compared with those sown on 19th july on the other hand pulse crops are generally more sensitive to the moisture salinity and temperature stress at different growth stages and production of these leguminous crops can be seriously affected by soil salinity and high temperature hanumantharao et al 2016 meena and lal 2018 the duration of grass pea also decreased with a delay in sowing date due to temperature and moisture stress ghosh and khan 2019 these variations in the phenological events due to different sowing dates were well captured by the apsim grasspea model in this coastal dynamically saline environment 4 3 simulation of biomass and grain yield under saline conditions the model generally captured the effect of the sowing date treatments on grain and biomass yield for both rice and grasspea sowing time is one of the major factors in rice cultivation and indirectly determines soil temperature and weather conditions to which young seedlings and rice plants are exposed during different development stages delay in sowing of rice beyond the optimum sowing window can have negative effect on crop yield balwinder singh et al 2016 pal et al 2017 adjustment of sowing time of the rice crop is undertaken because it ensures the vegetative growth occurs during a period of satisfactory temperatures and high levels of solar radiation farrell et al 2003 in the present experiment early sown rice and relay grass pea 15th june 21st june for rice 2nd november 07th november for grass pea performed better than latter sown crops in terms of grain and biomass yield higher remobilization of resources in the early sown crop which probably was linked to the higher dry matter of the crop thus representing the potential source for dry matter remobilization pal et al 2017 przulj and momcilovic 2001 agro meteorological factors like air temperature solar radiation and seasonal destitution of rainfall also plays a significant role to determine the yield of wet season rice chen et al 2013 huang et al 2019 early sown rice has significant yield advantages for the relay sown pulse crops by better utilization of soil water and alleviating the effect of post monsoon salinity stress kar et al 2012 malik et al 2016 the grain and biomass yield for both the crops is reasonably higher in medium lowland situation than crop sown in medium upland situation may be due to low salinity rinsing and higher soil water pro prolonged growth period apsim oryza and apsim grasspea captured these variations in different land situations for both experimental seasons in some treatments the grass pea model overestimated the biomass production but within the range of experimental uncertainty sowing time of pulse crops plays a critical role in regulating the yield components by altering the availability of moisture heat and salinity stress as well as other abiotic and biotic factors late season salinity stress also seemed to be detrimental to the growth of the pulse crops the most crucial and important stage in the life cycle of species growing in saline environment is the period of seed germination and early development of the seedlings ranganathan and rajalakshmi 2006 the soil salinity in csz of west bengal follows a seasonal salinity dynamics the significant increment in soil salinity is observed from the end of march in csz mainuddin et al 2019b thus delayed sown end of january pulse crops have to face extreme salinity and moisture stress in their early to mid pod development stages thus irrespective of land situations sowing of winter pulses at early dates is always advocated as a preventive measure for escaping the late season salinity as well as moisture stress and this unique phenomenon of the complex coastal saline zone was well captured by both the apsim swim3 and apsim grass pea models 4 4 scenario analysis the four long term 33 year hypothetical scenarios conducted with rice and grass pea natural saline system with and without gws with and without gwt and also the natural system minus both salt and gwt illustrated apsim s capacity to differentiate or disaggregate the key drivers and their significance in simulating cropping system performance in a saline environment different performance was also simulated over the long term between the two land situations with different sowing dates preferred to maximise grain yields this of course would be driven by different hydrological outcomes from different seasons for those two land elevations and whereas we do not have observed data to confirm this simulated finding it does illustrate apsim s capacity to differentiate the impact of climate and land situation on crop performance the scenarios illustrate the value in cropping systems modelling for contextualising observed short term experimental data in the long term perspective for example experiments in the medium lowland situation indicated the 1st sowing date 2nd nov resulted in the best grain yields from grass pea crops but the long term simulation analysis suggested that the 3rd sowing date 13th nov would be better on average in more years over a 33 year climate record this illustrates the value of well tested cropping systems models in contextualising experimental results but of course those models must be responsive to the different relative changes that occur in key driving parameters across the seasons our scenarios also illustrated the power of models like apsim to differentiate disaggregate and gauge the relative influence of driving variables like salt and water table dynamics on crop performance in different complex environments where the relative magnitude of these drivers may not be obvious in this particular environment the impact of salt was shown to be minimal on the crops of focus but still relevant when no water table was present it must be remembered however that our long term scenarios used only the water table and water table salinity data from the 2 years of the experimental record to populate the entire 33 years of the simulation it is quite possible that different real combinations of water table depth and salinity which could occur over that 33 year period could indeed change the relative impact of salinity and water stress on the crops it is clear that movement of saline ground water table gwt plays a pivotal role to regulate the moisture depletion pattern and removal building of salinity with the soil profile mainuddin et al 2019a 2019b the gwt table is one of the key driving factors influencing crop growth and yield and this was illustrated in our scenario analyses movement of shallow freshwater is considered a critical factor for crop production in coastal environments stofberg et al 2017 water use by vegetation is in turn significant to the dynamic nature water table mainuddin et al 2020 in this present study this dynamic nature of water tables and salt in the coastal saline zone was captured sensibly by apsim the water table of csz is following a dynamic seasonal pattern which may change into the future thus for assured supply of soil moisture to the root zone of the plants and minimisation of salinity risk under potential future conditions the selection of appropriate land situation and sowing window is of utmost importance the capability demonstrated through these simulations illustrates the value of complex cropping systems models like apsim to understand the key drivers in such complex environments their relative importance and to develop crop management strategies which maximise outcomes 4 5 key functionality demonstrated apsim is a point scale model and cannot know anything about regional dynamics of groundwater in this work we have shown the model to be capable of successfully simulating complex point scale surface soil dynamics moisture and salinity driven by model inputs of complex water table moisture and salinity dynamics and then subsequently simulating the equally complex crop response to these simulated surface soil dynamics across a range of sowing dates and two environmental positions thus we conclude that apsim is a useful tool to explain and predict future scenarios with changing climate water table and salinity dynamics and the associated effects on cropping system performance this unique feature of apsim can be successfully integrated with other polder level models mainuddin et al 2020 2021 mainuddin and kirby 2021 to facilitate broader or regional scale analysis if apsim is supplied with future water table dynamics climate change projections obtained from hydrological models like modflow feflow etc together with future projected meteorological data we believe our analysis here has demonstrated that apsim is capable of sensibly simulating the resultant surface soil water and salinity dynamics for different cropping systems and managements and the associated crop performance by predicting such dynamic behaviour of soil moisture salinity and crop performance it becomes a useful tool for the research scientist to explore and select suitable crops sowing times and agronomic management practices for the coastal saline zone 4 6 limitations and future development strategy our field experimentation and modelling studies were conducted in a complex coastal saline environment using apsim swim3 there is considerable scope for development of this module such as the introduction of other salts expects chloride like calcium carbonate magnesium sulphate etc as well as boundary layer related problems in the present experiment gwt salinity reached a maximum of 4 ds m 1 in the summer season similarly the shallowest gwt depth was at 50 cm with salinity level 1 ds m 1 on the other hand during initialization of the experiment soil salinity was low 0 2 ds m 1 due to removal of salt from the upper layer via rainfall thus the rainy season rice crop at early stages of growth did not face significant salt stress there is also scope for further development of apsim grass pea model and its testing across diverse climates soil environments and management practices in the south asian region the current prototype module does not simulate grain weathering although it is possible to simulate the number of rainfall events during pod fill using the manager module and use this as a surrogate of weathering damage apsim grass pea is not phosphorus responsive and crop growth is not currently sensitive to waterlogging both these limitations should be addressed in the future to expand the module s applicability 5 conclusions the apsim model was calibrated and validated in the complex cropping environment of the coastal saline zone of sundarbans west bengal india for different sowing dates under a rice grass pea cropping system in different land situations elevations apsim swim3 was used in a novel manner to simulate soil water and salinity dynamics within the crop root zone driven solely by highly dynamic measured inputs of groundwater table depth and salinity level specified farmer management and daily climate this can only be achieved by realistic simulation of soil evaporation capillary rise and solute transport the apsim oryza module and a prototype apsim grasspea module were then shown to perform satisfactorily in responding to these simulated soil dynamics by adequately simulating the observed crop phenology biomass and grain yield this illustrates that crop performance in such complex environments can be robustly simulated and that models like apsim can be useful tools to translate outputs from other models at different scales for example climate change from gcm and future changes to groundwater depth and salinity dynamics from regional hydrological models into changes in cropping system performance from this perspective we have shown apsim to be a robust research tool for climate change studies on agronomic management and adaptations in such regions apsim may also be used for development of decision support tools to assist farmers in selecting suitable crops cultivars their sowing times and optimal agronomic management practices for the coastal saline zone under prevailing and projected conditions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the study is funded by the australian centre for international agricultural research aciar through the project cropping system intensification in the salt affected coastal zones of bangladesh and west bengal india lwr 2014 073 the farmers of rangabelia village of gosaba island west bengal are also gratefully acknowledged for proving their precious land to conduct the field experiments the authors also thank the bckv csiro and ipni for the financial support to the first author s phd research appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105239 
25687,model emulation has become an integral tool in scenario analysis risk assessment and calibration of environmental models of particular interest is dynamic emulation the approximation of model outputs from inputs or processes that vary in time this paper presents a method for data driven dynamic emulation of high dimensional model outputs that overcomes the logistical challenges from assumptions in traditional multivariate statistics concerning output covariance in this method outputs are subjected to principal component analysis and gaussian random fields are fit along new orthogonal axes to accommodate spatial heterogeneity and serial correlation the technique is demonstrated on a regional groundwater model of metropolitan mexico city where it successfully emulates spatial and temporal dynamics of land subsidence and aquifer level fluctuation resulting from two management scenarios in doing so we introduce methodological advances to emulation techniques which facilitate the use of models with high dimensional outputs in computationally expensive planning and optimization applications keywords water resources planning process based models emulation modeling spatiotemporal emulation high dimensional emulation dynamic emulation 1 introduction computer simulation models of environmental systems allow decision makers to understand the response of existing systems and proposed investments to a wide range of possible futures thereby quantifying system vulnerabilities and ranges of potential future system performance environmental models can serve as the common space for decision makers scientists engineers and other vested stakeholders to examine a system of interest the models must therefore 1 accurately reproduce natural processes and human environmental interactions e g stormwater drainage reservoir storage groundwater pumping across several spatial temporal domains 2 produce results within reasonable run times to allow for evaluation of a wide range of possible scenarios and interactions and 3 be interpretable pragmatic i e capable of demonstrating tradeoffs and decision relevant process based modeling has a long history of application for accurately reproducing the behavior of natural and human systems a process based hydrological model for example is a mathematical formulation that represents the state space of a watershed system by solving governing equations of the laws of mass energy and momentum at a temporal spatial resolution representative of the underlying physical processes fatichi et al 2016 when applied to problems demanding high numbers of mathematical evaluations or the evaluation of large spatial domains models of this type often push the limits of available computational resources clark et al 2017 and inefficiently allocate analytical resources to hydrologic modeling efforts that would be better spent modeling more relevant uncertainties such as demographic or financial whereas the relative contribution of hydrologic uncertainties to total uncertainties involved in water system planning are often small ray et al 2018 computationally heavy process based models sometimes demand data and time out of proportion with the level of confidence they provide heavy computational burden typically forces compromises concerning incomplete calibration sensitivity analysis or the inability to resolve model weaknesses due to time constraints on repeated runs borgonovo et al 2011 jeremy oakley and anthony o hagan 2002 confalonieri et al 2010 modern approaches to human environmental decision support are challenged by the growing consensus regarding the need for robustness based decision analytic approaches marchau vincent et al 2019 such applications often require coupling of multiple process based models into increasingly complex human environmental systems models as model complexity increases so too do computational requirements despite advances that reduce model runtime the computational costs associated with complex human environmental models are a limiting factor in decision analytic exercises which require high numbers of runs e g optimization based decision making uncertainty analysis ultimately making such problems computationally intractable castelletti et al 2012 castelletti et al 2012 ratto et al 2012 clarke et al 2005 higdon et al 2008 ray and brown 2015 thus we are left with a trade off between the goal of high fidelity simulation of human environmental system response at informative temporal spatial scales and robust scenario analysis for decision relevant applications analysts have looked to model emulation to reduce this computational burden and enable analysis which is relevant to study objectives model emulators sometimes called model surrogates are developed primarily to address a limited computational budget for simulation or global optimization simpson et al 2014 since the surrogates are abstractions the loss of model accuracy is only acceptable in return for the ability to complete complex analyses such as global optimization or bayesian model calibration schnorbus and cannon 2014 reichert et al 2011 kennedy and o hagan 2001 surrogate modeling has become an established part of water resources engineering for decision support as well as for identifying the most crucial experiments in which to invest computational resources with the original process based model in order to improve understanding of system response reichert et al 2011 razavi et al 2012 however the state of the art is limited in its ability to account for spatial heterogeneity while maintaining temporally varying dynamics razavi et al 2012 rougier 2017 asher et al 2015a the emulation technique introduced in this paper is designed for dynamic problems involving high dimensional outputs tens of thousands this is done with dimension reduction via principal components analysis pca by subjecting model outputs to pca simultaneous observations of the state space of the model are projected onto orthogonal axes which can be linearly summed back into the original state space representation since the model outputs can be expressed as a linear sum of processes on orthogonal axes this circumvents the limitations and assumptions otherwise required by multivariate regression approaches and allows for a richer expression of the dependent nature of discretized process models by allowing the response variables along the re projected axes to be distinct univariate regression problems while this method also allows innovations in dynamic emulation of univariate model outputs to be applied in parallel of perhaps the greatest value is the ability to accommodate high dimensionality and spatial heterogeneity characteristics common to most modern environmental problems and presently out of reach for standard emulation techniques section 1 1 describes multivariate emulation and section 1 2 describes reduced dimension emulation the bases for the method proposed here the method is then demonstrated with a case study to emulate transient flow and land subsidence in a highly nonlinear groundwater model of mexico city over a 52 year horizon 1 1 dynamic emulation emulating environmental models for decision support or management applications often requires the ability to perform dynamic emulation castelletti et al 2012 this paper adopts a definition of dynamic emulation as the estimation of an original simulation that either 1 has inputs and or parameters that are not held constant over the simulation period or 2 depicts time dependent processes that create variation in the outputs over time even when inputs parameters are held constant this latter issue is often the case when emulating process models governed by partial differential equations pde s and discretized in time and space as the state space solution in one timestep is a function of the state space of the previous timestep dynamic emulation of these types of process models is an area of established research castelletti et al 2012 ratto and pagano 2010 with focus on emulation of a single model output e g streamflow a challenge in dynamic emulation unique to these types of process models is the need for an appropriate transition function to account for the influence of the previous state on the current state castelletti et al 2012 castelletti et al 2012 there are generally three approaches to simplifying the state space in model emulation data driven structural and hierarchical asher et al 2015b hierarchical methods primarily focus on reducing the topological or analytical complexity e g adopting a coarser resolution of the original model for quicker runtime and convergence structural approaches analytically solve the model s governing equations in a reduced basis e g via orthonormal projection razavi et al 2012 asher et al 2015b ratto et al 2012 data driven methods are generally regression based and of the three approaches can best support the generation of response surfaces described by razavi et al 2012 in which a single aggregated model output is approximated at different parameter values because their method for speeding run times is to lump adjacent cells of a fine resolution mesh to produce a coarser resolution mesh hierarchical approaches are limited in their usefulness to water resources problems in which such uniformly aggregated versions of the original model are misleading such as when spatial covariance is not constant structural and data driven approaches are more nuanced in their handling of spatial heterogeneity and are therefore more common in the water resources literature asher et al 2015b they offer inverse sets of advantages and disadvantages while structural approaches can numerically reproduce simulations from high dimensional nonlinear models the re projected basis they produce is only valid for one set of parameter values e g well pumping rate which must remain uniform over time thus structural approaches are not well suited to the emulation of model outputs from dynamic inputs this limitation renders such structural approaches numerically unstable when subjected to transient conditions in addition classic structural approaches which are more reliable under transient conditions i e the response matrix methods or the embedding method have historically tended to be computationally untenable with large model domains and optimization problems with many decision variables datta and kourakos 2015 when combined with machine learning techniques data driven approaches have proven able to accommodate time dynamics and the nonlinearities that result from the inclusion of temporal transition functions castelletti et al 2012 however data driven approaches do not easily accommodate high output dimensionality razavi et al 2012 a problem in multivariate regression stemming from restrictive assumptions concerning the relations among model outputs necessary to make most methods tractable alexopoulos 2010 as a result the current state of the art in emulation within water resources practices has focused on emulating process models with univariate outputs see for example castelletti galelli restelli et al 2012 1 2 multivariate emulation the emulation of multiple simultaneous outputs from a model is referred to herein as multivariate emulation the importance and difficulty of emulating multiple simultaneous model outputs has been discussed in many statistical works rougier 2017 fricker et al 2013 and the high dimensionality of finite element models places their emulation at the forefront for multivariate emulation one common approach to emulating a simulation model with a multivariate output is to use a gaussian process gp model with a separable covariance function conti and o hagan 2010 rougier 2017 this approach uses a gp model with a separable and stationary covariance function with an assumed constant e y x described by 1 c o v y x y x exp x x t r x x where x and x are any two arbitrary different input parameter settings and r is a matrix of range parameters which contextualize how the distance x and x translate to correlation however due to the nature of the separable covariance function the spatial covariance structure for any given input parameter setting to the model and the time point must remain the same rougier 2017 cressie and huang 1999 fricker et al 2013 not only is this restrictive for most modeling exercises but it is not generally compatible with the nature of the governing equations of many hydrologic models varouchakis emmanouil a and hristopulos 2019 kolovos et al 2004 another aspect of this method incompatible with environmental modeling applications is the assumption of spatial stationarity in a spatial field s with locations s 1 s n s a stationary covariance structure implies that the correlation structure is invariant across spatial shift h refer to 2 2 c o v y s 1 y s 2 c o v y s 1 h y s 2 h for example in groundwater models representing geologic heterogeneity or regional effects e g regional pumping concentrated recharge formation anisotropy this statistical assumption is unrealistic this is because the shape and extent of the covariance of discretized model elements is highly dependent on local simulation specific processes such as pumping and recharge from a computational standpoint even in the instances where a suboptimal separable covariance approximation is permissible the separable covariance structure suffers from high computational costs in large model domains model fitting through maximum likelihood estimation usually requires inverting the covariance matrix σ in a repeated manner typically hundreds or thousands of times and the computational cost for such inversion is in the order o n 3 flops when the model output is large dependent data such as a high resolution spatial pattern model fitting becomes computationally intractable due to this computational cost heaton et al 2019 2 methods the work proposed here expands on chang et al 2014 and higdon et al 2008 which attempt to address the same issues of covariance shared with high dimensional tens of thousands of input variables process based models in other applications the primary contribution is the ability to dynamically emulate the entire output space of a nonlinear model throughout a simulation driven by inputs that vary over time while these methods have not been used for emulation based simulation of groundwater models they have been recently used to enable analysis of the high dimensional input parameter space of a groundwater model crevillén garcía et al 2019 crevillén garcía 2018 2 1 reduced dimension emulation 2 1 1 principal component analysis on spatial data for prediction from emulators a main conceptual tenet of the approach in chang et al 2014 is the process of applying singular value decomposition svd to spatiotemporal datasets the approach here uses pca which is equivalent to svd for continuous variables for dimensional reduction of the model outputs the emulation process is done on repeated model runs by perturbing a set of training variables which are in the training domain θ each model output is a spatial pattern for many fixed spatial locations across different model runs each training variable refers to a process that the modeler chooses to explore and may be an individual input variable which governs a distinct point process in the physical model or spatial aggregations of input variables who will either be set at the same level and or perturbed similarly together the spatial domain has dimensionality n the number of model elements while the training domain θ has a dimensionality of q the number of training variables therefore y i y θ i s 1 y θ i s n t is the set of computer model outputs denoted as a spatial process observed at n different spatial locations at the i parameter setting the essence of this technique is to identify the most important elements of this spatial process and model how it changes with alternative choices of training variables and over time to analyze this all computer model outputs from all observations θ 1 θ p were collected into matrix m a p by n matrix storing these model results as shown in 3 3 m y 1 t y p t the first step was to preprocess m so that the column means of m are all zero applying pca to m returns 1 the basis matrix for computer model output k y whose columns are scaled eigenvectors k 1 λ 1 e 1 k n λ n e n where λ 1 λ 2 λ n are the ordered eigenvalues and e 1 e n are the corresponding eigenvectors of the covariance matrix of m and 2 the basis transformed representation of each p th observation in m along each principal component y i r y i 1 r y i n r t where y i j r contains the jth principal component score for the ith model run see fig 1 for a visual representation of these outputs the number of principal components chosen as adequate for explaining the data j y depends on the proportion of explained variance given via the eigenvalues as indicated in 4 4 i 1 j y λ i i 1 n λ i the approach taken here chose enough basis vectors so that 90 of the distribution of data was explained this means that across the n dimensional distribution of raw data output 90 of the variance in the data falls within a transformed coordinate system with j y dimensions where j y n the actual process of emulation occurs by conditioning a gaussian random field relating the covariance structure of the different input parameter settings θ i i 1 p with the corresponding principal component scores along the first j y components for each of the first j y columns of y r arguably the most popular covariance function is the squared exponential which is infinitely differentiable and very smooth rasmussen and williams 2005 however various covariance functions such as the matérn stein 2012 or the spartan covariance function elogne et al 2008 varouchakis e a and hristopulos 2013 can be appropriate when processes should be modeled as less smooth see chang et al 2014 for a more detailed description of fitting a gaussian random field this enables emulation since the predictive distribution for the j th principal component at a new input parameter setting y θ j r given by the gaussian random field can be written as 5 y θ j r y j r n μ j σ θ θ i j σ θ i j 1 y j r 1 μ j σ θ σ θ θ i j σ θ i j 1 σ θ θ i j t where σ θ θ i j is the covariance vector between y θ j r and y j r σ θ is the marginal variance for y θ j r σ θ i j is the marginal covariance matrices for y j r emulation takes place in reduced dimensions however the process of pca provides the means to re project our reduced space emulation results into the original spatial pattern via the basis matrix k y at a new parameter setting θ the projections in the original space are the linear sum of first j y principal components selected re projected via basis matrix k y with the column means of m re added equation 7 6 y ˆ θ j 1 j y k y j y θ j r m where y ˆ θ is the emulated output in the original spatial locations and m is the vector of the column means of y the summation term of the basis matrix and the corresponding emulated score as a function of θ is summarized as η θ resulting in 7 7 y ˆ θ k y η θ m 2 1 2 dynamic reduced dimension emulation one unique challenge that we need to solve in our emulation problem is serial correlation to be more specific the simulation result at each time point t heavily depends on the status of the system at the previous time step t 1 spatiotemporally discretized models governed by pde s such as groundwater models contain the property that state space in the next timestep of the system is a function of the current explained in the following sections serial correlation greatly complicates the emulation problem when we desire to emulate model outputs at multiple timesteps or outputs that result from a simulation in which model parameters change over time the emulation problem in chang et al 2014 does not require considering such dynamic nature of model behavior as the emulated model outputs are purely spatial patterns computed by time averaging 2 1 2 1 proposed formulations for dynamic reduced dimension emulation in a non dynamic emulation scenario all perturbed parameters remain constant and outputs are assumed independent so that there is no notion of time when only the final state of the multi output system is desired this can be emulated as dictated in 7 however this situation becomes dynamic when outputs of successive timesteps are needed as a series this has the same formulation as 7 but now we have additional input variable t 1 2 t for t timesteps of interest now the model in 7 can be rewritten as follows 8 y ˆ θ t k y η θ t m in most practical dynamic situations however θ is also changing over time and therefore the values that θ took in previous timesteps must be considered we propose two formulations that can train a regression to the dimension reduced data without the need for multiplying the dimensionality by t the first is similar to a time input ti approach conti and o hagan 2010 which makes predictions at any timestep of the simulation training period with a single emulator by providing time as an additional training variable 9 y ˆ θ t k y η θ t t m in the context of fitting gaussian random fields this method assumes that the result of a simulation at time t i can be found with both the choice of test input parameters at that timestep θ t and the current timestep index t i since temporal effects are measured in the joint distribution of the time training variable and the other training variables whether by the nature of the physical model or the experimental design the relation between the same timestep across various training simulations can be weak this may be reasonable when emulating hydraulic head in a groundwater model as processes in pumping and recharge up until the timestep in question will create different hydraulic head surfaces across the model and therefore time as an explicit training variable may not be sufficient some authors addressing the problem of dynamic emulation have suggested using a state space representation with an autoregressive approach as the transition function castelletti et al 2012 this approach was deemed appropriate for our purposes as the scores along each principal component are already in essence a summarized state space representation of the system when the solution to the physical model requires information about the current state of the system i e hydraulic gradient using an autoregressive ar formulation can help provide sufficient information this translates as well to reduced dimension emulation as the score of a specific observation along any component y i j r is simply a re mapping of the entire output space at a given observation therefore if using an ar approach when training a gaussian process for the j th principal component y j r the p x q matrix containing all the parameter combinations used for training θ is adjusted the adjustment adds the previous score and changes θ to θ j via θ i j θ i t i y t i 1 j r where θ i and t i are input parameter settings and the time index of observation i respectively the inclusion of time as a training variable is still important in capturing temporal interactions this changes the emulation notation to 10 y ˆ θ t k y η θ t t y t 1 r m in this case the initial condition of the system should also be included as an additional observation in m so that the score of the initial condition on each principal component is captured which can be done by decomposing the initial state of the system along the columns of k y note that since this is distinct to each simulation within the larger training dataset the value of y t i 1 j r will be the decomposed initial condition along the jth column of k y any time t i 1 the first time index the overall emulation procedure is summarized in the workflow presented in fig 2 3 case study 3 1 mexico city aquifer 3 1 1 hydraulic history of mexico city the original lake system of the basin of mexico and current administrative boundaries of mexico city are shown in fig 3 currently approximately half of mexico city s water is supplied from well systems located in the metropolitan zone of the basin of mexico s aquifer system the other half is from imports from neighboring basins such as the cutzamala system which contributes approximately 1 3 of the supply 10 m3 s and is pumped a distance of 120 km with a vertical lift of approximately 1100 m sistema de aguas de la ciudad de méxico 2012 the inter basin transfer has been politically fraught and options for future development e g for climate change adaptation focus on better practices related to the aquifer such as pump scheduling and augmented aquifer storage and recovery historical over extraction has led to land subsidence that reverses drainage gradients exacerbating flooding issues and damaging ground level e g roads and subsurface e g pipes infrastructure the resultant losses from the pressurized water distribution system are added to the city s already over burdened drainage system these problems require study before plans can be enacted to further develop local aquifer resources efforts are ongoing to address water supply deficits without increasing already large water import projects while also minimizing further land subsidence one of the most important aspects of this problem is the aquifer an abundant local source that has been overexploited for years while there are differing estimates on the long term water balance for the local aquifer it is widely understood that anthropogenic extraction began exceeding natural recharge in the early 20th century birkle et al 1998 sistema de aguas de la ciudad de méxico 2012 urban growth and changes to climatic patterns may further reduce the net amount of water infiltrating and recharging the aquifer behzadi et al 2020 3 1 2 the process based model the groundwater model used in this series of experiments is a physically based finite element simulation of the aquifer of the basin of mexico with the spatial extent of the model shown in fig 4 the basin of mexico is bordered by steep mountains surrounding lowlands where an ancient lake system once existed detailed descriptions of the geology of the basin are available edmunds et al 2002 arce et al 2019 the model is designed to estimate land subsidence throughout greater mexico city in response to water extraction from a series of connected aquifers therefore the model s geographic extent includes the lower plains of the valley while the volcanic piedmont and mountainous areas at higher elevation are excluded but represented as the boundary conditions the groundwater model uses a finite volume mesh in space and an implicit finite difference scheme to simulate groundwater flow and land subsidence with a spatial resolution of 1 km and a simulation time step of 1 year pumping records are available from 1935 up to the year 2018 and historical recharge was estimated by combining historical rainfall data and information about the permeability of local geologic formations the model depicts a shallow phreatic aquifer separated by an extensive leaky clay aquitard of varying thickness from the main water bearing alluvial layer beneath a relevant feature of the aquifer is its confinement in large areas by clay upon head drawdown in the aquifer an important interaction occurs draining the water stored in the pores of the clay to the aquifer in significant amounts vertical flow this drained water is in fact responsible for the land subsidence that occurs when the aquifer is pumped this phenomenon of drawdown means that past pumping is having effects today and will also affect the future behavior of the system flow calculations are solved in two dimensions in the lower upper aquifer while only vertical flux is considered through the aquitard subsidence occurs in the model as the aquitard is depressurized from water released from storage thus subsidence is calculated on a time varying basis in response to changes to the clay deformation modulus which vary with the sign of the net hydrostatic pressure change cruickshank villanueva 1984 the model has 4217 spatial elements representing outputs of water level in the main lower aquifer as well as land subsidence across the basin it represents extraction natural recharge water transfer via the aquitard and artificial recharge sites since the properties of the aquitard are determined by the clay modulus which is a function of the current pressure and water flux direction at a given cell subsidence and water level development in any given simulation are non steady the draining of the clay layer which is directly responsible for land subsidence and changes to aquifer level is governed by a nonlinear relation between inputs and outputs which is highly relevant to the choice of emulation methods like many regional groundwater models the runtime of the mexico city process based groundwater model is too long to be integrated into a robust optimization framework e g ray et al 2014 what is more the model is proprietary and thus access is permitted to only a limited number of model runs 3 2 use of methodology for decision support the groundwater model of the basin of mexico is embedded in a decision support model workflow connected with regional climate models water distribution models local hydrological models and models of the major water import infrastructure systems risk assessment requires thousands of runs of the groundwater model across a wide range of local conditions climate land use demographic urbanization etc in order to trace out the response of the groundwater aquifer and subsidence to multidimensional stressors in the risk management exercise formulated as a robust optimization problem evaluation of the same thousands of risk assessment scenarios will be repeated hundreds or thousands of times each time for a different combination portfolio of water system interventions in total hundreds of thousands or millions of model runs are required the result will be a set of pareto efficient management policies within the basin of mexico and import basins an emulator is necessary to link the process based groundwater model with a model of local urban hydrology i e runoff and infiltration and a water distribution system model since the emulator informs regional groundwater management decisions the interest is in preserving spatial structure in order to estimate changes in one region relative to the others the decisions to be made regarding interaction with the local aquifer are spatial in nature should well fields be increased reduced in the east of the city or the south should groundwater injection and managed aquifer recharge be developed in the north of the city or the south second costs of groundwater extraction are responsive to water table depth and water quality considerations each of which is spatially heterogeneous third the changing geometry of subsidence is of vital importance for cost considerations and for a new surface map for flood analyses 4 results demonstration of approach 4 1 design of experiment and selection of training variables work plan step 1 4 1 1 selecting training variables the groundwater model outputs of interest are groundwater level and land subsidence across the model area the process based groundwater model was run continuously throughout a 52 year planning horizon until approximately 2070 to accommodate potential future changes to infrastructure configurations operating procedures and meteorological variables in all groundwater simulations using the process based model here referred to as training runs for the emulator no flow boundary conditions were implemented table 1 summarizes the 19 training variables θ q 1 7 r r 1 10 t altered when running the process based groundwater model for emulator training given that the time step of the original model was annual all of these processes are annual averages land subsidence and aquifer changes are calculated simultaneously in the process model and emulated separately as described below due to the large nature of the space time domain of this problem neither the raw model output for the aquifer level data nor the emulator output for this data were transformed in order to find a valid solution under mass balance rather it was deemed sufficient to rely on expert guidance to ensure confidence that the emulator would not return unrealistic results within the ranges of the training variables 4 1 2 design of experiment the previous section introduced the set of 19 training variables that govern the modeling experiments practical limitations of computational time and resources limited the number of simulations to 40 quasi random annual sequences a rule of thumb for training size of an n variable problem is 10n williams et al 2003 however the intention to dynamically emulate processes over time and not just the final state as well as the explicit inclusion of time as a training variable meant that the potential sample size in this case was 40 runs 52 years per run 2080 temporal sets of outputs superior to a sample size of 40 in order to train a model with 19 training variables changing q 1 7 r y 1 10 at every yearly time step in the manner of a quasi random sequence would make the outputs essentially unidentifiable since these processes are slow moving therefore the design used a two year stress period for the model in which q 1 7 r r 1 10 remained constant and there were p 1040 available replications for consideration in a random latin hypercube sampling mckay et al 1979 with a uniform distribution this type of sampling scheme can be important when sampling for multidimensional stress tests as the factors can be efficiently sampled over predetermined ranges or probability functions ray et al 2018 mckay et al 1979 this sampling scheme assigned values for q 1 7 r r 1 10 and blocks were split into 40 sections with t from 1 52 added as the final column of each the annual time step increased the set of training observations by a multiple of 52 and this design of experiment doe prevented the need to similarly multiply the input dimensionality by 52 by including the current timestep as an additional training variable the use of latin hypercube sampling instead of an ensemble of realistic scenarios was chosen to not only increase sample space coverage but also to reduce redundant information via correlation as explained in miftakhova et al 2020 this method posits that when a limited number of model runs can be extracted as was the case here it is more efficient to train an emulator upon artificially created uncorrelated data as opposed to a collection of realistic runs this is because such realistic runs are likely to be correlated and thus provide a lower aggregate amount of information to train the model upon the authors show the success of this method by training upon four orthogonal input scenarios and still achieving good predictive power upon out of fold realistic scenarios while showing that training upon a limited collection of likely scenarios does not jointly contain a sufficient basis to form an emulator due to applicability of this method to the limited number of model runs available in this work the method was adapted here using 1 latin hypercube sampling for the creation of orthogonal training scenarios and 2 comparison of predictive error on the two realistic test scenarios directly to serve as the best choice of covariance function parameterization this method does not include the traditional step of cross validation as the test and training data are purposefully uncorrelated from each other and therefore not at risk of contaminating the ability to gauge the predictive power of the emulator 4 2 workplan steps 2 5 training data processing pca and component selection the model output matrix for subsidence m s and model output matrix for the aquifer level m a created from the doe each had dimensions p 2080 and n 4217 both output matrices were mean centered and subjected to pca per steps 3 and 4 of the workplan to get the products k y a k y s y r a and y r s to assist in interpretation fig 6 demonstrates the re creation of the model outputs in the first simulation year using the entire leading and remaining set of principal components in both m s 1 and m a 1 the re addition of m a or m s is not shown in fig 6 so that the additive nature of the variance explained by the components is apparent fig 7 shows graphically the values of k y 1 n j for j 1 2 3 4 for both k y s and k y a fig 7 is similar in interpretation to a traditional biplot gower et al 2010 in which higher magnitudes of k y i j are indicative of areas that have the largest correlation with the component and the signs indicating how locations tend to co vary the leading 10 components cumulatively explain 90 of the variance across the observations for land subsidence and 12 for groundwater level with 90 explained variance a common threshold for modeling applications jolliffe 2002 this was adopted as well and thus the number of components up to this threshold dictates the number of gaussian random fields to be fit fig 7 shows that a large proportion of explained variance is clustered around small spatial locations in the water level simulations these coincide with the location of the artificial injection wells as well as the location of the most intensive collection of wells within the pumping systems which fall into small groups of one more finite grid elements therefore these clusters are point processes whose fluctuations drastically affect the surrounding hydraulic field while the other processes of interest are spatially distributed 4 3 step 6 gaussian random field fitting and validation as explained in the design of experiment the selection and optimization of hyperparameters was intended to find the lowest predictive root mean square error rmse from two out of sample test scenarios while the training scenarios were uncorrelated with two year stress periods to allow for the effect of drawdown and recovery to be captured after large fluctuations in training variables these out of fold scenarios detailed below were formulated to be realistic non random simulations with stress periods of 1 year similar to the emulator s intended use in test scenario 1 there was no artificial recharge pumping systems 3 and 7 located in the south and north of the model domain respectively in fig 5 were subjected to a random increasing trend in extraction and natural recharge was modeled as a random decreasing trend test scenario 2 was identical to test scenario 1 except that artificial recharge projects were fully operational beginning in year 25 of the simulation the remaining user defined training variables all excluding t and y t 1 r were assigned random values within one positive standard deviation from their historical mean the matlab octave gpml package rasmussen and nickisch 2018 was used to create custom covariance functions for each covariance function tried initial starting points were randomized in batches and optimized for each component proper performance was measured by decomposing the annual results of the test scenarios via k y a or k y s from steps 3 and 4 into the proper score for each component at each time step the time required to fit an individual gaussian process gp is heavily influenced by the size of training data optimization tolerance and initial starting point on average fitting the models with the data in this study took approximately 30 40 min while the execution of a 52 year scenario requires approximately 2 s 4 3 1 land subsidence emulation fig 8 shows example scores of the leading 10 components in the land subsidence data from an exploratory 52 year simulation outside the training and test data in which q 1 7 r y 1 10 were held constant and decomposed using k y s the parabolic shape of the developing scores along several components reflects the dynamic behavior of the clay subsidence modeled in the original groundwater model and the nonlinear effects that it introduces 4 3 2 groundwater level emulation initial attempts at fitting the gaussian random fields revealed that for the groundwater level processes years representing transitions between stress periods showed poor results this indicated the inadequacy of relying only on the time step as a training variable in capturing the dynamic nature of this problem as shown in 9 unlike land subsidence changes in groundwater level could be positive or negative and have continually increasing decreasing trends based on the model parameters preceding a given time step while including time as an input training variable helps to account for nonseparable behavior the quasi random sequences of the training data weaken the temporal covariance for identical years between training simulations it was for this reason that a first order ar state space representation was chosen for dynamic emulation in this case represented by 10 in this formulation θ is changed to θ j via θ i j θ i t i y i 1 j r in order to provide the training variable y i 1 j r for the first j y components for training and testing prediction the initial condition of the system m 0 dimensions 1 n is decomposed using k y a generated from the training data 4 3 3 model testing error metrics and physical interpretation fig 9 compares the final state of land subsidence in each scenario produced by the emulator to that of the original physically based model allowing for reasonable tolerances the emulator accurately represents the spatial pattern of the response of subsidence to artificial injection returning to fig 7 all non zero loadings occur in the same set of model cells but do not map to the physical space in consistent ways fig 10 shows the same result wherein for water level emulation capturing both the location and magnitude of the physical model processes is important in understanding the validity as results show global and local effects are re created with the emulator in test scenario 1 and the changes to these processes with the introduction of artificial injection are captured again in scenario 2 unlike the land subsidence processes the final state of the aquifer level estimation does not directly overlay i e is not an easy visual match for the primary components in fig 7 this is because unlike land subsidence water level can recover some cells may even finish a simulation at a higher level than they began the patterns appearing at the end of the simulation are the sum of space time interactions resulting from the model s unique features and pde governing equations since the usage of spatial principal components can remove the effect of spatial interactions and therefore stationarity within the physical model domain the onus of the analysis in this methodology lies upon modeling the effects of nonseparability and serial correlation this was done by finding a proper function for each column of y r that both properly represents the unique covariance structure within θ that dominates each principal component as well as time related effects which may need to be parameterized by appending θ figs 9 and 10 show that despite these unique nonlinearities from both the physical model structure and the nature of serial correlation these effects were correctly emulated and thus their superposition back into physical space resulted in recreating the physical processes of interest with sufficient detail despite the close visual match between emulated and modeled results in both land subsidence and aquifer level the error metrics do show that there is a general loss generated from two factors the first is that only enough components were chosen to model up to a certain threshold of the variance which is part of the initial accepted loss in accuracy to make the method computationally tractable see fig 6 the second is primary in the aquifer level emulation where if the training data contain highly variable point processes the high frequency variability in those point processes can come to dominate the pca washing out lower frequencies in regional aquifer behavior while alternate forms of dimension reduction are beyond the scope of this paper if these point processes are part of an aggregated training variable such as the wellfields in this paper interpolation may be improved by disaggregating these points and making them their own covariate despite this attribute both regional and local processes were re created and thus this methodology adequately meets the needs of dynamic emulation for univariate responses as identified in castelletti et al 2012a b while being applicable for high dimensional applications as shown here given that application of this emulator is for regional management the re creation of spatial detail at a larger scale is acceptable here the acceptable local error and therefore the effort required to model more components or invest in more exhaustive model fitting procedures is ultimately dependent on the purpose of the emulator application applications which require higher local precision while using the gp approach here may try increasing the variance threshold modeling more components or implementing an optimization search criteria on the initial starting points 4 3 4 necessity of a pca approach a brief exploration of the training data and test scenarios is helpful in order to better highlight the benefits of using pca rather than direct emulation techniques to model spatial variance a common practice in emulation of environmental process models is to aggregate the output to a single summary statistic e g the spatial mean response so that univariate emulation techniques can be used see the supplementary information for additional details of the current state of groundwater emulation literature figs 11 and 12 illustrate the impact of this practice with aquifer level outputs from the regional groundwater model used as the case study in this work fig 11 graphically represents variability of the model outputs from the training runs by examining the correlation r2 between model output change in aquifer level at each of the n locations across p 1 2080 observations to the corresponding spatially averaged response with the correlation value at location n r n calculated via 11 r n p 1 2080 y n i y n y p y p 1 2080 y n i y n 2 p 1 2080 y i y 2 we can see that many regions especially the area within mexico city have low correlations and hence cannot be predicted well by the overall mean therefore even a well performing dynamic emulator of the spatial mean response is not a pathway to obtaining temporal spatial insights since this insight came from the 40 randomized training scenarios a similar analysis on two the realistic test scenarios is important to see if the same holds when more realistic variability is introduced fig 12 shows the same correlation calculation from the results of the two test scenarios both constructed with realistic climate and consumption traces in the second test scenario artificial recharge projects become operational in year 25 of the simulation and this large contribution is sufficient to create very different spatial profiles detailing areas which could be said to be represented by the overall mean fitting an emulator for each column of y r allows for different covariance functions to be used to quantify the primary processes instead of attempting to find one single function which appropriately captures them all 5 discussion and conclusions despite the success and utility of univariate approaches in dynamically emulating environmental models a substantial gap in the literature exists for the dynamic emulation of models where the insight cannot be logically summarized by a few independent statistics attempts to do so face the potential error from assumptions of independence and separability which are prerequisites of existing methods these errors become more likely and more severe when the model domain grows larger this paper demonstrates an approach to streamline emulation of multiple outputs and multivariate model outputs at non adjacent spatial locations thereby enabling the nuance of high dimensional models to be utilized for computationally expensive planning and optimization applications dynamic multivariate emulation is crucial for these applications as it enables understanding of how spatially heterogeneous systems can be managed and affected by decisions or processes which change over time experiment 1 showed how heterogeneity renders single summary statistics ineffective based on the value of the training variables and how attempts to identify and emulate heterogeneity gives rise to this method experiment 2 showed that the doe and reduced dimension emulation was able to track the localized and larger regional changes throughout the simulation window without divergence over time with accommodations for dominant point processes as explained in section 4 3 step 6 gaussian random field fitting and validation other modifications to the design may be relevant for applications with smaller timesteps where the short term effects are more of interest i e decaying response of drawdown from pumping changes as opposed to long term changes as was the goal here in these cases a new method of sampling and parameterizing time effects may be more effective similar to the question posed in siade et al 2010 it is also possible that gaussian interpolation will not be a suitable framework for modeling the columns of y r for a given model or problem type or that methods more suited to high dimensional input spaces such as deep learning may be required as the size of the training variable set increases in the context of the application to mexico city as well as other regional case studies the ability to conceptualize the effects of spatial heterogeneity and time varying effects is crucial to include groundwater as an active and nuanced part of facing water challenges the ability of the emulator to capture the spatial heterogeneity of the aquifer response and training variables allows for the needs and characteristics of different municipalities throughout the region to be valued and accounted for in the model e g equity issues distribution of costs and benefits spatial heterogeneity in adaptation philosophy wetland preservation the preservation of the spatial domain also allows planners to change the optimization metrics coming from the emulator i e summary statistics of results model areas considered objective function without needing to create a new one unlike the standard response surface approach the inclusion of time varying effects allows for analyses of climate and demographic change and the staging of investments in time the ability to emulate this model with its spatiotemporal nuances at a low computational cost provides a path to allow for cutting edge planning optimization and scenario analysis the technique of reduced dimension dynamic emulation introduced here allows for process based models to be used in more sophisticated decision support applications that were previously logistically infeasible for the existing methods this work is embedded in a stakeholder driven water resilience project sponsored by the rockefeller foundation and the world bank st george freeman et al 2020 the analysis is a decision making under deep uncertainty based dmdu based methodology which relies on the ability to perform many simulations of linked models of the water import systems the aquifer processes of extraction injection and recharge the water distribution system and the drainage system of the valley of mexico in cases such as this one or more models typically must be emulated or approximated so that they can all be used in the scenario exploratory simulation heavy dmdu methodology together and or in a multi objective optimization framework out of that need this methodology is introduced to help leverage the nuance of a class of models which has been categorically difficult to emulate and help promote their potential in understanding both the solutions and the pathways to achieve them declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is made possible by the world bank group contract 7190616 integrating a mexico city urban water system model with a groundwater model and a draining system model for holistic adaptation to climate change risks as well as the rockefeller foundation special thanks to local partners at sistema de aguas de le ciudad de méxico and universidad autónoma nacional de méxico we are grateful to the journal editors and anonymous reviewers for their careful attention to this manuscript and the many improvements that resulted from their thoughtful comments appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105238 
25687,model emulation has become an integral tool in scenario analysis risk assessment and calibration of environmental models of particular interest is dynamic emulation the approximation of model outputs from inputs or processes that vary in time this paper presents a method for data driven dynamic emulation of high dimensional model outputs that overcomes the logistical challenges from assumptions in traditional multivariate statistics concerning output covariance in this method outputs are subjected to principal component analysis and gaussian random fields are fit along new orthogonal axes to accommodate spatial heterogeneity and serial correlation the technique is demonstrated on a regional groundwater model of metropolitan mexico city where it successfully emulates spatial and temporal dynamics of land subsidence and aquifer level fluctuation resulting from two management scenarios in doing so we introduce methodological advances to emulation techniques which facilitate the use of models with high dimensional outputs in computationally expensive planning and optimization applications keywords water resources planning process based models emulation modeling spatiotemporal emulation high dimensional emulation dynamic emulation 1 introduction computer simulation models of environmental systems allow decision makers to understand the response of existing systems and proposed investments to a wide range of possible futures thereby quantifying system vulnerabilities and ranges of potential future system performance environmental models can serve as the common space for decision makers scientists engineers and other vested stakeholders to examine a system of interest the models must therefore 1 accurately reproduce natural processes and human environmental interactions e g stormwater drainage reservoir storage groundwater pumping across several spatial temporal domains 2 produce results within reasonable run times to allow for evaluation of a wide range of possible scenarios and interactions and 3 be interpretable pragmatic i e capable of demonstrating tradeoffs and decision relevant process based modeling has a long history of application for accurately reproducing the behavior of natural and human systems a process based hydrological model for example is a mathematical formulation that represents the state space of a watershed system by solving governing equations of the laws of mass energy and momentum at a temporal spatial resolution representative of the underlying physical processes fatichi et al 2016 when applied to problems demanding high numbers of mathematical evaluations or the evaluation of large spatial domains models of this type often push the limits of available computational resources clark et al 2017 and inefficiently allocate analytical resources to hydrologic modeling efforts that would be better spent modeling more relevant uncertainties such as demographic or financial whereas the relative contribution of hydrologic uncertainties to total uncertainties involved in water system planning are often small ray et al 2018 computationally heavy process based models sometimes demand data and time out of proportion with the level of confidence they provide heavy computational burden typically forces compromises concerning incomplete calibration sensitivity analysis or the inability to resolve model weaknesses due to time constraints on repeated runs borgonovo et al 2011 jeremy oakley and anthony o hagan 2002 confalonieri et al 2010 modern approaches to human environmental decision support are challenged by the growing consensus regarding the need for robustness based decision analytic approaches marchau vincent et al 2019 such applications often require coupling of multiple process based models into increasingly complex human environmental systems models as model complexity increases so too do computational requirements despite advances that reduce model runtime the computational costs associated with complex human environmental models are a limiting factor in decision analytic exercises which require high numbers of runs e g optimization based decision making uncertainty analysis ultimately making such problems computationally intractable castelletti et al 2012 castelletti et al 2012 ratto et al 2012 clarke et al 2005 higdon et al 2008 ray and brown 2015 thus we are left with a trade off between the goal of high fidelity simulation of human environmental system response at informative temporal spatial scales and robust scenario analysis for decision relevant applications analysts have looked to model emulation to reduce this computational burden and enable analysis which is relevant to study objectives model emulators sometimes called model surrogates are developed primarily to address a limited computational budget for simulation or global optimization simpson et al 2014 since the surrogates are abstractions the loss of model accuracy is only acceptable in return for the ability to complete complex analyses such as global optimization or bayesian model calibration schnorbus and cannon 2014 reichert et al 2011 kennedy and o hagan 2001 surrogate modeling has become an established part of water resources engineering for decision support as well as for identifying the most crucial experiments in which to invest computational resources with the original process based model in order to improve understanding of system response reichert et al 2011 razavi et al 2012 however the state of the art is limited in its ability to account for spatial heterogeneity while maintaining temporally varying dynamics razavi et al 2012 rougier 2017 asher et al 2015a the emulation technique introduced in this paper is designed for dynamic problems involving high dimensional outputs tens of thousands this is done with dimension reduction via principal components analysis pca by subjecting model outputs to pca simultaneous observations of the state space of the model are projected onto orthogonal axes which can be linearly summed back into the original state space representation since the model outputs can be expressed as a linear sum of processes on orthogonal axes this circumvents the limitations and assumptions otherwise required by multivariate regression approaches and allows for a richer expression of the dependent nature of discretized process models by allowing the response variables along the re projected axes to be distinct univariate regression problems while this method also allows innovations in dynamic emulation of univariate model outputs to be applied in parallel of perhaps the greatest value is the ability to accommodate high dimensionality and spatial heterogeneity characteristics common to most modern environmental problems and presently out of reach for standard emulation techniques section 1 1 describes multivariate emulation and section 1 2 describes reduced dimension emulation the bases for the method proposed here the method is then demonstrated with a case study to emulate transient flow and land subsidence in a highly nonlinear groundwater model of mexico city over a 52 year horizon 1 1 dynamic emulation emulating environmental models for decision support or management applications often requires the ability to perform dynamic emulation castelletti et al 2012 this paper adopts a definition of dynamic emulation as the estimation of an original simulation that either 1 has inputs and or parameters that are not held constant over the simulation period or 2 depicts time dependent processes that create variation in the outputs over time even when inputs parameters are held constant this latter issue is often the case when emulating process models governed by partial differential equations pde s and discretized in time and space as the state space solution in one timestep is a function of the state space of the previous timestep dynamic emulation of these types of process models is an area of established research castelletti et al 2012 ratto and pagano 2010 with focus on emulation of a single model output e g streamflow a challenge in dynamic emulation unique to these types of process models is the need for an appropriate transition function to account for the influence of the previous state on the current state castelletti et al 2012 castelletti et al 2012 there are generally three approaches to simplifying the state space in model emulation data driven structural and hierarchical asher et al 2015b hierarchical methods primarily focus on reducing the topological or analytical complexity e g adopting a coarser resolution of the original model for quicker runtime and convergence structural approaches analytically solve the model s governing equations in a reduced basis e g via orthonormal projection razavi et al 2012 asher et al 2015b ratto et al 2012 data driven methods are generally regression based and of the three approaches can best support the generation of response surfaces described by razavi et al 2012 in which a single aggregated model output is approximated at different parameter values because their method for speeding run times is to lump adjacent cells of a fine resolution mesh to produce a coarser resolution mesh hierarchical approaches are limited in their usefulness to water resources problems in which such uniformly aggregated versions of the original model are misleading such as when spatial covariance is not constant structural and data driven approaches are more nuanced in their handling of spatial heterogeneity and are therefore more common in the water resources literature asher et al 2015b they offer inverse sets of advantages and disadvantages while structural approaches can numerically reproduce simulations from high dimensional nonlinear models the re projected basis they produce is only valid for one set of parameter values e g well pumping rate which must remain uniform over time thus structural approaches are not well suited to the emulation of model outputs from dynamic inputs this limitation renders such structural approaches numerically unstable when subjected to transient conditions in addition classic structural approaches which are more reliable under transient conditions i e the response matrix methods or the embedding method have historically tended to be computationally untenable with large model domains and optimization problems with many decision variables datta and kourakos 2015 when combined with machine learning techniques data driven approaches have proven able to accommodate time dynamics and the nonlinearities that result from the inclusion of temporal transition functions castelletti et al 2012 however data driven approaches do not easily accommodate high output dimensionality razavi et al 2012 a problem in multivariate regression stemming from restrictive assumptions concerning the relations among model outputs necessary to make most methods tractable alexopoulos 2010 as a result the current state of the art in emulation within water resources practices has focused on emulating process models with univariate outputs see for example castelletti galelli restelli et al 2012 1 2 multivariate emulation the emulation of multiple simultaneous outputs from a model is referred to herein as multivariate emulation the importance and difficulty of emulating multiple simultaneous model outputs has been discussed in many statistical works rougier 2017 fricker et al 2013 and the high dimensionality of finite element models places their emulation at the forefront for multivariate emulation one common approach to emulating a simulation model with a multivariate output is to use a gaussian process gp model with a separable covariance function conti and o hagan 2010 rougier 2017 this approach uses a gp model with a separable and stationary covariance function with an assumed constant e y x described by 1 c o v y x y x exp x x t r x x where x and x are any two arbitrary different input parameter settings and r is a matrix of range parameters which contextualize how the distance x and x translate to correlation however due to the nature of the separable covariance function the spatial covariance structure for any given input parameter setting to the model and the time point must remain the same rougier 2017 cressie and huang 1999 fricker et al 2013 not only is this restrictive for most modeling exercises but it is not generally compatible with the nature of the governing equations of many hydrologic models varouchakis emmanouil a and hristopulos 2019 kolovos et al 2004 another aspect of this method incompatible with environmental modeling applications is the assumption of spatial stationarity in a spatial field s with locations s 1 s n s a stationary covariance structure implies that the correlation structure is invariant across spatial shift h refer to 2 2 c o v y s 1 y s 2 c o v y s 1 h y s 2 h for example in groundwater models representing geologic heterogeneity or regional effects e g regional pumping concentrated recharge formation anisotropy this statistical assumption is unrealistic this is because the shape and extent of the covariance of discretized model elements is highly dependent on local simulation specific processes such as pumping and recharge from a computational standpoint even in the instances where a suboptimal separable covariance approximation is permissible the separable covariance structure suffers from high computational costs in large model domains model fitting through maximum likelihood estimation usually requires inverting the covariance matrix σ in a repeated manner typically hundreds or thousands of times and the computational cost for such inversion is in the order o n 3 flops when the model output is large dependent data such as a high resolution spatial pattern model fitting becomes computationally intractable due to this computational cost heaton et al 2019 2 methods the work proposed here expands on chang et al 2014 and higdon et al 2008 which attempt to address the same issues of covariance shared with high dimensional tens of thousands of input variables process based models in other applications the primary contribution is the ability to dynamically emulate the entire output space of a nonlinear model throughout a simulation driven by inputs that vary over time while these methods have not been used for emulation based simulation of groundwater models they have been recently used to enable analysis of the high dimensional input parameter space of a groundwater model crevillén garcía et al 2019 crevillén garcía 2018 2 1 reduced dimension emulation 2 1 1 principal component analysis on spatial data for prediction from emulators a main conceptual tenet of the approach in chang et al 2014 is the process of applying singular value decomposition svd to spatiotemporal datasets the approach here uses pca which is equivalent to svd for continuous variables for dimensional reduction of the model outputs the emulation process is done on repeated model runs by perturbing a set of training variables which are in the training domain θ each model output is a spatial pattern for many fixed spatial locations across different model runs each training variable refers to a process that the modeler chooses to explore and may be an individual input variable which governs a distinct point process in the physical model or spatial aggregations of input variables who will either be set at the same level and or perturbed similarly together the spatial domain has dimensionality n the number of model elements while the training domain θ has a dimensionality of q the number of training variables therefore y i y θ i s 1 y θ i s n t is the set of computer model outputs denoted as a spatial process observed at n different spatial locations at the i parameter setting the essence of this technique is to identify the most important elements of this spatial process and model how it changes with alternative choices of training variables and over time to analyze this all computer model outputs from all observations θ 1 θ p were collected into matrix m a p by n matrix storing these model results as shown in 3 3 m y 1 t y p t the first step was to preprocess m so that the column means of m are all zero applying pca to m returns 1 the basis matrix for computer model output k y whose columns are scaled eigenvectors k 1 λ 1 e 1 k n λ n e n where λ 1 λ 2 λ n are the ordered eigenvalues and e 1 e n are the corresponding eigenvectors of the covariance matrix of m and 2 the basis transformed representation of each p th observation in m along each principal component y i r y i 1 r y i n r t where y i j r contains the jth principal component score for the ith model run see fig 1 for a visual representation of these outputs the number of principal components chosen as adequate for explaining the data j y depends on the proportion of explained variance given via the eigenvalues as indicated in 4 4 i 1 j y λ i i 1 n λ i the approach taken here chose enough basis vectors so that 90 of the distribution of data was explained this means that across the n dimensional distribution of raw data output 90 of the variance in the data falls within a transformed coordinate system with j y dimensions where j y n the actual process of emulation occurs by conditioning a gaussian random field relating the covariance structure of the different input parameter settings θ i i 1 p with the corresponding principal component scores along the first j y components for each of the first j y columns of y r arguably the most popular covariance function is the squared exponential which is infinitely differentiable and very smooth rasmussen and williams 2005 however various covariance functions such as the matérn stein 2012 or the spartan covariance function elogne et al 2008 varouchakis e a and hristopulos 2013 can be appropriate when processes should be modeled as less smooth see chang et al 2014 for a more detailed description of fitting a gaussian random field this enables emulation since the predictive distribution for the j th principal component at a new input parameter setting y θ j r given by the gaussian random field can be written as 5 y θ j r y j r n μ j σ θ θ i j σ θ i j 1 y j r 1 μ j σ θ σ θ θ i j σ θ i j 1 σ θ θ i j t where σ θ θ i j is the covariance vector between y θ j r and y j r σ θ is the marginal variance for y θ j r σ θ i j is the marginal covariance matrices for y j r emulation takes place in reduced dimensions however the process of pca provides the means to re project our reduced space emulation results into the original spatial pattern via the basis matrix k y at a new parameter setting θ the projections in the original space are the linear sum of first j y principal components selected re projected via basis matrix k y with the column means of m re added equation 7 6 y ˆ θ j 1 j y k y j y θ j r m where y ˆ θ is the emulated output in the original spatial locations and m is the vector of the column means of y the summation term of the basis matrix and the corresponding emulated score as a function of θ is summarized as η θ resulting in 7 7 y ˆ θ k y η θ m 2 1 2 dynamic reduced dimension emulation one unique challenge that we need to solve in our emulation problem is serial correlation to be more specific the simulation result at each time point t heavily depends on the status of the system at the previous time step t 1 spatiotemporally discretized models governed by pde s such as groundwater models contain the property that state space in the next timestep of the system is a function of the current explained in the following sections serial correlation greatly complicates the emulation problem when we desire to emulate model outputs at multiple timesteps or outputs that result from a simulation in which model parameters change over time the emulation problem in chang et al 2014 does not require considering such dynamic nature of model behavior as the emulated model outputs are purely spatial patterns computed by time averaging 2 1 2 1 proposed formulations for dynamic reduced dimension emulation in a non dynamic emulation scenario all perturbed parameters remain constant and outputs are assumed independent so that there is no notion of time when only the final state of the multi output system is desired this can be emulated as dictated in 7 however this situation becomes dynamic when outputs of successive timesteps are needed as a series this has the same formulation as 7 but now we have additional input variable t 1 2 t for t timesteps of interest now the model in 7 can be rewritten as follows 8 y ˆ θ t k y η θ t m in most practical dynamic situations however θ is also changing over time and therefore the values that θ took in previous timesteps must be considered we propose two formulations that can train a regression to the dimension reduced data without the need for multiplying the dimensionality by t the first is similar to a time input ti approach conti and o hagan 2010 which makes predictions at any timestep of the simulation training period with a single emulator by providing time as an additional training variable 9 y ˆ θ t k y η θ t t m in the context of fitting gaussian random fields this method assumes that the result of a simulation at time t i can be found with both the choice of test input parameters at that timestep θ t and the current timestep index t i since temporal effects are measured in the joint distribution of the time training variable and the other training variables whether by the nature of the physical model or the experimental design the relation between the same timestep across various training simulations can be weak this may be reasonable when emulating hydraulic head in a groundwater model as processes in pumping and recharge up until the timestep in question will create different hydraulic head surfaces across the model and therefore time as an explicit training variable may not be sufficient some authors addressing the problem of dynamic emulation have suggested using a state space representation with an autoregressive approach as the transition function castelletti et al 2012 this approach was deemed appropriate for our purposes as the scores along each principal component are already in essence a summarized state space representation of the system when the solution to the physical model requires information about the current state of the system i e hydraulic gradient using an autoregressive ar formulation can help provide sufficient information this translates as well to reduced dimension emulation as the score of a specific observation along any component y i j r is simply a re mapping of the entire output space at a given observation therefore if using an ar approach when training a gaussian process for the j th principal component y j r the p x q matrix containing all the parameter combinations used for training θ is adjusted the adjustment adds the previous score and changes θ to θ j via θ i j θ i t i y t i 1 j r where θ i and t i are input parameter settings and the time index of observation i respectively the inclusion of time as a training variable is still important in capturing temporal interactions this changes the emulation notation to 10 y ˆ θ t k y η θ t t y t 1 r m in this case the initial condition of the system should also be included as an additional observation in m so that the score of the initial condition on each principal component is captured which can be done by decomposing the initial state of the system along the columns of k y note that since this is distinct to each simulation within the larger training dataset the value of y t i 1 j r will be the decomposed initial condition along the jth column of k y any time t i 1 the first time index the overall emulation procedure is summarized in the workflow presented in fig 2 3 case study 3 1 mexico city aquifer 3 1 1 hydraulic history of mexico city the original lake system of the basin of mexico and current administrative boundaries of mexico city are shown in fig 3 currently approximately half of mexico city s water is supplied from well systems located in the metropolitan zone of the basin of mexico s aquifer system the other half is from imports from neighboring basins such as the cutzamala system which contributes approximately 1 3 of the supply 10 m3 s and is pumped a distance of 120 km with a vertical lift of approximately 1100 m sistema de aguas de la ciudad de méxico 2012 the inter basin transfer has been politically fraught and options for future development e g for climate change adaptation focus on better practices related to the aquifer such as pump scheduling and augmented aquifer storage and recovery historical over extraction has led to land subsidence that reverses drainage gradients exacerbating flooding issues and damaging ground level e g roads and subsurface e g pipes infrastructure the resultant losses from the pressurized water distribution system are added to the city s already over burdened drainage system these problems require study before plans can be enacted to further develop local aquifer resources efforts are ongoing to address water supply deficits without increasing already large water import projects while also minimizing further land subsidence one of the most important aspects of this problem is the aquifer an abundant local source that has been overexploited for years while there are differing estimates on the long term water balance for the local aquifer it is widely understood that anthropogenic extraction began exceeding natural recharge in the early 20th century birkle et al 1998 sistema de aguas de la ciudad de méxico 2012 urban growth and changes to climatic patterns may further reduce the net amount of water infiltrating and recharging the aquifer behzadi et al 2020 3 1 2 the process based model the groundwater model used in this series of experiments is a physically based finite element simulation of the aquifer of the basin of mexico with the spatial extent of the model shown in fig 4 the basin of mexico is bordered by steep mountains surrounding lowlands where an ancient lake system once existed detailed descriptions of the geology of the basin are available edmunds et al 2002 arce et al 2019 the model is designed to estimate land subsidence throughout greater mexico city in response to water extraction from a series of connected aquifers therefore the model s geographic extent includes the lower plains of the valley while the volcanic piedmont and mountainous areas at higher elevation are excluded but represented as the boundary conditions the groundwater model uses a finite volume mesh in space and an implicit finite difference scheme to simulate groundwater flow and land subsidence with a spatial resolution of 1 km and a simulation time step of 1 year pumping records are available from 1935 up to the year 2018 and historical recharge was estimated by combining historical rainfall data and information about the permeability of local geologic formations the model depicts a shallow phreatic aquifer separated by an extensive leaky clay aquitard of varying thickness from the main water bearing alluvial layer beneath a relevant feature of the aquifer is its confinement in large areas by clay upon head drawdown in the aquifer an important interaction occurs draining the water stored in the pores of the clay to the aquifer in significant amounts vertical flow this drained water is in fact responsible for the land subsidence that occurs when the aquifer is pumped this phenomenon of drawdown means that past pumping is having effects today and will also affect the future behavior of the system flow calculations are solved in two dimensions in the lower upper aquifer while only vertical flux is considered through the aquitard subsidence occurs in the model as the aquitard is depressurized from water released from storage thus subsidence is calculated on a time varying basis in response to changes to the clay deformation modulus which vary with the sign of the net hydrostatic pressure change cruickshank villanueva 1984 the model has 4217 spatial elements representing outputs of water level in the main lower aquifer as well as land subsidence across the basin it represents extraction natural recharge water transfer via the aquitard and artificial recharge sites since the properties of the aquitard are determined by the clay modulus which is a function of the current pressure and water flux direction at a given cell subsidence and water level development in any given simulation are non steady the draining of the clay layer which is directly responsible for land subsidence and changes to aquifer level is governed by a nonlinear relation between inputs and outputs which is highly relevant to the choice of emulation methods like many regional groundwater models the runtime of the mexico city process based groundwater model is too long to be integrated into a robust optimization framework e g ray et al 2014 what is more the model is proprietary and thus access is permitted to only a limited number of model runs 3 2 use of methodology for decision support the groundwater model of the basin of mexico is embedded in a decision support model workflow connected with regional climate models water distribution models local hydrological models and models of the major water import infrastructure systems risk assessment requires thousands of runs of the groundwater model across a wide range of local conditions climate land use demographic urbanization etc in order to trace out the response of the groundwater aquifer and subsidence to multidimensional stressors in the risk management exercise formulated as a robust optimization problem evaluation of the same thousands of risk assessment scenarios will be repeated hundreds or thousands of times each time for a different combination portfolio of water system interventions in total hundreds of thousands or millions of model runs are required the result will be a set of pareto efficient management policies within the basin of mexico and import basins an emulator is necessary to link the process based groundwater model with a model of local urban hydrology i e runoff and infiltration and a water distribution system model since the emulator informs regional groundwater management decisions the interest is in preserving spatial structure in order to estimate changes in one region relative to the others the decisions to be made regarding interaction with the local aquifer are spatial in nature should well fields be increased reduced in the east of the city or the south should groundwater injection and managed aquifer recharge be developed in the north of the city or the south second costs of groundwater extraction are responsive to water table depth and water quality considerations each of which is spatially heterogeneous third the changing geometry of subsidence is of vital importance for cost considerations and for a new surface map for flood analyses 4 results demonstration of approach 4 1 design of experiment and selection of training variables work plan step 1 4 1 1 selecting training variables the groundwater model outputs of interest are groundwater level and land subsidence across the model area the process based groundwater model was run continuously throughout a 52 year planning horizon until approximately 2070 to accommodate potential future changes to infrastructure configurations operating procedures and meteorological variables in all groundwater simulations using the process based model here referred to as training runs for the emulator no flow boundary conditions were implemented table 1 summarizes the 19 training variables θ q 1 7 r r 1 10 t altered when running the process based groundwater model for emulator training given that the time step of the original model was annual all of these processes are annual averages land subsidence and aquifer changes are calculated simultaneously in the process model and emulated separately as described below due to the large nature of the space time domain of this problem neither the raw model output for the aquifer level data nor the emulator output for this data were transformed in order to find a valid solution under mass balance rather it was deemed sufficient to rely on expert guidance to ensure confidence that the emulator would not return unrealistic results within the ranges of the training variables 4 1 2 design of experiment the previous section introduced the set of 19 training variables that govern the modeling experiments practical limitations of computational time and resources limited the number of simulations to 40 quasi random annual sequences a rule of thumb for training size of an n variable problem is 10n williams et al 2003 however the intention to dynamically emulate processes over time and not just the final state as well as the explicit inclusion of time as a training variable meant that the potential sample size in this case was 40 runs 52 years per run 2080 temporal sets of outputs superior to a sample size of 40 in order to train a model with 19 training variables changing q 1 7 r y 1 10 at every yearly time step in the manner of a quasi random sequence would make the outputs essentially unidentifiable since these processes are slow moving therefore the design used a two year stress period for the model in which q 1 7 r r 1 10 remained constant and there were p 1040 available replications for consideration in a random latin hypercube sampling mckay et al 1979 with a uniform distribution this type of sampling scheme can be important when sampling for multidimensional stress tests as the factors can be efficiently sampled over predetermined ranges or probability functions ray et al 2018 mckay et al 1979 this sampling scheme assigned values for q 1 7 r r 1 10 and blocks were split into 40 sections with t from 1 52 added as the final column of each the annual time step increased the set of training observations by a multiple of 52 and this design of experiment doe prevented the need to similarly multiply the input dimensionality by 52 by including the current timestep as an additional training variable the use of latin hypercube sampling instead of an ensemble of realistic scenarios was chosen to not only increase sample space coverage but also to reduce redundant information via correlation as explained in miftakhova et al 2020 this method posits that when a limited number of model runs can be extracted as was the case here it is more efficient to train an emulator upon artificially created uncorrelated data as opposed to a collection of realistic runs this is because such realistic runs are likely to be correlated and thus provide a lower aggregate amount of information to train the model upon the authors show the success of this method by training upon four orthogonal input scenarios and still achieving good predictive power upon out of fold realistic scenarios while showing that training upon a limited collection of likely scenarios does not jointly contain a sufficient basis to form an emulator due to applicability of this method to the limited number of model runs available in this work the method was adapted here using 1 latin hypercube sampling for the creation of orthogonal training scenarios and 2 comparison of predictive error on the two realistic test scenarios directly to serve as the best choice of covariance function parameterization this method does not include the traditional step of cross validation as the test and training data are purposefully uncorrelated from each other and therefore not at risk of contaminating the ability to gauge the predictive power of the emulator 4 2 workplan steps 2 5 training data processing pca and component selection the model output matrix for subsidence m s and model output matrix for the aquifer level m a created from the doe each had dimensions p 2080 and n 4217 both output matrices were mean centered and subjected to pca per steps 3 and 4 of the workplan to get the products k y a k y s y r a and y r s to assist in interpretation fig 6 demonstrates the re creation of the model outputs in the first simulation year using the entire leading and remaining set of principal components in both m s 1 and m a 1 the re addition of m a or m s is not shown in fig 6 so that the additive nature of the variance explained by the components is apparent fig 7 shows graphically the values of k y 1 n j for j 1 2 3 4 for both k y s and k y a fig 7 is similar in interpretation to a traditional biplot gower et al 2010 in which higher magnitudes of k y i j are indicative of areas that have the largest correlation with the component and the signs indicating how locations tend to co vary the leading 10 components cumulatively explain 90 of the variance across the observations for land subsidence and 12 for groundwater level with 90 explained variance a common threshold for modeling applications jolliffe 2002 this was adopted as well and thus the number of components up to this threshold dictates the number of gaussian random fields to be fit fig 7 shows that a large proportion of explained variance is clustered around small spatial locations in the water level simulations these coincide with the location of the artificial injection wells as well as the location of the most intensive collection of wells within the pumping systems which fall into small groups of one more finite grid elements therefore these clusters are point processes whose fluctuations drastically affect the surrounding hydraulic field while the other processes of interest are spatially distributed 4 3 step 6 gaussian random field fitting and validation as explained in the design of experiment the selection and optimization of hyperparameters was intended to find the lowest predictive root mean square error rmse from two out of sample test scenarios while the training scenarios were uncorrelated with two year stress periods to allow for the effect of drawdown and recovery to be captured after large fluctuations in training variables these out of fold scenarios detailed below were formulated to be realistic non random simulations with stress periods of 1 year similar to the emulator s intended use in test scenario 1 there was no artificial recharge pumping systems 3 and 7 located in the south and north of the model domain respectively in fig 5 were subjected to a random increasing trend in extraction and natural recharge was modeled as a random decreasing trend test scenario 2 was identical to test scenario 1 except that artificial recharge projects were fully operational beginning in year 25 of the simulation the remaining user defined training variables all excluding t and y t 1 r were assigned random values within one positive standard deviation from their historical mean the matlab octave gpml package rasmussen and nickisch 2018 was used to create custom covariance functions for each covariance function tried initial starting points were randomized in batches and optimized for each component proper performance was measured by decomposing the annual results of the test scenarios via k y a or k y s from steps 3 and 4 into the proper score for each component at each time step the time required to fit an individual gaussian process gp is heavily influenced by the size of training data optimization tolerance and initial starting point on average fitting the models with the data in this study took approximately 30 40 min while the execution of a 52 year scenario requires approximately 2 s 4 3 1 land subsidence emulation fig 8 shows example scores of the leading 10 components in the land subsidence data from an exploratory 52 year simulation outside the training and test data in which q 1 7 r y 1 10 were held constant and decomposed using k y s the parabolic shape of the developing scores along several components reflects the dynamic behavior of the clay subsidence modeled in the original groundwater model and the nonlinear effects that it introduces 4 3 2 groundwater level emulation initial attempts at fitting the gaussian random fields revealed that for the groundwater level processes years representing transitions between stress periods showed poor results this indicated the inadequacy of relying only on the time step as a training variable in capturing the dynamic nature of this problem as shown in 9 unlike land subsidence changes in groundwater level could be positive or negative and have continually increasing decreasing trends based on the model parameters preceding a given time step while including time as an input training variable helps to account for nonseparable behavior the quasi random sequences of the training data weaken the temporal covariance for identical years between training simulations it was for this reason that a first order ar state space representation was chosen for dynamic emulation in this case represented by 10 in this formulation θ is changed to θ j via θ i j θ i t i y i 1 j r in order to provide the training variable y i 1 j r for the first j y components for training and testing prediction the initial condition of the system m 0 dimensions 1 n is decomposed using k y a generated from the training data 4 3 3 model testing error metrics and physical interpretation fig 9 compares the final state of land subsidence in each scenario produced by the emulator to that of the original physically based model allowing for reasonable tolerances the emulator accurately represents the spatial pattern of the response of subsidence to artificial injection returning to fig 7 all non zero loadings occur in the same set of model cells but do not map to the physical space in consistent ways fig 10 shows the same result wherein for water level emulation capturing both the location and magnitude of the physical model processes is important in understanding the validity as results show global and local effects are re created with the emulator in test scenario 1 and the changes to these processes with the introduction of artificial injection are captured again in scenario 2 unlike the land subsidence processes the final state of the aquifer level estimation does not directly overlay i e is not an easy visual match for the primary components in fig 7 this is because unlike land subsidence water level can recover some cells may even finish a simulation at a higher level than they began the patterns appearing at the end of the simulation are the sum of space time interactions resulting from the model s unique features and pde governing equations since the usage of spatial principal components can remove the effect of spatial interactions and therefore stationarity within the physical model domain the onus of the analysis in this methodology lies upon modeling the effects of nonseparability and serial correlation this was done by finding a proper function for each column of y r that both properly represents the unique covariance structure within θ that dominates each principal component as well as time related effects which may need to be parameterized by appending θ figs 9 and 10 show that despite these unique nonlinearities from both the physical model structure and the nature of serial correlation these effects were correctly emulated and thus their superposition back into physical space resulted in recreating the physical processes of interest with sufficient detail despite the close visual match between emulated and modeled results in both land subsidence and aquifer level the error metrics do show that there is a general loss generated from two factors the first is that only enough components were chosen to model up to a certain threshold of the variance which is part of the initial accepted loss in accuracy to make the method computationally tractable see fig 6 the second is primary in the aquifer level emulation where if the training data contain highly variable point processes the high frequency variability in those point processes can come to dominate the pca washing out lower frequencies in regional aquifer behavior while alternate forms of dimension reduction are beyond the scope of this paper if these point processes are part of an aggregated training variable such as the wellfields in this paper interpolation may be improved by disaggregating these points and making them their own covariate despite this attribute both regional and local processes were re created and thus this methodology adequately meets the needs of dynamic emulation for univariate responses as identified in castelletti et al 2012a b while being applicable for high dimensional applications as shown here given that application of this emulator is for regional management the re creation of spatial detail at a larger scale is acceptable here the acceptable local error and therefore the effort required to model more components or invest in more exhaustive model fitting procedures is ultimately dependent on the purpose of the emulator application applications which require higher local precision while using the gp approach here may try increasing the variance threshold modeling more components or implementing an optimization search criteria on the initial starting points 4 3 4 necessity of a pca approach a brief exploration of the training data and test scenarios is helpful in order to better highlight the benefits of using pca rather than direct emulation techniques to model spatial variance a common practice in emulation of environmental process models is to aggregate the output to a single summary statistic e g the spatial mean response so that univariate emulation techniques can be used see the supplementary information for additional details of the current state of groundwater emulation literature figs 11 and 12 illustrate the impact of this practice with aquifer level outputs from the regional groundwater model used as the case study in this work fig 11 graphically represents variability of the model outputs from the training runs by examining the correlation r2 between model output change in aquifer level at each of the n locations across p 1 2080 observations to the corresponding spatially averaged response with the correlation value at location n r n calculated via 11 r n p 1 2080 y n i y n y p y p 1 2080 y n i y n 2 p 1 2080 y i y 2 we can see that many regions especially the area within mexico city have low correlations and hence cannot be predicted well by the overall mean therefore even a well performing dynamic emulator of the spatial mean response is not a pathway to obtaining temporal spatial insights since this insight came from the 40 randomized training scenarios a similar analysis on two the realistic test scenarios is important to see if the same holds when more realistic variability is introduced fig 12 shows the same correlation calculation from the results of the two test scenarios both constructed with realistic climate and consumption traces in the second test scenario artificial recharge projects become operational in year 25 of the simulation and this large contribution is sufficient to create very different spatial profiles detailing areas which could be said to be represented by the overall mean fitting an emulator for each column of y r allows for different covariance functions to be used to quantify the primary processes instead of attempting to find one single function which appropriately captures them all 5 discussion and conclusions despite the success and utility of univariate approaches in dynamically emulating environmental models a substantial gap in the literature exists for the dynamic emulation of models where the insight cannot be logically summarized by a few independent statistics attempts to do so face the potential error from assumptions of independence and separability which are prerequisites of existing methods these errors become more likely and more severe when the model domain grows larger this paper demonstrates an approach to streamline emulation of multiple outputs and multivariate model outputs at non adjacent spatial locations thereby enabling the nuance of high dimensional models to be utilized for computationally expensive planning and optimization applications dynamic multivariate emulation is crucial for these applications as it enables understanding of how spatially heterogeneous systems can be managed and affected by decisions or processes which change over time experiment 1 showed how heterogeneity renders single summary statistics ineffective based on the value of the training variables and how attempts to identify and emulate heterogeneity gives rise to this method experiment 2 showed that the doe and reduced dimension emulation was able to track the localized and larger regional changes throughout the simulation window without divergence over time with accommodations for dominant point processes as explained in section 4 3 step 6 gaussian random field fitting and validation other modifications to the design may be relevant for applications with smaller timesteps where the short term effects are more of interest i e decaying response of drawdown from pumping changes as opposed to long term changes as was the goal here in these cases a new method of sampling and parameterizing time effects may be more effective similar to the question posed in siade et al 2010 it is also possible that gaussian interpolation will not be a suitable framework for modeling the columns of y r for a given model or problem type or that methods more suited to high dimensional input spaces such as deep learning may be required as the size of the training variable set increases in the context of the application to mexico city as well as other regional case studies the ability to conceptualize the effects of spatial heterogeneity and time varying effects is crucial to include groundwater as an active and nuanced part of facing water challenges the ability of the emulator to capture the spatial heterogeneity of the aquifer response and training variables allows for the needs and characteristics of different municipalities throughout the region to be valued and accounted for in the model e g equity issues distribution of costs and benefits spatial heterogeneity in adaptation philosophy wetland preservation the preservation of the spatial domain also allows planners to change the optimization metrics coming from the emulator i e summary statistics of results model areas considered objective function without needing to create a new one unlike the standard response surface approach the inclusion of time varying effects allows for analyses of climate and demographic change and the staging of investments in time the ability to emulate this model with its spatiotemporal nuances at a low computational cost provides a path to allow for cutting edge planning optimization and scenario analysis the technique of reduced dimension dynamic emulation introduced here allows for process based models to be used in more sophisticated decision support applications that were previously logistically infeasible for the existing methods this work is embedded in a stakeholder driven water resilience project sponsored by the rockefeller foundation and the world bank st george freeman et al 2020 the analysis is a decision making under deep uncertainty based dmdu based methodology which relies on the ability to perform many simulations of linked models of the water import systems the aquifer processes of extraction injection and recharge the water distribution system and the drainage system of the valley of mexico in cases such as this one or more models typically must be emulated or approximated so that they can all be used in the scenario exploratory simulation heavy dmdu methodology together and or in a multi objective optimization framework out of that need this methodology is introduced to help leverage the nuance of a class of models which has been categorically difficult to emulate and help promote their potential in understanding both the solutions and the pathways to achieve them declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is made possible by the world bank group contract 7190616 integrating a mexico city urban water system model with a groundwater model and a draining system model for holistic adaptation to climate change risks as well as the rockefeller foundation special thanks to local partners at sistema de aguas de le ciudad de méxico and universidad autónoma nacional de méxico we are grateful to the journal editors and anonymous reviewers for their careful attention to this manuscript and the many improvements that resulted from their thoughtful comments appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105238 
25688,traditional population viability analysis pva does not address the degree of measurement error or spatial and temporal variability of vital rate parameters potentially leading to inappropriate conservation decision making we provide a methodology of applying bayesian network bn modeling to pva addressing these considerations particularly for species with complex stage class structures we provide examples of three species from eastern australia hip pocket frog assa darilingtoni squirrel glider petaurus norfolcensis and giant burrowing frog heleioporus australiacus comparing traditional matrix based pva with bn model analyses of mean stage abundance quasi extinction probability and interval threshold extinction risk both approaches project similar population sizes but bn pva gave more clearly identifiable thresholds of population changes and extinction levels the pva bn uniquely represents complex stage class structures and in a single network including variation and uncertainty propagation of vital rates to better inform conservation management decisions keywords bayesian network population viability analysis demographic modeling hip pocket frog squirrel glider giant burrowing frog 1 introduction a building block of conservation is ensuring the recovery and continued viability of species populations particularly at risk species e g schultz and hammond 2003 decision makers often rely on demographic projection models to gauge the potential outcomes of management actions affecting the viability size trend and probability of persistence of populations saunders et al 2018 these models are subject to the uncertainty in the input data failure to account for uncertainty can result in incorrect decisions with dire consequences for population conservation outcomes population viability analysis pva is a useful method for the quantitative projection of the size of a biological population under scenarios of specified survival and reproductive vital rates the projection determines probabilities of decline or extinction over a specified time horizon shaffer 1990 pvas have been central to population conservation for decades soule 1987 gerber and gonzález suárez 2010 chirakkal and gerber 2010 saunders et al 2018 pvas can be conducted aspatially based on demographic vital rates with the use of a standard leslie matrix life table analysis and simulation projection models kajin et al 2012 using programs such as vortex and ramas lindenmayer et al 2000 larue and nielsen 2016 pvas also can be spatialised with individual based simulation models watkins and rose 2017 such as hexsim schumaker and brookes 2018 or through spatially and temporally explicit population simulations visitin et al 2020 results of pvas are used in management e g schtickzelle et al 2005 to help identify minimum viable population sizes to meet conservation objectives reed et al 2003 to evaluate potential success of reintroductions licht et al 2017 to determine potential impacts on populations from environmental disturbances and anthropogenic stressors tuma et al 2016 and for informing other management objectives e g klavitter et al 2003 schultz and hammond 2003 pvas are also used to determine the probability of a population falling below a particular non zero size known as a quasi extinction level ginzburg et al 1982 such probabilities are calculated as the proportion of replicate model runs with n below a specified quasi extinction level at a particular point in time or over a given duration of time pvas can also be used to project potential impacts of demographic and environmental stochasticity including random variation in vital rates of survivorship and reproduction due to environmental variation engen et al 2005 fox 2005 a fundamental aspect of uncertainty to consider is the degree of measurement error and spatial and temporal variability of vital rate parameters age or stage class survivorship and reproduction which existing pvas generally do not address a construct that holds promise for addressing both types of uncertainty in an efficient manner is that of bayesian network bn modeling bns are directed acyclic graphs that link variables with conditional probabilities koski and noble 2011 bns have been used in a very wide array of environmental ecological and conservation problems pourret et al 2008 including determining the iucn international union for conservation of nature red list of threatened species categories newton 2010 and evaluating impacts of habitat conditions disturbances and stressors on populations of fish vilizzi et al 2013 carnivores johnson et al 2013 and marine mammals jay et al 2011 bns have been used to evaluate general population responses to habitat conditions threats and management considerations e g brown and ferguson 2019 zeigler et al 2019 although bayesian statistical non network approaches have been used with pvas for some time goodman 2002 saunders et al 2018 servanty et al 2014 maunder 2004 mccarthy et al 2001 bns have not yet been developed as pvas per se explicitly depicting age or stage class vital rates the structure of bns is flexible and lends itself to modeling the event space of population stage classes to track cohort strength over time e g johnson et al 2010 mimicking and extending traditional and non network bayesian pva constructs traditional pvas use repeat sampling within distributions among stage classes such as with markov chain monte carlo mcmc algorithms gross et al 2002 bns can propagate uncertainty throughout the model as do bayesian pvas saunders et al 2018 however bns are more flexible in their structure and can better depict complex life stages such as substages less than a single time step in the model for example the egg and juvenile stage of most birds this aspect of bns allows for stage specific management interactions to be tested across the life cycle of species in turn this would result in improved decision making for conservation further bns can help solve the quandary posed by fox and kendall 2002 who suggested that systematic variation rather than random variation among individuals leads to overestimation of extinction risk in populations that is bns can include probability distributions of many forms as explicit depictions of random variation in vital rates whereas traditional pva modeling at best typically includes systematic variation in vital rates although recent advances may include such considerations in non network bayesian implementations of pva saunders et al 2018 here we provide a framework methodology and demonstration of applying bn modeling to pva the framework better accounts for variability and uncertainty in demographic vital rates and provides a more flexible framework than existing matrix or simulation approaches for species with complex stage class structures we first develop the concepts then provide the computational modeling structure explore three species examples and conclude with a review of the value and limitations of the approach and future development needs 2 methods 2 1 study species three species were used for modelling population viability in this study the hip pocket frog assa darilingtoni hereafter assa squirrel glider petaurus norfolcensis hereafter petaurus and the giant burrowing frog heleioporus australiacus hereafter heleioporus the three species were chosen due to the availability of population viability models keith et al 2014 penman et al 2015 h kujala n cadenhead and l o connor university of melbourne australia pers comm and the life stages of the species both assa and petaurus have life histories that fit within the traditional pva model that is they have life histories with annual life stages such as juvenile young adult mature adult the three species are found in forests and woodlands of south eastern australia fig 1 assa occurs in moist rainforests and eucalypt forests of the coastal escarpment generally in areas about 600m elevation keith et al 2014 it lays a small number of large eggs and has a relatively quick tadpole period 40 days after which they emerge as sub adults petaurus occurs throughout forests and woodlands of eastern australia although much of its habitat has been cleared for agriculture van der ree 2002 petaurus is a hollow dependent marsupial species and its population ecology has been well studied quin 1995 van der ree 2002 smith 2003 heleioporus is a ground dwelling forest frog lemckert and brassil 2003 littlejohn and martin 1967 with a complex life cycle where adults move to breeding sites to lay eggs which hatch into tadpoles within two days to a week these individuals can remain in the tadpole stage for three months to two years daly 1996 penman et al 2004 after transformation the juveniles disperse into the forest before returning to the breeding population site up to several years later penman et al 2008 heleioporus has greater complexity in its life history than the other two example species explored here that results in a traditional pva needing to combine individual stages into composite stages within a single year an individual can advance from egg to tadpole and finally to juvenile frog stages all of these stages are subject to different survival rates variations and risks previous studies have combined these stages into a single stage in the leslie matrix thereby making it difficult to disentangle the effects of management on the individual stages penman et al 2015 2 2 population viability modelling approach two approaches to pva were considered in this study each being an aspatial representation of a single population the first was the traditional leslie matrix approach implemented in the ramas gis program version 5 akçakaya and root 2005 the leslie matrix approach divides the population into groups based on age classes using estimates of survival and fecundity matrix multiplication is used to model the changes in each age class of a population over time in discrete time steps this approach is the foundation for pva in a range of software packages lindemayer and burgman 2005 although ramas gis links spatial distribution data with pva to estimate population extinction risk only the basic ramas functions are used in this study for comparison the second approach was to develop non parametric continuous bayesian networks bns hanea et al 2015 using uninet software v2 97 16 https lighttwist software com uninet accessed august 2020 operated via r version 3 4 4 r development core tea 2007 with the rdcomclient package version 0 93 0 www omegahat net rdcomclient discrete bns are more commonly used in environmental decision making aguilera et al 2010 2011 johnson et al 2010 marcot et al 2001 newton 2010 penman et al 2020 in discrete bn models the nodes represent discrete random variables where the model specifies marginal distributions for nodes with no parents that is that lack direct antecedents and conditional probability tables for all child nodes that is with direct antecedents because all variables in our study were continuous we chose to use the relatively new approach of non parametric continuous bns which associates nodes with random variables for which no parametric marginal distribution assumption is made hanea et al 2015 and arcs links between nodes are parameterized by conditional rank correlations using normal copulas nelsen 2007 it is well beyond the scope of this paper to describe non parametric continuous bns in detail but we refer readers to hanea et al 2015 who provide extensive details of the method our two pva approaches are described more fully below ramas matrix models were developed based on available model data keith et al 2014 penman et al 2015 all matrix models are female only the leslie matrix structures including vital rate mean and standard deviation values and initial abundances used in the ramas models of each species are presented in supplementary a the life stages vital rates and their standard deviations are the same for the matrix model and the bn models vital rates as implemented in the ramas and bn models varied between life stages and also varied annually because of demographic stochasticity each ramas model was run for up to 100 years the time period was chosen to replicate studies using two of the study species keith et al 2014 penman et al 2015 to examine the effects of variations in vital rates we ran both 100 and 1000 replicates for each species density dependence was represented by a ceiling model akçakaya and root 2005 for assa based on keith et al 2014 and by a ceiling model for heleioporus based on penman et al 2015 there was no density dependence provided for petaurus and this was not relevant as the population shrank to extinction and is therefore not expected to be influenced by density for simplicity we only modeled a single population for all species and therefore did not include dispersal or patch recolonization bn models were designed to represent stage transition dynamics for a single year nodes in the bn models represent vital rates and numbers of individuals of each life stage and arcs represent the directional influence of each source or affector node termed parent node to their immediate outcomes or child nodes nyberg et al 2006 in bn models distributions in the child nodes are determined through equations relating conditional influences of the parent nodes for simplicity we used gaussian distributions requiring only empirically based mean values of numbers and vital rates and their standard deviations to represent demographic stochasticity we elected to use gaussian distributions for a direct comparison with the ramas model but noted that uninet also allows for a diverse range of parametric non parametric and empirical distributions which could significantly expand the application of our approach the bn models represent the full life stage structure of each species when run the models are looped so that the output distribution becomes the input distribution in the following year thereby carrying the uncertainty forward the bn model for assa is presented in fig 2 this model works for a single year and is iterated over 100 years to get outputs comparable with ramas nodes are included to represent the number of individuals prefix n per stage for either the start of the year y0 or at the end of the year y1 for example n1y0 represents the number of individuals in stage 1 at the start of the year whereas n1y1 represents the number of individuals in stage 1 at the end of the year transition rates represent both survival and fecundity transition rates are represented by nodes prefixed with t and the numbers representing the rates from stage x to stage y for example t 1 2 represents the transition rate for stage 1 to stage 2 numbers for each stage at the end of the year are the product of the number at the start of the year and the transition rate in the case where multiple stages breed or contribute to a life stage these values are then added to determine the total number for that stage for the following year at the end of each year distributions for all y1 nodes are used as y0 nodes for the following year if values are calculated to fall below 0 they are truncated to 0 these calculations were undertaken in r and the resultant distribution returned to the uninet model returned distributions are then no longer considered gaussian distributions rather they are considered empirical distributions derived from the model a more complex model was developed for heleioporus to demonstrate the capacity of the bn modelling approach fig 3 traditional matrix model pvas require each stage to be of a similar time step often annual in the bn approach for heleioporus we can include transition rates across multiple stages within a single modeling cycle as well as the annual transitions heleioporus lays eggs which hatch within a week penman et al 2004 this was included in nodes prefixed with neg the tadpole phase can last six weeks to two years daly 1996 and therefore we included two stages of tadpoles those that metamorphosed in a single season prefixed with t1 and those that took two seasons t2 the species then remains in the transformed juvenile phase for approximately three years represented by nodes prefixed with nj juveniles then become sub adults with lower breeding rates nodes prefixed with nsa and then move to larger adults with higher breeding rates nodes prefixed with nla individuals were assumed to survive a maximum of 11 years penman et al 2015 we do not vary survival rates within each stage as there is no evidence to support such an approach penman et al 2004 2015 2 3 analysis we used three metrics to compare the two modelling approaches mean stage abundance quasi extinction probability and interval threshold extinction probability mean stage abundance is the abundance of each stage per year as calculated from the ramas 100 and 1000 replicate results and from the uninet bn results hereafter uninet quasi extinction probability is the probability that the population will fall below a threshold population size we scaled populations to a threshold of 1 0 to allow for simple comparisons within and between species the uninet model uses a distribution of values to derive the extinction probability as the proportion of values below 1 the interval threshold extinction risk gives the probability that population size will fall below a threshold of abundance at least once during the simulation in the uninet model we calculated this using the proportion of the distribution that fell below the range of abundances during the simulation we assessed the three modeling constructs ramas with 100 replicates ramas with 1000 replicates and uninet based on graphical comparisons mean and uncertainty values were examined with non overlapping 95 confidence intervals ramas and with 95 credible intervals uninet that are equivalent to significance at the p 0 05 level for a two sample t test walshe et al 2007 here we make the assumption that the confidence and credible intervals are approximately equivalent plots are presented for the mean values in the results for clarity 3 results there was strong agreement with the stage class abundances of assa and petaurus across the uninet and ramas 1000 replicate models fig 4 with the ramas 100 replicate model suggesting a decline over the 100 years the other two models predicted that all three stages of the assa model plateaued around 15 years from the start of the analysis at abundance values of 150 90 and 30 individuals in stages 1 2 and 3 respectively after this point there was little variation over time with any of the three models the models for petaurus all predicted extinction of the species between 30 and 35 years after the simulation began fig 4 there was very little difference in the abundances for each stage between the modelling approaches differences were seen in the heleioporus model with ramas predicting higher abundance values of stage 1 juveniles compared to uninet fig 4 in contrast ramas predicted similar abundance values of stage 2 small adults and uninet and ramas predicted significantly lower abundance values of stage 3 large adults the uninet models resulted in far narrower variations sd in average total population sizes for assa and petaurus but wider variations in the more complex life history structure of heleioporus supplementary material fig s1 differences among the quasi extinction probability estimates occurred between the modeling approaches fig 5 all three modeling approaches predicted no or very low extinction probabilities for assa over the 100 years with a maximum value of 0 2 from the ramas 1000 model patterns for petaurus were similar between the two ramas approaches but differed with the uninet approach fig 5 both ramas models predicted the quasi extinction probability to rise from around 10 to 20 years after the model started to eventually reaching values of approximately 0 9 by 60 years in contrast the uninet model predicted a zero probability until around 30 years when it switched to a quasi extinction probability of close to 1 no model predicted a quasi extinction probability greater than zero for heleioporus thus not included in fig 5 there were differences among the modelling approaches in the results for the interval threshold extinction risk ramas models of assa populations predicted a rise from a probability value of 0 1 for small populations up to 1 at an extinction threshold level of around 300 in contrast the uninet model predicted a steep threshold between 260 and 280 where the extinction risk rises from 0 to 1 fig 6 all three approaches for petaurus predicted interval threshold risk to be 1 for all population sizes fig 6 both ramas and uninet resulted in logistic shaped responses for heleioporus although the modeling approaches differed in the resulting absolute values of population abundance thresholds extinction probabilities ramas predicted threshold extinction risk values starting from 0 1 and rising to 0 75 at population sizes of approximately 150 uninet predicted extinction risk values of 0 up to population sizes of approximately 30 and rising to an extinction risk of 1 at a population size of approximately 100 4 discussion we have demonstrated that the pva bn approach results in essentially the same projected overall population sizes resulting from more traditional leslie matrix analysis such as used in ramas for the three case studies investigated however projected sizes of specific life stages of some species e g stage 1 of heleiporus fig 4 may differ between the two approaches the pva bn approach results in more prominent thresholds of population changes and extinction levels which could better determine specific quasi extinction brinks or minimum viable population sizes brook et al 2000 reed et al 2003 a major difference between the two models was the estimation of the extinction risk values in most cases the bn approach predicted a threshold value where risk switched from 0 to 1 whereas the leslie matrix approach generally predicted a more continuous transition the exception to this was the helioporus model where similar shaped responses were found but with the bn predicting extinction at smaller population sizes there are a number of reasons these differences could occur one of the main reasons would be the methods used to calculate the values the leslie matrix approach selects values randomly from distributions and then makes multiple traces finally averaging across the traces to determine values and uncertainties in contrast the bn approach multiplies distributions to determine the values only a single replicate of the bn is required and therefore it is less subject to stochasticity and is more data driven greater uncertainty in population estimates can also represent demographic stochasticity which can lead to a greater probability of extinction under low population sizes jeppsson and forslund 2012 the choice of model used and the method for dealing with uncertainty distributions vs replicates clearly influence estimates of population size extinction and quasi extinction risks and therefore have implications for conservation decision making the bn pva approach explicitly accounts for variation and uncertainty in population vital rates of births and deaths and for propagation of that uncertainty across life stages and time periods this is evident through the cycling of empirical distributions between years as such it can explicitly account for demographic and environmental stochasticity and can track relative cohort strengths over time bayesian pva can include random deviates of any distributional pattern in defining the probability distributions of vital rate values with specified levels of uncertainty and variation saunders et al 2018 whereas the leslie matrix includes only frequentist statistical parameters of variability such as standard deviation additionally the influence of external disturbance events on those probability distributions can be added easily and explicitly into a bn pva model through additional nodes or probabilistic sub models our approach can also account for complex or overlapping life stages in stage structured populations i e multiple stages occurring within one age class as defined by a leslie matrix this was demonstrated with our heleioporus example potentially having both an egg stage and more than one tadpole stage other examples include analysis by aubry et al 2010 for a toad species that can pulse breed with several successive cohorts of eggs and tadpoles within the same season however rather than the complex set of multiple population matrices resulting from their analysis our bn pva approach can more simply represent overlapping life stages and population outcomes in a single network the bn pva model can also be extended to various time frames representing specified numbers of generations to represent real world cases the pva bn can be initialized with empirical abundances of each life stage class also the bn pva approach can be used to combine otherwise disparate information sources on population structure and vital rates such as from multiple studies and expert knowledge elicitation much as used in integrated population models saunders et al 2019 but with explicit calculations of the sequential propagation of value uncertainties in population projections our pva bn approach is in the early stages of development and does not utilize the full capacity of bns in this study we sought to demonstrate the method rather than definitively summarize the strength of bns the bn could be expanded beyond the pva approach here to quantify the influence and stochasticity of environmental factors on survival and reproduction enrght et al 2014 the role of disturbances such as fire that result in increases in population size through germination of soil stored seed banks swab et al 2012 or complex interactions with other species by combining two pva bns furthermore we initialized our model with simple gaussian distributions however any parametric non parametric or empirical distribution could be used we do note that it is likely that these steps could potentially be programmed into statistical packages such as r or matlab and our approach presented is not necessarily limited to bns however the bn approach has an existing structure available software and a well established literature supporting its use for such approaches we offer several caveats of the pva bn approach first it may be difficult in this framework to incorporate density dependency limitations and allee effects that represent biological constraints to unlimited population growth that can be modeled with time dynamic logistic equations cross and beissinger 2001 or other analytic approaches carlos and braumann 2017 second our pva bn modeling framework is essentially insensitive to population structures because 1 it remains aspatial and 2 is structured for evaluating viability of single populations rather than multiple populations leasure et al 2019 although other non network bayesian methods have been used to evaluate population structures harrison et al 2011 o hara et al 2002 third our framework does not account for variations in life histories among individuals within a population for example as found in some species of pacific salmonid fishes fujiwara 2007 and finally although results of pva bn projections could be mapped the structure currently is essentially aspatial but may be a useful complement to spatially explicit individual movement models the major advantages of the pva bn approach lie in efficiently representing entire stage class structures in a single network and displaying the effect of variation and propagation of uncertainty in those classes representing demographic and environmental stochasticity on projected population size and trend next steps in development of the pva bn framework could include making it spatially explicit swab et al 2012 penman et al 2015 schtickzelle and baguette 2004 traditional leslie matrix pvas tend not to be spatially referenced although packages such as ramas seek to address this issue bns also have that capability whereby results can be mapped showing resulting probabilities uncertainties and their empirical basis or sample sizes havron et al 2017 wiest et al 2019 life stages within the pva bn could be assigned individual spatial occurrences by modeling them as objects in object oriented and agent based bayesian networks marcot and penman 2019 with results applied to geographic information systems to map outcomes denoting projected population size trend and uncertainties 5 conclusions modeling population viability with probability networks provides a means of representing age or stage class structures and effects of random uncertainties in vital rates on population outcomes in a single parsimonious and efficient network structure rather than at best a complex set of population matrices specifically our pva bn approach as implemented here in the bn modeling shell uninet as continuous variable networks compares well with traditional results calculated with leslie matrices with the ramas program moreover the pva bn approach provides a far more flexible structure for explicitly and clearly representing complex life history stage classes and the role and influence of disturbances the pva bn model structure provides probability distributions of the size of each stage class and of total population size at each time interval analyzed such distributions can be used to quickly calculate bayesian credible intervals of stage class cohort and population size including probabilities of quasi extinction rates our method allows for population modelling for a greater diversity of species particularly those with complex and overlapping life stages conservation managers can use model outputs to make informed decisions over a greater array of species and explicitly accounting for environmental and demographic stochasticity and data driven uncertainty declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors da salary is provided by a grant from the victorian department of environment land water and planning smg is supported by an australian federal government research training program scholarship through the university of melbourne bgm acknowledges support from u s forest service pacific northwest research station mention of commercial products does not necessarily constitute endorsement by the u s forest service and u s federal government appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105242 
25688,traditional population viability analysis pva does not address the degree of measurement error or spatial and temporal variability of vital rate parameters potentially leading to inappropriate conservation decision making we provide a methodology of applying bayesian network bn modeling to pva addressing these considerations particularly for species with complex stage class structures we provide examples of three species from eastern australia hip pocket frog assa darilingtoni squirrel glider petaurus norfolcensis and giant burrowing frog heleioporus australiacus comparing traditional matrix based pva with bn model analyses of mean stage abundance quasi extinction probability and interval threshold extinction risk both approaches project similar population sizes but bn pva gave more clearly identifiable thresholds of population changes and extinction levels the pva bn uniquely represents complex stage class structures and in a single network including variation and uncertainty propagation of vital rates to better inform conservation management decisions keywords bayesian network population viability analysis demographic modeling hip pocket frog squirrel glider giant burrowing frog 1 introduction a building block of conservation is ensuring the recovery and continued viability of species populations particularly at risk species e g schultz and hammond 2003 decision makers often rely on demographic projection models to gauge the potential outcomes of management actions affecting the viability size trend and probability of persistence of populations saunders et al 2018 these models are subject to the uncertainty in the input data failure to account for uncertainty can result in incorrect decisions with dire consequences for population conservation outcomes population viability analysis pva is a useful method for the quantitative projection of the size of a biological population under scenarios of specified survival and reproductive vital rates the projection determines probabilities of decline or extinction over a specified time horizon shaffer 1990 pvas have been central to population conservation for decades soule 1987 gerber and gonzález suárez 2010 chirakkal and gerber 2010 saunders et al 2018 pvas can be conducted aspatially based on demographic vital rates with the use of a standard leslie matrix life table analysis and simulation projection models kajin et al 2012 using programs such as vortex and ramas lindenmayer et al 2000 larue and nielsen 2016 pvas also can be spatialised with individual based simulation models watkins and rose 2017 such as hexsim schumaker and brookes 2018 or through spatially and temporally explicit population simulations visitin et al 2020 results of pvas are used in management e g schtickzelle et al 2005 to help identify minimum viable population sizes to meet conservation objectives reed et al 2003 to evaluate potential success of reintroductions licht et al 2017 to determine potential impacts on populations from environmental disturbances and anthropogenic stressors tuma et al 2016 and for informing other management objectives e g klavitter et al 2003 schultz and hammond 2003 pvas are also used to determine the probability of a population falling below a particular non zero size known as a quasi extinction level ginzburg et al 1982 such probabilities are calculated as the proportion of replicate model runs with n below a specified quasi extinction level at a particular point in time or over a given duration of time pvas can also be used to project potential impacts of demographic and environmental stochasticity including random variation in vital rates of survivorship and reproduction due to environmental variation engen et al 2005 fox 2005 a fundamental aspect of uncertainty to consider is the degree of measurement error and spatial and temporal variability of vital rate parameters age or stage class survivorship and reproduction which existing pvas generally do not address a construct that holds promise for addressing both types of uncertainty in an efficient manner is that of bayesian network bn modeling bns are directed acyclic graphs that link variables with conditional probabilities koski and noble 2011 bns have been used in a very wide array of environmental ecological and conservation problems pourret et al 2008 including determining the iucn international union for conservation of nature red list of threatened species categories newton 2010 and evaluating impacts of habitat conditions disturbances and stressors on populations of fish vilizzi et al 2013 carnivores johnson et al 2013 and marine mammals jay et al 2011 bns have been used to evaluate general population responses to habitat conditions threats and management considerations e g brown and ferguson 2019 zeigler et al 2019 although bayesian statistical non network approaches have been used with pvas for some time goodman 2002 saunders et al 2018 servanty et al 2014 maunder 2004 mccarthy et al 2001 bns have not yet been developed as pvas per se explicitly depicting age or stage class vital rates the structure of bns is flexible and lends itself to modeling the event space of population stage classes to track cohort strength over time e g johnson et al 2010 mimicking and extending traditional and non network bayesian pva constructs traditional pvas use repeat sampling within distributions among stage classes such as with markov chain monte carlo mcmc algorithms gross et al 2002 bns can propagate uncertainty throughout the model as do bayesian pvas saunders et al 2018 however bns are more flexible in their structure and can better depict complex life stages such as substages less than a single time step in the model for example the egg and juvenile stage of most birds this aspect of bns allows for stage specific management interactions to be tested across the life cycle of species in turn this would result in improved decision making for conservation further bns can help solve the quandary posed by fox and kendall 2002 who suggested that systematic variation rather than random variation among individuals leads to overestimation of extinction risk in populations that is bns can include probability distributions of many forms as explicit depictions of random variation in vital rates whereas traditional pva modeling at best typically includes systematic variation in vital rates although recent advances may include such considerations in non network bayesian implementations of pva saunders et al 2018 here we provide a framework methodology and demonstration of applying bn modeling to pva the framework better accounts for variability and uncertainty in demographic vital rates and provides a more flexible framework than existing matrix or simulation approaches for species with complex stage class structures we first develop the concepts then provide the computational modeling structure explore three species examples and conclude with a review of the value and limitations of the approach and future development needs 2 methods 2 1 study species three species were used for modelling population viability in this study the hip pocket frog assa darilingtoni hereafter assa squirrel glider petaurus norfolcensis hereafter petaurus and the giant burrowing frog heleioporus australiacus hereafter heleioporus the three species were chosen due to the availability of population viability models keith et al 2014 penman et al 2015 h kujala n cadenhead and l o connor university of melbourne australia pers comm and the life stages of the species both assa and petaurus have life histories that fit within the traditional pva model that is they have life histories with annual life stages such as juvenile young adult mature adult the three species are found in forests and woodlands of south eastern australia fig 1 assa occurs in moist rainforests and eucalypt forests of the coastal escarpment generally in areas about 600m elevation keith et al 2014 it lays a small number of large eggs and has a relatively quick tadpole period 40 days after which they emerge as sub adults petaurus occurs throughout forests and woodlands of eastern australia although much of its habitat has been cleared for agriculture van der ree 2002 petaurus is a hollow dependent marsupial species and its population ecology has been well studied quin 1995 van der ree 2002 smith 2003 heleioporus is a ground dwelling forest frog lemckert and brassil 2003 littlejohn and martin 1967 with a complex life cycle where adults move to breeding sites to lay eggs which hatch into tadpoles within two days to a week these individuals can remain in the tadpole stage for three months to two years daly 1996 penman et al 2004 after transformation the juveniles disperse into the forest before returning to the breeding population site up to several years later penman et al 2008 heleioporus has greater complexity in its life history than the other two example species explored here that results in a traditional pva needing to combine individual stages into composite stages within a single year an individual can advance from egg to tadpole and finally to juvenile frog stages all of these stages are subject to different survival rates variations and risks previous studies have combined these stages into a single stage in the leslie matrix thereby making it difficult to disentangle the effects of management on the individual stages penman et al 2015 2 2 population viability modelling approach two approaches to pva were considered in this study each being an aspatial representation of a single population the first was the traditional leslie matrix approach implemented in the ramas gis program version 5 akçakaya and root 2005 the leslie matrix approach divides the population into groups based on age classes using estimates of survival and fecundity matrix multiplication is used to model the changes in each age class of a population over time in discrete time steps this approach is the foundation for pva in a range of software packages lindemayer and burgman 2005 although ramas gis links spatial distribution data with pva to estimate population extinction risk only the basic ramas functions are used in this study for comparison the second approach was to develop non parametric continuous bayesian networks bns hanea et al 2015 using uninet software v2 97 16 https lighttwist software com uninet accessed august 2020 operated via r version 3 4 4 r development core tea 2007 with the rdcomclient package version 0 93 0 www omegahat net rdcomclient discrete bns are more commonly used in environmental decision making aguilera et al 2010 2011 johnson et al 2010 marcot et al 2001 newton 2010 penman et al 2020 in discrete bn models the nodes represent discrete random variables where the model specifies marginal distributions for nodes with no parents that is that lack direct antecedents and conditional probability tables for all child nodes that is with direct antecedents because all variables in our study were continuous we chose to use the relatively new approach of non parametric continuous bns which associates nodes with random variables for which no parametric marginal distribution assumption is made hanea et al 2015 and arcs links between nodes are parameterized by conditional rank correlations using normal copulas nelsen 2007 it is well beyond the scope of this paper to describe non parametric continuous bns in detail but we refer readers to hanea et al 2015 who provide extensive details of the method our two pva approaches are described more fully below ramas matrix models were developed based on available model data keith et al 2014 penman et al 2015 all matrix models are female only the leslie matrix structures including vital rate mean and standard deviation values and initial abundances used in the ramas models of each species are presented in supplementary a the life stages vital rates and their standard deviations are the same for the matrix model and the bn models vital rates as implemented in the ramas and bn models varied between life stages and also varied annually because of demographic stochasticity each ramas model was run for up to 100 years the time period was chosen to replicate studies using two of the study species keith et al 2014 penman et al 2015 to examine the effects of variations in vital rates we ran both 100 and 1000 replicates for each species density dependence was represented by a ceiling model akçakaya and root 2005 for assa based on keith et al 2014 and by a ceiling model for heleioporus based on penman et al 2015 there was no density dependence provided for petaurus and this was not relevant as the population shrank to extinction and is therefore not expected to be influenced by density for simplicity we only modeled a single population for all species and therefore did not include dispersal or patch recolonization bn models were designed to represent stage transition dynamics for a single year nodes in the bn models represent vital rates and numbers of individuals of each life stage and arcs represent the directional influence of each source or affector node termed parent node to their immediate outcomes or child nodes nyberg et al 2006 in bn models distributions in the child nodes are determined through equations relating conditional influences of the parent nodes for simplicity we used gaussian distributions requiring only empirically based mean values of numbers and vital rates and their standard deviations to represent demographic stochasticity we elected to use gaussian distributions for a direct comparison with the ramas model but noted that uninet also allows for a diverse range of parametric non parametric and empirical distributions which could significantly expand the application of our approach the bn models represent the full life stage structure of each species when run the models are looped so that the output distribution becomes the input distribution in the following year thereby carrying the uncertainty forward the bn model for assa is presented in fig 2 this model works for a single year and is iterated over 100 years to get outputs comparable with ramas nodes are included to represent the number of individuals prefix n per stage for either the start of the year y0 or at the end of the year y1 for example n1y0 represents the number of individuals in stage 1 at the start of the year whereas n1y1 represents the number of individuals in stage 1 at the end of the year transition rates represent both survival and fecundity transition rates are represented by nodes prefixed with t and the numbers representing the rates from stage x to stage y for example t 1 2 represents the transition rate for stage 1 to stage 2 numbers for each stage at the end of the year are the product of the number at the start of the year and the transition rate in the case where multiple stages breed or contribute to a life stage these values are then added to determine the total number for that stage for the following year at the end of each year distributions for all y1 nodes are used as y0 nodes for the following year if values are calculated to fall below 0 they are truncated to 0 these calculations were undertaken in r and the resultant distribution returned to the uninet model returned distributions are then no longer considered gaussian distributions rather they are considered empirical distributions derived from the model a more complex model was developed for heleioporus to demonstrate the capacity of the bn modelling approach fig 3 traditional matrix model pvas require each stage to be of a similar time step often annual in the bn approach for heleioporus we can include transition rates across multiple stages within a single modeling cycle as well as the annual transitions heleioporus lays eggs which hatch within a week penman et al 2004 this was included in nodes prefixed with neg the tadpole phase can last six weeks to two years daly 1996 and therefore we included two stages of tadpoles those that metamorphosed in a single season prefixed with t1 and those that took two seasons t2 the species then remains in the transformed juvenile phase for approximately three years represented by nodes prefixed with nj juveniles then become sub adults with lower breeding rates nodes prefixed with nsa and then move to larger adults with higher breeding rates nodes prefixed with nla individuals were assumed to survive a maximum of 11 years penman et al 2015 we do not vary survival rates within each stage as there is no evidence to support such an approach penman et al 2004 2015 2 3 analysis we used three metrics to compare the two modelling approaches mean stage abundance quasi extinction probability and interval threshold extinction probability mean stage abundance is the abundance of each stage per year as calculated from the ramas 100 and 1000 replicate results and from the uninet bn results hereafter uninet quasi extinction probability is the probability that the population will fall below a threshold population size we scaled populations to a threshold of 1 0 to allow for simple comparisons within and between species the uninet model uses a distribution of values to derive the extinction probability as the proportion of values below 1 the interval threshold extinction risk gives the probability that population size will fall below a threshold of abundance at least once during the simulation in the uninet model we calculated this using the proportion of the distribution that fell below the range of abundances during the simulation we assessed the three modeling constructs ramas with 100 replicates ramas with 1000 replicates and uninet based on graphical comparisons mean and uncertainty values were examined with non overlapping 95 confidence intervals ramas and with 95 credible intervals uninet that are equivalent to significance at the p 0 05 level for a two sample t test walshe et al 2007 here we make the assumption that the confidence and credible intervals are approximately equivalent plots are presented for the mean values in the results for clarity 3 results there was strong agreement with the stage class abundances of assa and petaurus across the uninet and ramas 1000 replicate models fig 4 with the ramas 100 replicate model suggesting a decline over the 100 years the other two models predicted that all three stages of the assa model plateaued around 15 years from the start of the analysis at abundance values of 150 90 and 30 individuals in stages 1 2 and 3 respectively after this point there was little variation over time with any of the three models the models for petaurus all predicted extinction of the species between 30 and 35 years after the simulation began fig 4 there was very little difference in the abundances for each stage between the modelling approaches differences were seen in the heleioporus model with ramas predicting higher abundance values of stage 1 juveniles compared to uninet fig 4 in contrast ramas predicted similar abundance values of stage 2 small adults and uninet and ramas predicted significantly lower abundance values of stage 3 large adults the uninet models resulted in far narrower variations sd in average total population sizes for assa and petaurus but wider variations in the more complex life history structure of heleioporus supplementary material fig s1 differences among the quasi extinction probability estimates occurred between the modeling approaches fig 5 all three modeling approaches predicted no or very low extinction probabilities for assa over the 100 years with a maximum value of 0 2 from the ramas 1000 model patterns for petaurus were similar between the two ramas approaches but differed with the uninet approach fig 5 both ramas models predicted the quasi extinction probability to rise from around 10 to 20 years after the model started to eventually reaching values of approximately 0 9 by 60 years in contrast the uninet model predicted a zero probability until around 30 years when it switched to a quasi extinction probability of close to 1 no model predicted a quasi extinction probability greater than zero for heleioporus thus not included in fig 5 there were differences among the modelling approaches in the results for the interval threshold extinction risk ramas models of assa populations predicted a rise from a probability value of 0 1 for small populations up to 1 at an extinction threshold level of around 300 in contrast the uninet model predicted a steep threshold between 260 and 280 where the extinction risk rises from 0 to 1 fig 6 all three approaches for petaurus predicted interval threshold risk to be 1 for all population sizes fig 6 both ramas and uninet resulted in logistic shaped responses for heleioporus although the modeling approaches differed in the resulting absolute values of population abundance thresholds extinction probabilities ramas predicted threshold extinction risk values starting from 0 1 and rising to 0 75 at population sizes of approximately 150 uninet predicted extinction risk values of 0 up to population sizes of approximately 30 and rising to an extinction risk of 1 at a population size of approximately 100 4 discussion we have demonstrated that the pva bn approach results in essentially the same projected overall population sizes resulting from more traditional leslie matrix analysis such as used in ramas for the three case studies investigated however projected sizes of specific life stages of some species e g stage 1 of heleiporus fig 4 may differ between the two approaches the pva bn approach results in more prominent thresholds of population changes and extinction levels which could better determine specific quasi extinction brinks or minimum viable population sizes brook et al 2000 reed et al 2003 a major difference between the two models was the estimation of the extinction risk values in most cases the bn approach predicted a threshold value where risk switched from 0 to 1 whereas the leslie matrix approach generally predicted a more continuous transition the exception to this was the helioporus model where similar shaped responses were found but with the bn predicting extinction at smaller population sizes there are a number of reasons these differences could occur one of the main reasons would be the methods used to calculate the values the leslie matrix approach selects values randomly from distributions and then makes multiple traces finally averaging across the traces to determine values and uncertainties in contrast the bn approach multiplies distributions to determine the values only a single replicate of the bn is required and therefore it is less subject to stochasticity and is more data driven greater uncertainty in population estimates can also represent demographic stochasticity which can lead to a greater probability of extinction under low population sizes jeppsson and forslund 2012 the choice of model used and the method for dealing with uncertainty distributions vs replicates clearly influence estimates of population size extinction and quasi extinction risks and therefore have implications for conservation decision making the bn pva approach explicitly accounts for variation and uncertainty in population vital rates of births and deaths and for propagation of that uncertainty across life stages and time periods this is evident through the cycling of empirical distributions between years as such it can explicitly account for demographic and environmental stochasticity and can track relative cohort strengths over time bayesian pva can include random deviates of any distributional pattern in defining the probability distributions of vital rate values with specified levels of uncertainty and variation saunders et al 2018 whereas the leslie matrix includes only frequentist statistical parameters of variability such as standard deviation additionally the influence of external disturbance events on those probability distributions can be added easily and explicitly into a bn pva model through additional nodes or probabilistic sub models our approach can also account for complex or overlapping life stages in stage structured populations i e multiple stages occurring within one age class as defined by a leslie matrix this was demonstrated with our heleioporus example potentially having both an egg stage and more than one tadpole stage other examples include analysis by aubry et al 2010 for a toad species that can pulse breed with several successive cohorts of eggs and tadpoles within the same season however rather than the complex set of multiple population matrices resulting from their analysis our bn pva approach can more simply represent overlapping life stages and population outcomes in a single network the bn pva model can also be extended to various time frames representing specified numbers of generations to represent real world cases the pva bn can be initialized with empirical abundances of each life stage class also the bn pva approach can be used to combine otherwise disparate information sources on population structure and vital rates such as from multiple studies and expert knowledge elicitation much as used in integrated population models saunders et al 2019 but with explicit calculations of the sequential propagation of value uncertainties in population projections our pva bn approach is in the early stages of development and does not utilize the full capacity of bns in this study we sought to demonstrate the method rather than definitively summarize the strength of bns the bn could be expanded beyond the pva approach here to quantify the influence and stochasticity of environmental factors on survival and reproduction enrght et al 2014 the role of disturbances such as fire that result in increases in population size through germination of soil stored seed banks swab et al 2012 or complex interactions with other species by combining two pva bns furthermore we initialized our model with simple gaussian distributions however any parametric non parametric or empirical distribution could be used we do note that it is likely that these steps could potentially be programmed into statistical packages such as r or matlab and our approach presented is not necessarily limited to bns however the bn approach has an existing structure available software and a well established literature supporting its use for such approaches we offer several caveats of the pva bn approach first it may be difficult in this framework to incorporate density dependency limitations and allee effects that represent biological constraints to unlimited population growth that can be modeled with time dynamic logistic equations cross and beissinger 2001 or other analytic approaches carlos and braumann 2017 second our pva bn modeling framework is essentially insensitive to population structures because 1 it remains aspatial and 2 is structured for evaluating viability of single populations rather than multiple populations leasure et al 2019 although other non network bayesian methods have been used to evaluate population structures harrison et al 2011 o hara et al 2002 third our framework does not account for variations in life histories among individuals within a population for example as found in some species of pacific salmonid fishes fujiwara 2007 and finally although results of pva bn projections could be mapped the structure currently is essentially aspatial but may be a useful complement to spatially explicit individual movement models the major advantages of the pva bn approach lie in efficiently representing entire stage class structures in a single network and displaying the effect of variation and propagation of uncertainty in those classes representing demographic and environmental stochasticity on projected population size and trend next steps in development of the pva bn framework could include making it spatially explicit swab et al 2012 penman et al 2015 schtickzelle and baguette 2004 traditional leslie matrix pvas tend not to be spatially referenced although packages such as ramas seek to address this issue bns also have that capability whereby results can be mapped showing resulting probabilities uncertainties and their empirical basis or sample sizes havron et al 2017 wiest et al 2019 life stages within the pva bn could be assigned individual spatial occurrences by modeling them as objects in object oriented and agent based bayesian networks marcot and penman 2019 with results applied to geographic information systems to map outcomes denoting projected population size trend and uncertainties 5 conclusions modeling population viability with probability networks provides a means of representing age or stage class structures and effects of random uncertainties in vital rates on population outcomes in a single parsimonious and efficient network structure rather than at best a complex set of population matrices specifically our pva bn approach as implemented here in the bn modeling shell uninet as continuous variable networks compares well with traditional results calculated with leslie matrices with the ramas program moreover the pva bn approach provides a far more flexible structure for explicitly and clearly representing complex life history stage classes and the role and influence of disturbances the pva bn model structure provides probability distributions of the size of each stage class and of total population size at each time interval analyzed such distributions can be used to quickly calculate bayesian credible intervals of stage class cohort and population size including probabilities of quasi extinction rates our method allows for population modelling for a greater diversity of species particularly those with complex and overlapping life stages conservation managers can use model outputs to make informed decisions over a greater array of species and explicitly accounting for environmental and demographic stochasticity and data driven uncertainty declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors da salary is provided by a grant from the victorian department of environment land water and planning smg is supported by an australian federal government research training program scholarship through the university of melbourne bgm acknowledges support from u s forest service pacific northwest research station mention of commercial products does not necessarily constitute endorsement by the u s forest service and u s federal government appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105242 
25689,this paper presents the agent based modelling system of spatial distribution of species sdsim sdsim is an agent based modelling system designed to simulate spatial distribution of species and populations for conservation and management purposes sdsim gives to modellers the ability to simulate movements and colonization patterns of species given locations under study and a set of eco geographical variables in which species depends on keywords agent based modelling and simulation distribution of species environmental modelling 1 introduction nowadays species distribution models sdms are widely used by researchers in ecology and biology to perform studies for both conservation and management purposes ecological events can be described using these approaches particularly shifting edge ranges observed under climate change scenarios edwards and richardson 2004 hazen et al 2013 brown et al 2016 in fact recent climate changes have been considered one of the main causes affecting the geo graphical distribution and persistence of species and populations heikkinen et al 2006 moore 2003 parmesan and yohe 2003 walther et al 2002 kwon et al 2015 knowledge of species distribution becomes critical even for economical reasons furthermore public institutions and administrations are starting to grasp the benefits of resorting to sdms for managing biological resources sdms distinguishes the occurrence environment relationships in order to project the distribution of species in different environment scenarios past present or future meynard et al 2019 araújo and new 2007 the number of studies that are focused on sdms has increased considerably cf guisan and zimmermann 2000 barbet massin et al 2018 norberg et al 2019 normally sdms implicates the use of real distribution data of a species occurrence data in an environment described by a set of eco geographical variables egvs that calibrates the model to predict accurately future environment scenarios occurrence data are then used to validate and test the predictive power of the model generally real data are unreliable to test sdms and in many cases it fails to give a full picture of the species distribution meynard et al 2019 hirzel et al 2001 to address these issues virtual species are widely applied in sdms miller 2014 generating virtual species consists of simulating the distribution of a species knowing the occurrence environment relationship however generating virtual species and sdms are two different approaches since virtual species simulation involves exclusively the necessary steps to create virtual species meynard et al 2019 alongside with the traditional modelling approach agentbased modelling and simulation approaches abm have been quite used in ecology mainly due to their ability to simulate in a more realistic way the dynamics of different ecosystems resulting from the behavior and local interactions between individual entities agents e g jaxa rozen et al 2019 several studies have implemented abm to build species distribution models capable of emulating the behavior and dynamics of real ecosystems across space and time manson et al 2020 janssen et al 2020 there are several solutions that implement abm based simulations to predict the spatial distribution of species and populations e g pepin et al 2017 reuter et al 2016 xing et al 2017 parry et al 2017 however most of them have a fundamental limitation because they simulate a particular species for which that abm has been specifically designed preventing for a more general use williams 2021 coakley et al 2012 collier et al 2015 furthermore these frameworks require advanced programming skills in order to fit them properly grimm et al 2006 the approach presented in this paper goes one step further in a different direction in the sense that it allows the simulation of the species geographical range in a continuum time spreading over a predicted environment as a result a novel generalized user friendly web abm system is introduced in this study the species distribution simulator sdsim allows any modeller without any programming skills to model and simulate distribution of species and populations in real or potential environmental scenarios sdsim was designed to study species distribution in an environmental landscape based on a set of parameters entered by the researcher in a nutshell sdsim starts by enabling users to produce a sdm based on the species response functions to each of the egvs that influence the distribution of a particular species a gaussian distribution function was chosen as the response function to each eco geographical variable egv therefore user provides as input data every egv as raster maps and for each egv a mean and a standard deviation defining a normal distribution hypothesized as optimal for the distribution of that species 1 1 alternatively if presence data are available the referred means and standard deviations can be automatically calculated upon user request using these real data whenever there is occurrence data available sdsim gives a glimpse of model performance by calculating the roc curve and the corresponding auc response functions are combined in an additive or multiplicative model to create a sdm that represents environmental suitability for the species this virtualization of the species distribution proceeds constrained by the environmental suitability but in close agreement with the species life cycle algorithm after a defined quantity of a virtual species is placed in random or selected a priori locations of a loaded landscape a simulation can start at each iteration the virtual species will promote colonization of those locations deemed as suitable moreover sdsim is able to monitor and analyse the evolution of the species spatiotemporal distribution in a landscape by using a visual component 2 related work there are different software packages used to model the distribution of species to the best of our knowledge most of them are based on the r package muscarella et al 2014 golding et al 2018 kass et al 2018 naimi and araújo 2016 thuiller et al 2009 but there are also some offering specially tailored graphical user interfaces gui e g brown et al 2017 usually these packages project the past current and future scenarios of the distribution of species the methods applied to predict the distribution of species can be divided in two categories machine learning and statistical methods these methods are calibrated by a set of predictor variables and a sample of the known distribution of the species presence only or presence absence data in order to evaluate the prediction performance these software implement some widely used performance measures such as area under the roc curve auc true skill statistics tss sensitivity specificity and others predicting results are heavily influenced by the data quality bias poor data quality etc for this reason several studies adopt the use of virtual species in order to have the full control of the relationship between the virtual species and the environment egvs meynard et al 2019 there are several software packages developed to generate virtual species e g duan et al 2015 leroy et al 2016 phillips et al 2006 qiao et al 2016 generally these software packages receive as input data the environmental variables related to the species under study and the response functions that describe this relationship and produce as the output the environment suitability suitability map for the species this suitability map is then converted into potential presence absence map of the species in that location meynard et al 2019 different techniques are implemented to generate presence absence map see leroy et al 2016 normally a sampling of the presence absence points is saved to be used in a sdm as presence only or presence absence data generally speaking these software are bounded to predicting the areas in which a species may or may not occur a biologically guided simulation process in which it is possible to observe how the species spreads spatially in the environment over time following a life cycle is usually absent therefore obtaining information regarding where a species may or may not occur may be insufficient particularly for management species conservation and resource optimization for example based on the information regarding how a species of plants is able to swiftly occupy some locations better transplanting strategies could be adopted to optimize the allocated resources the presented web based software solution sdsim while sharing the common concerns of the available software packages for modeling the distribution of species provides components that empower the user to visualize and analyse how species spreads spatially in the environment at each time interval 3 simulator highlights sdsim is a software tool allowing users to monitor interactively the movement of a species across any real or putative environmental scenario introduced by a researcher modellers can easily analyse from the beginning of the simulation how an ecological system is capable to spread spatially and behave in the sdsim web application landscape is defined by a set of egvs encoded in raster maps that are made up as a matrix of pixels also referred to as cells simulation outputs depend on a set of parameters that provides a flexible virtual framework to define a colonization pattern for virtually any species bioco et al 2020 i an initial distribution of patches set of cells from which the simulation can start ii the cell capacity the maximum number of specimens allowed in the cell iii three life cycle parameters to define species distribution arrangement birth rate death rate and spread rate iv any of multiplicative or additive approaches to model habitat suitability v type of moore approach to simulate neighbourhood expansion pattern through a landscape and vi a stopping criterion table 1 summarizes input data and parameters of the sdsim web application 3 1 habitat suitability function habitat suitability functions become crucial to provide a realistic simulation scenario in general terms species show habitat preferences for example in a location where environmental conditions are not suitable for a certain species the probability of colonization and expansion should be lower sdsim landscape can be characterized by a set of egvs relying on the researcher s knowledge about a species ecology which ones could limit or otherwise promote a species distribution from a species perspective the overall suitability of the region is determined by the probability of occurrence of the species given the environmental conditions in that location elith and leathwick 2009 it is the result of the aggregation of local egv values that influence its life cycle in sdsim each egv is characterized by a normal distribution around a hypothesized optimal value for that species mean and standard deviation should be provided for each variable according to the preferences of that species studied in the simulation alternatively in sdsim these values can be automatically calculated by providing the coordinates of the occurrences of the species observed directly on the terrain as a result habitat suitability would be internally calculated in a map which values will be normalized in a closed interval from 0 unsuitable to 1 optimal these values are obtained through probability density functions parzen 1962 that incorporate egv in each map location as arguments sdsim standardizes each egv map andrews and mallows 1974 xi xi μ σ where xi is the value of an egv in that location μ is the mean i e egv s optimal suitability value for a species and σ represents the standard deviation for that egv map sdsim implements two different model aggregation operators that can be selected by the researcher in order to compute an overall suitability map for a given species additive and multiplicative additive option is a straightforward implementation of a generalized additive model gam therefore habitat suitability map is obtained by adding egv values in each raster cell after applying a probability density function under multiplicative option habitat suitability map is obtained by a strict archimedean triangular norm in this case habitat suitability is more restrictive because product t norm produces stronger conjunction of probabilistic values multiplicative model might become useful in particular circumstances e g invasive species colonization of clonal organisms 3 2 general workflow in order to perform a simulation users should set all required simulation input data and parameters showed in table 1 sdsim allows users to create both real and simulated scenarios by uploading a different set of egvs as raster maps for a defining mean and standard deviation in order to build a suitability function associated with each egv for that species sdsim allows users to select a type of neighbourhood from any of moore 1962 or weighted moore lipowski and lipowska 2012 options assuming a regular grid of a raster map by using moore s neighbourhood species will expand homogeneously to their eight neighbours when using weighted moore option each one of the eight neighbouring cells will receive a number of transferred individuals directly proportional to its suitability sdsim generates a suitability map based on egv maps and every specific probability density function the more suitable is an adjacent cell for a species the more likely it will be chosen for range expansion of that species each cell would contain two values representing the capacity and the suitability fitness of the habitat initially population patches are randomly placed in a landscape before starting a simulation during a simulation sdsim calculates the difference between previous and current states at each iteration by the sum of the cell by cell differences between successive states of the system see algorithm 1 the simulation can be stopped when the system reaches a stable state or when a maximum number of iterations is completed in this regard the system is said to be stable when the difference between two consecutive states of the simulation converges to zero sdsim saves an output of a simulation according to an interval previously defined by the user at each iteration or after a given number of epochs at the end of a simulation sdsim produces as output the species distribution map in three file formats i text file ii ascii grid file iii image file and a video file see fig 1 for future reference the text file containing the values of all parameters used in the simulation is also available algorithm 1 sdsim general algorithm image 1 3 3 species life cycle algorithm species life cycle algorithm includes three steps reproduction expansion colonization and death see algorithm 2 this algorithm tries to imitate a natural biological generation so that species may stay in habitats that are more appropriate for them to colonize establish and finally expand during the reproduction phase species spreads spatially according to a birth rate or survival percentage in each raster cell across a landscape during the death phase a percentage of a cell capacity would disappear according to a death rate or extinction percentage during the expansion phase a percentage of a cell capacity is transferred to their neighbour cells according to a spread rate or colonization percentage an optimal strategy for a species in a particular and suitable landscape will ensure an optimal colonization of that particular setting table 2 summarizes the main functions implemented in sdsim abm 3 4 direction constraints directional egv degv can be used to promote or otherwise limit movement of a species in certain spatial directions typically a degv is characterized by two components that together represent a vector field magnitude intensity and direction each component should be represented by a raster map as an example for marine data currents should be split in magnitude or intensity and direction for intensity preferences of the species the treatment is similar to the one previously described i e given the intensity optimal parameters mean and standard deviation for a given species the corresponding density value is an input to the model aggregation which determines the overall suitability map for the species direction component will be likewise integrated in the model once suitability is computed direction map should include values expressed in degrees clockwise from the geographic north thus each map cell has a direction value d 0 d 360 representing the flow or directional movement species are able to move from the core cell to any of its 8 neighbouring cells each neighbour has a relative direction towards the core cell as depicted in fig 2 in order to compute direction of each neighbour sdsim computes the difference between the relative direction of the neighbour and the direction of movement for that cell 1 δk min d dk d 360 dk where k 1 8 stands for the neighbour cell and d k is the relative direction of such neighbour in fig 2 those directions are represented as values in each one of the neighbours of their core cell hence k 1 8 0 δ k 180 values are then normalized to the unit interval and incorporated into the model aggregation species expansion will be favoured by the overall direction information codified in every degv i e most of the transferred individuals will migrate from a core cell to neighbouring ones that are well aligned with the direction of movement let us return to the intensity component of a degv besides being treated as a mere egv representing the preference of a species for a given value e g some species might prefer waters with less current intensity it worthwhile to notice that most times there is a physical facet attached to it which should also have implications to the species fixation in a locus or to the speed of range expansion e g some species travel easily if the current speed is higher in such cases we propose the introduction of a momentum species dependent constant m s 0 1 constraining the number of individuals that are transferred to neighbouring cells n spread in the following way 2 n spread n spr i m s where n is the cell s number of individuals spr denotes the species spread ratio as introduced before and i 0 1 is the normalized intensity value observed at the cell level algorithm 2 species life cycle image 2 thus the intensity of a directional egv constrains the spread of the species not only in what regards preferences of the species but also by applying the modelled traction forces notice that some species heavily depend on such variables to perform their spreading while others can expand its range even if they are positioned in a zero intensity region hence the need for the introduction of a momentum constant 4 web interface sdsim is available online at https sdsim it ubi pt it provides a user friendly web interface that allows users to perform their simulations avoiding local installation in order to get access to the application users request an account by sending an email to the sdsim administrator providing a username to associate that account after an account is created the user receives a notification with credentials to log in and access available services of sdsim application that are presented in the main screen see fig 3 in the section my simulations users can access to details from previous simulations including simulation parameters and output data simulation results users can download output data as set of raster maps containing the state of the simulation at different time steps figures of the state of the simulation at each time step the video file that shows the spatial distribution evolution and a performance metric graph receiver operating characteristic curve roc curve if a species occurrences file was provided the user can also perform new simulations based on previous ones or remove them see fig 4 in this section users can find an initial set of simulation examples to explore and get acquaintance with this system in the upload section users are able to upload all necessary egvs and degvs in form of raster maps in order to describe the landscape that is intended to simulate sdsim does not use any specific datum or projection relying on user needs to make such decisions at this point the web application accepts only ascii grid raster format please see gdal library for raster and vector geospatial data formats at https gdal org in addition the user can also upload a comma separated values csv file containing the coordinates of the occurrences and or absences of any sampled species this file facilitates the user s work in such a way that he she does not need to provide the mean and standard deviation for each egv in order to estimate each probability density function the sdsim performs all the necessary calculations to provide the mean and standard deviation for each egv depending on the occurrences that the user has uploaded presence absence file can be uploaded to sdsim allowing a numerical comparison between the results of different simulations based on the correct classification of presence absence locations showing a roc curve and the area under the curve auc at the end of the simulation in the section simulation users can start a new simulation by filling a form with all the required parameters as described in table 1 users should follow all these steps after authentication to perform a simulation 1 access the section upload and add egvs see fig 5 2 return to the main screen and access the simulation section where users should complete all the required parameters including the selection of the corresponding egvs and their parameters to estimate each probability density function see fig 6 3 results species distribution maps and outputs can be managed in a gallery of images after the completion of the simulation see fig 7 users can also see the video that shows how the species temporal distribution evolved see fig 8 4 a simulation can be saved initial parameters and results in order to reformulate any experiment and refine new ones based on previously stored simulations 5 case study honeybee apis mellifera l is distributed in a wide area populations of the iberian peninsula are of particular interest because of the hypothesized hybrid status of a m iberiensis engel 1999 in agreement with this hypothesis a m iberiensis distribution reflects colonization movements associated to an environmental gradient probably showing selective factors of climatic tolerance cánovas et al 2014 in order to compare results both against previous simulation studies bioco et al 2018 and against real experimental data collected on the field cánovas et al 2014 the spatial distribution of the african lineage of the iberian honeybee a m iberiensis in the iberian peninsula was modelled and simulated in sdsim landscape was described by four main egvs that were previously found to have an important role to shape present spatial distribution of this species maximum temperature of the warmest month mxtrm minimum temperature of the coldest month mntcm rainfall seasonality rfseas and average annual temperature tann cánovas et al 2014 egvs were obtained from the climatic atlas of the world hijmans et al 2005 raster maps had a dimension of 196 122 cells to illustrate the range of freedom that is provided to the user we report four simulations covering the different combinations between the available types of neighbourhood moore and weighted moore and model aggregation multiplicative and additive the overall input parameters were the same for all four simulations see table 3 simulation results after 100 iterations are showed in fig 9 the left column of the figure presents the results for the moore neighbourhood the amount of transferred individuals from each cell is equally distributed by the eight neighbouring cells in fig 9 a the type of aggregation is additive i e as a result we get generalized additive model for the four considered egvs in fig 9 c the aggregation is multiplicative thus heavily penalizing poor values in any of the egvs the column on the right presents the results for the same variation in the model aggregation operator but for the case of the weighted moore neighbourhood in this case the neighbouring cells receive a quantity of transferred individuals directly proportional to their suitability i e neighbours with better suitability receive a greater quantity of species than the less suitable ones in order to evaluate the performance of the model we compared the simulation results against the 210 field observations species presence and absence csv file containing 210 locations latitude and longitude in fig 10 we show a roc curve and auc values for the types of neighbourhood and model aggregation the additive model seems to perform better than the multiplicative model and in the additive model both moore and weighted moore neighbourhood showed similar final results auc 0 78 considering the additive model in fig 11 detail differences can be followed as the species spreads spatially using moore neighbourhood on the left and weighted moore neighbourhood on the right these differences are more evident at these early stages of the simulation and are diluted once stabilization is reached in moore neighbourhood a more regular deployment is able to produce almost circular regions whereas weighted moore neighbourhood made colonization more irregular advancing faster in the track for more suitable regions overall the weighted moore method seems to be a good choice for this species because it seems closer to an expected biological behavior such as the observed in previous studies cánovas et al 2014 species colonized with greater abundance in the most suitable areas defined by a set of egvs moreover environmental suitability calculated using an additive model seems to be more appropriate according to what was observed for this species however choices regarding type of neighbourhood and aggregation strongly rely on the specific knowledge that users have about the behavior of each particular system furthermore the great variability on the distribution that is possible to obtain for any given species as is clearly exemplified in fig 9 far from being considered a drawback is seen as a mean to easily test and evaluate different hypothesis on the species mechanism of colonization results of this case study are available to all users registered in the application allowing access exploration and reproduction of experiments available in the sdsim website the impact of each egv was analysed in the simulation results fixing the model additive and the neighbourhood weighted moore and performing eight egv combinations as follow first we perform simulations with each egv individually and then removing each egv one at a time from the complete set giving rise to the following combinations mntcm rfseas tann mxtwm rfseas tann mxtwm mntcm tann and mxtwm mntcm rfseas this comparison is summarised in fig 12 which depicts the auc values for each experiment it is possible to notice that rainfall seasonality rfseas had the greatest impact in the overall results of the simulation followed by the average annual temperature tann the minimum temperature of the coldest month mntcm and the maximum temperature of the warmest month mxtrm showed the least impact since according to fig 12 if one of these variables is removed the quality degradation after stabilization is not significant this result seems to indicate that the studied species can be very robust when faced with one off sudden variations on the temperature as long as the average annual temperature stays within an admissible range 6 conclusion in this paper an abm system was designed to model and simulate spatial distribution of biological species and populations by using a set of egvs sdsim computes a habitat suitability index producing an internal species suitability map sdsim assumes a standard normal distribution as a probabilistic response function for each egv those are later aggregated using an additive or a multiplicative model chosen at users will together with egvs sdsim receives a set of input parameters which fit abm behavior and can be easily tuned therefore any species could be modelled by using this abm in different environmental scenarios a simulation will always start by generating an initial occupation of the available habitat in random locations at each iteration of the simulation species will then find more suitable locations for them to survive following a defined species life cycle with corresponding parameters sdsim allows users to study and understand the species environment relationship by changing the values of the environmental variables in order to verify the behavior of any simulation scenario as illustrated in the reported case study if in possession of real experimental data collected on the field the web interface provides supporting tools for assessing and compare a set of distinct hypothesis subsumed by the different experimental setups moreover the flexibility and user friendliness of the deployed web abm system enables the visual analysis of the evolution of species in any hypothetical landscape without requiring any programming skills from the user sdsim will incorporate new features the relationship between geological time and computational epochs will be useful for modellers to decide simulation time according to evolutionary biological time steps instead of stabilization of the simulation such ability will give extra tools to modellers who will be able to program simulations in evolutionary time rather than in computational one declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by centro 01 0145 feder 000019 c4 centro de competências em cloud computing cofinanced by the european regional development fund erdf through the programa operacional regional do centro centro 2020 in the scope of the sistema de apoio à investigação científica e tecnológica programas integrados de ic dt this work was also funded by fct mctes through national funds and when applicable co funded eu funds under the project uidb 50008 2020 authors thank the department of zoology and anthropology from the university of murcia in which the hypotheses proposed here with honeybees were generated and tested in previously published scientific manuscripts therefore providing a suitable case study to test sdsim the authors wish to thank pedro violante s contribution to the development of the front end lastly but not least the authors gratefully acknowledge an anonymous reviewer for his her thoroughly revision and insightful remarks 
25689,this paper presents the agent based modelling system of spatial distribution of species sdsim sdsim is an agent based modelling system designed to simulate spatial distribution of species and populations for conservation and management purposes sdsim gives to modellers the ability to simulate movements and colonization patterns of species given locations under study and a set of eco geographical variables in which species depends on keywords agent based modelling and simulation distribution of species environmental modelling 1 introduction nowadays species distribution models sdms are widely used by researchers in ecology and biology to perform studies for both conservation and management purposes ecological events can be described using these approaches particularly shifting edge ranges observed under climate change scenarios edwards and richardson 2004 hazen et al 2013 brown et al 2016 in fact recent climate changes have been considered one of the main causes affecting the geo graphical distribution and persistence of species and populations heikkinen et al 2006 moore 2003 parmesan and yohe 2003 walther et al 2002 kwon et al 2015 knowledge of species distribution becomes critical even for economical reasons furthermore public institutions and administrations are starting to grasp the benefits of resorting to sdms for managing biological resources sdms distinguishes the occurrence environment relationships in order to project the distribution of species in different environment scenarios past present or future meynard et al 2019 araújo and new 2007 the number of studies that are focused on sdms has increased considerably cf guisan and zimmermann 2000 barbet massin et al 2018 norberg et al 2019 normally sdms implicates the use of real distribution data of a species occurrence data in an environment described by a set of eco geographical variables egvs that calibrates the model to predict accurately future environment scenarios occurrence data are then used to validate and test the predictive power of the model generally real data are unreliable to test sdms and in many cases it fails to give a full picture of the species distribution meynard et al 2019 hirzel et al 2001 to address these issues virtual species are widely applied in sdms miller 2014 generating virtual species consists of simulating the distribution of a species knowing the occurrence environment relationship however generating virtual species and sdms are two different approaches since virtual species simulation involves exclusively the necessary steps to create virtual species meynard et al 2019 alongside with the traditional modelling approach agentbased modelling and simulation approaches abm have been quite used in ecology mainly due to their ability to simulate in a more realistic way the dynamics of different ecosystems resulting from the behavior and local interactions between individual entities agents e g jaxa rozen et al 2019 several studies have implemented abm to build species distribution models capable of emulating the behavior and dynamics of real ecosystems across space and time manson et al 2020 janssen et al 2020 there are several solutions that implement abm based simulations to predict the spatial distribution of species and populations e g pepin et al 2017 reuter et al 2016 xing et al 2017 parry et al 2017 however most of them have a fundamental limitation because they simulate a particular species for which that abm has been specifically designed preventing for a more general use williams 2021 coakley et al 2012 collier et al 2015 furthermore these frameworks require advanced programming skills in order to fit them properly grimm et al 2006 the approach presented in this paper goes one step further in a different direction in the sense that it allows the simulation of the species geographical range in a continuum time spreading over a predicted environment as a result a novel generalized user friendly web abm system is introduced in this study the species distribution simulator sdsim allows any modeller without any programming skills to model and simulate distribution of species and populations in real or potential environmental scenarios sdsim was designed to study species distribution in an environmental landscape based on a set of parameters entered by the researcher in a nutshell sdsim starts by enabling users to produce a sdm based on the species response functions to each of the egvs that influence the distribution of a particular species a gaussian distribution function was chosen as the response function to each eco geographical variable egv therefore user provides as input data every egv as raster maps and for each egv a mean and a standard deviation defining a normal distribution hypothesized as optimal for the distribution of that species 1 1 alternatively if presence data are available the referred means and standard deviations can be automatically calculated upon user request using these real data whenever there is occurrence data available sdsim gives a glimpse of model performance by calculating the roc curve and the corresponding auc response functions are combined in an additive or multiplicative model to create a sdm that represents environmental suitability for the species this virtualization of the species distribution proceeds constrained by the environmental suitability but in close agreement with the species life cycle algorithm after a defined quantity of a virtual species is placed in random or selected a priori locations of a loaded landscape a simulation can start at each iteration the virtual species will promote colonization of those locations deemed as suitable moreover sdsim is able to monitor and analyse the evolution of the species spatiotemporal distribution in a landscape by using a visual component 2 related work there are different software packages used to model the distribution of species to the best of our knowledge most of them are based on the r package muscarella et al 2014 golding et al 2018 kass et al 2018 naimi and araújo 2016 thuiller et al 2009 but there are also some offering specially tailored graphical user interfaces gui e g brown et al 2017 usually these packages project the past current and future scenarios of the distribution of species the methods applied to predict the distribution of species can be divided in two categories machine learning and statistical methods these methods are calibrated by a set of predictor variables and a sample of the known distribution of the species presence only or presence absence data in order to evaluate the prediction performance these software implement some widely used performance measures such as area under the roc curve auc true skill statistics tss sensitivity specificity and others predicting results are heavily influenced by the data quality bias poor data quality etc for this reason several studies adopt the use of virtual species in order to have the full control of the relationship between the virtual species and the environment egvs meynard et al 2019 there are several software packages developed to generate virtual species e g duan et al 2015 leroy et al 2016 phillips et al 2006 qiao et al 2016 generally these software packages receive as input data the environmental variables related to the species under study and the response functions that describe this relationship and produce as the output the environment suitability suitability map for the species this suitability map is then converted into potential presence absence map of the species in that location meynard et al 2019 different techniques are implemented to generate presence absence map see leroy et al 2016 normally a sampling of the presence absence points is saved to be used in a sdm as presence only or presence absence data generally speaking these software are bounded to predicting the areas in which a species may or may not occur a biologically guided simulation process in which it is possible to observe how the species spreads spatially in the environment over time following a life cycle is usually absent therefore obtaining information regarding where a species may or may not occur may be insufficient particularly for management species conservation and resource optimization for example based on the information regarding how a species of plants is able to swiftly occupy some locations better transplanting strategies could be adopted to optimize the allocated resources the presented web based software solution sdsim while sharing the common concerns of the available software packages for modeling the distribution of species provides components that empower the user to visualize and analyse how species spreads spatially in the environment at each time interval 3 simulator highlights sdsim is a software tool allowing users to monitor interactively the movement of a species across any real or putative environmental scenario introduced by a researcher modellers can easily analyse from the beginning of the simulation how an ecological system is capable to spread spatially and behave in the sdsim web application landscape is defined by a set of egvs encoded in raster maps that are made up as a matrix of pixels also referred to as cells simulation outputs depend on a set of parameters that provides a flexible virtual framework to define a colonization pattern for virtually any species bioco et al 2020 i an initial distribution of patches set of cells from which the simulation can start ii the cell capacity the maximum number of specimens allowed in the cell iii three life cycle parameters to define species distribution arrangement birth rate death rate and spread rate iv any of multiplicative or additive approaches to model habitat suitability v type of moore approach to simulate neighbourhood expansion pattern through a landscape and vi a stopping criterion table 1 summarizes input data and parameters of the sdsim web application 3 1 habitat suitability function habitat suitability functions become crucial to provide a realistic simulation scenario in general terms species show habitat preferences for example in a location where environmental conditions are not suitable for a certain species the probability of colonization and expansion should be lower sdsim landscape can be characterized by a set of egvs relying on the researcher s knowledge about a species ecology which ones could limit or otherwise promote a species distribution from a species perspective the overall suitability of the region is determined by the probability of occurrence of the species given the environmental conditions in that location elith and leathwick 2009 it is the result of the aggregation of local egv values that influence its life cycle in sdsim each egv is characterized by a normal distribution around a hypothesized optimal value for that species mean and standard deviation should be provided for each variable according to the preferences of that species studied in the simulation alternatively in sdsim these values can be automatically calculated by providing the coordinates of the occurrences of the species observed directly on the terrain as a result habitat suitability would be internally calculated in a map which values will be normalized in a closed interval from 0 unsuitable to 1 optimal these values are obtained through probability density functions parzen 1962 that incorporate egv in each map location as arguments sdsim standardizes each egv map andrews and mallows 1974 xi xi μ σ where xi is the value of an egv in that location μ is the mean i e egv s optimal suitability value for a species and σ represents the standard deviation for that egv map sdsim implements two different model aggregation operators that can be selected by the researcher in order to compute an overall suitability map for a given species additive and multiplicative additive option is a straightforward implementation of a generalized additive model gam therefore habitat suitability map is obtained by adding egv values in each raster cell after applying a probability density function under multiplicative option habitat suitability map is obtained by a strict archimedean triangular norm in this case habitat suitability is more restrictive because product t norm produces stronger conjunction of probabilistic values multiplicative model might become useful in particular circumstances e g invasive species colonization of clonal organisms 3 2 general workflow in order to perform a simulation users should set all required simulation input data and parameters showed in table 1 sdsim allows users to create both real and simulated scenarios by uploading a different set of egvs as raster maps for a defining mean and standard deviation in order to build a suitability function associated with each egv for that species sdsim allows users to select a type of neighbourhood from any of moore 1962 or weighted moore lipowski and lipowska 2012 options assuming a regular grid of a raster map by using moore s neighbourhood species will expand homogeneously to their eight neighbours when using weighted moore option each one of the eight neighbouring cells will receive a number of transferred individuals directly proportional to its suitability sdsim generates a suitability map based on egv maps and every specific probability density function the more suitable is an adjacent cell for a species the more likely it will be chosen for range expansion of that species each cell would contain two values representing the capacity and the suitability fitness of the habitat initially population patches are randomly placed in a landscape before starting a simulation during a simulation sdsim calculates the difference between previous and current states at each iteration by the sum of the cell by cell differences between successive states of the system see algorithm 1 the simulation can be stopped when the system reaches a stable state or when a maximum number of iterations is completed in this regard the system is said to be stable when the difference between two consecutive states of the simulation converges to zero sdsim saves an output of a simulation according to an interval previously defined by the user at each iteration or after a given number of epochs at the end of a simulation sdsim produces as output the species distribution map in three file formats i text file ii ascii grid file iii image file and a video file see fig 1 for future reference the text file containing the values of all parameters used in the simulation is also available algorithm 1 sdsim general algorithm image 1 3 3 species life cycle algorithm species life cycle algorithm includes three steps reproduction expansion colonization and death see algorithm 2 this algorithm tries to imitate a natural biological generation so that species may stay in habitats that are more appropriate for them to colonize establish and finally expand during the reproduction phase species spreads spatially according to a birth rate or survival percentage in each raster cell across a landscape during the death phase a percentage of a cell capacity would disappear according to a death rate or extinction percentage during the expansion phase a percentage of a cell capacity is transferred to their neighbour cells according to a spread rate or colonization percentage an optimal strategy for a species in a particular and suitable landscape will ensure an optimal colonization of that particular setting table 2 summarizes the main functions implemented in sdsim abm 3 4 direction constraints directional egv degv can be used to promote or otherwise limit movement of a species in certain spatial directions typically a degv is characterized by two components that together represent a vector field magnitude intensity and direction each component should be represented by a raster map as an example for marine data currents should be split in magnitude or intensity and direction for intensity preferences of the species the treatment is similar to the one previously described i e given the intensity optimal parameters mean and standard deviation for a given species the corresponding density value is an input to the model aggregation which determines the overall suitability map for the species direction component will be likewise integrated in the model once suitability is computed direction map should include values expressed in degrees clockwise from the geographic north thus each map cell has a direction value d 0 d 360 representing the flow or directional movement species are able to move from the core cell to any of its 8 neighbouring cells each neighbour has a relative direction towards the core cell as depicted in fig 2 in order to compute direction of each neighbour sdsim computes the difference between the relative direction of the neighbour and the direction of movement for that cell 1 δk min d dk d 360 dk where k 1 8 stands for the neighbour cell and d k is the relative direction of such neighbour in fig 2 those directions are represented as values in each one of the neighbours of their core cell hence k 1 8 0 δ k 180 values are then normalized to the unit interval and incorporated into the model aggregation species expansion will be favoured by the overall direction information codified in every degv i e most of the transferred individuals will migrate from a core cell to neighbouring ones that are well aligned with the direction of movement let us return to the intensity component of a degv besides being treated as a mere egv representing the preference of a species for a given value e g some species might prefer waters with less current intensity it worthwhile to notice that most times there is a physical facet attached to it which should also have implications to the species fixation in a locus or to the speed of range expansion e g some species travel easily if the current speed is higher in such cases we propose the introduction of a momentum species dependent constant m s 0 1 constraining the number of individuals that are transferred to neighbouring cells n spread in the following way 2 n spread n spr i m s where n is the cell s number of individuals spr denotes the species spread ratio as introduced before and i 0 1 is the normalized intensity value observed at the cell level algorithm 2 species life cycle image 2 thus the intensity of a directional egv constrains the spread of the species not only in what regards preferences of the species but also by applying the modelled traction forces notice that some species heavily depend on such variables to perform their spreading while others can expand its range even if they are positioned in a zero intensity region hence the need for the introduction of a momentum constant 4 web interface sdsim is available online at https sdsim it ubi pt it provides a user friendly web interface that allows users to perform their simulations avoiding local installation in order to get access to the application users request an account by sending an email to the sdsim administrator providing a username to associate that account after an account is created the user receives a notification with credentials to log in and access available services of sdsim application that are presented in the main screen see fig 3 in the section my simulations users can access to details from previous simulations including simulation parameters and output data simulation results users can download output data as set of raster maps containing the state of the simulation at different time steps figures of the state of the simulation at each time step the video file that shows the spatial distribution evolution and a performance metric graph receiver operating characteristic curve roc curve if a species occurrences file was provided the user can also perform new simulations based on previous ones or remove them see fig 4 in this section users can find an initial set of simulation examples to explore and get acquaintance with this system in the upload section users are able to upload all necessary egvs and degvs in form of raster maps in order to describe the landscape that is intended to simulate sdsim does not use any specific datum or projection relying on user needs to make such decisions at this point the web application accepts only ascii grid raster format please see gdal library for raster and vector geospatial data formats at https gdal org in addition the user can also upload a comma separated values csv file containing the coordinates of the occurrences and or absences of any sampled species this file facilitates the user s work in such a way that he she does not need to provide the mean and standard deviation for each egv in order to estimate each probability density function the sdsim performs all the necessary calculations to provide the mean and standard deviation for each egv depending on the occurrences that the user has uploaded presence absence file can be uploaded to sdsim allowing a numerical comparison between the results of different simulations based on the correct classification of presence absence locations showing a roc curve and the area under the curve auc at the end of the simulation in the section simulation users can start a new simulation by filling a form with all the required parameters as described in table 1 users should follow all these steps after authentication to perform a simulation 1 access the section upload and add egvs see fig 5 2 return to the main screen and access the simulation section where users should complete all the required parameters including the selection of the corresponding egvs and their parameters to estimate each probability density function see fig 6 3 results species distribution maps and outputs can be managed in a gallery of images after the completion of the simulation see fig 7 users can also see the video that shows how the species temporal distribution evolved see fig 8 4 a simulation can be saved initial parameters and results in order to reformulate any experiment and refine new ones based on previously stored simulations 5 case study honeybee apis mellifera l is distributed in a wide area populations of the iberian peninsula are of particular interest because of the hypothesized hybrid status of a m iberiensis engel 1999 in agreement with this hypothesis a m iberiensis distribution reflects colonization movements associated to an environmental gradient probably showing selective factors of climatic tolerance cánovas et al 2014 in order to compare results both against previous simulation studies bioco et al 2018 and against real experimental data collected on the field cánovas et al 2014 the spatial distribution of the african lineage of the iberian honeybee a m iberiensis in the iberian peninsula was modelled and simulated in sdsim landscape was described by four main egvs that were previously found to have an important role to shape present spatial distribution of this species maximum temperature of the warmest month mxtrm minimum temperature of the coldest month mntcm rainfall seasonality rfseas and average annual temperature tann cánovas et al 2014 egvs were obtained from the climatic atlas of the world hijmans et al 2005 raster maps had a dimension of 196 122 cells to illustrate the range of freedom that is provided to the user we report four simulations covering the different combinations between the available types of neighbourhood moore and weighted moore and model aggregation multiplicative and additive the overall input parameters were the same for all four simulations see table 3 simulation results after 100 iterations are showed in fig 9 the left column of the figure presents the results for the moore neighbourhood the amount of transferred individuals from each cell is equally distributed by the eight neighbouring cells in fig 9 a the type of aggregation is additive i e as a result we get generalized additive model for the four considered egvs in fig 9 c the aggregation is multiplicative thus heavily penalizing poor values in any of the egvs the column on the right presents the results for the same variation in the model aggregation operator but for the case of the weighted moore neighbourhood in this case the neighbouring cells receive a quantity of transferred individuals directly proportional to their suitability i e neighbours with better suitability receive a greater quantity of species than the less suitable ones in order to evaluate the performance of the model we compared the simulation results against the 210 field observations species presence and absence csv file containing 210 locations latitude and longitude in fig 10 we show a roc curve and auc values for the types of neighbourhood and model aggregation the additive model seems to perform better than the multiplicative model and in the additive model both moore and weighted moore neighbourhood showed similar final results auc 0 78 considering the additive model in fig 11 detail differences can be followed as the species spreads spatially using moore neighbourhood on the left and weighted moore neighbourhood on the right these differences are more evident at these early stages of the simulation and are diluted once stabilization is reached in moore neighbourhood a more regular deployment is able to produce almost circular regions whereas weighted moore neighbourhood made colonization more irregular advancing faster in the track for more suitable regions overall the weighted moore method seems to be a good choice for this species because it seems closer to an expected biological behavior such as the observed in previous studies cánovas et al 2014 species colonized with greater abundance in the most suitable areas defined by a set of egvs moreover environmental suitability calculated using an additive model seems to be more appropriate according to what was observed for this species however choices regarding type of neighbourhood and aggregation strongly rely on the specific knowledge that users have about the behavior of each particular system furthermore the great variability on the distribution that is possible to obtain for any given species as is clearly exemplified in fig 9 far from being considered a drawback is seen as a mean to easily test and evaluate different hypothesis on the species mechanism of colonization results of this case study are available to all users registered in the application allowing access exploration and reproduction of experiments available in the sdsim website the impact of each egv was analysed in the simulation results fixing the model additive and the neighbourhood weighted moore and performing eight egv combinations as follow first we perform simulations with each egv individually and then removing each egv one at a time from the complete set giving rise to the following combinations mntcm rfseas tann mxtwm rfseas tann mxtwm mntcm tann and mxtwm mntcm rfseas this comparison is summarised in fig 12 which depicts the auc values for each experiment it is possible to notice that rainfall seasonality rfseas had the greatest impact in the overall results of the simulation followed by the average annual temperature tann the minimum temperature of the coldest month mntcm and the maximum temperature of the warmest month mxtrm showed the least impact since according to fig 12 if one of these variables is removed the quality degradation after stabilization is not significant this result seems to indicate that the studied species can be very robust when faced with one off sudden variations on the temperature as long as the average annual temperature stays within an admissible range 6 conclusion in this paper an abm system was designed to model and simulate spatial distribution of biological species and populations by using a set of egvs sdsim computes a habitat suitability index producing an internal species suitability map sdsim assumes a standard normal distribution as a probabilistic response function for each egv those are later aggregated using an additive or a multiplicative model chosen at users will together with egvs sdsim receives a set of input parameters which fit abm behavior and can be easily tuned therefore any species could be modelled by using this abm in different environmental scenarios a simulation will always start by generating an initial occupation of the available habitat in random locations at each iteration of the simulation species will then find more suitable locations for them to survive following a defined species life cycle with corresponding parameters sdsim allows users to study and understand the species environment relationship by changing the values of the environmental variables in order to verify the behavior of any simulation scenario as illustrated in the reported case study if in possession of real experimental data collected on the field the web interface provides supporting tools for assessing and compare a set of distinct hypothesis subsumed by the different experimental setups moreover the flexibility and user friendliness of the deployed web abm system enables the visual analysis of the evolution of species in any hypothetical landscape without requiring any programming skills from the user sdsim will incorporate new features the relationship between geological time and computational epochs will be useful for modellers to decide simulation time according to evolutionary biological time steps instead of stabilization of the simulation such ability will give extra tools to modellers who will be able to program simulations in evolutionary time rather than in computational one declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by centro 01 0145 feder 000019 c4 centro de competências em cloud computing cofinanced by the european regional development fund erdf through the programa operacional regional do centro centro 2020 in the scope of the sistema de apoio à investigação científica e tecnológica programas integrados de ic dt this work was also funded by fct mctes through national funds and when applicable co funded eu funds under the project uidb 50008 2020 authors thank the department of zoology and anthropology from the university of murcia in which the hypotheses proposed here with honeybees were generated and tested in previously published scientific manuscripts therefore providing a suitable case study to test sdsim the authors wish to thank pedro violante s contribution to the development of the front end lastly but not least the authors gratefully acknowledge an anonymous reviewer for his her thoroughly revision and insightful remarks 
