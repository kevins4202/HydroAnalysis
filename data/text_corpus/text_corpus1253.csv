index,text
6265,high arsenic concentrations average 0 1 mg l of groundwater were found in lanyang plain of taiwan in this study 39 groundwater samples from 23 wells were collected and 14 hydro geochemical parameters were analyzed factor analysis was applied to determine major influence factors of the arsenic enriched groundwater quality and phreeqc was used to calculate the distribution of aqueous species and saturation index of which affected the hydrogeochemistry of groundwater 393 geological core samples from 9 drilling wells were collected and analyzed the contents of total arsenic and iron moreover core samples associated with high arsenic concentration groundwater were selected mineralogical phases were analyzed using x ray fluorescence xrf high resolution x ray photoelectron xps and scanning electron microscope and energy dispersive spectrometer sem eds results of the arsenic enrichment factor determined by factor analysis indicated that infiltration of the organic and nitrogen pollutants from anthropogenic activities to shallow groundwater and the reductive dissolution from iron oxyhydroxides in the deep aquifer were the main processes of arsenic release to groundwater from the sediment total arsenic and iron contents of the core samples were well correlated in marine sequences the presence of clay layer within the subsurface may increase in the as contamination in groundwater aquifer however the time for as release from clay layer to lower aquifer may require tens or hundreds years to complete under natural environment condition surface analyses of core sample performed by xps showed that arsenic was adsorbed or co precipitated with non crystalline iron oxyhdroxides and sulfides after a long term burial of sediment microbial metabolism of organic matter creates a more reducing environment arsenic may then be gradually released from iron oxyhydroxides by reductive dissolution or desorption to aqueous phase the framboidal diagenetic type phase was identified by xps and the groundwater is supersaturated with respect to pyrite and orpiment determined by phreeqc are suggesting sulfide minerals co precipitate as arsenic in sediments is released into groundwater primarily by the reductive dissolution of as bearing fe oxyhydroxides in reducing environment in the lanyang plain keywords arsenic factor analysis mineralogical analysis geochemical modelling lanyang plain 1 introduction in the southwestern coast of taiwan blackfoot disease bfd is known as an endemic peripheral vascular disease arsenic has been identified as a major risk factor for bfd tseng 1977 ingestion of arsenic compounds in well water has been associated with age adjusted mortality from diabetes lai et al 1994 hypertension and cerebrovascular disease brown and chen 1995 chiou et al 1997 and cancer of lung liver bladder kidney prostate and nasal cavity chen and wang 1990 chiou et al 2001 in the northeastern taiwan the lanyang plain is also an arsenic affected region arsenic concentrations in groundwater largely exceed the taiwan epa drinking water limit of 10 μg l some well waters are up to 600 μg l or higher chiou et al 1997 residents of the lanyang plain have used shallow wells water depths 40 m to obtain drinking since the 1940s chiou et al 2001 although nowadays 90 of households have tap water supply groundwater is still commonly used as a source of drinking water and aquacultural water in the rural village and coastal fishpond of lanyang plain liang et al 2013 2018 significant dose dependent relationships between the arsenic concentration in well water and an increased risks of cerebrovascular disease urinary cancer and other cancers and adverse pregnancy outcomes has also been found chiou et al 2001 lee et al 2007a b the use of high as groundwater for aquacultural needs may bio accumulate as in farmed fish causing a potential cancer risk for consumption liang et al 2013 the arsenic is of natural origin and is believed to be released to groundwater as a result of a number of mechanisms mukherjee et al 2019 coomar et al 2019 maity et al 2017 geochemical processes involving redox reactions mineral dissolution precipitation adsorption and desorption substantially influence as mobilization jia et al 2014 this release appears to be associated with the burial of fresh sediment and the generation of anaerobic groundwater conditions guo et al 2008 the arsenic is then desorbed and dissolved from iron oxides which had earlier scavenged the arsenic from river water during their transport as part of the normal river sediment load natural variation in the amount of iron oxide at the time of sediment burial may be a key factor in controlling the distribution of high arsenic groundwater yang et al 2016 release of as in groundwater is generally correlated with geological and sediment environment redox conditions and their reactive processes determine the variation of as species concentrations in groundwater zheng et al 2004 polizzotto et al 2005 hsu et al 2010 the as contents of core sample at three monitoring wells locate at the mid and distal fan of lanyang plain were analyzed chen 2001 the average as contents of the core samples at three wells were 7 6 mg kg 2 4 mg kg and 3 4 mg kg respectively the highest as content of 51 9 mg kg 26 1 mg kg and 15 9 mg kg were found at 37 m 106 m 136 m respectively below the ground chen 2001 release from natural source is the dominant cause of elevated as concentrations in groundwater smedley and kinniburgh 2002 kao et al 2013 maity et al 2017 mukherjee et al 2019 the study investigated the distribution of as species and the redox geochemistry in groundwater in the lanyang plain 39 groundwater samples from 22 wells were collected the concentrations of 14 water quality parameters were measured and relations between as and other chemical parameters were statistically assessed using correlation and factor analysis arsenic and iron contents and the mineralogical characteristics of core samples from 9 drilling wells were evaluated aqueous chemical speciation and mineral saturation calculations were performed using phreeqc parkhurst 1995 the objectives of the study are to 1 characterize the sources distribution geochemical and mineralogical properties of as in groundwater and sediments in the lanyang plain 2 assess the main hydrogeochemical factors controlling as mobilization 2 methods and materials 2 1 study site the lanyang plain located in yilan county in northeastern taiwan it is an alluvial fan flooded by the lanyang river fig 1 the region is triangular bordered by the pacific ocean to the east the snow mountain to the northwest and the central mountains to the southwest the lanyang river flows through the middle in the same direction of groundwater from west to east the triangular plain area is approximately 400 km2 with 30 km in each side the groundwater region of lanyang plain is divided by the lanyang river of the north and south banks according to recharge sources the north bank is recharged by the snow mountain whereas the south bank is recharged by the central mountain peng 1995 according to the subsurface stratigraphic analysis of the lanyang plain the sequence boundary of the basement is formed with weathered and un integrated surfaces at about 18 ka bp marine sequence is deposited with alluvial sediment an transgressive lags in the range 6 18 ka bp and reaches to maximum flooding surface with a stable seawater table at 6 ka bp chen 2000 the basin filled up with increasing quantities of alluvial sediments through aggradations during 3 6 ka bp progradation occurred toward the sea at 3 ka bp chen 2000 is non marine sequence the depth of alluvial plain is in the range several hundred meters the surface layer is covered by sediments from the quaternary period including silt sand and clay and the plain is partitioned into proximal mid and distal fan areas chen 2000 the hydrogeological profile of lanyang plain fig 3 is constructed according to the cross section of stratigraphic survey denoted in fig 2 additionally the 23 hydrogeological stations with depths from 13 to 227 m were setup by the taiwan water resources agency wra based on the hydrogeological property for monitoring groundwater levels and quality groundwater aquifers are divided into two depth intervals according to marine and non marine sequence of aquifer 1 13 70 m and aquifer 2 70 250 m 2 2 groundwater sample analysis thirty nine groundwater samples were collected from 23 hydrogeological stations including 23 shallow groundwater samples aquifer 1 and 16 deep groundwater samples aquifer 2 ph dissolved oxygen do redox potential eh and electrical conductivity ec were measured in situ the remaining 14 physicochemical parameters of groundwater including na k ca2 mg2 hco3 cl so4 2 nh4 no3 hs as toc fe and mn were analyzed in the laboratory the field sampling method followed the niea national institute of environmental analysis niea code w103 52b established by the taiwan environmental protection administration at least three wellbore volumes of groundwater were purged before taking samples water samples were collected only after ph and ec stabilized and when the fluctuations of ph and relative ec were less than 0 1 and 5 respectively samples were then kept in ice boxes and delivered to the laboratory within 24 h alkalinity was analyzed using the gran titration method sulfide was determined through spectrophotometry by using turbidimetric methods un acidified parameters no3 cl and so42 and acidified parameters nh4 ca2 mg2 na and k were measured using ion chromatography dionex ics 900 the acidified parameters of fe and mn were measured using inductively coupled plasma and atomic emission spectrometry varian vista mpx the toc was measured using the high temperature combustion method by shimadzu toc 5000a lenore et al 1998 the lower detection limit was 0 05 mg l variances of duplicate measurements were less than 3 recoveries of check and spike samples were between 90 and 110 the analytical method for as iii and as v was followed closely from our previous study huang et al 2003 after pumping all groundwater samples were filtered through a 0 2 μm pore membrane syringe filter to prevent microbial activity and remove suspended particles in this study we used 1 ml of 8 7 m acetic acid for the preservation of as species per 100 ml of groundwater sample all samples were stored at 4 c and kept in the dark before analysis within 2 weeks concentrations of as species were analyzed using a high performance liquid chromatograph hitachi 7110 connected to a hydride generation fias 400 perkin elmer and atomic absorption spectroscopy perkin elmer aa100 the detection limits of as iii and as v were 0 4 and 0 3 μg l respectively samples were spiked with as species to determine the recovery rate in the laboratory procedure which yielded as iii and as v recovery rates of 100 7 3 8 and 97 2 4 0 respectively the coefficient of variation was used to test the reliability and was less than 5 in all experiments for sulfides the lower detection limit was 0 03 mg l variances of duplicate measurements were less than 10 recoveries of check and spike samples were between 85 and 115 for all parameters except as and sulfides a total of 10 samples comprising blank spiked duplicate and check samples standard solution from merck were sequentially measured lenore et al 1998 the variance of duplicate measurements was less than 3 the recoveries of the check and spiked samples were between 90 and 110 2 3 factor analysis factor analysis fa is a multivariate statistical method and yields a general relationship between measured chemical variables by elucidating the multivariate patterns that may help to classify the original data it can be used to determine the geographical distribution of the resulting factors the geochemical interpretation of factor analysis provides insight into the main processes that may govern the distribution of hydrochemical variables it is frequently employed to characterize the quality of groundwater liu et al 2003 sixteen hydrochemical parameters of the lanyang plain table 1 were examined to evaluate the characteristics of groundwater using fa with spss software spss inc 1998 2 4 geological core samples analysis geological core samples were collected from 9 drilling stations of water resources agency w03 w04 w05 w07 w11 w13 w16 w17 and w23 not water monitoring well at 5 m intervals to the bottom of the well as and fe contents of a total of 393 geological core samples were analyzed a 30 h2o2 and 9 6 m hcl solution were added to geological core sample to remove organic matter and to destroy structure of soil grain after filtering all samples were examined using an electro thermal atomic absorption spectrometer aa100 perkinelmer wellesley ma and a hydride generation system fias100 perkinelmer 0 5 nabh4 in 0 1 naoh and 1 m hcl solution was added to reduce arsenic to arsine the total as concentration was determined additionally a concentrated hno3 30 h2o2 and concentrated hcl solution was added to geological core sample to digest after filtering all samples were examined using a flame atomic absorption spectrometer flaa400 perkinelmer wellesley ma and the total fe concentration was determined moreover the amounts of various elements eg si al fe ca k and mg in the core samples were determine by x ray fluorescence xrf spectro xe pos feature of main as bearing phase such as probable ferrihydrites with various fe as molar ratio exits in which as is present as surface sorbed and or incorporated species was explored chemical characterization of well screen core sample of three drilling stations w03 w07 and w11 locate at mid and distal fan area respectively are identified by high resolution x ray photoelectron spectroscopy hr xps ulvac phi quantera sxm and scanning electron microscope sem hitachi s 3000n both xps and sem are surface chemical analysis techniques that can be used to analyze the surface chemistry of a material xps provides information on the elemental composition empirical formula chemical state and electronic state of the elements that exist within the surface or reaction layers of minerals and grains frau et al 2005 sem is designed for direct studying of surface sem images have great depth of field yielding a characteristic three dimensional appearance useful for understanding surface structure of a mineral hou et al 2006 2 5 geochemical speciation and saturation index the geochemical program phreeqc based on the database wateq4f dat was applied to calculate the distribution of aqueous species parkhurst and appelo 1999 the program adopted the ion associated theory of aqueous solutions to perform various aqueous geochemical computations phreeqc can also determine which solids might precipitate or dissolve by employing the saturation index si the si is defined as the logarithm of the ratio of the ion activity product iap of component ions for a solid in solution to the solubility product ksp of the solid si log iap ksp nordstrom and alpers 1999 in this study 16 hydrogeochemical parameters of groundwater samples including ph do eh na k ca2 mg2 hco3 cl so4 2 nh4 no3 hs as fe and mn concentrations were used to calculate equilibrium speciation and si 3 results and discussion 3 1 groundwater compositions the hydrochemical data of 39 analyzed groundwater samples are listed in table 1 fig 4 shows the plot of a piper diagram of the groundwater quality of lanyang plain according to the classifications of the piper diagram type i represented the carbonated temporary hardness type ii represented the alkali carbonate type iii represented the non carbonate permanent hardness and type iv represented saline piper 1953 the principal water type in the lanyang plain is type i n 20 followed by type ii n 15 only three groundwater samples in the coastal area of north bank were type iv which were caused by the sea water intrusion kao et al 2015 the high prevalence of carbonate water in the lanyang plain is attributed to the high hydraulic conductivity of the subsurface aquifer the ph is ranged 7 8 ehs are 0 mv except in the recharge zone of the mountain proximal fan the average arsenic concentration is 0 1 mg l with highest arsenic concentration of 1 01 mg l at w06 84 groundwater as exceed the drinking water standard of 0 01 mg l fig 5 a e plots the as concentration distribution versus depth eh do no3 and so4 2 in the lanyang plain the monitor wells located in the north and south banks of the lanyang river were denoted by different legends high as concentrations mostly appear in low eh do no3 and so4 2 of the south bank aquifers because the reductive dissolution of as rich fe oxyhydroxide is the most probable mechanism of the as release to groundwater in sedimentary aquifers wang et al 2007 nath et al 2008 fig 6 shows the regressional analyses of a as vs hco3 b as vs toc c fe vs hco3 d fe vs toc and e as vs fe as vs hco3 and toc yield higher correlations in the south bank of lanyang plain with r2 of 0 45 and 0 13 respectively similarly fe vs hco3 and toc also present higher correlations in the south bank of lanyang plain with r2 of 0 25 and 0 46 however as vs fe show low correlation the decoupling of as and fe in reducing aquifers is commonly found around world including the chianan plain of taiwan nath et al 2008 sracek et al 2018 the redox state redox potential eh of groundwater is an important parameter affecting as mobility and transformation the redox conditions of groundwater vary widely from approximately 300 mv to 300 mv in the lanyang aquifers we herein delineated four redox boundaries using four redox couples at standard state mn4 mn2 as5 as3 fe3 fe2 and so4 2 hs and plot in fig 7 a fe concentration vs eh fig 7 b as concentration vs eh signes pastor et al 2007 the as and fe concentrations were low in redox state of eh 80 mv and high in the redox state of 200 mv eh 80 mv as redox potential 200 mv fe sulfate and as may be reduced to precipitate as pyrite arsenopyrite realgar or orpiment minerals and decrease the aqueous concentrations 3 2 distribution of arsenic species table 2 shows the as species concentrations in aquifer 1 and 2 of lanyang plain the major arsenic species in all groundwater wells was as iii the ratio of as iii as total 65 and 78 in aquifer 1 and 2 respectively implying that the groundwater systems were in reduced condition other redox parameters including negative redox potential with average of 105 mv and low do value of 0 74 mg l all support this reductive environment finding previous studies have reported the predominant as iii species in groundwater of taiwan and us chen et al 1994 hering and chiu 2000 however others have found that as v was the dominant species in groundwater at several regions chen et al 1999 smedley et al 1996 or as v occurred in roughly equimolar proportion with as iii while as iii may be metastable to varying degrees in aerobic environments as iii exists more stable under anaerobic conditions several different bacteria strains were capable of reducing as v to as iii liao et al 2011 and act as a detoxification mechanism ji and silver 1995 rosen et al 1995 reduction of as ⅴ to as iii was observed in the nature gradient tracer experiment kent et al 2001 where as v was injected into an anoxic groundwater zone containing high concentration of dissolved fe ⅱ and reduced directly to as iii by fe ⅱ with the aid of microorganisms 3 3 factor analysis table 3 presents the eigenvalues of first four factors their percentage of variance and cumulative percentage of variance it reveals that the eigenvalues of the four factors which exceed one explain 86 49 of the total variance of the data set table 4 presents the loading of the varimax rotation factor matrix for the four factors model the term strong moderate and weak as applied to factor loadings refer to absolute loading values of 0 75 0 75 0 5 and 0 5 0 3 respectively liu et al 2003 this study selected absolute factor loading of over 0 6 to elucidate the relationships between the factors and hydrochemical data a factor score associated with each monitoring well was determined they were plotted to illustrate the spatial characteristics of the quality of groundwater in the lanyang plain factor 1 which has strong positive loading on cl k ec mg2 na mn and ca2 explained 48 81 of the total variance the strong positive terms are the major solutes in seawater factor 1 is thus called the salinization factor over pumping and salty water infiltration from coastal fishponds are the two main causes fig 8 a1 and a2 show the spatial score distribution of factor 1 of aquifer 1 and 2 where only shallow aquifer 1 in the north coast has salinization the deep aquifer 2 is free from brackish water peng 1995 used the isotope analysis to survey the groundwater age he confirmed that the northern coast groundwater was relative young suggesting the seawater intrusion and the infiltration of salty water responsible for the salinization factor 2 characterizes by strong positive loading of fe and toc which accounts 19 29 of the total variance fig 8 b1 and b2 show the high score distribution of factor 2 in the north mid fan and in the south coast of aquifer 1 and 2 respectively the source of toc in aquifer 1 was infiltrated from the sanitary landfill leachate whereas the toc source in aquifer 2 was dissolved from the organic rich sediment high toc in groundwater creates a more reducing environment causing fe ii release to groundwater via reductive dissolution of fe oxides in sediment chen 2001 lawati et al 2012 fe oxides acts as an important electron acceptor to reductive dissolution and release of fe2 into groundwater factor 3 explains 11 4 of the total variance which associates with strong loading of as and hco3 and moderate loading of nh4 fig 8 c1 and c2 display that the high scores of factor 3 distribute along the middle sea coast and downstream area of the aquifer 2 in south bank of lanyang plain the mineralization of sedimentary organic matters results in bicarbonate production and subsequent dissolution of calcite rising the alkalinity the dissolved carbonate may influence the adsorption of trace metals by competing for sites on mineral surface forming carbonate complex that can either enhance or suppress adsorption and forming precipitates villalobos and leckie 2001 the mobilization of adsorbed as with dissolved bicarbonate has proposed to be one of the major causes of high levels of as in groundwater appelo et al 2002 wang et al 2007 denitrification reduced no3 to nh4 resulting in depletion of no3 and increase in nh4 leading to the release of as from as bearing fe oxyhydroxides into groundwater weng et al 2017 factor 3 is thus called the as enrichment factor factor 4 which has strong positive and negative loadings on eh and ph respectively explains 7 25 of the total variance it represents the geochemical characteristics of the study region suggesting a tendency of redox potential decrease from the proximal fan to the distal fan spatial distribution of factor 4 scores from positive to negative along the direction from west to east fig 8 d1 and d2 the inverse relationship between ph and eh controls the solubility of minerals eh ph diagrams are commonly applied to represent the dominate chemical species and mobility of metals in groundwater appelo and postma 1993 factor 4 is called the redox factor 3 4 sediment characteristics and distribution of elements as and fe contents in 393 core samples of nine drilling stations were analyzed fig 9 illustrates the vertical distribution of as and fe contents in north and south banks of lanyang plain low as and fe contents generally found in the proximal fan in both north w16 17 and south w11 banks of lanyang plain figs 10 and 11 show that as and fe contents in marine sequence were positively correlated but were poorly correlated in non marine sequence marine sequence consists of clay silt whereas non marine sequence comprises by sand gravel the small grain size of sediment materials provides a large surface area enabling high adsorption capacity of arsenic and resulting increased as enrichment in clay and silt moreover the marine formation contains fine clay with sea organisms that may have high arsenic content resulting from bioaccumulation and bioconcentration francesconi et al 1998 liu et al 2006 the moderate to low correlation between as and fe in marine sediment may be due to the fraction of silicate bound as and as retained by fe oxhydroxide norrs et al 2005 nine core samples from various intervals in the well screens of 3 drilling stations in the south bank of lanyang plain were selected from bulk analysis of elemental distribution by xrf table 5 the main chemical constituents of sediment incudes sio2 al2o3 fe2o3 k2o cao2 mgo and tio2 accounting for the majority of the samples weight manganese sulfur and arsenic were minor compositional elements ranging from 2 94 to 67 4 mg kg 348 3 to 4404 mg kg and 6 7 to 22 4 mg kg respectively among these samples as content was weekly correlated with mn r2 0 34 p 0 05 and fe r2 0 24 p 0 05 indicating as bearing fe mn phases were the predominant as host minerals in the sediment nine core samples from three drilling stations in the south bank of lanyang plain were selected for xps analyses each xps result for fe fig 12 comprises to curves 1 the experimental curve after smoothing and 2 curve of the fitted components the results of the fe2 p 3 2 lines can be fitted by multiple components six types of fe minerals were observed including a mixing valence type fe3o4 two reducing form types feo fes and three oxidizing form types fe2o3 feooh and fef3 in the non marine sequence feo and feooh are dominate minerals in the marine sequence the fe minerals distributions are complex the detection limit is such that the spectra of mn2 p 3 2 and asd5 2 yielded no information regarding specific mineral compounds of mn and as samples w11 2 and w07 2 of marine sequence were chosen for further investigation by sem eds fig 13 shows images of w11 2 and w07 2 by sem fig 13a and b and the spectra show fe s si o are main peaks and as is small peaks fig 13c and d the presence of colloid like fabrics shows amorphous or poorly crystalline fe as phase as coating on silicate grain due to co precipitation pyrite was found in both samples and was similar to that found in the southern choushui river alluvial fan taiwan lu et al 2010 where it was identified as the framboidal diagentic type liu et al 2013 akai et al 2004 3 5 aqueous speciation and saturation indices table 6 presents the ratios of the particular chemical species concentration to the total chemical element concentration calculated by phreeqc the major species of as c and s were haso3 hco3 and so4 2 respectively however the major fe species were fe2 fehco3 and feco3 because of the high alkalinity in the groundwater table 7 shows the mineral saturation index of 13 groundwater samples computed using phreeqc the groundwater was the supersaturated with respect to orpiment in 9 well samples moreover groundwater was oversaturated with respect to siderite and was close to saturate with respect to calcite it suggests that the elevated hco3 levels are not only controlled by the dissolution of the carbonate minerals in the lanyang aquifer high hco3 concentrations correlate with the levels of dissolved organic carbon toc up to 24 1 mg l in groundwater toc levels showed distinct trends of variation with as and fe concentrations no3 levels in groundwater are generally low with no correlation to as but nh4 correlated well with as co2 is the primary degraded product of organic matters causing carbonate minerals dissolved including the reduction of no3 as well as the reductive dissolution of fe oxyhdroxides in solid phase this explains that the fe and toc formed as the iron reduction factor and as associated with hco3 and nh4 as as enrichment factor in the factor analysis groundwater was under saturated with respect to anhydrite epsomite and magnesite the si values for most of iron minerals including goethite hematite magnetite siderite and pyrite were greater than zero indicating that these minerals may be precipitated the xps and sem eds results confirmed these findings the positive sis of pyrite 10 indicated the high potential for precipitation fe2 may be co precipitated with hs resulted in low hs the results of sem also showed that amorphous or poorly crystalline fe as phase in samples 11 2 and 7 2 were present 3 6 discussion factor analysis shows that the iron reduction factor and as enrichment factor both include nh4 with moderate loading these two factors consist of fe toc nh4 as and hco3 are generally responsible for moderately reducing environment and arsenic release to groundwater might be caused by mineralization or organic in reducing conditions liu et al 2003 lawati et al 2012 scores of factor 2 are distributed close to the landfill w31 and theme park w08 in the aquifer 1 the site was for traditional dumping which was operated from 1990 to 1999 and buried municipal waste with no impermeable liner the theme park is a popular scenic area and attracts more than one million tourists annually the anthropogenic organic pollutants infiltrate to groundwater likely causing the adsorbed as ions release from fe oxyhdroxide surface to the aquifer 1 however arsenic concentrations in aquifer 1 is less than those of in aquifer 2 due to the high as was accumulated in the marine formation generally in the suboxic to anoxic conditions the presence of dissolved fe corresponds to the dissolved as nh4 n and hco3 which are consistent with mechanism of reductive dissolution of fe oxyhydroxides via respiration of organic matter nickson et al 2000 mcarthur et al 2004 hco3 presents the local baseline that results from weathering oxygen consumption and nitrate reduction which is the major dissolved inorganic carbon dic nickson et al 2000 anawar et al 2004 respiration of dissolved organic carbon doc produces ammonia and co2 and latter may induce calcite dissolution harvey et al 2002 carbon isotopes 14c of dic bicarbonate in groundwater of lanyang plain was analyzed by peng 1995 indicating the groundwater is the mixture of invading fresh water with older resident water at mid fan and distal fan areas of lanyang plain and recharge from the western mountains are the primary source of groundwater in the aquifers young groundwater and surface water contain less bicarbonate while it is preponderantly high in old and reducing groundwater mcarthur et al 2001 the older dic can be oxidative product of doc that mobilized from sediment and invades to groundwater appelo et al 2002 indicates that sediment groundwater interface contains high dissolved bicarbonate content and as may be mobilized by displacement from sediment surface a poor correlation exists between fe and as in groundwater which may be caused by adsorption of fe ii onto solid surface or precipitation as fe ii or mixed valence solid nickson et al 2000 this study identifies various iron compounds by xps analysis anawar et al 2004 demonstrates bicarbonate ion exchange substitution may be another important process to as mobilization and may explain the poor correlation between aqueous as and fe phreeqc simulation indicates fe2 and fehco3 are primary species for iron and molar ratio of fehco3 increases with increasing depth based on geochemical modeling and further form siderite welch and lico 1998 groundwaters are supersaturated with respect to other iron minerals including hematite fe2o3 goethite feooh and magnetite fe3o4 high concentrations of hco3 are partially due to the moderately dissolving tendency of calcite and dolomite based on the geochemical modelling table 7 reductive dissolution of fe oxide minerals and the subsequent release of adsorbed and or co precipitated as are main causes of high as concentrations in groundwater under reducing conditions ahmed et al 2004 jia et al 2014 however gradual reductive dissolution of fe oxides could also allow re sorption of as released by this process onto the residual solid until the sorption capacity of the solid reached and or the solid is lost by dissolution mcarthur et al 2004 sracek et al 2018 the de coupling of as and fe in reducing aquifers is common and has been observed in many sites around the world where as is released as a consequence of redox processes including bangladesh west bengal assam in india cambodia and taiwan sracek et al 2018 as and fe contents of core samples in marine sequence were positively correlated marine sequence comprised clay silt and organic matter the as contents in marine sequence were generally higher than that of in non marine sequence liu et al 2006 moreover organic matter can strongly influence the solubility and mobility of as through redox reactions competitive adsorption desorption and complexation reactions suggesting that the organic matter is a redox driver and also one of the sources of as in groundwater anawar et al 2013 the presence of clay layer within the subsurface may thus increase in the as contamination in groundwater aquifer however the time for as release from clay layer to lower aquifer may require tens or hundreds years to complete under natural environment condition recently erban et al 2013 reported that as released from clayey aquitards caused by pumping induced land subsidence may take a decade or more to affect the as concentration in the lower aquifer in mekong delta vietnam their study provides a clue to investigate the time lag process of as released from clay layer to deep aquifers the nonlinear relation between sorbed and dissolved as is important factor for the mobility and transport of as in aquifer swartz et al 2004 the extent of as adsorbed onto fe oxyhydroxides is strongly influenced by as oxidation state and presence of inorganic and organic solutes hering et al 1997 arsenite and bicarbonate ions species become primary species for as and carbon respectively in groundwater at mid fan and distal fan area and their molar ratios rapidly increase with increasing depth based on phreeqc modelling in aquifer 1 mineralization of organic matter in sediment cause onset of reducing conditions and fe oxyhydroxides are the important acceptors of electrons providing for the mineralization of organic matter stumm and morgan 1996 this leads to dissolution of as rich feooh coating on soil particles or reduction of some of the adsorbed arsenate to arsenite and its release to groundwater however some arsenate may re adsorb onto feooh in aquifer 2 mineralization of organic matter progressively drives reductive dissolution of feooh and converts arsenate to arsenite mcarthur et al 2001 lee et al 2007a b additionally high levels of bicarbonate may contribute to limit adsorption sites of fe oxyhydroxides to sorb as harvey et al 2002 resulting in higher level of as many shallow alluvial aquifers in various parts of the world such as bangladesh west bengal india china and taiwan have the as contamination problems smedley and kinniburgh 2002 arsenic is generally derived from weathering of as rich minerals and then enter to the groundwater by reductive dissolution of fe oxhydroxides under anaerobic conditions in the alluvial systems nath et al 2008 wang et al 2007 reza et al 2011 conducted a comparative study on as in alluvial aquifers of bengal delta plain chianan plain and lanyang plain the as concentrations are generally higher in the chianan plain groundwater than those in the lanyang plain and bengal delta plain groundwater the mean as concentrations in bengal delta plain chianan plain and lanyang plain are 50 65 μg l 2 8 170 8 μg l n 20 393 μg l 9 704 μg l n 5 and 104 5 μg l 2 51 543 μg l n 6 respectively reza et al 2011 the reductive dissolution of as adsorbed mn oxyhydroxides is the most probable mechanism for mobilization of as in the bengal delta plain hasan et al 2007 however in the chianan plain and lanyang plain microbially mediated reductive dissolution of as adsorbed amorphous crystalline fe oxyhydroxides in organic rich sediments is the primary mechanism for releasing as to groundwater liu et al 2013 lee et al 2007a b arsenic organic matter and humic substance in the lanyang plain groundwater are comparatively lower than in the chianan plain groundwater and the bfd has not been reported in the lanyang plain high levels of as and humic substances may possibly play a critical role in causing the unique bfd in the chianan plain of southwestern taiwan reza et al 2011 4 conclusion thirty nine groundwater quality samples and 393 geological core samples with 5 m interval from 9 drilling stations of the lanyang plain taiwan were collected analyzed factor analysis fa was applied to wells with 16 hydrogeochemical parameters of 39 groundwater samples high resolution x ray photoelectron spectroscopy hr xps and scan electron microscope sem were used to determine the mineralogy of core samples fe and as contents of core sample were also analyzed factor analysis extracted four factors from the data for groundwater aquifers 1 and 2 these factors are mostly related to salinization and arsenic enrichment analytical results of fa suggest that the distribution of the salinization is in aquifer 1 and the main causes of saline groundwater are infiltration from fishpond salty water and sea water intrusion the leachate from the landfill site infiltrated to the aquifer 1 and caused reducing condition with high as concentrations in the local aquifer analytical results of core samples indicate that as and fe contents was correlated with location of clay layer in marine sequence and as adsorbed or co precipitated with fe oxyhydroxides the major minerals identified by xps and sem eds were goethite hematite magnetite pyrite and siderite agreeing with the si values calculated by phreeqc the arsenic enrichment in the reduced geological environment and the adsorption co precipitation of as on the fe oxyhydroxides may be used to interpret the possible processes of arsenic release to groundwater in the aquifers arsenic in sediments is released into groundwater primarily by the reductive dissolution of as bearing fe oxyhydroxides in reducing environment in the lanyang plain declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the ministry of sciences and technology of the republic of china for financially supporting this research under contracts nos 104 2313 b 002 026 my3 and 107 2313 b 002 019 my3 
6265,high arsenic concentrations average 0 1 mg l of groundwater were found in lanyang plain of taiwan in this study 39 groundwater samples from 23 wells were collected and 14 hydro geochemical parameters were analyzed factor analysis was applied to determine major influence factors of the arsenic enriched groundwater quality and phreeqc was used to calculate the distribution of aqueous species and saturation index of which affected the hydrogeochemistry of groundwater 393 geological core samples from 9 drilling wells were collected and analyzed the contents of total arsenic and iron moreover core samples associated with high arsenic concentration groundwater were selected mineralogical phases were analyzed using x ray fluorescence xrf high resolution x ray photoelectron xps and scanning electron microscope and energy dispersive spectrometer sem eds results of the arsenic enrichment factor determined by factor analysis indicated that infiltration of the organic and nitrogen pollutants from anthropogenic activities to shallow groundwater and the reductive dissolution from iron oxyhydroxides in the deep aquifer were the main processes of arsenic release to groundwater from the sediment total arsenic and iron contents of the core samples were well correlated in marine sequences the presence of clay layer within the subsurface may increase in the as contamination in groundwater aquifer however the time for as release from clay layer to lower aquifer may require tens or hundreds years to complete under natural environment condition surface analyses of core sample performed by xps showed that arsenic was adsorbed or co precipitated with non crystalline iron oxyhdroxides and sulfides after a long term burial of sediment microbial metabolism of organic matter creates a more reducing environment arsenic may then be gradually released from iron oxyhydroxides by reductive dissolution or desorption to aqueous phase the framboidal diagenetic type phase was identified by xps and the groundwater is supersaturated with respect to pyrite and orpiment determined by phreeqc are suggesting sulfide minerals co precipitate as arsenic in sediments is released into groundwater primarily by the reductive dissolution of as bearing fe oxyhydroxides in reducing environment in the lanyang plain keywords arsenic factor analysis mineralogical analysis geochemical modelling lanyang plain 1 introduction in the southwestern coast of taiwan blackfoot disease bfd is known as an endemic peripheral vascular disease arsenic has been identified as a major risk factor for bfd tseng 1977 ingestion of arsenic compounds in well water has been associated with age adjusted mortality from diabetes lai et al 1994 hypertension and cerebrovascular disease brown and chen 1995 chiou et al 1997 and cancer of lung liver bladder kidney prostate and nasal cavity chen and wang 1990 chiou et al 2001 in the northeastern taiwan the lanyang plain is also an arsenic affected region arsenic concentrations in groundwater largely exceed the taiwan epa drinking water limit of 10 μg l some well waters are up to 600 μg l or higher chiou et al 1997 residents of the lanyang plain have used shallow wells water depths 40 m to obtain drinking since the 1940s chiou et al 2001 although nowadays 90 of households have tap water supply groundwater is still commonly used as a source of drinking water and aquacultural water in the rural village and coastal fishpond of lanyang plain liang et al 2013 2018 significant dose dependent relationships between the arsenic concentration in well water and an increased risks of cerebrovascular disease urinary cancer and other cancers and adverse pregnancy outcomes has also been found chiou et al 2001 lee et al 2007a b the use of high as groundwater for aquacultural needs may bio accumulate as in farmed fish causing a potential cancer risk for consumption liang et al 2013 the arsenic is of natural origin and is believed to be released to groundwater as a result of a number of mechanisms mukherjee et al 2019 coomar et al 2019 maity et al 2017 geochemical processes involving redox reactions mineral dissolution precipitation adsorption and desorption substantially influence as mobilization jia et al 2014 this release appears to be associated with the burial of fresh sediment and the generation of anaerobic groundwater conditions guo et al 2008 the arsenic is then desorbed and dissolved from iron oxides which had earlier scavenged the arsenic from river water during their transport as part of the normal river sediment load natural variation in the amount of iron oxide at the time of sediment burial may be a key factor in controlling the distribution of high arsenic groundwater yang et al 2016 release of as in groundwater is generally correlated with geological and sediment environment redox conditions and their reactive processes determine the variation of as species concentrations in groundwater zheng et al 2004 polizzotto et al 2005 hsu et al 2010 the as contents of core sample at three monitoring wells locate at the mid and distal fan of lanyang plain were analyzed chen 2001 the average as contents of the core samples at three wells were 7 6 mg kg 2 4 mg kg and 3 4 mg kg respectively the highest as content of 51 9 mg kg 26 1 mg kg and 15 9 mg kg were found at 37 m 106 m 136 m respectively below the ground chen 2001 release from natural source is the dominant cause of elevated as concentrations in groundwater smedley and kinniburgh 2002 kao et al 2013 maity et al 2017 mukherjee et al 2019 the study investigated the distribution of as species and the redox geochemistry in groundwater in the lanyang plain 39 groundwater samples from 22 wells were collected the concentrations of 14 water quality parameters were measured and relations between as and other chemical parameters were statistically assessed using correlation and factor analysis arsenic and iron contents and the mineralogical characteristics of core samples from 9 drilling wells were evaluated aqueous chemical speciation and mineral saturation calculations were performed using phreeqc parkhurst 1995 the objectives of the study are to 1 characterize the sources distribution geochemical and mineralogical properties of as in groundwater and sediments in the lanyang plain 2 assess the main hydrogeochemical factors controlling as mobilization 2 methods and materials 2 1 study site the lanyang plain located in yilan county in northeastern taiwan it is an alluvial fan flooded by the lanyang river fig 1 the region is triangular bordered by the pacific ocean to the east the snow mountain to the northwest and the central mountains to the southwest the lanyang river flows through the middle in the same direction of groundwater from west to east the triangular plain area is approximately 400 km2 with 30 km in each side the groundwater region of lanyang plain is divided by the lanyang river of the north and south banks according to recharge sources the north bank is recharged by the snow mountain whereas the south bank is recharged by the central mountain peng 1995 according to the subsurface stratigraphic analysis of the lanyang plain the sequence boundary of the basement is formed with weathered and un integrated surfaces at about 18 ka bp marine sequence is deposited with alluvial sediment an transgressive lags in the range 6 18 ka bp and reaches to maximum flooding surface with a stable seawater table at 6 ka bp chen 2000 the basin filled up with increasing quantities of alluvial sediments through aggradations during 3 6 ka bp progradation occurred toward the sea at 3 ka bp chen 2000 is non marine sequence the depth of alluvial plain is in the range several hundred meters the surface layer is covered by sediments from the quaternary period including silt sand and clay and the plain is partitioned into proximal mid and distal fan areas chen 2000 the hydrogeological profile of lanyang plain fig 3 is constructed according to the cross section of stratigraphic survey denoted in fig 2 additionally the 23 hydrogeological stations with depths from 13 to 227 m were setup by the taiwan water resources agency wra based on the hydrogeological property for monitoring groundwater levels and quality groundwater aquifers are divided into two depth intervals according to marine and non marine sequence of aquifer 1 13 70 m and aquifer 2 70 250 m 2 2 groundwater sample analysis thirty nine groundwater samples were collected from 23 hydrogeological stations including 23 shallow groundwater samples aquifer 1 and 16 deep groundwater samples aquifer 2 ph dissolved oxygen do redox potential eh and electrical conductivity ec were measured in situ the remaining 14 physicochemical parameters of groundwater including na k ca2 mg2 hco3 cl so4 2 nh4 no3 hs as toc fe and mn were analyzed in the laboratory the field sampling method followed the niea national institute of environmental analysis niea code w103 52b established by the taiwan environmental protection administration at least three wellbore volumes of groundwater were purged before taking samples water samples were collected only after ph and ec stabilized and when the fluctuations of ph and relative ec were less than 0 1 and 5 respectively samples were then kept in ice boxes and delivered to the laboratory within 24 h alkalinity was analyzed using the gran titration method sulfide was determined through spectrophotometry by using turbidimetric methods un acidified parameters no3 cl and so42 and acidified parameters nh4 ca2 mg2 na and k were measured using ion chromatography dionex ics 900 the acidified parameters of fe and mn were measured using inductively coupled plasma and atomic emission spectrometry varian vista mpx the toc was measured using the high temperature combustion method by shimadzu toc 5000a lenore et al 1998 the lower detection limit was 0 05 mg l variances of duplicate measurements were less than 3 recoveries of check and spike samples were between 90 and 110 the analytical method for as iii and as v was followed closely from our previous study huang et al 2003 after pumping all groundwater samples were filtered through a 0 2 μm pore membrane syringe filter to prevent microbial activity and remove suspended particles in this study we used 1 ml of 8 7 m acetic acid for the preservation of as species per 100 ml of groundwater sample all samples were stored at 4 c and kept in the dark before analysis within 2 weeks concentrations of as species were analyzed using a high performance liquid chromatograph hitachi 7110 connected to a hydride generation fias 400 perkin elmer and atomic absorption spectroscopy perkin elmer aa100 the detection limits of as iii and as v were 0 4 and 0 3 μg l respectively samples were spiked with as species to determine the recovery rate in the laboratory procedure which yielded as iii and as v recovery rates of 100 7 3 8 and 97 2 4 0 respectively the coefficient of variation was used to test the reliability and was less than 5 in all experiments for sulfides the lower detection limit was 0 03 mg l variances of duplicate measurements were less than 10 recoveries of check and spike samples were between 85 and 115 for all parameters except as and sulfides a total of 10 samples comprising blank spiked duplicate and check samples standard solution from merck were sequentially measured lenore et al 1998 the variance of duplicate measurements was less than 3 the recoveries of the check and spiked samples were between 90 and 110 2 3 factor analysis factor analysis fa is a multivariate statistical method and yields a general relationship between measured chemical variables by elucidating the multivariate patterns that may help to classify the original data it can be used to determine the geographical distribution of the resulting factors the geochemical interpretation of factor analysis provides insight into the main processes that may govern the distribution of hydrochemical variables it is frequently employed to characterize the quality of groundwater liu et al 2003 sixteen hydrochemical parameters of the lanyang plain table 1 were examined to evaluate the characteristics of groundwater using fa with spss software spss inc 1998 2 4 geological core samples analysis geological core samples were collected from 9 drilling stations of water resources agency w03 w04 w05 w07 w11 w13 w16 w17 and w23 not water monitoring well at 5 m intervals to the bottom of the well as and fe contents of a total of 393 geological core samples were analyzed a 30 h2o2 and 9 6 m hcl solution were added to geological core sample to remove organic matter and to destroy structure of soil grain after filtering all samples were examined using an electro thermal atomic absorption spectrometer aa100 perkinelmer wellesley ma and a hydride generation system fias100 perkinelmer 0 5 nabh4 in 0 1 naoh and 1 m hcl solution was added to reduce arsenic to arsine the total as concentration was determined additionally a concentrated hno3 30 h2o2 and concentrated hcl solution was added to geological core sample to digest after filtering all samples were examined using a flame atomic absorption spectrometer flaa400 perkinelmer wellesley ma and the total fe concentration was determined moreover the amounts of various elements eg si al fe ca k and mg in the core samples were determine by x ray fluorescence xrf spectro xe pos feature of main as bearing phase such as probable ferrihydrites with various fe as molar ratio exits in which as is present as surface sorbed and or incorporated species was explored chemical characterization of well screen core sample of three drilling stations w03 w07 and w11 locate at mid and distal fan area respectively are identified by high resolution x ray photoelectron spectroscopy hr xps ulvac phi quantera sxm and scanning electron microscope sem hitachi s 3000n both xps and sem are surface chemical analysis techniques that can be used to analyze the surface chemistry of a material xps provides information on the elemental composition empirical formula chemical state and electronic state of the elements that exist within the surface or reaction layers of minerals and grains frau et al 2005 sem is designed for direct studying of surface sem images have great depth of field yielding a characteristic three dimensional appearance useful for understanding surface structure of a mineral hou et al 2006 2 5 geochemical speciation and saturation index the geochemical program phreeqc based on the database wateq4f dat was applied to calculate the distribution of aqueous species parkhurst and appelo 1999 the program adopted the ion associated theory of aqueous solutions to perform various aqueous geochemical computations phreeqc can also determine which solids might precipitate or dissolve by employing the saturation index si the si is defined as the logarithm of the ratio of the ion activity product iap of component ions for a solid in solution to the solubility product ksp of the solid si log iap ksp nordstrom and alpers 1999 in this study 16 hydrogeochemical parameters of groundwater samples including ph do eh na k ca2 mg2 hco3 cl so4 2 nh4 no3 hs as fe and mn concentrations were used to calculate equilibrium speciation and si 3 results and discussion 3 1 groundwater compositions the hydrochemical data of 39 analyzed groundwater samples are listed in table 1 fig 4 shows the plot of a piper diagram of the groundwater quality of lanyang plain according to the classifications of the piper diagram type i represented the carbonated temporary hardness type ii represented the alkali carbonate type iii represented the non carbonate permanent hardness and type iv represented saline piper 1953 the principal water type in the lanyang plain is type i n 20 followed by type ii n 15 only three groundwater samples in the coastal area of north bank were type iv which were caused by the sea water intrusion kao et al 2015 the high prevalence of carbonate water in the lanyang plain is attributed to the high hydraulic conductivity of the subsurface aquifer the ph is ranged 7 8 ehs are 0 mv except in the recharge zone of the mountain proximal fan the average arsenic concentration is 0 1 mg l with highest arsenic concentration of 1 01 mg l at w06 84 groundwater as exceed the drinking water standard of 0 01 mg l fig 5 a e plots the as concentration distribution versus depth eh do no3 and so4 2 in the lanyang plain the monitor wells located in the north and south banks of the lanyang river were denoted by different legends high as concentrations mostly appear in low eh do no3 and so4 2 of the south bank aquifers because the reductive dissolution of as rich fe oxyhydroxide is the most probable mechanism of the as release to groundwater in sedimentary aquifers wang et al 2007 nath et al 2008 fig 6 shows the regressional analyses of a as vs hco3 b as vs toc c fe vs hco3 d fe vs toc and e as vs fe as vs hco3 and toc yield higher correlations in the south bank of lanyang plain with r2 of 0 45 and 0 13 respectively similarly fe vs hco3 and toc also present higher correlations in the south bank of lanyang plain with r2 of 0 25 and 0 46 however as vs fe show low correlation the decoupling of as and fe in reducing aquifers is commonly found around world including the chianan plain of taiwan nath et al 2008 sracek et al 2018 the redox state redox potential eh of groundwater is an important parameter affecting as mobility and transformation the redox conditions of groundwater vary widely from approximately 300 mv to 300 mv in the lanyang aquifers we herein delineated four redox boundaries using four redox couples at standard state mn4 mn2 as5 as3 fe3 fe2 and so4 2 hs and plot in fig 7 a fe concentration vs eh fig 7 b as concentration vs eh signes pastor et al 2007 the as and fe concentrations were low in redox state of eh 80 mv and high in the redox state of 200 mv eh 80 mv as redox potential 200 mv fe sulfate and as may be reduced to precipitate as pyrite arsenopyrite realgar or orpiment minerals and decrease the aqueous concentrations 3 2 distribution of arsenic species table 2 shows the as species concentrations in aquifer 1 and 2 of lanyang plain the major arsenic species in all groundwater wells was as iii the ratio of as iii as total 65 and 78 in aquifer 1 and 2 respectively implying that the groundwater systems were in reduced condition other redox parameters including negative redox potential with average of 105 mv and low do value of 0 74 mg l all support this reductive environment finding previous studies have reported the predominant as iii species in groundwater of taiwan and us chen et al 1994 hering and chiu 2000 however others have found that as v was the dominant species in groundwater at several regions chen et al 1999 smedley et al 1996 or as v occurred in roughly equimolar proportion with as iii while as iii may be metastable to varying degrees in aerobic environments as iii exists more stable under anaerobic conditions several different bacteria strains were capable of reducing as v to as iii liao et al 2011 and act as a detoxification mechanism ji and silver 1995 rosen et al 1995 reduction of as ⅴ to as iii was observed in the nature gradient tracer experiment kent et al 2001 where as v was injected into an anoxic groundwater zone containing high concentration of dissolved fe ⅱ and reduced directly to as iii by fe ⅱ with the aid of microorganisms 3 3 factor analysis table 3 presents the eigenvalues of first four factors their percentage of variance and cumulative percentage of variance it reveals that the eigenvalues of the four factors which exceed one explain 86 49 of the total variance of the data set table 4 presents the loading of the varimax rotation factor matrix for the four factors model the term strong moderate and weak as applied to factor loadings refer to absolute loading values of 0 75 0 75 0 5 and 0 5 0 3 respectively liu et al 2003 this study selected absolute factor loading of over 0 6 to elucidate the relationships between the factors and hydrochemical data a factor score associated with each monitoring well was determined they were plotted to illustrate the spatial characteristics of the quality of groundwater in the lanyang plain factor 1 which has strong positive loading on cl k ec mg2 na mn and ca2 explained 48 81 of the total variance the strong positive terms are the major solutes in seawater factor 1 is thus called the salinization factor over pumping and salty water infiltration from coastal fishponds are the two main causes fig 8 a1 and a2 show the spatial score distribution of factor 1 of aquifer 1 and 2 where only shallow aquifer 1 in the north coast has salinization the deep aquifer 2 is free from brackish water peng 1995 used the isotope analysis to survey the groundwater age he confirmed that the northern coast groundwater was relative young suggesting the seawater intrusion and the infiltration of salty water responsible for the salinization factor 2 characterizes by strong positive loading of fe and toc which accounts 19 29 of the total variance fig 8 b1 and b2 show the high score distribution of factor 2 in the north mid fan and in the south coast of aquifer 1 and 2 respectively the source of toc in aquifer 1 was infiltrated from the sanitary landfill leachate whereas the toc source in aquifer 2 was dissolved from the organic rich sediment high toc in groundwater creates a more reducing environment causing fe ii release to groundwater via reductive dissolution of fe oxides in sediment chen 2001 lawati et al 2012 fe oxides acts as an important electron acceptor to reductive dissolution and release of fe2 into groundwater factor 3 explains 11 4 of the total variance which associates with strong loading of as and hco3 and moderate loading of nh4 fig 8 c1 and c2 display that the high scores of factor 3 distribute along the middle sea coast and downstream area of the aquifer 2 in south bank of lanyang plain the mineralization of sedimentary organic matters results in bicarbonate production and subsequent dissolution of calcite rising the alkalinity the dissolved carbonate may influence the adsorption of trace metals by competing for sites on mineral surface forming carbonate complex that can either enhance or suppress adsorption and forming precipitates villalobos and leckie 2001 the mobilization of adsorbed as with dissolved bicarbonate has proposed to be one of the major causes of high levels of as in groundwater appelo et al 2002 wang et al 2007 denitrification reduced no3 to nh4 resulting in depletion of no3 and increase in nh4 leading to the release of as from as bearing fe oxyhydroxides into groundwater weng et al 2017 factor 3 is thus called the as enrichment factor factor 4 which has strong positive and negative loadings on eh and ph respectively explains 7 25 of the total variance it represents the geochemical characteristics of the study region suggesting a tendency of redox potential decrease from the proximal fan to the distal fan spatial distribution of factor 4 scores from positive to negative along the direction from west to east fig 8 d1 and d2 the inverse relationship between ph and eh controls the solubility of minerals eh ph diagrams are commonly applied to represent the dominate chemical species and mobility of metals in groundwater appelo and postma 1993 factor 4 is called the redox factor 3 4 sediment characteristics and distribution of elements as and fe contents in 393 core samples of nine drilling stations were analyzed fig 9 illustrates the vertical distribution of as and fe contents in north and south banks of lanyang plain low as and fe contents generally found in the proximal fan in both north w16 17 and south w11 banks of lanyang plain figs 10 and 11 show that as and fe contents in marine sequence were positively correlated but were poorly correlated in non marine sequence marine sequence consists of clay silt whereas non marine sequence comprises by sand gravel the small grain size of sediment materials provides a large surface area enabling high adsorption capacity of arsenic and resulting increased as enrichment in clay and silt moreover the marine formation contains fine clay with sea organisms that may have high arsenic content resulting from bioaccumulation and bioconcentration francesconi et al 1998 liu et al 2006 the moderate to low correlation between as and fe in marine sediment may be due to the fraction of silicate bound as and as retained by fe oxhydroxide norrs et al 2005 nine core samples from various intervals in the well screens of 3 drilling stations in the south bank of lanyang plain were selected from bulk analysis of elemental distribution by xrf table 5 the main chemical constituents of sediment incudes sio2 al2o3 fe2o3 k2o cao2 mgo and tio2 accounting for the majority of the samples weight manganese sulfur and arsenic were minor compositional elements ranging from 2 94 to 67 4 mg kg 348 3 to 4404 mg kg and 6 7 to 22 4 mg kg respectively among these samples as content was weekly correlated with mn r2 0 34 p 0 05 and fe r2 0 24 p 0 05 indicating as bearing fe mn phases were the predominant as host minerals in the sediment nine core samples from three drilling stations in the south bank of lanyang plain were selected for xps analyses each xps result for fe fig 12 comprises to curves 1 the experimental curve after smoothing and 2 curve of the fitted components the results of the fe2 p 3 2 lines can be fitted by multiple components six types of fe minerals were observed including a mixing valence type fe3o4 two reducing form types feo fes and three oxidizing form types fe2o3 feooh and fef3 in the non marine sequence feo and feooh are dominate minerals in the marine sequence the fe minerals distributions are complex the detection limit is such that the spectra of mn2 p 3 2 and asd5 2 yielded no information regarding specific mineral compounds of mn and as samples w11 2 and w07 2 of marine sequence were chosen for further investigation by sem eds fig 13 shows images of w11 2 and w07 2 by sem fig 13a and b and the spectra show fe s si o are main peaks and as is small peaks fig 13c and d the presence of colloid like fabrics shows amorphous or poorly crystalline fe as phase as coating on silicate grain due to co precipitation pyrite was found in both samples and was similar to that found in the southern choushui river alluvial fan taiwan lu et al 2010 where it was identified as the framboidal diagentic type liu et al 2013 akai et al 2004 3 5 aqueous speciation and saturation indices table 6 presents the ratios of the particular chemical species concentration to the total chemical element concentration calculated by phreeqc the major species of as c and s were haso3 hco3 and so4 2 respectively however the major fe species were fe2 fehco3 and feco3 because of the high alkalinity in the groundwater table 7 shows the mineral saturation index of 13 groundwater samples computed using phreeqc the groundwater was the supersaturated with respect to orpiment in 9 well samples moreover groundwater was oversaturated with respect to siderite and was close to saturate with respect to calcite it suggests that the elevated hco3 levels are not only controlled by the dissolution of the carbonate minerals in the lanyang aquifer high hco3 concentrations correlate with the levels of dissolved organic carbon toc up to 24 1 mg l in groundwater toc levels showed distinct trends of variation with as and fe concentrations no3 levels in groundwater are generally low with no correlation to as but nh4 correlated well with as co2 is the primary degraded product of organic matters causing carbonate minerals dissolved including the reduction of no3 as well as the reductive dissolution of fe oxyhdroxides in solid phase this explains that the fe and toc formed as the iron reduction factor and as associated with hco3 and nh4 as as enrichment factor in the factor analysis groundwater was under saturated with respect to anhydrite epsomite and magnesite the si values for most of iron minerals including goethite hematite magnetite siderite and pyrite were greater than zero indicating that these minerals may be precipitated the xps and sem eds results confirmed these findings the positive sis of pyrite 10 indicated the high potential for precipitation fe2 may be co precipitated with hs resulted in low hs the results of sem also showed that amorphous or poorly crystalline fe as phase in samples 11 2 and 7 2 were present 3 6 discussion factor analysis shows that the iron reduction factor and as enrichment factor both include nh4 with moderate loading these two factors consist of fe toc nh4 as and hco3 are generally responsible for moderately reducing environment and arsenic release to groundwater might be caused by mineralization or organic in reducing conditions liu et al 2003 lawati et al 2012 scores of factor 2 are distributed close to the landfill w31 and theme park w08 in the aquifer 1 the site was for traditional dumping which was operated from 1990 to 1999 and buried municipal waste with no impermeable liner the theme park is a popular scenic area and attracts more than one million tourists annually the anthropogenic organic pollutants infiltrate to groundwater likely causing the adsorbed as ions release from fe oxyhdroxide surface to the aquifer 1 however arsenic concentrations in aquifer 1 is less than those of in aquifer 2 due to the high as was accumulated in the marine formation generally in the suboxic to anoxic conditions the presence of dissolved fe corresponds to the dissolved as nh4 n and hco3 which are consistent with mechanism of reductive dissolution of fe oxyhydroxides via respiration of organic matter nickson et al 2000 mcarthur et al 2004 hco3 presents the local baseline that results from weathering oxygen consumption and nitrate reduction which is the major dissolved inorganic carbon dic nickson et al 2000 anawar et al 2004 respiration of dissolved organic carbon doc produces ammonia and co2 and latter may induce calcite dissolution harvey et al 2002 carbon isotopes 14c of dic bicarbonate in groundwater of lanyang plain was analyzed by peng 1995 indicating the groundwater is the mixture of invading fresh water with older resident water at mid fan and distal fan areas of lanyang plain and recharge from the western mountains are the primary source of groundwater in the aquifers young groundwater and surface water contain less bicarbonate while it is preponderantly high in old and reducing groundwater mcarthur et al 2001 the older dic can be oxidative product of doc that mobilized from sediment and invades to groundwater appelo et al 2002 indicates that sediment groundwater interface contains high dissolved bicarbonate content and as may be mobilized by displacement from sediment surface a poor correlation exists between fe and as in groundwater which may be caused by adsorption of fe ii onto solid surface or precipitation as fe ii or mixed valence solid nickson et al 2000 this study identifies various iron compounds by xps analysis anawar et al 2004 demonstrates bicarbonate ion exchange substitution may be another important process to as mobilization and may explain the poor correlation between aqueous as and fe phreeqc simulation indicates fe2 and fehco3 are primary species for iron and molar ratio of fehco3 increases with increasing depth based on geochemical modeling and further form siderite welch and lico 1998 groundwaters are supersaturated with respect to other iron minerals including hematite fe2o3 goethite feooh and magnetite fe3o4 high concentrations of hco3 are partially due to the moderately dissolving tendency of calcite and dolomite based on the geochemical modelling table 7 reductive dissolution of fe oxide minerals and the subsequent release of adsorbed and or co precipitated as are main causes of high as concentrations in groundwater under reducing conditions ahmed et al 2004 jia et al 2014 however gradual reductive dissolution of fe oxides could also allow re sorption of as released by this process onto the residual solid until the sorption capacity of the solid reached and or the solid is lost by dissolution mcarthur et al 2004 sracek et al 2018 the de coupling of as and fe in reducing aquifers is common and has been observed in many sites around the world where as is released as a consequence of redox processes including bangladesh west bengal assam in india cambodia and taiwan sracek et al 2018 as and fe contents of core samples in marine sequence were positively correlated marine sequence comprised clay silt and organic matter the as contents in marine sequence were generally higher than that of in non marine sequence liu et al 2006 moreover organic matter can strongly influence the solubility and mobility of as through redox reactions competitive adsorption desorption and complexation reactions suggesting that the organic matter is a redox driver and also one of the sources of as in groundwater anawar et al 2013 the presence of clay layer within the subsurface may thus increase in the as contamination in groundwater aquifer however the time for as release from clay layer to lower aquifer may require tens or hundreds years to complete under natural environment condition recently erban et al 2013 reported that as released from clayey aquitards caused by pumping induced land subsidence may take a decade or more to affect the as concentration in the lower aquifer in mekong delta vietnam their study provides a clue to investigate the time lag process of as released from clay layer to deep aquifers the nonlinear relation between sorbed and dissolved as is important factor for the mobility and transport of as in aquifer swartz et al 2004 the extent of as adsorbed onto fe oxyhydroxides is strongly influenced by as oxidation state and presence of inorganic and organic solutes hering et al 1997 arsenite and bicarbonate ions species become primary species for as and carbon respectively in groundwater at mid fan and distal fan area and their molar ratios rapidly increase with increasing depth based on phreeqc modelling in aquifer 1 mineralization of organic matter in sediment cause onset of reducing conditions and fe oxyhydroxides are the important acceptors of electrons providing for the mineralization of organic matter stumm and morgan 1996 this leads to dissolution of as rich feooh coating on soil particles or reduction of some of the adsorbed arsenate to arsenite and its release to groundwater however some arsenate may re adsorb onto feooh in aquifer 2 mineralization of organic matter progressively drives reductive dissolution of feooh and converts arsenate to arsenite mcarthur et al 2001 lee et al 2007a b additionally high levels of bicarbonate may contribute to limit adsorption sites of fe oxyhydroxides to sorb as harvey et al 2002 resulting in higher level of as many shallow alluvial aquifers in various parts of the world such as bangladesh west bengal india china and taiwan have the as contamination problems smedley and kinniburgh 2002 arsenic is generally derived from weathering of as rich minerals and then enter to the groundwater by reductive dissolution of fe oxhydroxides under anaerobic conditions in the alluvial systems nath et al 2008 wang et al 2007 reza et al 2011 conducted a comparative study on as in alluvial aquifers of bengal delta plain chianan plain and lanyang plain the as concentrations are generally higher in the chianan plain groundwater than those in the lanyang plain and bengal delta plain groundwater the mean as concentrations in bengal delta plain chianan plain and lanyang plain are 50 65 μg l 2 8 170 8 μg l n 20 393 μg l 9 704 μg l n 5 and 104 5 μg l 2 51 543 μg l n 6 respectively reza et al 2011 the reductive dissolution of as adsorbed mn oxyhydroxides is the most probable mechanism for mobilization of as in the bengal delta plain hasan et al 2007 however in the chianan plain and lanyang plain microbially mediated reductive dissolution of as adsorbed amorphous crystalline fe oxyhydroxides in organic rich sediments is the primary mechanism for releasing as to groundwater liu et al 2013 lee et al 2007a b arsenic organic matter and humic substance in the lanyang plain groundwater are comparatively lower than in the chianan plain groundwater and the bfd has not been reported in the lanyang plain high levels of as and humic substances may possibly play a critical role in causing the unique bfd in the chianan plain of southwestern taiwan reza et al 2011 4 conclusion thirty nine groundwater quality samples and 393 geological core samples with 5 m interval from 9 drilling stations of the lanyang plain taiwan were collected analyzed factor analysis fa was applied to wells with 16 hydrogeochemical parameters of 39 groundwater samples high resolution x ray photoelectron spectroscopy hr xps and scan electron microscope sem were used to determine the mineralogy of core samples fe and as contents of core sample were also analyzed factor analysis extracted four factors from the data for groundwater aquifers 1 and 2 these factors are mostly related to salinization and arsenic enrichment analytical results of fa suggest that the distribution of the salinization is in aquifer 1 and the main causes of saline groundwater are infiltration from fishpond salty water and sea water intrusion the leachate from the landfill site infiltrated to the aquifer 1 and caused reducing condition with high as concentrations in the local aquifer analytical results of core samples indicate that as and fe contents was correlated with location of clay layer in marine sequence and as adsorbed or co precipitated with fe oxyhydroxides the major minerals identified by xps and sem eds were goethite hematite magnetite pyrite and siderite agreeing with the si values calculated by phreeqc the arsenic enrichment in the reduced geological environment and the adsorption co precipitation of as on the fe oxyhydroxides may be used to interpret the possible processes of arsenic release to groundwater in the aquifers arsenic in sediments is released into groundwater primarily by the reductive dissolution of as bearing fe oxyhydroxides in reducing environment in the lanyang plain declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the ministry of sciences and technology of the republic of china for financially supporting this research under contracts nos 104 2313 b 002 026 my3 and 107 2313 b 002 019 my3 
6266,to manage a river sudden pollution incident a fundamental task is to quickly identify when where and how much pollutant was released the source identification of this kind of pollution incident due to instantaneously spilled pollutant from point source remains a challenging problem because of the limited observations and the ill posedness in this paper the ensemble kalman filter enkf is coupled with the backward location probability blp to improve its performance in identifying the river pollution source when applied in practice the proposed blp enkf method has two important advantages first it supports on line identification and can mitigate the limitation from shortage of observations in the sudden river pollution case second blp enkf performs much better than conventional enkf in terms of computation time because it can identify the pollution source without restart forecast process the effectiveness and efficiency of blp enkf is tested and demonstrated by a synthetic case study the case results show that the blp enkf can identify all the source parameters with a relative error approximately 1 00 or smaller its performance can be further improved with more accurate estimation of observational error or dispersion coefficient a real world case in ganjiang river further demonstrates the applicability of blp enkf in practice the pollution source is identified successfully with relative errors smaller than 3 0 for all the source parameters while the computation time is sharply shorted from 8 0 h of conventional enkf to 22 0 s of blp enkf keywords ensemble kalman filter backward location probability point source identification on line identification computation time list of symbols x location from the source m t time since the pollutant released s c pollutant concentration mg l q flow discharge m3 s a water area perpendicular to river flow direction m2 e dispersion coefficient in flow direction m2 s k first order decay coefficient s 1 c 0 instantaneous pollutant concentration at source location when released mg l l river length m z water level m s f energy slope x s possible location of the unknown pollution source m t d starting time of observations s t backward time s p backward location probability of x s cross section at time t 1 m 1 x d location of the observation cross section gauging section m m released pollutant mass kg θ state vector to be updated n number of ensemble members x o pollution source location m t o release time s τ perturbation to state vector α shrinkage factor typically restricted to 0 95 0 99 h smoothing factor with constraint of α 2 h 2 1 c t i forecasted concentration mg l c t o observed concentration mg l ε forecast model error e observational error r covariance of e k kalman gain vector 1 introduction sudden pollution incidents in rivers is a risky environmental problem because of its great uncertainty time urgency and severe consequences zhang and xin 2017 yao et al 2015 this kind of pollution incidents due to instantaneously spilled pollutant from point source are usually caused by industrial waste or transportation accidents occurring frequently in recent years yang et al 2016 wei et al 2016 when a pollution incident occurs signals are usually observed at downstream gauge stations thus the priority is to identify when time where location and how much pollutant total mass was released into the river xu and gómez hernández 2016 according to downstream observations addressing these questions is the primary purpose of source identification research which is crucial to pollution disposal and environment management in emergencies identifying the pollution source is an inverse problem of pollution simulation boano et al 2005 sun et al 2006 originating from the reconstruction of groundwater contaminant transport process this topic has been researched for nearly 40 years cheng and jia 2010 amirabdollahian and datta 2013 various methods for pollution source identification have been proposed and can be roughly classified into two types deterministic and stochastic atmadja and bagtzoglou 2001 michalak and kitanidis 2004 sun et al 2006 sun 2007 wang et al 2018 deterministic methods search for determinate solutions examples including the least squares ls approach gorelick et al 1983 alapati and kabala 2000 the tikhonov regularization tr approach skaggs and kabala 1994 akçelik et al 2003 and the quasi reversibility method skaggs and kabala 1995 stochastic methods in contrast are developed based on probability theory modeling the release history as a random process sun 2007 hazart et al 2014 one of the commonly used stochastic methods is the bayesian and markov chain monte carlo method mcmc hazart et al 2014 yang et al 2016 based on the bayesian inference theory and mcmc sampling technique this method converts pollution source identification into a reiterative computation for the posterior probability distribution of pollution source parameters another popular stochastic method is the adjoint state method neupauer and wilson 1999 michalak and kitanidis 2004 using the backward location probability to calculate the pollutant concentration this method can identify the pollution source efficiently ghane et al 2016 wang et al 2018 cheng and jia 2010 besides the geostatistically based method is widely used in the pollution source identification in groundwater michalak and kitanidis 2004 sun 2007 compared with the deterministic methods the stochastic methods can analyze the uncertainty of identification results more applicable to the problems with sparse prior information hazart et al 2014 yang et al 2016 more detailed reviews of pollution source identification methods can be found in the papers by atmadja and bagtzoglou 2001 michalak and kitanidis 2004 and yang et al 2016 in sudden river pollution case the concentration observations are usually very limited with real time updates before pollution disposal unfortunately all the above mentioned identification methods are off line thus resulting in poor efficiency when using the real time updating observations preis and ostfeld 2006 each time the data updated off line identification models have to be run again from the first observation otherwise waiting for enough observations however it s difficult to justify how many observations are enough to solve this issue the data assimilation method i e ensemble kalman filter enkf evensen 2003 has recently drawn much attention in the problem of pollution source identification xu and gómez hernández 2015 xu and gómez hernández 2016 zhang and huang 2017 jiang et al 2018 the enkf is known for its good performance and ease of implementation in real time parameter calibration and forecast correction reichle et al 2002 aanonsen et al 2009 when applied to solve inverse problems of pollution source identification the enkf is easy to be combined with different forecast model able to use the real time observations efficiently and account for uncertainties in identification results chen et al 2018 although the enkf is promising for its advantages as above mentioned to the best of our knowledge there is no application to the river pollution source identification for simultaneously identifying the pollution location release time and the released mass a critical deficiency makes it lose the priority in river case each time for state updated the restart process of concentration forecast from initial time is needed xu and gómez hernández 2018 chen et al 2018 this restart process solves the advection dispersion equation ade repeatedly leading to poor efficiency therefore improvements in computation time of enkf for the fast decision of pollution disposal are needed this is one of the motivations of this paper in adjoint method the backward location probability blp is used to calculate the pollutant concentration which avoids time consuming repetitive computation for each possible pollution source wang et al 2018 likewise this idea can be employed in the concentration forecast of enkf because the updated pollution source in enkf essentially corresponds to a group of parameters while the changes of these parameters result in the requirements of solving the ade from initial time besides the time consuming computation for different ensemble realizations can also be improved with blp therefore the blp is adopted to improve the calculation efficiency of enkf this paper proposes a performance improved enkf entitled blp enkf method in which the pollutant concentration forecast will be realized with the blp instead of solving the ade the blp enkf can overcome the time consuming deficiency of enkf while keeps its efficiency in using real time observations thus mitigating the limitation from shortage of observations in sudden pollution case the remainder of this paper is organized as follows an introduction of the proposed blp enkf is given first then a synthetic case is employed to test its effectiveness and efficiency after that a real world river case follows to examine its applicability in practice finally conclusions are drawn and presented 2 methodology 2 1 river flow and pollutant transport equations in rivers the pollutant transport process is simulated by the one dimensional ade expressed as follows 1 a c t q c x x e a c x k a c c x 0 0 0 x l c 0 t c 0 t 0 c x t x 0 x l t 0 where x is the location from the source m t is the time since pollutant released s c is the pollutant concentration mg l q is the flow discharge m3 s a is the water area perpendicular to river flow direction m2 e is the dispersion coefficient in flow direction m2 s k is the first order decay coefficient s 1 c 0 is the instantaneous concentration at source location when pollutant released mg l and l is the river length m the hydrodynamic variables q and a in eq 1 can be determined by a hydrodynamics model based on the saint venant equation as follows 2 a t q x 0 q t x q 2 a g a z x g a s f 0 where z is the water level m and s f is the energy slope the parameter e in eq 1 is evaluated by empirical equations or based on experiments this parameter is generally assumed to be a constant value ghane et al 2016 yang et al 2016 zhang and xin 2017 abderrezzak et al 2015 both eqs 1 and 2 are solved using a numerical method known as the finite difference method and the solutions have been justified see our previous work on bpm wang et al 2018 2 2 backward location probability backward location probability density function used in pollution source identification was originally derived by liu 1995 in the backward location probability model both the river pollutant concentration and the possible locations of pollution source can be described using probability density function the pollutant s transport along the river is defined as the forward process while the transport of pollution source location probability is defined as the backward process cheng and jia 2010 neupauer and wilson 2001 derived the adjoint state equation of eq 1 for the backward location probability as follows 3 a p t q p x s x s e a p x s k s a p 0 p x s t d 0 x 0 x s x d p x d t 0 t 0 p x s t d 1 p x s t x s 0 x s x d where x s is the possible location of unknown pollution source m t d is the starting time of observations s t is the backward time s p is the backward location probability of x s cross section at time t 1 m 1 and x d is the location of the observation cross section gauging section m the evolution of the backward process essentially follows the same physical law as the forward process and the forward pollutant concentration c x t can be estimated with the backward location probability p x s t which is determined by solving eq 3 as follows cheng and jia 2010 neupauer and wilson 2001 wang et al 2018 4 c x t m a p x s t where m is the released pollutant mass kg for each updated pollution source x 0 i i is a serial number of possible pollution sources in fig 1 eq 1 has to be solved with respect to c x t this repetitive and time consuming computation can be avoided by using the relationship in eq 4 because all the location probabilities p x s t can be determined after solving eq 3 only once for a specific gauging section therefore the eq 4 is a better alternative to the solution of eq 1 when forecasting the pollutant concentration 2 3 blp enkf 2 3 1 general framework of enkf enkf can address the nonlinear problem by propagating an ensemble of model realizations to represent the error covariance of filtering states evensen 2003 the enkf updates the prior ensembles with a linear combination of simulation and observation moradkhani et al 2005 the enkf operates sequentially by performing in turn a forecast step and then a filter update step for the identification of pollution source parameters the loop of enkf is as follows 2 3 1 1 initialization the pollution source is described by three independent parameters m for released pollutant mass x o for pollution source location and t o for release time these parameters constitute the initial state vector as follows 5 θ 0 i m x o t o 0 i 1 n where θ is the state vector to be updated n is the number of ensemble members greater than 50 and determined by balancing the assimilation accuracy and calculation efficiency evensen 2003 in this study all the initial ensemble samples were realized using the monte carlo method mc considering the available prior information regarding pollution source an initialization with uniform distribution was applied beven and binley 1992 xu and gómez hernández 2016 moradkhani et al 2005 2 3 1 2 calculation of the mean and covariance the mean and covariance of ensemble members are used for approximation as follows 6 θ t 1 1 n i 1 n θ t 1 i 7 var θ t 1 i 1 n 1 i 1 n θ t 1 i θ t 1 2 where the positive superscript represents the state vector after t 1 step calibration 2 3 1 3 parameter evolution it is assumed that the parameters update following a random walk and a small perturbation is introduced to the posterior distribution of each evolved parameter at each time step as follows 8 θ t i θ t 1 i τ t 1 i i 1 n where τ t 1 i is estimated by the covariance of θ t 1 i τ t 1 i n 0 var θ t 1 i and the negative superscript represents the state vector before t step calibration based on previous research a drawback is inevitably caused by adding random perturbations to the posterior distribution at each time step this artificial perturbation may cause over dispersion of parameter samples loss of information between updating time steps and a diffused posterior spread of parameters xie and zhang 2013 to address this problem the kernel smoothing of parameter samples is employed west 1993 liu 2000 xie and zhang 2013 as follows 9 θ t i α θ t 1 i 1 α θ t 1 τ t 1 i i 1 n 10 τ t 1 i n 0 h 2 v a r θ t 1 i where α is the shrinkage factor typically restricted to 0 95 0 99 and h is the smoothing factor with constraint of α 2 h 2 1 2 3 1 4 concentration forecast in conventional enkf each time the pollution source parameters updated the state eq 1 needs to be re solved from initial time xu and gómez hernández 2016 chen et al 2018 once the parameter vector θ i updated the pollution transport process should be evolved from the beginning as follows 11 c t i φ c 0 o θ t i ε t i i 1 n where c t i is the forecasted concentration mg l and ε t i is the forecast model error with the blp the forecast model in eq 11 can be substituted as follows 12 p t i φ θ t i i 1 n 13 c t i m t i p t i ε t i i 1 n in eqs 12 and 13 the c t i is forecasted directly using the updating parameter and the pre determined backward location probability no longer relied on eq 1 and initial state 2 3 1 5 parameter updating updating the ensemble parameter members can be completed according to the standard kalman filter equation as follows 14 θ t i θ t i k t c t o e t i c t i i 1 n e t i n 0 r t where c t o is the observed concentration mg l e t i is the estimated observational error r t is the covariance of e t i and the kalman gain vector k t can be obtained as follows 15 k t cov θ t c t cov c t c t r t 1 2 3 1 6 looping and termination going back to step 2 it is repeated until all the observations have been assimilated 2 3 2 implementation of blp enkf in source identification process the usage of blp for concentration forecast can make the identification not blocked by the restart problem the identification process with blp enkf includes four steps and its flowchart is shown in fig 2 step 1 according to the observations of flow and pollutant concentration the backward location probability is first determined by solving eqs 2 and 3 step 2 on basis of the site investigation the prior ranges of pollution source parameters are estimated wang et al 2018 and the initial ensembles are randomly generated from uniform distributions using mc step 3 the data assimilation is implemented following the listed steps in section 2 3 1 step 4 termination of identification process the data assimilation is repeated until the evolution gets convergent 3 synthetic case study 3 1 case description synthetic examples are usually used in model tests before applications to real world cases especially when the real world observed data are poor sun et al 2006 ghane et al 2016 fig 3 shows a straight river with length of over 8 km the details of this experimental river are as follows a bottom width of 67 5 m a side slope of 2 5 a longitudinal slope of 0 00015 a roughness of 0 027 a dispersion coefficient of 6 4 m2 s and a first order decay coefficient of 0 the flow field is steady with a discharge of 50 m3 s and a depth of 3 m at the gauging cross section a case of sudden pollution released into the river will be investigated before the tests the pollutant concentration is simulated synthetically using the river flow and pollutant transport equations provided in section 2 1 the observational error is considered and drawn from a gaussian distribution with variance equal to 0 012 mg l 2 when the pollutant concentration exceeds 0 05 mg l the observation is recorded every 5 min for use with source identification the details of the pollution source are listed in table 1 using mc a total of 500 initial ensemble members are generated from uniform distributions in table 1 i e m u 0 2000 kg x u 0 7 5 km and t 0 u 0 5 10 h the incident is constructed with the true source parameters in table 1 and the observed concentration with artificial errors plays out in fig 4 3 2 identification results implementing the identification ten times the sudden pollution source is identified as shown in tables 2 and 3 the ensemble mean value of each test is listed in table 2 because of random perturbations the identification result of each test slightly varies here averaging the tests greatly reduces the uncertainties and in turn improves the accuracy the relative identification errors in table 3 are approximately 1 00 or smaller which demonstrates a high accuracy in table 2 a closer location to the gauging station corresponds to a later release time which indicates the parameters of source location and release time are related to each other compared with the source location and release time the identification error of released mass is relatively higher caused by its relative insensitivity in calculating pollutant concentration the time evolution of ensemble members and their mean value taking test 1 as an example is shown in fig 5 it is clearly shown in fig 5 that the evolution of all the parameters get convergent after almost 120 steps fig 5 shows how the ensemble members gathering together from a completely random state the suspect range is narrowed and the ensemble mean finally moves to the target value indicating that the blp enkf can effectively identify the point source of a sudden pollution incident however if the true parameters in fig 5 are not available always in real world case the identification based simulation is an alternative for verification using the identified pollution source parameters the identification results can be verified by the forward concentration simulation fig 6 shows a good fitting relationship much close to 1 1 line between the identification based simulation and the observation of pollutant concentration at gauging station besides the mean relative error mre of identification based simulation is only 3 42 and the nash sutcliffe efficiency nse nash and sutcliffe 1970 is 0 99 which further verify that the evolution converges to the true value 3 3 performance and uncertainty analysis 3 3 1 uncertainty from observational error estimation the observational error e t in eq 14 is assumed to be gaussian distributed with standard deviation equal to that of the actual observational error however in a real world case it is impossible to obtain the exact observational error thus uncertainty analysis was conducted using different estimated observational errors as shown in figs 7 and 8 the relative error shown in fig 7 represents the identification accuracy and the standard deviation of ten repeated tests shown in fig 8 represents the stability or fluctuation of identification results comparing fig 7a with fig 7b and fig 7c a good variation consistency of the relative identification error can be found for an increase in observational error the decreasing and then increasing trend of relative identification errors plays out when the standard deviation of observational error is near 0 01 the identification result is optimal a similar optimal point can also be seen in fig 8 where the stability of identification result is shown according to figs 7 and 8 it can be concluded that the uncertainty from observational error estimation has significant effects on identification result the more accurate estimation of observational error the better identification result thus improving estimation of observational error is helpful for point pollution source identification 3 3 2 effects of initial parameter distribution in the afore mentioned tests the initial ensembles of each parameter are generated with a uniform distribution this uniform distribution is encouraged in parameter identification for the case of poor prior information zhou et al 2011 however enkf works better when the parameters follow a gaussian distribution xu and gómez hernández 2015 the manner in which the initial parameter distribution affects the identification results is not clear thus a comparison between the identification results with uniform distributed and gaussian distributed initial members was conducted the gaussian distributed initial members following distributions m n 1000 50 0 2 kg x n 4 25 2 21 5 2 km and t 0 n 5 25 2 62 5 2 h the comparison results are shown in table 4 the difference in table 4 is not significant when uniform distributed and gaussian distributed initial members are employed further the updating process of posteriori distribution of the released mass in test 1 is shown in fig 9 the posteriori distribution can gradually converge to the gaussian distribution from a uniform distribution the two updating processes get very close to each other after 25 steps the ensemble members gather together and then converge to the target value both table 4 and fig 9 imply that the bp enkf is not sensitive to the initial distribution 3 3 3 effects of ensemble size ensemble size is a key factor in identification efficiency a reasonable ensemble size can balance the model accuracy and efficiency the effects of ensemble size are analyzed as shown in figs 10 and 11 further to determine a proper size balancing the accuracy and efficiency how the computational efficiency varies with different ensemble size is investigated in table 5 both accuracy and stability of the identification results decrease when the ensemble size expands until to 500 when the size is larger than 500 the effects become very slight therefore when the ensemble size increases from 500 to 1000 the largely increased computation time only achieves slightly improved accuracy for all parameters this result fully supports the employed ensemble size of 500 3 3 4 effects from estimation accuracy of dispersion coefficient a common assumption in the pollution source identification is that the dispersion coefficient which is usually estimated with empirical formulations koussis and rodríguez mirasol 1998 or field experiments is a pre determined constant however it is impossible to determine the dispersion coefficient accurately therefore assessing the effects from estimation accuracy of dispersion coefficient is needed in figs 12 and 13 the relative identification errors of source location and release time reach to 60 when the dispersion coefficient is wrongly estimated to be 15 0 the identification stability gets poor when the dispersion coefficient is wrongly estimated to be 0 5 the large deviation of dispersion coefficient is apparently bad for identification nonetheless if the dispersion coefficient fluctuates in the range from 4 0 to 8 0 corresponding to a relative estimation error from 37 5 to 25 0 the identification is acceptable with a relative error smaller than 15 0 in this range the standard deviation of repeated identification is very close to the case of true dispersion coefficient 3 3 5 effects of flow rate the flow field determined by eq 2 is fundamental for the calculation of backward location probability the performance of the blp enkf under changing flow rate is shown in figs 14 and 15 when the flow rate changes from 5 m3 s to 200 m3 s all the relative identification errors are not larger than 4 while a slight decrease tendency can be found in the standard deviation of repeated identification in fig 15 although the smaller flow rate induces more uncertainty the performance of bp enkf is always good in different cases and not limited by flow rate 3 3 6 comparison with previous methods the blp enkf is expected to be more time saving than conventional enkf this advantage is demonstrated with a comparison shown in table 6 compared with the conventional enkf the proposed blp enkf achieves a significant reduction in computation time from 44 7 min to 8 0 s which can make the disposal decision more rapid in sudden pollution incidents this improvement is attributed to the usage of backward location probability in concentration forecast skipping the restart process and avoiding repetitively solving the ade for each ensemble realization the identification results obtained from other two methods i e the adjoint method and bayesian mcmc are also compared in table 6 different method has different parameters for example ensemble size for enkf and blp enkf number of optimization iterations for adjoint and bayesian mcmc the four groups of identification results are based on a balance of accuracy and computation time wang et al 2018 in terms of the accuracy all four methods achieve an identified level of relative error and standard deviation although the result from bayesian mcmc is slightly worse particularly a better accuracy in source location and release time corresponds to a worse released mass for the four group of results when the computation time is considered only the blp enkf and adjoint method stand out because both of them adopt the backward location probability to calculate pollutant concentration however the adjoint method is an off line method when compared with blp enkf the adjoint method is relatively inflexible and low efficient in using the real time updating observations in sudden pollution incidents besides the adjoint method applied in river pollution source identification may rely on an optimization method when an objective function is employed cheng and jia 2010 ghane et al 2016 wang et al 2018 but no optimization is needed in the identification process of blp enkf xu and gómez hernández 2016 4 application to a real world river case the south tributary at end of the ganjiang river is used for the real world case analysis the river flows through an industrial area of nanchang city in jiangxi province and is at high risk of pollution from sewage treatment plants this case considers a scenario where soluble pollutants are suddenly released from a potential source as shown in fig 16 the associated data are as follows 1 the river has a length of 21 4 km fig 16c 2 the point pollution source is located at 2 0 km away from the river entrance and the pollutant was released at 19 00 with mass of 1000 kg 3 the pollution gauging station chucha is located at 21 4 km away from the river entrance and continuous concentration observations were recorded on the third day from 19 30 fig 17 as no concentration data for such real pollution source incident had been documented the water quality data were simulated with mike11 wang et al 2018 4 the river flow is typically non uniform with a discharge of 250 m3 s when this incident occurred 5 roughness coefficient is 0 03 longitudinal dispersion coefficient is 6 5 m2 s and first order decay coefficient is 0 6 topographic data were obtained as shown in fig 16c red points represent position in real world case observational concentration is affected by various noises thus a random observational error of gaussian distribution is usually added to perturb the observed concentration and evaluate the model performance cheng and jia 2010 mahar and datta 2001 xu and gómez hernández 2016 the variance of observational error in fig 17 is equal to 0 0012 mg l 2 using mc a total of 500 initial ensemble members are generated from uniform distributions m u 0 2000 kg x u 0 20 km and t 0 u 1 96 h after ten times implementation of blp enkf the pollution source is identified as shown in table 7 in this real world river case the flow and pollutant transport processes are more complex than that in the synthetic cases because the distance between pollution source and gauging station is considerably long for the pollutant diffusion the difference of location probability within unit length along the river gets much smaller than that in synthetic cases this relatively small difference reduces the identifiability of different suspect pollution source location thus resulting in a larger fluctuation range standard deviation in table 7 for the identified source location and release time nevertheless the pollution source has been identified successfully with relative errors smaller than 3 0 for all parameters the identification results in table 7 are certainly useful in the practice of pollution emergency disposal in this case the computation time of blp enkf and conventional enkf are 22 s and 8 h respectively as the flow and release history get more complex the improved efficiency by blp enkf is more significant this comparison result further demonstrates the time saving advantage of blp enkf 5 conclusions this paper proposes an effective method to improve the performance of enkf in point source identification of sudden river pollution to the best of our knowledge the blp is first used in the enkf to solve an inverse problem applied in practice the proposed blp enkf method has two important advantages first it supports on line identification thus can mitigate the limitation from shortage of observations in the sudden river pollution case second blp enkf performs much better than conventional enkf in terms of computation time because it can identify the pollution source without restart forecast process when tested in a synthetic case study the blp enkf obtains all the source information with a relative error approximately 1 00 or smaller the uncertainty of the proposed method is mainly attributed to the observational error and the dispersion coefficient estimation more accurate estimation of observational error and dispersion coefficient can help in obtaining the source parameters with smaller errors and fluctuation ranges an ensemble size larger than 500 makes little influence on the identification accuracy but increasing the computation time significantly in additions the bp enkf is not sensitive to the initial distributions of ensemble members and not limited by flow rate compared with conventional enkf the advantage of blp enkf is evident in terms of identification time compared to the adjoint method the blp enkf can use the real time observations more efficiently without optimization process applied in a real world river case in ganjiang river the bp enkf identifies all the pollution source parameters with relative errors smaller than 3 0 and using much less time than conventional enkf this real world river case further verifies the efficiency and applicability of blp enkf in practice although the blp enkf is an on line and effective point pollution source identification method to be proposed more research is still needed in real world sudden pollution incidents much information may be unknown or limited particularly regarding the dispersion coefficient and the total mass of released pollutant thus further work should be conducted to improve the performance and adaptability of blp enkf and to improve this method for jointly identifying the pollution source and the dispersion coefficient the uncertainty of blp enkf needs to be further analyzed by applying it to more real world cases the extension for the continuous pollution cases and multi point cases is also expected in the following research declaration of competing interest the authors declare no conflicts of interest acknowledgments this research was funded by the national key research and development program of china 2017yfc0404403 and 2016yfc0401302 and the national natural science foundation of china 91747208 and 51579129 
6266,to manage a river sudden pollution incident a fundamental task is to quickly identify when where and how much pollutant was released the source identification of this kind of pollution incident due to instantaneously spilled pollutant from point source remains a challenging problem because of the limited observations and the ill posedness in this paper the ensemble kalman filter enkf is coupled with the backward location probability blp to improve its performance in identifying the river pollution source when applied in practice the proposed blp enkf method has two important advantages first it supports on line identification and can mitigate the limitation from shortage of observations in the sudden river pollution case second blp enkf performs much better than conventional enkf in terms of computation time because it can identify the pollution source without restart forecast process the effectiveness and efficiency of blp enkf is tested and demonstrated by a synthetic case study the case results show that the blp enkf can identify all the source parameters with a relative error approximately 1 00 or smaller its performance can be further improved with more accurate estimation of observational error or dispersion coefficient a real world case in ganjiang river further demonstrates the applicability of blp enkf in practice the pollution source is identified successfully with relative errors smaller than 3 0 for all the source parameters while the computation time is sharply shorted from 8 0 h of conventional enkf to 22 0 s of blp enkf keywords ensemble kalman filter backward location probability point source identification on line identification computation time list of symbols x location from the source m t time since the pollutant released s c pollutant concentration mg l q flow discharge m3 s a water area perpendicular to river flow direction m2 e dispersion coefficient in flow direction m2 s k first order decay coefficient s 1 c 0 instantaneous pollutant concentration at source location when released mg l l river length m z water level m s f energy slope x s possible location of the unknown pollution source m t d starting time of observations s t backward time s p backward location probability of x s cross section at time t 1 m 1 x d location of the observation cross section gauging section m m released pollutant mass kg θ state vector to be updated n number of ensemble members x o pollution source location m t o release time s τ perturbation to state vector α shrinkage factor typically restricted to 0 95 0 99 h smoothing factor with constraint of α 2 h 2 1 c t i forecasted concentration mg l c t o observed concentration mg l ε forecast model error e observational error r covariance of e k kalman gain vector 1 introduction sudden pollution incidents in rivers is a risky environmental problem because of its great uncertainty time urgency and severe consequences zhang and xin 2017 yao et al 2015 this kind of pollution incidents due to instantaneously spilled pollutant from point source are usually caused by industrial waste or transportation accidents occurring frequently in recent years yang et al 2016 wei et al 2016 when a pollution incident occurs signals are usually observed at downstream gauge stations thus the priority is to identify when time where location and how much pollutant total mass was released into the river xu and gómez hernández 2016 according to downstream observations addressing these questions is the primary purpose of source identification research which is crucial to pollution disposal and environment management in emergencies identifying the pollution source is an inverse problem of pollution simulation boano et al 2005 sun et al 2006 originating from the reconstruction of groundwater contaminant transport process this topic has been researched for nearly 40 years cheng and jia 2010 amirabdollahian and datta 2013 various methods for pollution source identification have been proposed and can be roughly classified into two types deterministic and stochastic atmadja and bagtzoglou 2001 michalak and kitanidis 2004 sun et al 2006 sun 2007 wang et al 2018 deterministic methods search for determinate solutions examples including the least squares ls approach gorelick et al 1983 alapati and kabala 2000 the tikhonov regularization tr approach skaggs and kabala 1994 akçelik et al 2003 and the quasi reversibility method skaggs and kabala 1995 stochastic methods in contrast are developed based on probability theory modeling the release history as a random process sun 2007 hazart et al 2014 one of the commonly used stochastic methods is the bayesian and markov chain monte carlo method mcmc hazart et al 2014 yang et al 2016 based on the bayesian inference theory and mcmc sampling technique this method converts pollution source identification into a reiterative computation for the posterior probability distribution of pollution source parameters another popular stochastic method is the adjoint state method neupauer and wilson 1999 michalak and kitanidis 2004 using the backward location probability to calculate the pollutant concentration this method can identify the pollution source efficiently ghane et al 2016 wang et al 2018 cheng and jia 2010 besides the geostatistically based method is widely used in the pollution source identification in groundwater michalak and kitanidis 2004 sun 2007 compared with the deterministic methods the stochastic methods can analyze the uncertainty of identification results more applicable to the problems with sparse prior information hazart et al 2014 yang et al 2016 more detailed reviews of pollution source identification methods can be found in the papers by atmadja and bagtzoglou 2001 michalak and kitanidis 2004 and yang et al 2016 in sudden river pollution case the concentration observations are usually very limited with real time updates before pollution disposal unfortunately all the above mentioned identification methods are off line thus resulting in poor efficiency when using the real time updating observations preis and ostfeld 2006 each time the data updated off line identification models have to be run again from the first observation otherwise waiting for enough observations however it s difficult to justify how many observations are enough to solve this issue the data assimilation method i e ensemble kalman filter enkf evensen 2003 has recently drawn much attention in the problem of pollution source identification xu and gómez hernández 2015 xu and gómez hernández 2016 zhang and huang 2017 jiang et al 2018 the enkf is known for its good performance and ease of implementation in real time parameter calibration and forecast correction reichle et al 2002 aanonsen et al 2009 when applied to solve inverse problems of pollution source identification the enkf is easy to be combined with different forecast model able to use the real time observations efficiently and account for uncertainties in identification results chen et al 2018 although the enkf is promising for its advantages as above mentioned to the best of our knowledge there is no application to the river pollution source identification for simultaneously identifying the pollution location release time and the released mass a critical deficiency makes it lose the priority in river case each time for state updated the restart process of concentration forecast from initial time is needed xu and gómez hernández 2018 chen et al 2018 this restart process solves the advection dispersion equation ade repeatedly leading to poor efficiency therefore improvements in computation time of enkf for the fast decision of pollution disposal are needed this is one of the motivations of this paper in adjoint method the backward location probability blp is used to calculate the pollutant concentration which avoids time consuming repetitive computation for each possible pollution source wang et al 2018 likewise this idea can be employed in the concentration forecast of enkf because the updated pollution source in enkf essentially corresponds to a group of parameters while the changes of these parameters result in the requirements of solving the ade from initial time besides the time consuming computation for different ensemble realizations can also be improved with blp therefore the blp is adopted to improve the calculation efficiency of enkf this paper proposes a performance improved enkf entitled blp enkf method in which the pollutant concentration forecast will be realized with the blp instead of solving the ade the blp enkf can overcome the time consuming deficiency of enkf while keeps its efficiency in using real time observations thus mitigating the limitation from shortage of observations in sudden pollution case the remainder of this paper is organized as follows an introduction of the proposed blp enkf is given first then a synthetic case is employed to test its effectiveness and efficiency after that a real world river case follows to examine its applicability in practice finally conclusions are drawn and presented 2 methodology 2 1 river flow and pollutant transport equations in rivers the pollutant transport process is simulated by the one dimensional ade expressed as follows 1 a c t q c x x e a c x k a c c x 0 0 0 x l c 0 t c 0 t 0 c x t x 0 x l t 0 where x is the location from the source m t is the time since pollutant released s c is the pollutant concentration mg l q is the flow discharge m3 s a is the water area perpendicular to river flow direction m2 e is the dispersion coefficient in flow direction m2 s k is the first order decay coefficient s 1 c 0 is the instantaneous concentration at source location when pollutant released mg l and l is the river length m the hydrodynamic variables q and a in eq 1 can be determined by a hydrodynamics model based on the saint venant equation as follows 2 a t q x 0 q t x q 2 a g a z x g a s f 0 where z is the water level m and s f is the energy slope the parameter e in eq 1 is evaluated by empirical equations or based on experiments this parameter is generally assumed to be a constant value ghane et al 2016 yang et al 2016 zhang and xin 2017 abderrezzak et al 2015 both eqs 1 and 2 are solved using a numerical method known as the finite difference method and the solutions have been justified see our previous work on bpm wang et al 2018 2 2 backward location probability backward location probability density function used in pollution source identification was originally derived by liu 1995 in the backward location probability model both the river pollutant concentration and the possible locations of pollution source can be described using probability density function the pollutant s transport along the river is defined as the forward process while the transport of pollution source location probability is defined as the backward process cheng and jia 2010 neupauer and wilson 2001 derived the adjoint state equation of eq 1 for the backward location probability as follows 3 a p t q p x s x s e a p x s k s a p 0 p x s t d 0 x 0 x s x d p x d t 0 t 0 p x s t d 1 p x s t x s 0 x s x d where x s is the possible location of unknown pollution source m t d is the starting time of observations s t is the backward time s p is the backward location probability of x s cross section at time t 1 m 1 and x d is the location of the observation cross section gauging section m the evolution of the backward process essentially follows the same physical law as the forward process and the forward pollutant concentration c x t can be estimated with the backward location probability p x s t which is determined by solving eq 3 as follows cheng and jia 2010 neupauer and wilson 2001 wang et al 2018 4 c x t m a p x s t where m is the released pollutant mass kg for each updated pollution source x 0 i i is a serial number of possible pollution sources in fig 1 eq 1 has to be solved with respect to c x t this repetitive and time consuming computation can be avoided by using the relationship in eq 4 because all the location probabilities p x s t can be determined after solving eq 3 only once for a specific gauging section therefore the eq 4 is a better alternative to the solution of eq 1 when forecasting the pollutant concentration 2 3 blp enkf 2 3 1 general framework of enkf enkf can address the nonlinear problem by propagating an ensemble of model realizations to represent the error covariance of filtering states evensen 2003 the enkf updates the prior ensembles with a linear combination of simulation and observation moradkhani et al 2005 the enkf operates sequentially by performing in turn a forecast step and then a filter update step for the identification of pollution source parameters the loop of enkf is as follows 2 3 1 1 initialization the pollution source is described by three independent parameters m for released pollutant mass x o for pollution source location and t o for release time these parameters constitute the initial state vector as follows 5 θ 0 i m x o t o 0 i 1 n where θ is the state vector to be updated n is the number of ensemble members greater than 50 and determined by balancing the assimilation accuracy and calculation efficiency evensen 2003 in this study all the initial ensemble samples were realized using the monte carlo method mc considering the available prior information regarding pollution source an initialization with uniform distribution was applied beven and binley 1992 xu and gómez hernández 2016 moradkhani et al 2005 2 3 1 2 calculation of the mean and covariance the mean and covariance of ensemble members are used for approximation as follows 6 θ t 1 1 n i 1 n θ t 1 i 7 var θ t 1 i 1 n 1 i 1 n θ t 1 i θ t 1 2 where the positive superscript represents the state vector after t 1 step calibration 2 3 1 3 parameter evolution it is assumed that the parameters update following a random walk and a small perturbation is introduced to the posterior distribution of each evolved parameter at each time step as follows 8 θ t i θ t 1 i τ t 1 i i 1 n where τ t 1 i is estimated by the covariance of θ t 1 i τ t 1 i n 0 var θ t 1 i and the negative superscript represents the state vector before t step calibration based on previous research a drawback is inevitably caused by adding random perturbations to the posterior distribution at each time step this artificial perturbation may cause over dispersion of parameter samples loss of information between updating time steps and a diffused posterior spread of parameters xie and zhang 2013 to address this problem the kernel smoothing of parameter samples is employed west 1993 liu 2000 xie and zhang 2013 as follows 9 θ t i α θ t 1 i 1 α θ t 1 τ t 1 i i 1 n 10 τ t 1 i n 0 h 2 v a r θ t 1 i where α is the shrinkage factor typically restricted to 0 95 0 99 and h is the smoothing factor with constraint of α 2 h 2 1 2 3 1 4 concentration forecast in conventional enkf each time the pollution source parameters updated the state eq 1 needs to be re solved from initial time xu and gómez hernández 2016 chen et al 2018 once the parameter vector θ i updated the pollution transport process should be evolved from the beginning as follows 11 c t i φ c 0 o θ t i ε t i i 1 n where c t i is the forecasted concentration mg l and ε t i is the forecast model error with the blp the forecast model in eq 11 can be substituted as follows 12 p t i φ θ t i i 1 n 13 c t i m t i p t i ε t i i 1 n in eqs 12 and 13 the c t i is forecasted directly using the updating parameter and the pre determined backward location probability no longer relied on eq 1 and initial state 2 3 1 5 parameter updating updating the ensemble parameter members can be completed according to the standard kalman filter equation as follows 14 θ t i θ t i k t c t o e t i c t i i 1 n e t i n 0 r t where c t o is the observed concentration mg l e t i is the estimated observational error r t is the covariance of e t i and the kalman gain vector k t can be obtained as follows 15 k t cov θ t c t cov c t c t r t 1 2 3 1 6 looping and termination going back to step 2 it is repeated until all the observations have been assimilated 2 3 2 implementation of blp enkf in source identification process the usage of blp for concentration forecast can make the identification not blocked by the restart problem the identification process with blp enkf includes four steps and its flowchart is shown in fig 2 step 1 according to the observations of flow and pollutant concentration the backward location probability is first determined by solving eqs 2 and 3 step 2 on basis of the site investigation the prior ranges of pollution source parameters are estimated wang et al 2018 and the initial ensembles are randomly generated from uniform distributions using mc step 3 the data assimilation is implemented following the listed steps in section 2 3 1 step 4 termination of identification process the data assimilation is repeated until the evolution gets convergent 3 synthetic case study 3 1 case description synthetic examples are usually used in model tests before applications to real world cases especially when the real world observed data are poor sun et al 2006 ghane et al 2016 fig 3 shows a straight river with length of over 8 km the details of this experimental river are as follows a bottom width of 67 5 m a side slope of 2 5 a longitudinal slope of 0 00015 a roughness of 0 027 a dispersion coefficient of 6 4 m2 s and a first order decay coefficient of 0 the flow field is steady with a discharge of 50 m3 s and a depth of 3 m at the gauging cross section a case of sudden pollution released into the river will be investigated before the tests the pollutant concentration is simulated synthetically using the river flow and pollutant transport equations provided in section 2 1 the observational error is considered and drawn from a gaussian distribution with variance equal to 0 012 mg l 2 when the pollutant concentration exceeds 0 05 mg l the observation is recorded every 5 min for use with source identification the details of the pollution source are listed in table 1 using mc a total of 500 initial ensemble members are generated from uniform distributions in table 1 i e m u 0 2000 kg x u 0 7 5 km and t 0 u 0 5 10 h the incident is constructed with the true source parameters in table 1 and the observed concentration with artificial errors plays out in fig 4 3 2 identification results implementing the identification ten times the sudden pollution source is identified as shown in tables 2 and 3 the ensemble mean value of each test is listed in table 2 because of random perturbations the identification result of each test slightly varies here averaging the tests greatly reduces the uncertainties and in turn improves the accuracy the relative identification errors in table 3 are approximately 1 00 or smaller which demonstrates a high accuracy in table 2 a closer location to the gauging station corresponds to a later release time which indicates the parameters of source location and release time are related to each other compared with the source location and release time the identification error of released mass is relatively higher caused by its relative insensitivity in calculating pollutant concentration the time evolution of ensemble members and their mean value taking test 1 as an example is shown in fig 5 it is clearly shown in fig 5 that the evolution of all the parameters get convergent after almost 120 steps fig 5 shows how the ensemble members gathering together from a completely random state the suspect range is narrowed and the ensemble mean finally moves to the target value indicating that the blp enkf can effectively identify the point source of a sudden pollution incident however if the true parameters in fig 5 are not available always in real world case the identification based simulation is an alternative for verification using the identified pollution source parameters the identification results can be verified by the forward concentration simulation fig 6 shows a good fitting relationship much close to 1 1 line between the identification based simulation and the observation of pollutant concentration at gauging station besides the mean relative error mre of identification based simulation is only 3 42 and the nash sutcliffe efficiency nse nash and sutcliffe 1970 is 0 99 which further verify that the evolution converges to the true value 3 3 performance and uncertainty analysis 3 3 1 uncertainty from observational error estimation the observational error e t in eq 14 is assumed to be gaussian distributed with standard deviation equal to that of the actual observational error however in a real world case it is impossible to obtain the exact observational error thus uncertainty analysis was conducted using different estimated observational errors as shown in figs 7 and 8 the relative error shown in fig 7 represents the identification accuracy and the standard deviation of ten repeated tests shown in fig 8 represents the stability or fluctuation of identification results comparing fig 7a with fig 7b and fig 7c a good variation consistency of the relative identification error can be found for an increase in observational error the decreasing and then increasing trend of relative identification errors plays out when the standard deviation of observational error is near 0 01 the identification result is optimal a similar optimal point can also be seen in fig 8 where the stability of identification result is shown according to figs 7 and 8 it can be concluded that the uncertainty from observational error estimation has significant effects on identification result the more accurate estimation of observational error the better identification result thus improving estimation of observational error is helpful for point pollution source identification 3 3 2 effects of initial parameter distribution in the afore mentioned tests the initial ensembles of each parameter are generated with a uniform distribution this uniform distribution is encouraged in parameter identification for the case of poor prior information zhou et al 2011 however enkf works better when the parameters follow a gaussian distribution xu and gómez hernández 2015 the manner in which the initial parameter distribution affects the identification results is not clear thus a comparison between the identification results with uniform distributed and gaussian distributed initial members was conducted the gaussian distributed initial members following distributions m n 1000 50 0 2 kg x n 4 25 2 21 5 2 km and t 0 n 5 25 2 62 5 2 h the comparison results are shown in table 4 the difference in table 4 is not significant when uniform distributed and gaussian distributed initial members are employed further the updating process of posteriori distribution of the released mass in test 1 is shown in fig 9 the posteriori distribution can gradually converge to the gaussian distribution from a uniform distribution the two updating processes get very close to each other after 25 steps the ensemble members gather together and then converge to the target value both table 4 and fig 9 imply that the bp enkf is not sensitive to the initial distribution 3 3 3 effects of ensemble size ensemble size is a key factor in identification efficiency a reasonable ensemble size can balance the model accuracy and efficiency the effects of ensemble size are analyzed as shown in figs 10 and 11 further to determine a proper size balancing the accuracy and efficiency how the computational efficiency varies with different ensemble size is investigated in table 5 both accuracy and stability of the identification results decrease when the ensemble size expands until to 500 when the size is larger than 500 the effects become very slight therefore when the ensemble size increases from 500 to 1000 the largely increased computation time only achieves slightly improved accuracy for all parameters this result fully supports the employed ensemble size of 500 3 3 4 effects from estimation accuracy of dispersion coefficient a common assumption in the pollution source identification is that the dispersion coefficient which is usually estimated with empirical formulations koussis and rodríguez mirasol 1998 or field experiments is a pre determined constant however it is impossible to determine the dispersion coefficient accurately therefore assessing the effects from estimation accuracy of dispersion coefficient is needed in figs 12 and 13 the relative identification errors of source location and release time reach to 60 when the dispersion coefficient is wrongly estimated to be 15 0 the identification stability gets poor when the dispersion coefficient is wrongly estimated to be 0 5 the large deviation of dispersion coefficient is apparently bad for identification nonetheless if the dispersion coefficient fluctuates in the range from 4 0 to 8 0 corresponding to a relative estimation error from 37 5 to 25 0 the identification is acceptable with a relative error smaller than 15 0 in this range the standard deviation of repeated identification is very close to the case of true dispersion coefficient 3 3 5 effects of flow rate the flow field determined by eq 2 is fundamental for the calculation of backward location probability the performance of the blp enkf under changing flow rate is shown in figs 14 and 15 when the flow rate changes from 5 m3 s to 200 m3 s all the relative identification errors are not larger than 4 while a slight decrease tendency can be found in the standard deviation of repeated identification in fig 15 although the smaller flow rate induces more uncertainty the performance of bp enkf is always good in different cases and not limited by flow rate 3 3 6 comparison with previous methods the blp enkf is expected to be more time saving than conventional enkf this advantage is demonstrated with a comparison shown in table 6 compared with the conventional enkf the proposed blp enkf achieves a significant reduction in computation time from 44 7 min to 8 0 s which can make the disposal decision more rapid in sudden pollution incidents this improvement is attributed to the usage of backward location probability in concentration forecast skipping the restart process and avoiding repetitively solving the ade for each ensemble realization the identification results obtained from other two methods i e the adjoint method and bayesian mcmc are also compared in table 6 different method has different parameters for example ensemble size for enkf and blp enkf number of optimization iterations for adjoint and bayesian mcmc the four groups of identification results are based on a balance of accuracy and computation time wang et al 2018 in terms of the accuracy all four methods achieve an identified level of relative error and standard deviation although the result from bayesian mcmc is slightly worse particularly a better accuracy in source location and release time corresponds to a worse released mass for the four group of results when the computation time is considered only the blp enkf and adjoint method stand out because both of them adopt the backward location probability to calculate pollutant concentration however the adjoint method is an off line method when compared with blp enkf the adjoint method is relatively inflexible and low efficient in using the real time updating observations in sudden pollution incidents besides the adjoint method applied in river pollution source identification may rely on an optimization method when an objective function is employed cheng and jia 2010 ghane et al 2016 wang et al 2018 but no optimization is needed in the identification process of blp enkf xu and gómez hernández 2016 4 application to a real world river case the south tributary at end of the ganjiang river is used for the real world case analysis the river flows through an industrial area of nanchang city in jiangxi province and is at high risk of pollution from sewage treatment plants this case considers a scenario where soluble pollutants are suddenly released from a potential source as shown in fig 16 the associated data are as follows 1 the river has a length of 21 4 km fig 16c 2 the point pollution source is located at 2 0 km away from the river entrance and the pollutant was released at 19 00 with mass of 1000 kg 3 the pollution gauging station chucha is located at 21 4 km away from the river entrance and continuous concentration observations were recorded on the third day from 19 30 fig 17 as no concentration data for such real pollution source incident had been documented the water quality data were simulated with mike11 wang et al 2018 4 the river flow is typically non uniform with a discharge of 250 m3 s when this incident occurred 5 roughness coefficient is 0 03 longitudinal dispersion coefficient is 6 5 m2 s and first order decay coefficient is 0 6 topographic data were obtained as shown in fig 16c red points represent position in real world case observational concentration is affected by various noises thus a random observational error of gaussian distribution is usually added to perturb the observed concentration and evaluate the model performance cheng and jia 2010 mahar and datta 2001 xu and gómez hernández 2016 the variance of observational error in fig 17 is equal to 0 0012 mg l 2 using mc a total of 500 initial ensemble members are generated from uniform distributions m u 0 2000 kg x u 0 20 km and t 0 u 1 96 h after ten times implementation of blp enkf the pollution source is identified as shown in table 7 in this real world river case the flow and pollutant transport processes are more complex than that in the synthetic cases because the distance between pollution source and gauging station is considerably long for the pollutant diffusion the difference of location probability within unit length along the river gets much smaller than that in synthetic cases this relatively small difference reduces the identifiability of different suspect pollution source location thus resulting in a larger fluctuation range standard deviation in table 7 for the identified source location and release time nevertheless the pollution source has been identified successfully with relative errors smaller than 3 0 for all parameters the identification results in table 7 are certainly useful in the practice of pollution emergency disposal in this case the computation time of blp enkf and conventional enkf are 22 s and 8 h respectively as the flow and release history get more complex the improved efficiency by blp enkf is more significant this comparison result further demonstrates the time saving advantage of blp enkf 5 conclusions this paper proposes an effective method to improve the performance of enkf in point source identification of sudden river pollution to the best of our knowledge the blp is first used in the enkf to solve an inverse problem applied in practice the proposed blp enkf method has two important advantages first it supports on line identification thus can mitigate the limitation from shortage of observations in the sudden river pollution case second blp enkf performs much better than conventional enkf in terms of computation time because it can identify the pollution source without restart forecast process when tested in a synthetic case study the blp enkf obtains all the source information with a relative error approximately 1 00 or smaller the uncertainty of the proposed method is mainly attributed to the observational error and the dispersion coefficient estimation more accurate estimation of observational error and dispersion coefficient can help in obtaining the source parameters with smaller errors and fluctuation ranges an ensemble size larger than 500 makes little influence on the identification accuracy but increasing the computation time significantly in additions the bp enkf is not sensitive to the initial distributions of ensemble members and not limited by flow rate compared with conventional enkf the advantage of blp enkf is evident in terms of identification time compared to the adjoint method the blp enkf can use the real time observations more efficiently without optimization process applied in a real world river case in ganjiang river the bp enkf identifies all the pollution source parameters with relative errors smaller than 3 0 and using much less time than conventional enkf this real world river case further verifies the efficiency and applicability of blp enkf in practice although the blp enkf is an on line and effective point pollution source identification method to be proposed more research is still needed in real world sudden pollution incidents much information may be unknown or limited particularly regarding the dispersion coefficient and the total mass of released pollutant thus further work should be conducted to improve the performance and adaptability of blp enkf and to improve this method for jointly identifying the pollution source and the dispersion coefficient the uncertainty of blp enkf needs to be further analyzed by applying it to more real world cases the extension for the continuous pollution cases and multi point cases is also expected in the following research declaration of competing interest the authors declare no conflicts of interest acknowledgments this research was funded by the national key research and development program of china 2017yfc0404403 and 2016yfc0401302 and the national natural science foundation of china 91747208 and 51579129 
6267,water resources management often involves models that simulate physical chemical processes to make predictions of future system behavior these predictions often contain uncertainty that must be considered in order to make robust decisions the quantification of this uncertainty is often not conducted in practice due to computational limitations and a lack of flexible software capabilities to bridge this gap we have developed a heuristic multi objective model independent optimization methodology using tcp ip network communications for parallel run management on high performance computing systems the proposed optimization methodology is based on particle swarm optimization pso where the memory like nature of pso makes it ideal for tracing a pareto front that graphically illustrates the trade off between competing objective functions although the focus of this study is on addressing the likelihood of an undesirable or contested model prediction the proposed methodology can be extended to any multi objective optimization context and is also able to handle inequality constraints that reflect additional conditions that must be met along the front we have demonstrated the algorithm on two important real world case studies the first case study involved water allocation issues in antelope valley california usa where the uncertainty in total natural recharge into the valley has raised significant debates over water management the second case study involved the re injection of coal seam gas co produced water into deep aquifers in the surat basin queensland australia where the potential impact of an undesired mobilization of arsenic concentrations needed to be understood and managed this case study required a highly nonlinear field scale reactive transport model and an inequality constraint was also necessary to maintain consistency with a laboratory scale geochemical model the efficiency at which the proposed methodology solved these complex case studies demonstrates its effectiveness for a broad range of applications keywords multi objective optimization particle swarm optimization uncertainty quantification groundwater modeling high performance computing nomenclature cmaes covariance matrix adaptation evolution strategy csg coal seam gas csiro commonwealth scientific and industrial research organisation gl yr gigaliters per year gc scm generalized composite surface complexation model hpc high performance computing mopso multi objective particle swarm optimization modflow finite difference groundwater flow modeling software mpi message passage interface panther parallel non intrusive handling of model runs in environmental management pest parameter estimation software suite pest parameter estimation software suite with advanced parallelization pht3d multicomponent reactive transport software pso particle swarm optimization rmif add run subroutine for adding simulations to the panther queue rmif get run subroutine for retrieving results from panther memory rmif run subroutine for executing simulations in the panther queue rtm reactive transport model slurm simple linux utility for resource management tcp ip transmission control protocol internet protocol b i log base for the transformation of the i th parameter c 1 cognitive constant c 2 social constant f j fitness value assigned to the j th repository position l j loneliness of the j th repository position l max maximum loneliness value for the repository n d total number of objective functions n do number of objective functions for which a pareto set is evaluated n rep repository size n s swarm size p weakly optimal pareto set p parameter vector p ij value of the j th particle for the i th parameter p i lb lower bound for the i th parameter p i ub upper bound for the i th parameter r j j th repository position r uniform random number on the interval 0 1 v ij velocity of the j th particle for the i th parameter z ig g best position for the i th parameter z ij p best position of the j th particle for the i th parameter α exponent used to control emphasis on lonely repository positions δ transformed range of parameters ε i upper limit for the i th constraint ω feasible region ω inertia ϕ i the i th objective function 1 introduction quantitative predictions of the past current and future quality of hydrologic systems and the assessment of potential management and remediation strategies often rely on knowledge derived from complex numerical models for example to accurately forecast the response of an aquifer system to proposed management decisions such as the reduction of agricultural inputs or the implementation of remediation techniques a multitude of coupled physical groundwater flow transport and biogeochemical processes must often be considered and integrated into the modeling prommer et al 2019 in turn the reliability and accuracy of predictive simulations using such models hinges on the degree of uncertainty in model parameters and conceptualization this requires the judicious and computationally expensive calibration of a significant number of process specific parameters that often results in an underdetermined inverse problem moreover this process may need to be repeated for multiple potential conceptual models the inability to objectively and uniquely define a single conceptual model and its parameter values as the best representation of reality can undermine the reliability of model predictions therefore decision makers must employ a means to quantify predictive uncertainty in order to understand the likelihood of success for specific management options this has resulted in a growing need for efficient software that can be easily deployed on high performance computing hpc systems to quantify predictive uncertainty although there exist a number of monte carlo based techniques and software for quantifying predictive uncertainty in water resources management tonkin and doherty 2009 vrugt et al 2009 white et al 2016 siade et al 2017 these methods are often too computationally intensive to be feasible and decision makers must rely on other means to quantify uncertainty one such method is to use multi objective optimization to address the trade off between model calibration and an uncertain or contested model outcome or prediction this is a form of hypothesis testing doherty and vogwill 2016 the solution to this type of optimization problem consists of a pareto front that graphically depicts this trade off function miettinen 1998 this approach allows the decision maker to address the likelihood of a model outcome or future event to occur regardless of the parameters chosen to calibrate the model so long as the model is sufficiently calibrated such an analysis has the potential to be far more computationally efficient than monte carlo based uncertainty analyses because it does not require sampling from a posterior probability distribution and instead focuses specifically on the feasibility of a particular event or prediction of interest there are a few multi objective optimisation tools and techniques available to decision makers but these methods are often either inefficient i e they require numerous model simulations they lack powerful parallel computing capabilities or they cannot honour inequality constraints for example moore et al 2010 evaluated the trade off between i the calibration of a rainfall runoff model and ii the simulation of a particular measured streamflow event using a multi objective formulation of the covariance matrix adaptation evolution strategy cmaes hansen et al 2003 they found that in order for the model to simulate a streamflow similar to the observed flow the trade off in model to measurement errors was too large this likely indicates the presence of a model defect or structure error however this method is computationally expensive and may be intractable for some models if hpc resources are not available moore et al 2010 another example by wöhling et al 2008 is the use of multi objective optimization during calibration to accommodate for model structure error by allowing observation data that is sensitive to model defects to have a relatively larger misfit than the remaining observation data they used the amalgam software vrugt and robinson 2007 to evaluate a three dimensional pareto front that illustrates the trade off between the individual calibration of pressure heads observed at three separate locations in the vadose zone while the use of multi objective optimization for evaluating the trade off in this way shows significant merit practitioners must be cautious as the resulting parameter estimates can still be far from the true parameter values doherty 2015 doherty and welter 2010 the method employed by wöhling et al 2008 is computationally expensive and without parallel computing technologies likely to be infeasible in practice for computationally demanding groundwater models finally a very commonly used application of multi objective optimization is through the implementation of a bayesian regularization procedure where expected values for parameters and their associated probability density functions are assumed a priori gill et al 2006 developed a methodology for evaluating the trade off between prior information and model misfit using the heuristic method of particle swarm optimization pso eberhart and kennedy 1995 bonyadi and michalewicz 2017 which has shown to be a very effective algorithm for multi objective optimization compared to other techniques coello et al 2004 baltar and fontane 2008 however their method and those mentioned previously cannot honour additional inequality constraints that may be required to produce a reasonable pareto front e g one may wish to enforce a non zero discharge at a groundwater drain for every solution along the pareto front furthermore these techniques are not easily parallelized either within a hpc environment or across multiple desktop computers in this study we present a heuristic approach to multi objective model independent optimization that can evaluate the pareto trade off curve for conflicting objective functions either within a hpc system or across multiple desktop computers inequality constraints are implemented to handle additional factors or conditions that must be met for each solution along the pareto front the proposed methodology is based on the approach outlined by coello et al 2004 which uses the pso methodology eberhart and kennedy 1995 however lexicographical ordering was used to calculate fitness in this study pso is based on swarm theory which is intuitively an ideal approach for filling a pareto front with nondominated solutions the method proposed by coello et al 2004 is chosen due its flexibility which largely comes from the fact that it does not rely on complex weighting schemes it has the ability to handle nonlinear inequality constraints and it s relatively efficient which has been thoroughly tested in their work to the best of the authors knowledge however multi objective pso mopso has received little development beyond coello et al 2004 as indicated by cui et al 2017 and has not yet been implemented within a flexible network based parallelized run manager like the so called panther run manager in pest welter et al 2015 nor has it been used to address the uncertainty or likelihood of a particular model prediction our proposed software capability fills these gaps and is based on the same user interface as that of standard pest therefore very little effort is required to set up the algorithm beyond the normal setup of pest input files and through pest simulations can be deployed in parallel on hpc systems across many cores and or across many desktop computers this is possible through the implementation of tcp ip network communication technologies along with artificially intelligent run managers that provide a great deal of flexibility during implementation of the proposed method prior to conducting mopso one should produce at least one solution on the pareto front to enhance the performance of the mopso procedure this workflow and the proposed algorithm was demonstrated with two real world applications where multi objective optimization was necessary to address the feasibility of simulating an unwanted or contested prediction in order to quantify its likelihood the first case study involved water allocation issues in antelope valley california usa where the uncertainty in total natural recharge into the valley has raised significant debates over water management the trade off between model misfit and increasing volumes of net groundwater recharge are evaluated siade et al 2015 the second case study involved the re injection of coal seam gas co produced water into deep aquifers in the surat basin queensland australia where the uncertainty behind the mobilization of arsenic has raised water safety concerns the trade off between model misfit and decreasing quantities of oxidized arsenopyrite was evaluated this application must also adhere to the additional constraint that a numerical model representing laboratory experiments is calibrated within a reasonable tolerance this is an inequality constraint with a specified upper bound rathi et al 2017 this paper starts with a brief background on multi objective optimization and the pso algorithm then we describe the proposed multi objective pso algorithm followed by benchmark results and two illustrative case studies 2 multi objective optimization the objective of this study is to efficiently evaluate a pareto front or curve using highly parallelized computing that illustrates the trade off between the optimization of one objective over the optimization of another e g the weighted least squares objective associated with a particular observation group the ability to simulate a hypothesized outcome adherence to prior information etc we refer to the i th objective function value as ϕ i where i 1 n d and n d is the number of objective functions under consideration the vector of objective functions is denoted as φ consider a vector of parameter values p that when input to a numerical model return a value for each objective function the general unconstrained multi objective optimization problem is therefore written as miettinen 1998 1 min p φ ϕ 1 ϕ 2 ϕ n d subject to p ω where ω is the feasible region for the parameters although the term parameters is used throughout the background theory and the proposed workflow can be applied to any decision variable e g groundwater pumping rates etc the complete solution to the problem in eq 1 is referred to as a weakly pareto optimal set and the optimal objective functions corresponding to this set of parameter values are referred to as the pareto front miettinen 1998 due to the fact that evaluating a continuous pareto function is generally impossible especially when the model under investigation is numerical in the sense that it is simulated using external software e g modflow harbaugh 2005 the pareto function is usually approximated using a discrete set of parameter vectors the optimality conditions for this discrete set of parameter vectors can be summarised as follows baltar and fontane 2008 a parameter vector p 1 is said to be pareto dominant or efficient over another vector p 2 if and only if ϕ i 1 ϕ i 2 i 1 n d therefore if there is at least one objective for p 1 that is greater than that of p 2 p 1 does not dominate p 2 a parameter vector p j is said to be nondominated if there exists no other parameter vector in a given set that dominates it i e for each parameter vector in the set either ϕ i j ϕ i k i 1 n d k j or there is at least one objective i for which ϕ i j ϕ i k a weakly pareto optimal set p is a set of parameter vectors that are nondominated over the feasible region miettinen 1998 the pareto front is the set of objective function values φ corresponding to the parameter vectors in p often existing optimization software convert eq 1 into a single objective optimization problem when attempting to define the pareto front e g pest s pareto mode and the method proposed by gill et al 2006 this is accomplished using a sophisticated weighting scheme where each objective is assigned a weight based on some criteria or fitness function this form of scalarization has drawbacks in that a bad choice of weights can result in a suboptimal pareto front the algorithm presented in this study alleviates the need for scalarization and maintains the independence of each objective the solution to eq 1 can be very useful to decision makers when attempting to evaluate effective solutions for model calibration and water resource management however in practice unconstrained optimization does not consider additional factors that may affect decision making for example each pareto optimal solution for a particular groundwater management problem must also adhere to i the drinking water threshold of a specific contaminant or ii sufficient water levels to maintain groundwater dependent ecosystems etc of course factors like these can be included as additional objective functions but this inflates the dimensionality of the optimization problem which can make the analysis computationally infeasible therefore these additional factors or conditions are included in the optimization problem as ε constraints miettinen 1998 2 min p φ ϕ 1 ϕ 2 ϕ n do subject to ϕ j ε j j n do 1 n d p ω where n do is the number of objective functions for which a pareto front is obtained and ε j is the upper bound for constraint j for example assume that for a particular calibration exercise there exist a large amount of 1 bromide concentration observations 2 arsenic concentration observations and 3 a wealth of prior information from hydrogeological and biogeochemical investigations i e n d 3 both observation groups are sensitive to the flow and transport parameters but arsenic is the only observation data type sensitive to the biogeochemical parameters generating a pareto front between these two observation groups in terms of calibration can be illuminating when choosing the appropriate calibration parameter set that will be used for making predictions to maintain agreement with prior information and to reduce the dimensionality of the optimization problem an upper bound can be set on its associated objective function therefore this example would contain two objectives n do 2 and an ε constraint that represents the prior information the ε value for this constraint should reflect the maximum deviation the parameters are allowed to stray away from expected values in other words in this example every point on the resulting pareto front would also reasonably adhere to prior information it is important to note that even for a small number of objective functions the pareto front can be difficult to obtain however since the early 2000 s the heuristic algorithm pso has shown great promise in efficiently approximating the pareto front due to its relatively high speed of convergence and its ability to obtain a diverse set of solutions spanning the entire front kennedy et al 2001 coello et al 2004 one attractive feature of the pso algorithm is its heuristic derivative free nature which excels in problems that are highly nonlinear such as those relating to the reactive transport of solutes in groundwater or those that involve discrete or integer valued parameters and observations 3 algorithmic framework multi objective particle swarm optimization consistent with the objective of this study the algorithm chosen for multi objective optimization regarding calibration and management for environmental models should be highly parallelized able to handle nonlinear nonconvex objectives constraints and alleviate the need to develop complex weighting schemes through scalarization the primary algorithm employed to accomplish this is through multi objective pso mopso which is based largely on that proposed by coello et al 2004 however for this study lexicographical ordering is used for promoting diversity along the pareto front 3 1 basic particle swarm optimization basic pso is a simple algorithm that utilizes the sociocognitive behavior associated with individuals or particles interacting with each other within a swarm kennedy et al 2001 in the context of parameter estimation a particle is defined as an n p dimensional vector of parameter values where n p is the number of parameters the particle s position consists of its location in the n p dimensional parameter space defined by ω the swarm keeps track of a global best position denoted as g best and each individual particle keeps track of its own local best position denoted as p best in the context of parameter estimation the magnitude of the least squares objective function is used to evaluate whether one position is better than another initially the particles p j 0 j 1 n s are assigned random positions based on the prior probability distribution of the parameters where n s is the number of particles in the swarm at each iteration a velocity is calculated for each particle and the particle moves in the corresponding direction as follows eberhart and kennedy 1995 3 p ij t 1 p ij t v ij t 1 where p ij is the parameter value assigned for the i th parameter in j th the particle v ij is the velocity assigned to the parameter and t is the iteration count the velocity of a particle is determined based on the best position observed by both the swarm and the individual particle 4 v ij t 1 ω t v ij t c 1 r 1 z ij t p ij t c 2 r 2 z ig t p ij t where z ij is the local p best value for the i th parameter observed by the j th particle z ig is the value of the i th parameter associated with global g best position of the swarm g represents the index of the particle with the g best position c 1 is referred to as the cognitive constant c 2 is referred to as the social constant ω is referred to as inertia r 1 and r 2 are uniform random numbers on the interval 0 1 particles are updated iteratively using eqs 3 and 4 until convergence is achieved which typically occurs when the g best position is no longer being updated this basic form of single objective pso has been successfully applied in several recent biogeochemical and reactive contaminant transport studies rawson et al 2016 rathi et al 2017 rathi et al 2017 jamieson et al 2018 sun et al 2018 prommer et al 2018 the implementation of pso in these studies is conducted using standard pest interface protocols pest uses tcp ip network communications to parallelize numerous model runs either within a single computer e g hpc system or across multiple computers welter et al 2015 a capability that is currently unavailable in other existing software the pest panther run manager is used to parallelize the simulations of the swarm at each iteration since the swarm can be of any size and each simulation in the swarm is completely independent the use of this form of parallel computing is fitting providing a great deal of flexibility in the implementation of pso for example if the user has only 45 cores available they can use a swarm size of 45 which requires the clock time of a single model evaluation per iteration a swarm size of 90 will require twice this clock time etc additionally individual model simulations in the swarm can be spawned or removed at any time without disrupting the progress of the pso algorithm this technology is also employed in the mopso methodology described in the following 3 2 multi objective optimization with pso the mopso algorithm employed in this study is largely based on the method presented by coello et al 2004 with some modifications for improved performance therefore we adopt some of their terminology here the g best position assigned to a given particle in the swarm at a given iteration can correspond to any nondominated solution obtained thus far therefore nondominated solutions must be recorded as the algorithm proceeds this record or memory is referred to as a repository in this study we refer to solutions in the swarm as particle positions and solutions in the repository as repository positions the j th repository position is denoted as r j and the repository size is denoted as n rep at each iteration the dominance relationships within the swarm and the repository are calculated if a particle in the swarm dominates a repository position s that particle if completely nondominated by other particles will enter the repository and the now dominated repository position s will be discarded for practical implementation of this method there must be a maximum repository size set by the user at each iteration if the repository size exceeds this value repository positions are discarded until the maximum repository size limitation is met most mopso algorithms discard repository positions in an effort to promote diversity of solutions along the pareto front bartz beielstein et al 2003 coello et al 2004 wang and singh 2006 a review of various methods can be found in banks et al 2008 in other words repository positions located relatively close to many other positions in terms of their respective objective functions i e clustered together in objective space are selectively discarded there have been a number of methods proposed for carrying out this process which is often rely on fitness metrics hu and eberhart 2002 use a dynamic neighborhood concept which assigns fitness based on the objective functions of neighboring positions in the objective space bartz beielstein et al 2003 and coello et al 2004 define fitness based on the implementation of an adaptive grid wang and singh 2006 use a fuzziness concept combined with niching and fitness sharing in the algorithm presented herein we implement a lexicographical ordering approach which differs and is arguably more efficient than the adaptive grid based approach of coello et al 2004 generally positions with the smallest fitness are removed first once the dominance relationships are determined and the repository size limitation is met at a given iteration the new velocities are calculated velocities are determined in the same way as in basic pso eq 4 however the g best and p best positions are assigned to each particle in the swarm differently determining the p best position for a particle in the swarm is straightforward if the current position of the particle dominates its p best position its p best position is updated to that of the current position if neither the p best nor the current position dominate one of them is chosen randomly for the p best position the choice of the g best position assigned to each particle in the swarm is more challenging since there are many potential nondominated solutions in the repository most mopso studies in the literature appear to use the same fitness concepts used for controlling repository size to assign g best positions to the particles in the swarm similarly fitness is calculated in such a way as to promote diversity by assigning greater fitness values to positions located furthest in objective space from other positions in the repository a random sampling procedure is then used to select a g best position from the repository for each particle in the swarm based on fitness which is a probabilistic measure on the interval 0 1 hu and eberhart 2002 bartz beielstein et al 2003 coello et al 2004 wang and singh 2006 banks et al 2008 however gill et al 2006 assign a fitness value to each position on the pareto front based on a scalarization of the objective functions then the position with the median fitness is assigned as the g best position for calculating all particle velocities 3 3 promoting diversity along the pareto front at each iteration of the mopso algorithm described in this study the repository must be updated and a fitness value assigned to each corresponding position if the repository size is too large positions must be removed until the size limitation is met then a roulette wheel selection procedure is used to randomly select repository positions to be assigned as the g best position for each particle in the swarm this roulette wheel selection procedure proceeds by 1 randomly choosing a repository position and 2 accepting the repository position as the g best position for a particle if a uniform random number generated on the interval 0 1 falls below the fitness or probability that is assigned to that repository position this is repeated for each particle in the swarm until each particle is assigned a g best position from the repository the fitness value assigned to each repository position for either deletion or selection as a g best position is determined in such a way as to promote diversity for example if a repository position is located within close proximity in terms of objective function values to a number of other repository positions it should be removed from the repository if the repository is too big or it should be assigned a relatively small fitness value so it is less likely to be chosen as a g best position within the swarm the converse is true for repository positions that are far from other repository positions in objective space fig 1 presents an illustrative example of a potential scenario for repository positions based on visual inspection if a repository position is to be removed it should be either 4 or 5 accordingly positions 4 and 5 should be assigned the smallest fitness values coello et al 2004 used a grid based methodology to assign fitness values to each repository position based on the number of other repository positions residing in the same respective grid cell or hypercube however under some circumstances this method can be inefficient as it may produce granular pareto fronts if the grid spacing i e hypercube size is not optimal which is difficult to determine at the outset of the problem at hand the optimal hypercube size is dependent on several factors including the absolute minimum value for each objective function i e the extreme points on the pareto front the number of particles in the swarm the repository size etc for example if a particular hypercube was relatively large compared to the distribution of the repository positions at a particular iteration this hypercube could encompass a region of the objective space consisting of both a large cluster of positions and one position that is relatively far from that cluster in this situation the same fitness value would be assigned to each repository position within this hypercube which does not promote the fact that there is one position in the hypercube that is relatively far from the others ideally this lonely position should be assigned a larger fitness value in an effort to fill in the pareto front around it for example in fig 1 positions 3 4 5 6 and 7 would be assigned the same fitness using this grid based approach however position 7 should have a greater fitness than that of the other positions in hypercube c conversely if the size of the hypercubes was relatively small compared to the distribution of the repository positions each nonempty hypercube could run the risk of only containing a single position which would result in the same fitness value assigned to all repository positions which again may not consider their distribution in objective space in this study we promote diversity by calculating the fitness value assigned to each repository position based on how lonely that position is with regard to the repository positions surrounding it this is accomplished via lexicographical ordering which simply orders the pareto set with one objective function value in an increasing order and in doing so the other objective function will by the properties of nondominance be ordered in a decreasing order then the fitness for a given repository position can be calculated based on its euclidean distance in objective space from the repository position above and below that position in this ordered list using position 2 in fig 1 as an example this lexicographical ordering approach would select positions 1 and 3 during the fitness calculation in comparison if a simple euclidean distance were employed to find position 2 s nearest neighbors positions 3 and 4 would be selected the use of these two particles for determining fitness does not properly reflect the loneliness of position 2 i e the gap observed between positions 1 and 2 once the nondominated solutions are ordered lexicographically the appropriate neighbors are selected and a measure of the loneliness l j of a repository position j is calculated using the sum of the euclidean distances between the repository position and its neighbors 5 l j φ j φ j 1 2 φ j φ j 1 2 to convert this metric into a probability of acceptance for the roulette wheel selection scheme i e converting it to a value that ranges from 0 1 6 f j l j l max α t where f j is the fitness value assigned to repository position j l max is the maximum loneliness value for the repository and the exponent α controls the emphasis placed on lonely positions e g large values of α will keep the fitness of the loneliest position at 1 0 but will drive the fitness of the remaining positions to 0 0 in this case the g best value assigned to each particle in the swarm will be set to the loneliest position in the repository this is ideal if convergence is nearly obtained and the user wishes to fill in the pareto front as uniformly as possible therefore the value for α should increase as the repository becomes full at which point it should remain constant 3 4 extreme values and pareto optimal subsets often in multi objective optimization the decision maker is only interested in a subset of the weakly pareto set this is due to the fact that many of the solutions in the weakly pareto optimal set may have marginal trade offs with the solutions surrounding them this can be visualized as regions of the pareto front that are nearly vertical or horizontal decision makers are primarily interested in solutions that exhibit a significant trade off in one objective due to an increase or decrease in another additionally decision makers may not be interested in solutions where objective functions have extreme values e g a water manager may not be interested in solutions where the total groundwater yield is below the required demand or in the case of parameter estimation the decision maker will have some idea for an upper bound on the least squares objective function i e the maximum level of misfit allowed all values above this maximum level of misfit are of no interest this results in the need for only a subset of the full weakly pareto optimal set therefore in the algorithm proposed in this study the user can enter an upper bound on each objective function specified such that the resulting pareto optimal subset resides within these bounds upper bounds on objective functions are handled by the proposed algorithm as follows fig 2 assume that at some iteration a particle in the swarm violates the upper bound on any objective function that particle will not enter the repository regardless of whether or not it is nondominated by the positions currently in the repository managing the p best position for that particle however is not so straightforward if that particle has had in a previous iteration objective functions that satisfy their associated upper bounds the p best position is not updated however if the particle has never been feasible in terms of objective function bounds the p best position is updated only if the current position is closer to the upper bounds than the currently saved p best position the closeness of a particle position to the upper bounds of the objective functions is measured as the euclidean distance of the particle s objective function values to their associated upper bounds this distance only applies to objective functions that violate their upper bounds objective functions satisfying upper bounds do not contribute to this distance to remove the effects of the vastly differing magnitudes of the objective functions their values are divided or normalized by their associated upper bound values before calculating this distance this process is outlined in fig 2 it is important to not only constrain objective functions within upper bounds but also to ensure that the resulting pareto front spans the entire region encapsulated by these bounds to achieve a pareto set that reaches the upper bounds of each objective function the extreme values in the repository i e the solid black dots in fig 1 must receive significant attention in the roulette wheel selection mechanism in order to achieve this these extreme repository positions are always assigned a fitness value of 1 0 regardless of their associated grid based or loneliness metric this will ensure that at least some of the particles in the swarm are being assigned these extreme values as their associated g best positions at each iteration 3 5 handling ε constraints evaluating high dimensional pareto fronts can be computationally infeasible this is due to the fact that the repository size must be quite large which may require an extremely high number of model runs to sufficiently populate it furthermore visualizing pareto fronts with more than two objective functions can be cumbersome the number of competing objective functions can be reduced by either employing scalarization or ε constraints miettinen 1998 for example if a pareto analysis involved five objective functions this analysis could be reduced to two objective functions by placing an appropriate upper bound on the remaining three objective functions in this study we employ a simple method for handling ε constraints that is similar to that discussed in the previous section for pareto optimal subsets fig 2 a particle position in the swarm is considered feasible if it does not violate any of the ε constraints eq 2 an infeasible position is more feasible than another infeasible position if it violates the ε constraint to a lesser extent the magnitude of this violation is measured by summing the difference between each objective function value and its corresponding upper bound or ε value this sum is only calculated using the differences associated with constraints that are actually violated i e ε constraints that are satisfied do not contribute to this sum the resulting algorithm begins by populating the swarm with positions based on the prior probability distributions of the parameters therefore at the outset of the algorithm many or perhaps all particles may violate the ε constraints then at each iteration the repository is updated only with the particle positions that are feasible however some adjustments to the choice of g best and p best positions for the swarm must be made if the repository is empty i e there are no feasible particle positions obtained so far the g best position assigned to each particle in the swarm is that which violates the ε constraints the least once there is at least a single feasible position in the repository the g best position assigned to each particle is selected from the repository normally as explained in the previous sections if a particle in the swarm has never been feasible its p best position is updated only if the current position is more feasible if a particle has been feasible previously but its current position is no longer feasible the p best position is not updated for that particle if a particle is feasible and its current position is feasible the p best position is updated normally as described in the previous sections 3 6 parameter transformations commonly during the calibration of groundwater flow and reactive transport models using the popular gauss levenberg marquardt algorithm doherty 2015 parameters are transformed using a logarithm with base 10 this is particularly beneficial for parameters that span many orders of magnitude such as hydraulic conductivity and can alleviate some of the issues regarding model nonlinearity with respect to the parameters or decision variables doherty 2015 the effectiveness of the mopso algorithm presented in this study also stands to benefit from this approach however rather than applying a logarithmic transformation with base 10 the base is chosen separately for each parameter such that the overall range of variability of each parameter between its transformed upper and lower bounds is equivalent this is accomplished by firstly determining the parameter with the maximum range in terms of magnitude i e in terms of a base 10 once this parameter is selected its transformed range is recorded δ using base 10 then the logarithm base b i for the i th parameter is chosen such that its respective transformed range is equal to δ 7 b i p i ub p i lb 1 δ where p i ub and p i lb are the i th base parameter s upper and lower bounds respectively once this is done for each parameter the transformed parameters will all have precisely the same transformed range however the transformed upper and lower bounds may differ therefore the mopso algorithm sees the parameters as having the same variability furthermore it is often recommended that assigning a maximum velocity v max to each particle can improve convergence eberhart and kennedy 1995 coello et al 2004 however it is difficult in practice to assign such a value for each parameter as they may have different magnitudes and ranges applying the transformation method described above alleviates this requirement as each transformed parameter now resides on the same range therefore a single maximum velocity can be set for the entire parameter set as a percentage of the now uniform parameter range δ in summary the proposed parameter transformation not only improves performance it also simplifies the specification of v max 3 7 benchmark test functions the mopso algorithm developed in this study was tested with three commonly used heuristic multi objective optimization test functions to illustrate its effectiveness and the quality of the resulting pareto fronts the three test functions considered for this study were developed by kita et al 1996 kursawe 1991 and deb 1999 the formulae for the associated multi objective optimization problems are listed in appendix a and the results are shown in fig 3 each benchmark was conducted with 100 iterations using a repository size of 100 swarm size of 100 and α set to 2 0 the results indicate that the mopso algorithm presented in this study is very effective at solving highly nonlinear constrained multi objective optimization problems generally new heuristic algorithms require numerous trials which are analyzed statistically to both demonstrate the properties of the algorithm and make comparisons with other existing algorithms this is often referred to as a random seed analysis although the mopso algorithm presented in this study has been tested numerous times for a number of conditions such an analysis was beyond the scope of this study as we adopt and combine the strategies of other studies for which such random seed analyses have already been conducted coello et al 2004 however comparing the performance of the benchmark problems considered in this study with those of coello et al 2004 under the same control variables e g inertia values etc it is clear that our approach is at least equally as effective furthermore comparisons of overall computational performance of our approach with that of others is generally not possible due to the use of advanced tcp ip parallelization techniques that are not available for other algorithms that is our approach will most likely outperform another simply because of the flexibility and efficiency of the panther run manager that is employed in our method in fact the use of such technologies provides a significant advantage of our approach over others for practical reasons welter et al 2015 the focus of this study is therefore shifted towards addressing real world water resources case studies involving highly nonlinear complex multi objective optimization problems and the implementation of the mopso approach within multiple hpc systems 3 8 workflow for efficient mopso performance when implementing the proposed methodology in practice for hypothesis testing the first step in achieving an effective pareto front is to calibrate the model this will provide a point on or near to the pareto front having this point as a particle in the initial swarm will dramatically speed up the swarm s convergence by filling in the front around this point in fact if feasible one should calibrate the model under any number of scenarios to provide multiple points near the pareto front for optimal performance for example if one wishes to use mopso to address the trade off between model misfit and a contested outcome one may want to calibrate the model in such a way as to achieve this contested outcome as closely as possible producing a poor model fit having done this in addition to the best calibrated model one would potentially provide two points in very different portions of the pareto front the mopso algorithm will then proceed to fill in the front around these points relatively quickly in summary the computational savings associated with calibrating the model and using this result as an initial particle position in the swarm for mopso is comparable to the expense of conducting the calibration itself therefore it is recommended that one always calibrate the model prior to conducting mopso 3 9 mopso parallelization via network communications a major advantage of the proposed mopso methodology is its ability to be conducted in parallel across many compute cores on a wide variety of computing hardware this is due to the fact that each particle s simulation is independent of the other particles in the swarm that is if the swarm size is n s a number of n s independent model simulations are required at each iteration of the mopso procedure this obviates the need for shared memory parallel programming and can be conducted across a network allowing for the modeller to create a virtual cluster amongst multiple desktop computers while still providing the means to operate within an hpc cluster this is accomplished via tcp ip communications whose programming operates similarly to message passage interface mpi techniques the pest software suite provides a series of subroutines that can be employed to send and receive parameters or decision variables and model outputs respectively over a network or the internet welter et al 2015 in this study the rmif add run fortran subroutine was used to add parameter sets to the panther run manager queue and the rmif get run subroutine was used to retrieve their corresponding model outputs of interest once the simulations have completed the rmif run subroutine executes the simulations that are in the queue one for each parameter set added this subroutine contains the panther run manager an artificially intelligent software capable of handling a series of issues in parallel run management such as sending queued simulations to new worker cores as they become available reassigning simulations to worker cores that have disappeared taking optimal advantage of faster compute cores by monitoring simulation run times etc the reader is referred to the pest website for more details on the implementation and execution of the panther run manager http www pesthomepage org pest and pestpp php the implementation of the method proposed in this study is relatively simple and involves two basic steps here we use beekeeping terminology to define parallel run management 1 initialize the run manager the first step is to initialize the mopso procedure by starting the queen bee core the user supplies the pest control file and a port number for which the network communications are to occur on the associated computer once this is done the queen core will remain idle until it receives communication from the worker cores 2 stage the workers and execute the second step involves staging or making copies of the simulation model on each worker bee compute core and pointing them to the queen the user provides a simplified version of the pest control file the ip address of the queen core and the port number over which the communication will occur on the queen s computer which can be the same computer as that of the worker core the worker then sends a message to the queen and from there the panther run manager handles the sending and receiving of information over the network through this methodology worker cores could be on any computer in the world and participate in the mopso procedure so long as they have access to an internet connection this is a very sophisticated implementation of pso and mopso and well suited for the swarm like nature of these algorithms to the best of the authors knowledge this approach to the operation of any pso algorithm is the first of its kind 4 results and discussion to demonstrate the effectiveness of the methodology developed in this study the proposed mopso algorithm was applied to two independent real world case studies these two case studies involve complex hydrological decision making with potentially profound implications for the environmental and the economy 4 1 quantifying natural groundwater recharge antelope valley california usa antelope valley is a topographically closed basin located in mojave desert of southern california just north of the city of los angeles fig 4 the antelope valley groundwater basin has an aerial extent of approximately 2400 km2 and an arid to semi arid climate prior to 1972 groundwater has been the primary source of water for the valley with the major water use being agricultural as a result groundwater levels have declined significantly resulting in increased pumping lifts reduced well efficiency and significant land subsidence due to recent increases in population growth and agricultural practices future groundwater demand is likely to rise as a result recent legal proceedings have led to the adjudication of the antelope valley groundwater basin the los angeles county superior court has ruled that the basin is in a state of overdraft los angeles county superior court 2011 the court has also set an upper limit on the total sustainable amount of groundwater that can be extracted from the basin beeby et al 2010b beeby et al 2010a this limit is based on the fluxes associated with numerous components of the water budget throughout the basin however the most uncertain and sensitive component of this water budget is the total annual natural recharge into the basin the testimony of many experts in the adjudication process have resulted in estimates of natural recharge that range from 37 to 197 gl yr siade et al 2014 historically the us geological survey has developed several numerical models to simulate groundwater flow and subsidence in the antelope valley siade et al 2014 leighton and phillips 2003 durbin 1978 the purpose of all of these models was to provide a tool to aid in the management of the valley s groundwater resources the analysis contained in each study resulted in an estimate of the total annual natural recharge into the basin however the most recent study by siade et al 2015 is the first to quantify the uncertainty of this estimate fig 4 illustrates the extent of the model grid boundaries and the locations of the model cells used to simulate natural recharge which primarily occurs along the mountain fronts as subsurface inflow as part of the total natural recharge uncertainty quantification siade et al 2015 used the sequential scalarization pareto trade off methodology contained in the pest software to visualize the relationship between model calibration and total annual natural recharge volumes the calibration dataset consisted primarily of measured water levels and land surface deformations as a result of land subsidence their study showed that for total natural recharge volumes exceeding 54 gl yr the model calibration began to deteriorate rapidly indicating that recharge rates above this value are highly unlikely the pareto method employed in siade et al 2015 consists of placing a penalty within the least squares objective function to penalize the parameter estimates for producing a prediction that deviates from some desired prediction in this case the desired prediction is a very large value for total natural recharge the penalty function when incorporated into the least squares objective function is weighted such that for small weights the influence of this penalty is negligible and vice versa the pareto curve is therefore calculated by incrementally increasing this weight and re calibrating the model for each weight value considered however this method can be difficult to implement because it is not clear ahead of time what the initial weight should be and how this weight should be adjusted furthermore this method requires the model to converge for every parameter set tested as the pareto front is traversed which is often a challenge for highly nonlinear models therefore the implementation of this method requires a trial and error process by which many weight management schemes must be tested while maintaining model convergence for all reasonable parameter values as a result of these issues the pareto curve presented in the study by siade et al 2015 was very coarse with only eight significantly different nondominated solutions some of these solutions also consisted of very large weighted least squares objective function values representing solutions that are very far from calibration furthermore their curve may not be accurate due to the nonlinear nature of the model and the non uniqueness of the estimates of model parameters the last solution on the trade off curve presented by siade et al 2015 dominates the previous solution along the front this inconsistency is likely due to the nonlinearity associated with simulating subsidence as discussed by siade et al 2015 the mopso methodology proposed in this study overcomes these drawbacks and can produce a relatively smooth detailed pareto front within user specified bounds as mentioned previously it is important to use at least one solution near the pareto to initialize the swarm prior to running the mopso procedure the ten solutions obtained by siade et al 2015 were used as starting positions for ten particles in the initial swarm these initial solutions improve the performance of the mopso procedure if fewer initial solutions were available the convergence of the mopso procedure will likely be somewhat slower there were 203 independent parameters consisting of hydraulic conductivity zones mountain front recharge pilot points storage properties including those associated with subsidence fault conductance pre consolidation head among others a single forward simulation of the model took about 2 min on a basic desktop computer both the swarm size and the repository size were set to 100 with an α value of 2 0 an upper bound was placed on the weighted least squares objective function that was approximately five times as large as the calibrated result reported by siade et al 2015 weighted least squares objective values above this bound are well beyond reason and therefore unimportant for this study the mopso procedure was deployed across two 16 core virtual unix machines on the commonwealth scientific and industrial research organisation s csiro bowen research cloud fig 5 displays the resulting pareto front after 400 iterations however the pareto front was no longer changing significantly after about 200 iterations many of the solutions obtained by siade et al 2015 were maintained in the repository however some of these solutions were suboptimal and discarded the mopso methodology proposed in this study was able to find solutions that dominate the results of siade et al 2015 showing that the proposed mopso method can be very effective at approximating the true pareto front the results of this study continue to validate the results of siade et al 2015 in that values of total natural recharge above 54 gl yr continue to be unreasonable the average residual increases by 50 at a value of 60 gl yr it is important to note that without the ten initial solutions provided by siade et al 2015 the mopso procedure would have required more iterations to achieve the final result show in fig 5 however as mentioned previously one should always endeavor to provide at least one solution near the pareto front prior to initializing the mopso procedure 4 2 re injection of coal seam gas co produced groundwater reedy creek queensland australia recently the production of coal seam gas csg as a source of energy has risen dramatically worldwide with the usa and australia being the largest producers csg consists primarily of methane and is extracted from deep subsurface coal seams by lowering the surrounding groundwater pressure via groundwater extraction although this process provides a very efficient source of energy it is accompanied by excessive amounts of co produced groundwater with future estimates indicating that a total of 70 gl yr of groundwater will be extracted for csg in australia alone dnrm 2016 managing such large volumes of co produced groundwater is not straightforward considering its high salinity and residual concentrations of organic substances due to a number of climatic ecological and social factors for some locations including reedy creek the injection of csg co produced groundwater into deep aquifers after a comprehensive treatment process is viewed as the most viable water management option prior to the large scale injection of csg co produced groundwater at the reedy creek site a comprehensive pilot study was conducted to understand the potential changes in groundwater quality rathi et al 2017 a short term injection trial was conducted where treated csg co produced groundwater was injected for a short period 85 days into the deep precipice formation of the surat basin allowed to react with the subsurface environment during a storage period 64 days and subsequently extracted 309 days the quality of both the injectant and the extracted groundwater was monitored periodically in addition to the injection trial supporting laboratory experiments were conducted with sediment samples collected from the targeted injection zone to better characterize the local geochemistry for a detailed description of both the injection trial and the laboratory experiments see rathi et al 2017 due to the presence of elevated arsenic concentrations in the extracted groundwater a detailed modeling study was also conducted to understand the mechanisms responsible for subsurface arsenic mobilization given that neither the ambient groundwater nor the injectant contained arsenic concentrations above the detection limit a radially symmetric groundwater flow and reactive transport model rtm was developed for the field site fig 6 using modflow harbaugh 2005 and pht3d prommer et al 2003 as simulators of relevant hydrogeological and biogeochemical processes respectively field scale reactive transport simulations incorporated a laboratory derived generalized composite surface complexation gc scm model davis et al 1998 that was constrained by the experimental data collected in batch sorption experiments this allowed for the adequate simulation of arsenic sorption behaviour under variable geochemical conditions initial model results indicated that arsenic de sorption alone primarily caused by an injection induced rise in ph could not adequately explain the observed arsenic concentrations of the extracted groundwater due to the presence of significant sulfate concentrations in the extracted groundwater it was then hypothesized that arsenic could also be derived through a second release mechanism i e the oxidation of arsenic bearing pyrite a process that was previously shown to occur in response to the injection of aerobic water into pyritic aquifers wallis et al 2010 wallis et al 2011 however the concentration of dissolved oxygen in the injectant was periodically monitored and consistently found to be below the detection limit nevertheless only with the oxidation of pyrite and the associated co release of arsenic in the following referred to as arsenopyrite oxidation was the rtm able to reproduce both the observed sulfate and arsenic concentrations this raised critical questions regarding the potential source and nature of the oxidant as well as the relative contributions of i arsenic de sorption versus ii arsenopyrite oxidation to the observed arsenic concentrations as a result rathi et al 2017 conducted a monte carlo uncertainty analysis to quantify the effect that correlations between these two processes may have on the rtm model s predictions of long term fate and transport of arsenic although they found a significant degree of predictive uncertainty all realizations of their method indicated that future arsenic concentrations are likely to remain below drinking water standards since the injectant water showed non detectable amounts of dissolved oxygen and the characterization of aquifer sediment samples did not confirm the presence of arsenopyrite the question on how much arsenic must be produced from arsenopyrite oxidation in order to achieve a well calibrated rtm remained clearly in the absence of supplementary and more decisive field observed geochemical evidence the oxidation should not need to be considered in the model while on the other hand there was also some positive indication that the process had occurred and cannot be ignored to resolve this contradiction we were interested in elucidating the minimum required contribution of the oxidation process to address this problem we have adopted the mopso methodology developed in this study the competing objectives in this case are i rtm calibration or misfit and ii total moles of arsenopyrite oxidized however since the rtm employs an upscaled laboratory gc scm to simulate sorption dynamics we must maintain the condition that this laboratory gc scm is always calibrated within a reasonable tolerance this condition is maintained via an ε constraint therefore the multi objective optimization problem becomes 8 min p ϕ rtm ϕ as pyr subject to ϕ gc scm ϕ gc scm max where ϕ rtm and ϕ gc scm are the weighted least squares objective functions employed by rathi et al 2017 and ϕ as pyr is the total moles of arsenopyrite oxidized in the rtm simulation the laboratory dataset consisted of measured arsenic and phosphate concentrations and the injection trial dataset consisted of measured arsenic phosphate ph and sulfate concentrations the calibration threshold for the gc scm ϕ gc scm max employed by rathi et al 2017 was used for this study to solve the problem in eq 8 a total of 14 parameters were considered consisting of both equilibrium constants and surface site densities for surface complexation reactions dispersivity heat conduction oxidation rate of arsenopyrite and the dissolved oxygen concentration in the injectant both the swarm and repository size were set to 100 and an α value of 2 0 was used as mentioned previously it is best to initialize the mopso swarm with solutions near the pareto front initial solutions were taken from the calibration constrained monte carlo results in rathi et al 2017 along with a single parameter set developed in this study that results in very little arsenopyrite oxidation these initial solutions reside on the two extremes of the pareto front essentially providing two initial pareto optimal solutions i e the monte carlo results are clustered together near the maximum mass of arsenopyrite oxidized a single forward flow and reactive transport simulation for this case study required about 45 min to complete on the csiro pearcey cluster a unix system using the simple linux utility for resource management slurm the swarm was fully parallelized on the cluster such that one iteration of the mopso algorithm required about 45 min therefore for example 10 iterations required only about 7 5 h to conduct the resulting pareto front and its associated convergence is depicted in fig 7 the results depicted in fig 7 illustrate that the convergence of the mopso algorithm proposed in this study is quite fast the algorithm produced a reasonable approximation of the pareto front after only 10 iterations 1000 forward model simulations after 20 iterations the pareto front has essentially fully converged as very little change is observed over the next 80 iterations this is a very attractive feature especially for nonlinear models with long cpu run times therefore the mopso algorithm presented in this study is a very efficient method for quantifying the likelihood of smaller amounts of arsenopyrite oxidation at the study site the pareto front resulting from eq 8 fig 8 indicates that the total amount of arsenopyrite oxidized is likely to be above 13 mol and that it has a large relative contribution to the observed aqueous arsenic concentrations at the well while the calibration can perhaps be argued to be reasonable at point d at point c the misfit for aqueous arsenic concentrations has become significant this marks the point where the calibration deteriorates which corresponds to approximately 13 mol of total arsenopyrite oxidized another interesting result is the inflection of the pareto front at point b the curve between points a and b is relatively steep meaning that a large improvement in calibration is achieved for very little increase in oxidized arsenopyrite this is due to that fact that parameter combinations can produce a situation where pyrite is being oxidized but the amount of arsenic incorporated into its structure is still very low this allows the model to match sulfate concentrations and ph quite well reducing the weighted least squares objective function however once observed sulfate concentrations and the ph data are matched as best as possible the fraction of arsenopyrite must begin to increase in order to continue reducing the least squares objective i e matching the observed aqueous arsenic concentrations hence the change in slope at point b fig 8 after this point large trade offs are needed in order to achieve a reasonable calibrated arsenic response i e up to point d the results of this pareto analysis also agree well with the monte carlo uncertainty analysis reported in rathi et al 2017 the monte carlo results produce total arsenopyrite oxidation quantities roughly between 13 and 17 mol since some of these results are used to initialize the mopso algorithm this range can be seen in fig 7 after 10 iterations the initial parameters that were used to initialize the mopso algorithm are still clustered at the bottom right corner of the pareto front ranging between 13 and just over 16 mol of arsenopyrite oxidized therefore the mopso algorithm developed in this study confirms the results of rathi et al 2017 with a comparably much smaller computational effort 5 conclusions we have developed a multi objective optimization algorithm based largely on the algorithm presented by coello et al 2004 however lexicographical ordering is used for fitness calculations the proposed algorithm uses swarm theory i e pso to quickly evaluate pareto optimal solutions we have incorporated our algorithm into the pest software suite welter et al 2015 for parallel implementation across many compute cores using tcp ip communications this approach to parallel computing is extremely advantageous for the proposed mopso algorithm as it provides the flexibility to deploy model simulations across multiple desktop computers within any hpc environment or a combination thereof furthermore the proposed mopso method does not require subjective scalarization and instead evaluates each objective function independently finally the method can incorporate inequality constraints that decision makers may require to be met for each point along the pareto front the proposed mopso algorithm was tested on two real world case studies the first case study explored the uncertainty associated with total natural recharge entering a desert groundwater basin in antelope valley california usa the second case study explored the uncertainty associated with arsenopyrite oxidation during the re injection of csg co produced water into deep aquifers in reedy creek queensland australia the proposed methodology was able to quickly and accurately evaluate the pareto optimal set for both case studies in the first case study the proposed algorithm produced a more detailed and dominating pareto front compared to the coarse one evaluated previously and re affirmed that the likelihood of natural recharge exceeding 54 gl yr is very low in the second case study the proposed algorithm quickly evaluated a detailed pareto front illustrating the trade off between model fit and arsenopyrite oxidation the results indicate that at least 13 mol of arsenopyrite must have been oxidized in order to calibrate the reactive transport model for the site a major limitation of the proposed mopso workflow and software is that in order to be most effective one must have access to a multi core computing system this can range from a multi core desktop to many single or multi core desktops to cloud based computing to an hpc cluster etc or any combination thereof this is however the case with all multi objective optimisation approaches due to the propensity for this type of analysis to be computationally demanding however a major advantage of the methods proposed in this study is that they can extend to any general type of multi objective optimization problem there are a number of examples in water resource management e g one may wish to address the trade off between groundwater yield and the overall impact on groundwater dependent ecosystems where pumping rates are the decision variables another important example is within monitoring network design e g siade et al 2017 where one may wish to address the trade off between reducing parameter uncertainty and reducing predictive uncertainty where sampling locations are the decision variables 6 software availability the proposed mopso algorithm was developed as the software pestpp pso the source code for pestpp pso is publicly available within the pest software suite welter et al 2015 https github com dwelter pestpp the pestpp pso statically linked osx and pc executables are also provided in the git repository the data for the antelope valley case study is publicly available via the us geological survey at https pubs usgs gov sir 2014 5166 the data for the reedy creek case study is available to download from csiro data access portal http doi org 10 4225 08 59e079f75f7c2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded primarily by the national centre for groundwater research and training ncgrt financial support for h p and a j s was also provided by the gas industry social environment research alliance gisera of australia the authors thank origin energy as upstream operator of australia pacific lng for the use of their extensive field data set and jeremy white for his technical support in the implementation of pest computational resources were provided by csiro with technical support provided by ondrej hlinka for the use of these hpc systems appendix a the formulation of the benchmark problems considered in this study are as follows kita et al 1996 9 max x φ ϕ 1 ϕ 2 ϕ 1 x 1 2 x 2 ϕ 2 1 2 x 1 x 2 1 subject to 1 6 x 1 x 2 13 2 0 1 2 x 1 x 2 15 2 0 5 x 1 x 2 30 0 0 x 1 x 2 7 kursawe 1991 10 min x φ ϕ 1 ϕ 2 ϕ 1 i 1 2 10 exp 0 2 x i 2 x i 1 2 ϕ 2 i 1 3 x i 0 8 5 sin x i 3 subject to 5 x 1 x 2 x 3 5 deb 1999 11 min x φ ϕ 1 ϕ 2 ϕ 1 x 1 ϕ 2 g x h x g x 11 x 2 2 10 cos 2 π x 2 h x 1 x 1 g x if x 1 g x 0 otherwise subject to 0 x 1 1 30 x 2 30 
6267,water resources management often involves models that simulate physical chemical processes to make predictions of future system behavior these predictions often contain uncertainty that must be considered in order to make robust decisions the quantification of this uncertainty is often not conducted in practice due to computational limitations and a lack of flexible software capabilities to bridge this gap we have developed a heuristic multi objective model independent optimization methodology using tcp ip network communications for parallel run management on high performance computing systems the proposed optimization methodology is based on particle swarm optimization pso where the memory like nature of pso makes it ideal for tracing a pareto front that graphically illustrates the trade off between competing objective functions although the focus of this study is on addressing the likelihood of an undesirable or contested model prediction the proposed methodology can be extended to any multi objective optimization context and is also able to handle inequality constraints that reflect additional conditions that must be met along the front we have demonstrated the algorithm on two important real world case studies the first case study involved water allocation issues in antelope valley california usa where the uncertainty in total natural recharge into the valley has raised significant debates over water management the second case study involved the re injection of coal seam gas co produced water into deep aquifers in the surat basin queensland australia where the potential impact of an undesired mobilization of arsenic concentrations needed to be understood and managed this case study required a highly nonlinear field scale reactive transport model and an inequality constraint was also necessary to maintain consistency with a laboratory scale geochemical model the efficiency at which the proposed methodology solved these complex case studies demonstrates its effectiveness for a broad range of applications keywords multi objective optimization particle swarm optimization uncertainty quantification groundwater modeling high performance computing nomenclature cmaes covariance matrix adaptation evolution strategy csg coal seam gas csiro commonwealth scientific and industrial research organisation gl yr gigaliters per year gc scm generalized composite surface complexation model hpc high performance computing mopso multi objective particle swarm optimization modflow finite difference groundwater flow modeling software mpi message passage interface panther parallel non intrusive handling of model runs in environmental management pest parameter estimation software suite pest parameter estimation software suite with advanced parallelization pht3d multicomponent reactive transport software pso particle swarm optimization rmif add run subroutine for adding simulations to the panther queue rmif get run subroutine for retrieving results from panther memory rmif run subroutine for executing simulations in the panther queue rtm reactive transport model slurm simple linux utility for resource management tcp ip transmission control protocol internet protocol b i log base for the transformation of the i th parameter c 1 cognitive constant c 2 social constant f j fitness value assigned to the j th repository position l j loneliness of the j th repository position l max maximum loneliness value for the repository n d total number of objective functions n do number of objective functions for which a pareto set is evaluated n rep repository size n s swarm size p weakly optimal pareto set p parameter vector p ij value of the j th particle for the i th parameter p i lb lower bound for the i th parameter p i ub upper bound for the i th parameter r j j th repository position r uniform random number on the interval 0 1 v ij velocity of the j th particle for the i th parameter z ig g best position for the i th parameter z ij p best position of the j th particle for the i th parameter α exponent used to control emphasis on lonely repository positions δ transformed range of parameters ε i upper limit for the i th constraint ω feasible region ω inertia ϕ i the i th objective function 1 introduction quantitative predictions of the past current and future quality of hydrologic systems and the assessment of potential management and remediation strategies often rely on knowledge derived from complex numerical models for example to accurately forecast the response of an aquifer system to proposed management decisions such as the reduction of agricultural inputs or the implementation of remediation techniques a multitude of coupled physical groundwater flow transport and biogeochemical processes must often be considered and integrated into the modeling prommer et al 2019 in turn the reliability and accuracy of predictive simulations using such models hinges on the degree of uncertainty in model parameters and conceptualization this requires the judicious and computationally expensive calibration of a significant number of process specific parameters that often results in an underdetermined inverse problem moreover this process may need to be repeated for multiple potential conceptual models the inability to objectively and uniquely define a single conceptual model and its parameter values as the best representation of reality can undermine the reliability of model predictions therefore decision makers must employ a means to quantify predictive uncertainty in order to understand the likelihood of success for specific management options this has resulted in a growing need for efficient software that can be easily deployed on high performance computing hpc systems to quantify predictive uncertainty although there exist a number of monte carlo based techniques and software for quantifying predictive uncertainty in water resources management tonkin and doherty 2009 vrugt et al 2009 white et al 2016 siade et al 2017 these methods are often too computationally intensive to be feasible and decision makers must rely on other means to quantify uncertainty one such method is to use multi objective optimization to address the trade off between model calibration and an uncertain or contested model outcome or prediction this is a form of hypothesis testing doherty and vogwill 2016 the solution to this type of optimization problem consists of a pareto front that graphically depicts this trade off function miettinen 1998 this approach allows the decision maker to address the likelihood of a model outcome or future event to occur regardless of the parameters chosen to calibrate the model so long as the model is sufficiently calibrated such an analysis has the potential to be far more computationally efficient than monte carlo based uncertainty analyses because it does not require sampling from a posterior probability distribution and instead focuses specifically on the feasibility of a particular event or prediction of interest there are a few multi objective optimisation tools and techniques available to decision makers but these methods are often either inefficient i e they require numerous model simulations they lack powerful parallel computing capabilities or they cannot honour inequality constraints for example moore et al 2010 evaluated the trade off between i the calibration of a rainfall runoff model and ii the simulation of a particular measured streamflow event using a multi objective formulation of the covariance matrix adaptation evolution strategy cmaes hansen et al 2003 they found that in order for the model to simulate a streamflow similar to the observed flow the trade off in model to measurement errors was too large this likely indicates the presence of a model defect or structure error however this method is computationally expensive and may be intractable for some models if hpc resources are not available moore et al 2010 another example by wöhling et al 2008 is the use of multi objective optimization during calibration to accommodate for model structure error by allowing observation data that is sensitive to model defects to have a relatively larger misfit than the remaining observation data they used the amalgam software vrugt and robinson 2007 to evaluate a three dimensional pareto front that illustrates the trade off between the individual calibration of pressure heads observed at three separate locations in the vadose zone while the use of multi objective optimization for evaluating the trade off in this way shows significant merit practitioners must be cautious as the resulting parameter estimates can still be far from the true parameter values doherty 2015 doherty and welter 2010 the method employed by wöhling et al 2008 is computationally expensive and without parallel computing technologies likely to be infeasible in practice for computationally demanding groundwater models finally a very commonly used application of multi objective optimization is through the implementation of a bayesian regularization procedure where expected values for parameters and their associated probability density functions are assumed a priori gill et al 2006 developed a methodology for evaluating the trade off between prior information and model misfit using the heuristic method of particle swarm optimization pso eberhart and kennedy 1995 bonyadi and michalewicz 2017 which has shown to be a very effective algorithm for multi objective optimization compared to other techniques coello et al 2004 baltar and fontane 2008 however their method and those mentioned previously cannot honour additional inequality constraints that may be required to produce a reasonable pareto front e g one may wish to enforce a non zero discharge at a groundwater drain for every solution along the pareto front furthermore these techniques are not easily parallelized either within a hpc environment or across multiple desktop computers in this study we present a heuristic approach to multi objective model independent optimization that can evaluate the pareto trade off curve for conflicting objective functions either within a hpc system or across multiple desktop computers inequality constraints are implemented to handle additional factors or conditions that must be met for each solution along the pareto front the proposed methodology is based on the approach outlined by coello et al 2004 which uses the pso methodology eberhart and kennedy 1995 however lexicographical ordering was used to calculate fitness in this study pso is based on swarm theory which is intuitively an ideal approach for filling a pareto front with nondominated solutions the method proposed by coello et al 2004 is chosen due its flexibility which largely comes from the fact that it does not rely on complex weighting schemes it has the ability to handle nonlinear inequality constraints and it s relatively efficient which has been thoroughly tested in their work to the best of the authors knowledge however multi objective pso mopso has received little development beyond coello et al 2004 as indicated by cui et al 2017 and has not yet been implemented within a flexible network based parallelized run manager like the so called panther run manager in pest welter et al 2015 nor has it been used to address the uncertainty or likelihood of a particular model prediction our proposed software capability fills these gaps and is based on the same user interface as that of standard pest therefore very little effort is required to set up the algorithm beyond the normal setup of pest input files and through pest simulations can be deployed in parallel on hpc systems across many cores and or across many desktop computers this is possible through the implementation of tcp ip network communication technologies along with artificially intelligent run managers that provide a great deal of flexibility during implementation of the proposed method prior to conducting mopso one should produce at least one solution on the pareto front to enhance the performance of the mopso procedure this workflow and the proposed algorithm was demonstrated with two real world applications where multi objective optimization was necessary to address the feasibility of simulating an unwanted or contested prediction in order to quantify its likelihood the first case study involved water allocation issues in antelope valley california usa where the uncertainty in total natural recharge into the valley has raised significant debates over water management the trade off between model misfit and increasing volumes of net groundwater recharge are evaluated siade et al 2015 the second case study involved the re injection of coal seam gas co produced water into deep aquifers in the surat basin queensland australia where the uncertainty behind the mobilization of arsenic has raised water safety concerns the trade off between model misfit and decreasing quantities of oxidized arsenopyrite was evaluated this application must also adhere to the additional constraint that a numerical model representing laboratory experiments is calibrated within a reasonable tolerance this is an inequality constraint with a specified upper bound rathi et al 2017 this paper starts with a brief background on multi objective optimization and the pso algorithm then we describe the proposed multi objective pso algorithm followed by benchmark results and two illustrative case studies 2 multi objective optimization the objective of this study is to efficiently evaluate a pareto front or curve using highly parallelized computing that illustrates the trade off between the optimization of one objective over the optimization of another e g the weighted least squares objective associated with a particular observation group the ability to simulate a hypothesized outcome adherence to prior information etc we refer to the i th objective function value as ϕ i where i 1 n d and n d is the number of objective functions under consideration the vector of objective functions is denoted as φ consider a vector of parameter values p that when input to a numerical model return a value for each objective function the general unconstrained multi objective optimization problem is therefore written as miettinen 1998 1 min p φ ϕ 1 ϕ 2 ϕ n d subject to p ω where ω is the feasible region for the parameters although the term parameters is used throughout the background theory and the proposed workflow can be applied to any decision variable e g groundwater pumping rates etc the complete solution to the problem in eq 1 is referred to as a weakly pareto optimal set and the optimal objective functions corresponding to this set of parameter values are referred to as the pareto front miettinen 1998 due to the fact that evaluating a continuous pareto function is generally impossible especially when the model under investigation is numerical in the sense that it is simulated using external software e g modflow harbaugh 2005 the pareto function is usually approximated using a discrete set of parameter vectors the optimality conditions for this discrete set of parameter vectors can be summarised as follows baltar and fontane 2008 a parameter vector p 1 is said to be pareto dominant or efficient over another vector p 2 if and only if ϕ i 1 ϕ i 2 i 1 n d therefore if there is at least one objective for p 1 that is greater than that of p 2 p 1 does not dominate p 2 a parameter vector p j is said to be nondominated if there exists no other parameter vector in a given set that dominates it i e for each parameter vector in the set either ϕ i j ϕ i k i 1 n d k j or there is at least one objective i for which ϕ i j ϕ i k a weakly pareto optimal set p is a set of parameter vectors that are nondominated over the feasible region miettinen 1998 the pareto front is the set of objective function values φ corresponding to the parameter vectors in p often existing optimization software convert eq 1 into a single objective optimization problem when attempting to define the pareto front e g pest s pareto mode and the method proposed by gill et al 2006 this is accomplished using a sophisticated weighting scheme where each objective is assigned a weight based on some criteria or fitness function this form of scalarization has drawbacks in that a bad choice of weights can result in a suboptimal pareto front the algorithm presented in this study alleviates the need for scalarization and maintains the independence of each objective the solution to eq 1 can be very useful to decision makers when attempting to evaluate effective solutions for model calibration and water resource management however in practice unconstrained optimization does not consider additional factors that may affect decision making for example each pareto optimal solution for a particular groundwater management problem must also adhere to i the drinking water threshold of a specific contaminant or ii sufficient water levels to maintain groundwater dependent ecosystems etc of course factors like these can be included as additional objective functions but this inflates the dimensionality of the optimization problem which can make the analysis computationally infeasible therefore these additional factors or conditions are included in the optimization problem as ε constraints miettinen 1998 2 min p φ ϕ 1 ϕ 2 ϕ n do subject to ϕ j ε j j n do 1 n d p ω where n do is the number of objective functions for which a pareto front is obtained and ε j is the upper bound for constraint j for example assume that for a particular calibration exercise there exist a large amount of 1 bromide concentration observations 2 arsenic concentration observations and 3 a wealth of prior information from hydrogeological and biogeochemical investigations i e n d 3 both observation groups are sensitive to the flow and transport parameters but arsenic is the only observation data type sensitive to the biogeochemical parameters generating a pareto front between these two observation groups in terms of calibration can be illuminating when choosing the appropriate calibration parameter set that will be used for making predictions to maintain agreement with prior information and to reduce the dimensionality of the optimization problem an upper bound can be set on its associated objective function therefore this example would contain two objectives n do 2 and an ε constraint that represents the prior information the ε value for this constraint should reflect the maximum deviation the parameters are allowed to stray away from expected values in other words in this example every point on the resulting pareto front would also reasonably adhere to prior information it is important to note that even for a small number of objective functions the pareto front can be difficult to obtain however since the early 2000 s the heuristic algorithm pso has shown great promise in efficiently approximating the pareto front due to its relatively high speed of convergence and its ability to obtain a diverse set of solutions spanning the entire front kennedy et al 2001 coello et al 2004 one attractive feature of the pso algorithm is its heuristic derivative free nature which excels in problems that are highly nonlinear such as those relating to the reactive transport of solutes in groundwater or those that involve discrete or integer valued parameters and observations 3 algorithmic framework multi objective particle swarm optimization consistent with the objective of this study the algorithm chosen for multi objective optimization regarding calibration and management for environmental models should be highly parallelized able to handle nonlinear nonconvex objectives constraints and alleviate the need to develop complex weighting schemes through scalarization the primary algorithm employed to accomplish this is through multi objective pso mopso which is based largely on that proposed by coello et al 2004 however for this study lexicographical ordering is used for promoting diversity along the pareto front 3 1 basic particle swarm optimization basic pso is a simple algorithm that utilizes the sociocognitive behavior associated with individuals or particles interacting with each other within a swarm kennedy et al 2001 in the context of parameter estimation a particle is defined as an n p dimensional vector of parameter values where n p is the number of parameters the particle s position consists of its location in the n p dimensional parameter space defined by ω the swarm keeps track of a global best position denoted as g best and each individual particle keeps track of its own local best position denoted as p best in the context of parameter estimation the magnitude of the least squares objective function is used to evaluate whether one position is better than another initially the particles p j 0 j 1 n s are assigned random positions based on the prior probability distribution of the parameters where n s is the number of particles in the swarm at each iteration a velocity is calculated for each particle and the particle moves in the corresponding direction as follows eberhart and kennedy 1995 3 p ij t 1 p ij t v ij t 1 where p ij is the parameter value assigned for the i th parameter in j th the particle v ij is the velocity assigned to the parameter and t is the iteration count the velocity of a particle is determined based on the best position observed by both the swarm and the individual particle 4 v ij t 1 ω t v ij t c 1 r 1 z ij t p ij t c 2 r 2 z ig t p ij t where z ij is the local p best value for the i th parameter observed by the j th particle z ig is the value of the i th parameter associated with global g best position of the swarm g represents the index of the particle with the g best position c 1 is referred to as the cognitive constant c 2 is referred to as the social constant ω is referred to as inertia r 1 and r 2 are uniform random numbers on the interval 0 1 particles are updated iteratively using eqs 3 and 4 until convergence is achieved which typically occurs when the g best position is no longer being updated this basic form of single objective pso has been successfully applied in several recent biogeochemical and reactive contaminant transport studies rawson et al 2016 rathi et al 2017 rathi et al 2017 jamieson et al 2018 sun et al 2018 prommer et al 2018 the implementation of pso in these studies is conducted using standard pest interface protocols pest uses tcp ip network communications to parallelize numerous model runs either within a single computer e g hpc system or across multiple computers welter et al 2015 a capability that is currently unavailable in other existing software the pest panther run manager is used to parallelize the simulations of the swarm at each iteration since the swarm can be of any size and each simulation in the swarm is completely independent the use of this form of parallel computing is fitting providing a great deal of flexibility in the implementation of pso for example if the user has only 45 cores available they can use a swarm size of 45 which requires the clock time of a single model evaluation per iteration a swarm size of 90 will require twice this clock time etc additionally individual model simulations in the swarm can be spawned or removed at any time without disrupting the progress of the pso algorithm this technology is also employed in the mopso methodology described in the following 3 2 multi objective optimization with pso the mopso algorithm employed in this study is largely based on the method presented by coello et al 2004 with some modifications for improved performance therefore we adopt some of their terminology here the g best position assigned to a given particle in the swarm at a given iteration can correspond to any nondominated solution obtained thus far therefore nondominated solutions must be recorded as the algorithm proceeds this record or memory is referred to as a repository in this study we refer to solutions in the swarm as particle positions and solutions in the repository as repository positions the j th repository position is denoted as r j and the repository size is denoted as n rep at each iteration the dominance relationships within the swarm and the repository are calculated if a particle in the swarm dominates a repository position s that particle if completely nondominated by other particles will enter the repository and the now dominated repository position s will be discarded for practical implementation of this method there must be a maximum repository size set by the user at each iteration if the repository size exceeds this value repository positions are discarded until the maximum repository size limitation is met most mopso algorithms discard repository positions in an effort to promote diversity of solutions along the pareto front bartz beielstein et al 2003 coello et al 2004 wang and singh 2006 a review of various methods can be found in banks et al 2008 in other words repository positions located relatively close to many other positions in terms of their respective objective functions i e clustered together in objective space are selectively discarded there have been a number of methods proposed for carrying out this process which is often rely on fitness metrics hu and eberhart 2002 use a dynamic neighborhood concept which assigns fitness based on the objective functions of neighboring positions in the objective space bartz beielstein et al 2003 and coello et al 2004 define fitness based on the implementation of an adaptive grid wang and singh 2006 use a fuzziness concept combined with niching and fitness sharing in the algorithm presented herein we implement a lexicographical ordering approach which differs and is arguably more efficient than the adaptive grid based approach of coello et al 2004 generally positions with the smallest fitness are removed first once the dominance relationships are determined and the repository size limitation is met at a given iteration the new velocities are calculated velocities are determined in the same way as in basic pso eq 4 however the g best and p best positions are assigned to each particle in the swarm differently determining the p best position for a particle in the swarm is straightforward if the current position of the particle dominates its p best position its p best position is updated to that of the current position if neither the p best nor the current position dominate one of them is chosen randomly for the p best position the choice of the g best position assigned to each particle in the swarm is more challenging since there are many potential nondominated solutions in the repository most mopso studies in the literature appear to use the same fitness concepts used for controlling repository size to assign g best positions to the particles in the swarm similarly fitness is calculated in such a way as to promote diversity by assigning greater fitness values to positions located furthest in objective space from other positions in the repository a random sampling procedure is then used to select a g best position from the repository for each particle in the swarm based on fitness which is a probabilistic measure on the interval 0 1 hu and eberhart 2002 bartz beielstein et al 2003 coello et al 2004 wang and singh 2006 banks et al 2008 however gill et al 2006 assign a fitness value to each position on the pareto front based on a scalarization of the objective functions then the position with the median fitness is assigned as the g best position for calculating all particle velocities 3 3 promoting diversity along the pareto front at each iteration of the mopso algorithm described in this study the repository must be updated and a fitness value assigned to each corresponding position if the repository size is too large positions must be removed until the size limitation is met then a roulette wheel selection procedure is used to randomly select repository positions to be assigned as the g best position for each particle in the swarm this roulette wheel selection procedure proceeds by 1 randomly choosing a repository position and 2 accepting the repository position as the g best position for a particle if a uniform random number generated on the interval 0 1 falls below the fitness or probability that is assigned to that repository position this is repeated for each particle in the swarm until each particle is assigned a g best position from the repository the fitness value assigned to each repository position for either deletion or selection as a g best position is determined in such a way as to promote diversity for example if a repository position is located within close proximity in terms of objective function values to a number of other repository positions it should be removed from the repository if the repository is too big or it should be assigned a relatively small fitness value so it is less likely to be chosen as a g best position within the swarm the converse is true for repository positions that are far from other repository positions in objective space fig 1 presents an illustrative example of a potential scenario for repository positions based on visual inspection if a repository position is to be removed it should be either 4 or 5 accordingly positions 4 and 5 should be assigned the smallest fitness values coello et al 2004 used a grid based methodology to assign fitness values to each repository position based on the number of other repository positions residing in the same respective grid cell or hypercube however under some circumstances this method can be inefficient as it may produce granular pareto fronts if the grid spacing i e hypercube size is not optimal which is difficult to determine at the outset of the problem at hand the optimal hypercube size is dependent on several factors including the absolute minimum value for each objective function i e the extreme points on the pareto front the number of particles in the swarm the repository size etc for example if a particular hypercube was relatively large compared to the distribution of the repository positions at a particular iteration this hypercube could encompass a region of the objective space consisting of both a large cluster of positions and one position that is relatively far from that cluster in this situation the same fitness value would be assigned to each repository position within this hypercube which does not promote the fact that there is one position in the hypercube that is relatively far from the others ideally this lonely position should be assigned a larger fitness value in an effort to fill in the pareto front around it for example in fig 1 positions 3 4 5 6 and 7 would be assigned the same fitness using this grid based approach however position 7 should have a greater fitness than that of the other positions in hypercube c conversely if the size of the hypercubes was relatively small compared to the distribution of the repository positions each nonempty hypercube could run the risk of only containing a single position which would result in the same fitness value assigned to all repository positions which again may not consider their distribution in objective space in this study we promote diversity by calculating the fitness value assigned to each repository position based on how lonely that position is with regard to the repository positions surrounding it this is accomplished via lexicographical ordering which simply orders the pareto set with one objective function value in an increasing order and in doing so the other objective function will by the properties of nondominance be ordered in a decreasing order then the fitness for a given repository position can be calculated based on its euclidean distance in objective space from the repository position above and below that position in this ordered list using position 2 in fig 1 as an example this lexicographical ordering approach would select positions 1 and 3 during the fitness calculation in comparison if a simple euclidean distance were employed to find position 2 s nearest neighbors positions 3 and 4 would be selected the use of these two particles for determining fitness does not properly reflect the loneliness of position 2 i e the gap observed between positions 1 and 2 once the nondominated solutions are ordered lexicographically the appropriate neighbors are selected and a measure of the loneliness l j of a repository position j is calculated using the sum of the euclidean distances between the repository position and its neighbors 5 l j φ j φ j 1 2 φ j φ j 1 2 to convert this metric into a probability of acceptance for the roulette wheel selection scheme i e converting it to a value that ranges from 0 1 6 f j l j l max α t where f j is the fitness value assigned to repository position j l max is the maximum loneliness value for the repository and the exponent α controls the emphasis placed on lonely positions e g large values of α will keep the fitness of the loneliest position at 1 0 but will drive the fitness of the remaining positions to 0 0 in this case the g best value assigned to each particle in the swarm will be set to the loneliest position in the repository this is ideal if convergence is nearly obtained and the user wishes to fill in the pareto front as uniformly as possible therefore the value for α should increase as the repository becomes full at which point it should remain constant 3 4 extreme values and pareto optimal subsets often in multi objective optimization the decision maker is only interested in a subset of the weakly pareto set this is due to the fact that many of the solutions in the weakly pareto optimal set may have marginal trade offs with the solutions surrounding them this can be visualized as regions of the pareto front that are nearly vertical or horizontal decision makers are primarily interested in solutions that exhibit a significant trade off in one objective due to an increase or decrease in another additionally decision makers may not be interested in solutions where objective functions have extreme values e g a water manager may not be interested in solutions where the total groundwater yield is below the required demand or in the case of parameter estimation the decision maker will have some idea for an upper bound on the least squares objective function i e the maximum level of misfit allowed all values above this maximum level of misfit are of no interest this results in the need for only a subset of the full weakly pareto optimal set therefore in the algorithm proposed in this study the user can enter an upper bound on each objective function specified such that the resulting pareto optimal subset resides within these bounds upper bounds on objective functions are handled by the proposed algorithm as follows fig 2 assume that at some iteration a particle in the swarm violates the upper bound on any objective function that particle will not enter the repository regardless of whether or not it is nondominated by the positions currently in the repository managing the p best position for that particle however is not so straightforward if that particle has had in a previous iteration objective functions that satisfy their associated upper bounds the p best position is not updated however if the particle has never been feasible in terms of objective function bounds the p best position is updated only if the current position is closer to the upper bounds than the currently saved p best position the closeness of a particle position to the upper bounds of the objective functions is measured as the euclidean distance of the particle s objective function values to their associated upper bounds this distance only applies to objective functions that violate their upper bounds objective functions satisfying upper bounds do not contribute to this distance to remove the effects of the vastly differing magnitudes of the objective functions their values are divided or normalized by their associated upper bound values before calculating this distance this process is outlined in fig 2 it is important to not only constrain objective functions within upper bounds but also to ensure that the resulting pareto front spans the entire region encapsulated by these bounds to achieve a pareto set that reaches the upper bounds of each objective function the extreme values in the repository i e the solid black dots in fig 1 must receive significant attention in the roulette wheel selection mechanism in order to achieve this these extreme repository positions are always assigned a fitness value of 1 0 regardless of their associated grid based or loneliness metric this will ensure that at least some of the particles in the swarm are being assigned these extreme values as their associated g best positions at each iteration 3 5 handling ε constraints evaluating high dimensional pareto fronts can be computationally infeasible this is due to the fact that the repository size must be quite large which may require an extremely high number of model runs to sufficiently populate it furthermore visualizing pareto fronts with more than two objective functions can be cumbersome the number of competing objective functions can be reduced by either employing scalarization or ε constraints miettinen 1998 for example if a pareto analysis involved five objective functions this analysis could be reduced to two objective functions by placing an appropriate upper bound on the remaining three objective functions in this study we employ a simple method for handling ε constraints that is similar to that discussed in the previous section for pareto optimal subsets fig 2 a particle position in the swarm is considered feasible if it does not violate any of the ε constraints eq 2 an infeasible position is more feasible than another infeasible position if it violates the ε constraint to a lesser extent the magnitude of this violation is measured by summing the difference between each objective function value and its corresponding upper bound or ε value this sum is only calculated using the differences associated with constraints that are actually violated i e ε constraints that are satisfied do not contribute to this sum the resulting algorithm begins by populating the swarm with positions based on the prior probability distributions of the parameters therefore at the outset of the algorithm many or perhaps all particles may violate the ε constraints then at each iteration the repository is updated only with the particle positions that are feasible however some adjustments to the choice of g best and p best positions for the swarm must be made if the repository is empty i e there are no feasible particle positions obtained so far the g best position assigned to each particle in the swarm is that which violates the ε constraints the least once there is at least a single feasible position in the repository the g best position assigned to each particle is selected from the repository normally as explained in the previous sections if a particle in the swarm has never been feasible its p best position is updated only if the current position is more feasible if a particle has been feasible previously but its current position is no longer feasible the p best position is not updated for that particle if a particle is feasible and its current position is feasible the p best position is updated normally as described in the previous sections 3 6 parameter transformations commonly during the calibration of groundwater flow and reactive transport models using the popular gauss levenberg marquardt algorithm doherty 2015 parameters are transformed using a logarithm with base 10 this is particularly beneficial for parameters that span many orders of magnitude such as hydraulic conductivity and can alleviate some of the issues regarding model nonlinearity with respect to the parameters or decision variables doherty 2015 the effectiveness of the mopso algorithm presented in this study also stands to benefit from this approach however rather than applying a logarithmic transformation with base 10 the base is chosen separately for each parameter such that the overall range of variability of each parameter between its transformed upper and lower bounds is equivalent this is accomplished by firstly determining the parameter with the maximum range in terms of magnitude i e in terms of a base 10 once this parameter is selected its transformed range is recorded δ using base 10 then the logarithm base b i for the i th parameter is chosen such that its respective transformed range is equal to δ 7 b i p i ub p i lb 1 δ where p i ub and p i lb are the i th base parameter s upper and lower bounds respectively once this is done for each parameter the transformed parameters will all have precisely the same transformed range however the transformed upper and lower bounds may differ therefore the mopso algorithm sees the parameters as having the same variability furthermore it is often recommended that assigning a maximum velocity v max to each particle can improve convergence eberhart and kennedy 1995 coello et al 2004 however it is difficult in practice to assign such a value for each parameter as they may have different magnitudes and ranges applying the transformation method described above alleviates this requirement as each transformed parameter now resides on the same range therefore a single maximum velocity can be set for the entire parameter set as a percentage of the now uniform parameter range δ in summary the proposed parameter transformation not only improves performance it also simplifies the specification of v max 3 7 benchmark test functions the mopso algorithm developed in this study was tested with three commonly used heuristic multi objective optimization test functions to illustrate its effectiveness and the quality of the resulting pareto fronts the three test functions considered for this study were developed by kita et al 1996 kursawe 1991 and deb 1999 the formulae for the associated multi objective optimization problems are listed in appendix a and the results are shown in fig 3 each benchmark was conducted with 100 iterations using a repository size of 100 swarm size of 100 and α set to 2 0 the results indicate that the mopso algorithm presented in this study is very effective at solving highly nonlinear constrained multi objective optimization problems generally new heuristic algorithms require numerous trials which are analyzed statistically to both demonstrate the properties of the algorithm and make comparisons with other existing algorithms this is often referred to as a random seed analysis although the mopso algorithm presented in this study has been tested numerous times for a number of conditions such an analysis was beyond the scope of this study as we adopt and combine the strategies of other studies for which such random seed analyses have already been conducted coello et al 2004 however comparing the performance of the benchmark problems considered in this study with those of coello et al 2004 under the same control variables e g inertia values etc it is clear that our approach is at least equally as effective furthermore comparisons of overall computational performance of our approach with that of others is generally not possible due to the use of advanced tcp ip parallelization techniques that are not available for other algorithms that is our approach will most likely outperform another simply because of the flexibility and efficiency of the panther run manager that is employed in our method in fact the use of such technologies provides a significant advantage of our approach over others for practical reasons welter et al 2015 the focus of this study is therefore shifted towards addressing real world water resources case studies involving highly nonlinear complex multi objective optimization problems and the implementation of the mopso approach within multiple hpc systems 3 8 workflow for efficient mopso performance when implementing the proposed methodology in practice for hypothesis testing the first step in achieving an effective pareto front is to calibrate the model this will provide a point on or near to the pareto front having this point as a particle in the initial swarm will dramatically speed up the swarm s convergence by filling in the front around this point in fact if feasible one should calibrate the model under any number of scenarios to provide multiple points near the pareto front for optimal performance for example if one wishes to use mopso to address the trade off between model misfit and a contested outcome one may want to calibrate the model in such a way as to achieve this contested outcome as closely as possible producing a poor model fit having done this in addition to the best calibrated model one would potentially provide two points in very different portions of the pareto front the mopso algorithm will then proceed to fill in the front around these points relatively quickly in summary the computational savings associated with calibrating the model and using this result as an initial particle position in the swarm for mopso is comparable to the expense of conducting the calibration itself therefore it is recommended that one always calibrate the model prior to conducting mopso 3 9 mopso parallelization via network communications a major advantage of the proposed mopso methodology is its ability to be conducted in parallel across many compute cores on a wide variety of computing hardware this is due to the fact that each particle s simulation is independent of the other particles in the swarm that is if the swarm size is n s a number of n s independent model simulations are required at each iteration of the mopso procedure this obviates the need for shared memory parallel programming and can be conducted across a network allowing for the modeller to create a virtual cluster amongst multiple desktop computers while still providing the means to operate within an hpc cluster this is accomplished via tcp ip communications whose programming operates similarly to message passage interface mpi techniques the pest software suite provides a series of subroutines that can be employed to send and receive parameters or decision variables and model outputs respectively over a network or the internet welter et al 2015 in this study the rmif add run fortran subroutine was used to add parameter sets to the panther run manager queue and the rmif get run subroutine was used to retrieve their corresponding model outputs of interest once the simulations have completed the rmif run subroutine executes the simulations that are in the queue one for each parameter set added this subroutine contains the panther run manager an artificially intelligent software capable of handling a series of issues in parallel run management such as sending queued simulations to new worker cores as they become available reassigning simulations to worker cores that have disappeared taking optimal advantage of faster compute cores by monitoring simulation run times etc the reader is referred to the pest website for more details on the implementation and execution of the panther run manager http www pesthomepage org pest and pestpp php the implementation of the method proposed in this study is relatively simple and involves two basic steps here we use beekeeping terminology to define parallel run management 1 initialize the run manager the first step is to initialize the mopso procedure by starting the queen bee core the user supplies the pest control file and a port number for which the network communications are to occur on the associated computer once this is done the queen core will remain idle until it receives communication from the worker cores 2 stage the workers and execute the second step involves staging or making copies of the simulation model on each worker bee compute core and pointing them to the queen the user provides a simplified version of the pest control file the ip address of the queen core and the port number over which the communication will occur on the queen s computer which can be the same computer as that of the worker core the worker then sends a message to the queen and from there the panther run manager handles the sending and receiving of information over the network through this methodology worker cores could be on any computer in the world and participate in the mopso procedure so long as they have access to an internet connection this is a very sophisticated implementation of pso and mopso and well suited for the swarm like nature of these algorithms to the best of the authors knowledge this approach to the operation of any pso algorithm is the first of its kind 4 results and discussion to demonstrate the effectiveness of the methodology developed in this study the proposed mopso algorithm was applied to two independent real world case studies these two case studies involve complex hydrological decision making with potentially profound implications for the environmental and the economy 4 1 quantifying natural groundwater recharge antelope valley california usa antelope valley is a topographically closed basin located in mojave desert of southern california just north of the city of los angeles fig 4 the antelope valley groundwater basin has an aerial extent of approximately 2400 km2 and an arid to semi arid climate prior to 1972 groundwater has been the primary source of water for the valley with the major water use being agricultural as a result groundwater levels have declined significantly resulting in increased pumping lifts reduced well efficiency and significant land subsidence due to recent increases in population growth and agricultural practices future groundwater demand is likely to rise as a result recent legal proceedings have led to the adjudication of the antelope valley groundwater basin the los angeles county superior court has ruled that the basin is in a state of overdraft los angeles county superior court 2011 the court has also set an upper limit on the total sustainable amount of groundwater that can be extracted from the basin beeby et al 2010b beeby et al 2010a this limit is based on the fluxes associated with numerous components of the water budget throughout the basin however the most uncertain and sensitive component of this water budget is the total annual natural recharge into the basin the testimony of many experts in the adjudication process have resulted in estimates of natural recharge that range from 37 to 197 gl yr siade et al 2014 historically the us geological survey has developed several numerical models to simulate groundwater flow and subsidence in the antelope valley siade et al 2014 leighton and phillips 2003 durbin 1978 the purpose of all of these models was to provide a tool to aid in the management of the valley s groundwater resources the analysis contained in each study resulted in an estimate of the total annual natural recharge into the basin however the most recent study by siade et al 2015 is the first to quantify the uncertainty of this estimate fig 4 illustrates the extent of the model grid boundaries and the locations of the model cells used to simulate natural recharge which primarily occurs along the mountain fronts as subsurface inflow as part of the total natural recharge uncertainty quantification siade et al 2015 used the sequential scalarization pareto trade off methodology contained in the pest software to visualize the relationship between model calibration and total annual natural recharge volumes the calibration dataset consisted primarily of measured water levels and land surface deformations as a result of land subsidence their study showed that for total natural recharge volumes exceeding 54 gl yr the model calibration began to deteriorate rapidly indicating that recharge rates above this value are highly unlikely the pareto method employed in siade et al 2015 consists of placing a penalty within the least squares objective function to penalize the parameter estimates for producing a prediction that deviates from some desired prediction in this case the desired prediction is a very large value for total natural recharge the penalty function when incorporated into the least squares objective function is weighted such that for small weights the influence of this penalty is negligible and vice versa the pareto curve is therefore calculated by incrementally increasing this weight and re calibrating the model for each weight value considered however this method can be difficult to implement because it is not clear ahead of time what the initial weight should be and how this weight should be adjusted furthermore this method requires the model to converge for every parameter set tested as the pareto front is traversed which is often a challenge for highly nonlinear models therefore the implementation of this method requires a trial and error process by which many weight management schemes must be tested while maintaining model convergence for all reasonable parameter values as a result of these issues the pareto curve presented in the study by siade et al 2015 was very coarse with only eight significantly different nondominated solutions some of these solutions also consisted of very large weighted least squares objective function values representing solutions that are very far from calibration furthermore their curve may not be accurate due to the nonlinear nature of the model and the non uniqueness of the estimates of model parameters the last solution on the trade off curve presented by siade et al 2015 dominates the previous solution along the front this inconsistency is likely due to the nonlinearity associated with simulating subsidence as discussed by siade et al 2015 the mopso methodology proposed in this study overcomes these drawbacks and can produce a relatively smooth detailed pareto front within user specified bounds as mentioned previously it is important to use at least one solution near the pareto to initialize the swarm prior to running the mopso procedure the ten solutions obtained by siade et al 2015 were used as starting positions for ten particles in the initial swarm these initial solutions improve the performance of the mopso procedure if fewer initial solutions were available the convergence of the mopso procedure will likely be somewhat slower there were 203 independent parameters consisting of hydraulic conductivity zones mountain front recharge pilot points storage properties including those associated with subsidence fault conductance pre consolidation head among others a single forward simulation of the model took about 2 min on a basic desktop computer both the swarm size and the repository size were set to 100 with an α value of 2 0 an upper bound was placed on the weighted least squares objective function that was approximately five times as large as the calibrated result reported by siade et al 2015 weighted least squares objective values above this bound are well beyond reason and therefore unimportant for this study the mopso procedure was deployed across two 16 core virtual unix machines on the commonwealth scientific and industrial research organisation s csiro bowen research cloud fig 5 displays the resulting pareto front after 400 iterations however the pareto front was no longer changing significantly after about 200 iterations many of the solutions obtained by siade et al 2015 were maintained in the repository however some of these solutions were suboptimal and discarded the mopso methodology proposed in this study was able to find solutions that dominate the results of siade et al 2015 showing that the proposed mopso method can be very effective at approximating the true pareto front the results of this study continue to validate the results of siade et al 2015 in that values of total natural recharge above 54 gl yr continue to be unreasonable the average residual increases by 50 at a value of 60 gl yr it is important to note that without the ten initial solutions provided by siade et al 2015 the mopso procedure would have required more iterations to achieve the final result show in fig 5 however as mentioned previously one should always endeavor to provide at least one solution near the pareto front prior to initializing the mopso procedure 4 2 re injection of coal seam gas co produced groundwater reedy creek queensland australia recently the production of coal seam gas csg as a source of energy has risen dramatically worldwide with the usa and australia being the largest producers csg consists primarily of methane and is extracted from deep subsurface coal seams by lowering the surrounding groundwater pressure via groundwater extraction although this process provides a very efficient source of energy it is accompanied by excessive amounts of co produced groundwater with future estimates indicating that a total of 70 gl yr of groundwater will be extracted for csg in australia alone dnrm 2016 managing such large volumes of co produced groundwater is not straightforward considering its high salinity and residual concentrations of organic substances due to a number of climatic ecological and social factors for some locations including reedy creek the injection of csg co produced groundwater into deep aquifers after a comprehensive treatment process is viewed as the most viable water management option prior to the large scale injection of csg co produced groundwater at the reedy creek site a comprehensive pilot study was conducted to understand the potential changes in groundwater quality rathi et al 2017 a short term injection trial was conducted where treated csg co produced groundwater was injected for a short period 85 days into the deep precipice formation of the surat basin allowed to react with the subsurface environment during a storage period 64 days and subsequently extracted 309 days the quality of both the injectant and the extracted groundwater was monitored periodically in addition to the injection trial supporting laboratory experiments were conducted with sediment samples collected from the targeted injection zone to better characterize the local geochemistry for a detailed description of both the injection trial and the laboratory experiments see rathi et al 2017 due to the presence of elevated arsenic concentrations in the extracted groundwater a detailed modeling study was also conducted to understand the mechanisms responsible for subsurface arsenic mobilization given that neither the ambient groundwater nor the injectant contained arsenic concentrations above the detection limit a radially symmetric groundwater flow and reactive transport model rtm was developed for the field site fig 6 using modflow harbaugh 2005 and pht3d prommer et al 2003 as simulators of relevant hydrogeological and biogeochemical processes respectively field scale reactive transport simulations incorporated a laboratory derived generalized composite surface complexation gc scm model davis et al 1998 that was constrained by the experimental data collected in batch sorption experiments this allowed for the adequate simulation of arsenic sorption behaviour under variable geochemical conditions initial model results indicated that arsenic de sorption alone primarily caused by an injection induced rise in ph could not adequately explain the observed arsenic concentrations of the extracted groundwater due to the presence of significant sulfate concentrations in the extracted groundwater it was then hypothesized that arsenic could also be derived through a second release mechanism i e the oxidation of arsenic bearing pyrite a process that was previously shown to occur in response to the injection of aerobic water into pyritic aquifers wallis et al 2010 wallis et al 2011 however the concentration of dissolved oxygen in the injectant was periodically monitored and consistently found to be below the detection limit nevertheless only with the oxidation of pyrite and the associated co release of arsenic in the following referred to as arsenopyrite oxidation was the rtm able to reproduce both the observed sulfate and arsenic concentrations this raised critical questions regarding the potential source and nature of the oxidant as well as the relative contributions of i arsenic de sorption versus ii arsenopyrite oxidation to the observed arsenic concentrations as a result rathi et al 2017 conducted a monte carlo uncertainty analysis to quantify the effect that correlations between these two processes may have on the rtm model s predictions of long term fate and transport of arsenic although they found a significant degree of predictive uncertainty all realizations of their method indicated that future arsenic concentrations are likely to remain below drinking water standards since the injectant water showed non detectable amounts of dissolved oxygen and the characterization of aquifer sediment samples did not confirm the presence of arsenopyrite the question on how much arsenic must be produced from arsenopyrite oxidation in order to achieve a well calibrated rtm remained clearly in the absence of supplementary and more decisive field observed geochemical evidence the oxidation should not need to be considered in the model while on the other hand there was also some positive indication that the process had occurred and cannot be ignored to resolve this contradiction we were interested in elucidating the minimum required contribution of the oxidation process to address this problem we have adopted the mopso methodology developed in this study the competing objectives in this case are i rtm calibration or misfit and ii total moles of arsenopyrite oxidized however since the rtm employs an upscaled laboratory gc scm to simulate sorption dynamics we must maintain the condition that this laboratory gc scm is always calibrated within a reasonable tolerance this condition is maintained via an ε constraint therefore the multi objective optimization problem becomes 8 min p ϕ rtm ϕ as pyr subject to ϕ gc scm ϕ gc scm max where ϕ rtm and ϕ gc scm are the weighted least squares objective functions employed by rathi et al 2017 and ϕ as pyr is the total moles of arsenopyrite oxidized in the rtm simulation the laboratory dataset consisted of measured arsenic and phosphate concentrations and the injection trial dataset consisted of measured arsenic phosphate ph and sulfate concentrations the calibration threshold for the gc scm ϕ gc scm max employed by rathi et al 2017 was used for this study to solve the problem in eq 8 a total of 14 parameters were considered consisting of both equilibrium constants and surface site densities for surface complexation reactions dispersivity heat conduction oxidation rate of arsenopyrite and the dissolved oxygen concentration in the injectant both the swarm and repository size were set to 100 and an α value of 2 0 was used as mentioned previously it is best to initialize the mopso swarm with solutions near the pareto front initial solutions were taken from the calibration constrained monte carlo results in rathi et al 2017 along with a single parameter set developed in this study that results in very little arsenopyrite oxidation these initial solutions reside on the two extremes of the pareto front essentially providing two initial pareto optimal solutions i e the monte carlo results are clustered together near the maximum mass of arsenopyrite oxidized a single forward flow and reactive transport simulation for this case study required about 45 min to complete on the csiro pearcey cluster a unix system using the simple linux utility for resource management slurm the swarm was fully parallelized on the cluster such that one iteration of the mopso algorithm required about 45 min therefore for example 10 iterations required only about 7 5 h to conduct the resulting pareto front and its associated convergence is depicted in fig 7 the results depicted in fig 7 illustrate that the convergence of the mopso algorithm proposed in this study is quite fast the algorithm produced a reasonable approximation of the pareto front after only 10 iterations 1000 forward model simulations after 20 iterations the pareto front has essentially fully converged as very little change is observed over the next 80 iterations this is a very attractive feature especially for nonlinear models with long cpu run times therefore the mopso algorithm presented in this study is a very efficient method for quantifying the likelihood of smaller amounts of arsenopyrite oxidation at the study site the pareto front resulting from eq 8 fig 8 indicates that the total amount of arsenopyrite oxidized is likely to be above 13 mol and that it has a large relative contribution to the observed aqueous arsenic concentrations at the well while the calibration can perhaps be argued to be reasonable at point d at point c the misfit for aqueous arsenic concentrations has become significant this marks the point where the calibration deteriorates which corresponds to approximately 13 mol of total arsenopyrite oxidized another interesting result is the inflection of the pareto front at point b the curve between points a and b is relatively steep meaning that a large improvement in calibration is achieved for very little increase in oxidized arsenopyrite this is due to that fact that parameter combinations can produce a situation where pyrite is being oxidized but the amount of arsenic incorporated into its structure is still very low this allows the model to match sulfate concentrations and ph quite well reducing the weighted least squares objective function however once observed sulfate concentrations and the ph data are matched as best as possible the fraction of arsenopyrite must begin to increase in order to continue reducing the least squares objective i e matching the observed aqueous arsenic concentrations hence the change in slope at point b fig 8 after this point large trade offs are needed in order to achieve a reasonable calibrated arsenic response i e up to point d the results of this pareto analysis also agree well with the monte carlo uncertainty analysis reported in rathi et al 2017 the monte carlo results produce total arsenopyrite oxidation quantities roughly between 13 and 17 mol since some of these results are used to initialize the mopso algorithm this range can be seen in fig 7 after 10 iterations the initial parameters that were used to initialize the mopso algorithm are still clustered at the bottom right corner of the pareto front ranging between 13 and just over 16 mol of arsenopyrite oxidized therefore the mopso algorithm developed in this study confirms the results of rathi et al 2017 with a comparably much smaller computational effort 5 conclusions we have developed a multi objective optimization algorithm based largely on the algorithm presented by coello et al 2004 however lexicographical ordering is used for fitness calculations the proposed algorithm uses swarm theory i e pso to quickly evaluate pareto optimal solutions we have incorporated our algorithm into the pest software suite welter et al 2015 for parallel implementation across many compute cores using tcp ip communications this approach to parallel computing is extremely advantageous for the proposed mopso algorithm as it provides the flexibility to deploy model simulations across multiple desktop computers within any hpc environment or a combination thereof furthermore the proposed mopso method does not require subjective scalarization and instead evaluates each objective function independently finally the method can incorporate inequality constraints that decision makers may require to be met for each point along the pareto front the proposed mopso algorithm was tested on two real world case studies the first case study explored the uncertainty associated with total natural recharge entering a desert groundwater basin in antelope valley california usa the second case study explored the uncertainty associated with arsenopyrite oxidation during the re injection of csg co produced water into deep aquifers in reedy creek queensland australia the proposed methodology was able to quickly and accurately evaluate the pareto optimal set for both case studies in the first case study the proposed algorithm produced a more detailed and dominating pareto front compared to the coarse one evaluated previously and re affirmed that the likelihood of natural recharge exceeding 54 gl yr is very low in the second case study the proposed algorithm quickly evaluated a detailed pareto front illustrating the trade off between model fit and arsenopyrite oxidation the results indicate that at least 13 mol of arsenopyrite must have been oxidized in order to calibrate the reactive transport model for the site a major limitation of the proposed mopso workflow and software is that in order to be most effective one must have access to a multi core computing system this can range from a multi core desktop to many single or multi core desktops to cloud based computing to an hpc cluster etc or any combination thereof this is however the case with all multi objective optimisation approaches due to the propensity for this type of analysis to be computationally demanding however a major advantage of the methods proposed in this study is that they can extend to any general type of multi objective optimization problem there are a number of examples in water resource management e g one may wish to address the trade off between groundwater yield and the overall impact on groundwater dependent ecosystems where pumping rates are the decision variables another important example is within monitoring network design e g siade et al 2017 where one may wish to address the trade off between reducing parameter uncertainty and reducing predictive uncertainty where sampling locations are the decision variables 6 software availability the proposed mopso algorithm was developed as the software pestpp pso the source code for pestpp pso is publicly available within the pest software suite welter et al 2015 https github com dwelter pestpp the pestpp pso statically linked osx and pc executables are also provided in the git repository the data for the antelope valley case study is publicly available via the us geological survey at https pubs usgs gov sir 2014 5166 the data for the reedy creek case study is available to download from csiro data access portal http doi org 10 4225 08 59e079f75f7c2 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded primarily by the national centre for groundwater research and training ncgrt financial support for h p and a j s was also provided by the gas industry social environment research alliance gisera of australia the authors thank origin energy as upstream operator of australia pacific lng for the use of their extensive field data set and jeremy white for his technical support in the implementation of pest computational resources were provided by csiro with technical support provided by ondrej hlinka for the use of these hpc systems appendix a the formulation of the benchmark problems considered in this study are as follows kita et al 1996 9 max x φ ϕ 1 ϕ 2 ϕ 1 x 1 2 x 2 ϕ 2 1 2 x 1 x 2 1 subject to 1 6 x 1 x 2 13 2 0 1 2 x 1 x 2 15 2 0 5 x 1 x 2 30 0 0 x 1 x 2 7 kursawe 1991 10 min x φ ϕ 1 ϕ 2 ϕ 1 i 1 2 10 exp 0 2 x i 2 x i 1 2 ϕ 2 i 1 3 x i 0 8 5 sin x i 3 subject to 5 x 1 x 2 x 3 5 deb 1999 11 min x φ ϕ 1 ϕ 2 ϕ 1 x 1 ϕ 2 g x h x g x 11 x 2 2 10 cos 2 π x 2 h x 1 x 1 g x if x 1 g x 0 otherwise subject to 0 x 1 1 30 x 2 30 
6268,water sediment regulation wsr is an effective non engineering measure to alleviate the problem of suspended river and bring benefit to flood control security in sediment laden river however wsr may decrease the socio economic benefit of reservoirs for example reduction of hydropower production and water supply in order to satisfy the practical requirement of wsr and other utilization objectives this paper presents a multi objective operation model for a cascade reservoirs simultaneously considering the maximization water volume for wsr and power generation and water supply as well as various complex constraints then the non dominated sorting genetic algorithm nsga ii is improved to solve the aforementioned model and key control indicators of wsr are analyzed meanwhile a sediment transport model has been introduced to quantify the effect of wsr the models are applied to the cascade reservoirs in the upper yellow river the following conclusion can be drawn from results 1 pareto fronts of the model solution demonstrate a strong competition between wsr and water supply water supply and power generation a low sensitivity between wsr and power generation 2 the ability of wsr in upper yellow river is 6 times in 24 years which means the frequency of wsr is four years averagely 3 233 77 million tons of sediments are transported by long term wsr in the ningxia inner mongolia reaches account for 19 10 of sediment deposition 4 the risk free conditions of lyx and ljx reservoirs water volume for wsr are 137 42 108 m3 and 41 08 108 m3 respectively which could be used as a reference in actual operation the research results have an important practical significance and application for sediment control and governance of suspended river and the multi objective operation model of wsr proposed in this study can be effectively and suitably used in sediment regulation with similar conditions keywords water sediment regulation multi objectives regulation cascade reservoirs improved non dominated sorting genetic algorithm sediment laden river 1 introduction at the time being developing countries are facing a serious situation with mounting demand of water supply caused by high population growth and worsening river ecological health ren et al 2019 the problem gets even worse in sediment laden river basin and has become a major bottleneck inhibiting sustainable economic and social developments ching and mukherjee 2015 sediment deposition is an internal problem for sediment laden river that cause various negative problems for instance reduce channel discharge capacity decrease the available storage volume in reservoirs induce downstream morphological changes shrink the river channel raise the riverbed and form perched river which exacerbate the possibility of severe flooding greatly miao et al 2016 hauer et al 2018 tang et al 2019 undoubtedly the control and management of sediment deposition in rivers is a worldwide issue and increasingly seen as an important environmental challenge for the sustainable development of water resources nittrouer and viparelli 2014 hauer et al 2018 in fact many river basins around the world have to face the problems of sedimentation caused by anthropogenic activities the nile river basin could be a useful case study of the potential negative downstream impacts of a large dam the construction of the aswan high dam has trapped virtually all the sediment previously transported downstream resulting in channel degradation downstream and disruption of downstream ecosystems and activities fishing and agriculture liu et al 2018 strategies for sediment management include land management afforestation promotion of minimum till agricultural practices and erosion control programs dredging and flushing sediment through of dams are propose in nile river garazanti et al 2015 ebabu et al 2019 moreover the mississippi river basin julien and vensel 2005 remo et al 2018 is a highly managed major river system with many large dams and reservoirs numerous river training works extensive levee systems and control structures for flood control the impact of the decline in downstream sediment supply e g coastal wetland degradation is especially severe in the marshes and estuaries of the mississippi river delta and the authorities are working towards improving the situation maloney et al 2018 soil erosion and sediment delivery in the volga basin in central russia golosov and belyaev 2009 have undergone significant increases due to human activities and land clearing and constitute a serious risk to its sustainable management sediment management within the volga river basin is largely focused on improving land management and agricultural practices to reduce soil erosion gusarov et al 2018 the yellow river basin in china is well known for its very high sediment load and probably the highest rates of soil erosion and sediment yield in the world within the loess plateau shi et al 2017 tian et al 2019 widespread land management has been implemented in the yellow river basin including major dam construction afforestation terracing construction of check dams and planting of trees and grasses on former crop land in the past several decades shi et al 2019 overall it is thus evident that comprehensive control of sediment in watershed is a common challenge for sediment managers all over the world in general the comprehensive control of sediment deposition in river is a complicated system need concerning reduction of sediment input e g soil erosion land use change sediment retaining water sediment regulation hereafter wsr sediment transportation and artificial sand excavation li and sheng 2011 kondolf et al 2014 maechi et al 2019 one of them wsr as shown in fig 1 which is less investment faster effect and easier to implement release controlled flood from reservoirs to scour downstream riverbed which have raised gradually over past several decades owing to changes in river flow and sediment accumulation kong et al 2015a liu et al 2019 wsr is an effective non engineering measure to alleviate the problem of perched river and bring benefit to flood control security meanwhile we are aware that reservoirs play a significant role in regulating the fluctuant surface runoff to stably supply water for human needs and providing clean and renewable energy feng et al 2017 apparently wsr must inevitably lead to a more competitive relationship among multi objectives of water resource utilization and may threaten the safety of water supply and energy output in view of this the design and optimization of reservoirs for wsr must achieve a balance between sediment control and water resources development hydropower production flood control and so on in previous studies about wsr many researchers focused most of their attentions on operation of single reservoir and fewer objectives much more studies were related with the xiaolangdi hereafter xld a yearly reservoir located in the lower yellow river which had carried out the wsr annually since 2002 in order to scour the elevated river bed downstream and increased the bank full discharge from 3700 m3 s 1 in 2000 to 6900 m3 s 1 in 2012 xia et al 2014 the effects of wsr by xld reservoir had been reported in many studies such as the widening in main river channels ma et al 2012 fan et al 2018 changes in hydrological characteristics xia et al 2014 dong et al 2015 wang et al 2017a b as well as improvements in sedimentation features kong et al 2015b yang et al 2017 bi et al 2019 as outline above the theories and practice of wsr had been widely applied for managing single reservoir operations however a multi reservoir system with multi tasking e g wsr water supply power output ice and flood control especially the joint operation of multi yearly reservoir and yearly reservoir have complex structures of more than single reservoir in constraint conditions and numerous parameter variables the multi objectives optimal operation of wsr by multi reservoir is a challenging work to be solved additionally it is necessary to consider multi objective evolutionary algorithms moeas to solve multi objective problems undoubtedly the non dominated sorting genetic algorithm ii nsga ii has shown excellent performance in solving multi objective reservoir operation models chang et al 2014 uen et al 2018 actually the traditional nsga ii algorithm is searching optimal results based on randomly generated initial population in the entire search space and it is useful for short term e g one year regulation of single reservoir or parallel reservoirs however for long term operation of cascade reservoirs with interconnected and fixed regulation rules the entire space is too large to search optimal results and random generation of initial populations is no longer efficient and appropriate due to a large number of initial populations that do not conform to the regulation rules will reduce the maneuverability of the final optimal results for purpose of improving the efficiency and suitability of the algorithm the traditional nsga ii has been improved in this paper by shrinking feasible search space and generating initial population according to operation rules of cascade reservoirs to support the model solution overall how to guide the joint operation of multi reservoir based on improving the disharmonious relationship between water and sediment give full play to the positive role of multi reservoir in sediment control realize the dynamic balance between wsr and reservoirs utilizable benefit change the inappropriate operation modes of reservoirs which excessive pursuit of human benefits while neglect sediment problem at present provide decision making basis for risk free wsr in the actual operation of multi reservoir have become frontier problems of sediment management in sediment laden river therefore the present study is conducted to establish a multi objectives model of wsr by multi reservoir and solve it by improved nsga ii algorithm and also establish a sediment transport model to quantify sediment transport in wsr period then the relationships between multi objectives are revealed according to the pareto fronts the regulation rules and effects of wsr are obtained through the analysis of the frequency and sediment sluicing of wsr in the study area the dynamic balance between multi objectives are achieved by analysis of typical schemes lastly the operation modes and risk free conditions of cascade reservoirs for wsr are illustrated to guide the actual operation the research route of this article is shown in fig 2 2 study area 2 1 description of the yellow river the yellow river is the second longest river in china originates from the bayan har mountains in the qinghai tibet plateau flows through nine provinces with a length of 5464 km and a basin area of 0 75 million km2 finally import into bohai fig 3 wang et al 2019 xu et al 2019 the yellow river is a major source of freshwater for approximately 8 7 of the total population in china and water supply include municipal use industrial use irrigation and ecological use chang et al 2014 the monthly water supply demand of lanzhou hereafter lz section in upper stream are shown in table 1 the yellow river is also a famous sediment laden river in the world that has hyper concentration flow with the characteristics of less water and more sediment obviously miao et al 2010 wang et al 2017a b the recent data 2010 2013 shows the annual sediment load is approximately 1 5 108tons while the annual average runoff only 2 2 1010 m3 xu et al 2016 with the high speed development of social economy along the river and the reduction of upstream runoff there has a sharp contradictory between water supply and demand which impair the relationship between runoff and sediment the upper yellow river is also one of the thirteen major hydropower bases in china 25 reservoirs have been built or planned in this area with 16 3483 gw of total installed capacity undertake the important task of transporting clean energy to the north west electricity network li et al 2018 thus water supply and power generation are the two main benefit objectives for water utilization additionally flood control and ice control are the two major objectives for abolishing harmful in the upper yellow river the ningxia inner mongolia reach hereafter the nim reach enters the ice control period from november to march of the following year in this period the days with an average daily temperature below 0 c can last 4 5 months and the coldest temperatures in the winter can reach 35 c because the river flows from a low latitude to a high latitude the freeze up occurs from downstream to upstream in the winter and break up occurs from upstream to downstream in the spring which may lead to ice jams or ice dams due to the quick increase of the ice melt flood yang et al 2004 chang et al 2014 in view of this it is necessary to control ice disaster by limiting the discharge of upstream reservoir during the ice control period and maintaining the discharge within a stable and suitable range the upper limit discharge of upstream reservoir during ice control period are shown in table 2 in addition to analyze multi objectives regulation long and extensive runoff data are collected from yellow river conservancy commission hereafter yrcc which consisted of monthly runoff series of 24 years for cascade reservoirs in the upper yellow river 1987 2010 monthly fig 4 2 2 overview of sediment deposition in the nim reach the nim reach in the upper yellow river flows through four deserts they are the tengri desert the east sandy land of yellow river in ningxia the ulanbuh desert and the kubuqi desert shown in fig 3 ten primary tributaries of yellow river in this reach originate from the ordos plateau and flow through the hilly and gully region of the northern loess plateau and the hinterland of the kubuqi desert finally import into the yellow river in the north of ordos inner mongolia shown in fig 5 the precipitation is concentrated in flood season in the ordos plateau although the annual precipitation is small and usually in form of rainstorm in july and august thus high peak discharge and high sediment concentration are the main characteristics of flood in the ten tributaries among the measured data of a hydrological station in one of the tributaries the measured maximum peak discharge was 6940 m3 s the measured maximum sediment content was 1550 kg m3 the maximum sand transporting quantity of a flood was 47 4 million t and the sediment transport modulus was above 40 000 t km2 the river channel of nim reach had been shrunk and sediment deposited seriously over the past three decades as a sharp cut in runoff caused by construction of upstream dams had combined with high sediment concentration of ten tributaries inflow yao and liu 2018 finally a suspended river of 268 km has formed in the reach and the riverbed elevation is 3 5 m higher than cities along the river shown in fig 6 this suspended river not only cause frequent flood and ice disasters but also seriously affect the layout and implementation of major water conservancy projects and the utilization and development of water resources in the whole basin even more serious is that it endanger the safety of downstream river channel and life and poverty security of people chu 2014 given this circumstances it is urgent to carry out wsr in the upper yellow river 2 3 cascade reservoirs in the upper yellow river 2 3 1 overview of cascade reservoirs there are two pivotal reservoirs bear the responsibility of wsr water supply power generation ice and flood control in the upper yellow river longyangxia lyx a multi yearly reservoir and liujiaxia ljx a yearly reservoir in addition taking power generation or agricultural irrigation as main task thirteen run off reservoirs have been constructed in the river reach from lyx to lz hydrological section i laxiwa ii nina iii lijiaxia iv jishixia v zhiganglaka vi kangyang vii gongboxia viii shuzhi ix yanguoxia x bapanxia xi xiaoxia xii daxia and xiii qingtongxia the annual average power generating capacity of the multi reservoir system is 462 17 108 kw h fig 7 is the layout of the multi reservoir system the primary statistics of the two pivotal reservoirs are listed in table 3 2 3 2 regulation rules of cascade reservoirs in order to meet the requirements of comprehensive utilization of water resources lyx and ljx have formed unique regulation rules in different periods ice prevention period irrigation period flood control period gradually in practical joint operation which are used to guide the operation of cascade reservoirs the regulation rules are described as follows and shown in fig 8 1 ice control period november to march of the following year in this period outflow of ljx are limited strictly below upper discharge shown in table 2 to ensure the ice control safety of the nim reach downstream which escalate the conflict between prevention of ice disaster and power generation as an effective measure to alleviate this contradiction increasing the outflow of ljx in october and maintaining a reserve storage volume at the end of october before the ice control period is necessary to store the upstream generating flow of the lyx reservoir during ice control period thus the regulation rule of cascade reservoir in this period is that water level of lyx decrease continuously and water level of ljx rise constantly which can rise to the normal water level under ideal conditions the mathematical expression of the rules of this period are described as formula 1 2 wsr period and irrigation period april to june there is an overlap april in this two periods that undertake the important task of sediment regulation and agricultural irrigation to meet the large water demand in this period the cascade reservoirs need to increase outflow capacity thus the regulation rule of cascade reservoir in this two periods is that water level of lyx and ljx decrease continuously the mathematical expression of this rule are described as formula 2 3 flood control period july to october the main task of cascade reservoirs during this period is to store water as much as possible under the premise of ensuring the safety of flood control the water level of lyx reservoir cannot exceed the flood limit water level in the main flood season july to september but it can rise to the normal water level at the end of october different from lyx reservoir the water level of ljx reservoir must be lowered at the end of october to reserve enough storage capacity for ice control period thus the regulation rule of cascade reservoir in this period is that water level of lyx and ljx rise constantly and water level of ljx decrease in october the mathematical expression of this rule are described as formula 3 1 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j i 1 2 3 11 12 j 1 j 2 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j i 4 5 6 j 1 j 3 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j z ljx i j z ljx i 1 j i 7 8 9 j 1 j i 7 8 9 j 1 j i 10 j 1 j where z lyx i j and z lyx i 1 j are the water level of lyx reservoir at end of i month and i 1 month in j year respectively m z ljx i j and z ljx i 1 j are the water level of ljx reservoir at end of i month and i 1 month in j year respectively m 2 3 3 the role of cascade reservoirs for wsr in consideration of the huge amount of water needed for wsr how to distribute the wsr water in cascade reservoirs is an important issue of great concern to sustainability and economic feasibility of long term wsr among the cascade reservoirs in the upper yellow river only the lyx reservoir is able to bear such a huge amount of water alone but this will lead to large amount of abandonment water by lyx and its downstream power stations further exacerbate the contradiction between power generation and sediment regulation therefore the amount of sediment regulation water should be shared by lyx and ljx reservoir for the regulation discharge of wsr the lyx reservoir provide 1200 m3 s i e discharge for maximum power generation to avoid large amount of hydropower be discarded by lyx reservoir and eight run off reservoirs from lyx to ljx naturally the rest of the regulation discharge of wsr released from ljx reservoir 2 4 key control indicators of wsr in the upper yellow river regulation discharge regulation time and duration time of wsr are the three key control indicators which must be determined at first the regulation discharge should be determined in conjunction with the relationship between runoff and sediment in the study area the determination of regulation time and duration time of wsr should consider the multi utilization of water resources in each month and the safety of downstream channel for the upper yellow river the three key control indicators have been determined as follows 2 4 1 regulation discharge the regulation discharge of wsr is depended on the critical discharge of sediment transporting under different conditions of sediment concentration meanwhile for different intervals the critical discharge of wsr are inconsistent due to the disparities in geographical location geology landform river morphology and sediment conditions when the regulation discharge reach to the critical discharge at a certain sediment concentration the main channel sediment of the interval changes from siltation to scouring necessarily the nim reach has been divided into five intervals as shown in fig 3 xiaheyan xhy to qingtongxia qtx qingtongxia qtx to shizuishan szs shizuishan szs to bayangaole bygl bayangaole bygl to sanhuhekou shhk and sanhuhekou shhk to toudaoguai tdg the sediment concentration is divided into four sections they are 0 3 kg m3 3 7 kg m3 7 15 kg m3 above 15 kg m3 respectively critical discharge series of wsr in different sediment concentration of each interval can be obtained by analyzing the relationship between the average discharge during flood period and the sediment scouring or siltation amount of each interval based on historical data as shown in table 4 bai 2014 as can be seen from table 4 the critical discharge has grown with increasing of sediment concentration in each interval which reflect the characteristic of large discharge bring large sediment transport in the nim reach while wsr is un applicable for sediment concentration exceeded 15 kg m3 thus the maximum critical discharge is 2580 m3 s when the sediment concentration between 7 and 15 kg m3 in bygl shhk interval in other word the suspense sediment which s sediment concentration is less than 15 kg m3 will be scoured in every interval of nim reach by the discharge of 2580 m3 s at the same time to alleviate the contradiction between wsr and other water use objectives the second largest critical discharge of 2470 m3 s is chosen as the lower limit of controlling discharge at discharge of 2470 m3 s except the bygl shhk interval with sediment concentration between 7 and 15 kg m3 the river bed can be scour in most intervals of the nim reach thus in this paper the regulation discharge range of each section during wsr period is 2470 2580 m3 s recorded as q r 2470 2580 2 4 2 regulation time of wsr according to the spatial and temporal distribution of water and sediment in upper yellow river the nim reach enter ice period from november to march and enter flood period from july to october obviously the time of wsr must avoid these two periods while should been selected either follow the end of the ice control period april or before the flood control period june it is noteworthy that the xld reservoir in lower yellow river take wsr for 9 23 days in june every year dong et al 2018 in order to avoid the superposition of upstream flow and downstream flow what will lead flood disaster in regulating period the time of wsr in the upper yellow river could be april and choose 30 days as the duration of wsr 3 methods 3 1 model objectives five objectives which include requirement for wsr water supply hydropower generation ice and flood control are considered in the model and multi objective optimal operation model of cascade reservoirs are established it should be specially explained that cascade reservoirs in this model refer to reservoirs lyx and ljx the thirteen run off reservoirs are only used to count their electricity generation and not involved in optimal regulation the formulations of multiple objectives and related constraints are presented as follows 3 1 1 objective 1 water and sediment regulation wsr in order to decrease the sediment deposition in the suspended river wsr is urgent to implement effectively it is necessary to clearly recognize that for the upper yellow river normal and dry years are unsuitable for implementing wsr because of the heavy tasks of water supply and power generation of cascade reservoirs and wsr will increase the risk of insufficient water supply in these years while the years of high and partial high flow year are considered as the right time to carry out wsr therefore in the operation model some judgment conditions were set to judge wsr could be carried out or not in a given year the judgment conditions include that 1 whether the given year is a wet year with a water coming frequency of less than 40 2 whether if the wsr carried out in the given year will lead a successive water deficiency of water supply in the rest of regulating period finally take the maximum total water volume used for wsr as object shown as follows 4 w s max j 1 j q l j x out 4 j δ t s t q l j x out 4 j 1 q l j x out 4 j q l j x out 4 j q r q l j x out 4 j 0 q l j x out 4 j q l j x out 4 j q r where w s is the total water volume used for wsr m3 j is the number of year j 1 2 24 q l j x out 4 j is the outflow discharge of ljx reservoir at the fourth month i e april in j year m3 s q r is the regulation discharge of wsr see section 2 4 1 δt is the duration s 3 1 2 objective 2 water supply the yrcc has carried out the integrated planning of water resources on the yellow river aid to satisfy water demand of the whole watershed thus lz is selected as the control section of water supply take the minimum water shortage for supply as object shown as follows 5 w d min j j i i q d i j q g i j δ t q g i j q ljxout i j q ljx l z i j where w d is the total water shortage for supply m3 q d i j is the discharge demand in lz section at i month in j year m3 s q g i j is the regulating flow in lz section m3 s q ljxout i j is the actual outflow of the ljx reservoir m3 s q ljx l z i j is the inter zone inflow of ljx to lz interval reach m3 s it s worth noting that according to the design planning of water supply in the upper yellow river the design guaranteed rate is 75 for long term water supply 3 1 3 objective 3 hydropower generation the original intention of building cascade reservoirs in the upper yellow river is improving the ability of meeting the demand of electric power with the development of economy thus hydropower generation defined as follows is one of the most important objectives for the cascade reservoirs 6 e max j 1 j i 1 i m 1 m n m i j δ t where e is the total generated energy of the cascade reservoirs in j year kwh n m i j is the power output of m reservoir at i month in j year kw it is noteworthy that according to the design planning of hydropower generation in the upper yellow river the design guaranteed rate is 90 for long term power generation 3 1 4 objective 4 flood control in flood period flood control level of each reservoir must be controlled strictly to ensure the safety of dam and downstream areas shown as follows 7 z min m i j z m i j z max m i j where m is the number of reservoir z m i j is the water level of m reservoir at end of i month in j year m z min m i j and z max m i j are the minimum and maximum allowable water level of m reservoir at end of i month in j year respectively m in general z min m i j is the dead water level z max m i j is the flood control level 3 1 5 objective 5 ice control in ice control period november to next march the main channel of ningxia inner mongolia reaches would be frozen when temperature dips below freezing the stream discharge during ice control period must be descended into a low and safe magnitude determined by yrcc to maintain the safety of the ningxia inner mongolia reaches ljx is the nearest reservoir upper the ningxia inner mongolia reaches can control the discharge in ice control period the formula is described as follow 8 q ljxout i j q ice c o n t r o l i j where q ljxout i j is the actual outflow of the ljx reservoir m3 s q ice c o n t r o l i j is the upper limit of outflow during ice period m3 s table 2 the conflict of interests among the five objectives mentioned above is a challenge for the joint optimal operation of cascade reservoirs and the efficient utilization of water resources more specifically the implementation of wsr obj 1 will cause abandon electricity that reduce the ability of power output obj 3 and reduce the reservoirs storage that may cause insufficient water supply obj 2 in the subsequent time period in addition in ice control period the safe discharge of nim reach obj 5 are too little to meet the demand of water supply obj 2 and the guaranteed output of ljx reservoir obj 3 moreover the obj 3 needs to optimize both the outflow and water level of cascade reservoirs in order to maximize the hydropower generation it is necessary to reduce the outflow of reservoirs to raise the power water head sometimes this would also contradict the obj 2 as it could lead to a failure to meet the water supply 3 2 constraints 3 2 1 water balance of single reservoir 9 v m i j 1 v m i j q in m i j q out m i j δ t where q in m i j and q out m i j are the inflow and outflow of m reservoir at i month in j year m3 s v m i j and v m i j 1 are the initial and end storage capacity at i month in j year respectively m3 3 2 2 water balance between reservoirs 10 q lz i j q lyxin i j δ q lyx i j q lyx l j x i j δ q ljx i j q ljx l z i j where q lyxin i j is the inflow of lyx reservoir at i month in j year m3 s δ q lyx i j and δ q ljx i j are the discharge equated with storage or supply water quantity of lyx and ljx reservoir respectively m3 s q lyx l j x i j and q ljx l z i j are the inter zone inflow of lyx to ljx interval and ljx to lz interval reach respectively m3 s 3 2 3 water level 11 z min m i j z m i j z max m i j where z min m i j and z max m i j are the dead level and the maximum water level of m reservoir at end of i month in j year respectively m 3 2 4 outflow 12 q min m i j q m i j q max m i j where q min m i j and q max m i j are the minimum and maximum allowable outflow of m reservoir at i month in j year respectively m3 s in general the minimum outflow of reservoir is ecology base runoff of 300 m3 s 3 2 5 power generation output 13 n min m i j n m i j n max m i j where n min m i j and n max m i j are minimum output and maximum output of m reservoir at i month in j year respectively kw in general n min i j is the guaranteed output and n max i j is the installed capacity 3 3 model solution by using improved nsga ii to dumb down the difficulty of solving the model we reduce the dimension of multi objectives some of the objectives in section 3 1 can be transformed into constraints which expressed in form of inequality obj 4 and obj 5 so that the multi objective problem is changed into a three dimensional problem it s important to note that in order to facilitate model solving we converted the formula of obj 2 from looking for minima to seeking maximum value through adding minus in front the nsga ii is one of the most efficient and steady population based moeas and has been widely used for the multi objective analysis of multi reservoir systems chang and chang 2009 kumphon 2013 uen et al 2018 the nsga ii is proposed in 2000 based on nsga which was proposed by srinivas and deb in 1990 deb et al 2000 and it can efficiently solve optimization problems existing mutual restriction and influence among objectives obviously in this study relationships between power generation water supply and wsr are considered be counter balance in view of this we improve the nsga ii algorithm to solve the multi objective operation model and the detailed description of the improve methods are addressed as follows 3 3 1 the shrinkage of feasible search space in view of the special requirement on reservoirs operation in flood period and ice prevention period and the limitation of inflow and maximum or minimum outflow discharge the feasible search space must be smaller than that generated by initial constraints then the feasible search space could be extracted from initial search region though removing unfeasible solutions this action includes three steps 1 firstly all constraints are classified into three kinds water level outflow and power output while constraints include the same elements in the same category 2 secondly the intersection of the same kind of constraints are taken as a feasible region which means polymerization of constraints 3 lastly reclassified the three kinds of constraints into two types transformable constraints and un transformable constraints transformable constraints mean that constraints of water level and outflow can be transformed into optimization variables directly un transformable constraints mean that constraints of power output can t be transformed into optimal variables and shown as implicit function of optimal variables for un transformable constraints we control operators of nsga ii by judging whether the decision variable power output meets requirement for transformable constraints we reject infeasible solution and punish infeasible operators to shrink and optimize feasible search space before the initial population of swarm intelligence algorithm flow chart of shrinking the feasible search space is shown in fig 9 3 3 2 the generation of initial population according to regulation rules after shrinking the feasible search space generation of initial population is a key step for optimization and generated randomly in the traditional nsga ii algorithm when applied to the optimal operation of cascade reservoirs water level is usually taken as state variable for initial individual however the water level process which randomly generated time interval by time interval in procedure of initial population generation must have contained state variables that do not conform to the regulation rules of cascade reservoirs and this will be unfavorable to obtain more realistic optimization results therefore generating initial population follow the regulation rules is an effective and practical improvement measure to enhance the adaptability of nsga ii algorithm in optimal operation of cascade reservoirs different from the operation rule of single reservoir the cascade reservoirs are often needed to cooperate with each other in joint operation to produce more comprehensive benefits thus the regulation rules of cascade reservoirs are more complicated and the upstream and downstream reservoirs have fixed operation rules in different periods if the initial population can be generated according to this rules more realistic optimization results will be got for the study area in this paper the regulation rules of lyx and ljx cascade reservoirs have been described in detail in section 2 3 2 in step of initial population generation the water level variation processes of cascade reservoirs for each initial individual are generated according to formula 1 formula 2 and formula 3 given the above fig 10 shows the flowchart of applying the improved nsga ii to derive a non inferior set of operation processes for multi objectives regulation by cascade reservoirs 3 4 sediment transport model for the nim reach the sediment transporting quantity is an important physical value and useful engineering parameter to reflect the transportability of sediments of river channel establishing the conversion relationship between regulation discharge of wsr and sediment transporting quantity of the nim reach is an important link to evaluate the effect of long term wsr in fact bai 2014 had established a sediment transport model which reflect the correlation formulas between sediment transport rate and section discharge and sediment content of each section reach based on the measured data of 65 historical floods in nim and the errors between calculated values and measured values were less than 10 in this paper the model shown as follows were employed to calculate the transported sediment quantity 14 qtx section r qtx i j 0 011702 q qtx 0 705 i j s xhy 0 794 i j 15 szs section r szs i j 0 000424 q szs 1 242 i j s qtx 0 412 i j 16 bygl section r bygl i j 0 000164 q bygl 1 240 i j s szs 1 083 i j 17 shhk section r shhk i j 0 000159 q shhk 1 377 i j s bygl 0 489 i j 18 tdg section r tdg i j 0 000064 q tdg 1 482 i j s shhk 0 609 i j 19 q n i j q n 1 i j q n in i j q n out i j where r i j is the sediment transport rate in one section kg s q n i j is the average discharge in n section m3 s n 0 1 2 3 6 represent the ljx xhy qtx szs bygl shhk tdg section respectively q n in i j and q n out i j are the inter zone inflow and outflow of interval reach from n 1 section to n section respectively m3 s s i j is the sediment content of upper stream section kg m3 the sediment transport model given above is benefit to calculate the scouring sediment amount of nim reach and the fig 11 shows the calculating process of sediment transport in wsr period it s important to note that it is impossible to obtain the measured value of sediment content during wsr period in each section needed in formulas 14 18 because wsr have not yet been carried out in the nim reach in reality fortunately artificial floods caused by wsr in april should have similar characteristics of sediment transport with natural floods in flood season therefore the values of sediment content of each section during wsr period could be replaced by the measured data of a historical flood which s peak flow of maximal month flood discharge is closest to the controlling discharge of wsr 4 results and discussion usually for evolutionary algorithms in engineering applications multiple trials are needed depending on two aspects 1 the randomness which may largely influence the performance of evolutionary algorithms and 2 the complexity of the optimization problem thus we choose and analyze a relatively superior trial among many tries the main parameters of the improved nsga ii algorithm as population size number of generation crossover ratio and mutation ratio are 100 3000 0 8 and 0 3 0 01 respectively 4 1 competitive relationships between multi objectives the pareto front or the decision space contains 100 feasible design alternatives derived by improved nsga ii algorithm has been shown in fig 12 meanwhile the pareto front has been projected into 2d space as shown in fig 13 fig 12 show that the pareto front of three objectives are well distributed in a curved surface from 13840 67 108 kw h to 13901 74 108 kw h for the total generation from 311 83 108 m3 to 322 93 108 m3 for the total shortage for water supply and 375 68 108 m3 to 414 92 108 m3 for the total water volume of wsr in addition the transformation law between the three objectives had be revealed when one objective increases at least one of the other two objects decreases which demonstrate apparent contradiction between the three objectives furthermore fig 13 shows the relationship and sensitivity of every pair of objectives through two dimensional planes subfigure a shows that the power generation is decreasing while the shortage of water supply is decreasing i e the water supply is increasing which proves that there is an obvious competitive relationship between the two optimization objectives it can be observed from subfigure b that the competitive relationship is still clear between the water volume of wsr and the shortage of water supply however the competitive relationship is less clear between the water volume of wsr and the power generation in subfigure c demonstrate that the power generation is less sensitive to the increase of the water volume of wsr this may be due to two reasons 1 the operation policy of cascade reservoirs during the period of wsr the outflow of lyx reservoir is only 1200 m3 s maximum power generating flow to avoid a great loss of hydropower for eight runoff reservoirs from lyx to ljx and minimize the losses of hydropower 2 in periods of wsr which is in a minority the water volume for wsr is far greater than the maximal usable water for power generation cause the power generation is low insensitive to a spot of increasing or decreasing of wsr water in general the relationship between the three objectives can be described that as shown in fig 14 the obj 1 has an intense competition with obj 2 owing to the water supply capacity of cascade reservoirs is restricted in several months after wsr similarly the obj 2 has an intense competition with obj 3 because of the relatively stable process of water supply leading the cascade reservoirs reduce the power water head considerably whereas the obj 3 is insensitive to obj 1 4 2 multi objective analysis of typical schemes 4 2 1 the comprehensive efficiencies for multi objectives four typical schemes were chosen from among 100 alternatives to further analyze the relationships between the three objectives they are scheme 1 minimum shortage for water supply scheme 2 maximum water volume of wsr scheme 3 maximum generation and scheme 4 a compromise scheme as shown in fig 12 the comprehensive efficiencies for multi objectives of four schemes are listed in table 6 table 6 shows some indicators related to the three objectives such as the times of wsr the average water volume of once wsr the annual cascade power generation and power generating guarantee rate annual shortage for water supply and water supply guarantee rate it can be seen in table 6 that 1 wsr has been carried out 6 times for the long term operation that means wsr should be taken once every four years averagely the maximal water volume of wsr is 408 92 108 m3 and the average water volume of wsr is 68 15 108 m3 in scheme 2 while the minimal water volume of wsr is 400 92 108 m3 and the average water volume of wsr is 66 82 108 m3 in scheme 3 2 the requirement of power generation has been reached in all schemes the power generating guarantee rates of four schemes are 92 36 91 67 92 81 92 79 respectively which are all above the design guaranteed rate the annual cascade power generation of four schemes are 576 86 108 kw h 576 69 108 kw h 579 24 108 kw h and 578 74 108 kw h respectively higher than the design cascade power generation of 565 108 kw h 3 the guarantee rates of water supply of four schemes are 79 33 77 07 76 14 78 65 respectively higher than the design guaranteed rate of 75 and meet the requirement of water supply upper the yellow river meanwhile the maximal annual shortage for water supply is 13 27 108 m3 in scheme 3 scheme of maximum generation reflect a strong competition between water supply and power generation 4 2 2 water demand and sediment sluicing for wsr table 7 gives the water volume and discharge for wsr during the long term optimal operation of four schemes it is clearly seen that wsr could been carried out in six years according to the long term operation i e 1989 1992 1993 1999 2005 and 2009 and the water coming frequency of the six years are all less than 25 this shows that the suitable years for wsr are the high and partial high flow years the difference of outflow of ljx reservoir in april for wsr among the four schemes are small and the outflow values range from 2541 m3 s to 2682 m3 s with an average of 2601 m3 s particularly the outflow of ljx reservoir in four schemes are identical in 1992 1999 2009 respectively while for the rest years the outflow values of ljx reservoir in scheme 2 are the maximum of four schemes taking the sediment regulation in 1989 of scheme 4 as an example the incoming sediment and sediment transport of each section and the scouring sediment amount of five intervals of nim reach are calculated based on the sediment transport model the calculation results are shown in table 8 as shown in table 8 considering the influence of tributaries and diversion in the condition that the outflow of ljx reservoir is 2682 m3 s the discharge values of each section in nim reach can meet the requirements of wsr controlling discharge in table 4 i e q r 2470 2580 it is worth noting that the discharge values of sections xhy and szs shown in table 8 are outside of the regulation discharge range because of water diversion for agricultural irrigation in xhy qtx and szs bygl intervals in april the discharge values of sections qtx and bygl has reduced obviously during wsr period and the discharge of section bygl is 2485 m3 s which only slightly above the minimum limit discharge for wsr i e 2470 m3 s in view of this to ensure that the discharge of each section is greater than the minimum limit discharge for wsr the discharge of sections xhy and szs are higher than 2580 m3 s the result of sediment deposition or sluicing of intervals in table 8 shows that the first interval riverbed xhy to qtx is silted with 2 9 million t sand and the other four intervals are all scoured during wsr period which shows an increasing trend along the river and the total amount of sluicing sand of riverbed in the nim reach is 39 3 million t among the four scoured intervals the amount of sluicing sand in shhk tdg interval is the largest accounting for 39 95 of the total sluicing sand as the last section of nim reach the tdg section has transport sand of 61 2 million t during wsr period the above data only reflect the effect of one times of wsr in order to reflect the sluicing effect of long term wsr in the nim reach intuitively the sediment sluicing results of 6 years of four schemes are listed in table 9 as shown in table 9 there are 233 6 million tons of riverbed sediments of nim reach have been sluicing by long term sediment regulation in scheme 1 234 5 million tons in scheme 2 233 2 million tons in scheme 3 and 233 8 million tons in scheme 4 the average value of total sluicing sand by wsr of four schemes is 233 78 million tons according to the research about sediment deposition volume of recent 50 years in nim reach which pointed out that the rate of sediment deposition is 0 51billion t a approximately thus the total sediment deposition amount in the riverbed of nim reach from 1987 to 2010 is 1224 million tons shi 2010 as a consequence the total amount of sand sluicing by long term wsr account for 19 10 of the sediment deposition from 1987 to 2010 it is an undeniable fact that the ability of mitigating sedimentation by wsr is limited due to the contradiction of limited water quantity and multi utilization nonetheless wsr is useful and necessary for the upper yellow river to mitigate the increasingly serious problem of sediment deposition and riverbed siltation 4 2 3 water supply and hydropower generation considering wsr taking the scheme 4 as an example fig 15 shows the annual water shortage and power generation processes of scheme 4 it can be observed that the shortage volume of water supply increase sharply in years with the implementation of wsr such as 1989 1992 1993 2009 reflect the negative impact of wsr on the water supply the year of maximal water shortage is 1992 with shortage volume of 30 03 108 m3 and the year of minimal shortage is 2008 with shortage volume of 8 56 108 m3 in most of the years the volume of annual water shortage are within the range from 10 95 108 m3 to 15 42 108 m3 which are mainly caused by the contradiction between the limit discharge of ljx reservoir and the lz section water demand during ice control period the annual power generation process shows that the year of maximal energy output is 1990 with output of 508 84 108 kw h which is 46 67 108 kw h higher than the annual average power generating capacity of cascade reservoirs the year of minimal output is 2002 with output of 439 98 108 kw h 22 19 108 kw h less than the annual average power generating capacity based on the above analysis of results in section 4 2 it can be concluded that dynamic balance between wsr and other multi objectives can be achieved for the cascade reservoirs in the upper yellow river wsr is feasible and sustainable which can mitigate sediment deposition and alleviate the problem of suspended river to a certain extent although long term wsr will bring some negative effects on power generation and water supply it will not break the design indexes of these two objectives and will be able to perform the tasks of flood control ice flood control and ecological base flow in the upper yellow river 4 3 operation modes and risk free conditions of cascade reservoirs for wsr taking the scheme four as an example as well this paper analyzes the changing process of inflow and outflow of cascade reservoirs to reflect the joint operation modes of them as shown in fig 16 to reflect the change of operation modes of cascade reservoirs by long term wsr the multi objective operation model has been modified by removing the object 1 and solve the model once again the pareto solution set without wsr are obtained and one of the non inferior solutions is selected then the monthly water level changing process of cascade reservoirs of the non inferior solution without wsr is compared with that of scheme 4 as shown in fig 17 it is can be observed from subfigure a of fig 16 that the lyx reservoir takes full advantage of huge regulating storage to regulate the natural runoff in the upper yellow river and greatly changes the natural runoff process especially reduces the flood peak discharge in flood season and increases the downstream runoff in dry season in the long term regulation the abandoned water quantity of lyx reservoir is 0 m3 and the maximum outflow discharge is 1200 m3 s which are all occurred in the wsr period as the anti regulating reservoir of lyx the inflow and outflow of ljx reservoir are closely related to the outflow of lyx reservoir to meet the comprehensive water requirement in downstream the subfigure b of fig 16 shows that the ljx reservoir has anti regulated the outflow of lyx as follows 1 reducing the water of entering the downstream channel and strictly observing the upper limit outflow discharge during the ice control period 2 the outflow discharge of ljx reservoir is larger than the inflow during the irrigation period especially in the wsr period the outflow increases to more than 2500 m3 s 3 in the main flood season a part of the outflow of lyx reservoir is properly stored under the premise of ensuring the safety of flood control and the outflow discharge of ljx reservoir in october is increased obviously the subfigure a of fig 17 shows the difference between the water level process of lyx reservoir with or without wsr from 1987 to 2003 the water level process of lyx reservoir is less affected by wsr because of the supplement of abundant runoff in flood season that make the water level could rise rapidly however from 2004 to 2010 the water level process of lyx reservoir is great changed by wsr which is manifested by dropping to the dead water level and unable to recover to high water level the reason is the decrease of runoff 3 dry years in this period and the lyx reservoir has to lower the water level and increase the discharge to meet the comprehensive water demand it is noticeable that the water level of lyx reservoir had dropped to the dead water level in the end of april in 2009 what represent the capability of long term wsr has been fully exploited finally the water level of lyx reservoir with wsr drop to 2557 0 m at the end of the operation period which is 29 68 m lower than that in the scheme without wsr and the storage capacity is reduced by 68 83 108 m3 it can be seen from the subfigure b of fig 17 that the change of water level of ljx reservoir caused by wsr is temporary in the years when wsr has been taken the water level of ljx drop to the dead level in april due to the small storage capacity of ljx and the water compensation of lyx reservoir in flood season the water level of ljx rises gradually from july to september at last the water level of ljx reservoir with wsr rise to 1721 37 m at the end of the operation period which is 8 63 m lower than that in the scheme without wsr and the storage capacity was decreased by 10 45 108 m3 actually the optimal operation for cascade reservoirs in this paper is based on historical runoff data however in the actual reservoir operation due to the short forecast period of hydrological forecasting technology it is often impossible to accurately know the long term runoff in the future especially in april it is impossible to judge whether the runoff in flood season is abundant or not so it is more difficult to select the right time to carry out wsr in order to guide the cascade reservoirs to carry out risk free wsr effectively in practice it is absolutely essential to make clear the risk free conditions of the cascade reservoirs for wsr table 10 gives the information of water level and capacity before taking wsr for lyx and ljx reservoir which is used as a reference in actual operation it can be observed from table 10 that 1 for lyx reservoir the average water level before wsr is 2565 79 m and the corresponding capacity is 137 42 108 m3 the average lowering of water level by once wsr is 8 21 m and the average lowering of capacity by once wsr is 21 11 108 m3 2 for ljx reservoir the average water level before wsr is 1734 22 m and the corresponding capacity is 41 08 108 m3 the average lowering of water level is 37 48 m and the average lowering of capacity is 32 94 108 m3 this indicate that in the actual operation if the runoff in the future flood season is uncertain when the water level and capacity of the cascade reservoirs reach those above average values before april the wsr can be carry out without risk 4 4 discussion about ecological impact of wsr and countermeasures wsr is a non engineering measure to reduce the sediment deposition in the downstream riverbed through artificial flood regulated by reservoirs as an effective means of river sediment management wsr bring some expected benefits of reducing river bed elevation alleviating suspended river enhancing flood and ice flood discharge capacity of the river courses however wsr is a double edged sword for river ecological system although wsr has not been carried out in the upper yellow river in reality and it is impossible to accurately quantify the ecological impact of wsr fortunately by consulting the literatures on the ecological effects of wsr regulated by the xld reservoir in the lower yellow river we can get some qualitative conclusions of the ecological impact of wsr the ecological benefit of wsr is water supplement for wetlands liu et al 2016 in the past 20 years affected by climate change and human activities the areas of wetland in ningxia plain and inner mongolia plain in the yellow river basin have decreased by 20 48 km2 and 49 41 km2 respectively zheng et al 2016 wang et al 2018 in addition to scouring sediment a month long artificial flood caused by wsr in the nim reach can also raise groundwater level of river wetlands by seepage supply it is conceivable that wsr in the nim reach can benefit to vegetation growth increase the biodiversity improve the ecology function increase the bird population and prevent the shrinkage of wetland area the adverse impact of wsr is mainly reflected on fish and ecologically sensitive areas zhu et al 2012 affected by artificial floods released by cascade reservoirs in wsr period the fish resources in the reservoirs area and the lyx ljx reach will be reduced and the diversity of aquatic species will be decreased the sharp decline in water level of reservoirs in wsr period will also lead to the loss of ecological function of the spawning ground feeding ground and wintering ground of fish moreover impacted by wsr the sediment content of the nim reach will increases greatly in wsr period which will lead to the rapid increase of ammonia nitrogen content and the decrease of oxygen content in the river and may lead to the death of a number of fish to mitigate this negative impact countermeasures including establishment of fish resources protected areas fishery stock enhancement and releasing fish breeding sites downstream of the tributaries in nim reach as temporary shelter for fish are necessary 5 conclusion wsr water supply and hydropower generation are the most three important objectives for the utilization of water resources in sediment laden river under serious circumstance of suspended river and runoff decrease however the competitive relationships between the three objectives are uncovered and the effect and necessary conditions of wsr are indefinite which have bring obstacles to sediment management in sediment laden river additionally whether dynamic balance between long term wsr and other objectives could be achieved is an important issue related to the sustainability of wsr moreover the traditional nsga ii algorithm is inefficient and unsuitable to solve multi objective model for cascade reservoirs with interconnected and fixed regulation rules thus it is necessary to improve the algorithm different from other similar studies about wsr that focused on operation of single reservoir and fewer objectives this paper present a multi objective operation model for cascade reservoirs where five conflicting objectives and a set of complicated operational constrains are all considered simultaneously and also a sediment transport model was introduced to quantify the effect of wsr then the nsga ii algorithm was improved through shrinking feasible search space and generating initial population follow regulation rules to effectively solve the operation model and key control indicators of wsr i e the regulation discharge and regulating time were analyzed methodology mentioned above are applied in the upper yellow river basin the results show that wsr could be carried out every four years averagely in the study area and 233 78 million tons of sediments can be sluicing by long term wsr which account for 19 10 of the downstream sediment deposition in the operation period water supply has a strong competition with power generation an intensified competition with wsr as well meanwhile the competition between wsr and power generation is seen as secondary which means that in order to mitigate the sediment deposition problem it is essential to compromise on water supply benefit appropriately for actual operation that limited by existing hydrological forecasting technology the necessary conditions of lyx and ljx reservoirs water volume are 137 42 108 m3 and 41 08 108 m3 respectively which are a reference for taking wsr without risk the ecological benefits of wsr include reducing river bed elevation alleviating suspended river and water supplement for wetlands while adverse impact on fish and ecologically sensitive areas cannot be ignored and some countermeasures such as establishment of fish resources protected areas and fish breeding sites are suggested in this study through the optimization operation model dynamic balance between long term wsr and water supply power generation flood control ice flood control and ecology base runoff in sediment laden river have been achieved for the first time via the cooperation of cascade reservoirs more importantly the competitive relationships between wsr and other objectives have been revealed the ability and effect of long term wsr have been obtained and the operation modes and risk free conditions of cascade reservoirs for wsr have been put forward to guide actual operation which expand the theoretical system and technical method of wsr although the models and methods have only been applied to the upper yellow river in this paper its generic formulation allows its application to a broad range of rivers over the world admittedly some inadequacies of this work are expected to be improved the values of key control indicators of wsr are static rather than dynamic in wsr period and have no function of optimizing with the response of channel morphology and river bed evolution the improvement suggestion for this problem is to shorten the calculation interval into day or ten days during wsr period and establish the relationship between the evolution of river bed and the regulation discharge of wsr in the nim reach in this way the dynamic coupling between cascade reservoirs and river channel can be realized by feeding back the response results of river morphology to the water sediment multi objectives regulation model sediment management is a global and complex problem for sediment laden rivers like the yellow river how to realize the combination of wsr and multi objective utilization of water resources in the whole river and study the high efficiency sediment transport mode of cascade reservoirs under the common action of various sediment control measures such as sediment retaining sediment transportation and artificial sand excavation are the future directions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national key research and development program of china 2017yfc0404406 and the national natural science foundation of china 51879214 51679187 91647112 51679189 the authors extend special thanks to editors and numerous anonymous reviewers for their valuable reviews their comments and suggestions improved the quality of this paper 
6268,water sediment regulation wsr is an effective non engineering measure to alleviate the problem of suspended river and bring benefit to flood control security in sediment laden river however wsr may decrease the socio economic benefit of reservoirs for example reduction of hydropower production and water supply in order to satisfy the practical requirement of wsr and other utilization objectives this paper presents a multi objective operation model for a cascade reservoirs simultaneously considering the maximization water volume for wsr and power generation and water supply as well as various complex constraints then the non dominated sorting genetic algorithm nsga ii is improved to solve the aforementioned model and key control indicators of wsr are analyzed meanwhile a sediment transport model has been introduced to quantify the effect of wsr the models are applied to the cascade reservoirs in the upper yellow river the following conclusion can be drawn from results 1 pareto fronts of the model solution demonstrate a strong competition between wsr and water supply water supply and power generation a low sensitivity between wsr and power generation 2 the ability of wsr in upper yellow river is 6 times in 24 years which means the frequency of wsr is four years averagely 3 233 77 million tons of sediments are transported by long term wsr in the ningxia inner mongolia reaches account for 19 10 of sediment deposition 4 the risk free conditions of lyx and ljx reservoirs water volume for wsr are 137 42 108 m3 and 41 08 108 m3 respectively which could be used as a reference in actual operation the research results have an important practical significance and application for sediment control and governance of suspended river and the multi objective operation model of wsr proposed in this study can be effectively and suitably used in sediment regulation with similar conditions keywords water sediment regulation multi objectives regulation cascade reservoirs improved non dominated sorting genetic algorithm sediment laden river 1 introduction at the time being developing countries are facing a serious situation with mounting demand of water supply caused by high population growth and worsening river ecological health ren et al 2019 the problem gets even worse in sediment laden river basin and has become a major bottleneck inhibiting sustainable economic and social developments ching and mukherjee 2015 sediment deposition is an internal problem for sediment laden river that cause various negative problems for instance reduce channel discharge capacity decrease the available storage volume in reservoirs induce downstream morphological changes shrink the river channel raise the riverbed and form perched river which exacerbate the possibility of severe flooding greatly miao et al 2016 hauer et al 2018 tang et al 2019 undoubtedly the control and management of sediment deposition in rivers is a worldwide issue and increasingly seen as an important environmental challenge for the sustainable development of water resources nittrouer and viparelli 2014 hauer et al 2018 in fact many river basins around the world have to face the problems of sedimentation caused by anthropogenic activities the nile river basin could be a useful case study of the potential negative downstream impacts of a large dam the construction of the aswan high dam has trapped virtually all the sediment previously transported downstream resulting in channel degradation downstream and disruption of downstream ecosystems and activities fishing and agriculture liu et al 2018 strategies for sediment management include land management afforestation promotion of minimum till agricultural practices and erosion control programs dredging and flushing sediment through of dams are propose in nile river garazanti et al 2015 ebabu et al 2019 moreover the mississippi river basin julien and vensel 2005 remo et al 2018 is a highly managed major river system with many large dams and reservoirs numerous river training works extensive levee systems and control structures for flood control the impact of the decline in downstream sediment supply e g coastal wetland degradation is especially severe in the marshes and estuaries of the mississippi river delta and the authorities are working towards improving the situation maloney et al 2018 soil erosion and sediment delivery in the volga basin in central russia golosov and belyaev 2009 have undergone significant increases due to human activities and land clearing and constitute a serious risk to its sustainable management sediment management within the volga river basin is largely focused on improving land management and agricultural practices to reduce soil erosion gusarov et al 2018 the yellow river basin in china is well known for its very high sediment load and probably the highest rates of soil erosion and sediment yield in the world within the loess plateau shi et al 2017 tian et al 2019 widespread land management has been implemented in the yellow river basin including major dam construction afforestation terracing construction of check dams and planting of trees and grasses on former crop land in the past several decades shi et al 2019 overall it is thus evident that comprehensive control of sediment in watershed is a common challenge for sediment managers all over the world in general the comprehensive control of sediment deposition in river is a complicated system need concerning reduction of sediment input e g soil erosion land use change sediment retaining water sediment regulation hereafter wsr sediment transportation and artificial sand excavation li and sheng 2011 kondolf et al 2014 maechi et al 2019 one of them wsr as shown in fig 1 which is less investment faster effect and easier to implement release controlled flood from reservoirs to scour downstream riverbed which have raised gradually over past several decades owing to changes in river flow and sediment accumulation kong et al 2015a liu et al 2019 wsr is an effective non engineering measure to alleviate the problem of perched river and bring benefit to flood control security meanwhile we are aware that reservoirs play a significant role in regulating the fluctuant surface runoff to stably supply water for human needs and providing clean and renewable energy feng et al 2017 apparently wsr must inevitably lead to a more competitive relationship among multi objectives of water resource utilization and may threaten the safety of water supply and energy output in view of this the design and optimization of reservoirs for wsr must achieve a balance between sediment control and water resources development hydropower production flood control and so on in previous studies about wsr many researchers focused most of their attentions on operation of single reservoir and fewer objectives much more studies were related with the xiaolangdi hereafter xld a yearly reservoir located in the lower yellow river which had carried out the wsr annually since 2002 in order to scour the elevated river bed downstream and increased the bank full discharge from 3700 m3 s 1 in 2000 to 6900 m3 s 1 in 2012 xia et al 2014 the effects of wsr by xld reservoir had been reported in many studies such as the widening in main river channels ma et al 2012 fan et al 2018 changes in hydrological characteristics xia et al 2014 dong et al 2015 wang et al 2017a b as well as improvements in sedimentation features kong et al 2015b yang et al 2017 bi et al 2019 as outline above the theories and practice of wsr had been widely applied for managing single reservoir operations however a multi reservoir system with multi tasking e g wsr water supply power output ice and flood control especially the joint operation of multi yearly reservoir and yearly reservoir have complex structures of more than single reservoir in constraint conditions and numerous parameter variables the multi objectives optimal operation of wsr by multi reservoir is a challenging work to be solved additionally it is necessary to consider multi objective evolutionary algorithms moeas to solve multi objective problems undoubtedly the non dominated sorting genetic algorithm ii nsga ii has shown excellent performance in solving multi objective reservoir operation models chang et al 2014 uen et al 2018 actually the traditional nsga ii algorithm is searching optimal results based on randomly generated initial population in the entire search space and it is useful for short term e g one year regulation of single reservoir or parallel reservoirs however for long term operation of cascade reservoirs with interconnected and fixed regulation rules the entire space is too large to search optimal results and random generation of initial populations is no longer efficient and appropriate due to a large number of initial populations that do not conform to the regulation rules will reduce the maneuverability of the final optimal results for purpose of improving the efficiency and suitability of the algorithm the traditional nsga ii has been improved in this paper by shrinking feasible search space and generating initial population according to operation rules of cascade reservoirs to support the model solution overall how to guide the joint operation of multi reservoir based on improving the disharmonious relationship between water and sediment give full play to the positive role of multi reservoir in sediment control realize the dynamic balance between wsr and reservoirs utilizable benefit change the inappropriate operation modes of reservoirs which excessive pursuit of human benefits while neglect sediment problem at present provide decision making basis for risk free wsr in the actual operation of multi reservoir have become frontier problems of sediment management in sediment laden river therefore the present study is conducted to establish a multi objectives model of wsr by multi reservoir and solve it by improved nsga ii algorithm and also establish a sediment transport model to quantify sediment transport in wsr period then the relationships between multi objectives are revealed according to the pareto fronts the regulation rules and effects of wsr are obtained through the analysis of the frequency and sediment sluicing of wsr in the study area the dynamic balance between multi objectives are achieved by analysis of typical schemes lastly the operation modes and risk free conditions of cascade reservoirs for wsr are illustrated to guide the actual operation the research route of this article is shown in fig 2 2 study area 2 1 description of the yellow river the yellow river is the second longest river in china originates from the bayan har mountains in the qinghai tibet plateau flows through nine provinces with a length of 5464 km and a basin area of 0 75 million km2 finally import into bohai fig 3 wang et al 2019 xu et al 2019 the yellow river is a major source of freshwater for approximately 8 7 of the total population in china and water supply include municipal use industrial use irrigation and ecological use chang et al 2014 the monthly water supply demand of lanzhou hereafter lz section in upper stream are shown in table 1 the yellow river is also a famous sediment laden river in the world that has hyper concentration flow with the characteristics of less water and more sediment obviously miao et al 2010 wang et al 2017a b the recent data 2010 2013 shows the annual sediment load is approximately 1 5 108tons while the annual average runoff only 2 2 1010 m3 xu et al 2016 with the high speed development of social economy along the river and the reduction of upstream runoff there has a sharp contradictory between water supply and demand which impair the relationship between runoff and sediment the upper yellow river is also one of the thirteen major hydropower bases in china 25 reservoirs have been built or planned in this area with 16 3483 gw of total installed capacity undertake the important task of transporting clean energy to the north west electricity network li et al 2018 thus water supply and power generation are the two main benefit objectives for water utilization additionally flood control and ice control are the two major objectives for abolishing harmful in the upper yellow river the ningxia inner mongolia reach hereafter the nim reach enters the ice control period from november to march of the following year in this period the days with an average daily temperature below 0 c can last 4 5 months and the coldest temperatures in the winter can reach 35 c because the river flows from a low latitude to a high latitude the freeze up occurs from downstream to upstream in the winter and break up occurs from upstream to downstream in the spring which may lead to ice jams or ice dams due to the quick increase of the ice melt flood yang et al 2004 chang et al 2014 in view of this it is necessary to control ice disaster by limiting the discharge of upstream reservoir during the ice control period and maintaining the discharge within a stable and suitable range the upper limit discharge of upstream reservoir during ice control period are shown in table 2 in addition to analyze multi objectives regulation long and extensive runoff data are collected from yellow river conservancy commission hereafter yrcc which consisted of monthly runoff series of 24 years for cascade reservoirs in the upper yellow river 1987 2010 monthly fig 4 2 2 overview of sediment deposition in the nim reach the nim reach in the upper yellow river flows through four deserts they are the tengri desert the east sandy land of yellow river in ningxia the ulanbuh desert and the kubuqi desert shown in fig 3 ten primary tributaries of yellow river in this reach originate from the ordos plateau and flow through the hilly and gully region of the northern loess plateau and the hinterland of the kubuqi desert finally import into the yellow river in the north of ordos inner mongolia shown in fig 5 the precipitation is concentrated in flood season in the ordos plateau although the annual precipitation is small and usually in form of rainstorm in july and august thus high peak discharge and high sediment concentration are the main characteristics of flood in the ten tributaries among the measured data of a hydrological station in one of the tributaries the measured maximum peak discharge was 6940 m3 s the measured maximum sediment content was 1550 kg m3 the maximum sand transporting quantity of a flood was 47 4 million t and the sediment transport modulus was above 40 000 t km2 the river channel of nim reach had been shrunk and sediment deposited seriously over the past three decades as a sharp cut in runoff caused by construction of upstream dams had combined with high sediment concentration of ten tributaries inflow yao and liu 2018 finally a suspended river of 268 km has formed in the reach and the riverbed elevation is 3 5 m higher than cities along the river shown in fig 6 this suspended river not only cause frequent flood and ice disasters but also seriously affect the layout and implementation of major water conservancy projects and the utilization and development of water resources in the whole basin even more serious is that it endanger the safety of downstream river channel and life and poverty security of people chu 2014 given this circumstances it is urgent to carry out wsr in the upper yellow river 2 3 cascade reservoirs in the upper yellow river 2 3 1 overview of cascade reservoirs there are two pivotal reservoirs bear the responsibility of wsr water supply power generation ice and flood control in the upper yellow river longyangxia lyx a multi yearly reservoir and liujiaxia ljx a yearly reservoir in addition taking power generation or agricultural irrigation as main task thirteen run off reservoirs have been constructed in the river reach from lyx to lz hydrological section i laxiwa ii nina iii lijiaxia iv jishixia v zhiganglaka vi kangyang vii gongboxia viii shuzhi ix yanguoxia x bapanxia xi xiaoxia xii daxia and xiii qingtongxia the annual average power generating capacity of the multi reservoir system is 462 17 108 kw h fig 7 is the layout of the multi reservoir system the primary statistics of the two pivotal reservoirs are listed in table 3 2 3 2 regulation rules of cascade reservoirs in order to meet the requirements of comprehensive utilization of water resources lyx and ljx have formed unique regulation rules in different periods ice prevention period irrigation period flood control period gradually in practical joint operation which are used to guide the operation of cascade reservoirs the regulation rules are described as follows and shown in fig 8 1 ice control period november to march of the following year in this period outflow of ljx are limited strictly below upper discharge shown in table 2 to ensure the ice control safety of the nim reach downstream which escalate the conflict between prevention of ice disaster and power generation as an effective measure to alleviate this contradiction increasing the outflow of ljx in october and maintaining a reserve storage volume at the end of october before the ice control period is necessary to store the upstream generating flow of the lyx reservoir during ice control period thus the regulation rule of cascade reservoir in this period is that water level of lyx decrease continuously and water level of ljx rise constantly which can rise to the normal water level under ideal conditions the mathematical expression of the rules of this period are described as formula 1 2 wsr period and irrigation period april to june there is an overlap april in this two periods that undertake the important task of sediment regulation and agricultural irrigation to meet the large water demand in this period the cascade reservoirs need to increase outflow capacity thus the regulation rule of cascade reservoir in this two periods is that water level of lyx and ljx decrease continuously the mathematical expression of this rule are described as formula 2 3 flood control period july to october the main task of cascade reservoirs during this period is to store water as much as possible under the premise of ensuring the safety of flood control the water level of lyx reservoir cannot exceed the flood limit water level in the main flood season july to september but it can rise to the normal water level at the end of october different from lyx reservoir the water level of ljx reservoir must be lowered at the end of october to reserve enough storage capacity for ice control period thus the regulation rule of cascade reservoir in this period is that water level of lyx and ljx rise constantly and water level of ljx decrease in october the mathematical expression of this rule are described as formula 3 1 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j i 1 2 3 11 12 j 1 j 2 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j i 4 5 6 j 1 j 3 z lyx i j z lyx i 1 j z ljx i j z ljx i 1 j z ljx i j z ljx i 1 j i 7 8 9 j 1 j i 7 8 9 j 1 j i 10 j 1 j where z lyx i j and z lyx i 1 j are the water level of lyx reservoir at end of i month and i 1 month in j year respectively m z ljx i j and z ljx i 1 j are the water level of ljx reservoir at end of i month and i 1 month in j year respectively m 2 3 3 the role of cascade reservoirs for wsr in consideration of the huge amount of water needed for wsr how to distribute the wsr water in cascade reservoirs is an important issue of great concern to sustainability and economic feasibility of long term wsr among the cascade reservoirs in the upper yellow river only the lyx reservoir is able to bear such a huge amount of water alone but this will lead to large amount of abandonment water by lyx and its downstream power stations further exacerbate the contradiction between power generation and sediment regulation therefore the amount of sediment regulation water should be shared by lyx and ljx reservoir for the regulation discharge of wsr the lyx reservoir provide 1200 m3 s i e discharge for maximum power generation to avoid large amount of hydropower be discarded by lyx reservoir and eight run off reservoirs from lyx to ljx naturally the rest of the regulation discharge of wsr released from ljx reservoir 2 4 key control indicators of wsr in the upper yellow river regulation discharge regulation time and duration time of wsr are the three key control indicators which must be determined at first the regulation discharge should be determined in conjunction with the relationship between runoff and sediment in the study area the determination of regulation time and duration time of wsr should consider the multi utilization of water resources in each month and the safety of downstream channel for the upper yellow river the three key control indicators have been determined as follows 2 4 1 regulation discharge the regulation discharge of wsr is depended on the critical discharge of sediment transporting under different conditions of sediment concentration meanwhile for different intervals the critical discharge of wsr are inconsistent due to the disparities in geographical location geology landform river morphology and sediment conditions when the regulation discharge reach to the critical discharge at a certain sediment concentration the main channel sediment of the interval changes from siltation to scouring necessarily the nim reach has been divided into five intervals as shown in fig 3 xiaheyan xhy to qingtongxia qtx qingtongxia qtx to shizuishan szs shizuishan szs to bayangaole bygl bayangaole bygl to sanhuhekou shhk and sanhuhekou shhk to toudaoguai tdg the sediment concentration is divided into four sections they are 0 3 kg m3 3 7 kg m3 7 15 kg m3 above 15 kg m3 respectively critical discharge series of wsr in different sediment concentration of each interval can be obtained by analyzing the relationship between the average discharge during flood period and the sediment scouring or siltation amount of each interval based on historical data as shown in table 4 bai 2014 as can be seen from table 4 the critical discharge has grown with increasing of sediment concentration in each interval which reflect the characteristic of large discharge bring large sediment transport in the nim reach while wsr is un applicable for sediment concentration exceeded 15 kg m3 thus the maximum critical discharge is 2580 m3 s when the sediment concentration between 7 and 15 kg m3 in bygl shhk interval in other word the suspense sediment which s sediment concentration is less than 15 kg m3 will be scoured in every interval of nim reach by the discharge of 2580 m3 s at the same time to alleviate the contradiction between wsr and other water use objectives the second largest critical discharge of 2470 m3 s is chosen as the lower limit of controlling discharge at discharge of 2470 m3 s except the bygl shhk interval with sediment concentration between 7 and 15 kg m3 the river bed can be scour in most intervals of the nim reach thus in this paper the regulation discharge range of each section during wsr period is 2470 2580 m3 s recorded as q r 2470 2580 2 4 2 regulation time of wsr according to the spatial and temporal distribution of water and sediment in upper yellow river the nim reach enter ice period from november to march and enter flood period from july to october obviously the time of wsr must avoid these two periods while should been selected either follow the end of the ice control period april or before the flood control period june it is noteworthy that the xld reservoir in lower yellow river take wsr for 9 23 days in june every year dong et al 2018 in order to avoid the superposition of upstream flow and downstream flow what will lead flood disaster in regulating period the time of wsr in the upper yellow river could be april and choose 30 days as the duration of wsr 3 methods 3 1 model objectives five objectives which include requirement for wsr water supply hydropower generation ice and flood control are considered in the model and multi objective optimal operation model of cascade reservoirs are established it should be specially explained that cascade reservoirs in this model refer to reservoirs lyx and ljx the thirteen run off reservoirs are only used to count their electricity generation and not involved in optimal regulation the formulations of multiple objectives and related constraints are presented as follows 3 1 1 objective 1 water and sediment regulation wsr in order to decrease the sediment deposition in the suspended river wsr is urgent to implement effectively it is necessary to clearly recognize that for the upper yellow river normal and dry years are unsuitable for implementing wsr because of the heavy tasks of water supply and power generation of cascade reservoirs and wsr will increase the risk of insufficient water supply in these years while the years of high and partial high flow year are considered as the right time to carry out wsr therefore in the operation model some judgment conditions were set to judge wsr could be carried out or not in a given year the judgment conditions include that 1 whether the given year is a wet year with a water coming frequency of less than 40 2 whether if the wsr carried out in the given year will lead a successive water deficiency of water supply in the rest of regulating period finally take the maximum total water volume used for wsr as object shown as follows 4 w s max j 1 j q l j x out 4 j δ t s t q l j x out 4 j 1 q l j x out 4 j q l j x out 4 j q r q l j x out 4 j 0 q l j x out 4 j q l j x out 4 j q r where w s is the total water volume used for wsr m3 j is the number of year j 1 2 24 q l j x out 4 j is the outflow discharge of ljx reservoir at the fourth month i e april in j year m3 s q r is the regulation discharge of wsr see section 2 4 1 δt is the duration s 3 1 2 objective 2 water supply the yrcc has carried out the integrated planning of water resources on the yellow river aid to satisfy water demand of the whole watershed thus lz is selected as the control section of water supply take the minimum water shortage for supply as object shown as follows 5 w d min j j i i q d i j q g i j δ t q g i j q ljxout i j q ljx l z i j where w d is the total water shortage for supply m3 q d i j is the discharge demand in lz section at i month in j year m3 s q g i j is the regulating flow in lz section m3 s q ljxout i j is the actual outflow of the ljx reservoir m3 s q ljx l z i j is the inter zone inflow of ljx to lz interval reach m3 s it s worth noting that according to the design planning of water supply in the upper yellow river the design guaranteed rate is 75 for long term water supply 3 1 3 objective 3 hydropower generation the original intention of building cascade reservoirs in the upper yellow river is improving the ability of meeting the demand of electric power with the development of economy thus hydropower generation defined as follows is one of the most important objectives for the cascade reservoirs 6 e max j 1 j i 1 i m 1 m n m i j δ t where e is the total generated energy of the cascade reservoirs in j year kwh n m i j is the power output of m reservoir at i month in j year kw it is noteworthy that according to the design planning of hydropower generation in the upper yellow river the design guaranteed rate is 90 for long term power generation 3 1 4 objective 4 flood control in flood period flood control level of each reservoir must be controlled strictly to ensure the safety of dam and downstream areas shown as follows 7 z min m i j z m i j z max m i j where m is the number of reservoir z m i j is the water level of m reservoir at end of i month in j year m z min m i j and z max m i j are the minimum and maximum allowable water level of m reservoir at end of i month in j year respectively m in general z min m i j is the dead water level z max m i j is the flood control level 3 1 5 objective 5 ice control in ice control period november to next march the main channel of ningxia inner mongolia reaches would be frozen when temperature dips below freezing the stream discharge during ice control period must be descended into a low and safe magnitude determined by yrcc to maintain the safety of the ningxia inner mongolia reaches ljx is the nearest reservoir upper the ningxia inner mongolia reaches can control the discharge in ice control period the formula is described as follow 8 q ljxout i j q ice c o n t r o l i j where q ljxout i j is the actual outflow of the ljx reservoir m3 s q ice c o n t r o l i j is the upper limit of outflow during ice period m3 s table 2 the conflict of interests among the five objectives mentioned above is a challenge for the joint optimal operation of cascade reservoirs and the efficient utilization of water resources more specifically the implementation of wsr obj 1 will cause abandon electricity that reduce the ability of power output obj 3 and reduce the reservoirs storage that may cause insufficient water supply obj 2 in the subsequent time period in addition in ice control period the safe discharge of nim reach obj 5 are too little to meet the demand of water supply obj 2 and the guaranteed output of ljx reservoir obj 3 moreover the obj 3 needs to optimize both the outflow and water level of cascade reservoirs in order to maximize the hydropower generation it is necessary to reduce the outflow of reservoirs to raise the power water head sometimes this would also contradict the obj 2 as it could lead to a failure to meet the water supply 3 2 constraints 3 2 1 water balance of single reservoir 9 v m i j 1 v m i j q in m i j q out m i j δ t where q in m i j and q out m i j are the inflow and outflow of m reservoir at i month in j year m3 s v m i j and v m i j 1 are the initial and end storage capacity at i month in j year respectively m3 3 2 2 water balance between reservoirs 10 q lz i j q lyxin i j δ q lyx i j q lyx l j x i j δ q ljx i j q ljx l z i j where q lyxin i j is the inflow of lyx reservoir at i month in j year m3 s δ q lyx i j and δ q ljx i j are the discharge equated with storage or supply water quantity of lyx and ljx reservoir respectively m3 s q lyx l j x i j and q ljx l z i j are the inter zone inflow of lyx to ljx interval and ljx to lz interval reach respectively m3 s 3 2 3 water level 11 z min m i j z m i j z max m i j where z min m i j and z max m i j are the dead level and the maximum water level of m reservoir at end of i month in j year respectively m 3 2 4 outflow 12 q min m i j q m i j q max m i j where q min m i j and q max m i j are the minimum and maximum allowable outflow of m reservoir at i month in j year respectively m3 s in general the minimum outflow of reservoir is ecology base runoff of 300 m3 s 3 2 5 power generation output 13 n min m i j n m i j n max m i j where n min m i j and n max m i j are minimum output and maximum output of m reservoir at i month in j year respectively kw in general n min i j is the guaranteed output and n max i j is the installed capacity 3 3 model solution by using improved nsga ii to dumb down the difficulty of solving the model we reduce the dimension of multi objectives some of the objectives in section 3 1 can be transformed into constraints which expressed in form of inequality obj 4 and obj 5 so that the multi objective problem is changed into a three dimensional problem it s important to note that in order to facilitate model solving we converted the formula of obj 2 from looking for minima to seeking maximum value through adding minus in front the nsga ii is one of the most efficient and steady population based moeas and has been widely used for the multi objective analysis of multi reservoir systems chang and chang 2009 kumphon 2013 uen et al 2018 the nsga ii is proposed in 2000 based on nsga which was proposed by srinivas and deb in 1990 deb et al 2000 and it can efficiently solve optimization problems existing mutual restriction and influence among objectives obviously in this study relationships between power generation water supply and wsr are considered be counter balance in view of this we improve the nsga ii algorithm to solve the multi objective operation model and the detailed description of the improve methods are addressed as follows 3 3 1 the shrinkage of feasible search space in view of the special requirement on reservoirs operation in flood period and ice prevention period and the limitation of inflow and maximum or minimum outflow discharge the feasible search space must be smaller than that generated by initial constraints then the feasible search space could be extracted from initial search region though removing unfeasible solutions this action includes three steps 1 firstly all constraints are classified into three kinds water level outflow and power output while constraints include the same elements in the same category 2 secondly the intersection of the same kind of constraints are taken as a feasible region which means polymerization of constraints 3 lastly reclassified the three kinds of constraints into two types transformable constraints and un transformable constraints transformable constraints mean that constraints of water level and outflow can be transformed into optimization variables directly un transformable constraints mean that constraints of power output can t be transformed into optimal variables and shown as implicit function of optimal variables for un transformable constraints we control operators of nsga ii by judging whether the decision variable power output meets requirement for transformable constraints we reject infeasible solution and punish infeasible operators to shrink and optimize feasible search space before the initial population of swarm intelligence algorithm flow chart of shrinking the feasible search space is shown in fig 9 3 3 2 the generation of initial population according to regulation rules after shrinking the feasible search space generation of initial population is a key step for optimization and generated randomly in the traditional nsga ii algorithm when applied to the optimal operation of cascade reservoirs water level is usually taken as state variable for initial individual however the water level process which randomly generated time interval by time interval in procedure of initial population generation must have contained state variables that do not conform to the regulation rules of cascade reservoirs and this will be unfavorable to obtain more realistic optimization results therefore generating initial population follow the regulation rules is an effective and practical improvement measure to enhance the adaptability of nsga ii algorithm in optimal operation of cascade reservoirs different from the operation rule of single reservoir the cascade reservoirs are often needed to cooperate with each other in joint operation to produce more comprehensive benefits thus the regulation rules of cascade reservoirs are more complicated and the upstream and downstream reservoirs have fixed operation rules in different periods if the initial population can be generated according to this rules more realistic optimization results will be got for the study area in this paper the regulation rules of lyx and ljx cascade reservoirs have been described in detail in section 2 3 2 in step of initial population generation the water level variation processes of cascade reservoirs for each initial individual are generated according to formula 1 formula 2 and formula 3 given the above fig 10 shows the flowchart of applying the improved nsga ii to derive a non inferior set of operation processes for multi objectives regulation by cascade reservoirs 3 4 sediment transport model for the nim reach the sediment transporting quantity is an important physical value and useful engineering parameter to reflect the transportability of sediments of river channel establishing the conversion relationship between regulation discharge of wsr and sediment transporting quantity of the nim reach is an important link to evaluate the effect of long term wsr in fact bai 2014 had established a sediment transport model which reflect the correlation formulas between sediment transport rate and section discharge and sediment content of each section reach based on the measured data of 65 historical floods in nim and the errors between calculated values and measured values were less than 10 in this paper the model shown as follows were employed to calculate the transported sediment quantity 14 qtx section r qtx i j 0 011702 q qtx 0 705 i j s xhy 0 794 i j 15 szs section r szs i j 0 000424 q szs 1 242 i j s qtx 0 412 i j 16 bygl section r bygl i j 0 000164 q bygl 1 240 i j s szs 1 083 i j 17 shhk section r shhk i j 0 000159 q shhk 1 377 i j s bygl 0 489 i j 18 tdg section r tdg i j 0 000064 q tdg 1 482 i j s shhk 0 609 i j 19 q n i j q n 1 i j q n in i j q n out i j where r i j is the sediment transport rate in one section kg s q n i j is the average discharge in n section m3 s n 0 1 2 3 6 represent the ljx xhy qtx szs bygl shhk tdg section respectively q n in i j and q n out i j are the inter zone inflow and outflow of interval reach from n 1 section to n section respectively m3 s s i j is the sediment content of upper stream section kg m3 the sediment transport model given above is benefit to calculate the scouring sediment amount of nim reach and the fig 11 shows the calculating process of sediment transport in wsr period it s important to note that it is impossible to obtain the measured value of sediment content during wsr period in each section needed in formulas 14 18 because wsr have not yet been carried out in the nim reach in reality fortunately artificial floods caused by wsr in april should have similar characteristics of sediment transport with natural floods in flood season therefore the values of sediment content of each section during wsr period could be replaced by the measured data of a historical flood which s peak flow of maximal month flood discharge is closest to the controlling discharge of wsr 4 results and discussion usually for evolutionary algorithms in engineering applications multiple trials are needed depending on two aspects 1 the randomness which may largely influence the performance of evolutionary algorithms and 2 the complexity of the optimization problem thus we choose and analyze a relatively superior trial among many tries the main parameters of the improved nsga ii algorithm as population size number of generation crossover ratio and mutation ratio are 100 3000 0 8 and 0 3 0 01 respectively 4 1 competitive relationships between multi objectives the pareto front or the decision space contains 100 feasible design alternatives derived by improved nsga ii algorithm has been shown in fig 12 meanwhile the pareto front has been projected into 2d space as shown in fig 13 fig 12 show that the pareto front of three objectives are well distributed in a curved surface from 13840 67 108 kw h to 13901 74 108 kw h for the total generation from 311 83 108 m3 to 322 93 108 m3 for the total shortage for water supply and 375 68 108 m3 to 414 92 108 m3 for the total water volume of wsr in addition the transformation law between the three objectives had be revealed when one objective increases at least one of the other two objects decreases which demonstrate apparent contradiction between the three objectives furthermore fig 13 shows the relationship and sensitivity of every pair of objectives through two dimensional planes subfigure a shows that the power generation is decreasing while the shortage of water supply is decreasing i e the water supply is increasing which proves that there is an obvious competitive relationship between the two optimization objectives it can be observed from subfigure b that the competitive relationship is still clear between the water volume of wsr and the shortage of water supply however the competitive relationship is less clear between the water volume of wsr and the power generation in subfigure c demonstrate that the power generation is less sensitive to the increase of the water volume of wsr this may be due to two reasons 1 the operation policy of cascade reservoirs during the period of wsr the outflow of lyx reservoir is only 1200 m3 s maximum power generating flow to avoid a great loss of hydropower for eight runoff reservoirs from lyx to ljx and minimize the losses of hydropower 2 in periods of wsr which is in a minority the water volume for wsr is far greater than the maximal usable water for power generation cause the power generation is low insensitive to a spot of increasing or decreasing of wsr water in general the relationship between the three objectives can be described that as shown in fig 14 the obj 1 has an intense competition with obj 2 owing to the water supply capacity of cascade reservoirs is restricted in several months after wsr similarly the obj 2 has an intense competition with obj 3 because of the relatively stable process of water supply leading the cascade reservoirs reduce the power water head considerably whereas the obj 3 is insensitive to obj 1 4 2 multi objective analysis of typical schemes 4 2 1 the comprehensive efficiencies for multi objectives four typical schemes were chosen from among 100 alternatives to further analyze the relationships between the three objectives they are scheme 1 minimum shortage for water supply scheme 2 maximum water volume of wsr scheme 3 maximum generation and scheme 4 a compromise scheme as shown in fig 12 the comprehensive efficiencies for multi objectives of four schemes are listed in table 6 table 6 shows some indicators related to the three objectives such as the times of wsr the average water volume of once wsr the annual cascade power generation and power generating guarantee rate annual shortage for water supply and water supply guarantee rate it can be seen in table 6 that 1 wsr has been carried out 6 times for the long term operation that means wsr should be taken once every four years averagely the maximal water volume of wsr is 408 92 108 m3 and the average water volume of wsr is 68 15 108 m3 in scheme 2 while the minimal water volume of wsr is 400 92 108 m3 and the average water volume of wsr is 66 82 108 m3 in scheme 3 2 the requirement of power generation has been reached in all schemes the power generating guarantee rates of four schemes are 92 36 91 67 92 81 92 79 respectively which are all above the design guaranteed rate the annual cascade power generation of four schemes are 576 86 108 kw h 576 69 108 kw h 579 24 108 kw h and 578 74 108 kw h respectively higher than the design cascade power generation of 565 108 kw h 3 the guarantee rates of water supply of four schemes are 79 33 77 07 76 14 78 65 respectively higher than the design guaranteed rate of 75 and meet the requirement of water supply upper the yellow river meanwhile the maximal annual shortage for water supply is 13 27 108 m3 in scheme 3 scheme of maximum generation reflect a strong competition between water supply and power generation 4 2 2 water demand and sediment sluicing for wsr table 7 gives the water volume and discharge for wsr during the long term optimal operation of four schemes it is clearly seen that wsr could been carried out in six years according to the long term operation i e 1989 1992 1993 1999 2005 and 2009 and the water coming frequency of the six years are all less than 25 this shows that the suitable years for wsr are the high and partial high flow years the difference of outflow of ljx reservoir in april for wsr among the four schemes are small and the outflow values range from 2541 m3 s to 2682 m3 s with an average of 2601 m3 s particularly the outflow of ljx reservoir in four schemes are identical in 1992 1999 2009 respectively while for the rest years the outflow values of ljx reservoir in scheme 2 are the maximum of four schemes taking the sediment regulation in 1989 of scheme 4 as an example the incoming sediment and sediment transport of each section and the scouring sediment amount of five intervals of nim reach are calculated based on the sediment transport model the calculation results are shown in table 8 as shown in table 8 considering the influence of tributaries and diversion in the condition that the outflow of ljx reservoir is 2682 m3 s the discharge values of each section in nim reach can meet the requirements of wsr controlling discharge in table 4 i e q r 2470 2580 it is worth noting that the discharge values of sections xhy and szs shown in table 8 are outside of the regulation discharge range because of water diversion for agricultural irrigation in xhy qtx and szs bygl intervals in april the discharge values of sections qtx and bygl has reduced obviously during wsr period and the discharge of section bygl is 2485 m3 s which only slightly above the minimum limit discharge for wsr i e 2470 m3 s in view of this to ensure that the discharge of each section is greater than the minimum limit discharge for wsr the discharge of sections xhy and szs are higher than 2580 m3 s the result of sediment deposition or sluicing of intervals in table 8 shows that the first interval riverbed xhy to qtx is silted with 2 9 million t sand and the other four intervals are all scoured during wsr period which shows an increasing trend along the river and the total amount of sluicing sand of riverbed in the nim reach is 39 3 million t among the four scoured intervals the amount of sluicing sand in shhk tdg interval is the largest accounting for 39 95 of the total sluicing sand as the last section of nim reach the tdg section has transport sand of 61 2 million t during wsr period the above data only reflect the effect of one times of wsr in order to reflect the sluicing effect of long term wsr in the nim reach intuitively the sediment sluicing results of 6 years of four schemes are listed in table 9 as shown in table 9 there are 233 6 million tons of riverbed sediments of nim reach have been sluicing by long term sediment regulation in scheme 1 234 5 million tons in scheme 2 233 2 million tons in scheme 3 and 233 8 million tons in scheme 4 the average value of total sluicing sand by wsr of four schemes is 233 78 million tons according to the research about sediment deposition volume of recent 50 years in nim reach which pointed out that the rate of sediment deposition is 0 51billion t a approximately thus the total sediment deposition amount in the riverbed of nim reach from 1987 to 2010 is 1224 million tons shi 2010 as a consequence the total amount of sand sluicing by long term wsr account for 19 10 of the sediment deposition from 1987 to 2010 it is an undeniable fact that the ability of mitigating sedimentation by wsr is limited due to the contradiction of limited water quantity and multi utilization nonetheless wsr is useful and necessary for the upper yellow river to mitigate the increasingly serious problem of sediment deposition and riverbed siltation 4 2 3 water supply and hydropower generation considering wsr taking the scheme 4 as an example fig 15 shows the annual water shortage and power generation processes of scheme 4 it can be observed that the shortage volume of water supply increase sharply in years with the implementation of wsr such as 1989 1992 1993 2009 reflect the negative impact of wsr on the water supply the year of maximal water shortage is 1992 with shortage volume of 30 03 108 m3 and the year of minimal shortage is 2008 with shortage volume of 8 56 108 m3 in most of the years the volume of annual water shortage are within the range from 10 95 108 m3 to 15 42 108 m3 which are mainly caused by the contradiction between the limit discharge of ljx reservoir and the lz section water demand during ice control period the annual power generation process shows that the year of maximal energy output is 1990 with output of 508 84 108 kw h which is 46 67 108 kw h higher than the annual average power generating capacity of cascade reservoirs the year of minimal output is 2002 with output of 439 98 108 kw h 22 19 108 kw h less than the annual average power generating capacity based on the above analysis of results in section 4 2 it can be concluded that dynamic balance between wsr and other multi objectives can be achieved for the cascade reservoirs in the upper yellow river wsr is feasible and sustainable which can mitigate sediment deposition and alleviate the problem of suspended river to a certain extent although long term wsr will bring some negative effects on power generation and water supply it will not break the design indexes of these two objectives and will be able to perform the tasks of flood control ice flood control and ecological base flow in the upper yellow river 4 3 operation modes and risk free conditions of cascade reservoirs for wsr taking the scheme four as an example as well this paper analyzes the changing process of inflow and outflow of cascade reservoirs to reflect the joint operation modes of them as shown in fig 16 to reflect the change of operation modes of cascade reservoirs by long term wsr the multi objective operation model has been modified by removing the object 1 and solve the model once again the pareto solution set without wsr are obtained and one of the non inferior solutions is selected then the monthly water level changing process of cascade reservoirs of the non inferior solution without wsr is compared with that of scheme 4 as shown in fig 17 it is can be observed from subfigure a of fig 16 that the lyx reservoir takes full advantage of huge regulating storage to regulate the natural runoff in the upper yellow river and greatly changes the natural runoff process especially reduces the flood peak discharge in flood season and increases the downstream runoff in dry season in the long term regulation the abandoned water quantity of lyx reservoir is 0 m3 and the maximum outflow discharge is 1200 m3 s which are all occurred in the wsr period as the anti regulating reservoir of lyx the inflow and outflow of ljx reservoir are closely related to the outflow of lyx reservoir to meet the comprehensive water requirement in downstream the subfigure b of fig 16 shows that the ljx reservoir has anti regulated the outflow of lyx as follows 1 reducing the water of entering the downstream channel and strictly observing the upper limit outflow discharge during the ice control period 2 the outflow discharge of ljx reservoir is larger than the inflow during the irrigation period especially in the wsr period the outflow increases to more than 2500 m3 s 3 in the main flood season a part of the outflow of lyx reservoir is properly stored under the premise of ensuring the safety of flood control and the outflow discharge of ljx reservoir in october is increased obviously the subfigure a of fig 17 shows the difference between the water level process of lyx reservoir with or without wsr from 1987 to 2003 the water level process of lyx reservoir is less affected by wsr because of the supplement of abundant runoff in flood season that make the water level could rise rapidly however from 2004 to 2010 the water level process of lyx reservoir is great changed by wsr which is manifested by dropping to the dead water level and unable to recover to high water level the reason is the decrease of runoff 3 dry years in this period and the lyx reservoir has to lower the water level and increase the discharge to meet the comprehensive water demand it is noticeable that the water level of lyx reservoir had dropped to the dead water level in the end of april in 2009 what represent the capability of long term wsr has been fully exploited finally the water level of lyx reservoir with wsr drop to 2557 0 m at the end of the operation period which is 29 68 m lower than that in the scheme without wsr and the storage capacity is reduced by 68 83 108 m3 it can be seen from the subfigure b of fig 17 that the change of water level of ljx reservoir caused by wsr is temporary in the years when wsr has been taken the water level of ljx drop to the dead level in april due to the small storage capacity of ljx and the water compensation of lyx reservoir in flood season the water level of ljx rises gradually from july to september at last the water level of ljx reservoir with wsr rise to 1721 37 m at the end of the operation period which is 8 63 m lower than that in the scheme without wsr and the storage capacity was decreased by 10 45 108 m3 actually the optimal operation for cascade reservoirs in this paper is based on historical runoff data however in the actual reservoir operation due to the short forecast period of hydrological forecasting technology it is often impossible to accurately know the long term runoff in the future especially in april it is impossible to judge whether the runoff in flood season is abundant or not so it is more difficult to select the right time to carry out wsr in order to guide the cascade reservoirs to carry out risk free wsr effectively in practice it is absolutely essential to make clear the risk free conditions of the cascade reservoirs for wsr table 10 gives the information of water level and capacity before taking wsr for lyx and ljx reservoir which is used as a reference in actual operation it can be observed from table 10 that 1 for lyx reservoir the average water level before wsr is 2565 79 m and the corresponding capacity is 137 42 108 m3 the average lowering of water level by once wsr is 8 21 m and the average lowering of capacity by once wsr is 21 11 108 m3 2 for ljx reservoir the average water level before wsr is 1734 22 m and the corresponding capacity is 41 08 108 m3 the average lowering of water level is 37 48 m and the average lowering of capacity is 32 94 108 m3 this indicate that in the actual operation if the runoff in the future flood season is uncertain when the water level and capacity of the cascade reservoirs reach those above average values before april the wsr can be carry out without risk 4 4 discussion about ecological impact of wsr and countermeasures wsr is a non engineering measure to reduce the sediment deposition in the downstream riverbed through artificial flood regulated by reservoirs as an effective means of river sediment management wsr bring some expected benefits of reducing river bed elevation alleviating suspended river enhancing flood and ice flood discharge capacity of the river courses however wsr is a double edged sword for river ecological system although wsr has not been carried out in the upper yellow river in reality and it is impossible to accurately quantify the ecological impact of wsr fortunately by consulting the literatures on the ecological effects of wsr regulated by the xld reservoir in the lower yellow river we can get some qualitative conclusions of the ecological impact of wsr the ecological benefit of wsr is water supplement for wetlands liu et al 2016 in the past 20 years affected by climate change and human activities the areas of wetland in ningxia plain and inner mongolia plain in the yellow river basin have decreased by 20 48 km2 and 49 41 km2 respectively zheng et al 2016 wang et al 2018 in addition to scouring sediment a month long artificial flood caused by wsr in the nim reach can also raise groundwater level of river wetlands by seepage supply it is conceivable that wsr in the nim reach can benefit to vegetation growth increase the biodiversity improve the ecology function increase the bird population and prevent the shrinkage of wetland area the adverse impact of wsr is mainly reflected on fish and ecologically sensitive areas zhu et al 2012 affected by artificial floods released by cascade reservoirs in wsr period the fish resources in the reservoirs area and the lyx ljx reach will be reduced and the diversity of aquatic species will be decreased the sharp decline in water level of reservoirs in wsr period will also lead to the loss of ecological function of the spawning ground feeding ground and wintering ground of fish moreover impacted by wsr the sediment content of the nim reach will increases greatly in wsr period which will lead to the rapid increase of ammonia nitrogen content and the decrease of oxygen content in the river and may lead to the death of a number of fish to mitigate this negative impact countermeasures including establishment of fish resources protected areas fishery stock enhancement and releasing fish breeding sites downstream of the tributaries in nim reach as temporary shelter for fish are necessary 5 conclusion wsr water supply and hydropower generation are the most three important objectives for the utilization of water resources in sediment laden river under serious circumstance of suspended river and runoff decrease however the competitive relationships between the three objectives are uncovered and the effect and necessary conditions of wsr are indefinite which have bring obstacles to sediment management in sediment laden river additionally whether dynamic balance between long term wsr and other objectives could be achieved is an important issue related to the sustainability of wsr moreover the traditional nsga ii algorithm is inefficient and unsuitable to solve multi objective model for cascade reservoirs with interconnected and fixed regulation rules thus it is necessary to improve the algorithm different from other similar studies about wsr that focused on operation of single reservoir and fewer objectives this paper present a multi objective operation model for cascade reservoirs where five conflicting objectives and a set of complicated operational constrains are all considered simultaneously and also a sediment transport model was introduced to quantify the effect of wsr then the nsga ii algorithm was improved through shrinking feasible search space and generating initial population follow regulation rules to effectively solve the operation model and key control indicators of wsr i e the regulation discharge and regulating time were analyzed methodology mentioned above are applied in the upper yellow river basin the results show that wsr could be carried out every four years averagely in the study area and 233 78 million tons of sediments can be sluicing by long term wsr which account for 19 10 of the downstream sediment deposition in the operation period water supply has a strong competition with power generation an intensified competition with wsr as well meanwhile the competition between wsr and power generation is seen as secondary which means that in order to mitigate the sediment deposition problem it is essential to compromise on water supply benefit appropriately for actual operation that limited by existing hydrological forecasting technology the necessary conditions of lyx and ljx reservoirs water volume are 137 42 108 m3 and 41 08 108 m3 respectively which are a reference for taking wsr without risk the ecological benefits of wsr include reducing river bed elevation alleviating suspended river and water supplement for wetlands while adverse impact on fish and ecologically sensitive areas cannot be ignored and some countermeasures such as establishment of fish resources protected areas and fish breeding sites are suggested in this study through the optimization operation model dynamic balance between long term wsr and water supply power generation flood control ice flood control and ecology base runoff in sediment laden river have been achieved for the first time via the cooperation of cascade reservoirs more importantly the competitive relationships between wsr and other objectives have been revealed the ability and effect of long term wsr have been obtained and the operation modes and risk free conditions of cascade reservoirs for wsr have been put forward to guide actual operation which expand the theoretical system and technical method of wsr although the models and methods have only been applied to the upper yellow river in this paper its generic formulation allows its application to a broad range of rivers over the world admittedly some inadequacies of this work are expected to be improved the values of key control indicators of wsr are static rather than dynamic in wsr period and have no function of optimizing with the response of channel morphology and river bed evolution the improvement suggestion for this problem is to shorten the calculation interval into day or ten days during wsr period and establish the relationship between the evolution of river bed and the regulation discharge of wsr in the nim reach in this way the dynamic coupling between cascade reservoirs and river channel can be realized by feeding back the response results of river morphology to the water sediment multi objectives regulation model sediment management is a global and complex problem for sediment laden rivers like the yellow river how to realize the combination of wsr and multi objective utilization of water resources in the whole river and study the high efficiency sediment transport mode of cascade reservoirs under the common action of various sediment control measures such as sediment retaining sediment transportation and artificial sand excavation are the future directions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research is supported by the national key research and development program of china 2017yfc0404406 and the national natural science foundation of china 51879214 51679187 91647112 51679189 the authors extend special thanks to editors and numerous anonymous reviewers for their valuable reviews their comments and suggestions improved the quality of this paper 
6269,concentrations of uranium u 30 µg l in groundwater are relatively uncommon in drinking water in the united states but can be of concern in those areas where complex interactions of aquifer materials and anthropogenic alterations of the natural flow regime mobilize u high concentrations 30 µg l of u in the southeastern san joaquin valley california usa have been detected in 24 percent of 257 domestic irrigation and public supply wells sampled across an approximately 110 000 km2 area in this study we evaluated mechanisms for mobilization of u in the san joaquin valley proposed in previous studies confirming mobilization by hco3 and refuting mobilization by no3 and we refined our understanding of the geologic sources of u to the scale of individual alluvial fans the location of high concentrations depends on the interactions of geological u sources from fluvial fans that originate in the sierra nevada to the east and seepage of irrigation water that contains high concentrations of hco3 that leaches u from the sediments in addition interactions with po4 from fertilized irrigated fields may sequester u in the aquifer principal component analysis of the data demonstrates that hco3 and ions associated with high total dissolved solids in the aquifer and the percentage of agriculture near the well sampled are associated with high u concentrations nitrate concentrations do not appear to control release of u to the aquifer age dating of the groundwater and generally increasing u concentrations of the past 25 years in resampled wells where irrigation is prevalent suggests that high u concentrations are associated with younger water indicating that irrigation of fields over the past 100 years has significantly contributed to increasing concentrations and mobilizing u in some places the groundwater is supersaturated with uranyl containing minerals as would be expected in roll front deposits in general the interaction of natural geological sources high in u the anthropogenically driven addition of hco3 and possibly phosphate fertilizer control the location and concentration of u in each individual fluvial fan but the addition of nitrate in fertilizer does not appear control the location of high u these geochemical interactions are complex but can be used to determine controls on anomalously high u in alluvial aquifers keywords uranium geochemistry groundwater san joaquin valley central valley california 1 introduction uranium u concentrations in groundwater sampled in the united states from public supply domestic and monitoring wells are generally below the u s environmental protection agency us epa maximum contaminant level mcl of 30 µg l with 1 6 percent of wells above the mcl desimone et al 2014 however it is the 6th most common contaminant that occurs above an mcl in the united states although 238u is a radioactive element its long half life of 4 5 billion years makes it only weakly carcinogenic however u appears to impair kidney function at concentrations 30 µg l when consumed in drinking water over long exposure periods years voegtlin and hodge 1953 thun et al 1985 stannard 1988 zamora et al 1998 kurttio et al 2002 the long term implications to kidney function are still unknown but high concentrations of u may make people predisposed to develop acute renal impairment caused by other environmental nephrotoxic compounds that may not have damaged the kidney without the presence of u vicente vicente et al 2010 in general the relatively prevalent elevated concentrations of u in drinking water wells in some areas makes determining the source of u to the groundwater important for protecting human health there are more detections of u at elevated concentrations in the western united states than in the east due to low humidity and low natural recharge rates prevalence of oxic groundwater long flow paths long residence time and a greater spatial distribution of high u in soil and aquifer sediments derived from granitic crystalline rocks desimone et al 2014 burow et al 2017 the highest concentrations detected in drinking water derived from groundwater in national scale studies in the united states are generally less than 180 µg l scott and barker 1962 desimone 2009 desimone et al 2014 burow et al 2017 with the highest concentration of 429 µg l found in crystalline rocks of the northeast ayotte et al 2007 maximum concentrations in the central valley of california and the high plains aquifer in the central united states exceed concentrations of 2000 µg l nolan and weber 2015 these high concentrations reported by nolan and weber 2015 are located in shallow monitoring wells that are not used for drinking water supplies and are in arid southern areas of the tulare lake basin where u deposits are present and u is evapoconcentrated fujii and swain 1995 the san joaquin valley is the southern portion of the central valley of california from san joaquin county in the north to kern county in the south it is bounded to the east by the sierra nevada mountains and to the west by the california coast ranges fig 1 on the eastern side of the san joaquin valley east of the san joaquin river referred to here as the eastern san joaquin aquifer fig 1 high concentrations of u 100 µg l occur in specific parts of the aquifer associated with particular fluvial fans originating in the granitic rocks of the sierra nevada to the east jurgens et al 2008 2010 jurgens et al 2010 and burow et al 2017 found that the higher concentrations of u were associated with agricultural irrigation water that reacted with the partial pressure of co2 p co 2 in the soil and created additional alkalinity that was flushed into the shallow aquifer the increase in p co 2 at least partially mobilized u from adsorption sites from shallow sediments jurgens et al 2010 the resulting alkalinity and u from the soil zone then complexed with u in the oxic aquifer to form mostly a neutral calcium uranyl carbonate complex which increased the concentration of u in the shallow aquifer however wells with high u 100 µg l in the aquifer are not evenly distributed across the oxic aquifer and some wells with high u are not easily explained by redox conditions in the aquifer as suggested by jurgens et al 2010 additional chemical pathways such as dissolution by nitrate nolan and weber 2015 and precipitation with phosphorus mehta et al 2014 as well as the geologic source and distribution of u in the aquifer may also play a role in where high concentrations may occur nolan and weber 2015 showed that in the san joaquin aquifer and the ogallala aquifer in the midwest usa that nitrate concentrations from agricultural fertilizers correlated with high natural uranium concentrations in groundwater and suggested that nitrate altered the u solubility in aquifer materials by oxidative dissolution of reduced u iv minerals conversely mehta et al 2014 demonstrated that high phosphate concentrations in groundwater may adsorb or precipitate uranium minerals particularly if calcium concentrations are high in the solution these competing chemical mechanisms have not been addressed in previous studies of the san joaquin aquifer system nor has the role of the source materials that contribute sediment to the individual alluvial fans from the sierras the purpose of this study is to determine which of the above chemical and geological parameters are most important in the spatial distribution of high u concentrations in the eastern san joaquin aquifer the hypothesis to be tested is that agricultural irrigation water and redox control the overall distribution of elevated u concentrations but that specific other factors such as aquifer source materials high phosphate or nitrate concentrations also contribute to where u concentrations exceed 100 µg l these different mechanisms for concentrating u have not been tested together to determine their relative importance in any of the previous studies a better understanding of the key chemical geological and human drivers of u mobilization in aquifers will help in determining the risk and trends in u concentrations in other alluvial aquifers 2 methods in order to address the hypothesis that agricultural irrigation water and redox control the overall distribution of elevated u concentrations but that other natural and anthropogenic factors also contribute to u concentrations exceeding 100 µg l the following methods have been employed 1 compilation of u concentrations for various datasets with quality assured data 2 aero radiometric data of surficial u concentrations to delineate where u concentrations are high in the soil 3 determination of redox conditions to assess u mobility the relationship between the age of the groundwater and the concentration of u which may be related to an agricultural source and chemical speciation to see if concentrations are sufficiently high to precipitate u minerals and 4 principal component analysis pca of water quality data land use well depth groundwater age and geological factors to determine correlations between all parameters that may contribute to high u concentrations finally a decadal trend analysis was conducted to determine if u concentrations were increasing over time and if any observed trends were consistent with where irrigation from agricultural land use was causing u to be released to the groundwater 2 1 data compilation data were compiled from groundwater quality data collected for u s geological survey california groundwater ambient monitoring assessment program priority basin project gama pbp belitz et al 2003 and national water quality assessment project nawqa hirsch et al 1988 studies in the madera chowchilla kings kaweah tule and tulare lake subbasins of the san joaquin valley groundwater basins fig 1 the 257 wells sampled included 162 domestic wells median depth 61 m bls 62 public supply wells median depth 119 m bls 15 irrigation wells median depth 146 m bls and 18 monitoring wells median depth 47 m bls fram 2019 table 1 ion balances were calculated for these 257 wells and 89 percent of the wells were within 5 percent of a perfect balance the remaining 11 percent 29 wells were within 17 percent of perfect balance between cations and anions all the wells were sampled at least once during 2005 2018 most during 2013 2018 and 78 were sampled more than once during 1993 2018 fram 2019 table 2 gama pbp data are available from the usgs gama pbp https ca water usgs gov projects gama water quality results and the california state water board gama groundwater information system http geotracker waterboards ca gov gama gamamap public and nawqa data are available from the usgs national water information system https waterdata usgs gov nwis the dataset was subdivided according to the boundaries of the fluvial fans delineated by weissmann et al 2005 chowchilla and fresno river fans 37 wells san joaquin river fan 37 wells kings river fan 90 wells kaweah river fan 30 wells and inter fan areas outside of the fan boundaries 63 wells the inter fan wells were mostly located in the eastern part of the basin above the fans near the sierra nevada fig 1 uranium data were censored at 1 µg l although lower detection limits were used starting in 2001 censoring to a common reporting level avoided bias in the analysis samples with a concentration of 1 µg l were assigned a value of 0 99 to make computations possible this is an arbitrary value but should not make a difference in the results of the analysis particularly because this analysis is concerned with where high concentrations of u are located and is not concerned with delineating how u is released to solution at low concentrations water quality parameters used to interpret u concentrations included ph dissolved oxygen major ions hco3 sulfate so4 chloride cl calcium ca sodium na potassium k magnesium mg minor elements nitrate as nitrogen no3 n phosphate as phosphorus po4 p manganese mn iron fe and trace elements bromide br fluoride f vanadium v strontium sr barium ba and molybdenum mo these water quality parameters were used as explanatory variables in correlation and regression analyses as u complexes with other ions that may make it more soluble other data included well depths 246 of 257 wells lateral distance of the well from the valley axis to the edge of the valley where bedrock is exposed 2001 land use data from usgs nlcde land use coverage of percentages of agriculture urban areas and natural landscapes within a 500 m buffer around each well fram 2019 table 1 koterba 1998 these were all included in the initial pca see below to determine significant parameters to test further overall well depths ranged from 12 m to 433 m bsl with a median well depth of 71 5 m bsl twenty seven of 246 wells were deeper than 153 m bsl and only 3 were deeper than 305 m bsl aero radiometric data hill et al 2009 were used to estimate concentrations of u in shallow sediment around the wells fig 2 fram 2019 table 1 bismuth 214 and 208th are decay products of u and thorium along with 40k they give identifiable peaks in the aerial gamma ray spectra of naturally occurring radiation at the surface of the earth the element data and the ratios of the element data are used to map surficial geology and to detect concentrations of radioactive minerals hill et al 2009 these data only determine where high u concentrations are present near the surface and not at depth in the aquifer but they provide a general guide to where high u may be present in the subsurface 2 2 classification of redox conditions groundwater age dating and chemical speciation the oxidation reduction redox status of samples was classified using the classification scheme of mcmahon and chapelle 2008 that was automated by jurgens et al 2009 redox classes were grouped into three categories for statistical analysis oxic o2 reducing no3 reducing or suboxic anoxic mn reducing fe reducing or so4 reducing and mixed o2 reducing and mn or fe reducing mixing of different sources of water in a well can be caused by long open intervals in the wells short circuiting of water caused by poor well construction or by changes in hydraulic gradients caused by pumping given the lack of data on most wells it isn t possible to quantitatively determine the amount of mixing in individual wells groundwater age the length of time groundwater resides in the aquifer system was represented by a three level classification scheme wells were classified as having modern mixed or pre modern groundwater based on tritium 3h and carbon 14 14c concentrations similar to jurgens et al 2016 tritium activities were decay corrected to 2016 and compared to the decay corrected atmospheric 3h input records from 1950 to 2016 for the latitude and longitude of the well site michel et al 2018 half of the samples with 3h data also had 14c data samples with decay corrected 3h 1 0 tu primarily composed of water recharged after about 1955 samples with 3h 0 25 tu were defined as pre modern primarily composed of water recharged prior to 1955 samples with 0 25 3h 1 0 tu were classified as mixed of the samples with 14c data 91 of the samples classified as modern had 14c 85 pmc and 92 of the samples classified as pre modern had 14c 85 pmc in reality pre modern groundwater could contain very small fractions of modern water and modern groundwater could contain very small fractions of pre modern water speciation of dissolved u and saturation indices of uranium and carbonate minerals in groundwater were calculated using phreeqc parkhurst and appelo 2013 formation constants for u complexes in the phreeqc thermodynamic database were updated grenthe et al 1992 and other ternary complexes were added dong and brooks 2006 values of hypothetical electron activity pɛ were specified based on the redox classification for each sample fram 2019 table 2 2 3 statistical analyses nonparametric kruskal wallis anova tests of each fan and inter fan u concentrations were done to determine whether differences in u concentrations existed between the different fans and the inter fan locations the nonparametric kruskal wallis anova test used with independent variables was used because the number of less than values in each dataset made parametric tests invalid and the differences in sample size between each fan did not lend itself to pair tests significance was considered to be established if p values were less than 0 05 linear regression statistical tests were performed to determine correlations between variables correlation were deemed significant if p values were less than 0 05 95 percent confidence limit principal component analyses pca is a data reduction technique that applies a linear combination of the analyzed variables to obtain new uncorrelated variables representing the maximum variance of the data set which are defined as principal components kramer 1998 analyses were conducted of the entire dataset to look for differences in the basin as a whole to reduce autocorrelation chemicals and predictive variables were selected that would best represent those variables that co varied for this analysis tds was used to represent the major ions except hco3 which was also used because of its likely relation with u other variables used were u well depth generalized age of the water modern mixed or pre modern land use agriculture urban or natural minimally disturbed lateral position from the basin center zero is the basin center and the saturation index of the water with respect to calcite and uranium the age of the water was given a numeric value of 1 for modern water 2 for mixed water and 3 for pre modern water data used in the pca were first scaled and centered by the mean using the equation of kramer 1998 principal component analyses were conducted using originpro 2018b software version b9 5 5 409 originlab northampton ma add in module that allows better graphics than the software that comes with the program the add in uses the same computational methods to determine the principal components as the originpro software 2 4 analysis of changes in uranium concentration with time uranium and alkalinity concentrations in 68 wells within the study area were sampled on two or three occasions thirty seven wells were sampled at time 1 t1 between 1993 and 1995 65 wells were sampled during time 2 t2 between 2001 and 2008 and all 68 wells were sampled at time 3 t3 between 2013 and 2018 the amount of change determined was from the samples that were farthest apart in time t3 minus t1 or t3 minus t2 uranium concentrations were determined to have changed if the difference between the farthest time a part was greater than 5 µg l while this is an arbitrary cutoff it gives confidence that the change is real and not a false positive this may lead to small changes being counted as no change false negative but because we are concerned here with large changes in u over time false negatives can be accepted uranium concentrations were compared to hco3 concentrations to determine if they were changing in the same direction and relative magnitude alkalinity concentrations were not available for the 1993 1995 period and field determined alkalinities for some wells were not available for other periods the following procedure was used to obtain alkalinity hco3 measurements for all samples field gran titrations were used when available for all samples if gran titrations were not available field incremental titrations were used if field titrations were not available field titrations were calculated from lab titrations based on previous gama pbp studies field alkalinity is systematically lower than lab alkalinity bennett and fram 2014 for the samples in this dataset there is a linear relationship supplementary fig s1 the slope 0 99 0 01 and intercept 2 85 2 16 from this relationship r2 0 98 p 0 0001 was used to calculate a field alkalinity from the lab alkalinity for samples without field alkalinities for those samples without alkalinity measurements 1993 1995 samples field alkalinities were calculated from charge balance using ca mg na k cl so4 and no3 n as the major ions all the alkalinity was assumed to be hco3 which is likely because most ph values are less than 8 3 the relation between the calculated and measured alkalinity values was linear so that the slope and intercept of the line was used to calculate a field alkalinity from the alkalinity calculated from the charge balance 3 geologic background and land use river fans were used as the primary geologic category for the wells because the composition of sediment in contact with groundwater is likely to affect groundwater chemistry the san joaquin kings and kaweah fans are dominated by sediments derived from granitic rocks because the watersheds extend to higher elevations of the southern sierra nevada that are primarily granitic rocks eroded by glaciation weissman et al 2005 in contrast the fresno and chowchilla are dominated by sediment from metasedimentary and metavolcanic rocks because the watersheds of those rivers are smaller and are primarily restricted to the lower elevation unglaciated areas of the central sierra nevada where granitic rocks are not exposed weissman et al 2005 sediment derived from sierra nevada granitic rocks generally contains higher concentrations of u than does sediment from the other rocks desimone et al 2014 aero radiometric data hill et al 2009 confirm that the u content of surficial sediments in the fresno chowchilla fans is generally less than that in the san joaquin kings and kaweah fans fig 2 however the aero radiometric data only indicates the surface sediments river courses have varied and the fans likely interfinger land use within the study area has been broadly categorized into three dominant types natural land use that has had minimal human disturbance irrigated agriculture and urban areas pumping of groundwater occurs in all three categories land use maps from 2001 were used for this study as more modern land use may not yet influence the water below the land use but land use recorded in 2001 up to 14 years earlier than the last sampling event performed on wells in this study more likely has had time to impact the water quality particularly where pumping and fertilizer use was prevalent land use is dominated by agriculture but a significant number of wells are in areas with predominantly urban land use the location of the wells dominated by natural land use is mostly in the upper fan and inter fan areas closest to the sierra nevada to establish the baseline or pre development alkalinity as bicarbonate hco3 jurgens et al 2008 2010 used pre development values of between 108 and 119 mg l hco3 determined from historic hco3 data analyzed by mendenhall et al 1916 and from land use around deep wells sampled in their study therefore a hco3 concentration 120 mg l which is the upper value of the mendenhall et al 1916 data will be used as likely pre development hco3 concentration in this study 4 results and discussion overall u concentrations in the 257 wells ranged from less than 1 µg l to as high as 449 µg l the lowest concentrations occurred primarily in the upper parts of the fluvial fans in the inter fan areas and at the most distal part of the kings kaweah river fans fig 2 the highest u concentration in the kings kaweah river fan area was 449 µg l the highest u concentration in the san joaquin river fan area was 250 µg l and the highest concentration in the chowchilla fresno river fan area was 87 µg l the highest inter fan concentration was 95 µg l median u concentrations of each fan and inter fan set of wells varied from 2 05 µg l in the inter fan wells to 14 5 µg l in the san joaquin fan the percentage of wells above 30 µg l u concentration also varied by fan with the san joaquin river fan having 46 percent of wells 30 µg l the kings kaweah river fan having 27 percent the chowchilla fresno river fan having 14 percent and the inter fan 8 percent overall 24 percent of the 257 wells sampled had u concentrations greater than the mcl nonparametric kruskal wallis tests of fan and inter fan u concentrations show that the populations are significantly different at a 0 05 confidence level although the median inter fan concentrations and the chowchilla fresno fans u concentrations are not significantly different the highest u concentrations are found in the kings kaweah fan but the san joaquin river fan has the highest median and mean u concentrations given that each fan has statistically different u concentrations and the chowchilla fresno fan and inter fan wells have the lowest u concentrations the discussion will concentrate on the factors that contribute to where the highest u concentrations are found 4 1 high uranium concentrations associated with geology uranium concentrations of the water sampled from wells are compared to the u concentrations derived from aero radiometric data and the mapped geology of the areas where the alluvial fans originate figs 1 and 2 in general among the three fans and the inter fan wells u concentrations in the water from sampled wells were lowest in the proximal areas of the fans upgradient from the previously artesian area mapped by mendenhall et al 1916 because of widespread pumping the previously artesian distal sediments are now drained and the water table is well below land surface however these distal sediments would tend to have higher organic matter concentrations due to water logging of the soils on which u could have been accumulated the highest concentrations of u in the water from sampled wells tend to occur in the mid to distal areas of the san joaquin and kings kaweah river fans because of this accumulation of u in these formerly waterlogged and relatively organic rich sediments compared to proximal sediments exceedances of the u mcl in groundwater from wells in the chowchilla fresno river fan area occur primarily in the southernmost distal part of the fresno river fan it is possible that the sediments tapped by these wells which are much deeper 36 253 m in the chowchilla fresno river fan area than the surficial sediments were derived from the san joaquin river fan as the fan delineations by weissmann et al 2005 were based on near surface sediments at the very least the distal fresno river fan sediments may interfinger with the san joaquin river fan sediments because the san joaquin river drains a much larger watershed and its headwaters are higher in the sierras than the chowchilla and fresno rivers the san joaquin river is also much larger than the chowchilla and fresno rivers so that the volume of sediment deposited from the san joaquin is much greater than the fresno river and the san joaquin river likely meandered to the north at some time in the past the lower concentrations of u in the chowchilla fresno river fans may also be caused by the difference in upstream rock type and the elevation of the headwaters that these rivers drain although the upstream portions of the chowchilla and fresno river fans erode granitic rock the downstream portions cut through jurassic meta sedimentary rocks that likely have a lesser u content churchill 1991 occurrence of high concentrations of u in surficial rocks and sediment is related to proximity to granitic rocks within the sierra nevada and in the valley to watershed extent and contact with glaciated source material of streams draining the sierra nevada uranium concentrations in surficial rocks and sediment are highest in the granitic rocks in the high elevation previously glaciated regions of the sierra nevada and in the proximal parts of the san joaquin kings and kaweah rivers where those streams enter the valley the fresno and chowchilla rivers watersheds do not reach the glaciated high sierras and have much smaller watersheds than the san joaquin or kings and kaweah rivers weissmann et al 2005 therefore the amount of sediments deposited in these fans is smaller than the other fans and the dominant sediment source may have come from lower elevation non granitic and non glaciated sediments the highest concentrations of u in groundwater do not directly correlate with the highest u concentrations in surficial rocks and sediment estimated from aero radiometric data fig 2 this is likely because the wells are significantly deeper than what is mapped at the near surface so processes at depth may not be reflected in the aero radiometric data as noted earlier the highest concentrations in the surficial rocks and sediments correspond with the shape of the fluvial fans in the proximal portion where the rivers enter the valley these proximal locations may have provided the u needed for transport along the long groundwater flow paths of the larger fans which allowed for sufficient geochemical evolution to accumulate u on the sediments in the distal parts of the fans the amount of u that may be easily mobilized is typically only a small fraction of the total u on the sediment shown in the aero radiometric data however jurgens et al 2008 the groundwater chemistry and the u source controls the release of u to the groundwater therefore although the geology of the fans contributes the source of u it doesn t solely explain the exceptionally high concentrations found in some wells of the san joaquin and kings kaweah fans 4 2 high uranium associated with irrigated agriculture no well with more than 20 percent natural land use surrounding the well has a u concentration greater than 30 µg l fig 3 high u concentrations are almost exclusively found in areas where agriculture is the dominant land use although there are a few wells with mixed agriculture and urban land use that have high u concentrations fig 3 jurgens et al 2010 showed that u concentrations in the eastern san joaquin valley are strongly correlated to hco3 concentrations in groundwater the eastern san joaquin valley is intensively farmed and irrigated faunt 2009 changes in u concentrations were also strongly correlated to changes in hco3 concentrations in arid irrigated parts of the western u s for example eastern washington western nevada central arizona and new mexico and northern utah and colorado burow et al 2017 jurgens et al 2010 found that u sorbed on iron oxyhydroxide coatings sediment grains clay mineral edges or to organic matter hsi and langmuir 1985 waite et al 1994 porcelli and swarzenski 2003 davis et al 2003 catalano and brown 2005 is being leached by high hco3 recharge primarily from the irrigated agriculture although the median hco3 concentration of wells located in agricultural areas is 233 mg l compared to natural and other land use that have median hco3 concentrations of approximately 162 174 mg l the median concentrations are not statistically different nonparametric kruskal wallis anova independent sample test this is likely because the variability in the hco3 concentrations is high and most of the wells studied here are in areas dominated by agricultural 178 wells out of 257 wells have land use surrounding the well that is 60 percent agriculture in this study u concentrations in wells are also strongly correlated to hco3 concentrations based on significant p 0 05 linear regressions of data from each fan especially on the chowchilla fresno and san joaquin river fans fig 4 the kings kaweah fan may have a lower correlation simply because of the larger number of wells sampled than in the other fans however even when the two fans are separated the correlations are low the kings kaweah fan is also larger than the other fans and there may be other geochemical processes at work that is confounding the correlation it is interesting to note that the mixed and reduced redox wells have hco3 concentrations of about 200 400 mg l and u concentrations from 1 to nearly 300 µg l located in the san joaquin river fan sediments all but 1 of these 8 wells are located at the most distal extent of the mapped san joaquin river fan this zone at the toe of the fan is likely where the redox boundary exists between the oxic upgradient water and the reduced downgradient water the presence of high concentrations of u in reduced water likely indicates the samples are from mixed sources of water and may indicate that some of the u dissolved in groundwater is derived from dissolution of u bearing minerals such as uraninite the tds in these wells is generally 500 mg l na ranges from about 100 to 300 mg l and the groundwater ages are mixed and pre modern suggesting these wells tap predominantly more evolved groundwater at the edge of the redox front some of the mixing may be due to long screened wells tapping into shallower oxic water that contains the high u mixing with reduced water below other notable features on the san joaquin river fan are the 10 oxic wells with hco3 concentrations between 400 and 600 mg l and corresponding u concentrations from 120 to 250 µg l these wells are located in the mid fan area with characteristics of water that is less evolved than in the wells near the distal end of the fan because the wells are oxic it is likely that the high u is due to high hco3 concentrations and that u dominantly exists in a u vi oxidation state and that it has been desorbed from the fe oxyhydroxide coatings which contrasts with the distal fan processes the process for why u concentrations is higher than 100 µg l in the mid fan area is not well constrained but it suggests that the source of u sorbed on the sediments is not limited high concentrations of u 500 µg l have been reported elsewhere zamora et al 1998 kurttio et al 2002 vicente vicente et al 2010 but these studies were generally conducted in areas where uranium mining was occurring and explanations for these exceptionally high u concentrations were not given in these studies 4 2 1 relations between uranium and nitrate and phosphorous the association of high u with irrigated agriculture in the eastern san joaquin valley suggests that aside from hco3 other agricultural associated chemicals may be important in either mobilizing or sequestering u from the aquifer water nolan and weber 2015 have shown that high no3 n concentrations in the central valley and the high plains aquifer correlate with high u concentrations in both these basins although the correlation is relatively weak in their study they conclude that high no3 n concentrations may enhance u mobility by oxidative dissolution of reduced u iv minerals from the aquifer materials however the correlation may simply be because excess nitrogen applied to farm fields occurs with irrigation of the crops and associated hco3 increase and the correlation with no3 n may not be associated with the geochemical reactions occurring in the aquifer in the groundwater samples analyzed for this study u and no3 n are only weakly correlated when all wells located in fans are plotted pearson s r 0 27 at a significance level of 0 05 there is no significant correlation between u and no3 n for wells located in inter fan areas when wells are grouped by individual fans u and no3 n correlations for the san joaquin river and chowchilla fresno fans are stronger with pearson s r values of 0 68 and 0 53 respectively fig 5 a but pearson s r correlation in the kings kaweah fan is 0 30 the lower pearson s r for the kings kaweah fan is likely due to the much larger sample size of wells in this fan 120 compared to the other two 37 wells in each fan which indicates that the correlation is dependent on the sample size or other chemical processes occurring in these fans while the correlations indicate that the slope of the lines are significantly different than zero except for the inter fan wells the slope of each line is different and there is considerable variability in the slopes and the lines explain generally less than 50 percent of the data except for wells from the san joaquin fan when u concentrations 30 µg l us epa mcl across all fan and inter fan areas were plotted against no3 n for all wells n 60 in a manner similar to nolan and weber 2015 the correlation was not significant and showed a slight negative slope to the regression line fig 5b it may be that the data analyzed by nolan and weber 2015 for the central valley were highly influenced by extremely high u 1000 µg l and no3 n 50 mg l concentrations in shallow monitoring wells from the tulare basin 15 m that are located near uranium deposits that were also concentrated by evaporation fujii and swain 1995 and by extremely low values that occur in all fans that may explain why the correlation is significant in individual fans but not significant when only the high concentrations are plotted however the data presented here indicate little statistical correlation between no3 n and u concentrations particularly at u concentrations 30 µg l suggesting that the release of hco3 from the soil due to irrigation contributes more to altering u solubility than oxidative dissolution of reduced u iv minerals caused by high no3 n concentrations although no3 n concentrations may play a small role in mobilizing u in some parts of the san joaquin basin phosphorus concentrations are also relatively high up to 2 mg l as dissolved p in some locations in the eastern san joaquin valley but u and phosphorous generally do not co occur in the basin supplementary fig s2 when u is high phosphorus concentrations are below detection and vice versa mehta et al 2014 found that uranyl phosphate solids are relatively insoluble and are associated with uranium ores and the products and solubility of the uranyl phosphate minerals can be affected by ph dissolved inorganic carbon and the dominant cation sodium or calcium in batch experiments mehta et al 2014 found that in sodium dominated systems sodium autunite and autunite are the main uranyl phosphates to form but in calcium dominated systems the observed concentrations were below the predicted solubility of autunite they suggested that u may be adsorbed or incorporated into calcium phosphate precipitates in addition to precipitation of autunite in the eastern san joaquin valley where ca and hco3 are generally the dominant ions in solution phreeqc calculations indicate that all samples are undersaturated with autunite and most samples with p 0 15 mg l are saturated with hydroxylapatite and all samples saturated with hydroxylapatite have u 40 µg l this suggests that excessive addition of phosphate fertilizer could at least partially reduce u concentrations in some areas sodium concentrations are higher towards the center of the basin where more reduced water is located supplementary fig s3 the higher na values in the center of the basin reflect greater dissolution of aquifer material over the longer flow paths the addition of irrigation water may also enhance dissolution of materials in the vadose zone and lead to greater concentrations near the basin center where agriculture is more prevalent 4 2 2 pca associations of the data and agriculture principal component analysis shows that the first two components explain 40 percent of the variance of the data fig 6 the third and fourth principle components each explain a little more than 10 percent of variance and so are marginally significant table 1 and cumulatively with pc1 and pc2 explain 60 percent of the data variance variables were excluded in the final analysis to minimize autocorrelation for example ca autocorrelates with hco3 because of calcite caco3 dissolution in the soil zone and the aquifer and most of the major ions autocorrelated with total dissolved solids tds because the individual major ions sum to produce the tds therefore most of the major ions were left out of the pca because they all autocorrelated with tds however hco3 was left in the pca to determine if there is a relation with u the pca indicates that u total dissolved solids and hco3 are closely related in the first principle component pc1 as expected given the close correlations already determined with bivariate analysis fig 5 in addition percent agriculture and saturation index with respect to calcite also are important in pc1 fig 6 table 1 a saturation index that indicates calcium carbonate precipitation is possible is likely to correlate with high hco3 if ca is also high but this is not a strict auto correlation between hco3 and saturation index because there are other important variables such as high ca concentrations temperature and ph that are needed to create a high saturation index for calcite in the groundwater more importantly the dissolution of hco3 from minerals in the vadose zone promotes carbonate saturation in the groundwater where irrigated agriculture occurs stumm and morgan 1996 therefore all these parameters hco3 u percent agriculture and saturation index with respect to calcite are related and interact to cause this cluster in pc1 and show the greatest loading scores for pc1 table 1 nitrate is weakly associated with pc1 but is not as closely associated with u as hco3 this may indicate that the association is more due to the agricultural land use and use of nitrogen fertilizers than with the association with u principle component two pc2 shows high loading scores for groundwater age depth of well no3 n concentration and lateral position from the center of the basin table 1 lateral position towards the center of the basin visually appears to be correlated with u concentration and the pca shows that that the lateral position of a well in the basin is inversely correlated with u fig 6 this is because the position of a well in the basin is designated as zero in the middle of the basin and increases toward the east thus there is a correlation of lateral position in the basin and u concentration similarly the age of the groundwater was designated as modern with a value of one and premodern with a value of 3 and the depth of the wells has smaller values for shallow wells so the correlation of old groundwater age and deeper wells on the opposite side of the pca diagram indicates that high u and hco3 concentrations are associated with young water fig 7 in shallow wells nitrate is also not closely grouped with u and indicates that it is unlikely that no3 n is an important cause of u mobilization phosphate however should negatively correlate with u if its presence sequesters u although not exactly opposite to u it does plot far away from the u loading fig 6 pc3 and 4 do not explain much of the variance in the data but may show that redox is somewhat important because uranium saturation index and mn have high loading scores in pc3 pc4 shows that urban land use explains the variance in the pc but this is likely showing that urban land use is antithetic to u concentrations due to the direction of the loadings on the axes fig 6 overall the pca confirms that irrigated agriculture is an important driver of the occurrence of u in the san joaquin valley however there is a lack of numerical data for geological information at each well so the importance of geological source material could not be evaluated with the pca 4 3 location of uranium concentrations the pca shows a correlation of u concentration with position near the center of the basin some of the highest concentrations of u in groundwater are within the artesian area mapped by mendenhall et al 1916 during the early part of the 20th century these artesian zones have since been dewatered such that the water table is significantly below land surface but previous artesian areas on the distal parts of the fans are expected to be higher in organic matter because flow slows in this part of fan and organic matter is more likely to settle out of the slow moving water in addition artesian areas may create marsh lands that are high in organic matter uranium can be trapped in organic sediments soil by adsorption ion exchange or by reduction otton et al 1989 and because the uranium entrapment in the sediments is relatively young high concentrations of u are not often captured on airborne surveys otton et al 1989 as seen in fig 2 u concentrations in groundwater generally increase from the proximal to distal ends of the fluvial fans the highest concentrations on the kings kaweah river fans are in mixed and reduced groundwater similar to the san joaquin river fan this indicates that these wells are drawing mixed water at the edge of the redox boundary major ion concentrations including relatively conservative na and cl ions show a similar increase with distance from proximal to distal parts of the fluvial fans supplementary fig s3 and have similar loadings in the pca to u consistent with evolution of the groundwater as it travels down the fan however most high u concentrations occur in wells that show modern or mixed groundwater ages the high u concentrations and high hco3 concentrations fig 7 suggest that addition of u and hco3 concentrations to the groundwater in these fans occurred most likely in the last 100 years or so particularly because most pre modern water has lower u and hco3 concentrations than recently recharged water fig 7 this is similar to the increase in total dissolved solids over the past 100 years for the eastern san joaquin valley hansen et al 2018 which further indicates that large scale irrigation of valley sediments has leached chemicals from vadose zone sediments this indicates that modern water from extensive irrigation over the past 100 years plays a large role in mobilizing u from the aquifer materials 4 4 change in u concentrations over time sixty eight wells within all the fans used in this study were sampled on multiple occasions from 1993 to 2018 fig 8 in order to assess whether irrigation water is mobilizing u by leaching hco3 from the soil wells with an increase in u concentration of more than 5 µg l are significantly correlated with increases in hco3 concentrations fig 9 this indicates that there is a relation between change in u concentrations and hco3 concentrations both positive and negative those wells that appear to have increases in hco3 but little or no increase in u may not have u available in the aquifer to be mobilized by the hco3 or alternatively hco3 addition occurs rapidly and it takes time to mobilize the u in the aquifer this latter hypothesis suggests that u concentrations could increase in these wells additional monitoring of wells with increasing hco3 concentrations may then be warranted to assess whether u will increase in the future decreases in u associated with decreases in hco3 may be related to precipitation or absorption of uranyl carbonate compounds in the aquifer materials but there is currently no data to determine if this is occurring alternatively decreasing concentrations could simply be caused by cessation of irrigation in these areas the largest increasing u concentrations are more than 100 µg l in many places and appear to be mostly concentrated in the central area of the basin where agricultural is the dominant land use the wells with decreasing u concentrations generally show changes less than 30 µg l and in some cases are near the edges of urban areas fig 8 the decreasing concentrations near urban areas may be caused by land use change from irrigated agriculture to urban land use the cessation of irrigation may decrease the dissolution of carbonate minerals in the aquifer that causes a subsequent decrease of hco3 which then decreases the u being complexed with hco3 and released to the aquifer however jurgens et al 2008 showed that hco3 and u was just as high beneath the urban areas as in the agricultural areas this could mean that decreasing u concentrations in the wells sampled in this study were fortuitously located near urban areas or that land use change did not have sufficient time to alter u concentrations when the jurgens et al 2008 study was completed a correlation between changes in u and nitrate nitrite no3 n no2 n would also be expected if addition of nitrate fertilizers was mobilizing u in the soil zone and subsequently recharging high nitrate and u water to the aquifer however there appears to be no correlation between u and no3 n no2 n changes in these same wells supplementary fig s4 this indicates that high no3 n concentrations are not the primary cause of increasing u concentrations in the eastern san joaquin aquifer system 5 mobilization of uranium the wells with the highest u occur at the edge of the redox boundary in mixed and anoxic redox water in the lower part of the san joaquin river and kings kaweah river fans supplementary fig s5 the chowchilla fresno river fans did not have any wells with mixed redox conditions and overall the water sampled in the chowchilla fresno river fan aquifer was oxic except one well with reduced water and concentrations of u were also low uranium may have accumulated in the sediment at the locations where the redox front begins providing higher concentrations of u in the sediment from which u was mobilized into groundwater although the concentrations of u in the sediments here are likely not high enough to be of economic value it is possible that the apparent accumulation of u at the distal ends of the fluvial fans could have been deposited by processes similar to uranium roll front deposits uranium roll front deposits occur in sandstone deposits and are produced by movement of oxic groundwater and subsequent mineral precipitation of those constituents upon interaction with reducing agents harshman 1974 abzalov 2012 uranium is leached from the original source rock before being precipitated into the host material in uranium roll front deposits enrichment in trace elements such as mo se and te have been found harshman 1974 min et al 2005 abzalov 2012 bullock and parnell 2017 in conventional roll front models se tends to concentrate at the redox front while mo concentrates in reduced unaltered sands harshman 1966 1974 rubin 1970 finch and davis 1985 spinks et al 2014 2016 to test the hypothesis of whether oxidation of uraninite may have contributed to the anomalously high uranium content of some samples saturation indices for all the samples with u 30 µg l using hypothetical electron activity pε ranging from 4 typically assigned to oxic samples to 3 5 typically assigned to methanogenic samples were used to determine what pε would be required for saturation for uraninite si between 0 5 and 0 5 the pε required ranged from 0 to 1 5 stumm and morgan 1996 give ranges for pε of reduction reactions stumm and morgan 1996 fig 8 14 a pε between 0 and 1 5 would be roughly consistent with fe reduction and reduction of no3 to nh3 groundwater samples were then divided into those that were too oxic to have that pε and those that were either reduced or could be mixtures of more reduced and oxic waters fig 10 in fig 10 the wells that could be considered possibly saturated with respect to uraninite squares are all inside the area of artesian conditions as defined by mendenhall et al 1916 and most of the samples that were undersaturated with respect to uraninite circles are outside of that area the squares include the 5 highest u concentrations 234 449 µg l and half of all samples with u 100 µg l in addition 80 of the squares are modern or mixed in age so this water has not had a long time to interact with the aquifer materials the water designated by the squares could thus represent mixtures of younger oxic water and older anoxic water with the oxygen from the young water oxidizing the uraninite and the high hco3 making it possible for the u to stay in solution rather than simply sorbing to the sediments the circles only have the one mechanism high hco3causing desorption and so don t have as high u concentrations these data can also be used to determine whether no3 n concentrations are important for releasing u to solution among the samples with u 30 µg l the squares have median no3 n of 2 5 mg l and median u of 138 µg l fig 10 the circles have median no3 n of 13 3 mg l and median u concentrations of 87 µg l the difference in no3 n between the samples designated with squares and circles is significant at p 0 000001 but the difference at these same sites in u is significant at only p 0 043 which agrees with the lack of correlation seen when no3 n and u for u samples 30 µg l are plotted supplementary fig s4 although it could be that there was denitrification or nitrate reduction or even nitrate oxidizing uraninite nitrate oxidation of uraninite is not necessary to explain the data the fact that the young water has oxygen and bicarbonate is sufficient 6 conclusions uranium sampled in groundwater in the eastern part of the san joaquin basin can reach concentrations of nearly 500 µg l in the mid to distal fan areas of the san joaquin river and kings kaweah fluvial fans mobilization of u concentrations at concentrations that high is relatively rare outside of uranium mining districts previous studies have not looked at the source of u to the individual alluvial fans that form the aquifer and have not analyzed competing mechanisms of bicarbonate nitrate and phosphate contributions to the anomalously high concentrations of u in the aquifer our analysis is consistent with our hypothesis that agricultural irrigation water and redox may control the overall distribution of elevated u concentrations but that specific other factors such as aquifer source materials and low phosphate concentrations also contribute to high u concentrations high no3 n concentrations do not appear to be correlated with high u concentrations in the fan deposits in contrast to what has been suggested by previous studies our analysis has shown that anomalously high u concentrations in the eastern san joaquin aquifer system require a geologic source of uranium in this case erosion of glacially eroded granitic rocks from high elevations in the sierra nevada depending on the u source of the individual fluvial fans maximum concentrations of u in each fan may be more than 300 µg l different than adjacent fans inter fan sediments which are only partially sourced from the high sierras have the lowest u concentrations mobilization occurs when young irrigation water applied to agricultural fields releases hco3 through chemical interactions in the vadose zone and this hco3 is carried into the groundwater where u that is sorbed on iron oxyhydroxide coatings sediment grains clay mineral edges or to organic matter is being leached by high hco3 recharge and complexed with hco3 ions nitrate concentrations in the irrigated agricultural water does not appear to enhance u dissolution but addition of phosphate may reduce the solubility of u by forming insoluble uranyl phosphate compounds at the toe of the fluvial fans mixed redox conditions may further enhance u dissolution to the point of uraninite saturation similar to the process that occurs in uranium roll front deposits where u is mined although this is currently a rare process in the san joaquin as more u is leached from alluvial deposits of the san joaquin valley it may become more prevalent in the future uranium concentrations have been shown to be increasing in the western united states this study has shown the complexity of predicting where high u concentrations will be found further study in other areas of the western united states and around the world would benefit from considering the mechanisms for mobilization and sequestration of u demonstrated here to understand u mobilization elsewhere declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the personnel of the california water science center ca wsc who collected all the samples for this study quality assurance of the data by sylvia stork was invaluable for providing a clean reproduceable dataset we would like to thank bryant jurgens for providing age dating classifications and discussion of preliminary drafts of the manuscript we would also like to thank the well owners who allowed us to collect samples from their wells dina saleh ca wsc provided all the gis figures for this manuscript and her contributions are greatly appreciated reviews by usgs personnel anke mueller solger and craig brown and anonymous journal of hydrology reviewers greatly improved the clarity of this manuscript funding for this work was provided by the california state water resources control board groundwater ambient monitoring and assessment program usgs cooperative matching funds and the usgs national water quality program appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124009 appendix a supplementary data the following are the supplementary data to this article supplementary figure 1 supplementary figure 2 supplementary figure 3 supplementary figure 4 supplementary figure 5 supplementary data 1 
6269,concentrations of uranium u 30 µg l in groundwater are relatively uncommon in drinking water in the united states but can be of concern in those areas where complex interactions of aquifer materials and anthropogenic alterations of the natural flow regime mobilize u high concentrations 30 µg l of u in the southeastern san joaquin valley california usa have been detected in 24 percent of 257 domestic irrigation and public supply wells sampled across an approximately 110 000 km2 area in this study we evaluated mechanisms for mobilization of u in the san joaquin valley proposed in previous studies confirming mobilization by hco3 and refuting mobilization by no3 and we refined our understanding of the geologic sources of u to the scale of individual alluvial fans the location of high concentrations depends on the interactions of geological u sources from fluvial fans that originate in the sierra nevada to the east and seepage of irrigation water that contains high concentrations of hco3 that leaches u from the sediments in addition interactions with po4 from fertilized irrigated fields may sequester u in the aquifer principal component analysis of the data demonstrates that hco3 and ions associated with high total dissolved solids in the aquifer and the percentage of agriculture near the well sampled are associated with high u concentrations nitrate concentrations do not appear to control release of u to the aquifer age dating of the groundwater and generally increasing u concentrations of the past 25 years in resampled wells where irrigation is prevalent suggests that high u concentrations are associated with younger water indicating that irrigation of fields over the past 100 years has significantly contributed to increasing concentrations and mobilizing u in some places the groundwater is supersaturated with uranyl containing minerals as would be expected in roll front deposits in general the interaction of natural geological sources high in u the anthropogenically driven addition of hco3 and possibly phosphate fertilizer control the location and concentration of u in each individual fluvial fan but the addition of nitrate in fertilizer does not appear control the location of high u these geochemical interactions are complex but can be used to determine controls on anomalously high u in alluvial aquifers keywords uranium geochemistry groundwater san joaquin valley central valley california 1 introduction uranium u concentrations in groundwater sampled in the united states from public supply domestic and monitoring wells are generally below the u s environmental protection agency us epa maximum contaminant level mcl of 30 µg l with 1 6 percent of wells above the mcl desimone et al 2014 however it is the 6th most common contaminant that occurs above an mcl in the united states although 238u is a radioactive element its long half life of 4 5 billion years makes it only weakly carcinogenic however u appears to impair kidney function at concentrations 30 µg l when consumed in drinking water over long exposure periods years voegtlin and hodge 1953 thun et al 1985 stannard 1988 zamora et al 1998 kurttio et al 2002 the long term implications to kidney function are still unknown but high concentrations of u may make people predisposed to develop acute renal impairment caused by other environmental nephrotoxic compounds that may not have damaged the kidney without the presence of u vicente vicente et al 2010 in general the relatively prevalent elevated concentrations of u in drinking water wells in some areas makes determining the source of u to the groundwater important for protecting human health there are more detections of u at elevated concentrations in the western united states than in the east due to low humidity and low natural recharge rates prevalence of oxic groundwater long flow paths long residence time and a greater spatial distribution of high u in soil and aquifer sediments derived from granitic crystalline rocks desimone et al 2014 burow et al 2017 the highest concentrations detected in drinking water derived from groundwater in national scale studies in the united states are generally less than 180 µg l scott and barker 1962 desimone 2009 desimone et al 2014 burow et al 2017 with the highest concentration of 429 µg l found in crystalline rocks of the northeast ayotte et al 2007 maximum concentrations in the central valley of california and the high plains aquifer in the central united states exceed concentrations of 2000 µg l nolan and weber 2015 these high concentrations reported by nolan and weber 2015 are located in shallow monitoring wells that are not used for drinking water supplies and are in arid southern areas of the tulare lake basin where u deposits are present and u is evapoconcentrated fujii and swain 1995 the san joaquin valley is the southern portion of the central valley of california from san joaquin county in the north to kern county in the south it is bounded to the east by the sierra nevada mountains and to the west by the california coast ranges fig 1 on the eastern side of the san joaquin valley east of the san joaquin river referred to here as the eastern san joaquin aquifer fig 1 high concentrations of u 100 µg l occur in specific parts of the aquifer associated with particular fluvial fans originating in the granitic rocks of the sierra nevada to the east jurgens et al 2008 2010 jurgens et al 2010 and burow et al 2017 found that the higher concentrations of u were associated with agricultural irrigation water that reacted with the partial pressure of co2 p co 2 in the soil and created additional alkalinity that was flushed into the shallow aquifer the increase in p co 2 at least partially mobilized u from adsorption sites from shallow sediments jurgens et al 2010 the resulting alkalinity and u from the soil zone then complexed with u in the oxic aquifer to form mostly a neutral calcium uranyl carbonate complex which increased the concentration of u in the shallow aquifer however wells with high u 100 µg l in the aquifer are not evenly distributed across the oxic aquifer and some wells with high u are not easily explained by redox conditions in the aquifer as suggested by jurgens et al 2010 additional chemical pathways such as dissolution by nitrate nolan and weber 2015 and precipitation with phosphorus mehta et al 2014 as well as the geologic source and distribution of u in the aquifer may also play a role in where high concentrations may occur nolan and weber 2015 showed that in the san joaquin aquifer and the ogallala aquifer in the midwest usa that nitrate concentrations from agricultural fertilizers correlated with high natural uranium concentrations in groundwater and suggested that nitrate altered the u solubility in aquifer materials by oxidative dissolution of reduced u iv minerals conversely mehta et al 2014 demonstrated that high phosphate concentrations in groundwater may adsorb or precipitate uranium minerals particularly if calcium concentrations are high in the solution these competing chemical mechanisms have not been addressed in previous studies of the san joaquin aquifer system nor has the role of the source materials that contribute sediment to the individual alluvial fans from the sierras the purpose of this study is to determine which of the above chemical and geological parameters are most important in the spatial distribution of high u concentrations in the eastern san joaquin aquifer the hypothesis to be tested is that agricultural irrigation water and redox control the overall distribution of elevated u concentrations but that specific other factors such as aquifer source materials high phosphate or nitrate concentrations also contribute to where u concentrations exceed 100 µg l these different mechanisms for concentrating u have not been tested together to determine their relative importance in any of the previous studies a better understanding of the key chemical geological and human drivers of u mobilization in aquifers will help in determining the risk and trends in u concentrations in other alluvial aquifers 2 methods in order to address the hypothesis that agricultural irrigation water and redox control the overall distribution of elevated u concentrations but that other natural and anthropogenic factors also contribute to u concentrations exceeding 100 µg l the following methods have been employed 1 compilation of u concentrations for various datasets with quality assured data 2 aero radiometric data of surficial u concentrations to delineate where u concentrations are high in the soil 3 determination of redox conditions to assess u mobility the relationship between the age of the groundwater and the concentration of u which may be related to an agricultural source and chemical speciation to see if concentrations are sufficiently high to precipitate u minerals and 4 principal component analysis pca of water quality data land use well depth groundwater age and geological factors to determine correlations between all parameters that may contribute to high u concentrations finally a decadal trend analysis was conducted to determine if u concentrations were increasing over time and if any observed trends were consistent with where irrigation from agricultural land use was causing u to be released to the groundwater 2 1 data compilation data were compiled from groundwater quality data collected for u s geological survey california groundwater ambient monitoring assessment program priority basin project gama pbp belitz et al 2003 and national water quality assessment project nawqa hirsch et al 1988 studies in the madera chowchilla kings kaweah tule and tulare lake subbasins of the san joaquin valley groundwater basins fig 1 the 257 wells sampled included 162 domestic wells median depth 61 m bls 62 public supply wells median depth 119 m bls 15 irrigation wells median depth 146 m bls and 18 monitoring wells median depth 47 m bls fram 2019 table 1 ion balances were calculated for these 257 wells and 89 percent of the wells were within 5 percent of a perfect balance the remaining 11 percent 29 wells were within 17 percent of perfect balance between cations and anions all the wells were sampled at least once during 2005 2018 most during 2013 2018 and 78 were sampled more than once during 1993 2018 fram 2019 table 2 gama pbp data are available from the usgs gama pbp https ca water usgs gov projects gama water quality results and the california state water board gama groundwater information system http geotracker waterboards ca gov gama gamamap public and nawqa data are available from the usgs national water information system https waterdata usgs gov nwis the dataset was subdivided according to the boundaries of the fluvial fans delineated by weissmann et al 2005 chowchilla and fresno river fans 37 wells san joaquin river fan 37 wells kings river fan 90 wells kaweah river fan 30 wells and inter fan areas outside of the fan boundaries 63 wells the inter fan wells were mostly located in the eastern part of the basin above the fans near the sierra nevada fig 1 uranium data were censored at 1 µg l although lower detection limits were used starting in 2001 censoring to a common reporting level avoided bias in the analysis samples with a concentration of 1 µg l were assigned a value of 0 99 to make computations possible this is an arbitrary value but should not make a difference in the results of the analysis particularly because this analysis is concerned with where high concentrations of u are located and is not concerned with delineating how u is released to solution at low concentrations water quality parameters used to interpret u concentrations included ph dissolved oxygen major ions hco3 sulfate so4 chloride cl calcium ca sodium na potassium k magnesium mg minor elements nitrate as nitrogen no3 n phosphate as phosphorus po4 p manganese mn iron fe and trace elements bromide br fluoride f vanadium v strontium sr barium ba and molybdenum mo these water quality parameters were used as explanatory variables in correlation and regression analyses as u complexes with other ions that may make it more soluble other data included well depths 246 of 257 wells lateral distance of the well from the valley axis to the edge of the valley where bedrock is exposed 2001 land use data from usgs nlcde land use coverage of percentages of agriculture urban areas and natural landscapes within a 500 m buffer around each well fram 2019 table 1 koterba 1998 these were all included in the initial pca see below to determine significant parameters to test further overall well depths ranged from 12 m to 433 m bsl with a median well depth of 71 5 m bsl twenty seven of 246 wells were deeper than 153 m bsl and only 3 were deeper than 305 m bsl aero radiometric data hill et al 2009 were used to estimate concentrations of u in shallow sediment around the wells fig 2 fram 2019 table 1 bismuth 214 and 208th are decay products of u and thorium along with 40k they give identifiable peaks in the aerial gamma ray spectra of naturally occurring radiation at the surface of the earth the element data and the ratios of the element data are used to map surficial geology and to detect concentrations of radioactive minerals hill et al 2009 these data only determine where high u concentrations are present near the surface and not at depth in the aquifer but they provide a general guide to where high u may be present in the subsurface 2 2 classification of redox conditions groundwater age dating and chemical speciation the oxidation reduction redox status of samples was classified using the classification scheme of mcmahon and chapelle 2008 that was automated by jurgens et al 2009 redox classes were grouped into three categories for statistical analysis oxic o2 reducing no3 reducing or suboxic anoxic mn reducing fe reducing or so4 reducing and mixed o2 reducing and mn or fe reducing mixing of different sources of water in a well can be caused by long open intervals in the wells short circuiting of water caused by poor well construction or by changes in hydraulic gradients caused by pumping given the lack of data on most wells it isn t possible to quantitatively determine the amount of mixing in individual wells groundwater age the length of time groundwater resides in the aquifer system was represented by a three level classification scheme wells were classified as having modern mixed or pre modern groundwater based on tritium 3h and carbon 14 14c concentrations similar to jurgens et al 2016 tritium activities were decay corrected to 2016 and compared to the decay corrected atmospheric 3h input records from 1950 to 2016 for the latitude and longitude of the well site michel et al 2018 half of the samples with 3h data also had 14c data samples with decay corrected 3h 1 0 tu primarily composed of water recharged after about 1955 samples with 3h 0 25 tu were defined as pre modern primarily composed of water recharged prior to 1955 samples with 0 25 3h 1 0 tu were classified as mixed of the samples with 14c data 91 of the samples classified as modern had 14c 85 pmc and 92 of the samples classified as pre modern had 14c 85 pmc in reality pre modern groundwater could contain very small fractions of modern water and modern groundwater could contain very small fractions of pre modern water speciation of dissolved u and saturation indices of uranium and carbonate minerals in groundwater were calculated using phreeqc parkhurst and appelo 2013 formation constants for u complexes in the phreeqc thermodynamic database were updated grenthe et al 1992 and other ternary complexes were added dong and brooks 2006 values of hypothetical electron activity pɛ were specified based on the redox classification for each sample fram 2019 table 2 2 3 statistical analyses nonparametric kruskal wallis anova tests of each fan and inter fan u concentrations were done to determine whether differences in u concentrations existed between the different fans and the inter fan locations the nonparametric kruskal wallis anova test used with independent variables was used because the number of less than values in each dataset made parametric tests invalid and the differences in sample size between each fan did not lend itself to pair tests significance was considered to be established if p values were less than 0 05 linear regression statistical tests were performed to determine correlations between variables correlation were deemed significant if p values were less than 0 05 95 percent confidence limit principal component analyses pca is a data reduction technique that applies a linear combination of the analyzed variables to obtain new uncorrelated variables representing the maximum variance of the data set which are defined as principal components kramer 1998 analyses were conducted of the entire dataset to look for differences in the basin as a whole to reduce autocorrelation chemicals and predictive variables were selected that would best represent those variables that co varied for this analysis tds was used to represent the major ions except hco3 which was also used because of its likely relation with u other variables used were u well depth generalized age of the water modern mixed or pre modern land use agriculture urban or natural minimally disturbed lateral position from the basin center zero is the basin center and the saturation index of the water with respect to calcite and uranium the age of the water was given a numeric value of 1 for modern water 2 for mixed water and 3 for pre modern water data used in the pca were first scaled and centered by the mean using the equation of kramer 1998 principal component analyses were conducted using originpro 2018b software version b9 5 5 409 originlab northampton ma add in module that allows better graphics than the software that comes with the program the add in uses the same computational methods to determine the principal components as the originpro software 2 4 analysis of changes in uranium concentration with time uranium and alkalinity concentrations in 68 wells within the study area were sampled on two or three occasions thirty seven wells were sampled at time 1 t1 between 1993 and 1995 65 wells were sampled during time 2 t2 between 2001 and 2008 and all 68 wells were sampled at time 3 t3 between 2013 and 2018 the amount of change determined was from the samples that were farthest apart in time t3 minus t1 or t3 minus t2 uranium concentrations were determined to have changed if the difference between the farthest time a part was greater than 5 µg l while this is an arbitrary cutoff it gives confidence that the change is real and not a false positive this may lead to small changes being counted as no change false negative but because we are concerned here with large changes in u over time false negatives can be accepted uranium concentrations were compared to hco3 concentrations to determine if they were changing in the same direction and relative magnitude alkalinity concentrations were not available for the 1993 1995 period and field determined alkalinities for some wells were not available for other periods the following procedure was used to obtain alkalinity hco3 measurements for all samples field gran titrations were used when available for all samples if gran titrations were not available field incremental titrations were used if field titrations were not available field titrations were calculated from lab titrations based on previous gama pbp studies field alkalinity is systematically lower than lab alkalinity bennett and fram 2014 for the samples in this dataset there is a linear relationship supplementary fig s1 the slope 0 99 0 01 and intercept 2 85 2 16 from this relationship r2 0 98 p 0 0001 was used to calculate a field alkalinity from the lab alkalinity for samples without field alkalinities for those samples without alkalinity measurements 1993 1995 samples field alkalinities were calculated from charge balance using ca mg na k cl so4 and no3 n as the major ions all the alkalinity was assumed to be hco3 which is likely because most ph values are less than 8 3 the relation between the calculated and measured alkalinity values was linear so that the slope and intercept of the line was used to calculate a field alkalinity from the alkalinity calculated from the charge balance 3 geologic background and land use river fans were used as the primary geologic category for the wells because the composition of sediment in contact with groundwater is likely to affect groundwater chemistry the san joaquin kings and kaweah fans are dominated by sediments derived from granitic rocks because the watersheds extend to higher elevations of the southern sierra nevada that are primarily granitic rocks eroded by glaciation weissman et al 2005 in contrast the fresno and chowchilla are dominated by sediment from metasedimentary and metavolcanic rocks because the watersheds of those rivers are smaller and are primarily restricted to the lower elevation unglaciated areas of the central sierra nevada where granitic rocks are not exposed weissman et al 2005 sediment derived from sierra nevada granitic rocks generally contains higher concentrations of u than does sediment from the other rocks desimone et al 2014 aero radiometric data hill et al 2009 confirm that the u content of surficial sediments in the fresno chowchilla fans is generally less than that in the san joaquin kings and kaweah fans fig 2 however the aero radiometric data only indicates the surface sediments river courses have varied and the fans likely interfinger land use within the study area has been broadly categorized into three dominant types natural land use that has had minimal human disturbance irrigated agriculture and urban areas pumping of groundwater occurs in all three categories land use maps from 2001 were used for this study as more modern land use may not yet influence the water below the land use but land use recorded in 2001 up to 14 years earlier than the last sampling event performed on wells in this study more likely has had time to impact the water quality particularly where pumping and fertilizer use was prevalent land use is dominated by agriculture but a significant number of wells are in areas with predominantly urban land use the location of the wells dominated by natural land use is mostly in the upper fan and inter fan areas closest to the sierra nevada to establish the baseline or pre development alkalinity as bicarbonate hco3 jurgens et al 2008 2010 used pre development values of between 108 and 119 mg l hco3 determined from historic hco3 data analyzed by mendenhall et al 1916 and from land use around deep wells sampled in their study therefore a hco3 concentration 120 mg l which is the upper value of the mendenhall et al 1916 data will be used as likely pre development hco3 concentration in this study 4 results and discussion overall u concentrations in the 257 wells ranged from less than 1 µg l to as high as 449 µg l the lowest concentrations occurred primarily in the upper parts of the fluvial fans in the inter fan areas and at the most distal part of the kings kaweah river fans fig 2 the highest u concentration in the kings kaweah river fan area was 449 µg l the highest u concentration in the san joaquin river fan area was 250 µg l and the highest concentration in the chowchilla fresno river fan area was 87 µg l the highest inter fan concentration was 95 µg l median u concentrations of each fan and inter fan set of wells varied from 2 05 µg l in the inter fan wells to 14 5 µg l in the san joaquin fan the percentage of wells above 30 µg l u concentration also varied by fan with the san joaquin river fan having 46 percent of wells 30 µg l the kings kaweah river fan having 27 percent the chowchilla fresno river fan having 14 percent and the inter fan 8 percent overall 24 percent of the 257 wells sampled had u concentrations greater than the mcl nonparametric kruskal wallis tests of fan and inter fan u concentrations show that the populations are significantly different at a 0 05 confidence level although the median inter fan concentrations and the chowchilla fresno fans u concentrations are not significantly different the highest u concentrations are found in the kings kaweah fan but the san joaquin river fan has the highest median and mean u concentrations given that each fan has statistically different u concentrations and the chowchilla fresno fan and inter fan wells have the lowest u concentrations the discussion will concentrate on the factors that contribute to where the highest u concentrations are found 4 1 high uranium concentrations associated with geology uranium concentrations of the water sampled from wells are compared to the u concentrations derived from aero radiometric data and the mapped geology of the areas where the alluvial fans originate figs 1 and 2 in general among the three fans and the inter fan wells u concentrations in the water from sampled wells were lowest in the proximal areas of the fans upgradient from the previously artesian area mapped by mendenhall et al 1916 because of widespread pumping the previously artesian distal sediments are now drained and the water table is well below land surface however these distal sediments would tend to have higher organic matter concentrations due to water logging of the soils on which u could have been accumulated the highest concentrations of u in the water from sampled wells tend to occur in the mid to distal areas of the san joaquin and kings kaweah river fans because of this accumulation of u in these formerly waterlogged and relatively organic rich sediments compared to proximal sediments exceedances of the u mcl in groundwater from wells in the chowchilla fresno river fan area occur primarily in the southernmost distal part of the fresno river fan it is possible that the sediments tapped by these wells which are much deeper 36 253 m in the chowchilla fresno river fan area than the surficial sediments were derived from the san joaquin river fan as the fan delineations by weissmann et al 2005 were based on near surface sediments at the very least the distal fresno river fan sediments may interfinger with the san joaquin river fan sediments because the san joaquin river drains a much larger watershed and its headwaters are higher in the sierras than the chowchilla and fresno rivers the san joaquin river is also much larger than the chowchilla and fresno rivers so that the volume of sediment deposited from the san joaquin is much greater than the fresno river and the san joaquin river likely meandered to the north at some time in the past the lower concentrations of u in the chowchilla fresno river fans may also be caused by the difference in upstream rock type and the elevation of the headwaters that these rivers drain although the upstream portions of the chowchilla and fresno river fans erode granitic rock the downstream portions cut through jurassic meta sedimentary rocks that likely have a lesser u content churchill 1991 occurrence of high concentrations of u in surficial rocks and sediment is related to proximity to granitic rocks within the sierra nevada and in the valley to watershed extent and contact with glaciated source material of streams draining the sierra nevada uranium concentrations in surficial rocks and sediment are highest in the granitic rocks in the high elevation previously glaciated regions of the sierra nevada and in the proximal parts of the san joaquin kings and kaweah rivers where those streams enter the valley the fresno and chowchilla rivers watersheds do not reach the glaciated high sierras and have much smaller watersheds than the san joaquin or kings and kaweah rivers weissmann et al 2005 therefore the amount of sediments deposited in these fans is smaller than the other fans and the dominant sediment source may have come from lower elevation non granitic and non glaciated sediments the highest concentrations of u in groundwater do not directly correlate with the highest u concentrations in surficial rocks and sediment estimated from aero radiometric data fig 2 this is likely because the wells are significantly deeper than what is mapped at the near surface so processes at depth may not be reflected in the aero radiometric data as noted earlier the highest concentrations in the surficial rocks and sediments correspond with the shape of the fluvial fans in the proximal portion where the rivers enter the valley these proximal locations may have provided the u needed for transport along the long groundwater flow paths of the larger fans which allowed for sufficient geochemical evolution to accumulate u on the sediments in the distal parts of the fans the amount of u that may be easily mobilized is typically only a small fraction of the total u on the sediment shown in the aero radiometric data however jurgens et al 2008 the groundwater chemistry and the u source controls the release of u to the groundwater therefore although the geology of the fans contributes the source of u it doesn t solely explain the exceptionally high concentrations found in some wells of the san joaquin and kings kaweah fans 4 2 high uranium associated with irrigated agriculture no well with more than 20 percent natural land use surrounding the well has a u concentration greater than 30 µg l fig 3 high u concentrations are almost exclusively found in areas where agriculture is the dominant land use although there are a few wells with mixed agriculture and urban land use that have high u concentrations fig 3 jurgens et al 2010 showed that u concentrations in the eastern san joaquin valley are strongly correlated to hco3 concentrations in groundwater the eastern san joaquin valley is intensively farmed and irrigated faunt 2009 changes in u concentrations were also strongly correlated to changes in hco3 concentrations in arid irrigated parts of the western u s for example eastern washington western nevada central arizona and new mexico and northern utah and colorado burow et al 2017 jurgens et al 2010 found that u sorbed on iron oxyhydroxide coatings sediment grains clay mineral edges or to organic matter hsi and langmuir 1985 waite et al 1994 porcelli and swarzenski 2003 davis et al 2003 catalano and brown 2005 is being leached by high hco3 recharge primarily from the irrigated agriculture although the median hco3 concentration of wells located in agricultural areas is 233 mg l compared to natural and other land use that have median hco3 concentrations of approximately 162 174 mg l the median concentrations are not statistically different nonparametric kruskal wallis anova independent sample test this is likely because the variability in the hco3 concentrations is high and most of the wells studied here are in areas dominated by agricultural 178 wells out of 257 wells have land use surrounding the well that is 60 percent agriculture in this study u concentrations in wells are also strongly correlated to hco3 concentrations based on significant p 0 05 linear regressions of data from each fan especially on the chowchilla fresno and san joaquin river fans fig 4 the kings kaweah fan may have a lower correlation simply because of the larger number of wells sampled than in the other fans however even when the two fans are separated the correlations are low the kings kaweah fan is also larger than the other fans and there may be other geochemical processes at work that is confounding the correlation it is interesting to note that the mixed and reduced redox wells have hco3 concentrations of about 200 400 mg l and u concentrations from 1 to nearly 300 µg l located in the san joaquin river fan sediments all but 1 of these 8 wells are located at the most distal extent of the mapped san joaquin river fan this zone at the toe of the fan is likely where the redox boundary exists between the oxic upgradient water and the reduced downgradient water the presence of high concentrations of u in reduced water likely indicates the samples are from mixed sources of water and may indicate that some of the u dissolved in groundwater is derived from dissolution of u bearing minerals such as uraninite the tds in these wells is generally 500 mg l na ranges from about 100 to 300 mg l and the groundwater ages are mixed and pre modern suggesting these wells tap predominantly more evolved groundwater at the edge of the redox front some of the mixing may be due to long screened wells tapping into shallower oxic water that contains the high u mixing with reduced water below other notable features on the san joaquin river fan are the 10 oxic wells with hco3 concentrations between 400 and 600 mg l and corresponding u concentrations from 120 to 250 µg l these wells are located in the mid fan area with characteristics of water that is less evolved than in the wells near the distal end of the fan because the wells are oxic it is likely that the high u is due to high hco3 concentrations and that u dominantly exists in a u vi oxidation state and that it has been desorbed from the fe oxyhydroxide coatings which contrasts with the distal fan processes the process for why u concentrations is higher than 100 µg l in the mid fan area is not well constrained but it suggests that the source of u sorbed on the sediments is not limited high concentrations of u 500 µg l have been reported elsewhere zamora et al 1998 kurttio et al 2002 vicente vicente et al 2010 but these studies were generally conducted in areas where uranium mining was occurring and explanations for these exceptionally high u concentrations were not given in these studies 4 2 1 relations between uranium and nitrate and phosphorous the association of high u with irrigated agriculture in the eastern san joaquin valley suggests that aside from hco3 other agricultural associated chemicals may be important in either mobilizing or sequestering u from the aquifer water nolan and weber 2015 have shown that high no3 n concentrations in the central valley and the high plains aquifer correlate with high u concentrations in both these basins although the correlation is relatively weak in their study they conclude that high no3 n concentrations may enhance u mobility by oxidative dissolution of reduced u iv minerals from the aquifer materials however the correlation may simply be because excess nitrogen applied to farm fields occurs with irrigation of the crops and associated hco3 increase and the correlation with no3 n may not be associated with the geochemical reactions occurring in the aquifer in the groundwater samples analyzed for this study u and no3 n are only weakly correlated when all wells located in fans are plotted pearson s r 0 27 at a significance level of 0 05 there is no significant correlation between u and no3 n for wells located in inter fan areas when wells are grouped by individual fans u and no3 n correlations for the san joaquin river and chowchilla fresno fans are stronger with pearson s r values of 0 68 and 0 53 respectively fig 5 a but pearson s r correlation in the kings kaweah fan is 0 30 the lower pearson s r for the kings kaweah fan is likely due to the much larger sample size of wells in this fan 120 compared to the other two 37 wells in each fan which indicates that the correlation is dependent on the sample size or other chemical processes occurring in these fans while the correlations indicate that the slope of the lines are significantly different than zero except for the inter fan wells the slope of each line is different and there is considerable variability in the slopes and the lines explain generally less than 50 percent of the data except for wells from the san joaquin fan when u concentrations 30 µg l us epa mcl across all fan and inter fan areas were plotted against no3 n for all wells n 60 in a manner similar to nolan and weber 2015 the correlation was not significant and showed a slight negative slope to the regression line fig 5b it may be that the data analyzed by nolan and weber 2015 for the central valley were highly influenced by extremely high u 1000 µg l and no3 n 50 mg l concentrations in shallow monitoring wells from the tulare basin 15 m that are located near uranium deposits that were also concentrated by evaporation fujii and swain 1995 and by extremely low values that occur in all fans that may explain why the correlation is significant in individual fans but not significant when only the high concentrations are plotted however the data presented here indicate little statistical correlation between no3 n and u concentrations particularly at u concentrations 30 µg l suggesting that the release of hco3 from the soil due to irrigation contributes more to altering u solubility than oxidative dissolution of reduced u iv minerals caused by high no3 n concentrations although no3 n concentrations may play a small role in mobilizing u in some parts of the san joaquin basin phosphorus concentrations are also relatively high up to 2 mg l as dissolved p in some locations in the eastern san joaquin valley but u and phosphorous generally do not co occur in the basin supplementary fig s2 when u is high phosphorus concentrations are below detection and vice versa mehta et al 2014 found that uranyl phosphate solids are relatively insoluble and are associated with uranium ores and the products and solubility of the uranyl phosphate minerals can be affected by ph dissolved inorganic carbon and the dominant cation sodium or calcium in batch experiments mehta et al 2014 found that in sodium dominated systems sodium autunite and autunite are the main uranyl phosphates to form but in calcium dominated systems the observed concentrations were below the predicted solubility of autunite they suggested that u may be adsorbed or incorporated into calcium phosphate precipitates in addition to precipitation of autunite in the eastern san joaquin valley where ca and hco3 are generally the dominant ions in solution phreeqc calculations indicate that all samples are undersaturated with autunite and most samples with p 0 15 mg l are saturated with hydroxylapatite and all samples saturated with hydroxylapatite have u 40 µg l this suggests that excessive addition of phosphate fertilizer could at least partially reduce u concentrations in some areas sodium concentrations are higher towards the center of the basin where more reduced water is located supplementary fig s3 the higher na values in the center of the basin reflect greater dissolution of aquifer material over the longer flow paths the addition of irrigation water may also enhance dissolution of materials in the vadose zone and lead to greater concentrations near the basin center where agriculture is more prevalent 4 2 2 pca associations of the data and agriculture principal component analysis shows that the first two components explain 40 percent of the variance of the data fig 6 the third and fourth principle components each explain a little more than 10 percent of variance and so are marginally significant table 1 and cumulatively with pc1 and pc2 explain 60 percent of the data variance variables were excluded in the final analysis to minimize autocorrelation for example ca autocorrelates with hco3 because of calcite caco3 dissolution in the soil zone and the aquifer and most of the major ions autocorrelated with total dissolved solids tds because the individual major ions sum to produce the tds therefore most of the major ions were left out of the pca because they all autocorrelated with tds however hco3 was left in the pca to determine if there is a relation with u the pca indicates that u total dissolved solids and hco3 are closely related in the first principle component pc1 as expected given the close correlations already determined with bivariate analysis fig 5 in addition percent agriculture and saturation index with respect to calcite also are important in pc1 fig 6 table 1 a saturation index that indicates calcium carbonate precipitation is possible is likely to correlate with high hco3 if ca is also high but this is not a strict auto correlation between hco3 and saturation index because there are other important variables such as high ca concentrations temperature and ph that are needed to create a high saturation index for calcite in the groundwater more importantly the dissolution of hco3 from minerals in the vadose zone promotes carbonate saturation in the groundwater where irrigated agriculture occurs stumm and morgan 1996 therefore all these parameters hco3 u percent agriculture and saturation index with respect to calcite are related and interact to cause this cluster in pc1 and show the greatest loading scores for pc1 table 1 nitrate is weakly associated with pc1 but is not as closely associated with u as hco3 this may indicate that the association is more due to the agricultural land use and use of nitrogen fertilizers than with the association with u principle component two pc2 shows high loading scores for groundwater age depth of well no3 n concentration and lateral position from the center of the basin table 1 lateral position towards the center of the basin visually appears to be correlated with u concentration and the pca shows that that the lateral position of a well in the basin is inversely correlated with u fig 6 this is because the position of a well in the basin is designated as zero in the middle of the basin and increases toward the east thus there is a correlation of lateral position in the basin and u concentration similarly the age of the groundwater was designated as modern with a value of one and premodern with a value of 3 and the depth of the wells has smaller values for shallow wells so the correlation of old groundwater age and deeper wells on the opposite side of the pca diagram indicates that high u and hco3 concentrations are associated with young water fig 7 in shallow wells nitrate is also not closely grouped with u and indicates that it is unlikely that no3 n is an important cause of u mobilization phosphate however should negatively correlate with u if its presence sequesters u although not exactly opposite to u it does plot far away from the u loading fig 6 pc3 and 4 do not explain much of the variance in the data but may show that redox is somewhat important because uranium saturation index and mn have high loading scores in pc3 pc4 shows that urban land use explains the variance in the pc but this is likely showing that urban land use is antithetic to u concentrations due to the direction of the loadings on the axes fig 6 overall the pca confirms that irrigated agriculture is an important driver of the occurrence of u in the san joaquin valley however there is a lack of numerical data for geological information at each well so the importance of geological source material could not be evaluated with the pca 4 3 location of uranium concentrations the pca shows a correlation of u concentration with position near the center of the basin some of the highest concentrations of u in groundwater are within the artesian area mapped by mendenhall et al 1916 during the early part of the 20th century these artesian zones have since been dewatered such that the water table is significantly below land surface but previous artesian areas on the distal parts of the fans are expected to be higher in organic matter because flow slows in this part of fan and organic matter is more likely to settle out of the slow moving water in addition artesian areas may create marsh lands that are high in organic matter uranium can be trapped in organic sediments soil by adsorption ion exchange or by reduction otton et al 1989 and because the uranium entrapment in the sediments is relatively young high concentrations of u are not often captured on airborne surveys otton et al 1989 as seen in fig 2 u concentrations in groundwater generally increase from the proximal to distal ends of the fluvial fans the highest concentrations on the kings kaweah river fans are in mixed and reduced groundwater similar to the san joaquin river fan this indicates that these wells are drawing mixed water at the edge of the redox boundary major ion concentrations including relatively conservative na and cl ions show a similar increase with distance from proximal to distal parts of the fluvial fans supplementary fig s3 and have similar loadings in the pca to u consistent with evolution of the groundwater as it travels down the fan however most high u concentrations occur in wells that show modern or mixed groundwater ages the high u concentrations and high hco3 concentrations fig 7 suggest that addition of u and hco3 concentrations to the groundwater in these fans occurred most likely in the last 100 years or so particularly because most pre modern water has lower u and hco3 concentrations than recently recharged water fig 7 this is similar to the increase in total dissolved solids over the past 100 years for the eastern san joaquin valley hansen et al 2018 which further indicates that large scale irrigation of valley sediments has leached chemicals from vadose zone sediments this indicates that modern water from extensive irrigation over the past 100 years plays a large role in mobilizing u from the aquifer materials 4 4 change in u concentrations over time sixty eight wells within all the fans used in this study were sampled on multiple occasions from 1993 to 2018 fig 8 in order to assess whether irrigation water is mobilizing u by leaching hco3 from the soil wells with an increase in u concentration of more than 5 µg l are significantly correlated with increases in hco3 concentrations fig 9 this indicates that there is a relation between change in u concentrations and hco3 concentrations both positive and negative those wells that appear to have increases in hco3 but little or no increase in u may not have u available in the aquifer to be mobilized by the hco3 or alternatively hco3 addition occurs rapidly and it takes time to mobilize the u in the aquifer this latter hypothesis suggests that u concentrations could increase in these wells additional monitoring of wells with increasing hco3 concentrations may then be warranted to assess whether u will increase in the future decreases in u associated with decreases in hco3 may be related to precipitation or absorption of uranyl carbonate compounds in the aquifer materials but there is currently no data to determine if this is occurring alternatively decreasing concentrations could simply be caused by cessation of irrigation in these areas the largest increasing u concentrations are more than 100 µg l in many places and appear to be mostly concentrated in the central area of the basin where agricultural is the dominant land use the wells with decreasing u concentrations generally show changes less than 30 µg l and in some cases are near the edges of urban areas fig 8 the decreasing concentrations near urban areas may be caused by land use change from irrigated agriculture to urban land use the cessation of irrigation may decrease the dissolution of carbonate minerals in the aquifer that causes a subsequent decrease of hco3 which then decreases the u being complexed with hco3 and released to the aquifer however jurgens et al 2008 showed that hco3 and u was just as high beneath the urban areas as in the agricultural areas this could mean that decreasing u concentrations in the wells sampled in this study were fortuitously located near urban areas or that land use change did not have sufficient time to alter u concentrations when the jurgens et al 2008 study was completed a correlation between changes in u and nitrate nitrite no3 n no2 n would also be expected if addition of nitrate fertilizers was mobilizing u in the soil zone and subsequently recharging high nitrate and u water to the aquifer however there appears to be no correlation between u and no3 n no2 n changes in these same wells supplementary fig s4 this indicates that high no3 n concentrations are not the primary cause of increasing u concentrations in the eastern san joaquin aquifer system 5 mobilization of uranium the wells with the highest u occur at the edge of the redox boundary in mixed and anoxic redox water in the lower part of the san joaquin river and kings kaweah river fans supplementary fig s5 the chowchilla fresno river fans did not have any wells with mixed redox conditions and overall the water sampled in the chowchilla fresno river fan aquifer was oxic except one well with reduced water and concentrations of u were also low uranium may have accumulated in the sediment at the locations where the redox front begins providing higher concentrations of u in the sediment from which u was mobilized into groundwater although the concentrations of u in the sediments here are likely not high enough to be of economic value it is possible that the apparent accumulation of u at the distal ends of the fluvial fans could have been deposited by processes similar to uranium roll front deposits uranium roll front deposits occur in sandstone deposits and are produced by movement of oxic groundwater and subsequent mineral precipitation of those constituents upon interaction with reducing agents harshman 1974 abzalov 2012 uranium is leached from the original source rock before being precipitated into the host material in uranium roll front deposits enrichment in trace elements such as mo se and te have been found harshman 1974 min et al 2005 abzalov 2012 bullock and parnell 2017 in conventional roll front models se tends to concentrate at the redox front while mo concentrates in reduced unaltered sands harshman 1966 1974 rubin 1970 finch and davis 1985 spinks et al 2014 2016 to test the hypothesis of whether oxidation of uraninite may have contributed to the anomalously high uranium content of some samples saturation indices for all the samples with u 30 µg l using hypothetical electron activity pε ranging from 4 typically assigned to oxic samples to 3 5 typically assigned to methanogenic samples were used to determine what pε would be required for saturation for uraninite si between 0 5 and 0 5 the pε required ranged from 0 to 1 5 stumm and morgan 1996 give ranges for pε of reduction reactions stumm and morgan 1996 fig 8 14 a pε between 0 and 1 5 would be roughly consistent with fe reduction and reduction of no3 to nh3 groundwater samples were then divided into those that were too oxic to have that pε and those that were either reduced or could be mixtures of more reduced and oxic waters fig 10 in fig 10 the wells that could be considered possibly saturated with respect to uraninite squares are all inside the area of artesian conditions as defined by mendenhall et al 1916 and most of the samples that were undersaturated with respect to uraninite circles are outside of that area the squares include the 5 highest u concentrations 234 449 µg l and half of all samples with u 100 µg l in addition 80 of the squares are modern or mixed in age so this water has not had a long time to interact with the aquifer materials the water designated by the squares could thus represent mixtures of younger oxic water and older anoxic water with the oxygen from the young water oxidizing the uraninite and the high hco3 making it possible for the u to stay in solution rather than simply sorbing to the sediments the circles only have the one mechanism high hco3causing desorption and so don t have as high u concentrations these data can also be used to determine whether no3 n concentrations are important for releasing u to solution among the samples with u 30 µg l the squares have median no3 n of 2 5 mg l and median u of 138 µg l fig 10 the circles have median no3 n of 13 3 mg l and median u concentrations of 87 µg l the difference in no3 n between the samples designated with squares and circles is significant at p 0 000001 but the difference at these same sites in u is significant at only p 0 043 which agrees with the lack of correlation seen when no3 n and u for u samples 30 µg l are plotted supplementary fig s4 although it could be that there was denitrification or nitrate reduction or even nitrate oxidizing uraninite nitrate oxidation of uraninite is not necessary to explain the data the fact that the young water has oxygen and bicarbonate is sufficient 6 conclusions uranium sampled in groundwater in the eastern part of the san joaquin basin can reach concentrations of nearly 500 µg l in the mid to distal fan areas of the san joaquin river and kings kaweah fluvial fans mobilization of u concentrations at concentrations that high is relatively rare outside of uranium mining districts previous studies have not looked at the source of u to the individual alluvial fans that form the aquifer and have not analyzed competing mechanisms of bicarbonate nitrate and phosphate contributions to the anomalously high concentrations of u in the aquifer our analysis is consistent with our hypothesis that agricultural irrigation water and redox may control the overall distribution of elevated u concentrations but that specific other factors such as aquifer source materials and low phosphate concentrations also contribute to high u concentrations high no3 n concentrations do not appear to be correlated with high u concentrations in the fan deposits in contrast to what has been suggested by previous studies our analysis has shown that anomalously high u concentrations in the eastern san joaquin aquifer system require a geologic source of uranium in this case erosion of glacially eroded granitic rocks from high elevations in the sierra nevada depending on the u source of the individual fluvial fans maximum concentrations of u in each fan may be more than 300 µg l different than adjacent fans inter fan sediments which are only partially sourced from the high sierras have the lowest u concentrations mobilization occurs when young irrigation water applied to agricultural fields releases hco3 through chemical interactions in the vadose zone and this hco3 is carried into the groundwater where u that is sorbed on iron oxyhydroxide coatings sediment grains clay mineral edges or to organic matter is being leached by high hco3 recharge and complexed with hco3 ions nitrate concentrations in the irrigated agricultural water does not appear to enhance u dissolution but addition of phosphate may reduce the solubility of u by forming insoluble uranyl phosphate compounds at the toe of the fluvial fans mixed redox conditions may further enhance u dissolution to the point of uraninite saturation similar to the process that occurs in uranium roll front deposits where u is mined although this is currently a rare process in the san joaquin as more u is leached from alluvial deposits of the san joaquin valley it may become more prevalent in the future uranium concentrations have been shown to be increasing in the western united states this study has shown the complexity of predicting where high u concentrations will be found further study in other areas of the western united states and around the world would benefit from considering the mechanisms for mobilization and sequestration of u demonstrated here to understand u mobilization elsewhere declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank the personnel of the california water science center ca wsc who collected all the samples for this study quality assurance of the data by sylvia stork was invaluable for providing a clean reproduceable dataset we would like to thank bryant jurgens for providing age dating classifications and discussion of preliminary drafts of the manuscript we would also like to thank the well owners who allowed us to collect samples from their wells dina saleh ca wsc provided all the gis figures for this manuscript and her contributions are greatly appreciated reviews by usgs personnel anke mueller solger and craig brown and anonymous journal of hydrology reviewers greatly improved the clarity of this manuscript funding for this work was provided by the california state water resources control board groundwater ambient monitoring and assessment program usgs cooperative matching funds and the usgs national water quality program appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124009 appendix a supplementary data the following are the supplementary data to this article supplementary figure 1 supplementary figure 2 supplementary figure 3 supplementary figure 4 supplementary figure 5 supplementary data 1 
