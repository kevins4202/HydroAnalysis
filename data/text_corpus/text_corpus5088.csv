index,text
25440,a distributed model was proposed by coupling the index of sediment connectivity ic and the swat model ic swat sediment delivery ratio sdr was used to quantify the sediment deposition and the swat model was used to obtain the spatiotemporal distribution of soil p the proposed model was then applied to a mountainous watershed in three georges reservoir region china the results suggested that the ic swat model had better performance on simulation of sy and pp while the traditional swat model overestimated the area of hotspots of sy and pp by 6 7 and 5 2 returning cropland to forest and fertilizer reduction on the cropland with the highest soil p could remove 3 51 and 1 05 of pp indicating cropland with the highest soil p should be preferentially controlled the proposed model offers an approach for soil erosion and erosion type nps pollution simulation and provides strategies for management practices on grid scale keywords particulate p soil erosion watershed model non point source pollution sediment delivery ratio abbreviations sediment delivery ratio sdr sediment yield with deposition removed sy particulate p entering into the river pp pp model coupling the concept of ic and swat model ic swat data availability data will be made available on request software availability software name ic swat year first available 2022 software required saga gis for the ic calculation and python 3 9 for the ic swat model availability the ic swat model code can be assessed through the github repository https github com ostrichzkh ic swat cost free 1 introduction soil erosion and non point source nps pollution are two worldwide environmental problems which pose a great threat to water quality behera and panda 2006 koiter et al 2013 typically nps pollution is mainly carried into water bodies by runoff and eroded sediment and soil erosion is an important form and carrier of nps pollution in particulate state shojaeezadeh et al 2022 meinen and robinson 2021a in china 37 2 of the land suffers from soil erosion and leads to nps pollution in particulate state li et al 2017 wu and zhang 2006 indicated that phosphorus p pesticides and heavy metals in soil mainly exist in particulate state and are mainly transported into water bodies with eroded sediment sediment is the most important carrier of particulate p entering into the river pp since it buffers dissolved phosphate through particle adsorption dolph et al 2019 pan et al 2002 pp accounts for up to 80 of the total p during wet season and is further transformed into bioavailable p leading to eutrophication toxic algal concentration and oxygen depletion paerl et al 2011 wang et al 2013 controlling pp pollution is a great challenge which is influenced by factors such as climate geographical characteristics and agricultural practices han et al 2021 identifying key periods and hotspots with models is an effective measure for pp pollution control which mainly involves the simulation of sediment generation and transportation and p behavior in the watershed many physically based models have been developed for erosion and nps pollution prediction including areal nonpoint source watershed environment response simulation answers agricultural nonpoint source pollution agnps hydrological simulation program fortran hspf and soil and water assessment tool swat arnold et al 1998 beasley et al 1980 young et al 1989 although most models can well simulate nps pollution the deposition of sediment is ignored and leads to the wrong estimation of pp most models are semi distributed based on hydrological response unit hru which cannot consider the up downstream relationship and ignore the deposition of sediment and thus overestimate nps pp arnold et al 2010 swat model introduces the concept of p enrichment ratio for pp simulation radcliffe et al 2015 but still fails to identify the deposition of sediment which may lead to the overestimation of pp negewo and sarma 2021 showed that about 50 of the sediment was deposited or intercepted during transportation in an agricultural watershed therefore evaluating the on site soil erosion and its deposition is necessary for a more accurate pp simulation the revised universal soil loss equation rusle is commonly used for on site soil erosion renard et al 1991 however sediment would deposit in the transport pathways from the erosion sites to the river which results in the loss of most sediment during transport meinen and robinson 2021b nicoll and brierley 2017 oeurng et al 2011 zi et al 2016 sediment delivery ratio sdr is often used to represent the loss of sediment during transportation from on site soil erosion entering the river cristan et al 2019 a common method of estimating sdr is to construct the functional relationship between sdr and watershed area which makes the sdr fixed for the whole watershed de vente et al 2007 however sdr is a function of geographical characteristics and unevenly distributed in the watershed michalek et al 2021 which makes it necessary to calculate sdr on the grid scale to show its spatial heterogeneity therefore in this paper sdr is calculated on grid scale and refers to the ratio of sediment entering the river and on site sediment yield on each grid to date integrating connectivity theory with sediment model is a potential solution for describing the sources and behavior pathways of sediment ali et al 2018 wohl et al 2019 borselli et al 2008 and cavalli et al 2013 developed an index of sediment connectivity ic which takes all the links between a cell and other components of the watershed vigiak et al 2012 then proposed a function between ic and sdr indicating that ic could well quantify the sediment deposits in the transportation process therefore the concept of ic is a potential method to quantify the deposition of sediment however few studies have been performed by coupling the deposition of sediment with spatiotemporal distribution of soil p to study the erosion type phosphorus non point source pollution the objectives of this study were to 1 develop a new model for pp simulation by coupling ic and swat model 2 identify the key periods and hotspots of sy and pp 3 provide suggestions for management practices the proposed model was then tested in the daning river watershed china 2 material and methods 2 1 study area description the daning river watershed 30 49 to 31 42 n 107 56 to 108 54 e located in the north of the three gorges reservoir region tgrr china fig a 1 was selected as the study watershed it has a drainage area of approximately 4046 km2 and forest 61 75 cropland 23 99 and pasture 11 95 were the dominant land use types the annual average temperature is 18 4 c and the annual rainfall ranges from 1030 mm to 1950 mm affected by the wet and warm air in summer and cold and dry air in winter the annual rainfall is unevenly distributed and shows a clear seasonal trend rainfall is mainly concentrated in summer resulting in serious soil erosion due to a large amount of fertilizer the study watershed is in a state of surplus p and thus is prone to serious nps pollution during rainfall shen et al 2015 zhu et al 2021 soil erosion is serious in tgrr posing a threat of eutrophication to the tgrr tang et al 2018 the required data includes the digital elevation model dem the daily rainfall data the soil dataset the land use type the normalized difference vegetation index ndvi and farming measures the daily rainfall data of three stations in the watershed from 2000 to 2018 were collected from the meteorological bureau of wuxi county and china national meteorological administration the digital elevation model dem was acquired from the geospatial data cloud http www gscloud cn in order to obtain the soil dataset 38 soil sampling points were evenly distributed in the study area to collect topsoil and test its physical and chemical properties the land use map at resolution of 1 100 000 was obtained from the resources and environment science data center of the chinese sciences academy the monthly ndvi was collected from nasa s modis dataset https ladsweb modaps eosdis nasa gov all data were resampled at a 100m 100m resolution the monthly water quality and sediment data were obtained from the yangtze river basin water conservancy commission and the wuxi county environmental protection bureau for model calibration and validation farming measures such as crop planting type of fertilization and amount of fertilization were acquired by field research 2 2 development of the ic swat model 2 2 1 general framework the proposed model as shown in fig 1 integrates the concept of sediment connectivity soil erosion modeling and watershed modeling the distributed ic swat model was proposed for evaluating the spatiotemporal distribution of sy and pp aiming to identify the key periods and hotspots of sy and pp on grid scale firstly the on site erosion is estimated based on rusle and the sdr is calculated based on the ic to assess the deposition of sediment secondly the swat model is used to simulate the spatiotemporal distribution of soil p and assess the effects of rainfall and fertilizer application on soil p then parameters of the ic swat model are calibrated with a nondominated sorting genetic algorithm nsga iii finally key periods and hotspots of sy and pp are identified on grid scale the on site erosion ic and sdr were calculated in arcgis 10 6 the distribution of soil p was obtained with arcswat 2012 and the calibration was based on a self compiled python program several basic assumptions are made assumption 1 sdr is unevenly distributed within the watershed and affected by geographical characteristics including slope erosion area flow path and distance assumption 2 the variation of soil p is affected by rainfall and fertilizer application and could be simulated with the calibrated model 2 2 2 methodology 2 2 2 1 step 1 estimating on site erosion and its deposition the rusle model has been widely used to simulate soil erosion at watershed scale the rusle model is mostly applied on the monthly scale in this study benavidez et al 2018 borrelli et al 2020 while in this study sy was simulated on the monthly scale which brought difficulty for high precision simulation the equation is as follows 1 a r k l s c p where a is the monthly sediment yield t ha 1 month 1 r is the rainfall erosivity factor mj mm ha 1 h 1 month 1 k is the soil erodibility factor t ha mj 1 mm 1 l is the slope length factor s is the slope factor c is the vegetation cover factor and p is the erosion control practice factor the equations of rusle factors are listed in table a1 the conception of the index of sediment connectivity ic was proposed by borselli et al 2008 and modified by cavalli et al 2013 the ic index is calculated for each grid and referred to the probability that eroded sediments transporting from hillsides to the reach which fully considers the underlying factors topographic characteristics drainage area and transport path and is estimated by an upslope module d up and a downslope module d dn the ic index is calculated in the following forms 2 i c log 10 d up d dn the upslope module d up indicates the potential capacity for downward routing of eroded sediments on the upslope with consideration of the slope and area of erosion source d up is calculated as follows 3 d up w s a where w is average weighting factor of the upslope contributing area s is average slope gradient of the upslope contributing area m m and a is upslope contributing area the weight factor w represents the blocking effect of the underlying surface on sediment which varies from land use and soil properties and was represented by c factor in rusle models borselli et al 2008 the downslope module d dn indicates the possibility of sediment reaching the target reach or watershed outlet along the flow path which integrates the factors of slope gradient underlying surface characteristics flow path and distance d dn is calculated as follows 4 d dn i d i w i s i where d i is the length measured along the steepest downslope path of the i th grid m s i is the mean slope gradient of the i th grid m m and w i is the weight factor of the i th grid m m sediment delivery ratio sdr is defined as the ratio of gross on site erosion to the sediment entering the water bodies vigiak et al 2012 has shown that the relationship between the ic which qualitatively characterizes potential transport capacity and sdr which quantitatively characterizes loss in sediment transport can be expressed by a boltzmann type sigmoid curve 5 s d r s d r max 1 exp i c 0 i c k i c 1 where ic 0 and k ic are parameters to be calibrated sdr max is the maximum value of sdr taken as 0 9 calibratio of ic 0 and k ic is a multi objective optimization process with r2 and nse as objective functions 2 2 2 2 step 2 estimating soil p and particulate p soil information can be obtained by monitoring remote sensing and model simulation the model simulation is an ideal tool to simulate the spatiotemporal distribution of soil p due to its low cost and high precision the physically based swat model can simulate the migration and transformation of p in soil and assess the effect of rainfall and fertilizer application on soil p vadas and white 2010 swat s soil p routines see https swat tamu edu media 99192 swat2009 theory pdf for detail were originally developed for the epic model jones et al 1984 and include two organic p pools fresh and humus and three inorganic p pools solution active and stable the p module in swat model can predict long term and short term changes of soil p and assess the effect of rainfall and fertilizer application on soil p fig a 2 shows the specific process of phosphorus cycle here after inputting fertilizer application measures and soil parameters the amount of p adsorbed on sediment in topsoil conc sedp is calculated by 6 c o n c s e d p 100 min p a c t s u r f min p s t a s u r f org p h u m s u r f org p f r s h s u r f ρ b d e p t h s u r f where conc sedp is the amount of p adsorbed on sediment in topsoil g t min p a c t s u r f is the content of p in active pool in topsoil kg hm2 min p s t a s u r f is the content of p in stable pool in topsoil kg hm2 org p h u m s u r f is the content of p in humus pool in topsoil kg hm2 org p f r s h s u r f is the content of p in fresh pool in topsoil kg hm2 ρ b is the bulk density of soil t m3 and d e p t h s u r f is the depth of surface soil 10 mm all these variables are output by swat model based on eq 6 monthly soil p are calculated on hru scale and converted into grid file since the pp formula in swat directly takes the sediment yield calculated by modified universal soil loss equation musle without considering the transportation loss of sediment before entering the river which accounts for a large part of sediment yield rajbanshi and bhattacharya 2020 the concept of sdr is combined with rusle to modify the related formula in swat as follows 7 p p i 1 n 0 001 c o n c s e d p i s y i ε p i 8 ε p i e 2 0 2 ln s y t r i 9 s y i a i s d r i where p p is the amount of particulate p entering into the river with sediment kg hm2 sy i is the sediment yield with deposition removed of the i th grid calculated by eq 1 t ε p i is the enrichment ratio of p of the i th grid defined as the ratio of p transported with sediment to p in topsoil and sy i is the sediment yield of the i th grid t ha 1 month 1 the data required in this step includes the basic data required for swat modeling same as step 1 and fertilizer application data field investigation 2 2 2 3 step 3 ic swat calibration here two parameters ic 0 and k ic in eq 5 and the parameters related to soil phosphorus cycle in swat model are taken as the parameters to be calibrated the coefficient of determination r2 and the nash sutcliffe coefficient nse of sy and pp is set as the objective calibration function to calibrate the parameters the r2 and nse are calculated as follows 10 r 2 i 1 n o i o p i p i 1 n o i o 2 i 1 n p i p 2 2 11 n s e 1 i 1 n o i p i 2 i 1 n o i o 2 where o i is the ith observed value o is the average of the observed value p i is the ith simulated value p is the average of the simulated value and n is the number of observed values nondominated sorting genetic algorithm nsga iii is one of the most popular multi objective algorithms and has the advantages of fast running speed and good convergence of solution set deb and jain 2014 here nsga iii is applied to the multi objective optimization process of calibrating the parameters to realize the simultaneous calibration of sy and pp the r2 and nse of sy and pp are taken as the objective function of nsga iii the initial values of ic 0 and k ic are 1 and vary from 10 to 10 the calibration process is as follows 1 read the parameters related to soil phosphorus from swat files 2 run swat model to obtain the spatial distribution of soil phosphorus every month 3 calculate the on site erosion with eq 1 and the sdr with eq 5 4 estimate pp distribution with eq 7 eq 9 5 optimize the parameters on nsga iii and repeat the above steps until a satisfactory calibration result is obtained based on four constant factors and two variable factors sy for 204 months from 2002 to 2018 was calculated based on rusle as shown in fig a 3 the k l s and p factors were constant factors and the variation of r factor and c factor caused the monthly variation of sy based on the daily rainfall data the r factors of three meteorological stations in the basin from 2002 to 2018 are calculated and spatial distribution of r factor was obtained by kriging interpolation c factor also varied greatly in different months due to the withering of vegetation which was calculated according to the ndvi value obtained with landset 8 remote sensing image observed sy data of 2002 2009 and 2010 2014 was used for sy calibration and validation and observed pp data of 2002 2009 and 2010 2017 was used for pp calibration and validation respectively as shown in fig a 4 the r2 of sy and pp were both greater than 0 7 and the nse of sy and pp were both greater than 0 6 indicating good performance of the ic swat model 2 2 2 4 step 4 hotspots identification the ic swat model results were then used for identifying the key periods and hotspots of soil erosion and nps pollution evaluating the effect of management practices such as returning cropland to forest and fertilizer reduction and forecasting soil erosion and nps pollution the distributions of sy and pp from 2002 to 2018 each month were obtained with rusle sdr and soil p distribution thus the sy and pp loss in different land use and slope could be quantified and 10 spots with the highest sy and soil p were identified as hotspots for further management practices application 2 3 scenario analysis two strategies of pp removal were considered in this study fertilizer reduction was set as 30 as this application has slight impact on crop yield xing and zhu 2002 returning cropland to forest rcf was also considered to reduce soil erosion and p delivery wang et al 2019 therefore three fertilizer reduction scenarios and three rcf scenarios were established to discuss the effect of rcf and fertilizer reduction on pp removal fig a 5a fig a 5d based on the distributed simulation results the hot spots of soil p and sy can be identified and then fertilizer reduction and rcf will be implemented on the identified spots which will affect the pp and sy yield and then the impact of different scenarios on pp loss can be quantitatively evaluated 1 fertilizer reduction on the random cropland sc1 10 of cropland was randomly selected and fertilizer application was reduced by 30 on these cropland 2 rcf on the random cropland sc2 10 of cropland was randomly selected and rcf was implemented on these cropland 3 fertilizer reduction on the cropland with the highest soil p sc3 10 of cropland with the highest soil p content was identified and fertilizer application was reduced by 30 on these cropland 4 rcf on the cropland with the highest soil p sc4 10 of cropland with the highest soil p content was identified and rcf was implemented on these cropland 5 fertilizer reduction on the cropland with the highest sy sc5 10 of cropland with the highest sy content was identified and fertilizer application was reduced by 30 on these cropland 6 rcf on the cropland with the highest sy sc6 10 of cropland with the highest sy content was identified and rcf was implemented on these cropland 3 results and discussion 3 1 spatiotemporal distribution analysis with the calibrated ic swat model monthly sy and pp were obtained fig 2 shows the temporal sy and pp in different land uses and slopes which are recognized as two main geographical factors affecting sy guo et al 2021 from 2002 to 2018 an average of 1 84 106 t sy and 99 t pp entered into the river per year among different land uses the cropland suffered the most soil erosion while the forest and the pasture suffered less the sy load of forest cropland and pasture were 402 t km 2 yr 1 534 t km 2 yr 1 and 462 t km 2 yr 1 and contributed an average of 57 4 29 8 and 12 8 of total sy respectively fig 2a among different months the proportion of sy in different land uses remained unchanged but the proportion of cropland slightly decreases in spring and summer this may be due to the planting of crops in spring and summer which resulted in the increase of c factor of cropland and the corresponding reduction of sy fig 2e the sy loads of land with slope of 0 15 15 40 and 40 90 were 242 t km 2 yr 1 392 t km 2 yr 1 and 916 t km 2 yr 1 and contributed an average of 11 3 60 6 and 28 1 of total sy respectively fig 2f the proportion of sy in the land with slope 40 reaches a maximum of 37 31 in summer and a minimum of about 24 in spring and winter the proportion of sy with slope between 40 and 90 stayed stable throughout the year and the proportion of sy with slope 15 decreases from 17 63 in winter to 7 51 in summer this was because the heavy rainfall in summer would cause more on site erosion and the land with a higher slope tends to be higher in altitude which often has larger ic and sdr fig a 3c the distribution of pp also varied in different land uses and slopes although the sy in forest was much greater than that in cropland the contribution of cropland and forest to pp was almost equal due to the higher soil p in cropland caused by fertilizer application the pp load of forest cropland and pasture were 17 8 kg km 2 yr 1 48 9 kg km 2 yr 1 and 14 3 kg km 2 yr 1 and contributed an average of 45 1 47 9 and 7 0 of total sy respectively fig 2a among different months the proportion of pp in cropland increased from 37 9 in winter to 49 1 in summer fig 2g although the sy of cropland decreased in spring and summer fertilizer application was mainly concentrated in this period resulting in the highest soil p around the year the pp load of land with slope of 0 15 15 40 and 40 90 were 46 3 t km 2 yr 1 19 8 t km 2 yr 1 and 15 2 t km 2 yr 1 and contributed an average of 37 9 53 9 and 8 2 of total pp respectively fig 2h the land with a slope less than 40 contributed most of the pp for about 90 fig 2d and this proportion was even higher in spring and summer to quantify the impact of rainfall on the sy and pp fitting curves of rainfall with the sy and pp of different slope and land use types were drawn fig a 6 the r2 values were all greater than 0 7 and the correlation between rainfall and sy was higher than that between rainfall and pp table 1 shows the impact of the joint distribution of land use type and slope on sy and pp among cropland the cropland with slope of 0 40 contributed 221 1 t sy each year which took most part of cropland sy the forest with slope of 15 40 and 40 contributed 442 9 t and 259 6 t sy each year respectively accounting for more than half of the total sy in contrast due to higher soil p the cropland with slope 0 40 was the main source of pp and contributed 75 8 t pp each year although soil p of forest was lower sy of forest was higher so the forest with slope 15 was another major source of pp with 49 4 t pp contributed each year due to lower soil p and smaller area of pasture the sy and pp contributed by pasture of different slopes were all at a low level fig 3 a and fig 3b show spatial distributions of sy and pp respectively average of 17 years spring and summer were key periods of soil erosion and the hotspots were mainly located in the middle and northeast of the watershed while the soil erosion in the south and northwest of the watershed was relatively slight this was because these areas had lower s factor due to the gentle topographic relief and urban land was mainly concentrated in these areas making these areas not prone to soil erosion due to the close relationship between pp and sy sy was lower in autumn and winter and higher in spring and summer however the area of hotspots of pp was much smaller than that of sy because of the frequent fertilizer application in spring and summer soil p of cropland was higher than that of other areas as shown in table 1 cropland contributed about 50 of pp with only 20 of the area therefore the pp load of cropland was much higher and should be controlled at higher priority 3 2 scenario simulation results as shown in fig 4 a the pp removal effect of three fertilizer reduction scenarios ranked as sc3 sc5 sc1 about 1 04 t yr 1 05 0 61 t yr 0 62 and 0 37 t yr 0 38 of pp at the outlet of the watershed was removed respectively fertilizer application and soil erosion were two main factors affecting pp therefore the amount of pp removal of sc3 and sc5 increased in a near linear fashion and was higher than that of sc1 indicating random fertilizer reduction was not a wise choice with a comparison of sc3 and sc5 it is noted that fertilizer reduction in cropland with the highest soil p has a better effect on pp removal than in cropland with the highest sy indicating that priority should be given to the cropland with high soil p when implementing fertilizer reduction for example in order to achieve the goal of 0 3 t pp removal 21 2 7 1 and 12 8 fertilizer application needs to be reduced on 10 cropland identified in sc1 sc3 and sc5 as for the rcf practices about 3 48 t yr 3 51 2 03 t yr 2 05 and 1 54 t yr 1 55 pp was removed and the ranking was sc4 sc6 sc2 fig 4b similar to fertilizer reduction the amount of pp removal increased linearly with the percent of rcf in cropland with the highest soil p and sy it is worth noting that although rcf implemented on the cropland with the highest sy would remove more sediment the effect on pp removal in the cropland with the highest sy sc4 was not as good due to the relatively lower soil p this indicated that the cropland with the highest soil p sc6 was the management target so priority should be given to the cropland with the highest soil p rather than sy similarly rcf needs to be implemented on 5 8 2 2 and 4 1 of cropland identified in sc2 sc4 and sc6 in order to achieve the goal of 1 t pp removal additionally the sy removal effect of rc scenarios sc2 sc4 and sc6 was quantified in fig 4c the sy removal effect of fertilizer reduction scenarios was not significant with 26000 t yr 49000 t yr and 29000 t yr sy was removed in three scenarios indicating that rcf implemented on the cropland with highest sy has removal effect while rcf implemented on the cropland with highest soil p or on the random cropland similar removal effect to achieve the goal of 15000 t yr sy removal rcf needs to be implemented on 3 6 2 5 and 4 6 of cropland identified in sc2 sc4 and sc6 4 discussion and implications 4 1 advantages of the new method many attempts have simulated pp with watershed models by considering the p migration and transformation process i e wang et al 2021 estimated pp transporting in a rice paddy watershed with swat however these models always ignore the deposition of sediment which brings great errors to the simulation of pp and management practices naqvi et al 2019 and makes it hard to calibrate sy and pp simultaneously therefore this section evaluated the error to sy and pp simulation caused by the faultiness of the sediment module of the swat model for comparison sy and pp were simulated with the ic swat model and the swat model simultaneously fig 5 a fig 5d in the ic swat model the ic index was used to simulate deposition of sediment during transport and the swat model was used to simulate the spatiotemporal of soil phosphorus while in the swat model the deposition of sediment was ignored the ic swat model has well simulated sy and pp but the swat model had poor performance on sy simulation because it ignored the deposition of sediment while pp was well simulated the value of sy was underestimated because the soil p varied greatly during the year affected by the rainfall and fertilizer application the wet season and fertilization period overlapped within the study area leading to obvious underestimation of pp in the wet season and low performance of sediment simulation nse was only 0 16 due to the large difference from the observed value furthermore the identification of sy and pp hotspots with the ic swat model and the swat model were compared fig 5e and h the results of the ic swat model indicated that 18 6 of the area contribute 50 of sy while this ration was 25 3 with the swat model since the ic swat model has better performance on sy simulation the swat model was considered to overestimate the sy hotspots by 6 7 of the area similarly the ic swat model and the swat model indicated that 9 9 and 15 1 of the area contribute 50 of pp and the swat model overestimated the pp hotspots by 5 2 of the area which would lead to incorrect estimates of pp removal strategies according to the traditional definition fixed sdr is used for the whole watershed de vente et al 2007 li and xie 2022 however sdr is unevenly distributed and affected by various factors such as vegetation cover land use types soil type slope and so on michalek et al 2021 the introduction of ic and its boltzmann type sigmoid relationship with sdr makes the spatial distribution of sdr possible borselli et al 2008 vigiak et al 2012 in the study watershed sdr ranged from 0 to 0 8 and showed great spatial distribution as shown in fig a 3 larger sdr is found on the hillside so these areas are the hotspot of sy during the simulation period 81 3 of sediment 9 84 106 t deposits during the transportation process however the traditional model ignores the deposition in transportation process which may lead to wrong parameter estimation compared with the fixed sdr de vente et al 2007 li and xie 2022 the ic based method could take several influencing factors into consideration and obtain the spatial distribution of sdr spots with higher sdr are always the hotspots of soil erosion but the evenly distributed sdr would lead to an underestimation of sediment yield 4 2 management implications soil erosion and nps pollution are two worldwide problems and also inseparable phenomena as the sediment is specific nps pollution and also a carrier of pollutants wang et al 2013 wu et al 2016 thus erosion type nps pollution is defined in this study as a major concern especially for agricultural watersheds there are three major concerns involved in the erosion type nps pollution the on site erosion deposition of sediment and pollutant s fate in the study area since the rainfall and fertilizer application are both concentrated in spring and summer the key periods of sy and pp overlap fig 5a and b therefore the seasonal measures such as fertilizer reduction should be made a priority in these key periods located in the mountainous area hotspots of sy are widely distributed in the watershed however as the soil p of cropland is much higher than that of other lands hotspots of pp are mainly distributed in hilly cropland the traditional cognition was that rcf should be implemented on the cropland with the highest sediment yield karamage et al 2016 however rcf on these areas was not always the best scheme for pp removal according to the sc4 and sc6 fig 4f rcf should be preferentially implemented on the cropland with the highest soil p rather than sy implementation of rcf and fertilizer reduction on the cropland with the highest soil p could remove 3 48t 4 25 and 1 04t 1 05 of pp respectively but only 0 61t 0 62 and 2 03t 2 48 of pp could be removed on the cropland with the highest sy in addition to simulating the effect of management practices forecasting and early warning of soil erosion and nps pollution is another important issue which is mostly realized based on machine learning liu et al 2015 developed an early warning system for riverine nps loadings based on bayesian recursive regression tree however the forecasting and early warning based on machine learning algorithm require long term monitoring and accurately identify the hotspots of soil erosion and nps pollution is difficult the proposed distributed ic swat model is developed based on easily accessible data making accurate forecasting and early warning of sy and pp possible based on the latest rainfall forecast and remote sensing data the ic swat model can forecast the hotspots and key periods of sy and pp and can be fully applied to the management of soil erosion and nps pollution in other watersheds 5 conclusion in this study a distributed model for predicting erosion type pollution coupling the concept of index of connectivity and swat model ic swat was proposed the results indicated the following 1 the ic swat model has a better performance on simulation of sy and pp than swat model 2 sy was mainly contributed by forest while pp was equally contributed by forest and cropland due to the high soil p on the cropland 3 compared with the ic swat model the swat model overestimated the area of hotspots of sy and pp by 6 7 and 5 2 4 fertilizer reduction and rcf implemented on the cropland with highest soil p could remove 1 06 and 3 51 of pp every year while only 0 62 and 2 05 pp were removed with fertilizer reduction and rcf implemented on the cropland with highest sy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the national natural science foundation of china no 42277044 the fund for innovative research group of the national natural science foundation of china no 52221003 and the national key r d program of china grant no 2021yfd1700600 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105662 
25440,a distributed model was proposed by coupling the index of sediment connectivity ic and the swat model ic swat sediment delivery ratio sdr was used to quantify the sediment deposition and the swat model was used to obtain the spatiotemporal distribution of soil p the proposed model was then applied to a mountainous watershed in three georges reservoir region china the results suggested that the ic swat model had better performance on simulation of sy and pp while the traditional swat model overestimated the area of hotspots of sy and pp by 6 7 and 5 2 returning cropland to forest and fertilizer reduction on the cropland with the highest soil p could remove 3 51 and 1 05 of pp indicating cropland with the highest soil p should be preferentially controlled the proposed model offers an approach for soil erosion and erosion type nps pollution simulation and provides strategies for management practices on grid scale keywords particulate p soil erosion watershed model non point source pollution sediment delivery ratio abbreviations sediment delivery ratio sdr sediment yield with deposition removed sy particulate p entering into the river pp pp model coupling the concept of ic and swat model ic swat data availability data will be made available on request software availability software name ic swat year first available 2022 software required saga gis for the ic calculation and python 3 9 for the ic swat model availability the ic swat model code can be assessed through the github repository https github com ostrichzkh ic swat cost free 1 introduction soil erosion and non point source nps pollution are two worldwide environmental problems which pose a great threat to water quality behera and panda 2006 koiter et al 2013 typically nps pollution is mainly carried into water bodies by runoff and eroded sediment and soil erosion is an important form and carrier of nps pollution in particulate state shojaeezadeh et al 2022 meinen and robinson 2021a in china 37 2 of the land suffers from soil erosion and leads to nps pollution in particulate state li et al 2017 wu and zhang 2006 indicated that phosphorus p pesticides and heavy metals in soil mainly exist in particulate state and are mainly transported into water bodies with eroded sediment sediment is the most important carrier of particulate p entering into the river pp since it buffers dissolved phosphate through particle adsorption dolph et al 2019 pan et al 2002 pp accounts for up to 80 of the total p during wet season and is further transformed into bioavailable p leading to eutrophication toxic algal concentration and oxygen depletion paerl et al 2011 wang et al 2013 controlling pp pollution is a great challenge which is influenced by factors such as climate geographical characteristics and agricultural practices han et al 2021 identifying key periods and hotspots with models is an effective measure for pp pollution control which mainly involves the simulation of sediment generation and transportation and p behavior in the watershed many physically based models have been developed for erosion and nps pollution prediction including areal nonpoint source watershed environment response simulation answers agricultural nonpoint source pollution agnps hydrological simulation program fortran hspf and soil and water assessment tool swat arnold et al 1998 beasley et al 1980 young et al 1989 although most models can well simulate nps pollution the deposition of sediment is ignored and leads to the wrong estimation of pp most models are semi distributed based on hydrological response unit hru which cannot consider the up downstream relationship and ignore the deposition of sediment and thus overestimate nps pp arnold et al 2010 swat model introduces the concept of p enrichment ratio for pp simulation radcliffe et al 2015 but still fails to identify the deposition of sediment which may lead to the overestimation of pp negewo and sarma 2021 showed that about 50 of the sediment was deposited or intercepted during transportation in an agricultural watershed therefore evaluating the on site soil erosion and its deposition is necessary for a more accurate pp simulation the revised universal soil loss equation rusle is commonly used for on site soil erosion renard et al 1991 however sediment would deposit in the transport pathways from the erosion sites to the river which results in the loss of most sediment during transport meinen and robinson 2021b nicoll and brierley 2017 oeurng et al 2011 zi et al 2016 sediment delivery ratio sdr is often used to represent the loss of sediment during transportation from on site soil erosion entering the river cristan et al 2019 a common method of estimating sdr is to construct the functional relationship between sdr and watershed area which makes the sdr fixed for the whole watershed de vente et al 2007 however sdr is a function of geographical characteristics and unevenly distributed in the watershed michalek et al 2021 which makes it necessary to calculate sdr on the grid scale to show its spatial heterogeneity therefore in this paper sdr is calculated on grid scale and refers to the ratio of sediment entering the river and on site sediment yield on each grid to date integrating connectivity theory with sediment model is a potential solution for describing the sources and behavior pathways of sediment ali et al 2018 wohl et al 2019 borselli et al 2008 and cavalli et al 2013 developed an index of sediment connectivity ic which takes all the links between a cell and other components of the watershed vigiak et al 2012 then proposed a function between ic and sdr indicating that ic could well quantify the sediment deposits in the transportation process therefore the concept of ic is a potential method to quantify the deposition of sediment however few studies have been performed by coupling the deposition of sediment with spatiotemporal distribution of soil p to study the erosion type phosphorus non point source pollution the objectives of this study were to 1 develop a new model for pp simulation by coupling ic and swat model 2 identify the key periods and hotspots of sy and pp 3 provide suggestions for management practices the proposed model was then tested in the daning river watershed china 2 material and methods 2 1 study area description the daning river watershed 30 49 to 31 42 n 107 56 to 108 54 e located in the north of the three gorges reservoir region tgrr china fig a 1 was selected as the study watershed it has a drainage area of approximately 4046 km2 and forest 61 75 cropland 23 99 and pasture 11 95 were the dominant land use types the annual average temperature is 18 4 c and the annual rainfall ranges from 1030 mm to 1950 mm affected by the wet and warm air in summer and cold and dry air in winter the annual rainfall is unevenly distributed and shows a clear seasonal trend rainfall is mainly concentrated in summer resulting in serious soil erosion due to a large amount of fertilizer the study watershed is in a state of surplus p and thus is prone to serious nps pollution during rainfall shen et al 2015 zhu et al 2021 soil erosion is serious in tgrr posing a threat of eutrophication to the tgrr tang et al 2018 the required data includes the digital elevation model dem the daily rainfall data the soil dataset the land use type the normalized difference vegetation index ndvi and farming measures the daily rainfall data of three stations in the watershed from 2000 to 2018 were collected from the meteorological bureau of wuxi county and china national meteorological administration the digital elevation model dem was acquired from the geospatial data cloud http www gscloud cn in order to obtain the soil dataset 38 soil sampling points were evenly distributed in the study area to collect topsoil and test its physical and chemical properties the land use map at resolution of 1 100 000 was obtained from the resources and environment science data center of the chinese sciences academy the monthly ndvi was collected from nasa s modis dataset https ladsweb modaps eosdis nasa gov all data were resampled at a 100m 100m resolution the monthly water quality and sediment data were obtained from the yangtze river basin water conservancy commission and the wuxi county environmental protection bureau for model calibration and validation farming measures such as crop planting type of fertilization and amount of fertilization were acquired by field research 2 2 development of the ic swat model 2 2 1 general framework the proposed model as shown in fig 1 integrates the concept of sediment connectivity soil erosion modeling and watershed modeling the distributed ic swat model was proposed for evaluating the spatiotemporal distribution of sy and pp aiming to identify the key periods and hotspots of sy and pp on grid scale firstly the on site erosion is estimated based on rusle and the sdr is calculated based on the ic to assess the deposition of sediment secondly the swat model is used to simulate the spatiotemporal distribution of soil p and assess the effects of rainfall and fertilizer application on soil p then parameters of the ic swat model are calibrated with a nondominated sorting genetic algorithm nsga iii finally key periods and hotspots of sy and pp are identified on grid scale the on site erosion ic and sdr were calculated in arcgis 10 6 the distribution of soil p was obtained with arcswat 2012 and the calibration was based on a self compiled python program several basic assumptions are made assumption 1 sdr is unevenly distributed within the watershed and affected by geographical characteristics including slope erosion area flow path and distance assumption 2 the variation of soil p is affected by rainfall and fertilizer application and could be simulated with the calibrated model 2 2 2 methodology 2 2 2 1 step 1 estimating on site erosion and its deposition the rusle model has been widely used to simulate soil erosion at watershed scale the rusle model is mostly applied on the monthly scale in this study benavidez et al 2018 borrelli et al 2020 while in this study sy was simulated on the monthly scale which brought difficulty for high precision simulation the equation is as follows 1 a r k l s c p where a is the monthly sediment yield t ha 1 month 1 r is the rainfall erosivity factor mj mm ha 1 h 1 month 1 k is the soil erodibility factor t ha mj 1 mm 1 l is the slope length factor s is the slope factor c is the vegetation cover factor and p is the erosion control practice factor the equations of rusle factors are listed in table a1 the conception of the index of sediment connectivity ic was proposed by borselli et al 2008 and modified by cavalli et al 2013 the ic index is calculated for each grid and referred to the probability that eroded sediments transporting from hillsides to the reach which fully considers the underlying factors topographic characteristics drainage area and transport path and is estimated by an upslope module d up and a downslope module d dn the ic index is calculated in the following forms 2 i c log 10 d up d dn the upslope module d up indicates the potential capacity for downward routing of eroded sediments on the upslope with consideration of the slope and area of erosion source d up is calculated as follows 3 d up w s a where w is average weighting factor of the upslope contributing area s is average slope gradient of the upslope contributing area m m and a is upslope contributing area the weight factor w represents the blocking effect of the underlying surface on sediment which varies from land use and soil properties and was represented by c factor in rusle models borselli et al 2008 the downslope module d dn indicates the possibility of sediment reaching the target reach or watershed outlet along the flow path which integrates the factors of slope gradient underlying surface characteristics flow path and distance d dn is calculated as follows 4 d dn i d i w i s i where d i is the length measured along the steepest downslope path of the i th grid m s i is the mean slope gradient of the i th grid m m and w i is the weight factor of the i th grid m m sediment delivery ratio sdr is defined as the ratio of gross on site erosion to the sediment entering the water bodies vigiak et al 2012 has shown that the relationship between the ic which qualitatively characterizes potential transport capacity and sdr which quantitatively characterizes loss in sediment transport can be expressed by a boltzmann type sigmoid curve 5 s d r s d r max 1 exp i c 0 i c k i c 1 where ic 0 and k ic are parameters to be calibrated sdr max is the maximum value of sdr taken as 0 9 calibratio of ic 0 and k ic is a multi objective optimization process with r2 and nse as objective functions 2 2 2 2 step 2 estimating soil p and particulate p soil information can be obtained by monitoring remote sensing and model simulation the model simulation is an ideal tool to simulate the spatiotemporal distribution of soil p due to its low cost and high precision the physically based swat model can simulate the migration and transformation of p in soil and assess the effect of rainfall and fertilizer application on soil p vadas and white 2010 swat s soil p routines see https swat tamu edu media 99192 swat2009 theory pdf for detail were originally developed for the epic model jones et al 1984 and include two organic p pools fresh and humus and three inorganic p pools solution active and stable the p module in swat model can predict long term and short term changes of soil p and assess the effect of rainfall and fertilizer application on soil p fig a 2 shows the specific process of phosphorus cycle here after inputting fertilizer application measures and soil parameters the amount of p adsorbed on sediment in topsoil conc sedp is calculated by 6 c o n c s e d p 100 min p a c t s u r f min p s t a s u r f org p h u m s u r f org p f r s h s u r f ρ b d e p t h s u r f where conc sedp is the amount of p adsorbed on sediment in topsoil g t min p a c t s u r f is the content of p in active pool in topsoil kg hm2 min p s t a s u r f is the content of p in stable pool in topsoil kg hm2 org p h u m s u r f is the content of p in humus pool in topsoil kg hm2 org p f r s h s u r f is the content of p in fresh pool in topsoil kg hm2 ρ b is the bulk density of soil t m3 and d e p t h s u r f is the depth of surface soil 10 mm all these variables are output by swat model based on eq 6 monthly soil p are calculated on hru scale and converted into grid file since the pp formula in swat directly takes the sediment yield calculated by modified universal soil loss equation musle without considering the transportation loss of sediment before entering the river which accounts for a large part of sediment yield rajbanshi and bhattacharya 2020 the concept of sdr is combined with rusle to modify the related formula in swat as follows 7 p p i 1 n 0 001 c o n c s e d p i s y i ε p i 8 ε p i e 2 0 2 ln s y t r i 9 s y i a i s d r i where p p is the amount of particulate p entering into the river with sediment kg hm2 sy i is the sediment yield with deposition removed of the i th grid calculated by eq 1 t ε p i is the enrichment ratio of p of the i th grid defined as the ratio of p transported with sediment to p in topsoil and sy i is the sediment yield of the i th grid t ha 1 month 1 the data required in this step includes the basic data required for swat modeling same as step 1 and fertilizer application data field investigation 2 2 2 3 step 3 ic swat calibration here two parameters ic 0 and k ic in eq 5 and the parameters related to soil phosphorus cycle in swat model are taken as the parameters to be calibrated the coefficient of determination r2 and the nash sutcliffe coefficient nse of sy and pp is set as the objective calibration function to calibrate the parameters the r2 and nse are calculated as follows 10 r 2 i 1 n o i o p i p i 1 n o i o 2 i 1 n p i p 2 2 11 n s e 1 i 1 n o i p i 2 i 1 n o i o 2 where o i is the ith observed value o is the average of the observed value p i is the ith simulated value p is the average of the simulated value and n is the number of observed values nondominated sorting genetic algorithm nsga iii is one of the most popular multi objective algorithms and has the advantages of fast running speed and good convergence of solution set deb and jain 2014 here nsga iii is applied to the multi objective optimization process of calibrating the parameters to realize the simultaneous calibration of sy and pp the r2 and nse of sy and pp are taken as the objective function of nsga iii the initial values of ic 0 and k ic are 1 and vary from 10 to 10 the calibration process is as follows 1 read the parameters related to soil phosphorus from swat files 2 run swat model to obtain the spatial distribution of soil phosphorus every month 3 calculate the on site erosion with eq 1 and the sdr with eq 5 4 estimate pp distribution with eq 7 eq 9 5 optimize the parameters on nsga iii and repeat the above steps until a satisfactory calibration result is obtained based on four constant factors and two variable factors sy for 204 months from 2002 to 2018 was calculated based on rusle as shown in fig a 3 the k l s and p factors were constant factors and the variation of r factor and c factor caused the monthly variation of sy based on the daily rainfall data the r factors of three meteorological stations in the basin from 2002 to 2018 are calculated and spatial distribution of r factor was obtained by kriging interpolation c factor also varied greatly in different months due to the withering of vegetation which was calculated according to the ndvi value obtained with landset 8 remote sensing image observed sy data of 2002 2009 and 2010 2014 was used for sy calibration and validation and observed pp data of 2002 2009 and 2010 2017 was used for pp calibration and validation respectively as shown in fig a 4 the r2 of sy and pp were both greater than 0 7 and the nse of sy and pp were both greater than 0 6 indicating good performance of the ic swat model 2 2 2 4 step 4 hotspots identification the ic swat model results were then used for identifying the key periods and hotspots of soil erosion and nps pollution evaluating the effect of management practices such as returning cropland to forest and fertilizer reduction and forecasting soil erosion and nps pollution the distributions of sy and pp from 2002 to 2018 each month were obtained with rusle sdr and soil p distribution thus the sy and pp loss in different land use and slope could be quantified and 10 spots with the highest sy and soil p were identified as hotspots for further management practices application 2 3 scenario analysis two strategies of pp removal were considered in this study fertilizer reduction was set as 30 as this application has slight impact on crop yield xing and zhu 2002 returning cropland to forest rcf was also considered to reduce soil erosion and p delivery wang et al 2019 therefore three fertilizer reduction scenarios and three rcf scenarios were established to discuss the effect of rcf and fertilizer reduction on pp removal fig a 5a fig a 5d based on the distributed simulation results the hot spots of soil p and sy can be identified and then fertilizer reduction and rcf will be implemented on the identified spots which will affect the pp and sy yield and then the impact of different scenarios on pp loss can be quantitatively evaluated 1 fertilizer reduction on the random cropland sc1 10 of cropland was randomly selected and fertilizer application was reduced by 30 on these cropland 2 rcf on the random cropland sc2 10 of cropland was randomly selected and rcf was implemented on these cropland 3 fertilizer reduction on the cropland with the highest soil p sc3 10 of cropland with the highest soil p content was identified and fertilizer application was reduced by 30 on these cropland 4 rcf on the cropland with the highest soil p sc4 10 of cropland with the highest soil p content was identified and rcf was implemented on these cropland 5 fertilizer reduction on the cropland with the highest sy sc5 10 of cropland with the highest sy content was identified and fertilizer application was reduced by 30 on these cropland 6 rcf on the cropland with the highest sy sc6 10 of cropland with the highest sy content was identified and rcf was implemented on these cropland 3 results and discussion 3 1 spatiotemporal distribution analysis with the calibrated ic swat model monthly sy and pp were obtained fig 2 shows the temporal sy and pp in different land uses and slopes which are recognized as two main geographical factors affecting sy guo et al 2021 from 2002 to 2018 an average of 1 84 106 t sy and 99 t pp entered into the river per year among different land uses the cropland suffered the most soil erosion while the forest and the pasture suffered less the sy load of forest cropland and pasture were 402 t km 2 yr 1 534 t km 2 yr 1 and 462 t km 2 yr 1 and contributed an average of 57 4 29 8 and 12 8 of total sy respectively fig 2a among different months the proportion of sy in different land uses remained unchanged but the proportion of cropland slightly decreases in spring and summer this may be due to the planting of crops in spring and summer which resulted in the increase of c factor of cropland and the corresponding reduction of sy fig 2e the sy loads of land with slope of 0 15 15 40 and 40 90 were 242 t km 2 yr 1 392 t km 2 yr 1 and 916 t km 2 yr 1 and contributed an average of 11 3 60 6 and 28 1 of total sy respectively fig 2f the proportion of sy in the land with slope 40 reaches a maximum of 37 31 in summer and a minimum of about 24 in spring and winter the proportion of sy with slope between 40 and 90 stayed stable throughout the year and the proportion of sy with slope 15 decreases from 17 63 in winter to 7 51 in summer this was because the heavy rainfall in summer would cause more on site erosion and the land with a higher slope tends to be higher in altitude which often has larger ic and sdr fig a 3c the distribution of pp also varied in different land uses and slopes although the sy in forest was much greater than that in cropland the contribution of cropland and forest to pp was almost equal due to the higher soil p in cropland caused by fertilizer application the pp load of forest cropland and pasture were 17 8 kg km 2 yr 1 48 9 kg km 2 yr 1 and 14 3 kg km 2 yr 1 and contributed an average of 45 1 47 9 and 7 0 of total sy respectively fig 2a among different months the proportion of pp in cropland increased from 37 9 in winter to 49 1 in summer fig 2g although the sy of cropland decreased in spring and summer fertilizer application was mainly concentrated in this period resulting in the highest soil p around the year the pp load of land with slope of 0 15 15 40 and 40 90 were 46 3 t km 2 yr 1 19 8 t km 2 yr 1 and 15 2 t km 2 yr 1 and contributed an average of 37 9 53 9 and 8 2 of total pp respectively fig 2h the land with a slope less than 40 contributed most of the pp for about 90 fig 2d and this proportion was even higher in spring and summer to quantify the impact of rainfall on the sy and pp fitting curves of rainfall with the sy and pp of different slope and land use types were drawn fig a 6 the r2 values were all greater than 0 7 and the correlation between rainfall and sy was higher than that between rainfall and pp table 1 shows the impact of the joint distribution of land use type and slope on sy and pp among cropland the cropland with slope of 0 40 contributed 221 1 t sy each year which took most part of cropland sy the forest with slope of 15 40 and 40 contributed 442 9 t and 259 6 t sy each year respectively accounting for more than half of the total sy in contrast due to higher soil p the cropland with slope 0 40 was the main source of pp and contributed 75 8 t pp each year although soil p of forest was lower sy of forest was higher so the forest with slope 15 was another major source of pp with 49 4 t pp contributed each year due to lower soil p and smaller area of pasture the sy and pp contributed by pasture of different slopes were all at a low level fig 3 a and fig 3b show spatial distributions of sy and pp respectively average of 17 years spring and summer were key periods of soil erosion and the hotspots were mainly located in the middle and northeast of the watershed while the soil erosion in the south and northwest of the watershed was relatively slight this was because these areas had lower s factor due to the gentle topographic relief and urban land was mainly concentrated in these areas making these areas not prone to soil erosion due to the close relationship between pp and sy sy was lower in autumn and winter and higher in spring and summer however the area of hotspots of pp was much smaller than that of sy because of the frequent fertilizer application in spring and summer soil p of cropland was higher than that of other areas as shown in table 1 cropland contributed about 50 of pp with only 20 of the area therefore the pp load of cropland was much higher and should be controlled at higher priority 3 2 scenario simulation results as shown in fig 4 a the pp removal effect of three fertilizer reduction scenarios ranked as sc3 sc5 sc1 about 1 04 t yr 1 05 0 61 t yr 0 62 and 0 37 t yr 0 38 of pp at the outlet of the watershed was removed respectively fertilizer application and soil erosion were two main factors affecting pp therefore the amount of pp removal of sc3 and sc5 increased in a near linear fashion and was higher than that of sc1 indicating random fertilizer reduction was not a wise choice with a comparison of sc3 and sc5 it is noted that fertilizer reduction in cropland with the highest soil p has a better effect on pp removal than in cropland with the highest sy indicating that priority should be given to the cropland with high soil p when implementing fertilizer reduction for example in order to achieve the goal of 0 3 t pp removal 21 2 7 1 and 12 8 fertilizer application needs to be reduced on 10 cropland identified in sc1 sc3 and sc5 as for the rcf practices about 3 48 t yr 3 51 2 03 t yr 2 05 and 1 54 t yr 1 55 pp was removed and the ranking was sc4 sc6 sc2 fig 4b similar to fertilizer reduction the amount of pp removal increased linearly with the percent of rcf in cropland with the highest soil p and sy it is worth noting that although rcf implemented on the cropland with the highest sy would remove more sediment the effect on pp removal in the cropland with the highest sy sc4 was not as good due to the relatively lower soil p this indicated that the cropland with the highest soil p sc6 was the management target so priority should be given to the cropland with the highest soil p rather than sy similarly rcf needs to be implemented on 5 8 2 2 and 4 1 of cropland identified in sc2 sc4 and sc6 in order to achieve the goal of 1 t pp removal additionally the sy removal effect of rc scenarios sc2 sc4 and sc6 was quantified in fig 4c the sy removal effect of fertilizer reduction scenarios was not significant with 26000 t yr 49000 t yr and 29000 t yr sy was removed in three scenarios indicating that rcf implemented on the cropland with highest sy has removal effect while rcf implemented on the cropland with highest soil p or on the random cropland similar removal effect to achieve the goal of 15000 t yr sy removal rcf needs to be implemented on 3 6 2 5 and 4 6 of cropland identified in sc2 sc4 and sc6 4 discussion and implications 4 1 advantages of the new method many attempts have simulated pp with watershed models by considering the p migration and transformation process i e wang et al 2021 estimated pp transporting in a rice paddy watershed with swat however these models always ignore the deposition of sediment which brings great errors to the simulation of pp and management practices naqvi et al 2019 and makes it hard to calibrate sy and pp simultaneously therefore this section evaluated the error to sy and pp simulation caused by the faultiness of the sediment module of the swat model for comparison sy and pp were simulated with the ic swat model and the swat model simultaneously fig 5 a fig 5d in the ic swat model the ic index was used to simulate deposition of sediment during transport and the swat model was used to simulate the spatiotemporal of soil phosphorus while in the swat model the deposition of sediment was ignored the ic swat model has well simulated sy and pp but the swat model had poor performance on sy simulation because it ignored the deposition of sediment while pp was well simulated the value of sy was underestimated because the soil p varied greatly during the year affected by the rainfall and fertilizer application the wet season and fertilization period overlapped within the study area leading to obvious underestimation of pp in the wet season and low performance of sediment simulation nse was only 0 16 due to the large difference from the observed value furthermore the identification of sy and pp hotspots with the ic swat model and the swat model were compared fig 5e and h the results of the ic swat model indicated that 18 6 of the area contribute 50 of sy while this ration was 25 3 with the swat model since the ic swat model has better performance on sy simulation the swat model was considered to overestimate the sy hotspots by 6 7 of the area similarly the ic swat model and the swat model indicated that 9 9 and 15 1 of the area contribute 50 of pp and the swat model overestimated the pp hotspots by 5 2 of the area which would lead to incorrect estimates of pp removal strategies according to the traditional definition fixed sdr is used for the whole watershed de vente et al 2007 li and xie 2022 however sdr is unevenly distributed and affected by various factors such as vegetation cover land use types soil type slope and so on michalek et al 2021 the introduction of ic and its boltzmann type sigmoid relationship with sdr makes the spatial distribution of sdr possible borselli et al 2008 vigiak et al 2012 in the study watershed sdr ranged from 0 to 0 8 and showed great spatial distribution as shown in fig a 3 larger sdr is found on the hillside so these areas are the hotspot of sy during the simulation period 81 3 of sediment 9 84 106 t deposits during the transportation process however the traditional model ignores the deposition in transportation process which may lead to wrong parameter estimation compared with the fixed sdr de vente et al 2007 li and xie 2022 the ic based method could take several influencing factors into consideration and obtain the spatial distribution of sdr spots with higher sdr are always the hotspots of soil erosion but the evenly distributed sdr would lead to an underestimation of sediment yield 4 2 management implications soil erosion and nps pollution are two worldwide problems and also inseparable phenomena as the sediment is specific nps pollution and also a carrier of pollutants wang et al 2013 wu et al 2016 thus erosion type nps pollution is defined in this study as a major concern especially for agricultural watersheds there are three major concerns involved in the erosion type nps pollution the on site erosion deposition of sediment and pollutant s fate in the study area since the rainfall and fertilizer application are both concentrated in spring and summer the key periods of sy and pp overlap fig 5a and b therefore the seasonal measures such as fertilizer reduction should be made a priority in these key periods located in the mountainous area hotspots of sy are widely distributed in the watershed however as the soil p of cropland is much higher than that of other lands hotspots of pp are mainly distributed in hilly cropland the traditional cognition was that rcf should be implemented on the cropland with the highest sediment yield karamage et al 2016 however rcf on these areas was not always the best scheme for pp removal according to the sc4 and sc6 fig 4f rcf should be preferentially implemented on the cropland with the highest soil p rather than sy implementation of rcf and fertilizer reduction on the cropland with the highest soil p could remove 3 48t 4 25 and 1 04t 1 05 of pp respectively but only 0 61t 0 62 and 2 03t 2 48 of pp could be removed on the cropland with the highest sy in addition to simulating the effect of management practices forecasting and early warning of soil erosion and nps pollution is another important issue which is mostly realized based on machine learning liu et al 2015 developed an early warning system for riverine nps loadings based on bayesian recursive regression tree however the forecasting and early warning based on machine learning algorithm require long term monitoring and accurately identify the hotspots of soil erosion and nps pollution is difficult the proposed distributed ic swat model is developed based on easily accessible data making accurate forecasting and early warning of sy and pp possible based on the latest rainfall forecast and remote sensing data the ic swat model can forecast the hotspots and key periods of sy and pp and can be fully applied to the management of soil erosion and nps pollution in other watersheds 5 conclusion in this study a distributed model for predicting erosion type pollution coupling the concept of index of connectivity and swat model ic swat was proposed the results indicated the following 1 the ic swat model has a better performance on simulation of sy and pp than swat model 2 sy was mainly contributed by forest while pp was equally contributed by forest and cropland due to the high soil p on the cropland 3 compared with the ic swat model the swat model overestimated the area of hotspots of sy and pp by 6 7 and 5 2 4 fertilizer reduction and rcf implemented on the cropland with highest soil p could remove 1 06 and 3 51 of pp every year while only 0 62 and 2 05 pp were removed with fertilizer reduction and rcf implemented on the cropland with highest sy declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was funded by the national natural science foundation of china no 42277044 the fund for innovative research group of the national natural science foundation of china no 52221003 and the national key r d program of china grant no 2021yfd1700600 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105662 
25441,crop growth models can be useful tools to evaluate potential scenarios yet the limited field data is an obstacle for providing significant insights at the local level this certainly applies to several regions in africa where crop models built regional scenarios based on low resolution field data leading to unsupported agricultural interventions on smallholders systems this review provides a synthesis analysis of crop modeling efforts in africa using agricultural production systems simulator apsim studies as a case study this research aims to highlight the value of standardized protocols to collect store and deploy field data and highlights the critical issue of limited data accessibility of published manuscripts and unavailability of a data sharing platform investment in local level data collection and data sharing platforms is critical to guarantee the advancement of science and to provide reliable assessments to address complex challenges of food nutrition and climate security in africa graphical abstract image 1 keywords genetic parameters field data model performance model reliability apsim africa data availability data will be made available on request 1 introduction food security remains an elusive target for africa fao 2019 although progress has been achieved with the support of multiple disciplines and funding agencies significant trends of increasing hunger persist within the continent with high reliance on the local level to supply food for their community frelat et al 2016 previous reviews investigated the impact of agricultural strategies and innovations on food availability and stability for improving outcomes in human nutrition and health phalkey et al 2015 however previous studies documented the potential implications of the lack of local level data and data aggregation when developing estimates at a regional scale hoffmann et al 2016 this problem is not only linked to one crop growth model but to a broader issue previously identified in the literature for example for wofost world food studies model de wit et al 2019 reported that minor changes in parameters produced large variations of outcomes therefore the lack of high resolution field data could lead to the implementation of default coefficients derived from original version of the model adjusted to different cropping systems and environments producing irrelevant synthetic data in this context crop growth models arise as useful tools to represent key components of farming systems and to evaluate the impact of potential interventions e g productivity improvement or climate change mitigation but only when data is available to properly calibrate and validate the model at a local level the agricultural production systems simulator apsim model is used worldwide by thousands of researchers holzworth et al 2018 due to its robust mechanistic approach to simulate biophysical processes within farming systems holzworth et al 2014 2015 keating et al 2003 since its inception in 1990 mccown et al 1995 1996 several modules were added to the platform expanding the number of crops and soil environmental processes to be explored keating et al 2003 globally and within the african continent apsim has been employed to assess diverse topics such as climate change and adaptation tidjani and akponikpe 2012 tachie obeng et al 2013 chauhan et al 2015 adam et al 2020 food security policy assessment nezomba et al 2018 chimonyo et al 2020 farming strategies design akponikpè et al 2010 rurinda et al 2015 beah et al 2021 and resource use efficiency akinseye et al 2020a chimonyo et al 2016 ncube et al 2009 among other features holzworth et al 2015 although agriculture system model applications have expanded less emphasis has been given to delineating quality standards chisanga et al 2020 porter et al 2014 in order to provide reliable outcomes crop growth models should include data collection conscious calibration and extensive validation baroni and tarantola 2014 recently harou et al 2021 discussed knowledge informed probabilistic approaches in crop models to provide uncertainties in so called data poor environments without detailed ground data to build good quality calibrations the outputs of the model could be as reliable as the assumptions taken saltelli et al 2020 thus our estimations and assessments of food security and response to changing climate and management practices are as reliable as the potential proximity between the outcomes generated with the reality at the local level in this review a synthesis analysis was performed using the apsim cropping system model as a case study with the goal of describing past and current research efforts discussing limitations challenges and future research investments for relevant food security assessments in africa the main objectives were to i summarize the current state of knowledge of modeling exercises using apsim within the african continent ii explore the variability of crop genetic parameters iii synthesize the model performance for yield biomass leaf area and phenology for the studied crops and iv evaluate the model sensitivity of the most variable genetic parameters and the potential impact on food security assessments of the assumptions based on no local scale data 2 materials and methods 2 1 data collection the literature search was limited to apsim simulation studies conducted within the african continent for this purpose two data sources were included in the analysis i scopus search engine www scopus com and ii apsim web page fig 1 i the search was conducted from november 21 2021 to december 31 2021 on november 22 2021 the references in bibtex format were exported from scopus and the list of available papers from the apsim webpage was retrieved papers published after november 21 2021 were not included in this database the screening and selection process was done after november 22 2021 until december 31 2021 scopus is a well known abstract and citation database that includes nearly 37000 titles from approximately 12000 publishers the first step was establishing keywords to use in the scopus search engine selecting apsim combined with i africa ii african and iii each country in the african continent as individual searches the next step was the manual screening of titles and abstracts via the r package revtools westgate 2019 this package facilitates the article screening process via an enhanced display of the titles and abstract and an interactive menu for article selection or exclusion lastly a list of peer review articles using the apsim model in africa was obtained from the publication metrics section of the apsim website https www apsim info this list was used as an independent search to check and complement the scopus search the handling of this data source involved manual checking of the titles listed and selecting only the papers related to studies in africa after merging the two data sources duplicated entries were discarded the abstract and title screen fig 1 ii for both data sources did not restrict inclusion of crops in this step the frequency of each crop was determined and only crops with at least three publications were retained thereby the list of studied crops was defined as i maize zea mays l ii sorghum sorghum bicolor iii sugarcane saccharum officinarum iv pearl millet pennisetum glaucum v wheat triticum aestivum vi soybean glycine max and vii cowpea vigna unguiculata following initial screening a full text screening was performed fig 1 iii based on the presence of either the crop cultivar genetic parameters used or a validation of the model comparing observed versus predicted values for yield biomass leaf area index lai days to anthesis or days to maturity this process resulted in the final number of publications included in the final database fig 1 iv lastly the manual extraction of the data was performed using the webplotdigitizer software https automeris io webplotdigitizer this online tool allows the user to upload jpg files define the extent and range of the axis and finally extract the values of each point manually the collected data including the genetic parameters and the data extracted for the validation assessment and the references of the selected publications are available at 10 6084 m9 figshare 19726009 2 2 genetic parameters description the genetic parameters were retrieved when available within the publication if the parameters employed were not specified within the publication yet the source was clearly stated these parameters were retrieved as well the cultivar or genetic parameters variability was explored for each crop using standard deviation frequency of occurrence minimum maximum and range 2 3 crops simulation performance the performance of the simulations was assessed using the collected simulated observed data pairs each crop was evaluated independently including different environments and management practices when available the retrieved variables were i yield ii biomass iii lai iv days to anthesis and v days to maturity these variables were selected based on the availability of data within each crop the agreement between simulated and observed values was evaluated by estimating a variety of prediction performance metrics a k a scoring rules that account for distinct prediction quality aspects thereby the following performance metrics were used i the mean bias error mbe variable units as the average difference of simulated with respect to observed values for which positive values indicate a systematic under prediction and negative values indicate over prediction ii the root mean square error rmse variable units as an error metric based on squared errors that heavily penalizes large residuals iii the normalized or relative rmse rrmse as a metric of percentage deviation from the observed mean iv the kling gupta efficiency kge normalized with near one ideal kling et al 2012 as a refined model efficiency nash and sutcliffe 1970 krause et al 2005 v the concordance correlation coefficient ccc as a normalized metric that accounts for general agreement by weighting the pearson correlation coefficient r by an index of accuracy lin 1989 and vi the coefficient of determination r2 as a goodness of fit index in addition a bivariate linear regression standardized major axis was used to determine the general relationship pattern between simulated and observed values and to decompose the mean squared error into lack of accuracy percentage lack of accuracy pla and lack of precision percentage lack of precision plp components suggested by correndo et al 2021 specific formulas are provided in supplementary table s1 the performance analysis was conducted using the metrica r package correndo et al 2022 further model performance analysis was conducted for maize as it was the crop with the most observations the simulations performance assessment was split into two contrasting classes based on genetic parameters source i no calibration publications that used genetic parameters from previous studies conducted outside africa and did not report the phenology days to anthesis and days to maturity validation within the study ii detailed calibration publications that calibrated the parameters used in the study or used one from a previous study within the same region and reported the phenology days to anthesis and days to maturity validation within the study 2 4 parameters sensitivity the effect of the genetic parameters on the model outcomes such as phenology and yield components was tested using maize as a case study for this purpose apsim classic 7 10 model was employed to perform the simulations three articles guan et al 2015 seyoum et al 2018 and hoffmann et al 2020 which encompassed contrasting regions senegal ethiopia and south africa respectively were selected to extract the site coordinates and the management was representative of locations for our simulations weather data from 1981 to 2021 was retrieved from nasapower sparks 2018 and chirps funk et al 2015 and soil parameters were collected from soil grids data base hengl et al 2015 tested cultivars were built using apsim maize standard medium duration cultivar parameters as a base modifying only one parameter at a time the three parameters which showed the greatest variability were chosen for this analysis i time from emergence to floral initiation ii time from flowering to maturity and iii maximum grain number coefficient for each of these parameters the maximum and the minimum were tested and compared to the medium duration standard cultivar as mentioned the management was defined based on the local management described in each paper the crop management among regions differed in planting dates senegal 15 jul 01 aug and 15 aug south africa 01 nov 15 nov and 15 dec ethiopia 15 may 15 jun and 15 jul whereas the rest of the management options were maintained constant plant density 6 plants m2 row spacing 72 cm sowing depth 30 mm n fertilization 150 kg ha urea 3 results 3 1 dataset outline the dataset encompassed 71 publications 1474 yield observations across 24 countries within africa including seven major crops supplementary table s2 of all the papers in the database 53 were dedicated to explore and optimize agronomic practices with 21 of those studies focused on n fertilization and the remaining 32 varying greatly with topics such as inter cropping smethurst et al 2017 smith et al 2016 hoffmann et al 2020 crop rotations smith et al 2016 masikati et al 2014 hoffmann et al 2020 nezomba et al 2018 envirotyping seyoum et al 2017 and plant density magaia et al 2017 seyoum et al 2018 these management oriented publications placed more importance on yield stability and reducing production risks for smallholders in addition 27 of the papers included in the database involved climate change assessments and 13 model improvements this last group included new phosphorus p modules fosu mensah et al 2012 radiation use efficiency rue jones et al 2021 and lai jones et al 2019 routine modifications and specific model parameters calibration magaia et al 2017 lastly the 7 remaining corresponded to agroforestry model improvements and management strategies smith et al 2016 ndoli et al 2017 smethurst et al 2017 dilla et al 2018 hoffmann et al 2020 chemura et al 2021 across all studies in the database 47 presented their own calibration of the genetic parameters and from this group almost all the publications included the validation of the parameters 94 the remaining 53 that did not have a formal calibration process with local data were split in i publications utilizing standard default cultivars available in apsim 33 ii publications that utilized parameters from previous published papers 17 and iii papers that neither clarify the genotype nor the data source of the parameters used but included a validation 3 lastly 82 of the explored publications included the validation of some output of the model 3 2 genetic parameters description maize presented the largest proportion of publications compared to the rest of the crops and it covered a larger geographical area within the continent fig 2 across all maize studies n 42 a total of 88 cultivars were employed time from flowering to maturity tt flower to maturity ranged broadly 590 990 ocd however lack of variation has been reported for this parameter among the three standard hybrids early medium and late available in apsim presenting a constant value of 990 ocd in addition of the 34 publications that reported the duration between flowering to grain filling only four chauhan et al 2015 dixit et al 2011 chikowo et al 2008 chemura et al 2021 kept the standard value 100 ocd whereas the rest of the publications diminished the duration between flowering to grain filling mostly by setting a value of 0 representing an immediate change from flowering to the start of grain filling a similar situation can be found in the variation in time from the end of the juvenile phase to floral initiation this parameter is characterized by photoperiod sensitivity and represents the moment when the final leaf number is defined which ultimately impacts the time to anthesis the screened publications displayed values ranging from 0 to 100 ocd with 50 of the 88 hybrids presenting the value of 0 ocd and only two at 100 ocd smethurst et al 2017 mulwa et al 2016 the rationale behind these low values is the extension of emergence to the end of the juvenile phase tt emerg to endjuv from 150 to 385 ocd instead to obtain a biologically acceptable length of the vegetative stages this seems to be a pragmatic decision to change the vegetative duration without adjusting for photoperiod changes lastly hoffmann et al 2020 changed the time from physiological maturity to ripe to fit with the observed harvest 70 90 ocd while the rest of the publications utilized the standard value of 1 ocd despite the several reported variations only eight publications presented field observations to validate phenology assumptions shamudzarira and robertson 2002 fosu mensah et al 2012 araya et al 2015 seyoum et al 2018 yamusa and akinseye 2018 chimonyo et al 2020 beah et al 2021 feleke et al 2021 no changes were generally made to the photoperiod sensitivity parameters mainly driven by the detailed field or greenhouse data that is required to characterize the genotypes grimm et al 1993 1994 yin et al 1997 due to this limitation most of the publications use the standard values photoperiod crit1 12 5 photoperiod crit2 24 photoperiod slope 23 however chemura et al 2021 arbitrarily defined a decrease in the photoperiod crit1 to 10 h of daylight the photoperiod slope is set as 0 photoneutral hybrids in most of the standard genotypes although 23 and 10 are commonly accepted values for african genotypes ellis et al 1992 brown et al 2014 finally regarding yield determination the main parameters displaying frequent variation were those related with the potential number of kernels standard deviation 118 kernels and kernel weight standard deviation 234 interestingly most of the studies included in the database did not report observed values of these yield component traits but adjusted them until an acceptable level e g rmse of the yield model evaluation was attained sorghum was the crop with the second largest number of publications n 14 including 21 cultivars most of the publications carried out their calibration process based on collected experimental data n 10 fig 3 b once again parameters related to plant phenology were most frequently modified in the publications displaying the diversity of sorghum cultivars calibrated for different regions from emergence to maturity all the stages presented variations in thermal time emergence to end of juvenile phase tt emerg to endjuv ranged from 100 to 242 ocd juvenile period to floral initiation tt endjuv to int ranged from 50 to 280 ocd flag leaf to flowering tt flag to flower ranged from 140 to 231 ocd and the thermal time from flowering to maturity tt flower to maturity ranged from 420 to 865 ocd the photoperiod sensitivity slope values ranged from 0 01 to 43 03 fig 3 these results corroborate a wide range of photoperiod sensitivity values described in the literature for sorghum cultivars in west africa sanon et al 2014 seven of the sorghum publications reported variation in the parameters that determine the leaf appearance the growing degree days required to expand a leaf ranged from 41 to 53 ocd leaf app rate 1 and 26 5 and 75 ocd leaf app rate 2 fig 3a these parameters were estimated in three studies while four studies utilized values found in the literature for ten cultivars in five publications akinseye et al 2017 2019 2020a 2020b the radiation use efficiency rue ranged from 1 25 to 1 85 g mj 1 fig 3a datasets used for model calibration in these studies were collected within africa chimonyo et al 2016 determined greater rue values 1 95 2 85 g mj 1 under intercropping and different water availability conditions the remaining 22 publications included four cultivars for cowpea seven cultivars for soybean six cultivars for sugarcane six cultivars for pearl millet and five cultivars for wheat across these five crops only six publications calibrated the genetic coefficients based on experimental data jones et al 2019 araya et al 2020 bahri et al 2019 sennhenn et al 2017 sida et al 2018 traore et al 2017 and nine publications adopted standard calibration from the apsim model all studies for soybean employed cultivars calibrated for countries outside africa two papers for sugarcane did not present information regarding the parameter used in general phenology parameters presented different values due to the number of cultivars and regions of africa fig 4 a for pearl millet the grain number per head head grain no max ranged from 2000 to 5500 the highest value reported for this trait in the publications was greater than the coefficients from the standard cultivars in the apsim model 4600 photoperiod and vernalization sensitivity are key factors to be considered in the simulations of growth and production for wheat the parameters related to these photop sens and vern sens presented a wide range across cultivars and countries in africa the geographical distribution of the publications highlighted the overall distribution of those crops within the continent pearl millet was concentrated in the northwest region of africa soybean and sugarcane were only found towards the south and wheat in the northern region fig 4 b parameters which reported no variation among the publications were documented in supplementary table s4 3 3 model performance synthesis in general for all the crops and variables the model efficiency kse reported fair values 0 4 and most of the error corresponded to precision problems plp pla yield and biomass were the variables which presented the most observations for these variables sorghum presented the best model efficiency kge 0 93 and 0 94 for yield and biomass respectively conversely phenology observations days to anthesis and days to maturity represented only 15 of the total number of yield observations regarding phenology maize presented the best performance rmse for days to anthesis 0 06 days and days to maturity 3 days the leguminous crops included in this review soybean and cowpea presented similar performance regarding biomass despite the difference in number of observations 17 and 74 for soybean and cowpea respectively these crops presented a conspicuous lower number of observations for validating yield n 25 which impacted the model efficiency kge 0 45 compared to the cereals yield metrics showed lower r2 ccc and kge displaying lower agreement between observed and predicted but this difference was not clear for the rest of the variables table 1 fig 5 lastly biomass rrmse ranged from 16 wheat to 43 maize presenting this variable mostly lack of precision plp pla contrastingly lai kge ranged from 0 40 wheat to 0 84 maize presenting opposite behavior compared to biomass further analysis was conducted for maize defining two classes according to the quality of the calibration the calibrated and validated class showed a refined performance compared to the studies that applied non calibrated and or validated genetic parameters for local conditions fig 6 most of the evaluated metrics reflected this differential performance for calibrated validated cases lower mbe rmse and rrmse as well as higher ccc and kge indices interestingly out of the eight evaluated metrics the r2 was lower for calibrated cases however r2 is not an appropriate metric to summarize overall agreement as it only measures strength of linear association a precision indicator but does not penalize a lack of accuracy yang et al 2014 correndo et al 2021 for instance non calibrated validated cases in maize fig 6a clearly denote a lack of accuracy general prediction trend biased from the 1 1 line for yield simulations as compared to the more accurate trend of yield simulations when coefficients were locally calibrated fig 6b furthermore the decomposition of the prediction error into lack of accuracy pla and lack of precision plp indicates as expected that most of the prediction error in non calibrated datasets comes from problems with lack of accuracy pla 79 the calibrated datasets are mostly accurate pla 5 and most of the error seems in random nature plp 95 3 4 parameters sensitivity using maize as a case study the impacts on yield of the three parameters which presented the broadest variation were tested for three locations within africa for gnmaxcoef greater differences were found with high average yields explored across sites reaching an overall difference between utilizing the minimum versus maximum coefficient values of roughly 10 000 kg ha fig 7 even though great impacts in yield were shown among cultivars no observed values were reported regarding the actual variation in grain numbers to support these changes in the gnmaxcoef regarding the phenology parameters tt flower to maturity and tt emerg to endjuv the maximum values were closely related to the standard medium genotype reported by apsim fig 7 and similar to the medium level for this trait this agreed with the genetic variation towards shorter cycle cultivars furthermore the response of the cultivars by site with more variation in ethiopia and some in senegal between medium and minimum values for these phenology coefficients indicated a strong influence of the time of flowering favoring shorter cultivars to fit the seasons 4 discussion this review provides insights on major concerns linked to model outcomes not always supported by field measurements at the local scale highlighting i the lack of investment on high quality field data research and ii the critical issue of lack of accessibility of published data and unavailability of a platform to share data in addition the limited integration of datasets and open access severely restricts the relevancy of this data to inform policy changes several institutional and technical limitations were highlighted in a recent review by carletto 2021 undoubtedly a reasonable representation of the complex agricultural system requires high quality data at finer spatial resolution however there is a constant mismatch between the data collected from field studies and the data needed for process based crop models driving simulations based on unsupported by local level data assumptions hammer 2020 saltelli et al 2020 harou et al 2021 hence as we consider that the usefulness of the models depends on the overall accuracy of their predictions wallach et al 2014 reliability of the model outcomes will be constrained when less realistic estimates are employed during the last decade several organizations focused on the overall efforts to improve agricultural data recognized this critical issue and pushed the development of protocols for minimum data requirements and formatting e g data smart initiative 50x2030 org big data in agriculture bigdata cgiar org and agmip agmip org constraints on data availability and lack of relevant local level data to match the ever increasing access to information from technological innovations remains a challenge 4 1 lack of common criteria uncertainty of calibration could be related to the nature of the observed data confalonieri et al 2016 the human subjectiveness wallach et al 2021a b or even the model structure sandor et al 2016 alderman and stanfill 2017 most of the calibrations studied here presented modifications in the crop phenology parameters which agrees with most of the standard protocols wallach 2011 accurate simulation of crop phenology should be a priority when calibrating crop growth models archontoulis et al 2014 as it impacts many physiological processes such as leaf area development and biomass partitioning robertson et al 2002 however most of the analyzed literature did not collect field observations to produce a formal validation process the rmse was halved for maize cases that included phenology data in their analysis doubled model performance the lack of observed data for any step of the modeling process seems to be a constant challenge across crop simulation studies in africa models are blindly adjusted without even limiting the estimates to reasonable value ranges seidel et al 2018 across the explored crops a conspicuous number of publications chose to use default apsim cultivars instead of parameters of previous studies with calibrations within the same region utilization of local level data even though not tailored would be a much closer representation of the genetic background and cultivar traits even more worrisome is the number of papers that adjusted parameters without field observations the present maize crop coefficient variability can translate into doubled yields depending on the explored environment large unsupported assumptions are made without considering the impact on the final outcome or the propagation of error as those estimates are upscale from local to regional scale affecting food productions systems of vulnerable regions from a publication standpoint this study highlights the need to reinforce standards and improve the overall quality of the peer review process selecting the right experts as reviewers is the first step to improve standards of the process goymer 2022 nevertheless the disagreement among experts in a topic is such that whether or not a publication is accepted depends in a large proportion on which reviewers happen to be selected for it cole et al 1981 there is a lack of common criteria about what entails a proper modeling assessment which translates to a wide range of quality in the publications publishers can integrate into their peer review systems ways of measuring the degree to which peer reviewed publications meet a reporting standard for the journal lee and moher 2017 in the past efforts for establishing better standards have been suggested e g sinclair 2000 wallach et al 2021a b pasquel et al 2022 but are far from being implemented at the journal level an example could be to implement journal publication thresholds to reject papers which do not provide evidence of local model calibration and testing minimum datasets and constraints linked to arbitrarily not well justified assumptions lastly increasing the transparency and openness in the peer review process entails reputational risk associated with conducting and reporting goymer 2022 however there are still several pros and cons for open peer review that should be taken into consideration for the future of our scientific community schmidt et al 2018 nat neuros 1999 4 2 lack of high quality ground truth data previous efforts discussed the need to describe data quality rosenzweig et al 2013 grassini et al 2015 ruane et al 2017 yet the need for more holistic protocols of data collection addressing the true complexity of the cropping system have not been universally formalized a clear example is illustrated by the case of crop phenology as only the date of anthesis is not useful without a complete description such as planting date the crop response to photoperiod or even if the crop was subjected to a water or heat stress during various stages affecting the regular progress on crop phenology the lack of data accessibility cornered researchers to make unsupported assumptions to fill knowledge gaps during the calibration process and to generalize the context of the cropping system however a major concern is the lack of transparency of these assumptions and methods grassini et al 2015 hammer 2020 addressing these concerns agmip developed an initiative to harmonize data for interoperability porter et al 2014 ruane et al 2017 and promote interdisciplinary modeling efforts to avoid contradictory outcomes von lampe et al 2014 nevertheless these protocols are model user oriented without considering the systems complexity for the social economic environment and human domains musumba et al 2017 stewart et al 2018 in summary the concerns presented here should not be visualized as a conundrum between using crop models in data poor environments or only collecting local level data without a proper research framework clearly there is a need for more integration before investing in decision support tools to develop unsupported food assessments without a relevant context at the local level recently efforts are emerging from africa with a more unified front in a multi institution approach with the goal of developing standardized protocols for field data collection and open sharing of complete datasets in ethiopia the coalition of the willing was established to bring together soil and agronomic field trial data tamene et al 2021 this coalition brought together over 30 000 data points however due to the non standardized protocols used across the compiled trials significant data gaps still exist in a similar effort the sustainable opportunities for improving livelihoods with soils soils consortium developed a standardized protocol in collaboration with many partners the utilization of a unified protocol including a standard set of treatments trial data and rigorous site characterization is critical to guide identification of functionally significant variables that drive the hyper localization of appropriate field level recommendations amede et al 2020 such localized recommendations are the foundation to scaling up increased nutrient use efficiency strategies and agronomic approaches at national levels especially in areas with high levels of heterogeneity and lack of access to soil testing herrick et al 2022 4 3 limitations and future steps limitations of this work are linked to the narrow focus of our case study based on apsim cropping system model however the lack of high quality data is ubiquitous and it is a valid issue for implementation of any crop based mechanistic and process model for this region furthermore uncalibrated and validated soils maynard et al 2022 and low resolution climate data which is not locally relevant grassini et al 2015 are large sources of uncertainty not addressed in this analysis this critical problem could be addressed by redirecting more research investments to developing more uniform data collection from design studies including minimum number of agricultural datapoints needed to provide useful insights facilitating the use of modeling approaches to accurately quantify the impact of different management strategies changing environment and identify key areas of policy implications carletto 2021 provided a priority list of actions that could promote data rich environments i create new platforms for data sharing more when those are driven by the funding agency and with a clear data collection protocol ii develop tools to maintain data privacy and proper credits to the organization researchers that assisted on collecting this data iii promote open access in all funding agencies as a standard protocol iv reward and invest in research teams collecting high quality data also facilitating the establishment of detailed protocols based on research goals but promoting expansion of data collection beyond research goals v provide more opportunities for publishing only data descriptor papers and critical datasets without the need of analysis and interpretation with the goal of facilitating data sharing among research teams vi establish new funding opportunities to support research teams for open access data in the known data poor regions around the globe and vii enhance the discussion of this topic in our scientific communities facilitate and assist mentoring young researchers on this critical topic to guarantee a change in mentality to the generations to come and secure the future of open access of critical data sources this priority list of actions should be a core pillar of the african union commission s auc prioritized action plan set to be adopted by african heads of state during the auc s soil health and fertilizer summit in 2023 future research should re emphasize the need for collecting high quality field data to provide reliable outcomes that can be transformed into relevant agricultural innovations and future policies for our farming systems around the globe 5 conclusions this review provides a case study for apsim crop modeling research in africa highlighting that 53 of gathered publications did not have a calibration and 18 had no validation with relevant local level field data of all the field crop traits yield information was the factor most broadly reported but crop phenology was only available in less than 15 of the publications with yield observations from the standpoint of model performance and reliability of outcomes availability of field local level data on crop phenology doubled overall performance relative to when this critical ground data was not available inclusion of unsupported assumptions lack of local level field data in crop models as observed through the variation between minimum and maximum values for several crop coefficients clearly demonstrates the implications on yield deviations and consequently misleading assessments this synthesis re emphasizes the critical need for future investments in the collection of local level field data and the need to promote development of standard protocols for data collection as well as the importance of data sharing and accessibility for future usage this is currently a major challenge as data is limited and not available in this region the united nations report entitled transforming our world the 2030 agenda for sustainable development from 2015 emphasized the need to access quality timely and reliable disaggregated data as key to decision making and to provide food assessments with real potential to make an impact with innovations at local level this remains a major gap that must be addressed immediately to make progress towards meeting sustainable development goals funding this study was supported by the feed the future innovation lab for collaborative research on sustainable intensification siil at kansas state university through funding from the united states agency for international development usaid under the cooperative agreement grant number aid oaa l 14 00006 contribution no 23 191 j from the kansas agricultural experiment station declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the authors report financial support was provided by usaid acknowledgments acknowledgment is made to the apsim initiative which takes responsibility for quality assurance and a structured innovation programme for apsim s modelling software which is provided free for research and development use see www apsim info for details appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105633 
25441,crop growth models can be useful tools to evaluate potential scenarios yet the limited field data is an obstacle for providing significant insights at the local level this certainly applies to several regions in africa where crop models built regional scenarios based on low resolution field data leading to unsupported agricultural interventions on smallholders systems this review provides a synthesis analysis of crop modeling efforts in africa using agricultural production systems simulator apsim studies as a case study this research aims to highlight the value of standardized protocols to collect store and deploy field data and highlights the critical issue of limited data accessibility of published manuscripts and unavailability of a data sharing platform investment in local level data collection and data sharing platforms is critical to guarantee the advancement of science and to provide reliable assessments to address complex challenges of food nutrition and climate security in africa graphical abstract image 1 keywords genetic parameters field data model performance model reliability apsim africa data availability data will be made available on request 1 introduction food security remains an elusive target for africa fao 2019 although progress has been achieved with the support of multiple disciplines and funding agencies significant trends of increasing hunger persist within the continent with high reliance on the local level to supply food for their community frelat et al 2016 previous reviews investigated the impact of agricultural strategies and innovations on food availability and stability for improving outcomes in human nutrition and health phalkey et al 2015 however previous studies documented the potential implications of the lack of local level data and data aggregation when developing estimates at a regional scale hoffmann et al 2016 this problem is not only linked to one crop growth model but to a broader issue previously identified in the literature for example for wofost world food studies model de wit et al 2019 reported that minor changes in parameters produced large variations of outcomes therefore the lack of high resolution field data could lead to the implementation of default coefficients derived from original version of the model adjusted to different cropping systems and environments producing irrelevant synthetic data in this context crop growth models arise as useful tools to represent key components of farming systems and to evaluate the impact of potential interventions e g productivity improvement or climate change mitigation but only when data is available to properly calibrate and validate the model at a local level the agricultural production systems simulator apsim model is used worldwide by thousands of researchers holzworth et al 2018 due to its robust mechanistic approach to simulate biophysical processes within farming systems holzworth et al 2014 2015 keating et al 2003 since its inception in 1990 mccown et al 1995 1996 several modules were added to the platform expanding the number of crops and soil environmental processes to be explored keating et al 2003 globally and within the african continent apsim has been employed to assess diverse topics such as climate change and adaptation tidjani and akponikpe 2012 tachie obeng et al 2013 chauhan et al 2015 adam et al 2020 food security policy assessment nezomba et al 2018 chimonyo et al 2020 farming strategies design akponikpè et al 2010 rurinda et al 2015 beah et al 2021 and resource use efficiency akinseye et al 2020a chimonyo et al 2016 ncube et al 2009 among other features holzworth et al 2015 although agriculture system model applications have expanded less emphasis has been given to delineating quality standards chisanga et al 2020 porter et al 2014 in order to provide reliable outcomes crop growth models should include data collection conscious calibration and extensive validation baroni and tarantola 2014 recently harou et al 2021 discussed knowledge informed probabilistic approaches in crop models to provide uncertainties in so called data poor environments without detailed ground data to build good quality calibrations the outputs of the model could be as reliable as the assumptions taken saltelli et al 2020 thus our estimations and assessments of food security and response to changing climate and management practices are as reliable as the potential proximity between the outcomes generated with the reality at the local level in this review a synthesis analysis was performed using the apsim cropping system model as a case study with the goal of describing past and current research efforts discussing limitations challenges and future research investments for relevant food security assessments in africa the main objectives were to i summarize the current state of knowledge of modeling exercises using apsim within the african continent ii explore the variability of crop genetic parameters iii synthesize the model performance for yield biomass leaf area and phenology for the studied crops and iv evaluate the model sensitivity of the most variable genetic parameters and the potential impact on food security assessments of the assumptions based on no local scale data 2 materials and methods 2 1 data collection the literature search was limited to apsim simulation studies conducted within the african continent for this purpose two data sources were included in the analysis i scopus search engine www scopus com and ii apsim web page fig 1 i the search was conducted from november 21 2021 to december 31 2021 on november 22 2021 the references in bibtex format were exported from scopus and the list of available papers from the apsim webpage was retrieved papers published after november 21 2021 were not included in this database the screening and selection process was done after november 22 2021 until december 31 2021 scopus is a well known abstract and citation database that includes nearly 37000 titles from approximately 12000 publishers the first step was establishing keywords to use in the scopus search engine selecting apsim combined with i africa ii african and iii each country in the african continent as individual searches the next step was the manual screening of titles and abstracts via the r package revtools westgate 2019 this package facilitates the article screening process via an enhanced display of the titles and abstract and an interactive menu for article selection or exclusion lastly a list of peer review articles using the apsim model in africa was obtained from the publication metrics section of the apsim website https www apsim info this list was used as an independent search to check and complement the scopus search the handling of this data source involved manual checking of the titles listed and selecting only the papers related to studies in africa after merging the two data sources duplicated entries were discarded the abstract and title screen fig 1 ii for both data sources did not restrict inclusion of crops in this step the frequency of each crop was determined and only crops with at least three publications were retained thereby the list of studied crops was defined as i maize zea mays l ii sorghum sorghum bicolor iii sugarcane saccharum officinarum iv pearl millet pennisetum glaucum v wheat triticum aestivum vi soybean glycine max and vii cowpea vigna unguiculata following initial screening a full text screening was performed fig 1 iii based on the presence of either the crop cultivar genetic parameters used or a validation of the model comparing observed versus predicted values for yield biomass leaf area index lai days to anthesis or days to maturity this process resulted in the final number of publications included in the final database fig 1 iv lastly the manual extraction of the data was performed using the webplotdigitizer software https automeris io webplotdigitizer this online tool allows the user to upload jpg files define the extent and range of the axis and finally extract the values of each point manually the collected data including the genetic parameters and the data extracted for the validation assessment and the references of the selected publications are available at 10 6084 m9 figshare 19726009 2 2 genetic parameters description the genetic parameters were retrieved when available within the publication if the parameters employed were not specified within the publication yet the source was clearly stated these parameters were retrieved as well the cultivar or genetic parameters variability was explored for each crop using standard deviation frequency of occurrence minimum maximum and range 2 3 crops simulation performance the performance of the simulations was assessed using the collected simulated observed data pairs each crop was evaluated independently including different environments and management practices when available the retrieved variables were i yield ii biomass iii lai iv days to anthesis and v days to maturity these variables were selected based on the availability of data within each crop the agreement between simulated and observed values was evaluated by estimating a variety of prediction performance metrics a k a scoring rules that account for distinct prediction quality aspects thereby the following performance metrics were used i the mean bias error mbe variable units as the average difference of simulated with respect to observed values for which positive values indicate a systematic under prediction and negative values indicate over prediction ii the root mean square error rmse variable units as an error metric based on squared errors that heavily penalizes large residuals iii the normalized or relative rmse rrmse as a metric of percentage deviation from the observed mean iv the kling gupta efficiency kge normalized with near one ideal kling et al 2012 as a refined model efficiency nash and sutcliffe 1970 krause et al 2005 v the concordance correlation coefficient ccc as a normalized metric that accounts for general agreement by weighting the pearson correlation coefficient r by an index of accuracy lin 1989 and vi the coefficient of determination r2 as a goodness of fit index in addition a bivariate linear regression standardized major axis was used to determine the general relationship pattern between simulated and observed values and to decompose the mean squared error into lack of accuracy percentage lack of accuracy pla and lack of precision percentage lack of precision plp components suggested by correndo et al 2021 specific formulas are provided in supplementary table s1 the performance analysis was conducted using the metrica r package correndo et al 2022 further model performance analysis was conducted for maize as it was the crop with the most observations the simulations performance assessment was split into two contrasting classes based on genetic parameters source i no calibration publications that used genetic parameters from previous studies conducted outside africa and did not report the phenology days to anthesis and days to maturity validation within the study ii detailed calibration publications that calibrated the parameters used in the study or used one from a previous study within the same region and reported the phenology days to anthesis and days to maturity validation within the study 2 4 parameters sensitivity the effect of the genetic parameters on the model outcomes such as phenology and yield components was tested using maize as a case study for this purpose apsim classic 7 10 model was employed to perform the simulations three articles guan et al 2015 seyoum et al 2018 and hoffmann et al 2020 which encompassed contrasting regions senegal ethiopia and south africa respectively were selected to extract the site coordinates and the management was representative of locations for our simulations weather data from 1981 to 2021 was retrieved from nasapower sparks 2018 and chirps funk et al 2015 and soil parameters were collected from soil grids data base hengl et al 2015 tested cultivars were built using apsim maize standard medium duration cultivar parameters as a base modifying only one parameter at a time the three parameters which showed the greatest variability were chosen for this analysis i time from emergence to floral initiation ii time from flowering to maturity and iii maximum grain number coefficient for each of these parameters the maximum and the minimum were tested and compared to the medium duration standard cultivar as mentioned the management was defined based on the local management described in each paper the crop management among regions differed in planting dates senegal 15 jul 01 aug and 15 aug south africa 01 nov 15 nov and 15 dec ethiopia 15 may 15 jun and 15 jul whereas the rest of the management options were maintained constant plant density 6 plants m2 row spacing 72 cm sowing depth 30 mm n fertilization 150 kg ha urea 3 results 3 1 dataset outline the dataset encompassed 71 publications 1474 yield observations across 24 countries within africa including seven major crops supplementary table s2 of all the papers in the database 53 were dedicated to explore and optimize agronomic practices with 21 of those studies focused on n fertilization and the remaining 32 varying greatly with topics such as inter cropping smethurst et al 2017 smith et al 2016 hoffmann et al 2020 crop rotations smith et al 2016 masikati et al 2014 hoffmann et al 2020 nezomba et al 2018 envirotyping seyoum et al 2017 and plant density magaia et al 2017 seyoum et al 2018 these management oriented publications placed more importance on yield stability and reducing production risks for smallholders in addition 27 of the papers included in the database involved climate change assessments and 13 model improvements this last group included new phosphorus p modules fosu mensah et al 2012 radiation use efficiency rue jones et al 2021 and lai jones et al 2019 routine modifications and specific model parameters calibration magaia et al 2017 lastly the 7 remaining corresponded to agroforestry model improvements and management strategies smith et al 2016 ndoli et al 2017 smethurst et al 2017 dilla et al 2018 hoffmann et al 2020 chemura et al 2021 across all studies in the database 47 presented their own calibration of the genetic parameters and from this group almost all the publications included the validation of the parameters 94 the remaining 53 that did not have a formal calibration process with local data were split in i publications utilizing standard default cultivars available in apsim 33 ii publications that utilized parameters from previous published papers 17 and iii papers that neither clarify the genotype nor the data source of the parameters used but included a validation 3 lastly 82 of the explored publications included the validation of some output of the model 3 2 genetic parameters description maize presented the largest proportion of publications compared to the rest of the crops and it covered a larger geographical area within the continent fig 2 across all maize studies n 42 a total of 88 cultivars were employed time from flowering to maturity tt flower to maturity ranged broadly 590 990 ocd however lack of variation has been reported for this parameter among the three standard hybrids early medium and late available in apsim presenting a constant value of 990 ocd in addition of the 34 publications that reported the duration between flowering to grain filling only four chauhan et al 2015 dixit et al 2011 chikowo et al 2008 chemura et al 2021 kept the standard value 100 ocd whereas the rest of the publications diminished the duration between flowering to grain filling mostly by setting a value of 0 representing an immediate change from flowering to the start of grain filling a similar situation can be found in the variation in time from the end of the juvenile phase to floral initiation this parameter is characterized by photoperiod sensitivity and represents the moment when the final leaf number is defined which ultimately impacts the time to anthesis the screened publications displayed values ranging from 0 to 100 ocd with 50 of the 88 hybrids presenting the value of 0 ocd and only two at 100 ocd smethurst et al 2017 mulwa et al 2016 the rationale behind these low values is the extension of emergence to the end of the juvenile phase tt emerg to endjuv from 150 to 385 ocd instead to obtain a biologically acceptable length of the vegetative stages this seems to be a pragmatic decision to change the vegetative duration without adjusting for photoperiod changes lastly hoffmann et al 2020 changed the time from physiological maturity to ripe to fit with the observed harvest 70 90 ocd while the rest of the publications utilized the standard value of 1 ocd despite the several reported variations only eight publications presented field observations to validate phenology assumptions shamudzarira and robertson 2002 fosu mensah et al 2012 araya et al 2015 seyoum et al 2018 yamusa and akinseye 2018 chimonyo et al 2020 beah et al 2021 feleke et al 2021 no changes were generally made to the photoperiod sensitivity parameters mainly driven by the detailed field or greenhouse data that is required to characterize the genotypes grimm et al 1993 1994 yin et al 1997 due to this limitation most of the publications use the standard values photoperiod crit1 12 5 photoperiod crit2 24 photoperiod slope 23 however chemura et al 2021 arbitrarily defined a decrease in the photoperiod crit1 to 10 h of daylight the photoperiod slope is set as 0 photoneutral hybrids in most of the standard genotypes although 23 and 10 are commonly accepted values for african genotypes ellis et al 1992 brown et al 2014 finally regarding yield determination the main parameters displaying frequent variation were those related with the potential number of kernels standard deviation 118 kernels and kernel weight standard deviation 234 interestingly most of the studies included in the database did not report observed values of these yield component traits but adjusted them until an acceptable level e g rmse of the yield model evaluation was attained sorghum was the crop with the second largest number of publications n 14 including 21 cultivars most of the publications carried out their calibration process based on collected experimental data n 10 fig 3 b once again parameters related to plant phenology were most frequently modified in the publications displaying the diversity of sorghum cultivars calibrated for different regions from emergence to maturity all the stages presented variations in thermal time emergence to end of juvenile phase tt emerg to endjuv ranged from 100 to 242 ocd juvenile period to floral initiation tt endjuv to int ranged from 50 to 280 ocd flag leaf to flowering tt flag to flower ranged from 140 to 231 ocd and the thermal time from flowering to maturity tt flower to maturity ranged from 420 to 865 ocd the photoperiod sensitivity slope values ranged from 0 01 to 43 03 fig 3 these results corroborate a wide range of photoperiod sensitivity values described in the literature for sorghum cultivars in west africa sanon et al 2014 seven of the sorghum publications reported variation in the parameters that determine the leaf appearance the growing degree days required to expand a leaf ranged from 41 to 53 ocd leaf app rate 1 and 26 5 and 75 ocd leaf app rate 2 fig 3a these parameters were estimated in three studies while four studies utilized values found in the literature for ten cultivars in five publications akinseye et al 2017 2019 2020a 2020b the radiation use efficiency rue ranged from 1 25 to 1 85 g mj 1 fig 3a datasets used for model calibration in these studies were collected within africa chimonyo et al 2016 determined greater rue values 1 95 2 85 g mj 1 under intercropping and different water availability conditions the remaining 22 publications included four cultivars for cowpea seven cultivars for soybean six cultivars for sugarcane six cultivars for pearl millet and five cultivars for wheat across these five crops only six publications calibrated the genetic coefficients based on experimental data jones et al 2019 araya et al 2020 bahri et al 2019 sennhenn et al 2017 sida et al 2018 traore et al 2017 and nine publications adopted standard calibration from the apsim model all studies for soybean employed cultivars calibrated for countries outside africa two papers for sugarcane did not present information regarding the parameter used in general phenology parameters presented different values due to the number of cultivars and regions of africa fig 4 a for pearl millet the grain number per head head grain no max ranged from 2000 to 5500 the highest value reported for this trait in the publications was greater than the coefficients from the standard cultivars in the apsim model 4600 photoperiod and vernalization sensitivity are key factors to be considered in the simulations of growth and production for wheat the parameters related to these photop sens and vern sens presented a wide range across cultivars and countries in africa the geographical distribution of the publications highlighted the overall distribution of those crops within the continent pearl millet was concentrated in the northwest region of africa soybean and sugarcane were only found towards the south and wheat in the northern region fig 4 b parameters which reported no variation among the publications were documented in supplementary table s4 3 3 model performance synthesis in general for all the crops and variables the model efficiency kse reported fair values 0 4 and most of the error corresponded to precision problems plp pla yield and biomass were the variables which presented the most observations for these variables sorghum presented the best model efficiency kge 0 93 and 0 94 for yield and biomass respectively conversely phenology observations days to anthesis and days to maturity represented only 15 of the total number of yield observations regarding phenology maize presented the best performance rmse for days to anthesis 0 06 days and days to maturity 3 days the leguminous crops included in this review soybean and cowpea presented similar performance regarding biomass despite the difference in number of observations 17 and 74 for soybean and cowpea respectively these crops presented a conspicuous lower number of observations for validating yield n 25 which impacted the model efficiency kge 0 45 compared to the cereals yield metrics showed lower r2 ccc and kge displaying lower agreement between observed and predicted but this difference was not clear for the rest of the variables table 1 fig 5 lastly biomass rrmse ranged from 16 wheat to 43 maize presenting this variable mostly lack of precision plp pla contrastingly lai kge ranged from 0 40 wheat to 0 84 maize presenting opposite behavior compared to biomass further analysis was conducted for maize defining two classes according to the quality of the calibration the calibrated and validated class showed a refined performance compared to the studies that applied non calibrated and or validated genetic parameters for local conditions fig 6 most of the evaluated metrics reflected this differential performance for calibrated validated cases lower mbe rmse and rrmse as well as higher ccc and kge indices interestingly out of the eight evaluated metrics the r2 was lower for calibrated cases however r2 is not an appropriate metric to summarize overall agreement as it only measures strength of linear association a precision indicator but does not penalize a lack of accuracy yang et al 2014 correndo et al 2021 for instance non calibrated validated cases in maize fig 6a clearly denote a lack of accuracy general prediction trend biased from the 1 1 line for yield simulations as compared to the more accurate trend of yield simulations when coefficients were locally calibrated fig 6b furthermore the decomposition of the prediction error into lack of accuracy pla and lack of precision plp indicates as expected that most of the prediction error in non calibrated datasets comes from problems with lack of accuracy pla 79 the calibrated datasets are mostly accurate pla 5 and most of the error seems in random nature plp 95 3 4 parameters sensitivity using maize as a case study the impacts on yield of the three parameters which presented the broadest variation were tested for three locations within africa for gnmaxcoef greater differences were found with high average yields explored across sites reaching an overall difference between utilizing the minimum versus maximum coefficient values of roughly 10 000 kg ha fig 7 even though great impacts in yield were shown among cultivars no observed values were reported regarding the actual variation in grain numbers to support these changes in the gnmaxcoef regarding the phenology parameters tt flower to maturity and tt emerg to endjuv the maximum values were closely related to the standard medium genotype reported by apsim fig 7 and similar to the medium level for this trait this agreed with the genetic variation towards shorter cycle cultivars furthermore the response of the cultivars by site with more variation in ethiopia and some in senegal between medium and minimum values for these phenology coefficients indicated a strong influence of the time of flowering favoring shorter cultivars to fit the seasons 4 discussion this review provides insights on major concerns linked to model outcomes not always supported by field measurements at the local scale highlighting i the lack of investment on high quality field data research and ii the critical issue of lack of accessibility of published data and unavailability of a platform to share data in addition the limited integration of datasets and open access severely restricts the relevancy of this data to inform policy changes several institutional and technical limitations were highlighted in a recent review by carletto 2021 undoubtedly a reasonable representation of the complex agricultural system requires high quality data at finer spatial resolution however there is a constant mismatch between the data collected from field studies and the data needed for process based crop models driving simulations based on unsupported by local level data assumptions hammer 2020 saltelli et al 2020 harou et al 2021 hence as we consider that the usefulness of the models depends on the overall accuracy of their predictions wallach et al 2014 reliability of the model outcomes will be constrained when less realistic estimates are employed during the last decade several organizations focused on the overall efforts to improve agricultural data recognized this critical issue and pushed the development of protocols for minimum data requirements and formatting e g data smart initiative 50x2030 org big data in agriculture bigdata cgiar org and agmip agmip org constraints on data availability and lack of relevant local level data to match the ever increasing access to information from technological innovations remains a challenge 4 1 lack of common criteria uncertainty of calibration could be related to the nature of the observed data confalonieri et al 2016 the human subjectiveness wallach et al 2021a b or even the model structure sandor et al 2016 alderman and stanfill 2017 most of the calibrations studied here presented modifications in the crop phenology parameters which agrees with most of the standard protocols wallach 2011 accurate simulation of crop phenology should be a priority when calibrating crop growth models archontoulis et al 2014 as it impacts many physiological processes such as leaf area development and biomass partitioning robertson et al 2002 however most of the analyzed literature did not collect field observations to produce a formal validation process the rmse was halved for maize cases that included phenology data in their analysis doubled model performance the lack of observed data for any step of the modeling process seems to be a constant challenge across crop simulation studies in africa models are blindly adjusted without even limiting the estimates to reasonable value ranges seidel et al 2018 across the explored crops a conspicuous number of publications chose to use default apsim cultivars instead of parameters of previous studies with calibrations within the same region utilization of local level data even though not tailored would be a much closer representation of the genetic background and cultivar traits even more worrisome is the number of papers that adjusted parameters without field observations the present maize crop coefficient variability can translate into doubled yields depending on the explored environment large unsupported assumptions are made without considering the impact on the final outcome or the propagation of error as those estimates are upscale from local to regional scale affecting food productions systems of vulnerable regions from a publication standpoint this study highlights the need to reinforce standards and improve the overall quality of the peer review process selecting the right experts as reviewers is the first step to improve standards of the process goymer 2022 nevertheless the disagreement among experts in a topic is such that whether or not a publication is accepted depends in a large proportion on which reviewers happen to be selected for it cole et al 1981 there is a lack of common criteria about what entails a proper modeling assessment which translates to a wide range of quality in the publications publishers can integrate into their peer review systems ways of measuring the degree to which peer reviewed publications meet a reporting standard for the journal lee and moher 2017 in the past efforts for establishing better standards have been suggested e g sinclair 2000 wallach et al 2021a b pasquel et al 2022 but are far from being implemented at the journal level an example could be to implement journal publication thresholds to reject papers which do not provide evidence of local model calibration and testing minimum datasets and constraints linked to arbitrarily not well justified assumptions lastly increasing the transparency and openness in the peer review process entails reputational risk associated with conducting and reporting goymer 2022 however there are still several pros and cons for open peer review that should be taken into consideration for the future of our scientific community schmidt et al 2018 nat neuros 1999 4 2 lack of high quality ground truth data previous efforts discussed the need to describe data quality rosenzweig et al 2013 grassini et al 2015 ruane et al 2017 yet the need for more holistic protocols of data collection addressing the true complexity of the cropping system have not been universally formalized a clear example is illustrated by the case of crop phenology as only the date of anthesis is not useful without a complete description such as planting date the crop response to photoperiod or even if the crop was subjected to a water or heat stress during various stages affecting the regular progress on crop phenology the lack of data accessibility cornered researchers to make unsupported assumptions to fill knowledge gaps during the calibration process and to generalize the context of the cropping system however a major concern is the lack of transparency of these assumptions and methods grassini et al 2015 hammer 2020 addressing these concerns agmip developed an initiative to harmonize data for interoperability porter et al 2014 ruane et al 2017 and promote interdisciplinary modeling efforts to avoid contradictory outcomes von lampe et al 2014 nevertheless these protocols are model user oriented without considering the systems complexity for the social economic environment and human domains musumba et al 2017 stewart et al 2018 in summary the concerns presented here should not be visualized as a conundrum between using crop models in data poor environments or only collecting local level data without a proper research framework clearly there is a need for more integration before investing in decision support tools to develop unsupported food assessments without a relevant context at the local level recently efforts are emerging from africa with a more unified front in a multi institution approach with the goal of developing standardized protocols for field data collection and open sharing of complete datasets in ethiopia the coalition of the willing was established to bring together soil and agronomic field trial data tamene et al 2021 this coalition brought together over 30 000 data points however due to the non standardized protocols used across the compiled trials significant data gaps still exist in a similar effort the sustainable opportunities for improving livelihoods with soils soils consortium developed a standardized protocol in collaboration with many partners the utilization of a unified protocol including a standard set of treatments trial data and rigorous site characterization is critical to guide identification of functionally significant variables that drive the hyper localization of appropriate field level recommendations amede et al 2020 such localized recommendations are the foundation to scaling up increased nutrient use efficiency strategies and agronomic approaches at national levels especially in areas with high levels of heterogeneity and lack of access to soil testing herrick et al 2022 4 3 limitations and future steps limitations of this work are linked to the narrow focus of our case study based on apsim cropping system model however the lack of high quality data is ubiquitous and it is a valid issue for implementation of any crop based mechanistic and process model for this region furthermore uncalibrated and validated soils maynard et al 2022 and low resolution climate data which is not locally relevant grassini et al 2015 are large sources of uncertainty not addressed in this analysis this critical problem could be addressed by redirecting more research investments to developing more uniform data collection from design studies including minimum number of agricultural datapoints needed to provide useful insights facilitating the use of modeling approaches to accurately quantify the impact of different management strategies changing environment and identify key areas of policy implications carletto 2021 provided a priority list of actions that could promote data rich environments i create new platforms for data sharing more when those are driven by the funding agency and with a clear data collection protocol ii develop tools to maintain data privacy and proper credits to the organization researchers that assisted on collecting this data iii promote open access in all funding agencies as a standard protocol iv reward and invest in research teams collecting high quality data also facilitating the establishment of detailed protocols based on research goals but promoting expansion of data collection beyond research goals v provide more opportunities for publishing only data descriptor papers and critical datasets without the need of analysis and interpretation with the goal of facilitating data sharing among research teams vi establish new funding opportunities to support research teams for open access data in the known data poor regions around the globe and vii enhance the discussion of this topic in our scientific communities facilitate and assist mentoring young researchers on this critical topic to guarantee a change in mentality to the generations to come and secure the future of open access of critical data sources this priority list of actions should be a core pillar of the african union commission s auc prioritized action plan set to be adopted by african heads of state during the auc s soil health and fertilizer summit in 2023 future research should re emphasize the need for collecting high quality field data to provide reliable outcomes that can be transformed into relevant agricultural innovations and future policies for our farming systems around the globe 5 conclusions this review provides a case study for apsim crop modeling research in africa highlighting that 53 of gathered publications did not have a calibration and 18 had no validation with relevant local level field data of all the field crop traits yield information was the factor most broadly reported but crop phenology was only available in less than 15 of the publications with yield observations from the standpoint of model performance and reliability of outcomes availability of field local level data on crop phenology doubled overall performance relative to when this critical ground data was not available inclusion of unsupported assumptions lack of local level field data in crop models as observed through the variation between minimum and maximum values for several crop coefficients clearly demonstrates the implications on yield deviations and consequently misleading assessments this synthesis re emphasizes the critical need for future investments in the collection of local level field data and the need to promote development of standard protocols for data collection as well as the importance of data sharing and accessibility for future usage this is currently a major challenge as data is limited and not available in this region the united nations report entitled transforming our world the 2030 agenda for sustainable development from 2015 emphasized the need to access quality timely and reliable disaggregated data as key to decision making and to provide food assessments with real potential to make an impact with innovations at local level this remains a major gap that must be addressed immediately to make progress towards meeting sustainable development goals funding this study was supported by the feed the future innovation lab for collaborative research on sustainable intensification siil at kansas state university through funding from the united states agency for international development usaid under the cooperative agreement grant number aid oaa l 14 00006 contribution no 23 191 j from the kansas agricultural experiment station declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests the authors report financial support was provided by usaid acknowledgments acknowledgment is made to the apsim initiative which takes responsibility for quality assurance and a structured innovation programme for apsim s modelling software which is provided free for research and development use see www apsim info for details appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2023 105633 
25442,data driven surrogate modeling introducing spatial lag to consider spatial autocorrelation of flooding within urban drainage systems heng li a chunxiao zhang a b 1 min chen c dingtao shen d e yunyun niu a a school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china b observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china c key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china d key laboratory for geographical process analysis simulation of hubei province central china normal university 430079 wuhan china key laboratory for geographical process analysis simulation of hubei province central china normal university wuhan 430079 china key laboratory for geographical process analysis simulation of hubei province central china normal university 430079 wuhan china e college of urban and environmental sciences central china normal university 430079 wuhan china college of urban and environmental sciences central china normal university wuhan 430079 china college of urban and environmental sciences central china normal university 430079 wuhan china corresponding author china university of geosciences in beijing rm 216 no 3 teaching building no 29 xueyuan road haidian district beijing 100083 china china university of geosciences in beijing rm 216 no 3 teaching building no 29 xueyuan road haidian district beijing 100083 china 1 zhang s research interests are knowledge and data driven geographic simulation and virtual geographic environments handling editor daniel p ames data driven surrogate modeling has been increasingly employed for flooding simulation of urban drainage systems udss due to its high computational efficiency and accuracy however spatial autocorrelation is prevalent in many typical scenarios including the uds this omission of spatial information is very likely to cause the machine learning model to capture the wrong uds overflow mechanism from the data to capture the spatial autocorrelation an artificial neural network ann based surrogate modeling method that introduces spatial lag to account for the spatial autocorrelation of flooding within the uds is proposed and coupled with a genetic algorithm ga to reduce the uncertainty caused by random initialization of ann in this study a surrogate modeling experiment was carried out for the storm water management model swmm the experimental results show that the ann can successfully capture the spatial autocorrelation induced by flooding within the uds and accurately replicate the output simulated by swmm keywords machine learning based surrogate modeling mlsm urban flooding simulation spatial autocorrelation spatial lag storm water management model swmm data availability data will be made available on request 1 introduction urban drainage systems udss are a core component of urban infrastructure designed that limit flooding to acceptable levels in cities to improve flooding resilience brown et al 2009 bach et al 2014 jamali et al 2020 however urbanization climate change and rapid population growth have resulted in frequent urban flooding which has adversely impacted human life the economy and the environment across the world aronica et al 2012 improving computer modeling and forecast to characterize flooding rapidly and comprehensively poses a significant challenge to current and future urban flooding risk management strategies many physically based models for simulating flooding have been developed over the past few years such as the storm water management model swmm rossman 2009 mike 11 danish hydraulic institute danish hydraulic institute 2017a and sobek deltares n d however traditional physically based modeling is highly specialized and requires expensive computational costs making it unsuitable for efficient flooding simulation and real time forecasting bermúdez et al 2018 to reduce the high computational cost of physically based models and enable real time forecasting data driven surrogate modeling has received extensive attention from uds modelers in recent years also known as machine learning based surrogate modeling mlsm garzón et al 2022 with its excellent nonlinear learning and generalization abilities it has the potential to capture physical mechanisms from data machine learning models once trained can be orders of magnitude faster than raw physically based models without sacrificing too much accuracy reichstein et al 2019 chu et al 2020 currently the main uses of the mlsm in uds are to approximate original model responses and real time problems carbajal et al 2017 asher et al 2015 jhong et al 2017 developed a real time flooding forecasting model using support vector machines svms to approximate the inundation depth simulated by the flo 2d model at a reference point rjeily et al 2017 used a nonlinear autoregressive exogenous narx neural network to emulate the water depth of key manholes in urban watersheds the inputs to the model are the rainfall intensity and water depth from the previous time step the above studies used classical machine learning methods to approximate physically based urban flooding models instead the maximum water depths during storm events were also emulated moreover the time series characteristics of floods are constructed which is beneficial to the research of real time flooding modeling and describing the change in water depth during urban storm events with the development of machine learning techniques new machine learning models optimization algorithms and data augmentation have begun to appear in the mlsm doorn 2021 pylianidis et al 2022 some studies have begun to use recurrent neural networks rnns and convolutional neural networks cnns to emulate the water depth and flow velocity at specific coordinates from the corresponding input of rainfall intensity bui et al 2020 guo et al 2020 jiang et al 2020 berkhahn et al 2019 introduced the ensemble learning algorithm and the greedy algorithm into artificial neural networks anns and further improved the emulation accuracy by optimizing the ann model parameters and topology the computation time of the ann is on the order of seconds and the accuracy of the results is also convincing kim and han 2020 used a data augmentation algorithm to augment the input data of the machine learning model and used the data augmented ann to emulate the total accumulative overflow simulated by swmm confirming the significant improvement in forecast performance after applying data augmentation recent studies have benefited from the development of the above technologies and further improved the performance of mlsm nonetheless there are still unresolved questions a more challenging aspect of the mlsm is to gain understanding from data in addition to optimal forecast and to maximize learning from the data and capture the process evolving features e g temporal spatial spatiotemporal features of the physically based model reichstein et al 2019 razavi 2021 the spatial autocorrelation due to flooding within the uds that is the spatial dependence of geographic factors in the uds seems to be rarely considered in previous studies typically when flood simulation is performed based on uds overflow manholes at various points in space interact affecting each other this phenomenon is common in many typical scenarios especially in urban environments löchl and axhausen 2010 clancy et al 2022 this spatial dependence is also called spatial lag in the field of spatial analysis miller 2000 that is adjacent elements will be spatially correlated and affect each other ignoring the spatial autocorrelation is likely to cause the mlsm to capture the wrong uds overflow mechanism from the data which may hinder mlsm based model analysis and scenario applications e g uncertainty analysis multi objective optimization real time problems garzón et al 2022 li et al 2021 on the one hand from the perspective of urban environment research song et al 2014 considered the spatial lag in the study of the impact of land cover types on urban land surface temperature ulst and concluded that the spatial autocorrelation of ulst is more significant than the effect of land cover type on ulst this result is important for mitigating the urban heat island effect hao and liu 2016 introduced a spatial lag to control for spatial autocorrelation and avoid biased and inconsistent estimation results when studying the influencing factors of pm2 5 concentrations in 73 cities in china aune et al 2022 recently reviewed the mechanisms and severity of the impact of extreme urban storm events on infectious diseases similarly pointing out the importance of considering spatial autocorrelation in the process on the other hand from the methodological perspective the importance of considering spatial autocorrelation has recently been noted in machine learning based spatial forecast research fouedjio and klump 2019 liu et al 2022 introduced spatial lag in the spatial forecast of housing prices in meuse and california and the results indicated that the random forest rf model with the introduction of spatial lag produced lower errors difference up to 33 than the traditional rf model it can be seen that the introduction of spatial lag in the mlsm has the potential to capture the spatial features of urban flooding however few studies have considered this critical factor in the mlsm it is worthwhile to introduce a spatial lag in the mlsm to account for spatial autocorrelation of flooding within the uds therefore the objective of this study is to explore the introduction of a spatial lag in the mlsm to account for spatial autocorrelation of flooding within the uds specifically our main goals are to a propose an mlsm workflow that introduces spatial lag b and implements the workflow to train models and c evaluate whether the trained model successfully captures spatial autocorrelation with higher accuracy to this end we approximate the swmm response maximum overflow and overflow hydrographs for manholes using ann based surrogate modeling the rest of the paper is structured as follows a general mlsm workflow that introduces spatial lag is described in section 2 implementation of the workflow in section 3 the forecasting ability of the model is tested in section 4 section 5 discusses and summarizes the limitations of this study section 6 discusses the conclusions and future work 2 methodology 2 1 artificial neural network based surrogate modeling workflow introducing a spatial lag a general artificial neural network ann based surrogate modeling workflow hereafter called annsm sl that introduces a spatial lag is proposed to emulate the overflow information maximum overflow and overflow hydrographs of manholes in urban drainage systems udss annsm sl is shown in fig 1 the workflow can be described in five steps first storm water management model swmm based flooding simulations are performed for multiple urban storm events in the uds to generate a raw dataset manhole overflow information at different points in space a specific spatial weight matrix is constructed based on the obtained dataset that is the spatial relationship between overflow manholes in the uds is defined second based on the constructed spatial weight matrix spatial autocorrelation analysis is performed on the uds and the spatial lag is obtained third the spatial lag is introduced into the training process of the anns fourth the genetic algorithm ga is used to optimize the parameters of the ann training process and the optimal parameter population is selected to avoid model overfitting finally the trained anns are used for emulation under new storm events and compared with the simulation results of swmm 2 2 spatial autocorrelation analysis defining the spatial weight matrix w i j is the first step in performing spatial autocorrelation analysis and is necessary to construct spatial lags in principle the construction of such a spatial weight matrix involves two processes the definition of the neighborhood and the computation of the spatial weights the neighborhood determines the position of the link i to j and the weight determines the strength of the link weights can be determined via binary settings or computed via distance based functions such as inverse distance and kernel functions matrices of different sizes represent spatial relationships at separate scales in this study the first order queen matrix is used to construct the spatial weight matrix of a typical overflow manhole within the uds that is when the subcatchment area where the manhole i is located is adjacent to the subcatchment area where the manhole j is located it is defined as 1 otherwise it is 0 neighbors can be collinear or common vertices thus the w i j are 1 w i j 1 0 i f i a n d j a r e n e i g h b o r s o t h e r w i s e the spatial autocorrelation is distinct from the ordinary regression model in regression modeling the spatial lag is introduced when the spatial autocorrelation of the dependent variable is considered that is the spatial lag model is established in this model the dependent variable is affected not only by the independent variable but also by the dependent variable that is spatially adjacent to it the model expression is 2 y ρ w i j s u r r o u n d y x β ε 3 ε n 0 σ 2 i in the formula equation 2 and 3 y is the n 1 dimension dependent variable x is the n k independent variable matrix w i j is the n n dimension spatial weight matrix s u r r o u n d y is the spatially weighted average around the dependent variable y w i j s u r r o u n d y is the spatial lag factor about y ρ 1 1 is the spatial autocorrelation coefficient of w i j s u r r o u n d y ε is a n 1 dimension random error and each element is independent and identically distributed with a mean of zero and limited variance σ 2 i the spatial lag w i j s u r r o u n d y can be regarded as a dummy variable that affects the overflow manholes within the uds in this study introducing w i j s u r r o u n d y into the input layer of ann can make ann contain the spatial autocorrelation of dependent variables the spatial lag model is a multiple regression model that includes spatial correlations and is essentially a linear model the w i j s u r r o u n d y is introduced into the input layer of ann such that it considers the spatial autoregression between overflow manholes and make use of the strong nonlinear learning ability of ann to make up for the insufficiency of the spatial lag model equation 2 and 3 2 3 physically based model the physically based model is the swmm which is an urban runoff model that can be used for hydrological hydraulic simulation of uds for analysis of the overflow according to various storm events the saint venant equations equation 4 and 5 were used 4 q w 1 n d d p 5 3 s 1 2 5 q t g a s f 2 v a t v 2 a x g a h x 0 here q is runoff m³ s w is the subwatershed width m n is manning s roughness coefficient d is the depth m d p is the ground reservoir lost depth m s is the subcatchment slope a is the surface flow cross sectional area of the subcatchment m2 and v is the surface flow velocity m s the runoff analysis results of swmm were used as the target value of the ann from the results of the swmm only manhole overflow was considered although more information would be available in principle 2 4 artificial neural network introducing a spatial lag for flooding emulation the purpose of the proposed annsm sl is to develop a computationally efficient data driven ann model for flooding emulation therefore we use the overflow manhole data simulated by swmm as the sample dataset the dataset was used to train the ann and evaluate model performance to forecast the maximum overflow and overflow hydrographs of the manholes in the uds two types of ann models are constructed in this study these models consist of an input layer an output layer and one hidden layer in between each layer consists of a certain number of neurons which are responsible for processing incoming information the topology of the first type of ann model hereafter called annsl oh is shown in fig 2 which forecasts the entire overflow process of the manholes in this model the rainfall intensity and the spatial lag w i j s u r r o u n d y of the previous three t times and the area and characteristic width of the subcatchments where the manhole is located are used as inputs to forecast the manhole overflow at current time t therefore its input layer consists of a total of 8 neurons the output layer consists of one neuron and the hidden layer neurons are set to 20 the topology of the second type of ann model hereafter called annsl mo is shown in fig 3 which forecasts the maximum overflow of the manhole during the storm event in this model the maximum overflow of the manhole is forecasted using the rainfall intensity and the spatial lag w i j s u r r o u n d y of the entire storm event as well as the area and characteristic width of the subcatchment where the manhole is located therefore the input layer consists of n 3 neurons the output layer consists of one neuron and the hidden layer neurons are also set to 20 ann training is sensitive to initial connection weights and bias parameters between neurons but these parameters are numerous and cannot be accurately obtained in this study a genetic algorithm ga is used to optimize the weights and biases of two types of anns to capture the uncertainty caused by random initialization the number of weights and bias terms of the two types of ann is shown in table 1 the number of parameters of annsl oh is 621 and the number of parameters of annsl mo is 20n 521 3 study area and data 3 1 study area the study area is set in shunqing district nanchong city sichuan province with coordinates between latitude 106 03 e to 107 07 e and longitude 30 41 n to 30 51 n due to the influence of the monsoon climate precipitation mostly occurs in summer and autumn the long term annual average temperature and precipitation are 17 4 c and 1020 8 mm respectively the total study area is approximately 33 02 square kilometers see fig 4 a fig 4 b shows the urban drainage system constructed based on the swmm model in this area the real drainage system was reasonably trimmed to maintain anonymity which consists of 131 pipe segments 105 manholes and 8 outfalls the study area was eventually divided into 106 subcatchments 3 2 rainfall data in this study by analyzing the hourly rainfall data recorded by a local meteorological station in the study area over the last 15 years a storm event was defined as rainfall reaching 25 mm within 24 h and 148 storm events were selected as data samples these samples are divided into 116 samples for model training and 29 samples for model validation the remaining 3 samples are regarded as the storm events outside the samples and applied to the trained ann model to evaluate the forecasting ability of the model this division is performed manually to obtain a good representation of heavy and weak rainfall events in all ensembles finally the above rainfall events are simulated by the swmm and the overflow results are obtained according to the input and output features of the two types of ann models the dataset required for the model was made 3 3 swmm simulation data due to the lack of recorded flood markers and measured data on water levels and pipeline flows physically based models cannot be calibrated and validated nevertheless this study still uses the runoff coefficient method to verify the rationality of the swmm simulation results the method compares the comprehensive surface runoff coefficient in the study area with the runoff coefficient calculated based on the swmm if the relative error between the two is within 5 it proves that the model simulation results are relatively reliable in this study three storm events with different intensities were selected for verification the modeling process based on the physically based model is not the focus of this study therefore this paper does not focus further on the uncertainties caused by simulation based on physically based models first the weighted calculation is carried out according to the proportion of different land use types in the study area and the comprehensive surface runoff coefficient is obtained as 0 715 second three storm events were selected to calculate the runoff coefficient based on swmm and compared with the comprehensive runoff coefficient the results are shown in table 2 the relative error between the runoff coefficient calculated by the swmm model and the comprehensive surface runoff coefficient in the study area is controlled within 5 which demonstrates that the swmm simulation results are acceptable 4 results here the spatial autocorrelation analysis of overflow manhole simulated by swmm is carried out to further reveal the strong spatial autocorrelation phenomenon in the uds based flood simulation then two types of neural networks are used to simulate the maximum overflow and overflow hydrograph of manholes and the training results are compared with swmm three storm events fig 5 that have never participated in the training process were selected to analyze the performance of the proposed anns in response to the new storm events among them r11 represents a storm event with 54 4 mm over 11 h r13 indicates a storm event with 34 4 mm over 13 h and r16 indicates a storm event with 26 9 mm over 16 h 4 1 spatial autocorrelation analysis for overflow manhole data simulated by swmm to test the strength of the spatial autocorrelation between overflow manholes the global moran index moran s i moran 1950 was selected as a measure moran s i is a measure of spatial correlation equation 6 6 m o r a n s i i 1 n j 1 n ω i j y i y y j y s 2 i 1 n j 1 n ω i j here s 2 1 n i 1 n y i y y 1 n i 1 n y i and y i is the observation value of the i th position which in this study refers to the overflow simulated by swmm n is the number of sample points and ω i j is the corresponding element in the spatial weight matrix w i j after normalization moran s i range is 1 1 if moran s i 0 there is a positive spatial correlation the larger the value is the more significant the spatial correlation is and vice versa thirty six typical overflow manholes were selected to create the queen spatial weight matrix fig 6 shows the spatial relationship connectivity diagram of the 36 overflow manholes based on the spatial weight matrix second the overflow results of the swmm simulation under four storm events with separate rainfall intensities are selected for spatial autocorrelation analysis according to the spatial weight matrix the moran s i of 36 overflow manholes table 3 and the local spatial autocorrelation scattergram fig 7 were obtained table 3 shows that the moran s i values of the four separate rainfall intensities are all greater than 0 the p values are all less than 0 05 the z values are greater than 1 96 indicating that the confidence level is above 95 this shows that there is a strong positive spatial autocorrelation between the typical overflow manholes in this area from a global perspective although there is a strong spatial autocorrelation between overflow manholes from a global perspective we would like to obtain additional details fig 7 shows the local spatial correlations of 36 overflow manholes under four separate storm events the local spatial autocorrelation scatterplot is divided into four quadrants the high high cluster hh the low low cluster ll and the random regions i e the low high cluster lh and the high low cluster hl by analyzing the scatter plot which manholes that present hh ll clustering in local space can be determined including their proportion and distribution in global space and local changes in different scenarios for example fig 7 a shows that there are 24 manholes in the hh and ll accounting for 66 67 of the total manholes with the increase in rainfall intensity some manholes were transferred from random regions lh or hl to cluster regions hh or ll the rainfall intensity of r16 8 has increased compared with r16 3 table 3 the number of manholes in the cluster regions lh or hl increased to 28 accounting for 77 78 of the total manholes among them the hh added 3 manholes and the ll increased 1 manhole the reason for the change may be that with the increase in rainfall intensity the overflow of manholes increases continuously resulting in a strong spatial correlation between manholes that had no spatial correlation before regardless of the perspective of global space or from the analysis of local space when flood simulation is based on an urban drainage system there is a strong spatial autocorrelation between overflow manholes therefore the uncertainty caused by its spatial effect needs to be considered when conducting mlsm 4 2 training and implementation of annsl oh and annsl mo a total of 116 storm event samples are used in the training process of the genetic algorithm ga to optimize annsl oh and annsl mo and 29 samples are used to select the models with optimal parameters the hyperparameter settings in the model training process are shown in table 4 the epochs of annsl oh and annsl mo are both set to 100 the epochs ga epochs of the respective ga are set to 200 and 300 respectively the population size of the ga ga npop is set to 100 the crossover rate ga cross is set to 0 9 and the mutation rate ga mut is set to 0 01 throughout the training process the mean absolute error mae is used as the objective function to find the initial weights and biases that performs best on the validation set the mae and mean square error mse of the model training and validation process are shown in table 5 the two anns ann oh and ann mo in the table are traditional models that do not introduce the spatial lag w i j s u r r o u n d y and are used for comparative analysis with annsl oh and annsl mo obviously the mae and mse of annsl oh and annsl mo considering the spatial autocorrelation are significantly lower than those of the traditional ann model fig 8 shows the change in the minimum mae of the two classes of models during ga based training the horizontal axis of the graph represents the number of iterations of a ga and the vertical axis represents the minimum mae of the objective function by observing the evolution process of annsl oh in the stage 1 see fig 8 a it can be found that the performance of the traditional ann ann oh validation and annsl oh validation in the validation set is basically the same in the stage 2 the mae of both show a downward trend and they are increasingly fitted to the performance of annsl oh on the training set annsl oh train the reason may be that the effect of optimizing the initial weights and biases is greater than the effect of introducing w i j s u r r o u n d y in this stage in the stage 3 the performance of annsl oh validation approaches that of annsl oh train while the mae of ann oh validation hardly drops the reason for this change is that the effect of introducing w i j s u r r o u n d y is greater than the effect of the ga that is the ga can no longer help the ann further reduce the error from the aspect of model parameter optimization at this stage while the ann introducing w i j s u r r o u n d y can make the mae continue to decrease with the increase in iterations to improve the fitting degree of the model similarly fig 8 b shows the same change trend for annsl mo the evolutionary hydrograph show that the error of the anns considering the spatial autocorrelation is smaller than that of the traditional anns whether it forecasts the maximum overflow or the entire overflow process the performance of the model in response to new storm events is discussed further in the following subsections 4 3 forecasting maximum overflow with annsl mo during storm events the maximum overflow of typical overflow manholes within the uds is one of the most concerning pieces of information which helps local government staff to quickly implement emergency flooding control measures for specific areas here 36 typical overflow manholes were selected for annsl mo based emulation and compared with the swmm simulation results fig 9 shows the distribution of the local spatial autocorrelation of 36 manholes j3 j38 within the uds the manholes show hh ll and the random regions lh and hl in space under separate storm events which affect the forecasting results of annsl mo to varying degrees for example both j7 and j16 showed ll with surrounding manholes under the storm events of r11 and r13 respectively see fig 9 a and b annsl mo successfully captured their spatial autocorrelation and the forecasting results were close to swmm see table 6 however under the storm event of r16 due to the obvious weakening of the rainfall intensity both j7 and j16 no longer exhibit spatial autocorrelation with the surrounding manholes see fig 9 c resulting in similar forecasting results of annsl mo and ann mo and a certain gap with the forecasting results of swmm see table 6 in addition j20 and j38 exhibited the spatial autocorrelation of ll under the three storm events and the forecasting results of annsl mo were closer to swmm than ann mo j25 j26 and j34 all showed the spatial autocorrelation of hh under the three storm events and the forecasting result of annsl mo was closer to swmm than that of ann mo d tre in table 6 refers to the difference in the total relative error of the forecasting results of annsl mo and ann mo obviously annsl mo not only learns from the data but also captures the spatial autocorrelation expressed by overflow manholes from the data effectively fig 10 shows the maximum overflow of 36 manholes j3 j38 emulated by annsl mo and swmm under the three rainfall events among them fig 10 a and d are the emulation results of the r11 storm event and the coefficient of determination r2 is 0 9814 fig 10 b and e are the emulation results of the r13 storm event and r2 is 0 9643 fig 10 c and f show the emulation results of the r16 storm events with an r2 of 0 9573 the r2 of ann is above 0 95 under the three storm events annsl mo exhibits excellent forecasting ability for swmm 4 4 forecasting overflow hydrographs with annsl oh the overflow hydrographs of manholes provide more complete flooding information in the time distribution which is helpful to analyze the trend of overflow in real time this information can guide the integrated management of urban floods and improve the ability of cities to cope with flooding risk here 6 manholes were selected from 36 typical manholes and their overflow hydrographs were subjected to annsl oh emulation under the three storm events the overflow of manholes at each time step can be viewed as a forecasting of the maximum overflow section 4 1 is sufficient to illustrate the need to consider spatial autocorrelations therefore the comparative analysis with traditional ann is not carried out again in this section annsl oh was directly compared with the swmm simulation results and evaluated using r2 fig 11 shows the overflow hydrographs for 6 manholes the r2 of annsl oh to swmm is above 0 9 under the three storm events specifically because j7 and j16 did not show spatial autocorrelation under the r16 storm event the r2 was lower than that of the other two storm events the other manholes all showed spatial autocorrelation of different natures and degrees under the three storm events and the r2 was basically above 0 95 5 discussions and limitations recently researchers have focused on further improving the performance of machine learning based surrogate modeling mlsm from different perspectives such as new models model optimization and data augmentation this progress makes surrogate modeling increasingly suitable for a variety of applications concerning uds flooding forecasting multiobjective optimization uncertainty analysis etc this study focuses on the spatial autocorrelation effect that occurs during uds simulations the experimental results show that the ann with the introduction of spatial lag can correctly capture the spatial autocorrelation mechanism of uds from the output data of the physically based model and has lower training and testing errors than the traditional ann model in the face of new storm events it can also be close to the simulation results of the physically based model showing excellent forecasting ability however this study still has limitations mainly in the following four points 1 due to the limitations of the physical mechanism itself the performance of ann can only get close as possible to swmm 2 due to the lack of measured data the simulation results of swmm cannot be calibrated in this study the influence of uncertainty generated by swmm on the spatial autocorrelation cannot be quantified and discussed 3 there is a lack of a set of benchmark uds for testing the performance of new mlsms garzón et al 2022 first this lack of benchmarks hinders comparisons between mlsms across studies second new surrogate modeling approaches are still lacking studies of how the model changes with the complexity of the uds for this study a set of benchmark udss is needed to explore the influence of spatial autocorrelation in udss of different characteristics e g scale topology slope 4 the data driven emulation based on uds is still for a specific point group and cannot fully express the spatial characteristics of the entire study area spatial autocorrelation may be more pronounced in 2d flooding emulations overall we suggest that future mlsm should integrate physically based and machine learning based approaches this integration will enhance the mlsm s description of the spatiotemporal dependencies among interacting geographic factors making the mlsm not only adaptable to data but also more able to capture the spatiotemporal evolution mechanism of processes from data despite the necessary and yet to implemented further developments listed above the proposed model can be seen as a step toward the realization of mlsms that capture spatial mechanisms 6 conclusions and future steps in this study a data driven surrogate modeling method introducing spatial lag is proposed and two types of anns are constructed based on the method to forecast the maximum overflow and overflow hydrographs of manholes within the uds the main contributions of this study are summarized as follows 1 in combination with the idea of spatial autoregression this study introduces the spatial lag into the ann training process and the error of the ann trained with 145 storm events is significantly lower than that of the traditional ann 2 the three storm events to test the forecasting ability of the trained ann for the maximum overflow and overflow hydrograph of typical overflow manholes and compared with the swmm simulation results both r2 values are above 0 9 proving the excellent forecasting ability nevertheless the following aspects need to be improved in future work for example coupling with 2d flooding forecasting models may be considered in the future to provide spatially more comprehensive spatial information second from the model perspective it is necessary to introduce more physical mechanisms into data driven models to alleviate data dependencies in addition we will conduct more comprehensive research on this basis including uncertainty analysis of physically based models and validation based on measured sites to be more reliable data and code availability repositories title ga ann for uds developer heng li contact address lh mygis 163 com source code and data available https github com lhmygis ga ann for uds language python questions and bugs reports should be submitted using that website or e mailed to the corresponding author declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china no 42077438 and the fundamental research funds for the central universities no 2652018082 this work was supported by the national natural science foundation of china no 61872325 62172373 the data support from the nanchong meteorological bureau is gratefully acknowledged given their roles as environmental modelling software editor min chen was not involved in the peer review of this article and has no access to information regarding its peer review full responsibility for the editorial process for this article was delegated to journal editor dr daniel p ames 
25442,data driven surrogate modeling introducing spatial lag to consider spatial autocorrelation of flooding within urban drainage systems heng li a chunxiao zhang a b 1 min chen c dingtao shen d e yunyun niu a a school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china school of information engineering china university of geosciences in beijing no 29 xueyuan road haidian district beijing 100083 china b observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china observation and research station of beijing fangshan comprehensive exploration ministry of natural resources beijing 100083 china c key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china key laboratory of virtual geographic environment nanjing normal university ministry of education nanjing 210023 china d key laboratory for geographical process analysis simulation of hubei province central china normal university 430079 wuhan china key laboratory for geographical process analysis simulation of hubei province central china normal university wuhan 430079 china key laboratory for geographical process analysis simulation of hubei province central china normal university 430079 wuhan china e college of urban and environmental sciences central china normal university 430079 wuhan china college of urban and environmental sciences central china normal university wuhan 430079 china college of urban and environmental sciences central china normal university 430079 wuhan china corresponding author china university of geosciences in beijing rm 216 no 3 teaching building no 29 xueyuan road haidian district beijing 100083 china china university of geosciences in beijing rm 216 no 3 teaching building no 29 xueyuan road haidian district beijing 100083 china 1 zhang s research interests are knowledge and data driven geographic simulation and virtual geographic environments handling editor daniel p ames data driven surrogate modeling has been increasingly employed for flooding simulation of urban drainage systems udss due to its high computational efficiency and accuracy however spatial autocorrelation is prevalent in many typical scenarios including the uds this omission of spatial information is very likely to cause the machine learning model to capture the wrong uds overflow mechanism from the data to capture the spatial autocorrelation an artificial neural network ann based surrogate modeling method that introduces spatial lag to account for the spatial autocorrelation of flooding within the uds is proposed and coupled with a genetic algorithm ga to reduce the uncertainty caused by random initialization of ann in this study a surrogate modeling experiment was carried out for the storm water management model swmm the experimental results show that the ann can successfully capture the spatial autocorrelation induced by flooding within the uds and accurately replicate the output simulated by swmm keywords machine learning based surrogate modeling mlsm urban flooding simulation spatial autocorrelation spatial lag storm water management model swmm data availability data will be made available on request 1 introduction urban drainage systems udss are a core component of urban infrastructure designed that limit flooding to acceptable levels in cities to improve flooding resilience brown et al 2009 bach et al 2014 jamali et al 2020 however urbanization climate change and rapid population growth have resulted in frequent urban flooding which has adversely impacted human life the economy and the environment across the world aronica et al 2012 improving computer modeling and forecast to characterize flooding rapidly and comprehensively poses a significant challenge to current and future urban flooding risk management strategies many physically based models for simulating flooding have been developed over the past few years such as the storm water management model swmm rossman 2009 mike 11 danish hydraulic institute danish hydraulic institute 2017a and sobek deltares n d however traditional physically based modeling is highly specialized and requires expensive computational costs making it unsuitable for efficient flooding simulation and real time forecasting bermúdez et al 2018 to reduce the high computational cost of physically based models and enable real time forecasting data driven surrogate modeling has received extensive attention from uds modelers in recent years also known as machine learning based surrogate modeling mlsm garzón et al 2022 with its excellent nonlinear learning and generalization abilities it has the potential to capture physical mechanisms from data machine learning models once trained can be orders of magnitude faster than raw physically based models without sacrificing too much accuracy reichstein et al 2019 chu et al 2020 currently the main uses of the mlsm in uds are to approximate original model responses and real time problems carbajal et al 2017 asher et al 2015 jhong et al 2017 developed a real time flooding forecasting model using support vector machines svms to approximate the inundation depth simulated by the flo 2d model at a reference point rjeily et al 2017 used a nonlinear autoregressive exogenous narx neural network to emulate the water depth of key manholes in urban watersheds the inputs to the model are the rainfall intensity and water depth from the previous time step the above studies used classical machine learning methods to approximate physically based urban flooding models instead the maximum water depths during storm events were also emulated moreover the time series characteristics of floods are constructed which is beneficial to the research of real time flooding modeling and describing the change in water depth during urban storm events with the development of machine learning techniques new machine learning models optimization algorithms and data augmentation have begun to appear in the mlsm doorn 2021 pylianidis et al 2022 some studies have begun to use recurrent neural networks rnns and convolutional neural networks cnns to emulate the water depth and flow velocity at specific coordinates from the corresponding input of rainfall intensity bui et al 2020 guo et al 2020 jiang et al 2020 berkhahn et al 2019 introduced the ensemble learning algorithm and the greedy algorithm into artificial neural networks anns and further improved the emulation accuracy by optimizing the ann model parameters and topology the computation time of the ann is on the order of seconds and the accuracy of the results is also convincing kim and han 2020 used a data augmentation algorithm to augment the input data of the machine learning model and used the data augmented ann to emulate the total accumulative overflow simulated by swmm confirming the significant improvement in forecast performance after applying data augmentation recent studies have benefited from the development of the above technologies and further improved the performance of mlsm nonetheless there are still unresolved questions a more challenging aspect of the mlsm is to gain understanding from data in addition to optimal forecast and to maximize learning from the data and capture the process evolving features e g temporal spatial spatiotemporal features of the physically based model reichstein et al 2019 razavi 2021 the spatial autocorrelation due to flooding within the uds that is the spatial dependence of geographic factors in the uds seems to be rarely considered in previous studies typically when flood simulation is performed based on uds overflow manholes at various points in space interact affecting each other this phenomenon is common in many typical scenarios especially in urban environments löchl and axhausen 2010 clancy et al 2022 this spatial dependence is also called spatial lag in the field of spatial analysis miller 2000 that is adjacent elements will be spatially correlated and affect each other ignoring the spatial autocorrelation is likely to cause the mlsm to capture the wrong uds overflow mechanism from the data which may hinder mlsm based model analysis and scenario applications e g uncertainty analysis multi objective optimization real time problems garzón et al 2022 li et al 2021 on the one hand from the perspective of urban environment research song et al 2014 considered the spatial lag in the study of the impact of land cover types on urban land surface temperature ulst and concluded that the spatial autocorrelation of ulst is more significant than the effect of land cover type on ulst this result is important for mitigating the urban heat island effect hao and liu 2016 introduced a spatial lag to control for spatial autocorrelation and avoid biased and inconsistent estimation results when studying the influencing factors of pm2 5 concentrations in 73 cities in china aune et al 2022 recently reviewed the mechanisms and severity of the impact of extreme urban storm events on infectious diseases similarly pointing out the importance of considering spatial autocorrelation in the process on the other hand from the methodological perspective the importance of considering spatial autocorrelation has recently been noted in machine learning based spatial forecast research fouedjio and klump 2019 liu et al 2022 introduced spatial lag in the spatial forecast of housing prices in meuse and california and the results indicated that the random forest rf model with the introduction of spatial lag produced lower errors difference up to 33 than the traditional rf model it can be seen that the introduction of spatial lag in the mlsm has the potential to capture the spatial features of urban flooding however few studies have considered this critical factor in the mlsm it is worthwhile to introduce a spatial lag in the mlsm to account for spatial autocorrelation of flooding within the uds therefore the objective of this study is to explore the introduction of a spatial lag in the mlsm to account for spatial autocorrelation of flooding within the uds specifically our main goals are to a propose an mlsm workflow that introduces spatial lag b and implements the workflow to train models and c evaluate whether the trained model successfully captures spatial autocorrelation with higher accuracy to this end we approximate the swmm response maximum overflow and overflow hydrographs for manholes using ann based surrogate modeling the rest of the paper is structured as follows a general mlsm workflow that introduces spatial lag is described in section 2 implementation of the workflow in section 3 the forecasting ability of the model is tested in section 4 section 5 discusses and summarizes the limitations of this study section 6 discusses the conclusions and future work 2 methodology 2 1 artificial neural network based surrogate modeling workflow introducing a spatial lag a general artificial neural network ann based surrogate modeling workflow hereafter called annsm sl that introduces a spatial lag is proposed to emulate the overflow information maximum overflow and overflow hydrographs of manholes in urban drainage systems udss annsm sl is shown in fig 1 the workflow can be described in five steps first storm water management model swmm based flooding simulations are performed for multiple urban storm events in the uds to generate a raw dataset manhole overflow information at different points in space a specific spatial weight matrix is constructed based on the obtained dataset that is the spatial relationship between overflow manholes in the uds is defined second based on the constructed spatial weight matrix spatial autocorrelation analysis is performed on the uds and the spatial lag is obtained third the spatial lag is introduced into the training process of the anns fourth the genetic algorithm ga is used to optimize the parameters of the ann training process and the optimal parameter population is selected to avoid model overfitting finally the trained anns are used for emulation under new storm events and compared with the simulation results of swmm 2 2 spatial autocorrelation analysis defining the spatial weight matrix w i j is the first step in performing spatial autocorrelation analysis and is necessary to construct spatial lags in principle the construction of such a spatial weight matrix involves two processes the definition of the neighborhood and the computation of the spatial weights the neighborhood determines the position of the link i to j and the weight determines the strength of the link weights can be determined via binary settings or computed via distance based functions such as inverse distance and kernel functions matrices of different sizes represent spatial relationships at separate scales in this study the first order queen matrix is used to construct the spatial weight matrix of a typical overflow manhole within the uds that is when the subcatchment area where the manhole i is located is adjacent to the subcatchment area where the manhole j is located it is defined as 1 otherwise it is 0 neighbors can be collinear or common vertices thus the w i j are 1 w i j 1 0 i f i a n d j a r e n e i g h b o r s o t h e r w i s e the spatial autocorrelation is distinct from the ordinary regression model in regression modeling the spatial lag is introduced when the spatial autocorrelation of the dependent variable is considered that is the spatial lag model is established in this model the dependent variable is affected not only by the independent variable but also by the dependent variable that is spatially adjacent to it the model expression is 2 y ρ w i j s u r r o u n d y x β ε 3 ε n 0 σ 2 i in the formula equation 2 and 3 y is the n 1 dimension dependent variable x is the n k independent variable matrix w i j is the n n dimension spatial weight matrix s u r r o u n d y is the spatially weighted average around the dependent variable y w i j s u r r o u n d y is the spatial lag factor about y ρ 1 1 is the spatial autocorrelation coefficient of w i j s u r r o u n d y ε is a n 1 dimension random error and each element is independent and identically distributed with a mean of zero and limited variance σ 2 i the spatial lag w i j s u r r o u n d y can be regarded as a dummy variable that affects the overflow manholes within the uds in this study introducing w i j s u r r o u n d y into the input layer of ann can make ann contain the spatial autocorrelation of dependent variables the spatial lag model is a multiple regression model that includes spatial correlations and is essentially a linear model the w i j s u r r o u n d y is introduced into the input layer of ann such that it considers the spatial autoregression between overflow manholes and make use of the strong nonlinear learning ability of ann to make up for the insufficiency of the spatial lag model equation 2 and 3 2 3 physically based model the physically based model is the swmm which is an urban runoff model that can be used for hydrological hydraulic simulation of uds for analysis of the overflow according to various storm events the saint venant equations equation 4 and 5 were used 4 q w 1 n d d p 5 3 s 1 2 5 q t g a s f 2 v a t v 2 a x g a h x 0 here q is runoff m³ s w is the subwatershed width m n is manning s roughness coefficient d is the depth m d p is the ground reservoir lost depth m s is the subcatchment slope a is the surface flow cross sectional area of the subcatchment m2 and v is the surface flow velocity m s the runoff analysis results of swmm were used as the target value of the ann from the results of the swmm only manhole overflow was considered although more information would be available in principle 2 4 artificial neural network introducing a spatial lag for flooding emulation the purpose of the proposed annsm sl is to develop a computationally efficient data driven ann model for flooding emulation therefore we use the overflow manhole data simulated by swmm as the sample dataset the dataset was used to train the ann and evaluate model performance to forecast the maximum overflow and overflow hydrographs of the manholes in the uds two types of ann models are constructed in this study these models consist of an input layer an output layer and one hidden layer in between each layer consists of a certain number of neurons which are responsible for processing incoming information the topology of the first type of ann model hereafter called annsl oh is shown in fig 2 which forecasts the entire overflow process of the manholes in this model the rainfall intensity and the spatial lag w i j s u r r o u n d y of the previous three t times and the area and characteristic width of the subcatchments where the manhole is located are used as inputs to forecast the manhole overflow at current time t therefore its input layer consists of a total of 8 neurons the output layer consists of one neuron and the hidden layer neurons are set to 20 the topology of the second type of ann model hereafter called annsl mo is shown in fig 3 which forecasts the maximum overflow of the manhole during the storm event in this model the maximum overflow of the manhole is forecasted using the rainfall intensity and the spatial lag w i j s u r r o u n d y of the entire storm event as well as the area and characteristic width of the subcatchment where the manhole is located therefore the input layer consists of n 3 neurons the output layer consists of one neuron and the hidden layer neurons are also set to 20 ann training is sensitive to initial connection weights and bias parameters between neurons but these parameters are numerous and cannot be accurately obtained in this study a genetic algorithm ga is used to optimize the weights and biases of two types of anns to capture the uncertainty caused by random initialization the number of weights and bias terms of the two types of ann is shown in table 1 the number of parameters of annsl oh is 621 and the number of parameters of annsl mo is 20n 521 3 study area and data 3 1 study area the study area is set in shunqing district nanchong city sichuan province with coordinates between latitude 106 03 e to 107 07 e and longitude 30 41 n to 30 51 n due to the influence of the monsoon climate precipitation mostly occurs in summer and autumn the long term annual average temperature and precipitation are 17 4 c and 1020 8 mm respectively the total study area is approximately 33 02 square kilometers see fig 4 a fig 4 b shows the urban drainage system constructed based on the swmm model in this area the real drainage system was reasonably trimmed to maintain anonymity which consists of 131 pipe segments 105 manholes and 8 outfalls the study area was eventually divided into 106 subcatchments 3 2 rainfall data in this study by analyzing the hourly rainfall data recorded by a local meteorological station in the study area over the last 15 years a storm event was defined as rainfall reaching 25 mm within 24 h and 148 storm events were selected as data samples these samples are divided into 116 samples for model training and 29 samples for model validation the remaining 3 samples are regarded as the storm events outside the samples and applied to the trained ann model to evaluate the forecasting ability of the model this division is performed manually to obtain a good representation of heavy and weak rainfall events in all ensembles finally the above rainfall events are simulated by the swmm and the overflow results are obtained according to the input and output features of the two types of ann models the dataset required for the model was made 3 3 swmm simulation data due to the lack of recorded flood markers and measured data on water levels and pipeline flows physically based models cannot be calibrated and validated nevertheless this study still uses the runoff coefficient method to verify the rationality of the swmm simulation results the method compares the comprehensive surface runoff coefficient in the study area with the runoff coefficient calculated based on the swmm if the relative error between the two is within 5 it proves that the model simulation results are relatively reliable in this study three storm events with different intensities were selected for verification the modeling process based on the physically based model is not the focus of this study therefore this paper does not focus further on the uncertainties caused by simulation based on physically based models first the weighted calculation is carried out according to the proportion of different land use types in the study area and the comprehensive surface runoff coefficient is obtained as 0 715 second three storm events were selected to calculate the runoff coefficient based on swmm and compared with the comprehensive runoff coefficient the results are shown in table 2 the relative error between the runoff coefficient calculated by the swmm model and the comprehensive surface runoff coefficient in the study area is controlled within 5 which demonstrates that the swmm simulation results are acceptable 4 results here the spatial autocorrelation analysis of overflow manhole simulated by swmm is carried out to further reveal the strong spatial autocorrelation phenomenon in the uds based flood simulation then two types of neural networks are used to simulate the maximum overflow and overflow hydrograph of manholes and the training results are compared with swmm three storm events fig 5 that have never participated in the training process were selected to analyze the performance of the proposed anns in response to the new storm events among them r11 represents a storm event with 54 4 mm over 11 h r13 indicates a storm event with 34 4 mm over 13 h and r16 indicates a storm event with 26 9 mm over 16 h 4 1 spatial autocorrelation analysis for overflow manhole data simulated by swmm to test the strength of the spatial autocorrelation between overflow manholes the global moran index moran s i moran 1950 was selected as a measure moran s i is a measure of spatial correlation equation 6 6 m o r a n s i i 1 n j 1 n ω i j y i y y j y s 2 i 1 n j 1 n ω i j here s 2 1 n i 1 n y i y y 1 n i 1 n y i and y i is the observation value of the i th position which in this study refers to the overflow simulated by swmm n is the number of sample points and ω i j is the corresponding element in the spatial weight matrix w i j after normalization moran s i range is 1 1 if moran s i 0 there is a positive spatial correlation the larger the value is the more significant the spatial correlation is and vice versa thirty six typical overflow manholes were selected to create the queen spatial weight matrix fig 6 shows the spatial relationship connectivity diagram of the 36 overflow manholes based on the spatial weight matrix second the overflow results of the swmm simulation under four storm events with separate rainfall intensities are selected for spatial autocorrelation analysis according to the spatial weight matrix the moran s i of 36 overflow manholes table 3 and the local spatial autocorrelation scattergram fig 7 were obtained table 3 shows that the moran s i values of the four separate rainfall intensities are all greater than 0 the p values are all less than 0 05 the z values are greater than 1 96 indicating that the confidence level is above 95 this shows that there is a strong positive spatial autocorrelation between the typical overflow manholes in this area from a global perspective although there is a strong spatial autocorrelation between overflow manholes from a global perspective we would like to obtain additional details fig 7 shows the local spatial correlations of 36 overflow manholes under four separate storm events the local spatial autocorrelation scatterplot is divided into four quadrants the high high cluster hh the low low cluster ll and the random regions i e the low high cluster lh and the high low cluster hl by analyzing the scatter plot which manholes that present hh ll clustering in local space can be determined including their proportion and distribution in global space and local changes in different scenarios for example fig 7 a shows that there are 24 manholes in the hh and ll accounting for 66 67 of the total manholes with the increase in rainfall intensity some manholes were transferred from random regions lh or hl to cluster regions hh or ll the rainfall intensity of r16 8 has increased compared with r16 3 table 3 the number of manholes in the cluster regions lh or hl increased to 28 accounting for 77 78 of the total manholes among them the hh added 3 manholes and the ll increased 1 manhole the reason for the change may be that with the increase in rainfall intensity the overflow of manholes increases continuously resulting in a strong spatial correlation between manholes that had no spatial correlation before regardless of the perspective of global space or from the analysis of local space when flood simulation is based on an urban drainage system there is a strong spatial autocorrelation between overflow manholes therefore the uncertainty caused by its spatial effect needs to be considered when conducting mlsm 4 2 training and implementation of annsl oh and annsl mo a total of 116 storm event samples are used in the training process of the genetic algorithm ga to optimize annsl oh and annsl mo and 29 samples are used to select the models with optimal parameters the hyperparameter settings in the model training process are shown in table 4 the epochs of annsl oh and annsl mo are both set to 100 the epochs ga epochs of the respective ga are set to 200 and 300 respectively the population size of the ga ga npop is set to 100 the crossover rate ga cross is set to 0 9 and the mutation rate ga mut is set to 0 01 throughout the training process the mean absolute error mae is used as the objective function to find the initial weights and biases that performs best on the validation set the mae and mean square error mse of the model training and validation process are shown in table 5 the two anns ann oh and ann mo in the table are traditional models that do not introduce the spatial lag w i j s u r r o u n d y and are used for comparative analysis with annsl oh and annsl mo obviously the mae and mse of annsl oh and annsl mo considering the spatial autocorrelation are significantly lower than those of the traditional ann model fig 8 shows the change in the minimum mae of the two classes of models during ga based training the horizontal axis of the graph represents the number of iterations of a ga and the vertical axis represents the minimum mae of the objective function by observing the evolution process of annsl oh in the stage 1 see fig 8 a it can be found that the performance of the traditional ann ann oh validation and annsl oh validation in the validation set is basically the same in the stage 2 the mae of both show a downward trend and they are increasingly fitted to the performance of annsl oh on the training set annsl oh train the reason may be that the effect of optimizing the initial weights and biases is greater than the effect of introducing w i j s u r r o u n d y in this stage in the stage 3 the performance of annsl oh validation approaches that of annsl oh train while the mae of ann oh validation hardly drops the reason for this change is that the effect of introducing w i j s u r r o u n d y is greater than the effect of the ga that is the ga can no longer help the ann further reduce the error from the aspect of model parameter optimization at this stage while the ann introducing w i j s u r r o u n d y can make the mae continue to decrease with the increase in iterations to improve the fitting degree of the model similarly fig 8 b shows the same change trend for annsl mo the evolutionary hydrograph show that the error of the anns considering the spatial autocorrelation is smaller than that of the traditional anns whether it forecasts the maximum overflow or the entire overflow process the performance of the model in response to new storm events is discussed further in the following subsections 4 3 forecasting maximum overflow with annsl mo during storm events the maximum overflow of typical overflow manholes within the uds is one of the most concerning pieces of information which helps local government staff to quickly implement emergency flooding control measures for specific areas here 36 typical overflow manholes were selected for annsl mo based emulation and compared with the swmm simulation results fig 9 shows the distribution of the local spatial autocorrelation of 36 manholes j3 j38 within the uds the manholes show hh ll and the random regions lh and hl in space under separate storm events which affect the forecasting results of annsl mo to varying degrees for example both j7 and j16 showed ll with surrounding manholes under the storm events of r11 and r13 respectively see fig 9 a and b annsl mo successfully captured their spatial autocorrelation and the forecasting results were close to swmm see table 6 however under the storm event of r16 due to the obvious weakening of the rainfall intensity both j7 and j16 no longer exhibit spatial autocorrelation with the surrounding manholes see fig 9 c resulting in similar forecasting results of annsl mo and ann mo and a certain gap with the forecasting results of swmm see table 6 in addition j20 and j38 exhibited the spatial autocorrelation of ll under the three storm events and the forecasting results of annsl mo were closer to swmm than ann mo j25 j26 and j34 all showed the spatial autocorrelation of hh under the three storm events and the forecasting result of annsl mo was closer to swmm than that of ann mo d tre in table 6 refers to the difference in the total relative error of the forecasting results of annsl mo and ann mo obviously annsl mo not only learns from the data but also captures the spatial autocorrelation expressed by overflow manholes from the data effectively fig 10 shows the maximum overflow of 36 manholes j3 j38 emulated by annsl mo and swmm under the three rainfall events among them fig 10 a and d are the emulation results of the r11 storm event and the coefficient of determination r2 is 0 9814 fig 10 b and e are the emulation results of the r13 storm event and r2 is 0 9643 fig 10 c and f show the emulation results of the r16 storm events with an r2 of 0 9573 the r2 of ann is above 0 95 under the three storm events annsl mo exhibits excellent forecasting ability for swmm 4 4 forecasting overflow hydrographs with annsl oh the overflow hydrographs of manholes provide more complete flooding information in the time distribution which is helpful to analyze the trend of overflow in real time this information can guide the integrated management of urban floods and improve the ability of cities to cope with flooding risk here 6 manholes were selected from 36 typical manholes and their overflow hydrographs were subjected to annsl oh emulation under the three storm events the overflow of manholes at each time step can be viewed as a forecasting of the maximum overflow section 4 1 is sufficient to illustrate the need to consider spatial autocorrelations therefore the comparative analysis with traditional ann is not carried out again in this section annsl oh was directly compared with the swmm simulation results and evaluated using r2 fig 11 shows the overflow hydrographs for 6 manholes the r2 of annsl oh to swmm is above 0 9 under the three storm events specifically because j7 and j16 did not show spatial autocorrelation under the r16 storm event the r2 was lower than that of the other two storm events the other manholes all showed spatial autocorrelation of different natures and degrees under the three storm events and the r2 was basically above 0 95 5 discussions and limitations recently researchers have focused on further improving the performance of machine learning based surrogate modeling mlsm from different perspectives such as new models model optimization and data augmentation this progress makes surrogate modeling increasingly suitable for a variety of applications concerning uds flooding forecasting multiobjective optimization uncertainty analysis etc this study focuses on the spatial autocorrelation effect that occurs during uds simulations the experimental results show that the ann with the introduction of spatial lag can correctly capture the spatial autocorrelation mechanism of uds from the output data of the physically based model and has lower training and testing errors than the traditional ann model in the face of new storm events it can also be close to the simulation results of the physically based model showing excellent forecasting ability however this study still has limitations mainly in the following four points 1 due to the limitations of the physical mechanism itself the performance of ann can only get close as possible to swmm 2 due to the lack of measured data the simulation results of swmm cannot be calibrated in this study the influence of uncertainty generated by swmm on the spatial autocorrelation cannot be quantified and discussed 3 there is a lack of a set of benchmark uds for testing the performance of new mlsms garzón et al 2022 first this lack of benchmarks hinders comparisons between mlsms across studies second new surrogate modeling approaches are still lacking studies of how the model changes with the complexity of the uds for this study a set of benchmark udss is needed to explore the influence of spatial autocorrelation in udss of different characteristics e g scale topology slope 4 the data driven emulation based on uds is still for a specific point group and cannot fully express the spatial characteristics of the entire study area spatial autocorrelation may be more pronounced in 2d flooding emulations overall we suggest that future mlsm should integrate physically based and machine learning based approaches this integration will enhance the mlsm s description of the spatiotemporal dependencies among interacting geographic factors making the mlsm not only adaptable to data but also more able to capture the spatiotemporal evolution mechanism of processes from data despite the necessary and yet to implemented further developments listed above the proposed model can be seen as a step toward the realization of mlsms that capture spatial mechanisms 6 conclusions and future steps in this study a data driven surrogate modeling method introducing spatial lag is proposed and two types of anns are constructed based on the method to forecast the maximum overflow and overflow hydrographs of manholes within the uds the main contributions of this study are summarized as follows 1 in combination with the idea of spatial autoregression this study introduces the spatial lag into the ann training process and the error of the ann trained with 145 storm events is significantly lower than that of the traditional ann 2 the three storm events to test the forecasting ability of the trained ann for the maximum overflow and overflow hydrograph of typical overflow manholes and compared with the swmm simulation results both r2 values are above 0 9 proving the excellent forecasting ability nevertheless the following aspects need to be improved in future work for example coupling with 2d flooding forecasting models may be considered in the future to provide spatially more comprehensive spatial information second from the model perspective it is necessary to introduce more physical mechanisms into data driven models to alleviate data dependencies in addition we will conduct more comprehensive research on this basis including uncertainty analysis of physically based models and validation based on measured sites to be more reliable data and code availability repositories title ga ann for uds developer heng li contact address lh mygis 163 com source code and data available https github com lhmygis ga ann for uds language python questions and bugs reports should be submitted using that website or e mailed to the corresponding author declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the national natural science foundation of china no 42077438 and the fundamental research funds for the central universities no 2652018082 this work was supported by the national natural science foundation of china no 61872325 62172373 the data support from the nanchong meteorological bureau is gratefully acknowledged given their roles as environmental modelling software editor min chen was not involved in the peer review of this article and has no access to information regarding its peer review full responsibility for the editorial process for this article was delegated to journal editor dr daniel p ames 
25443,in ocean modelling systems transfer of information is typically from regional domain rd to local domain ld one way and where there is an advantage in upscaling the ld into the rd two way both domains are run at the same time transferring information online resulting in two way nesting systems this article develops an offline relaxation based upscaling approach enabling the upscaling of several lds simultaneously run by different institutions or modelling tools at the same time as the rd is improved with the best available local knowledge the approach is applied to the tagus region of freshwater influence portugal where incremental upscaling simulations are tested compared to the traditional downscaling approach and validated against field data results show smoother solutions with upscaling particularly at the boundaries between domains where a less restricted estuarine plume significantly improved the surface salinity patterns at both sides of the boundary during an extreme precipitation event keywords upscaling offline coupling tagus rofi two way data availability data will be made available on request 1 software the 3d mohid water model was first developed in 1985 and the current version is programmed in ansi fortran 95 using the object oriented philosophy the code size is 22 mb and is a free open access software developed and maintained in github https github com mohid water modelling system mohid more information on the software can be consulted in http mohid com 2 introduction nowadays the study of currents ecological processes and sediment dynamics in coastal areas is impossible without the use of numerical models constrained by field data for validation and for identification of the processes which need to be represented by the model these numerical models are essential tools for hindcast as well as for forecasting ocean variables such as currents nutrients chlorophyll waves or sediment concentrations hindcast is essential for model validation and for identification of processes and loads responsible for current ocean state while short term forecasting up to 7 days for safety of people and infrastructure e g in the case of overtopping and flooding in case of extreme events the evolution of modelled variables are particularly important in the context of climate change for management policies of municipalities and countries located in coastal areas especially as regards coastal erosion processes sea level rise or fisheries policies duong et al 2016 fox kemper et al 2019 plagányi and fulton 2017 traditionally the communication between model domains developed for structured grids which consists of a set of rows columns and vertical layers where the location of nodes in the physical space directly maps to their location in the program data array is done via a downscaling approach in which the regional domain rd provides open boundary conditions henceforth obc to one or multiple nested local domains ld one way nesting downscaling is necessary because direct local refinement of structured grids required to describe highly variable bathymetries found in coastal areas is difficult using downscaling a modeller can at any time implement additional lds forced by the rd to study new areas of interest without the need to create a new rd grid avoiding extra effort and saving simulation time however when the nested model domains run online all domains running at the same time and sharing information at every time iteration the overall simulation time becomes the sum of the lds and rd simulation times if run serial mode or the sum of the slowest ld plus the rd if the lds are run in parallel which presents a scalability problem for large areas with many lds making the use of ordinary servers difficult particularly for operational modelling systems that need to provide forecasts in a timely fashion offline downscaling approach can be a solution for this problem since in this approach the lds run separately from the rd and lds obc are obtained from rd output files allowing the simulation of several lds using a common rd output campuzano et al 2012 mason et al 2010 regardless of the approach in one way communication systems the rd does not take advantage of the more accurate representation of hydrodynamic and biogeochemical processes simulated by its nested lds given the structured grid disability to refine specific areas of a rd in an efficient manner the solution is to add an upscaling stage to these nested systems where information is also transferred from the ld to the rd using two way communication when communication is carried in runtime the same model application must be used to simulate the rd and the lds and the methodology is designated by two way nesting that has all the inconveniences described above for the online one way nesting described above the alternative proposed in this paper is the use of offline upscaling where rd and lds run in different computers and eventually using different models in different institutions and the solution of the lds is assimilated by the rd using a relaxation method upscaling of lds into rds aims to reduce the numerical diffusion associated with the lower grid resolution of the rds and enable the feedback of small scale processes not simulated by a rd as is the case of estuarine and lagoon tidal inlets of even the effect of current wave interaction in coastal areas upscaling can also be used to transfer to the regional model more detailed information of boundary conditions as is the case of local sources of nutrients from aquaculture systems or change the flow due to offshore energy systems such as underwater turbines calculated from high resolution lds by improving the rd one is implicitly transferring information between lds improving solutions of the lds used by local entities this is important for many modelling fields from the study of biological processes to morphodynamics in coastal systems such as estuaries that depend on other systems not included in a specific ld such as in ribeiro et al 2016 and oliveira et al 2021 there are currently three main methodologies for upscaling nudging of the rd is towards the lds barth et al 2005 sannino et al 2009 sobrinho et al 2021 teles machado et al 2016 spectral nudging including the technique described in sheng et al 2005 and applied in urrego blanco and sheng 2014 and urrego blanco et al 2016 and through data assimilation techniques barth et al 2007 vandenbulcke and barth 2019 for a more extensive review on the two way coupling its methods advantages and drawbacks the user is referred to the reviews of debreu et al 2008 debreu et al 2012 herzfeld and rizwi 2019 klingbeil et al 2018 and schulz stellenfleth 2016 however even though online two way simulations produce better results holt et al 2017 all domains must be operated by the same modeller its computational time cost is higher because it renders unusable the offline downscaling methodology and similarly to the online downscaling issues previously discussed removes any chance of using upscaling in operational forecast modelling as such a similar approach to that followed by offline one way systems should be considered in which the rd and the lds run separately from one another doing so a ld can receive its obc from one rd offline downscaling and its results can be upscaled by a different rd produced by a different institution for example a rd run by institution a covering the iberian peninsula could provide obc for a local estuary domain in portugal run by institution b and that estuary domain could be upscaled to a rd run by institution c as in a similar process suggested in caldeira et al 2016 in such an approach the lds are used in a similar fashion to the offline downscaling where the obc applied to a rd running with model a are provided by a global solution such as the ones in the copernicus marine service cmems running with model b additionally the models can be run in separate computers which enable these simulations in simpler it infrastructures as is the case of the institution where the results presented in this article were produced offline two way communication became a recent research subject due to the advantages for operational modelling with some applications being published recently herzfeld and rizwi 2019 applied the offline two way nesting to the great barrier reef where the transfer of information is done via model output files and vandenbulcke and barth et al 2019 which used an assimilation technique to upscale temperature and salinity fields from a ld covering the north western basin of the mediterranean sea and a rd covering the entire mediterranean the present study is the result of a continuous effort sobrinho et al 2021 to incorporate an upscaling capability in the 3d mohid water hereafter mohid modelling system in which we develop a methodology for offline upscaling based on the relaxation of a rd to one or multiple lds the methodology follows the online algorithm presented in sobrinho et al 2021 and extends if to run offline using hdf or netcdf ld output files in the online method information is transferred between domains at every time step while in the offline approach the period depends on the output frequency of the ld 15 min in the case presented here another difference is that in the online simulation the ld immediately gets updated information from the rd while in the offline approach it gets new info only once a day this is consistent with the overall operational modelling approach where simulations are repeated every day using new meteorological forecasts and eventually new global ocean model forecasts the number of times one day is simulated is usually imposed by the meteorological forecasts and usually varies between 3 and 7 the larger is the number of repetitions the higher is the accuracy another advantage of this methodology is that it enables the upscaling of specific parts of each ld only the methodology proposed is applied to the nested system comprised of the portuguese coast operational modelling system pcoms rd and the tagus rofi model domain tagus rofi ld during the extreme flood event of march april of 2013 results provided are compared against surface elevation and salinity field data measured by a fix buoy and with results of a traditional one way downscaling approach results using one and two upscaling iterations in this case measured in days were compared to estimate the impact of increasing grid communication frequency the comparisons showed that the offline two way coupling improved a lot the solution in the rofi area up to the north western open boundary of the ld which is most affected by the estuarine plume demonstrating the potential of this approach for the upscaling the results also show that two simulations of the same day are enough to get acceptable solutions and that this method is adequate for operational models that produce daily forecasts 3 days ahead this article focusses on validation of the upscaling methodology and on its ability to improve the rd solution using the ld to impose the tagus river discharge in the rd detailed information regarding the upscaling methodologies mentioned in this article as well as a variety of schematic tests performed to analyse conservation and stability of the solutions can be found in sobrinho 2021 3 materials and methods in this work we use the mohid model developed at maretec ist university of lisbon for arakawa c staggered grids where velocity components are computed over the faces of the scalars control volume as are the advective and diffusive fluxes the model is a 3d finite volume model which solves the 3d incompressible primitive equations leitão 2002 leitão et al 2005 martins et al 1998 2001 whose numerical code follows an object oriented philosophy braunschweig et al 2004 the model assumes hydrostatic equilibrium and partially the boussinesq approximation the density applied in the horizontal momentum equations varies in time and space although the momentum fluxes per unit of mass are calculated null velocity divergence is also considered 1 u i x i 0 where u i are the three velocity components integrating the along the water column between the bottom h and a depth z the vertical velocity at that level is derived 2 u 3 x 3 z x 1 h z u 1 d x 3 x 2 h z u 2 d x 3 h z q d x 3 where q represents water sources such as rivers or local wastewater discharges integrating this equation up to the free surface one obtains the free surface elevation η rate of change 3 η t x 1 h η u 1 d x 3 x 2 h η u 2 d x 3 h η q d x 3 in this equation q also includes rain and evaporation calculated at the free surface applying the hydrostatic approximation the vertical momentum equation is obtained 4 p x 3 ρ g which integrated over the water column between the free surface and a depth z results in 5 p x 3 z p a t m z η ρ g d x 3 the derivative of this equation along the horizontal axis produces the pressure gradient 6 p x i x 3 z p a t m x i g ρ x 3 η η x i g z η ρ x i d x 3 finally the horizontal momentum equations can be written as 7 ρ u 1 t u 1 u j x j f u 2 p a t m x 1 g ρ x 3 η η x 1 g z η ρ x 1 d z x j μ u 1 x j 8 ρ u 2 t u 2 u j x j f u 1 p a t m x 2 g ρ x 3 η η x 2 g z η ρ x 2 d z x j μ u 2 x j where f and μ represent the coriolis parameter a parallel line to the surface elevation and the turbulent viscosity respectively the mohid model is also capable of solving the non hydrostatic pressure component but that would require extra computing power and with little effect to the purpose of this article temporal discretization of the equations is done using a semi implicit scheme alternating direction implicit adi where two time levels per iteration are used the numerical schemes available for use in mohid include the abbot s 4 equations system abbott et al 1973 where the surface elevation is calculated at each half model time step and the velocities at each time step and the leendertse s 6 equations system leendertse 1967 in which the water level and the velocities are computed at half time step currently the default option in mohid is the latter and is the one used in this work tracer properties such as temperature and salinity are computed using the fluxes derived from the hydrodynamic fluxes and viscosities 9 p t p u i x i x i μ p x i s p i 1 2 3 where sp stands for sink sources of the property p in question horizontal and vertical advection are computed using the tvd advection scheme a combination of a high order scheme in the case of mohid a hybrid between 1st and 3rd order upwind schemes with a flux limiter superbee roe 2003 which is found to reduce spurious oscillations generated from shocks discontinuities or sharp changes in bathymetry at the bottom advective fluxes are imposed as null and diffusive flux of momentum is estimated by means of a bottom stress calculated by a non slip method with a quadratic law that depends on the near bottom velocity so the diffusive term at the bottom is written as 10 v v h z b o t t o m c d v h v h cd is the bottom drag coefficient that is calculated with the expression 11 c d k log z z 0 b z 0 b 2 where z is the distance to bottom κ is the von karman constant and z 0 b is the bottom roughness length this quadratic law is derived from the logarithmic law of the wall near boundaries characteristic of boundary layers as the bottom velocities are located half a grid box above the bottom this term is calculated semi implicitly following backhaus 1985 for the sake of numerical stability at the lateral closed boundaries an impermeable free slip condition is used applying zero normal water fluxes and zero momentum diffusive fluxes at the cells in contact with land at the surface wind stress is calculated according to a quadratic friction law 12 t w c d ρ a w w where c d is a drag coefficient that is function of the wind speed ρ a is air density and w is the wind speed at a height of 10 m over the sea surface 13 c d 1 14 e 3 w 10 m s 14 c d 4 4 e 4 6 5 e 5 w w 10 m s w 26 m s for more information on the model description the user is referred to the mohid description maretec 2007 3 1 upscaling algorithm the upscaling algorithm implemented in mohid model system is fully described in sobrinho et al 2021 and is based on the work of oey and chen 1992 and fox and maskell 1995 the algorithm considers the nudging of a child domain s ld velocities temperature and salinity fields by a parent domain rd and good results with minimum error production were obtained for online simulations of nested domains sobrinho et al 2021 the overlaying concept behind the offline upscaling algorithm is the nudging of the rd solution towards the ld solutions provided externally via the hdf files using a relaxation algorithm ld results are volume integrated and averaged into the rd model grid cells using the software routines already developed for the two way online coupling in sobrinho et al 2021 in order to optimise the code connection matrixes between ld cells and rd cells are built in the first model iteration and stored in memory as described in sobrinho et al 2021 the main difference between online and offline is data collection in regard to parametrizations the user can choose the upscaling time decay for relaxation henceforth utd and the number of ld line columns next to the open boundary to be ignored additionally in the case of multiple lds the user must also specify an id for the ld horizontal velocities are always upscaled other properties to be upscaled must be specified by the user when offline upscaling is used mohid equations 7 and 8 for the rd became as follow 15 ρ u 1 t u 1 u j x j f u 2 p a t m x 1 g ρ x 3 η η x 1 g z η ρ x 1 d z x j μ u 1 x j ρ u 1 u 1 l d u t d 16 u 1 l d u 1 i l d ϖ d r v i l d ϖ r d v r d 17 p t p u i x i x i v p x i s p p p l d u t d where u 1 l d and p l d stand respectively for the volume weighted average of velocity component along x 1 and tracer property to be imposed in rd cells respectively v r d is the regional domain cell volume and u i l d ϖ d r and v i l d ϖ r d represent corresponding ld cell velocity and volume respectively that are contained inside the rd cell utd stands for the relaxation time for upscaling in this formulation the total momentum inside the ld cells included inside a rd cell is transferred to the rd and the velocity is modified having in consideration the ratio between the ld volume and the rd volume imposing the average velocity would be equivalent to impose artificial forces and would result into artificial water fluxes and consequent artificial free surface changes on the contrary scalars are imposed per unit of volume temperature salinity this implies no mass heat conservation but the aim of the upscaling is to correct errors of the calculation of those properties due to low resolution or to bad boundary conditions imposed in the regional model 3 1 1 management of the land interface between local domains and the regional domain small estuaries and coastal lagoons are often treated by the rd as land because the spatial step is too large to describe them in tidal systems those areas are responsible for tidal flow and mixing of fresh and salt water and high oscillatory discharges of volume momentum and other properties at the mouth of the ld can occur which generate oscillatory momentum fluxes at the border of the rd those discharges are imposed at the boundary of the rd together with nudging inside the domain to avoid instabilities near inlets in the offline coupling the ld results are available from the second simulation of a given day onwards and discharges are computed by the upscaling algorithm at each time step assimilating ld velocities into the rd domain without including these discharges would generate a reflected wave at the boundary with too high water levels during flood and too low water levels during ebb fig 1 illustrates a grid nesting with a 1 3 ratio the dashed line shows the ld grid and the ld velocity points and two rd cells the blue with water and grey on land in an area where the ld domain has water for simplicity only two cells are shown on land the amplitude of the reflected wave increases with the number of cells 3 1 2 time interpolation and communication between grids fig 2 illustrates communication between grids in online two way coupling fig 2 left grids communicate at each ld time step in downscaling procedures and at each rd time step in the upscaling procedures in the offline simulations fig 2 rigtht interaction is done at the end of the simulations the figure shows the case of a 3 day forecast repeated every day and producing daily outputs in this case each day will be forecasted 3 times and each new simulation adds a period of one day to the previous simulation in every simulation there are no ld results to be upscaled in the last simulated day these results will be discarded and consequently any solution that assures stability is good in our case we have considered no upscaling on day 3 the stability of the system increases with the distance between the ld open boundary where rd results are injected into the ld and the region where the closed boundary of the rd is being opened using the ld results the rd model is the first to run on day 0 it simulates up to the end day 2 using no ld results upscaling and creating 3 daily output files after this simulation the ld domain runs for the same 3 days downscaling the rd results through its open boundary and also creates 3 output files one for each day then the rd performs a new simulation starting at day 1 and finishing at day 3 upscaling ld results for 2 days and then the procedure is repeated every day the stability is independent of the number of the days simulated depends only on the duration of the period with no upscaling and of the distance between the borders of the two models referred above however the accuracy of the results is expected to increase with the number of repetitions of a simulation this can be achieved increasing the number of days simulated or decreasing the time between simulations e g 6 h instead of 1 day only daily simulations were tested because our operational modelling system is prepared to run once a day simulating four days one in hindcast mode and 3 in forecast mode to feed the solution with the latest available meteorological and obc from regional and global ocean domains consequently each day is simulated 4 times by each model domain using downscaling only or using upscaling as such shifting an operational forecasting system from an offline downscaling approach to an offline two way approach is computationally nearly free of charge from a regional modelling system perspective upscaling from local domains offline upscaling would allow the upscaling of multiple solutions provided by different entities and models which would improve the solutions provided by these regional modelling solutions with higher resolution information near the coasts and with local knowledge 4 the pcoms tagus rofi nested modelling system the mohid model was used to simulate the tagus rofi during an extreme precipitation event that occurred in march april 2013 and led to a tagus flow rate of around 7500 m3s 1 about 30 times the average flow rate 258 m3s 1 a nested grid configuration in both offline one way and offline two way formulations was used and results are compared among them and with results of sobrinho 2021 obtained using an online simulation and the same boundary conditions and parameterization the one way offline downscaling approach is performed because online downscaling produces slightly different results than offline downscaling due to differences in the obc produced by the latter lower frequency transfer of information from rd to ld in the offline simulation information is transferred every 15 min instead of every time step as previously discussed in the offline upscaling the simulation time necessary to reach the solution increases when the frequency of information transfer between ld to rd decreases in this test information is transferred daily to compare the sensitivity of the results to the number of days simulated two simulations were done in one the duration of each simulation was two days and consequently each domain was simulated twice exchanging information once a day in this scenario results of the ld can be upscaled for only one day in each simulation on the other simulation three days were simulated and results for 2 days can be upscaled in each simulation results show that two days upscaling improved the solution reducing the gap between measured and simulated salinity values increasing the number of simulated days would still improve the results but two days of upscaling was considered good enough with the advantage that this scenario did not imply any modifications in our operational framework the validation of model results is performed using data measured at points shown in fig 3 free surface levels are measured in cascais ctg station vertical profiles of temperature and salinity are available at stations ctd p1 p2 and p3 comparisons refer to the entire period of simulation january 15 to april 10 with a focus on the peak flow period 25 march to 10 april 4 1 model setup 4 1 1 grid communication management offline simulations need pre processing and post processing operations to manage files used to communicate between domains while the parameterizations and obc are quite similar identical file management is already included in operational forecast modelling systems which require periodical 1 update of the simulation period and 2 downloading of obc files necessary to extract input data and 3 copying and renaming of input files required and output files produced for every simulation these pre and post processing operations are managed by a separate tool art campuzano et al 2012 the system was updated to perform the new offline upscaling procedures in case of a 3 day simulation as shown in fig 2 each model generates 3 output files one per day this allows the two models to run simultaneously for two days when the rd completes day 1 simulation the ld can start its day 1 simulation while the rd runs its day 2 simulation this procedure continues up to the last simulation day when the procedure is reinitiated on the next day both models completed the simulation of the same period and everything is ready to initiate the next set of simulations in normal operational mode the models run every day and the time needed to simulate one day is a few hours this assures that when the next simulation starts all files are ready however in case something gets wrong with one simulation or when we run the model in hindcast mode it can happen that when a model wants to start some files can be missing to manage this possibility a trigger system has been implemented consisting of simple text files containing the simulation period to which the output files refer and a keyword that states the current status of the simulation running or finished with this system in place the rd domain wanting to run the first day for the second simulation will wait for the finished status of the trigger file produced by the ld for that same day the ld trigger was already in place because it the one way nesting it needs the most recent output from the rd the last day of a rd run cannot perform upscaling because it is ahead in time see fig 2 the former approach is feasible if both models run in the same network sharing the triggers if the ld and the rd models run in different institutions sharing triggers is not feasible and an exception was introduced directly in the mohid code activated by the user now the code performs the search for all upscaling files specified by the user and if the files are not present in the location the user specified then the upscaling of those files is disabled and the regional domain will still work ignoring the upscaling of that ld and upscaling any other existing domains this methodology attempts to provide scientists and modellers involved with the modelling of coastal areas with a robust tool that can improve a rd with the information provided by multiple local modelling domains the procedure developed can be easily implemented in other modelling systems 4 1 2 implementation setup the modelling system is comprised of two nested domains fig 3 1 3d full baroclinic regional domain for the portuguese coast level 2 fig 3a 34 4⁰ n 45 0⁰ n and 12 6⁰ w 5 5⁰ w with a grid resolution of 5 7 km and 50 vertical layers 7 sigma at the surface and 43 cartesian below 2 3d full baroclinic domain for the tagus rofi level 3 fig 3b and adjacent coastal area with a variable grid from 2 km to 200 m 38 15⁰n 39 2⁰n 10⁰w 8 9w and 50 vertical layers 7 sigma at the surface and 43 cartesian below the tide level imposed to the rd is extracted from a 2d barotropic model encompassing the rd shown on fig 3 this model is forced using tidal harmonics from fes2004 lefèvre et al 2002 lyard et al 2006 a flather 1976 radiation scheme was applied to water level at the open boundary of pcoms followed by a flow relaxation scheme martinsen and engedahl 1987 frs to the mercator solution following the work of leitão et al 2005 in this setup the frs means an exponential decreasing relaxation coefficient along the 10 numerical cells of pcoms closer to the open boundary with a relaxation time of 105 s in the first open boundary cell and 109 s from the 10th cell inwards additionally a biharmonic filter of 5 5 109 m4s 1 is applied to reduce high frequency noise inside the domain tagus rofi domain is forced by pcoms at the lateral open boundary using the flather radiation scheme and a 10 cell frs with 900 s at the first cell to 109 s from the 10th cell inwards for velocities temperature and salinity the temperature and salinity open boundary condition is adaptative i e passive for inflow and active for outflow a biharmonic filter of 2 7e6 m4s 1 was applied a full description of the first two domains running in one way operationally in maretec is available in mateus et al 2012 and a description of the tagus rofi domain one way is described in campuzano et al 2012 and in de pablo et al 2019 the model setup configurations used in the systems for two way simulations is summarized in table 1 the relaxation time for upscaling utd was based on the previous work by sobrinho et al sobrinho 2021 this time must be short to accommodate issues with tide which requires a lower time decay while baroclinic velocities temperature and salinity could have higher lower utd values for an analysis of the decay term value the reader is referred to sobrinho 2021 in this article the upscaling stage of the coupling is performed using daily output files this low frequency of communication between models is possible because of the radiative obc used in the ld otherwise data should be exchanged more frequently 4 2 results a comparison between the three offline implementations is shown in the next sections and includes the traditional one way offline downscaling approach the new downscaling upscaling offline two way with one upscaling 1 day and two upscaling 2 days i e runs 2 day long and 3 day long the objective is to understand and quantify the effect of the number of upscaling iterations on the regional pcoms model 4 2 1 water level validation water level results obtained by the model implementations pcoms and tagus rofi under the three different parametrizations were compared with the cascais tide gauge data available for the period between january 15 and march 13 2013 pcoms fig 4 tagus rofi fig 5 this period does not include the tagus river freshwater flow peak used for the validation of surface salinity the figures show a direct comparisons between the water level obtained by the models and field data b a comparison between the bias of the three implementations and c the correlation between model and field data upscaling the tagus rofi domain into pcoms does not bring any visible changes on water levels except on the statistical parameters however results show a good agreement with the tide gauge data which means that at least in this coastal area close to the mouth of the estuary where local bathymetry and the estuary discharge play important roles the model domains can represent tidal variability also a statistical analysis including bias rmse and pearson correlation coefficient table 2 suggest overall that solutions are very similar in pcoms a small increase of the mean bias is verified for upscaling 1 day from 4 02 mm to 4 09 mm although with a reduction in the median bias from 2 21 mm to 1 84 mm rmse values diminish when upscaling is done for both upscaling 1 day and upscaling 2 days implementations from 0 0739 obtained by the offline one way downscaling to 0 0710 and 0 0724 obtained for upscaling 1 day and upscaling 2 days respectively as for the correlation values all implementations show the same good agreement with the tide gauge however when two days with upscaling are used some metrics are reverted median bias for example increases from 1 84 mm to 2 24 mm the implementation with only downscaling produced a value of 2 21 mm whereas rmse values although smaller than when using only downscaling increase from 0 071 to 0 0724 using one or two days of upscaling respectively once again correlation and nash values remain identical in all implementations regarding tagus rofi the same analysis can be made about the mean and median bias values however rmse values obtained by the offline two way system whether running the same day once or twice with upscaling are higher from 0 068 obtained by the offline one way system to 0 069 and 0 071 respectively the same pearson correlation coefficient and nash parameters were obtained by all implementations this analysis shows that all model applications performed quite well when compared with the tidal gauge data with very small differences between them which means that there is no significant degradation of any of the solutions during this period however the major impact of these implementations is not expected to occur neither in water level nor in the vicinity of the tagus rofi but in the interior of the domain and especially near the open boundaries of tagus rofi 4 2 2 surface salinity validation surface salinity obtained by tagus rofi under the three implementations was compared against field data from the moored buoy located near the mouth of the tagus rofi for the period of january 15 to april 10 fig 6 results demonstrate the model ability to reproduce the salinity variability over time especially during the peak flow event at the end of march beginning of april this peak flow is represented in grey in fig 6 and shows the extreme flow rate registered at the time which eventually submerged the buoy stopping the data acquisition of salinity during part of the event there are no significant differences between salinity obtained by the different implementations much due to the location of the buoy which is in a place dominated by the estuary s salinity plume and as such will have little impact from the changes occurring at the tagus rofi open boundary as observed in the water level there is a slight increase in model error in the upscaling 2 days implementation although with a small advantage of the upscaling 1 day implementation over the downscaling however and like in the water level comparisons the statistical parameters table 3 suggest that the model accuracy obtained by all implementations is hardly affected by using upscaling near the estuary mouth 4 2 3 salinity transition at the open boundary as mentioned above the major changes of surface salinity are expected to occur near the tagus rofi open boundaries where the gradient between pcoms and tagus rofi running in one way offline mode are highest and not near the estuary mouth a comparison of surface salinity time series extracted from both pcoms and tagus rofi is shown in fig 7 for the period between january 15 and april 10 at the location ts sal shown in fig 3 fig 7 shows results for the ld the tagus rofi on the bottom and of pcoms on the top on the left the figure show the whole period and on the right the figure shows a zoom for the high freshwater discharge event putting into evidence the differences between the results in the one way downscaling pcoms solution does not show the estuarine plume and the rofi ld model shows minimum salinities of about 32 using upscaling the pcoms model shows the estuarine plume and the rofi model shows much more freshwater and lower salinities minimum values decreased from 32 to 28 setting 3 days simulation upscaling is repeated twice improves the solution obtained with a single day of upscaling by about 0 5 that is expected to be of the order of the error induced by the uncertainty of the freshwater discharge rate improvement of the one way downscaling happened because in this scenario numerical diffusion destroys the rofi in the pcoms simulation and consequently when the water flows from the rd into the ld it flows with a salinity higher that the real increasing the salinity on the ld in the upscaling 1 day and upscaling 2 days implementations when the flow direction changes from northwards to southwards the salinity values provided by pcoms which upscales salinity from tagus rofi is lower and better specified to the tagus rofi open boundary this phenomenon can be illustrated comparing the surface salinity field obtained with downscaling and upscaling implementations fig 8 shows the salinity field difference between downscaling and 1 day and 2 days upscaling for the period between 25 march and april 10 2013 when the flow is mostly northwards the results shows that major differences occur near the open boundaries with higher salinity values obtained when using downscaling methodology and in front of tagus mouth with lower values obtained when using downscaling methodology the reason for this is that when the downscaling methodology was used the tagus plume was not able to reach the open boundaries due to the imposed level 2 obc and was deviated further to south whereas with upscaling methodology the plume is able to move easily northwards because of thermohaline effect with a second day of upscaling upscaling 2 days these differences are higher 4 2 4 vertical profiles of temperature and salinity temperature and salinity profiles were extracted at the 3 locations shown in fig 3 lisbon canyon p1 western boundary of tagus rofi p2 and the northeast boundary of tagus rofi near the coastline p3 time series of surface salinity extracted from pcoms and tagus rofi discussed above showed the improvement of the solution when upscaling is used in this section the impact on temperature and salinity vertical profiles is assessed and compared with field data in fig 9 for the period of march 25 to april 10 which corresponds to the peak of freshwater flow to use comparable results tagus rofi fields were previously interpolated via simple average into the pcoms grid which means that some caution is advised when looking at the comparisons as the average partially distorts the results in areas were the grid resolution of pcoms is highest and near the coast as some pcoms cells are only partially covered by tagus rofi temperature results show that upscaling can influence the results up to 100 m depth in the lisbon canyon p1 and at the west open boundary of tagus rofi p2 at the north eastern boundary of tagus rofi p3 this influence is evident over the entire water column where an increase in temperature is observed when upscaling is used furthermore there is a tendency towards the reduction of temperature and salinity vertical profile differences between all model domains which is the aim of the method a slight 0 15 c temperature increase from the one way to the two way implementation running upscaling once per day was registered in p1 and p2 and negligible changes in p3 the two way implementation running upscaling twice per day generated temperature increase of 0 15 c 0 5 c and 0 2 c at stations p1 p2 and p3 respectively this is a consequence of both the changes in local currents shown in fig 10 promoted by improved density gradients in the pcoms domain the salinity decrease imposed by the tagus estuary domain increased the water level near the shore and drove the currents northward due to the coriolis force dragging northwards the warmer southern waters fig 10 salinity vertical profiles fig 9 demonstrate the increased nudging effect between pcoms and tagus rofi domains when more runs per day with upscaling are performed another effect already visible in the surface salinity comparisons performed near the open boundary of tagus rofi is the lower surface salinity values obtained in the upscaling 2 days implementation when compared with the one way simulation this phenomenon is also visible at the west boundary of the tagus rofi domain p2 showing that upscaling effect extends beyond the area where the plume exerts direct influence as a consequence of density on the flow the largest improvement is obtained in pcoms salinity profiles in the results shown without upscaling the salinity is constant in time and vertically uniform while with upscaling physically realistic profiles consistent with the rofi profiles are generated the improvement extends from the surface up to 80 m with differences of up to 0 4 salinity units although these results are averages in time and include days with higher salinity differences this means that making a second iteration of the upscaling procedure does not bring many changes to the overall solution in operational modelling forecasts each day is simulated at least twice and very often 7 days and consequently upscaling will generate confident solutions 5 conclusion a new upscaling algorithm was developed and integrated in mohid this algorithm is now part of the offline upscaling methodology which enables a regional model to upscale multiple higher grid resolution domains local domains without the need for online nesting in the regional domain this new algorithm is suitable for operational forecast regional systems which can upscale local domains generated by several institutions doing conventional downscaling for example the pcoms regional model application would now be able to upscale from a tagus rofi model application developed and maintained by any institution and whose results are freely available this can be exported to any other location including the madeira and azores islands that have their own local models running and could provide better solutions for upscaling into an ocean scale model covering the entire portuguese zee one future source of information may be the cmems repository which does not yet hold results from such local domains through the offline upscaling methodology developed in this article regional cmems model application would be able to benefit from local models run by local institutions with local knowledge of their coastal areas a model implementation including pcoms and the tagus rofi model application was run for the same period 15 january to 10 april and validated using in situ data available including the cascais tide gauge and the surface salinity provided by the algés ctd this validation was successful in demonstrating the accuracy of the model as well as the new algorithm as the offline upscaling algorithm has a lower grid communication factor communication is done at the frequency equal to utd after one full day of simulation using daily results instead of for each time step two implementations were tested the first upscaling 1 day considered two model runs per day of simulation which include a first run without upscaling in pcoms as it is ahead of the tagus rofi domain and a second run but now with the upscaling of tagus rofi which performs a run after pcoms finishes its first run and followed by the second run of tagus rofi which now receives its obc from the updated version of pcoms the second upscaling 2 days considers an additional run of the same day in each model domain therefore performing two runs with upscaling results were compared with in situ data focusing on the northeast open boundary of tagus rofi where the greatest impact was expected due to the northward transport of the estuarine plume during rainy periods time series were compared at the surface as well as vertical salinity and temperature profiles comparisons highlighted the importance of upscaling the tagus estuary into the pcoms domain and have shown that one iteration upscaling 1 day has a great impact on the results although some additional improvement is obtained when a second run is performed applying the upscaling promoted a better representation of the circulation due to the salinity fields provided by pcoms and therefore improved the obc of tagus rofi increasing the amplitude of the temporal salinity variability the improvement of the pcoms solution outside the local domain is also essential to simulate the tagus rofi in its whole extension that goes beyond the local model domain contributing for a better representation of the western iberian buoyant plume wibp further north in the near future new tests must be performed upscaling rofis from other estuaries into pcoms this improvement is quite important for a regional model application covering the iberian peninsula as the lower salinities observed far from the mouth of the tagus estuary will be transported northwards during winter and spring and its plume can merge together with the plumes from other estuaries to produce the west iberian buoyant plume wibp as observed in campuzano 2018 it is however most relevant in large rofi areas subject to very high flow rates in these cases without upscaling the local model applications following the downscaling approach would need to be extremely large to properly represent the saline fronts generated by the large freshwater flow using upscaling local model applications can use smaller domains becoming more feasible for operational modelling purposes as small domains can still provide appropriate solutions another important aspect of the offline upscaling is its independence regarding simulation time of the local domains when operational forecast solutions are concerned in operational forecasting each day is run several times but usually between 3 and 7 times which means that the offline upscaling can be performed between 2 and 6 times for the same period without changing the overall simulation time this is an important improvement to the upscaling algorithm presented in sobrinho 2021 and will facilitate the integration of the method into operational modelling this work sets a good foundation for further developments and research in the offline upscaling procedure via nudging including the study of upscaling multiple lds into a rd or multiple rds into a global domain in regard to the upscaling impact of local solutions over a larger area of the rd not overlapped by the lds further validation using in situ and remote sensing data will provide a better insight on the parameterization of upscaling decay term to be used and the frequency of upscaling communication which in this article is 1 day higher frequencies should be tested to account for implications on tide propagation funding the present work was supported by fct mctes piddac through the project larsys fct pluriannual funding 2020 2023 uidb 50009 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the portuguese hydrographic institute ih for kindly providing data on the water level in the study area special thanks to manuela juliano of the azores university for her valuable help in the scripts for comparison between surface model results 
25443,in ocean modelling systems transfer of information is typically from regional domain rd to local domain ld one way and where there is an advantage in upscaling the ld into the rd two way both domains are run at the same time transferring information online resulting in two way nesting systems this article develops an offline relaxation based upscaling approach enabling the upscaling of several lds simultaneously run by different institutions or modelling tools at the same time as the rd is improved with the best available local knowledge the approach is applied to the tagus region of freshwater influence portugal where incremental upscaling simulations are tested compared to the traditional downscaling approach and validated against field data results show smoother solutions with upscaling particularly at the boundaries between domains where a less restricted estuarine plume significantly improved the surface salinity patterns at both sides of the boundary during an extreme precipitation event keywords upscaling offline coupling tagus rofi two way data availability data will be made available on request 1 software the 3d mohid water model was first developed in 1985 and the current version is programmed in ansi fortran 95 using the object oriented philosophy the code size is 22 mb and is a free open access software developed and maintained in github https github com mohid water modelling system mohid more information on the software can be consulted in http mohid com 2 introduction nowadays the study of currents ecological processes and sediment dynamics in coastal areas is impossible without the use of numerical models constrained by field data for validation and for identification of the processes which need to be represented by the model these numerical models are essential tools for hindcast as well as for forecasting ocean variables such as currents nutrients chlorophyll waves or sediment concentrations hindcast is essential for model validation and for identification of processes and loads responsible for current ocean state while short term forecasting up to 7 days for safety of people and infrastructure e g in the case of overtopping and flooding in case of extreme events the evolution of modelled variables are particularly important in the context of climate change for management policies of municipalities and countries located in coastal areas especially as regards coastal erosion processes sea level rise or fisheries policies duong et al 2016 fox kemper et al 2019 plagányi and fulton 2017 traditionally the communication between model domains developed for structured grids which consists of a set of rows columns and vertical layers where the location of nodes in the physical space directly maps to their location in the program data array is done via a downscaling approach in which the regional domain rd provides open boundary conditions henceforth obc to one or multiple nested local domains ld one way nesting downscaling is necessary because direct local refinement of structured grids required to describe highly variable bathymetries found in coastal areas is difficult using downscaling a modeller can at any time implement additional lds forced by the rd to study new areas of interest without the need to create a new rd grid avoiding extra effort and saving simulation time however when the nested model domains run online all domains running at the same time and sharing information at every time iteration the overall simulation time becomes the sum of the lds and rd simulation times if run serial mode or the sum of the slowest ld plus the rd if the lds are run in parallel which presents a scalability problem for large areas with many lds making the use of ordinary servers difficult particularly for operational modelling systems that need to provide forecasts in a timely fashion offline downscaling approach can be a solution for this problem since in this approach the lds run separately from the rd and lds obc are obtained from rd output files allowing the simulation of several lds using a common rd output campuzano et al 2012 mason et al 2010 regardless of the approach in one way communication systems the rd does not take advantage of the more accurate representation of hydrodynamic and biogeochemical processes simulated by its nested lds given the structured grid disability to refine specific areas of a rd in an efficient manner the solution is to add an upscaling stage to these nested systems where information is also transferred from the ld to the rd using two way communication when communication is carried in runtime the same model application must be used to simulate the rd and the lds and the methodology is designated by two way nesting that has all the inconveniences described above for the online one way nesting described above the alternative proposed in this paper is the use of offline upscaling where rd and lds run in different computers and eventually using different models in different institutions and the solution of the lds is assimilated by the rd using a relaxation method upscaling of lds into rds aims to reduce the numerical diffusion associated with the lower grid resolution of the rds and enable the feedback of small scale processes not simulated by a rd as is the case of estuarine and lagoon tidal inlets of even the effect of current wave interaction in coastal areas upscaling can also be used to transfer to the regional model more detailed information of boundary conditions as is the case of local sources of nutrients from aquaculture systems or change the flow due to offshore energy systems such as underwater turbines calculated from high resolution lds by improving the rd one is implicitly transferring information between lds improving solutions of the lds used by local entities this is important for many modelling fields from the study of biological processes to morphodynamics in coastal systems such as estuaries that depend on other systems not included in a specific ld such as in ribeiro et al 2016 and oliveira et al 2021 there are currently three main methodologies for upscaling nudging of the rd is towards the lds barth et al 2005 sannino et al 2009 sobrinho et al 2021 teles machado et al 2016 spectral nudging including the technique described in sheng et al 2005 and applied in urrego blanco and sheng 2014 and urrego blanco et al 2016 and through data assimilation techniques barth et al 2007 vandenbulcke and barth 2019 for a more extensive review on the two way coupling its methods advantages and drawbacks the user is referred to the reviews of debreu et al 2008 debreu et al 2012 herzfeld and rizwi 2019 klingbeil et al 2018 and schulz stellenfleth 2016 however even though online two way simulations produce better results holt et al 2017 all domains must be operated by the same modeller its computational time cost is higher because it renders unusable the offline downscaling methodology and similarly to the online downscaling issues previously discussed removes any chance of using upscaling in operational forecast modelling as such a similar approach to that followed by offline one way systems should be considered in which the rd and the lds run separately from one another doing so a ld can receive its obc from one rd offline downscaling and its results can be upscaled by a different rd produced by a different institution for example a rd run by institution a covering the iberian peninsula could provide obc for a local estuary domain in portugal run by institution b and that estuary domain could be upscaled to a rd run by institution c as in a similar process suggested in caldeira et al 2016 in such an approach the lds are used in a similar fashion to the offline downscaling where the obc applied to a rd running with model a are provided by a global solution such as the ones in the copernicus marine service cmems running with model b additionally the models can be run in separate computers which enable these simulations in simpler it infrastructures as is the case of the institution where the results presented in this article were produced offline two way communication became a recent research subject due to the advantages for operational modelling with some applications being published recently herzfeld and rizwi 2019 applied the offline two way nesting to the great barrier reef where the transfer of information is done via model output files and vandenbulcke and barth et al 2019 which used an assimilation technique to upscale temperature and salinity fields from a ld covering the north western basin of the mediterranean sea and a rd covering the entire mediterranean the present study is the result of a continuous effort sobrinho et al 2021 to incorporate an upscaling capability in the 3d mohid water hereafter mohid modelling system in which we develop a methodology for offline upscaling based on the relaxation of a rd to one or multiple lds the methodology follows the online algorithm presented in sobrinho et al 2021 and extends if to run offline using hdf or netcdf ld output files in the online method information is transferred between domains at every time step while in the offline approach the period depends on the output frequency of the ld 15 min in the case presented here another difference is that in the online simulation the ld immediately gets updated information from the rd while in the offline approach it gets new info only once a day this is consistent with the overall operational modelling approach where simulations are repeated every day using new meteorological forecasts and eventually new global ocean model forecasts the number of times one day is simulated is usually imposed by the meteorological forecasts and usually varies between 3 and 7 the larger is the number of repetitions the higher is the accuracy another advantage of this methodology is that it enables the upscaling of specific parts of each ld only the methodology proposed is applied to the nested system comprised of the portuguese coast operational modelling system pcoms rd and the tagus rofi model domain tagus rofi ld during the extreme flood event of march april of 2013 results provided are compared against surface elevation and salinity field data measured by a fix buoy and with results of a traditional one way downscaling approach results using one and two upscaling iterations in this case measured in days were compared to estimate the impact of increasing grid communication frequency the comparisons showed that the offline two way coupling improved a lot the solution in the rofi area up to the north western open boundary of the ld which is most affected by the estuarine plume demonstrating the potential of this approach for the upscaling the results also show that two simulations of the same day are enough to get acceptable solutions and that this method is adequate for operational models that produce daily forecasts 3 days ahead this article focusses on validation of the upscaling methodology and on its ability to improve the rd solution using the ld to impose the tagus river discharge in the rd detailed information regarding the upscaling methodologies mentioned in this article as well as a variety of schematic tests performed to analyse conservation and stability of the solutions can be found in sobrinho 2021 3 materials and methods in this work we use the mohid model developed at maretec ist university of lisbon for arakawa c staggered grids where velocity components are computed over the faces of the scalars control volume as are the advective and diffusive fluxes the model is a 3d finite volume model which solves the 3d incompressible primitive equations leitão 2002 leitão et al 2005 martins et al 1998 2001 whose numerical code follows an object oriented philosophy braunschweig et al 2004 the model assumes hydrostatic equilibrium and partially the boussinesq approximation the density applied in the horizontal momentum equations varies in time and space although the momentum fluxes per unit of mass are calculated null velocity divergence is also considered 1 u i x i 0 where u i are the three velocity components integrating the along the water column between the bottom h and a depth z the vertical velocity at that level is derived 2 u 3 x 3 z x 1 h z u 1 d x 3 x 2 h z u 2 d x 3 h z q d x 3 where q represents water sources such as rivers or local wastewater discharges integrating this equation up to the free surface one obtains the free surface elevation η rate of change 3 η t x 1 h η u 1 d x 3 x 2 h η u 2 d x 3 h η q d x 3 in this equation q also includes rain and evaporation calculated at the free surface applying the hydrostatic approximation the vertical momentum equation is obtained 4 p x 3 ρ g which integrated over the water column between the free surface and a depth z results in 5 p x 3 z p a t m z η ρ g d x 3 the derivative of this equation along the horizontal axis produces the pressure gradient 6 p x i x 3 z p a t m x i g ρ x 3 η η x i g z η ρ x i d x 3 finally the horizontal momentum equations can be written as 7 ρ u 1 t u 1 u j x j f u 2 p a t m x 1 g ρ x 3 η η x 1 g z η ρ x 1 d z x j μ u 1 x j 8 ρ u 2 t u 2 u j x j f u 1 p a t m x 2 g ρ x 3 η η x 2 g z η ρ x 2 d z x j μ u 2 x j where f and μ represent the coriolis parameter a parallel line to the surface elevation and the turbulent viscosity respectively the mohid model is also capable of solving the non hydrostatic pressure component but that would require extra computing power and with little effect to the purpose of this article temporal discretization of the equations is done using a semi implicit scheme alternating direction implicit adi where two time levels per iteration are used the numerical schemes available for use in mohid include the abbot s 4 equations system abbott et al 1973 where the surface elevation is calculated at each half model time step and the velocities at each time step and the leendertse s 6 equations system leendertse 1967 in which the water level and the velocities are computed at half time step currently the default option in mohid is the latter and is the one used in this work tracer properties such as temperature and salinity are computed using the fluxes derived from the hydrodynamic fluxes and viscosities 9 p t p u i x i x i μ p x i s p i 1 2 3 where sp stands for sink sources of the property p in question horizontal and vertical advection are computed using the tvd advection scheme a combination of a high order scheme in the case of mohid a hybrid between 1st and 3rd order upwind schemes with a flux limiter superbee roe 2003 which is found to reduce spurious oscillations generated from shocks discontinuities or sharp changes in bathymetry at the bottom advective fluxes are imposed as null and diffusive flux of momentum is estimated by means of a bottom stress calculated by a non slip method with a quadratic law that depends on the near bottom velocity so the diffusive term at the bottom is written as 10 v v h z b o t t o m c d v h v h cd is the bottom drag coefficient that is calculated with the expression 11 c d k log z z 0 b z 0 b 2 where z is the distance to bottom κ is the von karman constant and z 0 b is the bottom roughness length this quadratic law is derived from the logarithmic law of the wall near boundaries characteristic of boundary layers as the bottom velocities are located half a grid box above the bottom this term is calculated semi implicitly following backhaus 1985 for the sake of numerical stability at the lateral closed boundaries an impermeable free slip condition is used applying zero normal water fluxes and zero momentum diffusive fluxes at the cells in contact with land at the surface wind stress is calculated according to a quadratic friction law 12 t w c d ρ a w w where c d is a drag coefficient that is function of the wind speed ρ a is air density and w is the wind speed at a height of 10 m over the sea surface 13 c d 1 14 e 3 w 10 m s 14 c d 4 4 e 4 6 5 e 5 w w 10 m s w 26 m s for more information on the model description the user is referred to the mohid description maretec 2007 3 1 upscaling algorithm the upscaling algorithm implemented in mohid model system is fully described in sobrinho et al 2021 and is based on the work of oey and chen 1992 and fox and maskell 1995 the algorithm considers the nudging of a child domain s ld velocities temperature and salinity fields by a parent domain rd and good results with minimum error production were obtained for online simulations of nested domains sobrinho et al 2021 the overlaying concept behind the offline upscaling algorithm is the nudging of the rd solution towards the ld solutions provided externally via the hdf files using a relaxation algorithm ld results are volume integrated and averaged into the rd model grid cells using the software routines already developed for the two way online coupling in sobrinho et al 2021 in order to optimise the code connection matrixes between ld cells and rd cells are built in the first model iteration and stored in memory as described in sobrinho et al 2021 the main difference between online and offline is data collection in regard to parametrizations the user can choose the upscaling time decay for relaxation henceforth utd and the number of ld line columns next to the open boundary to be ignored additionally in the case of multiple lds the user must also specify an id for the ld horizontal velocities are always upscaled other properties to be upscaled must be specified by the user when offline upscaling is used mohid equations 7 and 8 for the rd became as follow 15 ρ u 1 t u 1 u j x j f u 2 p a t m x 1 g ρ x 3 η η x 1 g z η ρ x 1 d z x j μ u 1 x j ρ u 1 u 1 l d u t d 16 u 1 l d u 1 i l d ϖ d r v i l d ϖ r d v r d 17 p t p u i x i x i v p x i s p p p l d u t d where u 1 l d and p l d stand respectively for the volume weighted average of velocity component along x 1 and tracer property to be imposed in rd cells respectively v r d is the regional domain cell volume and u i l d ϖ d r and v i l d ϖ r d represent corresponding ld cell velocity and volume respectively that are contained inside the rd cell utd stands for the relaxation time for upscaling in this formulation the total momentum inside the ld cells included inside a rd cell is transferred to the rd and the velocity is modified having in consideration the ratio between the ld volume and the rd volume imposing the average velocity would be equivalent to impose artificial forces and would result into artificial water fluxes and consequent artificial free surface changes on the contrary scalars are imposed per unit of volume temperature salinity this implies no mass heat conservation but the aim of the upscaling is to correct errors of the calculation of those properties due to low resolution or to bad boundary conditions imposed in the regional model 3 1 1 management of the land interface between local domains and the regional domain small estuaries and coastal lagoons are often treated by the rd as land because the spatial step is too large to describe them in tidal systems those areas are responsible for tidal flow and mixing of fresh and salt water and high oscillatory discharges of volume momentum and other properties at the mouth of the ld can occur which generate oscillatory momentum fluxes at the border of the rd those discharges are imposed at the boundary of the rd together with nudging inside the domain to avoid instabilities near inlets in the offline coupling the ld results are available from the second simulation of a given day onwards and discharges are computed by the upscaling algorithm at each time step assimilating ld velocities into the rd domain without including these discharges would generate a reflected wave at the boundary with too high water levels during flood and too low water levels during ebb fig 1 illustrates a grid nesting with a 1 3 ratio the dashed line shows the ld grid and the ld velocity points and two rd cells the blue with water and grey on land in an area where the ld domain has water for simplicity only two cells are shown on land the amplitude of the reflected wave increases with the number of cells 3 1 2 time interpolation and communication between grids fig 2 illustrates communication between grids in online two way coupling fig 2 left grids communicate at each ld time step in downscaling procedures and at each rd time step in the upscaling procedures in the offline simulations fig 2 rigtht interaction is done at the end of the simulations the figure shows the case of a 3 day forecast repeated every day and producing daily outputs in this case each day will be forecasted 3 times and each new simulation adds a period of one day to the previous simulation in every simulation there are no ld results to be upscaled in the last simulated day these results will be discarded and consequently any solution that assures stability is good in our case we have considered no upscaling on day 3 the stability of the system increases with the distance between the ld open boundary where rd results are injected into the ld and the region where the closed boundary of the rd is being opened using the ld results the rd model is the first to run on day 0 it simulates up to the end day 2 using no ld results upscaling and creating 3 daily output files after this simulation the ld domain runs for the same 3 days downscaling the rd results through its open boundary and also creates 3 output files one for each day then the rd performs a new simulation starting at day 1 and finishing at day 3 upscaling ld results for 2 days and then the procedure is repeated every day the stability is independent of the number of the days simulated depends only on the duration of the period with no upscaling and of the distance between the borders of the two models referred above however the accuracy of the results is expected to increase with the number of repetitions of a simulation this can be achieved increasing the number of days simulated or decreasing the time between simulations e g 6 h instead of 1 day only daily simulations were tested because our operational modelling system is prepared to run once a day simulating four days one in hindcast mode and 3 in forecast mode to feed the solution with the latest available meteorological and obc from regional and global ocean domains consequently each day is simulated 4 times by each model domain using downscaling only or using upscaling as such shifting an operational forecasting system from an offline downscaling approach to an offline two way approach is computationally nearly free of charge from a regional modelling system perspective upscaling from local domains offline upscaling would allow the upscaling of multiple solutions provided by different entities and models which would improve the solutions provided by these regional modelling solutions with higher resolution information near the coasts and with local knowledge 4 the pcoms tagus rofi nested modelling system the mohid model was used to simulate the tagus rofi during an extreme precipitation event that occurred in march april 2013 and led to a tagus flow rate of around 7500 m3s 1 about 30 times the average flow rate 258 m3s 1 a nested grid configuration in both offline one way and offline two way formulations was used and results are compared among them and with results of sobrinho 2021 obtained using an online simulation and the same boundary conditions and parameterization the one way offline downscaling approach is performed because online downscaling produces slightly different results than offline downscaling due to differences in the obc produced by the latter lower frequency transfer of information from rd to ld in the offline simulation information is transferred every 15 min instead of every time step as previously discussed in the offline upscaling the simulation time necessary to reach the solution increases when the frequency of information transfer between ld to rd decreases in this test information is transferred daily to compare the sensitivity of the results to the number of days simulated two simulations were done in one the duration of each simulation was two days and consequently each domain was simulated twice exchanging information once a day in this scenario results of the ld can be upscaled for only one day in each simulation on the other simulation three days were simulated and results for 2 days can be upscaled in each simulation results show that two days upscaling improved the solution reducing the gap between measured and simulated salinity values increasing the number of simulated days would still improve the results but two days of upscaling was considered good enough with the advantage that this scenario did not imply any modifications in our operational framework the validation of model results is performed using data measured at points shown in fig 3 free surface levels are measured in cascais ctg station vertical profiles of temperature and salinity are available at stations ctd p1 p2 and p3 comparisons refer to the entire period of simulation january 15 to april 10 with a focus on the peak flow period 25 march to 10 april 4 1 model setup 4 1 1 grid communication management offline simulations need pre processing and post processing operations to manage files used to communicate between domains while the parameterizations and obc are quite similar identical file management is already included in operational forecast modelling systems which require periodical 1 update of the simulation period and 2 downloading of obc files necessary to extract input data and 3 copying and renaming of input files required and output files produced for every simulation these pre and post processing operations are managed by a separate tool art campuzano et al 2012 the system was updated to perform the new offline upscaling procedures in case of a 3 day simulation as shown in fig 2 each model generates 3 output files one per day this allows the two models to run simultaneously for two days when the rd completes day 1 simulation the ld can start its day 1 simulation while the rd runs its day 2 simulation this procedure continues up to the last simulation day when the procedure is reinitiated on the next day both models completed the simulation of the same period and everything is ready to initiate the next set of simulations in normal operational mode the models run every day and the time needed to simulate one day is a few hours this assures that when the next simulation starts all files are ready however in case something gets wrong with one simulation or when we run the model in hindcast mode it can happen that when a model wants to start some files can be missing to manage this possibility a trigger system has been implemented consisting of simple text files containing the simulation period to which the output files refer and a keyword that states the current status of the simulation running or finished with this system in place the rd domain wanting to run the first day for the second simulation will wait for the finished status of the trigger file produced by the ld for that same day the ld trigger was already in place because it the one way nesting it needs the most recent output from the rd the last day of a rd run cannot perform upscaling because it is ahead in time see fig 2 the former approach is feasible if both models run in the same network sharing the triggers if the ld and the rd models run in different institutions sharing triggers is not feasible and an exception was introduced directly in the mohid code activated by the user now the code performs the search for all upscaling files specified by the user and if the files are not present in the location the user specified then the upscaling of those files is disabled and the regional domain will still work ignoring the upscaling of that ld and upscaling any other existing domains this methodology attempts to provide scientists and modellers involved with the modelling of coastal areas with a robust tool that can improve a rd with the information provided by multiple local modelling domains the procedure developed can be easily implemented in other modelling systems 4 1 2 implementation setup the modelling system is comprised of two nested domains fig 3 1 3d full baroclinic regional domain for the portuguese coast level 2 fig 3a 34 4⁰ n 45 0⁰ n and 12 6⁰ w 5 5⁰ w with a grid resolution of 5 7 km and 50 vertical layers 7 sigma at the surface and 43 cartesian below 2 3d full baroclinic domain for the tagus rofi level 3 fig 3b and adjacent coastal area with a variable grid from 2 km to 200 m 38 15⁰n 39 2⁰n 10⁰w 8 9w and 50 vertical layers 7 sigma at the surface and 43 cartesian below the tide level imposed to the rd is extracted from a 2d barotropic model encompassing the rd shown on fig 3 this model is forced using tidal harmonics from fes2004 lefèvre et al 2002 lyard et al 2006 a flather 1976 radiation scheme was applied to water level at the open boundary of pcoms followed by a flow relaxation scheme martinsen and engedahl 1987 frs to the mercator solution following the work of leitão et al 2005 in this setup the frs means an exponential decreasing relaxation coefficient along the 10 numerical cells of pcoms closer to the open boundary with a relaxation time of 105 s in the first open boundary cell and 109 s from the 10th cell inwards additionally a biharmonic filter of 5 5 109 m4s 1 is applied to reduce high frequency noise inside the domain tagus rofi domain is forced by pcoms at the lateral open boundary using the flather radiation scheme and a 10 cell frs with 900 s at the first cell to 109 s from the 10th cell inwards for velocities temperature and salinity the temperature and salinity open boundary condition is adaptative i e passive for inflow and active for outflow a biharmonic filter of 2 7e6 m4s 1 was applied a full description of the first two domains running in one way operationally in maretec is available in mateus et al 2012 and a description of the tagus rofi domain one way is described in campuzano et al 2012 and in de pablo et al 2019 the model setup configurations used in the systems for two way simulations is summarized in table 1 the relaxation time for upscaling utd was based on the previous work by sobrinho et al sobrinho 2021 this time must be short to accommodate issues with tide which requires a lower time decay while baroclinic velocities temperature and salinity could have higher lower utd values for an analysis of the decay term value the reader is referred to sobrinho 2021 in this article the upscaling stage of the coupling is performed using daily output files this low frequency of communication between models is possible because of the radiative obc used in the ld otherwise data should be exchanged more frequently 4 2 results a comparison between the three offline implementations is shown in the next sections and includes the traditional one way offline downscaling approach the new downscaling upscaling offline two way with one upscaling 1 day and two upscaling 2 days i e runs 2 day long and 3 day long the objective is to understand and quantify the effect of the number of upscaling iterations on the regional pcoms model 4 2 1 water level validation water level results obtained by the model implementations pcoms and tagus rofi under the three different parametrizations were compared with the cascais tide gauge data available for the period between january 15 and march 13 2013 pcoms fig 4 tagus rofi fig 5 this period does not include the tagus river freshwater flow peak used for the validation of surface salinity the figures show a direct comparisons between the water level obtained by the models and field data b a comparison between the bias of the three implementations and c the correlation between model and field data upscaling the tagus rofi domain into pcoms does not bring any visible changes on water levels except on the statistical parameters however results show a good agreement with the tide gauge data which means that at least in this coastal area close to the mouth of the estuary where local bathymetry and the estuary discharge play important roles the model domains can represent tidal variability also a statistical analysis including bias rmse and pearson correlation coefficient table 2 suggest overall that solutions are very similar in pcoms a small increase of the mean bias is verified for upscaling 1 day from 4 02 mm to 4 09 mm although with a reduction in the median bias from 2 21 mm to 1 84 mm rmse values diminish when upscaling is done for both upscaling 1 day and upscaling 2 days implementations from 0 0739 obtained by the offline one way downscaling to 0 0710 and 0 0724 obtained for upscaling 1 day and upscaling 2 days respectively as for the correlation values all implementations show the same good agreement with the tide gauge however when two days with upscaling are used some metrics are reverted median bias for example increases from 1 84 mm to 2 24 mm the implementation with only downscaling produced a value of 2 21 mm whereas rmse values although smaller than when using only downscaling increase from 0 071 to 0 0724 using one or two days of upscaling respectively once again correlation and nash values remain identical in all implementations regarding tagus rofi the same analysis can be made about the mean and median bias values however rmse values obtained by the offline two way system whether running the same day once or twice with upscaling are higher from 0 068 obtained by the offline one way system to 0 069 and 0 071 respectively the same pearson correlation coefficient and nash parameters were obtained by all implementations this analysis shows that all model applications performed quite well when compared with the tidal gauge data with very small differences between them which means that there is no significant degradation of any of the solutions during this period however the major impact of these implementations is not expected to occur neither in water level nor in the vicinity of the tagus rofi but in the interior of the domain and especially near the open boundaries of tagus rofi 4 2 2 surface salinity validation surface salinity obtained by tagus rofi under the three implementations was compared against field data from the moored buoy located near the mouth of the tagus rofi for the period of january 15 to april 10 fig 6 results demonstrate the model ability to reproduce the salinity variability over time especially during the peak flow event at the end of march beginning of april this peak flow is represented in grey in fig 6 and shows the extreme flow rate registered at the time which eventually submerged the buoy stopping the data acquisition of salinity during part of the event there are no significant differences between salinity obtained by the different implementations much due to the location of the buoy which is in a place dominated by the estuary s salinity plume and as such will have little impact from the changes occurring at the tagus rofi open boundary as observed in the water level there is a slight increase in model error in the upscaling 2 days implementation although with a small advantage of the upscaling 1 day implementation over the downscaling however and like in the water level comparisons the statistical parameters table 3 suggest that the model accuracy obtained by all implementations is hardly affected by using upscaling near the estuary mouth 4 2 3 salinity transition at the open boundary as mentioned above the major changes of surface salinity are expected to occur near the tagus rofi open boundaries where the gradient between pcoms and tagus rofi running in one way offline mode are highest and not near the estuary mouth a comparison of surface salinity time series extracted from both pcoms and tagus rofi is shown in fig 7 for the period between january 15 and april 10 at the location ts sal shown in fig 3 fig 7 shows results for the ld the tagus rofi on the bottom and of pcoms on the top on the left the figure show the whole period and on the right the figure shows a zoom for the high freshwater discharge event putting into evidence the differences between the results in the one way downscaling pcoms solution does not show the estuarine plume and the rofi ld model shows minimum salinities of about 32 using upscaling the pcoms model shows the estuarine plume and the rofi model shows much more freshwater and lower salinities minimum values decreased from 32 to 28 setting 3 days simulation upscaling is repeated twice improves the solution obtained with a single day of upscaling by about 0 5 that is expected to be of the order of the error induced by the uncertainty of the freshwater discharge rate improvement of the one way downscaling happened because in this scenario numerical diffusion destroys the rofi in the pcoms simulation and consequently when the water flows from the rd into the ld it flows with a salinity higher that the real increasing the salinity on the ld in the upscaling 1 day and upscaling 2 days implementations when the flow direction changes from northwards to southwards the salinity values provided by pcoms which upscales salinity from tagus rofi is lower and better specified to the tagus rofi open boundary this phenomenon can be illustrated comparing the surface salinity field obtained with downscaling and upscaling implementations fig 8 shows the salinity field difference between downscaling and 1 day and 2 days upscaling for the period between 25 march and april 10 2013 when the flow is mostly northwards the results shows that major differences occur near the open boundaries with higher salinity values obtained when using downscaling methodology and in front of tagus mouth with lower values obtained when using downscaling methodology the reason for this is that when the downscaling methodology was used the tagus plume was not able to reach the open boundaries due to the imposed level 2 obc and was deviated further to south whereas with upscaling methodology the plume is able to move easily northwards because of thermohaline effect with a second day of upscaling upscaling 2 days these differences are higher 4 2 4 vertical profiles of temperature and salinity temperature and salinity profiles were extracted at the 3 locations shown in fig 3 lisbon canyon p1 western boundary of tagus rofi p2 and the northeast boundary of tagus rofi near the coastline p3 time series of surface salinity extracted from pcoms and tagus rofi discussed above showed the improvement of the solution when upscaling is used in this section the impact on temperature and salinity vertical profiles is assessed and compared with field data in fig 9 for the period of march 25 to april 10 which corresponds to the peak of freshwater flow to use comparable results tagus rofi fields were previously interpolated via simple average into the pcoms grid which means that some caution is advised when looking at the comparisons as the average partially distorts the results in areas were the grid resolution of pcoms is highest and near the coast as some pcoms cells are only partially covered by tagus rofi temperature results show that upscaling can influence the results up to 100 m depth in the lisbon canyon p1 and at the west open boundary of tagus rofi p2 at the north eastern boundary of tagus rofi p3 this influence is evident over the entire water column where an increase in temperature is observed when upscaling is used furthermore there is a tendency towards the reduction of temperature and salinity vertical profile differences between all model domains which is the aim of the method a slight 0 15 c temperature increase from the one way to the two way implementation running upscaling once per day was registered in p1 and p2 and negligible changes in p3 the two way implementation running upscaling twice per day generated temperature increase of 0 15 c 0 5 c and 0 2 c at stations p1 p2 and p3 respectively this is a consequence of both the changes in local currents shown in fig 10 promoted by improved density gradients in the pcoms domain the salinity decrease imposed by the tagus estuary domain increased the water level near the shore and drove the currents northward due to the coriolis force dragging northwards the warmer southern waters fig 10 salinity vertical profiles fig 9 demonstrate the increased nudging effect between pcoms and tagus rofi domains when more runs per day with upscaling are performed another effect already visible in the surface salinity comparisons performed near the open boundary of tagus rofi is the lower surface salinity values obtained in the upscaling 2 days implementation when compared with the one way simulation this phenomenon is also visible at the west boundary of the tagus rofi domain p2 showing that upscaling effect extends beyond the area where the plume exerts direct influence as a consequence of density on the flow the largest improvement is obtained in pcoms salinity profiles in the results shown without upscaling the salinity is constant in time and vertically uniform while with upscaling physically realistic profiles consistent with the rofi profiles are generated the improvement extends from the surface up to 80 m with differences of up to 0 4 salinity units although these results are averages in time and include days with higher salinity differences this means that making a second iteration of the upscaling procedure does not bring many changes to the overall solution in operational modelling forecasts each day is simulated at least twice and very often 7 days and consequently upscaling will generate confident solutions 5 conclusion a new upscaling algorithm was developed and integrated in mohid this algorithm is now part of the offline upscaling methodology which enables a regional model to upscale multiple higher grid resolution domains local domains without the need for online nesting in the regional domain this new algorithm is suitable for operational forecast regional systems which can upscale local domains generated by several institutions doing conventional downscaling for example the pcoms regional model application would now be able to upscale from a tagus rofi model application developed and maintained by any institution and whose results are freely available this can be exported to any other location including the madeira and azores islands that have their own local models running and could provide better solutions for upscaling into an ocean scale model covering the entire portuguese zee one future source of information may be the cmems repository which does not yet hold results from such local domains through the offline upscaling methodology developed in this article regional cmems model application would be able to benefit from local models run by local institutions with local knowledge of their coastal areas a model implementation including pcoms and the tagus rofi model application was run for the same period 15 january to 10 april and validated using in situ data available including the cascais tide gauge and the surface salinity provided by the algés ctd this validation was successful in demonstrating the accuracy of the model as well as the new algorithm as the offline upscaling algorithm has a lower grid communication factor communication is done at the frequency equal to utd after one full day of simulation using daily results instead of for each time step two implementations were tested the first upscaling 1 day considered two model runs per day of simulation which include a first run without upscaling in pcoms as it is ahead of the tagus rofi domain and a second run but now with the upscaling of tagus rofi which performs a run after pcoms finishes its first run and followed by the second run of tagus rofi which now receives its obc from the updated version of pcoms the second upscaling 2 days considers an additional run of the same day in each model domain therefore performing two runs with upscaling results were compared with in situ data focusing on the northeast open boundary of tagus rofi where the greatest impact was expected due to the northward transport of the estuarine plume during rainy periods time series were compared at the surface as well as vertical salinity and temperature profiles comparisons highlighted the importance of upscaling the tagus estuary into the pcoms domain and have shown that one iteration upscaling 1 day has a great impact on the results although some additional improvement is obtained when a second run is performed applying the upscaling promoted a better representation of the circulation due to the salinity fields provided by pcoms and therefore improved the obc of tagus rofi increasing the amplitude of the temporal salinity variability the improvement of the pcoms solution outside the local domain is also essential to simulate the tagus rofi in its whole extension that goes beyond the local model domain contributing for a better representation of the western iberian buoyant plume wibp further north in the near future new tests must be performed upscaling rofis from other estuaries into pcoms this improvement is quite important for a regional model application covering the iberian peninsula as the lower salinities observed far from the mouth of the tagus estuary will be transported northwards during winter and spring and its plume can merge together with the plumes from other estuaries to produce the west iberian buoyant plume wibp as observed in campuzano 2018 it is however most relevant in large rofi areas subject to very high flow rates in these cases without upscaling the local model applications following the downscaling approach would need to be extremely large to properly represent the saline fronts generated by the large freshwater flow using upscaling local model applications can use smaller domains becoming more feasible for operational modelling purposes as small domains can still provide appropriate solutions another important aspect of the offline upscaling is its independence regarding simulation time of the local domains when operational forecast solutions are concerned in operational forecasting each day is run several times but usually between 3 and 7 times which means that the offline upscaling can be performed between 2 and 6 times for the same period without changing the overall simulation time this is an important improvement to the upscaling algorithm presented in sobrinho 2021 and will facilitate the integration of the method into operational modelling this work sets a good foundation for further developments and research in the offline upscaling procedure via nudging including the study of upscaling multiple lds into a rd or multiple rds into a global domain in regard to the upscaling impact of local solutions over a larger area of the rd not overlapped by the lds further validation using in situ and remote sensing data will provide a better insight on the parameterization of upscaling decay term to be used and the frequency of upscaling communication which in this article is 1 day higher frequencies should be tested to account for implications on tide propagation funding the present work was supported by fct mctes piddac through the project larsys fct pluriannual funding 2020 2023 uidb 50009 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the portuguese hydrographic institute ih for kindly providing data on the water level in the study area special thanks to manuela juliano of the azores university for her valuable help in the scripts for comparison between surface model results 
25444,the northeast region of bangladesh is highly vulnerable to flash floods which often damage the only crop of that region the boro rice developing an efficient and real time flash flood forecasting system for that region is found essential the traditional model centric approach requires plenty of time and manpower to effectively model flash floods this paper discusses an open source data centric integrated flash flood modelling approach using a platform named delft fews it is based on three inter dependent models e g meteorological hydrologic and hydrodynamic the model was calibrated and validated with the flash flood data of 2010 12 and 2013 15 respectively the performance of the model in real time was assessed in the context of the 2021 flash flood season in both cases it performed satisfactorily the entire system helps the practitioners to work in a flexible environment to generate flash flood forecasting and early warnings keywords delft fews flash flood graphical user interface integrated modelling open source model data availability data will be made available on request 1 introduction flash flood is generally defined as an abrupt water rush through a narrow channel or over a sloping surface that occurs due to a sudden heavy rainfall in the upstream hilly regions sweeney 1992 roy et al 2019 compared to other flood events flash floods are uniquely characterized by their immediate inception within a short span collier 2007 haque 2016 das et al 2020 the higher frequency of devastating flood events due to climatic change reduced the mass acceptance of conventional structural steps for flood protection kuang and kuei hsien liao 2020 mohanty et al 2020 pour et al 2020 shah et al 2018 werner and whitfield 2007 in this regard the global community widely recognized the operational flood forecasting and warning system for its effectiveness haggett 1998 wmo 2006 cloke and pappenberger 2009 changa et al 2019 sahraei et al 2020 but these conventional model centric approaches require much labor in real time flood forecasting and therefore may not be suitable for flash flood forecasting werner and whitfield 2007 to make the system effective the user needs a flexible operational flood forecasting model integrated into a single platform werner et al 2013 modern flood forecasting models are generally based on multiple software models where each of them is assigned to an exclusive task i e the software assigned for rainfall forecasting will not perform the task of discharge modelling or water level forecasting the users or practitioners link these tools to get the end level forecast output it is cumbersome to work with multiple models in separate graphical user interfaces gui and often consumes more time than working on a single platform however multi model forecasts are proven to be comparatively better than the single model based forecasting system and therefore have attracted much attention recently barthélémy et al 2018 khan et al 2019 kao et al 2020 puttinaovarat and horkaew 2020 barthélémy et al 2018 developed a coupled one dimensional 1d two dimensional 2d hydraulic model for multi dimensional flow khan et al 2019 discussed the assimilation of multi sensor remote sensing data for the indus river basin irb loi et al 2019 coupled the swat and hec ras models to create a coupled hydrologic hydraulic modelling system for vu gia thu bon river basin vietnam ming et al 2020 integrated a numerical weather prediction model and a 2d high performance hydrodynamic model for real time flood forecasting kao et al 2020 proposed a long short term memory based encoder decoder lstm ed model for multi step ahead operational flood forecasting puttinaovarat and horkaew 2020 used an adaptive machine learning framework to integrate meteorological hydrological geospatial and crowdsource big data agarwal et al 2020 coupled the hec hms and bias corrected wrf rainfall forecast and thus operationalized the flood forecasting system of ayeyarwady river myanmar tian et al 2020 developed a coupled wrf gridded hebei model interestingly these models dealt with coupling a maximum of two forecast models either coupling the meteorological and the hydrological models or the hydrological and the hydraulic models limited research has been done on integrating more than two types of models in a single environment werner et al 2013 presented a hypothetical workflow integrating three types of models e g atmospheric model hydrological model and hydrodynamic model for flood forecasting in a simple basin a basin having a simple topography and including single river channel network rather than complex crisscrossed river network however they did not show the step by step software based modelling procedure and how to integrate them into a single platform keum and coulibaly 2018 integrated three models in the delft fews platform but all of the models were hydrologic models no atmospheric or hydraulic model was used in their study addressing this research gap a proper framework for integrating three different types of models e g atmospheric hydrologic and hydrodynamic models has been discussed in our study in the case of incorporating numerous modelling components in a single central data modelling platform a monolithic modelling approach will generate computational complexity harvey et al 2002 to avoid this difficulty a comparatively more flexible approach should be selected for operational flood forecasting werner et al 2013 since its first usage for the nile basin delft fews has been providing a general data centric platform for integrating various types of models grijssen et al 1992 using this platform the federal flood commission of pakistan developed the indus flood forecasting system werner and van dijk 2005 bogaard et al 2016 developed a hydro meteorological and morphological model based 2d framework which is connected with a bayesian network decision support system dss using delft fews it was also used in the national weather service and bonneville power administration in the united states of america yang and welles 2017 keum and coulibaly 2018 integrated three hydrologic models e g snow17 raven and watflood to build a multi watershed flood forecasting system using delft fews valchev et al 2018 implemented and validated a coastal hazard forecasting system for varna bay using this software the global fluvial flood forecasting system gloffis a real time fluvial flood forecasting system operated by deltares uses a workflow framework embedded within the delft fews den toom et al 2020 real time flash flood forecasting is different from other types of flood forecasting considering the greater uncertainty in precipitation forecasts than the other parameters e g water discharge and water level and a very short lead time mohammed et al 2017 particularly in the northeast region of bangladesh some extremely complex uncertain and nonlinear physical processes are involved in the conversion of rainfall and subsequent runoff into water levels therefore it has drawn the attention of the scientific community in recent years khan and mostafa ali 2020 developed a hydrologic model for the jadukata river basin situated in the northeast region of bangladesh using hec hms 3 5 0 but they did not include the entire northeast region outside of bangladesh long short term memory lstm networks song et al 2020 and entropy based decision approach lin et al 2021 have been used in flash flood forecasting the flood forecasting and warning center ffwc of the bangladesh water development board bwdb makes flash flood forecasts for bangladesh using the mike11 flood forecasting system mike11 ff paudyal 2002 currently ffwc is using a one dimensional fully hydrodynamic model mike11 hd which is linked to a lumped conceptual rainfall runoff model mike11 rr ffwc 2020 mike11 ff system is a non customizable system from the user end a customizable system allows the model developers to make the interaction between separate software components valchev et al 2018 and ensures greater flexibility since the community gets free access to the customizable features of these systems they are developed rapidly through interaction among the community members the xml files of the delft fews software used in this study are fully customizable from the user end and the codes provided with it are open for the users moreover the other three software used here wrf hec hms and hec ras are also free to use therefore the developed model provides ample opportunity to work in the field of open science in this context the institute of water and flood management iwfm buet has developed a customizable flash flood modelling system using delft fews it includes four components 1 wrf for forecasting rainfall over the upper meghna basin 2 hydrological model using hec hms to generate boundary flow of the transboundary rivers 3 hydraulic routing using a one dimensional model hec ras and 4 integrated graphical interface delft fews to prepare a real time forecast and provide early warnings a nonlinear autoregressive network with exogenous inputs narx model has been applied to the final product of the forecast evaluation to summarize the research gaps we have identified three points in particular i limited flash flood forecasting models had been developed incorporating the geographical complexity of the northeast region of bangladesh ii traditional flood forecasting models are incompetent to be used in flash floods and thus necessitates an integrated modelling environment iii current flash flood modelling system used by bwdb is non customizable necessitating an open source and customizable user friendly forecasting system to cover the research gaps mentioned earlier two specific objectives are fixed for this study i the development of a customizable open source flash flood forecasting and dissemination system integrating atmospheric hydrologic and hydrodynamic models and ii assessing its performance in real time flash flood season through statistical analyses for the northeast region of bangladesh 2 study area and data acquisition the study encompasses the meghna basin area covering 20 022 sq km consisting of seven districts of the northeast region of bangladesh e g sylhet sunamganj habiganj moulovi bazar kishoreganj brahmanbaria and netrokona cegis 2012 the entire basin area as well as the rain gauge stations of the bangladesh meteorological department bmd and the indian meteorological department imd are depicted in fig 1 a the water level wl and hec ras boundary stations are presented in fig 1 b this region is severely vulnerable to flash floods consisting of 400 wetlands with nearly 23 transboundary rivers that enter from neighboring india suman and bhattacharya 2015 in early 2017 it was severely affected by flash floods where nearly 1 million households and us 450 million worth of rice crops were damaged kamal et al 2018 a subtropical monsoonal climate prevails here with an average annual rainfall of approximately 4000 mm roy et al 2019 it is surrounded by indian states e g meghalaya in the north tripura in the south and assam in the east rahman et al 2018a haors bowl shaped depressions seasonally flooded with monsoon water and beels permanent shallow lakes which typically remain inundated even during the dry seasons are the prevalent hydrological features of this floodplain rahman et al 2018b the selected 25 water level stations for this study spread over the major rivers of this region bhogai kangsa dhalagang dhalai dhanu jadukata jhalukhali kalni khowai kushiyara manu sari gowain someswari surma and sutang all the observed water level data were collected from bwdb which is the officially mandated organization for collecting hydrologic data in bangladesh we considered 3 h water level data for the calibration validation and forecast evaluation period as the concentration of the flash floods is very short in duration all the water level data used in this study were in terms of the public works datum pwd it is approximately 0 46 m 1 5 ft below the mean sea level msl ffwc 2018 3 methodology 3 1 numerical weather prediction nwp model the mesoscale numerical model advanced research version of the weather research and forecasting wrf arw simulated precipitation product is used for estimating heavy precipitation in a finer resolution for the flash flood event of pre monsoon season das et al 2020 the wrf model is a new generation mesoscale numerical weather prediction nwp system designed to serve both operational forecasting and atmospheric research needs the model physics options and parameterization details are presented in skamarock et al 2019 wrf is suitable for a broad spectrum of applications across scales ranging from meters to thousands of kilometers the model is widely used for research purposes for resolving regional and local scale level phenomena nowadays it is popularly used in operational applications and decision making procedures abbasi et al 2021 chen et al 2020 kehrein et al 2020 the wrf model simulated three hourly precipitation obtained by studying model grid resolution three nested domains results are compared to check the grid resolution performance in fig 2 a global to regional g2r 1 3 i e 27 and 9 km and the global to convection permitting g2c 1 9 i e 9 and 3 km scale ratios fig 2 sensitivity analyses of different parameterization schemes are applied to find out the best combination for the flash flood trigger region the model simulated precipitation is assessed and verified with the available rain gauge observation along with india meteorological department imd and global precipitation measurement gpm mission merged datasets the wrf features used in this study are mentioned in table 1 the 1 0 1 0 gridded ncep fnl final operational global analysis and global forecast system gfs data are used as initial and lateral boundary conditions lbc of the numerical model simulation das et al 2020 the wrf model was simulated for a period of 78 h starting at 0000 utc every day as initial values every 30 minutes of model output were simulated for further calibration and validation due to the large volume of data only 3 hourly interval data are post processed from the model simulation which is comparable with the meteorological rain gauge station observation and trmm data 3 2 hydrological model in this hydrologic model we focused on the entire hydrograph and also captured the peak flows to better represent the flashy nature of the floods as flash floods depict multiple flood peaks during the pre monsoon season in bangladesh hec hms is suitable for this type of phenomenon czigány et al 2010 the soil moisture accounting sma method a continuous model available in hec hms is one of the most efficient continuous model simulations to simulate peak flow storm volume and time to peak razmkhah 2016 rainfall derived from the meteorological model is the only primary input data considered here to support the different parametric assumptions in the loss method land use and soil type data were used initial state values of baseflow for the stream were found considering the observed baseflow recorded for a basin then the model was simulated for a week with observed rainfall data for the stabilization of the modelling network later this initial run was saved and used for the hot start of the model for the validation run the end state of the calibration run was used to start the validation run to run hec hms in the delft fews environment several changes are needed in the hec hms files at first a new coldstate directory is created to keep the specific hec hms state file inside the fews environment the delft fews adapter prepared a dss file using the forcing time series from delft fews a zipped version of the hec hms files e g basin control gage etc are kept in the corresponding folder a general adapter file idmapfiles and a workflow file are created respectively after that the hec hms general adapter can run the models both in continuous and event modes we have continuously simulated the model from the beginning of the season for calibration and validation for forecasting purposes the model is simulated every time for five days with a 48 h hindcast to provide a 72 h forecast in this case operational flood forecasting was done and the continuous mode was chosen to conduct the process in the case of creating idmapfiles for hec ras to fews parameter interchanging a model state management step is followed instead of creating three sub folders for hec hms files a schematic representation of these steps is presented in fig 4 calibration was done manually in the hydrological model of the 16 parameters mentioned in table 2 the initial assumption for all the parameters was taken from previous literature on similar hilly sub basins and based on the curve number found for each basin the curve number which is unique to each basin is found by using land use data from globcover 2009 and soil use data from food and agriculture organization fao the source of each parameter is added to table 2 for reference only 7 parameters were calibrated based on the sensitivity of these parameters on the basin runoff and these parameters are initial storage maximum storage moisture in soil water to the groundwater layer 1 imperviousness soil storage and tension storage table 2 presents the calibrated parameters and their corresponding processes the parameters were calibrated based on the effect they had on the basin outflow haque et al 2017 performed a sensitivity analysis in the sari gowain river of the meghna basin the order of calibrating the parameters in our study was based on the ranking presented in this work automated tuning was employed but showed low improvement so tuning was done on each parameter individually to see which value presented the lowest rmse rse and highest r2 and nse in this study an automated calibration tool for multiple parameters was not implemented in the system therefore manual calibration was opted to account for the interdependent nature of each parameter in the basin here we have set up and calibrated the model manually based on a widely used model evaluation criteria as described in moriasi et al 2007 it sets up the performance rating criteria as such very good 0 75 nse 1 00 pbias 10 good 0 65 nse 0 75 10 pbias 15 satisfactory 0 50 nse 0 65 15 pbias 25 and unsatisfactory nse 0 50 pbias 25 the parameters were calibrated and validated until the statistical parameters achieved the best results achievable demonstrated by the comments it was not always very good for each of the cases sometimes the best result we achieved was good sometimes it was satisfactory and then we stopped hot start was used for the calibration and validation and the model results of the last run during calibration were used as a hotstart for the second run during validation to ensure a continuous model run parameter values were not the same throughout the basin it varied through different sub basins based on the topography soil and land use type of each sub catchment satellite data was used to determine the vegetation of a sub basin and the width of each of the channels table 2 the observed baseflow was recorded for each sub basin where data was available the lead time for the pre monsoon months of the calibration period was 1 month starting from february 2010 to march 2010 the calibration and validation were done in simulation mode preparing the model using observed historical data on the other hand near real time flash flood forecasting using the fews model was simulated in both hindcast and forecast modes in hindcast mode the model was simulated for 7 days forced by observed rainfall from bangladesh meteorological department bmd and india meteorological department imd while in forecast mode the model was simulated for 3 days forced by wrf simulated rainfall the hec hms model was forced by precipitation and monthly mean evapotranspiration for the water balance calculations in hindcast mode the hec hms model was simulated using observed daily rainfall from bmd and imd while in forecast mode the hec hms model was forced by hourly wrf forecasted rainfall in table 2 the initial canopy storage is defined as the percentage of the canopy storage that is full of water at the beginning of the simulation the canopy can store a fixed effective depth of water expressed in mm unit before external precipitation is added with it circulated through the soil surface this is identified as storage the percentage of moisture in the soil means the amount of water present in a certain volume of soil the percentage of water to the groundwater in the soil profile indicates the amount of water stored in the top layer of the soil compared to the outflow percolation contributing to the amount of groundwater considering a specific land cover layer there are certain portions where water cannot enter into the soil in a certain cross section or two dimensional flow area this is represented as the percentage of imperviousness compared to the entire area 3 3 hydrodynamic model hec ras the open source software for hydrodynamic modelling was applied for the flow assessment it uses finite difference solutions of the saint venant equations peters et al 2006 the river networks consist of a total of 173 junctions river cross section data were collected and inserted from bwdb and the iwfm database to conduct the unsteady flow simulation of the northeast region of bangladesh flow hydrographs of 34 rivers were inserted the manual calibration of the hydrodynamic model was done by selecting an appropriate value of manning s n value it was selected in such a way that the simulated water level data gets as close as the observed water level data in a particular time period in general the delft fews general adapter provides the necessary data in a standardized xml format to run hec ras and calls the hec ras module adapter this adapter transfers the xml data into the hec ras native file formats after the run gets completed the hec ras adapter passes the relevant result files back to the delft fews general adapter in xml format the entire process is schematically represented in fig 5 the entire model has been simulated for 72 h of lead time and a 1 week hindcast period 3 4 integration in delft fews in the open source flash flood forecasting model used by iwfm buet the use of delft fews provided strong integrity if the other three components e g wrf hec hms and hec ras were used separately without the involvement of delft fews it would become cumbersome to use the system the reason is in that case the user had to transfer model information and data transfer from the model to the model manually there are different types of files used in the delft fews environment among them the extensible markup language xml files zip files and comma separated values csv files are noteworthy besides them text files and chemical binary format cbin files are also used here however based on the usage of different models a variety of other file types e g dll basin gage met etc can be incorporated inside the software environment before running a module or any sort of data exchange startup activities were performed to remove files from the previous runs that might implicate the current simulation export activities were run to export all corresponding items to the external module using xml formats the external executables or java classes were run by the execute activities they are divided into three parts e g the pre adapter the actual module run and the post adapter after successfully running the module import activities were performed to bring back all the necessary items at last shutdown activities removed all the redundant files the entire model is run by calling the other components from a central database fig 6 input is taken from the weather forecaster and the hydrologist after the model calibration is performed the water level forecasting work is done inside the hec ras gui the hec ras native files are connected to the forecasting shells through the hec ras general adapter and fews pi xml files the master controller with the central database is inter connected with the forecasting shells the forecaster s local database and the hydrologist s local database the user visually interacts with delft fews through its gui to enable this deltares who developed the delft fews system provides an executable file with the software package all other xml files stored in their corresponding folders are connected with this executable file despite being a machine human readable format the xml coded files are not user friendly in their visual sense the delft fews user interface establishes that connection between the user and the delft fews data structure for example the data display attribute of the delft fews gui displays data e g amount of rainfall discharge water level etc in graphical and tabular format fig 7 the table and chart tools in the toolbar open up the data table and the corresponding graph chart respectively the viewer can see both the data and the graph regarding those data in a single gui of delft fews it gives a better comprehension of the forecast data than presenting only one either in tabular or graphical format in the interface several statistical functions can be used using the selection tool these are scatter plot double mass curve duration curve cumulative calendar aggregation accumulation per interval accumulation aggregation relative aggregation moving average and central moving average 3 5 nonlinear autoregressive network with exogenous inputs narx a nonlinear autoregressive network with exogenous inputs narx a recurrent dynamic network is based on feedback connections including multiple layers of the network where the nodes of a feedforward neural network fnn work on a one directional flow recurrent networks like narx based workflow goes in both directions forward and backward di nunno and granata 2020 the narx model is defined by this equation eqn 1 y t f y t 1 y t 2 y t ny o t 3 o t 4 o t no in this equation o t is the input layer which is the observed water level it starts from t 3 because the forecast was given with a 72 h lead time y t is the output layer which is the predicted water level of the model without narx n o and n y are the input and output network layers respectively which represent the total number of days for which the observed water levels are being considered and the forecast water levels are being delivered the hidden layer size was 2 as per the narx model architecture output y t is further put into the model as input values bayesian regularization backpropagation was used to update the weight w and bias b values according to the levenberg marquardt optimization mathworks 2020 f 1 and f 2 are the activation functions for the hidden layer and the output layer respectively h 1 and h 2 are the parameters of the hidden layer activation function whereas n is a parameter for the output layer activation function the schematic diagram of the full narx architecture is presented in fig 3 narx model was used on the forecast data of this study 3 6 statistical parameters the goodness of fit analysis has been carried out with four statistical indicators r square value r2 nash sutcliffe efficiency nse percent bias pbias and root mean square error rmse in hydrological modelling these four are the most widely used goodness of fit indices parhi et al 2012 tazin 2018 nse indicates the measured data variance compared to the magnitude of the residual variance it ranges from 1 to negative infinity where 1 is the optimal value on the other hand r2 indicates the amount of variance in the dependent variable predicted from the independent variable it ranges from 0 to 1 where 1 is the optimal value percent bias pbias indicates the overall tendency of the simulated values to deflect on either the positive or negative side with respect to the observed values a pbias value of 0 indicates its optimum accuracy meaning no deviation between the simulated and observed data root mean square error rmse was also calculated for the error quantification purpose eqn 2 n s e 1 i 1 n y i o b s y i s i m 2 i 1 n y i o b s y m e a n o b s 2 eqn 3 r 2 i 1 n y i o b s y m e a n o b s y i s i m y m e a n s i m i 1 n y i o b s y m e a n o b s 2 i 1 n y i s i m y m e a n s i m 2 2 eqn 4 p e r c e n t b i a s p b i a s i 1 n y i o b s y i s i m i 1 n y i o b s 100 eqn 5 r m s e 1 n i 1 n y i o b s y i s i m 2 where y i o b s and y i s i m are the ith observed and simulated constituents which is the water level in this case y m e a n o b s and y m e a n s i m are the mean observed and simulated water level data and n is the total number of observations 4 results and discussion 4 1 calibration and validation of the hec ras 1d model for flash flood forecasting 25 bwdb water level gauge stations were calibrated for 2010 12 and validated for 2013 15 figs 8 and 9 the goodness of fit parameters indicated the suitability of the hydrodynamic model showing minimally acceptable to a very good range result in most of the stations the r square value was above 0 7 which is satisfactory the statistical parameters had shown some discrepancies in depicting model performance in the case of some of the stations for ballah durgapur habiganj islampur jariajanjail and lourergorh the r square value ranged from 0 5 to 0 66 which is minimally acceptable but the nse value was quite satisfactory 0 83 0 99 for some stations the rmse value was greater than 1 e g fenchuganj gowainghat habiganj kalmakanda and sarighat nevertheless the value is satisfactory for gowainghat habiganj kalmakanda and sarighat as the water level in mpwd it is a water level measurement unit used by bwdb and other government organizations of bangladesh pwd is a horizontal datum believed originally to have zero at a determined mean sea level msl at calcutta pwd is located approx 1 5 ft below the msl established in india under british rule and brought to bangladesh during the great trigonometric survey range for these stations are 2m 5m 2m 5m 0m 3m and 2m 6m respectively as in fenchuganj the water level in mpwd varies from 1m to 3m an rmse value of 1 56 is minimally acceptable as the water level data range is not wide enough the pbias value is over 20 for three stations fenchuganj 27 03 habiganj 20 67 and sarighat 27 99 where the other stations are showing satisfactory pbias values these three stations have also shown poor performance in rmse values these deviations in the statistical performance values of these three stations may occur from the river channel s cross sectional or longitudinal geometry i e high steep slope relevant uncertainties in meteorological and hydrological prediction as well as the errors in observed data collection can also be a major factor here in the validation period fig 9 all the stations depicted an r square value greater than 0 7 except for durgapur 0 44 jarijanjail 0 45 and sarighat 0 62 ballah habiganj islampur and lourergarh obtained a better r square value 0 8 in the validation period than the calibration whereas sarighat performed poorly despite showing good results in the calibration period most of the stations have shown a satisfactory pbias value which is less than 20 except for fenchuganj 22 93 kalmakanda 34 01 kanairghat 21 41 markuli 22 5 and sunamganj 20 55 kalmakanda kanairghat markuli and sunamganj performed poorly whereas habiganj 7 72 and sarighat 3 81 did better in the validation period the difference in the performance indicates the year wise fluctuation in water level in some stations of the northeast region the accuracy of prediction also varied because of this 4 2 forecast evaluation using this model integrated into delft fews iwfm and buet provided a real time water level forecast for 24 stations to bwdb for the flash flood season of 2021 april may on a three hourly basis nonlinear autoregressive network with exogenous inputs narx model was used on the final product of delft fews for fine tuning the result it was used only in the case of forecast evaluation not in the calibration and validation phases the forecast accuracy of the stations for this season is presented in fig 10 with narx and fig 11 without narx all of the stations have shown satisfactory results in all four statistical parameters except for amalshid nse 0 59 and sutang rly bridge nse 0 5 which is minimally acceptable pbias value within 1 and rmse value less than 0 1 indicates good results in ballah durgapur and islampur none of the selected stations has shown extremely anomalous results with the narx model applied a comparison between figs 10 and 11 clearly shows that narx has improved the accuracy of the forecast evaluation a comparison between observed and simulated water levels is shown in fig 12 here the data from nine stations have been shown similarly forecasts were given for in total of 24 bwdb stations 5 conclusions this study focuses on developing an integrated flash flood forecasting model for the northeast region of bangladesh as the integration happened among multiple models there are some uncertainties concerned in every step e g meteorological hydrological and hydrodynamic models the uncertainties can arise from the model input uncertainties from the parameters and the simplification of the hydrological processes wang et al 2017 the errors that occurred in the end outputs might be due to these uncertainties and quantifying these can be a significant extension of this study however the quantification of uncertainty did not fall under the scope of this study where the primary goal was to display the model s performance in real time its mechanism and its advantages from the users perspective moreover flood forecasting can also be done using two dimensional frameworks dottori et al 2017 bhola et al 2018 though in this study one dimensional modelling was performed the following conclusions were drawn from this study 1 the integrated model performed well in both the calibration 2010 12 and validation 2013 15 periods some stations showed contrasting results in these two different periods indicating the year wise fluctuation of flash flood water level data 2 the model depicted good performance in real time to forecast the flash flood water level for the flash flood season of 2021 april may the r square value ranged from 0 78 to 0 99 for all the stations other statistical parameters also showed similar types of results delft fews is an automatic data handling platform that enables the user to incorporate multiple models in a single graphical user interface this paper illustrates a thorough procedure on how to integrate meteorological hydrological and hydrodynamic models in delft fews in the delft fews system rainfall forecasts from a weather forecast model wrf are transferred from a binary netcdf file into a comma separated value csv file which will then be used to derive the open source based hydrological model hec hms both machine and human readable extensible markup language xml files are the native data format of the delft fews system and all types of data are linked with it through an adapter file called the general adapter file this general adapter transfers the xml data into the hec hms native file format and after completion of the simulation the hec hms adapter passes the relevant results files back to the delft fews general adapter in xml format the hec ras model was derived using the flow boundary conditions of the hec hms model similar to the hec hms the general adapter of hec ras plays the role of input and output data exchange and simulates the hec ras model the delft fews user interface establishes the connection between the user and different types of data structures such as maps graphs satellite images etc this interface can be used to display and generate early warning messages containing different text and graphical plots such as time series plots spatial plots background maps etc this study presents the implementation of the delft fews system for flash flood forecasting and the generation of early warnings in the northeast region of bangladesh it will help the practitioners and other researchers to work with these models inside delft fews reduce the time of modelling the entire procedure and better understand the forecast within a short period declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work has been supported by a research project on developing flash flood early warning system capacity building and knowledge management for haor region of bangladesh currently being carried out at the institute of water and flood management iwfm of bangladesh university of engineering and technology funded by a haor area infrastructure and livelihood improvement hilip project of local govt engineering department lged sponsored by the international fund for agricultural development ifad the authors would like to acknowledge the use of hydrological data from the bangladesh water development board bwdb we also thank md jamal uddin khan ex research associate iwfm buet for his valuable suggestions appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105614 
25444,the northeast region of bangladesh is highly vulnerable to flash floods which often damage the only crop of that region the boro rice developing an efficient and real time flash flood forecasting system for that region is found essential the traditional model centric approach requires plenty of time and manpower to effectively model flash floods this paper discusses an open source data centric integrated flash flood modelling approach using a platform named delft fews it is based on three inter dependent models e g meteorological hydrologic and hydrodynamic the model was calibrated and validated with the flash flood data of 2010 12 and 2013 15 respectively the performance of the model in real time was assessed in the context of the 2021 flash flood season in both cases it performed satisfactorily the entire system helps the practitioners to work in a flexible environment to generate flash flood forecasting and early warnings keywords delft fews flash flood graphical user interface integrated modelling open source model data availability data will be made available on request 1 introduction flash flood is generally defined as an abrupt water rush through a narrow channel or over a sloping surface that occurs due to a sudden heavy rainfall in the upstream hilly regions sweeney 1992 roy et al 2019 compared to other flood events flash floods are uniquely characterized by their immediate inception within a short span collier 2007 haque 2016 das et al 2020 the higher frequency of devastating flood events due to climatic change reduced the mass acceptance of conventional structural steps for flood protection kuang and kuei hsien liao 2020 mohanty et al 2020 pour et al 2020 shah et al 2018 werner and whitfield 2007 in this regard the global community widely recognized the operational flood forecasting and warning system for its effectiveness haggett 1998 wmo 2006 cloke and pappenberger 2009 changa et al 2019 sahraei et al 2020 but these conventional model centric approaches require much labor in real time flood forecasting and therefore may not be suitable for flash flood forecasting werner and whitfield 2007 to make the system effective the user needs a flexible operational flood forecasting model integrated into a single platform werner et al 2013 modern flood forecasting models are generally based on multiple software models where each of them is assigned to an exclusive task i e the software assigned for rainfall forecasting will not perform the task of discharge modelling or water level forecasting the users or practitioners link these tools to get the end level forecast output it is cumbersome to work with multiple models in separate graphical user interfaces gui and often consumes more time than working on a single platform however multi model forecasts are proven to be comparatively better than the single model based forecasting system and therefore have attracted much attention recently barthélémy et al 2018 khan et al 2019 kao et al 2020 puttinaovarat and horkaew 2020 barthélémy et al 2018 developed a coupled one dimensional 1d two dimensional 2d hydraulic model for multi dimensional flow khan et al 2019 discussed the assimilation of multi sensor remote sensing data for the indus river basin irb loi et al 2019 coupled the swat and hec ras models to create a coupled hydrologic hydraulic modelling system for vu gia thu bon river basin vietnam ming et al 2020 integrated a numerical weather prediction model and a 2d high performance hydrodynamic model for real time flood forecasting kao et al 2020 proposed a long short term memory based encoder decoder lstm ed model for multi step ahead operational flood forecasting puttinaovarat and horkaew 2020 used an adaptive machine learning framework to integrate meteorological hydrological geospatial and crowdsource big data agarwal et al 2020 coupled the hec hms and bias corrected wrf rainfall forecast and thus operationalized the flood forecasting system of ayeyarwady river myanmar tian et al 2020 developed a coupled wrf gridded hebei model interestingly these models dealt with coupling a maximum of two forecast models either coupling the meteorological and the hydrological models or the hydrological and the hydraulic models limited research has been done on integrating more than two types of models in a single environment werner et al 2013 presented a hypothetical workflow integrating three types of models e g atmospheric model hydrological model and hydrodynamic model for flood forecasting in a simple basin a basin having a simple topography and including single river channel network rather than complex crisscrossed river network however they did not show the step by step software based modelling procedure and how to integrate them into a single platform keum and coulibaly 2018 integrated three models in the delft fews platform but all of the models were hydrologic models no atmospheric or hydraulic model was used in their study addressing this research gap a proper framework for integrating three different types of models e g atmospheric hydrologic and hydrodynamic models has been discussed in our study in the case of incorporating numerous modelling components in a single central data modelling platform a monolithic modelling approach will generate computational complexity harvey et al 2002 to avoid this difficulty a comparatively more flexible approach should be selected for operational flood forecasting werner et al 2013 since its first usage for the nile basin delft fews has been providing a general data centric platform for integrating various types of models grijssen et al 1992 using this platform the federal flood commission of pakistan developed the indus flood forecasting system werner and van dijk 2005 bogaard et al 2016 developed a hydro meteorological and morphological model based 2d framework which is connected with a bayesian network decision support system dss using delft fews it was also used in the national weather service and bonneville power administration in the united states of america yang and welles 2017 keum and coulibaly 2018 integrated three hydrologic models e g snow17 raven and watflood to build a multi watershed flood forecasting system using delft fews valchev et al 2018 implemented and validated a coastal hazard forecasting system for varna bay using this software the global fluvial flood forecasting system gloffis a real time fluvial flood forecasting system operated by deltares uses a workflow framework embedded within the delft fews den toom et al 2020 real time flash flood forecasting is different from other types of flood forecasting considering the greater uncertainty in precipitation forecasts than the other parameters e g water discharge and water level and a very short lead time mohammed et al 2017 particularly in the northeast region of bangladesh some extremely complex uncertain and nonlinear physical processes are involved in the conversion of rainfall and subsequent runoff into water levels therefore it has drawn the attention of the scientific community in recent years khan and mostafa ali 2020 developed a hydrologic model for the jadukata river basin situated in the northeast region of bangladesh using hec hms 3 5 0 but they did not include the entire northeast region outside of bangladesh long short term memory lstm networks song et al 2020 and entropy based decision approach lin et al 2021 have been used in flash flood forecasting the flood forecasting and warning center ffwc of the bangladesh water development board bwdb makes flash flood forecasts for bangladesh using the mike11 flood forecasting system mike11 ff paudyal 2002 currently ffwc is using a one dimensional fully hydrodynamic model mike11 hd which is linked to a lumped conceptual rainfall runoff model mike11 rr ffwc 2020 mike11 ff system is a non customizable system from the user end a customizable system allows the model developers to make the interaction between separate software components valchev et al 2018 and ensures greater flexibility since the community gets free access to the customizable features of these systems they are developed rapidly through interaction among the community members the xml files of the delft fews software used in this study are fully customizable from the user end and the codes provided with it are open for the users moreover the other three software used here wrf hec hms and hec ras are also free to use therefore the developed model provides ample opportunity to work in the field of open science in this context the institute of water and flood management iwfm buet has developed a customizable flash flood modelling system using delft fews it includes four components 1 wrf for forecasting rainfall over the upper meghna basin 2 hydrological model using hec hms to generate boundary flow of the transboundary rivers 3 hydraulic routing using a one dimensional model hec ras and 4 integrated graphical interface delft fews to prepare a real time forecast and provide early warnings a nonlinear autoregressive network with exogenous inputs narx model has been applied to the final product of the forecast evaluation to summarize the research gaps we have identified three points in particular i limited flash flood forecasting models had been developed incorporating the geographical complexity of the northeast region of bangladesh ii traditional flood forecasting models are incompetent to be used in flash floods and thus necessitates an integrated modelling environment iii current flash flood modelling system used by bwdb is non customizable necessitating an open source and customizable user friendly forecasting system to cover the research gaps mentioned earlier two specific objectives are fixed for this study i the development of a customizable open source flash flood forecasting and dissemination system integrating atmospheric hydrologic and hydrodynamic models and ii assessing its performance in real time flash flood season through statistical analyses for the northeast region of bangladesh 2 study area and data acquisition the study encompasses the meghna basin area covering 20 022 sq km consisting of seven districts of the northeast region of bangladesh e g sylhet sunamganj habiganj moulovi bazar kishoreganj brahmanbaria and netrokona cegis 2012 the entire basin area as well as the rain gauge stations of the bangladesh meteorological department bmd and the indian meteorological department imd are depicted in fig 1 a the water level wl and hec ras boundary stations are presented in fig 1 b this region is severely vulnerable to flash floods consisting of 400 wetlands with nearly 23 transboundary rivers that enter from neighboring india suman and bhattacharya 2015 in early 2017 it was severely affected by flash floods where nearly 1 million households and us 450 million worth of rice crops were damaged kamal et al 2018 a subtropical monsoonal climate prevails here with an average annual rainfall of approximately 4000 mm roy et al 2019 it is surrounded by indian states e g meghalaya in the north tripura in the south and assam in the east rahman et al 2018a haors bowl shaped depressions seasonally flooded with monsoon water and beels permanent shallow lakes which typically remain inundated even during the dry seasons are the prevalent hydrological features of this floodplain rahman et al 2018b the selected 25 water level stations for this study spread over the major rivers of this region bhogai kangsa dhalagang dhalai dhanu jadukata jhalukhali kalni khowai kushiyara manu sari gowain someswari surma and sutang all the observed water level data were collected from bwdb which is the officially mandated organization for collecting hydrologic data in bangladesh we considered 3 h water level data for the calibration validation and forecast evaluation period as the concentration of the flash floods is very short in duration all the water level data used in this study were in terms of the public works datum pwd it is approximately 0 46 m 1 5 ft below the mean sea level msl ffwc 2018 3 methodology 3 1 numerical weather prediction nwp model the mesoscale numerical model advanced research version of the weather research and forecasting wrf arw simulated precipitation product is used for estimating heavy precipitation in a finer resolution for the flash flood event of pre monsoon season das et al 2020 the wrf model is a new generation mesoscale numerical weather prediction nwp system designed to serve both operational forecasting and atmospheric research needs the model physics options and parameterization details are presented in skamarock et al 2019 wrf is suitable for a broad spectrum of applications across scales ranging from meters to thousands of kilometers the model is widely used for research purposes for resolving regional and local scale level phenomena nowadays it is popularly used in operational applications and decision making procedures abbasi et al 2021 chen et al 2020 kehrein et al 2020 the wrf model simulated three hourly precipitation obtained by studying model grid resolution three nested domains results are compared to check the grid resolution performance in fig 2 a global to regional g2r 1 3 i e 27 and 9 km and the global to convection permitting g2c 1 9 i e 9 and 3 km scale ratios fig 2 sensitivity analyses of different parameterization schemes are applied to find out the best combination for the flash flood trigger region the model simulated precipitation is assessed and verified with the available rain gauge observation along with india meteorological department imd and global precipitation measurement gpm mission merged datasets the wrf features used in this study are mentioned in table 1 the 1 0 1 0 gridded ncep fnl final operational global analysis and global forecast system gfs data are used as initial and lateral boundary conditions lbc of the numerical model simulation das et al 2020 the wrf model was simulated for a period of 78 h starting at 0000 utc every day as initial values every 30 minutes of model output were simulated for further calibration and validation due to the large volume of data only 3 hourly interval data are post processed from the model simulation which is comparable with the meteorological rain gauge station observation and trmm data 3 2 hydrological model in this hydrologic model we focused on the entire hydrograph and also captured the peak flows to better represent the flashy nature of the floods as flash floods depict multiple flood peaks during the pre monsoon season in bangladesh hec hms is suitable for this type of phenomenon czigány et al 2010 the soil moisture accounting sma method a continuous model available in hec hms is one of the most efficient continuous model simulations to simulate peak flow storm volume and time to peak razmkhah 2016 rainfall derived from the meteorological model is the only primary input data considered here to support the different parametric assumptions in the loss method land use and soil type data were used initial state values of baseflow for the stream were found considering the observed baseflow recorded for a basin then the model was simulated for a week with observed rainfall data for the stabilization of the modelling network later this initial run was saved and used for the hot start of the model for the validation run the end state of the calibration run was used to start the validation run to run hec hms in the delft fews environment several changes are needed in the hec hms files at first a new coldstate directory is created to keep the specific hec hms state file inside the fews environment the delft fews adapter prepared a dss file using the forcing time series from delft fews a zipped version of the hec hms files e g basin control gage etc are kept in the corresponding folder a general adapter file idmapfiles and a workflow file are created respectively after that the hec hms general adapter can run the models both in continuous and event modes we have continuously simulated the model from the beginning of the season for calibration and validation for forecasting purposes the model is simulated every time for five days with a 48 h hindcast to provide a 72 h forecast in this case operational flood forecasting was done and the continuous mode was chosen to conduct the process in the case of creating idmapfiles for hec ras to fews parameter interchanging a model state management step is followed instead of creating three sub folders for hec hms files a schematic representation of these steps is presented in fig 4 calibration was done manually in the hydrological model of the 16 parameters mentioned in table 2 the initial assumption for all the parameters was taken from previous literature on similar hilly sub basins and based on the curve number found for each basin the curve number which is unique to each basin is found by using land use data from globcover 2009 and soil use data from food and agriculture organization fao the source of each parameter is added to table 2 for reference only 7 parameters were calibrated based on the sensitivity of these parameters on the basin runoff and these parameters are initial storage maximum storage moisture in soil water to the groundwater layer 1 imperviousness soil storage and tension storage table 2 presents the calibrated parameters and their corresponding processes the parameters were calibrated based on the effect they had on the basin outflow haque et al 2017 performed a sensitivity analysis in the sari gowain river of the meghna basin the order of calibrating the parameters in our study was based on the ranking presented in this work automated tuning was employed but showed low improvement so tuning was done on each parameter individually to see which value presented the lowest rmse rse and highest r2 and nse in this study an automated calibration tool for multiple parameters was not implemented in the system therefore manual calibration was opted to account for the interdependent nature of each parameter in the basin here we have set up and calibrated the model manually based on a widely used model evaluation criteria as described in moriasi et al 2007 it sets up the performance rating criteria as such very good 0 75 nse 1 00 pbias 10 good 0 65 nse 0 75 10 pbias 15 satisfactory 0 50 nse 0 65 15 pbias 25 and unsatisfactory nse 0 50 pbias 25 the parameters were calibrated and validated until the statistical parameters achieved the best results achievable demonstrated by the comments it was not always very good for each of the cases sometimes the best result we achieved was good sometimes it was satisfactory and then we stopped hot start was used for the calibration and validation and the model results of the last run during calibration were used as a hotstart for the second run during validation to ensure a continuous model run parameter values were not the same throughout the basin it varied through different sub basins based on the topography soil and land use type of each sub catchment satellite data was used to determine the vegetation of a sub basin and the width of each of the channels table 2 the observed baseflow was recorded for each sub basin where data was available the lead time for the pre monsoon months of the calibration period was 1 month starting from february 2010 to march 2010 the calibration and validation were done in simulation mode preparing the model using observed historical data on the other hand near real time flash flood forecasting using the fews model was simulated in both hindcast and forecast modes in hindcast mode the model was simulated for 7 days forced by observed rainfall from bangladesh meteorological department bmd and india meteorological department imd while in forecast mode the model was simulated for 3 days forced by wrf simulated rainfall the hec hms model was forced by precipitation and monthly mean evapotranspiration for the water balance calculations in hindcast mode the hec hms model was simulated using observed daily rainfall from bmd and imd while in forecast mode the hec hms model was forced by hourly wrf forecasted rainfall in table 2 the initial canopy storage is defined as the percentage of the canopy storage that is full of water at the beginning of the simulation the canopy can store a fixed effective depth of water expressed in mm unit before external precipitation is added with it circulated through the soil surface this is identified as storage the percentage of moisture in the soil means the amount of water present in a certain volume of soil the percentage of water to the groundwater in the soil profile indicates the amount of water stored in the top layer of the soil compared to the outflow percolation contributing to the amount of groundwater considering a specific land cover layer there are certain portions where water cannot enter into the soil in a certain cross section or two dimensional flow area this is represented as the percentage of imperviousness compared to the entire area 3 3 hydrodynamic model hec ras the open source software for hydrodynamic modelling was applied for the flow assessment it uses finite difference solutions of the saint venant equations peters et al 2006 the river networks consist of a total of 173 junctions river cross section data were collected and inserted from bwdb and the iwfm database to conduct the unsteady flow simulation of the northeast region of bangladesh flow hydrographs of 34 rivers were inserted the manual calibration of the hydrodynamic model was done by selecting an appropriate value of manning s n value it was selected in such a way that the simulated water level data gets as close as the observed water level data in a particular time period in general the delft fews general adapter provides the necessary data in a standardized xml format to run hec ras and calls the hec ras module adapter this adapter transfers the xml data into the hec ras native file formats after the run gets completed the hec ras adapter passes the relevant result files back to the delft fews general adapter in xml format the entire process is schematically represented in fig 5 the entire model has been simulated for 72 h of lead time and a 1 week hindcast period 3 4 integration in delft fews in the open source flash flood forecasting model used by iwfm buet the use of delft fews provided strong integrity if the other three components e g wrf hec hms and hec ras were used separately without the involvement of delft fews it would become cumbersome to use the system the reason is in that case the user had to transfer model information and data transfer from the model to the model manually there are different types of files used in the delft fews environment among them the extensible markup language xml files zip files and comma separated values csv files are noteworthy besides them text files and chemical binary format cbin files are also used here however based on the usage of different models a variety of other file types e g dll basin gage met etc can be incorporated inside the software environment before running a module or any sort of data exchange startup activities were performed to remove files from the previous runs that might implicate the current simulation export activities were run to export all corresponding items to the external module using xml formats the external executables or java classes were run by the execute activities they are divided into three parts e g the pre adapter the actual module run and the post adapter after successfully running the module import activities were performed to bring back all the necessary items at last shutdown activities removed all the redundant files the entire model is run by calling the other components from a central database fig 6 input is taken from the weather forecaster and the hydrologist after the model calibration is performed the water level forecasting work is done inside the hec ras gui the hec ras native files are connected to the forecasting shells through the hec ras general adapter and fews pi xml files the master controller with the central database is inter connected with the forecasting shells the forecaster s local database and the hydrologist s local database the user visually interacts with delft fews through its gui to enable this deltares who developed the delft fews system provides an executable file with the software package all other xml files stored in their corresponding folders are connected with this executable file despite being a machine human readable format the xml coded files are not user friendly in their visual sense the delft fews user interface establishes that connection between the user and the delft fews data structure for example the data display attribute of the delft fews gui displays data e g amount of rainfall discharge water level etc in graphical and tabular format fig 7 the table and chart tools in the toolbar open up the data table and the corresponding graph chart respectively the viewer can see both the data and the graph regarding those data in a single gui of delft fews it gives a better comprehension of the forecast data than presenting only one either in tabular or graphical format in the interface several statistical functions can be used using the selection tool these are scatter plot double mass curve duration curve cumulative calendar aggregation accumulation per interval accumulation aggregation relative aggregation moving average and central moving average 3 5 nonlinear autoregressive network with exogenous inputs narx a nonlinear autoregressive network with exogenous inputs narx a recurrent dynamic network is based on feedback connections including multiple layers of the network where the nodes of a feedforward neural network fnn work on a one directional flow recurrent networks like narx based workflow goes in both directions forward and backward di nunno and granata 2020 the narx model is defined by this equation eqn 1 y t f y t 1 y t 2 y t ny o t 3 o t 4 o t no in this equation o t is the input layer which is the observed water level it starts from t 3 because the forecast was given with a 72 h lead time y t is the output layer which is the predicted water level of the model without narx n o and n y are the input and output network layers respectively which represent the total number of days for which the observed water levels are being considered and the forecast water levels are being delivered the hidden layer size was 2 as per the narx model architecture output y t is further put into the model as input values bayesian regularization backpropagation was used to update the weight w and bias b values according to the levenberg marquardt optimization mathworks 2020 f 1 and f 2 are the activation functions for the hidden layer and the output layer respectively h 1 and h 2 are the parameters of the hidden layer activation function whereas n is a parameter for the output layer activation function the schematic diagram of the full narx architecture is presented in fig 3 narx model was used on the forecast data of this study 3 6 statistical parameters the goodness of fit analysis has been carried out with four statistical indicators r square value r2 nash sutcliffe efficiency nse percent bias pbias and root mean square error rmse in hydrological modelling these four are the most widely used goodness of fit indices parhi et al 2012 tazin 2018 nse indicates the measured data variance compared to the magnitude of the residual variance it ranges from 1 to negative infinity where 1 is the optimal value on the other hand r2 indicates the amount of variance in the dependent variable predicted from the independent variable it ranges from 0 to 1 where 1 is the optimal value percent bias pbias indicates the overall tendency of the simulated values to deflect on either the positive or negative side with respect to the observed values a pbias value of 0 indicates its optimum accuracy meaning no deviation between the simulated and observed data root mean square error rmse was also calculated for the error quantification purpose eqn 2 n s e 1 i 1 n y i o b s y i s i m 2 i 1 n y i o b s y m e a n o b s 2 eqn 3 r 2 i 1 n y i o b s y m e a n o b s y i s i m y m e a n s i m i 1 n y i o b s y m e a n o b s 2 i 1 n y i s i m y m e a n s i m 2 2 eqn 4 p e r c e n t b i a s p b i a s i 1 n y i o b s y i s i m i 1 n y i o b s 100 eqn 5 r m s e 1 n i 1 n y i o b s y i s i m 2 where y i o b s and y i s i m are the ith observed and simulated constituents which is the water level in this case y m e a n o b s and y m e a n s i m are the mean observed and simulated water level data and n is the total number of observations 4 results and discussion 4 1 calibration and validation of the hec ras 1d model for flash flood forecasting 25 bwdb water level gauge stations were calibrated for 2010 12 and validated for 2013 15 figs 8 and 9 the goodness of fit parameters indicated the suitability of the hydrodynamic model showing minimally acceptable to a very good range result in most of the stations the r square value was above 0 7 which is satisfactory the statistical parameters had shown some discrepancies in depicting model performance in the case of some of the stations for ballah durgapur habiganj islampur jariajanjail and lourergorh the r square value ranged from 0 5 to 0 66 which is minimally acceptable but the nse value was quite satisfactory 0 83 0 99 for some stations the rmse value was greater than 1 e g fenchuganj gowainghat habiganj kalmakanda and sarighat nevertheless the value is satisfactory for gowainghat habiganj kalmakanda and sarighat as the water level in mpwd it is a water level measurement unit used by bwdb and other government organizations of bangladesh pwd is a horizontal datum believed originally to have zero at a determined mean sea level msl at calcutta pwd is located approx 1 5 ft below the msl established in india under british rule and brought to bangladesh during the great trigonometric survey range for these stations are 2m 5m 2m 5m 0m 3m and 2m 6m respectively as in fenchuganj the water level in mpwd varies from 1m to 3m an rmse value of 1 56 is minimally acceptable as the water level data range is not wide enough the pbias value is over 20 for three stations fenchuganj 27 03 habiganj 20 67 and sarighat 27 99 where the other stations are showing satisfactory pbias values these three stations have also shown poor performance in rmse values these deviations in the statistical performance values of these three stations may occur from the river channel s cross sectional or longitudinal geometry i e high steep slope relevant uncertainties in meteorological and hydrological prediction as well as the errors in observed data collection can also be a major factor here in the validation period fig 9 all the stations depicted an r square value greater than 0 7 except for durgapur 0 44 jarijanjail 0 45 and sarighat 0 62 ballah habiganj islampur and lourergarh obtained a better r square value 0 8 in the validation period than the calibration whereas sarighat performed poorly despite showing good results in the calibration period most of the stations have shown a satisfactory pbias value which is less than 20 except for fenchuganj 22 93 kalmakanda 34 01 kanairghat 21 41 markuli 22 5 and sunamganj 20 55 kalmakanda kanairghat markuli and sunamganj performed poorly whereas habiganj 7 72 and sarighat 3 81 did better in the validation period the difference in the performance indicates the year wise fluctuation in water level in some stations of the northeast region the accuracy of prediction also varied because of this 4 2 forecast evaluation using this model integrated into delft fews iwfm and buet provided a real time water level forecast for 24 stations to bwdb for the flash flood season of 2021 april may on a three hourly basis nonlinear autoregressive network with exogenous inputs narx model was used on the final product of delft fews for fine tuning the result it was used only in the case of forecast evaluation not in the calibration and validation phases the forecast accuracy of the stations for this season is presented in fig 10 with narx and fig 11 without narx all of the stations have shown satisfactory results in all four statistical parameters except for amalshid nse 0 59 and sutang rly bridge nse 0 5 which is minimally acceptable pbias value within 1 and rmse value less than 0 1 indicates good results in ballah durgapur and islampur none of the selected stations has shown extremely anomalous results with the narx model applied a comparison between figs 10 and 11 clearly shows that narx has improved the accuracy of the forecast evaluation a comparison between observed and simulated water levels is shown in fig 12 here the data from nine stations have been shown similarly forecasts were given for in total of 24 bwdb stations 5 conclusions this study focuses on developing an integrated flash flood forecasting model for the northeast region of bangladesh as the integration happened among multiple models there are some uncertainties concerned in every step e g meteorological hydrological and hydrodynamic models the uncertainties can arise from the model input uncertainties from the parameters and the simplification of the hydrological processes wang et al 2017 the errors that occurred in the end outputs might be due to these uncertainties and quantifying these can be a significant extension of this study however the quantification of uncertainty did not fall under the scope of this study where the primary goal was to display the model s performance in real time its mechanism and its advantages from the users perspective moreover flood forecasting can also be done using two dimensional frameworks dottori et al 2017 bhola et al 2018 though in this study one dimensional modelling was performed the following conclusions were drawn from this study 1 the integrated model performed well in both the calibration 2010 12 and validation 2013 15 periods some stations showed contrasting results in these two different periods indicating the year wise fluctuation of flash flood water level data 2 the model depicted good performance in real time to forecast the flash flood water level for the flash flood season of 2021 april may the r square value ranged from 0 78 to 0 99 for all the stations other statistical parameters also showed similar types of results delft fews is an automatic data handling platform that enables the user to incorporate multiple models in a single graphical user interface this paper illustrates a thorough procedure on how to integrate meteorological hydrological and hydrodynamic models in delft fews in the delft fews system rainfall forecasts from a weather forecast model wrf are transferred from a binary netcdf file into a comma separated value csv file which will then be used to derive the open source based hydrological model hec hms both machine and human readable extensible markup language xml files are the native data format of the delft fews system and all types of data are linked with it through an adapter file called the general adapter file this general adapter transfers the xml data into the hec hms native file format and after completion of the simulation the hec hms adapter passes the relevant results files back to the delft fews general adapter in xml format the hec ras model was derived using the flow boundary conditions of the hec hms model similar to the hec hms the general adapter of hec ras plays the role of input and output data exchange and simulates the hec ras model the delft fews user interface establishes the connection between the user and different types of data structures such as maps graphs satellite images etc this interface can be used to display and generate early warning messages containing different text and graphical plots such as time series plots spatial plots background maps etc this study presents the implementation of the delft fews system for flash flood forecasting and the generation of early warnings in the northeast region of bangladesh it will help the practitioners and other researchers to work with these models inside delft fews reduce the time of modelling the entire procedure and better understand the forecast within a short period declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work has been supported by a research project on developing flash flood early warning system capacity building and knowledge management for haor region of bangladesh currently being carried out at the institute of water and flood management iwfm of bangladesh university of engineering and technology funded by a haor area infrastructure and livelihood improvement hilip project of local govt engineering department lged sponsored by the international fund for agricultural development ifad the authors would like to acknowledge the use of hydrological data from the bangladesh water development board bwdb we also thank md jamal uddin khan ex research associate iwfm buet for his valuable suggestions appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105614 
