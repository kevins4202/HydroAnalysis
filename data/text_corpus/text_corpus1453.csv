index,text
7265,in this study a novel surrogate model assisted multiobjective memetic algorithm smoma is developed for optimal pumping strategies of large scale coastal groundwater problems the proposed smoma integrates an efficient data driven surrogate model with an improved non dominated sorted genetic algorithm ii nsgaii that employs a local search operator to accelerate its convergence in optimization the surrogate model based on kernel extreme learning machine kelm is developed and evaluated as an approximate simulator to generate the patterns of regional groundwater flow and salinity levels in coastal aquifers for reducing huge computational burden the kelm model is adaptively trained during evolutionary search to satisfy desired fidelity level of surrogate so that it inhibits error accumulation of forecasting and results in correctly converging to true pareto optimal front the proposed methodology is then applied to a large scale coastal aquifer management in baldwin county alabama objectives of minimizing the saltwater mass increase and maximizing the total pumping rate in the coastal aquifers are considered the optimal solutions achieved by the proposed adaptive surrogate model are compared against those solutions obtained from one shot surrogate model and original simulation model the adaptive surrogate model does not only improve the prediction accuracy of pareto optimal solutions compared with those by the one shot surrogate model but also maintains the equivalent quality of pareto optimal solutions compared with those by nsgaii coupled with original simulation model while retaining the advantage of surrogate models in reducing computational burden up to 94 of time saving this study shows that the proposed methodology is a computationally efficient and promising tool for multiobjective optimizations of coastal aquifer managements keywords seawater intrusion surrogate model multiobjective optimization memetic algorithm pumping optimization 1 introduction the contradiction between intensive water demands and groundwater environment restrictions exists in planning and development of coastal regions groundwater in the coastal aquifers is susceptible to deterioration due to its proximity to saltwater in combination with pumping activity and climate change typically irrigation behavior of groundwater resource utilization directly results in seawater intrusion si and further reduces the amount of available freshwater resources given that exceeding 1 of seawater 250 mg l chloride concentration indicates freshwater is unsuitable for drinking werner et al 2013 thus pumping optimization of coastal aquifer is essential to alleviate si caused by continuous and unplanned pumping activity while satisfying water demands and environmental constraints christelis and mantoglou 2016 the linked simulation optimization s o methodologies mantoglou et al 2004 mantoglou and papantoniou 2008 qahman et al 2005 sedki and ouazar 2011 abd elhamid and javadi 2011 javadi et al 2015 have been popularly used in the determination of optimal pumping strategies of coastal groundwater management the s o methodology has the advantages of applicability to non linear groundwater system and universal optimum solution for policymaking however with the s o methodology thousands of evaluations of the simulation model need to be implemented before the optimal set is obtained thus the precision and accuracy of model predictions and computational efficiency of optimization algorithm always determine the practicality and performance of linked s o process bhattacharjya and datta 2005 si involves complex physical and chemical processes including dispersive mixing surface hydrology and density effects caused unstable convection anthropogenic influences and geological characteristics leading to multifaceted challenges for solving coastal groundwater management problems werner et al 2013 fortunately many modular numerical codes such as the commonly used finite difference program seawat guo and langevin 2002 the finite element program femwater lin et al 1997 and the hybridization of finite element and integrated finite difference program sutra voss and provost 2010 can be extensively used to solve the si models for the coupled density dependent flow and solute transport problems however for a regional coastal aquifer the si model is numerically complicated and computationally demanding beyond that decision makers always consider several conflicting objectives of optimization for coastal groundwater management e g maximization of total pumping from production well and minimization of the extent of si which generate a particularly intricate multiobjective optimization problem due to the complexity of coastal aquifer management the s o approaches by use of surrogate models assisted multiobjective evolutionary algorithms smoeas have been receiving increasing attention in recent si optimization problems surrogate models also known as meta models proxy models lower fidelity models and response surfaces are computationally efficient emulators designed to mimic key characteristics of simulation model and have great potential to overcome the computational limitations caused by the optimization management of complex models asher et al 2015 smoeas utilize surrogate models to partially substitute cpu intensive simulation models to save computational cost and solve computationally intensive optimization problems sun et al 2017 surrogate models combined with coastal groundwater management in the linked s o frameworks include a great diversity of available approaches such as radial basis functions christelis and mantoglou 2016 modular neural networks kourakos and mantoglou 2009 2013 genetic programming sreekanth and datta 2010 2011 multivariate adaptive regression splines roy and datta 2017 and evolutionary polynomial regressions hussain et al 2015 actually these surrogate models can be divided into two types i e the on line and off line frameworks at present there are relatively limited on line frameworks implemented in evolutionary algorithm sreekanth and datta 2015 ketabchi and ataie ashtiani 2015 and major off line frameworks presented in coastal aquifer managements e g hussain et al 2015 ataie ashtiani et al 2014 sreekanth and datta 2011 2014 roy and datta 2017 nikolos et al 2008 bhattacharjya and datta 2009 dhar and datta 2009 in general the off line framework involves three steps 1 design of experiments which employ different space filling strategy to obtain key response characteristics of simulation model over design variables feasible space 2 training and validation of surrogate model 3 substitution of original simulation model throughout the optimization process a potential disadvantage of off line framework is that one shot training surrogate model probably cannot accurately represent potential functional relationship between the original model and the interesting and important regions of design variable space or the region of near pareto optimal solutions razavi et al 2012 for example sreekanth and datta 2010 proposed genetic programming coupled with multiobjective genetic algorithm which modified search space based on the relative importance of decision variables and further adaptively retrained surrogate model for achieving more accurate predictions in the vicinity of pareto optimal solutions so as to prevent evolutionary search from falling into local optimum solutions jin 2011 kourakos and mantoglou 2013 employed three criteria based on convergence and diversity of solutions for selecting the most promising offspring to implement adaptive training of modular neural network models and multiobjective optimization management in the central aquifer of santorini island the results suggested that the pareto solutions achieved by surrogate model were better than those solutions by nsgaii coupled with simulation model however the training process used for surrogate model was time consuming even though kourakos and mantoglou 2013 reduced the number of decision variables to simplify the complexity of management model the construction of surrogate model combined with coastal groundwater management is a difficult and computationally demanding task especially in cases with high dimensional decision variables and multi outputs to the best of our knowledge there is no research about coastal groundwater optimization management that employs extreme learning machine elm as surrogate model which has been proposed for training a single hidden layer feedforward neural network huang et al 2006 the essential advantages of elm are high learning accuracy very fast learning speed and least user intervention which can explicitly tackle aforementioned challenges huang et al 2015 the number of hidden layer nodes is a crucial parameter selected by time consuming methods for the prediction performance of elm kernel extreme learning machine kelm is developed which replaces the hidden layer mapping by the kernel function mapping to avoid the hidden layer nodes selection problem wang and han 2014 kelm is more accurate and effective than elm and has better generalization performance for regression and binary class classification applications chen et al 2014 the purpose of this study is to present a linked s o framework that integrates seawat with kelm assisted multiobjective memetic algorithm for pumping optimization of coastal groundwater management subject to environment constraints and water demands the proposed algorithm is then applied to a real world case study in the coastal aquifer underlying southern baldwin county owning to increasing populations economic development and tourism groundwater pumping drastically increased and land use varies considerably in the study region murgulet and tick 2008 lin et al 2009 the multiobjective optimization management of coastal groundwater attempts to find out the optimal pumping design strategy between socioeconomic and environmental factors for simultaneously maximizing the total pumping rates and minimizing the extent of si the proposed s o methodology is generally applicable to any highly parameterized si models at the real world field and large scale coastal groundwater management problems this paper is organized in five sections following this introduction section 2 describes the surrogate model assisted multiobjective optimization framework for coastal aquifer management then section 3 presents the application of the methodology to the real world coastal groundwater management case study in the baldwin county alabama next section 4 illustrates the analysis of optimization results and discussions finally section 5 summarizes and concludes this paper 2 methodology surrogate model assisted multiobjective optimization framework developed in this study for pumping optimization of coastal aquifer comprises two components the first one is the development of kelm surrogate model for substituting the physically based simulators of seawat the second component is an optimization model using surrogate model assisted multiobjective memetic algorithm integrated with kernel extreme learning machine smoma kelm to optimize the pumping strategies satisfying the imposed environment and physical constraints 2 1 numerical model of variable density groundwater flow and solute transport the modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 based program seawat was designed to simulate density dependent groundwater flow and multi species solute transport guo and langevin 2002 the general mathematical equation describing variable density groundwater flow and transport process can be stated as 1 x i ρ k fi h f x i ρ ρ f ρ f z x i ρ s q s ρ s f h f t θ ρ c c t 2 x i θ d ij c k x j x i θ ν i c k q s c k s r n θ c k t where ρ is the density of the native aquifer water ml 3 k fi is the principal component of equivalent freshwater hydraulic conductivity tensor aligned with the principal directions of permeability lt 1 ρf is the density of freshwater ml 3 z is the elevation l hf is the equivalent freshwater head l s f is equivalent freshwater specific storage l 1 t is time t θ is effective porosity c is solute concentration ml 3 ρs is fluid density of source or sink water ml 3 and qs is the volumetric flow rate of sources and sinks per unit volume of aquifer t 1 ck is dissolved concentration of species k ml 3 d ij is the hydrodynamic dispersion tensor l2t 1 vi is the seepage velocity lt 1 ck s is concentration of source or sink flux for species k ml 3 and rn is the chemical reaction term ml 3t 1 the equivalent freshwater head varies with not only pressure and elevation but also the difference in groundwater density while solute concentration further affects the density field thus the flow and transport processes have to be resolved based on explicit or implicit coupling framework the fluid density is regarded as the function of solute concentration and ignored the effects of pressure and temperature 2 2 kernel extreme learning machine extreme learning machine proposed by huang et al 2006 is a novel learning algorithm for single hidden layer feedforward neural networks and composed by a simple three layer structure input layer output layer and hidden layer elm has three distinct advantages i e the extremely fast learning speed the non adjusting hidden node parameters and homogenous architectures for regression analysis or classification for the given training samples n elm can be mathematically stated as 3 i 1 l β i g w i x j b i f j j 1 n where βi is the weight connecting the ith the hidden node to the output node g is a nonlinear piecewise continuous activation function w i is the weight vector connecting the input nodes to the ith the hidden node x j is jth training sample w i x j signifies the inner product of w i and x j bi is the bias of the ith hidden node fj is the output of elm with respect to input vector and l is the number of the hidden nodes the matrix vector form can be further described as 4 h β f 5 h g w 1 x 1 b 1 g w l x 1 b l g w 1 x n b 1 g w l x n b l n l 6 β β 1 β 2 β l t f f 1 f 2 f n t 7 β h t where h is the output matrix of the hidden layer with respect to input matrix which maps the data from n dimensional input space to l dimensional hidden layer random feature space β is the weight vector connecting the ith hidden node and the output nodes h is the moore penrose generalized inverse of matrix h and t t 1 t2 tn t is the actual objective function vectors when elm can learn training samples n with no residuals the orthogonal projection method can be used to calculate matrix h huang 2014 the minimal norm least square method is used in the original implementation of elm to minimize the training error the configuration of elm model is shown in fig 1 in elm if the hidden layer mapping k x in the special kernel implementation is unknown to users the corresponding kernel matrix defined will be given hence the kernel extreme learning machine is proposed to replace the hidden layer mapping in the extreme machine by kernel function mapping in the support vector machine kelm avoids hidden nodes number selection that is a difficult task and important to the performance of prediction model then the output function of elm can be stated as 8 f x k x h t hh t 1 ω 1 t ke x x 1 ke x x n t ω elm 1 ω 1 t 9 ω elm hh t ω elm k x i k x j ke x i x j where ω is a user specified regularization parameter the excellent strength of kelm lies in its learning speed that can be thousands of times faster than traditional feedforward network learning algorithms like back propagation algorithm while achieve better generalization performance than elm wang and han 2014 therefore kelm is ideally suited to evolutionary optimization assisted by adaptive surrogate model 2 3 optimization model and methodological framework 2 3 1 multiobjective optimization management model coastal groundwater management model in this study involves two conflicting objectives maximizing total pumping rate for water demands and minimizing the extent of si expressed by the percentage of mass increase in the aquifer at the end of the management horizon furthermore a set of imposed physical constraints ensure that salinity concentrations at the monitoring well locations cannot exceed the prescribed lower limit 500 mg l tds according to water quality requirement and total capacity of pumping wells must exceed the local safe value for water demands the mathematical formulations of management model are given by 10 max j 1 n 1 n t 1 t q n t 11 min j 2 mass end mass ini mass ini 100 subject to 12 c i t c max i 1 2 m t 1 2 t 13 q min q n t q max n 1 2 n t 1 2 t 14 n 1 n t 1 t q n t q cons where j 1 is the first objective indicating total pumping rate l3t 1 qn t is the pumping rate from nth production well during tth management period l3t 1 j 2 is the second objective indicating the percentage of mass increase caused by si in the aquifer at the end of the management horizon massini and massend are the total solute mass in the aquifers at the beginning and end of the management horizon m respectively ci t is the concentration of ith monitoring well at the end of tth management horizon ml 3 c max is the maximum permissible concentration constraint at the monitoring well locations ml 3 eq 13 gives a set of constraints representing the pumping capacity of nth well at the tth management period must be within the specified lower and upper bounds q min q max eq 14 represents total pumping rate must exceed prescribed minimum water demands qcons satisfying the local development both the second objective eq 11 and the constraint eq 12 are the functions of state variables of concentrations calculated by seawat based on decision variables in the present study we exploit trained and tested kelm model ψ and φ to predict the percentage of total mass increase in the coastal aquifers and salinity concentrations at all the monitoring well locations resulting from groundwater extraction in the proposed optimization framework the mathematical formulations of ψ and φ can be stated as 15 j 2 ψ q n t t 1 t n 1 n 16 c i t φ q n t i 1 2 m t 1 2 t n 1 2 n 2 3 2 surrogate model assisted multiobjective memetic algorithm in this study we develop a novel surrogate model assisted multiobjective memetic algorithm integrated with kernel extreme learning machine smoma kelm to optimize the groundwater extraction strategies while satisfying the imposed environment and physical constraints as illustrated in fig 2 the algorithm first generates nt samples spanning evenly over feasible variable space and then establishes the preliminary surrogate model all generated offspring individuals are evaluated based on surrogate models and combined with initial or previous generation of population used for the fast non domination sorting procedure then nsel promising individuals about 20 of population size npop are selected from the approximate pareto optimal solutions based on convergence and diversity at intervals of several generations also the local search operator modified from chen et al 2015 is used to enhance the local optimality of the selected individuals next the nsel optimal local individuals are reevaluated utilizing numerical simulation model and then merged with approximate pareto optimal solutions all solutions evaluated by exact simulation model are archived into external database served as training datasets to improve the accuracy of surrogate model during the optimization finally all individuals in the database compared by fast non dominated sorting to obtain final pareto optimal front the proposed smoma kelm includes three core modules the memetic algorithm criteria for choosing promising individuals and local search operator 2 3 2 1 core module 1 memetic algorithms evolutionary multiobjective optimization emo algorithms have been widely used for solving many practical problems and have flexibility in handing strongly nonlinear groundwater optimization problems however emo algorithms exhibits several shortcomings such as slow convergence speed lack of theoretical convergence proof and efficient stopping criterion sindhya et al 2013 memetic algorithms mas also called hybrid genetic algorithms or cultural algorithms are population based evolutionary search methods that composed by natural evolution based on darwinian principles and cultural evolution capable of local refinements which can alleviate aforementioned problems lim et al 2010 sindhya et al 2008 lara et al 2010 the surrogate model assisted memetic algorithm takes advantages of exploration ability of genetic operators and exploitation capacity of local search for search space furthermore the use of surrogate model can greatly reduce computational burden for the real world optimization applications while maintaining high quality of nondominated solutions the selection of local search methodology is crucial for the performance of memetic algorithms palar et al 2016 and random mutation based on gaussian process is considered in this study 2 3 2 2 core module 2 criteria for choosing promising individuals in this study two infill criteria including the hypervolume improvement akhtar and shoemaker 2016 and the crowding distance deb et al 2002 are employed to improve the efficiency of selection strategies the first selection criterion is hypervolume indicator hv that is mainly employed to compare the performance of the different multiobjective evolutionary algorithms the hypervolume of a given pareto front denotes the dominated region of the non dominated solutions relative to the reference point gray region in fig 3 a the obvious strength of hv is the monotonically increasing relationship between the indicator value and pareto dominance which suggests that the pareto optimal front achieves the maximum hypervolume and the lower indicator value means the worse pareto front bader and zitzler 2011 the hypervolume improvement hypervolume contribution indicator couckuyt et al 2012 2014 implies that the new pareto solutions produce the hypervolume increase of the objective space dominated by a set of non domination solutions dark region in fig 3a the second selection criterion is crowding distance that aims to maintain diversity of pareto optimal solutions in the smoma kelm if the magnitude of hypervolume improvement is less than the specified threshold the comparison of crowding distances is the next criterion for selecting the promising individuals as shown in fig 3b we calculate normalized distance of two consecutive pareto solutions for all candidate solutions and then select the candidate with the largest crowding distance exceptionally if the candidate solution is the boundary solution that is of the smallest or largest value of objective function the crowding distance is set to an infinite value by default finally the new training datasets are generated to retrain kelm model for improving prediction accuracy and further prescreening promising candidate solutions 2 3 2 3 core module 3 local search operator gaussian perturbation is an effective strategy adopted to find an appropriate neighborhood of the candidate solution given a population p and a solution x the set of neighborhood solutions is generated as 17 i i 1 i 1 i n i n 18 i i s 1 s 2 s i c u i r i s n 19 i i s 1 s 2 s i c u i r i s n where i is a set of neighborhood solution vectors s s 1 s 2 si sn is an n dimensional decision variable vector that represents a solution u u 1 u 2 ui un and r r 1 r 2 r i r n are two solutions randomly chosen from the population p i i and i i are two neighborhood solutions of s c is a perturbation factor and n is the number of decision variables each decision variable of the selected solution is mutated by adding the gaussian disturbance to generate 2n neighborhood solutions the strategy deciding whether the neighborhood solutions can replace the current solutions complies with pareto domination concept the parameter c follows a gaussian distribution n μ σ 2 μ and σ are the mean value and the standard deviation respectively the ranges of μ and σ are identically recommended as 0 1 and the ability of local search is insensitive to the setting of the parameters chen et al 2015 surrogate model is a computationally efficient approximate model that can substitute for the time consuming simulation model during coastal groundwater optimization a majority of evaluations of objective functions and constraints can be implemented using surrogate models leading to a substantial time saving in optimization moreover the memetic algorithm combines an evolutionary algorithm ea with a local search module to implement a refinement of local individual solutions and achieve a more computationally efficient and accurate convergence to pareto optimal solutions sindhya et al 2011 therefore smoma kelm possesses the ability of highly effective global search for pareto optimal solutions finding higher quality and diverse solutions with local search operator while solving sophisticated and computationally expensive optimization problems with a limited computational budget 3 application to a real world coastal groundwater management 3 1 hydrogeological conditions and si model 3 1 1 hydrogeological conditions the proposed smoma kelm is applied to pumping optimization in the coastal aquifer primarily affected by si in the southernmost portion of baldwin county fig 4 depicts both the locations and the main hydrogeological characteristic of the study area over the past few decades groundwater as the main freshwater source in this region has been over exploited for municipal industrial private and irrigation purposes resulting in saltwater intrusion into coastal aquifers murgulet and tick 2008 2016 lin et al 2009 the representative cross sections through the study area are illustrated in fig 5 the aquifer system consists of three hydrostratigraphic units aquifer units interbedded with clay aquitards 1 the aquifer unit a1 known as beach sand aquifer is an unconfined aquifer with a thickness of 20 m adjacent to the coastline and not appropriate for public supply due to the vulnerability to contamination from si 2 the aquifer unit a2 known as gulf shores aquifer is unconfined in the northern study area where is overlain by a marine clay layer and separated by a locally continuous clay layer resulting in two obvious sandy aquifer units a2a and a2b and 3 the deep aquifer unit a3 also called miocene pliocene aquifer is a low head artesian aquifer with the thickness range of 90 175 m chandler et al 1996 in the study area si has mainly occurred in aquifer unit a2 especially near the gulf of mexico as the result of groundwater over exploitation and saltwater downward movement from the aquifer unit a1 currently groundwater samples obtained from wells completed in aquifer a3 exhibited low concentrations of chloride typically associated with si murgulet and tick 2008 we have analyzed the extent of si in the aquifer a3 with numerical model and the results indicated that aquifer a3 is less susceptible to si throughout the management period thus the goal of the present study is to achieve the optimal pumping scheme in the main aquifer unit a2 with the proposed algorithm however it is difficult to obtain comprehensive geochemical data to confirm the extent of si in the aquifer unit a3 with certainty especially in the coastal zone murgulet and tick 2013 therefore we include the aquifer unit a3 in the simulation optimization modeling in order to conveniently improve si model and optimization model once the integrated data is obtained in the future and further enhance sustainable use of coastal groundwater in the perspective of manager 3 1 2 si model in this study region the si model has been developed in the previous work of lin et al 2009 which is based on the seawat code the aquifer is discretized into 102 rows and 122 columns with a uniform grid spacing of 201 2 m 660 ft covering an area of approximately 503 75 km2 the model consists of seven layers representing the hydrostratigraphy of the study area in the vertical direction as shown in fig 5 the confining layers c1 c2 and c3 are represented as low conductivity hydrogeological units with layers 2 4 and 6 in the simulation model the aquifer units a1 a2a a2b and a3 corresponding to layers 1 3 5 and 7 of model and layers 3 and 5 are the target units for multiobjective optimization management the average representative horizontal hydraulic conductivity kh ranged from 5 0 to 137 0 m d is then identified during model calibration in the aquifer the detailed zonation distribution of hydraulic conductivity in the target aquifers of optimization model is shown in fig 6 kh of confining units ranges from 3 81 10 3 to 7 62 10 3 m d and is assumed to be a constant for each confining layer the vertical hydraulic conductivity kv is considered to 5 of kh for all the hydrogeological units streams and rivers are simulated with the river package of modflow the area recharge is applied to aquifer unit a1 and the average rate ranges from 3 05 10 5 to 3 05 10 3 m d lin et al 2009 the primary parameters are listed in table 1 the seaside boundary adjacent to gulf of mexico is considered as the constant head of 0 m representing mean sea level and constant salinity concentration of 3 5 104 mg l for the all layers in wolf bay mobile bay and weeks bay boundary conditions of layer 1 and layer 2 consist of specified head boundary with the constant concentration 1 75 104 mg l that represents the mixing of freshwater and saltwater and no flow boundary for the inland portion of study area in the north the boundary conditions of layers 3 7 are set to specified head for groundwater flow processes and mass flux boundary regarding the solute transport 3 2 implementation of smoma kelm the management objectives are minimization of the extent of si and maximization of the total pumping rate for the development demand in the baldwin county as shown in fig 4 18 public supply wells in the aquifer unit a2 are used for abstraction from layer 3 and layer 5 with the maximum pumping capacity of 3500 m3 d the lower bound of pumping well rate is assumed 500 pw4 6 9 12 13 16 18 or 1000 pw1 3 5 7 8 10 11 14 15 m3 d in accordance with hydrogeological conditions of aquifer unit a2 the total minimum demand of portable water assigned to 2 5 104 m3 d for satisfying local development the maximum and minimum values of total pumping rate are chosen to analyze the extent of si where is identified as the most sensitive area of the salinity concentration variation then we select six representative monitoring wells mw1 mw6 based on the results of numerical experiments in order to control further deterioration of water quality salinity concentration of any monitoring well locations exceeds the prescribed value indicating that the concentration constraint condition is violated that is the solution is infeasible in the perspective of decision making the pumping rate is considered as uniform during the 10 year management period and the initial state of si is assumed the same as the extent of si in 1996 simulated by lin et al 2009 as shown in fig 4 the proposed algorithm utilizes kelm surrogate models to evaluate constraint conditions and objective functions the adaptive surrogate model obtains high precision prediction around the pareto optimal solutions latin hypercube sample lhs generated 350 pumping patterns which are 15 20 times of the number of decision variables over the entire search space wang et al 2014 the multiple runs of seawat output response values corresponding to concentrations at the monitoring well locations and the percentage of mass increase at the end of management horizon therefore thirteen surrogate models were developed based on kelm twelve of these are concentrations of six monitoring wells mw1 mw6 c m at layer 3 and layer 5 respectively and the last one corresponds to the ratio of mass increase m r the prediction results of surrogate models are discussed in section 4 in the multiobjective memetic algorithm population size npop of 200 and selected individuals nsel of 40 in every five generations of evolutionary search are used the parameters required by the proposed algorithm are given in table 2 4 results and discussion 4 1 kelm emulation results the 350 pumping patterns were selected by lhs to train kelm surrogate models the additional 50 patterns of pumping were randomly generated by lhs in order to verify the capability of kelm in capturing the underlying relationship between state variable i e concentration reflecting the state of the groundwater flow and transport system and decision variable i e pumping rate representing the specific scheme of management model the prediction accuracy of developed models is evaluated based on root mean square error rmse and correlation coefficient r respectively given by 20 rmse i 1 n y f i y o i 2 n 21 r i 1 n y f i y fm y o i y om i 1 n y f i y fm 2 i 1 n y o i y om 2 where yf i and yo i are the predicted value of surrogate model and exact value of numerical simulation model for ith sample n is the number of sample and yfm and yom are the mean value of predicted and exact value respectively the results of training and testing surrogate model shown in fig 7 demonstrate that predicted values of monitoring well concentrations and ratio of mass increase are in good agreement with those results from seawat simulation model thus the developed kelm models have potential in predicting nonlinear behavior of si model which significantly surpasses the s o process with original simulation model in lessening the computational burden however the potential relationship of si model may be more complicated and cannot be entirely explored according to the information available from a limited number of samples thus an adaptive strategy is proposed to guide the evolutionary search towards the region containing the optimal solutions and then to be implemented a thorough search 4 2 assessment of the proposed optimization methodology 4 2 1 comparison of algorithms in this study a novel multiobjective evolutionary algorithm is developed for coastal groundwater management in baldwin county to examine its performance in the field scale case study to investigate the quality of solutions obtained by smoma kelm the well known and extensively used algorithm nsgaii deb et al 2002 is considered as the base algorithm in comparison with proposed algorithm for the sake of clarity we combined nsgaii with initial training surrogate model and simulation model seawat as nsgaii kelm nsgaii seawat respectively the population size for these three algorithms is identically set to 200 and the maximum number of optimization generations is uniformly set to 100 due to the popularity the basic sequential optimization framework of nsgaii kelm is usually the optimal choice from the perspective of computational efficiency however as shown in fig 8 the quality of pareto optimal solutions based on smoma kelm is far superior to that of solutions obtained by nsgaii kelm the reason for the failure mode is that surrogate model developed in off line optimization framework cannot accurately represent the original variable density groundwater simulation model in the promising region of the search space for the sake of comparison the pareto front achieved by nsgaii seawat can be considered as reference pareto optimal solutions and be further compared with those solutions based on the proposed algorithm although majorities of solutions obtained by nsgaii seawat are equally optimal in quality compared against those obtained by smoma kelm as in fig 8 the process model for objective function evaluation and constraint conditions is highly cpu intensive especially for the simulation model with respect to the high dimensional and complicated problem with a large number of parameters hv metric describing convergence and diversity of pareto solutions and the inverted generational distance igd measuring how close the optimal pareto fronts to the current non dominated solutions are regarded as performance metrics of the algorithms the detailed description of hv can be found in section 2 3 2 above for the coastal groundwater management problem where the optimal pareto front is not known a prior thus all individuals evaluated by numerical simulation model from algorithms are applied to find non dominated solutions used as reference points for igd calculation the igd metric is formulated as 22 igd p ref p v p ref dis v p p ref where pref is the reference pareto set p is the approximate pareto set at the each generation dis v p is the minimum euclidean distance between v and solutions in p and pref is the number of pareto solutions in pref the advantages of igd is that it combines the measure of proximity and diversity into a single performance metric which is very useful for the comparison of many solutions from different kinds of algorithms fig 9 depicts the evolutions of the quality of approximate pareto solutions for various algorithms assessed by using hv and igd over the number of generations respectively the convergence of the metrics indicates that smoma kelm is slightly slower during early generations but is able to surpass nsgaii kelm and to reach the same convergence speed of nsgaii seawat during the middle generations the trends can be attributed to both the adaptive training that enhances the accuracy of surrogate models and the local search that strengthens the capability of exploitation during search space judged from the average performance at the later stage of search the proposed algorithm can obviously improve the solutions without sacrificing the accuracy of pareto optimal solutions and maintaining the good convergence properties as indicated by its low igd and high hv values 4 2 2 importance of adaptive training kelm models are retrained using approximate pareto optimal solutions at the stage of local search and then adaptively improved in order to alleviate error accumulation of one shot surrogate model the response values of simulation model resulting from nsgaii seawat are considered as test datasets and reevaluated using kelm models at each generation for comparing the accuracy of adaptive surrogate models and one shot surrogate models as shown in fig 10 one shot surrogate model suffers from potential inaccuracies in the evaluation of objective functions and constraint conditions which may contribute to the initial training datasets and need much more sample points to learn features of the fitness function landscape mar exhibits obvious decline at the early period of evolution indicating that more samples provided from decision variables space enhance the prediction ability of kelm to attain higher fidelity level the extent of improvement becomes progressively less obvious at the later period of evolutionary search when sufficient samples are generated for retraining surrogate model this shows that it is crucial to use approximate optimal solutions as training datasets in the s o process to achieve superior pareto front at the cost of acceptable computing burden 4 2 3 computational efficiency the fundamental intention of employing surrogate model coupled with evolutionary search is to converge to approximate region of pareto optimal solutions as instantly as possible and then the required computational time can be substantially reduced see table 3 the computational run time required for the evaluation of single individual with exact variable density model is approximately 50 s on a desktop pc equipped with a 3 4 ghz intel i7 processor and 8 gb of ram nsgaii seawat requires a total runtime of about 332 h for the performance of 20 200 numerical simulation runs in the framework of s o nevertheless smoma kelm employing surrogate model requires only about 5 h for the performance of 350 numerical simulation runs for initial training and 15 h for the performance of 800 numerical simulation runs and evolutionary search for adaptively training at the stage of the single s o running process the main time consuming process derives from the evaluation of seawat model since computation time required for the completion of surrogate models and evolutionary search is comparatively negligible that is to say compared with nsgaii seawat smoma kelm can achieve a substantial time saving up to 94 while ensuring the accuracy of solutions without any significant loss in the optimization process for this real world application 4 3 optimal management schemes as shown in fig 11 three typical management schemes with total pumping rate of respective 46776 m3 d 37397 m3 d and 25123 m3 d are selected the variability of decision variables among all the pareto optimal solutions is determined by the coefficient of variation cv as 23 cv i k 1 n pw i k pw i ave 2 n 1 pw i ave where n is the number of pareto solutions pwi k is ith decision variable of kth optimal scheme pwi ave is the average of ith decision variable among all the optimal solutions cvs of the decision variables of pareto optimal solutions are demonstrated with red points in fig 11 the pumping rates of wells 4 6 wells 9 11 and wells 14 15 vary obviously among pareto solutions showing that these wells can be adjusted largely based on trade off of stakeholders between conflicting management objectives the pumping rates of wells 12 13 and wells 16 18 corresponding to typical optimum solutions are close to the imposed lower bound of pumping capacity which reflects that the pumping rates of nearby wells from coastline are drastically reduced and greatly influenced by si such a distribution of optimal solutions mainly attributes to the fact that the salinity concentration variation in the aquifer is very sensitive to pumping activity in the region adjacent to the gulf of mexico the remaining wells are of no significant effects on the extent of si due to the locations far from the gulf of mexico or unable substantially alter groundwater flow field in the region of si it can be seen in fig 12 that salinity concentration in the aquifer unit a2 that is layer 3 and layer 5 cannot exceed the imposed concentration constraint at the monitoring well locations and saltwater intrusion line keep away from the pumping wells after implementation of optimal groundwater exploitation schemes the extent of si in the aquifer layer 3 is not alleviated clearly by the natural recharge fig 12a c when only reduction of pumping rate is considered thus the complementary management methodologies including utilization of subsurface barriers artificial recharge and pumping of intruded saline water javadi et al 2015 should be employed to mitigate si in the confined aquifer the aquifer layer 5 is more vulnerable to si fig 12d f thus multiobjective optimal groundwater management strategy will be very favorable to balance the most suitable solutions in terms of economic development and environment constraint from the perspective of the decision makers the above analysis results indicate multiobjective optimization framework based on adaptive surrogate model has potential and effectiveness in resolving the real world coastal groundwater management problems 5 conclusions in this study an improved surrogate model assisted multiobjective memetic algorithm was developed for solving pumping optimization of coastal aquifer and demonstrated its capability and effectiveness through a large scale real world coastal groundwater management at the baldwin county in southwestern alabama kelm is a learning method for single hidden layer feedforward neural networks used to describe functional relationship of groundwater system between different pumping strategies and response variables including objective function and constraint conditions the capacity of kelm in predicting monitoring well concentrations and ratio of mass increase was investigated the analysis of statistic test results suggests kelm models have great power to capture potential response relationship of input and output variables in the sample points generated by lhs nevertheless it is noteworthy that kelm models cannot accurately describe response variables during evolutionary search and guarantee the convergence of optimal pareto front in order to alleviate above problem the developed kelm models integrated with multiobjective memetic algorithm and were adaptively retrained for improving the accuracy of surrogate models as the training datasets are constantly updated the structure of feedforward neural networks is adjusted and the ability to predict in the region of approximate pareto solutions is significantly enhanced in the smoma kelm we select new sample points based on hypervolume improvement and crowding distance for achieving the convergence and diversity of pareto solutions moreover gaussian perturbation local search was recursively applied to selected solutions for speeding up the convergence rate of population and improving the capacity of evolutionary search according to the analysis of real world field scale application the proposed algorithm can reach the pareto optimal front that is better than the quality of solutions gained by nsgaii kelm in comparison with nsgaii seawat the proposed algorithm can lead to 94 of cpu time saving while guaranteeing the accuracy of solutions to achieve the desired level the imprecise prediction of one shot surrogate models is the main reason of misleading the evolutionary search direction in nsgaii kelm as shown in fig 10 the mean absolute error of adaptive surrogate model can be reduced by retraining kelm models with updated datasets although smoma kelm can solve coastal aquifer multiobjective optimization problem with acceptable computational burden at the large scale field sites si model coupled with multiple complex physical and chemical processes and multiple management periods could generate more complicated response relationship and much more decision variables known as curse of dimensionality such a sophisticated si model probably results in inaccuracy of surrogates or inapplicability of proposed algorithm future research needs to further improve the proposed algorithm and enhance practicability and feasibility in real world optimization with the consideration of more sophisticated simulation model while addressing more conflicting management objectives meanwhile optimal schemes of coastal groundwater managements based on the deterministic si models for the field applications may become non optimal due to epistemic and aleatory uncertainty thus decision making under uncertainty will be the focus of future research to provide reliable and robust solutions in the real world optimizations acknowledgements the authors gratefully acknowledge the financial support from the national key research and development plan of china 2016yfc0402807 the national natural science foundation of china 41772254 and 41402198 and the national natural science foundation of china xinjiang project u1503282 the authors are also grateful to the high performance computing center of nanjing university for providing the computing facility in particular the authors are profoundly grateful to the editor in chief dr geoff syme associate editor dr craig t simmons and three anonymous reviewers whose constructive suggestions have led to significant improvement of this manuscript 
7265,in this study a novel surrogate model assisted multiobjective memetic algorithm smoma is developed for optimal pumping strategies of large scale coastal groundwater problems the proposed smoma integrates an efficient data driven surrogate model with an improved non dominated sorted genetic algorithm ii nsgaii that employs a local search operator to accelerate its convergence in optimization the surrogate model based on kernel extreme learning machine kelm is developed and evaluated as an approximate simulator to generate the patterns of regional groundwater flow and salinity levels in coastal aquifers for reducing huge computational burden the kelm model is adaptively trained during evolutionary search to satisfy desired fidelity level of surrogate so that it inhibits error accumulation of forecasting and results in correctly converging to true pareto optimal front the proposed methodology is then applied to a large scale coastal aquifer management in baldwin county alabama objectives of minimizing the saltwater mass increase and maximizing the total pumping rate in the coastal aquifers are considered the optimal solutions achieved by the proposed adaptive surrogate model are compared against those solutions obtained from one shot surrogate model and original simulation model the adaptive surrogate model does not only improve the prediction accuracy of pareto optimal solutions compared with those by the one shot surrogate model but also maintains the equivalent quality of pareto optimal solutions compared with those by nsgaii coupled with original simulation model while retaining the advantage of surrogate models in reducing computational burden up to 94 of time saving this study shows that the proposed methodology is a computationally efficient and promising tool for multiobjective optimizations of coastal aquifer managements keywords seawater intrusion surrogate model multiobjective optimization memetic algorithm pumping optimization 1 introduction the contradiction between intensive water demands and groundwater environment restrictions exists in planning and development of coastal regions groundwater in the coastal aquifers is susceptible to deterioration due to its proximity to saltwater in combination with pumping activity and climate change typically irrigation behavior of groundwater resource utilization directly results in seawater intrusion si and further reduces the amount of available freshwater resources given that exceeding 1 of seawater 250 mg l chloride concentration indicates freshwater is unsuitable for drinking werner et al 2013 thus pumping optimization of coastal aquifer is essential to alleviate si caused by continuous and unplanned pumping activity while satisfying water demands and environmental constraints christelis and mantoglou 2016 the linked simulation optimization s o methodologies mantoglou et al 2004 mantoglou and papantoniou 2008 qahman et al 2005 sedki and ouazar 2011 abd elhamid and javadi 2011 javadi et al 2015 have been popularly used in the determination of optimal pumping strategies of coastal groundwater management the s o methodology has the advantages of applicability to non linear groundwater system and universal optimum solution for policymaking however with the s o methodology thousands of evaluations of the simulation model need to be implemented before the optimal set is obtained thus the precision and accuracy of model predictions and computational efficiency of optimization algorithm always determine the practicality and performance of linked s o process bhattacharjya and datta 2005 si involves complex physical and chemical processes including dispersive mixing surface hydrology and density effects caused unstable convection anthropogenic influences and geological characteristics leading to multifaceted challenges for solving coastal groundwater management problems werner et al 2013 fortunately many modular numerical codes such as the commonly used finite difference program seawat guo and langevin 2002 the finite element program femwater lin et al 1997 and the hybridization of finite element and integrated finite difference program sutra voss and provost 2010 can be extensively used to solve the si models for the coupled density dependent flow and solute transport problems however for a regional coastal aquifer the si model is numerically complicated and computationally demanding beyond that decision makers always consider several conflicting objectives of optimization for coastal groundwater management e g maximization of total pumping from production well and minimization of the extent of si which generate a particularly intricate multiobjective optimization problem due to the complexity of coastal aquifer management the s o approaches by use of surrogate models assisted multiobjective evolutionary algorithms smoeas have been receiving increasing attention in recent si optimization problems surrogate models also known as meta models proxy models lower fidelity models and response surfaces are computationally efficient emulators designed to mimic key characteristics of simulation model and have great potential to overcome the computational limitations caused by the optimization management of complex models asher et al 2015 smoeas utilize surrogate models to partially substitute cpu intensive simulation models to save computational cost and solve computationally intensive optimization problems sun et al 2017 surrogate models combined with coastal groundwater management in the linked s o frameworks include a great diversity of available approaches such as radial basis functions christelis and mantoglou 2016 modular neural networks kourakos and mantoglou 2009 2013 genetic programming sreekanth and datta 2010 2011 multivariate adaptive regression splines roy and datta 2017 and evolutionary polynomial regressions hussain et al 2015 actually these surrogate models can be divided into two types i e the on line and off line frameworks at present there are relatively limited on line frameworks implemented in evolutionary algorithm sreekanth and datta 2015 ketabchi and ataie ashtiani 2015 and major off line frameworks presented in coastal aquifer managements e g hussain et al 2015 ataie ashtiani et al 2014 sreekanth and datta 2011 2014 roy and datta 2017 nikolos et al 2008 bhattacharjya and datta 2009 dhar and datta 2009 in general the off line framework involves three steps 1 design of experiments which employ different space filling strategy to obtain key response characteristics of simulation model over design variables feasible space 2 training and validation of surrogate model 3 substitution of original simulation model throughout the optimization process a potential disadvantage of off line framework is that one shot training surrogate model probably cannot accurately represent potential functional relationship between the original model and the interesting and important regions of design variable space or the region of near pareto optimal solutions razavi et al 2012 for example sreekanth and datta 2010 proposed genetic programming coupled with multiobjective genetic algorithm which modified search space based on the relative importance of decision variables and further adaptively retrained surrogate model for achieving more accurate predictions in the vicinity of pareto optimal solutions so as to prevent evolutionary search from falling into local optimum solutions jin 2011 kourakos and mantoglou 2013 employed three criteria based on convergence and diversity of solutions for selecting the most promising offspring to implement adaptive training of modular neural network models and multiobjective optimization management in the central aquifer of santorini island the results suggested that the pareto solutions achieved by surrogate model were better than those solutions by nsgaii coupled with simulation model however the training process used for surrogate model was time consuming even though kourakos and mantoglou 2013 reduced the number of decision variables to simplify the complexity of management model the construction of surrogate model combined with coastal groundwater management is a difficult and computationally demanding task especially in cases with high dimensional decision variables and multi outputs to the best of our knowledge there is no research about coastal groundwater optimization management that employs extreme learning machine elm as surrogate model which has been proposed for training a single hidden layer feedforward neural network huang et al 2006 the essential advantages of elm are high learning accuracy very fast learning speed and least user intervention which can explicitly tackle aforementioned challenges huang et al 2015 the number of hidden layer nodes is a crucial parameter selected by time consuming methods for the prediction performance of elm kernel extreme learning machine kelm is developed which replaces the hidden layer mapping by the kernel function mapping to avoid the hidden layer nodes selection problem wang and han 2014 kelm is more accurate and effective than elm and has better generalization performance for regression and binary class classification applications chen et al 2014 the purpose of this study is to present a linked s o framework that integrates seawat with kelm assisted multiobjective memetic algorithm for pumping optimization of coastal groundwater management subject to environment constraints and water demands the proposed algorithm is then applied to a real world case study in the coastal aquifer underlying southern baldwin county owning to increasing populations economic development and tourism groundwater pumping drastically increased and land use varies considerably in the study region murgulet and tick 2008 lin et al 2009 the multiobjective optimization management of coastal groundwater attempts to find out the optimal pumping design strategy between socioeconomic and environmental factors for simultaneously maximizing the total pumping rates and minimizing the extent of si the proposed s o methodology is generally applicable to any highly parameterized si models at the real world field and large scale coastal groundwater management problems this paper is organized in five sections following this introduction section 2 describes the surrogate model assisted multiobjective optimization framework for coastal aquifer management then section 3 presents the application of the methodology to the real world coastal groundwater management case study in the baldwin county alabama next section 4 illustrates the analysis of optimization results and discussions finally section 5 summarizes and concludes this paper 2 methodology surrogate model assisted multiobjective optimization framework developed in this study for pumping optimization of coastal aquifer comprises two components the first one is the development of kelm surrogate model for substituting the physically based simulators of seawat the second component is an optimization model using surrogate model assisted multiobjective memetic algorithm integrated with kernel extreme learning machine smoma kelm to optimize the pumping strategies satisfying the imposed environment and physical constraints 2 1 numerical model of variable density groundwater flow and solute transport the modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 based program seawat was designed to simulate density dependent groundwater flow and multi species solute transport guo and langevin 2002 the general mathematical equation describing variable density groundwater flow and transport process can be stated as 1 x i ρ k fi h f x i ρ ρ f ρ f z x i ρ s q s ρ s f h f t θ ρ c c t 2 x i θ d ij c k x j x i θ ν i c k q s c k s r n θ c k t where ρ is the density of the native aquifer water ml 3 k fi is the principal component of equivalent freshwater hydraulic conductivity tensor aligned with the principal directions of permeability lt 1 ρf is the density of freshwater ml 3 z is the elevation l hf is the equivalent freshwater head l s f is equivalent freshwater specific storage l 1 t is time t θ is effective porosity c is solute concentration ml 3 ρs is fluid density of source or sink water ml 3 and qs is the volumetric flow rate of sources and sinks per unit volume of aquifer t 1 ck is dissolved concentration of species k ml 3 d ij is the hydrodynamic dispersion tensor l2t 1 vi is the seepage velocity lt 1 ck s is concentration of source or sink flux for species k ml 3 and rn is the chemical reaction term ml 3t 1 the equivalent freshwater head varies with not only pressure and elevation but also the difference in groundwater density while solute concentration further affects the density field thus the flow and transport processes have to be resolved based on explicit or implicit coupling framework the fluid density is regarded as the function of solute concentration and ignored the effects of pressure and temperature 2 2 kernel extreme learning machine extreme learning machine proposed by huang et al 2006 is a novel learning algorithm for single hidden layer feedforward neural networks and composed by a simple three layer structure input layer output layer and hidden layer elm has three distinct advantages i e the extremely fast learning speed the non adjusting hidden node parameters and homogenous architectures for regression analysis or classification for the given training samples n elm can be mathematically stated as 3 i 1 l β i g w i x j b i f j j 1 n where βi is the weight connecting the ith the hidden node to the output node g is a nonlinear piecewise continuous activation function w i is the weight vector connecting the input nodes to the ith the hidden node x j is jth training sample w i x j signifies the inner product of w i and x j bi is the bias of the ith hidden node fj is the output of elm with respect to input vector and l is the number of the hidden nodes the matrix vector form can be further described as 4 h β f 5 h g w 1 x 1 b 1 g w l x 1 b l g w 1 x n b 1 g w l x n b l n l 6 β β 1 β 2 β l t f f 1 f 2 f n t 7 β h t where h is the output matrix of the hidden layer with respect to input matrix which maps the data from n dimensional input space to l dimensional hidden layer random feature space β is the weight vector connecting the ith hidden node and the output nodes h is the moore penrose generalized inverse of matrix h and t t 1 t2 tn t is the actual objective function vectors when elm can learn training samples n with no residuals the orthogonal projection method can be used to calculate matrix h huang 2014 the minimal norm least square method is used in the original implementation of elm to minimize the training error the configuration of elm model is shown in fig 1 in elm if the hidden layer mapping k x in the special kernel implementation is unknown to users the corresponding kernel matrix defined will be given hence the kernel extreme learning machine is proposed to replace the hidden layer mapping in the extreme machine by kernel function mapping in the support vector machine kelm avoids hidden nodes number selection that is a difficult task and important to the performance of prediction model then the output function of elm can be stated as 8 f x k x h t hh t 1 ω 1 t ke x x 1 ke x x n t ω elm 1 ω 1 t 9 ω elm hh t ω elm k x i k x j ke x i x j where ω is a user specified regularization parameter the excellent strength of kelm lies in its learning speed that can be thousands of times faster than traditional feedforward network learning algorithms like back propagation algorithm while achieve better generalization performance than elm wang and han 2014 therefore kelm is ideally suited to evolutionary optimization assisted by adaptive surrogate model 2 3 optimization model and methodological framework 2 3 1 multiobjective optimization management model coastal groundwater management model in this study involves two conflicting objectives maximizing total pumping rate for water demands and minimizing the extent of si expressed by the percentage of mass increase in the aquifer at the end of the management horizon furthermore a set of imposed physical constraints ensure that salinity concentrations at the monitoring well locations cannot exceed the prescribed lower limit 500 mg l tds according to water quality requirement and total capacity of pumping wells must exceed the local safe value for water demands the mathematical formulations of management model are given by 10 max j 1 n 1 n t 1 t q n t 11 min j 2 mass end mass ini mass ini 100 subject to 12 c i t c max i 1 2 m t 1 2 t 13 q min q n t q max n 1 2 n t 1 2 t 14 n 1 n t 1 t q n t q cons where j 1 is the first objective indicating total pumping rate l3t 1 qn t is the pumping rate from nth production well during tth management period l3t 1 j 2 is the second objective indicating the percentage of mass increase caused by si in the aquifer at the end of the management horizon massini and massend are the total solute mass in the aquifers at the beginning and end of the management horizon m respectively ci t is the concentration of ith monitoring well at the end of tth management horizon ml 3 c max is the maximum permissible concentration constraint at the monitoring well locations ml 3 eq 13 gives a set of constraints representing the pumping capacity of nth well at the tth management period must be within the specified lower and upper bounds q min q max eq 14 represents total pumping rate must exceed prescribed minimum water demands qcons satisfying the local development both the second objective eq 11 and the constraint eq 12 are the functions of state variables of concentrations calculated by seawat based on decision variables in the present study we exploit trained and tested kelm model ψ and φ to predict the percentage of total mass increase in the coastal aquifers and salinity concentrations at all the monitoring well locations resulting from groundwater extraction in the proposed optimization framework the mathematical formulations of ψ and φ can be stated as 15 j 2 ψ q n t t 1 t n 1 n 16 c i t φ q n t i 1 2 m t 1 2 t n 1 2 n 2 3 2 surrogate model assisted multiobjective memetic algorithm in this study we develop a novel surrogate model assisted multiobjective memetic algorithm integrated with kernel extreme learning machine smoma kelm to optimize the groundwater extraction strategies while satisfying the imposed environment and physical constraints as illustrated in fig 2 the algorithm first generates nt samples spanning evenly over feasible variable space and then establishes the preliminary surrogate model all generated offspring individuals are evaluated based on surrogate models and combined with initial or previous generation of population used for the fast non domination sorting procedure then nsel promising individuals about 20 of population size npop are selected from the approximate pareto optimal solutions based on convergence and diversity at intervals of several generations also the local search operator modified from chen et al 2015 is used to enhance the local optimality of the selected individuals next the nsel optimal local individuals are reevaluated utilizing numerical simulation model and then merged with approximate pareto optimal solutions all solutions evaluated by exact simulation model are archived into external database served as training datasets to improve the accuracy of surrogate model during the optimization finally all individuals in the database compared by fast non dominated sorting to obtain final pareto optimal front the proposed smoma kelm includes three core modules the memetic algorithm criteria for choosing promising individuals and local search operator 2 3 2 1 core module 1 memetic algorithms evolutionary multiobjective optimization emo algorithms have been widely used for solving many practical problems and have flexibility in handing strongly nonlinear groundwater optimization problems however emo algorithms exhibits several shortcomings such as slow convergence speed lack of theoretical convergence proof and efficient stopping criterion sindhya et al 2013 memetic algorithms mas also called hybrid genetic algorithms or cultural algorithms are population based evolutionary search methods that composed by natural evolution based on darwinian principles and cultural evolution capable of local refinements which can alleviate aforementioned problems lim et al 2010 sindhya et al 2008 lara et al 2010 the surrogate model assisted memetic algorithm takes advantages of exploration ability of genetic operators and exploitation capacity of local search for search space furthermore the use of surrogate model can greatly reduce computational burden for the real world optimization applications while maintaining high quality of nondominated solutions the selection of local search methodology is crucial for the performance of memetic algorithms palar et al 2016 and random mutation based on gaussian process is considered in this study 2 3 2 2 core module 2 criteria for choosing promising individuals in this study two infill criteria including the hypervolume improvement akhtar and shoemaker 2016 and the crowding distance deb et al 2002 are employed to improve the efficiency of selection strategies the first selection criterion is hypervolume indicator hv that is mainly employed to compare the performance of the different multiobjective evolutionary algorithms the hypervolume of a given pareto front denotes the dominated region of the non dominated solutions relative to the reference point gray region in fig 3 a the obvious strength of hv is the monotonically increasing relationship between the indicator value and pareto dominance which suggests that the pareto optimal front achieves the maximum hypervolume and the lower indicator value means the worse pareto front bader and zitzler 2011 the hypervolume improvement hypervolume contribution indicator couckuyt et al 2012 2014 implies that the new pareto solutions produce the hypervolume increase of the objective space dominated by a set of non domination solutions dark region in fig 3a the second selection criterion is crowding distance that aims to maintain diversity of pareto optimal solutions in the smoma kelm if the magnitude of hypervolume improvement is less than the specified threshold the comparison of crowding distances is the next criterion for selecting the promising individuals as shown in fig 3b we calculate normalized distance of two consecutive pareto solutions for all candidate solutions and then select the candidate with the largest crowding distance exceptionally if the candidate solution is the boundary solution that is of the smallest or largest value of objective function the crowding distance is set to an infinite value by default finally the new training datasets are generated to retrain kelm model for improving prediction accuracy and further prescreening promising candidate solutions 2 3 2 3 core module 3 local search operator gaussian perturbation is an effective strategy adopted to find an appropriate neighborhood of the candidate solution given a population p and a solution x the set of neighborhood solutions is generated as 17 i i 1 i 1 i n i n 18 i i s 1 s 2 s i c u i r i s n 19 i i s 1 s 2 s i c u i r i s n where i is a set of neighborhood solution vectors s s 1 s 2 si sn is an n dimensional decision variable vector that represents a solution u u 1 u 2 ui un and r r 1 r 2 r i r n are two solutions randomly chosen from the population p i i and i i are two neighborhood solutions of s c is a perturbation factor and n is the number of decision variables each decision variable of the selected solution is mutated by adding the gaussian disturbance to generate 2n neighborhood solutions the strategy deciding whether the neighborhood solutions can replace the current solutions complies with pareto domination concept the parameter c follows a gaussian distribution n μ σ 2 μ and σ are the mean value and the standard deviation respectively the ranges of μ and σ are identically recommended as 0 1 and the ability of local search is insensitive to the setting of the parameters chen et al 2015 surrogate model is a computationally efficient approximate model that can substitute for the time consuming simulation model during coastal groundwater optimization a majority of evaluations of objective functions and constraints can be implemented using surrogate models leading to a substantial time saving in optimization moreover the memetic algorithm combines an evolutionary algorithm ea with a local search module to implement a refinement of local individual solutions and achieve a more computationally efficient and accurate convergence to pareto optimal solutions sindhya et al 2011 therefore smoma kelm possesses the ability of highly effective global search for pareto optimal solutions finding higher quality and diverse solutions with local search operator while solving sophisticated and computationally expensive optimization problems with a limited computational budget 3 application to a real world coastal groundwater management 3 1 hydrogeological conditions and si model 3 1 1 hydrogeological conditions the proposed smoma kelm is applied to pumping optimization in the coastal aquifer primarily affected by si in the southernmost portion of baldwin county fig 4 depicts both the locations and the main hydrogeological characteristic of the study area over the past few decades groundwater as the main freshwater source in this region has been over exploited for municipal industrial private and irrigation purposes resulting in saltwater intrusion into coastal aquifers murgulet and tick 2008 2016 lin et al 2009 the representative cross sections through the study area are illustrated in fig 5 the aquifer system consists of three hydrostratigraphic units aquifer units interbedded with clay aquitards 1 the aquifer unit a1 known as beach sand aquifer is an unconfined aquifer with a thickness of 20 m adjacent to the coastline and not appropriate for public supply due to the vulnerability to contamination from si 2 the aquifer unit a2 known as gulf shores aquifer is unconfined in the northern study area where is overlain by a marine clay layer and separated by a locally continuous clay layer resulting in two obvious sandy aquifer units a2a and a2b and 3 the deep aquifer unit a3 also called miocene pliocene aquifer is a low head artesian aquifer with the thickness range of 90 175 m chandler et al 1996 in the study area si has mainly occurred in aquifer unit a2 especially near the gulf of mexico as the result of groundwater over exploitation and saltwater downward movement from the aquifer unit a1 currently groundwater samples obtained from wells completed in aquifer a3 exhibited low concentrations of chloride typically associated with si murgulet and tick 2008 we have analyzed the extent of si in the aquifer a3 with numerical model and the results indicated that aquifer a3 is less susceptible to si throughout the management period thus the goal of the present study is to achieve the optimal pumping scheme in the main aquifer unit a2 with the proposed algorithm however it is difficult to obtain comprehensive geochemical data to confirm the extent of si in the aquifer unit a3 with certainty especially in the coastal zone murgulet and tick 2013 therefore we include the aquifer unit a3 in the simulation optimization modeling in order to conveniently improve si model and optimization model once the integrated data is obtained in the future and further enhance sustainable use of coastal groundwater in the perspective of manager 3 1 2 si model in this study region the si model has been developed in the previous work of lin et al 2009 which is based on the seawat code the aquifer is discretized into 102 rows and 122 columns with a uniform grid spacing of 201 2 m 660 ft covering an area of approximately 503 75 km2 the model consists of seven layers representing the hydrostratigraphy of the study area in the vertical direction as shown in fig 5 the confining layers c1 c2 and c3 are represented as low conductivity hydrogeological units with layers 2 4 and 6 in the simulation model the aquifer units a1 a2a a2b and a3 corresponding to layers 1 3 5 and 7 of model and layers 3 and 5 are the target units for multiobjective optimization management the average representative horizontal hydraulic conductivity kh ranged from 5 0 to 137 0 m d is then identified during model calibration in the aquifer the detailed zonation distribution of hydraulic conductivity in the target aquifers of optimization model is shown in fig 6 kh of confining units ranges from 3 81 10 3 to 7 62 10 3 m d and is assumed to be a constant for each confining layer the vertical hydraulic conductivity kv is considered to 5 of kh for all the hydrogeological units streams and rivers are simulated with the river package of modflow the area recharge is applied to aquifer unit a1 and the average rate ranges from 3 05 10 5 to 3 05 10 3 m d lin et al 2009 the primary parameters are listed in table 1 the seaside boundary adjacent to gulf of mexico is considered as the constant head of 0 m representing mean sea level and constant salinity concentration of 3 5 104 mg l for the all layers in wolf bay mobile bay and weeks bay boundary conditions of layer 1 and layer 2 consist of specified head boundary with the constant concentration 1 75 104 mg l that represents the mixing of freshwater and saltwater and no flow boundary for the inland portion of study area in the north the boundary conditions of layers 3 7 are set to specified head for groundwater flow processes and mass flux boundary regarding the solute transport 3 2 implementation of smoma kelm the management objectives are minimization of the extent of si and maximization of the total pumping rate for the development demand in the baldwin county as shown in fig 4 18 public supply wells in the aquifer unit a2 are used for abstraction from layer 3 and layer 5 with the maximum pumping capacity of 3500 m3 d the lower bound of pumping well rate is assumed 500 pw4 6 9 12 13 16 18 or 1000 pw1 3 5 7 8 10 11 14 15 m3 d in accordance with hydrogeological conditions of aquifer unit a2 the total minimum demand of portable water assigned to 2 5 104 m3 d for satisfying local development the maximum and minimum values of total pumping rate are chosen to analyze the extent of si where is identified as the most sensitive area of the salinity concentration variation then we select six representative monitoring wells mw1 mw6 based on the results of numerical experiments in order to control further deterioration of water quality salinity concentration of any monitoring well locations exceeds the prescribed value indicating that the concentration constraint condition is violated that is the solution is infeasible in the perspective of decision making the pumping rate is considered as uniform during the 10 year management period and the initial state of si is assumed the same as the extent of si in 1996 simulated by lin et al 2009 as shown in fig 4 the proposed algorithm utilizes kelm surrogate models to evaluate constraint conditions and objective functions the adaptive surrogate model obtains high precision prediction around the pareto optimal solutions latin hypercube sample lhs generated 350 pumping patterns which are 15 20 times of the number of decision variables over the entire search space wang et al 2014 the multiple runs of seawat output response values corresponding to concentrations at the monitoring well locations and the percentage of mass increase at the end of management horizon therefore thirteen surrogate models were developed based on kelm twelve of these are concentrations of six monitoring wells mw1 mw6 c m at layer 3 and layer 5 respectively and the last one corresponds to the ratio of mass increase m r the prediction results of surrogate models are discussed in section 4 in the multiobjective memetic algorithm population size npop of 200 and selected individuals nsel of 40 in every five generations of evolutionary search are used the parameters required by the proposed algorithm are given in table 2 4 results and discussion 4 1 kelm emulation results the 350 pumping patterns were selected by lhs to train kelm surrogate models the additional 50 patterns of pumping were randomly generated by lhs in order to verify the capability of kelm in capturing the underlying relationship between state variable i e concentration reflecting the state of the groundwater flow and transport system and decision variable i e pumping rate representing the specific scheme of management model the prediction accuracy of developed models is evaluated based on root mean square error rmse and correlation coefficient r respectively given by 20 rmse i 1 n y f i y o i 2 n 21 r i 1 n y f i y fm y o i y om i 1 n y f i y fm 2 i 1 n y o i y om 2 where yf i and yo i are the predicted value of surrogate model and exact value of numerical simulation model for ith sample n is the number of sample and yfm and yom are the mean value of predicted and exact value respectively the results of training and testing surrogate model shown in fig 7 demonstrate that predicted values of monitoring well concentrations and ratio of mass increase are in good agreement with those results from seawat simulation model thus the developed kelm models have potential in predicting nonlinear behavior of si model which significantly surpasses the s o process with original simulation model in lessening the computational burden however the potential relationship of si model may be more complicated and cannot be entirely explored according to the information available from a limited number of samples thus an adaptive strategy is proposed to guide the evolutionary search towards the region containing the optimal solutions and then to be implemented a thorough search 4 2 assessment of the proposed optimization methodology 4 2 1 comparison of algorithms in this study a novel multiobjective evolutionary algorithm is developed for coastal groundwater management in baldwin county to examine its performance in the field scale case study to investigate the quality of solutions obtained by smoma kelm the well known and extensively used algorithm nsgaii deb et al 2002 is considered as the base algorithm in comparison with proposed algorithm for the sake of clarity we combined nsgaii with initial training surrogate model and simulation model seawat as nsgaii kelm nsgaii seawat respectively the population size for these three algorithms is identically set to 200 and the maximum number of optimization generations is uniformly set to 100 due to the popularity the basic sequential optimization framework of nsgaii kelm is usually the optimal choice from the perspective of computational efficiency however as shown in fig 8 the quality of pareto optimal solutions based on smoma kelm is far superior to that of solutions obtained by nsgaii kelm the reason for the failure mode is that surrogate model developed in off line optimization framework cannot accurately represent the original variable density groundwater simulation model in the promising region of the search space for the sake of comparison the pareto front achieved by nsgaii seawat can be considered as reference pareto optimal solutions and be further compared with those solutions based on the proposed algorithm although majorities of solutions obtained by nsgaii seawat are equally optimal in quality compared against those obtained by smoma kelm as in fig 8 the process model for objective function evaluation and constraint conditions is highly cpu intensive especially for the simulation model with respect to the high dimensional and complicated problem with a large number of parameters hv metric describing convergence and diversity of pareto solutions and the inverted generational distance igd measuring how close the optimal pareto fronts to the current non dominated solutions are regarded as performance metrics of the algorithms the detailed description of hv can be found in section 2 3 2 above for the coastal groundwater management problem where the optimal pareto front is not known a prior thus all individuals evaluated by numerical simulation model from algorithms are applied to find non dominated solutions used as reference points for igd calculation the igd metric is formulated as 22 igd p ref p v p ref dis v p p ref where pref is the reference pareto set p is the approximate pareto set at the each generation dis v p is the minimum euclidean distance between v and solutions in p and pref is the number of pareto solutions in pref the advantages of igd is that it combines the measure of proximity and diversity into a single performance metric which is very useful for the comparison of many solutions from different kinds of algorithms fig 9 depicts the evolutions of the quality of approximate pareto solutions for various algorithms assessed by using hv and igd over the number of generations respectively the convergence of the metrics indicates that smoma kelm is slightly slower during early generations but is able to surpass nsgaii kelm and to reach the same convergence speed of nsgaii seawat during the middle generations the trends can be attributed to both the adaptive training that enhances the accuracy of surrogate models and the local search that strengthens the capability of exploitation during search space judged from the average performance at the later stage of search the proposed algorithm can obviously improve the solutions without sacrificing the accuracy of pareto optimal solutions and maintaining the good convergence properties as indicated by its low igd and high hv values 4 2 2 importance of adaptive training kelm models are retrained using approximate pareto optimal solutions at the stage of local search and then adaptively improved in order to alleviate error accumulation of one shot surrogate model the response values of simulation model resulting from nsgaii seawat are considered as test datasets and reevaluated using kelm models at each generation for comparing the accuracy of adaptive surrogate models and one shot surrogate models as shown in fig 10 one shot surrogate model suffers from potential inaccuracies in the evaluation of objective functions and constraint conditions which may contribute to the initial training datasets and need much more sample points to learn features of the fitness function landscape mar exhibits obvious decline at the early period of evolution indicating that more samples provided from decision variables space enhance the prediction ability of kelm to attain higher fidelity level the extent of improvement becomes progressively less obvious at the later period of evolutionary search when sufficient samples are generated for retraining surrogate model this shows that it is crucial to use approximate optimal solutions as training datasets in the s o process to achieve superior pareto front at the cost of acceptable computing burden 4 2 3 computational efficiency the fundamental intention of employing surrogate model coupled with evolutionary search is to converge to approximate region of pareto optimal solutions as instantly as possible and then the required computational time can be substantially reduced see table 3 the computational run time required for the evaluation of single individual with exact variable density model is approximately 50 s on a desktop pc equipped with a 3 4 ghz intel i7 processor and 8 gb of ram nsgaii seawat requires a total runtime of about 332 h for the performance of 20 200 numerical simulation runs in the framework of s o nevertheless smoma kelm employing surrogate model requires only about 5 h for the performance of 350 numerical simulation runs for initial training and 15 h for the performance of 800 numerical simulation runs and evolutionary search for adaptively training at the stage of the single s o running process the main time consuming process derives from the evaluation of seawat model since computation time required for the completion of surrogate models and evolutionary search is comparatively negligible that is to say compared with nsgaii seawat smoma kelm can achieve a substantial time saving up to 94 while ensuring the accuracy of solutions without any significant loss in the optimization process for this real world application 4 3 optimal management schemes as shown in fig 11 three typical management schemes with total pumping rate of respective 46776 m3 d 37397 m3 d and 25123 m3 d are selected the variability of decision variables among all the pareto optimal solutions is determined by the coefficient of variation cv as 23 cv i k 1 n pw i k pw i ave 2 n 1 pw i ave where n is the number of pareto solutions pwi k is ith decision variable of kth optimal scheme pwi ave is the average of ith decision variable among all the optimal solutions cvs of the decision variables of pareto optimal solutions are demonstrated with red points in fig 11 the pumping rates of wells 4 6 wells 9 11 and wells 14 15 vary obviously among pareto solutions showing that these wells can be adjusted largely based on trade off of stakeholders between conflicting management objectives the pumping rates of wells 12 13 and wells 16 18 corresponding to typical optimum solutions are close to the imposed lower bound of pumping capacity which reflects that the pumping rates of nearby wells from coastline are drastically reduced and greatly influenced by si such a distribution of optimal solutions mainly attributes to the fact that the salinity concentration variation in the aquifer is very sensitive to pumping activity in the region adjacent to the gulf of mexico the remaining wells are of no significant effects on the extent of si due to the locations far from the gulf of mexico or unable substantially alter groundwater flow field in the region of si it can be seen in fig 12 that salinity concentration in the aquifer unit a2 that is layer 3 and layer 5 cannot exceed the imposed concentration constraint at the monitoring well locations and saltwater intrusion line keep away from the pumping wells after implementation of optimal groundwater exploitation schemes the extent of si in the aquifer layer 3 is not alleviated clearly by the natural recharge fig 12a c when only reduction of pumping rate is considered thus the complementary management methodologies including utilization of subsurface barriers artificial recharge and pumping of intruded saline water javadi et al 2015 should be employed to mitigate si in the confined aquifer the aquifer layer 5 is more vulnerable to si fig 12d f thus multiobjective optimal groundwater management strategy will be very favorable to balance the most suitable solutions in terms of economic development and environment constraint from the perspective of the decision makers the above analysis results indicate multiobjective optimization framework based on adaptive surrogate model has potential and effectiveness in resolving the real world coastal groundwater management problems 5 conclusions in this study an improved surrogate model assisted multiobjective memetic algorithm was developed for solving pumping optimization of coastal aquifer and demonstrated its capability and effectiveness through a large scale real world coastal groundwater management at the baldwin county in southwestern alabama kelm is a learning method for single hidden layer feedforward neural networks used to describe functional relationship of groundwater system between different pumping strategies and response variables including objective function and constraint conditions the capacity of kelm in predicting monitoring well concentrations and ratio of mass increase was investigated the analysis of statistic test results suggests kelm models have great power to capture potential response relationship of input and output variables in the sample points generated by lhs nevertheless it is noteworthy that kelm models cannot accurately describe response variables during evolutionary search and guarantee the convergence of optimal pareto front in order to alleviate above problem the developed kelm models integrated with multiobjective memetic algorithm and were adaptively retrained for improving the accuracy of surrogate models as the training datasets are constantly updated the structure of feedforward neural networks is adjusted and the ability to predict in the region of approximate pareto solutions is significantly enhanced in the smoma kelm we select new sample points based on hypervolume improvement and crowding distance for achieving the convergence and diversity of pareto solutions moreover gaussian perturbation local search was recursively applied to selected solutions for speeding up the convergence rate of population and improving the capacity of evolutionary search according to the analysis of real world field scale application the proposed algorithm can reach the pareto optimal front that is better than the quality of solutions gained by nsgaii kelm in comparison with nsgaii seawat the proposed algorithm can lead to 94 of cpu time saving while guaranteeing the accuracy of solutions to achieve the desired level the imprecise prediction of one shot surrogate models is the main reason of misleading the evolutionary search direction in nsgaii kelm as shown in fig 10 the mean absolute error of adaptive surrogate model can be reduced by retraining kelm models with updated datasets although smoma kelm can solve coastal aquifer multiobjective optimization problem with acceptable computational burden at the large scale field sites si model coupled with multiple complex physical and chemical processes and multiple management periods could generate more complicated response relationship and much more decision variables known as curse of dimensionality such a sophisticated si model probably results in inaccuracy of surrogates or inapplicability of proposed algorithm future research needs to further improve the proposed algorithm and enhance practicability and feasibility in real world optimization with the consideration of more sophisticated simulation model while addressing more conflicting management objectives meanwhile optimal schemes of coastal groundwater managements based on the deterministic si models for the field applications may become non optimal due to epistemic and aleatory uncertainty thus decision making under uncertainty will be the focus of future research to provide reliable and robust solutions in the real world optimizations acknowledgements the authors gratefully acknowledge the financial support from the national key research and development plan of china 2016yfc0402807 the national natural science foundation of china 41772254 and 41402198 and the national natural science foundation of china xinjiang project u1503282 the authors are also grateful to the high performance computing center of nanjing university for providing the computing facility in particular the authors are profoundly grateful to the editor in chief dr geoff syme associate editor dr craig t simmons and three anonymous reviewers whose constructive suggestions have led to significant improvement of this manuscript 
7266,in the present study the moisture distribution on the wetting front during drainage and imbibition in a 2d sand chamber is studied thoroughly based on the high resolution data measured by light transmission method the moisture distribution is observed and then analyzed quantitatively during drainage and imbibition different moisture distributions are observed a during drainage moisture contents fluctuate in a larger range and fingers can be seen on the wetting front b while during imbibition moisture contents fluctuate in a smaller range and the wetting front is more regular the hurst coefficients are successful in capturing different characteristics of the moisture distribution between drainage and imbibition during imbibition the hurst coefficients are around 0 2 on the wetting front while during drainage the hurst coefficients are around 0 5 as the porosity changes from 0 336 to 0 383 the moisture distribution in the sand chamber does not display obvious change while as the imbibition rate increases from 5 ml min to 400 ml min the moisture distribution on the wetting front becomes more uniform keywords moisture distribution wetting front light transmission hurst coefficient 1 introduction studies of the moisture distribution in the unsaturated zone are of interest for a wide range of applications such as irrigation groundwater remediation and landslide treatment according to lenormand and zarcone 1984 the decrease in moisture content is called drainage and the increase in moisture content is called imbibition although the definition of drainage is consistent the definition of imbibition is controversial in the literature according to the relationship between water pressure pw and atmosphere pressure pa three kinds of imbibition can be seen the free imbibition pw pa forced imbibition pw pa and restrained imbibition pw pa chesworth et al 2008 and the definition of imbibition is restricted by some authors to free imbibition only bear 1979 in this paper the definition of imbibition is the general version proposed by lenormand and zarcone 1984 including all the three kinds of imbibition during imbibition or drainage the moisture content in the soil or sand changes periodically as the moisture content increases the reflectance from the soil or sand surface will decrease bogrekci et al 2004 thus the wetted soil or sand usually takes a darker color compared with its original appearance according to the definition by parkin et al 2008 the region of rapid change in color due to increased water content is called wetting front fig 1 studies of moisture dynamics during drainage and imbibition can be seen in the literature from time to time lenhard et al 1991 lehmann et al 1998 nielsen and perrochet 2000 stauffer and kinzelbach 2001 wildenschild et al 2001 cartwright 2014 li et al 2014 shoushtari et al 2017 most of these researches are carried out using one dimensional vertical sand columns and mainly focused on hysteresis the hysteretic behavior of moisture dynamics is manifested by scanning pc sw curves during consecutive drainage and imbibition lehmann et al 1998 carried out column experiments and found out that moisture dynamics was damped by hysteresis lehman s work was later confirmed by stauffer and kinzelbach 2001 stauffer and kinzelbach 2001 concluded that hysteresis effects should be considered in order to simulate the moisture dynamics above their periodic boundary conditions it was found out by cartwright 2014 that the moisture pressure dynamics became non hysteretic when short oscillation periods were applied furthermore shoushtari et al 2017 found out that the hysteretic behavior depended not only on oscillation periods but also on the distance from the driving head boundary despite many researches on the hysteretic behavior of moisture dynamics a thorough understanding of the hysteretic behavior of moisture dynamics is still lacking it was recently found out that moisture distribution may have a significant effect on the hysteretic behavior of moisture dynamics in porous media armstrong et al 2016 schlüter et al 2016 however few attempts have been made to study the detailed moisture distribution on the wetting front so more work is needed to study the difference in moisture distribution on the wetting front during drainage and imbibition the moisture distribution on the wetting front is controlled by the underlying pore scale flow mechanisms a number of studies have been carried out to investigate the flow mechanisms at the pore scale during drainage and imbibition suekane et al 2009 zhou et al 2010 mohammadian et al 2015 schlüter et al 2016 classical pore scale flow processes such as ganglion dynamics during imbibition and haines jumps during drainage have been investigated by armstrong and berg systematically berg et al 2013a 2013b armstrong et al 2015 2016 rücker et al 2015 however it could be argued that the two processes at the pore scale would average out at the darcy scale and thus can be neglected armstrong et al 2015 while according to the simulations of ferrari and lunati 2014 pore scale processes need to be considered when up scaling to solve this controversy further studies are needed to investigate the detailed moisture distribution at the darcy scale and whether the effect of pore scale processes on moisture distribution can be observed at the darcy scale the objective of this research is to study the difference in the moisture distribution on the wetting front during drainage and imbibition in a 2d sand chamber to accomplish this objective light transmission method ltm is used to observe the moisture distribution during drainage and imbibition in a 2d sand chamber based on the ltm data the factors and underlying mechanisms affecting the moisture distribution on the wetting front are then discussed hurst coefficient is used to analyze the characteristics of the moisture distribution on the wetting front during drainage and imbibition 2 experimental methods 2 1 experimental setup the light transmission system details of which has been introduced by niemet and selker 2001 was constructed by a chamber a light bank and a charge coupled device ccd camera fig 2 the chamber into which the working sand was packed tightly consisted of a u shaped aluminum spacer 2 0 cm thick 55 cm wide 45 cm high clamped by two glass panels 1 0 cm thick the light bank with 6 fluorescent tubes panasonic yz18rr6500k 60 cm was placed 5 0 cm away from the chamber and worked as the only light source of the system a light diffusion plate made of acrylic separated the light bank from the chamber the ccd camera ap2e apogee instruments auburn ca was placed 1 8 m away from the chamber on the other side the ccd camera was connected to a computer so that the light transmission images could be recorded automatically using the software maxim dl diffraction limited ottawa canada accusand silica sands mined in ottawa mn unimin corporation in 40 50 grade were used in the experiments this sand is transparent high purity with very low organic content and is suitable for the light transmission experiments prior to packing the sand was soaked in 10 nitric acid for 1 day and was then thoroughly rinsed with deionized water to remove fine residues that might be present according to niemet and selker 2001 the sand was oven dried at 45 c for at least 48 h to prevent possible preferential flow paths inside the working sand a wet packing procedure was employed according to this procedure the water table in the chamber was maintained a little bit above the sand level as the sand was gradually deposited into the chamber in this research three sand chambers under different packing densities were used for dense packing the sand was packed into the chamber in small increments with both tapping and shaking between each successive addition and for moderate packing only shaking was employed without any tapping between each successive addition while for loose packing no tapping or shaking was employed during the packing procedure the mass of dry sand ms added into the sand chamber was recorded at each addition the density of the sand particle was ρs 2 65 g cm3 thus the volume occupied by the sand particles can be calculated by vs ms ρs the total volume of the sand chamber was v0 2 0 55 45 cm3 4950 cm3 and the porosity of the working sand was calculated by ϕ 1 vs v0 for dense packing the porosity ϕd was 0 336 and for moderate packing the porosity ϕm was 0 364 while for loose packing the porosity ϕl was 0 383 the top of the chamber was connected to the atmosphere through six air inlets so that air could flow in and out freely water flowed in and out of the chamber through drain ports at the bottom of the spacer under the control of a peristaltic pump longer pump bt100 1f to make sure that water flowed evenly over the full width of the lower boundary a 1 cm thick coarse sand layer was packed into the chamber beneath the working sand before the experiments began several drainage imbibition cycles were conducted to ensure the stability of the media structure the general view of the experimental setup and schematic diagram of the sand chamber is shown in fig 2 2 2 experimental procedure 2 2 1 consecutive drainage imbibition cycles initially the working sand was saturated by co2 completely and then imbibed by water from the bottom at the rate of 10 ml min at the end of imbibition a small amount of co2 will be trapped in the chamber due to capillary trapping and the residual co2 will dissolve gradually in water after 2 days of flushing thus a completely water saturated state can be achieved at the beginning of the experiments when the light intensity throughout the sand chamber does not change anymore it was assumed that the pore space was full of water and no co2 exists anymore thus the water volume equals the pore space volume and the saturated volumetric water content θs was assumed to be equal to the porosity ϕ throughout the sand chamber here the volumetric water content θw is defined as 1 θ w volume of water volume of porespace volume of sand particles the light transmission image under the completely saturated condition was obtained at the beginning of the experiments then the consecutive drainage imbibition cycles were carried out the chamber was drained primary drainage by a peristaltic pump through the drain ports at the rate of 10 ml min for 150 min after a relaxation time of 50 min the pump was reversed pumping water in at the rate of 10 ml min for 100 min and the chamber was imbibed again primary imbibition after a relaxation time of 50 min the chamber was then drained and imbibed twice main drainage main imbibition secondary drainage and secondary imbibition and for each period the pump worked for 100 min and relaxed for 50 min the relaxation time can help to minimize potential oscillations in the moisture distribution that could be induced by abrupt changes in boundary conditions two other parallel experiments were also carried out to test the reproducibility of the experimental data during the experiments light transmission images were taken by the ccd camera every 1 min and the exposure time was set to be 6 s it will be observed in the following sections that in zones where 0 10 θw less than0 25 the water content changes most rapidly along the vertical direction and for clarity the zones where water content θw ranged from 0 10 to 0 25 are referred to as wetting front in the following discussion during the experiments the wetting front fell or rose at the rate of approximately 0 3 cm min thus during the exposure time of 6 s the moving distance of the wetting front was 0 03 cm which was shorter than the length of a pixel greater than 0 045 cm in the light transmission image 2 2 2 imbibition drainage tests under different flow rates in order to investigate the characteristics of the moisture distribution under different flow rates three additional imbibition drainage tests were carried out under different flow rates 5 ml min 100 ml min and 400 ml min in the dense packed sand chamber ϕ 0 336 the flow rates employed in the experiments covered a wide range normally encountered in field tests and laboratory experiments lehmann et al 1998 cartwright 2014 shoushtari et al 2017 after obtaining the saturated transmission image the chamber was drained as completely as possible before each test for each test the chamber was firstly imbibed at the appointed rate to be fully saturated then relaxed for 50 min and finally drained at the same rate as completely as possible for the 5 ml min test an exposure time of 6 s was used and light transmission images were taken every 1 min while for the 100 ml min and 400 ml min test an exposure time of 1 s the minimum exposure time of the ccd camera was used and light transmission images were taken every 3 s 2 3 interpretation of the ltm images the light transmission images were interpreted into moisture content profiles using the image processing algorithm proposed by niemet and selker 2001 an overview of the image processing algorithm is presented here in air water two phase systems the light intensity transmitted through unsaturated porous media can be calculated by fresnel s law 2 i c i 0 τ pl 2 ks τ pg 2 k 1 s exp α p d p k where c is a constant for every single observation point during the experiments i0 is the intensity of the light source τpl is the transmittance of the solid liquid interface τpg is the transmittance of the solid gas interface k is the number of particles pores across the media thickness s is the water saturation and equals to the fraction of pores that are water filled αp is the absorption coefficient of the solid particles dp is the diameter of sand particles taking the nature logarithm of both sides of eq 2 yields 3 ln i a s b where both a and b are constants with a equaling to 2 kln τpl τpg and b equaling to ln ci0τ2 k pg αpdpk it can be seen in eq 3 that ln i is linearly related to s thus the value of s can be easily calculated by the light intensity i if values of a and b are known here the values of a and b are calculated using the light intensity i under completely saturated conditions is and residual conditions ires in the experiments is was determined at the beginning of the primary drainage period when the sand chamber was completely saturated and at the end of primary drainage the light intensity fluctuated around 1200 under residual conditions so ires was set to be 1200 under completely saturated conditions the fraction of pores that are water filled is 1 0 thus ss is 1 0 under completely saturated conditions the residual saturation sres is defined as the saturation s at which a fluid becomes discontinuous and is immobilized under ambient flow conditions mercer and cohen 1990 the sres for the accusand in 40 50 grade is 0 057 according to schroth et al 1996 according to eq 3 under completely saturated conditions ss 1 and residual conditions s sres the measured light intensity transmitted through the working sand satisfies 4 ln i s a 1 b 5 ln i res a s res b where is is the measured light intensity under saturated conditions and ires is the measured light intensity under residual conditions the values of constants a and b can be solved using eqs 4 and 5 taking the values of a and b into eq 3 or directly combining eqs 3 5 yields 6 s ln i ln i res ln i s ln i res 1 s res s res by using eq 6 the water saturation s can be calculated from the light intensity measured by the ccd camera and the moisture content is simply calculated by 7 θ w s ϕ where θw is the volumetric moisture content and ϕ is the porosity 2 4 accuracy and precision analysis of the ltm data the accuracy of ltm was analyzed by comparing the actual volume of water drained from imbibed into the sand chamber with the volume of water measured by ltm the root mean squared errors rmses of the resulting mass balance for each drainage and imbibition period are shown in table 1 the rmse represents the average error over the whole drainage imbibition period and is given by 8 rmse 1 n v actu v meas 2 where n is the number of data vactu is the actual inflow outflow volume and vmeas is the measured inflow outflow volume the rmse represents the overall deviation of the measured inflow outflow volume from the actual inflow outflow volume the low rmses in table 1 indicate that ltm is successful in capturing the real time moisture distribution and brings little systematic error the systematic error can be attributed to several causes for example the pixels near the boundaries of the chamber may have an effect on the measured volume because these pixels may overlap with the opaque boundaries the light near the boundaries may be blocked up by the boundaries additionally the sand is packed into the chamber from bottom to top which will unavoidably make the sand at the bottom slightly denser than the sand at the top this gradual change in density will also bring overall deviation to the water volume measured by ltm because the density is assumed to be uniform throughout the chamber when the ltm images are interpreted apart from systematic errors ltm data is also affected by random errors composed of electrical noise photon shot noise sand grain color variability etc niemet and selker 2001 the random errors will not contribute to the rmses because the random noises and variability will be averaged out when the total inflow outflow volume is calculated the random errors will bring variations to the single point measurement thus can affect the precision of the ltm data the precision of ltm data was analyzed by calculating the standard deviation s d of the moisture contents in residual zones and completely saturated zones in residual zones and completely saturated zones the moisture contents are assumed to be constant and equal to θres and θs respectively thus the variability in the measured moisture contents should be attributed solely to random errors in these two zones within the saturated zone of each period the maximum variability 2 s d of θs θs was 2 70 and in zones under residual conditions the maximum variability 2 s d of θres θs was 1 50 the maximum variability 2 s d is presented in table 1 as the random errors brought by ltm system and can be seen as a measure of the precision of the ltm data generally speaking the rmse is a valid estimation of the accuracy of ltm results taking all the systematic errors into consideration however the rmses do not contain random errors and it should be noted that the estimation of hurst coefficient is based on the pixel to pixel variations in moisture contents see eqs 9 and 10 in the following section the analysis results will be more sensitive to the random errors presented in table 1 while the systematic deviation represented by rmses will have little effect on the analysis results 2 5 estimation of the hurst coefficients in this paper the stochastic fractal model of fractional brownian motion fbm is employed to quantitatively analyze the moisture distribution during drainage and imbibition the concept of fbm is originally introduced by mandelbrot and van ness 1968 and has been used widely in hydrology fbm has been successfully used in the analysis of the distribution of porosity hydraulic conductivity and dispersity with the length scales ranging from 1 cm to several kilometers gelhar et al 1992 neuman 1990 1995 2013 lu et al 2003 neuman et al 2013 guadagnini et al 2014 it is reported that the moisture distribution is affected by the distribution of hydraulic conductivity or porosity suekane et al 2009 zhou et al 2010 thus fbm may also be used to analyze the moisture distribution at the darcy scale in the 1 d framework fbm is defined as a random process y x of the independent spatial or temporal variable x with the increments of y x being statistically invariant with respect to an affine transformation molz et al 1997 in the most elementary form this means that the increment y xn y x1 satisfies 9 y x n y x 1 x n x 1 h where is the expectation function is the absolute value function h is the hurst coefficient 0 h 1 based on the value of h a random process can be classified into three categories 1 when h is less than 0 5 the increments of y x are negatively correlated and the process is said to be anti persistent barunik and kristoufek 2010 an anti persistent process has a characteristic of mean reversion which means that y x tends to regress strongly toward the mean the characteristic of mean reverting becomes more evident as the h approaches 0 2 when h is larger than 0 5 the increments of y x are positively correlated and the process is said to be persistent barunik and kristoufek 2010 a persistent process has a characteristic of trend reinforcing which means that y x tends to increase decrease continuously towards a higher lower value the characteristic of trend reinforcing becomes more evident as the h approaches 1 3 when h equals to 0 5 the increments of y x may be termed random steps because the increments are uncorrelated with each other in this situation the process can be seen as a classical brownian motion cbm the hurst coefficient of a given fbm data sequence y x can be estimated based on the statistical invariance of y x the variance vn of y x over the interval x1 xn is defined as the variance of y values over that interval thus a dimensionless rescaled variance of y x may be defined by dividing the vn by the standard deviation sn of the y x increments according to cajueiro and tabak 2005 the rescaled adjusted variance of y x vn s2 n should satisfy the following relationship 10 v n s n 2 x n x 1 2 h where vn is the variance of adjusted y x in x1 xn and sn is the standard deviation of the increments of adjusted y x and is defined as below 11 v n 1 n k 1 n i 1 k dy i dy 2 1 n k 1 n i 1 k dy i dy 2 12 s n 1 n i 1 n dy i dy 2 1 2 where dyi is the increment of y and is given by yi yi 1 dy equals to i 1 n dy i n the eqs 9 and 10 can be used to estimate the hurst coefficient of an fbm data sequence according to eqs 9 and 10 the log log plot of y x n y x 1 or v n s n 2 versus x n x 1 will yield lines of slope h or 2h the two estimation methods of h are called intensity difference method chen et al 1989 and v s analysis method cajueiro and tabak 2005 respectively 3 results and discussion 3 1 the moisture distribution on the wetting front during drainage and imbibition the moisture distribution is presented in the form of 3d moisture content surfaces in fig 3 as can be seen in fig 3a as the moisture content changes the moisture distribution displays different characteristics based on the characteristics of the moisture distribution the moisture content surface can be divided into 3 different zones in zone i where moisture contents are lower than 0 10 the moisture contents show little fluctuation however in zone ii where moisture contents are between 0 10 0 25 the moisture contents show obvious fluctuation and fingers can be seen in this zone in zone iii where moisture contents are larger than 0 25 the moisture contents show little fluctuation again similar fingers can also be seen on the wetting front zone ii of main drainage and secondary drainage period fig 3c and e while for imbibition periods fig 3b d and f no significant fingers are presented on the wetting front zone ii the different characteristics of the moisture distribution during drainage and imbibition may be induced by the following causes the drainage process is a gravity driven process and the capillary pressure cannot always maintain balance with gravity causing unstable drainage events to happen and fingers to develop on the wetting front while the imbibition process can be seen as a capillary driven process and the capillary pressure is always balanced with the gravity making the imbibition process more stable and frontal the unstable drainage event which is called the haines jump at the pore scale has been recognized for long haines 1930 the event of haines jump happens when the air passes from a pore neck into a wider pore body displacing the water and is usually accompanied by a sudden drop in capillary pressure berg et al 2013a thus the haines jump can bring large fluctuations in water distribution at the pore scale in fact the unstable drainage event or haines jump at the pore scale is a widespread phenomenon in the porous media the drainage process at the darcy scale can be seen as an ensemble of pore scale haines jumps occurring as avalanche like events armstrong et al 2015 in summary these fingers observed in fig 3a c and e on the wetting front provide evidence that the unstable pore scale drainage event or haines jump can influence the moisture distribution at the darcy scale 3 2 analysis of the characteristics of the moisture distribution on the wetting front to further investigate the characteristics of the moisture distribution on the wetting front during drainage and imbibition the horizontal moisture distribution in the sand chamber is extracted and analyzed quantitatively it should be mentioned that the moisture distribution tends to be irregular close to the left and right boundary because of the dominant channels near the frame hence the moisture contents near the central vertical line central 400 pixels e g fig 4 are discussed in the following sections fig 4 shows the moisture distribution on the wetting front at the 50th min of main drainage and main imbibition as can be seen in fig 4 the horizontal moisture contents fluctuate during both drainage and imbibition periods during main drainage period it fluctuates in a larger range from 0 145 to 0 175 while during main imbibition period it only fluctuates in a smaller range from 0 150 to 0 165 the large fluctuation in the moisture distribution during drainage can be seen as the direct cause of fingers on the wetting front as observed in fig 3 3 2 1 correlation coefficients of the horizontal moisture distribution in order to study the factors affecting the moisture distribution during drainage and imbibition the horizontal moisture contents on the wetting front at the 50th min of drainage and imbibition are compared in fig 5 it can be observed from fig 5a that the pattern of the moisture distribution during main drainage period is quite similar to that of secondary drainage period in fig 5b the moisture distribution during main imbibition period displays a similar pattern to that of secondary imbibition period the correlation coefficients r are calculated using the moisture contents shown in fig 5 400 pixels for each period and the correlation matrix is presented in table 2 as shown in table 2 the spearman correlation coefficient of the moisture contents during the two drainage periods is 0 71 and during the two imbibition periods the moisture contents also display strong positive correlation r 0 79 the positive correlation in the moisture distribution during different drainage or imbibition periods may be attributed to the spatial characteristics of the working sand suekane et al 2009 measured the porosity distribution as well as the equilibrium moisture distribution in sandstone cores and glass beads using x ray tomography it was found out by suekane et al 2009 that the moisture contents decreased with an increase in the porosity it was later found out by zhou et al 2010 that the equilibrium moisture distribution was highly comparable to the distribution of the porosity and the equilibrium moisture distribution remains stable under different flow rates although the local porosity of the 2d sand chamber used in this paper is hard to measure it can be inferred that the moisture distribution is controlled by the porosity distribution in the sand chamber under the same flow condition because the porosity distribution remains stable during the experiments the patterns of the moisture distribution change little during different drainage or imbibition periods as also shown in table 2 the moisture distribution during drainage periods does not correlate with the moisture distribution during imbibition periods it can be inferred that the moisture distribution is affected not only by the spatial characteristics of the porous media but also by the direction of the water flow 3 2 2 hurst coefficients of the moisture distribution the hurst coefficients of the horizontal moisture distribution at three different heights of the sand chamber during primary drainage are estimated using intensity difference methods and v s analysis as shown in fig 6 the two methods present fairly linear relationship between ln δθw or ln v s2 and ln δx which means that the horizontal moisture distribution can be described by fbm with the estimated hurst coefficients the hurst coefficients of the moisture distribution in the sand chamber during each drainage imbibition period are shown in fig 7 it can be observed from fig 7 that the peak value of hurst coefficients is always located on the wetting front with the peak value around 0 5 during drainage and around 0 2 during imbibition the peak value of hurst coefficients appearing on the wetting front implies that the moisture contents fluctuate in a larger range on the wetting front comparing to the other two zones during drainage and imbibition the value of hurst coefficients during drainage is relatively larger than that during imbibition which indicates that water moves in a more unstable manner during drainage than during imbibition the difference in the moisture distribution during drainage and imbibition captured by hurst coefficients is consistent with the experimental observations presented in figs 3 and 4 as mentioned in section 2 5 when hurst coefficient h is less than 0 5 the increments in moisture content will be negatively correlated and as h becomes smaller the characteristic of mean reversion in the moisture distribution becomes more evident the smaller peak value of h during imbibition periods indicates that the moisture distribution is constrained to around its mean value along the horizontal direction and fluctuates in a relatively smaller range while the larger peak value of h during drainage periods on the wetting front indicates that larger fluctuation in the moisture distribution can be seen on the wetting front during drainage it is observed in pore scale drainage experiments conducted by moebius and or 2012 that the apparently continuous motion of wetting fronts in porous media are inherently quite irregular at the pore scale this kind of irregularity on the wetting front during drainage can be easily captured by estimating the hurst coefficients of the moisture distribution 3 3 the moisture distribution under different experimental conditions 3 3 1 the effect of packing density on moisture distribution to assess the effect of packing density on moisture distribution the hurst coefficients of the moisture distribution estimated by v s analysis under different packing densities during consecutive drainage and imbibition are shown in fig 8 from fig 8 it can be observed that when packing density changes from 0 336 to 0 383 hurst coefficients display little change which means that the packing density of the working sand has little effect on the moisture distribution during drainage and imbibition the effect of packing density on moisture distribution has also been investigated in the studies of hincapié and germann 2010 and it was found out that the moisture distribution remains stable under different packing densities generally speaking it can be concluded that the moisture distribution on the wetting front is hardly affected by the packing density of the working sand during drainage and imbibition 3 3 2 the effect of flow rate on moisture distribution the hurst coefficients of the moisture distribution under different imbibition and drainage rates q 5 ml min 10 ml min 100 ml min and 400 ml min are shown in fig 9 as the drainage rate increases from 5 ml min to 400 ml min the hurst coefficients on the wetting front zone ii change little while the hurst coefficients above the wetting front zone i increase significantly as the drainage rate increases to 400 ml min little change in hurst coefficients on the wetting front indicates that the fluctuation in moisture contents remains stable on the wetting front under different drainage rates thus the moisture distribution remains similar on the wetting front under different drainage rates while the significant increase in hurst coefficients above the wetting front indicates that as drainage rate increases the moisture distribution changes significantly above the wetting front in fact at higher drainage rate more water is retained above the wetting front leading to significant change in the moisture distribution above the wetting front it can be seen in fig 9a d that as the imbibition rate increases from 5 ml min to 400 ml min the peak value of hurst coefficients decreases accordingly from around 0 2 to around 0 1 the decrease in hurst coefficient indicates that the fluctuation in moisture contents is suppressed and the wetting front becomes more regular as imbibition rate increases the effect of imbibition rate on the wetting front has been studied thoroughly by pore scale experiments and simulations lenormand and zarcone 1984 hughes and blunt 2000 nguyen et al 2006 as illustrated by hughes and blunt 2000 when the imbibition rate is high the viscous force dominate and the cooperative pore filling event happens frequently thus there is a tendency for water to fill in nearby pores rather than create extended capillary fingers leading to a front that is flat at the pore scale while when the imbibition rate is low the capillary force dominates which means that water fills the media in the order of pore size and irregular capillary rise develops on the wetting front at the pore scale from the processes observed at the pore scale it can be inferred that at the darcy scale as the imbibition rate increases the unbalanced capillary rise induced by local heterogeneity is also suppressed so the fluctuation in moisture contents on the wetting front is also suppressed as the imbibition rate increases and this change in the moisture distribution is captured by hurst coefficients 4 conclusions the moisture distribution during drainage and imbibition are studied thoroughly through experiments in a 2d sand chamber the moisture distribution can be observed using ltm and visualized on the 3d moisture content surface during drainage the moisture contents on the wetting front fluctuate in a larger range due to haines jumps and fingers can be seen on the moisture content surface while during imbibition the moisture contents on the wetting front fluctuate in a smaller range making the wetting front more frontal the difference of the moisture distribution on the wetting front between drainage and imbibition at the darcy scale clearly show that the pore scale processes would not average out when up scaling the hurst coefficient could be used to capture the moisture distribution during the experiments and carry integrated information about the underlying pore scale processes the peak value of the hurst coefficients always appears on the wetting front and it is larger during drainage than during imbibition the moisture distribution on the wetting front is hardly affected by the packing density of the working sand as flow rate increases from 5 ml min to 400 ml min the moisture distribution on the wetting front displays similar pattern during drainage while during imbibition the moisture distribution on the wetting front becomes more uniform with increasing flow rates it should be noted that all the results in this paper are based on the accusand silica sand in 40 50 grade given the diversity of the porous media more experiments should be conducted to investigate the effect of porous media on the moisture distribution during drainage and imbibition acknowledgments this work was supported by grant from the national natural science foundation of china grant no u1503282 and 41672233 and in part from the open fund of the state key laboratory of water resources and hydropower engineering science grant no 2014nsk01 and the key research and development project of jiangsu province china grant no be2015708 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 069 appendix b supplementary data supplementary data 1 
7266,in the present study the moisture distribution on the wetting front during drainage and imbibition in a 2d sand chamber is studied thoroughly based on the high resolution data measured by light transmission method the moisture distribution is observed and then analyzed quantitatively during drainage and imbibition different moisture distributions are observed a during drainage moisture contents fluctuate in a larger range and fingers can be seen on the wetting front b while during imbibition moisture contents fluctuate in a smaller range and the wetting front is more regular the hurst coefficients are successful in capturing different characteristics of the moisture distribution between drainage and imbibition during imbibition the hurst coefficients are around 0 2 on the wetting front while during drainage the hurst coefficients are around 0 5 as the porosity changes from 0 336 to 0 383 the moisture distribution in the sand chamber does not display obvious change while as the imbibition rate increases from 5 ml min to 400 ml min the moisture distribution on the wetting front becomes more uniform keywords moisture distribution wetting front light transmission hurst coefficient 1 introduction studies of the moisture distribution in the unsaturated zone are of interest for a wide range of applications such as irrigation groundwater remediation and landslide treatment according to lenormand and zarcone 1984 the decrease in moisture content is called drainage and the increase in moisture content is called imbibition although the definition of drainage is consistent the definition of imbibition is controversial in the literature according to the relationship between water pressure pw and atmosphere pressure pa three kinds of imbibition can be seen the free imbibition pw pa forced imbibition pw pa and restrained imbibition pw pa chesworth et al 2008 and the definition of imbibition is restricted by some authors to free imbibition only bear 1979 in this paper the definition of imbibition is the general version proposed by lenormand and zarcone 1984 including all the three kinds of imbibition during imbibition or drainage the moisture content in the soil or sand changes periodically as the moisture content increases the reflectance from the soil or sand surface will decrease bogrekci et al 2004 thus the wetted soil or sand usually takes a darker color compared with its original appearance according to the definition by parkin et al 2008 the region of rapid change in color due to increased water content is called wetting front fig 1 studies of moisture dynamics during drainage and imbibition can be seen in the literature from time to time lenhard et al 1991 lehmann et al 1998 nielsen and perrochet 2000 stauffer and kinzelbach 2001 wildenschild et al 2001 cartwright 2014 li et al 2014 shoushtari et al 2017 most of these researches are carried out using one dimensional vertical sand columns and mainly focused on hysteresis the hysteretic behavior of moisture dynamics is manifested by scanning pc sw curves during consecutive drainage and imbibition lehmann et al 1998 carried out column experiments and found out that moisture dynamics was damped by hysteresis lehman s work was later confirmed by stauffer and kinzelbach 2001 stauffer and kinzelbach 2001 concluded that hysteresis effects should be considered in order to simulate the moisture dynamics above their periodic boundary conditions it was found out by cartwright 2014 that the moisture pressure dynamics became non hysteretic when short oscillation periods were applied furthermore shoushtari et al 2017 found out that the hysteretic behavior depended not only on oscillation periods but also on the distance from the driving head boundary despite many researches on the hysteretic behavior of moisture dynamics a thorough understanding of the hysteretic behavior of moisture dynamics is still lacking it was recently found out that moisture distribution may have a significant effect on the hysteretic behavior of moisture dynamics in porous media armstrong et al 2016 schlüter et al 2016 however few attempts have been made to study the detailed moisture distribution on the wetting front so more work is needed to study the difference in moisture distribution on the wetting front during drainage and imbibition the moisture distribution on the wetting front is controlled by the underlying pore scale flow mechanisms a number of studies have been carried out to investigate the flow mechanisms at the pore scale during drainage and imbibition suekane et al 2009 zhou et al 2010 mohammadian et al 2015 schlüter et al 2016 classical pore scale flow processes such as ganglion dynamics during imbibition and haines jumps during drainage have been investigated by armstrong and berg systematically berg et al 2013a 2013b armstrong et al 2015 2016 rücker et al 2015 however it could be argued that the two processes at the pore scale would average out at the darcy scale and thus can be neglected armstrong et al 2015 while according to the simulations of ferrari and lunati 2014 pore scale processes need to be considered when up scaling to solve this controversy further studies are needed to investigate the detailed moisture distribution at the darcy scale and whether the effect of pore scale processes on moisture distribution can be observed at the darcy scale the objective of this research is to study the difference in the moisture distribution on the wetting front during drainage and imbibition in a 2d sand chamber to accomplish this objective light transmission method ltm is used to observe the moisture distribution during drainage and imbibition in a 2d sand chamber based on the ltm data the factors and underlying mechanisms affecting the moisture distribution on the wetting front are then discussed hurst coefficient is used to analyze the characteristics of the moisture distribution on the wetting front during drainage and imbibition 2 experimental methods 2 1 experimental setup the light transmission system details of which has been introduced by niemet and selker 2001 was constructed by a chamber a light bank and a charge coupled device ccd camera fig 2 the chamber into which the working sand was packed tightly consisted of a u shaped aluminum spacer 2 0 cm thick 55 cm wide 45 cm high clamped by two glass panels 1 0 cm thick the light bank with 6 fluorescent tubes panasonic yz18rr6500k 60 cm was placed 5 0 cm away from the chamber and worked as the only light source of the system a light diffusion plate made of acrylic separated the light bank from the chamber the ccd camera ap2e apogee instruments auburn ca was placed 1 8 m away from the chamber on the other side the ccd camera was connected to a computer so that the light transmission images could be recorded automatically using the software maxim dl diffraction limited ottawa canada accusand silica sands mined in ottawa mn unimin corporation in 40 50 grade were used in the experiments this sand is transparent high purity with very low organic content and is suitable for the light transmission experiments prior to packing the sand was soaked in 10 nitric acid for 1 day and was then thoroughly rinsed with deionized water to remove fine residues that might be present according to niemet and selker 2001 the sand was oven dried at 45 c for at least 48 h to prevent possible preferential flow paths inside the working sand a wet packing procedure was employed according to this procedure the water table in the chamber was maintained a little bit above the sand level as the sand was gradually deposited into the chamber in this research three sand chambers under different packing densities were used for dense packing the sand was packed into the chamber in small increments with both tapping and shaking between each successive addition and for moderate packing only shaking was employed without any tapping between each successive addition while for loose packing no tapping or shaking was employed during the packing procedure the mass of dry sand ms added into the sand chamber was recorded at each addition the density of the sand particle was ρs 2 65 g cm3 thus the volume occupied by the sand particles can be calculated by vs ms ρs the total volume of the sand chamber was v0 2 0 55 45 cm3 4950 cm3 and the porosity of the working sand was calculated by ϕ 1 vs v0 for dense packing the porosity ϕd was 0 336 and for moderate packing the porosity ϕm was 0 364 while for loose packing the porosity ϕl was 0 383 the top of the chamber was connected to the atmosphere through six air inlets so that air could flow in and out freely water flowed in and out of the chamber through drain ports at the bottom of the spacer under the control of a peristaltic pump longer pump bt100 1f to make sure that water flowed evenly over the full width of the lower boundary a 1 cm thick coarse sand layer was packed into the chamber beneath the working sand before the experiments began several drainage imbibition cycles were conducted to ensure the stability of the media structure the general view of the experimental setup and schematic diagram of the sand chamber is shown in fig 2 2 2 experimental procedure 2 2 1 consecutive drainage imbibition cycles initially the working sand was saturated by co2 completely and then imbibed by water from the bottom at the rate of 10 ml min at the end of imbibition a small amount of co2 will be trapped in the chamber due to capillary trapping and the residual co2 will dissolve gradually in water after 2 days of flushing thus a completely water saturated state can be achieved at the beginning of the experiments when the light intensity throughout the sand chamber does not change anymore it was assumed that the pore space was full of water and no co2 exists anymore thus the water volume equals the pore space volume and the saturated volumetric water content θs was assumed to be equal to the porosity ϕ throughout the sand chamber here the volumetric water content θw is defined as 1 θ w volume of water volume of porespace volume of sand particles the light transmission image under the completely saturated condition was obtained at the beginning of the experiments then the consecutive drainage imbibition cycles were carried out the chamber was drained primary drainage by a peristaltic pump through the drain ports at the rate of 10 ml min for 150 min after a relaxation time of 50 min the pump was reversed pumping water in at the rate of 10 ml min for 100 min and the chamber was imbibed again primary imbibition after a relaxation time of 50 min the chamber was then drained and imbibed twice main drainage main imbibition secondary drainage and secondary imbibition and for each period the pump worked for 100 min and relaxed for 50 min the relaxation time can help to minimize potential oscillations in the moisture distribution that could be induced by abrupt changes in boundary conditions two other parallel experiments were also carried out to test the reproducibility of the experimental data during the experiments light transmission images were taken by the ccd camera every 1 min and the exposure time was set to be 6 s it will be observed in the following sections that in zones where 0 10 θw less than0 25 the water content changes most rapidly along the vertical direction and for clarity the zones where water content θw ranged from 0 10 to 0 25 are referred to as wetting front in the following discussion during the experiments the wetting front fell or rose at the rate of approximately 0 3 cm min thus during the exposure time of 6 s the moving distance of the wetting front was 0 03 cm which was shorter than the length of a pixel greater than 0 045 cm in the light transmission image 2 2 2 imbibition drainage tests under different flow rates in order to investigate the characteristics of the moisture distribution under different flow rates three additional imbibition drainage tests were carried out under different flow rates 5 ml min 100 ml min and 400 ml min in the dense packed sand chamber ϕ 0 336 the flow rates employed in the experiments covered a wide range normally encountered in field tests and laboratory experiments lehmann et al 1998 cartwright 2014 shoushtari et al 2017 after obtaining the saturated transmission image the chamber was drained as completely as possible before each test for each test the chamber was firstly imbibed at the appointed rate to be fully saturated then relaxed for 50 min and finally drained at the same rate as completely as possible for the 5 ml min test an exposure time of 6 s was used and light transmission images were taken every 1 min while for the 100 ml min and 400 ml min test an exposure time of 1 s the minimum exposure time of the ccd camera was used and light transmission images were taken every 3 s 2 3 interpretation of the ltm images the light transmission images were interpreted into moisture content profiles using the image processing algorithm proposed by niemet and selker 2001 an overview of the image processing algorithm is presented here in air water two phase systems the light intensity transmitted through unsaturated porous media can be calculated by fresnel s law 2 i c i 0 τ pl 2 ks τ pg 2 k 1 s exp α p d p k where c is a constant for every single observation point during the experiments i0 is the intensity of the light source τpl is the transmittance of the solid liquid interface τpg is the transmittance of the solid gas interface k is the number of particles pores across the media thickness s is the water saturation and equals to the fraction of pores that are water filled αp is the absorption coefficient of the solid particles dp is the diameter of sand particles taking the nature logarithm of both sides of eq 2 yields 3 ln i a s b where both a and b are constants with a equaling to 2 kln τpl τpg and b equaling to ln ci0τ2 k pg αpdpk it can be seen in eq 3 that ln i is linearly related to s thus the value of s can be easily calculated by the light intensity i if values of a and b are known here the values of a and b are calculated using the light intensity i under completely saturated conditions is and residual conditions ires in the experiments is was determined at the beginning of the primary drainage period when the sand chamber was completely saturated and at the end of primary drainage the light intensity fluctuated around 1200 under residual conditions so ires was set to be 1200 under completely saturated conditions the fraction of pores that are water filled is 1 0 thus ss is 1 0 under completely saturated conditions the residual saturation sres is defined as the saturation s at which a fluid becomes discontinuous and is immobilized under ambient flow conditions mercer and cohen 1990 the sres for the accusand in 40 50 grade is 0 057 according to schroth et al 1996 according to eq 3 under completely saturated conditions ss 1 and residual conditions s sres the measured light intensity transmitted through the working sand satisfies 4 ln i s a 1 b 5 ln i res a s res b where is is the measured light intensity under saturated conditions and ires is the measured light intensity under residual conditions the values of constants a and b can be solved using eqs 4 and 5 taking the values of a and b into eq 3 or directly combining eqs 3 5 yields 6 s ln i ln i res ln i s ln i res 1 s res s res by using eq 6 the water saturation s can be calculated from the light intensity measured by the ccd camera and the moisture content is simply calculated by 7 θ w s ϕ where θw is the volumetric moisture content and ϕ is the porosity 2 4 accuracy and precision analysis of the ltm data the accuracy of ltm was analyzed by comparing the actual volume of water drained from imbibed into the sand chamber with the volume of water measured by ltm the root mean squared errors rmses of the resulting mass balance for each drainage and imbibition period are shown in table 1 the rmse represents the average error over the whole drainage imbibition period and is given by 8 rmse 1 n v actu v meas 2 where n is the number of data vactu is the actual inflow outflow volume and vmeas is the measured inflow outflow volume the rmse represents the overall deviation of the measured inflow outflow volume from the actual inflow outflow volume the low rmses in table 1 indicate that ltm is successful in capturing the real time moisture distribution and brings little systematic error the systematic error can be attributed to several causes for example the pixels near the boundaries of the chamber may have an effect on the measured volume because these pixels may overlap with the opaque boundaries the light near the boundaries may be blocked up by the boundaries additionally the sand is packed into the chamber from bottom to top which will unavoidably make the sand at the bottom slightly denser than the sand at the top this gradual change in density will also bring overall deviation to the water volume measured by ltm because the density is assumed to be uniform throughout the chamber when the ltm images are interpreted apart from systematic errors ltm data is also affected by random errors composed of electrical noise photon shot noise sand grain color variability etc niemet and selker 2001 the random errors will not contribute to the rmses because the random noises and variability will be averaged out when the total inflow outflow volume is calculated the random errors will bring variations to the single point measurement thus can affect the precision of the ltm data the precision of ltm data was analyzed by calculating the standard deviation s d of the moisture contents in residual zones and completely saturated zones in residual zones and completely saturated zones the moisture contents are assumed to be constant and equal to θres and θs respectively thus the variability in the measured moisture contents should be attributed solely to random errors in these two zones within the saturated zone of each period the maximum variability 2 s d of θs θs was 2 70 and in zones under residual conditions the maximum variability 2 s d of θres θs was 1 50 the maximum variability 2 s d is presented in table 1 as the random errors brought by ltm system and can be seen as a measure of the precision of the ltm data generally speaking the rmse is a valid estimation of the accuracy of ltm results taking all the systematic errors into consideration however the rmses do not contain random errors and it should be noted that the estimation of hurst coefficient is based on the pixel to pixel variations in moisture contents see eqs 9 and 10 in the following section the analysis results will be more sensitive to the random errors presented in table 1 while the systematic deviation represented by rmses will have little effect on the analysis results 2 5 estimation of the hurst coefficients in this paper the stochastic fractal model of fractional brownian motion fbm is employed to quantitatively analyze the moisture distribution during drainage and imbibition the concept of fbm is originally introduced by mandelbrot and van ness 1968 and has been used widely in hydrology fbm has been successfully used in the analysis of the distribution of porosity hydraulic conductivity and dispersity with the length scales ranging from 1 cm to several kilometers gelhar et al 1992 neuman 1990 1995 2013 lu et al 2003 neuman et al 2013 guadagnini et al 2014 it is reported that the moisture distribution is affected by the distribution of hydraulic conductivity or porosity suekane et al 2009 zhou et al 2010 thus fbm may also be used to analyze the moisture distribution at the darcy scale in the 1 d framework fbm is defined as a random process y x of the independent spatial or temporal variable x with the increments of y x being statistically invariant with respect to an affine transformation molz et al 1997 in the most elementary form this means that the increment y xn y x1 satisfies 9 y x n y x 1 x n x 1 h where is the expectation function is the absolute value function h is the hurst coefficient 0 h 1 based on the value of h a random process can be classified into three categories 1 when h is less than 0 5 the increments of y x are negatively correlated and the process is said to be anti persistent barunik and kristoufek 2010 an anti persistent process has a characteristic of mean reversion which means that y x tends to regress strongly toward the mean the characteristic of mean reverting becomes more evident as the h approaches 0 2 when h is larger than 0 5 the increments of y x are positively correlated and the process is said to be persistent barunik and kristoufek 2010 a persistent process has a characteristic of trend reinforcing which means that y x tends to increase decrease continuously towards a higher lower value the characteristic of trend reinforcing becomes more evident as the h approaches 1 3 when h equals to 0 5 the increments of y x may be termed random steps because the increments are uncorrelated with each other in this situation the process can be seen as a classical brownian motion cbm the hurst coefficient of a given fbm data sequence y x can be estimated based on the statistical invariance of y x the variance vn of y x over the interval x1 xn is defined as the variance of y values over that interval thus a dimensionless rescaled variance of y x may be defined by dividing the vn by the standard deviation sn of the y x increments according to cajueiro and tabak 2005 the rescaled adjusted variance of y x vn s2 n should satisfy the following relationship 10 v n s n 2 x n x 1 2 h where vn is the variance of adjusted y x in x1 xn and sn is the standard deviation of the increments of adjusted y x and is defined as below 11 v n 1 n k 1 n i 1 k dy i dy 2 1 n k 1 n i 1 k dy i dy 2 12 s n 1 n i 1 n dy i dy 2 1 2 where dyi is the increment of y and is given by yi yi 1 dy equals to i 1 n dy i n the eqs 9 and 10 can be used to estimate the hurst coefficient of an fbm data sequence according to eqs 9 and 10 the log log plot of y x n y x 1 or v n s n 2 versus x n x 1 will yield lines of slope h or 2h the two estimation methods of h are called intensity difference method chen et al 1989 and v s analysis method cajueiro and tabak 2005 respectively 3 results and discussion 3 1 the moisture distribution on the wetting front during drainage and imbibition the moisture distribution is presented in the form of 3d moisture content surfaces in fig 3 as can be seen in fig 3a as the moisture content changes the moisture distribution displays different characteristics based on the characteristics of the moisture distribution the moisture content surface can be divided into 3 different zones in zone i where moisture contents are lower than 0 10 the moisture contents show little fluctuation however in zone ii where moisture contents are between 0 10 0 25 the moisture contents show obvious fluctuation and fingers can be seen in this zone in zone iii where moisture contents are larger than 0 25 the moisture contents show little fluctuation again similar fingers can also be seen on the wetting front zone ii of main drainage and secondary drainage period fig 3c and e while for imbibition periods fig 3b d and f no significant fingers are presented on the wetting front zone ii the different characteristics of the moisture distribution during drainage and imbibition may be induced by the following causes the drainage process is a gravity driven process and the capillary pressure cannot always maintain balance with gravity causing unstable drainage events to happen and fingers to develop on the wetting front while the imbibition process can be seen as a capillary driven process and the capillary pressure is always balanced with the gravity making the imbibition process more stable and frontal the unstable drainage event which is called the haines jump at the pore scale has been recognized for long haines 1930 the event of haines jump happens when the air passes from a pore neck into a wider pore body displacing the water and is usually accompanied by a sudden drop in capillary pressure berg et al 2013a thus the haines jump can bring large fluctuations in water distribution at the pore scale in fact the unstable drainage event or haines jump at the pore scale is a widespread phenomenon in the porous media the drainage process at the darcy scale can be seen as an ensemble of pore scale haines jumps occurring as avalanche like events armstrong et al 2015 in summary these fingers observed in fig 3a c and e on the wetting front provide evidence that the unstable pore scale drainage event or haines jump can influence the moisture distribution at the darcy scale 3 2 analysis of the characteristics of the moisture distribution on the wetting front to further investigate the characteristics of the moisture distribution on the wetting front during drainage and imbibition the horizontal moisture distribution in the sand chamber is extracted and analyzed quantitatively it should be mentioned that the moisture distribution tends to be irregular close to the left and right boundary because of the dominant channels near the frame hence the moisture contents near the central vertical line central 400 pixels e g fig 4 are discussed in the following sections fig 4 shows the moisture distribution on the wetting front at the 50th min of main drainage and main imbibition as can be seen in fig 4 the horizontal moisture contents fluctuate during both drainage and imbibition periods during main drainage period it fluctuates in a larger range from 0 145 to 0 175 while during main imbibition period it only fluctuates in a smaller range from 0 150 to 0 165 the large fluctuation in the moisture distribution during drainage can be seen as the direct cause of fingers on the wetting front as observed in fig 3 3 2 1 correlation coefficients of the horizontal moisture distribution in order to study the factors affecting the moisture distribution during drainage and imbibition the horizontal moisture contents on the wetting front at the 50th min of drainage and imbibition are compared in fig 5 it can be observed from fig 5a that the pattern of the moisture distribution during main drainage period is quite similar to that of secondary drainage period in fig 5b the moisture distribution during main imbibition period displays a similar pattern to that of secondary imbibition period the correlation coefficients r are calculated using the moisture contents shown in fig 5 400 pixels for each period and the correlation matrix is presented in table 2 as shown in table 2 the spearman correlation coefficient of the moisture contents during the two drainage periods is 0 71 and during the two imbibition periods the moisture contents also display strong positive correlation r 0 79 the positive correlation in the moisture distribution during different drainage or imbibition periods may be attributed to the spatial characteristics of the working sand suekane et al 2009 measured the porosity distribution as well as the equilibrium moisture distribution in sandstone cores and glass beads using x ray tomography it was found out by suekane et al 2009 that the moisture contents decreased with an increase in the porosity it was later found out by zhou et al 2010 that the equilibrium moisture distribution was highly comparable to the distribution of the porosity and the equilibrium moisture distribution remains stable under different flow rates although the local porosity of the 2d sand chamber used in this paper is hard to measure it can be inferred that the moisture distribution is controlled by the porosity distribution in the sand chamber under the same flow condition because the porosity distribution remains stable during the experiments the patterns of the moisture distribution change little during different drainage or imbibition periods as also shown in table 2 the moisture distribution during drainage periods does not correlate with the moisture distribution during imbibition periods it can be inferred that the moisture distribution is affected not only by the spatial characteristics of the porous media but also by the direction of the water flow 3 2 2 hurst coefficients of the moisture distribution the hurst coefficients of the horizontal moisture distribution at three different heights of the sand chamber during primary drainage are estimated using intensity difference methods and v s analysis as shown in fig 6 the two methods present fairly linear relationship between ln δθw or ln v s2 and ln δx which means that the horizontal moisture distribution can be described by fbm with the estimated hurst coefficients the hurst coefficients of the moisture distribution in the sand chamber during each drainage imbibition period are shown in fig 7 it can be observed from fig 7 that the peak value of hurst coefficients is always located on the wetting front with the peak value around 0 5 during drainage and around 0 2 during imbibition the peak value of hurst coefficients appearing on the wetting front implies that the moisture contents fluctuate in a larger range on the wetting front comparing to the other two zones during drainage and imbibition the value of hurst coefficients during drainage is relatively larger than that during imbibition which indicates that water moves in a more unstable manner during drainage than during imbibition the difference in the moisture distribution during drainage and imbibition captured by hurst coefficients is consistent with the experimental observations presented in figs 3 and 4 as mentioned in section 2 5 when hurst coefficient h is less than 0 5 the increments in moisture content will be negatively correlated and as h becomes smaller the characteristic of mean reversion in the moisture distribution becomes more evident the smaller peak value of h during imbibition periods indicates that the moisture distribution is constrained to around its mean value along the horizontal direction and fluctuates in a relatively smaller range while the larger peak value of h during drainage periods on the wetting front indicates that larger fluctuation in the moisture distribution can be seen on the wetting front during drainage it is observed in pore scale drainage experiments conducted by moebius and or 2012 that the apparently continuous motion of wetting fronts in porous media are inherently quite irregular at the pore scale this kind of irregularity on the wetting front during drainage can be easily captured by estimating the hurst coefficients of the moisture distribution 3 3 the moisture distribution under different experimental conditions 3 3 1 the effect of packing density on moisture distribution to assess the effect of packing density on moisture distribution the hurst coefficients of the moisture distribution estimated by v s analysis under different packing densities during consecutive drainage and imbibition are shown in fig 8 from fig 8 it can be observed that when packing density changes from 0 336 to 0 383 hurst coefficients display little change which means that the packing density of the working sand has little effect on the moisture distribution during drainage and imbibition the effect of packing density on moisture distribution has also been investigated in the studies of hincapié and germann 2010 and it was found out that the moisture distribution remains stable under different packing densities generally speaking it can be concluded that the moisture distribution on the wetting front is hardly affected by the packing density of the working sand during drainage and imbibition 3 3 2 the effect of flow rate on moisture distribution the hurst coefficients of the moisture distribution under different imbibition and drainage rates q 5 ml min 10 ml min 100 ml min and 400 ml min are shown in fig 9 as the drainage rate increases from 5 ml min to 400 ml min the hurst coefficients on the wetting front zone ii change little while the hurst coefficients above the wetting front zone i increase significantly as the drainage rate increases to 400 ml min little change in hurst coefficients on the wetting front indicates that the fluctuation in moisture contents remains stable on the wetting front under different drainage rates thus the moisture distribution remains similar on the wetting front under different drainage rates while the significant increase in hurst coefficients above the wetting front indicates that as drainage rate increases the moisture distribution changes significantly above the wetting front in fact at higher drainage rate more water is retained above the wetting front leading to significant change in the moisture distribution above the wetting front it can be seen in fig 9a d that as the imbibition rate increases from 5 ml min to 400 ml min the peak value of hurst coefficients decreases accordingly from around 0 2 to around 0 1 the decrease in hurst coefficient indicates that the fluctuation in moisture contents is suppressed and the wetting front becomes more regular as imbibition rate increases the effect of imbibition rate on the wetting front has been studied thoroughly by pore scale experiments and simulations lenormand and zarcone 1984 hughes and blunt 2000 nguyen et al 2006 as illustrated by hughes and blunt 2000 when the imbibition rate is high the viscous force dominate and the cooperative pore filling event happens frequently thus there is a tendency for water to fill in nearby pores rather than create extended capillary fingers leading to a front that is flat at the pore scale while when the imbibition rate is low the capillary force dominates which means that water fills the media in the order of pore size and irregular capillary rise develops on the wetting front at the pore scale from the processes observed at the pore scale it can be inferred that at the darcy scale as the imbibition rate increases the unbalanced capillary rise induced by local heterogeneity is also suppressed so the fluctuation in moisture contents on the wetting front is also suppressed as the imbibition rate increases and this change in the moisture distribution is captured by hurst coefficients 4 conclusions the moisture distribution during drainage and imbibition are studied thoroughly through experiments in a 2d sand chamber the moisture distribution can be observed using ltm and visualized on the 3d moisture content surface during drainage the moisture contents on the wetting front fluctuate in a larger range due to haines jumps and fingers can be seen on the moisture content surface while during imbibition the moisture contents on the wetting front fluctuate in a smaller range making the wetting front more frontal the difference of the moisture distribution on the wetting front between drainage and imbibition at the darcy scale clearly show that the pore scale processes would not average out when up scaling the hurst coefficient could be used to capture the moisture distribution during the experiments and carry integrated information about the underlying pore scale processes the peak value of the hurst coefficients always appears on the wetting front and it is larger during drainage than during imbibition the moisture distribution on the wetting front is hardly affected by the packing density of the working sand as flow rate increases from 5 ml min to 400 ml min the moisture distribution on the wetting front displays similar pattern during drainage while during imbibition the moisture distribution on the wetting front becomes more uniform with increasing flow rates it should be noted that all the results in this paper are based on the accusand silica sand in 40 50 grade given the diversity of the porous media more experiments should be conducted to investigate the effect of porous media on the moisture distribution during drainage and imbibition acknowledgments this work was supported by grant from the national natural science foundation of china grant no u1503282 and 41672233 and in part from the open fund of the state key laboratory of water resources and hydropower engineering science grant no 2014nsk01 and the key research and development project of jiangsu province china grant no be2015708 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 069 appendix b supplementary data supplementary data 1 
7267,reliable streamflow forecasts can be highly valuable for water resources planning and management in this study we combined a hidden markov model hmm and gaussian mixture regression gmr for probabilistic monthly streamflow forecasting the hmm is initialized using a kernelized k medoids clustering method and the baum welch algorithm is then executed to learn the model parameters gmr derives a conditional probability distribution for the predictand given covariate information including the antecedent flow at a local station and two surrounding stations the performance of hmm gmr was verified based on the mean square error and continuous ranked probability score skill scores the reliability of the forecasts was assessed by examining the uniformity of the probability integral transform values the results show that hmm gmr obtained reasonably high skill scores and the uncertainty spread was appropriate different hmm states were assumed to be different climate conditions which would lead to different types of observed values we demonstrated that the hmm gmr approach can handle multimodal and heteroscedastic data keywords gaussian mixture regression hidden markov model kernelized k medoids clustering probabilistic streamflow forecasting 1 introduction streamflow forecasting plays a critical role in water resources planning and management chiew et al 2003 zhao and zhao 2014 reliable and skillful streamflow forecasts can help water resource managers to make better decisions as well as promoting the sustainable development of the local economy the existing approaches for streamflow forecasting are classified into three main categories physical based models conceptual methods and empirical models bourdin et al 2012 devia et al 2015 the early empirical models were usually linear such as autoregressive autoregressive moving average and linear regression castellano méndez et al 2004 haltiner and salas 1988 salas et al 1985 valipour et al 2013 wu et al 2009 however these models have a limited ability to handle the non stationary and non linear relations massively involved in hydrological processes zhang et al 2015 in addition to the conventional linear statistical techniques a wide range of machine learning methods have been developed and used for hydrological forecasting the two most commonly used machine learning methods applied in the hydrologic community are the artificial neural network ann mcculloch and pitts 1943 kohonen 1988 chiang et al 2004 cigizoglu 2005 mutlu et al 2008 and support vector machine svm vapnik 1995 collobert and bengio 2001 dibike et al 2001 wu et al 2009 the reliable quantification of forecast uncertainty is also very important for water resource management svm and ann are both point forecast algorithms and they cannot provide information about the intrinsic level of forecast uncertainty one approach for quantifying this uncertainty involves obtaining estimates of upper and lower bound prediction intervals which indicate the range within which the observed data are likely to occur with some probabilistic level of confidence such as 90 ye et al 2014 ye et al 2016 the bayesian technique is another approach for a direct quantification of prediction uncertainty where it estimates the posterior distribution based on the prior probability and likelihood murphy 2012 for example the bayesian joint probability method has been employed for monthly and seasonal streamflow forecasting wang et al 2009 wang and robertson 2011 zhao et al 2016 where this method assumes that the data are multivariate gaussian and it mainly focuses on learning the parameters of an enhanced box cox transform using monte carlo markov chain sampling however the bayesian joint probability method does not consider the potential climate states in the model different climate states will influence the rainfall runoff process so it is important and meaningful to consider the potential states and their variations during streamflow forecasting hidden markov models hmms also known as markov switching models or dependent mixture models comprise a discrete time discrete state markov chain with hidden states plus an observation model which can describe the potential states in a catchment previously it has been reported that hmm is a robust method for simulating hydrologic time series the hidden states of hydrologic time series are typically described as climate regimes akintug and rasmussen 2005 investigated the properties of hmm for generating annual time series a hmm was also developed to generate runoff scenarios and rainfall data respectively gelati et al 2010 sansom and thomson 2010 a hmm combined with climate indices was proposed for multidecadal streamflow simulation bracken et al 2014 however extensions of hmm are still needed for probabilistic monthly streamflow forecasting gaussian mixture regression gmr is an alternative method to obtain a predictive distribution from a joint distribution for a hmm although it is generally used for mixture models in contrast to other regression methods such as svm and ann gmr does not model the regression directly but instead it models a joint probability density function of the data and then derives the regression function from the joint density model carreau et al 2009 calinon et al 2010 lee et al 2016 this is an advantage for streamflow forecasting since density estimation can handle different sources of missing data non concurrent data and data with many occurrences of zero flows wang et al 2009 zhao et al 2016 compared hmm with an unconditional mixture model calinon et al 2007 it can be interpreted as an extension of a mixture model where the choice of mixture component for each observation is not selected independently but instead it depends on the choice of component for the previous observation in this study we considered a framework that combines hmm and gmr hmm gmr for monthly streamflow forecasting the main outcomes of this study are as follows 1 we used a kernelized k medoids clustering technique as a stable initialization strategy to avoid the model becoming trapped by poor local minima 2 we extended gmr by recursively computing a likelihood through the hmm representation thereby considering the predictors as well as the sequential information probabilistically encapsulated in the hmm 3 we verified the effectiveness of hmm gmr based on yichang station in the upstream region of yangtze river by using a monthly streamflow series where we mainly focused on the forecast reliability and skill the remainder of this paper is organized as follows in section 2 we introduce the model formulation the learning algorithm for hmm and gmr for probabilistic forecasting in section 3 we explain the forecast verification methods in section 4 we present an application of hmm gmr to forecasting streamflows at three hydrological stations in the upstream region of the yangtze river in chain in sections 5 and 6 we discuss our results and give our conclusions respectively 2 methods 2 1 hmm a hmm comprises a discrete time discrete state markov chain with hidden states z t 1 k plus an observation model p x t z t where t stands for the time indices and 1 t t the probability of zt depends on the state of the previous latent variable zt 1 via a conditional distribution p zt zt 1 the latent variables may be represented as k dimensional binary variables with k 1 0 s and a single 1 at position k indicating the state value so this conditional distribution corresponds to a table of numbers which we denote by a and its elements are known as transition probabilities 1 a a 11 a 1 k a k 1 a kk where a ij p z t j z t 1 i and they satisfy 0 a ij 1 with j a ij 1 the transition matrix is illustrated diagrammatically by drawing the states as nodes in a state transition diagram as shown in fig 1 for the case where k 3 in this formulation the observed sequence xt depends on the current hidden state zt thus the conditional distributions of the observed variables are defined as p x t z t k ϕ k where ϕ is a set of parameters that govern the distribution we consider d variables comprising both monthly streamflows to be forecast and their predictors such as climate and catchment indicators 2 x t x 1 x 2 x d in this study the distribution of the observations of each state is represented as a multivariate gaussian 3 p x t z t k ϕ k ℏ n x t μ k k where μ k is the mean vector and k is the covariance matrix and one way of estimating the parameters is the maximum likelihood estimate mle as follows 4 μ 1 t t 1 t x t x 5 σ 1 t t 1 t x t x x t x t 1 t t 1 t x t x t t x x t the joint probability distribution over both the latent and observed variables is then given by 6 p x z θ p z 1 π t 2 t p z t z t 1 a t 1 t p x t z t ϕ where x x 1 x t z z 1 z t and θ π a ϕ denotes the set of parameters of hmm π k is the initial probability of being in state k aij is the transitional probability from state i to state j and ϕ k μ k k where μ k and k represent the center and the covariance matrix of the kth gaussian distribution of the hmm respectively 2 2 learning for the hmm we now explain how to estimate the parameters θ π a ϕ the baum welch algorithm baum et al 1970 which is a variant of the expectation maximization em algorithm is used to learn the parameters in the same manner as the em algorithm we must be careful when we initialize the parameters in order to minimize the chance of being trapped by poor local optima thus the kernelized k medoids clustering technique is applied to the data to avoid being trapped by poor local minima 2 2 1 kernelized k medoids clustering the em algorithm requires an initial estimate to avoid being trapped by poor local minima the most common method employed is k means clustering calinon et al 2007 lee et al 2016 which is a heuristic clustering algorithm with computational simplicity however k means clustering uses the euclidean distance to measure dissimilarity which is not always appropriate for structured objects an alternative approach is to use a kernel function that measures the similarity between objects the kernel method has been used in many clustering and regression techniques such as svm and its reliability has been demonstrated thus we employ the k medoids algorithm with a kernel function the k medoids algorithm is similar to k means but instead of representing each cluster s centroid as the mean of all the data vectors assigned to this cluster k medoids set each centroid as one of the data vectors themselves thus it always deals with integer indexes rather than data objects the algorithm can be kernelized by using the kernel function k x i x i to replace the euclidean distance x i x i 2 and we use the radial basis function rbf kernel 7 d i i ℏ k x i x i exp x i x i 2 2 σ 2 if the two points are the same the kernel function d i i 1 and if the two points are far from each other then the value will be close to 0 clearly the function will have a larger value when the two data points are more similar the first step is to randomly select k centroids m 1 k from 1 n where k is equal to the number of states in the hmm and n is the sample number when updating the centroids each data point is classified according to its nearest centroid where we measure the sum of its distances from all the others in the same cluster we then select that with the largest sum as the new centroid the pseudo code for this process is given in algorithm 1 8 m k argmax i z i k i z i k d i i algorithm 1 kernelized k medoids clustering 1 initialize m 1 k as a random subset of size k from 1 n 2 repeat 3 z i argmax k d i m k for i 1 n 4 m k argmax i zi k i z i k d i i for k 1 k 5 until converged after the clustering we can get k clusters form the data each data point is labeled from 1 k and every cluster k has its mean vector and the covariance matrix so the parameter values θ π a ϕ can be obtained by the initial clusters 2 2 2 baum welch algorithm thereafter we employ the em algorithm to find an efficient framework for maximizing the likelihood function in hmms em is an iterative algorithm that alternates between inferring the hidden states given the parameters e step and then optimizing the parameters given the filled in data m step when applied to hmms this is also known as the baum welch algorithm baum et al 1970 2 2 2 1 e step the e step consists precisely in the computations of γ t k and ξ t i j the expected complete data log likelihood is given as follows 9 q θ θ old k 1 k γ 1 k ln π k t 2 t i 1 k j 1 k ξ t i j ln a ij s um t 1 t k 1 k γ t k ln p x t ϕ k the state occupation probability γ t k is the probability of occupying state k at time t given the sequence of observations 10 γ t k p z t k x θ old p x z t k θ old j 1 k p x z t j θ old the probability of being in state i at time t 1 and being in state j at time t ξ t i j can be expanded as follows 11 ξ t i j p z t 1 i z t j x θ old p z t 1 i z t j x θ old i 1 k j 1 k p z t 1 i z t j x θ old γ t k and ξ t i j can be obtained via backward and forward inductive computations in t which is known as the forward backward algorithm rabiner 1989 2 2 2 2 m step in the m step we re estimate the parameters using the current responsibilities γ t k and ξ t i j where we optimize q with respect to the parameters θ π a ϕ maximization with respect to π and a is achieved readily using appropriate lagrange multipliers with the result 12 π k γ 1 k j 1 k γ 1 j 13 a ij t 2 t ξ t i j k 1 k t 2 t ξ t i k to derive the m step for the μk and σk terms we consider the parts of q that depend on μk and σk which is a weighted version of the standard problem of computing the mles of an multivariate gaussian the new parameter estimates are given as follows 14 μ k t 1 t γ t k x n t 1 t γ t k 15 k t 1 t γ t k x t μ k x t μ k t t 1 t γ t k after computing the new estimates we set θ π a ϕ if the convergence criterion is not satisfied then return to the next e step 2 2 3 forward backward algorithm next we describe an efficient procedure called the forward backward algorithm for evaluating the quantities γ t k and ξ t i j which corresponds to the e step in the baum welch algorithm in the forward backward procedure we consider the forward variable α t k defined as 16 α t k p x 1 x t z t k θ old i 1 k a t 1 i a ik p x t z t k ϕ k i 1 k a t 1 i a ik n x t μ k k the quantity α t k represents the joint probability of observing all of the given data up to time t and occupying state k at time t where the initialization value is a 1 k π k n x 1 μ k k in a similar manner we can consider a backward variable β t k defined as 17 β t k p x t 1 x t z t k θ old i 1 k a ik p x t 1 z t 1 i ϕ i β t 1 i i 1 k a ik n x t 1 μ i i β t 1 i the quantity β t k represents the conditional probability of all future data from time t 1 up to t given the state at time t where the initialization value is β 1 k 1 then eq 10 can be expressed simply in terms of the forward backward variables 18 γ t k α t k β t k p x θ old α t k β t k i 1 k α t i β t i α t k accounts for the partial observation sequence x 1 x 2 xt and state k at time t while β t k accounts for the remainder of the observation sequence x t 1 xt given state k at time t the normalization factor p x θ old i 1 k α t i β t i makes γ t a probability measure such that i 1 k γ t i 1 from the definitions of the forward and backward variables we can write ξ t i j in the following form 19 ξ t i j α t 1 i a ij p x t z t j ϕ j β t j p x θ old α t 1 i a ij n x t μ j j β t j i 1 k j 1 k α t 1 i a ij n x t μ j j β t j we have already defined γ t i as the probability of being in state k at time t given the observation sequence and the mode so we can relate γ t i to ξ t i j by summing over j thereby obtaining γ t i j 1 k ξ t i j after the iteration we can consider the hidden state z t argmax k γ k 2 3 model selection the hmm can describe the data more accurately as the number of states increases but this may also result in overfitting therefore we need to make a tradeoff between optimizing the model s likelihood a measure of how well the model fits the data and minimizing the number of parameters needed to encode the data different approaches have been proposed to solve this problem such as cross validation seni and elder 2010 akaike information criteria akaike 1974 minimum description length rissanen 1978 and bayesian information criteria schwarz 1978 in our method we use leave five years out cross validation to select the number of states for the hmm this cross validation procedure generates a forecast for a particular year by fitting the hmm using all of the available data but by leaving out that year and the following four years as missing data thereby reducing the impact of the catchment memory and not artificially inflating the forecast skill the forecast is obtained by gmr and the performance criterion is evaluated according to the skill using the continuous ranked probability score crps 2 4 gmr for probabilistic forecasting next we explain how to derive the conditional distribution from a hmm the data x t can be separated into two subvectors 20 x t y t z t where y t comprise the predictors 21 y t x t 1 x t 2 x t d 1 and z t comprise the predictands 22 z t x t d 1 1 x t d 1 2 x t d 2 4 1 regression from the jointly gaussian distributions our starting point is the simple joint gaussian density of x y one classical result of the multivariate gaussian density is that when partitioning the joint density into fx y fy x f x both fy x and f x are also multivariate gaussian theorem 1 is a well established result murphy 2012 theorem 1 suppose that x y z is joint gaussian p y z n μ with parameters 23 μ μ y μ z yy yz zy zz the posterior conditional distribution is given as follows 24 p z y ℏ n μ z y z y μ z y μ z zy yy 1 y μ y z y zz zy yy 1 yz theorem 1 indicates that when p y z is a joint gaussian distribution then the conditional density is also gaussian this theorem can be extended to a finite gaussian mixture called gmr sung 2004 we use gmr to derivate the conditional density of the hmm 2 4 2 gmr for hmm hmms are also known as dependent mixture models and they can be interpreted as an extension of a mixture model where the choice of the mixture component for each observation is not selected independently but instead it depends on the choice of component for the previous observation the predictors and predictands in each state of the hmm are defined as 25 μ k μ y k μ z k k yy k yz k zy k zz k for each gaussian state k according to eq 24 the conditional expectation μ z t y t k of zt given yt and the estimated conditional covariance z t y t k of zt given yt are 26 μ z t y t k μ z k zy k yy k 1 y t μ y k 27 z y k zz k zy k yy k 1 yz k for a given time step t the observations are modeled by a mixture of k gaussian distributions k being the number of states of the hmm the conditional probability distribution function of zt yt is 28 f z t y t k 1 k h k y t n z t μ z t y t k z y k in the original gmr framework the influence of the different gaussians is represented by weights hk defined as the probability of an observed input belonging to each of the gaussians we propose to extend gmr to exploit the emission probability in the hmm framework by recursively computing a likelihood through the hmm representation thereby considering the predictors yt as well as the sequential information probabilistically h k y t 1 encapsulated in the hmm 29 h k y t i 1 k h i y t 1 a ik n y t μ y k yy k j 1 k i 1 k h i y t 1 a ij n y t μ y j yy j where h k y t represent the hmm forward variables initialized with h k y 1 π k n y 1 μ y k yy k which correspond to the probability of observing the partial sequence y 1 y 2 yt and being in state k at time t the conditional probability distribution function given in eq 28 is the full forecast probability density of hmm gmr and it can forecast the distribution of the predictands given the predictors the probability forecast skill score and the reliability are based on the conditional probability distribution function however if we want a point result for the forecast then the condition expectational μ z t y t of hmm gmr is derived as 30 μ z t y t k 1 k h k y t μ z t y t k 2 6 outline of hmm gmr an outline of hmm gmr is described in the following and a flow chart illustrating the hmm gmr framework is shown in fig 2 the main code for hmm gmr kernelized k medoids clustering baum welch algorithm and gmr are written used matlab which is very convenient for matrix operations step 1 data collection read the training data and testing data and do data preprocessing set k 1 where k is the number of states of the hmm step 2 model selection step 2 1 cross validation set t 1 where t is time indices 1 initialization use kernelized k medoids clustering to classify the training data into k categories 2 learning for hmm use the baum welch algorithm to maximize the likelihood function 3 if t t turn to step 2 2 else t t 1 return to 1 step 2 2 evaluate the performance criterion if k knum select the k with the best performance and turn to step 3 else k k 1 return to step 2 1 step 3 forecasting the posterior conditional distribution of the streamflows is calculated by gmr 3 forecast verification the quality of forecasts can be investigated based on the bias skill and reliability laio and tamea 2007 murphy 1993 bias can be defined as the correspondence between the mean forecast and observation in this study we evaluated the skill score based on the mean squared error mse and crps for the forecasts in addition we examined a uniform probability plot of the forecast probability integral transform pit value to assess the forecast reliability 3 1 skill score based on mse the mse is defined as the average of the squares of the errors in regression analysis the term mse is sometimes used to refer to the unbiased estimate of the error variance 31 mse 1 t t 1 t x t x obs t 2 where x t is the prediction at time t which we define as the expectation of the probabilistic forecast using eq 30 the skill score based on the mse is defined as follows 32 ss mse mse mse ref 0 mse ref when using observed historical climatology means as the reference forecasts mse ref 1 t t 1 t x x obs t 2 ssmse is equal to the nash sutcliffe efficiency nash and sutcliffe 1970 ssmse is greater than 0 when our forecast is better than the reference forecast but smaller than 0 when the forecast is inferior to the reference forecast 3 2 skill score based on crps the crps is suitable for deterministic ensemble and probabilistic forecasts of continuous variables for verification hersbach 2000 if we suppose that the probability distribution function forecast by hmm gmr is given by p x using eq 28 and that xobs is the observed value then the crps expressing some kind of distance between the probabilistic forecast p and truth xobs is defined as 33 crps f x h x x obs 2 dx where f x is the cumulative distribution function for the forecast 34 f x x p y dy and 35 h x x obs l 0 for x x obs 0 1 for x x obs 0 where h x x obs is the heaviside function for a deterministic single value or point forecast the crps is equal to the absolute error the minimum crps value of zero is achieved only in the case of a perfect single value forecast the skill score based on the crps is defined as 36 ss crps crps crps ref 0 crps ref where the overbar denotes averaging over the forecast cases and crpsref is the crps for a reference forecast usually based on climatology similarly sscrps is greater than 0 when our forecast is better than reference forecast and smaller than 0 when the forecast is poorer than reference forecast 3 3 reliability of the forecast reliability refers to the statistical consistency of forecasts and observations we examined a uniform probability plot of the forecast pit values to assess the forecast reliability a pit value is derived from the cumulative distribution function f x and the observed value xobs as follows 37 pit f x obs x obs p x dx when the forecasts are reliable the pit values follow a uniform distribution between 0 and 1 the uniformity can be checked by pooling together the pit values for all of the forecast cases t 1 2 t and displaying the ranked values in a uniform probability plot fig 3 this pit uniform probability plot can be used to indicate whether the predicted forecast probability distributions are excessively high or low or excessively wide or narrow laio and tamea 2007 4 application 4 1 data to demonstrate the effectiveness of the hmm gmr approach we considered monthly forecasting for the upstream region of the yangtze river the yangtze river has a length of 6380 km and it is the longest river in china and the third longest in the world for thousands of years this river has been used for water irrigation sanitation transportation and industry and thus it plays a vital role in the economic development and conservation of the ecological environmental in china the yangtze river originates from several tributaries in the eastern part of the tibetan plateau and it flows eastward into the east china sea at shanghai the drainage basin lies between 91 e 122 e and 25 n 35 n and it covers a total area of 1808500 km2 we focused on three hydrometric stations in the upper yangtze region the locations of the stations are shown in fig 3 the streamflows from december to march at yichang station were forecast respectively based on the antecedent streamflow at yichang station and two neighboring stations wulong station on wu river and beibei station on jialing river table 1 lists the predictors and predictands employed these data covered a period comprising 55 years of monthly mean streamflow at the three hydrological control stations from 1953 to 2007 4 2 forecast verification results 4 2 1 mse and crps skill scores the skill scores for the streamflow forecast from december to march at yichang station are given in table 2 the mse skill scores ssmse were used for point forecasts and mainly to verify the forecast bias eq 30 obtains a point forecast for hmm gmr and we used this regression function to calculate ssmse the sscrps values obtained via cross validation for hmm with state numbers varying from 1 to 5 are shown in fig 4 according to fig 4 the values of sscrps was high when the number of hmm states was equal to 2 and it became smaller when as k increased thus the number of hmm states k was selected as 2 in addition we employed svm in this study as a competitive model for point forecasts where we used the ls svmlab matlab toolbox for this application for further details see http www esat kuleuven ac be sista lssvmlab two extra parameters are required in order to make an svm where gam is the regularization parameter that determines the trade off between the fitting error minimization and smoothness and sig2 is the bandwidth in the common case of the rbf kernel the regularization parameter gam and kernel parameter sig2 for svm were optimized by cross validation different months had different parameters table 2 shows that both hmm gmr and svm obtained mse skill scores greater than 20 and the skill scores produced with hmm gmr were similar to those using svm therefore the point forecasts obtained by hmm gmr were satisfactory the crps scores sscrps penalize forecast bias as well as penalizing a distribution that is excessively wide or narrow eq 28 gives the conditional forecast distribution for hmm gmr where the crps skill scores measured the accuracy of the hmm gmr monthly forecasts compared with the climatology forecasts the results showed that all of the sscrps were greater than 10 thereby demonstrating that the forecasts had lower average errors than the climatology reference forecasts 4 2 2 monthly forecast reliability after examining the skill of the hmm gmr probabilistic monthly forecasts their reliability was evaluated further the reliability of the monthly forecasts at capturing the observations was examined using pit uniform probability plots as shown in fig 5 the pit values for december and january were generally close to the diagonal line although small departures from the diagonal line were observed in february and march but they were well within the kolmogorov 5 significance bands laio and tamea 2007 this suggests that the pit values were distributed quite uniformly and thus the forecast probability distributions were generally adequate because excessively high or low or excessively wide or narrow distributions were not predicted therefore we consider that the forecast probability distributions were generally unbiased and with appropriate spreads 4 2 3 comparison plots of the forecast and observed value the forecast mean and 0 1 0 9 quantile ranges based on an observed value for individual events are compared chronologically in fig 6 the open squares and vertical lines are the means of the forecasts and the forecast 0 10 0 90 quantile range obtained using hmm gmr the black horizontal line and shading represent the climatology mean and climatology 0 10 0 90 quantile range respectively the red dots denote the observed streamflow this plot clearly illustrates the probabilistic forecast compared with the climatology forecast according to fig 6 there was no obvious trend over time in terms of the relationship between the forecasts and observed values where the predictions were not biased in any particular direction over time fig 7 show the comparison plots according to the forecast mean where it indicates that the forecast mean appeared to be consistent with the observed values there was no obvious trend in the forecast mean in terms of the relationship between the forecasts and the observed values thus the predictions were not biased significantly in any particular direction with respect to forecast means figs 6 and 7 also compare the results obtained using the hmm gmr with the climatology reference forecasts a red point on the blue vertical line or gray shading denotes that the probabilistic forecast or climatology forecast was unbiased according to the results obtained for the four months 42 observed values from the climatology reference forecasts range were larger than those obtained by hmm gmr with only 31 outliers thereby demonstrating that hmm gmr obtained better predictions than climatology forecasting 4 2 4 pit plots figs 8 and 9 show the pit values for individual events where the events are displayed chronologically in fig 8 and according to the forecast mean in fig 9 the pit value is close to 1 if the forecast is excessively large and close to 0 when the forecast is excessively small the forecasts are unbiased when the pit values are clustered around 0 50 but the forecast distributions can be sharper or narrower the ideal forecasts should yield a uniform distribution for the pit values in 0 1 with no obvious trends over time or with respect to the forecast mean figs 9 and 10 show that the pit values had an almost uniform distribution with no obvious trend over time or with respect to the forecast mean 4 2 5 hidden states of the hmm the proposed hmm gmr approach uses a hmm to fit the streamflow data set where there are two hidden states in our hmm fig 10 shows the states of the observed values where the red dots and blue dots represent the two different states of the observed values the horizontal line and shading represent the streamflow mean and the 0 10 0 90 quantile range for points with two different states respectively fig 11 shows that the observed values were clearly divided into two areas and we assumed the two areas states corresponded to potential dry or wet climatic conditions these potential climatic conditions explained the trend in the observed values it should be noted that although the terms wet and dry are commonly used to describe the states of an hmm low flows can be generated in the wet state and vice versa after learning the hmm gmr is employed for streamflow forecasting gmr treats the distribution of the data set as a mixture of gaussian hmm is also a dependent mixture model that can describe multimodal and highly skewed data fig 11 shows the joint distribution of streamflow at yichang station predictand and the antecedent streamflow at beibei station one of the predictors in fig 11 the red dots and blue dots represent the two different states of the observed values the contour is the probability density of the distribution and it can be seen that mixture of gaussian fitted the data set well the final conditional probability distribution was derived based on the joint distribution in gmr 5 discussion our proposed hmm gmr approach can forecast the monthly streamflow given covariate information including the antecedent flow at a local station and two surrounding stations in practice large numbers of candidate predictors are often available for selection these predictors will influence the transition probabilities of the hidden states and the observation probability model therefore a selection procedure is required to choose reasonable predictors to improve the forecast the hmm learns the monthly streamflow distribution across multiple years where the hidden states of the hmm depend on whether the catchment is dry or wet in each year therefore only decades of annual data are available to train the hmm for every month so overfitting will readily occur as k increases however the hmm can be trained using the data set by pooling 12 months of data together where the hidden states are treated as stochastic seasonality but a problem may occur where the number of hidden states may be excessive and selection is difficult in future research we will investigate a new model with continuous hidden states which can avoid the model selection procedure 6 conclusion in this study we proposed the hmm gmr approach for monthly streamflow probability forecasting the framework of hmm gmr comprises two main components learning for hmm and forecasting with gmr the hmm comprises a discrete time discrete state markov chain with hidden states plus an observation model we proposed a kernelized k medoids clustering method to initialize the model when learning the parameters of hmm the baum welch algorithm is employed to optimize the initial probability π k transitional probability aij mean vector μ k and covariance matrix k cross validation is used to select the states k of the hmm after the learning process the conditional probability distribution of predictions is derived by gmr and a point forecast of hmm gmr is obtained based on the mean of the probability distribution we investigated the performance of hmm gmr at monthly streamflow probability forecasting by using monthly flow data from three stations comprising yichang station beibei station and wulong station on the yangtze river in chain the predictand was streamflow at yichang station and the predictors were the antecedent streamflows at the three stations the point forecasts obtained by hmm gmr were verified based on the mse skill score and the accuracy was demonstrated according to comparisons with svm the crps skill score was used to assess the probability forecasting performance and the pit uniform plot demonstrated the reliability of hmm gmr the hmm gmr approach obtained reasonably high skill scores and the uncertainty spread was appropriate several possible extensions may be considered to the model proposed in this study in particular further research is required with respect to the predictor selection procedure hidden seasonal switching model with continuous hidden states dealing with a large number of streamflow sites and applications to major water resource systems acknowledgements this work is supported by the national key r d program of china 2016yfc0402209 the major research plan of the national natural science foundation of china no 91647114 no 91547208 the natural science foundation of hubei province china 2013cfb400 the fundamental research funds for the central universities hust 2016yxzd047 and special thanks are given to the anonymous reviewers and editors for their constructive comments 
7267,reliable streamflow forecasts can be highly valuable for water resources planning and management in this study we combined a hidden markov model hmm and gaussian mixture regression gmr for probabilistic monthly streamflow forecasting the hmm is initialized using a kernelized k medoids clustering method and the baum welch algorithm is then executed to learn the model parameters gmr derives a conditional probability distribution for the predictand given covariate information including the antecedent flow at a local station and two surrounding stations the performance of hmm gmr was verified based on the mean square error and continuous ranked probability score skill scores the reliability of the forecasts was assessed by examining the uniformity of the probability integral transform values the results show that hmm gmr obtained reasonably high skill scores and the uncertainty spread was appropriate different hmm states were assumed to be different climate conditions which would lead to different types of observed values we demonstrated that the hmm gmr approach can handle multimodal and heteroscedastic data keywords gaussian mixture regression hidden markov model kernelized k medoids clustering probabilistic streamflow forecasting 1 introduction streamflow forecasting plays a critical role in water resources planning and management chiew et al 2003 zhao and zhao 2014 reliable and skillful streamflow forecasts can help water resource managers to make better decisions as well as promoting the sustainable development of the local economy the existing approaches for streamflow forecasting are classified into three main categories physical based models conceptual methods and empirical models bourdin et al 2012 devia et al 2015 the early empirical models were usually linear such as autoregressive autoregressive moving average and linear regression castellano méndez et al 2004 haltiner and salas 1988 salas et al 1985 valipour et al 2013 wu et al 2009 however these models have a limited ability to handle the non stationary and non linear relations massively involved in hydrological processes zhang et al 2015 in addition to the conventional linear statistical techniques a wide range of machine learning methods have been developed and used for hydrological forecasting the two most commonly used machine learning methods applied in the hydrologic community are the artificial neural network ann mcculloch and pitts 1943 kohonen 1988 chiang et al 2004 cigizoglu 2005 mutlu et al 2008 and support vector machine svm vapnik 1995 collobert and bengio 2001 dibike et al 2001 wu et al 2009 the reliable quantification of forecast uncertainty is also very important for water resource management svm and ann are both point forecast algorithms and they cannot provide information about the intrinsic level of forecast uncertainty one approach for quantifying this uncertainty involves obtaining estimates of upper and lower bound prediction intervals which indicate the range within which the observed data are likely to occur with some probabilistic level of confidence such as 90 ye et al 2014 ye et al 2016 the bayesian technique is another approach for a direct quantification of prediction uncertainty where it estimates the posterior distribution based on the prior probability and likelihood murphy 2012 for example the bayesian joint probability method has been employed for monthly and seasonal streamflow forecasting wang et al 2009 wang and robertson 2011 zhao et al 2016 where this method assumes that the data are multivariate gaussian and it mainly focuses on learning the parameters of an enhanced box cox transform using monte carlo markov chain sampling however the bayesian joint probability method does not consider the potential climate states in the model different climate states will influence the rainfall runoff process so it is important and meaningful to consider the potential states and their variations during streamflow forecasting hidden markov models hmms also known as markov switching models or dependent mixture models comprise a discrete time discrete state markov chain with hidden states plus an observation model which can describe the potential states in a catchment previously it has been reported that hmm is a robust method for simulating hydrologic time series the hidden states of hydrologic time series are typically described as climate regimes akintug and rasmussen 2005 investigated the properties of hmm for generating annual time series a hmm was also developed to generate runoff scenarios and rainfall data respectively gelati et al 2010 sansom and thomson 2010 a hmm combined with climate indices was proposed for multidecadal streamflow simulation bracken et al 2014 however extensions of hmm are still needed for probabilistic monthly streamflow forecasting gaussian mixture regression gmr is an alternative method to obtain a predictive distribution from a joint distribution for a hmm although it is generally used for mixture models in contrast to other regression methods such as svm and ann gmr does not model the regression directly but instead it models a joint probability density function of the data and then derives the regression function from the joint density model carreau et al 2009 calinon et al 2010 lee et al 2016 this is an advantage for streamflow forecasting since density estimation can handle different sources of missing data non concurrent data and data with many occurrences of zero flows wang et al 2009 zhao et al 2016 compared hmm with an unconditional mixture model calinon et al 2007 it can be interpreted as an extension of a mixture model where the choice of mixture component for each observation is not selected independently but instead it depends on the choice of component for the previous observation in this study we considered a framework that combines hmm and gmr hmm gmr for monthly streamflow forecasting the main outcomes of this study are as follows 1 we used a kernelized k medoids clustering technique as a stable initialization strategy to avoid the model becoming trapped by poor local minima 2 we extended gmr by recursively computing a likelihood through the hmm representation thereby considering the predictors as well as the sequential information probabilistically encapsulated in the hmm 3 we verified the effectiveness of hmm gmr based on yichang station in the upstream region of yangtze river by using a monthly streamflow series where we mainly focused on the forecast reliability and skill the remainder of this paper is organized as follows in section 2 we introduce the model formulation the learning algorithm for hmm and gmr for probabilistic forecasting in section 3 we explain the forecast verification methods in section 4 we present an application of hmm gmr to forecasting streamflows at three hydrological stations in the upstream region of the yangtze river in chain in sections 5 and 6 we discuss our results and give our conclusions respectively 2 methods 2 1 hmm a hmm comprises a discrete time discrete state markov chain with hidden states z t 1 k plus an observation model p x t z t where t stands for the time indices and 1 t t the probability of zt depends on the state of the previous latent variable zt 1 via a conditional distribution p zt zt 1 the latent variables may be represented as k dimensional binary variables with k 1 0 s and a single 1 at position k indicating the state value so this conditional distribution corresponds to a table of numbers which we denote by a and its elements are known as transition probabilities 1 a a 11 a 1 k a k 1 a kk where a ij p z t j z t 1 i and they satisfy 0 a ij 1 with j a ij 1 the transition matrix is illustrated diagrammatically by drawing the states as nodes in a state transition diagram as shown in fig 1 for the case where k 3 in this formulation the observed sequence xt depends on the current hidden state zt thus the conditional distributions of the observed variables are defined as p x t z t k ϕ k where ϕ is a set of parameters that govern the distribution we consider d variables comprising both monthly streamflows to be forecast and their predictors such as climate and catchment indicators 2 x t x 1 x 2 x d in this study the distribution of the observations of each state is represented as a multivariate gaussian 3 p x t z t k ϕ k ℏ n x t μ k k where μ k is the mean vector and k is the covariance matrix and one way of estimating the parameters is the maximum likelihood estimate mle as follows 4 μ 1 t t 1 t x t x 5 σ 1 t t 1 t x t x x t x t 1 t t 1 t x t x t t x x t the joint probability distribution over both the latent and observed variables is then given by 6 p x z θ p z 1 π t 2 t p z t z t 1 a t 1 t p x t z t ϕ where x x 1 x t z z 1 z t and θ π a ϕ denotes the set of parameters of hmm π k is the initial probability of being in state k aij is the transitional probability from state i to state j and ϕ k μ k k where μ k and k represent the center and the covariance matrix of the kth gaussian distribution of the hmm respectively 2 2 learning for the hmm we now explain how to estimate the parameters θ π a ϕ the baum welch algorithm baum et al 1970 which is a variant of the expectation maximization em algorithm is used to learn the parameters in the same manner as the em algorithm we must be careful when we initialize the parameters in order to minimize the chance of being trapped by poor local optima thus the kernelized k medoids clustering technique is applied to the data to avoid being trapped by poor local minima 2 2 1 kernelized k medoids clustering the em algorithm requires an initial estimate to avoid being trapped by poor local minima the most common method employed is k means clustering calinon et al 2007 lee et al 2016 which is a heuristic clustering algorithm with computational simplicity however k means clustering uses the euclidean distance to measure dissimilarity which is not always appropriate for structured objects an alternative approach is to use a kernel function that measures the similarity between objects the kernel method has been used in many clustering and regression techniques such as svm and its reliability has been demonstrated thus we employ the k medoids algorithm with a kernel function the k medoids algorithm is similar to k means but instead of representing each cluster s centroid as the mean of all the data vectors assigned to this cluster k medoids set each centroid as one of the data vectors themselves thus it always deals with integer indexes rather than data objects the algorithm can be kernelized by using the kernel function k x i x i to replace the euclidean distance x i x i 2 and we use the radial basis function rbf kernel 7 d i i ℏ k x i x i exp x i x i 2 2 σ 2 if the two points are the same the kernel function d i i 1 and if the two points are far from each other then the value will be close to 0 clearly the function will have a larger value when the two data points are more similar the first step is to randomly select k centroids m 1 k from 1 n where k is equal to the number of states in the hmm and n is the sample number when updating the centroids each data point is classified according to its nearest centroid where we measure the sum of its distances from all the others in the same cluster we then select that with the largest sum as the new centroid the pseudo code for this process is given in algorithm 1 8 m k argmax i z i k i z i k d i i algorithm 1 kernelized k medoids clustering 1 initialize m 1 k as a random subset of size k from 1 n 2 repeat 3 z i argmax k d i m k for i 1 n 4 m k argmax i zi k i z i k d i i for k 1 k 5 until converged after the clustering we can get k clusters form the data each data point is labeled from 1 k and every cluster k has its mean vector and the covariance matrix so the parameter values θ π a ϕ can be obtained by the initial clusters 2 2 2 baum welch algorithm thereafter we employ the em algorithm to find an efficient framework for maximizing the likelihood function in hmms em is an iterative algorithm that alternates between inferring the hidden states given the parameters e step and then optimizing the parameters given the filled in data m step when applied to hmms this is also known as the baum welch algorithm baum et al 1970 2 2 2 1 e step the e step consists precisely in the computations of γ t k and ξ t i j the expected complete data log likelihood is given as follows 9 q θ θ old k 1 k γ 1 k ln π k t 2 t i 1 k j 1 k ξ t i j ln a ij s um t 1 t k 1 k γ t k ln p x t ϕ k the state occupation probability γ t k is the probability of occupying state k at time t given the sequence of observations 10 γ t k p z t k x θ old p x z t k θ old j 1 k p x z t j θ old the probability of being in state i at time t 1 and being in state j at time t ξ t i j can be expanded as follows 11 ξ t i j p z t 1 i z t j x θ old p z t 1 i z t j x θ old i 1 k j 1 k p z t 1 i z t j x θ old γ t k and ξ t i j can be obtained via backward and forward inductive computations in t which is known as the forward backward algorithm rabiner 1989 2 2 2 2 m step in the m step we re estimate the parameters using the current responsibilities γ t k and ξ t i j where we optimize q with respect to the parameters θ π a ϕ maximization with respect to π and a is achieved readily using appropriate lagrange multipliers with the result 12 π k γ 1 k j 1 k γ 1 j 13 a ij t 2 t ξ t i j k 1 k t 2 t ξ t i k to derive the m step for the μk and σk terms we consider the parts of q that depend on μk and σk which is a weighted version of the standard problem of computing the mles of an multivariate gaussian the new parameter estimates are given as follows 14 μ k t 1 t γ t k x n t 1 t γ t k 15 k t 1 t γ t k x t μ k x t μ k t t 1 t γ t k after computing the new estimates we set θ π a ϕ if the convergence criterion is not satisfied then return to the next e step 2 2 3 forward backward algorithm next we describe an efficient procedure called the forward backward algorithm for evaluating the quantities γ t k and ξ t i j which corresponds to the e step in the baum welch algorithm in the forward backward procedure we consider the forward variable α t k defined as 16 α t k p x 1 x t z t k θ old i 1 k a t 1 i a ik p x t z t k ϕ k i 1 k a t 1 i a ik n x t μ k k the quantity α t k represents the joint probability of observing all of the given data up to time t and occupying state k at time t where the initialization value is a 1 k π k n x 1 μ k k in a similar manner we can consider a backward variable β t k defined as 17 β t k p x t 1 x t z t k θ old i 1 k a ik p x t 1 z t 1 i ϕ i β t 1 i i 1 k a ik n x t 1 μ i i β t 1 i the quantity β t k represents the conditional probability of all future data from time t 1 up to t given the state at time t where the initialization value is β 1 k 1 then eq 10 can be expressed simply in terms of the forward backward variables 18 γ t k α t k β t k p x θ old α t k β t k i 1 k α t i β t i α t k accounts for the partial observation sequence x 1 x 2 xt and state k at time t while β t k accounts for the remainder of the observation sequence x t 1 xt given state k at time t the normalization factor p x θ old i 1 k α t i β t i makes γ t a probability measure such that i 1 k γ t i 1 from the definitions of the forward and backward variables we can write ξ t i j in the following form 19 ξ t i j α t 1 i a ij p x t z t j ϕ j β t j p x θ old α t 1 i a ij n x t μ j j β t j i 1 k j 1 k α t 1 i a ij n x t μ j j β t j we have already defined γ t i as the probability of being in state k at time t given the observation sequence and the mode so we can relate γ t i to ξ t i j by summing over j thereby obtaining γ t i j 1 k ξ t i j after the iteration we can consider the hidden state z t argmax k γ k 2 3 model selection the hmm can describe the data more accurately as the number of states increases but this may also result in overfitting therefore we need to make a tradeoff between optimizing the model s likelihood a measure of how well the model fits the data and minimizing the number of parameters needed to encode the data different approaches have been proposed to solve this problem such as cross validation seni and elder 2010 akaike information criteria akaike 1974 minimum description length rissanen 1978 and bayesian information criteria schwarz 1978 in our method we use leave five years out cross validation to select the number of states for the hmm this cross validation procedure generates a forecast for a particular year by fitting the hmm using all of the available data but by leaving out that year and the following four years as missing data thereby reducing the impact of the catchment memory and not artificially inflating the forecast skill the forecast is obtained by gmr and the performance criterion is evaluated according to the skill using the continuous ranked probability score crps 2 4 gmr for probabilistic forecasting next we explain how to derive the conditional distribution from a hmm the data x t can be separated into two subvectors 20 x t y t z t where y t comprise the predictors 21 y t x t 1 x t 2 x t d 1 and z t comprise the predictands 22 z t x t d 1 1 x t d 1 2 x t d 2 4 1 regression from the jointly gaussian distributions our starting point is the simple joint gaussian density of x y one classical result of the multivariate gaussian density is that when partitioning the joint density into fx y fy x f x both fy x and f x are also multivariate gaussian theorem 1 is a well established result murphy 2012 theorem 1 suppose that x y z is joint gaussian p y z n μ with parameters 23 μ μ y μ z yy yz zy zz the posterior conditional distribution is given as follows 24 p z y ℏ n μ z y z y μ z y μ z zy yy 1 y μ y z y zz zy yy 1 yz theorem 1 indicates that when p y z is a joint gaussian distribution then the conditional density is also gaussian this theorem can be extended to a finite gaussian mixture called gmr sung 2004 we use gmr to derivate the conditional density of the hmm 2 4 2 gmr for hmm hmms are also known as dependent mixture models and they can be interpreted as an extension of a mixture model where the choice of the mixture component for each observation is not selected independently but instead it depends on the choice of component for the previous observation the predictors and predictands in each state of the hmm are defined as 25 μ k μ y k μ z k k yy k yz k zy k zz k for each gaussian state k according to eq 24 the conditional expectation μ z t y t k of zt given yt and the estimated conditional covariance z t y t k of zt given yt are 26 μ z t y t k μ z k zy k yy k 1 y t μ y k 27 z y k zz k zy k yy k 1 yz k for a given time step t the observations are modeled by a mixture of k gaussian distributions k being the number of states of the hmm the conditional probability distribution function of zt yt is 28 f z t y t k 1 k h k y t n z t μ z t y t k z y k in the original gmr framework the influence of the different gaussians is represented by weights hk defined as the probability of an observed input belonging to each of the gaussians we propose to extend gmr to exploit the emission probability in the hmm framework by recursively computing a likelihood through the hmm representation thereby considering the predictors yt as well as the sequential information probabilistically h k y t 1 encapsulated in the hmm 29 h k y t i 1 k h i y t 1 a ik n y t μ y k yy k j 1 k i 1 k h i y t 1 a ij n y t μ y j yy j where h k y t represent the hmm forward variables initialized with h k y 1 π k n y 1 μ y k yy k which correspond to the probability of observing the partial sequence y 1 y 2 yt and being in state k at time t the conditional probability distribution function given in eq 28 is the full forecast probability density of hmm gmr and it can forecast the distribution of the predictands given the predictors the probability forecast skill score and the reliability are based on the conditional probability distribution function however if we want a point result for the forecast then the condition expectational μ z t y t of hmm gmr is derived as 30 μ z t y t k 1 k h k y t μ z t y t k 2 6 outline of hmm gmr an outline of hmm gmr is described in the following and a flow chart illustrating the hmm gmr framework is shown in fig 2 the main code for hmm gmr kernelized k medoids clustering baum welch algorithm and gmr are written used matlab which is very convenient for matrix operations step 1 data collection read the training data and testing data and do data preprocessing set k 1 where k is the number of states of the hmm step 2 model selection step 2 1 cross validation set t 1 where t is time indices 1 initialization use kernelized k medoids clustering to classify the training data into k categories 2 learning for hmm use the baum welch algorithm to maximize the likelihood function 3 if t t turn to step 2 2 else t t 1 return to 1 step 2 2 evaluate the performance criterion if k knum select the k with the best performance and turn to step 3 else k k 1 return to step 2 1 step 3 forecasting the posterior conditional distribution of the streamflows is calculated by gmr 3 forecast verification the quality of forecasts can be investigated based on the bias skill and reliability laio and tamea 2007 murphy 1993 bias can be defined as the correspondence between the mean forecast and observation in this study we evaluated the skill score based on the mean squared error mse and crps for the forecasts in addition we examined a uniform probability plot of the forecast probability integral transform pit value to assess the forecast reliability 3 1 skill score based on mse the mse is defined as the average of the squares of the errors in regression analysis the term mse is sometimes used to refer to the unbiased estimate of the error variance 31 mse 1 t t 1 t x t x obs t 2 where x t is the prediction at time t which we define as the expectation of the probabilistic forecast using eq 30 the skill score based on the mse is defined as follows 32 ss mse mse mse ref 0 mse ref when using observed historical climatology means as the reference forecasts mse ref 1 t t 1 t x x obs t 2 ssmse is equal to the nash sutcliffe efficiency nash and sutcliffe 1970 ssmse is greater than 0 when our forecast is better than the reference forecast but smaller than 0 when the forecast is inferior to the reference forecast 3 2 skill score based on crps the crps is suitable for deterministic ensemble and probabilistic forecasts of continuous variables for verification hersbach 2000 if we suppose that the probability distribution function forecast by hmm gmr is given by p x using eq 28 and that xobs is the observed value then the crps expressing some kind of distance between the probabilistic forecast p and truth xobs is defined as 33 crps f x h x x obs 2 dx where f x is the cumulative distribution function for the forecast 34 f x x p y dy and 35 h x x obs l 0 for x x obs 0 1 for x x obs 0 where h x x obs is the heaviside function for a deterministic single value or point forecast the crps is equal to the absolute error the minimum crps value of zero is achieved only in the case of a perfect single value forecast the skill score based on the crps is defined as 36 ss crps crps crps ref 0 crps ref where the overbar denotes averaging over the forecast cases and crpsref is the crps for a reference forecast usually based on climatology similarly sscrps is greater than 0 when our forecast is better than reference forecast and smaller than 0 when the forecast is poorer than reference forecast 3 3 reliability of the forecast reliability refers to the statistical consistency of forecasts and observations we examined a uniform probability plot of the forecast pit values to assess the forecast reliability a pit value is derived from the cumulative distribution function f x and the observed value xobs as follows 37 pit f x obs x obs p x dx when the forecasts are reliable the pit values follow a uniform distribution between 0 and 1 the uniformity can be checked by pooling together the pit values for all of the forecast cases t 1 2 t and displaying the ranked values in a uniform probability plot fig 3 this pit uniform probability plot can be used to indicate whether the predicted forecast probability distributions are excessively high or low or excessively wide or narrow laio and tamea 2007 4 application 4 1 data to demonstrate the effectiveness of the hmm gmr approach we considered monthly forecasting for the upstream region of the yangtze river the yangtze river has a length of 6380 km and it is the longest river in china and the third longest in the world for thousands of years this river has been used for water irrigation sanitation transportation and industry and thus it plays a vital role in the economic development and conservation of the ecological environmental in china the yangtze river originates from several tributaries in the eastern part of the tibetan plateau and it flows eastward into the east china sea at shanghai the drainage basin lies between 91 e 122 e and 25 n 35 n and it covers a total area of 1808500 km2 we focused on three hydrometric stations in the upper yangtze region the locations of the stations are shown in fig 3 the streamflows from december to march at yichang station were forecast respectively based on the antecedent streamflow at yichang station and two neighboring stations wulong station on wu river and beibei station on jialing river table 1 lists the predictors and predictands employed these data covered a period comprising 55 years of monthly mean streamflow at the three hydrological control stations from 1953 to 2007 4 2 forecast verification results 4 2 1 mse and crps skill scores the skill scores for the streamflow forecast from december to march at yichang station are given in table 2 the mse skill scores ssmse were used for point forecasts and mainly to verify the forecast bias eq 30 obtains a point forecast for hmm gmr and we used this regression function to calculate ssmse the sscrps values obtained via cross validation for hmm with state numbers varying from 1 to 5 are shown in fig 4 according to fig 4 the values of sscrps was high when the number of hmm states was equal to 2 and it became smaller when as k increased thus the number of hmm states k was selected as 2 in addition we employed svm in this study as a competitive model for point forecasts where we used the ls svmlab matlab toolbox for this application for further details see http www esat kuleuven ac be sista lssvmlab two extra parameters are required in order to make an svm where gam is the regularization parameter that determines the trade off between the fitting error minimization and smoothness and sig2 is the bandwidth in the common case of the rbf kernel the regularization parameter gam and kernel parameter sig2 for svm were optimized by cross validation different months had different parameters table 2 shows that both hmm gmr and svm obtained mse skill scores greater than 20 and the skill scores produced with hmm gmr were similar to those using svm therefore the point forecasts obtained by hmm gmr were satisfactory the crps scores sscrps penalize forecast bias as well as penalizing a distribution that is excessively wide or narrow eq 28 gives the conditional forecast distribution for hmm gmr where the crps skill scores measured the accuracy of the hmm gmr monthly forecasts compared with the climatology forecasts the results showed that all of the sscrps were greater than 10 thereby demonstrating that the forecasts had lower average errors than the climatology reference forecasts 4 2 2 monthly forecast reliability after examining the skill of the hmm gmr probabilistic monthly forecasts their reliability was evaluated further the reliability of the monthly forecasts at capturing the observations was examined using pit uniform probability plots as shown in fig 5 the pit values for december and january were generally close to the diagonal line although small departures from the diagonal line were observed in february and march but they were well within the kolmogorov 5 significance bands laio and tamea 2007 this suggests that the pit values were distributed quite uniformly and thus the forecast probability distributions were generally adequate because excessively high or low or excessively wide or narrow distributions were not predicted therefore we consider that the forecast probability distributions were generally unbiased and with appropriate spreads 4 2 3 comparison plots of the forecast and observed value the forecast mean and 0 1 0 9 quantile ranges based on an observed value for individual events are compared chronologically in fig 6 the open squares and vertical lines are the means of the forecasts and the forecast 0 10 0 90 quantile range obtained using hmm gmr the black horizontal line and shading represent the climatology mean and climatology 0 10 0 90 quantile range respectively the red dots denote the observed streamflow this plot clearly illustrates the probabilistic forecast compared with the climatology forecast according to fig 6 there was no obvious trend over time in terms of the relationship between the forecasts and observed values where the predictions were not biased in any particular direction over time fig 7 show the comparison plots according to the forecast mean where it indicates that the forecast mean appeared to be consistent with the observed values there was no obvious trend in the forecast mean in terms of the relationship between the forecasts and the observed values thus the predictions were not biased significantly in any particular direction with respect to forecast means figs 6 and 7 also compare the results obtained using the hmm gmr with the climatology reference forecasts a red point on the blue vertical line or gray shading denotes that the probabilistic forecast or climatology forecast was unbiased according to the results obtained for the four months 42 observed values from the climatology reference forecasts range were larger than those obtained by hmm gmr with only 31 outliers thereby demonstrating that hmm gmr obtained better predictions than climatology forecasting 4 2 4 pit plots figs 8 and 9 show the pit values for individual events where the events are displayed chronologically in fig 8 and according to the forecast mean in fig 9 the pit value is close to 1 if the forecast is excessively large and close to 0 when the forecast is excessively small the forecasts are unbiased when the pit values are clustered around 0 50 but the forecast distributions can be sharper or narrower the ideal forecasts should yield a uniform distribution for the pit values in 0 1 with no obvious trends over time or with respect to the forecast mean figs 9 and 10 show that the pit values had an almost uniform distribution with no obvious trend over time or with respect to the forecast mean 4 2 5 hidden states of the hmm the proposed hmm gmr approach uses a hmm to fit the streamflow data set where there are two hidden states in our hmm fig 10 shows the states of the observed values where the red dots and blue dots represent the two different states of the observed values the horizontal line and shading represent the streamflow mean and the 0 10 0 90 quantile range for points with two different states respectively fig 11 shows that the observed values were clearly divided into two areas and we assumed the two areas states corresponded to potential dry or wet climatic conditions these potential climatic conditions explained the trend in the observed values it should be noted that although the terms wet and dry are commonly used to describe the states of an hmm low flows can be generated in the wet state and vice versa after learning the hmm gmr is employed for streamflow forecasting gmr treats the distribution of the data set as a mixture of gaussian hmm is also a dependent mixture model that can describe multimodal and highly skewed data fig 11 shows the joint distribution of streamflow at yichang station predictand and the antecedent streamflow at beibei station one of the predictors in fig 11 the red dots and blue dots represent the two different states of the observed values the contour is the probability density of the distribution and it can be seen that mixture of gaussian fitted the data set well the final conditional probability distribution was derived based on the joint distribution in gmr 5 discussion our proposed hmm gmr approach can forecast the monthly streamflow given covariate information including the antecedent flow at a local station and two surrounding stations in practice large numbers of candidate predictors are often available for selection these predictors will influence the transition probabilities of the hidden states and the observation probability model therefore a selection procedure is required to choose reasonable predictors to improve the forecast the hmm learns the monthly streamflow distribution across multiple years where the hidden states of the hmm depend on whether the catchment is dry or wet in each year therefore only decades of annual data are available to train the hmm for every month so overfitting will readily occur as k increases however the hmm can be trained using the data set by pooling 12 months of data together where the hidden states are treated as stochastic seasonality but a problem may occur where the number of hidden states may be excessive and selection is difficult in future research we will investigate a new model with continuous hidden states which can avoid the model selection procedure 6 conclusion in this study we proposed the hmm gmr approach for monthly streamflow probability forecasting the framework of hmm gmr comprises two main components learning for hmm and forecasting with gmr the hmm comprises a discrete time discrete state markov chain with hidden states plus an observation model we proposed a kernelized k medoids clustering method to initialize the model when learning the parameters of hmm the baum welch algorithm is employed to optimize the initial probability π k transitional probability aij mean vector μ k and covariance matrix k cross validation is used to select the states k of the hmm after the learning process the conditional probability distribution of predictions is derived by gmr and a point forecast of hmm gmr is obtained based on the mean of the probability distribution we investigated the performance of hmm gmr at monthly streamflow probability forecasting by using monthly flow data from three stations comprising yichang station beibei station and wulong station on the yangtze river in chain the predictand was streamflow at yichang station and the predictors were the antecedent streamflows at the three stations the point forecasts obtained by hmm gmr were verified based on the mse skill score and the accuracy was demonstrated according to comparisons with svm the crps skill score was used to assess the probability forecasting performance and the pit uniform plot demonstrated the reliability of hmm gmr the hmm gmr approach obtained reasonably high skill scores and the uncertainty spread was appropriate several possible extensions may be considered to the model proposed in this study in particular further research is required with respect to the predictor selection procedure hidden seasonal switching model with continuous hidden states dealing with a large number of streamflow sites and applications to major water resource systems acknowledgements this work is supported by the national key r d program of china 2016yfc0402209 the major research plan of the national natural science foundation of china no 91647114 no 91547208 the natural science foundation of hubei province china 2013cfb400 the fundamental research funds for the central universities hust 2016yxzd047 and special thanks are given to the anonymous reviewers and editors for their constructive comments 
7268,in this paper we explored how landscape characteristics such as topography geology soils and land cover influence the way catchments respond to changing climate conditions based on an ensemble of 15 regional climate models bias corrected with a distribution mapping approach present and future streamflow in 14 neighboring and rather similar catchments in northern sweden was simulated with the hbv model we established functional relationships between a range of landscape characteristics and projected changes in streamflow signatures these were then used to analyze hydrological consequences of physical perturbations in a hypothetically ungauged basin in a climate change context our analysis showed a strong connection between the forest cover extent and the sensitivity of different components of a catchment s hydrological regime to changing climate conditions this emphasizes the need to redefine forestry goals and practices in advance of climate change related risks and uncertainties keywords hydrological modeling streamflow signatures climate change forest clear cut ungauged 1 introduction agreement in the science community is wide spread that changing climate conditions in response to increasing atmospheric concentrations of greenhouse gases substantially affect the water cycle milly et al 2005 in the last century streamflow patterns have undergone profound changes as a consequence of shifts in temperature atmospheric water vapor and precipitation ipcc 2014 a continued warming of oceans and atmosphere in combination with shifting precipitation trends within the next decades alexander et al 2006 ipcc 2014 will severely perturb regional hydrology towards the end of the 21st century the available scientific literature on hydrological climate change impacts in different world regions consistently suggests changing amounts of annual river streamflow nijssen et al 2001 shifts in flood peak magnitudes and timing hirabayashi et al 2013 as well as alterations in flow duration curves arora and boer 2001 annual streamflow in snow dominated catchments in mid to higher latitudes is typically projected to increase andréasson et al 2004 bergström et al 2001 graham et al 2007a graham 2004 nijssen et al 2001 while most tropical and mid latitude basins will likely experience a reduction arora and boer 2001 nijssen et al 2001 but these findings are mostly based on individual catchments e g graham et al 2007a or on comparisons of catchments located in different climate zones e g bergström et al 2001 or nijssen et al 2001 the question arises as to whether it is reasonable to draw such generalized conclusions in terms of future hydrological changes for ungauged basins within a larger region based on a selection of representative catchment studies one could argue that nearby catchments within the same climate zone and underlying geology should function in similar ways which means that conclusions can be drawn for nearby ungauged basins with the same climate and geological conditions on the one hand this hypothesis is supported by the fact that spatial proximity has been found to be a good indicator of catchment similarity carey et al 2010 sawicz et al 2011 especially in humid runoff dominated regions patil and stieglitz 2012 on the other hand a recent study by karlsen et al 2016b discovered highly variable hydrological functioning of neighboring and rather similar catchments under current climate conditions the authors reasoned that these variations are controlled by different landscape characteristics such as topography geology soils and land cover in fact it has long been established that principal streamflow generating processes are not only controlled by external climatic conditions but also by physical properties beven 2002 buttle 1998 dunne 1978 trancoso et al 2016 a catchment s physical landscape characteristics result from perpetual adaptive ecological geomorphic and land forming processes sivapalan 2005 these physical attributes heavily influence together with external climate conditions the present day hydrological functioning as well as the variability at multiple temporal and spatial scales wagener et al 2007 such relationships between hydrological behavior and the landscape have been confirmed in many different parts of the world by a number of studies strongly suggesting that surface runoff infiltration water retention and snowmelt dynamics in a catchment are controlled by 1 topographic features such as elevation aspect or slope frisbee et al 2012 kokkonen and jakeman 2002 peña arancibia et al 2010 seyfried and wilcox 1995 williams et al 2009 2 soil characteristics such as soil types profiles or depth correa et al 2016 farmer et al 2003 seyfried and wilcox 1995 tetzlaff et al 2007 williams et al 2009 3 catchment area buttle and eimers 2009 lyon et al 2012 post and jakeman 1999 4 land use and land cover lyon et al 2012 ochoa tocachi et al 2016 schoonover et al 2006 5 vegetation type brown et al 2005 farmer et al 2003 ochoa tocachi et al 2016 seyfried and wilcox 1995 zhang et al 2001 and 6 geology correa et al 2016 seyfried and wilcox 1995 consequently the hydrological behavior of catchments in the same region with the same stationary climate conditions varies due to catchment specific landscape characteristics teutschbein et al 2015 took these findings one step further and used a diagnostic approach to demonstrate that neighboring catchments in the boreal region do not respond uniformly to the same change in climate conditions similar indications for considerably different streamflow responses to a changing climate across subcatchments were also found for other geographical regions such as north america chang and jung 2010 central europe kunstmann et al 2004 or east africa musau et al 2015 this emphasizes the complexity of the interlinkages between changing climate conditions landscape characteristics and hydrological behavior which make it difficult to generalize potential impacts on other catchments within a larger region we claim that landscape characteristics are not only important under stationary climate conditions but also play a fundamental role for the sensitivity of a catchment to changing climate conditions further we hypothesize that it is possible to predict the combined effects of changes in physical catchment and climate conditions on hydrological processes in ungauged basins given that the underlying functional relationships between landscape characteristics and hydrological shifts in a changing climate can be established to explore these theories the following procedure fig 1 was implemented based on a meso scale low land catchment and its associated partly nested subcatchments in the boreal region in northern sweden after collecting all required data step 1 present and future hydrological regimes were simulated with help of a hydrological model step 2 streamflow signatures were calculated for both present and future streamflow simulations to identify signature changes step 3 using a regionalization approach these signature changes were then linked to catchment specific landscape attributes with help of functional relationships step 4 thereafter the identified functional relationships were validated i e tested for their ability to provide information about the change in an hypothetically ungauged nearby catchment with known physical catchment characteristics step 5 finally we created two virtual forest change cases step 6 and made an attempt to predict the combined influence of landuse and climate change in hypothetically ungauged basins such an analysis is critical to understanding how watersheds will hydrologically respond to combined landuse transformations and future climatic perturbations which directly reflects upon our ability to reliably project future streamflow in ungauged basins 2 study site the krycklan catchment is located in the boreal region in northern sweden fig 2 it has been used as an experimental forest for almost an entire century and has served as a basis for water related research since the 1980 s for a detailed description of the krycklan catchment study kcs the reader is referred to laudon et al 2013 the 67 9 km2 krycklan catchment is according to the köppen geiger classification kottek et al 2006 characterized by a subarctic boreal climate with persistent seasonal snow cover and soil frost during winters annual mean temperature was on average 1 78 c while the annual precipitation averaged 640 mm during 1981 2010 the study catchment has 18 partly nested subcatchments of which the 14 gauged ones were used in this study fig 2a till and sediment are the two main types of parent material in the catchment fig 2b with some areas covered by peat at higher elevations the elevation ranges from 127 to 373 m a s l fig 2c krycklan is a typical catchment in the nemo boreal region with 87 forest cover fig 2d consisting of scots pine pinus sylvestris 63 norway spruce picea abies 26 and birch betula pubescens 10 laudon et al 2013 moreover the catchment includes a few wetlands 9 open and arable land 3 as well as lakes 1 3 data 3 1 landscape characteristics landscape characteristics that can potentially influence streamflow variability in a changing climate are summarized in table 1 for the entire krycklan catchment c16 and its nested subcatchments c01 c20 topographic features such as catchment area elevation above sea level slope and aspect were calculated from a gridded 2 m digital elevation model lantmäteriet gävle sweden we also included tangential curvature as a measure of flow divergence convergence conrad et al 2015 elevation above stream eas as an indicator of drainage potential laudon et al 2012 and median subcatchment area msca as a measure for hillslope and drainage network organization mcglynn et al 2003 geological soil characteristics were derived from the quaternary deposits map 1 100 000 geological survey of sweden uppsala sweden and catchment specific land cover characteristics from the property map 1 12 500 lantmäteriet gävle sweden forest attributes such as tree species distributions were obtained through professional interpretation of aerial photographs taken in 2004 and 2007 persson and fransson 2014 while tree biomass was calculated from the 25 m slu forest map 2010 which is based on spot 5 satellite data dept of forest resource management swedish university of agricultural sciences given that five of these characteristics showed only little variation had rather low percentages or were absent in several subcatchments i e slope rock open land agriculture lakes they were excluded from any further analysis in addition both wetland area and peat soils were not included in the subsequent analysis as they both have strong negative correlations with forest cover fig 3 a b and thus contain redundant information similarly spruce and biomass were excluded because they can be explained by the percentage of birch in the catchments fig 3a c consequently the remaining 11 catchment characteristics table 1 properties written in italic were chosen for our analysis because they provide a good representation of the landscape variability in the krycklan catchment without containing superfluous information 3 2 meteorological data as part of a reference monitoring program daily air temperature and precipitation were measured directly in the krycklan catchment following the recommendations from the world meteorological organization wmo from 1981 to present the penman monteith model monteith 1965 was used to estimate potential evapotranspiration within the monitoring program using air temperature humidity net radiation and wind speed that were also measured directly within the catchment this model was adjusted to the site using measurements of actual evapotranspiration that were obtained during 1981 1984 with a weighting lysimeter 1 m3 3 3 streamflow data daily streamflow in the 14 partly nested catchments has been measured since 2008 with help of pressure transducers campbell scientific inc usa capacitance rods trutrack inc new zealand and radar level sensor rls ott germany water levels were observed continuously during the ice free season with the help of heated housings to avoid ice effects during cold winter months continuous measurements throughout the entire year were possible at subcatchments c02 since winter 2011 2012 c04 since winter 2011 2012 c05 since winter 2012 2013 and c07 since 1981 measurement sites were either equipped with v notch weirs flumes or located at road culverts allowing for fixed and well defined cross sections or had well defined natural cross sections e g c14 c15 and c16 rating curves were assessed every year with more intense gauging during peak flow in spring and low flows in summer logger offsets were corrected through manual water height readings at regular intervals for further details we refer to karlsen et al 2016b on average streamflow observations were available for 210 days of the year streams are closed by a more or less permanent ice cover for the remaining days and covered about 80 of the annual flow 3 4 current and future climate data the public database provided by the ensembles eu project van der linden and mitchell 2009 offers 31 transient regional climate model rcm simulations forced by various global climate models gcms for download in this study we used daily temperature and precipitation simulations for a reference control period 1981 2010 and a future scenario period 2061 2090 from 15 regional climate models rcms that had in common that they were run at a resolution of 25 km 25 km had simulations available until year 2100 and assumed the special report on emissions scenarios sres a1b scenario nakicenovic et al 2000 these climate model simulations were corrected for biases i e systematic errors to impede the deterioration of subsequent hydrological modeling results ehret et al 2012 muerth et al 2013 teutschbein and seibert 2010 2012 2013 here we employed distribution scaling boe et al 2007 déqué et al 2007 ines and hansen 2006 to bias correct daily rcm simulated temperature and precipitation on a monthly basis distribution scaling has proven to be a reliable bias correction method for swedish catchments under current and future climate conditions teutschbein and seibert 2012 2013 it matches the theoretical cumulative distribution function cdf of rcm simulated data with the observed cdf for a more detailed mathematical description of the procedure we refer the reader to teutschbein and seibert 2012 4 methods 4 1 hydrological modeling 4 1 1 the hbv model the conceptual rainfall runoff model hbv bergström 1976 which has been used in more than 90 countries and in various versions throughout the years bergström and lindström 2015 was used to simulate daily streamflow in the individual catchments more specifically we employed the hbv light software package seibert and vis 2012 which was driven by daily temperature daily precipitation and long term monthly mean values of potential evaporation pet hbv light is a lumped model composed of different subroutines that determine snow soil moisture evapotranspiration groundwater and channel routing respectively for further detailed information about hbv please refer to papers on its model structure and parameter uncertainty bergström 1976 1992 bergström and lindström 2015 harlin and kung 1992 lindström et al 1997 seibert 1999 4 1 2 calibration and validation the twelve lumped parameters table 2 that regulate hbv s subroutines were calibrated to observed streamflow 2008 2013 separately for each catchment using the same observed temperature precipitation and potential evapotranspiration data from the earlier described reference monitoring program one hundred different optimal parameter sets were obtained through hundredfold calibration with a built in genetic algorithm and powell optimization gap function seibert 2000 to include parameter uncertainty site c07 was the only site with continuous streamflow observations since 1981 which enabled us to perform an actual split sample calibration validation procedure klemeš 1986 by calibrating hbv for the period 2008 2013 and validating the optimized parameter sets for the randomly chosen 10 year period 1991 2000 to evaluate the goodness of fit nash sutcliffe efficiency reff nash and sutcliffe 1970 nash sutcliffe efficiency with logarithmic values leff and volume error ve were weighted 75 20 and 5 respectively and combined to a fuzzy measure x which was computed at daily time steps following the recommendations by seibert et al 1997 for more details on this procedure we refer to teutschbein et al 2015 to further explore the hbv model performance we created a taylor diagram taylor 2001 which graphically summarizes the match of simulated and observed streamflow patterns for all subcatchments in terms of their correlation r their centered root mean square difference rmsd and their standard deviations σobs σsim because the observed streamflow variability is different for each catchment these statistics have to be non dimensionalized before the different catchments can be compared on the same graph taylor 2001 therefore rmsd σobs and σsim have to be normalized indicated by by the standard deviation of the corresponding observations σsim which does not change the correlation coefficient and results in a normalized diagram taylor 2001 1 rmsd rmsd σ obs 2 σ sim σ sim σ obs 3 σ obs σ obs σ obs 1 4 1 3 streamflow simulations after the calibration validation procedure the optimized parameter sets were used to model daily streamflow for a reference climate period 1981 2010 and a future period 2061 2090 using the bias corrected precipitation and temperature series from 15 rcms as input potential evapotranspiration which is also a required input variable to hbv was calculated for each rcm with the hamon equation xu and singh 2001 based on rcm simulated temperature 4 pet c 1 l d 12 2 ρ t 25 4 with ρ t 4 95 100 e c 2 t c 1 0 69 c 2 0 055 where pet is potential evapotranspiration in mm d c1 and c2 are calibrated constants ld is the daily daylight length in hours 25 4 is a factor to convert pet from inch d to mm d ρt is a saturated water vapor density term based on rcm simulated air temperature t constants c1 and c2 were calibrated so that rcm specific pet calculated based on eq 4 matched the available site specific penman monteith potential evapotranspiration see 3 1 meteorological data by combining an ensemble of 100 optimal hbv parameter sets with an ensemble of 15 rcms we covered a more realistic range of uncertainties in climate model structures and in hydrological model parameterization for each 30 yr time period 1981 2010 vs 2061 2090 for which we assumed the ensemble median to fit observations better than individual streamflow simulations teutschbein and seibert 2010 the first year of each 30 yr period was neglected as the warm up period of the hbv light model therefore we obtained 1500 streamflow simulations of 29 years each which provided us with 43 500 annual streamflow series for the reference period and 43 500 for the future period in total 87 000 annual streamflow series for each catchment 4 2 streamflow signature analysis streamflow was evaluated in terms of signatures s that represent dynamic catchment functioning gupta et al 2008 wagener et al 2007 quantify the hydrological responses toth 2013 and are characteristic of a specific catchment yadav et al 2007 initially such signatures had been developed for testing and improving hydrological models yilmaz et al 2008 but have in the past also proven useful for determining how streamflow and aquatic communities relate pool et al 2017 as well as for assessing a model s ability to reliably simulate hydrological systems under conditions different from those used for calibration for instance in a changing climate mendoza et al 2015 stahl et al 2011 the literature provides a wide range of possible streamflow signatures clausen and biggs 2000 ley et al 2011 shamir et al 2005 yadav et al 2007 yilmaz et al 2008 to describe the overall water balance the hydrograph i e seasonal and annual flow variability and flow durations i e frequency and timing of high mid segment and low flows a selection of 26 relevant signatures table 3 was used that could easily be derived from available observed and simulated streamflow and precipitation time series we followed the routine established by teutschbein et al 2015 to automatically analyze the set of 87 000 streamflow series for each of the 14 catchments and calculate the corresponding streamflow signatures this routine defined the spring flood peak as the maximum streamflow value within the first 6 months of the year based on which spring flood peak magnitude sfpmag and timing sfptime were calculated baseflow was then separated with an easy to implement recursive digital filter originally proposed by lyne and hollick 1979 which provides an objective and repeatable baseflow estimate nathan and mcmahon 1990 ladson et al 2013 this one parameter filter merely filters out high frequency signals which lacks any physical basis nathan and mcmahon 1990 ladson et al 2013 chapman 1991 in the present study we followed the standard procedure for the application of the lyne and hollick filter that is provided by ladson et al 2013 the separated baseflow served as a basis for finding the starting and ending points of the spring flood so that spring flood duration sfd and volume sfv could be calculated thereafter a wide variety of additional hydrologically relevant signatures related to streamflow baseflow flow durations and extreme events table 3 was computed for the reference period s1981 2010 and the future s2061 2090 4 3 relationship between landscape characteristics and hydrological change 4 3 1 identification of correlations and functional relationships first we related the projected streamflow signature changes δs in each catchment to the catchment specific landscape characteristics using the non parametric spearman s rank correlation coefficient ρs spearman 1904 spearman rank correlation was chosen over linear pearson product moment correlation pearson 1920 because spearman assumes only monotony without making prior assumptions about the nature of the relationships e g linear or logarithmic the correlation coefficient ρs was calculated for all 286 possible combinations of the 11 landscape characteristics table 1 and the projected relative changes δs in the 26 streamflow signatures table 3 based on the 14 catchment specific observations for all landscape signature pairs which were significantly correlated α 0 05 we used the principle of regionalization functional relationships were established by fitting different two parametric regression functions i e linear exponential power or logarithmic as suggested by seibert 1999 to the entire data set including all 14 catchments 4 3 2 validation of functional relationships using holdout leave one out and bootstrap method for the purpose of testing whether the identified functional relationships between landscape characteristics and projected future streamflow changes δs could potentially be used to obtain information about the change in an ungauged nearby catchment with known physical catchments characteristics an independent data set was needed for validation since such independent data was lacking we made use of the existing 14 observations i e one observation for each catchment as a basis for defining a calibration and a validation data set this was done separately for all landscape signature pairs that were significantly correlated and for which we were able to fit two parametric regression functions described in the previous section to create calibration and validation data sets solely based on the existing observations we applied three different approaches commonly used for accuracy estimation and model selection kohavi 1995 lendasse et al 2003 hold out leave one out and bootstrap with the hold out ho technique the available data set of length n 14 was randomly split into two mutually exclusive subsets roughly one third of the data i e a subset of 5 observations was set apart for validation i e sampled without replacement while the larger subset containing the remaining two thirds i e 9 observations of the data was used for calibration kohavi 1995 this procedure was repeated 1000 times to ensure that a wide range of possible combinations was covered it should be noted that this procedure is similar to the split sample test commonly used for systematic testing of hydrological model simulations klemeš 1986 leave one out loo is a cross validation technique where one observation from the available data set of length n 14 is chosen for validation again without replacement the remaining data n 1 13 are used for calibration lendasse et al 2003 this procedure was repeated n 14 times to make sure that each observation served as a validation set once according to efron 1983 loo gives nearly unbiased error estimates but typically with rather high variability especially if the sample size n is small this procedure is comparable to the traditional case of simulating an ungauged basin based on all available donor catchments which are used for calibration the bootstrap bts method efron 1979 creates a so called bootstrap sample by randomly sampling n instances uniformly with replacement from the original data set of length n kohavi 1995 this new bootstrap sample with the same size n as the original data forms the calibration data set while the original data set serves for validation due to the random sampling procedure with replacement some observations may occur multiple times in the bootstrap sample while others are not included on average however one bootstrap sample has 0 632 n different observations kim 2009 kohavi 1995 this procedure was repeated 1000 times to make it comparable to ho bts was shown to provide error estimates with low variability but tends to be overly optimistic due to overfitting efron 1983 for each of these three approaches four regression functions i e linear exponential power and logarithmic were fitted to the calibration data set of each signature but only the one with the highest coefficient of determination r2 nagelkerke 1991 was chosen for further validation the performance of the chosen regression model for each streamflow signature was then evaluated on the different validation data sets ho loo and boot using 1 the coefficient of determination r2 nagelkerke 1991 2 the index of agreement d willmott et al 1985 and 3 the normalized root mean square error nrmse 4 4 predicting combined forest and climate change impacts in ungauged basins we further utilized some of the identified functional relationships to analyze the extent to which the combined effects of physical catchment alterations and climate change on streamflow can be predicted in ungauged basins most of the catchment characteristics chosen in this study table 1 properties written in italic were assumed stationary as they were related to topography and geology soil which are unlikely to change by the end of this century the remaining characteristics were related to forest properties including forest cover and tree species which are more likely to change in the near future given the role of forest ecosystems in the global carbon cycle houghton et al 2009 and the importance of forestry in sweden slu 2015 and other parts of the world kirilenko and sedjo 2007 it is particularly important to improve our understanding of how changes in forest cover due to a continued intensification of the forest industry helmisaari et al 2014 and in particular extensions of managed forest land rytter et al 2013 might influence hydrological behavior existing case studies in boreal forests suggest that forest clear cuttings reduce interception and transpiration buttle and metcalfe 2000 which leads to earlier snowmelt schelker et al 2013 increasing total runoff bosch and hewlett 1982 sahin and hall 1996 as well as larger peak flows originating from both snowmelt and rainfall events guillemette et al 2005 global warming and changing precipitation patterns are likely to further amplify some of these effects tong et al 2012 even though the precipitation patterns are more difficult to predict kotlarski et al 2014 it requires sufficiently long data series to analyze and better understand these complex processes within the climate forest water nexus since the majority of watersheds of the world however are ungauged sivapalan et al 2003 our understanding of their behavior under stationary climate conditions is inadequate to project changing climate conditions with a sufficient level of confidence this problem is accentuated further when it comes to future projections in ungauged basins that are additionally affected by human activities such as landuse change sivapalan 2003 due to a lack of study catchments with actual forest alterations we created two hypothetical cases of forest disturbance one representing a forest clear cut deforestation and one representing afforestation in an ungauged basin we then tried to estimate and compare 1 the consequences of virtual forest disturbances 2 the influence of climate change and 3 their combined impact on the hydrological behavior of a hypothetically ungauged catchment by utilizing the previously identified and validated functional relationships 4 4 1 case 1 clear cut at site c13 in case 1 site c13 was considered an ungauged basin it had an upstream catchment area of 7 km2 and was covered by 88 forest had no open land and 10 wetlands in a first step regression models cf section 4 3 with forest cover as predictor variable were fitted to all possible streamflow signatures for the reference period s1981 2010 and the projected future changes in streamflow signatures δs based on loo using only n 1 13 donor catchments i e leaving out the hypothetically ungauged basin the calibrated regression equations were then applied to estimate both present day s1981 2010 and future streamflow signatures s2061 2090 in this particular hypothetically ungauged basin based with its original unchanged forest cover of 88 consequently this first step provided an estimate of climate change impacts on streamflow signatures without considering forest disturbance these results were validated by comparing them to the originally simulated signatures at c13 cf section 4 2 thereafter we assumed a virtual clear cut reducing the existing forest cover in c13 from 88 to 83 which equaled an area of 0 35 km2 this particular reduction was chosen to ensure that the results obtained by the regression analysis could be compared to the originally simulated signatures cf section 4 2 of another otherwise similar catchment here we compared the regression results to c12 hereafter referred to as the control catchment which had similar soil and geological features but only 83 forest cover compared to 88 in c13 the regression models calibrated in step 1 with forest cover as independent variable and present day signatures s1981 2010 as response variables were now used to estimate streamflow signatures during the reference period assuming the above mentioned reduced forest cover of 83 thus this second step provided an estimate of the consequences of forest disturbance without considering climate change in the final step the regression models calibrated in step 1 with forest cover as independent variable and the projected future changes in streamflow signatures δs as response variables were used to estimate future streamflow signatures s2061 2090 assuming the above mentioned reduced forest cover of 83 in other words this third step considered the combined effects of both climate change and forest disturbance 4 4 2 case 2 afforestation at site c10 in case 2 site c10 was chosen to be the hypothetically ungauged basin this subcatchment with an area of 3 4 km2 was covered by 74 forest and 26 wetlands we here created a scenario where roughly one third of the catchment s wetlands was hypothetically drained and then used for afforestation leading to an increased forest cover of 84 i e 0 34 km2 more forest we followed the same procedure as in case 1 to calibrate and utilize the regression models for present and future conditions the results from the regression analysis were compared to c09 hereafter referred to as control catchment which had soil and forest composition features rather similar to c10 but had a larger area covered by forest 84 compared to 74 in c10 5 results 5 1 changes in climate conditions our ensemble of rcm simulations covered a broad range of possible future changes fig 4 which consistently projected an increase in annual temperature precipitation and potential evapotranspiration considering only the ensemble median the catchment was projected to be 3 7 c warmer fig 4a receive 0 3 mm d 1 or 17 more precipitation fig 4b and be subject to 0 2 mm d 1 or 15 higher annual potential evapotranspiration fig 4c all three meteorological variables were projected to rise during all seasons but to a different extent fig 4 colder seasons such as autumn and winter will likely experience a stronger warming 3 9 c respective 4 3 c while spring and summer temperatures will increase less strongly by 3 3 c and 3 1 c respectively fig 4a the expected future warming in the catchment will push the spring thaw three weeks earlier and cause a temporal shift in seasons not shown here cf teutschbein et al 2015 which implies that the period with temperatures below 0 c is projected to shorten noticeably our simulations indicate that this also affects the rain to snow ratio while 66 72 of all precipitation are currently rain a considerably larger proportion 76 84 will be rain in the future precipitation projections were somewhat more uncertain as a few individual rcms indicate the possibility of no change or even a decrease in precipitation during spring and autumn fig 4b according to the median precipitation over the catchment will likely increase about 6 in summer 17 in autumn and 26 in winter and spring potential evapotranspiration showed the largest absolute increase in summer when potential evapotranspiration is relatively high and the largest percentage increase in winter when potential evapotranspiration is typically very low 5 2 hydrological modeling 5 2 1 calibration and validation for the period 2008 2013 with available streamflow measurements the hbv model driven with observed temperature and precipitation provided satisfying simulations with generally high values of reff 0 7 0 9 leff 0 6 0 8 and ve values 0 9 1 0 the fuzzy measure x ranged from 0 7 to 0 9 where 1 0 equals a perfect fit for site c07 the fuzzy measure decreased from 0 8 during the calibration period to 0 7 during the independent validation period indicating that the agreement between observed and modeled values was generally weaker during the validation due to the fact that the validation period was characterized by considerably different meteorological conditions from the calibration period 0 7 c lower mean temperature 10 less precipitation the relatively high value of 0 7 for the fuzzy measure suggested that the model is transferable to conditions different from those corresponding to the calibration record klemeš 1986 although it is not able to capture all climate driven dynamics for a more detailed assessment a taylor diagram fig 5 was created to visualize additional evaluation metrics the taylor diagram indicated a good model fit with high correlations between observed and simulated streamflow for all 14 catchments the radial distance from the origin embodies the ratio of standard deviations of the simulated and observed time series a perfect model with the same standard deviation as the observations located on the outer circle with a standard deviation equal to one and a correlation of one would thus fall on point obs for all catchments the correlation between observed and simulated streamflow was within a range of 0 82 and 0 95 the rmsd normalized by the observed standard deviation varied from 0 30 to 0 57 and the normalized standard deviation from 0 84 to 1 01 the taylor diagram also revealed that hbv underestimated the observed streamflow variability in all catchments furthermore hbv performed best for catchment c13 whereas all other catchments were clustered around slightly lower values 5 2 2 streamflow simulations in a changing climate simulations indicated a clear shift of the hydrological regime in all 14 catchments fig 6 the typical annual flow regimes which are currently characterized by a large spring flood peak usually in late april or early may and noticeably lower streamflow during the rest of the year fig 6a will in a future climate feature more steady flow conditions fig 6b as a consequence of increasing winter streamflow in combination with lower and early spring flood peaks fig 6c summer flows will experience only minor changes while the duration of spring floods will be shorter in a future climate fig 6c 5 3 streamflow signature analysis the selected signatures table 3 were computed for 1 hbv simulated streamflow based on observed meteorology 1981 2010 2 hbv simulations driven by the rcm climatology during the reference period 1981 2010 and 3 hbv simulations driven by the rcm climatology during the future period 2061 2090 the study by teutschbein et al 2015 which was based on the same set of catchments and hydrological simulations already compared the signatures for case one based on observations and two based on rcm simulations above they concluded that rcm driven hbv simulations were suitable for climate change impact studies because the majority of rcm simulated signatures featured biases of less than 10 here we focused instead on the comparison of the signatures for case two and three above i e future versus present day regionalized signature responses fig 7 according to our simulations all annual hydrograph features i e annual mean streamflow fmeanann baseflow bmeanann and base flow index bfiann were projected to increase in the future in terms of seasonal changes fmean was projected to rise during autumn and winter but slightly decrease during spring and summer bmean on the other hand featured an increase during all seasons although the increase was only weak in summer the seasonal bfi was projected to escalate considerably in spring and only slightly in summer while the simulations indicated a slight bfi reduction during autumn and winter all signatures related to the spring flood showed reduced values i e an earlier initiation of the flood a lower peak a shorter duration and a smaller volume fig 7 the analysis of signatures related to the flow duration curves indicated reduced high segment flows while median and low segment flows were projected to increase which indicated a changing tilt of the duration curves this was also reflected in a slight reduction of the mid segment slope a reduced cv and a smaller streamflow skewness fig 7 in general most signatures were projected to change in the range of 50 however a few signatures related to low flow conditions such as fmeandjf bmeandjf bmeanmam bfimam and fls will likely experience much stronger changes this can however be explained by the fact that the projected changes were given in percentages which caused a disproportionally large inflation of the apparent deviation at low flows 5 4 relationship between landscape characteristics and hydrological change 5 4 1 identification of correlations and functional relationships the computed spearman rank correlation matrix between landscape characteristics and streamflow signatures fig 8 a highlighted a number of significant correlations at the 5 significance level of the 286 possible relations between the 11 selected landscape characteristics table 1 and 26 streamflow signatures 65 pairs 23 were significantly correlated fig 8a furthermore each landscape characteristic was significantly correlated to at least two changes in streamflow signatures generally landscape characteristics such as forest till birch and area featured the most frequent and strongest correlations while pine aspect and curvature featured the least and weakest correlations the strongest significant correlations were however found between area and low segment flow fls ρs 0 82 forest and summer baseflow index bfijja ρs 0 79 forest and high segment flow fhs ρs 0 79 forest and spring flood magnitude ρs 0 78 as well as forest and annual mean streamflow fmeanann ρs 0 77 two parametric regression functions at the 5 significance level with r2 values ranging from 0 28 to 0 67 see supplemental information table s1 were successfully fitted to 38 out of the 65 significantly correlated pairs which represented roughly 13 of all possible combinations four of these pairs had r2 values of more than 0 6 fig 8b three landscape characteristics i e aspect curvature and pine were not useful explanatory variables in two parametric regression functions additionally we did not succeed to fit two parametric regression functions for predicting eight of the available streamflow signatures i e summer winter mean streamflow annual summer winter mean baseflow autumn baseflow index total spring flood volume and spring flood duration 5 4 2 validation of functional relationships using holdout leave one out and bootstrap method after having identified 38 significant functional relationships between boreal landscape forms and projected changes in streamflow signatures we made an attempt to calibrate the regression functions on a subsample of the available data so called training set and to validate the regression model on another set of data for all three validation approaches employed here i e ho loo bts the averaged performance measures indicated a reasonable fit of the regression models for the validation dataset fig 9 we obtained median values ranging from 0 38 ho to 0 53 bts for the coefficient of determination r2 while the index of agreement was 0 77 for ho 0 80 for loo and 0 81 for bts the nrmse had somewhat higher values for ho i e 0 37 and lower values of 0 30 and 0 34 for loo and bts respectively summarizing all three performance measures the best performance was achieved when validating on a bootstrap sample while the regression models seemed to perform slightly worse when calibrating with help of loo or ho in addition bts showed the lowest variability based on the interquartile ranges 5 5 predicting combined forest and climate change impacts on hydrological behavior of ungauged basins only for four streamflow signatures i e fmeanann sfpmag fhs and rr regression functions with forest cover as predictor were significant at the 5 significance level for both the present day streamflow signatures s1981 2010 and the future percentage change δs the fitted regression models had r2 values between 0 39 and 0 55 as fhs is highly correlated with sfpmag and almost identical results were obtained fhs results are not shown separately 5 5 1 case 1 clear cut at site c13 fig 10 provides an overview of the fitted regression curves under present and future climate conditions and shows the simulated signature alterations for the deforestation case under present conditions site c13 with a forest cover of 88 was characterized by an annual mean streamflow fmeanann of 283 mm per year a springflood peak sfpmag of 8 3 mm per day and a runoff ratio rr of 0 43 fig 10a c blue triangles using a regression model to estimate these three values as if c13 were an ungauged basin resulted in deviations between 9 and 13 from the above original values fig 10a c blue bars both fmeanann and rr were overestimated each by 13 while sfpmag was underestimated by 9 considering only the effect of climate change the regression analysis fig 10a c red bars indicated the same direction of change as the actual values fig 10a c red triangles both fmeanann and rr were projected to increase by 18 respective 2 but were overestimated by the regression function sfpmag was projected to decrease by 16 but was at the same time underestimated by roughly 11 according to the regression functions the virtual forest clear cut would result in a 5 to 6 increase in all three signatures fig 10a c green bars compared to the simulations under present conditions fig 10a c blue bars this was in line with the trend in the actual values of c12 fig 10a c green squares which was used here as control catchment for comparison as it had a natural forest cover of only 83 the same as c13 after the virtual forest clear cut for the combined influence of forest and climate change fig 10a c yellow bars the direction of change was simulated correctly with the regression models i e an increase in fmeanann and rr and a decrease in sfpmag given that both climate change and forest clear cut were projected to elevate fmeanann and rr it is not surprising that their combined impact fig 10a and c yellow bars boosted both signatures even more in contrast sfpmag was projected to decrease as a consequence of climate change fig 10b red bar but increase as a consequence of forest clear cut fig 10b green bar this led to a mutual weakening of these external impacts on spring flood peak magnitude regression models fitted the present day streamflow signatures well fig 10d f with r2 values ranging from 0 41 to 0 54 all three signatures showed a negative relationship with forest cover similarly regression models for the projected relative change fig 10g i showed a good performance with r2 values between 0 45 and 0 50 however the relative change in c13 due to climate change was underestimated for all three signatures fig 10g i red triangle while control site c12 was close to the regression line 5 5 2 case 2 afforestation at site c10 fig 11 summarizes the modeling for the afforestation case site c10 with a forest over of 72 had a mean annual streamflow of 382 mm per year under present day climate conditions it exhibited a sfpmag of 8 3 mm per day same as c13 and a rr of 0 58 fig 11a c blue triangles these three values were simulated rather well with a regression model fig 11a c blue bars which deviated only between 7 fmeanann and rr and 7 sfpmag from the original value in terms of climate change effects c10 showed a similar pattern as c13 in case 1 both fmeanann and rr were projected to increase 16 respective 0 3 while sfpmag was projected to decrease by 20 fig 11a c red bars modeling results for the afforestation case at site c10 fig 11a c green bars showed the opposite signals compared to the clear cut in case 1 fig 10a c green bars the virtual afforestation would result in a 8 to 9 decrease in all three signatures fig 11a c green bars compared to the simulations under present conditions fig 11a c blue bars this was in line with the trend in the actual values of control catchment c09 fig 11a c green squares the regression models showed a very good performance in simulating the combined influence of forest and climate change with deviations of only 1 to 4 fmeanann and rr were projected to increase while sfpmag simulations tended towards a decrease the regression curves matched the present day streamflow signatures well fig 11d f with r2 being in the range of 0 40 to 0 53 similarly regression models for the projected relative change fig 11g i showed also a good performance r2 0 45 0 46 this relative change in c10 due to climate change fig 11g i red triangle was better simulated than the change for c13 in case 1 fig 10g i red triangle in both virtual cases forest alterations and changing climate conditions considerably affected streamflow signatures fig 10 and fig 11 the combined effect of both forest and climate change differed markedly from the individual changes caused solely based on either climate change or forestry impacts overall climate change was the dominant factor driving the changes in fmeanann and sfpmag in both hypothetical forest alteration cases while rr was more effected by forest alterations furthermore a comparison of the regression based simulations with the original projections for the hypothetical ungauged and the control catchments cf section 4 4 revealed that the regression models captured the general signal in the ungauged basins well in all cases the direction of change was simulated correctly with deviations between 11 and 13 in the magnitude of change 6 discussion 6 1 changes in climate conditions projections based on an ensemble of 15 rcm gcm combinations under ghg emission scenario a1b provided by the ensembles project van der linden and mitchell 2009 pointed towards increasing precipitation temperature and potential evapotranspiration for all months of the year until the end of this century though the projections of precipitation are less certain than those for temperature kotlarski et al 2014 the obtained change signals are comparable to changes summarized by both the climatecost project christensen et al 2011 and the fifth assessment report ar5 of the united nations intergovernmental panel on climate change ipcc 2014 the changing climate conditions are expected to have multifold impacts on the environment and will inevitably affect catchment hydrology higher future precipitation will strongly influence the catchment s hydrology through changes in spring floods and aquifer recharge due to increasing temperatures spring thaw is expected to occur about 3 weeks earlier which in turn will have considerable consequences for both snow accumulation soil frost and water storage in the area on top of these direct climate change effects on the water balance changes in precipitation and temperature may also alter the vegetation and local climate feedbacks and thereby indirectly influence streamflow and hydrological partitioning zhang et al 2018 it is worth noting that the here adopted modeling approach is not able to explicitly account for these alterations possibly into ranges outside the historical observations which are used for regionalization and the consequent indirect effects on a catchment s hydrology in addition a longer growing season combined with increasing co2 levels will affect stomatal conductance and transpiration of trees donohue et al 2017 trancoso et al 2017 yang et al 2016 and therefore have the potential to considerably influence the annual water balance gedney et al 2006 hasper et al 2015 trancoso et al 2017 ukkola et al 2015 in our study the projected streamflow changes are conditional on the assumption that the biomass remains constant and that vegetation response will not change considerably the latter assumption is justified by the fact that the exact vegetation responses to increasing co2 levels are still not fully understood mengis et al 2015 which adds an extra layer of uncertainty in hydrological climate change impact studies however we found that biomass is indeed an important variable under our static vegetation response assumption which highlights the importance to better understand vegetation responses to future climate conditions to allow for more reliable projections of combined landuse and climate change effects in addition it should be noted that a rather simple temperature based pet estimate eq 4 was used in our study shaw and riha 2011 highlighted that the successful use of temperature based pet models on historical data is no guarantee for future accuracy under non stationary climate conditions because they do not account for future changes in radiation wild 2009 atmospheric humidity willett et al 2008 and wind speed mcvicar et al 2012 consequently temperature based approaches are overly sensitive to temperature which could result in unrealistic drying and excessive hydrologic sensitivity 6 2 hydrological modeling our analysis of current and future hydrological behavior within the krycklan catchment in northern sweden and its associated subcatchments was based on 43 500 streamflow time series each for the reference period 1981 2010 and for the future period 2061 2090 that were simulated with the hbv light software such a large streamflow ensemble provided a wide variety of possible outcomes but also more robust results because we considered uncertainties in climate model data by employing 15 different rcm gcm projections and uncertainties in hydrological model parameters by using 100 optimal parameter sets it should however be noted that the modeling procedure employed here does not cover the full range of uncertainties for example we did not account for hydrological model structure uncertainty which could potentially influence future streamflow simulations jiang et al 2007 jones et al 2006 mendoza et al 2015 surfleet et al 2012 furthermore error prone observational data used for calibration can also lead to potentially large uncertainties beven and westerberg 2011 beven 2002 this is particularly true for precipitation which is highly spatially variable and for streamflow which is estimated from logger measurements with associated rating curve uncertainties peña arancibia et al 2015 petersen øverleir 2004 tomkins 2014 westerberg et al 2016 and gaps when the streams were covered by ice karlsen et al 2016b nonetheless we were able to demonstrate that the hbv model is suitable to effectively simulate hydrological regimes for each individual catchment when driven with observed climate data teutschbein et al 2015 showed that hbv even performs well when driven with rcm simulated climate data during the reference period 1981 2010 which is essential for drawing meaningful conclusions about potential future streamflow changes our simulations of such future changes in krycklan and its associated subcatchments were comparable to other recent studies over sweden arheimer and lindström 2015 beldring et al 2008 graham et al 2007a 2007b teutschbein et al 2011 teutschbein and seibert 2012 and revealed that future streamflow is subject to substantial alterations as a consequence of changes in external climate conditions 6 3 streamflow signature analysis streamflow signatures were used here to provide a more in depth picture of the relative changes in individual hydrological components of the overall water balance the hydrograph and flow duration curves which may not have been apparent from the response time series alone yilmaz et al 2008 our comparison of regionalized response signatures for present and future climate conditions highlighted a couple of clear hydrological alterations caused by a changing climate the present streamflow regimes with large snowmelt driven spring floods and rather low winter baseflows can be expected to change to regimes with a much earlier onset of spring flood and less extreme flows both high and low arora and boer 2001 argued that such marked hydrological changes typically reflect alterations in a catchment s input storage or release of water the input i e precipitation was projected to increase throughout all seasons which explains the higher annual mean streamflow although even mean baseflow was projected to increase the future bfi was projected to decrease these latter projections however should be interpreted with caution baseflow is usually regulated by groundwater surface water snow and ice related processes beck et al 2013b in our study however baseflow was separated with a simply recursive digital filter which removes high frequency signals without any physical basis nathan and mcmahon 1990 ladson et al 2013 chapman 1991 consequently the projected changes in baseflow and bfi do not allow any conclusions concerning possible shifts in storm driven rapid flows but the decreasing bfi can be seen as an indication for more high frequency rain driven signals in the future streamflow simulations especially during winter as a consequence of an overall increase in precipitation and a shift from snow to rain dominated precipitation arheimer and lindström 2015 this transition in the coming decades will reduce snow accumulation directly affect the storage capacity and disturb the spatiotemporal distribution of catchment water williams et al 2009 in fact changes in the rain to snow ratio will likely result in a more even distribution of streamflow i e release of water over time with less streamflow variability as demonstrated in this work consequently future hydrological behavior in boreal sweden will likely take after today s streamflow regimes of regions much further south with serious consequences for stream connectivity and habitat lake 2003 for stream velocity and sedimentation rates wood and armitage 1997 and for water quality teutschbein et al 2016 our comparison of simulated streamflow signature changes among different catchments revealed clear spatial differences in the magnitude of change although the general direction of change i e increase or decrease of a signature was similar for all catchments this highlights the importance of noting that nearby catchments with seemingly similar landscape forms will not necessarily react in the same way to the same external climate change signal teutschbein et al 2015 6 4 landscape characteristics and hydrological change we were able to identify a large number of significant correlations and functional relationships between landscape forms and projected hydrological change all but two landscape characteristics showed significant functional relationships to one or more streamflow signature changes this strongly suggests that land cover vegetation soil type and topographic characteristics control the magnitude of climate change induced catchment specific streamflow changes by nature the here investigated boreal catchments are dominated by forests and wetlands and have only small fractions of agriculture open land and lakes laudon et al 2013 consequently significant and reliable correlations were found mostly for forest related e g forest cover or biomass and wetland related landscape characteristics e g wetland area or peat soils an earlier study of the krycklan catchment already demonstrated that spring flood peak magnitude and timing in wetland dominated catchments are more sensitive to changing climate conditions than in forested catchments while annual streamflow and summer base flow are less sensitive teutschbein et al 2015 on the contrary in forested catchments with little or no wetlands annual streamflow and summer base flow are more sensitive to changing climate conditions while the effects on spring flood events are less severe this can be explained by shallow groundwater tables and transmissivity feedback mechanisms in northern swedish forests and till soils bishop 1991 which generally cause more flashy hydrologic responses with little storage buffer capacity in drier seasons karlsen et al 2016a these features affect the hydrological sensitivity of forested areas to changing climate conditions implying that these results might only be valid for high latitude catchments in the boreal region in addition we believe that this relationship to landscape characteristics might also be a manifestation of the detected change in rain snow partitioning i e the change in the rain to snow ratio affects different landscape forms differently e g different interception rates and albedo control snow accumulation and melt it should also be noted that summer streamflow may be particularly sensitive to climate change driven forest changes such as shifting tree species composition age classes or leaf area jones 2011 jones et al 2012 and increasing evapotranspiration due to extended growing season huntington et al 2009 however understanding these forest responses to changing climate conditions and their impact on the hydrological cycle remains still a major challenge our analysis continued with an attempt to validate the fitted functional relationships i e regression models on an independent data set by applying three different techniques hold out ho leave one out loo and bootstrap bts kim 2009 demonstrated that bts generally works well for small samples using bts in our study resulted indeed in the best overall performance and lowest variability followed by loo it should however be noted that bts tends to provide biased estimates of the true performance error variance braga neto and dougherty 2004 the resulting values for the coefficient of determination and the index of agreement were promising and suggested that functional relationships between landscape characteristics and projected future streamflow changes could potentially be used to obtain information about the change in an ungauged nearby catchment with known physical catchments characteristics 6 5 predicting combined forest and climate change impacts on hydrological behavior of ungauged basins numerous studies have shown that both climate and land use change have considerable influence on future streamflow shifts bronstert et al 2002 defries and eshleman 2004 mao and cherkauer 2009 oni et al 2015 zhang and schilling 2006 bronstert et al 2002 states that vegetation changes such as forest cutting or afforestation largely affect surface and near surface hydrological processes such as interception litter and root zone storage which are all relevant for evapotranspiration energy balance and storm runoff generation but the potential impacts of deforestation or afforestation on streamflow remain contested ellison et al 2012 although many studies suggest that deforestation causes annual streamflow to increase while afforestation causes a decrease there have been some inconsistent responses beck et al 2013a lacombe et al 2016 indicating that dominant eco hydrological processes and their drivers are highly variable across spatial scales zhang et al 2017 the two virtual forest experiments designed in our study reinforced the importance of forest cover for hydrological behavior the amount of forested area in a catchment seems to play a key role in how sensitive different components of a catchment s hydrological regime are to changing climate conditions this new knowledge is crucial to help forest and water managers understand and predict how forest water quantity and quality is affected across space and over time the national academy of sciences 2008 for example teutschbein et al 2016 highlighted that rising winter streamflow caused by climate change directly increases the annual inorganic nitrogen loads to the baltic sea and accelerates freshwater and marine eutrophication considering now the influence of forest cover on different components of the hydrological regime land cover alterations such as de or afforestation may amplify or attenuate the effects of climate change on nitrogen loads considering these potential challenges and possibilities that come with forest cover alterations there is a need to develop a framework for conservation and management of forests which takes into account the implications of a changing climate milad et al 2013 such a framework could also provide the basis for improving the protection and restoration of stream water quality pinay et al 2015 it should however be noted that the reliability of these kinds of projections depends on the data quality and uncertainties of the gauged catchments as well as on uncertainties in the regionalization approach westerberg et al 2016 by using a regionalization approach changes in hydrological signatures as a consequence of combined landuse and climate change could generally be predicted for ungauged catchments especially when evaluating the overall trend of change i e increase or decrease the magnitude of change however showed some deviations which we believe might have been a consequence of working with too small a number of partly nested gauged basins with incomplete and partly overlapping landscape characteristics more advanced methods such as multi linear regression merz and blöschl 2004 ochoa tocachi et al 2016 or copula based methods samaniego et al 2010 might perform better at predicting the consequences of combined landuse and climate change as such methods are able to account for the interdependence between different landscape characteristics furthermore hbv is a model that does not assimilate land use information directly but conceptually translates this information to its parameters given the limitations of such conceptual lumped models using more complex distributed hydrological models might strengthen the analysis of land use change to better provide policy relevant advice to the forestry sector multi scale modeling approaches van dijk et al 2007 should be considered the lumped approach presented herein may not be sufficient to provide accurate information as to where in a catchment to perform clear cuts or reforestation to additionally maximize the variability range one could make a statistically smart choice of a small number of gauged donor catchments assuming a larger number of gauged catchments is available to choose from beck et al 2016 ideally a larger number of gauged basins covering a wider range of percentages of different land covers should be included kite and kouwen 1992 to feed the regression model calibration with more information and consequently to provide more reliable simulations for the ungauged basin this emphasizes the need for sufficient data from various catchments with a wide variety of boreal landscape forms to increase the information content for calibration and reduce uncertainties in future projections 7 conclusion different landscape characteristics such as topography geology soils and land cover are known to control hydrological behavior of catchments under the same stationary climate conditions their complex interactions and their combined influence on streamflow are however not well understood especially in the context of climate shifts based on the analysis of a meso scale catchment and its associated partly nested subcatchments in northern sweden we demonstrated that landscape characteristics are not only important under stationary climate conditions but also play a fundamental role for the sensitivity of a catchment to changing climate conditions we showed that a regionalization approach can be applied to establish significant functional relationships between different landscape forms and hydrological shifts in a changing climate which in turn can be used to predict the combined effects of changes in physical catchment and climate conditions on hydrological processes in an ungauged basin we believe that this approach is versatile and can also be applied to areas with different climate land use or catchment conditions in other parts of the world simulations of two different virtual cases of forest disturbances highlighted the importance of forest cover for the sensitivity of a catchment s hydrological response to changing climate conditions further research is still necessary to increase our understanding of how other landscape forms contribute to future streamflow changes which is key to quantifying the combined impacts of landuse and climate change on storage and release of water as well as on nutrient cycling although our findings are limited to a relatively small geographic region and remain to be confirmed for other catchments we recommend refining present forestry goals and practices given the risks and uncertainties of a changing climate a framework for conservation and management of forests is needed to promote sustainable forestry that protects forest water quality and ecological flows acknowledgements the uppsala university department of earth sciences program for air water and landscape sciences has funded the lead author this study is part of the krycklan catchment study http www slu se krycklan supported by vr formas forwater mistra future forests skb and the kempe foundation we especially thank those involved in field work the ensembles data used in this work http ensemblesrt3 dmi dk were funded by the eu fp6 integrated project ensembles contract 505539 whose support is gratefully acknowledged a special thank you to the anonymous reviewers and the editorial team for their highly constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 060 appendix a supplementary data supplementary data 1 supplementary data 2 supplementary data 3 
7268,in this paper we explored how landscape characteristics such as topography geology soils and land cover influence the way catchments respond to changing climate conditions based on an ensemble of 15 regional climate models bias corrected with a distribution mapping approach present and future streamflow in 14 neighboring and rather similar catchments in northern sweden was simulated with the hbv model we established functional relationships between a range of landscape characteristics and projected changes in streamflow signatures these were then used to analyze hydrological consequences of physical perturbations in a hypothetically ungauged basin in a climate change context our analysis showed a strong connection between the forest cover extent and the sensitivity of different components of a catchment s hydrological regime to changing climate conditions this emphasizes the need to redefine forestry goals and practices in advance of climate change related risks and uncertainties keywords hydrological modeling streamflow signatures climate change forest clear cut ungauged 1 introduction agreement in the science community is wide spread that changing climate conditions in response to increasing atmospheric concentrations of greenhouse gases substantially affect the water cycle milly et al 2005 in the last century streamflow patterns have undergone profound changes as a consequence of shifts in temperature atmospheric water vapor and precipitation ipcc 2014 a continued warming of oceans and atmosphere in combination with shifting precipitation trends within the next decades alexander et al 2006 ipcc 2014 will severely perturb regional hydrology towards the end of the 21st century the available scientific literature on hydrological climate change impacts in different world regions consistently suggests changing amounts of annual river streamflow nijssen et al 2001 shifts in flood peak magnitudes and timing hirabayashi et al 2013 as well as alterations in flow duration curves arora and boer 2001 annual streamflow in snow dominated catchments in mid to higher latitudes is typically projected to increase andréasson et al 2004 bergström et al 2001 graham et al 2007a graham 2004 nijssen et al 2001 while most tropical and mid latitude basins will likely experience a reduction arora and boer 2001 nijssen et al 2001 but these findings are mostly based on individual catchments e g graham et al 2007a or on comparisons of catchments located in different climate zones e g bergström et al 2001 or nijssen et al 2001 the question arises as to whether it is reasonable to draw such generalized conclusions in terms of future hydrological changes for ungauged basins within a larger region based on a selection of representative catchment studies one could argue that nearby catchments within the same climate zone and underlying geology should function in similar ways which means that conclusions can be drawn for nearby ungauged basins with the same climate and geological conditions on the one hand this hypothesis is supported by the fact that spatial proximity has been found to be a good indicator of catchment similarity carey et al 2010 sawicz et al 2011 especially in humid runoff dominated regions patil and stieglitz 2012 on the other hand a recent study by karlsen et al 2016b discovered highly variable hydrological functioning of neighboring and rather similar catchments under current climate conditions the authors reasoned that these variations are controlled by different landscape characteristics such as topography geology soils and land cover in fact it has long been established that principal streamflow generating processes are not only controlled by external climatic conditions but also by physical properties beven 2002 buttle 1998 dunne 1978 trancoso et al 2016 a catchment s physical landscape characteristics result from perpetual adaptive ecological geomorphic and land forming processes sivapalan 2005 these physical attributes heavily influence together with external climate conditions the present day hydrological functioning as well as the variability at multiple temporal and spatial scales wagener et al 2007 such relationships between hydrological behavior and the landscape have been confirmed in many different parts of the world by a number of studies strongly suggesting that surface runoff infiltration water retention and snowmelt dynamics in a catchment are controlled by 1 topographic features such as elevation aspect or slope frisbee et al 2012 kokkonen and jakeman 2002 peña arancibia et al 2010 seyfried and wilcox 1995 williams et al 2009 2 soil characteristics such as soil types profiles or depth correa et al 2016 farmer et al 2003 seyfried and wilcox 1995 tetzlaff et al 2007 williams et al 2009 3 catchment area buttle and eimers 2009 lyon et al 2012 post and jakeman 1999 4 land use and land cover lyon et al 2012 ochoa tocachi et al 2016 schoonover et al 2006 5 vegetation type brown et al 2005 farmer et al 2003 ochoa tocachi et al 2016 seyfried and wilcox 1995 zhang et al 2001 and 6 geology correa et al 2016 seyfried and wilcox 1995 consequently the hydrological behavior of catchments in the same region with the same stationary climate conditions varies due to catchment specific landscape characteristics teutschbein et al 2015 took these findings one step further and used a diagnostic approach to demonstrate that neighboring catchments in the boreal region do not respond uniformly to the same change in climate conditions similar indications for considerably different streamflow responses to a changing climate across subcatchments were also found for other geographical regions such as north america chang and jung 2010 central europe kunstmann et al 2004 or east africa musau et al 2015 this emphasizes the complexity of the interlinkages between changing climate conditions landscape characteristics and hydrological behavior which make it difficult to generalize potential impacts on other catchments within a larger region we claim that landscape characteristics are not only important under stationary climate conditions but also play a fundamental role for the sensitivity of a catchment to changing climate conditions further we hypothesize that it is possible to predict the combined effects of changes in physical catchment and climate conditions on hydrological processes in ungauged basins given that the underlying functional relationships between landscape characteristics and hydrological shifts in a changing climate can be established to explore these theories the following procedure fig 1 was implemented based on a meso scale low land catchment and its associated partly nested subcatchments in the boreal region in northern sweden after collecting all required data step 1 present and future hydrological regimes were simulated with help of a hydrological model step 2 streamflow signatures were calculated for both present and future streamflow simulations to identify signature changes step 3 using a regionalization approach these signature changes were then linked to catchment specific landscape attributes with help of functional relationships step 4 thereafter the identified functional relationships were validated i e tested for their ability to provide information about the change in an hypothetically ungauged nearby catchment with known physical catchment characteristics step 5 finally we created two virtual forest change cases step 6 and made an attempt to predict the combined influence of landuse and climate change in hypothetically ungauged basins such an analysis is critical to understanding how watersheds will hydrologically respond to combined landuse transformations and future climatic perturbations which directly reflects upon our ability to reliably project future streamflow in ungauged basins 2 study site the krycklan catchment is located in the boreal region in northern sweden fig 2 it has been used as an experimental forest for almost an entire century and has served as a basis for water related research since the 1980 s for a detailed description of the krycklan catchment study kcs the reader is referred to laudon et al 2013 the 67 9 km2 krycklan catchment is according to the köppen geiger classification kottek et al 2006 characterized by a subarctic boreal climate with persistent seasonal snow cover and soil frost during winters annual mean temperature was on average 1 78 c while the annual precipitation averaged 640 mm during 1981 2010 the study catchment has 18 partly nested subcatchments of which the 14 gauged ones were used in this study fig 2a till and sediment are the two main types of parent material in the catchment fig 2b with some areas covered by peat at higher elevations the elevation ranges from 127 to 373 m a s l fig 2c krycklan is a typical catchment in the nemo boreal region with 87 forest cover fig 2d consisting of scots pine pinus sylvestris 63 norway spruce picea abies 26 and birch betula pubescens 10 laudon et al 2013 moreover the catchment includes a few wetlands 9 open and arable land 3 as well as lakes 1 3 data 3 1 landscape characteristics landscape characteristics that can potentially influence streamflow variability in a changing climate are summarized in table 1 for the entire krycklan catchment c16 and its nested subcatchments c01 c20 topographic features such as catchment area elevation above sea level slope and aspect were calculated from a gridded 2 m digital elevation model lantmäteriet gävle sweden we also included tangential curvature as a measure of flow divergence convergence conrad et al 2015 elevation above stream eas as an indicator of drainage potential laudon et al 2012 and median subcatchment area msca as a measure for hillslope and drainage network organization mcglynn et al 2003 geological soil characteristics were derived from the quaternary deposits map 1 100 000 geological survey of sweden uppsala sweden and catchment specific land cover characteristics from the property map 1 12 500 lantmäteriet gävle sweden forest attributes such as tree species distributions were obtained through professional interpretation of aerial photographs taken in 2004 and 2007 persson and fransson 2014 while tree biomass was calculated from the 25 m slu forest map 2010 which is based on spot 5 satellite data dept of forest resource management swedish university of agricultural sciences given that five of these characteristics showed only little variation had rather low percentages or were absent in several subcatchments i e slope rock open land agriculture lakes they were excluded from any further analysis in addition both wetland area and peat soils were not included in the subsequent analysis as they both have strong negative correlations with forest cover fig 3 a b and thus contain redundant information similarly spruce and biomass were excluded because they can be explained by the percentage of birch in the catchments fig 3a c consequently the remaining 11 catchment characteristics table 1 properties written in italic were chosen for our analysis because they provide a good representation of the landscape variability in the krycklan catchment without containing superfluous information 3 2 meteorological data as part of a reference monitoring program daily air temperature and precipitation were measured directly in the krycklan catchment following the recommendations from the world meteorological organization wmo from 1981 to present the penman monteith model monteith 1965 was used to estimate potential evapotranspiration within the monitoring program using air temperature humidity net radiation and wind speed that were also measured directly within the catchment this model was adjusted to the site using measurements of actual evapotranspiration that were obtained during 1981 1984 with a weighting lysimeter 1 m3 3 3 streamflow data daily streamflow in the 14 partly nested catchments has been measured since 2008 with help of pressure transducers campbell scientific inc usa capacitance rods trutrack inc new zealand and radar level sensor rls ott germany water levels were observed continuously during the ice free season with the help of heated housings to avoid ice effects during cold winter months continuous measurements throughout the entire year were possible at subcatchments c02 since winter 2011 2012 c04 since winter 2011 2012 c05 since winter 2012 2013 and c07 since 1981 measurement sites were either equipped with v notch weirs flumes or located at road culverts allowing for fixed and well defined cross sections or had well defined natural cross sections e g c14 c15 and c16 rating curves were assessed every year with more intense gauging during peak flow in spring and low flows in summer logger offsets were corrected through manual water height readings at regular intervals for further details we refer to karlsen et al 2016b on average streamflow observations were available for 210 days of the year streams are closed by a more or less permanent ice cover for the remaining days and covered about 80 of the annual flow 3 4 current and future climate data the public database provided by the ensembles eu project van der linden and mitchell 2009 offers 31 transient regional climate model rcm simulations forced by various global climate models gcms for download in this study we used daily temperature and precipitation simulations for a reference control period 1981 2010 and a future scenario period 2061 2090 from 15 regional climate models rcms that had in common that they were run at a resolution of 25 km 25 km had simulations available until year 2100 and assumed the special report on emissions scenarios sres a1b scenario nakicenovic et al 2000 these climate model simulations were corrected for biases i e systematic errors to impede the deterioration of subsequent hydrological modeling results ehret et al 2012 muerth et al 2013 teutschbein and seibert 2010 2012 2013 here we employed distribution scaling boe et al 2007 déqué et al 2007 ines and hansen 2006 to bias correct daily rcm simulated temperature and precipitation on a monthly basis distribution scaling has proven to be a reliable bias correction method for swedish catchments under current and future climate conditions teutschbein and seibert 2012 2013 it matches the theoretical cumulative distribution function cdf of rcm simulated data with the observed cdf for a more detailed mathematical description of the procedure we refer the reader to teutschbein and seibert 2012 4 methods 4 1 hydrological modeling 4 1 1 the hbv model the conceptual rainfall runoff model hbv bergström 1976 which has been used in more than 90 countries and in various versions throughout the years bergström and lindström 2015 was used to simulate daily streamflow in the individual catchments more specifically we employed the hbv light software package seibert and vis 2012 which was driven by daily temperature daily precipitation and long term monthly mean values of potential evaporation pet hbv light is a lumped model composed of different subroutines that determine snow soil moisture evapotranspiration groundwater and channel routing respectively for further detailed information about hbv please refer to papers on its model structure and parameter uncertainty bergström 1976 1992 bergström and lindström 2015 harlin and kung 1992 lindström et al 1997 seibert 1999 4 1 2 calibration and validation the twelve lumped parameters table 2 that regulate hbv s subroutines were calibrated to observed streamflow 2008 2013 separately for each catchment using the same observed temperature precipitation and potential evapotranspiration data from the earlier described reference monitoring program one hundred different optimal parameter sets were obtained through hundredfold calibration with a built in genetic algorithm and powell optimization gap function seibert 2000 to include parameter uncertainty site c07 was the only site with continuous streamflow observations since 1981 which enabled us to perform an actual split sample calibration validation procedure klemeš 1986 by calibrating hbv for the period 2008 2013 and validating the optimized parameter sets for the randomly chosen 10 year period 1991 2000 to evaluate the goodness of fit nash sutcliffe efficiency reff nash and sutcliffe 1970 nash sutcliffe efficiency with logarithmic values leff and volume error ve were weighted 75 20 and 5 respectively and combined to a fuzzy measure x which was computed at daily time steps following the recommendations by seibert et al 1997 for more details on this procedure we refer to teutschbein et al 2015 to further explore the hbv model performance we created a taylor diagram taylor 2001 which graphically summarizes the match of simulated and observed streamflow patterns for all subcatchments in terms of their correlation r their centered root mean square difference rmsd and their standard deviations σobs σsim because the observed streamflow variability is different for each catchment these statistics have to be non dimensionalized before the different catchments can be compared on the same graph taylor 2001 therefore rmsd σobs and σsim have to be normalized indicated by by the standard deviation of the corresponding observations σsim which does not change the correlation coefficient and results in a normalized diagram taylor 2001 1 rmsd rmsd σ obs 2 σ sim σ sim σ obs 3 σ obs σ obs σ obs 1 4 1 3 streamflow simulations after the calibration validation procedure the optimized parameter sets were used to model daily streamflow for a reference climate period 1981 2010 and a future period 2061 2090 using the bias corrected precipitation and temperature series from 15 rcms as input potential evapotranspiration which is also a required input variable to hbv was calculated for each rcm with the hamon equation xu and singh 2001 based on rcm simulated temperature 4 pet c 1 l d 12 2 ρ t 25 4 with ρ t 4 95 100 e c 2 t c 1 0 69 c 2 0 055 where pet is potential evapotranspiration in mm d c1 and c2 are calibrated constants ld is the daily daylight length in hours 25 4 is a factor to convert pet from inch d to mm d ρt is a saturated water vapor density term based on rcm simulated air temperature t constants c1 and c2 were calibrated so that rcm specific pet calculated based on eq 4 matched the available site specific penman monteith potential evapotranspiration see 3 1 meteorological data by combining an ensemble of 100 optimal hbv parameter sets with an ensemble of 15 rcms we covered a more realistic range of uncertainties in climate model structures and in hydrological model parameterization for each 30 yr time period 1981 2010 vs 2061 2090 for which we assumed the ensemble median to fit observations better than individual streamflow simulations teutschbein and seibert 2010 the first year of each 30 yr period was neglected as the warm up period of the hbv light model therefore we obtained 1500 streamflow simulations of 29 years each which provided us with 43 500 annual streamflow series for the reference period and 43 500 for the future period in total 87 000 annual streamflow series for each catchment 4 2 streamflow signature analysis streamflow was evaluated in terms of signatures s that represent dynamic catchment functioning gupta et al 2008 wagener et al 2007 quantify the hydrological responses toth 2013 and are characteristic of a specific catchment yadav et al 2007 initially such signatures had been developed for testing and improving hydrological models yilmaz et al 2008 but have in the past also proven useful for determining how streamflow and aquatic communities relate pool et al 2017 as well as for assessing a model s ability to reliably simulate hydrological systems under conditions different from those used for calibration for instance in a changing climate mendoza et al 2015 stahl et al 2011 the literature provides a wide range of possible streamflow signatures clausen and biggs 2000 ley et al 2011 shamir et al 2005 yadav et al 2007 yilmaz et al 2008 to describe the overall water balance the hydrograph i e seasonal and annual flow variability and flow durations i e frequency and timing of high mid segment and low flows a selection of 26 relevant signatures table 3 was used that could easily be derived from available observed and simulated streamflow and precipitation time series we followed the routine established by teutschbein et al 2015 to automatically analyze the set of 87 000 streamflow series for each of the 14 catchments and calculate the corresponding streamflow signatures this routine defined the spring flood peak as the maximum streamflow value within the first 6 months of the year based on which spring flood peak magnitude sfpmag and timing sfptime were calculated baseflow was then separated with an easy to implement recursive digital filter originally proposed by lyne and hollick 1979 which provides an objective and repeatable baseflow estimate nathan and mcmahon 1990 ladson et al 2013 this one parameter filter merely filters out high frequency signals which lacks any physical basis nathan and mcmahon 1990 ladson et al 2013 chapman 1991 in the present study we followed the standard procedure for the application of the lyne and hollick filter that is provided by ladson et al 2013 the separated baseflow served as a basis for finding the starting and ending points of the spring flood so that spring flood duration sfd and volume sfv could be calculated thereafter a wide variety of additional hydrologically relevant signatures related to streamflow baseflow flow durations and extreme events table 3 was computed for the reference period s1981 2010 and the future s2061 2090 4 3 relationship between landscape characteristics and hydrological change 4 3 1 identification of correlations and functional relationships first we related the projected streamflow signature changes δs in each catchment to the catchment specific landscape characteristics using the non parametric spearman s rank correlation coefficient ρs spearman 1904 spearman rank correlation was chosen over linear pearson product moment correlation pearson 1920 because spearman assumes only monotony without making prior assumptions about the nature of the relationships e g linear or logarithmic the correlation coefficient ρs was calculated for all 286 possible combinations of the 11 landscape characteristics table 1 and the projected relative changes δs in the 26 streamflow signatures table 3 based on the 14 catchment specific observations for all landscape signature pairs which were significantly correlated α 0 05 we used the principle of regionalization functional relationships were established by fitting different two parametric regression functions i e linear exponential power or logarithmic as suggested by seibert 1999 to the entire data set including all 14 catchments 4 3 2 validation of functional relationships using holdout leave one out and bootstrap method for the purpose of testing whether the identified functional relationships between landscape characteristics and projected future streamflow changes δs could potentially be used to obtain information about the change in an ungauged nearby catchment with known physical catchments characteristics an independent data set was needed for validation since such independent data was lacking we made use of the existing 14 observations i e one observation for each catchment as a basis for defining a calibration and a validation data set this was done separately for all landscape signature pairs that were significantly correlated and for which we were able to fit two parametric regression functions described in the previous section to create calibration and validation data sets solely based on the existing observations we applied three different approaches commonly used for accuracy estimation and model selection kohavi 1995 lendasse et al 2003 hold out leave one out and bootstrap with the hold out ho technique the available data set of length n 14 was randomly split into two mutually exclusive subsets roughly one third of the data i e a subset of 5 observations was set apart for validation i e sampled without replacement while the larger subset containing the remaining two thirds i e 9 observations of the data was used for calibration kohavi 1995 this procedure was repeated 1000 times to ensure that a wide range of possible combinations was covered it should be noted that this procedure is similar to the split sample test commonly used for systematic testing of hydrological model simulations klemeš 1986 leave one out loo is a cross validation technique where one observation from the available data set of length n 14 is chosen for validation again without replacement the remaining data n 1 13 are used for calibration lendasse et al 2003 this procedure was repeated n 14 times to make sure that each observation served as a validation set once according to efron 1983 loo gives nearly unbiased error estimates but typically with rather high variability especially if the sample size n is small this procedure is comparable to the traditional case of simulating an ungauged basin based on all available donor catchments which are used for calibration the bootstrap bts method efron 1979 creates a so called bootstrap sample by randomly sampling n instances uniformly with replacement from the original data set of length n kohavi 1995 this new bootstrap sample with the same size n as the original data forms the calibration data set while the original data set serves for validation due to the random sampling procedure with replacement some observations may occur multiple times in the bootstrap sample while others are not included on average however one bootstrap sample has 0 632 n different observations kim 2009 kohavi 1995 this procedure was repeated 1000 times to make it comparable to ho bts was shown to provide error estimates with low variability but tends to be overly optimistic due to overfitting efron 1983 for each of these three approaches four regression functions i e linear exponential power and logarithmic were fitted to the calibration data set of each signature but only the one with the highest coefficient of determination r2 nagelkerke 1991 was chosen for further validation the performance of the chosen regression model for each streamflow signature was then evaluated on the different validation data sets ho loo and boot using 1 the coefficient of determination r2 nagelkerke 1991 2 the index of agreement d willmott et al 1985 and 3 the normalized root mean square error nrmse 4 4 predicting combined forest and climate change impacts in ungauged basins we further utilized some of the identified functional relationships to analyze the extent to which the combined effects of physical catchment alterations and climate change on streamflow can be predicted in ungauged basins most of the catchment characteristics chosen in this study table 1 properties written in italic were assumed stationary as they were related to topography and geology soil which are unlikely to change by the end of this century the remaining characteristics were related to forest properties including forest cover and tree species which are more likely to change in the near future given the role of forest ecosystems in the global carbon cycle houghton et al 2009 and the importance of forestry in sweden slu 2015 and other parts of the world kirilenko and sedjo 2007 it is particularly important to improve our understanding of how changes in forest cover due to a continued intensification of the forest industry helmisaari et al 2014 and in particular extensions of managed forest land rytter et al 2013 might influence hydrological behavior existing case studies in boreal forests suggest that forest clear cuttings reduce interception and transpiration buttle and metcalfe 2000 which leads to earlier snowmelt schelker et al 2013 increasing total runoff bosch and hewlett 1982 sahin and hall 1996 as well as larger peak flows originating from both snowmelt and rainfall events guillemette et al 2005 global warming and changing precipitation patterns are likely to further amplify some of these effects tong et al 2012 even though the precipitation patterns are more difficult to predict kotlarski et al 2014 it requires sufficiently long data series to analyze and better understand these complex processes within the climate forest water nexus since the majority of watersheds of the world however are ungauged sivapalan et al 2003 our understanding of their behavior under stationary climate conditions is inadequate to project changing climate conditions with a sufficient level of confidence this problem is accentuated further when it comes to future projections in ungauged basins that are additionally affected by human activities such as landuse change sivapalan 2003 due to a lack of study catchments with actual forest alterations we created two hypothetical cases of forest disturbance one representing a forest clear cut deforestation and one representing afforestation in an ungauged basin we then tried to estimate and compare 1 the consequences of virtual forest disturbances 2 the influence of climate change and 3 their combined impact on the hydrological behavior of a hypothetically ungauged catchment by utilizing the previously identified and validated functional relationships 4 4 1 case 1 clear cut at site c13 in case 1 site c13 was considered an ungauged basin it had an upstream catchment area of 7 km2 and was covered by 88 forest had no open land and 10 wetlands in a first step regression models cf section 4 3 with forest cover as predictor variable were fitted to all possible streamflow signatures for the reference period s1981 2010 and the projected future changes in streamflow signatures δs based on loo using only n 1 13 donor catchments i e leaving out the hypothetically ungauged basin the calibrated regression equations were then applied to estimate both present day s1981 2010 and future streamflow signatures s2061 2090 in this particular hypothetically ungauged basin based with its original unchanged forest cover of 88 consequently this first step provided an estimate of climate change impacts on streamflow signatures without considering forest disturbance these results were validated by comparing them to the originally simulated signatures at c13 cf section 4 2 thereafter we assumed a virtual clear cut reducing the existing forest cover in c13 from 88 to 83 which equaled an area of 0 35 km2 this particular reduction was chosen to ensure that the results obtained by the regression analysis could be compared to the originally simulated signatures cf section 4 2 of another otherwise similar catchment here we compared the regression results to c12 hereafter referred to as the control catchment which had similar soil and geological features but only 83 forest cover compared to 88 in c13 the regression models calibrated in step 1 with forest cover as independent variable and present day signatures s1981 2010 as response variables were now used to estimate streamflow signatures during the reference period assuming the above mentioned reduced forest cover of 83 thus this second step provided an estimate of the consequences of forest disturbance without considering climate change in the final step the regression models calibrated in step 1 with forest cover as independent variable and the projected future changes in streamflow signatures δs as response variables were used to estimate future streamflow signatures s2061 2090 assuming the above mentioned reduced forest cover of 83 in other words this third step considered the combined effects of both climate change and forest disturbance 4 4 2 case 2 afforestation at site c10 in case 2 site c10 was chosen to be the hypothetically ungauged basin this subcatchment with an area of 3 4 km2 was covered by 74 forest and 26 wetlands we here created a scenario where roughly one third of the catchment s wetlands was hypothetically drained and then used for afforestation leading to an increased forest cover of 84 i e 0 34 km2 more forest we followed the same procedure as in case 1 to calibrate and utilize the regression models for present and future conditions the results from the regression analysis were compared to c09 hereafter referred to as control catchment which had soil and forest composition features rather similar to c10 but had a larger area covered by forest 84 compared to 74 in c10 5 results 5 1 changes in climate conditions our ensemble of rcm simulations covered a broad range of possible future changes fig 4 which consistently projected an increase in annual temperature precipitation and potential evapotranspiration considering only the ensemble median the catchment was projected to be 3 7 c warmer fig 4a receive 0 3 mm d 1 or 17 more precipitation fig 4b and be subject to 0 2 mm d 1 or 15 higher annual potential evapotranspiration fig 4c all three meteorological variables were projected to rise during all seasons but to a different extent fig 4 colder seasons such as autumn and winter will likely experience a stronger warming 3 9 c respective 4 3 c while spring and summer temperatures will increase less strongly by 3 3 c and 3 1 c respectively fig 4a the expected future warming in the catchment will push the spring thaw three weeks earlier and cause a temporal shift in seasons not shown here cf teutschbein et al 2015 which implies that the period with temperatures below 0 c is projected to shorten noticeably our simulations indicate that this also affects the rain to snow ratio while 66 72 of all precipitation are currently rain a considerably larger proportion 76 84 will be rain in the future precipitation projections were somewhat more uncertain as a few individual rcms indicate the possibility of no change or even a decrease in precipitation during spring and autumn fig 4b according to the median precipitation over the catchment will likely increase about 6 in summer 17 in autumn and 26 in winter and spring potential evapotranspiration showed the largest absolute increase in summer when potential evapotranspiration is relatively high and the largest percentage increase in winter when potential evapotranspiration is typically very low 5 2 hydrological modeling 5 2 1 calibration and validation for the period 2008 2013 with available streamflow measurements the hbv model driven with observed temperature and precipitation provided satisfying simulations with generally high values of reff 0 7 0 9 leff 0 6 0 8 and ve values 0 9 1 0 the fuzzy measure x ranged from 0 7 to 0 9 where 1 0 equals a perfect fit for site c07 the fuzzy measure decreased from 0 8 during the calibration period to 0 7 during the independent validation period indicating that the agreement between observed and modeled values was generally weaker during the validation due to the fact that the validation period was characterized by considerably different meteorological conditions from the calibration period 0 7 c lower mean temperature 10 less precipitation the relatively high value of 0 7 for the fuzzy measure suggested that the model is transferable to conditions different from those corresponding to the calibration record klemeš 1986 although it is not able to capture all climate driven dynamics for a more detailed assessment a taylor diagram fig 5 was created to visualize additional evaluation metrics the taylor diagram indicated a good model fit with high correlations between observed and simulated streamflow for all 14 catchments the radial distance from the origin embodies the ratio of standard deviations of the simulated and observed time series a perfect model with the same standard deviation as the observations located on the outer circle with a standard deviation equal to one and a correlation of one would thus fall on point obs for all catchments the correlation between observed and simulated streamflow was within a range of 0 82 and 0 95 the rmsd normalized by the observed standard deviation varied from 0 30 to 0 57 and the normalized standard deviation from 0 84 to 1 01 the taylor diagram also revealed that hbv underestimated the observed streamflow variability in all catchments furthermore hbv performed best for catchment c13 whereas all other catchments were clustered around slightly lower values 5 2 2 streamflow simulations in a changing climate simulations indicated a clear shift of the hydrological regime in all 14 catchments fig 6 the typical annual flow regimes which are currently characterized by a large spring flood peak usually in late april or early may and noticeably lower streamflow during the rest of the year fig 6a will in a future climate feature more steady flow conditions fig 6b as a consequence of increasing winter streamflow in combination with lower and early spring flood peaks fig 6c summer flows will experience only minor changes while the duration of spring floods will be shorter in a future climate fig 6c 5 3 streamflow signature analysis the selected signatures table 3 were computed for 1 hbv simulated streamflow based on observed meteorology 1981 2010 2 hbv simulations driven by the rcm climatology during the reference period 1981 2010 and 3 hbv simulations driven by the rcm climatology during the future period 2061 2090 the study by teutschbein et al 2015 which was based on the same set of catchments and hydrological simulations already compared the signatures for case one based on observations and two based on rcm simulations above they concluded that rcm driven hbv simulations were suitable for climate change impact studies because the majority of rcm simulated signatures featured biases of less than 10 here we focused instead on the comparison of the signatures for case two and three above i e future versus present day regionalized signature responses fig 7 according to our simulations all annual hydrograph features i e annual mean streamflow fmeanann baseflow bmeanann and base flow index bfiann were projected to increase in the future in terms of seasonal changes fmean was projected to rise during autumn and winter but slightly decrease during spring and summer bmean on the other hand featured an increase during all seasons although the increase was only weak in summer the seasonal bfi was projected to escalate considerably in spring and only slightly in summer while the simulations indicated a slight bfi reduction during autumn and winter all signatures related to the spring flood showed reduced values i e an earlier initiation of the flood a lower peak a shorter duration and a smaller volume fig 7 the analysis of signatures related to the flow duration curves indicated reduced high segment flows while median and low segment flows were projected to increase which indicated a changing tilt of the duration curves this was also reflected in a slight reduction of the mid segment slope a reduced cv and a smaller streamflow skewness fig 7 in general most signatures were projected to change in the range of 50 however a few signatures related to low flow conditions such as fmeandjf bmeandjf bmeanmam bfimam and fls will likely experience much stronger changes this can however be explained by the fact that the projected changes were given in percentages which caused a disproportionally large inflation of the apparent deviation at low flows 5 4 relationship between landscape characteristics and hydrological change 5 4 1 identification of correlations and functional relationships the computed spearman rank correlation matrix between landscape characteristics and streamflow signatures fig 8 a highlighted a number of significant correlations at the 5 significance level of the 286 possible relations between the 11 selected landscape characteristics table 1 and 26 streamflow signatures 65 pairs 23 were significantly correlated fig 8a furthermore each landscape characteristic was significantly correlated to at least two changes in streamflow signatures generally landscape characteristics such as forest till birch and area featured the most frequent and strongest correlations while pine aspect and curvature featured the least and weakest correlations the strongest significant correlations were however found between area and low segment flow fls ρs 0 82 forest and summer baseflow index bfijja ρs 0 79 forest and high segment flow fhs ρs 0 79 forest and spring flood magnitude ρs 0 78 as well as forest and annual mean streamflow fmeanann ρs 0 77 two parametric regression functions at the 5 significance level with r2 values ranging from 0 28 to 0 67 see supplemental information table s1 were successfully fitted to 38 out of the 65 significantly correlated pairs which represented roughly 13 of all possible combinations four of these pairs had r2 values of more than 0 6 fig 8b three landscape characteristics i e aspect curvature and pine were not useful explanatory variables in two parametric regression functions additionally we did not succeed to fit two parametric regression functions for predicting eight of the available streamflow signatures i e summer winter mean streamflow annual summer winter mean baseflow autumn baseflow index total spring flood volume and spring flood duration 5 4 2 validation of functional relationships using holdout leave one out and bootstrap method after having identified 38 significant functional relationships between boreal landscape forms and projected changes in streamflow signatures we made an attempt to calibrate the regression functions on a subsample of the available data so called training set and to validate the regression model on another set of data for all three validation approaches employed here i e ho loo bts the averaged performance measures indicated a reasonable fit of the regression models for the validation dataset fig 9 we obtained median values ranging from 0 38 ho to 0 53 bts for the coefficient of determination r2 while the index of agreement was 0 77 for ho 0 80 for loo and 0 81 for bts the nrmse had somewhat higher values for ho i e 0 37 and lower values of 0 30 and 0 34 for loo and bts respectively summarizing all three performance measures the best performance was achieved when validating on a bootstrap sample while the regression models seemed to perform slightly worse when calibrating with help of loo or ho in addition bts showed the lowest variability based on the interquartile ranges 5 5 predicting combined forest and climate change impacts on hydrological behavior of ungauged basins only for four streamflow signatures i e fmeanann sfpmag fhs and rr regression functions with forest cover as predictor were significant at the 5 significance level for both the present day streamflow signatures s1981 2010 and the future percentage change δs the fitted regression models had r2 values between 0 39 and 0 55 as fhs is highly correlated with sfpmag and almost identical results were obtained fhs results are not shown separately 5 5 1 case 1 clear cut at site c13 fig 10 provides an overview of the fitted regression curves under present and future climate conditions and shows the simulated signature alterations for the deforestation case under present conditions site c13 with a forest cover of 88 was characterized by an annual mean streamflow fmeanann of 283 mm per year a springflood peak sfpmag of 8 3 mm per day and a runoff ratio rr of 0 43 fig 10a c blue triangles using a regression model to estimate these three values as if c13 were an ungauged basin resulted in deviations between 9 and 13 from the above original values fig 10a c blue bars both fmeanann and rr were overestimated each by 13 while sfpmag was underestimated by 9 considering only the effect of climate change the regression analysis fig 10a c red bars indicated the same direction of change as the actual values fig 10a c red triangles both fmeanann and rr were projected to increase by 18 respective 2 but were overestimated by the regression function sfpmag was projected to decrease by 16 but was at the same time underestimated by roughly 11 according to the regression functions the virtual forest clear cut would result in a 5 to 6 increase in all three signatures fig 10a c green bars compared to the simulations under present conditions fig 10a c blue bars this was in line with the trend in the actual values of c12 fig 10a c green squares which was used here as control catchment for comparison as it had a natural forest cover of only 83 the same as c13 after the virtual forest clear cut for the combined influence of forest and climate change fig 10a c yellow bars the direction of change was simulated correctly with the regression models i e an increase in fmeanann and rr and a decrease in sfpmag given that both climate change and forest clear cut were projected to elevate fmeanann and rr it is not surprising that their combined impact fig 10a and c yellow bars boosted both signatures even more in contrast sfpmag was projected to decrease as a consequence of climate change fig 10b red bar but increase as a consequence of forest clear cut fig 10b green bar this led to a mutual weakening of these external impacts on spring flood peak magnitude regression models fitted the present day streamflow signatures well fig 10d f with r2 values ranging from 0 41 to 0 54 all three signatures showed a negative relationship with forest cover similarly regression models for the projected relative change fig 10g i showed a good performance with r2 values between 0 45 and 0 50 however the relative change in c13 due to climate change was underestimated for all three signatures fig 10g i red triangle while control site c12 was close to the regression line 5 5 2 case 2 afforestation at site c10 fig 11 summarizes the modeling for the afforestation case site c10 with a forest over of 72 had a mean annual streamflow of 382 mm per year under present day climate conditions it exhibited a sfpmag of 8 3 mm per day same as c13 and a rr of 0 58 fig 11a c blue triangles these three values were simulated rather well with a regression model fig 11a c blue bars which deviated only between 7 fmeanann and rr and 7 sfpmag from the original value in terms of climate change effects c10 showed a similar pattern as c13 in case 1 both fmeanann and rr were projected to increase 16 respective 0 3 while sfpmag was projected to decrease by 20 fig 11a c red bars modeling results for the afforestation case at site c10 fig 11a c green bars showed the opposite signals compared to the clear cut in case 1 fig 10a c green bars the virtual afforestation would result in a 8 to 9 decrease in all three signatures fig 11a c green bars compared to the simulations under present conditions fig 11a c blue bars this was in line with the trend in the actual values of control catchment c09 fig 11a c green squares the regression models showed a very good performance in simulating the combined influence of forest and climate change with deviations of only 1 to 4 fmeanann and rr were projected to increase while sfpmag simulations tended towards a decrease the regression curves matched the present day streamflow signatures well fig 11d f with r2 being in the range of 0 40 to 0 53 similarly regression models for the projected relative change fig 11g i showed also a good performance r2 0 45 0 46 this relative change in c10 due to climate change fig 11g i red triangle was better simulated than the change for c13 in case 1 fig 10g i red triangle in both virtual cases forest alterations and changing climate conditions considerably affected streamflow signatures fig 10 and fig 11 the combined effect of both forest and climate change differed markedly from the individual changes caused solely based on either climate change or forestry impacts overall climate change was the dominant factor driving the changes in fmeanann and sfpmag in both hypothetical forest alteration cases while rr was more effected by forest alterations furthermore a comparison of the regression based simulations with the original projections for the hypothetical ungauged and the control catchments cf section 4 4 revealed that the regression models captured the general signal in the ungauged basins well in all cases the direction of change was simulated correctly with deviations between 11 and 13 in the magnitude of change 6 discussion 6 1 changes in climate conditions projections based on an ensemble of 15 rcm gcm combinations under ghg emission scenario a1b provided by the ensembles project van der linden and mitchell 2009 pointed towards increasing precipitation temperature and potential evapotranspiration for all months of the year until the end of this century though the projections of precipitation are less certain than those for temperature kotlarski et al 2014 the obtained change signals are comparable to changes summarized by both the climatecost project christensen et al 2011 and the fifth assessment report ar5 of the united nations intergovernmental panel on climate change ipcc 2014 the changing climate conditions are expected to have multifold impacts on the environment and will inevitably affect catchment hydrology higher future precipitation will strongly influence the catchment s hydrology through changes in spring floods and aquifer recharge due to increasing temperatures spring thaw is expected to occur about 3 weeks earlier which in turn will have considerable consequences for both snow accumulation soil frost and water storage in the area on top of these direct climate change effects on the water balance changes in precipitation and temperature may also alter the vegetation and local climate feedbacks and thereby indirectly influence streamflow and hydrological partitioning zhang et al 2018 it is worth noting that the here adopted modeling approach is not able to explicitly account for these alterations possibly into ranges outside the historical observations which are used for regionalization and the consequent indirect effects on a catchment s hydrology in addition a longer growing season combined with increasing co2 levels will affect stomatal conductance and transpiration of trees donohue et al 2017 trancoso et al 2017 yang et al 2016 and therefore have the potential to considerably influence the annual water balance gedney et al 2006 hasper et al 2015 trancoso et al 2017 ukkola et al 2015 in our study the projected streamflow changes are conditional on the assumption that the biomass remains constant and that vegetation response will not change considerably the latter assumption is justified by the fact that the exact vegetation responses to increasing co2 levels are still not fully understood mengis et al 2015 which adds an extra layer of uncertainty in hydrological climate change impact studies however we found that biomass is indeed an important variable under our static vegetation response assumption which highlights the importance to better understand vegetation responses to future climate conditions to allow for more reliable projections of combined landuse and climate change effects in addition it should be noted that a rather simple temperature based pet estimate eq 4 was used in our study shaw and riha 2011 highlighted that the successful use of temperature based pet models on historical data is no guarantee for future accuracy under non stationary climate conditions because they do not account for future changes in radiation wild 2009 atmospheric humidity willett et al 2008 and wind speed mcvicar et al 2012 consequently temperature based approaches are overly sensitive to temperature which could result in unrealistic drying and excessive hydrologic sensitivity 6 2 hydrological modeling our analysis of current and future hydrological behavior within the krycklan catchment in northern sweden and its associated subcatchments was based on 43 500 streamflow time series each for the reference period 1981 2010 and for the future period 2061 2090 that were simulated with the hbv light software such a large streamflow ensemble provided a wide variety of possible outcomes but also more robust results because we considered uncertainties in climate model data by employing 15 different rcm gcm projections and uncertainties in hydrological model parameters by using 100 optimal parameter sets it should however be noted that the modeling procedure employed here does not cover the full range of uncertainties for example we did not account for hydrological model structure uncertainty which could potentially influence future streamflow simulations jiang et al 2007 jones et al 2006 mendoza et al 2015 surfleet et al 2012 furthermore error prone observational data used for calibration can also lead to potentially large uncertainties beven and westerberg 2011 beven 2002 this is particularly true for precipitation which is highly spatially variable and for streamflow which is estimated from logger measurements with associated rating curve uncertainties peña arancibia et al 2015 petersen øverleir 2004 tomkins 2014 westerberg et al 2016 and gaps when the streams were covered by ice karlsen et al 2016b nonetheless we were able to demonstrate that the hbv model is suitable to effectively simulate hydrological regimes for each individual catchment when driven with observed climate data teutschbein et al 2015 showed that hbv even performs well when driven with rcm simulated climate data during the reference period 1981 2010 which is essential for drawing meaningful conclusions about potential future streamflow changes our simulations of such future changes in krycklan and its associated subcatchments were comparable to other recent studies over sweden arheimer and lindström 2015 beldring et al 2008 graham et al 2007a 2007b teutschbein et al 2011 teutschbein and seibert 2012 and revealed that future streamflow is subject to substantial alterations as a consequence of changes in external climate conditions 6 3 streamflow signature analysis streamflow signatures were used here to provide a more in depth picture of the relative changes in individual hydrological components of the overall water balance the hydrograph and flow duration curves which may not have been apparent from the response time series alone yilmaz et al 2008 our comparison of regionalized response signatures for present and future climate conditions highlighted a couple of clear hydrological alterations caused by a changing climate the present streamflow regimes with large snowmelt driven spring floods and rather low winter baseflows can be expected to change to regimes with a much earlier onset of spring flood and less extreme flows both high and low arora and boer 2001 argued that such marked hydrological changes typically reflect alterations in a catchment s input storage or release of water the input i e precipitation was projected to increase throughout all seasons which explains the higher annual mean streamflow although even mean baseflow was projected to increase the future bfi was projected to decrease these latter projections however should be interpreted with caution baseflow is usually regulated by groundwater surface water snow and ice related processes beck et al 2013b in our study however baseflow was separated with a simply recursive digital filter which removes high frequency signals without any physical basis nathan and mcmahon 1990 ladson et al 2013 chapman 1991 consequently the projected changes in baseflow and bfi do not allow any conclusions concerning possible shifts in storm driven rapid flows but the decreasing bfi can be seen as an indication for more high frequency rain driven signals in the future streamflow simulations especially during winter as a consequence of an overall increase in precipitation and a shift from snow to rain dominated precipitation arheimer and lindström 2015 this transition in the coming decades will reduce snow accumulation directly affect the storage capacity and disturb the spatiotemporal distribution of catchment water williams et al 2009 in fact changes in the rain to snow ratio will likely result in a more even distribution of streamflow i e release of water over time with less streamflow variability as demonstrated in this work consequently future hydrological behavior in boreal sweden will likely take after today s streamflow regimes of regions much further south with serious consequences for stream connectivity and habitat lake 2003 for stream velocity and sedimentation rates wood and armitage 1997 and for water quality teutschbein et al 2016 our comparison of simulated streamflow signature changes among different catchments revealed clear spatial differences in the magnitude of change although the general direction of change i e increase or decrease of a signature was similar for all catchments this highlights the importance of noting that nearby catchments with seemingly similar landscape forms will not necessarily react in the same way to the same external climate change signal teutschbein et al 2015 6 4 landscape characteristics and hydrological change we were able to identify a large number of significant correlations and functional relationships between landscape forms and projected hydrological change all but two landscape characteristics showed significant functional relationships to one or more streamflow signature changes this strongly suggests that land cover vegetation soil type and topographic characteristics control the magnitude of climate change induced catchment specific streamflow changes by nature the here investigated boreal catchments are dominated by forests and wetlands and have only small fractions of agriculture open land and lakes laudon et al 2013 consequently significant and reliable correlations were found mostly for forest related e g forest cover or biomass and wetland related landscape characteristics e g wetland area or peat soils an earlier study of the krycklan catchment already demonstrated that spring flood peak magnitude and timing in wetland dominated catchments are more sensitive to changing climate conditions than in forested catchments while annual streamflow and summer base flow are less sensitive teutschbein et al 2015 on the contrary in forested catchments with little or no wetlands annual streamflow and summer base flow are more sensitive to changing climate conditions while the effects on spring flood events are less severe this can be explained by shallow groundwater tables and transmissivity feedback mechanisms in northern swedish forests and till soils bishop 1991 which generally cause more flashy hydrologic responses with little storage buffer capacity in drier seasons karlsen et al 2016a these features affect the hydrological sensitivity of forested areas to changing climate conditions implying that these results might only be valid for high latitude catchments in the boreal region in addition we believe that this relationship to landscape characteristics might also be a manifestation of the detected change in rain snow partitioning i e the change in the rain to snow ratio affects different landscape forms differently e g different interception rates and albedo control snow accumulation and melt it should also be noted that summer streamflow may be particularly sensitive to climate change driven forest changes such as shifting tree species composition age classes or leaf area jones 2011 jones et al 2012 and increasing evapotranspiration due to extended growing season huntington et al 2009 however understanding these forest responses to changing climate conditions and their impact on the hydrological cycle remains still a major challenge our analysis continued with an attempt to validate the fitted functional relationships i e regression models on an independent data set by applying three different techniques hold out ho leave one out loo and bootstrap bts kim 2009 demonstrated that bts generally works well for small samples using bts in our study resulted indeed in the best overall performance and lowest variability followed by loo it should however be noted that bts tends to provide biased estimates of the true performance error variance braga neto and dougherty 2004 the resulting values for the coefficient of determination and the index of agreement were promising and suggested that functional relationships between landscape characteristics and projected future streamflow changes could potentially be used to obtain information about the change in an ungauged nearby catchment with known physical catchments characteristics 6 5 predicting combined forest and climate change impacts on hydrological behavior of ungauged basins numerous studies have shown that both climate and land use change have considerable influence on future streamflow shifts bronstert et al 2002 defries and eshleman 2004 mao and cherkauer 2009 oni et al 2015 zhang and schilling 2006 bronstert et al 2002 states that vegetation changes such as forest cutting or afforestation largely affect surface and near surface hydrological processes such as interception litter and root zone storage which are all relevant for evapotranspiration energy balance and storm runoff generation but the potential impacts of deforestation or afforestation on streamflow remain contested ellison et al 2012 although many studies suggest that deforestation causes annual streamflow to increase while afforestation causes a decrease there have been some inconsistent responses beck et al 2013a lacombe et al 2016 indicating that dominant eco hydrological processes and their drivers are highly variable across spatial scales zhang et al 2017 the two virtual forest experiments designed in our study reinforced the importance of forest cover for hydrological behavior the amount of forested area in a catchment seems to play a key role in how sensitive different components of a catchment s hydrological regime are to changing climate conditions this new knowledge is crucial to help forest and water managers understand and predict how forest water quantity and quality is affected across space and over time the national academy of sciences 2008 for example teutschbein et al 2016 highlighted that rising winter streamflow caused by climate change directly increases the annual inorganic nitrogen loads to the baltic sea and accelerates freshwater and marine eutrophication considering now the influence of forest cover on different components of the hydrological regime land cover alterations such as de or afforestation may amplify or attenuate the effects of climate change on nitrogen loads considering these potential challenges and possibilities that come with forest cover alterations there is a need to develop a framework for conservation and management of forests which takes into account the implications of a changing climate milad et al 2013 such a framework could also provide the basis for improving the protection and restoration of stream water quality pinay et al 2015 it should however be noted that the reliability of these kinds of projections depends on the data quality and uncertainties of the gauged catchments as well as on uncertainties in the regionalization approach westerberg et al 2016 by using a regionalization approach changes in hydrological signatures as a consequence of combined landuse and climate change could generally be predicted for ungauged catchments especially when evaluating the overall trend of change i e increase or decrease the magnitude of change however showed some deviations which we believe might have been a consequence of working with too small a number of partly nested gauged basins with incomplete and partly overlapping landscape characteristics more advanced methods such as multi linear regression merz and blöschl 2004 ochoa tocachi et al 2016 or copula based methods samaniego et al 2010 might perform better at predicting the consequences of combined landuse and climate change as such methods are able to account for the interdependence between different landscape characteristics furthermore hbv is a model that does not assimilate land use information directly but conceptually translates this information to its parameters given the limitations of such conceptual lumped models using more complex distributed hydrological models might strengthen the analysis of land use change to better provide policy relevant advice to the forestry sector multi scale modeling approaches van dijk et al 2007 should be considered the lumped approach presented herein may not be sufficient to provide accurate information as to where in a catchment to perform clear cuts or reforestation to additionally maximize the variability range one could make a statistically smart choice of a small number of gauged donor catchments assuming a larger number of gauged catchments is available to choose from beck et al 2016 ideally a larger number of gauged basins covering a wider range of percentages of different land covers should be included kite and kouwen 1992 to feed the regression model calibration with more information and consequently to provide more reliable simulations for the ungauged basin this emphasizes the need for sufficient data from various catchments with a wide variety of boreal landscape forms to increase the information content for calibration and reduce uncertainties in future projections 7 conclusion different landscape characteristics such as topography geology soils and land cover are known to control hydrological behavior of catchments under the same stationary climate conditions their complex interactions and their combined influence on streamflow are however not well understood especially in the context of climate shifts based on the analysis of a meso scale catchment and its associated partly nested subcatchments in northern sweden we demonstrated that landscape characteristics are not only important under stationary climate conditions but also play a fundamental role for the sensitivity of a catchment to changing climate conditions we showed that a regionalization approach can be applied to establish significant functional relationships between different landscape forms and hydrological shifts in a changing climate which in turn can be used to predict the combined effects of changes in physical catchment and climate conditions on hydrological processes in an ungauged basin we believe that this approach is versatile and can also be applied to areas with different climate land use or catchment conditions in other parts of the world simulations of two different virtual cases of forest disturbances highlighted the importance of forest cover for the sensitivity of a catchment s hydrological response to changing climate conditions further research is still necessary to increase our understanding of how other landscape forms contribute to future streamflow changes which is key to quantifying the combined impacts of landuse and climate change on storage and release of water as well as on nutrient cycling although our findings are limited to a relatively small geographic region and remain to be confirmed for other catchments we recommend refining present forestry goals and practices given the risks and uncertainties of a changing climate a framework for conservation and management of forests is needed to promote sustainable forestry that protects forest water quality and ecological flows acknowledgements the uppsala university department of earth sciences program for air water and landscape sciences has funded the lead author this study is part of the krycklan catchment study http www slu se krycklan supported by vr formas forwater mistra future forests skb and the kempe foundation we especially thank those involved in field work the ensembles data used in this work http ensemblesrt3 dmi dk were funded by the eu fp6 integrated project ensembles contract 505539 whose support is gratefully acknowledged a special thank you to the anonymous reviewers and the editorial team for their highly constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 03 060 appendix a supplementary data supplementary data 1 supplementary data 2 supplementary data 3 
7269,microbial contamination of recreational beaches is often at its worst after heavy rainfall events due to storm floods that carry fecal matter and other pollutants from the watershed similarly overflows of untreated sewage from combined sewerage systems may discharge directly into coastal water or via rivers and streams in order to understand the effect of rainfall events wind directions and tides on the recreational water quality gemss an integrated 3d hydrodynamic model was applied to assess the spreading of escherichia coli e coli at the sandvika beaches located in the oslo fjord the model was also used to theoretically investigate the effect of discharges from septic tanks from boats on the water quality at local beaches the model make use of microbial decay rate as the main input representing the survival of microbial pathogens in the ocean which vary widely depending on the type of pathogen and environmental stress the predicted beach water quality was validated against observed data after a heavy rainfall event using nash sutcliffe coefficient e and the overall result indicated that the model performed quite well and the simulation was in good agreement with the observed e coli concentrations for all beaches the result of this study indicated that 1 the bathing water quality was poor according to the eu bathing water directive up to two days after the heavy rainfall event depending on the location of the beach site 2 the discharge from a boat at 300 meter distance to the beaches slightly increased the e coli levels at the beaches 3 the spreading of microbial pathogens from its source to the different beaches depended on the wind speed and the wind direction keywords escherichia coli faecal contamination water quality modelling gemss model recreational water 1 introduction surface runoff after heavy rainfall potentially transports a large number of faecal matter and microbial pathogens to the coastal ocean and poses public health concerns for beach users ahn et al 2005 noble et al 2003 the sources of microbiological pollution of coastal waters varies from place to place colford jr et al 2007 the major pathways of faecal contamination of coastal environments are sewage discharges including partially treated sewage combined sewer overflows storm water discharges sewage network failures polluted river discharges possible run off from agricultural activities and specific discharges that could come from ships wild birds bathers and sediments clark et al 1989 vikas and dwarakish 2015 several studies have shown that coastal bathing waters located near river estuaries are often highly contaminated after rainfall events due to high discharges from the river billen and garnier 1997 ludwig et al 2009 tilburg et al 2015 an increasing concern about the bathing water quality at coastal beaches has inspired to the application of hydrodynamic models as a tool to understand the processes that affect the spreading of microbial contaminants in the coastal water and to predict the effect of changing conditions davies et al 2009 rodriguez et al 2004 significant variation of the spatial and temporal spreading of microbial contaminants at recreational beaches requires frequent in situ monitoring which is difficult in terms of operation and costly enns et al 2012 kinzelman et al 2006 hydrodynamic modelling has the potential to overcome such problems if the modelling have reasonable spatial and temporal resolution and combined with supplementary information from monitoring at a time interval bruni et al 2015 holt et al 2005 a hydrodynamic model is a comprehensive approach to mimic water dynamic processes generated by a number of different drivers the base of the model concept is the numerical solution for the governing equations of conservation of momentum and mass which is the set of equations that describe the motion of fluids liu et al 2007 coastal hydrodynamic modelling are applied at several localities to understand different ecological problems by using a range of model configurations and forcing ferrarin and umgiesser 2005 fossati and piedra cueva 2013 gao et al 2015 henderson et al 2001 zacharias and gianni 2008 the models utilize a wide range of meteorological data river inflow and tidal signals hydrodynamic modelling including e coli or specific microbial pathogens as a constituent and microbial decay rate as a model parameter is a useful tool to describe the temporal and spatial variability of microbial concentrations even below the detection limits of analytical methods furthermore hydrodynamic modelling is useful to explore the effect of different scenarios and situations in order to support management decisions a number of publications about hydrodynamic water quality modelling have focused on nutrients in relation to eutrophication and sediment transportation kock rasmussen et al 2009 park et al 2005 tkalich et al 2002 tufford and mckellar 1999 some studies include microbial water quality modelling using faecal coliform and e coli as a constituents bougeard et al 2010 sokolova et al 2014 the effects of heavy rainfalls on the microbial water quality at coastal beaches are of particular concern in the oslo fjord where the storm water from urban areas and farmland catchments directly discharge into the fjord moreover overflow from the combined sewer system and pumping stations during and after rainfall event discharge significant amount of untreated sewage water into the fjord this study was designed to characterize the temporal and spatial variations of faecal indicator bacteria e coli after rainfall events at the recreational beaches adjacent to the sandvika urban settlement receiving discharges from river sandvikselva and overflows from the local combined sewer system the gemss hydrodynamic model was set up and applied at the sandvika recreational coastline in order to visualize the impacts of different scenarios and discharges after rainfall events the overall objective of this study was to understanding the influence of different processes rainfall discharge from boats and wind directions on the microbial concentrations at the recreational beaches and to demonstrate the importance of hydrodynamic modelling as a tool to identify the risk of contamination of recreational beaches in order to prioritize mitigation measures 1 1 study area the study area is located in bærum municipality south of sandvika norway a number of bathing areas river and streams inflow and urban settlement along the coastline characterize the study area during the summer time a significant number of bathers who perform different recreational activities like boating swimming and various sports frequently visits the beaches for this study six beach sites were included kadettangen main beach and kadettangen to north which is the largest and most crowded beach during summer are connected to kalvøya island with a bridge the island has bays with sand beaches with swimming facilities these are kalvøya small kalvøya big and kalvøya nudist beach høvikodden beach is a sandy beach on the mainland east of kalvøya nudist beach fig 1 the main source of pollution in the area is river sandvikselva in particular after rainfall events when combined sewer overflows csos discharge into the river in addition two csos discharge directly to the fjord the catchment area of river sandvikselva include boreal forest 83 which is the upper parts of the catchment and the lower parts are dominated with farmland 6 5 and urban settlement 10 5 nizzetto et al 2016 2 gemss hydrodynamic model the complexity of physical processes governing the transport and fate of an introduced constituent such as bacteria in the ocean circulation system suggests the use of advanced hydrodynamic models ji 2017 for this study the gemss model was used to explore the hydrodynamic and related microbial water quality along the sandvika coastlines gemss is an integrated system of 3d hydrodynamic and transport models embedded in a geographic information and environmental data system gis grid generator and editor control file generator 2 d and 3 d post processing viewers and meteorological and flow data processor to support 3 d modelling the model is able to simulate horizontal and vertical distributions of water velocities and temperature salinity water surface elevations and water quality in rivers lakes reservoir estuaries and coastal water bodies at different spatio temporal resolution entrix et al 2001 kolluru et al 2014 the model has been applied in different regions for various water quality problems dargahi and setegn 2011 goetchius and salmun 2002 na and park 2006 wu et al 2001 the gemss model uses gllvht generalized longitudinal lateral vertical hydrodynamic and transport that computes time varying velocities water surface elevations and water quality constituent concentrations in different water bodies erm 2006 the hydrodynamic and transport relationships used in gllvht was developed from the horizontal momentum balance continuity constituent transport and the equation of state edinger and buchak 1980 the details of the model can be found in the technical documentation of gemss erm 2006 and also a detailed description of the model and its application can be found in the per reviewed publications dargahi and cvetkovic 2011 entrix et al 2001 kolluru et al 2014 3 boundary conditions and model application the horizontal and vertical model domains were defined from the shorelines and the bathymetry data the inner oslofjord fig 2 was divided in calculation cells horizontally the cells were of variable size the vertical layers were 1 m thick down to 20 m below surface and thereafter 10 m thick the horizontal resolution was more detailed in the sandvika area that was of special interest in this research in this area the average horizontal grid size was around 100 m 100 m for each cell the results were calculated forward in time with steps of some minutes the input data for the hydrodynamic model calibration and simulation were obtained from the norwegian meteorological institute eklima the norwegian marine data centre bærum municipality and direct observation the data set included flow data river discharge and combined sewer overflow cso forced meteorological data air temperature dew point temperature seawater temperature cloud cover pressure wind speed and wind direction and water quality parameters temperature salinity and e coli table 1 some small streams flow into the sandvika beach but only sandviksilva river that have significant discharge and two small csos discharging directly to the fjord were included in the model as point source inflow e coli concentrations and corresponding water flows monitored in the river and csos were used as an input to the model for the two small csos the registered time of overflow were used as input to the model assuming that 50 of the sewage was discharged in this period the water level difference mainly due to tides at the southern open boundary was about 1 m moreover oslo and bærum municipality were regularly monitored water flow and faecal indicator bacteria in the rivers around oslofjord and the data were utilized for this modelling for this study e coli were monitored in the sandvika beaches during and after the precipitation table 2 and both discharges and e coli concentrations in the sandviksilva river and csos were used as an input for this model 4 model simulation first the model was validated by comparing observed e coli concentration against modelled values afterwards simulation were conducted for three conditions 1 after rainfall event 2 boat discharge scenario 3 wind direction scenarios microbial contamination of the recreational beaches was studied during and after rainfall events during the summer 2014 we used two scenarios to separately assess the impact of boat sewage discharge and wind directions on the recreational beaches water quality the boat discharge scenario was if a single boat with 200 litre toilet tank discharge its sewage at 300 m from the nearest beach assuming e coli concentration is 3 107 mpn 100 ml equivalent to one day production of e coli from four persons al baz et al 2008 the wind direction scenario was developed by adjusting the wind input data set which was carried out by tuning all winds into one direction using the average wind speed for all 5 water quality modelling results 5 1 model validation model calibration in this hydrodynamic modelling is the processes of finding a set of optimal variables to yield the best agreement between the predicted and observed variable of interest the model was calibrated by making minor adjustments to the boundary conditions and by adjusting the chezy friction coefficient comparisons of the observed and computed salinity level was made to evaluate the performance of the calibration processes a good agreement observed between observed and computed values of salinity during the period of calibration this confirms that the model calculates the overall water movements in the fjord in a realistic way tjomsland et al 2014 to ensure that the simulated spatio temporal spreading of e coli at the beach sites was realistic the model results was validated by comparing the simulated e coli concentrations with monitored data for four consecutive days after the rainfall event at all beach sites model validation was based on the statistical comparison of daily observations of e coli and the corresponding model simulation results summarized for all beaches and shown in table 3 the value of nash sutcliffe coefficient which ranges from to one was 0 36 and the relative volume of error was 8 4 which was less than 10 suggesting reasonable close agreement between observed and simulated e coli concentration the error for minimum value was much higher compared with the maximum value 5 2 simulation of the spreading of e coli after the rainfall event the two main sources of faecal contamination of the sandvika beaches that were considered in this work were the river sandvikselva and a csos discharging close to høvikodden beach in addition swan droppings at each beach site were included while other potential minor sources were ignored the simulations showed that the impact of swan faeces was negligible due to the dilution effect to be able to model the local impact of swan faces a much denser grid than 100 100 m is required analysis of water samples showed a significant impact of swan faeces on the local water quality the survival of e coli after it is discharged into coastal water depends on many abiotic and biotic factors like sunlight temperature salinity competitive bacteria viruses predators etc rozen and belkin 2001 stewart et al 2008 to illustrate how the different decay rates may affect the simulated concentration at the beaches e coli was given two different decay coefficients k 0 7 and k 0 1 representing half life time of 1 day and 1 week representing the sensitive and resistance organisms the spreading of e coli from the sources into the beach areas were simulated for the consecutive three days after the rainfall event and the daily average e coli concentration were plotted for each decay rate coefficient as shown in fig 3 according to the simulation results the daily average e coli concentration one day after the rainfall event was much higher than the second and the third days at all beaches and the magnitude difference was highest in the case of kalvøya small beach followed by kalvøya big and kadettangen beaches in addition the impact of the microbial decay rate coefficient on the daily average e coli concentration was substantial if we take kadettangen and kalvøya small beaches as an example the change in half life time from 1 day to 1 week resulted in an increase in daily average e coli concentration by 38 6 95 0 and 146 7 at kadettangen beach and 17 3 44 9 and 61 1 at kalvøya small beach for the first the second and the third days respectively the simulation results of the spreading of e coli at the beach sites in graphics form for the top 1 m depth are shown in fig 4 as we can see from the figure the first three hours after the heavy rainfall event the e coli dispersion was limited only to the surrounding area of river sandvikselva and the river mouth however 24 h after the rainfall event that caused increased discharges of e coli via the river the affected coastal area was increased and then the concentration was gradually reduced until the end of the third day 5 3 the vertical distribution of e coli concentration at the beaches the stratification of the e coli concentration is complicated by its temporal and spatial variations within and among the beaches water column in order to simplify the presentation of the simulation result the vertical distribution of the e coli concentration at a specific time 15 00 the day after the rainfall event at two beaches is shown as an example in fig 5 as shown in the plot the situation was quite different at the two beaches e coli stratification had a two layer structure in the case of høvikodden surface layer 0 3 5 m depth and the bottom layer 3 5 7 5 m depth the bottom layer e coli concentration was increased from 64 mpn 100 ml at 3 5 m to 950 mpn 100 ml at 7 5 m depth while the surface layer varied from 64 mpn 100 ml at 3 5 m to 150 mpn 100 ml at the surface the highest e coli concentration at the bottom layer was caused by the csos discharging to the deep water around the høvikodden in the case of kadettangen beach the depth is relatively shallow and the e coli concentration decreased with depth from 495 mpn 100 ml at the surface to 425 mpn 100 ml at 1 5 m depth 5 4 scenario with discharge from a septic tank from a boat in the inner oslo fjord there are several thousand private boats yachts as the number of boats and beach users increases through time the pressure on the water quality along the coastal beaches increase and need proper protection measures the spreading of e coli from the discharge of boat sewage was simulated in order to investigate its impact on the recreational water quality of the beaches under different situations the distance between the discharging point and the beaches 300 m as the minimum required distance from the mainland according to the regulation of boat sewage discharge in the oslo fjord the simulation result showed that the discharge of 200 liter sewage with 3 107 e coli per 100 ml will most probably affect the nearby beaches by relatively low levels of e coli 20 24 mpn 100 ml fig 6 in this study the realistic simulation of e coli concentration from the boat discharge scenario could severely limited by the constraints on coarse spatial resolution therefore relatively smaller resolution the effect of different volume of discharge from different distance and directions could be investigated in the future study 5 5 scenarios with different wind directions the key factors for the spreading of pollutants in the coastal environments are wind and current and the influence of wind on the spreading of microbial pollutants because of ocean circulation was an important aspect of this hydrodynamics study in this regard the spreading of e coli from its source was investigated using different wind directions scenarios in these simulations the four scenarios were n s e w winds representing wind blowing to north south east and west respectively simulation using the actual observation was denoted by natural simulation in fig 7 a relative magnitude of simulated e coli concentration associated with the scenarios with different wind directions are presented different wind directions was shown to have various impacts on the spreading of e coli in the study area and as we can see from the fig 7 wind blowing to west affected kadettangen beach more than høvikodden and kalvøya nudist beach whereas wind that were blowing to south in the same direction as the pollution source flow was the predominant wind direction that affected all the beaches sites these simulations demonstrated that the effect of wind direction depended on the location of the beaches relative to the main pollution source and in this case the river sandvikselva was the main source of pollution 6 conclusion for beaches exposed to short term pollution during after heavy rainfall events it is useful to know the main factors affecting the water quality to make decisions about whether to warn against swimming or not and eventually for how many days to study this the three dimensional gemss hydrodynamic model was set up for the inner oslofjord and successfully applied to simulate the spatial and temporal spreading of e coli after a heavy rainfall event in the sandvika area the model was used to demonstrate the impact of different wind directions on the spreading of e coli as well as for investigating the effect of a discharge from a septic tank on a boat the results of the simulations lead to the following conclusions 1 the risk of microbial contamination was high after one day of heavy rainfall as compared with the second and third days and the level of risk was highest at kalvøya small beach due to the position of the beach which is located close to the river inlet 2 the risk of microbial contamination of the local beaches from a boat emptying the septic tank at 300 m distance from the beaches could substantial although minor increase in e coli was resulted in the simulation however the simulation could severely limited by the constraints on coarse spatial resolution therefore relatively smaller resolution the effect of different volume of discharge from different distance and directions recommended in the future study 3 the spreading of microbial contaminants from its source highly depended on wind speed and direction and the degree of pollution depends on the location of the beach relative to the source of pollution 4 hydrodynamic modelling offers a useful tool to understand the spatial temporal spreading of microbial pathogens at recreational beaches in order to prioritize mitigation measures for the beach management strategies acknowledgments the study was financially supported by regionale forskningsfond hovedstaden norway through the waterqualitytools project 217576 97227 and by niva s strategic institute initiative climate effects from mountains to fjords contract no 208279 the authors gratefully acknowledge lisbeth sloth and helle frodahl bærum municipality for providing information about sewage overflows and discharges vegard nilsen and melesse eshetu norwegian university of life sciences norway for their useful discussions and input during data analysis 
7269,microbial contamination of recreational beaches is often at its worst after heavy rainfall events due to storm floods that carry fecal matter and other pollutants from the watershed similarly overflows of untreated sewage from combined sewerage systems may discharge directly into coastal water or via rivers and streams in order to understand the effect of rainfall events wind directions and tides on the recreational water quality gemss an integrated 3d hydrodynamic model was applied to assess the spreading of escherichia coli e coli at the sandvika beaches located in the oslo fjord the model was also used to theoretically investigate the effect of discharges from septic tanks from boats on the water quality at local beaches the model make use of microbial decay rate as the main input representing the survival of microbial pathogens in the ocean which vary widely depending on the type of pathogen and environmental stress the predicted beach water quality was validated against observed data after a heavy rainfall event using nash sutcliffe coefficient e and the overall result indicated that the model performed quite well and the simulation was in good agreement with the observed e coli concentrations for all beaches the result of this study indicated that 1 the bathing water quality was poor according to the eu bathing water directive up to two days after the heavy rainfall event depending on the location of the beach site 2 the discharge from a boat at 300 meter distance to the beaches slightly increased the e coli levels at the beaches 3 the spreading of microbial pathogens from its source to the different beaches depended on the wind speed and the wind direction keywords escherichia coli faecal contamination water quality modelling gemss model recreational water 1 introduction surface runoff after heavy rainfall potentially transports a large number of faecal matter and microbial pathogens to the coastal ocean and poses public health concerns for beach users ahn et al 2005 noble et al 2003 the sources of microbiological pollution of coastal waters varies from place to place colford jr et al 2007 the major pathways of faecal contamination of coastal environments are sewage discharges including partially treated sewage combined sewer overflows storm water discharges sewage network failures polluted river discharges possible run off from agricultural activities and specific discharges that could come from ships wild birds bathers and sediments clark et al 1989 vikas and dwarakish 2015 several studies have shown that coastal bathing waters located near river estuaries are often highly contaminated after rainfall events due to high discharges from the river billen and garnier 1997 ludwig et al 2009 tilburg et al 2015 an increasing concern about the bathing water quality at coastal beaches has inspired to the application of hydrodynamic models as a tool to understand the processes that affect the spreading of microbial contaminants in the coastal water and to predict the effect of changing conditions davies et al 2009 rodriguez et al 2004 significant variation of the spatial and temporal spreading of microbial contaminants at recreational beaches requires frequent in situ monitoring which is difficult in terms of operation and costly enns et al 2012 kinzelman et al 2006 hydrodynamic modelling has the potential to overcome such problems if the modelling have reasonable spatial and temporal resolution and combined with supplementary information from monitoring at a time interval bruni et al 2015 holt et al 2005 a hydrodynamic model is a comprehensive approach to mimic water dynamic processes generated by a number of different drivers the base of the model concept is the numerical solution for the governing equations of conservation of momentum and mass which is the set of equations that describe the motion of fluids liu et al 2007 coastal hydrodynamic modelling are applied at several localities to understand different ecological problems by using a range of model configurations and forcing ferrarin and umgiesser 2005 fossati and piedra cueva 2013 gao et al 2015 henderson et al 2001 zacharias and gianni 2008 the models utilize a wide range of meteorological data river inflow and tidal signals hydrodynamic modelling including e coli or specific microbial pathogens as a constituent and microbial decay rate as a model parameter is a useful tool to describe the temporal and spatial variability of microbial concentrations even below the detection limits of analytical methods furthermore hydrodynamic modelling is useful to explore the effect of different scenarios and situations in order to support management decisions a number of publications about hydrodynamic water quality modelling have focused on nutrients in relation to eutrophication and sediment transportation kock rasmussen et al 2009 park et al 2005 tkalich et al 2002 tufford and mckellar 1999 some studies include microbial water quality modelling using faecal coliform and e coli as a constituents bougeard et al 2010 sokolova et al 2014 the effects of heavy rainfalls on the microbial water quality at coastal beaches are of particular concern in the oslo fjord where the storm water from urban areas and farmland catchments directly discharge into the fjord moreover overflow from the combined sewer system and pumping stations during and after rainfall event discharge significant amount of untreated sewage water into the fjord this study was designed to characterize the temporal and spatial variations of faecal indicator bacteria e coli after rainfall events at the recreational beaches adjacent to the sandvika urban settlement receiving discharges from river sandvikselva and overflows from the local combined sewer system the gemss hydrodynamic model was set up and applied at the sandvika recreational coastline in order to visualize the impacts of different scenarios and discharges after rainfall events the overall objective of this study was to understanding the influence of different processes rainfall discharge from boats and wind directions on the microbial concentrations at the recreational beaches and to demonstrate the importance of hydrodynamic modelling as a tool to identify the risk of contamination of recreational beaches in order to prioritize mitigation measures 1 1 study area the study area is located in bærum municipality south of sandvika norway a number of bathing areas river and streams inflow and urban settlement along the coastline characterize the study area during the summer time a significant number of bathers who perform different recreational activities like boating swimming and various sports frequently visits the beaches for this study six beach sites were included kadettangen main beach and kadettangen to north which is the largest and most crowded beach during summer are connected to kalvøya island with a bridge the island has bays with sand beaches with swimming facilities these are kalvøya small kalvøya big and kalvøya nudist beach høvikodden beach is a sandy beach on the mainland east of kalvøya nudist beach fig 1 the main source of pollution in the area is river sandvikselva in particular after rainfall events when combined sewer overflows csos discharge into the river in addition two csos discharge directly to the fjord the catchment area of river sandvikselva include boreal forest 83 which is the upper parts of the catchment and the lower parts are dominated with farmland 6 5 and urban settlement 10 5 nizzetto et al 2016 2 gemss hydrodynamic model the complexity of physical processes governing the transport and fate of an introduced constituent such as bacteria in the ocean circulation system suggests the use of advanced hydrodynamic models ji 2017 for this study the gemss model was used to explore the hydrodynamic and related microbial water quality along the sandvika coastlines gemss is an integrated system of 3d hydrodynamic and transport models embedded in a geographic information and environmental data system gis grid generator and editor control file generator 2 d and 3 d post processing viewers and meteorological and flow data processor to support 3 d modelling the model is able to simulate horizontal and vertical distributions of water velocities and temperature salinity water surface elevations and water quality in rivers lakes reservoir estuaries and coastal water bodies at different spatio temporal resolution entrix et al 2001 kolluru et al 2014 the model has been applied in different regions for various water quality problems dargahi and setegn 2011 goetchius and salmun 2002 na and park 2006 wu et al 2001 the gemss model uses gllvht generalized longitudinal lateral vertical hydrodynamic and transport that computes time varying velocities water surface elevations and water quality constituent concentrations in different water bodies erm 2006 the hydrodynamic and transport relationships used in gllvht was developed from the horizontal momentum balance continuity constituent transport and the equation of state edinger and buchak 1980 the details of the model can be found in the technical documentation of gemss erm 2006 and also a detailed description of the model and its application can be found in the per reviewed publications dargahi and cvetkovic 2011 entrix et al 2001 kolluru et al 2014 3 boundary conditions and model application the horizontal and vertical model domains were defined from the shorelines and the bathymetry data the inner oslofjord fig 2 was divided in calculation cells horizontally the cells were of variable size the vertical layers were 1 m thick down to 20 m below surface and thereafter 10 m thick the horizontal resolution was more detailed in the sandvika area that was of special interest in this research in this area the average horizontal grid size was around 100 m 100 m for each cell the results were calculated forward in time with steps of some minutes the input data for the hydrodynamic model calibration and simulation were obtained from the norwegian meteorological institute eklima the norwegian marine data centre bærum municipality and direct observation the data set included flow data river discharge and combined sewer overflow cso forced meteorological data air temperature dew point temperature seawater temperature cloud cover pressure wind speed and wind direction and water quality parameters temperature salinity and e coli table 1 some small streams flow into the sandvika beach but only sandviksilva river that have significant discharge and two small csos discharging directly to the fjord were included in the model as point source inflow e coli concentrations and corresponding water flows monitored in the river and csos were used as an input to the model for the two small csos the registered time of overflow were used as input to the model assuming that 50 of the sewage was discharged in this period the water level difference mainly due to tides at the southern open boundary was about 1 m moreover oslo and bærum municipality were regularly monitored water flow and faecal indicator bacteria in the rivers around oslofjord and the data were utilized for this modelling for this study e coli were monitored in the sandvika beaches during and after the precipitation table 2 and both discharges and e coli concentrations in the sandviksilva river and csos were used as an input for this model 4 model simulation first the model was validated by comparing observed e coli concentration against modelled values afterwards simulation were conducted for three conditions 1 after rainfall event 2 boat discharge scenario 3 wind direction scenarios microbial contamination of the recreational beaches was studied during and after rainfall events during the summer 2014 we used two scenarios to separately assess the impact of boat sewage discharge and wind directions on the recreational beaches water quality the boat discharge scenario was if a single boat with 200 litre toilet tank discharge its sewage at 300 m from the nearest beach assuming e coli concentration is 3 107 mpn 100 ml equivalent to one day production of e coli from four persons al baz et al 2008 the wind direction scenario was developed by adjusting the wind input data set which was carried out by tuning all winds into one direction using the average wind speed for all 5 water quality modelling results 5 1 model validation model calibration in this hydrodynamic modelling is the processes of finding a set of optimal variables to yield the best agreement between the predicted and observed variable of interest the model was calibrated by making minor adjustments to the boundary conditions and by adjusting the chezy friction coefficient comparisons of the observed and computed salinity level was made to evaluate the performance of the calibration processes a good agreement observed between observed and computed values of salinity during the period of calibration this confirms that the model calculates the overall water movements in the fjord in a realistic way tjomsland et al 2014 to ensure that the simulated spatio temporal spreading of e coli at the beach sites was realistic the model results was validated by comparing the simulated e coli concentrations with monitored data for four consecutive days after the rainfall event at all beach sites model validation was based on the statistical comparison of daily observations of e coli and the corresponding model simulation results summarized for all beaches and shown in table 3 the value of nash sutcliffe coefficient which ranges from to one was 0 36 and the relative volume of error was 8 4 which was less than 10 suggesting reasonable close agreement between observed and simulated e coli concentration the error for minimum value was much higher compared with the maximum value 5 2 simulation of the spreading of e coli after the rainfall event the two main sources of faecal contamination of the sandvika beaches that were considered in this work were the river sandvikselva and a csos discharging close to høvikodden beach in addition swan droppings at each beach site were included while other potential minor sources were ignored the simulations showed that the impact of swan faeces was negligible due to the dilution effect to be able to model the local impact of swan faces a much denser grid than 100 100 m is required analysis of water samples showed a significant impact of swan faeces on the local water quality the survival of e coli after it is discharged into coastal water depends on many abiotic and biotic factors like sunlight temperature salinity competitive bacteria viruses predators etc rozen and belkin 2001 stewart et al 2008 to illustrate how the different decay rates may affect the simulated concentration at the beaches e coli was given two different decay coefficients k 0 7 and k 0 1 representing half life time of 1 day and 1 week representing the sensitive and resistance organisms the spreading of e coli from the sources into the beach areas were simulated for the consecutive three days after the rainfall event and the daily average e coli concentration were plotted for each decay rate coefficient as shown in fig 3 according to the simulation results the daily average e coli concentration one day after the rainfall event was much higher than the second and the third days at all beaches and the magnitude difference was highest in the case of kalvøya small beach followed by kalvøya big and kadettangen beaches in addition the impact of the microbial decay rate coefficient on the daily average e coli concentration was substantial if we take kadettangen and kalvøya small beaches as an example the change in half life time from 1 day to 1 week resulted in an increase in daily average e coli concentration by 38 6 95 0 and 146 7 at kadettangen beach and 17 3 44 9 and 61 1 at kalvøya small beach for the first the second and the third days respectively the simulation results of the spreading of e coli at the beach sites in graphics form for the top 1 m depth are shown in fig 4 as we can see from the figure the first three hours after the heavy rainfall event the e coli dispersion was limited only to the surrounding area of river sandvikselva and the river mouth however 24 h after the rainfall event that caused increased discharges of e coli via the river the affected coastal area was increased and then the concentration was gradually reduced until the end of the third day 5 3 the vertical distribution of e coli concentration at the beaches the stratification of the e coli concentration is complicated by its temporal and spatial variations within and among the beaches water column in order to simplify the presentation of the simulation result the vertical distribution of the e coli concentration at a specific time 15 00 the day after the rainfall event at two beaches is shown as an example in fig 5 as shown in the plot the situation was quite different at the two beaches e coli stratification had a two layer structure in the case of høvikodden surface layer 0 3 5 m depth and the bottom layer 3 5 7 5 m depth the bottom layer e coli concentration was increased from 64 mpn 100 ml at 3 5 m to 950 mpn 100 ml at 7 5 m depth while the surface layer varied from 64 mpn 100 ml at 3 5 m to 150 mpn 100 ml at the surface the highest e coli concentration at the bottom layer was caused by the csos discharging to the deep water around the høvikodden in the case of kadettangen beach the depth is relatively shallow and the e coli concentration decreased with depth from 495 mpn 100 ml at the surface to 425 mpn 100 ml at 1 5 m depth 5 4 scenario with discharge from a septic tank from a boat in the inner oslo fjord there are several thousand private boats yachts as the number of boats and beach users increases through time the pressure on the water quality along the coastal beaches increase and need proper protection measures the spreading of e coli from the discharge of boat sewage was simulated in order to investigate its impact on the recreational water quality of the beaches under different situations the distance between the discharging point and the beaches 300 m as the minimum required distance from the mainland according to the regulation of boat sewage discharge in the oslo fjord the simulation result showed that the discharge of 200 liter sewage with 3 107 e coli per 100 ml will most probably affect the nearby beaches by relatively low levels of e coli 20 24 mpn 100 ml fig 6 in this study the realistic simulation of e coli concentration from the boat discharge scenario could severely limited by the constraints on coarse spatial resolution therefore relatively smaller resolution the effect of different volume of discharge from different distance and directions could be investigated in the future study 5 5 scenarios with different wind directions the key factors for the spreading of pollutants in the coastal environments are wind and current and the influence of wind on the spreading of microbial pollutants because of ocean circulation was an important aspect of this hydrodynamics study in this regard the spreading of e coli from its source was investigated using different wind directions scenarios in these simulations the four scenarios were n s e w winds representing wind blowing to north south east and west respectively simulation using the actual observation was denoted by natural simulation in fig 7 a relative magnitude of simulated e coli concentration associated with the scenarios with different wind directions are presented different wind directions was shown to have various impacts on the spreading of e coli in the study area and as we can see from the fig 7 wind blowing to west affected kadettangen beach more than høvikodden and kalvøya nudist beach whereas wind that were blowing to south in the same direction as the pollution source flow was the predominant wind direction that affected all the beaches sites these simulations demonstrated that the effect of wind direction depended on the location of the beaches relative to the main pollution source and in this case the river sandvikselva was the main source of pollution 6 conclusion for beaches exposed to short term pollution during after heavy rainfall events it is useful to know the main factors affecting the water quality to make decisions about whether to warn against swimming or not and eventually for how many days to study this the three dimensional gemss hydrodynamic model was set up for the inner oslofjord and successfully applied to simulate the spatial and temporal spreading of e coli after a heavy rainfall event in the sandvika area the model was used to demonstrate the impact of different wind directions on the spreading of e coli as well as for investigating the effect of a discharge from a septic tank on a boat the results of the simulations lead to the following conclusions 1 the risk of microbial contamination was high after one day of heavy rainfall as compared with the second and third days and the level of risk was highest at kalvøya small beach due to the position of the beach which is located close to the river inlet 2 the risk of microbial contamination of the local beaches from a boat emptying the septic tank at 300 m distance from the beaches could substantial although minor increase in e coli was resulted in the simulation however the simulation could severely limited by the constraints on coarse spatial resolution therefore relatively smaller resolution the effect of different volume of discharge from different distance and directions recommended in the future study 3 the spreading of microbial contaminants from its source highly depended on wind speed and direction and the degree of pollution depends on the location of the beach relative to the source of pollution 4 hydrodynamic modelling offers a useful tool to understand the spatial temporal spreading of microbial pathogens at recreational beaches in order to prioritize mitigation measures for the beach management strategies acknowledgments the study was financially supported by regionale forskningsfond hovedstaden norway through the waterqualitytools project 217576 97227 and by niva s strategic institute initiative climate effects from mountains to fjords contract no 208279 the authors gratefully acknowledge lisbeth sloth and helle frodahl bærum municipality for providing information about sewage overflows and discharges vegard nilsen and melesse eshetu norwegian university of life sciences norway for their useful discussions and input during data analysis 
